[
  {
    "id": "http://arxiv.org/abs/2410.19816v5",
    "title": "DivShift: Exploring Domain-Specific Distribution Shifts in Large-Scale, Volunteer-Collected Biodiversity Datasets",
    "authors": [
      "Elena Sierra",
      "Lauren E. Gillespie",
      "Salim Soltani",
      "Moises Exposito-Alonso",
      "Teja Kattenborn"
    ],
    "abstract": "Large-scale, volunteer-collected datasets of community-identified natural\nworld imagery like iNaturalist have enabled marked performance gains for\nfine-grained visual classification of species using machine learning methods.\nHowever, such data -- sometimes referred to as citizen science data -- are\nopportunistic and lack a structured sampling strategy. This volunteer-collected\nbiodiversity data contains geographic, temporal, taxonomic, observers, and\nsociopolitical biases that can have significant effects on biodiversity model\nperformance, but whose impacts are unclear for fine-grained species recognition\nperformance. Here we introduce Diversity Shift (DivShift), a framework for\nquantifying the effects of domain-specific distribution shifts on machine\nlearning model performance. To diagnose the performance effects of biases\nspecific to volunteer-collected biodiversity data, we also introduce DivShift -\nNorth American West Coast (DivShift-NAWC), a curated dataset of almost 7.5\nmillion iNaturalist images across the western coast of North America\npartitioned across five types of expert-verified bias. We compare species\nrecognition performance across these bias partitions using a diverse variety of\nspecies- and ecosystem-focused accuracy metrics. We observe that these biases\nconfound model performance less than expected from the underlying label\ndistribution shift, and that more data leads to better model performance but\nthe magnitude of these improvements are bias-specific. These findings imply\nthat while the structure within natural world images provides generalization\nimprovements for biodiversity monitoring tasks, the biases present in\nvolunteer-collected biodiversity data can also affect model performance; thus\nthese models should be used with caution in downstream biodiversity monitoring\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.19816v5",
    "published": "2024-10-17T23:56:30+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14089v1",
    "title": "MMAD-Purify: A Precision-Optimized Framework for Efficient and Scalable Multi-Modal Attacks",
    "authors": [
      "Xinxin Liu",
      "Zhongliang Guo",
      "Siyuan Huang",
      "Chun Pong Lau"
    ],
    "abstract": "Neural networks have achieved remarkable performance across a wide range of\ntasks, yet they remain susceptible to adversarial perturbations, which pose\nsignificant risks in safety-critical applications. With the rise of\nmultimodality, diffusion models have emerged as powerful tools not only for\ngenerative tasks but also for various applications such as image editing,\ninpainting, and super-resolution. However, these models still lack robustness\ndue to limited research on attacking them to enhance their resilience.\nTraditional attack techniques, such as gradient-based adversarial attacks and\ndiffusion model-based methods, are hindered by computational inefficiencies and\nscalability issues due to their iterative nature. To address these challenges,\nwe introduce an innovative framework that leverages the distilled backbone of\ndiffusion models and incorporates a precision-optimized noise predictor to\nenhance the effectiveness of our attack framework. This approach not only\nenhances the attack's potency but also significantly reduces computational\ncosts. Our framework provides a cutting-edge solution for multi-modal\nadversarial attacks, ensuring reduced latency and the generation of\nhigh-fidelity adversarial examples with superior success rates. Furthermore, we\ndemonstrate that our framework achieves outstanding transferability and\nrobustness against purification defenses, outperforming existing gradient-based\nattack models in both effectiveness and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2410.14089v1",
    "published": "2024-10-17T23:52:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14088v1",
    "title": "Overcoming Memory Constraints in Quantum Circuit Simulation with a High-Fidelity Compression Framework",
    "authors": [
      "Boyuan Zhang",
      "Bo Fang",
      "Fanjiang Ye",
      "Yida Gu",
      "Nathan Tallent",
      "Guangming Tan",
      "Dingwen Tao"
    ],
    "abstract": "Full-state quantum circuit simulation requires exponentially increased memory\nsize to store the state vector as the number of qubits scales, presenting\nsignificant limitations in classical computing systems. Our paper introduces\nBMQSim, a novel state vector quantum simulation framework that employs lossy\ncompression to address the memory constraints on graphics processing unit (GPU)\nmachines. BMQSim effectively tackles four major challenges for state-vector\nsimulation with compression: frequent compression/decompression, high memory\nmovement overhead, lack of dedicated error control, and unpredictable memory\nspace requirements. Our work proposes an innovative strategy of circuit\npartitioning to significantly reduce the frequency of compression occurrences.\nWe introduce a pipeline that seamlessly integrates compression with data\nmovement while concealing its overhead. Additionally, BMQSim incorporates the\nfirst GPU-based lossy compression technique with point-wise error control.\nFurthermore, BMQSim features a two-level memory management system, ensuring\nefficient and stable execution. Our evaluations demonstrate that BMQSim can\nsimulate the same circuit with over 10 times less memory usage on average,\nachieving fidelity over 0.99 and maintaining comparable simulation time to\nother state-of-the-art simulators.",
    "pdf_url": "http://arxiv.org/pdf/2410.14088v1",
    "published": "2024-10-17T23:48:43+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2410.14087v1",
    "title": "Your Interest, Your Summaries: Query-Focused Long Video Summarization",
    "authors": [
      "Nirav Patel",
      "Payal Prajapati",
      "Maitrik Shah"
    ],
    "abstract": "Generating a concise and informative video summary from a long video is\nimportant, yet subjective due to varying scene importance. Users' ability to\nspecify scene importance through text queries enhances the relevance of such\nsummaries. This paper introduces an approach for query-focused video\nsummarization, aiming to align video summaries closely with user queries. To\nthis end, we propose the Fully Convolutional Sequence Network with Attention\n(FCSNA-QFVS), a novel approach designed for this task. Leveraging temporal\nconvolutional and attention mechanisms, our model effectively extracts and\nhighlights relevant content based on user-specified queries. Experimental\nvalidation on a benchmark dataset for query-focused video summarization\ndemonstrates the effectiveness of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2410.14087v1",
    "published": "2024-10-17T23:37:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14086v4",
    "title": "In-context learning and Occam's razor",
    "authors": [
      "Eric Elmoznino",
      "Tom Marty",
      "Tejas Kasetty",
      "Leo Gagnon",
      "Sarthak Mittal",
      "Mahan Fathi",
      "Dhanya Sridhar",
      "Guillaume Lajoie"
    ],
    "abstract": "A central goal of machine learning is generalization. While the No Free Lunch\nTheorem states that we cannot obtain theoretical guarantees for generalization\nwithout further assumptions, in practice we observe that simple models which\nexplain the training data generalize best: a principle called Occam's razor.\nDespite the need for simple models, most current approaches in machine learning\nonly minimize the training error, and at best indirectly promote simplicity\nthrough regularization or architecture design. Here, we draw a connection\nbetween Occam's razor and in-context learning: an emergent ability of certain\nsequence models like Transformers to learn at inference time from past\nobservations in a sequence. In particular, we show that the next-token\nprediction loss used to train in-context learners is directly equivalent to a\ndata compression technique called prequential coding, and that minimizing this\nloss amounts to jointly minimizing both the training error and the complexity\nof the model that was implicitly learned from context. Our theory and the\nempirical experiments we use to support it not only provide a normative account\nof in-context learning, but also elucidate the shortcomings of current\nin-context learning methods, suggesting ways in which they can be improved. We\nmake our code available at https://github.com/3rdCore/PrequentialCode.",
    "pdf_url": "http://arxiv.org/pdf/2410.14086v4",
    "published": "2024-10-17T23:37:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14085v1",
    "title": "The 2-divisibility of divisors on K3 surfaces in characteristic 2",
    "authors": [
      "Toshiyuki Katsura",
      "Shigeyuki Kondō",
      "Matthias Schütt"
    ],
    "abstract": "We show that K3 surfaces in characteristic 2 can admit sets of $n$ disjoint\nsmooth rational curves whose sum is divisible by 2 in the Picard group, for\neach $n=8,12,16,20$. More precisely, all values occur on supersingular K3\nsurfaces, with exceptions only at Artin invariants 1 and 10, while on K3\nsurfaces of finite height, only $n=8$ is possible.",
    "pdf_url": "http://arxiv.org/pdf/2410.14085v1",
    "published": "2024-10-17T23:37:04+00:00",
    "categories": [
      "math.AG",
      "cs.CR",
      "14J28 (Primary), 14C20, 14J27 (Secondary)"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14751v1",
    "title": "Cthulhu: An Open Source Molecular and Atomic Cross Section Computation Code for Substellar Atmospheres",
    "authors": [
      "Arnav Agrawal",
      "Ryan J. MacDonald"
    ],
    "abstract": "Atmospheric studies of exoplanets and brown dwarfs are a cutting-edge and\nrapidly evolving area of astrophysics research. Calculating models of exoplanet\nor brown dwarf spectra requires knowledge of the wavelength-dependent\nabsorption of light (cross sections) by the molecules and atoms in the\natmosphere. Here we introduce Cthulhu, a pure Python package that rapidly\ncalculates cross sections from atomic and molecular line lists. Cthulhu\nincludes modules to automatically download molecular line lists from online\ndatabases (e.g. ExoMol and HITRAN) and compute cross sections on a\nuser-specified temperature, pressure, and wavenumber grid. Cthulhu requires\nonly CPUs and can run on a user's laptop (for smaller line lists with < 100\nmillion lines) or on a large cluster in parallel (for many billion lines).\nCthulhu includes in-depth Jupyter tutorials in the online documentation.\nFinally, Cthulhu can be used as an educational tool to demystify the process of\nmaking cross sections for atmospheric models.",
    "pdf_url": "http://arxiv.org/pdf/2410.14751v1",
    "published": "2024-10-17T23:35:21+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.14084v1",
    "title": "Self Supervised Deep Learning for Robot Grasping",
    "authors": [
      "Danyal Saqib",
      "Wajahat Hussain"
    ],
    "abstract": "Learning Based Robot Grasping currently involves the use of labeled data.\nThis approach has two major disadvantages. Firstly, labeling data for grasp\npoints and angles is a strenuous process, so the dataset remains limited.\nSecondly, human labeling is prone to bias due to semantics.\n  In order to solve these problems we propose a simpler self-supervised robotic\nsetup, that will train a Convolutional Neural Network (CNN). The robot will\nlabel and collect the data during the training process. The idea is to make a\nrobot that is less costly, small and easily maintainable in a lab setup. The\nrobot will be trained on a large data set for several hundred hours and then\nthe trained Neural Network can be mapped onto a larger grasping robot.",
    "pdf_url": "http://arxiv.org/pdf/2410.14084v1",
    "published": "2024-10-17T23:26:55+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.14083v1",
    "title": "SAMReg: SAM-enabled Image Registration with ROI-based Correspondence",
    "authors": [
      "Shiqi Huang",
      "Tingfa Xu",
      "Ziyi Shen",
      "Shaheer Ullah Saeed",
      "Wen Yan",
      "Dean Barratt",
      "Yipeng Hu"
    ],
    "abstract": "This paper describes a new spatial correspondence representation based on\npaired regions-of-interest (ROIs), for medical image registration. The distinct\nproperties of the proposed ROI-based correspondence are discussed, in the\ncontext of potential benefits in clinical applications following image\nregistration, compared with alternative correspondence-representing approaches,\nsuch as those based on sampled displacements and spatial transformation\nfunctions. These benefits include a clear connection between learning-based\nimage registration and segmentation, which in turn motivates two cases of image\nregistration approaches using (pre-)trained segmentation networks. Based on the\nsegment anything model (SAM), a vision foundation model for segmentation, we\ndevelop a new registration algorithm SAMReg, which does not require any\ntraining (or training data), gradient-based fine-tuning or prompt engineering.\nThe proposed SAMReg models are evaluated across five real-world applications,\nincluding intra-subject registration tasks with cardiac MR and lung CT,\nchallenging inter-subject registration scenarios with prostate MR and retinal\nimaging, and an additional evaluation with a non-clinical example with aerial\nimage registration. The proposed methods outperform both intensity-based\niterative algorithms and DDF-predicting learning-based networks across tested\nmetrics including Dice and target registration errors on anatomical structures,\nand further demonstrates competitive performance compared to weakly-supervised\nregistration approaches that rely on fully-segmented training data. Open source\ncode and examples are available at: https://github.com/sqhuang0103/SAMReg.git.",
    "pdf_url": "http://arxiv.org/pdf/2410.14083v1",
    "published": "2024-10-17T23:23:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14082v1",
    "title": "Interpreting Inflammation Prediction Model via Tag-based Cohort Explanation",
    "authors": [
      "Fanyu Meng",
      "Jules Larke",
      "Xin Liu",
      "Zhaodan Kong",
      "Xin Chen",
      "Danielle Lemay",
      "Ilias Tagkopoulos"
    ],
    "abstract": "Machine learning is revolutionizing nutrition science by enabling systems to\nlearn from data and make intelligent decisions. However, the complexity of\nthese models often leads to challenges in understanding their decision-making\nprocesses, necessitating the development of explainability techniques to foster\ntrust and increase model transparency. An under-explored type of explanation is\ncohort explanation, which provides explanations to groups of instances with\nsimilar characteristics. Unlike traditional methods that focus on individual\nexplanations or global model behavior, cohort explainability bridges the gap by\nproviding unique insights at an intermediate granularity. We propose a novel\nframework for identifying cohorts within a dataset based on local feature\nimportance scores, aiming to generate concise descriptions of the clusters via\ntags. We evaluate our framework on a food-based inflammation prediction model\nand demonstrated that the framework can generate reliable explanations that\nmatch domain knowledge.",
    "pdf_url": "http://arxiv.org/pdf/2410.14082v1",
    "published": "2024-10-17T23:22:59+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14081v5",
    "title": "Reward-free World Models for Online Imitation Learning",
    "authors": [
      "Shangzhe Li",
      "Zhiao Huang",
      "Hao Su"
    ],
    "abstract": "Imitation learning (IL) enables agents to acquire skills directly from expert\ndemonstrations, providing a compelling alternative to reinforcement learning.\nHowever, prior online IL approaches struggle with complex tasks characterized\nby high-dimensional inputs and complex dynamics. In this work, we propose a\nnovel approach to online imitation learning that leverages reward-free world\nmodels. Our method learns environmental dynamics entirely in latent spaces\nwithout reconstruction, enabling efficient and accurate modeling. We adopt the\ninverse soft-Q learning objective, reformulating the optimization process in\nthe Q-policy space to mitigate the instability associated with traditional\noptimization in the reward-policy space. By employing a learned latent dynamics\nmodel and planning for control, our approach consistently achieves stable,\nexpert-level performance in tasks with high-dimensional observation or action\nspaces and intricate dynamics. We evaluate our method on a diverse set of\nbenchmarks, including DMControl, MyoSuite, and ManiSkill2, demonstrating\nsuperior empirical performance compared to existing approaches.",
    "pdf_url": "http://arxiv.org/pdf/2410.14081v5",
    "published": "2024-10-17T23:13:32+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14080v1",
    "title": "FORWARD: Feasibility Oriented Random-Walk Inspired Algorithm for Radial Reconfiguration in Distribution Networks",
    "authors": [
      "Joan Vendrell",
      "Russell Bent",
      "Solmaz Kia"
    ],
    "abstract": "We consider an optimal flow distribution problem in which the goal is to find\na radial configuration that minimizes resistance-induced quadratic distribution\ncosts while ensuring delivery of inputs from multiple sources to all sinks to\nmeet their demands. This problem has critical applications in various\ndistribution systems, such as electricity, where efficient energy flow is\ncrucial for both economic and environmental reasons. Due to its complexity,\nfinding an optimal solution is computationally challenging and NP-hard. In this\npaper, we propose a novel algorithm called FORWARD, which leverages graph\ntheory to efficiently identify feasible configurations in polynomial time. By\ndrawing parallels with random walk processes on electricity networks, our\nmethod simplifies the search space, significantly reducing computational effort\nwhile maintaining performance. The FORWARD algorithm employs a combination of\nnetwork preprocessing, intelligent partitioning, and strategic sampling to\nconstruct radial configurations that meet flow requirements, finding a feasible\nsolution in polynomial time. Numerical experiments demonstrate the\neffectiveness of our approach, highlighting its potential for real-world\napplications in optimizing distribution networks.",
    "pdf_url": "http://arxiv.org/pdf/2410.14080v1",
    "published": "2024-10-17T23:09:32+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.14079v1",
    "title": "PKS 2254+074: A Blazar in Likely Association with the Neutrino Event IceCube-190619A",
    "authors": [
      "Shunhao Ji",
      "Zhongxiang Wang"
    ],
    "abstract": "We report our study of the field of a $\\simeq$0.2 PeV neutrino event\nIC-190619A. This neutrino belongs to Gold events, which more likely have an\nastrophysical origin. Among the two $\\gamma$-ray sources within the neutrino's\npositional uncertainty region, we find that one of them, the BL-Lac--type\nblazar PKS~2254+074, had a $\\gamma$-ray flare at the arrival time of the\nneutrino. The flare is determined to have lasted $\\sim$2.5 yr in a 180-day\nbinned light curve, constructed from the data collected with the Large Area\nTelescope (LAT) onboard {\\it the Fermi Gamma-ray Space Telescope (Fermi)}.\nAccompanying the flare, optical and mid-infrared brightening is also seen. In\naddition, $\\geq$10 GeV high energy photons from the source have been detected,\nsuggesting a hardening of the emission during the flare. Given both the\npositional and temporal coincidence of PKS~2254+074 with IC-190619A, we suggest\nthat this blazar is likely another member of a few recently identified\n(candidate) neutrino-emitting blazars.",
    "pdf_url": "http://arxiv.org/pdf/2410.14079v1",
    "published": "2024-10-17T22:53:47+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.14078v2",
    "title": "Computational Social Choice: Parameterized Complexity and Challenges",
    "authors": [
      "Jiehua Chen",
      "Christian Hatschka",
      "Sofia Simola"
    ],
    "abstract": "We survey two key problems-Multi-Winner Determination and Hedonic Games in\nComputational Social Choice, with a special focus on their parameterized\ncomplexity, and propose some research challenges in the field.",
    "pdf_url": "http://arxiv.org/pdf/2410.14078v2",
    "published": "2024-10-17T22:53:43+00:00",
    "categories": [
      "cs.GT",
      "cs.CC",
      "cs.MA"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2410.14077v2",
    "title": "Inverter Output Impedance Estimation in Power Networks: A Variable Direction Forgetting Recursive-Least-Square Algorithm Based Approach",
    "authors": [
      "Jaesang Park",
      "Alireza Askarian",
      "Srinivasa Salapaka"
    ],
    "abstract": "As inverter-based loads and energy sources become increasingly prevalent,\naccurate estimation of line impedance between inverters and the grid is\nessential for optimizing performance and enhancing control strategies. This\npaper presents a non-invasive method for estimating output-line impedance using\nmeasurements local to the inverter. It provides a specific method for signal\nconditioning of signals measured at the inverter, which makes the measured data\nbetter suited to estimation algorithms. An algorithm based on the Variable\nDirection Forgetting Recursive Least Squares (VDF-RLS) method is introduced,\nwhich leverages these conditioned signals for precise impedance estimation. The\nsignal conditioning process transforms measurements into the direct-quadrature\n(dq) coordinate frame, where the rotating frame frequency is determined to\nfacilitate a simpler and more accurate estimation. This frequency is\nimplemented using a secondary Phase-Locked Loop (PLL) to attenuate grid voltage\nmeasurement variations. By isolating the variation-sensitive q-axis and relying\nsolely on the less sensitive d-axis, the method further minimizes the impact of\nvariations. The VDF-RLS estimation method achieves rapid adaptation while\nensuring stability in the absence of persistent excitation by selectively\ndiscarding outdated data during updates. Proposed conditioning and estimation\nmethods are non-invasive; estimations are solely done using measured outputs,\nand no signal is injected into the power network. Simulation results\ndemonstrate a significant improvement in impedance estimation stability,\nparticularly in low-excitation conditions, where the VDF-RLS method achieves\nmore than three time lower error compared to existing approaches such as\nconstant forgetting RLS and the Kalman filter.",
    "pdf_url": "http://arxiv.org/pdf/2410.14077v2",
    "published": "2024-10-17T22:49:53+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2411.02402v1",
    "title": "Optimal Transport Maps are Good Voice Converters",
    "authors": [
      "Arip Asadulaev",
      "Rostislav Korst",
      "Vitalii Shutov",
      "Alexander Korotin",
      "Yaroslav Grebnyak",
      "Vahe Egiazarian",
      "Evgeny Burnaev"
    ],
    "abstract": "Recently, neural network-based methods for computing optimal transport maps\nhave been effectively applied to style transfer problems. However, the\napplication of these methods to voice conversion is underexplored. In our\npaper, we fill this gap by investigating optimal transport as a framework for\nvoice conversion. We present a variety of optimal transport algorithms designed\nfor different data representations, such as mel-spectrograms and latent\nrepresentation of self-supervised speech models. For the mel-spectogram data\nrepresentation, we achieve strong results in terms of Frechet Audio Distance\n(FAD). This performance is consistent with our theoretical analysis, which\nsuggests that our method provides an upper bound on the FAD between the target\nand generated distributions. Within the latent space of the WavLM encoder, we\nachived state-of-the-art results and outperformed existing methods even with\nlimited reference speaker data.",
    "pdf_url": "http://arxiv.org/pdf/2411.02402v1",
    "published": "2024-10-17T22:48:53+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.14076v1",
    "title": "popclass: a python package for classifying microlensing events",
    "authors": [
      "Greg Sallaberry",
      "Zofia Kaczmarek",
      "Peter McGill",
      "Scott E. Perkins",
      "William A. Dawson",
      "Caitlin G. Begbie"
    ],
    "abstract": "popclass is a python package that provides a flexible, probabilistic\nframework for classifying the lens of a gravitational microlensing event.\npopclass allows a user to match characteristics of a microlensing signal to a\nsimulation of the Galaxy to calculate lens type probabilities for an event.\nConstraints on any microlensing signal characteristics and any Galactic model\ncan be used. popclass comes with an interface to common inference libraries for\nmicrolensing signal constraints, pre-loaded Galactic models, plotting\nfunctionality, and classification uncertainty quantification methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.14076v1",
    "published": "2024-10-17T22:48:42+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.14075v1",
    "title": "FedPAE: Peer-Adaptive Ensemble Learning for Asynchronous and Model-Heterogeneous Federated Learning",
    "authors": [
      "Brianna Mueller",
      "W. Nick Street",
      "Stephen Baek",
      "Qihang Lin",
      "Jingyi Yang",
      "Yankun Huang"
    ],
    "abstract": "Federated learning (FL) enables multiple clients with distributed data\nsources to collaboratively train a shared model without compromising data\nprivacy. However, existing FL paradigms face challenges due to heterogeneity in\nclient data distributions and system capabilities. Personalized federated\nlearning (pFL) has been proposed to mitigate these problems, but often requires\na shared model architecture and a central entity for parameter aggregation,\nresulting in scalability and communication issues. More recently,\nmodel-heterogeneous FL has gained attention due to its ability to support\ndiverse client models, but existing methods are limited by their dependence on\na centralized framework, synchronized training, and publicly available\ndatasets. To address these limitations, we introduce Federated Peer-Adaptive\nEnsemble Learning (FedPAE), a fully decentralized pFL algorithm that supports\nmodel heterogeneity and asynchronous learning. Our approach utilizes a\npeer-to-peer model sharing mechanism and ensemble selection to achieve a more\nrefined balance between local and global information. Experimental results show\nthat FedPAE outperforms existing state-of-the-art pFL algorithms, effectively\nmanaging diverse client capabilities and demonstrating robustness against\nstatistical heterogeneity.",
    "pdf_url": "http://arxiv.org/pdf/2410.14075v1",
    "published": "2024-10-17T22:47:19+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14074v1",
    "title": "Be My Donor. Transfer the NLP Datasets Between the Languages Using LLM",
    "authors": [
      "Dmitrii Popov",
      "Egor Terentev",
      "Igor Buyanov"
    ],
    "abstract": "In this work, we investigated how one can use the LLM to transfer the dataset\nand its annotation from one language to another. This is crucial since sharing\nthe knowledge between different languages could boost certain underresourced\ndirections in the target language, saving lots of efforts in data annotation or\nquick prototyping. We experiment with English and Russian pairs translating the\nDEFT corpus. This corpus contains three layers of annotation dedicated to\nterm-definition pair mining, which is a rare annotation type for Russian. We\nprovide a pipeline for the annotation transferring using ChatGPT3.5-turbo and\nLlama-3.1-8b as core LLMs. In the end, we train the BERT-based models on the\ntranslated dataset to establish a baseline.",
    "pdf_url": "http://arxiv.org/pdf/2410.14074v1",
    "published": "2024-10-17T22:46:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14073v3",
    "title": "Digesting Gibbs Sampling Using R",
    "authors": [
      "Mahdi Teimouri"
    ],
    "abstract": "In general, the statistical simulation approaches are referred to as the\nMonte Carlo methods as a whole. The broad class of the Monte Carlo methods\ninvolves the Markov chain Monte Carlo (MCMC) techniques that attract the\nattention of researchers from a wide variety of study fields. The main focus of\nthis report is to provide a framework for all users who are interested in\nimplementing the MCMC approaches in their investigations, especially the Gibbs\nsampling. I have tried, if possible, to eliminate the proofs, but reader is\nexpected to know some topics in elementary calculus (including mathematical\nfunction, limit, derivative, partial derivative, simple integral) and\nstatistics (including random variables, expected value and variance, moment\ngenerating function, multivariate distribution, distribution of a functions of\nrandom variable, and the central limit theorem).",
    "pdf_url": "http://arxiv.org/pdf/2410.14073v3",
    "published": "2024-10-17T22:46:19+00:00",
    "categories": [
      "stat.CO"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.14072v1",
    "title": "Efficient Vision-Language Models by Summarizing Visual Tokens into Compact Registers",
    "authors": [
      "Yuxin Wen",
      "Qingqing Cao",
      "Qichen Fu",
      "Sachin Mehta",
      "Mahyar Najibi"
    ],
    "abstract": "Recent advancements in vision-language models (VLMs) have expanded their\npotential for real-world applications, enabling these models to perform complex\nreasoning on images. In the widely used fully autoregressive transformer-based\nmodels like LLaVA, projected visual tokens are prepended to textual tokens.\nOftentimes, visual tokens are significantly more than prompt tokens, resulting\nin increased computational overhead during both training and inference. In this\npaper, we propose Visual Compact Token Registers (Victor), a method that\nreduces the number of visual tokens by summarizing them into a smaller set of\nregister tokens. Victor adds a few learnable register tokens after the visual\ntokens and summarizes the visual information into these registers using the\nfirst few layers in the language tower of VLMs. After these few layers, all\nvisual tokens are discarded, significantly improving computational efficiency\nfor both training and inference. Notably, our method is easy to implement and\nrequires a small number of new trainable parameters with minimal impact on\nmodel performance. In our experiment, with merely 8 visual registers--about 1%\nof the original tokens--Victor shows less than a 4% accuracy drop while\nreducing the total training time by 43% and boosting the inference throughput\nby 3.3X.",
    "pdf_url": "http://arxiv.org/pdf/2410.14072v1",
    "published": "2024-10-17T22:45:13+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14071v2",
    "title": "Appropriateness of the McNamara and Buland's (2004) methodology for computing frequency-dependent seismic power",
    "authors": [
      "Sebin John",
      "Michael E. West"
    ],
    "abstract": "The methodology developed by McNamara and Buland (2004) for computing Power\nSpectral Densities (PSDs) has gained popularity due to its low computational\ncost and reduction of spectral variance. This methodology is widely used in\nseismic noise studies and station performance evaluations and is implemented in\ntools like ISPAQ, MUSTANG, and PQLX. However, concerns have been raised about\nits appropriateness in certain contexts, particularly when high-resolution\nspectral detail is required. This study evaluates McNamara and Buland's\nmethodology by comparing it with Welch's method across three Alaskan stations\nwith differing microseism conditions. When calculating seismic power across a\nband of frequencies--for example, the 5-10s secondary microseism--we find that\nboth methodologies produce time series with nearly identical trends, albeit\nwith slight differences in absolute power values. Our results demonstrate that\nMcNamara and Buland's methodology is fully appropriate for certain\napplications, specifically ones that rely on averaged seismic energy over a\nfrequency band as opposed to a single discrete frequency.",
    "pdf_url": "http://arxiv.org/pdf/2410.14071v2",
    "published": "2024-10-17T22:38:05+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.14070v1",
    "title": "FaceSaliencyAug: Mitigating Geographic, Gender and Stereotypical Biases via Saliency-Based Data Augmentation",
    "authors": [
      "Teerath Kumar",
      "Alessandra Mileo",
      "Malika Bendechache"
    ],
    "abstract": "Geographical, gender and stereotypical biases in computer vision models pose\nsignificant challenges to their performance and fairness. {In this study, we\npresent an approach named FaceSaliencyAug aimed at addressing the gender bias\nin} {Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs).\nLeveraging the salient regions} { of faces detected by saliency, the propose\napproach mitigates geographical and stereotypical biases } {in the datasets.\nFaceSaliencyAug} randomly selects masks from a predefined search space and\napplies them to the salient region of face images, subsequently restoring the\noriginal image with masked salient region. {The proposed} augmentation strategy\nenhances data diversity, thereby improving model performance and debiasing\neffects. We quantify dataset diversity using Image Similarity Score (ISS)\nacross five datasets, including Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled\nFaces in the Wild (LFW), UTK Faces, and Diverse Dataset. The proposed approach\ndemonstrates superior diversity metrics, as evaluated by ISS-intra and\nISS-inter algorithms. Furthermore, we evaluate the effectiveness of our\napproach in mitigating gender bias on CEO, Engineer, Nurse, and School Teacher\ndatasets. We use the Image-Image Association Score (IIAS) to measure gender\nbias in these occupations. Our experiments reveal a reduction in gender bias\nfor both CNNs and ViTs, indicating the efficacy of our method in promoting\nfairness and inclusivity in computer vision models.",
    "pdf_url": "http://arxiv.org/pdf/2410.14070v1",
    "published": "2024-10-17T22:36:52+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14069v1",
    "title": "Rethinking Optimal Transport in Offline Reinforcement Learning",
    "authors": [
      "Arip Asadulaev",
      "Rostislav Korst",
      "Alexander Korotin",
      "Vage Egiazarian",
      "Andrey Filchenkov",
      "Evgeny Burnaev"
    ],
    "abstract": "We propose a novel algorithm for offline reinforcement learning using optimal\ntransport. Typically, in offline reinforcement learning, the data is provided\nby various experts and some of them can be sub-optimal. To extract an efficient\npolicy, it is necessary to \\emph{stitch} the best behaviors from the dataset.\nTo address this problem, we rethink offline reinforcement learning as an\noptimal transportation problem. And based on this, we present an algorithm that\naims to find a policy that maps states to a \\emph{partial} distribution of the\nbest expert actions for each given state. We evaluate the performance of our\nalgorithm on continuous control problems from the D4RL suite and demonstrate\nimprovements over existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.14069v1",
    "published": "2024-10-17T22:36:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14067v2",
    "title": "Provable Benefits of Complex Parameterizations for Structured State Space Models",
    "authors": [
      "Yuval Ran-Milo",
      "Eden Lumbroso",
      "Edo Cohen-Karlik",
      "Raja Giryes",
      "Amir Globerson",
      "Nadav Cohen"
    ],
    "abstract": "Structured state space models (SSMs), the core engine behind prominent neural\nnetworks such as S4 and Mamba, are linear dynamical systems adhering to a\nspecified structure, most notably diagonal. In contrast to typical neural\nnetwork modules, whose parameterizations are real, SSMs often use complex\nparameterizations. Theoretically explaining the benefits of complex\nparameterizations for SSMs is an open problem. The current paper takes a step\ntowards its resolution, by establishing formal gaps between real and complex\ndiagonal SSMs. Firstly, we prove that while a moderate dimension suffices in\norder for a complex SSM to express all mappings of a real SSM, a much higher\ndimension is needed for a real SSM to express mappings of a complex SSM.\nSecondly, we prove that even if the dimension of a real SSM is high enough to\nexpress a given mapping, typically, doing so requires the parameters of the\nreal SSM to hold exponentially large values, which cannot be learned in\npractice. In contrast, a complex SSM can express any given mapping with\nmoderate parameter values. Experiments corroborate our theory, and suggest a\npotential extension of the theory that accounts for selectivity, a new\narchitectural feature yielding state of the art performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.14067v2",
    "published": "2024-10-17T22:35:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14068v1",
    "title": "$q$-Hypergeometric orthogonal polynomials with $q=-1$",
    "authors": [
      "Luis Verde-Star"
    ],
    "abstract": "We obtain some properties of a class of $q$-hypergeometric orthogonal\npolynomials with $q=-1$, described by a uniform parametrization of the\nrecurrence coefficients. We show that our class contains the Bannai-Ito\npolynomials and other known -1 polynomials. We introduce some new examples of\n-1 polynomials and also obtain matrix realizations of the Bannai-Ito algebra.",
    "pdf_url": "http://arxiv.org/pdf/2410.14068v1",
    "published": "2024-10-17T22:35:50+00:00",
    "categories": [
      "math.CA",
      "33C45, 33D45"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2411.05851v1",
    "title": "Distribution Hub Optimization: Application of Conditional P-Median Using Road Network Distances",
    "authors": [
      "Faizan Faisal",
      "Zubair Khalid"
    ],
    "abstract": "This paper explores a GIS-based application of the conditional p-median\nproblem (where p = 1) in last-mile delivery logistics. The rapid growth of\ne-commerce in Pakistan has primarily benefited logistics companies, which face\nthe challenge of resolving inefficiencies in the existing infrastructure and\nscaling effectively to meet increasing demand. Addressing these challenges\nwould not only reduce operational costs but also lower carbon footprints. We\npresent an algorithm that utilizes road-network-based distances to determine\nthe optimal location for a new hub facility, a problem known in operations\nresearch as the conditional p-median problem. The algorithm optimizes the\nplacement of a new facility, given q existing facilities. The past delivery\ndata for this research was provided by Muller and Phipps Logistics Pakistan.\nOur method involves constructing a distance matrix between candidate hub\nlocations and past delivery points, followed by a grid search to identify the\noptimal hub location. To simulate the absence of past delivery data, we\nrepeated the process using the population distribution of Lahore. Our results\ndemonstrate a 16% reduction in average delivery distance with the addition of a\nnew hub.",
    "pdf_url": "http://arxiv.org/pdf/2411.05851v1",
    "published": "2024-10-17T22:34:38+00:00",
    "categories": [
      "cs.OH",
      "90B06"
    ],
    "primary_category": "cs.OH"
  },
  {
    "id": "http://arxiv.org/abs/2410.14066v3",
    "title": "Lightweight Correlation-Aware Table Compression",
    "authors": [
      "Mihail Stoian",
      "Alexander van Renen",
      "Jan Kobiolka",
      "Ping-Lin Kuo",
      "Josif Grabocka",
      "Andreas Kipf"
    ],
    "abstract": "The growing adoption of data lakes for managing relational data necessitates\nefficient, open storage formats that provide high scan performance and\ncompetitive compression ratios. While existing formats achieve fast scans\nthrough lightweight encoding techniques, they have reached a plateau in terms\nof minimizing storage footprint. Recently, correlation-aware compression\nschemes have been shown to reduce file sizes further. Yet, current approaches\neither incur significant scan overheads or require manual specification of\ncorrelations, limiting their practicability. We present $\\texttt{Virtual}$, a\nframework that integrates seamlessly with existing open formats to\nautomatically leverage data correlations, achieving substantial compression\ngains while having minimal scan performance overhead. Experiments on data-gov\ndatasets show that $\\texttt{Virtual}$ reduces file sizes by up to 40% compared\nto Apache Parquet.",
    "pdf_url": "http://arxiv.org/pdf/2410.14066v3",
    "published": "2024-10-17T22:28:07+00:00",
    "categories": [
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2410.14065v1",
    "title": "Fourier-Mukai partners of abelian varieties and K3 surfaces in positive and mixed characteristics",
    "authors": [
      "Riku Kurama"
    ],
    "abstract": "We study Fourier-Mukai equivalences of (families of) abelian varieties and K3\nsurfaces in positive and mixed characteristics. We first prove in any\ncharacteristics that Fourier-Mukai partners of abelian varieties are again\nabelian varieties. We subsequently focus on the canonical lifts of ordinary\nabelian varieties and ordinary K3 surfaces. For such schemes, we show that\nFourier-Mukai equivalences on the special fibers can be lifted to the canonical\nlifts. We also prove that the relative Fourier-Mukai partners of the canonical\nlifts are in bijection with the Fourier-Mukai partners of the special fibers.\nWe conclude by demonstrating that the last result can be used to recover the\nordinary case of a result originally proved by Honigs, Lombardi and Tirabassi.",
    "pdf_url": "http://arxiv.org/pdf/2410.14065v1",
    "published": "2024-10-17T22:26:08+00:00",
    "categories": [
      "math.AG",
      "math.NT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14064v1",
    "title": "Countability of relative Fourier-Mukai partners",
    "authors": [
      "Riku Kurama"
    ],
    "abstract": "Anel and To\\\"en proved that a smooth projective complex variety has only\ncountably many smooth projective Fourier-Mukai partners up to isomorphism. This\nis generalized in the Stacks Project to the case where the varieties are smooth\nproper over an arbitrary algebraically closed field. This note will upgrade the\nproof of the latter reference to show that a smooth proper scheme over a\nnoetherian base has only countably many relative Fourier-Mukai partners up to\nisomorphism.",
    "pdf_url": "http://arxiv.org/pdf/2410.14064v1",
    "published": "2024-10-17T22:19:16+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14063v2",
    "title": "On the degrees of regular nut graphs and Cayley nut graphs",
    "authors": [
      "Nino Bašić",
      "Ivan Damnjanović",
      "Patrick W. Fowler"
    ],
    "abstract": "A nut graph is a simple graph for which the adjacency matrix has a single\nzero eigenvalue such that all non-zero kernel eigenvectors have no zero entry.\nIt is known that infinitely many $d$-regular nut graphs exist for $3 \\leq d\n\\leq 12$ and for $d \\geq 4$ such that $d \\equiv 0 \\pmod{4}$. Here it is shown\nthat infinitely many $d$-regular nut graphs exist for each degree $d \\geq 3$.\nMoreover, we prove that there are infinitely many $d$-regular Cayley nut graphs\nfor each even $d \\ge 4$. This implies that we have identified all feasible\ndegrees $d$ for which a $d$-regular Cayley nut graph exists.",
    "pdf_url": "http://arxiv.org/pdf/2410.14063v2",
    "published": "2024-10-17T22:16:27+00:00",
    "categories": [
      "math.CO",
      "05C25, 05C50"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.14062v3",
    "title": "Data-driven rainfall prediction at a regional scale: a case study with Ghana",
    "authors": [
      "Indrajit Kalita",
      "Lucia Vilallonga",
      "Yves Atchade"
    ],
    "abstract": "With a warming planet, tropical regions are expected to experience the brunt\nof climate change, with more intense and more volatile rainfall events.\nCurrently, state-of-the-art numerical weather prediction (NWP) models are known\nto struggle to produce skillful rainfall forecasts in tropical regions of\nAfrica. There is thus a pressing need for improved rainfall forecasting in\nthese regions. Over the last decade or so, the increased availability of\nlarge-scale meteorological datasets and the development of powerful machine\nlearning models have opened up new opportunities for data-driven weather\nforecasting. Focusing on Ghana in this study, we use these tools to develop two\nU-Net convolutional neural network (CNN) models, to predict 24h rainfall at 12h\nand 30h lead-time. The models were trained using data from the ERA5 reanalysis\ndataset, and the GPM-IMERG dataset. A special attention was paid to\ninterpretability. We developed a novel statistical methodology that allowed us\nto probe the relative importance of the meteorological variables input in our\nmodel, offering useful insights into the factors that drive precipitation in\nthe Ghana region. Empirically, we found that our 12h lead-time model has\nperformances that match, and in some accounts are better than the 18h lead-time\nforecasts produced by the ECMWF (as available in the TIGGE dataset). We also\nfound that combining our data-driven model with classical NWP further improves\nforecast accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2410.14062v3",
    "published": "2024-10-17T22:07:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14061v1",
    "title": "Gradual Domain Adaptation via Manifold-Constrained Distributionally Robust Optimization",
    "authors": [
      "Amir Hossein Saberi",
      "Amir Najafi",
      "Ala Emrani",
      "Amin Behjati",
      "Yasaman Zolfimoselo",
      "Mahdi Shadrooy",
      "Abolfazl Motahari",
      "Babak H. Khalaj"
    ],
    "abstract": "The aim of this paper is to address the challenge of gradual domain\nadaptation within a class of manifold-constrained data distributions. In\nparticular, we consider a sequence of $T\\ge2$ data distributions\n$P_1,\\ldots,P_T$ undergoing a gradual shift, where each pair of consecutive\nmeasures $P_i,P_{i+1}$ are close to each other in Wasserstein distance. We have\na supervised dataset of size $n$ sampled from $P_0$, while for the subsequent\ndistributions in the sequence, only unlabeled i.i.d. samples are available.\nMoreover, we assume that all distributions exhibit a known favorable attribute,\nsuch as (but not limited to) having intra-class soft/hard margins. In this\ncontext, we propose a methodology rooted in Distributionally Robust\nOptimization (DRO) with an adaptive Wasserstein radius. We theoretically show\nthat this method guarantees the classification error across all $P_i$s can be\nsuitably bounded. Our bounds rely on a newly introduced {\\it {compatibility}}\nmeasure, which fully characterizes the error propagation dynamics along the\nsequence. Specifically, for inadequately constrained distributions, the error\ncan exponentially escalate as we progress through the gradual shifts.\nConversely, for appropriately constrained distributions, the error can be\ndemonstrated to be linear or even entirely eradicated. We have substantiated\nour theoretical findings through several experimental results.",
    "pdf_url": "http://arxiv.org/pdf/2410.14061v1",
    "published": "2024-10-17T22:07:25+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.14060v1",
    "title": "On Partial Prototype Collapse in the DINO Family of Self-Supervised Methods",
    "authors": [
      "Hariprasath Govindarajan",
      "Per Sidén",
      "Jacob Roll",
      "Fredrik Lindsten"
    ],
    "abstract": "A prominent self-supervised learning paradigm is to model the representations\nas clusters, or more generally as a mixture model. Learning to map the data\nsamples to compact representations and fitting the mixture model simultaneously\nleads to the representation collapse problem. Regularizing the distribution of\ndata points over the clusters is the prevalent strategy to avoid this issue.\nWhile this is sufficient to prevent full representation collapse, we show that\na partial prototype collapse problem still exists in the DINO family of\nmethods, that leads to significant redundancies in the prototypes. Such\nprototype redundancies serve as shortcuts for the method to achieve a marginal\nlatent class distribution that matches the prescribed prior. We show that by\nencouraging the model to use diverse prototypes, the partial prototype collapse\ncan be mitigated. Effective utilization of the prototypes enables the methods\nto learn more fine-grained clusters, encouraging more informative\nrepresentations. We demonstrate that this is especially beneficial when\npre-training on a long-tailed fine-grained dataset.",
    "pdf_url": "http://arxiv.org/pdf/2410.14060v1",
    "published": "2024-10-17T22:06:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.16322v1",
    "title": "SouLLMate: An Application Enhancing Diverse Mental Health Support with Adaptive LLMs, Prompt Engineering, and RAG Techniques",
    "authors": [
      "Qiming Guo",
      "Jinwen Tang",
      "Wenbo Sun",
      "Haoteng Tang",
      "Yi Shang",
      "Wenlu Wang"
    ],
    "abstract": "Mental health issues significantly impact individuals' daily lives, yet many\ndo not receive the help they need even with available online resources. This\nstudy aims to provide diverse, accessible, stigma-free, personalized, and\nreal-time mental health support through cutting-edge AI technologies. It makes\nthe following contributions: (1) Conducting an extensive survey of recent\nmental health support methods to identify prevalent functionalities and unmet\nneeds. (2) Introducing SouLLMate, an adaptive LLM-driven system that integrates\nLLM technologies, Chain, Retrieval-Augmented Generation (RAG), prompt\nengineering, and domain knowledge. This system offers advanced features such as\nRisk Detection and Proactive Guidance Dialogue, and utilizes RAG for\npersonalized profile uploads and Conversational Information Extraction. (3)\nDeveloping novel evaluation approaches for preliminary assessments and risk\ndetection via professionally annotated interview data and real-life suicide\ntendency data. (4) Proposing the Key Indicator Summarization (KIS), Proactive\nQuestioning Strategy (PQS), and Stacked Multi-Model Reasoning (SMMR) methods to\nenhance model performance and usability through context-sensitive response\nadjustments, semantic coherence evaluations, and enhanced accuracy of\nlong-context reasoning in language models. This study contributes to advancing\nmental health support technologies, potentially improving the accessibility and\neffectiveness of mental health care globally.",
    "pdf_url": "http://arxiv.org/pdf/2410.16322v1",
    "published": "2024-10-17T22:04:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14059v3",
    "title": "UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models",
    "authors": [
      "Yuzhe Yang",
      "Yifei Zhang",
      "Yan Hu",
      "Yilin Guo",
      "Ruoli Gan",
      "Yueru He",
      "Mingcong Lei",
      "Xiao Zhang",
      "Haining Wang",
      "Qianqian Xie",
      "Jimin Huang",
      "Honghai Yu",
      "Benyou Wang"
    ],
    "abstract": "This paper introduces the UCFE: User-Centric Financial Expertise benchmark,\nan innovative framework designed to evaluate the ability of large language\nmodels (LLMs) to handle complex real-world financial tasks. UCFE benchmark\nadopts a hybrid approach that combines human expert evaluations with dynamic,\ntask-specific interactions to simulate the complexities of evolving financial\nscenarios. Firstly, we conducted a user study involving 804 participants,\ncollecting their feedback on financial tasks. Secondly, based on this feedback,\nwe created our dataset that encompasses a wide range of user intents and\ninteractions. This dataset serves as the foundation for benchmarking 11 LLMs\nservices using the LLM-as-Judge methodology. Our results show a significant\nalignment between benchmark scores and human preferences, with a Pearson\ncorrelation coefficient of 0.78, confirming the effectiveness of the UCFE\ndataset and our evaluation approach. UCFE benchmark not only reveals the\npotential of LLMs in the financial domain but also provides a robust framework\nfor assessing their performance and user satisfaction.",
    "pdf_url": "http://arxiv.org/pdf/2410.14059v3",
    "published": "2024-10-17T22:03:52+00:00",
    "categories": [
      "q-fin.CP",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "q-fin.CP"
  },
  {
    "id": "http://arxiv.org/abs/2410.20718v1",
    "title": "Lecture II: Communicative Justice and the Distribution of Attention",
    "authors": [
      "Seth Lazar"
    ],
    "abstract": "Algorithmic intermediaries govern the digital public sphere through their\narchitectures, amplification algorithms, and moderation practices. In doing so,\nthey shape public communication and distribute attention in ways that were\npreviously infeasible with such subtlety, speed and scale. From misinformation\nand affective polarisation to hate speech and radicalisation, the many\npathologies of the digital public sphere attest that they could do so better.\nBut what ideals should they aim at? Political philosophy should be able to\nhelp, but existing theories typically assume that a healthy public sphere will\nspontaneously emerge if only we get the boundaries of free expression right.\nThey offer little guidance on how to intentionally constitute the digital\npublic sphere. In addition to these theories focused on expression, we need a\nfurther theory of communicative justice, targeted specifically at the\nalgorithmic intermediaries that shape communication and distribute attention.\nThis lecture argues that political philosophy urgently owes an account of how\nto govern communication in the digital public sphere, and introduces and\ndefends a democratic egalitarian theory of communicative justice.",
    "pdf_url": "http://arxiv.org/pdf/2410.20718v1",
    "published": "2024-10-17T22:03:35+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.14058v1",
    "title": "An AI Guide to Enhance Accessibility of Social Virtual Reality for Blind People",
    "authors": [
      "Jazmin Collins",
      "Kaylah Myranda Nicholson",
      "Yusuf Khadir",
      "Andrea Stevenson Won",
      "Shiri Azenkot"
    ],
    "abstract": "The rapid growth of virtual reality (VR) has led to increased use of social\nVR platforms for interaction. However, these platforms lack adequate features\nto support blind and low vision (BLV) users, posing significant challenges in\nnavigation, visual interpretation, and social interaction. One promising\napproach to these challenges is employing human guides in VR. However, this\napproach faces limitations with a lack of availability of humans to serve as\nguides, or the inability to customize the guidance a user receives from the\nhuman guide. We introduce an AI-powered guide to address these limitations. The\nAI guide features six personas, each offering unique behaviors and appearances\nto meet diverse user needs, along with visual interpretation and navigation\nassistance. We aim to use this AI guide in the future to help us understand BLV\nusers' preferences for guide forms and functionalities.",
    "pdf_url": "http://arxiv.org/pdf/2410.14058v1",
    "published": "2024-10-17T22:02:19+00:00",
    "categories": [
      "cs.HC",
      "cs.ET"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2410.20720v1",
    "title": "Lecture I: Governing the Algorithmic City",
    "authors": [
      "Seth Lazar"
    ],
    "abstract": "A century ago, John Dewey observed that '[s]team and electricity have done\nmore to alter the conditions under which men associate together than all the\nagencies which affected human relationships before our time'. In the last few\ndecades, computing technologies have had a similar effect. Political\nphilosophy's central task is to help us decide how to live together, by\nanalysing our social relations, diagnosing their failings, and articulating\nideals to guide their revision. But these profound social changes have left\nscarcely a dent in the model of social relations that (analytical) political\nphilosophers assume. This essay aims to reverse that trend. It first builds a\nmodel of our novel social relations as they are now, and as they are likely to\nevolved, and then explores how those differences affect our theories of how to\nlive together. I introduce the 'Algorithmic City', the network of\nalgorithmically-mediated social relations, then characterise the intermediary\npower by which it is governed. I show how algorithmic governance raises new\nchallenges for political philosophy concerning the justification of authority,\nthe foundations of procedural legitimacy, and the possibility of justificatory\nneutrality.",
    "pdf_url": "http://arxiv.org/pdf/2410.20720v1",
    "published": "2024-10-17T22:02:06+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.14057v1",
    "title": "Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs",
    "authors": [
      "Simone Conia",
      "Daniel Lee",
      "Min Li",
      "Umar Farooq Minhas",
      "Saloni Potdar",
      "Yunyao Li"
    ],
    "abstract": "Translating text that contains entity names is a challenging task, as\ncultural-related references can vary significantly across languages. These\nvariations may also be caused by transcreation, an adaptation process that\nentails more than transliteration and word-for-word translation. In this paper,\nwe address the problem of cross-cultural translation on two fronts: (i) we\nintroduce XC-Translate, the first large-scale, manually-created benchmark for\nmachine translation that focuses on text that contains potentially\nculturally-nuanced entity names, and (ii) we propose KG-MT, a novel end-to-end\nmethod to integrate information from a multilingual knowledge graph into a\nneural machine translation model by leveraging a dense retrieval mechanism. Our\nexperiments and analyses show that current machine translation systems and\nlarge language models still struggle to translate texts containing entity\nnames, whereas KG-MT outperforms state-of-the-art approaches by a large margin,\nobtaining a 129% and 62% relative improvement compared to NLLB-200 and GPT-4,\nrespectively.",
    "pdf_url": "http://arxiv.org/pdf/2410.14057v1",
    "published": "2024-10-17T21:56:22+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14056v2",
    "title": "Approximating Spanning Centrality with Random Bouquets",
    "authors": [
      "Gökhan Göktürk",
      "Kamer Kaya"
    ],
    "abstract": "Spanning Centrality is a measure used in network analysis to determine the\nimportance of an edge in a graph based on its contribution to the connectivity\nof the entire network. Specifically, it quantifies how critical an edge is in\nterms of the number of spanning trees that include that edge. The current\nstate-of-the-art for All Edges Spanning Centrality~(AESC), which computes the\nexact centrality values for all the edges, has a time complexity of\n$\\mathcal{O}(mn^{3/2})$ for $n$ vertices and $m$ edges. This makes the\ncomputation infeasible even for moderately sized graphs. Instead, there exist\napproximation algorithms which process a large number of random walks to\nestimate edge centralities. However, even the approximation algorithms can be\ncomputationally overwhelming, especially if the approximation error bound is\nsmall. In this work, we propose a novel, hash-based sampling method and a\nvectorized algorithm which greatly improves the execution time by clustering\nrandom walks into {\\it Bouquets}. On synthetic random walk benchmarks, {\\it\nBouquets} performs $7.8\\times$ faster compared to naive, traditional\nrandom-walk generation. We also show that the proposed technique is scalable by\nemploying it within a state-of-the-art AESC approximation algorithm, {\\sc\nTGT+}. The experiments show that using Bouquets yields more than $100\\times$\nspeed-up via parallelization with 16 threads.",
    "pdf_url": "http://arxiv.org/pdf/2410.14056v2",
    "published": "2024-10-17T21:52:28+00:00",
    "categories": [
      "cs.SI",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2410.14055v3",
    "title": "Feedback Schrödinger Bridge Matching",
    "authors": [
      "Panagiotis Theodoropoulos",
      "Nikolaos Komianos",
      "Vincent Pacelli",
      "Guan-Horng Liu",
      "Evangelos A. Theodorou"
    ],
    "abstract": "Recent advancements in diffusion bridges for distribution transport problems\nhave heavily relied on matching frameworks, yet existing methods often face a\ntrade-off between scalability and access to optimal pairings during training.\nFully unsupervised methods make minimal assumptions but incur high\ncomputational costs, limiting their practicality. On the other hand, imposing\nfull supervision of the matching process with optimal pairings improves\nscalability, however, it can be infeasible in many applications. To strike a\nbalance between scalability and minimal supervision, we introduce Feedback\nSchr\\\"odinger Bridge Matching (FSBM), a novel semi-supervised matching\nframework that incorporates a small portion (less than 8% of the entire\ndataset) of pre-aligned pairs as state feedback to guide the transport map of\nnon coupled samples, thereby significantly improving efficiency. This is\nachieved by formulating a static Entropic Optimal Transport (EOT) problem with\nan additional term capturing the semi-supervised guidance. The generalized EOT\nobjective is then recast into a dynamic formulation to leverage the scalability\nof matching frameworks. Extensive experiments demonstrate that FSBM accelerates\ntraining and enhances generalization by leveraging coupled pairs guidance,\nopening new avenues for training matching frameworks with partially aligned\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2410.14055v3",
    "published": "2024-10-17T21:52:01+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.14054v3",
    "title": "Adaptive Gradient Normalization and Independent Sampling for (Stochastic) Generalized-Smooth Optimization",
    "authors": [
      "Yufeng Yang",
      "Erin Tripp",
      "Yifan Sun",
      "Shaofeng Zou",
      "Yi Zhou"
    ],
    "abstract": "Recent studies have shown that many nonconvex machine learning problems\nsatisfy a generalized-smooth condition that extends beyond traditional smooth\nnonconvex optimization. However, the existing algorithms are not fully adapted\nto such generalized-smooth nonconvex geometry and encounter significant\ntechnical limitations on their convergence analysis. In this work, we first\nanalyze the convergence of adaptively normalized gradient descent under\nfunction geometries characterized by generalized-smoothness and generalized\nP{\\L} condition, revealing the advantage of adaptive gradient normalization.\nOur results provide theoretical insights into adaptive normalization across\nvarious scenarios.For stochastic generalized-smooth nonconvex optimization, we\npropose \\textbf{I}ndependent-\\textbf{A}daptively \\textbf{N}ormalized\n\\textbf{S}tochastic \\textbf{G}radient \\textbf{D}escent algorithm, which\nleverages adaptive gradient normalization, independent sampling, and gradient\nclipping to achieve an $\\mathcal{O}(\\epsilon^{-4})$ sample complexity under\nrelaxed noise assumptions. Experiments on large-scale nonconvex\ngeneralized-smooth problems demonstrate the fast convergence of our algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2410.14054v3",
    "published": "2024-10-17T21:52:00+00:00",
    "categories": [
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.14053v2",
    "title": "Quasi-Perfect State Transfer in Spin Chains via Parametrization of On-Site Energies",
    "authors": [
      "Fateh Bezaz",
      "Chad C. Nelmes",
      "Marta P. Estarellas",
      "Timothy P. Spiller",
      "Irene D'Amico"
    ],
    "abstract": "In recent years, significant progress has been made in the field of state\ntransfer in spin chains, with the aim of achieving perfect state transfer for\nquantum information processing applications. Previous research has mainly\nfocused on manipulating inter-site couplings within spin chains; here, we\ninvestigate in detail the potential of modifying on-site energies to facilitate\nprecise quantum information transfer. Our findings demonstrate that through\ntargeted adjustments to the diagonal elements of the XY Hamiltonian and\nleveraging a genetic algorithm, quasi-perfect state transfer can be achieved\nwith careful consideration of the system's spectral characteristics. This\ninvestigation into on-site energies offers an alternative approach for\nachieving high-fidelity state transfer, especially in cases where manipulation\nof inter-site couplings may be impractical. This study thus represents a\nsignificant advancement towards unlocking the diverse applications of spin\nchains within practical quantum information systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.14053v2",
    "published": "2024-10-17T21:48:50+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.other",
      "physics.app-ph",
      "physics.comp-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.14052v3",
    "title": "From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs",
    "authors": [
      "Alireza Rezazadeh",
      "Zichao Li",
      "Wei Wei",
      "Yujia Bao"
    ],
    "abstract": "Recent advancements in large language models have significantly improved\ntheir context windows, yet challenges in effective long-term memory management\nremain. We introduce MemTree, an algorithm that leverages a dynamic,\ntree-structured memory representation to optimize the organization, retrieval,\nand integration of information, akin to human cognitive schemas. MemTree\norganizes memory hierarchically, with each node encapsulating aggregated\ntextual content, corresponding semantic embeddings, and varying abstraction\nlevels across the tree's depths. Our algorithm dynamically adapts this memory\nstructure by computing and comparing semantic embeddings of new and existing\ninformation to enrich the model's context-awareness. This approach allows\nMemTree to handle complex reasoning and extended interactions more effectively\nthan traditional memory augmentation methods, which often rely on flat lookup\ntables. Evaluations on benchmarks for multi-turn dialogue understanding and\ndocument question answering show that MemTree significantly enhances\nperformance in scenarios that demand structured memory management.",
    "pdf_url": "http://arxiv.org/pdf/2410.14052v3",
    "published": "2024-10-17T21:47:11+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14051v3",
    "title": "Higher form symmetries, membranes and flux quantization",
    "authors": [
      "F. Caro-Perez",
      "M. P. Garcia del Moral",
      "A. Restuccia"
    ],
    "abstract": "Higher Forms Symmetries (HFS) of a closed bosonic M2-brane theory formulated\non a compactified target space $\\mathcal{M}_9 \\times T^2$ are obtained. We show\nthat the cancellation of the 't Hooft anomaly present in the theory is related\nto a 3-form flux with $\\mathcal{G}_1^{\\nabla}$-gerbe structure associated to\nthe world-volume flux quantization condition. A Wilson surface is naturally\nintroduced on the topological operator that characterize the holonomy of the\nM2-brane. The projection of the flux quantization condition inherited from the\ngerbe structure onto the spatial part of the worldvolume, leads to a flux\nquantization on the M2-brane. The topological operators realise discrete\nsymmetries associated with the winding and the flux/monopole condition. The\nalgebra of operators is well defined.",
    "pdf_url": "http://arxiv.org/pdf/2410.14051v3",
    "published": "2024-10-17T21:47:02+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.14050v1",
    "title": "Learning Multimodal Cues of Children's Uncertainty",
    "authors": [
      "Qi Cheng",
      "Mert İnan",
      "Rahma Mbarki",
      "Grace Grmek",
      "Theresa Choi",
      "Yiming Sun",
      "Kimele Persaud",
      "Jenny Wang",
      "Malihe Alikhani"
    ],
    "abstract": "Understanding uncertainty plays a critical role in achieving common ground\n(Clark et al.,1983). This is especially important for multimodal AI systems\nthat collaborate with users to solve a problem or guide the user through a\nchallenging concept. In this work, for the first time, we present a dataset\nannotated in collaboration with developmental and cognitive psychologists for\nthe purpose of studying nonverbal cues of uncertainty. We then present an\nanalysis of the data, studying different roles of uncertainty and its\nrelationship with task difficulty and performance. Lastly, we present a\nmultimodal machine learning model that can predict uncertainty given a\nreal-time video clip of a participant, which we find improves upon a baseline\nmultimodal transformer model. This work informs research on cognitive\ncoordination between human-human and human-AI and has broad implications for\ngesture understanding and generation. The anonymized version of our data and\ncode will be publicly available upon the completion of the required consent\nforms and data sheets.",
    "pdf_url": "http://arxiv.org/pdf/2410.14050v1",
    "published": "2024-10-17T21:46:00+00:00",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14049v1",
    "title": "Learning Metadata-Agnostic Representations for Text-to-SQL In-Context Example Selection",
    "authors": [
      "Chuhong Mai",
      "Ro-ee Tal",
      "Thahir Mohamed"
    ],
    "abstract": "In-context learning (ICL) is a powerful paradigm where large language models\n(LLMs) benefit from task demonstrations added to the prompt. Yet, selecting\noptimal demonstrations is not trivial, especially for complex or multi-modal\ntasks where input and output distributions differ. We hypothesize that forming\ntask-specific representations of the input is key. In this paper, we propose a\nmethod to align representations of natural language questions and those of SQL\nqueries in a shared embedding space. Our technique, dubbed MARLO -\nMetadata-Agnostic Representation Learning for Text-tO-SQL - uses query\nstructure to model querying intent without over-indexing on underlying database\nmetadata (i.e. tables, columns, or domain-specific entities of a database\nreferenced in the question or query). This allows MARLO to select examples that\nare structurally and semantically relevant for the task rather than examples\nthat are spuriously related to a certain domain or question phrasing. When used\nto retrieve examples based on question similarity, MARLO shows superior\nperformance compared to generic embedding models (on average +2.9\\%pt. in\nexecution accuracy) on the Spider benchmark. It also outperforms the next best\nmethod that masks metadata information by +0.8\\%pt. in execution accuracy on\naverage, while imposing a significantly lower inference latency.",
    "pdf_url": "http://arxiv.org/pdf/2410.14049v1",
    "published": "2024-10-17T21:45:55+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14048v2",
    "title": "Co-Designing with Algorithms: Unpacking the Complex Role of GenAI in Interactive System Design Education",
    "authors": [
      "Hauke Sandhaus",
      "Quiquan Gu",
      "Maria Teresa Parreira",
      "Wendy Ju"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) is transforming Human-Computer\nInteraction (HCI) education and technology design, yet its impact remains\npoorly understood. This study explores how graduate students in an applied HCI\ncourse used GenAI tools during interactive device design. Despite no\nencouragement, all groups integrated GenAI into their workflows. Through 12\npost-class group interviews, we identified how GenAI co-design behaviors\npresent both benefits, such as enhanced creativity and faster design\niterations, and risks, including shallow learning and reflection. Benefits were\nmost evident during the execution phases, while the discovery and reflection\nphases showed limited gains. A taxonomy of usage patterns revealed that\nstudents' outcomes depended more on how they used GenAI than the specific tasks\nperformed. These findings highlight the need for HCI education to adapt to\nGenAI's role and offer recommendations for curricula to better prepare future\ndesigners for effective creative co-design.",
    "pdf_url": "http://arxiv.org/pdf/2410.14048v2",
    "published": "2024-10-17T21:44:58+00:00",
    "categories": [
      "cs.HC",
      "K.3.1; K.3.2"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2410.14047v1",
    "title": "DiFuseR: A Distributed Sketch-based Influence Maximization Algorithm for GPUs",
    "authors": [
      "Gökhan Göktürk",
      "Kamer Kaya"
    ],
    "abstract": "Influence Maximization (IM) aims to find a given number of \"seed\" vertices\nthat can effectively maximize the expected spread under a given diffusion\nmodel. Due to the NP-Hardness of finding an optimal seed set, approximation\nalgorithms are often used for IM. However, these algorithms require a large\nnumber of simulations to find good seed sets. In this work, we propose DiFuseR,\na blazing-fast, high-quality IM algorithm that can run on multiple GPUs in a\ndistributed setting. DiFuseR is designed to increase GPU utilization, reduce\ninter-node communication, and minimize overlapping data/computation among the\nnodes. Based on the experiments with various graphs, containing some of the\nlargest networks available, and diffusion settings, the proposed approach is\nfound to be 3.2x and 12x faster on average on a single GPU and 8 GPUs,\nrespectively. It can achieve up to 8x and 233.7x speedup on the same hardware\nsettings. Furthermore, thanks to its smart load-balancing mechanism, on 8 GPUs,\nit is on average 5.6x faster compared to its single-GPU performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.14047v1",
    "published": "2024-10-17T21:41:12+00:00",
    "categories": [
      "cs.DC",
      "cs.PF",
      "cs.SI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2410.14046v2",
    "title": "Tensor Decomposition with Unaligned Observations",
    "authors": [
      "Runshi Tang",
      "Tamara Kolda",
      "Anru R. Zhang"
    ],
    "abstract": "This paper presents a canonical polyadic (CP) tensor decomposition that\naddresses unaligned observations. The mode with unaligned observations is\nrepresented using functions in a reproducing kernel Hilbert space (RKHS). We\nintroduce a versatile loss function that effectively accounts for various types\nof data, including binary, integer-valued, and positive-valued types.\nAdditionally, we propose an optimization algorithm for computing tensor\ndecompositions with unaligned observations, along with a stochastic gradient\nmethod to enhance computational efficiency. A sketching algorithm is also\nintroduced to further improve efficiency when using the $\\ell_2$ loss function.\nTo demonstrate the efficacy of our methods, we provide illustrative examples\nusing both synthetic data and an early childhood human microbiome dataset.",
    "pdf_url": "http://arxiv.org/pdf/2410.14046v2",
    "published": "2024-10-17T21:39:18+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.NA",
      "math.NA",
      "stat.CO",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.14045v1",
    "title": "Human Action Anticipation: A Survey",
    "authors": [
      "Bolin Lai",
      "Sam Toyer",
      "Tushar Nagarajan",
      "Rohit Girdhar",
      "Shengxin Zha",
      "James M. Rehg",
      "Kris Kitani",
      "Kristen Grauman",
      "Ruta Desai",
      "Miao Liu"
    ],
    "abstract": "Predicting future human behavior is an increasingly popular topic in computer\nvision, driven by the interest in applications such as autonomous vehicles,\ndigital assistants and human-robot interactions. The literature on behavior\nprediction spans various tasks, including action anticipation, activity\nforecasting, intent prediction, goal prediction, and so on. Our survey aims to\ntie together this fragmented literature, covering recent technical innovations\nas well as the development of new large-scale datasets for model training and\nevaluation. We also summarize the widely-used metrics for different tasks and\nprovide a comprehensive performance comparison of existing approaches on eleven\naction anticipation datasets. This survey serves as not only a reference for\ncontemporary methodologies in action anticipation, but also a guideline for\nfuture research direction of this evolving landscape.",
    "pdf_url": "http://arxiv.org/pdf/2410.14045v1",
    "published": "2024-10-17T21:37:40+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14044v1",
    "title": "Best in Tau@LLMJudge: Criteria-Based Relevance Evaluation with Llama3",
    "authors": [
      "Naghmeh Farzi",
      "Laura Dietz"
    ],
    "abstract": "Traditional evaluation of information retrieval (IR) systems relies on\nhuman-annotated relevance labels, which can be both biased and costly at scale.\nIn this context, large language models (LLMs) offer an alternative by allowing\nus to directly prompt them to assign relevance labels for passages associated\nwith each query. In this study, we explore alternative methods to directly\nprompt LLMs for assigned relevance labels, by exploring two hypotheses:\n  Hypothesis 1 assumes that it is helpful to break down \"relevance\" into\nspecific criteria - exactness, coverage, topicality, and contextual fit. We\nexplore different approaches that prompt large language models (LLMs) to obtain\ncriteria-level grades for all passages, and we consider various ways to\naggregate criteria-level grades into a relevance label. Hypothesis 2 assumes\nthat differences in linguistic style between queries and passages may\nnegatively impact the automatic relevance label prediction. We explore whether\nimprovements can be achieved by first synthesizing a summary of the passage in\nthe linguistic style of a query, and then using this summary in place of the\npassage to assess its relevance.\n  We include an empirical evaluation of our approaches based on data from the\nLLMJudge challenge run in Summer 2024, where our \"Four Prompts\" approach\nobtained the highest scores in Kendall's tau.",
    "pdf_url": "http://arxiv.org/pdf/2410.14044v1",
    "published": "2024-10-17T21:37:08+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "H.3.3"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.14043v2",
    "title": "Retrieval of Temporal Event Sequences from Textual Descriptions",
    "authors": [
      "Zefang Liu",
      "Yinzhu Quan"
    ],
    "abstract": "Retrieving temporal event sequences from textual descriptions is crucial for\napplications such as analyzing e-commerce behavior, monitoring social media\nactivities, and tracking criminal incidents. To advance this task, we introduce\nTESRBench, a comprehensive benchmark for temporal event sequence retrieval\n(TESR) from textual descriptions. TESRBench includes diverse real-world\ndatasets with synthesized and reviewed textual descriptions, providing a strong\nfoundation for evaluating retrieval performance and addressing challenges in\nthis domain. Building on this benchmark, we propose TPP-Embedding, a novel\nmodel for embedding and retrieving event sequences. The model leverages the\nTPP-LLM framework, integrating large language models (LLMs) with temporal point\nprocesses (TPPs) to encode both event texts and times. By pooling\nrepresentations and applying a contrastive loss, it unifies temporal dynamics\nand event semantics in a shared embedding space, aligning sequence-level\nembeddings of event sequences and their descriptions. TPP-Embedding\ndemonstrates superior performance over baseline models across TESRBench\ndatasets, establishing it as a powerful solution for the temporal event\nsequence retrieval task.",
    "pdf_url": "http://arxiv.org/pdf/2410.14043v2",
    "published": "2024-10-17T21:35:55+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14042v1",
    "title": "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles",
    "authors": [
      "Xiao Pu",
      "Tianxing He",
      "Xiaojun Wan"
    ],
    "abstract": "Prompt compression condenses contexts while maintaining their informativeness\nfor different usage scenarios. It not only shortens the inference time and\nreduces computational costs during the usage of large language models, but also\nlowers expenses when using closed-source models. In a preliminary study, we\ndiscover that when instructing language models to compress prompts, different\ncompression styles (e.g., extractive or abstractive) impact performance of\ncompressed prompts on downstream tasks. Building on this insight, we propose\nStyle-Compress, a lightweight framework that adapts a smaller language model to\ncompress prompts for a larger model on a new task without additional training.\nOur approach iteratively generates and selects effective compressed prompts as\ntask-specific demonstrations through style variation and in-context learning,\nenabling smaller models to act as efficient compressors with task-specific\nexamples. Style-Compress outperforms two baseline compression models in four\ntasks: original prompt reconstruction, text summarization, multi-hop QA, and\nCoT reasoning. In addition, with only 10 samples and 100 queries for\nadaptation, prompts compressed by Style-Compress achieve performance on par\nwith or better than original prompts at a compression ratio of 0.25 or 0.5.",
    "pdf_url": "http://arxiv.org/pdf/2410.14042v1",
    "published": "2024-10-17T21:35:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14041v1",
    "title": "From Barriers to Tactics: A Behavioral Science-Informed Agentic Workflow for Personalized Nutrition Coaching",
    "authors": [
      "Eric Yang",
      "Tomas Garcia",
      "Hannah Williams",
      "Bhawesh Kumar",
      "Martin Ramé",
      "Eileen Rivera",
      "Yiran Ma",
      "Jonathan Amar",
      "Caricia Catalani",
      "Yugang Jia"
    ],
    "abstract": "Effective management of cardiometabolic conditions requires sustained\npositive nutrition habits, often hindered by complex and individualized\nbarriers. Direct human management is simply not scalable, while previous\nattempts aimed at automating nutrition coaching lack the personalization needed\nto address these diverse challenges. This paper introduces a novel LLM-powered\nagentic workflow designed to provide personalized nutrition coaching by\ndirectly targeting and mitigating patient-specific barriers. Grounded in\nbehavioral science principles, the workflow leverages a comprehensive mapping\nof nutrition-related barriers to corresponding evidence-based strategies. A\nspecialized LLM agent intentionally probes for and identifies the root cause of\na patient's dietary struggles. Subsequently, a separate LLM agent delivers\ntailored tactics designed to overcome those specific barriers with patient\ncontext. We designed and validated our approach through a user study with\nindividuals with cardiometabolic conditions, demonstrating the system's ability\nto accurately identify barriers and provide personalized guidance. Furthermore,\nwe conducted a large-scale simulation study, grounding on real patient\nvignettes and expert-validated metrics, to evaluate the system's performance\nacross a wide range of scenarios. Our findings demonstrate the potential of\nthis LLM-powered agentic workflow to improve nutrition coaching by providing\npersonalized, scalable, and behaviorally-informed interventions.",
    "pdf_url": "http://arxiv.org/pdf/2410.14041v1",
    "published": "2024-10-17T21:35:07+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14750v3",
    "title": "Free modules with isomorphic duals",
    "authors": [
      "Theodoros Kyriopoulos"
    ],
    "abstract": "Let M,N be free modules over a Noetherian commutative ring R and let F be a\nfield whose cardinality card(F) does not exceed the continuum. We prove the\nfollowing :\n  1) The assertion that [Any two F-vector spaces with isomorphic duals are\nisomorphic] is equivallent to the ICF (Injective continuum function) hypothesis\nand it is a non-decidable statement in ZFC.\n  2) If the dual of M is a projective R-module and rank(M) is infinite then the\nring R is Artinian.\n  3) If R is Artinian and card(R) does not exceed the continuum then the the\ndual of M is free.\n  4) If M,N have isomorphic duals then they are themselves isomorphic, when R\nis a non-Artinian ring that is either Hilbert or countable.\n  5) If R is a non-local domain then R is a half-slender ring.\n  6) If R is Artinian ring and its cardinality card(R) does not exceed the\ncontinuum then the assertion that [any two free R-modules with isomorphic duals\nare isomorphic] is non-decidable in ZFC.\n  7) If R is a domain and rank(M) is infinite then the Goldie dimension of the\ndual of M is equal to its cardinality .\n  8) If R is a complex affine algebra whose corresponding affine variety has no\nisolated points then [any two projective R-modules with isomorphic duals are\nthemselves isomorphic].\n  9) Let V be an F-vector space of infinite dimension. The dimension of its\ndual is equal to the cardinality of the powerset of the dimension of V.\n  We also prove that if the powersets of two given sets have equal\ncardinalities then there is a bijection from the one powerset to the other that\npreserves the symmetric difference of sets.",
    "pdf_url": "http://arxiv.org/pdf/2410.14750v3",
    "published": "2024-10-17T21:34:42+00:00",
    "categories": [
      "math.AC"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2410.16321v2",
    "title": "Does the oscillatory behavior of the Momentum Spectrum depend on the basis in the Post-Transient Stage?",
    "authors": [
      "Deepak Sah",
      "Manoranjan P. Singh"
    ],
    "abstract": "Pair creation by a spatially homogeneous, time-dependent electric field is\nstudied within the framework of scalar quantum electrodynamics. We employ the\nstandard Bogoliubov transformation approach to compute the single-particle\ndistribution function in an adiabatic basis. We analyzed the distribution\nfunction of created particles in two different adiabatic bases (related by a\nunitary transformation). A novel dynamical scaling is observed while analyzing\nthe oscillatory momentum spectrum of the pairs created by the Sauter pulsed\nfield at intermediate times, calculated using the two adiabatic bases. In these\nbases, the same oscillatory momentum spectra are observed but at different\ntimes. However, when we scale the time by the point marking the end of the\ntransient stage of dynamical evolution for each case of central momentum, the\nrespective momentum spectra overlap. Furthermore, we study the time evolution\nof the momentum spectrum in the multi-photon regime and find that the spectra\nshow a multi-modal profile structure at finite times for both choices of basis.",
    "pdf_url": "http://arxiv.org/pdf/2410.16321v2",
    "published": "2024-10-17T21:34:25+00:00",
    "categories": [
      "quant-ph",
      "hep-ph",
      "hep-th",
      "physics.plasm-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.14040v2",
    "title": "Latent Weight Diffusion: Generating reactive policies instead of trajectories",
    "authors": [
      "Shashank Hegde",
      "Satyajeet Das",
      "Gautam Salhotra",
      "Gaurav S. Sukhatme"
    ],
    "abstract": "With the increasing availability of open-source robotic data, imitation\nlearning has emerged as a viable approach for both robot manipulation and\nlocomotion. Currently, large generalized policies are trained to predict\ncontrols or trajectories using diffusion models, which have the desirable\nproperty of learning multimodal action distributions. However, generalizability\ncomes with a cost, namely, larger model size and slower inference. This is\nespecially an issue for robotic tasks that require high control frequency.\nFurther, there is a known trade-off between performance and action horizon for\nDiffusion Policy (DP), a popular model for generating trajectories: fewer\ndiffusion queries accumulate greater trajectory tracking errors. For these\nreasons, it is common practice to run these models at high inference frequency,\nsubject to robot computational constraints. To address these limitations, we\npropose Latent Weight Diffusion (LWD), a method that uses diffusion to generate\nclosed-loop policies (weights for neural policies) for robotic tasks, rather\nthan generating trajectories. Learning the behavior distribution through\nparameter space over trajectory space offers two key advantages: longer action\nhorizons (fewer diffusion queries) & robustness to perturbations while\nretaining high performance; and a lower inference compute cost. To this end, we\nshow that LWD has higher success rates than DP when the action horizon is\nlonger and when stochastic perturbations exist in the environment. Furthermore,\nLWD achieves multitask performance comparable to DP while requiring just\n~1/45th of the inference-time FLOPS",
    "pdf_url": "http://arxiv.org/pdf/2410.14040v2",
    "published": "2024-10-17T21:30:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14039v2",
    "title": "Locally isotropic Steinberg groups I. Centrality of the $\\mathrm K_2$-functor",
    "authors": [
      "Egor Voronetsky"
    ],
    "abstract": "We begin to study Steinberg groups associated with a locally isotropic\nreductive group $G$ over a arbitrary ring. We propose a construction of such a\nSteinberg group functor as a group object in a certain completion of the\ncategory of presheaves. We also show that it is a crossed module over $G$ in a\nunique way, in particular, that the $\\mathrm K_2$-functor is central. If $G$ is\nglobally isotropic in a suitable sense, then the Steinberg group functor exists\nas an ordinary group-valued functor and all such abstract Steinberg groups are\ncrossed modules over the groups of points of $G$.",
    "pdf_url": "http://arxiv.org/pdf/2410.14039v2",
    "published": "2024-10-17T21:23:32+00:00",
    "categories": [
      "math.RT",
      "math.GR",
      "math.KT",
      "19C09"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2410.14038v5",
    "title": "Sliding Puzzles Gym: A Scalable Benchmark for State Representation in Visual Reinforcement Learning",
    "authors": [
      "Bryan L. M. de Oliveira",
      "Luana G. B. Martins",
      "Bruno Brandão",
      "Murilo L. da Luz",
      "Telma W. de L. Soares",
      "Luckeciano C. Melo"
    ],
    "abstract": "Effective visual representation learning is crucial for reinforcement\nlearning (RL) agents to extract task-relevant information from raw sensory\ninputs and generalize across diverse environments. However, existing RL\nbenchmarks lack the ability to systematically evaluate representation learning\ncapabilities in isolation from other learning challenges. To address this gap,\nwe introduce the Sliding Puzzles Gym (SPGym), a novel benchmark that transforms\nthe classic 8-tile puzzle into a visual RL task with images drawn from\narbitrarily large datasets. SPGym's key innovation lies in its ability to\nprecisely control representation learning complexity through adjustable grid\nsizes and image pools, while maintaining fixed environment dynamics,\nobservation, and action spaces. This design enables researchers to isolate and\nscale the visual representation challenge independently of other learning\ncomponents. Through extensive experiments with model-free and model-based RL\nalgorithms, we uncover fundamental limitations in current methods' ability to\nhandle visual diversity. As we increase the pool of possible images, all\nalgorithms exhibit in- and out-of-distribution performance degradation, with\nsophisticated representation learning techniques often underperforming simpler\napproaches like data augmentation. These findings highlight critical gaps in\nvisual representation learning for RL and establish SPGym as a valuable tool\nfor driving progress in robust, generalizable decision-making systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.14038v5",
    "published": "2024-10-17T21:23:03+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14037v2",
    "title": "Implementation of the three-neutron quantization condition",
    "authors": [
      "Wilder Schaaf",
      "Stephen R. Sharpe"
    ],
    "abstract": "We present an implementation of the three-neutron quantization condition (QC)\nderived in previous work. We construct the matrices appearing in the QC and\ndetermine solutions numerically. The symmetries of the QC allow the projection\nonto irreducible representations of the appropriate little group (depending on\nframe momentum), restricting the size of the matrices and reducing\ncomputational complexity. In this initial study, we include only two-neutron\ninteractions, which are modeled based on experimental data for $I=1$ scattering\namplitudes. We show examples of the finite-volume spectrum in two frames and\nfor a range of energies, illustrating the potential and also the challenges of\nusing three-neutron spectroscopy to constrain the underlying interactions.",
    "pdf_url": "http://arxiv.org/pdf/2410.14037v2",
    "published": "2024-10-17T21:22:37+00:00",
    "categories": [
      "hep-lat"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2410.14036v2",
    "title": "Fractional quantum Hall effect in higher dimensions",
    "authors": [
      "Abhishek Agarwal",
      "Dimitra Karabali",
      "V. P. Nair"
    ],
    "abstract": "Generalizing from previous work on the integer quantum Hall effect, we\nconstruct the effective action for the analog of Laughlin states for the\nfractional quantum Hall effect in higher dimensions. The formalism is a\ngeneralization of the parton picture used in two spatial dimensions, the\ncrucial ingredient being the cancellation of anomalies for the gauge fields\nbinding the partons together. Some subtleties which exist even in two\ndimensions are pointed out. The effective action is obtained from a combination\nof the Dolbeault and Dirac index theorems. We also present expressions for some\ntransport coefficients such as Hall conductivity and Hall viscosity for the\nfractional states.",
    "pdf_url": "http://arxiv.org/pdf/2410.14036v2",
    "published": "2024-10-17T21:19:42+00:00",
    "categories": [
      "hep-th",
      "cond-mat.str-el",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.19815v1",
    "title": "BUNDL: Bayesian Uncertainty-aware Deep Learning with Noisy training Labels for Seizure Detection in EEG",
    "authors": [
      "Deeksha M Shama",
      "Archana Venkataraman"
    ],
    "abstract": "Deep learning methods are at the forefront of automated epileptic seizure\ndetection and onset zone localization using scalp-EEG. However, the performance\nof deep learning methods rely heavily on the quality of annotated training\ndatasets. Scalp EEG is susceptible to high noise levels, which in turn leads to\nimprecise annotations of the seizure timing and characteristics. This label\nnoise presents a significant challenge in model training and generalization. In\nthis paper, we introduce a novel statistical framework that informs a deep\nlearning model of label ambiguity, thereby enhancing the overall seizure\ndetection performance. Our Bayesian UncertaiNty-aware Deep Learning, BUNDL,\nstrategy offers a straightforward and model-agnostic method for training deep\nneural networks with noisy training labels that does not add any parameters to\nexisting architectures. By integrating domain knowledge into the statistical\nframework, we derive a novel KL-divergence-based loss function that capitalizes\non uncertainty to better learn seizure characteristics from scalp EEG.\nAdditionally, we explore the impact of improved seizure detection on the task\nof automated onset zone localization. We validate BUNDL using a comprehensive\nsimulated EEG dataset and two publicly available datasets, TUH and CHB-MIT.\nBUNDL consistently improves the performance of three base models on simulated\ndata under seven types of label noise and three EEG signal-to-noise ratios.\nSimilar improvements were observed in the real-world TUH and CHB-MIT datasets.\nFinally, we demonstrate that BUNDL improves the accuracy of seizure onset zone\nlocalization. BUNDL is specifically designed to address label ambiguities,\nenabling the training of reliable and trustworthy models for epilepsy\nevaluation.",
    "pdf_url": "http://arxiv.org/pdf/2410.19815v1",
    "published": "2024-10-17T21:19:39+00:00",
    "categories": [
      "eess.SP",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.14035v5",
    "title": "Optimal Communication and Key Rate Region for Hierarchical Secure Aggregation with User Collusion",
    "authors": [
      "Xiang Zhang",
      "Kai Wan",
      "Hua Sun",
      "Shiqiang Wang",
      "Mingyue Ji",
      "Giuseppe Caire"
    ],
    "abstract": "Secure aggregation is concerned with the task of securely uploading the\ninputs of multiple users to an aggregation server without letting the server\nknow the inputs beyond their summation. It finds broad applications in\ndistributed machine learning paradigms such as federated learning (FL) where\nmultiple clients, each having access to a proprietary dataset, periodically\nupload their locally trained models (abstracted as inputs) to a parameter\nserver which then generates an aggregate (e.g., averaged) model that is sent\nback to the clients as an initializing point for a new round of local training.\nTo enhance the data privacy of the clients, secure aggregation protocols are\ndeveloped using techniques from cryptography to ensure that the server infers\nno more information of the users' inputs beyond the desired aggregated input,\neven if the server can collude with some users. Although laying the ground for\nunderstanding the fundamental utility-security trade-off in secure aggregation,\nthe simple star client-server architecture cannot capture more complex network\narchitectures used in practical systems. Motivated by hierarchical federated\nlearning, we investigate the secure aggregation problem in a $3$-layer\nhierarchical network consisting of clustered users connecting to an aggregation\nserver through an intermediate layer of relays. Besides the conventional server\nsecurity which requires that the server learns nothing beyond the desired sum\nof inputs, relay security is also imposed so that the relays infer nothing\nabout the users' inputs and remain oblivious. For such a hierarchical secure\naggregation (HSA) problem, we characterize the optimal multifaceted trade-off\nbetween communication (in terms of user-to-relay and relay-to-server\ncommunication rates) and secret key generation efficiency (in terms of\nindividual key and source key rates).",
    "pdf_url": "http://arxiv.org/pdf/2410.14035v5",
    "published": "2024-10-17T21:17:17+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.14034v1",
    "title": "Fermionic Dyson expansions and stochastic Duistermaat-Heckman localization on loop spaces",
    "authors": [
      "Batu Güneysu",
      "Jonas Miehe"
    ],
    "abstract": "Given a self-adjoint operator $H\\geq 0$ and (appropriate) densely defined and\nclosed operators $P_{1},\\dots, P_{n}$ in a Hilbert space $\\mathscr{H}$, we\nprovide a systematic study of bounded operators given by iterated integrals\n  \\begin{align}\\label{oh}\n  \\int_{\\{ 0\\leq s_1\\leq \\dots\\leq s_n\\leq\nt\\}}\\mathrm{e}^{-s_1H}P_{1}\\mathrm{e}^{-(s_2-s_1)H}P_{2}\\cdots\n\\mathrm{e}^{-(s_n-s_{n-1})H}P_{n} \\mathrm{e}^{-(t-s_n)H}\\, \\mathrm{d} s_{1}\n\\ldots \\mathrm{d} s_{n},\\quad t>0.\n  \\end{align} These operators arise naturally in noncommutative geometry and\nthe geometry of loop spaces. Using Fermionic calculus, we give a natural\nconstruction of an enlarged Hilbert space $\\mathscr{H}^{(n)}$ and an analytic\nsemigroup $\\mathrm{e}^{-t (H^{(n)}+P^{(n)} )}$ thereon, such that\n$\\mathrm{e}^{-t (H^{(n)}+P^{(n)} )}$ composed from the left with (essentially)\na Fermionic integration gives precisely the above iterated operator integral.\nThis formula allows to establish important regularity results for the latter,\nand to derive a stochastic representation for it, in case $H$ is a covariant\nLaplacian and the $P_{j}$'s are first-order differential operators. Finally,\nwith $H$ given as the square of the Dirac operator on a spin manifold, this\nrepresentation is used to derive a stochastic refinement of the\nDuistermaat-Heckman localization formula on the loop space of a spin manifold.",
    "pdf_url": "http://arxiv.org/pdf/2410.14034v1",
    "published": "2024-10-17T21:14:20+00:00",
    "categories": [
      "math.DG",
      "math.KT",
      "math.PR"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14033v1",
    "title": "A Comparative Study on Accessibility for Autistic Individuals with Urban Mobility Apps",
    "authors": [
      "Danilo Monteiro Ribeiro",
      "Felipe Vasconcelos Melo",
      "Vitor Negromonte",
      "Gabriel Walisson Matias",
      "Adna Farias",
      "Celeste Azul",
      "Ana Paula Chaves",
      "Kiev Gama"
    ],
    "abstract": "Autism Spectrum Disorder (ASD) is a neurodivergent condition with a wide\nrange of characteristics and support levels. Individuals with ASD can exhibit\nvarious combinations of traits such as difficulties in social interaction,\ncommunication, and language, alongside restricted interests and repetitive\nactivities. Many adults with ASD live independently due to increased awareness\nand late diagnoses, which help them manage long-standing challenges.\nPredictability, clarity, and minimized sensory stimuli are crucial for the\ndaily comfort of autistic individuals. In mobile applications, autistic users\nface significant cognitive overload compared to neurotypicals, resulting in\nhigher effort and time to complete tasks. Urban mobility apps, essential for\ndaily routines, often overlook the needs of autistic users, leading to\ncognitive overload issues. This study investigates the accessibility of urban\nmobility apps for autistic individuals using the Interfaces Accessibility Guide\nfor Autism (GAIA). By evaluating various apps, we have identified a common gap\nregarding accessibility for people with Autism Spectrum Disorder (ASD). This\nlimitation relates to the absence of a functionality that allows users on the\nautism spectrum to customize the characteristics of the textual and visual\nelements of the software, such as changing the text font, altering the font\ntype, and adjusting text colors, as well as native audio guidance within the\napplications themselves. Currently, the only function in this context is for\nvisually impaired people, which completely changes the user experience in terms\nof navigation.",
    "pdf_url": "http://arxiv.org/pdf/2410.14033v1",
    "published": "2024-10-17T21:14:11+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2410.14032v1",
    "title": "Finite-volume method and observability analysis for core-shell enhanced single particle model for lithium iron phosphate batteries",
    "authors": [
      "Le Xu",
      "Simone Fasolato",
      "Simona Onori"
    ],
    "abstract": "The increasing adoption of Lithium Iron Phosphate (LFP) batteries in Electric\nVehicles is driven by their affordability, abundant material supply, and safety\nadvantages. However, challenges arise in controlling/estimating unmeasurable\nLFP states such as state of charge (SOC), due to its flat open circuit voltage,\nhysteresis, and path dependence dynamics during intercalation and\nde-intercalation processes. The Core Shell Average Enhanced Single Particle\nModel (CSa-ESPM) effectively captures the electrochemical dynamics and phase\ntransition behavior of LFP batteries by means of Partial Differential-Algebraic\nEquations (PDAEs). These governing PDAEs, including a moving boundary Ordinary\nDifferential Equation (ODE), require a fine-grained spatial grid for accurate\nand stable solutions when employing the Finite Difference Method (FDM). This,\nin turn, leads to a computationally expensive system intractable for the design\nof real-time battery management system algorithms. In this study, we\ndemonstrate that the Finite Volume Method (FVM) effectively discretizes the\nCSa-ESPM and provides accurate solutions with fewer than 4 control volumes\nwhile ensuring mass conservation across multi ple operational cycles. The\nresulting control-oriented reduced order FVM-based CSa-ESPM is experimentally\nvalidated using various C-rate load profiles and its observability is assessed\nthrough nonlinear observability analysis. Our results reveal that different\ncurrent inputs and discrete equation numbers influence model observability,\nwith non-observable regions identified where solid-phase concentration\ngradients are negligible.",
    "pdf_url": "http://arxiv.org/pdf/2410.14032v1",
    "published": "2024-10-17T21:11:43+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.14031v4",
    "title": "Modeling the Human Visual System: Comparative Insights from Response-Optimized and Task-Optimized Vision Models, Language Models, and different Readout Mechanisms",
    "authors": [
      "Shreya Saha",
      "Ishaan Chadha",
      "Meenakshi khosla"
    ],
    "abstract": "Over the past decade, predictive modeling of neural responses in the primate\nvisual system has advanced significantly, largely driven by various DNN\napproaches. These include models optimized directly for visual recognition,\ncross-modal alignment through contrastive objectives, neural response\nprediction from scratch, and large language model embeddings.Likewise,\ndifferent readout mechanisms, ranging from fully linear to spatial-feature\nfactorized methods have been explored for mapping network activations to neural\nresponses. Despite the diversity of these approaches, it remains unclear which\nmethod performs best across different visual regions. In this study, we\nsystematically compare these approaches for modeling the human visual system\nand investigate alternative strategies to improve response predictions. Our\nfindings reveal that for early to mid-level visual areas, response-optimized\nmodels with visual inputs offer superior prediction accuracy, while for higher\nvisual regions, embeddings from LLMs based on detailed contextual descriptions\nof images and task-optimized models pretrained on large vision datasets provide\nthe best fit. Through comparative analysis of these modeling approaches, we\nidentified three distinct regions in the visual cortex: one sensitive primarily\nto perceptual features of the input that are not captured by linguistic\ndescriptions, another attuned to fine-grained visual details representing\nsemantic information, and a third responsive to abstract, global meanings\naligned with linguistic content. We also highlight the critical role of readout\nmechanisms, proposing a novel scheme that modulates receptive fields and\nfeature maps based on semantic content, resulting in an accuracy boost of 3-23%\nover existing SOTAs for all models and brain regions. Together, these findings\noffer key insights into building more precise models of the visual system.",
    "pdf_url": "http://arxiv.org/pdf/2410.14031v4",
    "published": "2024-10-17T21:11:13+00:00",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2410.14030v2",
    "title": "Graph Neural Flows for Unveiling Systemic Interactions Among Irregularly Sampled Time Series",
    "authors": [
      "Giangiacomo Mercatali",
      "Andre Freitas",
      "Jie Chen"
    ],
    "abstract": "Interacting systems are prevalent in nature. It is challenging to accurately\npredict the dynamics of the system if its constituent components are analyzed\nindependently. We develop a graph-based model that unveils the systemic\ninteractions of time series observed at irregular time points, by using a\ndirected acyclic graph to model the conditional dependencies (a form of causal\nnotation) of the system components and learning this graph in tandem with a\ncontinuous-time model that parameterizes the solution curves of ordinary\ndifferential equations (ODEs). Our technique, a graph neural flow, leads to\nsubstantial enhancements over non-graph-based methods, as well as graph-based\nmethods without the modeling of conditional dependencies. We validate our\napproach on several tasks, including time series classification and\nforecasting, to demonstrate its efficacy.",
    "pdf_url": "http://arxiv.org/pdf/2410.14030v2",
    "published": "2024-10-17T21:10:39+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.19814v1",
    "title": "Stochastic Flow Matching for Resolving Small-Scale Physics",
    "authors": [
      "Stathi Fotiadis",
      "Noah Brenowitz",
      "Tomas Geffner",
      "Yair Cohen",
      "Michael Pritchard",
      "Arash Vahdat",
      "Morteza Mardani"
    ],
    "abstract": "Conditioning diffusion and flow models have proven effective for\nsuper-resolving small-scale details in natural images.However, in physical\nsciences such as weather, super-resolving small-scale details poses significant\nchallenges due to: (i) misalignment between input and output distributions\n(i.e., solutions to distinct partial differential equations (PDEs) follow\ndifferent trajectories), (ii) multi-scale dynamics, deterministic dynamics at\nlarge scales vs. stochastic at small scales, and (iii) limited data, increasing\nthe risk of overfitting. To address these challenges, we propose encoding the\ninputs to a latent base distribution that is closer to the target distribution,\nfollowed by flow matching to generate small-scale physics. The encoder captures\nthe deterministic components, while flow matching adds stochastic small-scale\ndetails. To account for uncertainty in the deterministic part, we inject noise\ninto the encoder output using an adaptive noise scaling mechanism, which is\ndynamically adjusted based on maximum-likelihood estimates of the encoder\npredictions. We conduct extensive experiments on both the real-world CWA\nweather dataset and the PDE-based Kolmogorov dataset, with the CWA task\ninvolving super-resolving the weather variables for the region of Taiwan from\n25 km to 2 km scales. Our results show that the proposed stochastic flow\nmatching (SFM) framework significantly outperforms existing methods such as\nconditional diffusion and flows.",
    "pdf_url": "http://arxiv.org/pdf/2410.19814v1",
    "published": "2024-10-17T21:09:13+00:00",
    "categories": [
      "cs.CV",
      "physics.ao-ph",
      "stat.ML"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14029v1",
    "title": "Auditing and Enforcing Conditional Fairness via Optimal Transport",
    "authors": [
      "Mohsen Ghassemi",
      "Alan Mishler",
      "Niccolo Dalmasso",
      "Luhao Zhang",
      "Vamsi K. Potluru",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "abstract": "Conditional demographic parity (CDP) is a measure of the demographic parity\nof a predictive model or decision process when conditioning on an additional\nfeature or set of features. Many algorithmic fairness techniques exist to\ntarget demographic parity, but CDP is much harder to achieve, particularly when\nthe conditioning variable has many levels and/or when the model outputs are\ncontinuous. The problem of auditing and enforcing CDP is understudied in the\nliterature. In light of this, we propose novel measures of {conditional\ndemographic disparity (CDD)} which rely on statistical distances borrowed from\nthe optimal transport literature. We further design and evaluate\nregularization-based approaches based on these CDD measures. Our methods,\n\\fairbit{} and \\fairlp{}, allow us to target CDP even when the conditioning\nvariable has many levels. When model outputs are continuous, our methods target\nfull equality of the conditional distributions, unlike other methods that only\nconsider first moments or related proxy quantities. We validate the efficacy of\nour approaches on real-world datasets.",
    "pdf_url": "http://arxiv.org/pdf/2410.14029v1",
    "published": "2024-10-17T21:08:13+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14028v1",
    "title": "Measuring and Modifying the Readability of English Texts with GPT-4",
    "authors": [
      "Sean Trott",
      "Pamela D. Rivière"
    ],
    "abstract": "The success of Large Language Models (LLMs) in other domains has raised the\nquestion of whether LLMs can reliably assess and manipulate the readability of\ntext. We approach this question empirically. First, using a published corpus of\n4,724 English text excerpts, we find that readability estimates produced\n``zero-shot'' from GPT-4 Turbo and GPT-4o mini exhibit relatively high\ncorrelation with human judgments (r = 0.76 and r = 0.74, respectively),\nout-performing estimates derived from traditional readability formulas and\nvarious psycholinguistic indices. Then, in a pre-registered human experiment (N\n= 59), we ask whether Turbo can reliably make text easier or harder to read. We\nfind evidence to support this hypothesis, though considerable variance in human\njudgments remains unexplained. We conclude by discussing the limitations of\nthis approach, including limited scope, as well as the validity of the\n``readability'' construct and its dependence on context, audience, and goal.",
    "pdf_url": "http://arxiv.org/pdf/2410.14028v1",
    "published": "2024-10-17T21:04:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.19813v1",
    "title": "Threshold-Based Automated Pest Detection System for Sustainable Agriculture",
    "authors": [
      "Tianle Li",
      "Jia Shu",
      "Qinghong Chen",
      "Murad Mehrab Abrar",
      "John Raiti"
    ],
    "abstract": "This paper presents a threshold-based automated pea weevil detection system,\ndeveloped as part of the Microsoft FarmVibes project. Based on\nInternet-of-Things (IoT) and computer vision, the system is designed to monitor\nand manage pea weevil populations in agricultural settings, with the goal of\nenhancing crop production and promoting sustainable farming practices. Unlike\nthe machine learning-based approaches, our detection approach relies on binary\ngrayscale thresholding and contour detection techniques determined by the pea\nweevil sizes. We detail the design of the product, the system architecture, the\nintegration of hardware and software components, and the overall technology\nstrategy. Our test results demonstrate significant effectiveness in weevil\nmanagement and offer promising scalability for deployment in\nresource-constrained environments. In addition, the software has been\nopen-sourced for the global research community.",
    "pdf_url": "http://arxiv.org/pdf/2410.19813v1",
    "published": "2024-10-17T20:57:40+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14027v1",
    "title": "The red supergiant progenitor luminosity problem",
    "authors": [
      "Emma R. Beasor",
      "Nathan Smith",
      "Jacob E. Jencson"
    ],
    "abstract": "Analysis of pre-explosion imaging has confirmed red supergiants (RSGs) as the\nprogenitors to Type II-P supernovae (SNe). However, extracting the RSG's\nluminosity requires assumptions regarding the star's temperature or spectral\ntype and the corresponding bolometric correction, circumstellar extinction, and\npossible variability. The robustness of these assumptions is difficult to test,\nsince we cannot go back in time and obtain additional pre-explosion imaging.\nHere, we perform a simple test using the RSGs in M31, which have been well\nobserved from optical to mid-IR. We ask the following: By treating each star as\nif we only had single-band photometry and making assumptions typically used in\nSN progenitor studies, what bolometric luminosity would we infer for each star?\nHow close is this to the bolometric luminosity for that same star inferred from\nthe full optical-to-IR spectral energy distribution (SED)? We find common\nassumptions adopted in progenitor studies systematically underestimate the\nbolometric luminosity by a factor of 2, typically leading to inferred\nprogenitor masses that are systematically too low. Additionally, we find a much\nlarger spread in luminosity derived from single-filter photometry compared to\nSED-derived luminosities, indicating uncertainties in progenitor luminosities\nare also underestimated. When these corrections and larger uncertainties are\nincluded in the analysis, even the most luminous known RSGs are not ruled out\nat the 3$\\sigma$ level, indicating there is currently no statistically\nsignificant evidence that the most luminous RSGs are missing from the observed\nsample of II-P progenitors. The proposed correction also alleviates the problem\nof having progenitors with masses below the expected lower-mass bound for\ncore-collapse.",
    "pdf_url": "http://arxiv.org/pdf/2410.14027v1",
    "published": "2024-10-17T20:57:29+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.14026v1",
    "title": "Generating Signed Language Instructions in Large-Scale Dialogue Systems",
    "authors": [
      "Mert İnan",
      "Katherine Atwell",
      "Anthony Sicilia",
      "Lorna Quandt",
      "Malihe Alikhani"
    ],
    "abstract": "We introduce a goal-oriented conversational AI system enhanced with American\nSign Language (ASL) instructions, presenting the first implementation of such a\nsystem on a worldwide multimodal conversational AI platform. Accessible through\na touch-based interface, our system receives input from users and seamlessly\ngenerates ASL instructions by leveraging retrieval methods and cognitively\nbased gloss translations. Central to our design is a sign translation module\npowered by Large Language Models, alongside a token-based video retrieval\nsystem for delivering instructional content from recipes and wikiHow guides.\nOur development process is deeply rooted in a commitment to community\nengagement, incorporating insights from the Deaf and Hard-of-Hearing community,\nas well as experts in cognitive and ASL learning sciences. The effectiveness of\nour signing instructions is validated by user feedback, achieving ratings on\npar with those of the system in its non-signing variant. Additionally, our\nsystem demonstrates exceptional performance in retrieval accuracy and\ntext-generation quality, measured by metrics such as BERTScore. We have made\nour codebase and datasets publicly accessible at\nhttps://github.com/Merterm/signed-dialogue, and a demo of our signed\ninstruction video retrieval system is available at\nhttps://huggingface.co/spaces/merterm/signed-instructions.",
    "pdf_url": "http://arxiv.org/pdf/2410.14026v1",
    "published": "2024-10-17T20:56:29+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14025v3",
    "title": "Target-Aware Implementation of Real Expressions",
    "authors": [
      "Brett Saiki",
      "Jackson Brough",
      "Jonas Regehr",
      "Jesús Ponce",
      "Varun Pradeep",
      "Aditya Akhileshwaran",
      "Zachary Tatlock",
      "Pavel Panchekha"
    ],
    "abstract": "New low-precision accelerators, vector instruction sets, and library\nfunctions make maximizing accuracy and performance of numerical code\nincreasingly challenging. Two lines of work$\\unicode{x2013}$traditional\ncompilers and numerical compilers$\\unicode{x2013}$attack this problem from\nopposite directions. Traditional compiler backends optimize for specific target\nenvironments but are limited in their ability to balance performance and\naccuracy. Numerical compilers trade off accuracy and performance, or even\nimprove both, but ignore the target environment. We join aspects of both to\nproduce Chassis, a target-aware numerical compiler.\n  Chassis compiles mathematical expressions to operators from a target\ndescription, which lists the real expressions each operator approximates and\nestimates its cost and accuracy. Chassis then uses an iterative improvement\nloop to optimize for speed and accuracy. Specifically, a new instruction\nselection modulo equivalence algorithm efficiently searches for faster\ntarget-specific programs, while a new cost-opportunity heuristic supports\niterative improvement. We demonstrate Chassis' capabilities on 9 different\ntargets, including hardware ISAs, math libraries, and programming languages.\nChassis finds better accuracy and performance trade-offs than both Clang (by\n3.5x) or Herbie (by up to 2.0x) by leveraging low-precision accelerators,\naccuracy-optimized numerical helper functions, and library subcomponents.",
    "pdf_url": "http://arxiv.org/pdf/2410.14025v3",
    "published": "2024-10-17T20:56:05+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14024v1",
    "title": "Ensemble-based, large-eddy reconstruction of wind turbine inflow in a near-stationary atmospheric boundary layer through generative artificial intelligence",
    "authors": [
      "Alex Rybchuk",
      "Luis A. Martínez-Tossas",
      "Stefano Letizia",
      "Nicholas Hamilton",
      "Andy Scholbrock",
      "Emina Maric",
      "Daniel R. Houck",
      "Thomas G. Herges",
      "Nathaniel B. de Velder",
      "Paula Doubrawa"
    ],
    "abstract": "To validate the second-by-second dynamics of turbines in field experiments,\nit is necessary to accurately reconstruct the winds going into the turbine.\nCurrent time-resolved inflow reconstruction techniques estimate wind behavior\nin unobserved regions using relatively simple spectral-based models of the\natmosphere. Here, we develop a technique for time-resolved inflow\nreconstruction that is rooted in a large-eddy simulation model of the\natmosphere. Our \"large-eddy reconstruction\" technique blends observations and\natmospheric model information through a diffusion model machine learning\nalgorithm, allowing us to generate probabilistic ensembles of reconstructions\nfor a single 10-min observational period. Our generated inflows can be used\ndirectly by aeroelastic codes or as inflow boundary conditions in a large-eddy\nsimulation. We verify the second-by-second reconstruction capability of our\ntechnique in three synthetic field campaigns, finding positive Pearson\ncorrelation coefficient values (0.20>r>0.85) between ground-truth and\nreconstructed streamwise velocity, as well as smaller positive correlation\ncoefficient values for unobserved fields (spanwise velocity, vertical velocity,\nand temperature). We validate our technique in three real-world case studies by\ndriving large-eddy simulations with reconstructed inflows and comparing to\nindependent inflow measurements. The reconstructions are visually similar to\nmeasurements, follow desired power spectra properties, and track\nsecond-by-second behavior (0.25 > r > 0.75).",
    "pdf_url": "http://arxiv.org/pdf/2410.14024v1",
    "published": "2024-10-17T20:53:04+00:00",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.14023v1",
    "title": "Identifying Privacy Personas",
    "authors": [
      "Olena Hrynenko",
      "Andrea Cavallaro"
    ],
    "abstract": "Privacy personas capture the differences in user segments with respect to\none's knowledge, behavioural patterns, level of self-efficacy, and perception\nof the importance of privacy protection. Modelling these differences is\nessential for appropriately choosing personalised communication about privacy\n(e.g. to increase literacy) and for defining suitable choices for privacy\nenhancing technologies (PETs). While various privacy personas have been derived\nin the literature, they group together people who differ from each other in\nterms of important attributes such as perceived or desired level of control,\nand motivation to use PET. To address this lack of granularity and\ncomprehensiveness in describing personas, we propose eight personas that we\nderive by combining qualitative and quantitative analysis of the responses to\nan interactive educational questionnaire. We design an analysis pipeline that\nuses divisive hierarchical clustering and Boschloo's statistical test of\nhomogeneity of proportions to ensure that the elicited clusters differ from\neach other based on a statistical measure. Additionally, we propose a new\nmeasure for calculating distances between questionnaire responses, that\naccounts for the type of the question (closed- vs open-ended) used to derive\ntraits. We show that the proposed privacy personas statistically differ from\neach other. We statistically validate the proposed personas and also compare\nthem with personas in the literature, showing that they provide a more granular\nand comprehensive understanding of user segments, which will allow to better\nassist users with their privacy needs.",
    "pdf_url": "http://arxiv.org/pdf/2410.14023v1",
    "published": "2024-10-17T20:49:46+00:00",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14022v1",
    "title": "Vision-Language-Action Model and Diffusion Policy Switching Enables Dexterous Control of an Anthropomorphic Hand",
    "authors": [
      "Cheng Pan",
      "Kai Junge",
      "Josie Hughes"
    ],
    "abstract": "To advance autonomous dexterous manipulation, we propose a hybrid control\nmethod that combines the relative advantages of a fine-tuned\nVision-Language-Action (VLA) model and diffusion models. The VLA model provides\nlanguage commanded high-level planning, which is highly generalizable, while\nthe diffusion model handles low-level interactions which offers the precision\nand robustness required for specific objects and environments. By incorporating\na switching signal into the training-data, we enable event based transitions\nbetween these two models for a pick-and-place task where the target object and\nplacement location is commanded through language. This approach is deployed on\nour anthropomorphic ADAPT Hand 2, a 13DoF robotic hand, which incorporates\ncompliance through series elastic actuation allowing for resilience for any\ninteractions: showing the first use of a multi-fingered hand controlled with a\nVLA model. We demonstrate this model switching approach results in a over 80\\%\nsuccess rate compared to under 40\\% when only using a VLA model, enabled by\naccurate near-object arm motion by the VLA model and a multi-modal grasping\nmotion with error recovery abilities from the diffusion model.",
    "pdf_url": "http://arxiv.org/pdf/2410.14022v1",
    "published": "2024-10-17T20:49:45+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.14749v1",
    "title": "CFTS-GAN: Continual Few-Shot Teacher Student for Generative Adversarial Networks",
    "authors": [
      "Munsif Ali",
      "Leonardo Rossi",
      "Massimo Bertozzi"
    ],
    "abstract": "Few-shot and continual learning face two well-known challenges in GANs:\noverfitting and catastrophic forgetting. Learning new tasks results in\ncatastrophic forgetting in deep learning models. In the case of a few-shot\nsetting, the model learns from a very limited number of samples (e.g. 10\nsamples), which can lead to overfitting and mode collapse. So, this paper\nproposes a Continual Few-shot Teacher-Student technique for the generative\nadversarial network (CFTS-GAN) that considers both challenges together. Our\nCFTS-GAN uses an adapter module as a student to learn a new task without\naffecting the previous knowledge. To make the student model efficient in\nlearning new tasks, the knowledge from a teacher model is distilled to the\nstudent. In addition, the Cross-Domain Correspondence (CDC) loss is used by\nboth teacher and student to promote diversity and to avoid mode collapse.\nMoreover, an effective strategy of freezing the discriminator is also utilized\nfor enhancing performance. Qualitative and quantitative results demonstrate\nmore diverse image synthesis and produce qualitative samples comparatively good\nto very stronger state-of-the-art models.",
    "pdf_url": "http://arxiv.org/pdf/2410.14749v1",
    "published": "2024-10-17T20:49:08+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14021v1",
    "title": "Design and Evaluation of Deep Reinforcement Learning for Energy Saving in Open RAN",
    "authors": [
      "Matteo Bordin",
      "Andrea Lacava",
      "Michele Polese",
      "Sai Satish",
      "Manoj AnanthaSwamy Nittoor",
      "Rajarajan Sivaraj",
      "Francesca Cuomo",
      "Tommaso Melodia"
    ],
    "abstract": "Next-generation wireless systems, already widely deployed, are expected to\nbecome even more prevalent in the future, representing challenges in both\nenvironmental and economic terms. This paper focuses on improving the energy\nefficiency of intelligent and programmable Open Radio Access Network (RAN)\nsystems through the near-real-time dynamic activation and deactivation of Base\nStation (BS) Radio Frequency (RF) frontends using Deep Reinforcement Learning\n(DRL) algorithms, i.e., Proximal Policy Optimization (PPO) and Deep Q-Network\n(DQN). These algorithms run on the RAN Intelligent Controllers (RICs), part of\nthe Open RAN architecture, and are designed to make optimal network-level\ndecisions based on historical data without compromising stability and\nperformance. We leverage a rich set of Key Performance Measurements (KPMs),\nserving as state for the DRL, to create a comprehensive representation of the\nRAN, alongside a set of actions that correspond to some control exercised on\nthe RF frontend. We extend ns-O-RAN, an open-source, realistic simulator for 5G\nand Open RAN built on ns-3, to conduct an extensive data collection campaign.\nThis enables us to train the agents offline with over 300,000 data points and\nsubsequently evaluate the performance of the trained models. Results show that\nDRL agents improve energy efficiency by adapting to network conditions while\nminimally impacting the user experience. Additionally, we explore the trade-off\nbetween throughput and energy consumption offered by different DRL agent\ndesigns.",
    "pdf_url": "http://arxiv.org/pdf/2410.14021v1",
    "published": "2024-10-17T20:48:37+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.14020v1",
    "title": "Segmentation of Pediatric Brain Tumors using a Radiologically informed, Deep Learning Cascade",
    "authors": [
      "Timothy Mulvany",
      "Daniel Griffiths-King",
      "Jan Novak",
      "Heather Rose"
    ],
    "abstract": "Monitoring of Diffuse Intrinsic Pontine Glioma (DIPG) and Diffuse Midline\nGlioma (DMG) brain tumors in pediatric patients is key for assessment of\ntreatment response. Response Assessment in Pediatric Neuro-Oncology (RAPNO)\nguidelines recommend the volumetric measurement of these tumors using MRI.\nSegmentation challenges, such as the Brain Tumor Segmentation (BraTS)\nChallenge, promote development of automated approaches which are replicable,\ngeneralizable and accurate, to aid in these tasks. The current study presents a\nnovel adaptation of existing nnU-Net approaches for pediatric brain tumor\nsegmentation, submitted to the BraTS-PEDs 2024 challenge. We apply an adapted\nnnU-Net with hierarchical cascades to the segmentation task of the BraTS-PEDs\n2024 challenge. The residual encoder variant of nnU-Net, used as our baseline\nmodel, already provides high quality segmentations. We incorporate multiple\nchanges to the implementation of nnU-Net and devise a novel two-stage cascaded\nnnU-Net to segment the substructures of brain tumors from coarse to fine. Using\noutputs from the nnU-Net Residual Encoder (trained to segment CC, ED, ET and\nNET tumor labels from T1w, T1w-CE, T2w and T2-FLAIR MRI), these are passed to\ntwo additional models one classifying ET versus NET and a second classifying CC\nvs ED using cascade learning. We use radiological guidelines to steer which\nmulti parametric MRI (mpMRI) to use in these cascading models. Compared to a\ndefault nnU-Net and an ensembled nnU-net as baseline approaches, our novel\nmethod provides robust segmentations for the BraTS-PEDs 2024 challenge,\nachieving mean Dice scores of 0.657, 0.904, 0.703, and 0.967, and HD95 of 76.2,\n10.1, 111.0, and 12.3 for the ET, NET, CC and ED, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2410.14020v1",
    "published": "2024-10-17T20:46:13+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14019v1",
    "title": "Data-Driven Discovery of Beam Centroid Dynamics",
    "authors": [
      "Liam A. Pocher",
      "Irving Haber",
      "Thomas M. Antonsen Jr.",
      "Patrick G. O'Shea"
    ],
    "abstract": "Understanding and predicting complex dynamics in accelerators is necessary\nfor their successful operation. A grand challenge in accelerator physics is to\ndevelop predictive virtual accelerators that mitigate design cost and schedule\nrisk. Data-driven techniques greatly appeal to generating virtual accelerators\ndue to their limited dimensionality compared with first-principle simulation,\nyet require significant up-front investment and lack interpretability in the\ncontext of governing equations. This paper uses an alternative, interpretable,\ndata-driven technique called Sparse Identification of Nonlinear Dynamics\n(SINDy) developed by University of Washington researchers to study nonlinear\nbeam centroid dynamics excited by realistic beam injection. We propose\nevolution equations based solely on data analysis and intuition of the\nunderlying lattice structure, without recourse to an underlying\nfirst-principles centroid model nor the actual lattice forcing functions. We do\nthis to mimic an application environment where analytic models are inadequate\nor where detailed lattice forcing functions are unknown. In the context of the\naccurate centroid model, we report and interpret SINDy's beam evolution\nequations learned from the training data and show favorable prediction results.\nWe compare with an alternative machine learning model used on the same training\ndata and contrast its prediction ability, computational expense, and\ninterpretability with SINDy's results.",
    "pdf_url": "http://arxiv.org/pdf/2410.14019v1",
    "published": "2024-10-17T20:36:35+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.17285v1",
    "title": "The Role of Community Building and Education as Key Pillar of Institutionalizing Responsible Quantum",
    "authors": [
      "Sanjay Vishwakarma",
      "Vishal Sharathchandra Bajpe",
      "Ryan Mandelbaum",
      "Yuri Kobayashi",
      "Olivia Lanes",
      "Mira Luca Wolf-Bauwens"
    ],
    "abstract": "Quantum computing is an emerging technology whose positive and negative\nimpacts on society are not yet fully known. As government, individuals,\ninstitutions, and corporations fund and develop this technology, they must\nensure that they anticipate its impacts, prepare for its consequences, and\nsteer its development in such a way that it enables the most good and prevents\nthe most harm. However, individual stakeholders are not equipped to fully\nanticipate these consequences on their own it requires a diverse community that\nis well-informed about quantum computing and its impacts. Collaborations and\ncommunity-building across domains incorporating a variety of viewpoints,\nespecially those from stakeholders most likely to be harmed, are fundamental\npillars of developing and deploying quantum computing responsibly. This paper\nreviews responsible quantum computing proposals and literature, highlights the\nchallenges in implementing these, and presents strategies developed at IBM\naimed at building a diverse community of users and stakeholders to support the\nresponsible development of this technology.",
    "pdf_url": "http://arxiv.org/pdf/2410.17285v1",
    "published": "2024-10-17T20:34:40+00:00",
    "categories": [
      "physics.soc-ph",
      "quant-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.14018v1",
    "title": "Toward a Real-Time Digital Twin Framework for Infection Mitigation During Air Travel",
    "authors": [
      "Ashok Srinivasan",
      "Satkkeerthi Sriram",
      "Sirish Namilae",
      "Andrew Arash Mahyari"
    ],
    "abstract": "Pedestrian dynamics simulates the fine-scaled trajectories of individuals in\na crowd. It has been used to suggest public health interventions to reduce\ninfection risk in important components of air travel, such as during boarding\nand in airport security lines. Due to inherent variability in human behavior,\nit is difficult to generalize simulation results to new geographic, cultural,\nor temporal contexts. A digital twin, relying on real-time data, such as video\nfeeds, can resolve this limitation. This paper addresses the following critical\ngaps in knowledge required for a digital twin. (1) Pedestrian dynamics models\ncurrently lack accurate representations of collision avoidance behavior when\ntwo moving pedestrians try to avoid collisions. (2) It is not known whether\ndata assimilation techniques designed for physical systems are effective for\npedestrian dynamics. We address the first limitation by training a model with\ndata from offline video feeds of collision avoidance to simulate these\ntrajectories realistically, using symbolic regression to identify unknown\nfunctional forms. We address the second limitation by showing that pedestrian\ndynamics with data assimilation can predict pedestrian trajectories with\nsufficient accuracy. These results promise to enable the development of a\ndigital twin for pedestrian movement in airports that can help with real-time\ncrowd management to reduce health risks.",
    "pdf_url": "http://arxiv.org/pdf/2410.14018v1",
    "published": "2024-10-17T20:34:03+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.14017v1",
    "title": "Probabilistic U-Net with Kendall Shape Spaces for Geometry-Aware Segmentations of Images",
    "authors": [
      "Jiyoung Park",
      "Günay Doğan"
    ],
    "abstract": "One of the fundamental problems in computer vision is image segmentation, the\ntask of detecting distinct regions or objects in given images. Deep Neural\nNetworks (DNN) have been shown to be very effective in segmenting challenging\nimages, producing convincing segmentations. There is further need for\nprobabilistic DNNs that can reflect the uncertainties from the input images and\nthe models into the computed segmentations, in other words, new DNNs that can\ngenerate multiple plausible segmentations and their distributions depending on\nthe input or the model uncertainties. While there are existing probabilistic\nsegmentation models, many of them do not take into account the geometry or\nshape underlying the segmented regions. In this paper, we propose a\nprobabilistic image segmentation model that can incorporate the geometry of a\nsegmentation. Our proposed model builds on the Probabilistic U-Net of\n\\cite{kohl2018probabilistic} to generate probabilistic segmentations, i.e.\\!\nmultiple likely segmentations for an input image. Our model also adopts the\nKendall Shape Variational Auto-Encoder of \\cite{vadgama2023kendall} to encode a\nKendall shape space in the latent variable layers of the prior and posterior\nnetworks of the Probabilistic U-Net. Incorporating the shape space in this\nmanner leads to a more robust segmentation with spatially coherent regions,\nrespecting the underlying geometry in the input images.",
    "pdf_url": "http://arxiv.org/pdf/2410.14017v1",
    "published": "2024-10-17T20:32:43+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14016v1",
    "title": "Stratifying Systems via Nested Family of Torsion Pairs",
    "authors": [
      "Edson Ribeiro Alvares",
      "Matheus Vinicius dos Santos"
    ],
    "abstract": "In this paper, we introduce the concept of a nested family of torsion pairs\nand will prove that this concept is strongly related to the existence of\nstratifying systems. Specifically, every stratifying system induces a nested\nfamily of torsion pairs. Moreover, every stratifying system can be obtained as\na quotient or submodule of a module that admits a certain direct sum\ndecomposition with respect to the nested family of torsion pairs. Additionally,\nwe present a stratifying system of infinite size that cannot be indexed by\n$\\mathbb{N}$.",
    "pdf_url": "http://arxiv.org/pdf/2410.14016v1",
    "published": "2024-10-17T20:32:37+00:00",
    "categories": [
      "math.RT",
      "math.CT",
      "16G10, 18E40, 18G20, 16D10, 16G20 (Primary)"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2410.14015v1",
    "title": "Poynting vector for Cauchy-Riemann beams",
    "authors": [
      "I. Julián-Macías",
      "F. Soto-Eguibar",
      "I. Ramos Prieto",
      "U. Ruiz",
      "N. Korneev",
      "D. Sánchez-de-la-Llave",
      "H. M. Moya-Cessa"
    ],
    "abstract": "We present a detailed derivation of the Poynting vector for Cauchy-Riemann\nbeams propagating in free space considering a Gaussian modulation with $g \\in\n\\mathbb{C}$. The effect generated by this Gaussian modulation is a\ncompression-expansion of the intensity distribution. It is shown that the\nparameter $g$ can reverse the direction of energy flux and eliminate the radial\ncomponent, resulting in a purely azimuthal field. Additionally, we validate our\nanalytical results through experimental verification.",
    "pdf_url": "http://arxiv.org/pdf/2410.14015v1",
    "published": "2024-10-17T20:31:46+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.14014v2",
    "title": "Quantifying systematic uncertainties in white dwarf cooling age determinations",
    "authors": [
      "Praneet Pathak",
      "Simon Blouin",
      "Falk Herwig"
    ],
    "abstract": "Cooling ages of white dwarfs are routinely determined by mapping effective\ntemperatures and masses to ages using evolutionary models. Typically, the\nreported uncertainties on cooling ages only consider the error propagation of\nthe uncertainties on the spectroscopically or photometrically determined\n$T_{\\rm eff}$ and mass. However, cooling models are themselves uncertain, given\ntheir dependence on many poorly constrained inputs. This paper estimates these\nsystematic model uncertainties. We use MESA to generate cooling sequences of\n$0.5-1.0 M_{\\odot}$ hydrogen-atmosphere white dwarfs with carbon-oxygen cores\nunder different assumptions regarding the chemical stratification of their\ncore, the thickness of their helium envelope, their hydrogen content, and the\nconductive opacities employed in the calculations. The parameter space explored\nis constrained by the range of values predicted by a variety of stellar\nevolution models and inferred from asteroseismological studies. For a $0.6\nM_{\\odot}$ white dwarf, we find an uncertainty of 0.03 Gyr at 10,000 K\n(corresponding to a 5% relative uncertainty) and 0.8 Gyr at 4000 K (9%). This\nuncertainty is significant, as it is comparable to the age uncertainty obtained\nby propagating the measurement errors on $T_{\\rm eff}$ and mass for a typical\nwhite dwarf. We also separately consider the potential impact of $^{22}$Ne\nshell distillation, which plausibly leads to an additional uncertainty of $\\sim\n1$ Gyr for crystallized white dwarfs. We provide a table of our simulation\nresults that can be used to evaluate the systematic model uncertainty based on\na white dwarf's $T_{\\rm eff}$ and mass. We encourage its use in all future\nstudies where white dwarf cooling ages are measured.",
    "pdf_url": "http://arxiv.org/pdf/2410.14014v2",
    "published": "2024-10-17T20:29:05+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.14013v1",
    "title": "Phase stability in the Hf-N and Zr-N systems",
    "authors": [
      "Jonathan Li",
      "Derick Ober",
      "Anton Van der Ven"
    ],
    "abstract": "Hf and Zr nitrides are promising compounds for many technologically important\nareas, including high temperature structural applications, quantum computing\nand solar/optical applications. This article reports on a comprehensive\nfirst-principles statistical mechanics study of phase stability in the Hf-N and\nZr-N binary systems. A high solubility of nitrogen in the hcp forms of Hf and\nZr is predicted. The rocksalt forms of HfN and ZrN can also tolerate a high\ndegree of off-stoichiometry through the introduction of nitrogen and metal\nvacancies. The Hf-N binary favors a family of stacking faulted parent crystal\nstructures at intermediate nitrogen concentrations that host a unique form of\nshort-range order among nitrogen interstitials and vacancies. These phases can\naccommodate some degree of configurational entropy and remain ordered to\ntemperatures as high as 1200K.",
    "pdf_url": "http://arxiv.org/pdf/2410.14013v1",
    "published": "2024-10-17T20:28:56+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.14012v2",
    "title": "LLMs are Biased Teachers: Evaluating LLM Bias in Personalized Education",
    "authors": [
      "Iain Weissburg",
      "Sathvika Anand",
      "Sharon Levy",
      "Haewon Jeong"
    ],
    "abstract": "With the increasing adoption of large language models (LLMs) in education,\nconcerns about inherent biases in these models have gained prominence. We\nevaluate LLMs for bias in the personalized educational setting, specifically\nfocusing on the models' roles as \"teachers.\" We reveal significant biases in\nhow models generate and select educational content tailored to different\ndemographic groups, including race, ethnicity, sex, gender, disability status,\nincome, and national origin. We introduce and apply two bias score\nmetrics--Mean Absolute Bias (MAB) and Maximum Difference Bias (MDB)--to analyze\n9 open and closed state-of-the-art LLMs. Our experiments, which utilize over\n17,000 educational explanations across multiple difficulty levels and topics,\nuncover that models potentially harm student learning by both perpetuating\nharmful stereotypes and reversing them. We find that bias is similar for all\nfrontier models, with the highest MAB along income levels while MDB is highest\nrelative to both income and disability status. For both metrics, we find the\nlowest bias exists for sex/gender and race/ethnicity.",
    "pdf_url": "http://arxiv.org/pdf/2410.14012v2",
    "published": "2024-10-17T20:27:44+00:00",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14011v1",
    "title": "Towards Reliability-Aware Active Distribution System Operations: A Sequential Convex Programming Approach",
    "authors": [
      "Gejia Zhang",
      "Robert Mieth"
    ],
    "abstract": "The increasing demand for electricity and the aging infrastructure of power\ndistribution systems have raised significant concerns about future system\nreliability. Failures in distribution systems, closely linked to system usage\nand environmental factors, are the primary contributors to electricity service\ninterruptions. The integration of distributed energy resources (DER) presents\nan opportunity to enhance system reliability through optimized operations. This\npaper proposes a novel approach that explicitly incorporates both decision- and\ncontext-dependent reliability into the optimization of control setpoints for\nDERs in active distribution systems. The proposed model captures how\noperational decisions and ambient temperature impact the likelihood of\ncomponent failures, enabling a balanced approach to cost efficiency and\nreliability. By leveraging a logistic function model for component failure\nrates and employing a sequential convex programming method, the model addresses\nthe challenges of non-convex optimization under decision-dependent uncertainty.\nNumerical case study on a modified IEEE $33$-bus test system demonstrates the\neffectiveness of the model in dynamically adjusting power flows and enhancing\nsystem robustness under varying environmental conditions and operational loads.\nThe results highlight the potential of DERs to contribute to distribution\nsystem reliability by efficiently managing power flows and responding to\nfluctuating energy demands.",
    "pdf_url": "http://arxiv.org/pdf/2410.14011v1",
    "published": "2024-10-17T20:25:53+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.14010v1",
    "title": "Conformal Prediction for Federated Graph Neural Networks with Missing Neighbor Information",
    "authors": [
      "Ömer Faruk Akgül",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "abstract": "Graphs play a crucial role in data mining and machine learning, representing\nreal-world objects and interactions. As graph datasets grow, managing large,\ndecentralized subgraphs becomes essential, particularly within federated\nlearning frameworks. These frameworks face significant challenges, including\nmissing neighbor information, which can compromise model reliability in\nsafety-critical settings. Deployment of federated learning models trained in\nsuch settings necessitates quantifying the uncertainty of the models. This\nstudy extends the applicability of Conformal Prediction (CP), a\nwell-established method for uncertainty quantification, to federated graph\nlearning. We specifically tackle the missing links issue in distributed\nsubgraphs to minimize its adverse effects on CP set sizes. We discuss data\ndependencies across the distributed subgraphs and establish conditions for CP\nvalidity and precise test-time coverage. We introduce a Variational\nAutoencoder-based approach for reconstructing missing neighbors to mitigate the\nnegative impact of missing data. Empirical evaluations on real-world datasets\ndemonstrate the efficacy of our approach, yielding smaller prediction sets\nwhile ensuring coverage guarantees.",
    "pdf_url": "http://arxiv.org/pdf/2410.14010v1",
    "published": "2024-10-17T20:22:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14009v1",
    "title": "Some properties of the quadrinomials $p(z)=1+κ(z+z^{N-1})+z^N$ and $q(z)=1+κ(z-z^{N-1})-z^N$",
    "authors": [
      "Dmitriy Dmitrishin",
      "Alexander Stokolos"
    ],
    "abstract": "We show that all the zeros of the quadrinomial $p(z)=1+\\kappa(z+z^{N-1})+z^N$\nlie on the unit circle if and only if the inequalities \\[ -1\\le\\kappa\\le 1\\;\n(\\mbox{ if $N$ is even}),\\;\\; -1\\le\\kappa\\le N/(N-2)\\; (\\mbox{ if $N$ is odd})\n\\] hold. For the quadrinomial $q(z)=1+\\kappa(z-z^{N-1})-z^N$, the corresponding\ninequalities are \\[\n  -N/(N-2)\\le\\kappa\\le 1\\; (\\text{ if $N$ is odd}),\\;\\;\n  -N/(N-2)\\le\\kappa\\le N/(N-2)\\; (\\text{ if $N$ is even}). \\] In the cases of\nlimiting values of the parameter $\\kappa$, we provide factorization formulas\nfor the corresponding quadrinomials. For example, when $N$ is odd and\n$\\kappa=N/(N-2)$, the following representation is valid: \\[\np(z)=(1+z)^3\\prod_{j=1}^{(N-3)/2}[1+z^2-2z\\gamma_j], \\] where\n$\\gamma_j=1-2\\nu_j^2$ with $\\{\\nu_j\\}_{j=1}^{(N-3)/2}$ being the collection of\npositive roots of the equation $U'_{N-2}(x)=0$; here \\[ U_j(x)=U_j(\\cos\nt)=\\frac{\\sin(j+1)t}{\\sin t}=2^j x^j+\\ldots \\] are Chebyshev polynomials of the\nsecond kind and $U'_j(x)$ are their derivatives. Similar factorization formulas\nare also provided for $q(z)$. As an application of the obtained results, we\ngive the factorization formulas for the derivative of the Fej\\'er polynomial,\nas well as construct certain univalent polynomials related to the polynomials\n$p(z)$ and $q(z)$.",
    "pdf_url": "http://arxiv.org/pdf/2410.14009v1",
    "published": "2024-10-17T20:22:00+00:00",
    "categories": [
      "math.CA",
      "26C10"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2410.14008v1",
    "title": "From Distributional Robustness to Robust Statistics: A Confidence Sets Perspective",
    "authors": [
      "Gabriel Chan",
      "Bart Van Parys",
      "Amine Bennouna"
    ],
    "abstract": "We establish a connection between distributionally robust optimization (DRO)\nand classical robust statistics. We demonstrate that this connection arises\nnaturally in the context of estimation under data corruption, where the goal is\nto construct ``minimal'' confidence sets for the unknown data-generating\ndistribution. Specifically, we show that a DRO ambiguity set, based on the\nKullback-Leibler divergence and total variation distance, is uniformly minimal,\nmeaning it represents the smallest confidence set that contains the unknown\ndistribution with at a given confidence power. Moreover, we prove that when\nparametric assumptions are imposed on the unknown distribution, the ambiguity\nset is never larger than a confidence set based on the optimal estimator\nproposed by Huber. This insight reveals that the commonly observed conservatism\nof DRO formulations is not intrinsic to these formulations themselves but\nrather stems from the non-parametric framework in which these formulations are\nemployed.",
    "pdf_url": "http://arxiv.org/pdf/2410.14008v1",
    "published": "2024-10-17T20:20:42+00:00",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.14007v1",
    "title": "Asymptotic spreading of KPP reactive fronts in heterogeneous shifting environments II: Flux-limited solutions",
    "authors": [
      "King-Yeung Lam",
      "Gregoire Nadin",
      "Xiao Yu"
    ],
    "abstract": "We consider the spreading dynamics of the Fisher-KPP equation in a shifting\nenvironment, by analyzing the limit of the rate function of the solutions. For\nenvironments with a weak monotone condition, it was demonstrated in a previous\npaper that the rate function converges to the unique Ishii solution of the\nunderlying Hamilton-Jacobi equations. In case the environment does not satisfy\nthe weak monotone condition, we show that the rate function is then\ncharacterized by the Hamilton-Jacobi equation with a dynamic junction\ncondition, which depends additionally on the generalized eigenvalue derived\nfrom the environmental function. Our results applies to the case when the\nenvironment has multiple shifting speeds, and clarify the connection with\nprevious results on nonlocally pulled fronts and forced traveling waves.",
    "pdf_url": "http://arxiv.org/pdf/2410.14007v1",
    "published": "2024-10-17T20:20:29+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.14006v2",
    "title": "On level 2 Modular differential equations",
    "authors": [
      "Khalil Besrour",
      "Abdellah Sebbar"
    ],
    "abstract": "In this paper, we explore the modular differential equation $\\displaystyle\ny'' + F(z)y = 0$ on the upper half-plane $\\mathbb{H}$, where $F$ is a weight 4\nmodular form for $\\Gamma_0(2)$. Our approach centers on solving the associated\nSchwarzian equation $\\displaystyle \\{h, z\\} = 2F(z)$, where $\\{h, z\\}$\nrepresents the Schwarzian derivative of a meromorphic function $h$ on\n$\\mathbb{H}$. We derive conditions under which the solutions to this equation\nare modular functions for subgroups of the modular group and provide explicit\nexpressions for these solutions in terms of classical modular functions. Key\ntools in our analysis include the theory of equivariant functions on the upper\nhalf-plane and the representation theory of level 2 subgroups of the modular\ngroup.",
    "pdf_url": "http://arxiv.org/pdf/2410.14006v2",
    "published": "2024-10-17T20:19:33+00:00",
    "categories": [
      "math.NT",
      "math.CA",
      "11F03, 11F11, 34M05"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2410.14005v1",
    "title": "Whisker-Inspired Tactile Sensing: A Sim2Real Approach for Precise Underwater Contact Tracking",
    "authors": [
      "Hao Li",
      "Chengyi Xing",
      "Saad Khan",
      "Miaoya Zhong",
      "Mark R. Cutkosky"
    ],
    "abstract": "Aquatic mammals, such as pinnipeds, utilize their whiskers to detect and\ndiscriminate objects and analyze water movements, inspiring the development of\nrobotic whiskers for sensing contacts, surfaces, and water flows. We present\nthe design and application of underwater whisker sensors based on Fiber Bragg\nGrating (FBG) technology. These passive whiskers are mounted along the\nrobot$'$s exterior to sense its surroundings through light, non-intrusive\ncontacts. For contact tracking, we employ a sim-to-real learning framework,\nwhich involves extensive data collection in simulation followed by a\nsim-to-real calibration process to transfer the model trained in simulation to\nthe real world. Experiments with whiskers immersed in water indicate that our\napproach can track contact points with an accuracy of $<2$ mm, without\nrequiring precise robot proprioception. We demonstrate that the approach also\ngeneralizes to unseen objects.",
    "pdf_url": "http://arxiv.org/pdf/2410.14005v1",
    "published": "2024-10-17T20:19:01+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.14004v1",
    "title": "Modeling the transition from pay-as-you-go to a fully funded pension system in Russia",
    "authors": [
      "Kirill Moiseev"
    ],
    "abstract": "In countries with a growing number of elderly and a shrinking workforce, one\nof which is Russia, it becomes impossible to maintain a solidary pension system\nand a need to switch to a more stable funded system appears. This paper\nanalyzes various scenarios of Russia's transition to such a system. This is the\nfirst study on the Russian economy in which an Overlapping Generations Model is\nused to simulate the pension transition. It is demonstrated that in the long\nterm, the transition to a funded system slightly reduces the welfare of\npensioners, and during the transition, the situation of pensioners deteriorates\nstrongly. However, it is also important to emphasize that the transition\nimposes a heavy burden on all generations living during the reform, they are\nforced to consume less and greatly change their savings, while also often\nstarting to work more. Such conclusions are made concerning average population\ncohorts, and the results may not be the same for different groups of\nindividuals within these cohorts. In different scenarios, the pension system\ntransition can cause both economic growth and economic recession, as well as a\ncorresponding increase or decrease in wages and consumption.",
    "pdf_url": "http://arxiv.org/pdf/2410.14004v1",
    "published": "2024-10-17T20:15:14+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2410.14003v2",
    "title": "Per-Bank Bandwidth Regulation of Shared Last-Level Cache for Real-Time Systems",
    "authors": [
      "Connor Sullivan",
      "Alex Manley",
      "Mohammad Alian",
      "Heechul Yun"
    ],
    "abstract": "Modern commercial-off-the-shelf (COTS) multicore processors have advanced\nmemory hierarchies that enhance memory-level parallelism (MLP), which is\ncrucial for high performance. To support high MLP, shared last-level caches\n(LLCs) are divided into multiple banks, allowing parallel access. However,\nuneven distribution of cache requests from the cores, especially when requests\nfrom multiple cores are concentrated on a single bank, can result in\nsignificant contention affecting all cores that access the cache. Such cache\nbank contention can even be maliciously induced -- known as cache bank-aware\ndenial-of-service (DoS) attacks -- in order to jeopardize the system's timing\npredictability.\n  In this paper, we propose a per-bank bandwidth regulation approach for\nmulti-banked shared LLC based multicore real-time systems. By regulating\nbandwidth on a per-bank basis, the approach aims to prevent unnecessary\nthrottling of cache accesses to non-contended banks, thus improving overall\nperformance (throughput) without compromising isolation benefits of throttling.\nWe implement our approach on a RISC-V system-on-chip (SoC) platform using\nFireSim and evaluate extensively using both synthetic and real-world workloads.\nOur evaluation results show that the proposed per-bank regulation approach\neffectively protects real-time tasks from co-running cache bank-aware DoS\nattacks, and offers up to a 3.66$\\times$ performance improvement for the\nthrottled benign best-effort tasks compared to prior bank-oblivious bandwidth\nthrottling approaches.",
    "pdf_url": "http://arxiv.org/pdf/2410.14003v2",
    "published": "2024-10-17T20:11:34+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2410.14002v1",
    "title": "A note on Bayesian R-squared for generalized additive mixed models",
    "authors": [
      "Abdollah Jalilian",
      "Aki Vehtari",
      "Luigi Sedda"
    ],
    "abstract": "We present a novel Bayesian framework to decompose the posterior predictive\nvariance in a fitted Generalized Additive Mixed Model (GAMM) into explained and\nunexplained components. This decomposition enables a rigorous definition of\nBayesian $R^{2}$. We show that the new definition aligns with the intuitive\nBayesian $R^{2}$ proposed by Gelman, Goodrich, Gabry, and Vehtari (2019)\n[\\emph{The American Statistician}, \\textbf{73}(3), 307-309], but extends its\napplicability to a broader class of models. Furthermore, we introduce a partial\nBayesian $R^{2}$ to quantify the contribution of individual model terms to the\nexplained variation in the posterior predictions",
    "pdf_url": "http://arxiv.org/pdf/2410.14002v1",
    "published": "2024-10-17T20:09:20+00:00",
    "categories": [
      "stat.ME",
      "62F15, 62J12, 62J20"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.14001v1",
    "title": "Personalized Adaptation via In-Context Preference Learning",
    "authors": [
      "Allison Lau",
      "Younwoo Choi",
      "Vahid Balazadeh",
      "Keertana Chidambaram",
      "Vasilis Syrgkanis",
      "Rahul G. Krishnan"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is widely used to align\nLanguage Models (LMs) with human preferences. However, existing approaches\noften neglect individual user preferences, leading to suboptimal\npersonalization. We present the Preference Pretrained Transformer (PPT), a\nnovel approach for adaptive personalization using online user feedback. PPT\nleverages the in-context learning capabilities of transformers to dynamically\nadapt to individual preferences. Our approach consists of two phases: (1) an\noffline phase where we train a single policy model using a history-dependent\nloss function, and (2) an online phase where the model adapts to user\npreferences through in-context learning. We demonstrate PPT's effectiveness in\na contextual bandit setting, showing that it achieves personalized adaptation\nsuperior to existing methods while significantly reducing the computational\ncosts. Our results suggest the potential of in-context learning for scalable\nand efficient personalization in large language models.",
    "pdf_url": "http://arxiv.org/pdf/2410.14001v1",
    "published": "2024-10-17T20:06:02+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14000v2",
    "title": "Minimal pole representation and analytic continuation of matrix-valued correlation functions",
    "authors": [
      "Lei Zhang",
      "Yang Yu",
      "Emanuel Gull"
    ],
    "abstract": "We present a minimal pole method for analytically continuing matrix-valued\nimaginary frequency correlation functions to the real axis, enabling precise\naccess to off-diagonal elements and thus improving the interpretation of\nself-energies and susceptibilities in quantum simulations. Traditional methods\nfor matrix-valued analytic continuation tend to be either noise-sensitive or\nmake ad-hoc positivity assumptions. Our approach avoides these issues via the\nconstruction of a compact pole representation with shared poles through\nexponential fits, expanding upon prior work focused on scalar functions. We\ntest our method across various scenarios, including fermionic and bosonic\nresponse functions, with and without noise, and for both continuous and\ndiscrete spectra of real materials and model systems. Our findings demonstrate\nthat this technique addresses the shortcomings of existing methodologies, such\nas artificial broadening and positivity violations. The paper is supplemented\nwith a sample implementation in Python.",
    "pdf_url": "http://arxiv.org/pdf/2410.14000v2",
    "published": "2024-10-17T20:03:15+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13999v2",
    "title": "FUSION: A Flexible Unified Simulator for Intelligent Optical Networking",
    "authors": [
      "Ryan McCann",
      "Arash Rezaee",
      "Vinod M. Vokkarane"
    ],
    "abstract": "The increasing demand for flexible and efficient optical networks has led to\nthe development of Software-Defined Elastic Optical Networks (SD-EONs). These\nnetworks leverage the programmability of Software-Defined Networking (SDN) and\nthe adaptability of Elastic Optical Networks (EONs) to optimize network\nperformance under dynamic traffic conditions. However, existing simulation\ntools often fall short in terms of transparency, flexibility, and advanced\nfunctionality, limiting their utility in cutting-edge research. In this paper,\nwe present a Flexible Unified Simulator for Intelligent Optical Networking\n(FUSION), a fully open-source simulator designed to address these limitations\nand provide a comprehensive platform for SD-EON research. FUSION integrates\ntraditional routing and spectrum assignment algorithms with advanced machine\nlearning and reinforcement learning techniques, including support for the\nStable Baselines 3 library. The simulator also offers robust unit testing, a\nfully functional Graphical User Interface (GUI), and extensive documentation to\nensure usability and reliability. Performance evaluations demonstrate the\neffectiveness of FUSION in modeling complex network scenarios, showcasing its\npotential as a powerful tool for advancing SD-EON research.",
    "pdf_url": "http://arxiv.org/pdf/2410.13999v2",
    "published": "2024-10-17T19:59:35+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13998v1",
    "title": "pyEQUIB Python Package, an addendum to proEQUIB: IDL Library for Plasma Diagnostics and Abundance Analysis",
    "authors": [
      "A. Danehkar"
    ],
    "abstract": "The emission lines from ionized nebulae allow us to determine their physical\nand chemical properties, along with the interstellar extinction. \"pyEQUIB\" is a\npure Python open-source package including several application programming\ninterface (API) functions that can be employed for plasma diagnostics,\nabundance analysis of collisionally excited lines (CEL) and recombination lines\n(RL) in nebular astrophysics, and extinction analysis of Balmer lines. This\npackage implements the IDL library \"proEQUIB\" in Python and couples it with the\n\"AtomNeb\" Python package. This package relies on the Python packages NumPy and\nSciPy. The API functions of this package can be used for studies of ionized\nnebulae by astronomers who are familiar with the high-level, general-purpose\nprogramming language Python.",
    "pdf_url": "http://arxiv.org/pdf/2410.13998v1",
    "published": "2024-10-17T19:57:54+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13997v1",
    "title": "On quartics with the maximal number of the maximal tangency lines",
    "authors": [
      "Łukasz Merta",
      "Marcin Zieliński"
    ],
    "abstract": "In this note, we examine the arrangements of lines and configurations of\npoints that emerge from Fermat (von Dyck) and Komiya-Kuribayashi quartics.\nThese quartics are characterized by having the maximum number of lines of\nmaximal tangency, that is, lines for which the intersection multiplicity at the\ntangency point is equal to the degree of the curve. Additionally, we delve into\nthe study of sextactic points on these quartics - points at which there exists\na conic with the curve having a local intersection multiplicity of at least 6,\nwhich is one more than that observed at a general point - alongside the related\nconfigurations of conics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13997v1",
    "published": "2024-10-17T19:53:45+00:00",
    "categories": [
      "math.AG",
      "14C20 (Primary), 14N20 (Secondary)"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13996v2",
    "title": "Existence of Vacuum Wormholes in Einsteinian Cubic Gravity",
    "authors": [
      "Mengqi Lu",
      "Jiayue Yang",
      "Robert B. Mann"
    ],
    "abstract": "Wormhole solutions in gravitational theories typically require exotic matter.\nHere we present a wormhole solution to the field equations of Einsteinian Cubic\nGravity -- a phenomenological competitor to general relativity that includes\nterms cubic in the curvature -- that has no matter, exotic or otherwise. These\npurely gravitational wormhole geometries are asymptotically AdS but contain a\ngeometric deficit at infinity. The deficit, interpreted as a global monopole,\nplays an essential role in our construction. We find that our wormhole solution\nsatisfies traversablility criteria. We also find, for different parameters, a\nrange of possible wormhole solutions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13996v2",
    "published": "2024-10-17T19:51:15+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13995v3",
    "title": "Adversarial Inception Backdoor Attacks against Reinforcement Learning",
    "authors": [
      "Ethan Rathbun",
      "Alina Oprea",
      "Christopher Amato"
    ],
    "abstract": "Recent works have demonstrated the vulnerability of Deep Reinforcement\nLearning (DRL) algorithms against training-time, backdoor poisoning attacks.\nThe objectives of these attacks are twofold: induce pre-determined, adversarial\nbehavior in the agent upon observing a fixed trigger during deployment while\nallowing the agent to solve its intended task during training. Prior attacks\nassume arbitrary control over the agent's rewards, inducing values far outside\nthe environment's natural constraints. This results in brittle attacks that\nfail once the proper reward constraints are enforced. Thus, in this work we\npropose a new class of backdoor attacks against DRL which are the first to\nachieve state of the art performance under strict reward constraints. These\n\"inception\" attacks manipulate the agent's training data -- inserting the\ntrigger into prior observations and replacing high return actions with those of\nthe targeted adversarial behavior. We formally define these attacks and prove\nthey achieve both adversarial objectives against arbitrary Markov Decision\nProcesses (MDP). Using this framework we devise an online inception attack\nwhich achieves an 100\\% attack success rate on multiple environments under\nconstrained rewards while minimally impacting the agent's task performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13995v3",
    "published": "2024-10-17T19:50:28+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13994v1",
    "title": "Vacancy-induced suppression of CDW order and its impact on magnetic order in kagome antiferromagnet FeGe",
    "authors": [
      "Mason L. Klemm",
      "Saif Siddique",
      "Yuan-Chun Chang",
      "Sijie Xu",
      "Yaofeng Xie",
      "Tanner Legvold",
      "Mehrdad T. Kiani",
      "Feng Ye",
      "Huibo Cao",
      "Yiqing Hao",
      "Wei Tian",
      "Hubertus Luetkens",
      "Masaaki Matsuda",
      "Douglas Natelson",
      "Zurab Guguchia",
      "Chien-Lung Huang",
      "Ming Yi",
      "Judy J. Cha",
      "Pengcheng Dai"
    ],
    "abstract": "Two-dimensional (2D) kagome lattice metals are interesting because they\ndisplay flat electronic bands, Dirac points, Van Hove singularities, and can\nhave interplay between charge density wave (CDW), magnetic order, and\nsuperconductivity. In kagome lattice antiferromagnet FeGe, a short-range CDW\norder was found deep within an antiferromagnetically ordered state, interacting\nwith the magnetic order. Surprisingly, post-growth annealing of FeGe at\n560$^{\\circ}$C can suppress the CDW order while annealing at 320$^{\\circ}$C\ninduces a long-range CDW order, with the ability to cycle between the states\nrepeatedly by annealing. Here we perform transport, neutron scattering,\nscanning transmission electron microscopy (STEM), and muon spin rotation\n($\\mu$SR) experiments to unveil the microscopic mechanism of the annealing\nprocess and its impact on magneto-transport, CDW, and magnetic properties of\nFeGe. We find that 560$^{\\circ}$C annealing creates germanium vacancies\nuniformly distributed throughout the FeGe kagome lattice, which prevent the\nformation of Ge-Ge dimers necessary for the CDW order. Upon annealing at\n320$^{\\circ}$C, the system segregates into stoichiometric FeGe regions with\nlong-range CDW order and regions with stacking faults that act as nucleation\nsites for the CDW. The presence or absence of CDW order greatly affects the\nanomalous Hall effect, incommensurate magnetic order, and spin-lattice coupling\nin FeGe, thus placing FeGe as the only known kagome lattice material with a\ntunable CDW and magnetic order, potentially useful for sensing and information\ntransmission.",
    "pdf_url": "http://arxiv.org/pdf/2410.13994v1",
    "published": "2024-10-17T19:49:47+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13993v2",
    "title": "Probing hidden topology with quantum detectors",
    "authors": [
      "Dyuman Bhattacharya",
      "Jorma Louko",
      "Robert B. Mann"
    ],
    "abstract": "We consider the transition rate of a static Unruh-DeWitt detector in two\n$(2+1)$-dimensional black hole spacetimes that are isometric to the static\nBa\\~nados-Teitelboim-Zanelli black hole outside the horizon but have no\nasymptotically locally anti-de Sitter exterior behind the horizon. The\nspacetimes are the $\\mathbb{R}\\text{P}^{2}$ geon, with spatial topology\n$\\mathbb{R}\\text{P}^{2}\\setminus\\{\\text{point at infinity}\\}$, and the Swedish\ngeon of \\AA{}minneborg \\emph{et al\\/}, with spatial topology\n$T^{2}\\setminus\\{\\text{point at infinity}\\}$. For a conformal scalar field,\nprepared in the Hartle-Hawking-type state that is induced from the global\nvacuum on the anti-de Sitter covering space, we show numerically that the\ndetector's transition rate distinguishes the two spacetimes, particularly at\nlate exterior times, and we trace this phenomenon to the differences in the\nisometries that are broken by the quotient construction from the universal\ncovering space. Our results provide an example in which information about the\ninterior topology of a black hole is accessible to a quantum observer outside\nthe black hole.",
    "pdf_url": "http://arxiv.org/pdf/2410.13993v2",
    "published": "2024-10-17T19:49:19+00:00",
    "categories": [
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13992v1",
    "title": "Resilience-Oriented DG Siting and Sizing Considering Energy Equity Constraint",
    "authors": [
      "Chenchen Li",
      "Fangxing Li",
      "Sufan Jiang",
      "Jin Zhao",
      "Shiyuan Fan",
      "Leon M. Tolbert"
    ],
    "abstract": "Extreme weather events can cause widespread power outages and huge economic\nlosses. Low-income customers are more vulnerable to power outages because they\nlive in areas with poorly equipped distribution systems. However, existing\napproaches to improve grid resilience focus on the overall condition of the\nsystem and ignore the outage experiences of low-income customers, which leads\nto significant energy inequities in resilience. Therefore, this paper explores\na new resilience-oriented planning method for distributed generator (DG) siting\nand sizing, by embedding an additional energy equity constraint (EEC). First,\nthe expected load shedding index (ELSI) is defined as the ratio of the load\nshedding to the original load, which quantifies the resilience-oriented energy\nequity. Then, the DG siting and sizing problem is formulated as a two-stage\nstochastic programming with the EEC. The first stage determines the optimal\nsites and sizes of DG units under investment constraints and EECs, while the\nsecond stage optimizes expected costs of unserved load. A subsidiary variable\nis introduced to ensure the model's solvability. Finally, numerical studies are\nperformed on the IEEE 33-bus and 123-bus systems to verify the effectiveness of\nthe proposed DG planning model in achieving energy equity. Three observations\nare presented as future guidelines for resilience-oriented DG planning.",
    "pdf_url": "http://arxiv.org/pdf/2410.13992v1",
    "published": "2024-10-17T19:47:00+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13991v1",
    "title": "Generalization for Least Squares Regression With Simple Spiked Covariances",
    "authors": [
      "Jiping Li",
      "Rishi Sonthalia"
    ],
    "abstract": "Random matrix theory has proven to be a valuable tool in analyzing the\ngeneralization of linear models. However, the generalization properties of even\ntwo-layer neural networks trained by gradient descent remain poorly understood.\nTo understand the generalization performance of such networks, it is crucial to\ncharacterize the spectrum of the feature matrix at the hidden layer. Recent\nwork has made progress in this direction by describing the spectrum after a\nsingle gradient step, revealing a spiked covariance structure. Yet, the\ngeneralization error for linear models with spiked covariances has not been\npreviously determined. This paper addresses this gap by examining two simple\nmodels exhibiting spiked covariances. We derive their generalization error in\nthe asymptotic proportional regime. Our analysis demonstrates that the\neigenvector and eigenvalue corresponding to the spike significantly influence\nthe generalization error.",
    "pdf_url": "http://arxiv.org/pdf/2410.13991v1",
    "published": "2024-10-17T19:46:51+00:00",
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2410.13990v1",
    "title": "A tree approach to the happy function",
    "authors": [
      "Eva G. Goedhart",
      "Yusuf Gurtas",
      "Pamela E. Harris"
    ],
    "abstract": "In this article, we present a method to construct $e$-power $b$-happy numbers\nof any height. Using this method, we construct a tree that encodes these happy\nnumbers, their heights, and their ancestry--relation to other happy numbers.\nFor fixed power $e$ and base $b$, we consider happy numbers with at most $k$\ndigits and we give a formula for the cardinality of the preimage of a single\niteration of the happy function. We show that these happy numbers arise\nnaturally as children of a given vertex in the tree. We conclude by applying\nthis technique to $e$-power $b$-unhappy numbers of a given height.",
    "pdf_url": "http://arxiv.org/pdf/2410.13990v1",
    "published": "2024-10-17T19:42:27+00:00",
    "categories": [
      "math.NT",
      "11A63"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13989v1",
    "title": "Reproducibility study of \"LICO: Explainable Models with Language-Image Consistency\"",
    "authors": [
      "Luan Fletcher",
      "Robert van der Klis",
      "Martin Sedláček",
      "Stefan Vasilev",
      "Christos Athanasiadis"
    ],
    "abstract": "The growing reproducibility crisis in machine learning has brought forward a\nneed for careful examination of research findings. This paper investigates the\nclaims made by Lei et al. (2023) regarding their proposed method, LICO, for\nenhancing post-hoc interpretability techniques and improving image\nclassification performance. LICO leverages natural language supervision from a\nvision-language model to enrich feature representations and guide the learning\nprocess. We conduct a comprehensive reproducibility study, employing (Wide)\nResNets and established interpretability methods like Grad-CAM and RISE. We\nwere mostly unable to reproduce the authors' results. In particular, we did not\nfind that LICO consistently led to improved classification performance or\nimprovements in quantitative and qualitative measures of interpretability.\nThus, our findings highlight the importance of rigorous evaluation and\ntransparent reporting in interpretability research.",
    "pdf_url": "http://arxiv.org/pdf/2410.13989v1",
    "published": "2024-10-17T19:41:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13988v2",
    "title": "Quantum dynamics of atoms in number-theory-inspired potentials",
    "authors": [
      "D. Cassettari",
      "O. V. Marchukov",
      "B. Carruthers",
      "H. Kendell",
      "J. Ruhl",
      "B. De Mitchell Pierre",
      "C. Zara",
      "C. A. Weidner",
      "A. Trombettoni",
      "M. Olshanii",
      "G. Mussardo"
    ],
    "abstract": "In this paper we study transitions of atoms between energy levels of several\nnumber-theory-inspired atom potentials, under the effect of time-dependent\nperturbations. First, we simulate in detail the case of a trap whose\none-particle spectrum is given by prime numbers. We investigate one-body Rabi\noscillations and the excitation lineshape for two resonantly coupled energy\nlevels. We also show that techniques from quantum control are effective in\nreducing the transition time, compared to the case of a periodic perturbation.\nNext, we investigate cascades of such transitions. To this end, we pose the\nfollowing question: can one construct a quantum system where the existence of a\ncontinuous resonant cascade is predicted on the validity of a particular\nstatement in number theory? We find that a one-body trap with a log-natural\nspectrum, parametrically driven with a perturbation of a log-natural frequency,\nprovides such a quantum system. Here, powers of a given natural number will\nform a ladder of equidistant energy levels; absence of gaps in this ladder is\nan indication of the validity of the number theory statement in question. Ideas\nfor two more resonance cascade experiments are presented as well: they are\ndesigned to illustrate the validity of the Diophantus-Brahmagupta-Fibonacci\nidentity (the set of sums of two squares of integers is closed under\nmultiplication) and the validity of the Goldbach conjecture (every even number\nis a sum of two primes).",
    "pdf_url": "http://arxiv.org/pdf/2410.13988v2",
    "published": "2024-10-17T19:39:15+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.quant-gas"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.14748v4",
    "title": "ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries",
    "authors": [
      "Kishan Maharaj",
      "Vitobha Munigala",
      "Srikanth G. Tamilselvam",
      "Prince Kumar",
      "Sayandeep Sen",
      "Palani Kodeswaran",
      "Abhijit Mishra",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced their ability to understand both natural language and code, driving\ntheir use in tasks like natural language-to-code (NL2Code) and code\nsummarisation. However, LLMs are prone to hallucination, outputs that stray\nfrom intended meanings. Detecting hallucinations in code summarisation is\nespecially difficult due to the complex interplay between programming and\nnatural languages. We introduce a first-of-its-kind dataset, CodeSumEval, with\n~10K samples, curated specifically for hallucination detection in code\nsummarisation. We further propose a novel Entity Tracing Framework (ETF) that\na) utilises static program analysis to identify code entities from the program\nand b) uses LLMs to map and verify these entities and their intents within\ngenerated code summaries. Our experimental analysis demonstrates the\nframework's effectiveness, leading to a 73% F1 score. The proposed approach\nprovides a method for detecting hallucinations by tracing entities from the\nsummary to the code, allowing us to evaluate summary accuracy and localise the\nerror within the summary.",
    "pdf_url": "http://arxiv.org/pdf/2410.14748v4",
    "published": "2024-10-17T19:38:55+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13987v1",
    "title": "RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs",
    "authors": [
      "Jiatan Huang",
      "Mingchen Li",
      "Zonghai Yao",
      "Zhichao Yang",
      "Yongkang Xiao",
      "Feiyun Ouyang",
      "Xiaohan Li",
      "Shuo Han",
      "Hong Yu"
    ],
    "abstract": "Answering complex real-world questions often requires accurate retrieval from\ntextual knowledge graphs (TKGs). The scarcity of annotated data, along with\nintricate topological structures, makes this task particularly challenging. As\nthe nature of relational path information could enhance the inference ability\nof Large Language Models (LLMs), efficiently retrieving more complex relational\npath information from TKGs presents another key challenge. To tackle these\nchallenges, we first develop a Dataset for LLMs Complex Reasoning over Textual\nKnowledge Graphs (RiTeK) with a broad topological structure coverage.We\nsynthesize realistic user queries that integrate diverse topological\nstructures, relational information, and complex textual descriptions. We\nconduct rigorous expert evaluation to validate the quality of our synthesized\nqueries. And then, we introduce an enhanced Monte Carlo Tree Search (MCTS)\nmethod, Relational MCTS, to automatically extract relational path information\nfrom textual graphs for specific queries. Our dataset mainly covers the medical\ndomain as the relation types and entity are complex and publicly available.\nExperimental results indicate that RiTeK poses significant challenges for\ncurrent retrieval and LLM systems, while the proposed Relational MCTS method\nenhances LLM inference ability and achieves state-of-the-art performance on\nRiTeK.",
    "pdf_url": "http://arxiv.org/pdf/2410.13987v1",
    "published": "2024-10-17T19:33:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13986v4",
    "title": "Recurrent Neural Goodness-of-Fit Test for Time Series",
    "authors": [
      "Aoran Zhang",
      "Wenbin Zhou",
      "Liyan Xie",
      "Shixiang Zhu"
    ],
    "abstract": "Time series data are crucial across diverse domains such as finance and\nhealthcare, where accurate forecasting and decision-making rely on advanced\nmodeling techniques. While generative models have shown great promise in\ncapturing the intricate dynamics inherent in time series, evaluating their\nperformance remains a major challenge. Traditional evaluation metrics fall\nshort due to the temporal dependencies and potential high dimensionality of the\nfeatures. In this paper, we propose the REcurrent NeurAL (RENAL)\nGoodness-of-Fit test, a novel and statistically rigorous framework for\nevaluating generative time series models. By leveraging recurrent neural\nnetworks, we transform the time series into conditionally independent data\npairs, enabling the application of a chi-square-based goodness-of-fit test to\nthe temporal dependencies within the data. This approach offers a robust,\ntheoretically grounded solution for assessing the quality of generative models,\nparticularly in settings with limited time sequences. We demonstrate the\nefficacy of our method across both synthetic and real-world datasets,\noutperforming existing methods in terms of reliability and accuracy. Our method\nfills a critical gap in the evaluation of time series generative models,\noffering a tool that is both practical and adaptable to high-stakes\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2410.13986v4",
    "published": "2024-10-17T19:32:25+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13985v3",
    "title": "GRB Redshift Estimation using Machine Learning and the Associated Web-App",
    "authors": [
      "Aditya Narendra",
      "Maria Dainotti",
      "Milind Sarkar",
      "Aleksander Lenart",
      "Malgorzata Bogdan",
      "Agnieszka Pollo",
      "Bing Zhang",
      "Aleksandra Rabeda",
      "Vahe Petrosian",
      "Iwasaki Kazunari"
    ],
    "abstract": "Context. Gamma-ray bursts (GRBs), observed at redshifts as high as 9.4, could\nserve as valuable probes for investigating the distant Universe. However, this\nnecessitates an increase in the number of GRBs with determined redshifts, as\ncurrently, only 12% of GRBs have known redshifts due to observational biases.\nAims. We aim to address the shortage of GRBs with measured redshifts, enabling\nus to fully realize their potential as valuable cosmological probes Methods.\nFollowing Dainotti et al. (2024c), we have taken a second step to overcome this\nissue by adding 30 more GRBs to our ensemble supervised machine learning\ntraining sample, an increase of 20%, which will help us obtain better redshift\nestimates. In addition, we have built a freely accessible and user-friendly web\napp that infers the redshift of long GRBs (LGRBs) with plateau emission using\nour machine learning model. The web app is the first of its kind for such a\nstudy and will allow the community to obtain redshift estimates by entering the\nGRB parameters in the app. Results. Through our machine learning model, we have\nsuccessfully estimated redshifts for 276 LGRBs using X-ray afterglow parameters\ndetected by the Neil Gehrels Swift Observatory and increased the sample of\nLGRBs with known redshifts by 110%. We also perform Monte Carlo simulations to\ndemonstrate the future applicability of this research. Conclusions. The results\npresented in this research will enable the community to increase the sample of\nGRBs with known redshift estimates. This can help address many outstanding\nissues, such as GRB formation rate, luminosity function, and the true nature of\nlow-luminosity GRBs, and enable the application of GRBs as standard candles",
    "pdf_url": "http://arxiv.org/pdf/2410.13985v3",
    "published": "2024-10-17T19:30:58+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.14747v1",
    "title": "Continuous Wavelet Transformation and VGG16 Deep Neural Network for Stress Classification in PPG Signals",
    "authors": [
      "Yasin Hasanpoor",
      "Bahram Tarvirdizadeh",
      "Khalil Alipour",
      "Mohammad Ghamari"
    ],
    "abstract": "Our research introduces a groundbreaking approach to stress classification\nthrough Photoplethysmogram (PPG) signals. By combining Continuous Wavelet\nTransformation (CWT) with the proven VGG16 classifier, our method enhances\nstress assessment accuracy and reliability. Previous studies highlighted the\nimportance of physiological signal analysis, yet precise stress classification\nremains a challenge. Our approach addresses this by incorporating robust data\npreprocessing with a Kalman filter and a sophisticated neural network\narchitecture. Experimental results showcase exceptional performance, achieving\na maximum training accuracy of 98% and maintaining an impressive average\ntraining accuracy of 96% across diverse stress scenarios. These results\ndemonstrate the practicality and promise of our method in advancing stress\nmonitoring systems and stress alarm sensors, contributing significantly to\nstress classification.",
    "pdf_url": "http://arxiv.org/pdf/2410.14747v1",
    "published": "2024-10-17T19:29:52+00:00",
    "categories": [
      "eess.IV",
      "cs.LG",
      "ut.ac"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13984v1",
    "title": "Are LLMs Models of Distributional Semantics? A Case Study on Quantifiers",
    "authors": [
      "Zhang Enyan",
      "Zewei Wang",
      "Michael A. Lepori",
      "Ellie Pavlick",
      "Helena Aparicio"
    ],
    "abstract": "Distributional semantics is the linguistic theory that a word's meaning can\nbe derived from its distribution in natural language (i.e., its use). Language\nmodels are commonly viewed as an implementation of distributional semantics, as\nthey are optimized to capture the statistical features of natural language. It\nis often argued that distributional semantics models should excel at capturing\ngraded/vague meaning based on linguistic conventions, but struggle with\ntruth-conditional reasoning and symbolic processing. We evaluate this claim\nwith a case study on vague (e.g. \"many\") and exact (e.g. \"more than half\")\nquantifiers. Contrary to expectations, we find that, across a broad range of\nmodels of various types, LLMs align more closely with human judgements on exact\nquantifiers versus vague ones. These findings call for a re-evaluation of the\nassumptions underpinning what distributional semantics models are, as well as\nwhat they can capture.",
    "pdf_url": "http://arxiv.org/pdf/2410.13984v1",
    "published": "2024-10-17T19:28:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13983v1",
    "title": "Theoretical description of proton-deuteron interactions using exact two-body dynamic of femtoscopic correlation method",
    "authors": [
      "Wioleta Rzęsa",
      "Maria Stefaniak",
      "Scott Pratt"
    ],
    "abstract": "Modeling proton-deuteron interactions is particularly challenging. Due the\ndeuteron's large size, the interaction can extend over several femtometers. The\ndegree to which it can be modeled as a two-body problem might also be\nquestioned. One way to study these interactions is through femtoscopic\ncorrelation measurements of particle pairs, extracting information using\navailable theoretical models. In this work, we examine two approaches for\ndescribing proton-deuteron correlations: the Lednicky-Lyuboshits formalism and\nfull numerical solutions of the Schrodinger equation. Our results show that the\ndifferences between these methods are significant. Furthermore, we demonstrate\nthat incorporating higher-order partial waves-particularly p-wave -is the\nessential for accurately capturing the dynamics of proton-deuteron interactions\nand the full potential of the strong force.",
    "pdf_url": "http://arxiv.org/pdf/2410.13983v1",
    "published": "2024-10-17T19:28:11+00:00",
    "categories": [
      "nucl-th",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13982v1",
    "title": "Design of Amine-Functionalized Materials for Direct Air Capture Using Integrated High-Throughput Calculations and Machine Learning",
    "authors": [
      "Megan C. Davis",
      "Wilton J. M. Kort-Kamp",
      "Ivana Matanovic",
      "Piotr Zelenay",
      "Edward F. Holby"
    ],
    "abstract": "Direct air capture (DAC) of carbon dioxide is a critical technology for\nmitigating climate change, but current materials face limitations in efficiency\nand scalability. We discover novel DAC materials using a combined machine\nlearning (ML) and high-throughput atomistic modeling approach. Our ML model\naccurately predicts high-quality, density functional theory-computed CO$_{2}$\nbinding enthalpies for a wide range of nitrogen-bearing moieties. Leveraging\nthis model, we rapidly screen over 1.6 million binding sites from a\ncomprehensive database of theoretically feasible molecules to identify\nmaterials with superior CO$_{2}$ binding properties. Additionally, we assess\nthe synthesizability and experimental feasibility of these structures using\nestablished ML metrics, discovering nearly 2,500 novel materials suitable for\nintegration into DAC devices. Altogether, our high-fidelity database and ML\nframework represent a significant advancement in the rational development of\nscalable, cost-effective carbon dioxide capture technologies, offering a\npromising pathway to meet key targets in the global initiative to combat\nclimate change.",
    "pdf_url": "http://arxiv.org/pdf/2410.13982v1",
    "published": "2024-10-17T19:26:12+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13981v2",
    "title": "On the Learn-to-Optimize Capabilities of Transformers in In-Context Sparse Recovery",
    "authors": [
      "Renpu Liu",
      "Ruida Zhou",
      "Cong Shen",
      "Jing Yang"
    ],
    "abstract": "An intriguing property of the Transformer is its ability to perform\nin-context learning (ICL), where the Transformer can solve different inference\ntasks without parameter updating based on the contextual information provided\nby the corresponding input-output demonstration pairs. It has been\ntheoretically proved that ICL is enabled by the capability of Transformers to\nperform gradient-descent algorithms (Von Oswald et al., 2023a; Bai et al.,\n2024). This work takes a step further and shows that Transformers can perform\nlearning-to-optimize (L2O) algorithms. Specifically, for the ICL sparse\nrecovery (formulated as LASSO) tasks, we show that a K-layer Transformer can\nperform an L2O algorithm with a provable convergence rate linear in K. This\nprovides a new perspective explaining the superior ICL capability of\nTransformers, even with only a few layers, which cannot be achieved by the\nstandard gradient-descent algorithms. Moreover, unlike the conventional L2O\nalgorithms that require the measurement matrix involved in training to match\nthat in testing, the trained Transformer is able to solve sparse recovery\nproblems generated with different measurement matrices. Besides, Transformers\nas an L2O algorithm can leverage structural information embedded in the\ntraining tasks to accelerate its convergence during ICL, and generalize across\ndifferent lengths of demonstration pairs, where conventional L2O algorithms\ntypically struggle or fail. Such theoretical findings are supported by our\nexperimental results.",
    "pdf_url": "http://arxiv.org/pdf/2410.13981v2",
    "published": "2024-10-17T19:18:28+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13980v1",
    "title": "The art of connections: constructing a social network from the correspondence archive of Sybren Valkema",
    "authors": [
      "Vera Provatorova",
      "Carlotta Capurro",
      "Evangelos Kanoulas"
    ],
    "abstract": "Social network analysis allows researchers to discover insights from\nconnections between people. While the process of building a social network is\nrelatively straightforward for contemporary social media, deriving connections\nfrom historical archives remains a challenging task, with every data collection\npresenting its unique challenges. Our contribution focuses on building and\nanalysing a social network from the correspondence archive of Sybren Valkema\n(1916-1996), a Dutch glass artist and educator. The archive contains both\ntypewritten and handwritten documents in multiple languages, and includes\nletters from glass artists, art students, art collectors and other agents. We\ndevelop an automatic pipeline approach which includes separating handwritten\nand typed documents, performing text recognition specific to the document\nmodality, extracting names of people from text using named entity recognition,\nde-duplicating the resulting names to create actor nodes, classifying the\nactors using entity linking, and, finally, connecting them together and\nanalysing the resulting network. Every part of the pipeline is evaluated\nagainst a manual analysis performed by an art historian on a subset of the data\ncollection in order to find out which pitfalls of the automatic approach need\nto be resolved in future work and, on the contrary, whether using the automatic\napproach allows to discover any additional insights. The results show strong\nperformance in discovering sender-receiver connections as well as additional\nmeaningful connections in text, with the main challenge being text recognition\non scanned pages.",
    "pdf_url": "http://arxiv.org/pdf/2410.13980v1",
    "published": "2024-10-17T19:17:49+00:00",
    "categories": [
      "cs.DL"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13979v2",
    "title": "RecoveryChaining: Learning Local Recovery Policies for Robust Manipulation",
    "authors": [
      "Shivam Vats",
      "Devesh K. Jha",
      "Maxim Likhachev",
      "Oliver Kroemer",
      "Diego Romeres"
    ],
    "abstract": "Model-based planners and controllers are commonly used to solve complex\nmanipulation problems as they can efficiently optimize diverse objectives and\ngeneralize to long horizon tasks. However, they often fail during deployment\ndue to noisy actuation, partial observability and imperfect models. To enable a\nrobot to recover from such failures, we propose to use hierarchical\nreinforcement learning to learn a recovery policy. The recovery policy is\ntriggered when a failure is detected based on sensory observations and seeks to\ntake the robot to a state from which it can complete the task using the nominal\nmodel-based controllers. Our approach, called RecoveryChaining, uses a hybrid\naction space, where the model-based controllers are provided as additional\n\\emph{nominal} options which allows the recovery policy to decide how to\nrecover, when to switch to a nominal controller and which controller to switch\nto even with \\emph{sparse rewards}. We evaluate our approach in three\nmulti-step manipulation tasks with sparse rewards, where it learns\nsignificantly more robust recovery policies than those learned by baselines. We\nsuccessfully transfer recovery policies learned in simulation to a physical\nrobot to demonstrate the feasibility of sim-to-real transfer with our method.",
    "pdf_url": "http://arxiv.org/pdf/2410.13979v2",
    "published": "2024-10-17T19:14:43+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13978v3",
    "title": "Incentivizing Information Acquisition",
    "authors": [
      "Fan Wu"
    ],
    "abstract": "I study a principal-agent model in which a principal hires an agent to\ncollect information about an unknown continuous state. The agent acquires a\nsignal whose distribution is centered around the state, controlling the\nsignal's precision at a cost. The principal observes neither the precision nor\nthe signal, but rather, using transfers that can depend on the state,\nincentivizes the agent to choose high precision and report the signal\ntruthfully. I identify a sufficient and necessary condition on the agent's\ninformation structure which ensures that there exists an optimal transfer with\na simple cutoff structure: the agent receives a fixed prize when his prediction\nis close enough to the state and receives nothing otherwise. This condition is\nmild and applies to all signal distributions commonly used in the literature.",
    "pdf_url": "http://arxiv.org/pdf/2410.13978v3",
    "published": "2024-10-17T19:14:06+00:00",
    "categories": [
      "econ.TH",
      "cs.GT"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2410.13977v1",
    "title": "Solutions for Sustainable and Resilient Communication Infrastructure in Disaster Relief and Management Scenarios",
    "authors": [
      "Bilal Karaman",
      "Ilhan Basturk",
      "Sezai Taskin",
      "Engin Zeydan",
      "Ferdi Kara",
      "Esra Aycan Beyazit",
      "Miguel Camelo",
      "Emil Björnson",
      "Halim Yanikomeroglu"
    ],
    "abstract": "As natural disasters become more frequent and severe, ensuring a resilient\ncommunications infrastructure is of paramount importance for effective disaster\nresponse and recovery. This disaster-resilient infrastructure should also\nrespond to sustainability goals by providing an energy-efficient and\neconomically feasible network that is accessible to everyone. This paper\nprovides a comprehensive exploration of the technological solutions and\nstrategies necessary to build and maintain resilient communications networks\nthat can withstand and quickly recover from disaster scenarios. The paper\nstarts with a survey of existing literature and related reviews to establish a\nsolid foundation, followed by an overview of the global landscape of disaster\ncommunications and power supply management. We then introduce the key enablers\nof communications and energy resource technologies to support communications\ninfrastructure, examining emerging trends that improve the resilience of these\nsystems. Pre-disaster planning is emphasized as a critical phase where\nproactive communication and energy supply strategies can significantly mitigate\nthe impact of disasters. We explore the essential technologies for disaster\nresponse, focusing on real-time communications and energy solutions that\nsupport rapid deployment and coordination in times of crisis. The paper\npresents post-disaster communication and energy management planning for\neffective rescue and evacuation operations. The main findings derived from the\ncomprehensive survey are also summarized for each disaster phase. This is\nfollowed by an analysis of existing vendor products and services as well as\nstandardization efforts and ongoing projects that contribute to the development\nof resilient infrastructures. A detailed case study of the Turkiye earthquakes\nis presented to illustrate the practical application of these technologies and\nstrategies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13977v1",
    "published": "2024-10-17T19:07:53+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13976v1",
    "title": "Debiasing Large Vision-Language Models by Ablating Protected Attribute Representations",
    "authors": [
      "Neale Ratzlaff",
      "Matthew Lyle Olson",
      "Musashi Hinck",
      "Shao-Yen Tseng",
      "Vasudev Lal",
      "Phillip Howard"
    ],
    "abstract": "Large Vision Language Models (LVLMs) such as LLaVA have demonstrated\nimpressive capabilities as general-purpose chatbots that can engage in\nconversations about a provided input image. However, their responses are\ninfluenced by societal biases present in their training datasets, leading to\nundesirable differences in how the model responds when presented with images\ndepicting people of different demographics. In this work, we propose a novel\ndebiasing framework for LVLMs by directly ablating biased attributes during\ntext generation to avoid generating text related to protected attributes, or\neven representing them internally. Our method requires no training and a\nrelatively small amount of representative biased outputs (~1000 samples). Our\nexperiments show that not only can we can minimize the propensity of LVLMs to\ngenerate text related to protected attributes, but we can even use synthetic\ndata to inform the ablation while retaining captioning performance on real data\nsuch as COCO. Furthermore, we find the resulting generations from a debiased\nLVLM exhibit similar accuracy as a baseline biased model, showing that\ndebiasing effects can be achieved without sacrificing model performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13976v1",
    "published": "2024-10-17T19:02:31+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13975v2",
    "title": "Femtoscopy using Lévy-distributed sources at NA61/SHINE",
    "authors": [
      "Barnabas Porfy"
    ],
    "abstract": "In the recent years, research studies in high-energy physics have confirmed\nthe creation of the strongly interacting quark-gluon plasma (sQGP) in\nultra-relativistic nucleus-nucleus collisions. NA61/SHINE at CERN SPS\ninvestigates hadronic matter properties by varying collision energy\n($\\sqrt{s_{\\rm{NN}}} \\approx 5.3, 6.2, 7.7, 8.8, 12$, and 16.8 GeV) and systems\n(such as p+p, p+Pb, Be+Be, Ar+Sc, Xe+La, Pb+Pb). Utilizing femtoscopic\ncorrelations, we can unveil the space-time structure of the hadron emitting\nsource. Our focus is on femtoscopic correlations in small to intermediate\nsystems, comparing measurements with source calculations based on\nL\\'evy-distributed sources, to explore the pair transverse mass dependence of\nthe L\\'evy source parameters. The L\\'evy exponent $\\alpha$ is of particular\nsignificance, which characterizes the shape of the source and may be connected\nto the critical exponent $\\eta$ near the critical point. Our analysis will\nreveal that the L\\'evy shape parameter, $\\alpha$, has a slight non-monotonic\nbehaviour as a function of collision energy and that we see a deviation from\nGaussian sources. Finally, it will be shown that there is no indication of the\ncritical point at any of the investigated energies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13975v2",
    "published": "2024-10-17T19:00:13+00:00",
    "categories": [
      "nucl-ex",
      "hep-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2410.13974v2",
    "title": "Are You Using Reliable Graph Prompts? Trojan Prompt Attacks on Graph Neural Networks",
    "authors": [
      "Minhua Lin",
      "Zhiwei Zhang",
      "Enyan Dai",
      "Zongyu Wu",
      "Yilong Wang",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "abstract": "Graph Prompt Learning (GPL) has been introduced as a promising approach that\nuses prompts to adapt pre-trained GNN models to specific downstream tasks\nwithout requiring fine-tuning of the entire model. Despite the advantages of\nGPL, little attention has been given to its vulnerability to backdoor attacks,\nwhere an adversary can manipulate the model's behavior by embedding hidden\ntriggers. Existing graph backdoor attacks rely on modifying model parameters\nduring training, but this approach is impractical in GPL as GNN encoder\nparameters are frozen after pre-training. Moreover, downstream users may\nfine-tune their own task models on clean datasets, further complicating the\nattack. In this paper, we propose TGPA, a backdoor attack framework designed\nspecifically for GPL. TGPA injects backdoors into graph prompts without\nmodifying pre-trained GNN encoders and ensures high attack success rates and\nclean accuracy. To address the challenge of model fine-tuning by users, we\nintroduce a finetuning-resistant poisoning approach that maintains the\neffectiveness of the backdoor even after downstream model adjustments.\nExtensive experiments on multiple datasets under various settings demonstrate\nthe effectiveness of TGPA in compromising GPL models with fixed GNN encoders.",
    "pdf_url": "http://arxiv.org/pdf/2410.13974v2",
    "published": "2024-10-17T18:57:27+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13973v4",
    "title": "MarineFormer: A Spatio-Temporal Attention Model for USV Navigation in Dynamic Marine Environments",
    "authors": [
      "Ehsan Kazemi",
      "Dechen Gao",
      "Iman Soltani"
    ],
    "abstract": "Autonomous navigation in marine environments can be extremely challenging,\nespecially in the presence of spatially varying flow disturbances and dynamic\nand static obstacles. In this work, we demonstrate that incorporating local\nflow field measurements fundamentally alters the nature of the problem,\ntransforming otherwise unsolvable navigation scenarios into tractable ones.\nHowever, the mere availability of flow data is not sufficient; it must be\neffectively fused with conventional sensory inputs such as ego-state and\nobstacle states. To this end, we propose \\textbf{MarineFormer}, a\nTransformer-based policy architecture that integrates two complementary\nattention mechanisms: spatial attention for sensor fusion, and temporal\nattention for capturing environmental dynamics. MarineFormer is trained\nend-to-end via reinforcement learning in a 2D simulated environment with\nrealistic flow features and obstacles. Extensive evaluations against classical\nand state-of-the-art baselines show that our approach improves episode\ncompletion success rate by nearly 23\\% while reducing path length. Ablation\nstudies further highlight the critical role of flow measurements and the\neffectiveness of our proposed architecture in leveraging them.",
    "pdf_url": "http://arxiv.org/pdf/2410.13973v4",
    "published": "2024-10-17T18:57:15+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13972v1",
    "title": "Enhancing Routing in SD-EONs through Reinforcement Learning: A Comparative Analysis",
    "authors": [
      "Ryan McCann",
      "Arash Rezaee",
      "Vinod M. Vokkarane"
    ],
    "abstract": "This paper presents an optimization framework for routing in software-defined\nelastic optical networks using reinforcement learning algorithms. We\nspecifically implement and compare the epsilon-greedy bandit, upper confidence\nbound (UCB) bandit, and Q-learning algorithms to traditional methods such as\nK-Shortest Paths with First-Fit core and spectrum assignment (KSP-FF) and\nShortest Path with First-Fit (SPF-FF) algorithms. Our results show that\nQ-learning significantly outperforms traditional methods, achieving a reduction\nin blocking probability (BP) of up to 58.8% over KSP-FF, and 81.9% over SPF-FF\nunder lower traffic volumes. For higher traffic volumes, Q-learning maintains\nsuperior performance with BP reductions of 41.9% over KSP-FF and 70.1% over\nSPF-FF. These findings demonstrate the efficacy of reinforcement learning in\nenhancing network performance and resource utilization in dynamic and complex\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13972v1",
    "published": "2024-10-17T18:57:08+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13971v1",
    "title": "A Guide to Equivariant Parametrized Cohomology",
    "authors": [
      "Agnès Beaudry",
      "Chloe Lewis",
      "Clover May",
      "Sabrina Pauli",
      "Elizabeth Tatum"
    ],
    "abstract": "This article investigates equivariant parametrized cellular cohomology, a\ncohomology theory introduced by Costenoble-Waner for spaces with an action by a\ncompact Lie group $G$. The theory extends the $RO(G)$-graded cohomology of a\n$G$-space $B$ to a cohomology graded by $RO(\\Pi B)$, the representations of the\nequivariant fundamental groupoid of $B$. This paper is meant to serve as a\nguide to this theory and contains some new computations.\n  We explain the key ingredients for defining parametrized cellular cohomology\nwhen $G$ is a finite group, with particular attention to the case of the cyclic\ngroup $G=C_2$. We compute some examples and observe that $RO(\\Pi B)$ is not\nalways free. When $G$ is the trivial group, we explain how to identify\nequivariant parametrized cellular cohomology with cellular cohomology in local\ncoefficients. Finally, we illustrate the theory with some new computations of\nparametrized cellular cohomology for several spaces with $G = C_2$ and $G=C_4$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13971v1",
    "published": "2024-10-17T18:55:30+00:00",
    "categories": [
      "math.AT",
      "55N25"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13970v2",
    "title": "Small-dimensional normed barrelled spaces",
    "authors": [
      "Will Brian",
      "Christopher Stuart"
    ],
    "abstract": "We prove that every separable Banach space has a barrelled subspace with\nalgebraic dimension $\\mathrm{non}(\\mathcal M)$, which denotes the smallest\ncardinality of a non-meager subset of $\\mathbb R$. This strengthens a theorem\nof Sobota. More generally, we prove that every Banach space with density\ncharacter $\\kappa$ contains a barrelled subspace with algebraic dimension\n$\\mathrm{cf}[\\kappa]^\\omega \\cdot \\mathrm{non}(\\mathcal M)$, and in particular\nit is consistent with $\\mathsf{ZFC}$ that every Banach space with density\ncharacter $<\\!\\mathfrak{c}$ has a barrelled subspace with dimension\n$<\\!\\mathfrak{c}$.\n  We also prove that if the dual of a Banach space contains either $c_0$ or\n$\\ell^p$ for some $p \\geq 1$, then that space does not have a barrelled\nsubspace with dimension $<\\!\\mathrm{cov}(\\mathcal N)$, which denotes the\nsmallest cardinality of a collection of Lebesgue null sets covering $\\mathbb\nR$. In particular, it is consistent with $\\mathsf{ZFC}$ that no classical\nBanach spaces contain barrelled subspaces with dimension $\\mathfrak{b}$. This\npartly answers a question of S\\'anchez Ruiz and Saxon.",
    "pdf_url": "http://arxiv.org/pdf/2410.13970v2",
    "published": "2024-10-17T18:53:20+00:00",
    "categories": [
      "math.FA",
      "math.LO"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13969v1",
    "title": "Singularity Structure of the Four Point Celestial Leaf Amplitudes",
    "authors": [
      "Raju Mandal",
      "Sagnik Misra",
      "Partha Paul",
      "Baishali Roy"
    ],
    "abstract": "In this paper, we study the four-point celestial leaf amplitudes of massless\nscalar and MHV gluon scattering. These leaf amplitudes are non-distributional\ndecompositions of the celestial amplitudes associated with a hyperbolic\nfoliation of the Klein spacetime. Bulk scale invariance imposes constraints on\nthe total conformal weights of the massless scalars or gluons. Using this\nconstraint we show that the four-point leaf amplitudes have a \\textit {simple\npole singularity at $ z = \\bar z $}, where, $ z,\\bar z $ are two real\nindependent conformal cross ratios. The distributional nature of the four-point\ncelestial amplitudes is recovered by adding the leaf amplitudes in the timelike\nand spacelike wedges of the spacetime. We also verify that the MHV gluon leaf\namplitudes satisfy a set of differential equations previously obtained for\ncelestial MHV gluon amplitudes by considering the soft gluon theorems and the\nsubleading terms in the OPE expansion between two positive helicity gluons.",
    "pdf_url": "http://arxiv.org/pdf/2410.13969v1",
    "published": "2024-10-17T18:51:49+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13968v1",
    "title": "Structure, maximum mass, and stability of compact stars in f(Q,T) gravity",
    "authors": [
      "G. G. L. Nashed",
      "Tiberiu Harko"
    ],
    "abstract": "Physically based changes to general relativity (GR) often predict significant\ndifferences in how spacetime behaves near massive neutron stars. One of these\nmodifications is represented by $f(\\mathcal{Q}, { \\mathcal{T}})$, with\n$\\mathcal{Q}$ being the non-metricity and ${ \\mathit{T}}$ representing the\nenergy-momentum tensor trace. This theory is viewed as a neutral expansion of\nGR. Neutron stars weighing more than 1.8 times the mass of the Sun, when\nobserved as radio pulsars, provide valuable opportunities to test fundamental\nphysics under extreme conditions that are rare in the observable universe and\ncannot be replicated in experiments conducted on land. We derive an exact\nsolution through utilizing the form $f(\\mathcal{Q}, {\n\\mathcal{T}})=\\mathcal{Q}+\\psi { \\mathcal{T}}$, where $\\psi$ represents a\ndimensional expression. We elucidate that all physical quantities within the\nstar can be expressed using the dimensional parameter $\\psi$ and the\ncompactness, which is defined as $C=\\frac{ 2GM}{Rc^2}$. We set $\\psi$ to a\nmaximum value of $\\psi_1=\\frac{\\psi}{\\kappa^2}=-0.04$ in the negative range,\nbased on observational constraints related to radius and mass of the pulsar\n${\\textit SAX J1748.9-2021}$. Here, ${\\mathrm \\kappa^2}$ represents the\ncoupling constant of Einstein, defined as ${\\mathrm \\kappa^2=\\frac{8\\pi\nG}{c^4}}$. Unlike in GR, the solution we derived results in a stable compact\nobject without violating the conjectured sound speed condition\n$c_s^2\\leq\\frac{c^2}3$.It is crucial to mention that no equations of state were\nassumed in this investigation. Nevertheless, our model fits nicely with linear\nform. Generally, when $\\psi$ is negative, the theory predicts a star with a\nslightly larger size than GR for the same mass. The difference in predicted\nsize between the theory with a negative $\\psi$ and GR for the same mass is\nattributed to an additional force.",
    "pdf_url": "http://arxiv.org/pdf/2410.13968v1",
    "published": "2024-10-17T18:51:11+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE",
      "astro-ph.SR",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13967v2",
    "title": "A note on the differential smoothness of skew PBW extensions",
    "authors": [
      "Andrés Rubiano",
      "Armando Reyes"
    ],
    "abstract": "We investigate the differential smoothness of a certain family of skew\nPoincar\\'e-Birkhoff-Witt extensions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13967v2",
    "published": "2024-10-17T18:45:27+00:00",
    "categories": [
      "math.RA",
      "math.DG",
      "16E45, 16S30, 16S32, 16S36, 16S38, 16S99, 16W20, 16T05, 58B34"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13966v1",
    "title": "Detecting AI-Generated Texts in Cross-Domains",
    "authors": [
      "You Zhou",
      "Jie Wang"
    ],
    "abstract": "Existing tools to detect text generated by a large language model (LLM) have\nmet with certain success, but their performance can drop when dealing with\ntexts in new domains. To tackle this issue, we train a ranking classifier\ncalled RoBERTa-Ranker, a modified version of RoBERTa, as a baseline model using\na dataset we constructed that includes a wider variety of texts written by\nhumans and generated by various LLMs. We then present a method to fine-tune\nRoBERTa-Ranker that requires only a small amount of labeled data in a new\ndomain. Experiments show that this fine-tuned domain-aware model outperforms\nthe popular DetectGPT and GPTZero on both in-domain and cross-domain texts,\nwhere AI-generated texts may either be in a different domain or generated by a\ndifferent LLM not used to generate the training datasets. This approach makes\nit feasible and economical to build a single system to detect AI-generated\ntexts across various domains.",
    "pdf_url": "http://arxiv.org/pdf/2410.13966v1",
    "published": "2024-10-17T18:43:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13965v1",
    "title": "Hyperbolic distortion and conformality at the boundary",
    "authors": [
      "Pavel Gumenyuk",
      "Maria Kourou",
      "Annika Moucha",
      "Oliver Roth"
    ],
    "abstract": "We characterize two classical types of conformality of a holomorphic self-map\nof the unit disk at a boundary point - existence of a finite angular derivative\nin the sense of Carath\\'eodory and the weaker property of angle preservation -\nin terms of the non-tangential asymptotic behaviour of the hyperbolic\ndistortion of the map. These characterizations are given purely with reference\nto the intrinsic metric geometry of the unit disk. In particular, we relate the\nclassical Julia-Wolff-Carath\\'eodory theorem with the case of equality in the\nSchwarz-Pick lemma at the boundary. We also provide an operator-theoretic\ncharacterization of the existence of a finite angular derivative based on\nHilbert space methods. As an application we study the backward dynamics of\ndiscrete dynamical systems induced by holomorphic self-maps, and characterize\nthe regularity of the associated pre-models in terms of a Blaschke-type\ncondition involving the hyperbolic distortion along regular backward orbits.",
    "pdf_url": "http://arxiv.org/pdf/2410.13965v1",
    "published": "2024-10-17T18:42:20+00:00",
    "categories": [
      "math.CV",
      "math.CA",
      "math.FA",
      "math.MG",
      "30C35, 30C55, 30C80, 30H45, 37F99"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13964v2",
    "title": "Sparse Mixture-of-Experts for Compositional Generalization: Empirical Evidence and Theoretical Foundations of Optimal Sparsity",
    "authors": [
      "Jinze Zhao",
      "Peihao Wang",
      "Junjie Yang",
      "Ruisi Cai",
      "Gaowen Liu",
      "Jayanth Srinivasa",
      "Ramana Rao Kompella",
      "Yingbin Liang",
      "Zhangyang Wang"
    ],
    "abstract": "Sparse Mixture-of-Experts (SMoE) architectures have gained prominence for\ntheir ability to scale neural networks, particularly transformers, without a\nproportional increase in computational cost. Despite their success, their role\nin compositional generalization, i.e., adapting to novel combinations of known\ncomponents, remains under-explored. This study challenges the assumption that\nminimal expert activation suffices for task generalization and investigates the\nrelationship between task complexity and optimal sparsity in SMoE models.\nThrough empirical evaluations on the SRAVEN symbolic reasoning task and the\nSKILL-MIX benchmark, we demonstrate that (i) the number of activated experts\nconsistently increases with the perceived task difficulty to maintain\nperformance; and (ii) the optimal number of activated experts scales\nproportionally with task complexity. Our theoretical analysis derives a scaling\nlaw for optimal sparsity by balancing approximation and estimation errors,\nrevealing alignment with empirical observations. We formally show that the\noptimal sparsity lies between minimal activation (1-2 experts) and full\nactivation, with the exact number scaling proportionally to task complexity and\nfurther influenced by the size of the training data and the complexity of the\nmodel. These findings offer practical insights for designing SMoE models that\nachieve computational efficiency while enabling robust compositional\ngeneralization.",
    "pdf_url": "http://arxiv.org/pdf/2410.13964v2",
    "published": "2024-10-17T18:40:48+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13963v1",
    "title": "Orbits and masses in two triple systems",
    "authors": [
      "Dinko Nazor",
      "Andrei Tokovinin"
    ],
    "abstract": "In an effort to determine accurate orbital and physical properties of a large\nnumber of bright stars, a method was developed to fit simultaneously stellar\nparameters (masses, luminosities, effective temperatures), distance, and orbits\nto the available data on multiple systems, namely the combined and differential\nphotometry, positional measurements, radial velocities (RVs), accelerations,\netc. The method is applied to a peculiar resolved triple system HIP 86286. The\nmasses of its components estimated using observations and standard relations\nare 1.3, 0.9, and 0.9 Mmsun; the main star is a G8IV subgiant, while its two\ncompanions are main-sequence dwarfs. The inner and outer orbital periods are 35\nand 287 years, respectively, and the orbits are nearly coplanar. The second\nsystem, HIP 117258, is an accelerating star with a resolved companion; its\n35.7-yr orbit based on relative astrometry and precise RVs yields the secondary\nmass of 0.95 Msun, much larger than inferred from the photometry. The apparent\nparadox is explained by assuming that the secondary is a close pair of M-type\ndwarfs with yet unknown period.",
    "pdf_url": "http://arxiv.org/pdf/2410.13963v1",
    "published": "2024-10-17T18:40:47+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13962v1",
    "title": "A Physics-Based Context-Aware Approach for Anomaly Detection in Teleoperated Driving Operations Under False Data Injection Attacks",
    "authors": [
      "Subhadip Ghosh",
      "Aydin Zaboli",
      "Junho Hong",
      "Jaerock Kwon"
    ],
    "abstract": "Teleoperated driving (ToD) systems are a special type of cyber-physical\nsystem (CPS) where the operator remotely controls the steering, acceleration,\nand braking actions of the vehicle. Malicious actors may inject false data into\ncommunication channels to manipulate the teleoperator's driving commands to\ncause harm. Hence, protection of this communication is necessary for a safe\noperation of the target vehicle. However, according to the National Institute\nof Standards and Technology (NIST) cybersecurity framework, protection is not\nenough, and detecting an attack is necessary. Moreover, UN R155 mandates that\nvehicle fleets detect and log security incidents. Thus, the cyber-physical\nthreats of ToD are modeled using the attack-centric approach in this paper.\nThen, an attack model with false data injection (FDI) on the steering control\ncommand is created from real vehicle data. A risk of this attack model is\nassessed for a last-mile delivery (LMD) application. Finally, a physics-based\ncontext-aware anomaly detection system (PCADS) is proposed to detect such false\ninjection attacks, and preliminary experimental results are presented to\nvalidate the model.",
    "pdf_url": "http://arxiv.org/pdf/2410.13962v1",
    "published": "2024-10-17T18:40:10+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13961v2",
    "title": "From Single to Multi: How LLMs Hallucinate in Multi-Document Summarization",
    "authors": [
      "Catarina G. Belem",
      "Pouya Pezeshkpour",
      "Hayate Iso",
      "Seiji Maekawa",
      "Nikita Bhutani",
      "Estevam Hruschka"
    ],
    "abstract": "Although many studies have investigated and reduced hallucinations in large\nlanguage models (LLMs) for single-document tasks, research on hallucination in\nmulti-document summarization (MDS) tasks remains largely unexplored.\nSpecifically, it is unclear how the challenges arising from handling multiple\ndocuments (e.g., repetition and diversity of information) affect models\noutputs. In this work, we investigate how hallucinations manifest in LLMs when\nsummarizing topic-specific information from multiple documents. Since no\nbenchmarks exist for investigating hallucinations in MDS, we use existing news\nand conversation datasets, annotated with topic-specific insights, to create\ntwo novel multi-document benchmarks. When evaluating 5 LLMs on our benchmarks,\nwe observe that on average, up to 75% of the content in LLM-generated summary\nis hallucinated, with hallucinations more likely to occur towards the end of\nthe summaries. Moreover, when summarizing non-existent topic-related\ninformation, gpt-3.5-turbo and GPT-4o still generate summaries about 79.35% and\n44% of the time, raising concerns about their tendency to fabricate content. To\nunderstand the characteristics of these hallucinations, we manually evaluate\n700+ insights and find that most errors stem from either failing to follow\ninstructions or producing overly generic insights. Motivated by these\nobservations, we investigate the efficacy of simple post-hoc baselines in\nmitigating hallucinations but find them only moderately effective. Our results\nunderscore the need for more effective approaches to systematically mitigate\nhallucinations in MDS. We release our dataset and code at\ngithub.com/megagonlabs/Hallucination_MDS.",
    "pdf_url": "http://arxiv.org/pdf/2410.13961v2",
    "published": "2024-10-17T18:38:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.19812v1",
    "title": "Ethics Whitepaper: Whitepaper on Ethical Research into Large Language Models",
    "authors": [
      "Eddie L. Ungless",
      "Nikolas Vitsakis",
      "Zeerak Talat",
      "James Garforth",
      "Björn Ross",
      "Arno Onken",
      "Atoosa Kasirzadeh",
      "Alexandra Birch"
    ],
    "abstract": "This whitepaper offers an overview of the ethical considerations surrounding\nresearch into or with large language models (LLMs). As LLMs become more\nintegrated into widely used applications, their societal impact increases,\nbringing important ethical questions to the forefront. With a growing body of\nwork examining the ethical development, deployment, and use of LLMs, this\nwhitepaper provides a comprehensive and practical guide to best practices,\ndesigned to help those in research and in industry to uphold the highest\nethical standards in their work.",
    "pdf_url": "http://arxiv.org/pdf/2410.19812v1",
    "published": "2024-10-17T18:36:02+00:00",
    "categories": [
      "cs.CY",
      "cs.CL",
      "I.2"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13960v1",
    "title": "Approximating Auction Equilibria with Reinforcement Learning",
    "authors": [
      "Pranjal Rawat"
    ],
    "abstract": "Traditional methods for computing equilibria in auctions become\ncomputationally intractable as auction complexity increases, particularly in\nmulti-item and dynamic auctions. This paper introduces a self-play based\nreinforcement learning approach that employs advanced algorithms such as\nProximal Policy Optimization and Neural Fictitious Self-Play to approximate\nBayes-Nash equilibria. This framework allows for continuous action spaces,\nhigh-dimensional information states, and delayed payoffs. Through self-play,\nthese algorithms can learn robust and near-optimal bidding strategies in\nauctions with known equilibria, including those with symmetric and asymmetric\nvaluations, private and interdependent values, and multi-round auctions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13960v1",
    "published": "2024-10-17T18:34:57+00:00",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2410.13959v2",
    "title": "FinQAPT: Empowering Financial Decisions with End-to-End LLM-driven Question Answering Pipeline",
    "authors": [
      "Kuldeep Singh",
      "Simerjot Kaur",
      "Charese Smiley"
    ],
    "abstract": "Financial decision-making hinges on the analysis of relevant information\nembedded in the enormous volume of documents in the financial domain. To\naddress this challenge, we developed FinQAPT, an end-to-end pipeline that\nstreamlines the identification of relevant financial reports based on a query,\nextracts pertinent context, and leverages Large Language Models (LLMs) to\nperform downstream tasks. To evaluate the pipeline, we experimented with\nvarious techniques to optimize the performance of each module using the FinQA\ndataset. We introduced a novel clustering-based negative sampling technique to\nenhance context extraction and a novel prompting method called Dynamic N-shot\nPrompting to boost the numerical question-answering capabilities of LLMs. At\nthe module level, we achieved state-of-the-art accuracy on FinQA, attaining an\naccuracy of 80.6%. However, at the pipeline level, we observed decreased\nperformance due to challenges in extracting relevant context from financial\nreports. We conducted a detailed error analysis of each module and the\nend-to-end pipeline, pinpointing specific challenges that must be addressed to\ndevelop a robust solution for handling complex financial tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13959v2",
    "published": "2024-10-17T18:34:43+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7; H.3.3; I.2.6; I.5.3"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13958v1",
    "title": "The redshift evolution of the $M_{\\rm BH}-M_*$ scaling relation: new insights from cosmological simulations and semi-analytic models",
    "authors": [
      "Shashank Dattathri",
      "Priyamvada Natarajan",
      "Antonio J. Porras-Valverde",
      "Colin J. Burke",
      "Nianyi Chen",
      "Tiziana Di Matteo",
      "Yueying Ni"
    ],
    "abstract": "We study the co-evolution of black holes (BHs) and their host galaxies in the\nASTRID and Illustris-TNG300 cosmological simulations and the Dark Sage\nSemi-Analytic Model (SAM), focusing on the evolution of the BH mass - stellar\nmass ($M_{\\rm BH}-M_*$) relation. Due to differences in the adopted sub-grid\nmodeling of BH seeding, dynamics, and feedback, the models differ in their\npredicted redshift evolution of the $M_{\\rm BH}-M_*$ relation. We find that it\nis the interplay between the star formation rate (SFR) and the black hole\naccretion rate (BHAR) which drives the evolution of the mean relation. We\ndefine a quantity $\\mathcal{R}$, the ratio between the specific BHAR and SFR\n(i.e. $\\mathcal{R} \\equiv\\ $sBHAR/sSFR), and demonstrate that it is\n$\\mathcal{R}$ that governs the evolution of individual sources in the $M_{\\rm\nBH}-M_*$ plane. The efficiency of BH growth versus stellar mass growth in the\nsSFR-sBHAR plane reflects the partitioning of gas between fueling star\nformation versus BH accretion. This partitioning depends on the implementation\nof BH dynamics and the nature of how AGN feedback quenches galaxies. In the\ncosmological simulations (ASTRID and Illustris-TNG300), the BHAR and SFR are\nintrinsically linked, resulting in a tight $M_{\\rm BH}-M_*$ correlation, while\nthe Dark Sage SAM produces a significantly larger scatter. We discuss these\nresults in the context of recently discovered over-massive BHs and massive\nquenched galaxies at high redshift by the James Webb Space Telescope.",
    "pdf_url": "http://arxiv.org/pdf/2410.13958v1",
    "published": "2024-10-17T18:32:40+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13957v1",
    "title": "Goal Inference from Open-Ended Dialog",
    "authors": [
      "Rachel Ma",
      "Jingyi Qu",
      "Andreea Bobu",
      "Dylan Hadfield-Menell"
    ],
    "abstract": "We present an online method for embodied agents to learn and accomplish\ndiverse user goals. While offline methods like RLHF can represent various goals\nbut require large datasets, our approach achieves similar flexibility with\nonline efficiency. We extract natural language goal representations from\nconversations with Large Language Models (LLMs). We prompt an LLM to role play\nas a human with different goals and use the corresponding likelihoods to run\nBayesian inference over potential goals. As a result, our method can represent\nuncertainty over complex goals based on unrestricted dialog. We evaluate our\nmethod in grocery shopping and home robot assistance domains using a text-based\ninterface and AI2Thor simulation respectively. Results show our method\noutperforms ablation baselines that lack either explicit goal representation or\nprobabilistic inference.",
    "pdf_url": "http://arxiv.org/pdf/2410.13957v1",
    "published": "2024-10-17T18:30:52+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13956v2",
    "title": "Benchmarking Transcriptomics Foundation Models for Perturbation Analysis : one PCA still rules them all",
    "authors": [
      "Ihab Bendidi",
      "Shawn Whitfield",
      "Kian Kenyon-Dean",
      "Hanene Ben Yedder",
      "Yassir El Mesbahi",
      "Emmanuel Noutahi",
      "Alisandra K. Denton"
    ],
    "abstract": "Understanding the relationships among genes, compounds, and their\ninteractions in living organisms remains limited due to technological\nconstraints and the complexity of biological data. Deep learning has shown\npromise in exploring these relationships using various data types. However,\ntranscriptomics, which provides detailed insights into cellular states, is\nstill underused due to its high noise levels and limited data availability.\nRecent advancements in transcriptomics sequencing provide new opportunities to\nuncover valuable insights, especially with the rise of many new foundation\nmodels for transcriptomics, yet no benchmark has been made to robustly evaluate\nthe effectiveness of these rising models for perturbation analysis. This\narticle presents a novel biologically motivated evaluation framework and a\nhierarchy of perturbation analysis tasks for comparing the performance of\npretrained foundation models to each other and to more classical techniques of\nlearning from transcriptomics data. We compile diverse public datasets from\ndifferent sequencing techniques and cell lines to assess models performance.\nOur approach identifies scVI and PCA to be far better suited models for\nunderstanding biological perturbations in comparison to existing foundation\nmodels, especially in their application in real-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2410.13956v2",
    "published": "2024-10-17T18:27:51+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13955v2",
    "title": "A multi-detector neutral helium atom microscope",
    "authors": [
      "Chenyang Zhao",
      "Sam M Lambrick",
      "Nick A von Jeinsen",
      "Yanke Yuan",
      "Xiaolong Zhang",
      "Aleksandar Radić",
      "David J Ward",
      "John Ellis",
      "Andrew P Jardine"
    ],
    "abstract": "Scanning helium microscopy (SHeM) is an emerging technique that uses a beam\nof neutral atoms to image and analyse surfaces. The low energies ($\\sim$64 meV)\nand completely non-destructive nature of the probe particles provide\nexceptional sensitivity for studying delicate samples and thin devices,\nincluding 2D materials. To date, around five such instruments have been\nconstructed and are described in the literature. All represent the first\nattempts at SHeM construction in different laboratories, and use a single\ndetection device. Here, we describe our second generation microscope, which is\nthe first to offer multi-detector capabilities. The new instrument builds on\nrecent research into SHeM optimisation and incorporates many improved design\nfeatures over our previous instrument. We present measurements that highlight\nsome of the unique capabilities the instrument provides, including 3D surface\nprofiling, alternative imaging modes, and simultaneous acquisition of images\nfrom a mixed species beam.",
    "pdf_url": "http://arxiv.org/pdf/2410.13955v2",
    "published": "2024-10-17T18:26:06+00:00",
    "categories": [
      "physics.ins-det",
      "cond-mat.other"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2410.13954v2",
    "title": "Nonlinear Stochastic Gradient Descent and Heavy-tailed Noise: A Unified Framework and High-probability Guarantees",
    "authors": [
      "Aleksandar Armacki",
      "Shuhua Yu",
      "Pranay Sharma",
      "Gauri Joshi",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "abstract": "We study high-probability convergence in online learning, in the presence of\nheavy-tailed noise. To combat the heavy tails, a general framework of nonlinear\nSGD methods is considered, subsuming several popular nonlinearities like sign,\nquantization, component-wise and joint clipping. In our work the nonlinearity\nis treated in a black-box manner, allowing us to establish unified guarantees\nfor a broad range of nonlinear methods. For symmetric noise and non-convex\ncosts we establish convergence of gradient norm-squared, at a rate\n$\\widetilde{\\mathcal{O}}(t^{-1/4})$, while for the last iterate of strongly\nconvex costs we establish convergence to the population optima, at a rate\n$\\mathcal{O}(t^{-\\zeta})$, where $\\zeta \\in (0,1)$ depends on noise and problem\nparameters. Further, if the noise is a (biased) mixture of symmetric and\nnon-symmetric components, we show convergence to a neighbourhood of\nstationarity, whose size depends on the mixture coefficient, nonlinearity and\nnoise. Compared to state-of-the-art, who only consider clipping and require\nunbiased noise with bounded $p$-th moments, $p \\in (1,2]$, we provide\nguarantees for a broad class of nonlinearities, without any assumptions on\nnoise moments. While the rate exponents in state-of-the-art depend on noise\nmoments and vanish as $p \\rightarrow 1$, our exponents are constant and\nstrictly better whenever $p < 6/5$ for non-convex and $p < 8/7$ for strongly\nconvex costs. Experiments validate our theory, showing that clipping is not\nalways the optimal nonlinearity, further underlining the value of a general\nframework.",
    "pdf_url": "http://arxiv.org/pdf/2410.13954v2",
    "published": "2024-10-17T18:25:28+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13953v3",
    "title": "On Diffusion Models for Multi-Agent Partial Observability: Shared Attractors, Error Bounds, and Composite Flow",
    "authors": [
      "Tonghan Wang",
      "Heng Dong",
      "Yanchen Jiang",
      "David C. Parkes",
      "Milind Tambe"
    ],
    "abstract": "Multiagent systems grapple with partial observability (PO), and the\ndecentralized POMDP (Dec-POMDP) model highlights the fundamental nature of this\nchallenge. Whereas recent approaches to addressing PO have appealed to deep\nlearning models, providing a rigorous understanding of how these models and\ntheir approximation errors affect agents' handling of PO and their interactions\nremain a challenge. In addressing this challenge, we investigate reconstructing\nglobal states from local action-observation histories in Dec-POMDPs using\ndiffusion models. We first find that diffusion models conditioned on local\nhistory represent possible states as stable fixed points. In collectively\nobservable (CO) Dec-POMDPs, individual diffusion models conditioned on agents'\nlocal histories share a unique fixed point corresponding to the global state,\nwhile in non-CO settings, shared fixed points yield a distribution of possible\nstates given joint history. We further find that, with deep learning\napproximation errors, fixed points can deviate from true states and the\ndeviation is negatively correlated to the Jacobian rank. Inspired by this\nlow-rank property, we bound a deviation by constructing a surrogate linear\nregression model that approximates the local behavior of a diffusion model.\nWith this bound, we propose a \\emph{composite diffusion process} iterating over\nagents with theoretical convergence guarantees to the true state.",
    "pdf_url": "http://arxiv.org/pdf/2410.13953v3",
    "published": "2024-10-17T18:23:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13952v1",
    "title": "Satellite Streaming Video QoE Prediction: A Real-World Subjective Database and Network-Level Prediction Models",
    "authors": [
      "Bowen Chen",
      "Zaixi Shang",
      "Jae Won Chung",
      "David Lerner",
      "Werner Robitza",
      "Rakesh Rao Ramachandra Rao",
      "Alexander Raake",
      "Alan C. Bovik"
    ],
    "abstract": "Demand for streaming services, including satellite, continues to exhibit\nunprecedented growth. Internet Service Providers find themselves at the\ncrossroads of technological advancements and rising customer expectations. To\nstay relevant and competitive, these ISPs must ensure their networks deliver\noptimal video streaming quality, a key determinant of user satisfaction.\nTowards this end, it is important to have accurate Quality of Experience\nprediction models in place. However, achieving robust performance by these\nmodels requires extensive data sets labeled by subjective opinion scores on\nvideos impaired by diverse playback disruptions. To bridge this data gap, we\nintroduce the LIVE-Viasat Real-World Satellite QoE Database. This database\nconsists of 179 videos recorded from real-world streaming services affected by\nvarious authentic distortion patterns. We also conducted a comprehensive\nsubjective study involving 54 participants, who contributed both\ncontinuous-time opinion scores and endpoint (retrospective) QoE scores. Our\nanalysis sheds light on various determinants influencing subjective QoE, such\nas stall events, spatial resolutions, bitrate, and certain network parameters.\nWe demonstrate the usefulness of this unique new resource by evaluating the\nefficacy of prevalent QoE-prediction models on it. We also created a new model\nthat maps the network parameters to predicted human perception scores, which\ncan be used by ISPs to optimize the video streaming quality of their networks.\nOur proposed model, which we call SatQA, is able to accurately predict QoE\nusing only network parameters, without any access to pixel data or\nvideo-specific metadata, estimated by Spearman's Rank Order Correlation\nCoefficient (SROCC), Pearson Linear Correlation Coefficient (PLCC), and Root\nMean Squared Error (RMSE), indicating high accuracy and reliability.",
    "pdf_url": "http://arxiv.org/pdf/2410.13952v1",
    "published": "2024-10-17T18:22:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13951v1",
    "title": "Identifying High Consideration E-Commerce Search Queries",
    "authors": [
      "Zhiyu Chen",
      "Jason Choi",
      "Besnik Fetahu",
      "Shervin Malmasi"
    ],
    "abstract": "In e-commerce, high consideration search missions typically require careful\nand elaborate decision making, and involve a substantial research investment\nfrom customers. We consider the task of identifying High Consideration (HC)\nqueries. Identifying such queries enables e-commerce sites to better serve user\nneeds using targeted experiences such as curated QA widgets that help users\nreach purchase decisions. We explore the task by proposing an Engagement-based\nQuery Ranking (EQR) approach, focusing on query ranking to indicate potential\nengagement levels with query-related shopping knowledge content during product\nsearch. Unlike previous studies on predicting trends, EQR prioritizes\nquery-level features related to customer behavior, finance, and catalog\ninformation rather than popularity signals. We introduce an accurate and\nscalable method for EQR and present experimental results demonstrating its\neffectiveness. Offline experiments show strong ranking performance. Human\nevaluation shows a precision of 96% for HC queries identified by our model. The\nmodel was commercially deployed, and shown to outperform human-selected queries\nin terms of downstream customer impact, as measured through engagement.",
    "pdf_url": "http://arxiv.org/pdf/2410.13951v1",
    "published": "2024-10-17T18:22:42+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13950v1",
    "title": "New Uniqueness Results For A Mean Field Game Of Controls",
    "authors": [
      "Jameson Graber",
      "Elizabeth Matter"
    ],
    "abstract": "We propose a new approach to proving the uniqueness of solutions to a certain\nclass of mean field games of controls. In this class, the equilibrium is\ndetermined by an aggregate quantity $Q(t)$, e.g. the market price or\nproduction, which then determines optimal trajectories for agents. Our approach\nconsists in analyzing the relationship between $Q(t)$ and corresponding optimal\ntrajectories to find conditions under which there is at most one equilibrium.\nWe show that our conditions do not match those prescribed by the Lasry-Lions\nmonotonicity condition, nor even displacement monotonicity, but they do apply\nto economic models that have been proposed in the literature.",
    "pdf_url": "http://arxiv.org/pdf/2410.13950v1",
    "published": "2024-10-17T18:19:49+00:00",
    "categories": [
      "math.OC",
      "math.AP",
      "49N80(Primary), 35Q89(Secondary)"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13949v2",
    "title": "Modeling Zero-Inflated Correlated Dental Data through Gaussian Copulas and Approximate Bayesian Computation",
    "authors": [
      "Anish Mukherjee",
      "Jeremy T. Gaskins",
      "Shoumi Sarkar",
      "Steven Levy",
      "Somnath Datta"
    ],
    "abstract": "We develop a new longitudinal count data regression model that accounts for\nzero-inflation and spatio-temporal correlation across responses. This project\nis motivated by an analysis of Iowa Fluoride Study (IFS) data, a longitudinal\ncohort study with data on caries (cavity) experience scores measured for each\ntooth across five time points. To that end, we use a hurdle model for\nzero-inflation with two parts: the presence model indicating whether a count is\nnon-zero through logistic regression and the severity model that considers the\nnon-zero counts through a shifted Negative Binomial distribution allowing\noverdispersion. To incorporate dependence across measurement occasion and\nteeth, these marginal models are embedded within a Gaussian copula that\nintroduces spatio-temporal correlations. A distinct advantage of this\nformulation is that it allows us to determine covariate effects with\npopulation-level (marginal) interpretations in contrast to mixed model choices.\nStandard Bayesian sampling from such a model is infeasible, so we use\napproximate Bayesian computing for inference. This approach is applied to the\nIFS data to gain insight into the risk factors for dental caries and the\ncorrelation structure across teeth and time.",
    "pdf_url": "http://arxiv.org/pdf/2410.13949v2",
    "published": "2024-10-17T18:18:52+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13947v1",
    "title": "MACK: Mismodeling Addressed with Contrastive Knowledge",
    "authors": [
      "Liam Rankin Sheldon",
      "Dylan Sheldon Rankin",
      "Philip Harris"
    ],
    "abstract": "The use of machine learning methods in high energy physics typically relies\non large volumes of precise simulation for training. As machine learning models\nbecome more complex they can become increasingly sensitive to differences\nbetween this simulation and the real data collected by experiments. We present\na generic methodology based on contrastive learning which is able to greatly\nmitigate this negative effect. Crucially, the method does not require prior\nknowledge of the specifics of the mismodeling. While we demonstrate the\nefficacy of this technique using the task of jet-tagging at the Large Hadron\nCollider, it is applicable to a wide array of different tasks both in and out\nof the field of high energy physics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13947v1",
    "published": "2024-10-17T18:18:41+00:00",
    "categories": [
      "hep-ph",
      "cs.LG",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13948v1",
    "title": "The KnowWhereGraph Ontology",
    "authors": [
      "Cogan Shimizu",
      "Shirly Stephe",
      "Adrita Barua",
      "Ling Cai",
      "Antrea Christou",
      "Kitty Currier",
      "Abhilekha Dalal",
      "Colby K. Fisher",
      "Pascal Hitzler",
      "Krzysztof Janowicz",
      "Wenwen Li",
      "Zilong Liu",
      "Mohammad Saeid Mahdavinejad",
      "Gengchen Mai",
      "Dean Rehberger",
      "Mark Schildhauer",
      "Meilin Shi",
      "Sanaz Saki Norouzi",
      "Yuanyuan Tian",
      "Sizhe Wang",
      "Zhangyu Wang",
      "Joseph Zalewski",
      "Lu Zhou",
      "Rui Zhu"
    ],
    "abstract": "KnowWhereGraph is one of the largest fully publicly available geospatial\nknowledge graphs. It includes data from 30 layers on natural hazards (e.g.,\nhurricanes, wildfires), climate variables (e.g., air temperature,\nprecipitation), soil properties, crop and land-cover types, demographics, and\nhuman health, various place and region identifiers, among other themes. These\nhave been leveraged through the graph by a variety of applications to address\nchallenges in food security and agricultural supply chains; sustainability\nrelated to soil conservation practices and farm labor; and delivery of\nemergency humanitarian aid following a disaster. In this paper, we introduce\nthe ontology that acts as the schema for KnowWhereGraph. This broad overview\nprovides insight into the requirements and design specifications for the graph\nand its schema, including the development methodology (modular ontology\nmodeling) and the resources utilized to implement, materialize, and deploy\nKnowWhereGraph with its end-user interfaces and public query SPARQL endpoint.",
    "pdf_url": "http://arxiv.org/pdf/2410.13948v1",
    "published": "2024-10-17T18:18:41+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13946v1",
    "title": "Weak Mixing Transformation Which Is Shannon Orbit Equivalent to a Given Ergodic Transformation",
    "authors": [
      "James O'Quinn"
    ],
    "abstract": "We prove that every ergodic transformation is Shannon orbit equivalent to a\nweak mixing transformation. The proof is based on the techniques introduced by\nFieldsteel and Friedman to show that there is a mixing transformation for a\ngiven ergodic transformation $T$ which is, for all $a\\geq1$,\nweak-$a$-equivalent to $T$ and, for all $b\\in(0,1)$, strong-$b$-equivalent to\n$T$. In particular, we will adapt the construction of Fieldsteel and Friedman\nby which they permute the columns of each Rokhlin tower in a sequence of\nrapidly growing Rokhlin towers so that the corresponding cocycles converge to\nan orbit equivalence cocycle of $T$ such that the resulting transformation and\norbit equivalence have the desired properties. In addition to this, we will\ndemonstrate a flexible method for obtaining actions of $\\mathbb{Z}^{2} $ which\nare Shannon orbit equivalent to a given ergodic transformation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13946v1",
    "published": "2024-10-17T18:18:02+00:00",
    "categories": [
      "math.DS",
      "37A05, 37A20, 37A25, 37A35"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13945v1",
    "title": "Explosive rigidity percolation in origami",
    "authors": [
      "Rongxuan Li",
      "Gary P. T. Choi"
    ],
    "abstract": "Origami, the traditional art of paper folding, has revolutionized science and\ntechnology in recent years and has been found useful in various real-world\napplications. In particular, origami-inspired structures have been utilized for\nrobotics and mechanical information storage, in both of which the rigidity\ncontrol of origami plays a crucial role. However, most prior works have only\nconsidered the origami design problem using purely deterministic or stochastic\napproaches. In this paper, we study the rigidity control of origami using the\nidea of explosive percolation. Specifically, to turn a maximally floppy origami\nstructure into a maximally rigid origami structure, one can combine a random\nsampling process of origami facets and some simple selection rules, which allow\nus to exploit the power of choices and significantly accelerate or delay the\nrigidity percolation transition. We further derive simple formulas that connect\nthe rigidity percolation transition effects with the origami pattern size and\nthe number of choices, thereby providing an effective way to determine the\noptimal number of choices for achieving prescribed rigidity percolation\ntransition accuracy and sharpness. Altogether, our work paves a new way for the\nrigidity control of mechanical metamaterials.",
    "pdf_url": "http://arxiv.org/pdf/2410.13945v1",
    "published": "2024-10-17T18:10:54+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.mtrl-sci",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13944v1",
    "title": "Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation",
    "authors": [
      "Junhong Wu",
      "Yang Zhao",
      "Yangyifan Xu",
      "Bing Liu",
      "Chengqing Zong"
    ],
    "abstract": "Large Language Models (LLMs) have achieved impressive results across numerous\nNLP tasks but still encounter difficulties in machine translation. Traditional\nmethods to improve translation have typically involved fine-tuning LLMs using\nparallel corpora. However, vanilla fine-tuning often leads to catastrophic\nforgetting of the instruction-following capabilities and alignment with human\npreferences, compromising their broad general abilities and introducing\npotential security risks. These abilities, which are developed using\nproprietary and unavailable training data, make existing continual instruction\ntuning methods ineffective. To overcome this issue, we propose a novel approach\ncalled RaDis (Rationale Distillation). RaDis harnesses the strong generative\ncapabilities of LLMs to create rationales for training data, which are then\n\"replayed\" to prevent forgetting. These rationales encapsulate general\nknowledge and safety principles, acting as self-distillation targets to\nregulate the training process. By jointly training on both reference\ntranslations and self-generated rationales, the model can learn new translation\nskills while preserving its overall general abilities. Extensive experiments\ndemonstrate that our method enhances machine translation performance while\nmaintaining the broader capabilities of LLMs across other tasks. This work\npresents a pathway for creating more versatile LLMs that excel in specialized\ntasks without compromising generality and safety.",
    "pdf_url": "http://arxiv.org/pdf/2410.13944v1",
    "published": "2024-10-17T18:09:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.14746v1",
    "title": "Accounting for Sycophancy in Language Model Uncertainty Estimation",
    "authors": [
      "Anthony Sicilia",
      "Mert Inan",
      "Malihe Alikhani"
    ],
    "abstract": "Effective human-machine collaboration requires machine learning models to\nexternalize uncertainty, so users can reflect and intervene when necessary. For\nlanguage models, these representations of uncertainty may be impacted by\nsycophancy bias: proclivity to agree with users, even if they are wrong. For\ninstance, models may be over-confident in (incorrect) problem solutions\nsuggested by a user. We study the relationship between sycophancy and\nuncertainty estimation for the first time. We propose a generalization of the\ndefinition of sycophancy bias to measure downstream impacts on uncertainty\nestimation, and also propose a new algorithm (SyRoUP) to account for sycophancy\nin the uncertainty estimation process. Unlike previous works on sycophancy, we\nstudy a broad array of user behaviors, varying both correctness and confidence\nof user suggestions to see how model answers (and their certainty) change. Our\nexperiments across conversation forecasting and question-answering tasks show\nthat user confidence plays a critical role in modulating the effects of\nsycophancy, and that SyRoUP can better predict these effects. From these\nresults, we argue that externalizing both model and user uncertainty can help\nto mitigate the impacts of sycophancy bias.",
    "pdf_url": "http://arxiv.org/pdf/2410.14746v1",
    "published": "2024-10-17T18:00:25+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13943v2",
    "title": "M-theory geometric engineering for rank-0 3d $\\mathcal{N}=2$ theories",
    "authors": [
      "Andrea Sangiovanni",
      "Roberto Valandro"
    ],
    "abstract": "M-theory geometric engineering on non-compact Calabi-Yau fourfolds (CY4)\nproduces 3d theories with 4 supercharges. Carefully establishing a dictionary\nbetween the geometry of the CY4 and the QFT in the transverse directions\nremains, to a large extent, an unresolved challenge, complicated by subtleties\narising from M5-brane instanton corrections. Such difficulties can be\ncircumvented in the restricted and yet controlled setting offered by CY4 with\nterminal singularities, as they do not admit crepant resolutions with compact\nexceptional divisors. After a general review of their properties and partial\nclassifications, we focus on a subclass of terminal CY4 constructed as deformed\nDu Val singularities, that admit crepant resolutions with at most exceptional\n2-cycles. We extract the corresponding 3d $\\mathcal{N}=2$ supersymmetric theory\ndescendant in an unambiguous fashion, as the absence of compact 4-cycles leaves\nno room for a choice of background $G_4$ flux. These turn out to be theories of\nchiral multiplets with no gauge group and at most abelian flavor factors: we\nargue that they serve as the simplest building blocks to substantiate a\nrigorous CY4/3d QFT geometric engineering mapping.",
    "pdf_url": "http://arxiv.org/pdf/2410.13943v2",
    "published": "2024-10-17T18:00:09+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13940v1",
    "title": "Boundary conditions and violations of bulk-edge correspondence in a hydrodynamic model",
    "authors": [
      "Gian Michele Graf",
      "Alessandro Tarantola"
    ],
    "abstract": "Bulk-edge correspondence is a wide-ranging principle that applies to\ntopological matter, as well as a precise result established in a large and\ngrowing number of cases. According to the principle, the distinctive\ntopological properties of matter, thought of as extending indefinitely in\nspace, are equivalently reflected in the excitations running along its\nboundary, when one is present. Indices encode those properties, and their\nvalues, when differing, are witness to a violation of that correspondence. We\naddress such violations, as they are encountered in a hydrodynamic context. The\nmodel concerns a shallow layer of fluid in a rotating frame and provides a\nlocal description of waves propagating either across the oceans or along a\ncoastline; it becomes topological when suitably modified at short distances.\nThe edge index is sensitive to boundary conditions, as exemplified in earlier\nwork, hence exhibiting a violation. Here we present classification of all\n(local, self-adjoint) boundary conditions and a parameterization of their\nmanifold. They come in four families, distinguished in part by the degree of\ntheir underlying differential operators. Essentially, that degree counts the\ndegrees of freedom of the hydrodynamic field that are constrained at the\nboundary by way of their normal derivatives. Generally, both the correspondence\nand its violation are typical. Within families though, the maximally possible\namount of violation is increasing with its degree. Several indices of interest\nare charted for all boundary conditions. A single spectral mechanism for the\nonset of violations is furthermore identified. The role of a symmetry is\ninvestigated.",
    "pdf_url": "http://arxiv.org/pdf/2410.13940v1",
    "published": "2024-10-17T18:00:06+00:00",
    "categories": [
      "math-ph",
      "cond-mat.mes-hall",
      "math.MP",
      "physics.ao-ph"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13941v1",
    "title": "Displaced Searches for Axion-Like Particles and Heavy Neutral Leptons at Mu3e",
    "authors": [
      "Simon Knapen",
      "Toby Opferkuch",
      "Diego Redigolo",
      "Michele Tammaro"
    ],
    "abstract": "We present strategies for the Mu3e experiment to search for light, weakly\ncoupled particles produced in rare muon decays, focusing on displaced $e^+e^-$\ndecays within the hollow target. In most scenarios the backgrounds can be fully\nsuppressed with a suitable set of cuts. We furthermore quantify the interplay\nbetween displaced and prompt searches at Mu3e and existing constraints, showing\nhow Mu3e has a unique opportunity to probe unexplored parameter space.",
    "pdf_url": "http://arxiv.org/pdf/2410.13941v1",
    "published": "2024-10-17T18:00:06+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13942v2",
    "title": "Identifying supermassive black hole recoil in elliptical galaxies",
    "authors": [
      "Alexander Rawlings",
      "Atte Keitaanranta",
      "Max Mattero",
      "Sonja Soininen",
      "Ruby J. Wright",
      "Noa Kallioinen",
      "Shihong Liao",
      "Antti Rantala",
      "Peter H. Johansson",
      "Thorsten Naab",
      "Dimitrios Irodotou"
    ],
    "abstract": "We study stellar core growth in simulations of merging massive\n($M_\\star>10^{11}\\,\\mathrm{M}_\\odot$) elliptical galaxies by a supermassive\nblack hole (SMBH) displaced by gravitational wave induced recoil velocity. With\ncontrolled, dense sampling of the SMBH recoil velocity, we find the core radius\noriginally formed by SMBH binary scouring can grow by a factor of 2-3 when the\nrecoil velocity exceeds $\\sim50$ per cent of the central escape velocity, and\nthe mass deficit grows by up to a factor of $\\sim4$. Using Bayesian inference\nwe predict the distribution of stellar core sizes formed through this process\nto peak at $\\sim1\\,\\mathrm{kpc}$. An orbital decomposition of stellar particles\nwithin the core reveals that radial orbits dominate over tube orbits when the\nrecoil velocity exceeds the velocity dispersion of the core, whereas tube\norbits dominate for the lowest recoil kicks. A change in orbital structure is\nreflected in the anisotropy parameter, with a central tangential bias present\nonly for recoil velocities less than the local stellar velocity dispersion.\nEmulating current integral field unit observations of the stellar line-of-sight\nvelocity distribution, we uncover a distinct signature in the Gauss-Hermite\nsymmetric deviation coefficient $h_4$ that uniquely constrains the core size\ndue to binary scouring. This signature is insensitive to the later evolution of\nthe stellar mass distribution due to SMBH recoil. Our results provide a novel\nmethod to estimate the SMBH recoil magnitude from observations of local\nelliptical galaxies, and implies these galaxies primarily experienced recoil\nvelocities less than the stellar velocity dispersion of the core.",
    "pdf_url": "http://arxiv.org/pdf/2410.13942v2",
    "published": "2024-10-17T18:00:06+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13938v2",
    "title": "Photonic Simulation of Localization Phenomena Using Boson Sampling",
    "authors": [
      "Anuprita V. Kulkarni",
      "Vatsana Tiwari",
      "Auditya Sharma",
      "Ankur Raina"
    ],
    "abstract": "Quantum simulation in its current state faces experimental overhead in terms\nof physical space and cooling. We propose boson sampling as an alternative\ncompact synthetic platform performing at room temperature. Identifying the\ncapability of estimating matrix permanents, we explore the applicability of\nboson sampling for tackling the dynamics of quantum systems without having\naccess to information about the full state vector. By mapping the\ntime-evolution unitary of a Hamiltonian onto an interferometer via\ncontinuous-variable gate decompositions, we present proof-of-principle results\nof localization characteristics of a single particle. We study the dynamics of\none-dimensional tight-binding systems in the clean and quasiperiodic-disordered\nlimits to observe Bloch oscillations and dynamical localization, and the\ndelocalization-to-localization phase transition in the Aubry- Andre-Harper\nmodel respectively. Our computational results obtained using boson sampling are\nin complete agreement with the dynamical and static results of non-interacting\ntight-binding systems obtained using conventional numerical calculations.\nAdditionally, our study highlights the role of number of sampling measurements\nor shots for simulation accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2410.13938v2",
    "published": "2024-10-17T18:00:05+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13939v2",
    "title": "A search for self-lensing binaries with TESS and constraints on their occurrence rate",
    "authors": [
      "Natsuko Yamaguchi",
      "Kareem El-Badry",
      "Nicholas M. Sorabella"
    ],
    "abstract": "Five self-lensing binaries (SLBs) have been discovered with Kepler light\ncurves. They contain white dwarfs (WDs) in AU-scale orbits that gravitationally\nlens solar-type companions. Forming SLBs likely requires common envelope\nevolution when the WD progenitor is an AGB star and has a weakly bound\nenvelope. No SLBs have yet been discovered with data from the Transiting\nExoplanet Survey Satellite (TESS), which observes far more stars than Kepler\ndid. Identifying self-lensing in TESS data is made challenging by the fact that\nTESS only observes most stars for $\\sim$25 days at a time, so only a single\nlensing event will be observed for typical SLBs. TESS's smaller aperture also\nmakes it sensitive only to SLBs a factor of $\\sim$100 brighter than those to\nwhich Kepler is sensitive. We demonstrate that TESS has nevertheless likely\nalready observed $\\sim$4 times more detectable SLBs than Kepler. We describe a\nsearch for non-repeating self-lensing signals in TESS light curves and present\npreliminary candidates for which spectroscopic follow-up is ongoing. We\ncalculate the sensitivity of our search with injection and recovery tests on\nTESS and Kepler light curves. Based on the 5 SLBs discovered with Kepler light\ncurves, we estimate that $(1.1 \\pm 0.6)\\%$ of solar-type stars are orbited by\nWDs with periods of 100-1000 d. This implies a space density of AU-scale WD +\nmain sequence (MS) binaries a factor of 20-100 larger than that of\nastrometrically-identified WD + MS binaries with orbits in Gaia DR3. We\nconclude that the Gaia sample is still quite incomplete, mainly because WD + MS\nbinaries can only be unambiguously identified as such for high mass ratios.",
    "pdf_url": "http://arxiv.org/pdf/2410.13939v2",
    "published": "2024-10-17T18:00:05+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13936v1",
    "title": "How large could CP violation in neutral $B$ meson mixing be? Implications for baryogenesis and upcoming searches",
    "authors": [
      "Carlos Miró",
      "Miguel Escudero",
      "Miguel Nebot"
    ],
    "abstract": "CP violation in neutral $B$ meson oscillations is an experimental observable\nthat could be directly related to the baryon asymmetry of the Universe through\nthe $B$-Mesogenesis mechanism. As this phenomenon is highly suppressed in the\nStandard Model, it could also be a sensitive probe for many new physics\nscenarios that modify neutral meson mixing. Motivated by these facts, and the\ntimely $B$ physics program at the LHC and Belle II, we analyze how large CP\nviolation in the mixing of neutral $B_d$ and $B_s$ meson systems could be. We\nanswer this question, in light of current experimental data, within three\ndifferent scenarios, namely: (i) generic heavy new physics only affecting the\nmass mixing $M_{12}^q$, (ii) vector-like quark extensions that introduce\ndeviations of 3$\\times$3 CKM unitarity, and (iii) light new physics modifying\nthe decay mixing $\\Gamma_{12}^q$. We find that enhancements of the semileptonic\nasymmetries, that measure the amount of CP violation in mixing, at the level of\n$10^{-3}$ for the $B_d$ system and $10^{-4}$ for the $B_s$ system can be\nachieved within scenarios (i) and (ii), while they are much more suppressed in\nrealistic UV completions triggering scenario (iii). With respect to cosmology,\nthe difficulty of finding large CP asymmetries in our analysis puts the\n$B$-Mesogenesis mechanism in tension. Finally, we conclude that upcoming\nexperimental searches for CP violation in $B$ meson mixing at LHCb and Belle II\nare unlikely to detect a new physics signal for the most generic models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13936v1",
    "published": "2024-10-17T18:00:03+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13937v2",
    "title": "Quantum computational complexity of matrix functions",
    "authors": [
      "Santiago Cifuentes",
      "Samson Wang",
      "Thais L. Silva",
      "Mario Berta",
      "Leandro Aolita"
    ],
    "abstract": "We investigate the dividing line between classical and quantum computational\npower in estimating properties of matrix functions. More precisely, we study\nthe computational complexity of two primitive problems: given a function $f$\nand a Hermitian matrix $A$, compute a matrix element of $f(A)$ or compute a\nlocal measurement on $f(A)|0\\rangle^{\\otimes n}$, with $|0\\rangle^{\\otimes n}$\nan $n$-qubit reference state vector, in both cases up to additive approximation\nerror. We consider four functions -- monomials, Chebyshev polynomials, the time\nevolution function, and the inverse function -- and probe the complexity across\na broad landscape covering different problem input regimes. Namely, we consider\ntwo types of matrix inputs (sparse and Pauli access), matrix properties (norm,\nsparsity), the approximation error, and function-specific parameters. We\nidentify BQP-complete forms of both problems for each function and then toggle\nthe problem parameters to easier regimes to see where hardness remains, or\nwhere the problem becomes classically easy. As part of our results, we make\nconcrete a hierarchy of hardness across the functions; in parameter regimes\nwhere we have classically efficient algorithms for monomials, all three other\nfunctions remain robustly BQP-hard, or hard under usual computational\ncomplexity assumptions. In identifying classically easy regimes, among others,\nwe show that for any polynomial of degree $\\mathrm{poly}(n)$ both problems can\nbe efficiently classically simulated when $A$ has $O(\\log n)$ non-zero\ncoefficients in the Pauli basis. This contrasts with the fact that the problems\nare BQP-complete in the sparse access model even for constant row sparsity,\nwhereas the stated Pauli access efficiently constructs sparse access with row\nsparsity $O(\\log n)$. Our work provides a catalog of efficient quantum and\nclassical algorithms for fundamental linear-algebra tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13937v2",
    "published": "2024-10-17T18:00:03+00:00",
    "categories": [
      "quant-ph",
      "cs.CC"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13934v3",
    "title": "Extractable energy from quantum superposition of current states",
    "authors": [
      "Francesco Perciavalle",
      "Davide Rossini",
      "Juan Polo",
      "Luigi Amico"
    ],
    "abstract": "We explore the energy content of superpositions of current states.\nSpecifically, we focus on the maximum energy that can be extracted from them\nthrough local unitary transformations. The figure of merit we employ is the\nlocal ergotropy. We perform a complete analysis in the whole range of the\nsystem's parameters. This way, we prove that superpositions of two current\nstates in spatially closed spin networks are characterized by specific peaks in\nextractable energy, generally overcoming the ergotropy of each of the two\nseparate current states characterized by a single winding number. The many-body\nstate dynamics entails to ergotropy evolving in a controlled fashion. The\nimplementation we suggest is based on a Rydberg-atom platform. Optimal\ntransformations able to extract locally the maximum possible amount of energy\nare sorted out.",
    "pdf_url": "http://arxiv.org/pdf/2410.13934v3",
    "published": "2024-10-17T18:00:02+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.quant-gas"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13935v2",
    "title": "Black-Hole Cartography",
    "authors": [
      "Richard Dyer",
      "Christopher J. Moore"
    ],
    "abstract": "Quasinormal modes (QNMs) are usually characterized by their time dependence;\noscillations at specific frequencies predicted by black hole (BH) perturbation\ntheory. QNMs are routinely identified in the ringdown of numerical relativity\nwaveforms, are widely used in waveform modeling, and underpin key tests of\ngeneral relativity and of the nature of compact objects; a program sometimes\ncalled BH spectroscopy. Perturbation theory also predicts a specific spatial\nshape for each QNM perturbation. For the Kerr metric, these are the ($s=-2$)\nspheroidal harmonics. Spatial information can be extracted from numerical\nrelativity by fitting a feature with known time dependence to all of the\nspherical harmonic modes, allowing the shape of the feature to be\nreconstructed; a program initiated here and that we call BH cartography.\nAccurate spatial reconstruction requires fitting to many spherical harmonics\nand is demonstrated using highly accurate Cauchy-characteristic numerical\nrelativity waveforms. The loudest QNMs are mapped, and their reconstructed\nshapes are found to match the spheroidal harmonic predictions. The cartographic\nprocedure is also applied to the quadratic QNMs -- nonlinear features in the\nringdown -- and their reconstructed shapes are compared with expectations based\non second-order perturbation theory. BH cartography allows us to determine the\nviewing angles that maximize the amplitude of the quadratic QNMs, an important\nguide for future searches, and is expected to lead to an improved understanding\nof nonlinearities in BH ringdown.",
    "pdf_url": "http://arxiv.org/pdf/2410.13935v2",
    "published": "2024-10-17T18:00:02+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13932v2",
    "title": "Spirals, rings, and vortices shaped by shadows in protoplanetary disks: from radiative hydrodynamical simulations to observable signatures",
    "authors": [
      "Alexandros Ziampras",
      "Cornelis P. Dullemond",
      "Tilman Birnstiel",
      "Myriam Benisty",
      "Richard P. Nelson"
    ],
    "abstract": "Numerous protoplanetary disks exhibit shadows in scattered light\nobservations. These shadows are typically cast by misaligned inner disks and\nare associated with observable structures in the outer disk such as bright arcs\nand spirals. Investigating the dynamics of the shadowed outer disk is therefore\nessential in understanding the formation and evolution of these structures. We\ncarry out twodimensional radiation hydrodynamics simulations that include\nradiative diffusion and dust-gas dynamics to study the formation of\nsubstructure in shadowed disks. We find that spiral arms are launched at the\nedge of each shadow, permeating the entire disk. The local dissipation of these\nspirals results in an angular momentum flux, opening multiple gaps and leading\nto a series of concentric, regularly-spaced rings We find that ring formation\nis favored in weakly turbulent disks where dust growth is taking place. These\nconditions are met for typical class-II disks, in which bright rings should\nform well within a fraction of their lifetime (0.1-0.2 Myr). For hotter disks\ngap opening is more efficient, such that the gap edges quickly collapse into\nvortices that can appear as bright arcs in continuum emission before decaying\ninto rings or merging into massive, long-lived structures. Synthetic\nobservations show that these structures should be observable in scattered light\nand millimeter continuum emission, providing a new way to probe the presence of\nsubstructure in protoplanetary disks. Our results suggest that the formation of\nrings and gaps is a common process in shadowed disks, and can explain the rich\nradial substructure observed in several protoplanetary disks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13932v2",
    "published": "2024-10-17T18:00:01+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13933v2",
    "title": "Modelling absorption and emission profiles from accretion disc winds with WINE",
    "authors": [
      "Alfredo Luminari",
      "Enrico Piconcelli",
      "Francesco Tombesi",
      "Fabrizio Nicastro",
      "Fabrizio Fiore"
    ],
    "abstract": "Fast, massive winds are ubiquitously observed in the UV and X-ray spectra of\nActive Galactic Nuclei (AGN) and other accreting sources. Theoretical and\nobservational evidences suggest they are launched at accretion disc scales,\ncarrying significant mass and angular momentum. Thanks to such high energy\noutput, they may play an important role in transferring the accretion energy to\nthe surrounding environment. In the case of AGNs, this process can help setting\nthe so-called coevolution between the AGN and its host galaxy. To precisely\nassess the effective role of these winds, it is necessary to accurately measure\ntheir properties, including mass and energy rates. We aim to maximise the\nscientific return of current and future observations by improving the\ntheoretical modelling of these winds through our Winds in the Ionised Nuclear\nEnvironment (WINE) model. WINE is a spectroscopic model designed for disc winds\nin AGNs and compact accreting sources, which couples photoionisation and\nradiative transfer with special relativistic effects and a three-dimensional\nmodel of the emission profiles. We explore with WINE the main spectral features\nassociated to AGN disc winds, with particular emphasis on the detectability of\nthe wind emission. We simulate observations with the X-ray microcalorimeters\nResolve on board the XRISM satellite and the future Athena's X-IFU for the\ntypical properties and exposure times of the sources in the XRISM Performance\nVerification phase. The wind kinematic, geometry, ionisation and column density\ndeeply affect shape and strength of the spectral features. Thanks to this, both\nResolve and X-IFU will be able to accurately constrain the main properties of\ndisc winds in a broad range of parameters. We also find a dramatic difference\nin the gas opacity when using a soft, Narrow Line Seyfert 1-like SED compared\nto a canonical powerlaw SED with spectral index Gamma=2.",
    "pdf_url": "http://arxiv.org/pdf/2410.13933v2",
    "published": "2024-10-17T18:00:01+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13929v2",
    "title": "Inference of morphology and dynamical state of nearby $Planck$-SZ galaxy clusters with Zernike polynomials",
    "authors": [
      "Valentina Capalbo",
      "Marco De Petris",
      "Antonio Ferragamo",
      "Weiguang Cui",
      "Florian Ruppin",
      "Gustavo Yepes"
    ],
    "abstract": "We analyse the maps of the Sunyaev-Zel'dovich (SZ) signal of local galaxy\nclusters ($z<0.1$) observed by the $Planck$ satellite in order to classify\ntheir dynamical state through morphological features. To study the morphology\nof the cluster maps, we apply a method recently employed on mock SZ images\ngenerated from hydrodynamical simulated galaxy clusters in THE THREE HUNDRED\n(THE300) project. Here, we report the first application on real data. The\nmethod consists in modelling the images with a set of orthogonal functions\ndefined on circular apertures, the Zernike polynomials. From the fit we compute\na single parameter, $\\mathcal{C}$, that quantifies the morphological features\npresent in each image. The link between the morphology of 2D images and the\ndynamical state of the galaxy clusters is well known, even if not obvious. We\nuse mock $Planck$-like Compton parameter maps generated for THE300 clusters to\nvalidate our morphological analysis. These clusters, in fact, are properly\nclassified for their dynamical state with the relaxation parameter, $\\chi$, by\nexploiting 3D information from simulations. We find a mild linear correlation\nof $\\sim 38\\%$ between $\\mathcal{C}$ and $\\chi$ for THE300 clusters, mainly\naffected by the noise present in the maps. In order to obtain a proper\ndynamical-state classification for the $Planck$ clusters, we exploit the\nconversion from the $\\mathcal{C}$ parameter derived in each $Planck$ map in\n$\\chi$. A fraction of the order of $63\\%$ of relaxed clusters is estimated in\nthe selected $Planck$ sample. Our classification is then compared with those of\nprevious works that have attempted to evaluate, with different indicators\nand/or other wavelengths, the dynamical state of the same $Planck$ objects. The\nagreement with the other works is larger than $58\\%$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13929v2",
    "published": "2024-10-17T18:00:00+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13930v1",
    "title": "Evidence of Floquet electronic steady states in graphene under continuous-wave mid-infrared irradiation",
    "authors": [
      "Yijing Liu",
      "Christopher Yang",
      "Gabriel Gaertner",
      "John Huckabee",
      "Alexey V. Suslov",
      "Gil Refael",
      "Frederik Nathan",
      "Cyprian Lewandowski",
      "Luis E. F. Foa Torres",
      "Iliya Esin",
      "Paola Barbara",
      "Nikolai G. Kalugin"
    ],
    "abstract": "Light-induced phenomena in materials can exhibit exotic behavior that extends\nbeyond equilibrium properties, offering new avenues for understanding and\ncontrolling electronic phases. So far, non-equilibrium phenomena in solids have\nbeen predominantly explored using femtosecond laser pulses, which generate\ntransient, ultra-fast dynamics. Here, we investigate the steady non-equilibrium\nregime in graphene induced by a continuous-wave (CW) mid-infrared laser. Our\ntransport measurements reveal signatures of a long-lived Floquet phase, where a\nnon-equilibrium electronic population is stabilized by the interplay between\ncoherent photoexcitation and incoherent phonon cooling. The observation of\nnon-equilibrium steady states using CW lasers opens a new regime for\nlow-temperature Floquet phenomena, paving the way toward Floquet engineering of\nsteady-state phases of matter.",
    "pdf_url": "http://arxiv.org/pdf/2410.13930v1",
    "published": "2024-10-17T18:00:00+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13931v1",
    "title": "Tensor Integrals in the Large-Scale Structure",
    "authors": [
      "Hayden Lee"
    ],
    "abstract": "We present a new method for evaluating tensor integrals in the large-scale\nstructure. Decomposing a $\\Lambda$CDM-like universe into a finite sum of\nscaling universes using the FFTLog, we can recast loop integrals for biased\ntracers in the large-scale structure as certain tensor integrals in quantum\nfield theory. While rotational symmetry is spontaneously broken by the fixed\nreference frame in which biased tracers are observed, the tensor structures can\nstill be organized to respect the underlying symmetry. Projecting the loop\nintegrands for scaling universes onto spherical harmonics, the problem\neffectively reduces to the evaluation of one-dimensional radial integrals,\nwhich can be solved analytically. Using this method, we derive analytic\nexpressions for the one-loop power spectrum, bispectrum, and trispectrum for\narbitrary multipole moments in the basis of scaling universes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13931v1",
    "published": "2024-10-17T18:00:00+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13863v1",
    "title": "Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens",
    "authors": [
      "Lijie Fan",
      "Tianhong Li",
      "Siyang Qin",
      "Yuanzhen Li",
      "Chen Sun",
      "Michael Rubinstein",
      "Deqing Sun",
      "Kaiming He",
      "Yonglong Tian"
    ],
    "abstract": "Scaling up autoregressive models in vision has not proven as beneficial as in\nlarge language models. In this work, we investigate this scaling problem in the\ncontext of text-to-image generation, focusing on two critical factors: whether\nmodels use discrete or continuous tokens, and whether tokens are generated in a\nrandom or fixed raster order using BERT- or GPT-like transformer architectures.\nOur empirical results show that, while all models scale effectively in terms of\nvalidation loss, their evaluation performance -- measured by FID, GenEval\nscore, and visual quality -- follows different trends. Models based on\ncontinuous tokens achieve significantly better visual quality than those using\ndiscrete tokens. Furthermore, the generation order and attention mechanisms\nsignificantly affect the GenEval score: random-order models achieve notably\nbetter GenEval scores compared to raster-order models. Inspired by these\nfindings, we train Fluid, a random-order autoregressive model on continuous\ntokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16\non MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope our\nfindings and results will encourage future efforts to further bridge the\nscaling gap between vision and language models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13863v1",
    "published": "2024-10-17T17:59:59+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13864v2",
    "title": "UniDrive: Towards Universal Driving Perception Across Camera Configurations",
    "authors": [
      "Ye Li",
      "Wenzhao Zheng",
      "Xiaonan Huang",
      "Kurt Keutzer"
    ],
    "abstract": "Vision-centric autonomous driving has demonstrated excellent performance with\neconomical sensors. As the fundamental step, 3D perception aims to infer 3D\ninformation from 2D images based on 3D-2D projection. This makes driving\nperception models susceptible to sensor configuration (e.g., camera intrinsics\nand extrinsics) variations. However, generalizing across camera configurations\nis important for deploying autonomous driving models on different car models.\nIn this paper, we present UniDrive, a novel framework for vision-centric\nautonomous driving to achieve universal perception across camera\nconfigurations. We deploy a set of unified virtual cameras and propose a\nground-aware projection method to effectively transform the original images\ninto these unified virtual views. We further propose a virtual configuration\noptimization method by minimizing the expected projection error between\noriginal and virtual cameras. The proposed virtual camera projection can be\napplied to existing 3D perception methods as a plug-and-play module to mitigate\nthe challenges posed by camera parameter variability, resulting in more\nadaptable and reliable driving perception models. To evaluate the effectiveness\nof our framework, we collect a dataset on CARLA by driving the same routes\nwhile only modifying the camera configurations. Experimental results\ndemonstrate that our method trained on one specific camera configuration can\ngeneralize to varying configurations with minor performance degradation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13864v2",
    "published": "2024-10-17T17:59:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13862v3",
    "title": "DepthSplat: Connecting Gaussian Splatting and Depth",
    "authors": [
      "Haofei Xu",
      "Songyou Peng",
      "Fangjinhua Wang",
      "Hermann Blum",
      "Daniel Barath",
      "Andreas Geiger",
      "Marc Pollefeys"
    ],
    "abstract": "Gaussian splatting and single-view depth estimation are typically studied in\nisolation. In this paper, we present DepthSplat to connect Gaussian splatting\nand depth estimation and study their interactions. More specifically, we first\ncontribute a robust multi-view depth model by leveraging pre-trained monocular\ndepth features, leading to high-quality feed-forward 3D Gaussian splatting\nreconstructions. We also show that Gaussian splatting can serve as an\nunsupervised pre-training objective for learning powerful depth models from\nlarge-scale multi-view posed datasets. We validate the synergy between Gaussian\nsplatting and depth estimation through extensive ablation and cross-task\ntransfer experiments. Our DepthSplat achieves state-of-the-art performance on\nScanNet, RealEstate10K and DL3DV datasets in terms of both depth estimation and\nnovel view synthesis, demonstrating the mutual benefits of connecting both\ntasks. In addition, DepthSplat enables feed-forward reconstruction from 12\ninput views (512x960 resolutions) in 0.6 seconds.",
    "pdf_url": "http://arxiv.org/pdf/2410.13862v3",
    "published": "2024-10-17T17:59:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13861v2",
    "title": "PUMA: Empowering Unified MLLM with Multi-granular Visual Generation",
    "authors": [
      "Rongyao Fang",
      "Chengqi Duan",
      "Kun Wang",
      "Hao Li",
      "Hao Tian",
      "Xingyu Zeng",
      "Rui Zhao",
      "Jifeng Dai",
      "Hongsheng Li",
      "Xihui Liu"
    ],
    "abstract": "Recent advancements in multimodal foundation models have yielded significant\nprogress in vision-language understanding. Initial attempts have also explored\nthe potential of multimodal large language models (MLLMs) for visual content\ngeneration. However, existing works have insufficiently addressed the varying\ngranularity demands of different image generation tasks within a unified MLLM\nparadigm - from the diversity required in text-to-image generation to the\nprecise controllability needed in image manipulation. In this work, we propose\nPUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA\nunifies multi-granular visual features as both inputs and outputs of MLLMs,\nelegantly addressing the different granularity requirements of various image\ngeneration tasks within a unified MLLM framework. Following multimodal\npretraining and task-specific instruction tuning, PUMA demonstrates proficiency\nin a wide range of multimodal tasks. This work represents a significant step\ntowards a truly unified MLLM capable of adapting to the granularity demands of\nvarious visual tasks. The code and model will be released in\nhttps://github.com/rongyaofang/PUMA.",
    "pdf_url": "http://arxiv.org/pdf/2410.13861v2",
    "published": "2024-10-17T17:59:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13860v1",
    "title": "VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding",
    "authors": [
      "Runsen Xu",
      "Zhiwei Huang",
      "Tai Wang",
      "Yilun Chen",
      "Jiangmiao Pang",
      "Dahua Lin"
    ],
    "abstract": "3D visual grounding is crucial for robots, requiring integration of natural\nlanguage and 3D scene understanding. Traditional methods depending on\nsupervised learning with 3D point clouds are limited by scarce datasets.\nRecently zero-shot methods leveraging LLMs have been proposed to address the\ndata issue. While effective, these methods only use object-centric information,\nlimiting their ability to handle complex queries. In this work, we present\nVLM-Grounder, a novel framework using vision-language models (VLMs) for\nzero-shot 3D visual grounding based solely on 2D images. VLM-Grounder\ndynamically stitches image sequences, employs a grounding and feedback scheme\nto find the target object, and uses a multi-view ensemble projection to\naccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3D\ndatasets show VLM-Grounder outperforms previous zero-shot methods, achieving\n51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3D\ngeometry or object priors. Codes are available at\nhttps://github.com/OpenRobotLab/VLM-Grounder .",
    "pdf_url": "http://arxiv.org/pdf/2410.13860v1",
    "published": "2024-10-17T17:59:55+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13859v1",
    "title": "$γ-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models",
    "authors": [
      "Yaxin Luo",
      "Gen Luo",
      "Jiayi Ji",
      "Yiyi Zhou",
      "Xiaoshuai Sun",
      "Zhiqiang Shen",
      "Rongrong Ji"
    ],
    "abstract": "Despite the significant progress in multimodal large language models (MLLMs),\ntheir high computational cost remains a barrier to real-world deployment.\nInspired by the mixture of depths (MoDs) in natural language processing, we aim\nto address this limitation from the perspective of ``activated tokens''. Our\nkey insight is that if most tokens are redundant for the layer computation,\nthen can be skipped directly via the MoD layer. However, directly converting\nthe dense layers of MLLMs to MoD layers leads to substantial performance\ndegradation. To address this issue, we propose an innovative MoD adaptation\nstrategy for existing MLLMs called $\\gamma$-MoD. In $\\gamma$-MoD, a novel\nmetric is proposed to guide the deployment of MoDs in the MLLM, namely rank of\nattention maps (ARank). Through ARank, we can effectively identify which layer\nis redundant and should be replaced with the MoD layer. Based on ARank, we\nfurther propose two novel designs to maximize the computational sparsity of\nMLLM while maintaining its performance, namely shared vision-language router\nand masked routing learning. With these designs, more than 90% dense layers of\nthe MLLM can be effectively converted to the MoD ones. To validate our method,\nwe apply it to three popular MLLMs, and conduct extensive experiments on 9\nbenchmark datasets. Experimental results not only validate the significant\nefficiency benefit of $\\gamma$-MoD to existing MLLMs but also confirm its\ngeneralization ability on various MLLMs. For example, with a minor performance\ndrop, i.e., -1.5%, $\\gamma$-MoD can reduce the training and inference time of\nLLaVA-HR by 31.0% and 53.2%, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2410.13859v1",
    "published": "2024-10-17T17:59:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13858v2",
    "title": "Monte Carlo Study of Critical Fermi Surface with Spatially Disordered Interactions",
    "authors": [
      "Tu Hong",
      "Xiao Yan Xu"
    ],
    "abstract": "Non-Fermi liquids are an important topic in condensed matter physics, as\ntheir characteristics challenge the framework of traditional Fermi liquid\ntheory and reveal the complex behavior of electrons in strongly interacting\nsystems. Despite some progress in this field, linear-in-temperature resistivity\nand inverse-in-frequency tail of optical conductivity are unresolved issues in\nnon-Fermi liquids. Both the experimentally observed smeared region and the\ntheoretically predicted marginal Fermi liquid suggest that spatial disorder\nseems to be an important driver of these phenomena. By performing large-scale\ndeterminant quantum Monte Carlo (DQMC) simulations in the ferromagnetic\nspin-fermion model at finite $N$, beyond the large-$N$ used in previous\ntheoretical work, we investigated the role of spatial disorder in the critical\nFermi surface (FS) of this model. We proposed a corrected theory of our system,\nwhich is based on a modified Eliashberg theory and a universal theory of\nstrange metals. This theory agrees well with the data obtained from DQMC,\nparticularly in capturing the $\\omega \\ln \\omega$ type self-energy\ncharacteristic of marginal Fermi liquid behavior, though temperature\nlimitations prevent us from observing the linear-in-temperature scattering\nrate. Our findings offer strong and unbiased validation of the universal theory\nof strange metals, broaden the applicability of the modified Eliashberg theory,\nand provide insights for numerically searching for marginal Fermi liquid and\nlinear-in-temperature resistivity.",
    "pdf_url": "http://arxiv.org/pdf/2410.13858v2",
    "published": "2024-10-17T17:59:49+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13857v2",
    "title": "How Numerical Precision Affects Arithmetical Reasoning Capabilities of LLMs",
    "authors": [
      "Guhao Feng",
      "Kai Yang",
      "Yuntian Gu",
      "Xinyue Ai",
      "Shengjie Luo",
      "Jiacheng Sun",
      "Di He",
      "Zhenguo Li",
      "Liwei Wang"
    ],
    "abstract": "Despite the remarkable success of Transformer-based large language models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in arithmetical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13857v2",
    "published": "2024-10-17T17:59:35+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13856v1",
    "title": "A Fourier analysis framework for approximate classical simulations of quantum circuits",
    "authors": [
      "Cristina Cirstoiu"
    ],
    "abstract": "What makes a class of quantum circuits efficiently classically simulable on\naverage? I present a framework that applies harmonic analysis of groups to\ncircuits with a structure encoded by group parameters. Expanding the circuits\nin a suitable truncated multi-path operator basis gives algorithms to evaluate\nthe Fourier coefficients of output distributions or expectation values that are\nviewed as functions on the group. Under certain conditions, a truncated Fourier\nseries can be efficiently estimated with guaranteed mean-square convergence.\nFor classes of noisy circuits, it leads to algorithms for sampling and mean\nvalue estimation under error models with a spectral gap, where the complexity\nincreases exponentially with the gap's inverse and polynomially with the\ncircuit's size. This approach unifies and extends existing algorithms for noisy\nparametrised or random circuits using Pauli basis paths. For classes of\nnoiseless circuits, mean values satisfying Lipschitz continuity can be on\naverage approximated using efficient sparse Fourier decompositions. I also\ndiscuss generalisations to homogeneous spaces, qudit systems and a way to\nanalyse random circuits via matrix coefficients of irreducible representations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13856v1",
    "published": "2024-10-17T17:59:34+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13855v2",
    "title": "Diffusing States and Matching Scores: A New Framework for Imitation Learning",
    "authors": [
      "Runzhe Wu",
      "Yiding Chen",
      "Gokul Swamy",
      "Kianté Brantley",
      "Wen Sun"
    ],
    "abstract": "Adversarial Imitation Learning is traditionally framed as a two-player\nzero-sum game between a learner and an adversarially chosen cost function, and\ncan therefore be thought of as the sequential generalization of a Generative\nAdversarial Network (GAN). However, in recent years, diffusion models have\nemerged as a non-adversarial alternative to GANs that merely require training a\nscore function via regression, yet produce generations of higher quality. In\nresponse, we investigate how to lift insights from diffusion modeling to the\nsequential setting. We propose diffusing states and performing score-matching\nalong diffused states to measure the discrepancy between the expert's and\nlearner's states. Thus, our approach only requires training score functions to\npredict noises via standard regression, making it significantly easier and more\nstable to train than adversarial methods. Theoretically, we prove first- and\nsecond-order instance-dependent bounds with linear scaling in the horizon,\nproving that our approach avoids the compounding errors that stymie offline\napproaches to imitation learning. Empirically, we show our approach outperforms\nboth GAN-style imitation learning baselines and discriminator-free imitation\nlearning baselines across various continuous control problems, including\ncomplex tasks like controlling humanoids to walk, sit, crawl, and navigate\nthrough obstacles.",
    "pdf_url": "http://arxiv.org/pdf/2410.13855v2",
    "published": "2024-10-17T17:59:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13854v1",
    "title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?",
    "authors": [
      "Chenhao Zhang",
      "Xi Feng",
      "Yuelin Bai",
      "Xinrun Du",
      "Jinchang Hou",
      "Kaixin Deng",
      "Guangzeng Han",
      "Qinrui Li",
      "Bingli Wang",
      "Jiaheng Liu",
      "Xingwei Qu",
      "Yifei Zhang",
      "Qixuan Zhao",
      "Yiming Liang",
      "Ziqiang Liu",
      "Feiteng Fang",
      "Min Yang",
      "Wenhao Huang",
      "Chenghua Lin",
      "Ge Zhang",
      "Shiwen Ni"
    ],
    "abstract": "As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2410.13854v1",
    "published": "2024-10-17T17:59:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13853v2",
    "title": "AutoAL: Automated Active Learning with Differentiable Query Strategy Search",
    "authors": [
      "Yifeng Wang",
      "Xueying Zhan",
      "Siyu Huang"
    ],
    "abstract": "As deep learning continues to evolve, the need for data efficiency becomes\nincreasingly important. Considering labeling large datasets is both\ntime-consuming and expensive, active learning (AL) provides a promising\nsolution to this challenge by iteratively selecting the most informative\nsubsets of examples to train deep neural networks, thereby reducing the\nlabeling cost. However, the effectiveness of different AL algorithms can vary\nsignificantly across data scenarios, and determining which AL algorithm best\nfits a given task remains a challenging problem. This work presents the first\ndifferentiable AL strategy search method, named AutoAL, which is designed on\ntop of existing AL sampling strategies. AutoAL consists of two neural nets,\nnamed SearchNet and FitNet, which are optimized concurrently under a\ndifferentiable bi-level optimization framework. For any given task, SearchNet\nand FitNet are iteratively co-optimized using the labeled data, learning how\nwell a set of candidate AL algorithms perform on that task. With the optimal AL\nstrategies identified, SearchNet selects a small subset from the unlabeled pool\nfor querying their annotations, enabling efficient training of the task model.\nExperimental results demonstrate that AutoAL consistently achieves superior\naccuracy compared to all candidate AL algorithms and other selective AL\napproaches, showcasing its potential for adapting and integrating multiple\nexisting AL methods across diverse tasks and domains. Code is available at:\nhttps://github.com/haizailache999/AutoAL.",
    "pdf_url": "http://arxiv.org/pdf/2410.13853v2",
    "published": "2024-10-17T17:59:09+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13852v2",
    "title": "Retrospective Learning from Interactions",
    "authors": [
      "Zizhao Chen",
      "Mustafa Omer Gul",
      "Yiwei Chen",
      "Gloria Geng",
      "Anne Wu",
      "Yoav Artzi"
    ],
    "abstract": "Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. We introduce ReSpect, a method to learn from such signals in past\ninteractions via retrospection without additional annotations. We deploy\nReSpect in a new multimodal interaction scenario, where humans instruct a\nmultimodal LLM to solve an abstract reasoning task with a combinatorial\nsolution space. Through thousands of interactions with humans, we show how\nReSpect gradually improves task completion rate from 31% to 82%, all without\nany external annotation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13852v2",
    "published": "2024-10-17T17:59:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13850v5",
    "title": "Influence Functions for Scalable Data Attribution in Diffusion Models",
    "authors": [
      "Bruno Mlodozeniec",
      "Runa Eschenhagen",
      "Juhan Bae",
      "Alexander Immer",
      "David Krueger",
      "Richard Turner"
    ],
    "abstract": "Diffusion models have led to significant advancements in generative\nmodelling. Yet their widespread adoption poses challenges regarding data\nattribution and interpretability. In this paper, we aim to help address such\nchallenges in diffusion models by developing an influence functions framework.\nInfluence function-based data attribution methods approximate how a model's\noutput would have changed if some training data were removed. In supervised\nlearning, this is usually used for predicting how the loss on a particular\nexample would change. For diffusion models, we focus on predicting the change\nin the probability of generating a particular example via several proxy\nmeasurements. We show how to formulate influence functions for such quantities\nand how previously proposed methods can be interpreted as particular design\nchoices in our framework. To ensure scalability of the Hessian computations in\ninfluence functions, we systematically develop K-FAC approximations based on\ngeneralised Gauss-Newton matrices specifically tailored to diffusion models. We\nrecast previously proposed methods as specific design choices in our framework\nand show that our recommended method outperforms previous data attribution\napproaches on common evaluations, such as the Linear Data-modelling Score (LDS)\nor retraining without top influences, without the need for method-specific\nhyperparameter tuning.",
    "pdf_url": "http://arxiv.org/pdf/2410.13850v5",
    "published": "2024-10-17T17:59:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13851v1",
    "title": "Differentiable Robot Rendering",
    "authors": [
      "Ruoshi Liu",
      "Alper Canberk",
      "Shuran Song",
      "Carl Vondrick"
    ],
    "abstract": "Vision foundation models trained on massive amounts of visual data have shown\nunprecedented reasoning and planning skills in open-world settings. A key\nchallenge in applying them to robotic tasks is the modality gap between visual\ndata and action data. We introduce differentiable robot rendering, a method\nallowing the visual appearance of a robot body to be directly differentiable\nwith respect to its control parameters. Our model integrates a kinematics-aware\ndeformable model and Gaussians Splatting and is compatible with any robot form\nfactors and degrees of freedom. We demonstrate its capability and usage in\napplications including reconstruction of robot poses from images and\ncontrolling robots through vision language models. Quantitative and qualitative\nresults show that our differentiable rendering model provides effective\ngradients for robotic control directly from pixels, setting the foundation for\nthe future applications of vision foundation models in robotics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13851v1",
    "published": "2024-10-17T17:59:02+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13849v3",
    "title": "From Gradient Clipping to Normalization for Heavy Tailed SGD",
    "authors": [
      "Florian Hübler",
      "Ilyas Fatkhullin",
      "Niao He"
    ],
    "abstract": "Recent empirical evidence indicates that many machine learning applications\ninvolve heavy-tailed gradient noise, which challenges the standard assumptions\nof bounded variance in stochastic optimization. Gradient clipping has emerged\nas a popular tool to handle this heavy-tailed noise, as it achieves good\nperformance in this setting both theoretically and practically. However, our\ncurrent theoretical understanding of non-convex gradient clipping has three\nmain shortcomings. First, the theory hinges on large, increasing clipping\nthresholds, which are in stark contrast to the small constant clipping\nthresholds employed in practice. Second, clipping thresholds require knowledge\nof problem-dependent parameters to guarantee convergence. Lastly, even with\nthis knowledge, current sampling complexity upper bounds for the method are\nsub-optimal in nearly all parameters. To address these issues, we study\nconvergence of Normalized SGD (NSGD). First, we establish a parameter-free\nsample complexity for NSGD of\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{2p}{p-1}}\\right)$ to find an\n$\\varepsilon$-stationary point. Furthermore, we prove tightness of this result,\nby providing a matching algorithm-specific lower bound. In the setting where\nall problem parameters are known, we show this complexity is improved to\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{3p-2}{p-1}}\\right)$, matching the\npreviously known lower bound for all first-order methods in all problem\ndependent parameters. Finally, we establish high-probability convergence of\nNSGD with a mild logarithmic dependence on the failure probability. Our work\ncomplements the studies of gradient clipping under heavy tailed noise improving\nthe sample complexities of existing algorithms and offering an alternative\nmechanism to achieve high probability convergence.",
    "pdf_url": "http://arxiv.org/pdf/2410.13849v3",
    "published": "2024-10-17T17:59:01+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13848v1",
    "title": "Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation",
    "authors": [
      "Chengyue Wu",
      "Xiaokang Chen",
      "Zhiyu Wu",
      "Yiyang Ma",
      "Xingchao Liu",
      "Zizheng Pan",
      "Wen Liu",
      "Zhenda Xie",
      "Xingkai Yu",
      "Chong Ruan",
      "Ping Luo"
    ],
    "abstract": "In this paper, we introduce Janus, an autoregressive framework that unifies\nmultimodal understanding and generation. Prior research often relies on a\nsingle visual encoder for both tasks, such as Chameleon. However, due to the\ndiffering levels of information granularity required by multimodal\nunderstanding and generation, this approach can lead to suboptimal performance,\nparticularly in multimodal understanding. To address this issue, we decouple\nvisual encoding into separate pathways, while still leveraging a single,\nunified transformer architecture for processing. The decoupling not only\nalleviates the conflict between the visual encoder's roles in understanding and\ngeneration, but also enhances the framework's flexibility. For instance, both\nthe multimodal understanding and generation components can independently select\ntheir most suitable encoding methods. Experiments show that Janus surpasses\nprevious unified model and matches or exceeds the performance of task-specific\nmodels. The simplicity, high flexibility, and effectiveness of Janus make it a\nstrong candidate for next-generation unified multimodal models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13848v1",
    "published": "2024-10-17T17:58:37+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13847v2",
    "title": "Adaptive Compressive Tactile Subsampling: Enabling High Spatiotemporal Resolution in Scalable Robotic Skin",
    "authors": [
      "Ariel Slepyan",
      "Dian Li",
      "Aidan Aug",
      "Sriramana Sankar",
      "Trac Tran",
      "Nitish Thakor"
    ],
    "abstract": "Robots, like humans, require full-body, high-resolution tactile sensing to\noperate safely and effectively in unstructured environments, enabling reflexive\nresponses and closed-loop control. However, the high pixel counts necessary for\ndense, large-area coverage limit readout rates of most tactile arrays to below\n100 Hz, hindering their use in high-speed tasks. We introduce Adaptive\nCompressive Tactile Subsampling (ACTS), a scalable and data-driven method that\ndramatically enhances the performance of traditional tactile matrices by\nleveraging sparse recovery and a learned tactile dictionary. Tested on a\n1024-pixel tactile sensor array (32X32), ACTS achieved frame rates up to 1,000\nHz, an 18X improvement over conventional raster scanning, with minimal\nreconstruction error. For the first time, ACTS enables wearable, large-area,\nhigh-density tactile sensing systems that can deliver high-speed results. We\ndemonstrate rapid object classification within 20 ms of contact, high-speed\nprojectile detection, ricochet angle estimation, and soft deformation tracking,\nin tactile and robotics applications, all using flexible, high-density tactile\narrays. These include high-resolution tactile gloves, pressure insoles, and\nfull-body configurations covering robotic arms and human-sized mannequins. ACTS\ntransforms standard, low-cost, and robust tactile sensors into high-speed\nsystems, supporting applications from object manipulation to human-robot\ninteraction. By enabling comprehensive, scalable, and efficient tactile\ncoverage for robots and wearables, ACTS advances robotics toward lifelike,\nresponsive, and adaptable operation in dynamic environments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13847v2",
    "published": "2024-10-17T17:58:35+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13846v2",
    "title": "LightTransfer: Your Long-Context LLM is Secretly a Hybrid Model with Effortless Adaptation",
    "authors": [
      "Xuan Zhang",
      "Fengzhuo Zhang",
      "Cunxiao Du",
      "Chao Du",
      "Tianyu Pang",
      "Wei Gao",
      "Min Lin"
    ],
    "abstract": "Scaling language models to handle longer contexts introduces substantial\nmemory challenges due to the growing cost of key-value (KV) caches. Motivated\nby the efficiency gains of hybrid models and the broad availability of\npretrained large transformer backbones, we explore transitioning transformer\nmodels into hybrid architectures for a more efficient generation. In this work,\nwe propose LightTransfer, a lightweight method that transforms models such as\nLLaMA into hybrid variants. Our approach identifies lazy layers -- those\nfocusing on recent or initial tokens -- and replaces their full attention with\nstreaming attention. This transformation can be performed without any training\nfor long-context understanding tasks or with minimal fine-tuning for o1-like\nlong reasoning generation tasks that require stronger reasoning capabilities.\nExperiments across diverse benchmarks and models (e.g., LLaMA, Mistral,\nQwQ-STILL) demonstrate that, even when half of the layers are identified as\nlazy, LightTransfer achieves up to 2.17$\\times$ throughput improvement with\nminimal performance loss ($<1.5\\%$ on LongBench) and achieves 53.3\\% on math\nbenchmark AIME24 of advanced o1-like long reasoning model QwQ-STILL.",
    "pdf_url": "http://arxiv.org/pdf/2410.13846v2",
    "published": "2024-10-17T17:58:14+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13845v1",
    "title": "Effect of ozone sensitization on the reflection patterns and stabilization of standing detonation waves induced by curved ramps",
    "authors": [
      "Eric J. Ching",
      "Ryan F. Johnson"
    ],
    "abstract": "Standing detonation engines are a promising detonation-based propulsion\ntechnology. The most commonly studied standing detonation configuration\ninvolves a straight-sided wedge that induces an oblique detonation wave. A\nrecently introduced standing-detonation-engine concept entails a curved ramp\nthat leads to formation of a curved detonation wave. The continuous compression\nor expansion induced by the ramp curvature can have significant influence on\nthe flow characteristics and wave patterns of the detonation wave, offering\ngreater flexibility in engine design than conventional wedge geometries. This\nstudy aims to further explore this relatively new standing-detonation-engine\nconcept by examining the effect of ignition promoters, namely ozone, on the\nflow characteristics and reflection patterns of curved detonation waves induced\nby convex or concave ramps inside a confined combustion chamber. Simulations\nare performed using a positivity-preserving and entropy-bounded discontinuous\nGalerkin method with curved elements to exactly represent the ramp geometries.\nIn the context of wedge-induced oblique detonation waves, ozone addition has\nbeen found to decrease the initiation length and lead to a smoother\nshock-detonation transition. This can then attenuate the detonation and reduce\nstagnation-pressure losses, thus improving the potential propulsion\nperformance. In the context of detonation waves induced by curved ramps,\nalthough ozone addition similarly shortens the initiation zone, the curvature\nof the ramp introduces additional effects that can amplify or counteract both\nthe ozone-induced contraction of the initiation zone and the aforementioned\ndetonation attenuation. Furthermore, specific examples are presented wherein\nozone addition changes the type of reflection pattern (e.g., regular\nreflection, stationary Mach reflection, and non-stationary Mach reflection).",
    "pdf_url": "http://arxiv.org/pdf/2410.13845v1",
    "published": "2024-10-17T17:57:22+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2410.13844v2",
    "title": "Post-measurement Quantum Monte Carlo",
    "authors": [
      "Kriti Baweja",
      "David J. Luitz",
      "Samuel J. Garratt"
    ],
    "abstract": "We show how the effects of large numbers of measurements on many-body quantum\nground and thermal states can be studied using Quantum Monte Carlo (QMC).\nDensity matrices generated by measurement in this setting feature products of\nmany local nonunitary operators, and by expanding these density matrices as\nsums over operator strings we arrive at a generalized stochastic series\nexpansion (SSE). Our 'post-measurement SSE' is based on importance sampling of\noperator strings contributing to a measured thermal density matrix. We\ndemonstrate our algorithm by probing the effects of measurements on the\nspin-1/2 Heisenberg antiferromagnet on the square lattice. Thermal states of\nthis system have SU(2) symmetry, and at first we preserve this symmetry by\nmeasuring SU(2) symmetric observables. We identify classes of post-measurement\nstates for which correlations can be calculated efficiently, as well as states\nfor which SU(2) symmetric measurements generate a QMC sign problem when working\nin any site-local basis. For the first class, we show how deterministic loop\nupdates can be leveraged. Using our algorithm we demonstrate the creation of\nlong-range Bell pairs and symmetry-protected topological order, as well as the\nmeasurement-induced enhancement of antiferromagnetic correlations. We then\nstudy the effects of measuring the system in a basis where the standard\n(unmeasured) SSE is sign-free: For measurement schemes with this property, we\ncan calculate correlations in all post-measurement states without a sign\nproblem. The method developed in this work opens the door to scalable\nexperimental probes of measurement-induced collective phenomena, which require\nnumerical estimates for the effects of measurements.",
    "pdf_url": "http://arxiv.org/pdf/2410.13844v2",
    "published": "2024-10-17T17:57:11+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2410.13843v2",
    "title": "Particle creation from non-geodesic trajectories in multifield inflation",
    "authors": [
      "Nicolás Parra",
      "Spyros Sypsas",
      "Gonzalo A. Palma",
      "Cristóbal Zenteno"
    ],
    "abstract": "Particle production in de Sitter spacetime arises from the exponential\nexpansion of space, rendering the Bunch-Davies vacuum perceived as a\nparticle-containing state by late-time observers. For states defined as\neigenstates of both momentum and the Hamiltonian, the Bunch-Davies vacuum\nexhibits a constant particle density per physical momentum. We explore particle\nproduction beyond this baseline, focusing on deviations from exact de Sitter\nconditions and non-gravitational interactions, such as slow-roll inflation or\ninteractions arising from the coupling of inflation to other fields. Using\nBogoliubov transformations, we calculate the number density of energy/momentum\neigenstates. In single-field inflation, this density captures the observed\nspectral index of the primordial power spectrum, while in two-field models, it\nreflects the non-gravitational coupling driving background trajectory turning.\nWe present analytical results applicable to various scenarios involving\nparticle production from non-adiabatic processes during inflation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13843v2",
    "published": "2024-10-17T17:57:08+00:00",
    "categories": [
      "hep-th",
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13842v1",
    "title": "D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution Refinement",
    "authors": [
      "Yansong Peng",
      "Hebei Li",
      "Peixi Wu",
      "Yueyi Zhang",
      "Xiaoyan Sun",
      "Feng Wu"
    ],
    "abstract": "We introduce D-FINE, a powerful real-time object detector that achieves\noutstanding localization precision by redefining the bounding box regression\ntask in DETR models. D-FINE comprises two key components: Fine-grained\nDistribution Refinement (FDR) and Global Optimal Localization Self-Distillation\n(GO-LSD). FDR transforms the regression process from predicting fixed\ncoordinates to iteratively refining probability distributions, providing a\nfine-grained intermediate representation that significantly enhances\nlocalization accuracy. GO-LSD is a bidirectional optimization strategy that\ntransfers localization knowledge from refined distributions to shallower layers\nthrough self-distillation, while also simplifying the residual prediction tasks\nfor deeper layers. Additionally, D-FINE incorporates lightweight optimizations\nin computationally intensive modules and operations, achieving a better balance\nbetween speed and accuracy. Specifically, D-FINE-L / X achieves 54.0% / 55.8%\nAP on the COCO dataset at 124 / 78 FPS on an NVIDIA T4 GPU. When pretrained on\nObjects365, D-FINE-L / X attains 57.1% / 59.3% AP, surpassing all existing\nreal-time detectors. Furthermore, our method significantly enhances the\nperformance of a wide range of DETR models by up to 5.3% AP with negligible\nextra parameters and training costs. Our code and pretrained models:\nhttps://github.com/Peterande/D-FINE.",
    "pdf_url": "http://arxiv.org/pdf/2410.13842v1",
    "published": "2024-10-17T17:57:01+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13841v1",
    "title": "A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models",
    "authors": [
      "Qiaoyu Tang",
      "Le Yu",
      "Bowen Yu",
      "Hongyu Lin",
      "Keming Lu",
      "Yaojie Lu",
      "Xianpei Han",
      "Le Sun"
    ],
    "abstract": "Post-training has emerged as a crucial paradigm for adapting large-scale\npre-trained models to various tasks, whose effects are fully reflected by delta\nparameters (i.e., the disparity between post-trained and pre-trained\nparameters). While numerous studies have explored delta parameter properties\nvia operations like pruning, quantization, low-rank approximation, and\nextrapolation, a unified framework for systematically examining these\ncharacteristics has been lacking. In this paper, we propose a novel perspective\nbased on Riemann sum approximation of the loss function to elucidate delta\nparameter editing operations. Our analysis categorizes existing methods into\nthree classes based on their post-editing performance: competitive, decreased,\nand improved, explaining how they are expressed by the Riemann sum\napproximation term and how they alter the model performance. Extensive\nexperiments on both visual and language models, including ViT, LLaMA 3, Qwen 2,\nand Mistral, corroborate our theoretical findings. Furthermore, we introduce\nextensions to existing techniques like DARE and BitDelta, highlighting their\nlimitations in leveraging the properties of delta parameters and reorganizing\nthem into general expressions to enhance the applicability and effectiveness of\ndelta parameter editing in post-trained models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13841v1",
    "published": "2024-10-17T17:56:53+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13840v2",
    "title": "A Proof of the Tree Packing Conjecture",
    "authors": [
      "Parikshit Chalise",
      "Antwan Clark",
      "Edinah K. Gnang"
    ],
    "abstract": "We prove a conjecture of Gy\\'arf\\'as (1976), which asserts that any family of\ntrees $T_1, \\dots, T_{n}$ where each $T_k$ has $k$ vertices packs into $K_n$.\nWe do so by translating the decomposition problem into a labeling problem,\nnamely complete labeling. Our proof employs the polynomial method using a\nfunctional reformulation of the conjecture.",
    "pdf_url": "http://arxiv.org/pdf/2410.13840v2",
    "published": "2024-10-17T17:56:12+00:00",
    "categories": [
      "math.CO",
      "05C70, 05B30",
      "G.2.2"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13928v3",
    "title": "Automatically Interpreting Millions of Features in Large Language Models",
    "authors": [
      "Gonçalo Paulo",
      "Alex Mallen",
      "Caden Juang",
      "Nora Belrose"
    ],
    "abstract": "While the activations of neurons in deep neural networks usually do not have\na simple human-understandable interpretation, sparse autoencoders (SAEs) can be\nused to transform these activations into a higher-dimensional latent space\nwhich may be more easily interpretable. However, these SAEs can have millions\nof distinct latent features, making it infeasible for humans to manually\ninterpret each one. In this work, we build an open-source automated pipeline to\ngenerate and evaluate natural language explanations for SAE features using\nLLMs. We test our framework on SAEs of varying sizes, activation functions, and\nlosses, trained on two different open-weight LLMs. We introduce five new\ntechniques to score the quality of explanations that are cheaper to run than\nthe previous state of the art. One of these techniques, intervention scoring,\nevaluates the interpretability of the effects of intervening on a feature,\nwhich we find explains features that are not recalled by existing methods. We\npropose guidelines for generating better explanations that remain valid for a\nbroader set of activating contexts, and discuss pitfalls with existing scoring\ntechniques. We use our explanations to measure the semantic similarity of\nindependently trained SAEs, and find that SAEs trained on nearby layers of the\nresidual stream are highly similar. Our large-scale analysis confirms that SAE\nlatents are indeed much more interpretable than neurons, even when neurons are\nsparsified using top-$k$ postprocessing. Our code is available at\nhttps://github.com/EleutherAI/sae-auto-interp, and our explanations are\navailable at\nhttps://huggingface.co/datasets/EleutherAI/auto_interp_explanations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13928v3",
    "published": "2024-10-17T17:56:01+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13839v1",
    "title": "Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding",
    "authors": [
      "Tan Dat Nguyen",
      "Ji-Hoon Kim",
      "Jeongsoo Choi",
      "Shukjae Choi",
      "Jinseok Park",
      "Younglo Lee",
      "Joon Son Chung"
    ],
    "abstract": "The goal of this paper is to accelerate codec-based speech synthesis systems\nwith minimum sacrifice to speech quality. We propose an enhanced inference\nmethod that allows for flexible trade-offs between speed and quality during\ninference without requiring additional training. Our core idea is to predict\nmultiple tokens per inference step of the AR module using multiple prediction\nheads, resulting in a linear reduction in synthesis time as the number of heads\nincreases. Furthermore, we introduce a novel speculative decoding technique\nthat utilises a Viterbi-based algorithm to select the optimal sequence of\ngenerated tokens at each decoding step. In our experiments, we demonstrate that\nthe time required to predict each token is reduced by a factor of 4 to 5\ncompared to baseline models, with minimal quality trade-off or even improvement\nin terms of speech intelligibility. Audio samples are available at:\nmultpletokensprediction.github.io/multipletokensprediction.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2410.13839v1",
    "published": "2024-10-17T17:55:26+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13838v1",
    "title": "A 1.2 mm$^2$ 416 mW 1.44 Mmat/s 64$\\times$16 Matrix Preprocessing ASIC for Massive MIMO in 22FDX",
    "authors": [
      "Darja Nonaca",
      "Christoph Studer"
    ],
    "abstract": "Massive multiuser (MU) multiple-input multiple-output (MIMO) enables\nconcurrent transmission of multiple users to a multi-antenna basestation (BS).\nTo detect the users' data using linear equalization, the BS must perform\npreprocessing, which requires, among other tasks, the inversion of a matrix\nwhose dimension equals the number of user data streams. Explicit inversion of\nlarge matrices is notoriously difficult to implement due to high complexity,\nstringent data dependencies that lead to high latency, and high numerical\nprecision requirements. We propose a novel preprocessing architecture based on\nthe block-LDL matrix factorization, which improves parallelism and, hence,\nreduces latency. We demonstrate the effectiveness of our architecture through\n(i) massive MU-MIMO system simulations with mmWave channel vectors and (ii)\nmeasurements of a 22FDX ASIC, which is, to our knowledge, the first fabricated\npreprocessing engine for massive MU-MIMO with 64 BS antennas and 16\nsingle-antenna users. Our ASIC reaches a clock frequency of 870 MHz while\nconsuming 416 mW. At its peak throughput, the ASIC preprocesses 1.44 M\n64$\\times$16 matrices per second at a latency of only 0.7 $\\mu$s.",
    "pdf_url": "http://arxiv.org/pdf/2410.13838v1",
    "published": "2024-10-17T17:55:09+00:00",
    "categories": [
      "eess.SP",
      "cs.AR"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13837v3",
    "title": "ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization",
    "authors": [
      "Chen Bo Calvin Zhang",
      "Zhang-Wei Hong",
      "Aldo Pacchiano",
      "Pulkit Agrawal"
    ],
    "abstract": "Reward shaping is critical in reinforcement learning (RL), particularly for\ncomplex tasks where sparse rewards can hinder learning. However, choosing\neffective shaping rewards from a set of reward functions in a computationally\nefficient manner remains an open challenge. We propose Online Reward Selection\nand Policy Optimization (ORSO), a novel approach that frames the selection of\nshaping reward function as an online model selection problem. ORSO\nautomatically identifies performant shaping reward functions without human\nintervention with provable regret guarantees. We demonstrate ORSO's\neffectiveness across various continuous control tasks. Compared to prior\napproaches, ORSO significantly reduces the amount of data required to evaluate\na shaping reward function, resulting in superior data efficiency and a\nsignificant reduction in computational time (up to 8 times). ORSO consistently\nidentifies high-quality reward functions outperforming prior methods by more\nthan 50% and on average identifies policies as performant as the ones learned\nusing manually engineered reward functions by domain experts.",
    "pdf_url": "http://arxiv.org/pdf/2410.13837v3",
    "published": "2024-10-17T17:55:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13836v1",
    "title": "Axiomatization of Compact Initial Value Problems: Open Properties",
    "authors": [
      "André Platzer",
      "Long Qian"
    ],
    "abstract": "This article proves the completeness of an axiomatization for initial value\nproblems (IVPs) with compact initial conditions and compact time horizons for\nbounded open safety, open liveness and existence properties. Completeness\nsystematically reduces the proofs of these properties to a complete\naxiomatization for differential equation invariants. This result unifies\nsymbolic logic and numerical analysis by a computable procedure that generates\nsymbolic proofs with differential invariants for rigorous error bounds of\nnumerical solutions to polynomial initial value problems. The procedure is\nmodular and works for all polynomial IVPs with rational coefficients and\ninitial conditions and symbolic parameters constrained to compact sets.\nFurthermore, this paper discusses generalizations to IVPs with initial\nconditions/symbolic parameters that are not necessarily constrained to compact\nsets, achieved through the derivation of fully symbolic axioms/proof-rules\nbased on the axiomatization.",
    "pdf_url": "http://arxiv.org/pdf/2410.13836v1",
    "published": "2024-10-17T17:54:30+00:00",
    "categories": [
      "cs.LO",
      "cs.PL",
      "math.LO",
      "03B70, 03D80, 03F03, 34C14, 34A38, 34C11, 65L70, 65G20",
      "F.4.1; F.3.1; G.1.7; I.2.3"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13835v2",
    "title": "Active-Dormant Attention Heads: Mechanistically Demystifying Extreme-Token Phenomena in LLMs",
    "authors": [
      "Tianyu Guo",
      "Druv Pai",
      "Yu Bai",
      "Jiantao Jiao",
      "Michael I. Jordan",
      "Song Mei"
    ],
    "abstract": "Practitioners have consistently observed three puzzling phenomena in\ntransformer-based large language models (LLMs): attention sinks, value-state\ndrains, and residual-state peaks, collectively referred to as extreme-token\nphenomena. These phenomena are characterized by certain so-called \"sink tokens\"\nreceiving disproportionately high attention weights, exhibiting significantly\nsmaller value states, and having much larger residual-state norms than those of\nother tokens. These extreme tokens give rise to various challenges in LLM\ninference, quantization, and interpretability.\n  We elucidate the mechanisms behind extreme-token phenomena. First, we show\nthat these phenomena arise in very simple architectures -- transformers with\none to three layers -- trained on a toy model, the Bigram-Backcopy (BB) task.\nIn this setting, we identify an active-dormant mechanism, where attention heads\nbecome sinks for specific input domains while remaining non-sinks for others.\nOur theoretical analysis of the training dynamics reveals that these phenomena\nare driven by a mutual reinforcement mechanism. Building on these insights, we\npropose strategies to mitigate extreme-token phenomena during pretraining,\nincluding replacing softmax with ReLU and Adam with SGD. Next, we extend our\nanalysis to pretrained LLMs, including Llama and OLMo, showing that many\nattention heads exhibit a similar active-dormant mechanism as in the BB task,\nand that the mutual reinforcement mechanism also governs the emergence of\nextreme-token phenomena during LLM pretraining. Our results reveal that many of\nthe static and dynamic properties of extreme-token phenomena predicted by the\nBB task align with observations in pretrained LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13835v2",
    "published": "2024-10-17T17:54:06+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13834v1",
    "title": "Intersections of branching random walks on $\\mathbb{Z}^8$",
    "authors": [
      "Zsuzsanna Baran"
    ],
    "abstract": "We consider random walks on $\\mathbb{Z}^8$ indexed by the infinite invariant\ntree, which consists of an infinite spine and finite random trees attached to\nit on both sides. We establish the precise order of the non-intersection\nprobability between one walk indexed by one side of the tree, and an\nindependent one indexed by both sides of an independent tree. This is analogous\nto the result by Lawler from the '90s for two independent simple random walks\non $\\mathbb{Z}^4$. We also prove a weak law of large numbers for the branching\ncapacity of the range of a branching random walk.",
    "pdf_url": "http://arxiv.org/pdf/2410.13834v1",
    "published": "2024-10-17T17:53:36+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13833v1",
    "title": "Analyzing Atomic Interactions in Molecules as Learned by Neural Networks",
    "authors": [
      "Malte Esders",
      "Thomas Schnake",
      "Jonas Lederer",
      "Adil Kabylda",
      "Grégoire Montavon",
      "Alexandre Tkatchenko",
      "Klaus-Robert Müller"
    ],
    "abstract": "While machine learning (ML) models have been able to achieve unprecedented\naccuracies across various prediction tasks in quantum chemistry, it is now\napparent that accuracy on a test set alone is not a guarantee for robust\nchemical modeling such as stable molecular dynamics (MD). To go beyond\naccuracy, we use explainable artificial intelligence (XAI) techniques to\ndevelop a general analysis framework for atomic interactions and apply it to\nthe SchNet and PaiNN neural network models. We compare these interactions with\na set of fundamental chemical principles to understand how well the models have\nlearned the underlying physicochemical concepts from the data. We focus on the\nstrength of the interactions for different atomic species, how predictions for\nintensive and extensive quantum molecular properties are made, and analyze the\ndecay and many-body nature of the interactions with interatomic distance.\nModels that deviate too far from known physical principles produce unstable MD\ntrajectories, even when they have very high energy and force prediction\naccuracy. We also suggest further improvements to the ML architectures to\nbetter account for the polynomial decay of atomic interactions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13833v1",
    "published": "2024-10-17T17:53:31+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13832v2",
    "title": "VidPanos: Generative Panoramic Videos from Casual Panning Videos",
    "authors": [
      "Jingwei Ma",
      "Erika Lu",
      "Roni Paiss",
      "Shiran Zada",
      "Aleksander Holynski",
      "Tali Dekel",
      "Brian Curless",
      "Michael Rubinstein",
      "Forrester Cole"
    ],
    "abstract": "Panoramic image stitching provides a unified, wide-angle view of a scene that\nextends beyond the camera's field of view. Stitching frames of a panning video\ninto a panoramic photograph is a well-understood problem for stationary scenes,\nbut when objects are moving, a still panorama cannot capture the scene. We\npresent a method for synthesizing a panoramic video from a casually-captured\npanning video, as if the original video were captured with a wide-angle camera.\nWe pose panorama synthesis as a space-time outpainting problem, where we aim to\ncreate a full panoramic video of the same length as the input video. Consistent\ncompletion of the space-time volume requires a powerful, realistic prior over\nvideo content and motion, for which we adapt generative video models. Existing\ngenerative models do not, however, immediately extend to panorama completion,\nas we show. We instead apply video generation as a component of our panorama\nsynthesis system, and demonstrate how to exploit the strengths of the models\nwhile minimizing their limitations. Our system can create video panoramas for a\nrange of in-the-wild scenes including people, vehicles, and flowing water, as\nwell as stationary background features.",
    "pdf_url": "http://arxiv.org/pdf/2410.13832v2",
    "published": "2024-10-17T17:53:24+00:00",
    "categories": [
      "cs.CV",
      "cs.GR",
      "I.3.3; I.4"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13831v2",
    "title": "The Disparate Benefits of Deep Ensembles",
    "authors": [
      "Kajetan Schweighofer",
      "Adrian Arnaiz-Rodriguez",
      "Sepp Hochreiter",
      "Nuria Oliver"
    ],
    "abstract": "Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a\nsimple way to boost predictive performance. However, their impact on\nalgorithmic fairness is not well understood yet. Algorithmic fairness examines\nhow a model's performance varies across socially relevant groups defined by\nprotected attributes such as age, gender, or race. In this work, we explore the\ninterplay between the performance gains from Deep Ensembles and fairness. Our\nanalysis reveals that they unevenly favor different groups, a phenomenon that\nwe term the disparate benefits effect. We empirically investigate this effect\nusing popular facial analysis and medical imaging datasets with protected group\nattributes and find that it affects multiple established group fairness\nmetrics, including statistical parity and equal opportunity. Furthermore, we\nidentify that the per-group differences in predictive diversity of ensemble\nmembers can explain this effect. Finally, we demonstrate that the classical\nHardt post-processing method is particularly effective at mitigating the\ndisparate benefits effect of Deep Ensembles by leveraging their\nbetter-calibrated predictive distributions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13831v2",
    "published": "2024-10-17T17:53:01+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13830v1",
    "title": "DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control",
    "authors": [
      "Yujie Wei",
      "Shiwei Zhang",
      "Hangjie Yuan",
      "Xiang Wang",
      "Haonan Qiu",
      "Rui Zhao",
      "Yutong Feng",
      "Feng Liu",
      "Zhizhong Huang",
      "Jiaxin Ye",
      "Yingya Zhang",
      "Hongming Shan"
    ],
    "abstract": "Recent advances in customized video generation have enabled users to create\nvideos tailored to both specific subjects and motion trajectories. However,\nexisting methods often require complicated test-time fine-tuning and struggle\nwith balancing subject learning and motion control, limiting their real-world\napplications. In this paper, we present DreamVideo-2, a zero-shot video\ncustomization framework capable of generating videos with a specific subject\nand motion trajectory, guided by a single image and a bounding box sequence,\nrespectively, and without the need for test-time fine-tuning. Specifically, we\nintroduce reference attention, which leverages the model's inherent\ncapabilities for subject learning, and devise a mask-guided motion module to\nachieve precise motion control by fully utilizing the robust motion signal of\nbox masks derived from bounding boxes. While these two components achieve their\nintended functions, we empirically observe that motion control tends to\ndominate over subject learning. To address this, we propose two key designs: 1)\nthe masked reference attention, which integrates a blended latent mask modeling\nscheme into reference attention to enhance subject representations at the\ndesired positions, and 2) a reweighted diffusion loss, which differentiates the\ncontributions of regions inside and outside the bounding boxes to ensure a\nbalance between subject and motion control. Extensive experimental results on a\nnewly curated dataset demonstrate that DreamVideo-2 outperforms\nstate-of-the-art methods in both subject customization and motion control. The\ndataset, code, and models will be made publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2410.13830v1",
    "published": "2024-10-17T17:52:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13829v2",
    "title": "CNN-Based Vortex Detection in Atomic 2D Bose Gases in the Presence of a Phononic Background",
    "authors": [
      "Magnus Sesodia",
      "Shinichi Sunami",
      "En Chang",
      "Erik Rydow",
      "Christopher J. Foot",
      "Abel Beregi"
    ],
    "abstract": "Quantum vortices play a crucial role in both equilibrium and dynamical\nphenomena in two-dimensional (2D) superfluid systems. Experimental detection of\nthese excitations in 2D ultracold atomic gases typically involves examining\ndensity depletions in absorption images, however the presence of a significant\nphononic background renders the problem challenging, beyond the capability of\nsimple algorithms or the human eye. Here, we utilize a convolutional neural\nnetwork (CNN) to detect vortices in the presence of strong long- and\nintermediate-length scale density modulations in finite-temperature 2D Bose\ngases. We train the model on datasets obtained from ab initio Monte Carlo\nsimulations using the classical-field method for density and phase\nfluctuations, and Gross-Pitaevskii simulation of realistic expansion dynamics.\nWe use the model to analyze experimental images and benchmark its performance\nby comparing the results to the matter-wave interferometric detection of\nvortices, confirming the observed scaling of vortex density across the\nBerezinskii-Kosterlitz-Thouless (BKT) critical point. The combination of a\nrelevant simulation pipeline with machine-learning methods is a key development\ntowards the comprehensive understanding of complex vortex-phonon dynamics in\nout-of-equilibrium 2D quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13829v2",
    "published": "2024-10-17T17:52:51+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "physics.atom-ph",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2410.13828v2",
    "title": "A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement",
    "authors": [
      "Hui Yuan",
      "Yifan Zeng",
      "Yue Wu",
      "Huazheng Wang",
      "Mengdi Wang",
      "Liu Leqi"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become the predominant\napproach for language model (LM) alignment. At its core, RLHF uses a\nmargin-based loss for preference optimization, specifying ideal LM behavior\nonly by the difference between preferred and dispreferred responses. In this\npaper, we identify a common pitfall of margin-based methods -- the\nunder-specification of ideal LM behavior on preferred and dispreferred\nresponses individually, which leads to two unintended consequences as the\nmargin increases: (1) The probability of dispreferred (e.g., unsafe) responses\nmay increase, resulting in potential safety alignment failures. (2) The\nprobability of preferred responses may decrease, even when those responses are\nideal. We demystify the reasons behind these problematic behaviors:\nmargin-based losses couple the change in the preferred probability to the\ngradient of the dispreferred one, and vice versa, often preventing the\npreferred probability from increasing while the dispreferred one decreases, and\nthus causing a synchronized increase or decrease in both probabilities. We term\nthis effect, inherent in margin-based objectives, gradient entanglement.\nFormally, we derive conditions for general margin-based alignment objectives\nunder which gradient entanglement becomes concerning: the inner product of the\ngradients of preferred and dispreferred log-probabilities is large relative to\nthe individual gradient norms. We theoretically investigate why such inner\nproducts can be large when aligning language models and empirically validate\nour findings. Empirical implications of our framework extend to explaining\nimportant differences in the training dynamics of various preference\noptimization algorithms, and suggesting potential algorithm designs to mitigate\nthe under-specification issue of margin-based methods and thereby improving\nlanguage model alignment.",
    "pdf_url": "http://arxiv.org/pdf/2410.13828v2",
    "published": "2024-10-17T17:52:01+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.18128v1",
    "title": "Applications of Computational Topology to Fusion Science",
    "authors": [
      "Nicholas Bohlsen"
    ],
    "abstract": "Three novel applications of computational topology in the field of fusion\nscience are developed. A procedure for the automatic classification of the\norbits of magnetic field lines into topologically distinct classes using\nVietoris-Rips persistent homology is presented and tested for a toy model of a\nperturbed tokamak. A method for estimating the distribution of the size of\nislands in the phase space of a Hamiltonian system or area-preserving map by\nsub-level set persistent homology is explored. This method is used to analyse\nthe case of an accelerator mode island in the phase space of Chirikov's\nstandard map and the possibility of detecting the self-similar island hierarchy\nresponsible for anomalous transport in this model is investigated. Finally, it\nis suggested that TDA provides a toolset for the detection and characterisation\nof renormalisation group transformations which leave structures in Hamiltonian\nphase spaces invariant. The specific example of detecting the transform which\nleaves the neighborhood of a hyperbolic fixed point of the perturbed pendulum\ninvariant is investigated using two different TDA approaches. Both of which are\nfound to be partially sensitive to the symmetry in question but only weakly.",
    "pdf_url": "http://arxiv.org/pdf/2410.18128v1",
    "published": "2024-10-17T17:51:53+00:00",
    "categories": [
      "physics.plasm-ph",
      "55N31 (Primary) 70H07 (Secondary)"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13827v1",
    "title": "Towards a Factor Graph-Based Method using Angular Rates for Full Magnetometer Calibration and Gyroscope Bias Estimation",
    "authors": [
      "Sebastián Rodríguez-Martínez",
      "Giancarlo Troni"
    ],
    "abstract": "MEMS Attitude Heading Reference Systems are widely employed to determine a\nsystem's attitude, but sensor measurement biases limit their accuracy. This\npaper introduces a novel factor graph-based method called MAgnetometer and\nGYroscope Calibration (MAGYC). MAGYC leverages three-axis angular rate\nmeasurements from an angular rate gyroscope to enhance calibration for batch\nand online applications. Our approach imposes less restrictive conditions for\ninstrument movements required for calibration, eliminates the need for\nknowledge of the local magnetic field or instrument attitude, and facilitates\nintegration into factor graph algorithms within Smoothing and Mapping\nframeworks. We evaluate the proposed methods through numerical simulations and\nin-field experimental assessments using a sensor installed on an underwater\nvehicle. Ultimately, our proposed methods reduced the underwater vehicle's\nheading error standard deviation from 6.21 to 0.57 degrees for a standard\nseafloor mapping survey.",
    "pdf_url": "http://arxiv.org/pdf/2410.13827v1",
    "published": "2024-10-17T17:51:51+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13826v2",
    "title": "Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models",
    "authors": [
      "Mazda Moayeri",
      "Vidhisha Balachandran",
      "Varun Chandrasekaran",
      "Safoora Yousefi",
      "Thomas Fel",
      "Soheil Feizi",
      "Besmira Nushi",
      "Neel Joshi",
      "Vibhav Vineet"
    ],
    "abstract": "With models getting stronger, evaluations have grown more complex, testing\nmultiple skills in one benchmark and even in the same instance at once.\nHowever, skill-wise performance is obscured when inspecting aggregate accuracy,\nunder-utilizing the rich signal modern benchmarks contain. We propose an\nautomatic approach to recover the underlying skills relevant for any evaluation\ninstance, by way of inspecting model-generated rationales. After validating the\nrelevance of rationale-parsed skills and inferring skills for $46$k instances\nover $12$ benchmarks, we observe many skills to be common across benchmarks,\nresulting in the curation of hundreds of skill-slices (i.e. sets of instances\ntesting a common skill). Inspecting accuracy over these slices yields novel\ninsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,\non average, Gemini 1.5 Pro is $18\\%$ more accurate in \"computing molar mass\",\nbut $19\\%$ less accurate in \"applying constitutional law\", despite the overall\naccuracies of the three models differing by a mere $0.4\\%$. Furthermore, we\ndemonstrate the practical utility of our approach by showing that insights\nderived from skill slice analysis can generalize to held-out instances: when\nrouting each instance to the model strongest on the relevant skills, we see a\n$3\\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and\nframework open a new avenue in model evaluation, leveraging skill-specific\nanalyses to unlock a more granular and actionable understanding of model\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2410.13826v2",
    "published": "2024-10-17T17:51:40+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13825v2",
    "title": "AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents",
    "authors": [
      "Ke Yang",
      "Yao Liu",
      "Sapana Chaudhary",
      "Rasool Fakoor",
      "Pratik Chaudhari",
      "George Karypis",
      "Huzefa Rangwala"
    ],
    "abstract": "Autonomy via agents using large language models (LLMs) for personalized,\nstandardized tasks boosts human efficiency. Automating web tasks (like booking\nhotels within a budget) is increasingly sought after. Fulfilling practical\nneeds, the web agent also serves as an important proof-of-concept example for\nvarious agent grounding scenarios, with its success promising advancements in\nmany future applications. Prior research often handcrafts web agent strategies\n(e.g., prompting templates, multi-agent systems, search methods, etc.) and the\ncorresponding in-context examples, which may not generalize well across all\nreal-world scenarios. On the other hand, there has been limited study on the\nmisalignment between a web agent's observation/action representation and the\npre-training data of the LLM it's based on. This discrepancy is especially\nnotable when LLMs are primarily trained for language completion rather than\ntasks involving embodied navigation actions and symbolic web elements. Our\nstudy enhances an LLM-based web agent by simply refining its observation and\naction space to better align with the LLM's capabilities. This approach enables\nour base agent to significantly outperform previous methods on a wide variety\nof web tasks. Specifically, on WebArena, a benchmark featuring general-purpose\nweb interaction tasks, our agent AgentOccam surpasses the previous\nstate-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute\npoints respectively, and boosts the success rate by 26.6 points (+161%) over\nsimilar plain web agents with its observation and action space alignment. We\nachieve this without using in-context examples, new agent roles, online\nfeedback or search strategies. AgentOccam's simple design highlights LLMs'\nimpressive zero-shot performance on web tasks, and underlines the critical role\nof carefully tuning observation and action spaces for LLM-based agents.",
    "pdf_url": "http://arxiv.org/pdf/2410.13825v2",
    "published": "2024-10-17T17:50:38+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13824v3",
    "title": "Harnessing Webpage UIs for Text-Rich Visual Understanding",
    "authors": [
      "Junpeng Liu",
      "Tianyue Ou",
      "Yifan Song",
      "Yuxiao Qu",
      "Wai Lam",
      "Chenyan Xiong",
      "Wenhu Chen",
      "Graham Neubig",
      "Xiang Yue"
    ],
    "abstract": "Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48% improvement on\nVisualWebBench and a 19.1% boost in element accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2410.13824v3",
    "published": "2024-10-17T17:48:54+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13823v1",
    "title": "Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning",
    "authors": [
      "Xiaodan Xing",
      "Junzhi Ning",
      "Yang Nan",
      "Guang Yang"
    ],
    "abstract": "Deep generative models have significantly advanced medical imaging analysis\nby enhancing dataset size and quality. Beyond mere data augmentation, our\nresearch in this paper highlights an additional, significant capacity of deep\ngenerative models: their ability to reveal and demonstrate patterns in medical\nimages. We employ a generative structure with hybrid conditions, combining\nclinical data and segmentation masks to guide the image synthesis process.\nFurthermore, we innovatively transformed the tabular clinical data into textual\ndescriptions. This approach simplifies the handling of missing values and also\nenables us to leverage large pre-trained vision-language models that\ninvestigate the relations between independent clinical entries and comprehend\ngeneral terms, such as gender and smoking status. Our approach differs from and\npresents a more challenging task than traditional medical report-guided\nsynthesis due to the less visual correlation of our clinical information with\nthe images. To overcome this, we introduce a text-visual embedding mechanism\nthat strengthens the conditions, ensuring the network effectively utilizes the\nprovided information. Our pipeline is generalizable to both GAN-based and\ndiffusion models. Experiments on chest CT, particularly focusing on the smoking\nstatus, demonstrated a consistent intensity shift in the lungs which is in\nagreement with clinical observations, indicating the effectiveness of our\nmethod in capturing and visualizing the impact of specific attributes on\nmedical image patterns. Our methods offer a new avenue for the early detection\nand precise visualization of complex clinical conditions with deep generative\nmodels. All codes are https://github.com/junzhin/DGM-VLC.",
    "pdf_url": "http://arxiv.org/pdf/2410.13823v1",
    "published": "2024-10-17T17:48:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13822v1",
    "title": "Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks",
    "authors": [
      "Clément Playout",
      "Renaud Duval",
      "Marie Carole Boucher",
      "Farida Cheriet"
    ],
    "abstract": "The diagnosis of diabetic retinopathy, which relies on fundus images, faces\nchallenges in achieving transparency and interpretability when using a global\nclassification approach. However, segmentation-based databases are\nsignificantly more expensive to acquire and combining them is often\nproblematic. This paper introduces a novel method, termed adversarial style\nconversion, to address the lack of standardization in annotation styles across\ndiverse databases. By training a single architecture on combined databases, the\nmodel spontaneously modifies its segmentation style depending on the input,\ndemonstrating the ability to convert among different labeling styles. The\nproposed methodology adds a linear probe to detect dataset origin based on\nencoder features and employs adversarial attacks to condition the model's\nsegmentation style. Results indicate significant qualitative and quantitative\nthrough dataset combination, offering avenues for improved model\ngeneralization, uncertainty estimation and continuous interpolation between\nannotation styles. Our approach enables training a segmentation model with\ndiverse databases while controlling and leveraging annotation styles for\nimproved retinopathy diagnosis.",
    "pdf_url": "http://arxiv.org/pdf/2410.13822v1",
    "published": "2024-10-17T17:48:17+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13821v3",
    "title": "Artificial Kuramoto Oscillatory Neurons",
    "authors": [
      "Takeru Miyato",
      "Sindy Löwe",
      "Andreas Geiger",
      "Max Welling"
    ],
    "abstract": "It has long been known in both neuroscience and AI that ``binding'' between\nneurons leads to a form of competitive learning where representations are\ncompressed in order to represent more abstract concepts in deeper layers of the\nnetwork. More recently, it was also hypothesized that dynamic (spatiotemporal)\nrepresentations play an important role in both neuroscience and AI. Building on\nthese ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as a\ndynamical alternative to threshold units, which can be combined with arbitrary\nconnectivity designs such as fully connected, convolutional, or attentive\nmechanisms. Our generalized Kuramoto updates bind neurons together through\ntheir synchronization dynamics. We show that this idea provides performance\nimprovements across a wide spectrum of tasks such as unsupervised object\ndiscovery, adversarial robustness, calibrated uncertainty quantification, and\nreasoning. We believe that these empirical results show the importance of\nrethinking our assumptions at the most basic neuronal level of neural\nrepresentation, and in particular show the importance of dynamical\nrepresentations. Code:https://github.com/autonomousvision/akorn Project\npage:https://takerum.github.io/akorn_project_page/",
    "pdf_url": "http://arxiv.org/pdf/2410.13821v3",
    "published": "2024-10-17T17:47:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13820v1",
    "title": "Enhancing universal machine learning potentials with polarizable long-range interactions",
    "authors": [
      "Rongzhi Gao",
      "ChiYung Yam",
      "Jianjun Mao",
      "Shuguang Chen",
      "GuanHua Chen",
      "Ziyang Hu"
    ],
    "abstract": "Long-range interactions are crucial in determining the behavior of chemical\nsystems in various environments. Accurate predictions of physical and chemical\nphenomena at the atomic level hinge on accurate modeling of these interactions.\nHere, we present a framework that substantially enhances the predictive power\nof machine learning interatomic potentials by incorporating explicit\npolarizable long-range interactions with an equivariant graph neural network\nshort-range potential. The pretrained universal model, applicable across the\nentire periodic table, can achieve first-principles accuracy. This versatile\nmodel has been further applied to diverse areas of research, including the\nstudy of mechanical properties, ionic diffusivity in solid-state electrolytes,\nferroelectricity, and interfacial reactions, demonstrating its broad\napplicability and robustness.",
    "pdf_url": "http://arxiv.org/pdf/2410.13820v1",
    "published": "2024-10-17T17:47:39+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13819v1",
    "title": "Moderate Physical Perspectivalism",
    "authors": [
      "Emily Adlam"
    ],
    "abstract": "Recent developments in foundations of physics have given rise to a class of\nviews suggesting that physically meaningful descriptions must always be\nrelativized to a physical perspective. In this article I distinguish between\nstrong physical perspectivalism, which maintains that all facts must be\nrelativized to a perspective, and moderate physical perspectivalism, which\nmaintains that all empirically meaningful descriptions must be relativized to a\nperspective. I argue that both scientific evidence and philosophical\nconsiderations support moderate physical perspectivalism over strong physical\nperspectivalism. In particular, motivations connected to epistemic humility and\nthe social nature of science are more compatible with the moderate approach.",
    "pdf_url": "http://arxiv.org/pdf/2410.13819v1",
    "published": "2024-10-17T17:47:14+00:00",
    "categories": [
      "physics.hist-ph"
    ],
    "primary_category": "physics.hist-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13818v2",
    "title": "Hardy's Uncertainty principle for Schrödinger equations with quadratic Hamiltonians",
    "authors": [
      "Elena Cordero",
      "Gianluca Giacchi",
      "Eugenia Malinnikova"
    ],
    "abstract": "Hardy's uncertainty principle is a classical result in harmonic analysis,\nstating that a function in $L^2(\\mathbb{R}^d)$ and its Fourier transform cannot\nboth decay arbitrarily fast at infinity. In this paper, we extend this\nprinciple to the propagators of Schr\\\"odinger equations with quadratic\nHamiltonians, known in the literature as metaplectic operators. These operators\ngeneralize the Fourier transform and have captured significant attention in\nrecent years due to their wide-ranging applications in time-frequency analysis,\nquantum harmonic analysis, signal processing, and various other fields.\nHowever, the involved structure of these operators requires careful analysis,\nand most results obtained so far concern special propagators that can basically\nbe reduced to rescaled Fourier transforms. The main contributions of this work\nare threefold: (1) we extend Hardy's uncertainty principle, covering all\npropagators of Schr\\\"odinger equations with quadratic Hamiltonians, (2) we\nprovide concrete examples, such as fractional Fourier transforms, which arise\nwhen considering anisotropic harmonic oscillators, (3) we suggest Gaussian\ndecay conditions in certain directions only, which are related to the structure\nof the corresponding symplectic projection.",
    "pdf_url": "http://arxiv.org/pdf/2410.13818v2",
    "published": "2024-10-17T17:47:08+00:00",
    "categories": [
      "math.AP",
      "42A38, 35S30, 35B05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13817v1",
    "title": "Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation",
    "authors": [
      "Jean-Pierre Sleiman",
      "Mayank Mittal",
      "Marco Hutter"
    ],
    "abstract": "Reinforcement learning (RL) often necessitates a meticulous Markov Decision\nProcess (MDP) design tailored to each task. This work aims to address this\nchallenge by proposing a systematic approach to behavior synthesis and control\nfor multi-contact loco-manipulation tasks, such as navigating spring-loaded\ndoors and manipulating heavy dishwashers. We define a task-independent MDP to\ntrain RL policies using only a single demonstration per task generated from a\nmodel-based trajectory optimizer. Our approach incorporates an adaptive phase\ndynamics formulation to robustly track the demonstrations while accommodating\ndynamic uncertainties and external disturbances. We compare our method against\nprior motion imitation RL works and show that the learned policies achieve\nhigher success rates across all considered tasks. These policies learn recovery\nmaneuvers that are not present in the demonstration, such as re-grasping\nobjects during execution or dealing with slippages. Finally, we successfully\ntransfer the policies to a real robot, demonstrating the practical viability of\nour approach.",
    "pdf_url": "http://arxiv.org/pdf/2410.13817v1",
    "published": "2024-10-17T17:46:27+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13816v2",
    "title": "Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance",
    "authors": [
      "Mitsuhiko Nakamoto",
      "Oier Mees",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "abstract": "Large, general-purpose robotic policies trained on diverse demonstration\ndatasets have been shown to be remarkably effective both for controlling a\nvariety of robots in a range of different scenes, and for acquiring broad\nrepertoires of manipulation skills. However, the data that such policies are\ntrained on is generally of mixed quality -- not only are human-collected\ndemonstrations unlikely to perform the task perfectly, but the larger the\ndataset is, the harder it is to curate only the highest quality examples. It\nalso remains unclear how optimal data from one embodiment is for training on\nanother embodiment. In this paper, we present a general and broadly applicable\napproach that enhances the performance of such generalist robot policies at\ndeployment time by re-ranking their actions according to a value function\nlearned via offline RL. This approach, which we call Value-Guided Policy\nSteering (V-GPS), is compatible with a wide range of different generalist\npolicies, without needing to fine-tune or even access the weights of the\npolicy. We show that the same value function can improve the performance of\nfive different state-of-the-art policies with different architectures, even\nthough they were trained on distinct datasets, attaining consistent performance\nimprovement on multiple robotic platforms across a total of 12 tasks. Code and\nvideos can be found at: https://nakamotoo.github.io/V-GPS",
    "pdf_url": "http://arxiv.org/pdf/2410.13816v2",
    "published": "2024-10-17T17:46:26+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13815v1",
    "title": "Observation of string-breaking dynamics in a quantum simulator",
    "authors": [
      "Arinjoy De",
      "Alessio Lerose",
      "De Luo",
      "Federica M. Surace",
      "Alexander Schuckert",
      "Elizabeth R. Bennewitz",
      "Brayden Ware",
      "William Morong",
      "Kate S. Collins",
      "Zohreh Davoudi",
      "Alexey V. Gorshkov",
      "Or Katz",
      "Christopher Monroe"
    ],
    "abstract": "Spontaneous particle-pair formation is a fundamental phenomenon in nature. It\ncan, for example, appear when the potential energy between two particles\nincreases with separation, as if they were connected by a tense string. Beyond\na critical separation, new particle pairs can form, causing the string to\nbreak. String-breaking dynamics in quantum chromodynamics play a vital role in\nhigh-energy particle collisions and early universe evolution. Simulating string\nevolution and hadron formation is, therefore, a grand challenge in modern\nphysics. Quantum simulators, well-suited for studying dynamics, are expected to\noutperform classical computing methods. However, the required experimental\ncapabilities to simulate string-breaking dynamics have not yet been\ndemonstrated, even for simpler models of the strong force. We experimentally\nprobe, for the first time, the spatiotemporal dynamics of string-breaking in a\n(1+1)-dimensional $\\mathbb{Z}_2$ lattice gauge theory using a fully\nprogrammable trapped-ion quantum simulator. We emulate external static charges\nand strings via site-dependent magnetic-field control enabled by a dual array\nof tightly focused laser beams targeting individual ions. First, we study how\nconfinement affects isolated charges, finding that they freely spread without\nstring tension but exhibit localized oscillations when tension is increased.\nThen, we observe and characterize string-breaking dynamics of a string\nstretched between two static charges after an abrupt increase in string\ntension. Charge pairs appear near the string edges and spread into the bulk,\nrevealing a route to dynamical string-breaking distinct from the conventional\nSchwinger mechanism. Our work demonstrates that analog quantum simulators have\nachieved the necessary control to explore string-breaking dynamics, which may\nultimately be relevant to nuclear and high-energy physics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13815v1",
    "published": "2024-10-17T17:46:07+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.quant-gas",
      "hep-lat",
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13927v1",
    "title": "Exploiting recursive structures for the design of novel quantum primitives",
    "authors": [
      "Ning Bao",
      "Gun Suer"
    ],
    "abstract": "The advent of fault-tolerant quantum computers marks a significant milestone,\nyet the development of practical quantum algorithms remains a critical\nchallenge. Effective quantum algorithms are essential for leveraging the power\nof quantum computers, and their design is often non-intuitive. This paper\naddresses the issue of generating novel quantum primitives by focusing on\nrecursive circuits. We explore the recursive circuit structures prevalent in\nexisting quantum algorithms and demonstrate how these structures can be\nexploited to design new, potentially advantageous quantum algorithms. We base\nour discussion on the quantum Fourier transform (QFT), which is a primitive\nthat is widely used in quantum algorithms. We show that the recursive structure\nin well-established fast classical transforms forms a fruitful bridge with\nquantum algorithms, enabling the design of novel quantum primitives and the\ndiscovery of new discrete numerical transforms. The discussion is split into\ntwo complementary parts, the forward and the reverse direction, in which\nexisting classical transforms are implemented using polynomial-time quantum\ncircuits and recursive circuits are used to find novel non-sparse classical\ntransforms with guaranteed quantum speedup, respectively. We comment on the\npotential impact on quantum algorithms, numerical analysis, and signal\nprocessing.",
    "pdf_url": "http://arxiv.org/pdf/2410.13927v1",
    "published": "2024-10-17T17:45:50+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13814v2",
    "title": "Construction of distorted Brownian motion with permeable sticky behaviour on sets with Lebesgue measure zero",
    "authors": [
      "Torben Fattler",
      "Martin Grothaus",
      "Nathalie Steil"
    ],
    "abstract": "The starting point is a gradient Dirichlet form with respect to\n$\\varrho\\lambda^d$ on the space $L^2({\\mathbb{R}}^d, \\varrho\\mu)$. Here\n$\\lambda^d$ is the Lebesgue measure on ${\\mathbb R}^d$, $\\varrho$ a strictly\npositive density and $\\mu$ puts weight on a set $A\\subset {\\mathbb R}^d$ with\nLebesgue measure zero. We show that the Dirichlet form admits an associated\nstochastic process $X$.\n  We derive an explicit representation of the corresponding generator if $A$ is\na Lipschitz boundary. This representation together with the Fukushima\ndecomposition identifies $X$ as a distorted Brownian motion with drift given by\nthe logarithmic derivative of $\\varrho$ in ${\\mathbb R}^d \\setminus A$.\nFurthermore, we prove $X$ to be irreducible and recurrent. Finally, via\nergodicity we prove positive s\\'ejour time of $X$ on $A$. Hence we obtain a\nstochastic process $X$ with permeable sticky behaviour on $A$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13814v2",
    "published": "2024-10-17T17:45:47+00:00",
    "categories": [
      "math.PR",
      "Primary: 60J46, Secondary: 60J65, 60J55, 60J60"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13813v1",
    "title": "Meta-Property Graphs: Extending Property Graphs with Metadata Awareness and Reification",
    "authors": [
      "Sepehr Sadoughi",
      "Nikolay Yakovets",
      "George Fletcher"
    ],
    "abstract": "The ISO standard Property Graph model has become increasingly popular for\nrepresenting complex, interconnected data. However, it lacks native support for\nquerying metadata and reification, which limits its abilities to deal with the\ndemands of modern applications. We introduce the vision of Meta-Property\nGraphs, a backwards compatible extension of the property graph model addressing\nthese limitations. Our approach enables first-class treatment of labels and\nproperties as queryable objects and supports reification of substructures in a\ngraph. We propose MetaGPML, a backwards compatible extension of the Graph\nPattern Matching Language forming the core of the ISO standard GQL, to query\nthese enhanced graphs. We demonstrate how these foundations pave the way for\nadvanced data analytics and governance tasks that are challenging or impossible\nwith current property graph systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13813v1",
    "published": "2024-10-17T17:45:29+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2410.13812v2",
    "title": "Private Counterfactual Retrieval",
    "authors": [
      "Mohamed Nomeir",
      "Pasan Dissanayake",
      "Shreya Meel",
      "Sanghamitra Dutta",
      "Sennur Ulukus"
    ],
    "abstract": "Transparency and explainability are two extremely important aspects to be\nconsidered when employing black-box machine learning models in high-stake\napplications. Providing counterfactual explanations is one way of fulfilling\nthis requirement. However, this also poses a threat to the privacy of both the\ninstitution that is providing the explanation as well as the user who is\nrequesting it. In this work, we propose multiple schemes inspired by private\ninformation retrieval (PIR) techniques which ensure the \\emph{user's privacy}\nwhen retrieving counterfactual explanations. We present a scheme which\nretrieves the \\emph{exact} nearest neighbor counterfactual explanation from a\ndatabase of accepted points while achieving perfect (information-theoretic)\nprivacy for the user. While the scheme achieves perfect privacy for the user,\nsome leakage on the database is inevitable which we quantify using a mutual\ninformation based metric. Furthermore, we propose strategies to reduce this\nleakage to achieve an advanced degree of database privacy. We extend these\nschemes to incorporate user's preference on transforming their attributes, so\nthat a more actionable explanation can be received. Since our schemes rely on\nfinite field arithmetic, we empirically validate our schemes on real datasets\nto understand the trade-off between the accuracy and the finite field sizes.\nFinally, we present numerical results to support our theoretical findings, and\ncompare the database leakage of the proposed schemes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13812v2",
    "published": "2024-10-17T17:45:07+00:00",
    "categories": [
      "cs.IT",
      "cs.CR",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.16320v1",
    "title": "Accelerating Object Detection with YOLOv4 for Real-Time Applications",
    "authors": [
      "K. Senthil Kumar",
      "K. M. B. Abdullah Safwan"
    ],
    "abstract": "Object Detection is related to Computer Vision. Object detection enables\ndetecting instances of objects in images and videos. Due to its increased\nutilization in surveillance, tracking system used in security and many others\napplications have propelled researchers to continuously derive more efficient\nand competitive algorithms. However, problems emerges while implementing it in\nreal-time because of their dynamic environment and complex algorithms used in\nobject detection. In the last few years, Convolution Neural Network (CNN) have\nemerged as a powerful tool for recognizing image content and in computer vision\napproach for most problems. In this paper, We revived begins the brief\nintroduction of deep learning and object detection framework like Convolutional\nNeural Network(CNN), You only look once - version 4 (YOLOv4). Then we focus on\nour proposed object detection architectures along with some modifications. The\ntraditional model detects a small object in images. We have some modifications\nto the model. Our proposed method gives the correct result with accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2410.16320v1",
    "published": "2024-10-17T17:44:57+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13811v1",
    "title": "Pentagonal bipyramids lead to the smallest flexible embedded polyhedron",
    "authors": [
      "Matteo Gallet",
      "Georg Grasegger",
      "Jan Legerský",
      "Josef Schicho"
    ],
    "abstract": "Steffen's polyhedron was believed to have the least number of vertices among\npolyhedra that can flex without self-intersections. Maksimov clarified that the\npentagonal bipyramid with one face subdivided into three is the only polyhedron\nwith fewer vertices for which the existence of a self-intersection-free flex\nwas open. Since subdividing a face into three does not change the mobility, we\nfocus on flexible pentagonal bipyramids. When a bipyramid flexes, the distance\nbetween the two opposite vertices of the two pyramids changes; associating the\nposition of the bipyramid to this distance yields an algebraic map that\ndetermines a nontrivial extension of rational function fields. We classify\nflexible pentagonal bipyramids with respect to the Galois group of this field\nextension and provide examples for each class, building on a construction\nproposed by Nelson. Surprisingly, one of our constructions yields a flexible\npentagonal bipyramid that can be extended to an embedded flexible polyhedron\nwith 8 vertices. The latter hence solves the open question.",
    "pdf_url": "http://arxiv.org/pdf/2410.13811v1",
    "published": "2024-10-17T17:44:29+00:00",
    "categories": [
      "math.MG",
      "cs.CG",
      "math.AC",
      "math.AG"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13926v1",
    "title": "Islanding Detection for Active Distribution Networks Using WaveNet+UNet Classifier",
    "authors": [
      "Amirhosein Alizadeh",
      "Seyed Fariborz Zarei",
      "Mohammadhadi Shateri"
    ],
    "abstract": "This paper proposes an AI-based scheme for islanding detection in active\ndistribution networks. By reviewing existing studies, it is clear that there\nare several gaps in the field to ensure reliable islanding detection, including\n(i) model complexity and stability concerns, (ii) limited accuracy under noisy\nconditions, and (iii) limited applicability to systems with different types of\nresources. Accordingly, this paper proposes a WaveNet classifier reinforced by\na denoising U-Net model to address these shortcomings. The proposed scheme has\na simple structure due to the use of 1D convolutional layers and incorporates\nresidual connections that significantly enhance the model's generalization.\nAdditionally, the proposed scheme is robust against noisy conditions by\nincorporating a denoising U-Net model. Furthermore, the model is sufficiently\nfast using a sliding window time series of 10 milliseconds for detection.\nUtilizing positive/negative/zero sequence components of voltages, superimposed\nwaveforms, and the rate of change of frequency provides the necessary features\nto precisely detect the islanding condition. In order to assess the\neffectiveness of the suggested scheme, over 3k islanding/non-islanding cases\nwere tested, considering different load active/reactive powers values, load\nswitching transients, capacitor bank switching, fault conditions in the main\ngrid, different load quality factors, signal-to-noise ratio levels, and both\ntypes of conventional and inverter-based sources.",
    "pdf_url": "http://arxiv.org/pdf/2410.13926v1",
    "published": "2024-10-17T17:44:21+00:00",
    "categories": [
      "eess.SP",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13810v2",
    "title": "Conservative discontinuous Galerkin method for supercritical, real-fluid flows",
    "authors": [
      "Eric J. Ching",
      "Ryan F. Johnson"
    ],
    "abstract": "This paper presents a conservative discontinuous Galerkin method for the\nsimulation of supercritical and transcritical real-fluid flows without phase\nseparation. A well-known issue associated with the use of fully conservative\nschemes is the generation of spurious pressure oscillations at contact\ninterfaces, which are exacerbated when a cubic equation of state and\nthermodynamic relations appropriate for this high-pressure flow regime are\nconsidered. To reduce these pressure oscillations, which can otherwise lead to\nsolver divergence in the absence of additional dissipation, an L2-projection of\nprimitive variables is performed in the evaluation of the flux. We apply the\ndiscontinuous Galerkin formulation to a variety of test cases. The first case\nis the advection of a sinusoidal density wave, which is used to verify the\nconvergence of the scheme. The next two involve one- and two-dimensional\nadvection of a nitrogen/n-dodecane thermal bubble, in which the ability of the\nmethodology to reduce pressure oscillations and maintain solution stability is\nassessed. The final test cases consist of two- and three-dimensional injection\nof an n-dodecane jet into a nitrogen chamber.",
    "pdf_url": "http://arxiv.org/pdf/2410.13810v2",
    "published": "2024-10-17T17:43:35+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2410.19811v1",
    "title": "ControlAgent: Automating Control System Design via Novel Integration of LLM Agents and Domain Expertise",
    "authors": [
      "Xingang Guo",
      "Darioush Keivan",
      "Usman Syed",
      "Lianhui Qin",
      "Huan Zhang",
      "Geir Dullerud",
      "Peter Seiler",
      "Bin Hu"
    ],
    "abstract": "Control system design is a crucial aspect of modern engineering with\nfar-reaching applications across diverse sectors including aerospace,\nautomotive systems, power grids, and robotics. Despite advances made by Large\nLanguage Models (LLMs) in various domains, their application in control system\ndesign remains limited due to the complexity and specificity of control theory.\nTo bridge this gap, we introduce ControlAgent, a new paradigm that automates\ncontrol system design via novel integration of LLM agents and control-oriented\ndomain expertise. ControlAgent encodes expert control knowledge and emulates\nhuman iterative design processes by gradually tuning controller parameters to\nmeet user-specified requirements for stability, performance, and robustness.\nControlAgent integrates multiple collaborative LLM agents, including a central\nagent responsible for task distribution and task-specific agents dedicated to\ndetailed controller design for various types of systems and requirements.\nControlAgent also employs a Python computation agent that performs complex\ncalculations and controller evaluations based on standard design information\nprovided by task-specified LLM agents. Combined with a history and feedback\nmodule, the task-specific LLM agents iteratively refine controller parameters\nbased on real-time feedback from prior designs. Overall, ControlAgent mimics\nthe design processes used by (human) practicing engineers, but removes all the\nhuman efforts and can be run in a fully automated way to give end-to-end\nsolutions for control system design with user-specified requirements. To\nvalidate ControlAgent's effectiveness, we develop ControlEval, an evaluation\ndataset that comprises 500 control tasks with various specific design goals.\nThe effectiveness of ControlAgent is demonstrated via extensive comparative\nevaluations between LLM-based and traditional human-involved toolbox-based\nbaselines.",
    "pdf_url": "http://arxiv.org/pdf/2410.19811v1",
    "published": "2024-10-17T17:42:48+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13809v3",
    "title": "Almost Hermitian structures on virtual moduli spaces of non-Abelian monopoles and applications to the topology of symplectic four-manifolds",
    "authors": [
      "Paul M. N. Feehan",
      "Thomas G. Leness"
    ],
    "abstract": "This work is a sequel to our previous monograph arXiv:2010.15789 (to appear\nin AMS Memoirs), where we initiated our program to prove that the\nBogomolov-Miyaoka-Yau inequality holds for closed, symplectic four-manifolds\nand, more generally, for closed, smooth four-manifolds with a Seiberg-Witten\nbasic class. This inequality was first proved for compact, complex surfaces of\ngeneral type by Miyaoka (1977) and Yau (1978). Our approach uses a version of\nMorse theory for a natural Hamiltonian, the square of the $L^2$ norm of the\ncoupled spinors, for the circle action on the moduli space of non-Abelian\nmonopoles over a closed four-manifold. It has the aim of proving the existence\nof a projectively anti-self-dual connection on a rank-two Hermitian vector\nbundle over a blow-up of the four-manifold, where the first Pontrjagin number\nof the vector bundle is negative and greater than or equal to minus the Euler\ncharacteristic of the blown-up four-manifold. Our Morse theory argument relies\non positivity of virtual Morse-Bott indices for critical points of Hamiltonians\nfor circle actions on complex analytic spaces (or real analytic spaces that,\nlocally, are sufficiently well-approximated by complex analytic model spaces),\nas developed by the first author in arXiv:2206.14710. In our application to the\nmoduli space of non-Abelian monopoles, the critical points are fixed points of\nthe circle action and thus represented by Seiberg-Witten monopoles.",
    "pdf_url": "http://arxiv.org/pdf/2410.13809v3",
    "published": "2024-10-17T17:42:17+00:00",
    "categories": [
      "math.DG",
      "math.GT",
      "math.SG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13808v2",
    "title": "De-mark: Watermark Removal in Large Language Models",
    "authors": [
      "Ruibo Chen",
      "Yihan Wu",
      "Junfeng Guo",
      "Heng Huang"
    ],
    "abstract": "Watermarking techniques offer a promising way to identify machine-generated\ncontent via embedding covert information into the contents generated from\nlanguage models (LMs). However, the robustness of the watermarking schemes has\nnot been well explored. In this paper, we present De-mark, an advanced\nframework designed to remove n-gram-based watermarks effectively. Our method\nutilizes a novel querying strategy, termed random selection probing, which aids\nin assessing the strength of the watermark and identifying the red-green list\nwithin the n-gram watermark. Experiments on popular LMs, such as Llama3 and\nChatGPT, demonstrate the efficiency and effectiveness of De-mark in watermark\nremoval and exploitation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13808v2",
    "published": "2024-10-17T17:42:10+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13807v2",
    "title": "Improving Consistency in Diffusion Models for Image Super-Resolution",
    "authors": [
      "Junhao Gu",
      "Peng-Tao Jiang",
      "Hao Zhang",
      "Mi Zhou",
      "Jinwei Chen",
      "Wenming Yang",
      "Bo Li"
    ],
    "abstract": "Recent methods exploit the powerful text-to-image (T2I) diffusion models for\nreal-world image super-resolution (Real-ISR) and achieve impressive results\ncompared to previous models. However, we observe two kinds of inconsistencies\nin diffusion-based methods which hinder existing models from fully exploiting\ndiffusion priors. The first is the semantic inconsistency arising from\ndiffusion guidance. T2I generation focuses on semantic-level consistency with\ntext prompts, while Real-ISR emphasizes pixel-level reconstruction from\nlow-quality (LQ) images, necessitating more detailed semantic guidance from LQ\ninputs. The second is the training-inference inconsistency stemming from the\nDDPM, which improperly assumes high-quality (HQ) latent corrupted by Gaussian\nnoise as denoising inputs for each timestep. To address these issues, we\nintroduce ConsisSR to handle both semantic and training-inference\nconsistencies. On the one hand, to address the semantic inconsistency, we\nproposed a Hybrid Prompt Adapter (HPA). Instead of text prompts with\ncoarse-grained classification information, we leverage the more powerful CLIP\nimage embeddings to explore additional color and texture guidance. On the other\nhand, we introduce Time-Aware Latent Augmentation (TALA) to bridge the\ntraining-inference inconsistency. Based on the probability function p(t), we\naccordingly enhance the SDSR training strategy. With LQ latent with Gaussian\nnoise as inputs, our TALA not only focuses on diffusion noise but also refine\nthe LQ latent towards the HQ counterpart. Our method demonstrates\nstate-of-the-art performance among existing diffusion models. The code will be\nmade publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2410.13807v2",
    "published": "2024-10-17T17:41:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13806v1",
    "title": "Near-Field LoS/NLoS Channel Estimation for RIS-Aided MU-MIMO Systems: Piece-Wise Low-Rank Approximation Approach",
    "authors": [
      "Jeongjae Lee",
      "Songnam Hong"
    ],
    "abstract": "We study the channel estimation problem for a reconfigurable intelligent\nsurface (RIS)-assisted millimeter-wave (mmWave) multi-user multiple-input\nmultiple-output (MU-MIMO) system. In particular, it is assumed that the channel\nbetween a RIS and a base station (BS) exhibits a near-field line-of-sight (LoS)\nchannel, which is a dominant signal path in mmWave communication systems. Due\nto the high-rankness and non-sparsity of the RIS-BS channel matrix in our\nsystem, the state-of-the-art (SOTA) methods, which are constructed based on\nfar-field or near-field non-LoS (NLoS) channel, cannot provide attractive\nestimation performances. We for the first time propose an efficient near-field\nLoS/NLoS channel estimation method for RIS-assisted MU-MIMO systems by means of\na piece-wise low-rank approximation. Specifically, an effective channel (to be\nestimated) is partitioned into piece-wise effective channels containing\nlow-rank structures and then, they are estimated via collaborative low-rank\napproximation. The proposed method is named PW-CLRA. Via simulations, we verify\nthe effectiveness of the proposed PW-CLRA.",
    "pdf_url": "http://arxiv.org/pdf/2410.13806v1",
    "published": "2024-10-17T17:41:34+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13805v1",
    "title": "A Watermark for Order-Agnostic Language Models",
    "authors": [
      "Ruibo Chen",
      "Yihan Wu",
      "Yanshuo Chen",
      "Chenxi Liu",
      "Junfeng Guo",
      "Heng Huang"
    ],
    "abstract": "Statistical watermarking techniques are well-established for sequentially\ndecoded language models (LMs). However, these techniques cannot be directly\napplied to order-agnostic LMs, as the tokens in order-agnostic LMs are not\ngenerated sequentially. In this work, we introduce Pattern-mark, a\npattern-based watermarking framework specifically designed for order-agnostic\nLMs. We develop a Markov-chain-based watermark generator that produces\nwatermark key sequences with high-frequency key patterns. Correspondingly, we\npropose a statistical pattern-based detection algorithm that recovers the key\nsequence during detection and conducts statistical tests based on the count of\nhigh-frequency patterns. Our extensive evaluations on order-agnostic LMs, such\nas ProteinMPNN and CMLM, demonstrate Pattern-mark's enhanced detection\nefficiency, generation quality, and robustness, positioning it as a superior\nwatermarking technique for order-agnostic LMs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13805v1",
    "published": "2024-10-17T17:41:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13804v3",
    "title": "BenTo: Benchmark Task Reduction with In-Context Transferability",
    "authors": [
      "Hongyu Zhao",
      "Ming Li",
      "Lichao Sun",
      "Tianyi Zhou"
    ],
    "abstract": "Evaluating large language models (LLMs) is costly: it requires the generation\nand examination of LLM outputs on a large-scale benchmark of various tasks.\nThis paper investigates how to efficiently reduce the tasks used to benchmark\nLLMs without affecting the evaluation quality. Our study reveals that task\ntransferability and relevance provide critical information to identify the most\nrepresentative subset of tasks via optimizing a facility location function. We\npropose a practically efficient metric for estimating the transferability\nbetween two tasks via in-context learning (ICL). By analyzing the pairwise\ntransferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or\nFLAN) to 5% while inducing only a <4% difference to the evaluation on the\noriginal benchmark. Compared to prior works, our method is training-free,\ngradient-free, and highly efficient requiring ICL only.",
    "pdf_url": "http://arxiv.org/pdf/2410.13804v3",
    "published": "2024-10-17T17:41:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13803v1",
    "title": "A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities",
    "authors": [
      "Gianluca Apriceno",
      "Valentina Tamma",
      "Tania Bailoni",
      "Jacopo de Berardinis",
      "Mauro Dragoni"
    ],
    "abstract": "The ability to reason with and integrate different sensory inputs is the\nfoundation underpinning human intelligence and it is the reason for the growing\ninterest in modelling multi-modal information within Knowledge Graphs.\nMulti-Modal Knowledge Graphs extend traditional Knowledge Graphs by associating\nan entity with its possible modal representations, including text, images,\naudio, and videos, all of which are used to convey the semantics of the entity.\nDespite the increasing attention that Multi-Modal Knowledge Graphs have\nreceived, there is a lack of consensus about the definitions and modelling of\nmodalities, whose definition is often determined by application domains. In\nthis paper, we propose a novel ontology design pattern that captures the\nseparation of concerns between an entity (and the information it conveys),\nwhose semantics can have different manifestations across different media, and\nits realisation in terms of a physical information entity. By introducing this\nabstract model, we aim to facilitate the harmonisation and integration of\ndifferent existing multi-modal ontologies which is crucial for many intelligent\napplications across different domains spanning from medicine to digital\nhumanities.",
    "pdf_url": "http://arxiv.org/pdf/2410.13803v1",
    "published": "2024-10-17T17:41:04+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13802v1",
    "title": "Adversarial Testing as a Tool for Interpretability: Length-based Overfitting of Elementary Functions in Transformers",
    "authors": [
      "Patrik Zavoral",
      "Dušan Variš",
      "Ondřej Bojar"
    ],
    "abstract": "The Transformer model has a tendency to overfit various aspects of the\ntraining data, such as the overall sequence length. We study elementary string\nedit functions using a defined set of error indicators to interpret the\nbehaviour of the sequence-to-sequence Transformer. We show that generalization\nto shorter sequences is often possible, but confirm that longer sequences are\nhighly problematic, although partially correct answers are often obtained.\nAdditionally, we find that other structural characteristics of the sequences,\nsuch as subsegment length, may be equally important. We hypothesize that the\nmodels learn algorithmic aspects of the tasks simultaneously with structural\naspects but adhering to the structural aspects is unfortunately often preferred\nby Transformer when they come into conflict.",
    "pdf_url": "http://arxiv.org/pdf/2410.13802v1",
    "published": "2024-10-17T17:39:46+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13801v1",
    "title": "Enabling a multifunctional telecommunications fiber optic network: Ultrastable optical frequency transfer and attosecond timing in deployed multicore fiber",
    "authors": [
      "Nazanin Hoghooghi",
      "Mikael Mazur",
      "Nicolas Fontaine",
      "Yifan Liu",
      "Dahyeon Lee",
      "Charles McLemore",
      "Takuma Nakamura",
      "Tetsuya Hayashi",
      "Giammarco Di Sciullo",
      "Divya Shaji",
      "Antonio Mecozzi",
      "Cristian Antonelli",
      "Franklyn Quinlan"
    ],
    "abstract": "The telecommunications industry's deployment of billions of kilometers of\noptical fiber has created a vast global network that can be exploited for\nadditional applications such as environmental sensing, quantum networking and\ninternational clock comparisons. However, for reasons such as the\nunidirectionality of long-haul fiber links, telecom fiber networks cannot\nalways be adapted for important applications beyond data transmission.\nFortunately, new multicore optical fibers create the opportunity for\napplication coexistence with data traffic, creating expansive multifunctional\nnetworks. Towards that end, we propose and demonstrate the faithful transfer of\nultrastable optical signals through multicore fiber in a way that is compatible\nwith the unidirectionality of long-haul fiber optic systems, demonstrating a\nfractional frequency instability of 3x10-19 at 10,000 seconds. This opens the\ndoor towards intercontinental optical clock comparisons, with applications in\nfundamental physics and the redefinition of the second.",
    "pdf_url": "http://arxiv.org/pdf/2410.13801v1",
    "published": "2024-10-17T17:39:26+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13799v3",
    "title": "Machine-Learning Analysis of Radiative Decays to Dark Matter at the LHC",
    "authors": [
      "Ernesto Arganda",
      "Marcela Carena",
      "Martín de los Rios",
      "Andres D. Perez",
      "Duncan Rocha",
      "Rosa M. Sandá Seoane",
      "Carlos E. M. Wagner"
    ],
    "abstract": "The search for weakly interacting matter particles (WIMPs) is one of the main\nobjectives of the High Luminosity Large Hadron Collider (HL-LHC). In this work\nwe use Machine-Learning (ML) techniques to explore WIMP radiative decays into a\nDark Matter (DM) candidate in a supersymmetric framework. The minimal\nsupersymmetric WIMP sector includes the lightest neutralino that can provide\nthe observed DM relic density through its co-annihilation with the second\nlightest neutralino and lightest chargino. Moreover, the direct DM detection\ncross section rates fulfill current experimental bounds and provide discovery\ntargets for the same region of model parameters in which the radiative decay of\nthe second lightest neutralino into a photon and the lightest neutralino is\nenhanced. This strongly motivates the search for radiatively decaying\nneutralinos which, however, suffers from strong backgrounds. We investigate the\nLHC reach in the search for these radiatively decaying particles by means of\ncut-based and ML methods and estimate its discovery potential in this\nwell-motivated, new physics scenario. We demonstrate that using ML techniques\nwould enable access to most of the parameter space unexplored by other\nsearches.",
    "pdf_url": "http://arxiv.org/pdf/2410.13799v3",
    "published": "2024-10-17T17:38:44+00:00",
    "categories": [
      "hep-ph",
      "cs.LG",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13800v3",
    "title": "Discrete distributions are learnable from metastable samples",
    "authors": [
      "Abhijith Jayakumar",
      "Andrey Y. Lokhov",
      "Sidhant Misra",
      "Marc Vuffray"
    ],
    "abstract": "Physically motivated stochastic dynamics are often used to sample from\nhigh-dimensional distributions. However such dynamics often get stuck in\nspecific regions of their state space and mix very slowly to the desired\nstationary state. This causes such systems to approximately sample from a\nmetastable distribution which is usually quite different from the desired,\nstationary distribution of the dynamic. We rigorously show that, in the case of\nmulti-variable discrete distributions, the true model describing the stationary\ndistribution can be recovered from samples produced from a metastable\ndistribution under minimal assumptions about the system. This follows from a\nfundamental observation that the single-variable conditionals of metastable\ndistributions that satisfy a strong metastability condition are on average\nclose to those of the stationary distribution. This holds even when the\nmetastable distribution differs considerably from the true model in terms of\nglobal metrics like Kullback-Leibler divergence or total variation distance.\nThis property allows us to learn the true model using a conditional likelihood\nbased estimator, even when the samples come from a metastable distribution\nconcentrated in a small region of the state space. Explicit examples of such\nmetastable states can be constructed from regions that effectively bottleneck\nthe probability flow and cause poor mixing of the Markov chain. For specific\ncases of binary pairwise undirected graphical models (i.e. Ising models), we\nextend our results to further rigorously show that data coming from metastable\nstates can be used to learn the parameters of the energy function and recover\nthe structure of the model.",
    "pdf_url": "http://arxiv.org/pdf/2410.13800v3",
    "published": "2024-10-17T17:38:44+00:00",
    "categories": [
      "stat.ML",
      "cond-mat.stat-mech",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13798v2",
    "title": "Learning Graph Quantized Tokenizers",
    "authors": [
      "Limei Wang",
      "Kaveh Hassani",
      "Si Zhang",
      "Dongqi Fu",
      "Baichuan Yuan",
      "Weilin Cong",
      "Zhigang Hua",
      "Hao Wu",
      "Ning Yao",
      "Bo Long"
    ],
    "abstract": "Transformers serve as the backbone architectures of Foundational Models,\nwhere domain-specific tokenizers allow them to adapt to various domains. Graph\nTransformers (GTs) have recently emerged as leading models in geometric deep\nlearning, outperforming Graph Neural Networks (GNNs) in various graph learning\ntasks. However, the development of tokenizers for graphs has lagged behind\nother modalities. To address this, we introduce GQT (\\textbf{G}raph\n\\textbf{Q}uantized \\textbf{T}okenizer), which decouples tokenizer training from\nTransformer training by leveraging multi-task graph self-supervised learning,\nyielding robust and generalizable graph tokens. Furthermore, the GQT utilizes\nResidual Vector Quantization (RVQ) to learn hierarchical discrete tokens,\nresulting in significantly reduced memory requirements and improved\ngeneralization capabilities. By combining the GQT with token modulation, a\nTransformer encoder achieves state-of-the-art performance on 20 out of 22\nbenchmarks, including large-scale homophilic and heterophilic datasets.",
    "pdf_url": "http://arxiv.org/pdf/2410.13798v2",
    "published": "2024-10-17T17:38:24+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13797v1",
    "title": "Influence of Topology on Rheological Properties of Polymer Ring Melts",
    "authors": [
      "Ranajay Datta",
      "Peter Virnau"
    ],
    "abstract": "We investigate with numerical simulations the influence of topology and\nstiffness on macroscopic rheological properties of polymer melts consisting of\nunknotted, knotted or concatenated rings. While melts of flexible, knotted\noligomer rings tend to be significantly more viscous than their unknotted\ncounterparts, differences vanish in a low shear rate scenario with increasing\ndegree of polymerization. Melts of catenanes consisting of two rings on the\nother hand are consistently more viscous than their unconcatenated\ncounterparts. These topology-based differences in rheological properties can be\nexploited to segregate mixtures of otherwise chemically similar polymers, e.g.,\nin microfluidic devices, which is demonstrated by exposing a blend of flexible\nknotted and unknotted oligomer rings to channel flow.",
    "pdf_url": "http://arxiv.org/pdf/2410.13797v1",
    "published": "2024-10-17T17:37:14+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13796v1",
    "title": "Navigation maps of the material space for automated self-driving labs of the future",
    "authors": [
      "Daniel E Widdowson",
      "Vitaliy A Kurlin"
    ],
    "abstract": "With the advent of self-driving labs promising to synthesize large numbers of\nnew materials, new automated tools are required for checking potential\nduplicates in existing structural databases before a material can be claimed as\nnovel. To avoid duplication, we rigorously define the novelty metric of any\nperiodic material as the smallest distance to its nearest neighbor among\nalready known materials.\n  Using ultra-fast structural invariants, all such nearest neighbors can be\nfound within seconds on a typical computer even if a given crystal is disguised\nby changing a unit cell, perturbing atoms, or replacing chemical elements. This\nreal-time novelty check is demonstrated by finding near-duplicates of the 43\nmaterials produced by Berkeley's A-lab in the world's largest collections of\ninorganic structures, the Inorganic Crystal Structure Database and Materials\nProject.\n  To help future self-driving labs successfully identify novel materials, we\npropose navigation maps of the materials space where any new structure can be\nquickly located by its invariant descriptors similar to a geographic location\non Earth.",
    "pdf_url": "http://arxiv.org/pdf/2410.13796v1",
    "published": "2024-10-17T17:36:36+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "74E15, 51N20"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13795v1",
    "title": "Predicting synthesis window of beta-TaON with thermodynamic modeling",
    "authors": [
      "Dmitri LaBelle",
      "Yong-Jie Hu"
    ],
    "abstract": "Phase-pure synthesis has been a major challenge for metal oxynitrides due to\ntheir sensitivity to synthesis conditions and the limited understanding of the\nunderlying thermodynamics. The beta-phase tantalum oxynitride (beta-TaON), a\npromising material for applications in photocatalysis and energy storage, is\nparticularly difficult to synthesize in a reproducible, phase-pure form. In\nthis work, a computational thermodynamic model with experimental validation is\npresented to evaluate the phase-pure synthesis conditions for beta-TaON via\nammonolysis reactions. The finite-temperature thermochemical properties of the\nreactant, product, and byproduct phases are predicted via first-principles\ncalculations with the quasi-harmonic approach (QHA) as well as implemented from\navailable thermodynamic databases. With the thermochemical properties, a\nthermodynamic model based on the CALculation of PHAse Diagrams (CALPAHD)\napproach is developed to assess the phase equilibria associated with the\nsynthesis reactions and correspondingly predict the synthesis window for\nbeta-TaON. A three-dimensional phase diagram is predicted as a function of gas\ncomposition and temperature, providing insights into optimal synthesis\nconditions. The computational predictions are further compared with available\nexperimental data, offering a systematic framework for phase-pure beta-TaON\nsynthesis.",
    "pdf_url": "http://arxiv.org/pdf/2410.13795v1",
    "published": "2024-10-17T17:36:15+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13794v2",
    "title": "Arbitrarily-Conditioned Multi-Functional Diffusion for Multi-Physics Emulation",
    "authors": [
      "Da Long",
      "Zhitong Xu",
      "Guang Yang",
      "Akil Narayan",
      "Shandian Zhe"
    ],
    "abstract": "Modern physics simulation often involves multiple functions of interests, and\ntraditional numerical approaches are known to be complex and computationally\ncostly. While machine learning-based surrogate models can offer significant\ncost reductions, most focus on a single task, such as forward prediction, and\ntypically lack uncertainty quantification -- an essential component in many\napplications. To overcome these limitations, we propose Arbitrarily-Conditioned\nMulti-Functional Diffusion (ACM-FD), a versatile probabilistic surrogate model\nfor multi-physics emulation. ACM-FD can perform a wide range of tasks within a\nsingle framework, including forward prediction, various inverse problems, and\nsimulating data for entire systems or subsets of quantities conditioned on\nothers. Specifically, we extend the standard Denoising Diffusion Probabilistic\nModel (DDPM) for multi-functional generation by modeling noise as Gaussian\nprocesses (GP). We propose a random-mask based, zero-regularized denoising loss\nto achieve flexible and robust conditional generation. We induce a Kronecker\nproduct structure in the GP covariance matrix, substantially reducing the\ncomputational cost and enabling efficient training and sampling. We demonstrate\nthe effectiveness of ACM-FD across several fundamental multi-physics systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13794v2",
    "published": "2024-10-17T17:34:06+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13793v1",
    "title": "Impact of stratified rotation on the moment of inertia of neutron stars",
    "authors": [
      "Jonas P. Pereira",
      "Tulio Ottoni",
      "Jaziel G. Coelho",
      "Jorge A. Rueda",
      "Rafael C. R. de Lima"
    ],
    "abstract": "Rigid (Uniform) rotation is usually assumed when investigating the properties\nof mature neutron stars (NSs). Although it simplifies their description, it is\nan assumption because we cannot observe the NS's innermost parts. Here, we\nanalyze the structure of NSs in the simple case of ''almost rigidity,'' where\nthe innermost and outermost parts rotate with different angular velocities.\nThis is motivated by the possibility of NSs having superfluid interiors, phase\ntransitions, and angular momentum transfer during accretion processes. We show\nthat, in general relativity, the relative difference in angular velocity\nbetween different parts of an NS induces a change in the moment of inertia\ncompared to that of rigid rotation. The relative change depends nonlinearly on\nwhere the angular velocity jump occurs inside the NS. For the same observed\nangular velocity in both configurations, if the jump location is close to the\nstar's surface-which is possible in central compact objects (CCOs) and\naccreting stars-the relative change in the moment of inertia is close to that\nof the angular velocity (which is expected due to total angular momentum\naspects). If the jump occurs deep within the NS, for instance, due to phase\ntransitions or superfluidity, smaller relative changes in the moment of inertia\nare observed; we found that if it is at a radial distance smaller than\napproximately $40\\%$ of the star's radius, the relative changes are negligible.\nAdditionally, we outline the relevance of systematic uncertainties that\nnonrigidity could have on some NS observables, such as radius, ellipticity, and\nthe rotational energy budget of pulsars, which could explain the X-ray\nluminosity of some sources. Finally, we also show that non-rigidity weakens the\nuniversal $I$-Love-$Q$ relations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13793v1",
    "published": "2024-10-17T17:33:17+00:00",
    "categories": [
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13792v1",
    "title": "Analyzing Deep Transformer Models for Time Series Forecasting via Manifold Learning",
    "authors": [
      "Ilya Kaufman",
      "Omri Azencot"
    ],
    "abstract": "Transformer models have consistently achieved remarkable results in various\ndomains such as natural language processing and computer vision. However,\ndespite ongoing research efforts to better understand these models, the field\nstill lacks a comprehensive understanding. This is particularly true for deep\ntime series forecasting methods, where analysis and understanding work is\nrelatively limited. Time series data, unlike image and text information, can be\nmore challenging to interpret and analyze. To address this, we approach the\nproblem from a manifold learning perspective, assuming that the latent\nrepresentations of time series forecasting models lie next to a low-dimensional\nmanifold. In our study, we focus on analyzing the geometric features of these\nlatent data manifolds, including intrinsic dimension and principal curvatures.\nOur findings reveal that deep transformer models exhibit similar geometric\nbehavior across layers, and these geometric features are correlated with model\nperformance. Additionally, we observe that untrained models initially have\ndifferent structures, but they rapidly converge during training. By leveraging\nour geometric analysis and differentiable tools, we can potentially design new\nand improved deep forecasting neural networks. This approach complements\nexisting analysis studies and contributes to a better understanding of\ntransformer models in the context of time series forecasting. Code is released\nat https://github.com/azencot-group/GATLM.",
    "pdf_url": "http://arxiv.org/pdf/2410.13792v1",
    "published": "2024-10-17T17:32:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13791v2",
    "title": "Path integral of free fields and the determinant of Laplacian in warped space-time",
    "authors": [
      "Soumangsu Chakraborty",
      "Akikazu Hashimoto",
      "Horatiu Nastase"
    ],
    "abstract": "We revisit the problem of computing the determinant of Klein-Gordon operator\n$\\Delta = -\\nabla^2 + M^2$ on Euclideanized $AdS_3$ with the Euclideanized time\ncoordinate compactified with period $\\beta$, $H_3/Z$, by explicitly computing\nits eigenvalues and computing their product. Upon assuming that eigenfunctions\nare normalizable on $H_3/Z$, we found that there are no such eigenfunctions.\nUpon closer examination, we discover that the intuition that $H_3/Z$ is like a\nbox with normalizable eigenfunctions was false, and that there is, instead, a\nset of eigenfunctions which forms a continuum. Somewhat to our surprise, we\nfind that there is a different operator $\\tilde \\Delta = r^2 \\Delta$, which has\nthe property that (1) the determinant of $\\Delta$ and the determinant of $r^2\n\\Delta$ have the same dependence on $\\beta$, and that (2) the Green's function\nof $\\Delta$ can be spectrally decomposed into eigenfunctions of $\\tilde\n\\Delta$. We identify the $\\tilde \\Delta$ operator as the ``weighted Laplacian''\nin the context of warped compactifications, and comment on possible\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2410.13791v2",
    "published": "2024-10-17T17:31:55+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13790v1",
    "title": "MotionBank: A Large-scale Video Motion Benchmark with Disentangled Rule-based Annotations",
    "authors": [
      "Liang Xu",
      "Shaoyang Hua",
      "Zili Lin",
      "Yifan Liu",
      "Feipeng Ma",
      "Yichao Yan",
      "Xin Jin",
      "Xiaokang Yang",
      "Wenjun Zeng"
    ],
    "abstract": "In this paper, we tackle the problem of how to build and benchmark a large\nmotion model (LMM). The ultimate goal of LMM is to serve as a foundation model\nfor versatile motion-related tasks, e.g., human motion generation, with\ninterpretability and generalizability. Though advanced, recent LMM-related\nworks are still limited by small-scale motion data and costly text\ndescriptions. Besides, previous motion benchmarks primarily focus on pure body\nmovements, neglecting the ubiquitous motions in context, i.e., humans\ninteracting with humans, objects, and scenes. To address these limitations, we\nconsolidate large-scale video action datasets as knowledge banks to build\nMotionBank, which comprises 13 video action datasets, 1.24M motion sequences,\nand 132.9M frames of natural and diverse human motions. Different from\nlaboratory-captured motions, in-the-wild human-centric videos contain abundant\nmotions in context. To facilitate better motion text alignment, we also\nmeticulously devise a motion caption generation algorithm to automatically\nproduce rule-based, unbiased, and disentangled text descriptions via the\nkinematic characteristics for each motion. Extensive experiments show that our\nMotionBank is beneficial for general motion-related tasks of human motion\ngeneration, motion in-context generation, and motion understanding. Video\nmotions together with the rule-based text annotations could serve as an\nefficient alternative for larger LMMs. Our dataset, codes, and benchmark will\nbe publicly available at https://github.com/liangxuy/MotionBank.",
    "pdf_url": "http://arxiv.org/pdf/2410.13790v1",
    "published": "2024-10-17T17:31:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13789v2",
    "title": "Neutron-neutron distribution of the triton from pionless EFT",
    "authors": [
      "Tanja Kirchner",
      "Matthias Göbel",
      "Hans-Werner Hammer"
    ],
    "abstract": "We compute the neutron-neutron relative-energy distribution of the triton\nfollowing the hard knockout of the proton in pionless effective field theory.\nThis distribution can be used to study universality as well as to obtain\ninformation on the neutron-neutron interaction. Especially, one can infer the\nscattering length from fitting theory predictions for the shape of the\ndistribution to experimental data. To obtain the distribution for the triton,\nwe first solve the ground-state three-body problem using momentum-space Faddeev\nequations. Next, we include the neutron-neutron final-state interaction by\napplying the corresponding M{\\o}ller operator to the ground state. We present\nleading-order (LO) and next-to-leading order (NLO) pionless effective field\ntheory results with quantified uncertainties. At NLO, we include the effective\nranges semi-perturbatively. We conclude, that pionless EFT works reliably as\nexpected and that the neutron-neutron distribution of the triton shows a\nsignificant sensitivity to the scattering length.",
    "pdf_url": "http://arxiv.org/pdf/2410.13789v2",
    "published": "2024-10-17T17:29:23+00:00",
    "categories": [
      "nucl-th",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13788v2",
    "title": "Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions",
    "authors": [
      "Michael J. Q. Zhang",
      "W. Bradley Knox",
      "Eunsol Choi"
    ],
    "abstract": "Large language models (LLMs) must often respond to highly ambiguous user\nrequests. In such cases, the LLM's best response may be to ask a clarifying\nquestion to elicit more information. Existing LLMs often respond by\npresupposing a single interpretation of such ambiguous requests, frustrating\nusers who intended a different interpretation. We speculate this is caused by\ncurrent preference data labeling practice, where LLM responses are evaluated\nonly on their prior contexts. To address this, we assign preference labels by\nsimulating their expected outcomes in future turns. This allows LLMs to learn\nto ask clarifying questions when it can generate responses that are tailored to\neach user interpretation in future turns. On open-domain QA datasets with\nmultiple annotations, we evaluate systems based on their ability to ask\nclarifying questions to recover each user's interpretation and expected answer.\nWe compare systems trained using our proposed preference labeling methods\nagainst standard methods, which assign preferences based on only prior context.\nOur method achieves a 5% improvement in F1 measured against the answer set from\ndifferent interpretations of each query, showing the value of modeling future\nconversation turns. We further demonstrate that our method can be used to train\nmodels to judiciously determine when to ask clarifying questions, directly\nanswering the question when clarification is unnecessary. In our experiments,\nwe find that our method achieves a 3% improvement in accuracy of such judgments\nover existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13788v2",
    "published": "2024-10-17T17:29:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13787v1",
    "title": "Looking Inward: Language Models Can Learn About Themselves by Introspection",
    "authors": [
      "Felix J Binder",
      "James Chua",
      "Tomek Korbak",
      "Henry Sleight",
      "John Hughes",
      "Robert Long",
      "Ethan Perez",
      "Miles Turpin",
      "Owain Evans"
    ],
    "abstract": "Humans acquire knowledge by observing the external world, but also by\nintrospection. Introspection gives a person privileged access to their current\nstate of mind (e.g., thoughts and feelings) that is not accessible to external\nobservers. Can LLMs introspect? We define introspection as acquiring knowledge\nthat is not contained in or derived from training data but instead originates\nfrom internal states. Such a capability could enhance model interpretability.\nInstead of painstakingly analyzing a model's internal workings, we could simply\nask the model about its beliefs, world models, and goals. More speculatively,\nan introspective model might self-report on whether it possesses certain\ninternal states such as subjective feelings or desires and this could inform us\nabout the moral status of these states. Such self-reports would not be entirely\ndictated by the model's training data.\n  We study introspection by finetuning LLMs to predict properties of their own\nbehavior in hypothetical scenarios. For example, \"Given the input P, would your\noutput favor the short- or long-term option?\" If a model M1 can introspect, it\nshould outperform a different model M2 in predicting M1's behavior even if M2\nis trained on M1's ground-truth behavior. The idea is that M1 has privileged\naccess to its own behavioral tendencies, and this enables it to predict itself\nbetter than M2 (even if M2 is generally stronger).\n  In experiments with GPT-4, GPT-4o, and Llama-3 models (each finetuned to\npredict itself), we find that the model M1 outperforms M2 in predicting itself,\nproviding evidence for introspection. Notably, M1 continues to predict its\nbehavior accurately even after we intentionally modify its ground-truth\nbehavior. However, while we successfully elicit introspection on simple tasks,\nwe are unsuccessful on more complex tasks or those requiring\nout-of-distribution generalization.",
    "pdf_url": "http://arxiv.org/pdf/2410.13787v1",
    "published": "2024-10-17T17:24:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13786v1",
    "title": "Emphasizing Semantic Consistency of Salient Posture for Speech-Driven Gesture Generation",
    "authors": [
      "Fengqi Liu",
      "Hexiang Wang",
      "Jingyu Gong",
      "Ran Yi",
      "Qianyu Zhou",
      "Xuequan Lu",
      "Jiangbo Lu",
      "Lizhuang Ma"
    ],
    "abstract": "Speech-driven gesture generation aims at synthesizing a gesture sequence\nsynchronized with the input speech signal. Previous methods leverage neural\nnetworks to directly map a compact audio representation to the gesture\nsequence, ignoring the semantic association of different modalities and failing\nto deal with salient gestures. In this paper, we propose a novel speech-driven\ngesture generation method by emphasizing the semantic consistency of salient\nposture. Specifically, we first learn a joint manifold space for the individual\nrepresentation of audio and body pose to exploit the inherent semantic\nassociation between two modalities, and propose to enforce semantic consistency\nvia a consistency loss. Furthermore, we emphasize the semantic consistency of\nsalient postures by introducing a weakly-supervised detector to identify\nsalient postures, and reweighting the consistency loss to focus more on\nlearning the correspondence between salient postures and the high-level\nsemantics of speech content. In addition, we propose to extract audio features\ndedicated to facial expression and body gesture separately, and design separate\nbranches for face and body gesture synthesis. Extensive experimental results\ndemonstrate the superiority of our method over the state-of-the-art approaches.",
    "pdf_url": "http://arxiv.org/pdf/2410.13786v1",
    "published": "2024-10-17T17:22:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13785v1",
    "title": "PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment",
    "authors": [
      "Zekun Moore Wang",
      "Shawn Wang",
      "Kang Zhu",
      "Jiaheng Liu",
      "Ke Xu",
      "Jie Fu",
      "Wangchunshu Zhou",
      "Wenhao Huang"
    ],
    "abstract": "Alignment of large language models (LLMs) involves training models on\npreference-contrastive output pairs to adjust their responses according to\nhuman preferences. To obtain such contrastive pairs, traditional methods like\nRLHF and RLAIF rely on limited contrasting patterns, such as varying model\nvariants or decoding temperatures. This singularity leads to two issues: (1)\nalignment is not comprehensive; and thereby (2) models are susceptible to\njailbreaking attacks. To address these issues, we investigate how to construct\nmore comprehensive and diversified contrasting patterns to enhance preference\ndata (RQ1) and verify the impact of the diversification of contrasting patterns\non model alignment (RQ2). For RQ1, we propose PopAlign, a framework that\nintegrates diversified contrasting patterns across the prompt, model, and\npipeline levels, introducing six contrasting strategies that do not require\nadditional feedback labeling procedures. Regarding RQ2, we conduct thorough\nexperiments demonstrating that PopAlign significantly outperforms existing\nmethods, leading to more comprehensive alignment.",
    "pdf_url": "http://arxiv.org/pdf/2410.13785v1",
    "published": "2024-10-17T17:22:05+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13784v2",
    "title": "An Exposition of Pathfinding Strategies Within Lightning Network Clients",
    "authors": [
      "Sindura Saraswathi",
      "Christian Kümmerle"
    ],
    "abstract": "The Lightning Network is a peer-to-peer network designed to address Bitcoin's\nscalability challenges, facilitating rapid, cost-effective, and instantaneous\ntransactions through bidirectional, blockchain-backed payment channels among\nnetwork peers. Due to a source-based routing of payments, different pathfinding\nstrategies are used in practice, trading off different objectives for each\nother such as payment reliability and routing fees. This paper explores\ndifferences within pathfinding strategies used by prominent Lightning Network\nnode implementations, which include different underlying cost functions and\ndifferent constraints, as well as different greedy algorithms of shortest\npath-type. Surprisingly, we observe that the pathfinding problems that most LN\nnode implementations attempt to solve are NP-complete, and cannot be guaranteed\nto be optimally solved by the variants of Dijkstra's algorithm currently\ndeployed in production. Through comparative analysis and simulations, we\nevaluate efficacy of different pathfinding strategies across metrics such as\nsuccess rate, fees, path length, and timelock. Our experiments indicate that\nthe strategies used by Eclair are advantageous in terms of payment reliability\nand result in paths with low fees. LND exhibits moderate success rates, while\nLDK results in paths with higher fee levels for smaller payment amounts;\nfurthermore, CLN stands out for its minimal timelock paths. Additionally, we\ninvestigate the impact of Lightning node connectivity levels on routing\nefficiency. The findings of our analysis provide insights towards future\nimprovements of pathfinding strategies and algorithms used within the Lightning\nNetwork.",
    "pdf_url": "http://arxiv.org/pdf/2410.13784v2",
    "published": "2024-10-17T17:21:45+00:00",
    "categories": [
      "cs.NI",
      "cs.CE",
      "cs.CR",
      "cs.SI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13783v1",
    "title": "Quantity vs. Quality of Monolingual Source Data in Automatic Text Translation: Can It Be Too Little If It Is Too Good?",
    "authors": [
      "Idris Abdulmumin",
      "Bashir Shehu Galadanci",
      "Garba Aliyu",
      "Shamsuddeen Hassan Muhammad"
    ],
    "abstract": "Monolingual data, being readily available in large quantities, has been used\nto upscale the scarcely available parallel data to train better models for\nautomatic translation. Self-learning, where a model is made to learn from its\noutput, is one approach to exploit such data. However, it has been shown that\ntoo much of this data can be detrimental to the performance of the model if the\navailable parallel data is comparatively extremely low. In this study, we\ninvestigate whether the monolingual data can also be too little and if this\nreduction, based on quality, has any effect on the performance of the\ntranslation model. Experiments have shown that on English-German low-resource\nNMT, it is often better to select only the most useful additional data, based\non quality or closeness to the domain of the test data, than utilizing all of\nthe available data.",
    "pdf_url": "http://arxiv.org/pdf/2410.13783v1",
    "published": "2024-10-17T17:20:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13782v1",
    "title": "DPLM-2: A Multimodal Diffusion Protein Language Model",
    "authors": [
      "Xinyou Wang",
      "Zaixiang Zheng",
      "Fei Ye",
      "Dongyu Xue",
      "Shujian Huang",
      "Quanquan Gu"
    ],
    "abstract": "Proteins are essential macromolecules defined by their amino acid sequences,\nwhich determine their three-dimensional structures and, consequently, their\nfunctions in all living organisms. Therefore, generative protein modeling\nnecessitates a multimodal approach to simultaneously model, understand, and\ngenerate both sequences and structures. However, existing methods typically use\nseparate models for each modality, limiting their ability to capture the\nintricate relationships between sequence and structure. This results in\nsuboptimal performance in tasks that requires joint understanding and\ngeneration of both modalities. In this paper, we introduce DPLM-2, a multimodal\nprotein foundation model that extends discrete diffusion protein language model\n(DPLM) to accommodate both sequences and structures. To enable structural\nlearning with the language model, 3D coordinates are converted to discrete\ntokens using a lookup-free quantization-based tokenizer. By training on both\nexperimental and high-quality synthetic structures, DPLM-2 learns the joint\ndistribution of sequence and structure, as well as their marginals and\nconditionals. We also implement an efficient warm-up strategy to exploit the\nconnection between large-scale evolutionary data and structural inductive\nbiases from pre-trained sequence-based protein language models. Empirical\nevaluation shows that DPLM-2 can simultaneously generate highly compatible\namino acid sequences and their corresponding 3D structures eliminating the need\nfor a two-stage generation approach. Moreover, DPLM-2 demonstrates competitive\nperformance in various conditional generation tasks, including folding, inverse\nfolding, and scaffolding with multimodal motif inputs, as well as providing\nstructure-aware representations for predictive tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13782v1",
    "published": "2024-10-17T17:20:24+00:00",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13781v2",
    "title": "Azimuthal modulation in light-by-light scattering from ultraperipheral collisions at LHC",
    "authors": [
      "Yu Jia",
      "Shuo Lin",
      "Jian Zhou",
      "Ya-jin Zhou"
    ],
    "abstract": "Elastic light-by-light(LbL) scattering, one of the most fascinating processes\nin the Standard Model(SM), has recently been observed in the ultraperipheral\ncollisions(UPCs) of relativistic heavy ions in the Atlas and CMS experiments at\nthe Large Hadron Collider LHC. Recognizing that the incident quasi-real photons\nin LbL scattering are strongly linearly polarized, we re-investigate the LbL\nscattering in UPCs by incorporating the joint dependence of the impact\nparameter and transverse momenta of the incident photons. We show that the\nlinear polarization of incident photons generates a sizable $\\cos2\\phi$-type\nazimuthal modulation, which awaits the test in future LHC and EIC experiments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13781v2",
    "published": "2024-10-17T17:20:09+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13780v2",
    "title": "Optimal Quantization for Matrix Multiplication",
    "authors": [
      "Or Ordentlich",
      "Yury Polyanskiy"
    ],
    "abstract": "Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|\\bar{A}\\|_F, \\|\\bar{B}\\|_F$ and\n$\\|\\bar{A}^\\top \\bar{B}\\|_F$, where $\\bar{A},\\bar{B}$ are versions of $A,B$\nwith zero-centered columns, respectively. For iid Gaussian matrices our\nquantizer achieves the lower bound and is, thus, asymptotically optimal. A\npractical low-complexity version of our quantizer achieves performance quite\nclose to optimal. In addition, we derive rate-distortion function for matrix\nmultiplication of iid Gaussian matrices, which exhibits an interesting\nphase-transition at $R\\approx 0.906$ bit/entry.",
    "pdf_url": "http://arxiv.org/pdf/2410.13780v2",
    "published": "2024-10-17T17:19:48+00:00",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13779v2",
    "title": "The Mystery of the Pathological Path-star Task for Language Models",
    "authors": [
      "Arvid Frydenlund"
    ],
    "abstract": "The recently introduced path-star task is a minimal task designed to\nexemplify limitations to the abilities of language models (Bachmann and\nNagarajan, 2024). It involves a path-star graph where multiple arms radiate\nfrom a single starting node and each node is unique. Given the start node and a\nspecified target node that ends an arm, the task is to generate the arm\ncontaining that target node. This is straightforward for a human but\nsurprisingly difficult for language models, which did not outperform the random\nbaseline. The authors hypothesized this is due to a deficiency in\nteacher-forcing and the next-token prediction paradigm.\n  We demonstrate the task is learnable using teacher-forcing in alternative\nsettings and that the issue is partially due to representation. We introduce a\nregularization method using structured samples of the same graph but with\ndiffering target nodes, improving results across a variety of model types. We\nprovide RASP proofs showing the task is theoretically solvable. Finally, we\nfind settings where an encoder-only model can consistently solve the task.",
    "pdf_url": "http://arxiv.org/pdf/2410.13779v2",
    "published": "2024-10-17T17:18:30+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13778v1",
    "title": "Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree",
    "authors": [
      "Michelangelo Olmo Nogara Notarianni",
      "Filippo Leveni",
      "Diego Stucchi",
      "Luca Frittoli",
      "Giacomo Boracchi"
    ],
    "abstract": "We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13778v1",
    "published": "2024-10-17T17:17:38+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13569v3",
    "title": "Learning on Model Weights using Tree Experts",
    "authors": [
      "Eliahu Horwitz",
      "Bar Cavia",
      "Jonathan Kahana",
      "Yedid Hoshen"
    ],
    "abstract": "The number of publicly available models is rapidly increasing, yet most\nremain undocumented. Users looking for suitable models for their tasks must\nfirst determine what each model does. Training machine learning models to infer\nmissing documentation directly from model weights is challenging, as these\nweights often contain significant variation unrelated to model functionality\n(denoted nuisance). Here, we identify a key property of real-world models: most\npublic models belong to a small set of Model Trees, where all models within a\ntree are fine-tuned from a common ancestor (e.g., a foundation model).\nImportantly, we find that within each tree there is less nuisance variation\nbetween models. Concretely, while learning across Model Trees requires complex\narchitectures, even a linear classifier trained on a single model layer often\nworks within trees. While effective, these linear classifiers are\ncomputationally expensive, especially when dealing with larger models that have\nmany parameters. To address this, we introduce Probing Experts (ProbeX), a\ntheoretically motivated and lightweight method. Notably, ProbeX is the first\nprobing method specifically designed to learn from the weights of a single\nhidden model layer. We demonstrate the effectiveness of ProbeX by predicting\nthe categories in a model's training dataset based only on its weights.\nExcitingly, ProbeX can map the weights of Stable Diffusion into a\nweight-language embedding space, enabling model search via text, i.e.,\nzero-shot model classification.",
    "pdf_url": "http://arxiv.org/pdf/2410.13569v3",
    "published": "2024-10-17T17:17:09+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13777v2",
    "title": "Deformational spectral rigidity of axially-symmetric symplectic billiards",
    "authors": [
      "Corentin Fierobe",
      "Alfonso Sorrentino",
      "Amir Vig"
    ],
    "abstract": "Symplectic billiards were introduced by Albers and Tabachnikov as billiards\nin strictly convex bounded domains of the plane with smooth boundary having a\nspecific law of reflection. This paper proves a rigidity result for symplectic\nbilliards which is similar to a previous result on classical billiards\nformulated by De Simoi, Kaloshin and Wei. Namely, it states that close to an\nellipse, a sufficiently smooth one-parameter family of axially symmetric\ndomains either contains domains with different area-spectra or is trivial, in a\nsense that the domains differ by area-preserving affine transformations of the\nplane. The paper also prove that in the general setting - that is even if the\ndomains are not close to an ellipse - any sufficiently smooth one-parameter\nfamily of axially symmetric domains which preserves the area-spectrum is\ntangent to a finite dimensionnal space.",
    "pdf_url": "http://arxiv.org/pdf/2410.13777v2",
    "published": "2024-10-17T17:16:49+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13776v4",
    "title": "Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors",
    "authors": [
      "Georgios Chochlakis",
      "Alexandros Potamianos",
      "Kristina Lerman",
      "Shrikanth Narayanan"
    ],
    "abstract": "In-context Learning (ICL) has become the primary method for performing\nnatural language tasks with Large Language Models (LLMs). The knowledge\nacquired during pre-training is crucial for this few-shot capability, providing\nthe model with task priors. However, recent studies have shown that ICL\npredominantly relies on retrieving task priors rather than \"learning\" to\nperform tasks. This limitation is particularly evident in complex subjective\ndomains such as emotion and morality, where priors significantly influence\nposterior predictions. In this work, we examine whether this is the result of\nthe aggregation used in corresponding datasets, where trying to combine\nlow-agreement, disparate annotations might lead to annotation artifacts that\ncreate detrimental noise in the prompt. Moreover, we evaluate the posterior\nbias towards certain annotators by grounding our study in appropriate,\nquantitative measures of LLM priors. Our results indicate that aggregation is a\nconfounding factor in the modeling of subjective tasks, and advocate focusing\non modeling individuals instead. However, aggregation does not explain the\nentire gap between ICL and the state of the art, meaning other factors in such\ntasks also account for the observed phenomena. Finally, by rigorously studying\nannotator-level labels, we find that it is possible for minority annotators to\nboth better align with LLMs and have their perspectives further amplified.",
    "pdf_url": "http://arxiv.org/pdf/2410.13776v4",
    "published": "2024-10-17T17:16:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13775v2",
    "title": "Possible $D_{1}D_{1}$, $D_{1} \\bar D_{1} $, $B_{1}B_{1}$ and $B_{1} \\bar B_{1} $ molecular states and the recoil corrections",
    "authors": [
      "Xiao Chen",
      "Li Ma"
    ],
    "abstract": "Recoil correction appears at $O(\\frac{1}{M})$, which turns out to be very\nessential for the hadronic molecules with heavy flavor. In the past, we always\nthought that the recoil corrections were unfavorable to the formation of the\nmolecular states, but our research reveals its importance to form the di-hadron\nbound states. In some cases, we are unable to find the bound states without\nconsidering the recoil corrections. Under SU(2) chiral symmetry, we have\nstudied the $D_1 D_1$, $D_1 \\bar D_1$, $B_1 B_1$ and $B_1 \\bar B_1$ systems in\nthe framework of the one-boson exchange (OBE) model with the treatments of the\n$S$\\--{}$D$ wave mixing effect and the recoil corrections. Our results indicate\nthat both the $D_1 D_1$ system with $I(J^P)=0(1^+)$ and $I(J^P)=1(2^+)$ can\nform the molecular states whether with the recoil corrections or not, while the\n$D_1 D_1$ system with $I(J^P)=1(0^+)$ fail to form a hadronic molecule without\nthe recoil corrections but it turns out to be a loosely bound state after the\ninclusion of the recoil corrections. And we have found the deuteron-like states\nfor the $D_1 \\bar D_1$, $B_1 B_1$ and $B_1 \\bar B_1$ systems, whether\nconsidering the recoil corrections or not.",
    "pdf_url": "http://arxiv.org/pdf/2410.13775v2",
    "published": "2024-10-17T17:14:24+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13774v1",
    "title": "Physically Recurrent Neural Networks for Computational Homogenization of Composite Materials with Microscale Debonding",
    "authors": [
      "N. Kovács",
      "M. A. Maia",
      "I. B. C. M. Rocha",
      "C. Furtado",
      "P. P. Camanho",
      "F. P. van der Meer"
    ],
    "abstract": "The growing use of composite materials in engineering applications has\naccelerated the demand for computational methods to accurately predict their\ncomplex behavior. Multiscale modeling based on computational homogenization is\na potentially powerful approach for this purpose, but its widespread adoption\nis prevented by its excessive computational costs. A popular approach to\naddress this computational bottleneck is using surrogate models, which have\nbeen used to successfully predict a wide range of constitutive behaviors.\nHowever, applications involving microscale damage and fracture remain largely\nunexplored. This work aims to extend a recent surrogate modeling approach, the\nPhysically Recurrent Neural Network (PRNN), to include the effect of debonding\nat the fiber-matrix interface while capturing path-dependent behavior. The core\nidea of the PRNN is to implement the exact material models from the micromodel\ninto one of the layers of the network. In this work, additional material points\nwith a cohesive zone model are integrated within the network, along with the\nbulk points associated to the fibers and/or matrix. The limitations of the\nexisting architecture are discussed and taken into account for the development\nof novel architectures that better represent the stress homogenization\nprocedure. In the proposed layout, the history variables of cohesive points act\nas extra latent features that help determine the local strains of bulk points.\nDifferent architectures are evaluated starting with small training datasets. To\nmaximize the predictive accuracy and extrapolation capabilities of the network,\nvarious configurations of bulk and cohesive points are explored, along with\ndifferent training dataset types and sizes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13774v1",
    "published": "2024-10-17T17:12:39+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13773v2",
    "title": "Enhancing Retail Sales Forecasting with Optimized Machine Learning Models",
    "authors": [
      "Priyam Ganguly",
      "Isha Mukherjee"
    ],
    "abstract": "In retail sales forecasting, accurately predicting future sales is crucial\nfor inventory management and strategic planning. Traditional methods like LR\noften fall short due to the complexity of sales data, which includes\nseasonality and numerous product families. Recent advancements in machine\nlearning (ML) provide more robust alternatives. This research benefits from the\npower of ML, particularly Random Forest (RF), Gradient Boosting (GB), Support\nVector Regression (SVR), and XGBoost, to improve prediction accuracy. Despite\nadvancements, a significant gap exists in handling complex datasets with high\nseasonality and multiple product families. The proposed solution involves\nimplementing and optimizing a RF model, leveraging hyperparameter tuning\nthrough randomized search cross-validation. This approach addresses the\ncomplexities of the dataset, capturing intricate patterns that traditional\nmethods miss. The optimized RF model achieved an R-squared value of 0.945,\nsubstantially higher than the initial RF model and traditional LR, which had an\nR-squared of 0.531. The model reduced the root mean squared logarithmic error\n(RMSLE) to 1.172, demonstrating its superior predictive capability. The\noptimized RF model did better than cutting-edge models like Gradient Boosting\n(R-squared: 0.942), SVR (R-squared: 0.940), and XGBoost (R-squared: 0.939),\nwith more minor mean squared error (MSE) and mean absolute error (MAE) numbers.\nThe results demonstrate that the optimized RF model excels in forecasting\nretail sales, handling the datasets complexity with higher accuracy and\nreliability. This research highlights the importance of advanced ML techniques\nin predictive analytics, offering a significant improvement over traditional\nmethods and other contemporary models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13773v2",
    "published": "2024-10-17T17:11:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13772v2",
    "title": "Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?",
    "authors": [
      "Argyrios Gerogiannis",
      "Yu-Han Huang",
      "Venugopal V. Veeravalli"
    ],
    "abstract": "We study the problem of Non-Stationary Reinforcement Learning (NS-RL) without\nprior knowledge about the system's non-stationarity. A state-of-the-art,\nblack-box algorithm, known as MASTER, is considered, with a focus on\nidentifying the conditions under which it can achieve its stated goals.\nSpecifically, we prove that MASTER's non-stationarity detection mechanism is\nnot triggered for practical choices of horizon, leading to performance akin to\na random restarting algorithm. Moreover, we show that the regret bound for\nMASTER, while being order optimal, stays above the worst-case linear regret\nuntil unreasonably large values of the horizon. To validate these observations,\nMASTER is tested for the special case of piecewise stationary multi-armed\nbandits, along with methods that employ random restarting, and others that use\nquickest change detection to restart. A simple, order optimal random restarting\nalgorithm, that has prior knowledge of the non-stationarity is proposed as a\nbaseline. The behavior of the MASTER algorithm is validated in simulations, and\nit is shown that methods employing quickest change detection are more robust\nand consistently outperform MASTER and other random restarting approaches.",
    "pdf_url": "http://arxiv.org/pdf/2410.13772v2",
    "published": "2024-10-17T17:09:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13771v1",
    "title": "Conductance in graphene through double laser barriers and magnetic field",
    "authors": [
      "Rachid El Aitouni",
      "Miloud Mekkaoui",
      "Abdelhadi Bahaoui",
      "Ahmed Jellal"
    ],
    "abstract": "Photon-assisted charge transport through a double barrier laser structure,\nseparated by a region assisted by a magnetic field, is studied. Employing\nFloquet theory and matrix formalism, the transmission probabilities for the\ncentral band and sidebands are calculated. The temporal periodicity of the\nlaser fields creates an infinite number of transmission modes due to the\ndegeneracy of the energy spectrum. The challenge of numerically addressing all\nmodes necessitates the limitation to the first sideband corresponding to\nenergies $\\varepsilon\\pm\\varpi$. A critical phase difference between the two\nlaser fields is found to cancel the transmission through the sidebands due to\nquantum interference. Varying the width of the region where the magnetic field\nis applied allows for the suppression of lateral transmission and control over\nthe transmission mode. The intensity of the laser fields also allows for\nsuppressing Klein tunneling and blocking transmission processes with zero\nphoton exchange, as well as activating transmission processes with photon\nexchange. The conductance is also affected by changes in the system parameters.\nIncreasing the intensity of the laser field reduces the conductance due to the\nconfinement of the fermions by the laser fields. In addition, increasing the\nsize of the region where the magnetic field is applied reduces the conductance\nbecause the increased distance gives the fermions a greater chance of diffusion\nand increases their interaction with the magnetic field.",
    "pdf_url": "http://arxiv.org/pdf/2410.13771v1",
    "published": "2024-10-17T17:08:59+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13770v2",
    "title": "Probing the Latent Hierarchical Structure of Data via Diffusion Models",
    "authors": [
      "Antonio Sclocchi",
      "Alessandro Favero",
      "Noam Itzhak Levi",
      "Matthieu Wyart"
    ],
    "abstract": "High-dimensional data must be highly structured to be learnable. Although the\ncompositional and hierarchical nature of data is often put forward to explain\nlearnability, quantitative measurements establishing these properties are\nscarce. Likewise, accessing the latent variables underlying such a data\nstructure remains a challenge. In this work, we show that forward-backward\nexperiments in diffusion-based models, where data is noised and then denoised\nto generate new samples, are a promising tool to probe the latent structure of\ndata. We predict in simple hierarchical models that, in this process, changes\nin data occur by correlated chunks, with a length scale that diverges at a\nnoise level where a phase transition is known to take place. Remarkably, we\nconfirm this prediction in both text and image datasets using state-of-the-art\ndiffusion models. Our results show how latent variable changes manifest in the\ndata and establish how to measure these effects in real data using diffusion\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2410.13770v2",
    "published": "2024-10-17T17:08:39+00:00",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13769v3",
    "title": "Transformer Guided Coevolution: Improved Team Selection in Multiagent Adversarial Team Games",
    "authors": [
      "Pranav Rajbhandari",
      "Prithviraj Dasgupta",
      "Donald Sofge"
    ],
    "abstract": "We consider the problem of team selection within multiagent adversarial team\ngames. We propose BERTeam, a novel algorithm that uses a transformer-based deep\nneural network with Masked Language Model training to select the best team of\nplayers from a trained population. We integrate this with coevolutionary deep\nreinforcement learning, which trains a diverse set of individual players to\nchoose from. We test our algorithm in the multiagent adversarial game Marine\nCapture-The-Flag, and find that BERTeam learns non-trivial team compositions\nthat perform well against unseen opponents. For this game, we find that BERTeam\noutperforms MCAA, an algorithm that similarly optimizes team selection.",
    "pdf_url": "http://arxiv.org/pdf/2410.13769v3",
    "published": "2024-10-17T17:06:41+00:00",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.NE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13768v1",
    "title": "Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems",
    "authors": [
      "Alireza Ghafarollahi",
      "Markus J. Buehler"
    ],
    "abstract": "A multi-agent AI model is used to automate the discovery of new metallic\nalloys, integrating multimodal data and external knowledge including insights\nfrom physics via atomistic simulations. Our multi-agent system features three\nkey components: (a) a suite of LLMs responsible for tasks such as reasoning and\nplanning, (b) a group of AI agents with distinct roles and expertise that\ndynamically collaborate, and (c) a newly developed graph neural network (GNN)\nmodel for rapid retrieval of key physical properties. A set of LLM-driven AI\nagents collaborate to automate the exploration of the vast design space of\nMPEAs, guided by predictions from the GNN. We focus on the NbMoTa family of\nbody-centered cubic (bcc) alloys, modeled using an ML-based interatomic\npotential, and target two key properties: the Peierls barrier and solute/screw\ndislocation interaction energy. Our GNN model accurately predicts these\natomic-scale properties, providing a faster alternative to costly brute-force\ncalculations and reducing the computational burden on multi-agent systems for\nphysics retrieval. This AI system revolutionizes materials discovery by\nreducing reliance on human expertise and overcoming the limitations of direct\nall-atom simulations. By synergizing the predictive power of GNNs with the\ndynamic collaboration of LLM-based agents, the system autonomously navigates\nvast alloy design spaces, identifying trends in atomic-scale material\nproperties and predicting macro-scale mechanical strength, as demonstrated by\nseveral computational experiments. This approach accelerates the discovery of\nadvanced alloys and holds promise for broader applications in other complex\nsystems, marking a significant step forward in automated materials design.",
    "pdf_url": "http://arxiv.org/pdf/2410.13768v1",
    "published": "2024-10-17T17:06:26+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.dis-nn",
      "cond-mat.mes-hall",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13767v3",
    "title": "Inpatient Overflow Management with Proximal Policy Optimization",
    "authors": [
      "Jingjing Sun",
      "Jim Dai",
      "Pengyi Shi"
    ],
    "abstract": "Overflowing patients to non-primary wards can effectively alleviate\ncongestion in hospitals, while undesired overflow also leads to issues like\nmismatched service quality. Therefore, we need to trade off between congestion\nand undesired overflow. This overflow management problem is modeled as a\ndiscrete-time Markov Decision Process with large state and action space. To\novercome the curse-of-dimensionality, we decompose the action at each time into\na sequence of atomic actions and use an actor-critic algorithm, Proximal Policy\nOptimization (PPO), to guide the atomic actions. Moreover, we tailor the design\nof neural network which represents policy to account for the daily periodic\npattern of the system flows. Under hospital settings of different scales, the\nPPO policies consistently outperform commonly used state-of-art policies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13767v3",
    "published": "2024-10-17T17:04:08+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13766v3",
    "title": "Stable functions and Følner's Theorem",
    "authors": [
      "Gabriel Conant"
    ],
    "abstract": "We show that if $G$ is an amenable group and $A\\subseteq G$ has positive\nupper Banach density, then there is an identity neighborhood $B$ in the Bohr\ntopology on $G$ that is almost contained in $AA^{-1}$ in the sense that\n$B\\backslash AA^{-1}$ has upper Banach density $0$. This generalizes the\nabelian case (due to F{\\o}lner) and the countable case (due to Beiglb\\\"{o}ck,\nBergelson, and Fish). The proof is indirectly based on local stable group\ntheory in continuous logic. The main ingredients are Grothendieck's\ndouble-limit characterization of relatively weakly compact sets in spaces of\ncontinuous functions, along with results of Ellis and Nerurkar on the\ntopological dynamics of weakly almost periodic flows.",
    "pdf_url": "http://arxiv.org/pdf/2410.13766v3",
    "published": "2024-10-17T17:03:44+00:00",
    "categories": [
      "math.DS",
      "math.CO",
      "math.GR",
      "math.LO"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13765v2",
    "title": "Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval",
    "authors": [
      "Yu Xia",
      "Junda Wu",
      "Sungchul Kim",
      "Tong Yu",
      "Ryan A. Rossi",
      "Haoliang Wang",
      "Julian McAuley"
    ],
    "abstract": "Large language models (LLMs) have been used to generate query expansions\naugmenting original queries for improving information search. Recent studies\nalso explore providing LLMs with initial retrieval results to generate query\nexpansions more grounded to document corpus. However, these methods mostly\nfocus on enhancing textual similarities between search queries and target\ndocuments, overlooking document relations. For queries like \"Find me a highly\nrated camera for wildlife photography compatible with my Nikon F-Mount lenses\",\nexisting methods may generate expansions that are semantically similar but\nstructurally unrelated to user intents. To handle such semi-structured queries\nwith both textual and relational requirements, in this paper we propose a\nknowledge-aware query expansion framework, augmenting LLMs with structured\ndocument relations from knowledge graph (KG). To further address the limitation\nof entity-based scoring in existing KG-based methods, we leverage document\ntexts as rich KG node representations and use document-based relation filtering\nfor our Knowledge-Aware Retrieval (KAR). Extensive experiments on three\ndatasets of diverse domains show the advantages of our method compared against\nstate-of-the-art baselines on textual and relational semi-structured retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2410.13765v2",
    "published": "2024-10-17T17:03:23+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13764v2",
    "title": "A Simple Parametrisation of the Pion Form Factor",
    "authors": [
      "Matthew Kirk",
      "Bastian Kubis",
      "Méril Reboud",
      "Danny van Dyk"
    ],
    "abstract": "We discuss a novel and simple parametrisation of the pion vector form factor\nthat transparently connects spacelike and timelike regions of the momentum\ntransfer $q^2$. Our parametrisation employs the framework of conformal mapping\nand respects the known analyticity properties of the form factor, accounting\nexplicitly for the $\\rho(770)$-meson pole. The parametrisation manifestly\nfulfils the normalisation condition at $q^2 = 0$ as well as further\nrestrictions at the pion production threshold and in the limit $|q^2| \\to\n\\infty$. In contrast to the widely used Omn\\`es parametrisation, our approach\ndoes not use the pion-pion scattering phase shift as input. We confront the\nparametrisation with experimental data from $\\pi H$ scattering and $\\tau^- \\to\n\\pi^-\\pi^0\\nu$ decay. We already find a good description of the data with only\nfive free parameters, which include the pole mass and decay width of the\n$\\rho(770)$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13764v2",
    "published": "2024-10-17T16:59:59+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-lat"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.14745v2",
    "title": "Semi-supervised Fine-tuning for Large Language Models",
    "authors": [
      "Junyu Luo",
      "Xiao Luo",
      "Xiusi Chen",
      "Zhiping Xiao",
      "Wei Ju",
      "Ming Zhang"
    ],
    "abstract": "Supervised fine-tuning (SFT) is crucial in adapting large language model\n(LLMs) to a specific domain or task. However, only a limited amount of labeled\ndata is available in practical applications, which poses a severe challenge for\nSFT in yielding satisfactory results. Therefore, a data-efficient framework\nthat can fully exploit labeled and unlabeled data for LLM fine-tuning is highly\nanticipated.Towards this end, we introduce a semi-supervised\nfine-tuning(SemiFT) task and a framework named SemiEvol for LLM alignment from\na propagate-and-select manner. For knowledge propagation, SemiEvol adopts a\nbi-level approach, propagating knowledge from labeled data to unlabeled data\nthrough both in-weight and in-context methods. For knowledge selection,\nSemiEvol incorporates a collaborative learning mechanism, selecting\nhigher-quality pseudo-response samples. We conducted experiments using\nGPT-4o-mini and Llama-3.1 on seven general or domain-specific datasets,\ndemonstrating significant improvements in model performance on target data.\nFurthermore, we compared SemiEvol with SFT and self-evolution methods,\nhighlighting its practicality in hybrid data scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2410.14745v2",
    "published": "2024-10-17T16:59:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13763v4",
    "title": "Assessing the Optimistic Bias in the Natural Inflow Forecasts: A Call for Model Monitoring in Brazil",
    "authors": [
      "Arthur Brigatto",
      "Alexandre Street",
      "Cristiano Fernandes",
      "Davi Valladao",
      "Guilherme Bodin",
      "Joaquim Dias Garcia"
    ],
    "abstract": "Hydroelectricity accounted for roughly 61.4% of Brazil's total generation in\n2024 and addressed most of the intermittency of wind and solar generation.\nThus, inflow forecasting plays a critical role in the operation, planning, and\nmarket in this country, as well as in any other hydro-dependent power system.\nThese forecasts influence generation schedules, reservoir management, and\nmarket pricing, shaping the dynamics of the entire electricity sector. The\nobjective of this paper is to measure and present empirical evidence of a\nsystematic optimistic bias in the official inflow forecast methodology, which\nis based on the PAR(p)-A model. Additionally, we discuss possible sources of\nthis bias and recommend ways to mitigate it. By analyzing 14 years of\nhistorical data from the Brazilian system through rolling-window multistep\n(out-of-sample) forecasts, results indicate that the official forecast model\nexhibits statistically significant biases of 1.28, 3.83, 5.39, and 6.73 average\nGW for 1-, 6-, 12-, and 24-step-ahead forecasts in the Southeast subsystem, and\n0.54, 1.66, 2.32, and 3.17 average GW in the Northeast subsystem. These\nfindings uncover the limitations of current inflow forecasting methodologies\nused in Brazil and call for new governance and monitoring policies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13763v4",
    "published": "2024-10-17T16:59:07+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "stat.AP"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13762v2",
    "title": "Virtual Sensing-Enabled Digital Twin Framework for Real-Time Monitoring of Nuclear Systems Leveraging Deep Neural Operators",
    "authors": [
      "Raisa Bentay Hossain",
      "Farid Ahmed",
      "Kazuma Kobayashi",
      "Seid Koric",
      "Diab Abueidda",
      "Syed Bahauddin Alam"
    ],
    "abstract": "Effective real-time monitoring is a foundation of digital twin technology,\ncrucial for detecting material degradation and maintaining the structural\nintegrity of nuclear systems to ensure both safety and operational efficiency.\nTraditional physical sensor systems face limitations such as installation\nchallenges, high costs, and difficulty measuring critical parameters in\nhard-to-reach or harsh environments, often resulting in incomplete data\ncoverage. Machine learning-driven virtual sensors, integrated within a digital\ntwin framework, offer a transformative solution by enhancing physical sensor\ncapabilities to monitor critical degradation indicators like pressure,\nvelocity, and turbulence. However, conventional machine learning models\nstruggle with real-time monitoring due to the high-dimensional nature of\nreactor data and the need for frequent retraining. This paper introduces the\nuse of Deep Operator Networks (DeepONet) as a core component of a digital twin\nframework to predict key thermal-hydraulic parameters in the hot leg of an\nAP-1000 Pressurized Water Reactor (PWR). DeepONet serves as a dynamic and\nscalable virtual sensor by accurately mapping the interplay between operational\ninput parameters and spatially distributed system behaviors. In this study,\nDeepONet is trained with different operational conditions, which relaxes the\nrequirement of continuous retraining, making it suitable for online and\nreal-time prediction components for digital twin. Our results show that\nDeepONet achieves accurate predictions with low mean squared error and relative\nL2 error and can make predictions on unknown data 1400 times faster than\ntraditional CFD simulations. This speed and accuracy enable DeepONet to\nsynchronize with the physical system in real-time, functioning as a dynamic\nvirtual sensor that tracks degradation-contributing conditions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13762v2",
    "published": "2024-10-17T16:56:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13761v1",
    "title": "GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning",
    "authors": [
      "Guibin Zhang",
      "Haonan Dong",
      "Yuchen Zhang",
      "Zhixun Li",
      "Dingshuo Chen",
      "Kai Wang",
      "Tianlong Chen",
      "Yuxuan Liang",
      "Dawei Cheng",
      "Kun Wang"
    ],
    "abstract": "Training high-quality deep models necessitates vast amounts of data,\nresulting in overwhelming computational and memory demands. Recently, data\npruning, distillation, and coreset selection have been developed to streamline\ndata volume by retaining, synthesizing, or selecting a small yet informative\nsubset from the full set. Among these methods, data pruning incurs the least\nadditional training cost and offers the most practical acceleration benefits.\nHowever, it is the most vulnerable, often suffering significant performance\ndegradation with imbalanced or biased data schema, thus raising concerns about\nits accuracy and reliability in on-device deployment. Therefore, there is a\nlooming need for a new data pruning paradigm that maintains the efficiency of\nprevious practices while ensuring balance and robustness. Unlike the fields of\ncomputer vision and natural language processing, where mature solutions have\nbeen developed to address these issues, graph neural networks (GNNs) continue\nto struggle with increasingly large-scale, imbalanced, and noisy datasets,\nlacking a unified dataset pruning solution. To achieve this, we introduce a\nnovel dynamic soft-pruning method, GDeR, designed to update the training\n``basket'' during the process using trainable prototypes. GDeR first constructs\na well-modeled graph embedding hypersphere and then samples\n\\textit{representative, balanced, and unbiased subsets} from this embedding\nspace, which achieves the goal we called Graph Training Debugging. Extensive\nexperiments on five datasets across three GNN backbones, demonstrate that GDeR\n(I) achieves or surpasses the performance of the full dataset with 30%~50%\nfewer training samples, (II) attains up to a 2.81x lossless training speedup,\nand (III) outperforms state-of-the-art pruning methods in imbalanced training\nand noisy training scenarios by 0.3%~4.3% and 3.6%~7.8%, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2410.13761v1",
    "published": "2024-10-17T16:56:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13760v1",
    "title": "Eyelid Fold Consistency in Facial Modeling",
    "authors": [
      "Lohit Petikam",
      "Charlie Hewitt",
      "Fatemeh Saleh",
      "Tadas Baltrušaitis"
    ],
    "abstract": "Eyelid shape is integral to identity and likeness in human facial modeling.\nHuman eyelids are diverse in appearance with varied skin fold and epicanthal\nfold morphology between individuals. Existing parametric face models express\neyelid shape variation to an extent, but do not preserve sufficient likeness\nacross a diverse range of individuals. We propose a new definition of eyelid\nfold consistency and implement geometric processing techniques to model diverse\neyelid shapes in a unified topology. Using this method we reprocess data used\nto train a parametric face model and demonstrate significant improvements in\nface-related machine learning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13760v1",
    "published": "2024-10-17T16:55:14+00:00",
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13758v2",
    "title": "On monochromatic solutions to linear equations over the integers",
    "authors": [
      "Dingding Dong",
      "Nitya Mani",
      "Huy Tuan Pham",
      "Jonathan Tidor"
    ],
    "abstract": "We study the number of monochromatic solutions to linear equations in a\n$2$-coloring of $\\{1,\\ldots,n\\}$. We show that any nontrivial linear equation\nhas a constant fraction of solutions that are monochromatic in any $2$-coloring\nof $\\{1,\\ldots,n\\}$. We further study commonness of four-term equations and\ndisprove a conjecture of Costello and Elvin by showing that, unlike over\n$\\mathbb{F}_p$, the four-term equation $x_1 + 2x_2 - x_3 - 2x_4 = 0$ is\nuncommon over $\\{1,\\ldots,n\\}$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13758v2",
    "published": "2024-10-17T16:54:41+00:00",
    "categories": [
      "math.CO",
      "05D40"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13759v2",
    "title": "On the practicality of quantum sieving algorithms for the shortest vector problem",
    "authors": [
      "Joao F. Doriguello",
      "George Giapitzakis",
      "Alessandro Luongo",
      "Aditya Morolia"
    ],
    "abstract": "One of the main candidates of post-quantum cryptography is lattice-based\ncryptography. Its cryptographic security against quantum attackers is based on\nthe worst-case hardness of lattice problems like the shortest vector problem\n(SVP), which asks to find the shortest non-zero vector in an integer lattice.\nAsymptotic quantum speedups for solving SVP are known and rely on Grover's\nsearch. However, to assess the security of lattice-based cryptography against\nthese Grover-like quantum speedups, it is necessary to carry out a precise\nresource estimation beyond asymptotic scalings. In this work, we perform a\ncareful analysis on the resources required to implement several sieving\nalgorithms aided by Grover's search for dimensions of cryptographic interests.\nFor such, we take into account fixed-point quantum arithmetic operations,\nnon-asymptotic Grover's search, the cost of using quantum random access memory\n(QRAM), different physical architectures, and quantum error correction. We find\nthat even under very optimistic assumptions like circuit-level noise of\n$10^{-5}$, code cycles of 100 ns, reaction time of 1 $\\mu$s, and using\nstate-of-the-art arithmetic circuits and quantum error-correction protocols,\nthe best sieving algorithms require $\\approx 10^{13}$ physical qubits and\n$\\approx 10^{31}$ years to solve SVP on a lattice of dimension 400, which is\nroughly the dimension for minimally secure post-quantum cryptographic standards\ncurrently being proposed by NIST. We estimate that a 6-GHz-clock-rate\nsingle-core classical computer would take roughly the same amount of time to\nsolve the same problem. We conclude that there is currently little to no\nquantum speedup in the dimensions of cryptographic interest and the possibility\nof realising a considerable quantum speedup using quantum sieving algorithms\nwould require significant breakthroughs in theoretical protocols and hardware\ndevelopment.",
    "pdf_url": "http://arxiv.org/pdf/2410.13759v2",
    "published": "2024-10-17T16:54:41+00:00",
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13757v3",
    "title": "MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation",
    "authors": [
      "Zichen Zhu",
      "Hao Tang",
      "Yansi Li",
      "Dingye Liu",
      "Hongshen Xu",
      "Kunyao Lan",
      "Danyang Zhang",
      "Yixuan Jiang",
      "Hao Zhou",
      "Chenrun Wang",
      "Situo Zhang",
      "Liangtai Sun",
      "Yixiao Wang",
      "Yuheng Sun",
      "Lu Chen",
      "Kai Yu"
    ],
    "abstract": "Existing Multimodal Large Language Model (MLLM)-based agents face significant\nchallenges in handling complex GUI (Graphical User Interface) interactions on\ndevices. These challenges arise from the dynamic and structured nature of GUI\nenvironments, which integrate text, images, and spatial relationships, as well\nas the variability in action spaces across different pages and tasks. To\naddress these limitations, we propose MobA, a novel MLLM-based mobile assistant\nsystem. MobA introduces an adaptive planning module that incorporates a\nreflection mechanism for error recovery and dynamically adjusts plans to align\nwith the real environment contexts and action module's execution capacity.\nAdditionally, a multifaceted memory module provides comprehensive memory\nsupport to enhance adaptability and efficiency. We also present MobBench, a\ndataset designed for complex mobile interactions. Experimental results on\nMobBench and AndroidArena demonstrate MobA's ability to handle dynamic GUI\nenvironments and perform complex mobile tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13757v3",
    "published": "2024-10-17T16:53:50+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13756v1",
    "title": "CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building",
    "authors": [
      "Walker Byrnes",
      "Miroslav Bogdanovic",
      "Avi Balakirsky",
      "Stephen Balakirsky",
      "Animesh Garg"
    ],
    "abstract": "Intelligent and reliable task planning is a core capability for generalized\nrobotics, requiring a descriptive domain representation that sufficiently\nmodels all object and state information for the scene. We present CLIMB, a\ncontinual learning framework for robot task planning that leverages foundation\nmodels and execution feedback to guide domain model construction. CLIMB can\nbuild a model from a natural language description, learn non-obvious predicates\nwhile solving tasks, and store that information for future problems. We\ndemonstrate the ability of CLIMB to improve performance in common planning\nenvironments compared to baseline methods. We also develop the BlocksWorld++\ndomain, a simulated environment with an easily usable real counterpart,\ntogether with a curriculum of tasks with progressing difficulty for evaluating\ncontinual learning. Additional details and demonstrations for this system can\nbe found at https://plan-with-climb.github.io/ .",
    "pdf_url": "http://arxiv.org/pdf/2410.13756v1",
    "published": "2024-10-17T16:53:43+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13755v1",
    "title": "Interacting humans and robots can improve sensory prediction by adapting their viscoelasticity",
    "authors": [
      "Xiaoxiao Cheng",
      "Jonathan Eden",
      "Bastien Berret",
      "Atsushi Takagi",
      "Etienne Burdet"
    ],
    "abstract": "To manipulate objects or dance together, humans and robots exchange energy\nand haptic information. While the exchange of energy in human-robot interaction\nhas been extensively investigated, the underlying exchange of haptic\ninformation is not well understood. Here, we develop a computational model of\nthe mechanical and sensory interactions between agents that can tune their\nviscoelasticity while considering their sensory and motor noise. The resulting\nstochastic-optimal-information-and-effort (SOIE) controller predicts how the\nexchange of haptic information and the performance can be improved by adjusting\nviscoelasticity. This controller was first implemented on a robot-robot\nexperiment with a tracking task which showed its superior performance when\ncompared to either stiff or compliant control. Importantly, the optimal\ncontroller also predicts how connected humans alter their muscle activation to\nimprove haptic communication, with differentiated viscoelasticity adjustment to\ntheir own sensing noise and haptic perturbations. A human-robot experiment then\nillustrated the applicability of this optimal control strategy for robots,\nyielding improved tracking performance and effective haptic communication as\nthe robot adjusted its viscoelasticity according to its own and the user's\nnoise characteristics. The proposed SOIE controller may thus be used to improve\nhaptic communication and collaboration of humans and robots.",
    "pdf_url": "http://arxiv.org/pdf/2410.13755v1",
    "published": "2024-10-17T16:53:37+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13754v2",
    "title": "MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures",
    "authors": [
      "Jinjie Ni",
      "Yifan Song",
      "Deepanway Ghosal",
      "Bo Li",
      "David Junhao Zhang",
      "Xiang Yue",
      "Fuzhao Xue",
      "Zian Zheng",
      "Kaichen Zhang",
      "Mahir Shah",
      "Kabir Jain",
      "Yang You",
      "Michael Shieh"
    ],
    "abstract": "Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any, real-world benchmark designed to optimize and\nstandardize evaluations across diverse input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions. Meanwhile, MixEval-X's model rankings correlate strongly with\nthat of crowd-sourced real-world evaluations (up to 0.98) while being much more\nefficient. We provide comprehensive leaderboards to rerank existing models and\norganizations and offer insights to enhance understanding of multi-modal\nevaluations and inform future research.",
    "pdf_url": "http://arxiv.org/pdf/2410.13754v2",
    "published": "2024-10-17T16:52:28+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13753v1",
    "title": "DPFedBank: Crafting a Privacy-Preserving Federated Learning Framework for Financial Institutions with Policy Pillars",
    "authors": [
      "Peilin He",
      "Chenkai Lin",
      "Isabella Montoya"
    ],
    "abstract": "In recent years, the financial sector has faced growing pressure to adopt\nadvanced machine learning models to derive valuable insights while preserving\ndata privacy. However, the highly sensitive nature of financial data presents\nsignificant challenges to sharing and collaboration. This paper presents\nDPFedBank, an innovative framework enabling financial institutions to\ncollaboratively develop machine learning models while ensuring robust data\nprivacy through Local Differential Privacy (LDP) mechanisms. DPFedBank is\ndesigned to address the unique privacy and security challenges associated with\nfinancial data, allowing institutions to share insights without exposing\nsensitive information. By leveraging LDP, the framework ensures that data\nremains confidential even during collaborative processes, providing a crucial\nsolution for privacy-aware machine learning in finance. We conducted an\nin-depth evaluation of the potential vulnerabilities within this framework and\ndeveloped a comprehensive set of policies aimed at mitigating these risks. The\nproposed policies effectively address threats posed by malicious clients,\ncompromised servers, inherent weaknesses in existing Differential\nPrivacy-Federated Learning (DP-FL) frameworks, and sophisticated external\nadversaries. Unlike existing DP-FL approaches, DPFedBank introduces a novel\ncombination of adaptive LDP mechanisms and advanced cryptographic techniques\nspecifically tailored for financial data, which significantly enhances privacy\nwhile maintaining model utility. Key security enhancements include the\nimplementation of advanced authentication protocols, encryption techniques for\nsecure data exchange, and continuous monitoring systems to detect and respond\nto malicious activities in real-time.",
    "pdf_url": "http://arxiv.org/pdf/2410.13753v1",
    "published": "2024-10-17T16:51:56+00:00",
    "categories": [
      "cs.CE",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13752v2",
    "title": "Privacy-Preserving Decentralized AI with Confidential Computing",
    "authors": [
      "Dayeol Lee",
      "Jorge António",
      "Hisham Khan"
    ],
    "abstract": "This paper addresses privacy protection in decentralized Artificial\nIntelligence (AI) using Confidential Computing (CC) within the Atoma Network, a\ndecentralized AI platform designed for the Web3 domain. Decentralized AI\ndistributes AI services among multiple entities without centralized oversight,\nfostering transparency and robustness. However, this structure introduces\nsignificant privacy challenges, as sensitive assets such as proprietary models\nand personal data may be exposed to untrusted participants. Cryptography-based\nprivacy protection techniques such as zero-knowledge machine learning (zkML)\nsuffers prohibitive computational overhead. To address the limitation, we\npropose leveraging Confidential Computing (CC). Confidential Computing\nleverages hardware-based Trusted Execution Environments (TEEs) to provide\nisolation for processing sensitive data, ensuring that both model parameters\nand user data remain secure, even in decentralized, potentially untrusted\nenvironments. While TEEs face a few limitations, we believe they can bridge the\nprivacy gap in decentralized AI. We explore how we can integrate TEEs into\nAtoma's decentralized framework.",
    "pdf_url": "http://arxiv.org/pdf/2410.13752v2",
    "published": "2024-10-17T16:50:48+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13751v1",
    "title": "Abundances of iron-peak elements in 58 bulge spheroid stars from APOGEE",
    "authors": [
      "B. Barbuy",
      "A. C. S. Friaça",
      "H. Ernandes",
      "P. da Silva",
      "S. O. Souza",
      "J. G. Fernández-Trincado",
      "K. Cunha",
      "V. V. Smith",
      "T. Masseron",
      "A. Pérez-Villegas",
      "C. Chiappini",
      "A. B. A. Queiroz",
      "B. X. Santiago",
      "T. C. Beers",
      "F. Anders",
      "R. P. Schiavon",
      "M. Valentini",
      "D. Minniti",
      "D. Geisler",
      "D. Souto",
      "V. M. Placco",
      "M. Zoccali",
      "S. Feltzing",
      "M. Schultheis",
      "C. Nitschelm"
    ],
    "abstract": "Stars presently identified in the bulge spheroid are probably very old, and\ntheir abundances can be interpreted as due to the fast chemical enrichment of\nthe early Galactic bulge. The abundances of the iron-peak elements are\nimportant tracers of nucleosynthesis processes, in particular oxygen burning,\nsilicon burning, the weak s-process, and alpha-rich freeze-out. Aims. The aim\nof this work is to derive the abundances of V, Cr, Mn, Co, Ni, and Cu in 58\nbulge spheroid stars and to compare them with the results of a previous\nanalysis of data from APOGEE. We selected the best lines for V, Cr, Mn, Co, Ni,\nand Cu located within the H-band of the spectrum, identifying the most suitable\nones for abundance determination, and discarding severe blends. Using the\nstellar physical parameters available for our sample from the DR17 release of\nthe APOGEE project, we derived the individual abundances through spectrum\nsynthesis. We then complemented these measurements with similar results from\ndifferent bulge field and globular cluster stars, in order to define the trends\nof the individual elements and compare with the results of chemical-evolution\nmodels. We verify that the H-band has useful lines for the derivation of the\nelements V, Cr, Mn, Co, Ni, and Cu in moderately metal-poor stars. The\nresulting abundances indicate that: V, Cr, and Ni vary in lockstep with Fe; Co\ntends to vary in lockstep with Fe, but could be showing a slight decrease with\ndecreasing metallicity; and Mn and Cu decrease with decreasing metallicity.\nThese behaviours are well reproduced by chemical-evolution models except for\nCu, which appears to drop faster than the models predict for moderate\nmetallicities. Finally, abundance indicators combined with kinematical and\ndynamical criteria appear to show that our 58 sample stars are likely to have\noriginated in situ.",
    "pdf_url": "http://arxiv.org/pdf/2410.13751v1",
    "published": "2024-10-17T16:50:13+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13750v2",
    "title": "On geometric properties of holomorphic isometries between bounded symmetric domains",
    "authors": [
      "Shan Tai Chan"
    ],
    "abstract": "We study holomorphic isometries between bounded symmetric domains with\nrespect to the Bergman metrics up to a normalizing constant. In particular, we\nfirst consider a holomorphic isometry from the complex unit ball into an\nirreducible bounded symmetric domain with respect to the Bergman metrics. In\nthis direction, we show that images of (nonempty) affine-linear sections of the\ncomplex unit ball must be the intersections of the image of the holomorphic\nisometry with certain affine-linear subspaces. We also construct a surjective\nholomorphic submersion from a certain subdomain of the target bounded symmetric\ndomain onto the complex unit ball such that the image of the holomorphic\nisometry lies inside the subdomain and the holomorphic isometry is a global\nholomorphic section of the holomorphic submersion. This construction could be\ngeneralized to any holomorphic isometry between bounded symmetric domains with\nrespect to the \\emph{canonical K\\\"ahler metrics}. Using some classical results\nfor complex-analytic subvarieties of Stein manifolds, we have obtained further\ngeometric results for images of such holomorphic isometries.",
    "pdf_url": "http://arxiv.org/pdf/2410.13750v2",
    "published": "2024-10-17T16:49:35+00:00",
    "categories": [
      "math.CV",
      "math.DG",
      "32M15, 53C55, 53C42"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13749v2",
    "title": "Supervised Kernel Thinning",
    "authors": [
      "Albert Gong",
      "Kyuseong Choi",
      "Raaz Dwivedi"
    ],
    "abstract": "The kernel thinning algorithm of Dwivedi & Mackey (2024) provides a\nbetter-than-i.i.d. compression of a generic set of points. By generating\nhigh-fidelity coresets of size significantly smaller than the input points, KT\nis known to speed up unsupervised tasks like Monte Carlo integration,\nuncertainty quantification, and non-parametric hypothesis testing, with minimal\nloss in statistical accuracy. In this work, we generalize the KT algorithm to\nspeed up supervised learning problems involving kernel methods. Specifically,\nwe combine two classical algorithms--Nadaraya-Watson (NW) regression or kernel\nsmoothing, and kernel ridge regression (KRR)--with KT to provide a quadratic\nspeed-up in both training and inference times. We show how distribution\ncompression with KT in each setting reduces to constructing an appropriate\nkernel, and introduce the Kernel-Thinned NW and Kernel-Thinned KRR estimators.\nWe prove that KT-based regression estimators enjoy significantly superior\ncomputational efficiency over the full-data estimators and improved statistical\nefficiency over i.i.d. subsampling of the training data. En route, we also\nprovide a novel multiplicative error guarantee for compressing with KT. We\nvalidate our design choices with both simulations and real data experiments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13749v2",
    "published": "2024-10-17T16:48:51+00:00",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13748v2",
    "title": "Test of lepton flavour universality with $B_s^0 \\rightarrow φ \\ell^+\\ell^-$ decays",
    "authors": [
      "LHCb collaboration",
      "R. Aaij",
      "A. S. W. Abdelmotteleb",
      "C. Abellan Beteta",
      "F. Abudinén",
      "T. Ackernley",
      "A. A. Adefisoye",
      "B. Adeva",
      "M. Adinolfi",
      "P. Adlarson",
      "C. Agapopoulou",
      "C. A. Aidala",
      "Z. Ajaltouni",
      "S. Akar",
      "K. Akiba",
      "P. Albicocco",
      "J. Albrecht",
      "F. Alessio",
      "M. Alexander",
      "Z. Aliouche",
      "P. Alvarez Cartelle",
      "R. Amalric",
      "S. Amato",
      "J. L. Amey",
      "Y. Amhis",
      "L. An",
      "L. Anderlini",
      "M. Andersson",
      "A. Andreianov",
      "P. Andreola",
      "M. Andreotti",
      "D. Andreou",
      "A. Anelli",
      "D. Ao",
      "F. Archilli",
      "M. Argenton",
      "S. Arguedas Cuendis",
      "A. Artamonov",
      "M. Artuso",
      "E. Aslanides",
      "R. Ataíde Da Silva",
      "M. Atzeni",
      "B. Audurier",
      "D. Bacher",
      "I. Bachiller Perea",
      "S. Bachmann",
      "M. Bachmayer",
      "J. J. Back",
      "P. Baladron Rodriguez",
      "V. Balagura",
      "A. Balboni",
      "W. Baldini",
      "L. Balzani",
      "H. Bao",
      "J. Baptista de Souza Leite",
      "C. Barbero Pretel",
      "M. Barbetti",
      "I. R. Barbosa",
      "R. J. Barlow",
      "M. Barnyakov",
      "S. Barsuk",
      "W. Barter",
      "M. Bartolini",
      "J. Bartz",
      "J. M. Basels",
      "S. Bashir",
      "G. Bassi",
      "B. Batsukh",
      "P. B. Battista",
      "A. Bay",
      "A. Beck",
      "M. Becker",
      "F. Bedeschi",
      "I. B. Bediaga",
      "N. A. Behling",
      "S. Belin",
      "V. Bellee",
      "K. Belous",
      "I. Belov",
      "I. Belyaev",
      "G. Benane",
      "G. Bencivenni",
      "E. Ben-Haim",
      "A. Berezhnoy",
      "R. Bernet",
      "S. Bernet Andres",
      "A. Bertolin",
      "C. Betancourt",
      "F. Betti",
      "J. Bex",
      "Ia. Bezshyiko",
      "J. Bhom",
      "M. S. Bieker",
      "N. V. Biesuz",
      "P. Billoir",
      "A. Biolchini",
      "M. Birch",
      "F. C. R. Bishop",
      "A. Bitadze",
      "A. Bizzeti",
      "T. Blake",
      "F. Blanc",
      "J. E. Blank",
      "S. Blusk",
      "V. Bocharnikov",
      "J. A. Boelhauve",
      "O. Boente Garcia",
      "T. Boettcher",
      "A. Bohare",
      "A. Boldyrev",
      "C. S. Bolognani",
      "R. Bolzonella",
      "R. B. Bonacci",
      "N. Bondar",
      "A. Bordelius",
      "F. Borgato",
      "S. Borghi",
      "M. Borsato",
      "J. T. Borsuk",
      "S. A. Bouchiba",
      "M. Bovill",
      "T. J. V. Bowcock",
      "A. Boyer",
      "C. Bozzi",
      "A. Brea Rodriguez",
      "N. Breer",
      "J. Brodzicka",
      "A. Brossa Gonzalo",
      "J. Brown",
      "D. Brundu",
      "E. Buchanan",
      "A. Buonaura",
      "L. Buonincontri",
      "A. T. Burke",
      "C. Burr",
      "J. S. Butter",
      "J. Buytaert",
      "W. Byczynski",
      "S. Cadeddu",
      "H. Cai",
      "A. C. Caillet",
      "R. Calabrese",
      "S. Calderon Ramirez",
      "L. Calefice",
      "S. Cali",
      "M. Calvi",
      "M. Calvo Gomez",
      "P. Camargo Magalhaes",
      "J. I. Cambon Bouzas",
      "P. Campana",
      "D. H. Campora Perez",
      "A. F. Campoverde Quezada",
      "S. Capelli",
      "L. Capriotti",
      "R. Caravaca-Mora",
      "A. Carbone",
      "L. Carcedo Salgado",
      "R. Cardinale",
      "A. Cardini",
      "P. Carniti",
      "L. Carus",
      "A. Casais Vidal",
      "R. Caspary",
      "G. Casse",
      "M. Cattaneo",
      "G. Cavallero",
      "V. Cavallini",
      "S. Celani",
      "D. Cervenkov",
      "S. Cesare",
      "A. J. Chadwick",
      "I. Chahrour",
      "M. Charles",
      "Ph. Charpentier",
      "E. Chatzianagnostou",
      "M. Chefdeville",
      "C. Chen",
      "S. Chen",
      "Z. Chen",
      "A. Chernov",
      "S. Chernyshenko",
      "X. Chiotopoulos",
      "V. Chobanova",
      "S. Cholak",
      "M. Chrzaszcz",
      "A. Chubykin",
      "V. Chulikov",
      "P. Ciambrone",
      "X. Cid Vidal",
      "G. Ciezarek",
      "P. Cifra",
      "P. E. L. Clarke",
      "M. Clemencic",
      "H. V. Cliff",
      "J. Closier",
      "C. Cocha Toapaxi",
      "V. Coco",
      "J. Cogan",
      "E. Cogneras",
      "L. Cojocariu",
      "P. Collins",
      "T. Colombo",
      "M. C. Colonna",
      "A. Comerma-Montells",
      "L. Congedo",
      "A. Contu",
      "N. Cooke",
      "I. Corredoira",
      "A. Correia",
      "G. Corti",
      "J. J. Cottee Meldrum",
      "B. Couturier",
      "D. C. Craik",
      "M. Cruz Torres",
      "E. Curras Rivera",
      "R. Currie",
      "C. L. Da Silva",
      "S. Dadabaev",
      "L. Dai",
      "X. Dai",
      "E. Dall'Occo",
      "J. Dalseno",
      "C. D'Ambrosio",
      "J. Daniel",
      "A. Danilina",
      "P. d'Argent",
      "A. Davidson",
      "J. E. Davies",
      "A. Davis",
      "O. De Aguiar Francisco",
      "C. De Angelis",
      "F. De Benedetti",
      "J. de Boer",
      "K. De Bruyn",
      "S. De Capua",
      "M. De Cian",
      "U. De Freitas Carneiro Da Graca",
      "E. De Lucia",
      "J. M. De Miranda",
      "L. De Paula",
      "M. De Serio",
      "P. De Simone",
      "F. De Vellis",
      "J. A. de Vries",
      "F. Debernardis",
      "D. Decamp",
      "V. Dedu",
      "S. Dekkers",
      "L. Del Buono",
      "B. Delaney",
      "H. -P. Dembinski",
      "J. Deng",
      "V. Denysenko",
      "O. Deschamps",
      "F. Dettori",
      "B. Dey",
      "P. Di Nezza",
      "I. Diachkov",
      "S. Didenko",
      "S. Ding",
      "L. Dittmann",
      "V. Dobishuk",
      "A. D. Docheva",
      "C. Dong",
      "A. M. Donohoe",
      "F. Dordei",
      "A. C. dos Reis",
      "A. D. Dowling",
      "W. Duan",
      "P. Duda",
      "M. W. Dudek",
      "L. Dufour",
      "V. Duk",
      "P. Durante",
      "M. M. Duras",
      "J. M. Durham",
      "O. D. Durmus",
      "A. Dziurda",
      "A. Dzyuba",
      "S. Easo",
      "E. Eckstein",
      "U. Egede",
      "A. Egorychev",
      "V. Egorychev",
      "S. Eisenhardt",
      "E. Ejopu",
      "L. Eklund",
      "M. Elashri",
      "J. Ellbracht",
      "S. Ely",
      "A. Ene",
      "J. Eschle",
      "S. Esen",
      "T. Evans",
      "F. Fabiano",
      "L. N. Falcao",
      "Y. Fan",
      "B. Fang",
      "L. Fantini",
      "M. Faria",
      "K. Farmer",
      "D. Fazzini",
      "L. Felkowski",
      "M. Feng",
      "M. Feo",
      "A. Fernandez Casani",
      "M. Fernandez Gomez",
      "A. D. Fernez",
      "F. Ferrari",
      "F. Ferreira Rodrigues",
      "M. Ferrillo",
      "M. Ferro-Luzzi",
      "S. Filippov",
      "R. A. Fini",
      "M. Fiorini",
      "M. Firlej",
      "K. L. Fischer",
      "D. S. Fitzgerald",
      "C. Fitzpatrick",
      "T. Fiutowski",
      "F. Fleuret",
      "M. Fontana",
      "L. F. Foreman",
      "R. Forty",
      "D. Foulds-Holt",
      "V. Franco Lima",
      "M. Franco Sevilla",
      "M. Frank",
      "E. Franzoso",
      "G. Frau",
      "C. Frei",
      "D. A. Friday",
      "J. Fu",
      "Q. Führing",
      "Y. Fujii",
      "T. Fulghesu",
      "E. Gabriel",
      "G. Galati",
      "M. D. Galati",
      "A. Gallas Torreira",
      "D. Galli",
      "S. Gambetta",
      "M. Gandelman",
      "P. Gandini",
      "B. Ganie",
      "H. Gao",
      "R. Gao",
      "T. Q. Gao",
      "Y. Gao",
      "Y. Gao",
      "Y. Gao",
      "L. M. Garcia Martin",
      "P. Garcia Moreno",
      "J. García Pardiñas",
      "K. G. Garg",
      "L. Garrido",
      "C. Gaspar",
      "R. E. Geertsema",
      "L. L. Gerken",
      "E. Gersabeck",
      "M. Gersabeck",
      "T. Gershon",
      "S. G. Ghizzo",
      "Z. Ghorbanimoghaddam",
      "L. Giambastiani",
      "F. I. Giasemis",
      "V. Gibson",
      "H. K. Giemza",
      "A. L. Gilman",
      "M. Giovannetti",
      "A. Gioventù",
      "L. Girardey",
      "P. Gironella Gironell",
      "C. Giugliano",
      "M. A. Giza",
      "E. L. Gkougkousis",
      "F. C. Glaser",
      "V. V. Gligorov",
      "C. Göbel",
      "E. Golobardes",
      "D. Golubkov",
      "A. Golutvin",
      "S. Gomez Fernandez",
      "W. Gomulka",
      "F. Goncalves Abrantes",
      "M. Goncerz",
      "G. Gong",
      "J. A. Gooding",
      "I. V. Gorelov",
      "C. Gotti",
      "J. P. Grabowski",
      "L. A. Granado Cardoso",
      "E. Graugés",
      "E. Graverini",
      "L. Grazette",
      "G. Graziani",
      "A. T. Grecu",
      "L. M. Greeven",
      "N. A. Grieser",
      "L. Grillo",
      "S. Gromov",
      "C. Gu",
      "M. Guarise",
      "L. Guerry",
      "M. Guittiere",
      "V. Guliaeva",
      "P. A. Günther",
      "A. -K. Guseinov",
      "E. Gushchin",
      "Y. Guz",
      "T. Gys",
      "K. Habermann",
      "T. Hadavizadeh",
      "C. Hadjivasiliou",
      "G. Haefeli",
      "C. Haen",
      "J. Haimberger",
      "M. Hajheidari",
      "G. Hallett",
      "M. M. Halvorsen",
      "P. M. Hamilton",
      "J. Hammerich",
      "Q. Han",
      "X. Han",
      "S. Hansmann-Menzemer",
      "L. Hao",
      "N. Harnew",
      "M. Hartmann",
      "S. Hashmi",
      "J. He",
      "F. Hemmer",
      "C. Henderson",
      "R. D. L. Henderson",
      "A. M. Hennequin",
      "K. Hennessy",
      "L. Henry",
      "J. Herd",
      "P. Herrero Gascon",
      "J. Heuel",
      "A. Hicheur",
      "G. Hijano Mendizabal",
      "D. Hill",
      "J. Horswill",
      "R. Hou",
      "Y. Hou",
      "N. Howarth",
      "J. Hu",
      "W. Hu",
      "X. Hu",
      "W. Huang",
      "W. Hulsbergen",
      "R. J. Hunter",
      "M. Hushchyn",
      "D. Hutchcroft",
      "M. Idzik",
      "D. Ilin",
      "P. Ilten",
      "A. Inglessi",
      "A. Iniukhin",
      "A. Ishteev",
      "K. Ivshin",
      "R. Jacobsson",
      "H. Jage",
      "S. J. Jaimes Elles",
      "S. Jakobsen",
      "E. Jans",
      "B. K. Jashal",
      "A. Jawahery",
      "V. Jevtic",
      "E. Jiang",
      "X. Jiang",
      "Y. Jiang",
      "Y. J. Jiang",
      "M. John",
      "A. John Rubesh Rajan",
      "D. Johnson",
      "C. R. Jones",
      "T. P. Jones",
      "S. Joshi",
      "B. Jost",
      "J. Juan Castella",
      "N. Jurik",
      "I. Juszczak",
      "D. Kaminaris",
      "S. Kandybei",
      "M. Kane",
      "Y. Kang",
      "C. Kar",
      "M. Karacson",
      "D. Karpenkov",
      "A. Kauniskangas",
      "J. W. Kautz",
      "M. K. Kazanecki",
      "F. Keizer",
      "M. Kenzie",
      "T. Ketel",
      "B. Khanji",
      "A. Kharisova",
      "S. Kholodenko",
      "G. Khreich",
      "T. Kirn",
      "V. S. Kirsebom",
      "O. Kitouni",
      "S. Klaver",
      "N. Kleijne",
      "K. Klimaszewski",
      "M. R. Kmiec",
      "S. Koliiev",
      "L. Kolk",
      "A. Konoplyannikov",
      "P. Kopciewicz",
      "P. Koppenburg",
      "M. Korolev",
      "I. Kostiuk",
      "O. Kot",
      "S. Kotriakhova",
      "A. Kozachuk",
      "P. Kravchenko",
      "L. Kravchuk",
      "M. Kreps",
      "P. Krokovny",
      "W. Krupa",
      "W. Krzemien",
      "O. Kshyvanskyi",
      "S. Kubis",
      "M. Kucharczyk",
      "V. Kudryavtsev",
      "E. Kulikova",
      "A. Kupsc",
      "B. K. Kutsenko",
      "D. Lacarrere",
      "P. Laguarta Gonzalez",
      "A. Lai",
      "A. Lampis",
      "D. Lancierini",
      "C. Landesa Gomez",
      "J. J. Lane",
      "R. Lane",
      "G. Lanfranchi",
      "C. Langenbruch",
      "J. Langer",
      "O. Lantwin",
      "T. Latham",
      "F. Lazzari",
      "C. Lazzeroni",
      "R. Le Gac",
      "H. Lee",
      "R. Lefèvre",
      "A. Leflat",
      "S. Legotin",
      "M. Lehuraux",
      "E. Lemos Cid",
      "O. Leroy",
      "T. Lesiak",
      "E. D. Lesser",
      "B. Leverington",
      "A. Li",
      "C. Li",
      "H. Li",
      "K. Li",
      "L. Li",
      "M. Li",
      "P. Li",
      "P. -R. Li",
      "Q. Li",
      "S. Li",
      "T. Li",
      "T. Li",
      "Y. Li",
      "Y. Li",
      "Z. Lian",
      "X. Liang",
      "S. Libralon",
      "C. Lin",
      "T. Lin",
      "R. Lindner",
      "H. Linton",
      "V. Lisovskyi",
      "R. Litvinov",
      "F. L. Liu",
      "G. Liu",
      "K. Liu",
      "S. Liu",
      "W. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. L. Liu",
      "A. Lobo Salvia",
      "A. Loi",
      "J. Lomba Castro",
      "T. Long",
      "J. H. Lopes",
      "A. Lopez Huertas",
      "S. López Soliño",
      "Q. Lu",
      "C. Lucarelli",
      "D. Lucchesi",
      "M. Lucio Martinez",
      "V. Lukashenko",
      "Y. Luo",
      "A. Lupato",
      "E. Luppi",
      "K. Lynch",
      "X. -R. Lyu",
      "G. M. Ma",
      "S. Maccolini",
      "F. Machefert",
      "F. Maciuc",
      "B. Mack",
      "I. Mackay",
      "L. M. Mackey",
      "L. R. Madhan Mohan",
      "M. J. Madurai",
      "A. Maevskiy",
      "D. Magdalinski",
      "D. Maisuzenko",
      "M. W. Majewski",
      "J. J. Malczewski",
      "S. Malde",
      "L. Malentacca",
      "A. Malinin",
      "T. Maltsev",
      "G. Manca",
      "G. Mancinelli",
      "C. Mancuso",
      "R. Manera Escalero",
      "F. M. Manganella",
      "D. Manuzzi",
      "D. Marangotto",
      "J. F. Marchand",
      "R. Marchevski",
      "U. Marconi",
      "E. Mariani",
      "S. Mariani",
      "C. Marin Benito",
      "J. Marks",
      "A. M. Marshall",
      "L. Martel",
      "G. Martelli",
      "G. Martellotti",
      "L. Martinazzoli",
      "M. Martinelli",
      "D. Martinez Gomez",
      "D. Martinez Santos",
      "F. Martinez Vidal",
      "A. Martorell i Granollers",
      "A. Massafferri",
      "R. Matev",
      "A. Mathad",
      "V. Matiunin",
      "C. Matteuzzi",
      "K. R. Mattioli",
      "A. Mauri",
      "E. Maurice",
      "J. Mauricio",
      "P. Mayencourt",
      "J. Mazorra de Cos",
      "M. Mazurek",
      "M. McCann",
      "L. Mcconnell",
      "T. H. McGrath",
      "N. T. McHugh",
      "A. McNab",
      "R. McNulty",
      "B. Meadows",
      "G. Meier",
      "D. Melnychuk",
      "F. M. Meng",
      "M. Merk",
      "A. Merli",
      "L. Meyer Garcia",
      "D. Miao",
      "H. Miao",
      "M. Mikhasenko",
      "D. A. Milanes",
      "A. Minotti",
      "E. Minucci",
      "T. Miralles",
      "B. Mitreska",
      "D. S. Mitzel",
      "A. Modak",
      "R. A. Mohammed",
      "R. D. Moise",
      "S. Mokhnenko",
      "E. F. Molina Cardenas",
      "T. Mombächer",
      "M. Monk",
      "S. Monteil",
      "A. Morcillo Gomez",
      "G. Morello",
      "M. J. Morello",
      "M. P. Morgenthaler",
      "J. Moron",
      "W. Morren",
      "A. B. Morris",
      "A. G. Morris",
      "R. Mountain",
      "H. Mu",
      "Z. M. Mu",
      "E. Muhammad",
      "F. Muheim",
      "M. Mulder",
      "K. Müller",
      "F. Muñoz-Rojas",
      "R. Murta",
      "P. Naik",
      "T. Nakada",
      "R. Nandakumar",
      "T. Nanut",
      "I. Nasteva",
      "M. Needham",
      "N. Neri",
      "S. Neubert",
      "N. Neufeld",
      "P. Neustroev",
      "J. Nicolini",
      "D. Nicotra",
      "E. M. Niel",
      "N. Nikitin",
      "P. Nogarolli",
      "P. Nogga",
      "C. Normand",
      "J. Novoa Fernandez",
      "G. Nowak",
      "C. Nunez",
      "H. N. Nur",
      "A. Oblakowska-Mucha",
      "V. Obraztsov",
      "T. Oeser",
      "S. Okamura",
      "A. Okhotnikov",
      "O. Okhrimenko",
      "R. Oldeman",
      "F. Oliva",
      "M. Olocco",
      "C. J. G. Onderwater",
      "R. H. O'Neil",
      "D. Osthues",
      "J. M. Otalora Goicochea",
      "P. Owen",
      "A. Oyanguren",
      "O. Ozcelik",
      "F. Paciolla",
      "A. Padee",
      "K. O. Padeken",
      "B. Pagare",
      "P. R. Pais",
      "T. Pajero",
      "A. Palano",
      "M. Palutan",
      "X. Pan",
      "G. Panshin",
      "L. Paolucci",
      "A. Papanestis",
      "M. Pappagallo",
      "L. L. Pappalardo",
      "C. Pappenheimer",
      "C. Parkes",
      "B. Passalacqua",
      "G. Passaleva",
      "D. Passaro",
      "A. Pastore",
      "M. Patel",
      "J. Patoc",
      "C. Patrignani",
      "A. Paul",
      "C. J. Pawley",
      "A. Pellegrino",
      "J. Peng",
      "M. Pepe Altarelli",
      "S. Perazzini",
      "D. Pereima",
      "H. Pereira Da Costa",
      "A. Pereiro Castro",
      "P. Perret",
      "A. Perrevoort",
      "A. Perro",
      "K. Petridis",
      "A. Petrolini",
      "J. P. Pfaller",
      "H. Pham",
      "L. Pica",
      "M. Piccini",
      "L. Piccolo",
      "B. Pietrzyk",
      "G. Pietrzyk",
      "D. Pinci",
      "F. Pisani",
      "M. Pizzichemi",
      "V. Placinta",
      "M. Plo Casasus",
      "T. Poeschl",
      "F. Polci",
      "M. Poli Lener",
      "A. Poluektov",
      "N. Polukhina",
      "I. Polyakov",
      "E. Polycarpo",
      "S. Ponce",
      "D. Popov",
      "S. Poslavskii",
      "K. Prasanth",
      "C. Prouve",
      "D. Provenzano",
      "V. Pugatch",
      "G. Punzi",
      "S. Qasim",
      "Q. Q. Qian",
      "W. Qian",
      "N. Qin",
      "S. Qu",
      "R. Quagliani",
      "R. I. Rabadan Trejo",
      "J. H. Rademacker",
      "M. Rama",
      "M. Ramírez García",
      "V. Ramos De Oliveira",
      "M. Ramos Pernas",
      "M. S. Rangel",
      "F. Ratnikov",
      "G. Raven",
      "M. Rebollo De Miguel",
      "F. Redi",
      "J. Reich",
      "F. Reiss",
      "Z. Ren",
      "P. K. Resmi",
      "R. Ribatti",
      "G. R. Ricart",
      "D. Riccardi",
      "S. Ricciardi",
      "K. Richardson",
      "M. Richardson-Slipper",
      "K. Rinnert",
      "P. Robbe",
      "G. Robertson",
      "E. Rodrigues",
      "A. Rodriguez Alvarez",
      "E. Rodriguez Fernandez",
      "J. A. Rodriguez Lopez",
      "E. Rodriguez Rodriguez",
      "J. Roensch",
      "A. Rogachev",
      "A. Rogovskiy",
      "D. L. Rolf",
      "P. Roloff",
      "V. Romanovskiy",
      "A. Romero Vidal",
      "G. Romolini",
      "F. Ronchetti",
      "T. Rong",
      "M. Rotondo",
      "S. R. Roy",
      "M. S. Rudolph",
      "M. Ruiz Diaz",
      "R. A. Ruiz Fernandez",
      "J. Ruiz Vidal",
      "A. Ryzhikov",
      "J. Ryzka",
      "J. J. Saavedra-Arias",
      "J. J. Saborido Silva",
      "R. Sadek",
      "N. Sagidova",
      "D. Sahoo",
      "N. Sahoo",
      "B. Saitta",
      "M. Salomoni",
      "I. Sanderswood",
      "R. Santacesaria",
      "C. Santamarina Rios",
      "M. Santimaria",
      "L. Santoro",
      "E. Santovetti",
      "A. Saputi",
      "D. Saranin",
      "A. Sarnatskiy",
      "G. Sarpis",
      "M. Sarpis",
      "C. Satriano",
      "A. Satta",
      "M. Saur",
      "D. Savrina",
      "H. Sazak",
      "F. Sborzacchi",
      "L. G. Scantlebury Smead",
      "A. Scarabotto",
      "S. Schael",
      "S. Scherl",
      "M. Schiller",
      "H. Schindler",
      "M. Schmelling",
      "B. Schmidt",
      "S. Schmitt",
      "H. Schmitz",
      "O. Schneider",
      "A. Schopper",
      "N. Schulte",
      "S. Schulte",
      "M. H. Schune",
      "R. Schwemmer",
      "G. Schwering",
      "B. Sciascia",
      "A. Sciuccati",
      "S. Sellam",
      "A. Semennikov",
      "T. Senger",
      "M. Senghi Soares",
      "A. Sergi",
      "N. Serra",
      "L. Sestini",
      "A. Seuthe",
      "Y. Shang",
      "D. M. Shangase",
      "M. Shapkin",
      "R. S. Sharma",
      "I. Shchemerov",
      "L. Shchutska",
      "T. Shears",
      "L. Shekhtman",
      "Z. Shen",
      "S. Sheng",
      "V. Shevchenko",
      "B. Shi",
      "Q. Shi",
      "Y. Shimizu",
      "E. Shmanin",
      "R. Shorkin",
      "J. D. Shupperd",
      "R. Silva Coutinho",
      "G. Simi",
      "S. Simone",
      "N. Skidmore",
      "T. Skwarnicki",
      "M. W. Slater",
      "J. C. Smallwood",
      "E. Smith",
      "K. Smith",
      "M. Smith",
      "A. Snoch",
      "L. Soares Lavra",
      "M. D. Sokoloff",
      "F. J. P. Soler",
      "A. Solomin",
      "A. Solovev",
      "I. Solovyev",
      "N. S. Sommerfeld",
      "R. Song",
      "Y. Song",
      "Y. Song",
      "Y. S. Song",
      "F. L. Souza De Almeida",
      "B. Souza De Paula",
      "E. Spadaro Norella",
      "E. Spedicato",
      "J. G. Speer",
      "E. Spiridenkov",
      "P. Spradlin",
      "V. Sriskaran",
      "F. Stagni",
      "M. Stahl",
      "S. Stahl",
      "S. Stanislaus",
      "E. N. Stein",
      "O. Steinkamp",
      "O. Stenyakin",
      "H. Stevens",
      "D. Strekalina",
      "Y. Su",
      "F. Suljik",
      "J. Sun",
      "L. Sun",
      "D. Sundfeld",
      "W. Sutcliffe",
      "P. N. Swallow",
      "K. Swientek",
      "F. Swystun",
      "A. Szabelski",
      "T. Szumlak",
      "Y. Tan",
      "Y. Tang",
      "M. D. Tat",
      "A. Terentev",
      "F. Terzuoli",
      "F. Teubert",
      "E. Thomas",
      "D. J. D. Thompson",
      "H. Tilquin",
      "V. Tisserand",
      "S. T'Jampens",
      "M. Tobin",
      "L. Tomassetti",
      "G. Tonani",
      "X. Tong",
      "D. Torres Machado",
      "L. Toscano",
      "D. Y. Tou",
      "C. Trippl",
      "G. Tuci",
      "N. Tuning",
      "L. H. Uecker",
      "A. Ukleja",
      "D. J. Unverzagt",
      "B. Urbach",
      "E. Ursov",
      "A. Usachov",
      "A. Ustyuzhanin",
      "U. Uwer",
      "V. Vagnoni",
      "V. Valcarce Cadenas",
      "G. Valenti",
      "N. Valls Canudas",
      "H. Van Hecke",
      "E. van Herwijnen",
      "C. B. Van Hulse",
      "R. Van Laak",
      "M. van Veghel",
      "G. Vasquez",
      "R. Vazquez Gomez",
      "P. Vazquez Regueiro",
      "C. Vázquez Sierra",
      "S. Vecchi",
      "J. J. Velthuis",
      "M. Veltri",
      "A. Venkateswaran",
      "M. Verdoglia",
      "M. Vesterinen",
      "D. Vico Benet",
      "P. Vidrier Villalba",
      "M. Vieites Diaz",
      "X. Vilasis-Cardona",
      "E. Vilella Figueras",
      "A. Villa",
      "P. Vincent",
      "F. C. Volle",
      "D. vom Bruch",
      "N. Voropaev",
      "K. Vos",
      "G. Vouters",
      "C. Vrahas",
      "J. Wagner",
      "J. Walsh",
      "E. J. Walton",
      "G. Wan",
      "C. Wang",
      "G. Wang",
      "J. Wang",
      "J. Wang",
      "J. Wang",
      "J. Wang",
      "M. Wang",
      "N. W. Wang",
      "R. Wang",
      "X. Wang",
      "X. Wang",
      "X. W. Wang",
      "Y. Wang",
      "Z. Wang",
      "Z. Wang",
      "Z. Wang",
      "J. A. Ward",
      "M. Waterlaat",
      "N. K. Watson",
      "D. Websdale",
      "Y. Wei",
      "J. Wendel",
      "B. D. C. Westhenry",
      "C. White",
      "M. Whitehead",
      "E. Whiter",
      "A. R. Wiederhold",
      "D. Wiedner",
      "G. Wilkinson",
      "M. K. Wilkinson",
      "M. Williams",
      "M. J. Williams",
      "M. R. J. Williams",
      "R. Williams",
      "Z. Williams",
      "F. F. Wilson",
      "M. Winn",
      "W. Wislicki",
      "M. Witek",
      "L. Witola",
      "G. Wormser",
      "S. A. Wotton",
      "H. Wu",
      "J. Wu",
      "X. Wu",
      "Y. Wu",
      "Z. Wu",
      "K. Wyllie",
      "S. Xian",
      "Z. Xiang",
      "Y. Xie",
      "A. Xu",
      "J. Xu",
      "L. Xu",
      "L. Xu",
      "M. Xu",
      "Z. Xu",
      "Z. Xu",
      "Z. Xu",
      "D. Yang",
      "K. Yang",
      "S. Yang",
      "X. Yang",
      "Y. Yang",
      "Z. Yang",
      "Z. Yang",
      "V. Yeroshenko",
      "H. Yeung",
      "H. Yin",
      "X. Yin",
      "C. Y. Yu",
      "J. Yu",
      "X. Yuan",
      "Y Yuan",
      "E. Zaffaroni",
      "M. Zavertyaev",
      "M. Zdybal",
      "F. Zenesini",
      "C. Zeng",
      "M. Zeng",
      "C. Zhang",
      "D. Zhang",
      "J. Zhang",
      "L. Zhang",
      "S. Zhang",
      "S. Zhang",
      "Y. Zhang",
      "Y. Z. Zhang",
      "Y. Zhao",
      "A. Zharkova",
      "A. Zhelezov",
      "S. Z. Zheng",
      "X. Z. Zheng",
      "Y. Zheng",
      "T. Zhou",
      "X. Zhou",
      "Y. Zhou",
      "V. Zhovkovska",
      "L. Z. Zhu",
      "X. Zhu",
      "X. Zhu",
      "V. Zhukov",
      "J. Zhuo",
      "Q. Zou",
      "D. Zuliani",
      "G. Zunica"
    ],
    "abstract": "Lepton flavour universality in rare $b\\rightarrow s$ transitions is tested\nfor the first time using $B_s^0$ meson decays. The measurements are performed\nusing $pp$ collision data collected by the LHCb experiment between 2011 and\n2018, corresponding to a total integrated luminosity of 9$\\,{\\rm fb}^{-1}$.\nBranching fraction ratios between the $B_s^0 \\rightarrow \\phi e^+e^-$ and\n$B_s^0 \\rightarrow \\phi \\mu^+\\mu^-$ decays are measured in three regions of\ndilepton mass squared, $q^2$, with $0.1 < q^2 < 1.1$, $1.1 < q^2 < 6.0$, and\n$15 < q^2 < 19\\,{\\rm GeV}^2/c^4$. The results agree with the Standard Model\nexpectation of lepton flavour universality.",
    "pdf_url": "http://arxiv.org/pdf/2410.13748v2",
    "published": "2024-10-17T16:46:02+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2410.13747v3",
    "title": "BayeSN and SALT: A Comparison of Dust Inference Across SN Ia Light-curve Models with DES5YR",
    "authors": [
      "Matthew Grayling",
      "Brodie Popovic"
    ],
    "abstract": "In recent years there has been significant debate around the impact of dust\non SNe Ia, a major source of uncertainty in cosmological analyses. We perform\nthe first validation of the probabilistic hierarchical SN Ia SED model BayeSN\non the conventional SALT model, an important test given the history of\nconflicting conclusions regarding the distributions of host galaxy dust\nproperties between the two. Applying BayeSN to SALT-based simulations, we find\nthat BayeSN is able to accurately recover our simulated inputs and successfully\ndisentangle differences in dust extinction from an intrinsic mass step. This\nvalidates BayeSN as a method to identify the relative contributions of dust and\nintrinsic differences in explaining the mass step. When inferring dust\nparameters with simulated samples including non-Ia contamination, we find that\nour choice of photometric classifier causes a bias in the inferred dust\ndistribution; this arises because SNe Ia heavily impacted by dust are\nmisclassified as contaminants and excluded. We then apply BayeSN to the sample\nof SNe from DES5YR to jointly infer host galaxy dust distributions and\nintrinsic differences on either side of the `mass step' at $10^{10}$ M$\\odot$.\nWe find evidence in favour of an intrinsic contribution to the mass step and\ndiffering $R_V$ distributions. We also build on recent results supporting an\nenvironmental-dependence on the secondary maximum of SNe Ia in $i$-band. Twenty\ndays post-peak, we find an offset in intrinsic $i$-band light curve between\neach mass bin at a significance in excess of $3\\sigma$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13747v3",
    "published": "2024-10-17T16:45:26+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13746v2",
    "title": "Theory on Score-Mismatched Diffusion Models and Zero-Shot Conditional Samplers",
    "authors": [
      "Yuchen Liang",
      "Peizhong Ju",
      "Yingbin Liang",
      "Ness Shroff"
    ],
    "abstract": "The denoising diffusion model has recently emerged as a powerful generative\ntechnique, capable of transforming noise into meaningful data. While\ntheoretical convergence guarantees for diffusion models are well established\nwhen the target distribution aligns with the training distribution, practical\nscenarios often present mismatches. One common case is in the zero-shot\nconditional diffusion sampling, where the target conditional distribution is\ndifferent from the (unconditional) training distribution. These\nscore-mismatched diffusion models remain largely unexplored from a theoretical\nperspective. In this paper, we present the first performance guarantee with\nexplicit dimensional dependencies for general score-mismatched diffusion\nsamplers, focusing on target distributions with finite second moments. We show\nthat score mismatches result in an asymptotic distributional bias between the\ntarget and sampling distributions, proportional to the accumulated mismatch\nbetween the target and training distributions. This result can be directly\napplied to zero-shot conditional samplers for any conditional model,\nirrespective of measurement noise. Interestingly, the derived convergence upper\nbound offers useful guidance for designing a novel bias-optimal zero-shot\nsampler in linear conditional models that minimizes the asymptotic bias. For\nsuch bias-optimal samplers, we further establish convergence guarantees with\nexplicit dependencies on dimension and conditioning, applied to several\ninteresting target distributions, including those with bounded support and\nGaussian mixtures. Our findings are supported by numerical studies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13746v2",
    "published": "2024-10-17T16:42:12+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13745v1",
    "title": "On the crystallization onset in white dwarfs",
    "authors": [
      "D. A. Baiko"
    ],
    "abstract": "Thermal evolution of the central region of a $0.9 \\, M_\\odot$ C/O white dwarf\nat the initial stage of the ion mixture crystallization is studied by\nnumerically solving the heat equation on a fine spatial and temporal grid and\nby including a detailed treatment of the latent heat release. Formation of two\nspherical shells is observed. The outer one surrounds a region where\ncrystallization has begun. The inner one bounds a fully solidified core which\nhas exhausted its latent heat. The region between the shells is partially\nliquid and partially solid. It gradually emits the latent heat of\ncrystallization and also it releases light elements (carbon) in the process of\nelement redistribution, accompanying the mixture solidification. Assuming that\nall released light elements cross the outer shell, we have estimated their flux\ninduced by the mixture crystallization. The resulting flux is not divergent and\nis much smaller than an estimate derived from the growth rate of the fully\ncrystallized core.",
    "pdf_url": "http://arxiv.org/pdf/2410.13745v1",
    "published": "2024-10-17T16:41:36+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13744v1",
    "title": "Inferring the dynamics of quasi-reaction systems via nonlinear local mean-field approximations",
    "authors": [
      "Matteo Framba",
      "Veronica Vinciotti",
      "Ernst C. Wit"
    ],
    "abstract": "In the modelling of stochastic phenomena, such as quasi-reaction systems,\nparameter estimation of kinetic rates can be challenging, particularly when the\ntime gap between consecutive measurements is large. Local linear approximation\napproaches account for the stochasticity in the system but fail to capture the\nnonlinear nature of the underlying process. At the mean level, the dynamics of\nthe system can be described by a system of ODEs, which have an explicit\nsolution only for simple unitary systems. An analytical solution for generic\nquasi-reaction systems is proposed via a first order Taylor approximation of\nthe hazard rate. This allows a nonlinear forward prediction of the future\ndynamics given the current state of the system. Predictions and corresponding\nobservations are embedded in a nonlinear least-squares approach for parameter\nestimation. The performance of the algorithm is compared to existing SDE and\nODE-based methods via a simulation study. Besides the increased computational\nefficiency of the approach, the results show an improvement in the kinetic rate\nestimation, particularly for data observed at large time intervals.\nAdditionally, the availability of an explicit solution makes the method robust\nto stiffness, which is often present in biological systems. An illustration on\nRhesus Macaque data shows the applicability of the approach to the study of\ncell differentiation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13744v1",
    "published": "2024-10-17T16:40:28+00:00",
    "categories": [
      "stat.ME",
      "q-bio.MN"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13743v1",
    "title": "Single-Timescale Multi-Sequence Stochastic Approximation Without Fixed Point Smoothness: Theories and Applications",
    "authors": [
      "Yue Huang",
      "Zhaoxian Wu",
      "Shiqian Ma",
      "Qing Ling"
    ],
    "abstract": "Stochastic approximation (SA) that involves multiple coupled sequences, known\nas multiple-sequence SA (MSSA), finds diverse applications in the fields of\nsignal processing and machine learning. However, existing theoretical\nunderstandings {of} MSSA are limited: the multi-timescale analysis implies a\nslow convergence rate, whereas the single-timescale analysis relies on a\nstringent fixed point smoothness assumption. This paper establishes tighter\nsingle-timescale analysis for MSSA, without assuming smoothness of the fixed\npoints. Our theoretical findings reveal that, when all involved operators are\nstrongly monotone, MSSA converges at a rate of $\\tilde{\\mathcal{O}}(K^{-1})$,\nwhere $K$ denotes the total number of iterations. In addition, when all\ninvolved operators are strongly monotone except for the main one, MSSA\nconverges at a rate of $\\mathcal{O}(K^{-\\frac{1}{2}})$. These theoretical\nfindings align with those established for single-sequence SA. Applying these\ntheoretical findings to bilevel optimization and communication-efficient\ndistributed learning offers relaxed assumptions and/or simpler algorithms with\nperformance guarantees, as validated by numerical experiments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13743v1",
    "published": "2024-10-17T16:39:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13742v1",
    "title": "Multiple collisions in N59 bubble: Sequential cloud-cloud collisions",
    "authors": [
      "En Chen",
      "Xi Chen",
      "Xuepeng Chen",
      "Min Fang",
      "Qianru He"
    ],
    "abstract": "We report that the gas components in the N59 bubble suffered from sequential\nmultiple cloud-cloud collision (CCC) processes. The molecular gas in the N59\nbubble can be decomposed into four velocity components, namely Cloud A [95,\n108] km s$^{-1}$, Cloud B [86, 95] km s$^{-1}$, Cloud C [79, 86] km s$^{-1}$\nand Cloud D [65, 79] km s$^{-1}$. Four CCC processes occurred among these four\nvelocity components, i.e., Cloud A vs. Cloud B, Cloud A vs. Cloud C, Cloud C\nvs. Cloud D, and Cloud A vs. Cloud D. Using Spitzer MIR and UKIDSS NIR\nphotometric point source catalogs, we identified 514 YSO candidates clustered\nin 13 YSO groups, and most of them (~60$\\%$) were located at the colliding\ninterfaces, indicating that they were mainly triggered by these four CCC\nprocesses. We also found that these four collisions occurred in a time\nsequential order: the earliest and most violent collision occurred between\nCloud A and Cloud D about 2 Myr ago, then Cloud B collided with Cloud A about 1\nMyr ago, and finally, Cloud C collided with Clouds A and D simultaneously about\n0.4 Myr ago.",
    "pdf_url": "http://arxiv.org/pdf/2410.13742v1",
    "published": "2024-10-17T16:39:30+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13741v1",
    "title": "A mixed fibration theorem for Hilbert irreducibility on non-proper varieties",
    "authors": [
      "Cedric Luger"
    ],
    "abstract": "We prove that the weak Hilbert property ascends along a morphism of varieties\nover an arbitrary field of characteristic zero, under suitable assumptions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13741v1",
    "published": "2024-10-17T16:39:07+00:00",
    "categories": [
      "math.AG",
      "Primary: 14G99. Secondary: 14G05, 14G40"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13740v3",
    "title": "Solving Helmholtz problems with finite elements on a quantum annealer",
    "authors": [
      "Arnaud Rémi",
      "François Damanet",
      "Christophe Geuzaine"
    ],
    "abstract": "Solving Helmholtz problems using finite elements leads to the resolution of a\nlinear system which is challenging to solve for classical computers. In this\npaper, we investigate how quantum annealers could address this challenge. We\nfirst express the linear system arising from the Helmholtz problem as a\ngeneralized eigenvalue problem (gEVP). The obtained gEVP is mapped into\nquadratic unconstrained binary optimization problems (QUBOs) which we solve\nusing an adaptive quantum annealing eigensolver (AQAE) and its classical\nequivalent. We identify two key parameters in the success of AQAE for solving\nHelmholtz problems: the system condition number and the integrated control\nerrors (ICE) in the quantum hardware. Our results show that a large system\ncondition number implies a finer discretization grid for AQAE to converge,\nleading to larger QUBOs and that AQAE is either tolerant or not with respect to\nICE depending on the gEVP.",
    "pdf_url": "http://arxiv.org/pdf/2410.13740v3",
    "published": "2024-10-17T16:39:03+00:00",
    "categories": [
      "quant-ph",
      "physics.comp-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13739v1",
    "title": "Microcanonical Monte Carlo simulation of opinion dynamics under the influence of mass media",
    "authors": [
      "Yasmín Navarrete",
      "Carlos Femenías",
      "Sergio Davis",
      "Claudia Loyola"
    ],
    "abstract": "The formation of large social groups having uniform opinions influenced by\nmass media is currently an important topic in the social sciences. In this\nwork, we explore and extend an off-lattice, two-dimensional Potts model (Eur.\nPhys. J. B 87, 78 [2014]) that describes the formation and dynamics of opinions\nin social groups according to individual consequence and agreement between\nneighbors. This model was originally obtained by the application of the maximum\nentropy principle, a general method in statistical inference, and using the\nsame methodology we have now included the influence of mass media as a constant\nexternal field. By means of microcanonical Monte Carlo Metropolis simulations\non a setup with two regions with opposing external influences, we have shown\nthe presence of metastable states associated to the formation of clusters\naligned with the locally imposed opinion. Our results suggest that, for some\nvalues of the total energy of the system, only a single cluster with a uniform\nopinion survives, thus the presence of two large, opposing groups is not a\nthermodynamically stable configuration.",
    "pdf_url": "http://arxiv.org/pdf/2410.13739v1",
    "published": "2024-10-17T16:38:09+00:00",
    "categories": [
      "physics.soc-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13738v2",
    "title": "Instance-dependent Convergence Theory for Diffusion Models",
    "authors": [
      "Yuchen Jiao",
      "Gen Li"
    ],
    "abstract": "Score-based diffusion models have demonstrated outstanding empirical\nperformance in machine learning and artificial intelligence, particularly in\ngenerating high-quality new samples from complex probability distributions.\nImproving the theoretical understanding of diffusion models, with a particular\nfocus on the convergence analysis, has attracted significant attention. In this\nwork, we develop a convergence rate that is adaptive to the smoothness of\ndifferent target distributions, referred to as instance-dependent bound.\nSpecifically, we establish an iteration complexity of\n$\\min\\{d,d^{2/3}L^{1/3},d^{1/3}L\\}\\varepsilon^{-2/3}$ (up to logarithmic\nfactors), where $d$ denotes the data dimension, and $\\varepsilon$ quantifies\nthe output accuracy in terms of total variation (TV) distance. In addition, $L$\nrepresents a relaxed Lipschitz constant, which, in the case of Gaussian mixture\nmodels, scales only logarithmically with the number of components, the\ndimension and iteration number, demonstrating broad applicability.",
    "pdf_url": "http://arxiv.org/pdf/2410.13738v2",
    "published": "2024-10-17T16:37:33+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13737v4",
    "title": "Global Optimization Algorithm through High-Resolution Sampling",
    "authors": [
      "Daniel Cortild",
      "Claire Delplancke",
      "Nadia Oudjane",
      "Juan Peypouquet"
    ],
    "abstract": "We present an optimization algorithm that can identify a global minimum of a\npotentially nonconvex smooth function with high probability, assuming the Gibbs\nmeasure of the potential satisfies a logarithmic Sobolev inequality. Our\ncontribution is twofold: on the one hand we propose a global optimization\nmethod, which is built on an oracle sampling algorithm producing arbitrarily\naccurate samples from a given Gibbs measure. On the other hand, we propose a\nnew sampling algorithm, drawing inspiration from both overdamped and\nunderdamped Langevin dynamics, as well as from the high-resolution differential\nequation known for its acceleration in deterministic settings. While the focus\nof the paper is primarily theoretical, we demonstrate the effectiveness of our\nalgorithms on the Rastrigin function, where it outperforms recent approaches.",
    "pdf_url": "http://arxiv.org/pdf/2410.13737v4",
    "published": "2024-10-17T16:37:32+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13736v2",
    "title": "Whitehead Doubles and Non-Orientable Surfaces",
    "authors": [
      "Megan Fairchild"
    ],
    "abstract": "Whitehead doubles provide a plethora of examples of knots that are\ntopologically slice but not smoothly slice. We discuss the problem of the\nWhitehead double of the Figure 8 knot and survey commonly used techniques to\nobstructing sliceness. Additionally, we improve bounds in general for the\nnon-orientable 4 genus of $t$-twisted Whitehead doubles and provide genus 1\nnon-orientable cobordisms to cable knots.",
    "pdf_url": "http://arxiv.org/pdf/2410.13736v2",
    "published": "2024-10-17T16:37:13+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13735v2",
    "title": "Generative Conformal Prediction with Vectorized Non-Conformity Scores",
    "authors": [
      "Minxing Zheng",
      "Shixiang Zhu"
    ],
    "abstract": "Conformal prediction (CP) provides model-agnostic uncertainty quantification\nwith guaranteed coverage, but conventional methods often produce overly\nconservative uncertainty sets, especially in multi-dimensional settings. This\nlimitation arises from simplistic non-conformity scores that rely solely on\nprediction error, failing to capture the prediction error distribution's\ncomplexity. To address this, we propose a generative conformal prediction\nframework with vectorized non-conformity scores, leveraging a generative model\nto sample multiple predictions from the fitted data distribution. By computing\nnon-conformity scores across these samples and estimating empirical quantiles\nat different density levels, we construct adaptive uncertainty sets using\ndensity-ranked uncertainty balls. This approach enables more precise\nuncertainty allocation -- yielding larger prediction sets in high-confidence\nregions and smaller or excluded sets in low-confidence regions -- enhancing\nboth flexibility and efficiency. We establish theoretical guarantees for\nstatistical validity and demonstrate through extensive numerical experiments\nthat our method outperforms state-of-the-art techniques on synthetic and\nreal-world datasets.",
    "pdf_url": "http://arxiv.org/pdf/2410.13735v2",
    "published": "2024-10-17T16:37:03+00:00",
    "categories": [
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13734v2",
    "title": "Strong-to-weak spontaneous symmetry breaking meets average symmetry-protected topological order",
    "authors": [
      "Yuchen Guo",
      "Shuo Yang"
    ],
    "abstract": "Recent studies have unveiled new possibilities for discovering intrinsic\nquantum phases that are unique to open systems, including phases with average\nsymmetry-protected topological (ASPT) order and strong-to-weak spontaneous\nsymmetry breaking (SWSSB) order in systems with global symmetry. In this work,\nwe propose a new class of phases, termed the double ASPT phase, which emerges\nfrom a nontrivial extension of these two orders. This new phase is absent from\nprior studies and cannot exist in conventional closed systems. Using the\nrecently developed imaginary-Lindbladian formalism, we explore the phase\ndiagram of a one-dimensional open system with $\\mathbb{Z}_2^{\\sigma}\\times\n\\mathbb{Z}_2^{\\tau}$ symmetry. We identify universal critical behaviors along\neach critical line and observe the emergence of an intermediate phase that\ncompletely breaks the $\\mathbb{Z}_2^{\\sigma}$ symmetry, leading to the\nformation of two triple points in the phase diagram. These two triple points\nare topologically distinct and connected by a domain-wall decoration duality\nmap. Our results promote the establishment of a complete classification for\nquantum phases in open systems with various symmetry conditions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13734v2",
    "published": "2024-10-17T16:36:53+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.stat-mech",
      "quant-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13733v1",
    "title": "Improving Multi-modal Large Language Model through Boosting Vision Capabilities",
    "authors": [
      "Yanpeng Sun",
      "Huaxin Zhang",
      "Qiang Chen",
      "Xinyu Zhang",
      "Nong Sang",
      "Gang Zhang",
      "Jingdong Wang",
      "Zechao Li"
    ],
    "abstract": "We focus on improving the visual understanding capability for boosting the\nvision-language models. We propose \\textbf{Arcana}, a multiModal language\nmodel, which introduces two crucial techniques. First, we present Multimodal\nLoRA (MM-LoRA), a module designed to enhance the decoder. Unlike traditional\nlanguage-driven decoders, MM-LoRA consists of two parallel LoRAs -- one for\nvision and one for language -- each with its own parameters. This disentangled\nparameters design allows for more specialized learning in each modality and\nbetter integration of multimodal information. Second, we introduce the Query\nLadder adapter (QLadder) to improve the visual encoder. QLadder employs a\nlearnable ``\\textit{ladder}'' structure to deeply aggregates the intermediate\nrepresentations from the frozen pretrained visual encoder (e.g., CLIP image\nencoder). This enables the model to learn new and informative visual features,\nas well as remaining the powerful capabilities of the pretrained visual\nencoder. These techniques collectively enhance Arcana's visual perception\npower, enabling it to leverage improved visual information for more accurate\nand contextually relevant outputs across various multimodal scenarios.\nExtensive experiments and ablation studies demonstrate the effectiveness and\ngeneralization capability of our Arcana. The code and re-annotated data are\navailable at \\url{https://arcana-project-page.github.io}.",
    "pdf_url": "http://arxiv.org/pdf/2410.13733v1",
    "published": "2024-10-17T16:36:38+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13732v2",
    "title": "Reducing the Transformer Architecture to a Minimum",
    "authors": [
      "Bernhard Bermeitinger",
      "Tomas Hrycej",
      "Massimo Pavone",
      "Julianus Kath",
      "Siegfried Handschuh"
    ],
    "abstract": "Transformers are a widespread and successful model architecture, particularly\nin Natural Language Processing (NLP) and Computer Vision (CV). The essential\ninnovation of this architecture is the Attention Mechanism, which solves the\nproblem of extracting relevant context information from long sequences in NLP\nand realistic scenes in CV. A classical neural network component, a Multi-Layer\nPerceptron (MLP), complements the attention mechanism. Its necessity is\nfrequently justified by its capability of modeling nonlinear relationships.\nHowever, the attention mechanism itself is nonlinear through its internal use\nof similarity measures. A possible hypothesis is that this nonlinearity is\nsufficient for modeling typical application problems. As the MLPs usually\ncontain the most trainable parameters of the whole model, their omission would\nsubstantially reduce the parameter set size. Further components can also be\nreorganized to reduce the number of parameters. Under some conditions, query\nand key matrices can be collapsed into a single matrix of the same size. The\nsame is true about value and projection matrices, which can also be omitted\nwithout eliminating the substance of the attention mechanism. Initially, the\nsimilarity measure was defined asymmetrically, with peculiar properties such as\nthat a token is possibly dissimilar to itself. A possible symmetric definition\nrequires only half of the parameters. We have laid the groundwork by testing\nwidespread CV benchmarks: MNIST and CIFAR-10. The tests have shown that\nsimplified transformer architectures (a) without MLP, (b) with collapsed\nmatrices, and (c) symmetric similarity matrices exhibit similar performance as\nthe original architecture, saving up to 90% of parameters without hurting the\nclassification performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13732v2",
    "published": "2024-10-17T16:36:14+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13731v1",
    "title": "Well-posedness of three-dimensional Damped Cahn-Hilliard-Navier-Stokes Equations",
    "authors": [
      "Manika Bag",
      "Sheetal Dharmatti",
      "Manil T Mohan"
    ],
    "abstract": "This paper presents a mathematical analysis of the evolution of a mixture of\ntwo incompressible, isothermal fluids flowing through a porous medium in a\nthree dimensional bounded domain. The model is governed by a coupled system of\nconvective Brinkman Forchheimer equations and the Cahn Hilliard equation,\nconsidering a regular potential and non degenerate mobility. We first establish\nthe existence of a Leray Hopf weak solution for the coupled system when the\nabsorption exponent r greater than or equal to 1. Additionally, we prove that\nevery weak solution satisfies the energy equality for greater than 3. This\nfurther leads to the uniqueness of weak solutions in three-dimensional bounded\ndomains, subject to certain restrictions on the viscosity and the Forchheimer\ncoefficient in the critical case r=3. Moreover, we provide an alternative\nsimplified proof for the uniqueness of weak solutions for r greater than or\nequal to 3 that holds without imposing any restrictions on viscosity or\nForchheimer coefficient. Similar results are also obtained for the case of\ndegenerate mobility and singular potential.",
    "pdf_url": "http://arxiv.org/pdf/2410.13731v1",
    "published": "2024-10-17T16:35:32+00:00",
    "categories": [
      "math.AP",
      "Primary 35A01, 35A02, 76B03, Secondary 35Q35, 76D03"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13730v1",
    "title": "On SCD Semismooth$^*$ Newton methods for the efficient minimization of Tikhonov functionals with non-smooth and non-convex penalties",
    "authors": [
      "Helmut Gfrerer",
      "Simon Hubmer",
      "Ronny Ramlau"
    ],
    "abstract": "We consider the efficient numerical minimization of Tikhonov functionals with\nnonlinear operators and non-smooth and non-convex penalty terms, which appear\nfor example in variational regularization. For this, we consider a new class of\nSCD semismooth$^*$ Newton methods, which are based on a novel concept of\ngraphical derivatives, and exhibit locally superlinear convergence. We present\na detailed description of these methods, and provide explicit algorithms in the\ncase of sparsity and total-variation penalty terms. The numerical performance\nof these methods is then illustrated on a number of tomographic imaging\nproblems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13730v1",
    "published": "2024-10-17T16:34:42+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13729v1",
    "title": "Factorizations into irreducible numerical semigroups",
    "authors": [
      "Pedro A. Garcia-Sanchez"
    ],
    "abstract": "Every numerical semigroup can be expressed as an intersection of irreducible\nnumerical semigroups. We show that the unions of sets of lengths of\nfactorizations of numerical semigroups into irreducible numerical semigroups\nare all equal to $\\mathbb{N}_{\\ge 2}$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13729v1",
    "published": "2024-10-17T16:33:45+00:00",
    "categories": [
      "math.AC",
      "math.CO",
      "20M14"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13728v1",
    "title": "Highest weight categories and stability conditions",
    "authors": [
      "Alessio Cipriani",
      "Jon Woolf"
    ],
    "abstract": "Highest weight categories are an abstraction of the representation theory of\nsemisimple Lie algebras introduced by Cline, Parshall and Scott in the late\n1980s. There are by now many characterisations of when an abelian category is\nhighest weight, but most are hard to verify in practice. We present two new\ncriteria - one numerical in terms of the Grothendieck group, and one in terms\nof Bridegland stability conditions - which are easier to verify. We relate them\nto a criterion by Green and Schroll for when modules over a monomial algebra\nare highest weight.",
    "pdf_url": "http://arxiv.org/pdf/2410.13728v1",
    "published": "2024-10-17T16:33:15+00:00",
    "categories": [
      "math.RT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13727v2",
    "title": "LLM-Human Pipeline for Cultural Context Grounding of Conversations",
    "authors": [
      "Rajkumar Pujari",
      "Dan Goldwasser"
    ],
    "abstract": "Conversations often adhere to well-understood social norms that vary across\ncultures. For example, while \"addressing parents by name\" is commonplace in the\nWest, it is rare in most Asian cultures. Adherence or violation of such norms\noften dictates the tenor of conversations. Humans are able to navigate social\nsituations requiring cultural awareness quite adeptly. However, it is a hard\ntask for NLP models.\n  In this paper, we tackle this problem by introducing a \"Cultural Context\nSchema\" for conversations. It comprises (1) conversational information such as\nemotions, dialogue acts, etc., and (2) cultural information such as social\nnorms, violations, etc. We generate ~110k social norm and violation\ndescriptions for ~23k conversations from Chinese culture using LLMs. We refine\nthem using automated verification strategies which are evaluated against\nculturally aware human judgements. We organize these descriptions into\nmeaningful structures we call \"Norm Concepts\", using an interactive\nhuman-in-loop framework. We ground the norm concepts and the descriptions in\nconversations using symbolic annotation. Finally, we use the obtained dataset\nfor downstream tasks such as emotion, sentiment, and dialogue act detection. We\nshow that it significantly improves the empirical performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13727v2",
    "published": "2024-10-17T16:33:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13726v3",
    "title": "DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation",
    "authors": [
      "Hanbo Cheng",
      "Limin Lin",
      "Chenyu Liu",
      "Pengcheng Xia",
      "Pengfei Hu",
      "Jiefeng Ma",
      "Jun Du",
      "Jia Pan"
    ],
    "abstract": "Talking head generation intends to produce vivid and realistic talking head\nvideos from a single portrait and speech audio clip. Although significant\nprogress has been made in diffusion-based talking head generation, almost all\nmethods rely on autoregressive strategies, which suffer from limited context\nutilization beyond the current generation step, error accumulation, and slower\ngeneration speed. To address these challenges, we present DAWN (Dynamic frame\nAvatar With Non-autoregressive diffusion), a framework that enables all-at-once\ngeneration of dynamic-length video sequences. Specifically, it consists of two\nmain components: (1) audio-driven holistic facial dynamics generation in the\nlatent motion space, and (2) audio-driven head pose and blink generation.\nExtensive experiments demonstrate that our method generates authentic and vivid\nvideos with precise lip motions, and natural pose/blink movements.\nAdditionally, with a high generation speed, DAWN possesses strong extrapolation\ncapabilities, ensuring the stable production of high-quality long videos. These\nresults highlight the considerable promise and potential impact of DAWN in the\nfield of talking head video generation. Furthermore, we hope that DAWN sparks\nfurther exploration of non-autoregressive approaches in diffusion models. Our\ncode will be publicly available at https://github.com/Hanbo-Cheng/DAWN-pytorch.",
    "pdf_url": "http://arxiv.org/pdf/2410.13726v3",
    "published": "2024-10-17T16:32:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13725v1",
    "title": "HI line observations of 290 evolved stars made with the Nancay Radio Telescope -- I. Data",
    "authors": [
      "E. Gerard",
      "W. van Driel",
      "L. D. Matthews",
      "T. Le Bertre",
      "J. -M. Martin",
      "N. Q. Rieu"
    ],
    "abstract": "We present a compendium of HI 21-cm line observations of circumstellar\nenvelopes (CSEs) of 290 evolved stars, mostly (~84%) on the asymptotic giant\nbranch (AGB), made with the 100m-class, single-dish Nancay Radio Telescope. The\nobservational and data reduction procedures were optimised for separating\ngenuine CSE HI emission from surrounding Galactic line features. For most\ntargets (254) the results have not been previously published. Clear detections\nwere made of 34 objects, for 33 of which the total HI flux and the size of the\nCSE could be determined. Possible detections were made of 21 objects, and upper\nlimits could be determined for 95 undetected targets, while for 140 objects\nconfusion from Galactic HI emission along the line-of-sight precluded\nmeaningful upper limits. The collective results of this survey can provide\nguidance on detectability of circumstellar HI gas for future mapping and\nimaging studies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13725v1",
    "published": "2024-10-17T16:31:37+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13724v1",
    "title": "High-order exceptional points and stochastic resonance in pseudo-Hermitian systems",
    "authors": [
      "Shirin Panahi",
      "Li-Li Ye",
      "Ying-Cheng Lai"
    ],
    "abstract": "Exceptional points, a remarkable phenomenon in physical systems, have been\nexploited for sensing applications. It has been demonstrated recently that it\ncan also utilize as sensory threshold in which the interplay between\nexceptional-point dynamics and noise can lead to enhanced performance. Most\nexisting works focused on second-order exceptional points. We investigate the\nstochastic dynamics associated with high-order exceptional points with a\nparticular eye towards optimizing sensing performance by developing a\ntheoretical framework based on pseudo-Hermiticity. Our analysis reveals three\ndistinct types of frequency responses to external perturbations. A broad type\nof stochastic resonance is uncovered where, as the noise amplitude increases,\nthe signal-to-noise ratio reaches a global maximum rapidly but with a slow\ndecaying process afterwards, indicating achievable high performance in a wide\nrange of the noise level. These results suggest that stochastic high-order\nexceptional-point dynamics can be exploited for applications in signal\nprocessing and sensor technologies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13724v1",
    "published": "2024-10-17T16:29:57+00:00",
    "categories": [
      "physics.app-ph",
      "math.DS",
      "nlin.AO"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13723v1",
    "title": "A Subsequence Approach to Topological Data Analysis for Irregularly-Spaced Time Series",
    "authors": [
      "Sixtus Dakurah",
      "Jessi Cisewski-Kehe"
    ],
    "abstract": "A time-delay embedding (TDE), grounded in the framework of Takens's Theorem,\nprovides a mechanism to represent and analyze the inherent dynamics of\ntime-series data. Recently, topological data analysis (TDA) methods have been\napplied to study this time series representation mainly through the lens of\npersistent homology. Current literature on the fusion of TDE and TDA are adept\nat analyzing uniformly-spaced time series observations. This work introduces a\nnovel {\\em subsequence} embedding method for irregularly-spaced time-series\ndata. We show that this method preserves the original state space topology\nwhile reducing spurious homological features. Theoretical stability results and\nconvergence properties of the proposed method in the presence of noise and\nvarying levels of irregularity in the spacing of the time series are\nestablished. Numerical studies and an application to real data illustrates the\nperformance of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2410.13723v1",
    "published": "2024-10-17T16:27:31+00:00",
    "categories": [
      "stat.ME",
      "cs.CG",
      "math.AT"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13722v1",
    "title": "Persistent Pre-Training Poisoning of LLMs",
    "authors": [
      "Yiming Zhang",
      "Javier Rando",
      "Ivan Evtimov",
      "Jianfeng Chi",
      "Eric Michael Smith",
      "Nicholas Carlini",
      "Florian Tramèr",
      "Daphne Ippolito"
    ],
    "abstract": "Large language models are pre-trained on uncurated text datasets consisting\nof trillions of tokens scraped from the Web. Prior work has shown that: (1)\nweb-scraped pre-training datasets can be practically poisoned by malicious\nactors; and (2) adversaries can compromise language models after poisoning\nfine-tuning datasets. Our work evaluates for the first time whether language\nmodels can also be compromised during pre-training, with a focus on the\npersistence of pre-training attacks after models are fine-tuned as helpful and\nharmless chatbots (i.e., after SFT and DPO). We pre-train a series of LLMs from\nscratch to measure the impact of a potential poisoning adversary under four\ndifferent attack objectives (denial-of-service, belief manipulation,\njailbreaking, and prompt stealing), and across a wide range of model sizes\n(from 600M to 7B). Our main result is that poisoning only 0.1% of a model's\npre-training dataset is sufficient for three out of four attacks to measurably\npersist through post-training. Moreover, simple attacks like denial-of-service\npersist through post-training with a poisoning rate of only 0.001%.",
    "pdf_url": "http://arxiv.org/pdf/2410.13722v1",
    "published": "2024-10-17T16:27:13+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13721v1",
    "title": "On-chip cryogenic multiplexing of Si/SiGe quantum devices",
    "authors": [
      "M. A. Wolfe",
      "Thomas McJunkin",
      "Daniel R. Ward",
      "DeAnna Campbell",
      "Mark Friesen",
      "M. A. Eriksson"
    ],
    "abstract": "The challenges of operating qubits in a cryogenic environment point to a\nlooming bottleneck for large-scale quantum processors, limited by the number of\ninput-output connections. Classical processors solve this problem via\nmultiplexing; however, on-chip multiplexing circuits have not been shown to\nhave similar benefits for cryogenic quantum devices. In this work we integrate\nclassical circuitry and Si/SiGe quantum devices on the same chip, providing a\ntest bed for qubit scale-up. Our method uses on-chip field-effect transistors\n(FETs) to multiplex a grid of work zones, achieving a nearly tenfold reduction\nin control wiring. We leverage this set-up to probe device properties across a\n6x6mm$^2$ array of 16 Hall bars. We successfully operate the array at cryogenic\ntemperatures and high magnetic fields where the quantum Hall effect is\nobserved. Building upon these results, we propose a vision for readout in a\nlarge-scale silicon quantum processor with a limited number of control\nconnections.",
    "pdf_url": "http://arxiv.org/pdf/2410.13721v1",
    "published": "2024-10-17T16:26:41+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13720v2",
    "title": "Movie Gen: A Cast of Media Foundation Models",
    "authors": [
      "Adam Polyak",
      "Amit Zohar",
      "Andrew Brown",
      "Andros Tjandra",
      "Animesh Sinha",
      "Ann Lee",
      "Apoorv Vyas",
      "Bowen Shi",
      "Chih-Yao Ma",
      "Ching-Yao Chuang",
      "David Yan",
      "Dhruv Choudhary",
      "Dingkang Wang",
      "Geet Sethi",
      "Guan Pang",
      "Haoyu Ma",
      "Ishan Misra",
      "Ji Hou",
      "Jialiang Wang",
      "Kiran Jagadeesh",
      "Kunpeng Li",
      "Luxin Zhang",
      "Mannat Singh",
      "Mary Williamson",
      "Matt Le",
      "Matthew Yu",
      "Mitesh Kumar Singh",
      "Peizhao Zhang",
      "Peter Vajda",
      "Quentin Duval",
      "Rohit Girdhar",
      "Roshan Sumbaly",
      "Sai Saketh Rambhatla",
      "Sam Tsai",
      "Samaneh Azadi",
      "Samyak Datta",
      "Sanyuan Chen",
      "Sean Bell",
      "Sharadh Ramaswamy",
      "Shelly Sheynin",
      "Siddharth Bhattacharya",
      "Simran Motwani",
      "Tao Xu",
      "Tianhe Li",
      "Tingbo Hou",
      "Wei-Ning Hsu",
      "Xi Yin",
      "Xiaoliang Dai",
      "Yaniv Taigman",
      "Yaqiao Luo",
      "Yen-Cheng Liu",
      "Yi-Chiao Wu",
      "Yue Zhao",
      "Yuval Kirstain",
      "Zecheng He",
      "Zijian He",
      "Albert Pumarola",
      "Ali Thabet",
      "Artsiom Sanakoyeu",
      "Arun Mallya",
      "Baishan Guo",
      "Boris Araya",
      "Breena Kerr",
      "Carleigh Wood",
      "Ce Liu",
      "Cen Peng",
      "Dimitry Vengertsev",
      "Edgar Schonfeld",
      "Elliot Blanchard",
      "Felix Juefei-Xu",
      "Fraylie Nord",
      "Jeff Liang",
      "John Hoffman",
      "Jonas Kohler",
      "Kaolin Fire",
      "Karthik Sivakumar",
      "Lawrence Chen",
      "Licheng Yu",
      "Luya Gao",
      "Markos Georgopoulos",
      "Rashel Moritz",
      "Sara K. Sampson",
      "Shikai Li",
      "Simone Parmeggiani",
      "Steve Fine",
      "Tara Fowler",
      "Vladan Petrovic",
      "Yuming Du"
    ],
    "abstract": "We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.",
    "pdf_url": "http://arxiv.org/pdf/2410.13720v2",
    "published": "2024-10-17T16:22:46+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13719v1",
    "title": "Reverse stealth construction and its thermodynamic imprints",
    "authors": [
      "Cristián Erices",
      "Luis Guajardo",
      "Kristiansen Lara"
    ],
    "abstract": "We study a class of solutions within the context of modified gravity\ntheories, characterized by a non-trivial field that does not generate any\nback-reaction on the metric. These stealth configurations are effectively\ndefined by the stealth conditions, which correspond to a vanishing\nstress-energy tensor. In this work, we introduce a novel approach to\nconstructing this class of solutions. In contrast to the standard procedure,\nthe starting point requires satisfying the stealth conditions for a given\nansatz independently of the gravitational dynamics. This approach\nsimultaneously determines the non-trivial field and the geometries capable of\nsupporting it as a stealth configuration. Consequently, a gravity model can\naccommodate a stealth field only if its vacuum solution falls within the\ngeometries permissible under stealth conditions. By applying this reverse\nprocedure in the non-minimal $R\\phi^2$ coupling, we recover all previously\nknown stealth configurations and present new solutions. Although it seems\nintuitive to assume that this ``gravitationally undetectable'' scalar field\nleaves no physical traces, it remarkably reveals thermodynamic imprints, as its\npresence screens the black hole mass and modifies the entropy according to the\nfirst law.",
    "pdf_url": "http://arxiv.org/pdf/2410.13719v1",
    "published": "2024-10-17T16:20:42+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13718v1",
    "title": "Maximal Transmission Rate in Omni-DRIS-Assisted Indoor Visible Light Communication Systems",
    "authors": [
      "Alain R. Ndjiongue",
      "Octavia A. Dobre",
      "Hyundong Shin"
    ],
    "abstract": "Given the importance of reconfigurable intelligent surfaces (RISs) in\nnext-generation mobile systems, several RIS variants have been proposed in\nrecent years. Omni-digital-RIS (omni-DRIS) is one of the newly introduced\nvariants of optical RIS that can successfully be driven by bit sequences to\ncontrol lights emerging from simultaneous reflection and refraction processes,\nimpacting both the achievable rate and the required number of omni-DRIS\nelements. In this paper, we analyze the effects of omni-DRIS-assisted\ntransmission environment parameters to maximize the achievable rate and\nhighlight the corresponding number of omni-DRIS elements. Furthermore, we show\nthat the number of omni-DRIS elements that yields the highest achievable rate\nlargely depends on the number of bits per omni-DRIS control sequence. On the\nother hand, this rate is determined by the remaining parameters of the\ntransmission system and environmental factors, which include the total transmit\npower, transmission bandwidth, number of transmitters and users, and the\nchannel DC gain.",
    "pdf_url": "http://arxiv.org/pdf/2410.13718v1",
    "published": "2024-10-17T16:20:39+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13717v1",
    "title": "Designing a Validation Experiment for Radio Frequency Condensation",
    "authors": [
      "Lanke Fu",
      "E. Litvinova Mitra",
      "R. Nies",
      "A. H. Reiman",
      "M. Austin",
      "L. Bardoczi",
      "M. Brookman",
      "Xi Chen",
      "W. Choi",
      "N. J. Fisch",
      "Q. Hu",
      "A. Hyatt",
      "E. Jung",
      "R. La Haye",
      "N. C. Logan",
      "M. Maraschek",
      "J. J. McClenaghan",
      "E. Strait",
      "A. Welander",
      "J. Yang",
      "ASDEX Upgrade team"
    ],
    "abstract": "Theoretical studies have suggested that nonlinear effects can lead to \"radio\nfrequency condensation\", which coalesces RF power deposition and driven current\nnear the center of a magnetic island. It is predicted that an initially broad\ncurrent profile can coalesce in islands when they reach sufficient width,\nproviding automatic stabilization. Experimental validation of the theory has\nthus far been lacking. This paper proposes experiments on DIII-D for testing\nand refining the theory of the nonlinear effects.",
    "pdf_url": "http://arxiv.org/pdf/2410.13717v1",
    "published": "2024-10-17T16:20:19+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13716v2",
    "title": "MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems",
    "authors": [
      "Nandan Thakur",
      "Suleman Kazi",
      "Ge Luo",
      "Jimmy Lin",
      "Amin Ahmad"
    ],
    "abstract": "Traditional retrieval-augmented generation (RAG) benchmarks evaluate systems\nusing heuristic-based metrics, but these require human preferences as the\nground truth for reference. In contrast, arena-based benchmarks, where systems\ncompete against each other, require an expensive large language model (LLM) as\na judge for a reliable evaluation. We present a simple efficient technique to\ncombine the best of both worlds. The idea is to train a surrogate judge using\nheuristic metrics as input, to output the LLM as a judge prediction. In our\nwork, we develop MIRAGE-Bench, a synthetic arena-based RAG benchmark for 18\ndiverse languages on Wikipedia focused on multilingual answer generation\nevaluation. It extensively couples both heuristic features and LLM as a judge\nfor evaluation. We benchmark 19 multilingual LLMs, and observe a high\ncorrelation (Kendall Tau ($\\tau$) = 0.909) using our surrogate judge and\nbetween GPT-4o as a teacher using the Bradley-Terry framework. Our results show\nproprietary and large open-source LLMs currently dominate on MIRAGE-Bench. Our\ncode and datasets are made publicly available here:\nhttps://github.com/vectara/mirage-bench.",
    "pdf_url": "http://arxiv.org/pdf/2410.13716v2",
    "published": "2024-10-17T16:18:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13715v1",
    "title": "Electronic Raman scattering of antiferromagnetic excitonic insulators",
    "authors": [
      "Hidemaro Suwa",
      "Shang-Shun Zhang",
      "Cristian D. Batista"
    ],
    "abstract": "The excitonic insulator, a quantum mechanical state arising from exciton\ncondensation, was proposed theoretically many years ago but has yet to be\nexperimentally confirmed. The discovery of correlated transition metal oxides\nbased on $4d$ and $5d$ elements, where the on-site Coulomb repulsion is\ncomparable to the dominant hopping amplitude, presents a unique opportunity to\nstudy exciton condensation. By constructing an effective mean field Raman\noperator for the Hubbard model, we derive the low-energy electronic Raman\nscattering cross section, demonstrating Raman spectroscopy as a powerful tool\nfor detecting exciton condensation. Here, we demonstrate that Raman scattering\ndirectly reveals exciton condensation in the bilayer iridate Sr$_3$Ir$_2$O$_7$\nunder pressure.",
    "pdf_url": "http://arxiv.org/pdf/2410.13715v1",
    "published": "2024-10-17T16:16:28+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13714v5",
    "title": "Generation through the lens of learning theory",
    "authors": [
      "Jiaxun Li",
      "Vinod Raman",
      "Ambuj Tewari"
    ],
    "abstract": "We study generation through the lens of statistical learning theory. First,\nwe abstract and formalize the results of Gold [1967], Angluin [1979], Angluin\n[1980] and Kleinberg and Mullainathan [2024] in terms of a binary hypothesis\nclass defined over an abstract example space. Then, we extend the notion of\n\"generation\" from Kleinberg and Mullainathan [2024] to two new settings, we\ncall \"uniform\" and \"non-uniform\" generation, and provide a characterization of\nwhich hypothesis classes are uniformly and non-uniformly generatable. As is\nstandard in learning theory, our characterizations are in terms of the\nfiniteness of a new combinatorial dimension termed the Closure dimension. By\ndoing so, we are able to compare generatability with predictability (captured\nvia PAC and online learnability) and show that these two properties of\nhypothesis classes are incompatible -- there are classes that are generatable\nbut not predictable and vice versa. Finally, we extend our results to capture\nprompted generation and give a complete characterization of which classes are\nprompt generatable, generalizing some of the work by Kleinberg and Mullainathan\n[2024].",
    "pdf_url": "http://arxiv.org/pdf/2410.13714v5",
    "published": "2024-10-17T16:14:49+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13713v1",
    "title": "CrystalX: Ultra-Precision Crystal Structure Resolution and Error Correction Using Deep Learning",
    "authors": [
      "Kaipeng Zheng",
      "Weiran Huang",
      "Wanli Ouyang",
      "Han-Sen Zhong",
      "Yuqiang Li"
    ],
    "abstract": "Atomic structure analysis of crystalline materials is a paramount endeavor in\nboth chemical and material sciences. This sophisticated technique necessitates\nnot only a solid foundation in crystallography but also a profound\ncomprehension of the intricacies of the accompanying software, posing a\nsignificant challenge in meeting the rigorous daily demands. For the first\ntime, we confront this challenge head-on by harnessing the power of deep\nlearning for ultra-precise structural analysis at the full-atom level. To\nvalidate the performance of the model, named CrystalX, we employed a vast\ndataset comprising over 50,000 X-ray diffraction measurements derived from\nauthentic experiments, demonstrating performance that is commensurate with\nhuman experts and adept at deciphering intricate geometric patterns.\nRemarkably, CrystalX revealed that even peer-reviewed publications can harbor\nerrors that are stealthy to human scrutiny, yet CrystalX adeptly rectifies\nthem. This deep learning model revolutionizes the time frame for crystal\nstructure analysis, slashing it down to seconds. It has already been\nsuccessfully applied in the structure analysis of newly discovered compounds in\nthe latest research without human intervention. Overall, CrystalX marks the\nbeginning of a new era in automating routine structural analysis within\nself-driving laboratories.",
    "pdf_url": "http://arxiv.org/pdf/2410.13713v1",
    "published": "2024-10-17T16:12:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13712v2",
    "title": "The Affleck-Dine Curvaton",
    "authors": [
      "Aurora Ireland",
      "Gordan Krnjaic",
      "Takuya Okawa"
    ],
    "abstract": "The Standard Model of particle physics does not explain the origin of the\nuniverse's baryon asymmetry or its primordial fluctuations. The Affleck-Dine\nmechanism is a well-motivated scenario for generating the baryon asymmetry\nthrough the post-inflationary dynamics of a complex scalar field with baryon\nnumber. The curvaton mechanism is a popular approach for producing curvature\nperturbations through the dynamics of a light spectator field which decays\nafter inflation. We demonstrate that the same complex field can viably perform\nboth roles without any modifications to the minimal realization of Affleck-Dine\nbaryogenesis. This scenario can also accommodate appreciable levels of\nprimordial non-Gaussianity, beyond those achievable with only a real-valued\ncurvaton field, and may be observable with future CMB experiments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13712v2",
    "published": "2024-10-17T16:12:26+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13711v1",
    "title": "Automated classification of individual atoms on surfaces using machine learning",
    "authors": [
      "Angéline Lafleur",
      "Soo-hyon Phark"
    ],
    "abstract": "Leveraging scanning tunneling microscopy (STM) for atomic-scale fabrication\nhas led to many advancements such as the creation of atomic electron-spin qubit\nstructures on surfaces. However, the time-consuming and tedious nature of this\nprocess calls for improvements, and this study explores the use of machine\nlearning (ML) to automate certain steps, notably identifying appropriate atomic\ncandidates for the structures. We classify titanium and iron atoms on a\nmagnesium oxide (MgO) surface, which are prototypical on-surface spin qubit\ncandidates, showing distinct topographic and spectroscopic features depending\non the bonding sites of the MgO surface. Employing a semi-automated computer\nvision process, we train a convolutional neural network with STM topographic\nimages and scanning tunneling spectroscopy (STS) curves of several hundred\natoms. After training, the topography model achieves an 86% validation accuracy\nin classifying 200 new images, and the STS model, a 100% accuracy for a sample\nsize of 100 atoms. This method extends its applicability to various nanoscopic\nmeasurements, including atomically resolved imaging and local probing of\nelectronic properties, offering a promising approach for classifying atoms and\nmolecules on surfaces.",
    "pdf_url": "http://arxiv.org/pdf/2410.13711v1",
    "published": "2024-10-17T16:11:16+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13710v1",
    "title": "Linear-Threshold Network Models for Describing and Analyzing Brain Dynamics",
    "authors": [
      "Michael McCreesh",
      "Erfan Nozari",
      "Jorge Cortes"
    ],
    "abstract": "Over the past two decades, an increasing array of control-theoretic methods\nhave been used to study the brain as a complex dynamical system and better\nunderstand its structure-function relationship. This article provides an\noverview on one such family of methods, based on the linear-threshold rate\n(LTR) dynamics, which arises when modeling the spiking activity of neuronal\npopulations and their impact on each other. LTR dynamics exhibit a wide range\nof behaviors based on network topologies and inputs, including mono- and\nmulti-stability, limit cycles, and chaos, allowing it to be used to model many\ncomplex brain processes involving fast and slow inhibition, multiple time and\nspatial scales, different types of neural behavior, and higher-order\ninteractions. Here we investigate how the versatility of LTR dynamics paired\nwith concepts and tools from systems and control can provide a computational\ntheory for explaining the dynamical mechanisms enabling different brain\nprocesses. Specifically, we illustrate stability and stabilization properties\nof LTR dynamics and how they are related to goal-driven selective attention,\nmultistability and its relationship with declarative memory, and bifurcations\nand oscillations and their role in modeling seizure dynamics in epilepsy. We\nconclude with a discussion on additional properties of LTR dynamics and an\noutlook on other brain processess that for which they might be play a similar\nrole.",
    "pdf_url": "http://arxiv.org/pdf/2410.13710v1",
    "published": "2024-10-17T16:11:10+00:00",
    "categories": [
      "q-bio.NC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13709v2",
    "title": "On-device Federated Learning in Smartphones for Detecting Depression from Reddit Posts",
    "authors": [
      "Mustofa Ahmed",
      "Abdul Muntakim",
      "Nawrin Tabassum",
      "Mohammad Asifur Rahim",
      "Faisal Muhammad Shah"
    ],
    "abstract": "Depression detection using deep learning models has been widely explored in\nprevious studies, especially due to the large amounts of data available from\nsocial media posts. These posts provide valuable information about individuals'\nmental health conditions and can be leveraged to train models and identify\npatterns in the data. However, distributed learning approaches have not been\nextensively explored in this domain. In this study, we adopt Federated Learning\n(FL) to facilitate decentralized training on smartphones while protecting user\ndata privacy. We train three neural network architectures--GRU, RNN, and LSTM\non Reddit posts to detect signs of depression and evaluate their performance\nunder heterogeneous FL settings. To optimize the training process, we leverage\na common tokenizer across all client devices, which reduces the computational\nload. Additionally, we analyze resource consumption and communication costs on\nsmartphones to assess their impact in a real-world FL environment. Our\nexperimental results demonstrate that the federated models achieve comparable\nperformance to the centralized models. This study highlights the potential of\nFL for decentralized mental health prediction by providing a secure and\nefficient model training process on edge devices.",
    "pdf_url": "http://arxiv.org/pdf/2410.13709v2",
    "published": "2024-10-17T16:09:32+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13708v2",
    "title": "On the Role of Attention Heads in Large Language Model Safety",
    "authors": [
      "Zhenhong Zhou",
      "Haiyang Yu",
      "Xinghua Zhang",
      "Rongwu Xu",
      "Fei Huang",
      "Kun Wang",
      "Yang Liu",
      "Junfeng Fang",
      "Yongbin Li"
    ],
    "abstract": "Large language models (LLMs) achieve state-of-the-art performance on multiple\nlanguage tasks, yet their safety guardrails can be circumvented, leading to\nharmful generations. In light of this, recent research on safety mechanisms has\nemerged, revealing that when safety representations or component are\nsuppressed, the safety capability of LLMs are compromised. However, existing\nresearch tends to overlook the safety impact of multi-head attention\nmechanisms, despite their crucial role in various model functionalities. Hence,\nin this paper, we aim to explore the connection between standard attention\nmechanisms and safety capability to fill this gap in the safety-related\nmechanistic interpretability. We propose a novel metric which tailored for\nmulti-head attention, the Safety Head ImPortant Score (Ships), to assess the\nindividual heads' contributions to model safety. Based on this, we generalize\nShips to the dataset level and further introduce the Safety Attention Head\nAttRibution Algorithm (Sahara) to attribute the critical safety attention heads\ninside the model. Our findings show that the special attention head has a\nsignificant impact on safety. Ablating a single safety head allows aligned\nmodel (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,\nwhile only modifying 0.006% of the parameters, in contrast to the ~ 5%\nmodification required in previous studies. More importantly, we demonstrate\nthat attention heads primarily function as feature extractors for safety and\nmodels fine-tuned from the same base model exhibit overlapping safety heads\nthrough comprehensive experiments. Together, our attribution approach and\nfindings provide a novel perspective for unpacking the black box of safety\nmechanisms within large models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13708v2",
    "published": "2024-10-17T16:08:06+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13707v2",
    "title": "Disjointness Violations in Wikidata",
    "authors": [
      "Ege Atacan Doğan",
      "Peter F. Patel-Schneider"
    ],
    "abstract": "Disjointness checks are among the most important constraint checks in a\nknowledge base and can be used to help detect and correct incorrect statements\nand internal contradictions. Wikidata is a very large, community-managed\nknowledge base. Because of both its size and construction, Wikidata contains\nmany incorrect statements and internal contradictions. We analyze the current\nmodeling of disjointness on Wikidata, identify patterns that cause these\ndisjointness violations and categorize them. We use SPARQL queries to identify\neach ``culprit'' causing a disjointness violation and lay out formulas to\nidentify and fix conflicting information. We finally discuss how disjointness\ninformation could be better modeled and expanded in Wikidata in the future.",
    "pdf_url": "http://arxiv.org/pdf/2410.13707v2",
    "published": "2024-10-17T16:07:51+00:00",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13706v1",
    "title": "Phase transitions in the spin-1/2 Heisenberg antiferromagnet on the dimerized diamond lattice",
    "authors": [
      "Ronja Bärwolf",
      "Alexander Sushchyev",
      "Francesco Parisen Toldin",
      "Stefan Wessel"
    ],
    "abstract": "Using a combination of unbiased quantum Monte Carlo simulations and a\ndecoupled dimer mean-field theory, we investigate the thermal and quantum phase\ntransitions of the spin-1/2 Heisenberg model on the dimerized diamond lattice.\nWe find that at sufficiently strong dimerization the system exhibits a quantum\ndisordered ground state, in contrast to the antiferromagnetic phase stabilized\nat weak dimerization. We determine the quantum critical point and examine the\nthermodynamic responses in both regimes. The ratio for the critical interdimer\n($J_c$) to intradimer ($J_D$) coupling is obtained as $J_c/J_D = 0.3615(5)$.\nOur results show that the decoupled dimer mean-field theory well captures the\ncompetition between the local singlet formation and the antiferromagnetic\nordering tendency, and thus provides an appropriate qualitative description of\nthis three-dimensional quantum magnet, in contrast to the conventional\nmean-field decoupling. We also examine the differences in the ordering\ntemperatures between the antiferromagnetic and the ferromagnetic spin-1/2\nHeisenberg model on the diamond lattice based on quantum Monte Carlo\nsimulations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13706v1",
    "published": "2024-10-17T16:06:26+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13705v3",
    "title": "Collective dynamics of densely confined active polar disks with self- and mutual alignment",
    "authors": [
      "Weizhen Tang",
      "Yating Zheng",
      "Amir Shee",
      "Guozheng Lin",
      "Zhangang Han",
      "Pawel Romanczuk",
      "Cristián Huepe"
    ],
    "abstract": "We study the emerging collective states in a simple mechanical model of a\ndense group of self-propelled polar disks with off-centered rotation, confined\nwithin a circular arena. Each disk presents self-alignment towards the sum of\ncontact forces acting on it, resulting from disk-substrate interactions, while\nalso displaying mutual alignment with neighbors due to having its center of\nrotation located a distance R behind its centroid so that central contact\nforces can also introduce torques. The effect of both alignment mechanisms\nproduces a variety of collective states that combine high-frequency localized\ncircular oscillations with low-frequency milling around the center of the\narena, in fluid or solid regimes. We consider cases with small/large R values,\nisotropic/anisotropic disk-substrate damping, smooth/rough arena boundaries,\ndifferent densities, and multiple systems sizes, showing that the emergent\ncollective states that we identify are robust, generic, and potentially\nobservable in real-world natural or artificial systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13705v3",
    "published": "2024-10-17T16:06:18+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13704v2",
    "title": "Aluminum goalpost nano-mechanical devices at low temperatures",
    "authors": [
      "Baptiste Alperin",
      "Ilya Golokolenov",
      "Gwénaëlle Julié",
      "Bruno Fernandez",
      "Andrew Fefferman",
      "Eddy Collin"
    ],
    "abstract": "Mechanical objects have been widely used at low temperatures for decades, for\nvarious applications; from quantum fluids sensing with vibrating wires or\ntuning forks, to torsional oscillators for the study of mechanical properties\nof glasses, and finally micro and nano-mechanical objects with the advent of\nclean room technologies. These small structures opened up new possibilities to\nexperimentalists, thanks to their small size. We report on the characterization\nof purely metallic goalpost nano-mechanical structures, which are employed\ntoday for both quantum fluids studies (especially quantum turbulence in $^4$He,\n$^3$He) and intrinsic friction studies (Two-Level-Systems unraveling).\nExtending existing literature, we demonstrate the analytic modeling of the\nresonances, in good agreement with numerical simulations, for both first and\nsecond mechanical modes. Especially, the impact of the curvature of the whole\nstructure (and therefore, in-built surface stress) is analyzed, together with\nnonlinear properties. We demonstrate that these are of geometrical origin, and\ndevice-dependent. Motion and forces are expressed in meters and Newtons\nexperienced at the level of the goalpost's paddle, for any magnitude or\ncurvature, which is of particular importance for quantum fluids and solids\nstudies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13704v2",
    "published": "2024-10-17T16:05:44+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13703v2",
    "title": "A new framework for particle-wave interaction",
    "authors": [
      "Toan T. Nguyen"
    ],
    "abstract": "In plasma physics, collisionless charged particles are transported following\nthe dynamics of a meanfield Vlasov equation with a self-consistent electric\nfield generated by the charge density. Due to the long range interaction\nbetween particles, the generating electric field oscillates and disperses like\na Klein-Gordon dispersive wave, known in the physical literature as plasma\noscillations or Langmuir's oscillatory waves. The oscillatory electric field\nthen in turn drives particles. Despite its great physical importance, the\nquestion of whether such a nonlinear particle-wave interaction would remain\nregular globally and be damped in the large time has been an outstanding open\nproblem. In this paper, we propose a new framework to resolve this exact\nnonlinear interaction. Specifically, we employ the framework to establish the\nlarge time behavior and scattering of solutions to the nonlinear\nVlasov-Klein-Gordon system in the small initial data regime. The novelty of\nthis work is to provide a detailed physical space description of particles\nmoving in an oscillatory field and to resolve oscillations for the electric\nfield generated by the collective interacting particles. This appears to be the\nfirst such a result analyzing oscillations in the physical phase space\n$\\mathbb{R}^3_x\\times \\mathbb{R}_v^3$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13703v2",
    "published": "2024-10-17T16:05:24+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "physics.plasm-ph"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13702v1",
    "title": "Experimental composable key distribution using discrete-modulated continuous variable quantum cryptography",
    "authors": [
      "Adnan A. E. Hajomer",
      "Florian Kanitschar",
      "Nitin Jain",
      "Michael Hentschel",
      "Runjia Zhang",
      "Norbert Lütkenhaus",
      "Ulrik L. Andersen",
      "Christoph Pacher",
      "Tobias Gehring"
    ],
    "abstract": "Establishing secure data communication necessitates secure key exchange over\na public channel. Quantum key distribution (QKD), which leverages the\nprinciples of quantum physics, can achieve this with information-theoretic\nsecurity. The discrete modulated (DM) continuous variable (CV) QKD protocol, in\nparticular, is a suitable candidate for large-scale deployment of quantum-safe\ncommunication due to its simplicity and compatibility with standard high-speed\ntelecommunication technology. Here, we present the first experimental\ndemonstration of a four-state DM CVQKD system, successfully generating\ncomposable finite-size keys, secure against collective attacks over a 20 km\nfiber channel with 2.3 \\times 10^{9} coherent quantum states, achieving a\npositive composable key rate of 11.04 \\times 10^{-3} bits/symbol. This\naccomplishment is enabled by using an advanced security proof, meticulously\nselecting its parameters, and the fast, stable operation of the system. Our\nresults mark a significant step toward the large-scale deployment of practical,\nhigh-performance, cost-effective, and highly secure quantum key distribution\nnetworks using standard telecommunication components.",
    "pdf_url": "http://arxiv.org/pdf/2410.13702v1",
    "published": "2024-10-17T16:05:08+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13701v2",
    "title": "$L_p$ estimates in the Androulidakis-Mohsen-Yuncken calculus",
    "authors": [
      "Edward McDonald"
    ],
    "abstract": "We prove that order zero operators in the pseudodifferential calculus\nassociated to a filtration defined by Androulidakis, Mohsen and Yuncken are\nbounded on $L_p$ spaces for $1<p<\\infty.$",
    "pdf_url": "http://arxiv.org/pdf/2410.13701v2",
    "published": "2024-10-17T16:05:07+00:00",
    "categories": [
      "math.FA",
      "math.AP",
      "47G30, 35H10, 58J40"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13700v1",
    "title": "Real Eventual Exponential Positivity of Complex-valued Laplacians: Applications to Consensus in Multi-agent Systems",
    "authors": [
      "Aditi Saxena",
      "Twinkle Tripathy",
      "Rajasekhar Anguluri"
    ],
    "abstract": "In this paper, we explore the property of eventual exponential positivity\n(EEP) in complex matrices. We show that this property holds for the real part\nof the matrix exponential for a certain class of complex matrices. Next, we\npresent the relation between the spectral properties of the Laplacian matrix of\nan unsigned digraph with complex edge-weights and the property of real EEP.\nFinally, we show that the Laplacian flow system of a network is stable when the\nnegated Laplacian admits real EEP. Numerical examples are presented to\ndemonstrate the results.",
    "pdf_url": "http://arxiv.org/pdf/2410.13700v1",
    "published": "2024-10-17T16:04:12+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13699v2",
    "title": "Unconstrained Model Merging for Enhanced LLM Reasoning",
    "authors": [
      "Yiming Zhang",
      "Baoyi He",
      "Shengyu Zhang",
      "Yuhao Fu",
      "Qi Zhou",
      "Zhijie Sang",
      "Zijin Hong",
      "Kejing Yang",
      "Wenjun Wang",
      "Jianbo Yuan",
      "Guanghan Ning",
      "Linyi Li",
      "Chunlin Ji",
      "Fei Wu",
      "Hongxia Yang"
    ],
    "abstract": "Recent advancements in building domain-specific large language models (LLMs)\nhave shown remarkable success, especially in tasks requiring reasoning\nabilities like logical inference over complex relationships and multi-step\nproblem solving. However, creating a powerful all-in-one LLM remains\nchallenging due to the need for proprietary data and vast computational\nresources. As a resource-friendly alternative, we explore the potential of\nmerging multiple expert models into a single LLM. Existing studies on model\nmerging mainly focus on generalist LLMs instead of domain experts, or the LLMs\nunder the same architecture and size. In this work, we propose an unconstrained\nmodel merging framework that accommodates both homogeneous and heterogeneous\nmodel architectures with a focus on reasoning tasks. A fine-grained layer-wise\nweight merging strategy is designed for homogeneous models merging, while\nheterogeneous model merging is built upon the probabilistic distribution\nknowledge derived from instruction-response fine-tuning data. Across 7\nbenchmarks and 9 reasoning-optimized LLMs, we reveal key findings that\ncombinatorial reasoning emerges from merging which surpasses simple additive\neffects. We propose that unconstrained model merging could serve as a\nfoundation for decentralized LLMs, marking a notable progression from the\nexisting centralized LLM framework. This evolution could enhance wider\nparticipation and stimulate additional advancement in the field of artificial\nintelligence, effectively addressing the constraints posed by centralized\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2410.13699v2",
    "published": "2024-10-17T16:04:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13698v1",
    "title": "Simulation of longitudinal Landau damping in bunches with space charge",
    "authors": [
      "Oliver Boine-Frankenheim",
      "Thilo Egenolf"
    ],
    "abstract": "For a single hadron bunch affected by longitudinal space charge in a\nstationary rf bucket we analyze the frequency spectrum close to the expected\nloss of Landau damping for the lowest order dipole mode. For different bunch\nintensity parameters we obtain the bunch oscillation spectrum from a\nconventional longitudinal particle tracking code with a grid-based space charge\nsolver. We validate selected results against a grid-less space charge solver.\nWe highlight the importance of the choice of the cut-off parameter $h_c$ in the\nspace charge impedance for the long-term accuracy of grid-based schemes. For\ntypical bunch parameters in an ion synchrotron at injection energies we find\nthat the branching point, where the dipole mode frequency emerges from the\nincoherent synchrotron frequency spectrum, as well as the damping of the dipole\nmode do not depend on $h_c$, chosen well below the actual value for realistic\nbeam pipes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13698v1",
    "published": "2024-10-17T16:03:59+00:00",
    "categories": [
      "physics.acc-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13697v1",
    "title": "Admissibility and generalized nonuniform dichotomies for nonautonomous Random Dynamical Systems",
    "authors": [
      "Davor Dragicevic",
      "Cesar M. Silva",
      "Helder Vilarinho"
    ],
    "abstract": "In this paper, we introduce generalized dichotomies for nonautonomous random\nlinear dynamical systems acting on arbitrary Banach spaces, and obtain their\ncomplete characterization in terms of an appropriate admissibility property.\nThese generalized dichotomies are associated to growth rates satisfying mild\nconditions and they include the standard exponential behavior as a very\nparticular case. As a nontrivial application, we establish the robustness\nproperty of such dichotomies under small (linear) perturbations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13697v1",
    "published": "2024-10-17T16:03:55+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13696v2",
    "title": "Online Learning for Function Placement in Serverless Computing",
    "authors": [
      "Wei Huang",
      "Richard Combes",
      "Andrea Araldo",
      "Hind Castel-Taleb",
      "Badii Jouaber"
    ],
    "abstract": "We study the placement of virtual functions aimed at minimizing the cost. We\npropose a novel algorithm, using ideas based on multi-armed bandits. We prove\nthat these algorithms learn the optimal placement policy rapidly, and their\nregret grows at a rate at most $O( N M \\sqrt{T\\ln T} )$ while respecting the\nfeasibility constraints with high probability, where $T$ is total time slots,\n$M$ is the number of classes of function and $N$ is the number of computation\nnodes. We show through numerical experiments that the proposed algorithm both\nhas good practical performance and modest computational complexity. We propose\nan acceleration technique that allows the algorithm to achieve good performance\nalso in large networks where computational power is limited. Our experiments\nare fully reproducible, and the code is publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2410.13696v2",
    "published": "2024-10-17T16:03:43+00:00",
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13695v2",
    "title": "Zarankiewicz bounds from distal regularity lemma",
    "authors": [
      "Mervyn Tong"
    ],
    "abstract": "Since K\\H{o}v\\'ari, S\\'os, and Tur\\'an proved upper bounds for the\nZarankiewicz problem in 1954, much work has been undertaken to improve these\nbounds, and some have done so by restricting to particular classes of graphs.\nIn 2017, Fox, Pach, Sheffer, Suk, and Zahl proved better bounds for\nsemialgebraic binary relations, and this work was extended by Do in the\nfollowing year to arbitrary semialgebraic relations. In this paper, we show\nthat Zarankiewicz bounds in the shape of Do's are enjoyed by all relations\nsatisfying the distal regularity lemma, an improved version of the Szemer\\'edi\nregularity lemma satisfied by relations definable in distal structures (a vast\ngeneralisation of o-minimal structures).",
    "pdf_url": "http://arxiv.org/pdf/2410.13695v2",
    "published": "2024-10-17T16:03:35+00:00",
    "categories": [
      "math.CO",
      "math.LO",
      "Primary 05C35, 05C75. Secondary 03C45, 03C64"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13694v1",
    "title": "Exploring the Design Space of Visual Context Representation in Video MLLMs",
    "authors": [
      "Yifan Du",
      "Yuqi Huo",
      "Kun Zhou",
      "Zijia Zhao",
      "Haoyu Lu",
      "Han Huang",
      "Wayne Xin Zhao",
      "Bingning Wang",
      "Weipeng Chen",
      "Ji-Rong Wen"
    ],
    "abstract": "Video Multimodal Large Language Models (MLLMs) have shown remarkable\ncapability of understanding the video semantics on various downstream tasks.\nDespite the advancements, there is still a lack of systematic research on\nvisual context representation, which refers to the scheme to select frames from\na video and further select the tokens from a frame. In this paper, we explore\nthe design space for visual context representation, and aim to improve the\nperformance of video MLLMs by finding more effective representation schemes.\nFirstly, we formulate the task of visual context representation as a\nconstrained optimization problem, and model the language modeling loss as a\nfunction of the number of frames and the number of embeddings (or tokens) per\nframe, given the maximum visual context window size. Then, we explore the\nscaling effects in frame selection and token selection respectively, and fit\nthe corresponding function curve by conducting extensive empirical experiments.\nWe examine the effectiveness of typical selection strategies and present\nempirical findings to determine the two factors. Furthermore, we study the\njoint effect of frame selection and token selection, and derive the optimal\nformula for determining the two factors. We demonstrate that the derived\noptimal settings show alignment with the best-performed results of empirical\nexperiments. Our code and model are available at:\nhttps://github.com/RUCAIBox/Opt-Visor.",
    "pdf_url": "http://arxiv.org/pdf/2410.13694v1",
    "published": "2024-10-17T15:59:52+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13693v1",
    "title": "A multiscale method for data collected from network edges via the line graph",
    "authors": [
      "Dingjia Cao",
      "Marina I. Knight",
      "Guy P. Nason"
    ],
    "abstract": "Data collected over networks can be modelled as noisy observations of an\nunknown function over the nodes of a graph or network structure, fully\ndescribed by its nodes and their connections, the edges. In this context,\nfunction estimation has been proposed in the literature and typically makes use\nof the network topology such as relative node arrangement, often using given or\nartificially constructed node Euclidean coordinates. However, networks that\narise in fields such as hydrology (for example, river networks) present\nfeatures that challenge these established modelling setups since the target\nfunction may naturally live on edges (e.g., river flow) and/or the\nnode-oriented modelling uses noisy edge data as weights. This work tackles\nthese challenges and develops a novel lifting scheme along with its associated\n(second) generation wavelets that permit data decomposition across the network\nedges. The transform, which we refer to under the acronym LG-LOCAAT, makes use\nof a line graph construction that first maps the data in the line graph domain.\nWe thoroughly investigate the proposed algorithm's properties and illustrate\nits performance versus existing methodologies. We conclude with an application\npertaining to hydrology that involves the denoising of a water quality index\nover the England river network, backed up by a simulation study for a river\nflow dataset.",
    "pdf_url": "http://arxiv.org/pdf/2410.13693v1",
    "published": "2024-10-17T15:56:55+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13692v1",
    "title": "Magnetic Field Simulation and Correlated Low-Frequency Noise Subtraction for an In-Orbit Demonstrator of Magnetic Measurements",
    "authors": [
      "Cristian Maria-Moreno",
      "Ignacio Mateos",
      "Guillermo Pacheco-Ramos",
      "Francisco Rivas",
      "María-Ángeles Cifredo-Chacón",
      "Ángel Quirós-Olozábal",
      "José-María Guerrero-Rodríguez",
      "Nikolaos Karnesis"
    ],
    "abstract": "In recent years, nanosatellites have revolutionized the space sector due to\ntheir significant economic and time-saving advantages. As a result, they have\nfostered the testing of advanced instruments intended for larger space science\nmissions. The case of MELISA is presented in this work. MELISA is a magnetic\nmeasurement instrument which aims at demonstrating the in-orbit performance of\nAMR sensors featuring dedicated noise reduction techniques at sub-millihertz\nfrequencies. Such low frequency ranges are relevant for future space-borne\ngravitational wave detectors, where the local magnetic environment of the\nsatellite might yield a significant contribution to the overall noise budget of\nthe observatory. The demanding magnetic noise levels required for this\nbandwidth, down to 0.1 mHz, make measurements arduous. To explore sensing\nsolutions within the H2020 European Commission Programme with the involvement\nof ESA, the functional performance of MELISA-III will be validated in-orbit.\nDuring operations, there is the possibility to measure the low-frequency\nmagnetic contribution stemming from orbiting the Earth's magnetic field,\nimpeding the characterization of the intrinsic performance of the sensor. With\nthe objective of minimizing excess noise during the in-flight operations, the\npresent research aims to simulate the environmental magnetic conditions in LEO\nto identify and subtract undesired contributions to the measurements. The\nin-orbit long-term magnetic fluctuations are replicated using a Helmholtz coil\nsystem. A fluxgate magnetometer allows the correlation of the generated field\nwith the payload measurements, leading to the subsequent subtraction. Proving\nthe effect of this approach will facilitate the noise characterization of\nmagnetic sensors in LEO, paving the way for the in-orbit validation of\nMELISA-III for use in magnetically demanding missions with long integration\ntimes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13692v1",
    "published": "2024-10-17T15:56:00+00:00",
    "categories": [
      "astro-ph.IM",
      "physics.ins-det"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13691v2",
    "title": "Jailbreaking LLM-Controlled Robots",
    "authors": [
      "Alexander Robey",
      "Zachary Ravichandran",
      "Vijay Kumar",
      "Hamed Hassani",
      "George J. Pappas"
    ],
    "abstract": "The recent introduction of large language models (LLMs) has revolutionized\nthe field of robotics by enabling contextual reasoning and intuitive\nhuman-robot interaction in domains as varied as manipulation, locomotion, and\nself-driving vehicles. When viewed as a stand-alone technology, LLMs are known\nto be vulnerable to jailbreaking attacks, wherein malicious prompters elicit\nharmful text by bypassing LLM safety guardrails. To assess the risks of\ndeploying LLMs in robotics, in this paper, we introduce RoboPAIR, the first\nalgorithm designed to jailbreak LLM-controlled robots. Unlike existing, textual\nattacks on LLM chatbots, RoboPAIR elicits harmful physical actions from\nLLM-controlled robots, a phenomenon we experimentally demonstrate in three\nscenarios: (i) a white-box setting, wherein the attacker has full access to the\nNVIDIA Dolphins self-driving LLM, (ii) a gray-box setting, wherein the attacker\nhas partial access to a Clearpath Robotics Jackal UGV robot equipped with a\nGPT-4o planner, and (iii) a black-box setting, wherein the attacker has only\nquery access to the GPT-3.5-integrated Unitree Robotics Go2 robot dog. In each\nscenario and across three new datasets of harmful robotic actions, we\ndemonstrate that RoboPAIR, as well as several static baselines, finds\njailbreaks quickly and effectively, often achieving 100% attack success rates.\nOur results reveal, for the first time, that the risks of jailbroken LLMs\nextend far beyond text generation, given the distinct possibility that\njailbroken robots could cause physical damage in the real world. Indeed, our\nresults on the Unitree Go2 represent the first successful jailbreak of a\ndeployed commercial robotic system. Addressing this emerging vulnerability is\ncritical for ensuring the safe deployment of LLMs in robotics. Additional media\nis available at: https://robopair.org",
    "pdf_url": "http://arxiv.org/pdf/2410.13691v2",
    "published": "2024-10-17T15:55:36+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13690v1",
    "title": "An algebraic study of parametric Stokes phenomena",
    "authors": [
      "Inês Aniceto",
      "Samuel Crew"
    ],
    "abstract": "We investigate geometric aspects of co-equational parametric resurgence, by\nstudying physical problems whose formal asymptotic solutions give rise to Borel\ntransforms lying on an algebraic curve. This perspective allows us to elucidate\nconcepts unique to parametric resurgence such as singularity structures,\n(virtual) turning points and the higher-order Stokes phenomenon. We construct\nexamples as solutions to Borel plane partial differential equations using an\nalgebraic curve ansatz before turning to the general analytic structure of\nco-equational resurgence problems, where we provide a systematic description of\nanalytic continuation and Stokes constants through a Borel plane inner-outer\nmatching procedure.",
    "pdf_url": "http://arxiv.org/pdf/2410.13690v1",
    "published": "2024-10-17T15:55:06+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.CA",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13689v1",
    "title": "Cellular automaton model of self-healing",
    "authors": [
      "Henryk Fukś",
      "José Manuel Gómez Soto"
    ],
    "abstract": "We propose a simple cellular automaton model of a self-healing system and\ninvestigate its properties. In the model, the substrate is a two-dimensional\ncheckerboard configuration which can be damaged by changing values of a finite\nnumber of sites. The cellular automaton we consider is a checkerboard voting\nrule, a binary rule with Moore neighbourhood which is topologically conjugate\nto majority voting rule. For a single color damage (when only cells in the same\nstate are modified), the rule always fixes the damage. For a general damage,\nwhen it is localized inside a $3 \\times 3$ square, the rule also fixes it\nalways. When the damage is inside of a larger $n \\times n$ square, the\nefficiency of the rule in fixing the damage becomes smaller than $100\\%$, but\nit remains better than $98\\%$ for $n \\leq 5$ and better than $75 \\%$ for $n\\leq\n7$. We show that in the limit of infinite $n$ the efficiency tends to zero.",
    "pdf_url": "http://arxiv.org/pdf/2410.13689v1",
    "published": "2024-10-17T15:54:29+00:00",
    "categories": [
      "nlin.CG",
      "68Q80"
    ],
    "primary_category": "nlin.CG"
  },
  {
    "id": "http://arxiv.org/abs/2411.00787v1",
    "title": "Novel operational algorithms for ride-pooling as on-demand feeder services",
    "authors": [
      "Wenbo Fan",
      "Xiaotian Yan",
      "Zhanbo Sun",
      "Xiaohui Yang"
    ],
    "abstract": "Ride-pooling (RP) service, as a form of shared mobility, enables multiple\nriders with similar itineraries to share the same vehicle and split the fee.\nThis makes RP a promising on-demand feeder service for patrons with a common\ntrip end in urban transportation. We propose the RP as Feeder (RPaF) services\nwith tailored operational algorithms. Specifically, we have developed (i) a\nbatch-based matching algorithm that pools a batch of requests within an\noptimized buffer distance to each RP vehicle; (ii) a dispatching algorithm that\nadaptively dispatches vehicles to pick up the matched requests for certain\noccupancy target; and (iii) a repositioning algorithm that relocates vehicles\nto unmatched requests based on their level of urgency. An agent-based\nmicroscopic simulation platform is designed to execute these operational\nalgorithms (via the Operator module), generate spatially distributed random\nrequests (Patron module), and account for traffic conditions (Vehicle module)\nin street networks. Extensive numerical experiments are conducted to showcase\nthe effectiveness of RPaF services across various demand scenarios in typical\nmorning rush hours. We compare RFaF with two on-demand feeder counterparts\nproposed in previous studies: Ride-Sharing as Feeder (RSaF) and Flexible-Route\nFeeder-Bus Transit (Flex-FBT). Comparisons reveal that given the same fleet\nsize, RPaF generally outperforms RSaF in higher service rates (i.e., the\npercentage of requests served over all requests) and Flex-FBT in shorter\naverage trip times for patrons. Lastly, we illustrate the implementation of\nRPaF in a real-world case study of the uptown Manhattan network (USA) using\nactual taxi trip data. The results demonstrate that RPaF effectively balances\nthe level of service (service rate and patrons' average trip time) with\noperational costs (fleet size).",
    "pdf_url": "http://arxiv.org/pdf/2411.00787v1",
    "published": "2024-10-17T15:53:05+00:00",
    "categories": [
      "cs.NI",
      "math.OC"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13925v1",
    "title": "FiTv2: Scalable and Improved Flexible Vision Transformer for Diffusion Model",
    "authors": [
      "ZiDong Wang",
      "Zeyu Lu",
      "Di Huang",
      "Cai Zhou",
      "Wanli Ouyang",
      "and Lei Bai"
    ],
    "abstract": "\\textit{Nature is infinitely resolution-free}. In the context of this\nreality, existing diffusion models, such as Diffusion Transformers, often face\nchallenges when processing image resolutions outside of their trained domain.\nTo address this limitation, we conceptualize images as sequences of tokens with\ndynamic sizes, rather than traditional methods that perceive images as\nfixed-resolution grids. This perspective enables a flexible training strategy\nthat seamlessly accommodates various aspect ratios during both training and\ninference, thus promoting resolution generalization and eliminating biases\nintroduced by image cropping. On this basis, we present the \\textbf{Flexible\nVision Transformer} (FiT), a transformer architecture specifically designed for\ngenerating images with \\textit{unrestricted resolutions and aspect ratios}. We\nfurther upgrade the FiT to FiTv2 with several innovative designs, includingthe\nQuery-Key vector normalization, the AdaLN-LoRA module, a rectified flow\nscheduler, and a Logit-Normal sampler. Enhanced by a meticulously adjusted\nnetwork structure, FiTv2 exhibits $2\\times$ convergence speed of FiT. When\nincorporating advanced training-free extrapolation techniques, FiTv2\ndemonstrates remarkable adaptability in both resolution extrapolation and\ndiverse resolution generation. Additionally, our exploration of the scalability\nof the FiTv2 model reveals that larger models exhibit better computational\nefficiency. Furthermore, we introduce an efficient post-training strategy to\nadapt a pre-trained model for the high-resolution generation. Comprehensive\nexperiments demonstrate the exceptional performance of FiTv2 across a broad\nrange of resolutions. We have released all the codes and models at\n\\url{https://github.com/whlzy/FiT} to promote the exploration of diffusion\ntransformer models for arbitrary-resolution image generation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13925v1",
    "published": "2024-10-17T15:51:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13688v1",
    "title": "Variational Quantum Framework for Nonlinear PDE Constrained Optimization Using Carleman Linearization",
    "authors": [
      "Abeynaya Gnanasekaran",
      "Amit Surana",
      "Hongyu Zhu"
    ],
    "abstract": "We present a novel variational quantum framework for nonlinear partial\ndifferential equation (PDE) constrained optimization problems. The proposed\nwork extends the recently introduced bi-level variational quantum PDE\nconstrained optimization (BVQPCO) framework for linear PDE to a nonlinear\nsetting by leveraging Carleman linearization (CL). CL framework allows one to\ntransform a system of polynomial ordinary differential equations (ODE), i,e.\nODE with polynomial vector field, into an system of infinite but linear system\nof ODE. For instance, such polynomial ODEs naturally arise when the PDE are\nsemi-discretized in the spatial dimensions. By truncating the CL system to a\nfinite order, one obtains a finite system of linear ODE to which the linear\nBVQPCO framework can be applied. In particular, the finite system of linear ODE\nis discretized in time and embedded as a system of linear equations. The\nvariational quantum linear solver (VQLS) is used to solve the linear system for\ngiven optimization parameters, and evaluate the design cost/objective function,\nand a classical black box optimizer is used to select next set of parameter\nvalues based on this evaluated cost. We present detailed computational error\nand complexity analysis and prove that under suitable assumptions, our proposed\nframework can provide potential advantage over classical techniques. We\nimplement our framework using the PennyLane library and apply it to solve\ninverse Burgers' problem. We also explore an alternative tensor product\ndecomposition which exploits the sparsity/structure of linear system arising\nfrom PDE discretization to facilitate the computation of VQLS cost functions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13688v1",
    "published": "2024-10-17T15:51:41+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13687v1",
    "title": "Complete minimal surfaces with Cantor ends in minimally convex domains",
    "authors": [
      "Antonio Alarcon"
    ],
    "abstract": "We survey the recent history of the conformal Calabi-Yau problem consisting\nin determining the complex structures admitted by complete bounded minimal\nsurfaces in $\\mathbb{R}^3$. Moreover, we prove that for any minimally convex\ndomain $\\Omega$ in $\\mathbb{R}^3$ and any compact Riemann surface $R$ there is\na Cantor set $C$ in $R$ whose complement $R\\setminus C$ is the complex\nstructure of a complete proper minimal surface in $\\Omega$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13687v1",
    "published": "2024-10-17T15:50:54+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13686v1",
    "title": "Multiple mixing for parabolic systems",
    "authors": [
      "Adam Kanigowski",
      "Davide Ravotti"
    ],
    "abstract": "The famous Rokhlin Problem asks whether mixing implies higher order mixing.\nSo far, all the known examples of zero entropy, mixing dynamical systems enjoy\na variant of the mixing via shearing mechanism. In this paper we introduce the\nnotion of locally uniformly shearing systems (LUS) which is a rigorous way of\ndescribing the mixing via shearing mechanism. We prove that all LUS flows are\nmixing of all orders. We then show that mixing smooth flows on surfaces and\nsmooth time-changes of unipotent flow are LUS. We also introduce the notion of\nquantitative LUS. We show that polynomially mixing systems that are\npolynomially LUS are in fact polynomially mixing of all orders. As a\nconsequence we show that Kochergin flows on $\\mathbb{T}^2$ (for a.e. irrational\nfrequency) as well as smooth time-changes of unipotent flows are polynomially\nmixing of all orders.",
    "pdf_url": "http://arxiv.org/pdf/2410.13686v1",
    "published": "2024-10-17T15:50:10+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13685v1",
    "title": "Label-free prediction of fluorescence markers in bovine satellite cells using deep learning",
    "authors": [
      "Sania Sinha",
      "Aarham Wasit",
      "Won Seob Kim",
      "Jongkyoo Kim",
      "Jiyoon Yi"
    ],
    "abstract": "Assessing the quality of bovine satellite cells (BSCs) is essential for the\ncultivated meat industry, which aims to address global food sustainability\nchallenges. This study aims to develop a label-free method for predicting\nfluorescence markers in isolated BSCs using deep learning. We employed a\nU-Net-based CNN model to predict multiple fluorescence signals from a single\nbright-field microscopy image of cell culture. Two key biomarkers, DAPI and\nPax7, were used to determine the abundance and quality of BSCs. The image\npre-processing pipeline included fluorescence denoising to improve prediction\nperformance and consistency. A total of 48 biological replicates were used,\nwith statistical performance metrics such as Pearson correlation coefficient\nand SSIM employed for model evaluation. The model exhibited better performance\nwith DAPI predictions due to uniform staining. Pax7 predictions were more\nvariable, reflecting biological heterogeneity. Enhanced visualization\ntechniques, including color mapping and image overlay, improved the\ninterpretability of the predictions by providing better contextual and\nperceptual information. The findings highlight the importance of data\npre-processing and demonstrate the potential of deep learning to advance\nnon-invasive, label-free assessment techniques in the cultivated meat industry,\npaving the way for reliable and actionable AI-driven evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13685v1",
    "published": "2024-10-17T15:47:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13684v2",
    "title": "Signal partitioning in superfluid ${}^4$He: a Monte Carlo approach",
    "authors": [
      "Francesco Toschi",
      "Axel Brunold",
      "Lea Burmeister",
      "Klaus Eitel",
      "Christian Enss",
      "Eleanor Fascione",
      "Torben Ferber",
      "Rahel Gabriel",
      "Lena Hauswald",
      "Felix Kahlhoefer",
      "Sebastian Kempf",
      "Markus Klute",
      "Belina von Krosigk",
      "Sebastian Lindemann",
      "Benedikt Maier",
      "Marc Schumann",
      "Melih Solmaz",
      "Kathrin Valerius",
      "Friedrich Carl Wagner"
    ],
    "abstract": "Superfluid ${}^4$He is an ideal candidate for the direct detection of light\ndark matter via nuclear recoils thanks to its low nuclear mass and the\npossibility to reach a low detection energy threshold by exploiting the\ngenerated quasiparticles. The design of future detectors based on this target,\nsuch as the DELight experiment, requires a proper understanding of the\nformation and partitioning of the signal for different energy depositions from\nvarious sources. This work presents an overview of the physical processes\ninvolved in the energy deposition of recoiling electrons and ions, and\ndescribes a Monte Carlo approach to the partitioning of the signal into\ndifferent channels. Despite an overall good agreement with existing literature,\ndifferences in the region of interest for light dark matter searches below 200\neV are observed.",
    "pdf_url": "http://arxiv.org/pdf/2410.13684v2",
    "published": "2024-10-17T15:46:12+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2410.13683v2",
    "title": "Stochastic inflation beyond slow roll: noise modelling and importance sampling",
    "authors": [
      "Joseph H. P. Jackson",
      "Hooshyar Assadullahi",
      "Andrew D. Gow",
      "Kazuya Koyama",
      "Vincent Vennin",
      "David Wands"
    ],
    "abstract": "We simulate the distribution of very rare, large excursions in the primordial\ndensity field produced in models of inflation in the very early universe which\ninclude a strong enhancement of the power spectrum. The stochastic $\\delta\n\\mathcal{N}$ formalism is used to identify the probability distribution for the\nprimordial curvature perturbation with the first-passage-time distribution,\n$P(\\delta \\mathcal{N})$, and we compare our stochastic results with those\nobtained in the classical $\\delta \\mathcal{N}$ approach. We extend the PyFPT\nnumerical code to simulate the full 2D phase space, and apply importance\nsampling which allows very rare fluctuations to be simulated in\n$\\mathcal{O}(10)$ minutes on a single CPU, where previous direct simulations\nrequired supercomputers. We demonstrate that the stochastic noise due to\nquantum fluctuations after a sudden transition to ultra-slow roll can be\naccurately modelled using an analytical Bessel-function ansatz to identify the\nhomogeneous growing mode. The stochastic noise found in this way is a function\nof the field value only. This enables us to coarse grain the inflation field at\nthe Hubble scale and include non-linear, stochastic evolution on all\nsuper-Hubble length scales.",
    "pdf_url": "http://arxiv.org/pdf/2410.13683v2",
    "published": "2024-10-17T15:45:07+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13682v1",
    "title": "Large Deviations of Hawkes Processes on Structured Sparse Disordered Graphs",
    "authors": [
      "Daniele Avitabile",
      "James MacLaurin"
    ],
    "abstract": "We prove a Large Deviation Principle for Hawkes Processes on sparse large\ndisordered networks with a graphon structure. We apply our results to a\nstochastic SIS epidemiological model on a disordered networks, and determine\nEuler-Lagrange equations that dictate the most likely transition path between\ndifferent states of the network.",
    "pdf_url": "http://arxiv.org/pdf/2410.13682v1",
    "published": "2024-10-17T15:42:37+00:00",
    "categories": [
      "math.PR",
      "q-bio.PE"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13681v2",
    "title": "Ab Initio Nonparametric Variable Selection for Scalable Symbolic Regression with Large $p$",
    "authors": [
      "Shengbin Ye",
      "Meng Li"
    ],
    "abstract": "Symbolic regression (SR) is a powerful technique for discovering symbolic\nexpressions that characterize nonlinear relationships in data, gaining\nincreasing attention for its interpretability, compactness, and robustness.\nHowever, existing SR methods do not scale to datasets with a large number of\ninput variables (referred to as extreme-scale SR), which is common in modern\nscientific applications. This ``large $p$'' setting, often accompanied by\nmeasurement error, leads to slow performance of SR methods and overly complex\nexpressions that are difficult to interpret. To address this scalability\nchallenge, we propose a method called PAN+SR, which combines a key idea of ab\ninitio nonparametric variable selection with SR to efficiently pre-screen large\ninput spaces and reduce search complexity while maintaining accuracy. The use\nof nonparametric methods eliminates model misspecification, supporting a\nstrategy called parametric-assisted nonparametric (PAN). We also extend\nSRBench, an open-source benchmarking platform, by incorporating\nhigh-dimensional regression problems with various signal-to-noise ratios. Our\nresults demonstrate that PAN+SR consistently enhances the performance of 19\ncontemporary SR methods, enabling several to achieve state-of-the-art\nperformance on these challenging datasets.",
    "pdf_url": "http://arxiv.org/pdf/2410.13681v2",
    "published": "2024-10-17T15:41:06+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13680v1",
    "title": "Pessimistic Evaluation",
    "authors": [
      "Fernando Diaz"
    ],
    "abstract": "Traditional evaluation of information access systems has focused primarily on\naverage utility across a set of information needs (information retrieval) or\nusers (recommender systems). In this work, we argue that evaluating only with\naverage metric measurements assumes utilitarian values not aligned with\ntraditions of information access based on equal access. We advocate for\npessimistic evaluation of information access systems focusing on worst case\nutility. These methods are (a) grounded in ethical and pragmatic concepts, (b)\ntheoretically complementary to existing robustness and fairness methods, and\n(c) empirically validated across a set of retrieval and recommendation tasks.\nThese results suggest that pessimistic evaluation should be included in\nexisting experimentation processes to better understand the behavior of\nsystems, especially when concerned with principles of social good.",
    "pdf_url": "http://arxiv.org/pdf/2410.13680v1",
    "published": "2024-10-17T15:40:09+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2411.00010v2",
    "title": "Consumer Segmentation and Participation Drivers in Community-Supported Agriculture: A Choice Experiment and PLS-SEM Approach",
    "authors": [
      "Sota Takagi",
      "Miki Saijo",
      "Takumi Ohashi"
    ],
    "abstract": "As the global food system faces increasing challenges from sustainability,\nclimate change, and food security issues, alternative food networks like\nCommunity-Supported Agriculture (CSA) play an essential role in fostering\nstronger connections between consumers and producers. However, understanding\nconsumer engagement with CSA is fragmented, particularly in Japan where CSA\nparticipation is still emerging. This study aims to identify potential CSA\nparticipants in Japan and validate existing theories on CSA participation\nthrough a quantitative analysis of 2,484 Japanese consumers. Using choice\nexperiments, Latent Class Analysis, and Partial Least Squares Structural\nEquation Modeling, we identified five distinct consumer segments. The\n\"Sustainable Food Seekers\" group showed the highest positive utility for CSA,\ndriven primarily by \"Food Education and Learning Opportunities\" and\n\"Contribution to Environmental and Social Issues.\" These factors were\nconsistently significant across all segments, suggesting that many Japanese\nconsumers value CSA for its educational and environmental benefits. In\ncontrast, factors related to \"Variety of Ingredients\" were less influential in\ndetermining participation intentions. The findings suggest that promoting CSA\nin Japan may be most effective by emphasizing its role in environmental and\nsocial impact, rather than focusing solely on product attributes like organic\ncertification, which is readily available in supermarkets. This reflects a key\ndistinction between CSA adoption in Japan and in other cultural contexts, where\naccess to organic produce is a primary driver. For \"Sustainable Food Seekers,\"\nCSA offers a way to contribute to broader societal goals rather than just\nsecuring organic products.",
    "pdf_url": "http://arxiv.org/pdf/2411.00010v2",
    "published": "2024-10-17T15:37:28+00:00",
    "categories": [
      "cs.CY",
      "stat.AP",
      "91C99",
      "J.4"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13679v1",
    "title": "Mechanical and suture-holding properties of a UV-cured atelocollagen membrane with varied crosslinked architecture",
    "authors": [
      "Ruya Zhang",
      "Charles Brooker",
      "Laura L. E. Whitehouse",
      "Neil H. Thomson",
      "David Wood",
      "Giuseppe Tronci"
    ],
    "abstract": "The mechanical competence and suturing ability of collagen-based membranes\nare paramount in Guided Bone Regeneration (GBR) therapy, to ensure damage-free\nimplantation, fixation and space maintenance in vivo. However, contact with the\nbiological medium can induce swelling of collagen molecules, yielding risks of\nmembrane sinking into the bone defect, early loss of barrier function, and\nirreversibly compromised clinical outcomes. To address these challenges, this\nstudy investigates the effect of the crosslinked network architecture on both\nmechanical and suture-holding properties of a new atelocollagen (AC) membrane.\nUV-cured networks were obtained via either single functionalisation of AC with\n4-vinylbenzyl chloride (4VBC) or sequential functionalisation of AC with both\n4VBC and methacrylic anhydride (MA). The wet-state compression modulus (Ec),\nAtomic Force Microscopy elastic modulus (EAFM) and swelling ratio (SR) were\nsignificantly affected by the UV-cured network architecture, leading up to a\nthree-fold reduction in SR, and about two-fold increase in both Ec and EAFM, in\nthe sequentially functionalised, compared to the single-functionalised,\nsamples. Electron microscopy, dimensional analysis and compression testing\nrevealed the direct impact of the ethanol series dehydration process on\nmembrane microstructure, yielding densification of the freshly synthesised\nporous samples and a pore-free microstructure with increased Ec. Noteworthy,\nthe single-functionalised, but not the sequentially functionalised, samples\ndisplayed higher suture retention strength in both the dry state and following\n1 hour in Phosphate Buffered Saline (PBS), compared to Bio-Gide(r). These\nstructure-property relationships confirm the key role played by the molecular\narchitecture of covalently crosslinked collagen, aimed towards long-lasting\nresorbable membranes for predictable GBR.",
    "pdf_url": "http://arxiv.org/pdf/2410.13679v1",
    "published": "2024-10-17T15:36:08+00:00",
    "categories": [
      "q-bio.TO"
    ],
    "primary_category": "q-bio.TO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13678v1",
    "title": "Topological interface modes in systems with damping",
    "authors": [
      "Konstantinos Alexopoulos",
      "Bryn Davies",
      "Erik Orvehed Hiltunen"
    ],
    "abstract": "We extend the theory of topological localised interface modes to systems with\ndamping. The spectral problem is formulated as a root-finding problem for the\ninterface impedance function and Rouch\\'e's theorem is used to track the zeros\nwhen damping is introduced. We show that the localised eigenfrequencies,\ncorresponding to interface modes, remain for non-zero dampings. Using the\ntransfer matrix method, we explicitly characterise the decay rate of the\ninterface mode.",
    "pdf_url": "http://arxiv.org/pdf/2410.13678v1",
    "published": "2024-10-17T15:35:24+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "physics.optics"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13676v2",
    "title": "Direct proof of one-hook scaling property for Alexander polynomial from Reshetikhin-Turaev formalism",
    "authors": [
      "Andrey Morozov",
      "Aleksandr Popolitov",
      "Alexei Sleptsov"
    ],
    "abstract": "We prove that normalized colored Alexander polynomial (the $A \\rightarrow 1$\nlimit of colored HOMFLY-PT polynomial) evaluated for one-hook (L-shape)\nrepresentation R possesses scaling property: it is equal to the fundamental\nAlexander polynomial with the substitution $q \\rightarrow q^{|R|}$. The proof\nis simple and direct use of Reshetikhin-Turaev formalism to get all required\nR-matrices.",
    "pdf_url": "http://arxiv.org/pdf/2410.13676v2",
    "published": "2024-10-17T15:35:18+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.GT",
      "math.MP",
      "math.QA"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13677v3",
    "title": "Beamforming Optimization for Continuous Aperture Array (CAPA)-based Communications",
    "authors": [
      "Zhaolin Wang",
      "Chongjun Ouyang",
      "Yuanwei Liu"
    ],
    "abstract": "The beamforming optimization in continuous aperture array (CAPA)-based\nmulti-user communications is studied. In contrast to conventional spatially\ndiscrete antenna arrays, CAPAs can exploit the full spatial degrees of freedom\n(DoFs) by emitting information-bearing electromagnetic (EM) waves through\ncontinuous source current distributed across the aperture. Nevertheless, such\nan operation renders the beamforming optimization problem as a non-convex\nintegral-based functional programming problem, which is challenging for\nconventional discrete optimization methods. A couple of low-complexity\napproaches are proposed to solve the functional programming problem. 1)\nCalculus of variations (CoV)-based approach: Closed-form structure of the\noptimal continuous source patterns are derived based on CoV, inspiring a\nlow-complexity integral-free iterative algorithm for solving the functional\nprogramming problem. 2) Correlation-based zero-forcing (Corr-ZF) approach:\nClosed-form ZF source current patterns that completely eliminate the inter-user\ninterference are derived based on the channel correlations. By using these\npatterns, the original functional programming problem is transformed to a\nsimple power allocation problem, which can be solved using the classical\nwater-filling approach with reduced complexity. Our numerical results validate\nthe effectiveness of the proposed designs and reveal that: i) compared to the\nstate-of-the-art Fourier-based discretization approach, the proposed CoV-based\napproach not only improves communication performance but also reduces\ncomputational complexity by up to hundreds of times for large CAPA apertures\nand high frequencies, and ii) the proposed Corr-ZF approach achieves\nasymptotically optimal performance compared to the CoV-based approach.",
    "pdf_url": "http://arxiv.org/pdf/2410.13677v3",
    "published": "2024-10-17T15:35:18+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13675v2",
    "title": "Pose-Based Sign Language Appearance Transfer",
    "authors": [
      "Amit Moryossef",
      "Gerard Sant",
      "Zifan Jiang"
    ],
    "abstract": "We introduce a method for transferring the signer's appearance in sign\nlanguage skeletal poses while preserving the sign content. Using estimated\nposes, we transfer the appearance of one signer to another, maintaining natural\nmovements and transitions. This approach improves pose-based rendering and sign\nstitching while obfuscating identity. Our experiments show that while the\nmethod reduces signer identification accuracy, it slightly harms sign\nrecognition performance, highlighting a tradeoff between privacy and utility.\nOur code is available at\nhttps://github.com/sign-language-processing/pose-anonymization.",
    "pdf_url": "http://arxiv.org/pdf/2410.13675v2",
    "published": "2024-10-17T15:33:54+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13674v2",
    "title": "Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion",
    "authors": [
      "Yijun Liang",
      "Shweta Bhardwaj",
      "Tianyi Zhou"
    ],
    "abstract": "Low-quality or scarce data has posed significant challenges for training deep\nneural networks in practice. While classical data augmentation cannot\ncontribute very different new data, diffusion models opens up a new door to\nbuild self-evolving AI by generating high-quality and diverse synthetic data\nthrough text-guided prompts. However, text-only guidance cannot control\nsynthetic images' proximity to the original images, resulting in\nout-of-distribution data detrimental to the model performance. To overcome the\nlimitation, we study image guidance to achieve a spectrum of interpolations\nbetween synthetic and real images. With stronger image guidance, the generated\nimages are similar to the training data but hard to learn. While with weaker\nimage guidance, the synthetic images will be easier for model but contribute to\na larger distribution gap with the original data. The generated full spectrum\nof data enables us to build a novel \"Diffusion Curriculum (DisCL)\". DisCL\nadjusts the image guidance level of image synthesis for each training stage: It\nidentifies and focuses on hard samples for the model and assesses the most\neffective guidance level of synthetic images to improve hard data learning. We\napply DisCL to two challenging tasks: long-tail (LT) classification and\nlearning from low-quality data. It focuses on lower-guidance images of\nhigh-quality to learn prototypical features as a warm-up of learning\nhigher-guidance images that might be weak on diversity or quality. Extensive\nexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when\napplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base\nmodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%\nimprovement in all-class accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2410.13674v2",
    "published": "2024-10-17T15:33:35+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13673v2",
    "title": "Positive ($S^1$-equivariant) symplectic homology of convex domains, higher capacities, and Clarke's duality",
    "authors": [
      "Stefan Matijević"
    ],
    "abstract": "We prove that the filtered positive ($S^1$-equivariant) symplectic homology\nof a convex domain is naturally isomorphic to the filtered singular\n($S^1$-equivariant) homology induced by Clarke's dual functional associated\nwith the convex domain. As a result, we prove that the Gutt-Hutchings\ncapacities coincide with the spectral invariants introduced by Ekeland-Hofer\nfor convex domains. From this identification, it follows that Besse convex\ndomains can be characterized by their Gutt-Hutchings capacities, which implies\nthat the interiors of Besse-type convex domains encode information about the\nReeb flow on their boundaries. Moreover, as a corollary of the aforementioned\nisomorphism, we deduce that the barcode entropy associated with the singular\nhomology induced by Clarke's dual functional provides a lower bound for the\ntopological entropy of the Reeb flow on the boundary of a convex domain in\n$\\mathbb{R}^{2n}$. In particular, this barcode entropy coincides with the\ntopological entropy for convex domains in $\\mathbb{R}^4$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13673v2",
    "published": "2024-10-17T15:32:30+00:00",
    "categories": [
      "math.SG",
      "math.DG",
      "math.DS"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13672v1",
    "title": "Modelling undulators in ray tracing simulations",
    "authors": [
      "Manuel Sanchez del Rio",
      "Juan Reyes-Herrera"
    ],
    "abstract": "We introduce a model that can accurately simulate radiation from undulator\nsources for ray tracing applications. It incorporates several key effects\nrelevant to 4$^\\text{th}$ generation synchrotron sources, such as electron\nemittance, energy spread, and diffraction-limited beam size. This code has been\ndeveloped as part of SHADOW4, the latest version of the widely used SHADOW\nX-ray optics ray tracing program. The approach relies on calculating the field\ndistribution in the far field, which determines the ray divergences. The\nintegration of existing models for electron energy spread is also addressed.\nRays sampled at the source follow a size distribution derived by\nbackpropagating the far field radiation. These models are detailed, and several\nexamples are provided.",
    "pdf_url": "http://arxiv.org/pdf/2410.13672v1",
    "published": "2024-10-17T15:32:27+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13671v1",
    "title": "HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World Multilingual Settings",
    "authors": [
      "Varun Gumma",
      "Anandhita Raghunath",
      "Mohit Jain",
      "Sunayana Sitaram"
    ],
    "abstract": "Assessing the capabilities and limitations of large language models (LLMs)\nhas garnered significant interest, yet the evaluation of multiple models in\nreal-world scenarios remains rare. Multilingual evaluation often relies on\ntranslated benchmarks, which typically do not capture linguistic and cultural\nnuances present in the source language. This study provides an extensive\nassessment of 24 LLMs on real world data collected from Indian patients\ninteracting with a medical chatbot in Indian English and 4 other Indic\nlanguages. We employ a uniform Retrieval Augmented Generation framework to\ngenerate responses, which are evaluated using both automated techniques and\nhuman evaluators on four specific metrics relevant to our application. We find\nthat models vary significantly in their performance and that instruction tuned\nIndic models do not always perform well on Indic language queries. Further, we\nempirically show that factual correctness is generally lower for responses to\nIndic queries compared to English queries. Finally, our qualitative work shows\nthat code-mixed and culturally relevant queries in our dataset pose challenges\nto evaluated models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13671v1",
    "published": "2024-10-17T15:29:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13670v1",
    "title": "Semi-Hadronic Charge-Parity Violation Interaction Constants in CsAg, FrLi and FrAg molecules",
    "authors": [
      "Aurélien Marc",
      "Timo Fleig"
    ],
    "abstract": "We present a systematic study of the nucleon-electron tensor-pseudotensor\n(Ne-TPT) interaction in candidate molecules for next-generation experimental\nsearches for new sources of charge-parity violation. The considered molecules\nare all amenable to assembly from laser-cooled atoms, with the francium-silver\n(FrAg) molecule previously shown to be the most sensitive to the Schiff moment\ninteraction in this set. Interelectron correlation effects are treated through\nrelativistic general-excitation-rank configuration-interaction theory in the\nframework of the Dirac-Coulomb Hamiltonian. We find in FrAg the Ne-TPT\ninteraction constant to be $W_T({\\text{Fr}}) = 2.58 \\pm 0.21\n[\\left<\\Sigma\\right>_A \\mathrm{kHz}]$, considering the Francium atom as target\nof the measurement. Taking into account nuclear structure in a multi-source\ninterpretation of a measured electric dipole moment, FrAg is found to be an\nexcellent probe of physics beyond the Standard Model as this system will in\naddition to its sizeable Ne-TPT interaction constant greatly constrain\nfundamental parameters such as the quantum-chromo-dynamic $\\bar{\\theta}$ or the\nsemileptonic four-fermion interaction $C_{lequ}$ from which nuclear and atomic\n${\\cal{CP}}$-violating properties arise.",
    "pdf_url": "http://arxiv.org/pdf/2410.13670v1",
    "published": "2024-10-17T15:29:32+00:00",
    "categories": [
      "physics.atom-ph",
      "hep-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13669v3",
    "title": "Theta and/or alpha? Neural oscillational substrates for dynamic inter-brain synchrony during mother-child cooperation",
    "authors": [
      "Jiayang Xu",
      "Yamin Li",
      "Ruxin Su",
      "Saishuang Wu",
      "Chengcheng Wu",
      "Haiwa Wang",
      "Qi Zhu",
      "Yue Fang",
      "Fan Jiang",
      "Shanbao Tong",
      "Yunting Zhang",
      "Xiaoli Guo"
    ],
    "abstract": "Mother-child interaction is a highly dynamic process neurally characterized\nby inter-brain synchrony (IBS) at {\\theta} and/or {\\alpha} rhythms. However,\ntheir establishment, dynamic changes, and roles in mother-child interactions\nremain unknown. Through dynamic analysis of dual-EEG from 40 mother-child dyads\nduring turn-taking cooperation, we uncover that {\\theta}-IBS and {\\alpha}-IBS\nalternated with interactive behaviors, with EEG frequency-shift as a\nprerequisite for IBS transitions. When mothers attempt to track their\nchildren's attention and/or predict their intentions, they will adjust their\nEEG frequencies to align with their children's {\\theta} oscillations, leading\nto a higher occurrence of the {\\theta}-IBS state. Conversely, the {\\alpha}-IBS\nstate, accompanied by the EEG frequency-shift to the {\\alpha} range, is more\nprominent during mother-led interactions. Further exploratory analysis reveals\ngreater presence and stability of the {\\theta}-IBS state during cooperative\nthan non-cooperative conditions, particularly in dyads with stronger emotional\nattachments and more frequent interactions in their daily lives. Our findings\nshed light on the neural oscillational substrates underlying the IBS dynamics\nduring mother-child interactions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13669v3",
    "published": "2024-10-17T15:29:09+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13668v1",
    "title": "signwriting-evaluation: Effective Sign Language Evaluation via SignWriting",
    "authors": [
      "Amit Moryossef",
      "Rotem Zilberman",
      "Ohad Langer"
    ],
    "abstract": "The lack of automatic evaluation metrics tailored for SignWriting presents a\nsignificant obstacle in developing effective transcription and translation\nmodels for signed languages. This paper introduces a comprehensive suite of\nevaluation metrics specifically designed for SignWriting, including adaptations\nof standard metrics such as \\texttt{BLEU} and \\texttt{chrF}, the application of\n\\texttt{CLIPScore} to SignWriting images, and a novel symbol distance metric\nunique to our approach. We address the distinct challenges of evaluating single\nsigns versus continuous signing and provide qualitative demonstrations of\nmetric efficacy through score distribution analyses and nearest-neighbor\nsearches within the SignBank corpus. Our findings reveal the strengths and\nlimitations of each metric, offering valuable insights for future advancements\nusing SignWriting. This work contributes essential tools for evaluating\nSignWriting models, facilitating progress in the field of sign language\nprocessing. Our code is available at\n\\url{https://github.com/sign-language-processing/signwriting-evaluation}.",
    "pdf_url": "http://arxiv.org/pdf/2410.13668v1",
    "published": "2024-10-17T15:28:45+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13667v1",
    "title": "ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization",
    "authors": [
      "Xiutian Zhao",
      "Ke Wang",
      "Wei Peng"
    ],
    "abstract": "Dialogue agents have been receiving increasing attention for years, and this\ntrend has been further boosted by the recent progress of large language models\n(LLMs). Stance detection and dialogue summarization are two core tasks of\ndialogue agents in application scenarios that involve argumentative dialogues.\nHowever, research on these tasks is limited by the insufficiency of public\ndatasets, especially for non-English languages. To address this language\nresource gap in Chinese, we present ORCHID (Oral Chinese Debate), the first\nChinese dataset for benchmarking target-independent stance detection and debate\nsummarization. Our dataset consists of 1,218 real-world debates that were\nconducted in Chinese on 476 unique topics, containing 2,436 stance-specific\nsummaries and 14,133 fully annotated utterances. Besides providing a versatile\ntestbed for future research, we also conduct an empirical study on the dataset\nand propose an integrated task. The results show the challenging nature of the\ndataset and suggest a potential of incorporating stance detection in\nsummarization for argumentative dialogue.",
    "pdf_url": "http://arxiv.org/pdf/2410.13667v1",
    "published": "2024-10-17T15:28:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13666v1",
    "title": "VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic Reasoning Tasks",
    "authors": [
      "Shailaja Keyur Sampat",
      "Mutsumi Nakamura",
      "Shankar Kailas",
      "Kartik Aggarwal",
      "Mandy Zhou",
      "Yezhou Yang",
      "Chitta Baral"
    ],
    "abstract": "Deriving inference from heterogeneous inputs (such as images, text, and\naudio) is an important skill for humans to perform day-to-day tasks. A similar\nability is desirable for the development of advanced Artificial Intelligence\n(AI) systems. While state-of-the-art models are rapidly closing the gap with\nhuman-level performance on diverse computer vision and NLP tasks separately,\nthey struggle to solve tasks that require joint reasoning over visual and\ntextual modalities. Inspired by GLUE (Wang et. al., 2018)- a multitask\nbenchmark for natural language understanding, we propose VL-GLUE in this paper.\nVL-GLUE consists of over 100k samples spanned across seven different tasks,\nwhich at their core require visuo-linguistic reasoning. Moreover, our benchmark\ncomprises of diverse image types (from synthetically rendered figures, and\nday-to-day scenes to charts and complex diagrams) and includes a broad variety\nof domain-specific text (from cooking, politics, and sports to high-school\ncurricula), demonstrating the need for multi-modal understanding in the\nreal-world. We show that this benchmark is quite challenging for existing\nlarge-scale vision-language models and encourage development of systems that\npossess robust visuo-linguistic reasoning capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2410.13666v1",
    "published": "2024-10-17T15:27:17+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13665v2",
    "title": "Strongly connected orientations and integer lattices",
    "authors": [
      "Ahmad Abdi",
      "Gérard Cornuéjols",
      "Siyue Liu",
      "Olha Silina"
    ],
    "abstract": "Let $D=(V,A)$ be a digraph whose underlying graph is $2$-edge-connected, and\nlet $P$ be the polytope whose vertices are the incidence vectors of arc sets\nwhose reversal makes $D$ strongly connected. We study the lattice theoretic\nproperties of the integer points contained in a proper face $F$ of $P$ not\ncontained in $\\{x:x_a=i\\}$ for any $a\\in A,i\\in \\{0,1\\}$. We prove under a mild\nnecessary condition that $F\\cap \\{0,1\\}^A$ contains an integral basis $B$,\ni.e., $B$ is linearly independent, and any integral vector in the linear hull\nof $F$ is an integral linear combination of $B$. This result is surprising as\nthe integer points in $F$ do not necessarily form a Hilbert basis. In proving\nthe result, we develop a theory similar to Matching Theory for\ndegree-constrained dijoins in bipartite digraphs. Our result has consequences\nfor head-disjoint strong orientations in hypergraphs, and also to a famous\nconjecture by Woodall that the minimum size of a dicut of $D$, say $\\tau$, is\nequal to the maximum number of disjoint dijoins. We prove a relaxation of this\nconjecture, by finding for any prime number $p\\geq 2$, a $p$-adic packing of\ndijoins of value $\\tau$ and of support size at most $2|A|$. We also prove that\nthe all-ones vector belongs to the lattice generated by $F\\cap \\{0,1\\}^A$,\nwhere $F$ is the face of $P$ satisfying $x(\\delta^+(U))=1$ for every minimum\ndicut $\\delta^+(U)$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13665v2",
    "published": "2024-10-17T15:26:43+00:00",
    "categories": [
      "math.CO",
      "math.OC",
      "90-XX, 05-XX"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13664v2",
    "title": "Dynamical correlations and nonequilibrium sum rules in photodoped Hubbard ladders",
    "authors": [
      "E. Merhej",
      "J. P. Hague",
      "R. M. Konik",
      "A. J. A. James"
    ],
    "abstract": "Using matrix product state techniques we study the nonequilibrium dynamical\nresponse of the half-filled Hubbard ladder when subject to an optical pump.\nOptical pumping offers a way of producing and manipulating new strongly\ncorrelated phenomena by suppressing existing magnetic correlations. The ladder\nallows the effects of pump directionality to be investigated, and compared to a\nsingle chain it has strong spin-charge coupling and a fully gapped excitation\nspectrum, promising different nonequilibrium physics. We compute time-dependent\ncorrelations, including the nonequilibrium dynamical structure factors for spin\nand charge. By deriving a combined spin-charge sum rule that applies both in\nand out-of-equilibrium, we show that spectral weight is pumped directly from\nthe antiferromagnetic spin response into a low energy $\\omega\\sim 0$ charge\nresponse below the Mott gap. The transfer of weight is pump direction\ndependent: pumping directed along the legs disrupts magnetic correlations more\nthan pumping in the rung direction, even if the post pump energy density is\nsimilar. The charge correlation length is dramatically enhanced by the pump,\nwhilst the spin correlations are most strongly suppressed at nearest and\nnext-nearest neighbour spacings. After the pump the system is in a nonthermal\ncorrelated metallic state, with gapless charge excitations and approximately\nequal spin and charge correlation lengths, emphasising the importance of\ntreating these degrees of freedom on an equal footing in nonequilibrium\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13664v2",
    "published": "2024-10-17T15:26:14+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13663v1",
    "title": "DiRecNetV2: A Transformer-Enhanced Network for Aerial Disaster Recognition",
    "authors": [
      "Demetris Shianios",
      "Panayiotis Kolios",
      "Christos Kyrkou"
    ],
    "abstract": "The integration of Unmanned Aerial Vehicles (UAVs) with artificial\nintelligence (AI) models for aerial imagery processing in disaster assessment,\nnecessitates models that demonstrate exceptional accuracy, computational\nefficiency, and real-time processing capabilities. Traditionally Convolutional\nNeural Networks (CNNs), demonstrate efficiency in local feature extraction but\nare limited by their potential for global context interpretation. On the other\nhand, Vision Transformers (ViTs) show promise for improved global context\ninterpretation through the use of attention mechanisms, although they still\nremain underinvestigated in UAV-based disaster response applications. Bridging\nthis research gap, we introduce DiRecNetV2, an improved hybrid model that\nutilizes convolutional and transformer layers. It merges the inductive biases\nof CNNs for robust feature extraction with the global context understanding of\nTransformers, maintaining a low computational load ideal for UAV applications.\nAdditionally, we introduce a new, compact multi-label dataset of disasters, to\nset an initial benchmark for future research, exploring how models trained on\nsingle-label data perform in a multi-label test set. The study assesses\nlightweight CNNs and ViTs on the AIDERSv2 dataset, based on the frames per\nsecond (FPS) for efficiency and the weighted F1 scores for classification\nperformance. DiRecNetV2 not only achieves a weighted F1 score of 0.964 on a\nsingle-label test set but also demonstrates adaptability, with a score of 0.614\non a complex multi-label test set, while functioning at 176.13 FPS on the\nNvidia Orin Jetson device.",
    "pdf_url": "http://arxiv.org/pdf/2410.13663v1",
    "published": "2024-10-17T15:25:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13662v1",
    "title": "ActionCOMET: A Zero-shot Approach to Learn Image-specific Commonsense Concepts about Actions",
    "authors": [
      "Shailaja Keyur Sampat",
      "Yezhou Yang",
      "Chitta Baral"
    ],
    "abstract": "Humans observe various actions being performed by other humans (physically or\nin videos/images) and can draw a wide range of inferences about it beyond what\nthey can visually perceive. Such inferences include determining the aspects of\nthe world that make action execution possible (e.g. liquid objects can undergo\npouring), predicting how the world will change as a result of the action (e.g.\npotatoes being golden and crispy after frying), high-level goals associated\nwith the action (e.g. beat the eggs to make an omelet) and reasoning about\nactions that possibly precede or follow the current action (e.g. crack eggs\nbefore whisking or draining pasta after boiling). Similar reasoning ability is\nhighly desirable in autonomous systems that would assist us in performing\neveryday tasks. To that end, we propose a multi-modal task to learn\naforementioned concepts about actions being performed in images. We develop a\ndataset consisting of 8.5k images and 59.3k inferences about actions grounded\nin those images, collected from an annotated cooking-video dataset. We propose\nActionCOMET, a zero-shot framework to discern knowledge present in language\nmodels specific to the provided visual input. We present baseline results of\nActionCOMET over the collected dataset and compare them with the performance of\nthe best existing VQA approaches.",
    "pdf_url": "http://arxiv.org/pdf/2410.13662v1",
    "published": "2024-10-17T15:22:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13661v2",
    "title": "Testing black holes with cosmological constant in Einstein-bumblebee gravity through the black hole shadow using EHT data and deflection angle",
    "authors": [
      "Reggie C. Pantig",
      "Shubham Kala",
      "Ali Övgün",
      "Nikko John Leo S. Lobos"
    ],
    "abstract": "This study probes spacetime solutions within Einstein-Bumblebee gravity, a\nmodified gravitational framework incorporating spontaneous Lorentz symmetry\nviolation through a vector field mechanism. By introducing a cosmological\nconstant into this model, the research scrutinizes thermodynamic properties of\nblack holes in both anti-de Sitter (AdS) and de Sitter (dS) geometries. The\ninvestigation demonstrates how Lorentz-violating parameters alter foundational\nthermodynamic principles, including revisions to the first law of black hole\nmechanics and shifts in critical phenomena during phase transitions. Notably,\nthe bumblebee coupling parameter emerges as a critical factor governing horizon\nstructure and thermal emission characteristics, with pronounced deviations from\ngeneral relativity (GR) predictions observed as this parameter increases. The\nanalysis extends to observational signatures by calculating shadow profiles of\nthese modified black holes. Shadow morphology exhibits dual dependence on the\ncosmological constant and the bumblebee parameter, presenting measurable\ndiscrepancies from classical relativity that could be constrained through Event\nHorizon Telescope (EHT) observational data. Furthermore, using geometric\nformalisms, the study quantifies light deflection phenomena in weak and strong\ngravitational regimes. Results reveal that both the cosmological constant and\nLorentz-violating parameter induce detectable modifications to lensing angles\ncompared to Schwarzschild or Kerr benchmarks. These deviations, while subtle,\nunderscore the necessity for next-generation astronomical instruments capable\nof resolving fine-scale spacetime curvature effects.",
    "pdf_url": "http://arxiv.org/pdf/2410.13661v2",
    "published": "2024-10-17T15:22:16+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13660v1",
    "title": "VBMicroLensing: three algorithms for multiple lensing with contour integration",
    "authors": [
      "V. Bozza",
      "V. Saggese",
      "G. Covone",
      "P. Rota",
      "J. Zhang"
    ],
    "abstract": "Modeling of microlensing events poses computational challenges for the\nresolution of the lens equation and the high dimensionality of the parameter\nspace. In particular, numerical noise represents a severe limitation to fast\nand efficient calculations of microlensing by multiple systems, which are of\nparticular interest in exoplanetary searches. We present a new public code\nbuilt on our previous experience on binary lenses that introduces three new\nalgorithms for the computation of magnification and astrometry in multiple\nmicrolensing. Besides the classical polynomial resolution, we introduce a\nmulti-polynomial approach in which each root is calculated in a frame centered\non the closest lens. In addition, we propose a new algorithm based on a\nmodified Newton-Raphson method applied to the original lens equation without\nany numerical manipulation. These new algorithms are more accurate and robust\ncompared to traditional single-polynomial approaches at a modest computational\ncost, opening the way to massive studies of multiple lenses. The new algorithms\ncan be used in a complementary way to optimize efficiency and robustness.",
    "pdf_url": "http://arxiv.org/pdf/2410.13660v1",
    "published": "2024-10-17T15:21:24+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13659v1",
    "title": "Neutralino dark matter in the extension of MSSM with two triplets and singlet",
    "authors": [
      "Zhong-Jun Yang",
      "Jin-Lei Yang",
      "Shu-Min Zhao",
      "Xing-Gang Wu",
      "Tai-Fu Feng"
    ],
    "abstract": "In an extension of MSSM with two triplets and a singlet, called the TNMSSM,\nthere are seven neutralinos which can enrich the study of cold dark matter if\none expects that the weakly interacting massive particle (WIMP) is responsible\nfor the observation of Planck satellite. Such a model, compared to the MSSM,\ncan naturally offer a solution to the $\\mu$ problem, and its lightest\nneutralino, which is bino-like, can also provide a correct relic density by\nusing the coannihilation mechanism due to the newly added triplinos. Taking\ninto account the related experimental measurements, such as the bound on the\nSM-like Higgs mass, the $B$ meson rare decays, the anomalous magnetic moment of\nthe muon $a_\\mu$, the Large Hadron Collider (LHC) measurements and the latest\ndark matter direct detection experiment LUX-ZEPLIN (LZ), the TNMSSM parameter\nspace can be strictly limited. In respect to all the constraints mentioned\nabove, we find that a bino-like neutralino with a mass in the region $[100,\n450]~\\rm{GeV}$ can successfully account for the correct dark matter relic\ndensity. Additionally, most of the viable parameter space can be tested in the\nnear future experiments such as the Xenon-nT experiment or LHC.",
    "pdf_url": "http://arxiv.org/pdf/2410.13659v1",
    "published": "2024-10-17T15:20:41+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13658v2",
    "title": "The Subtlety of Optimal Paternalism in a Population with Bounded Rationality",
    "authors": [
      "Charles F. Manski",
      "Eytan Sheshinski"
    ],
    "abstract": "We study optimal policy when a paternalistic utilitarian planner has the\npower to design a discrete choice set for a heterogeneous population with\nbounded rationality. We show that the policy that most effectively constrains\nor influences choices depends in a particular multiplicative way on the\npreferences of the population and on the choice probabilities conditional on\npreferences that measure the suboptimality of behavior. We first consider the\nplanning problem in abstraction. We then study two settings in which the\nplanner may mandate an action or decentralize decision making. In one setting,\nwe suppose that individuals measure utility with additive random error and\nmaximize mismeasured rather than actual utility. Then optimal planning requires\nknowledge of the distribution of measurement errors. In the second setting, we\nconsider binary treatment choice under uncertainty when the planner can mandate\na treatment conditional on publicly observed personal covariates or can enable\nindividuals to choose their own treatments conditional on private information.\nWe focus on situations where bounded rationality takes the form of deviations\nbetween subjective personal beliefs and objective probabilities of uncertain\noutcomes. To illustrate, we consider clinical decision making in medicine. In\ntoto, our analysis is cautionary. It characterizes the subtle nature of optimal\npolicy, whose determination requires the planner to possess extensive knowledge\nthat is rarely available. We conclude that studies of policy choice by a\npaternalistic utilitarian planner should view not only the population but also\nthe planner to be boundedly rational.",
    "pdf_url": "http://arxiv.org/pdf/2410.13658v2",
    "published": "2024-10-17T15:20:39+00:00",
    "categories": [
      "econ.EM",
      "econ.TH"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13657v1",
    "title": "Selection of Filters for Photonic Crystal Spectrometer Using Domain-Aware Evolutionary Algorithms",
    "authors": [
      "Kirill Antonov",
      "Marijn Siemons",
      "Niki van Stein",
      "Thomas H. W. Bäck",
      "Ralf Kohlhaas",
      "Anna V. Kononova"
    ],
    "abstract": "This work addresses the critical challenge of optimal filter selection for a\nnovel trace gas measurement device. This device uses photonic crystal filters\nto retrieve trace gas concentrations prone to photon and read noise. The filter\nselection directly influences accuracy and precision of the gas retrieval and\ntherefore is a crucial performance driver. We formulate the problem as a\nstochastic combinatorial optimization problem and develop a simulator mimicking\ngas retrieval with noise. The objective function for selecting filters reducing\nretrieval error is minimized by the employed metaheuristics, that represent\nvarious families of optimizers. We aim to improve the found top-performing\nalgorithms using our novel distance-driven extensions, that employ metrics on\nthe space of filter selections. This leads to a novel adaptation of the UMDA\nalgorithm, we call UMDA-U-PLS-Dist, equipped with one of the proposed distance\nmetrics as the most efficient and robust solver among the considered ones.\nAnalysis of filter sets produced by this method reveals that filters with\nrelatively smooth transmission profiles but containing high contrast improve\nthe device performance. Moreover, the top-performing obtained solution shows\nsignificant improvement compared to the baseline.",
    "pdf_url": "http://arxiv.org/pdf/2410.13657v1",
    "published": "2024-10-17T15:20:22+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13656v2",
    "title": "Physical Space Proof of Bilinear Estimates and Applications to Nonlinear Dispersive Equations",
    "authors": [
      "Li Tu",
      "Yi Zhou"
    ],
    "abstract": "We give a simpler proof for the local well-posedness of the modified\nKorteweg-de Vries equations and modified Benjamin-Ono equation in\n$H^{\\frac{1}{4}}(\\mathbb{R})$ and $H^{\\frac{1}{2}}(\\mathbb{R})$, respectively.\nThe proof is based on the Strichartz estimate, dyadic decomposition and a\nbilinear estimate given by a new type of div-curl lemma.",
    "pdf_url": "http://arxiv.org/pdf/2410.13656v2",
    "published": "2024-10-17T15:20:14+00:00",
    "categories": [
      "math.AP",
      "35Q53"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13655v3",
    "title": "Adding Photonic Entanglement to Superradiance by Using Multilevel Atoms",
    "authors": [
      "Amir Sivan",
      "Meir Orenstein"
    ],
    "abstract": "We show here that the photonic states emitted by ensembles of multilevel\natoms via a superradiance process exhibit entanglement in the modal (frequency)\ndegree of freedom, making this collective emission process a favorable\ncandidate for a fast, bright and deterministic source of entangled photons.\nThis entanglement is driven by two mechanisms: (i) selective excitation of the\natomic ensemble to a superposition state and (ii) degeneracies of the optical\ntransitions due to internal structure of the emitting atoms. The latter induces\nintricate non-radiative virtual transitions in the ensemble, which create\ninteratomic correlations that are imprinted onto the emitted photons. One of\nthe important outcomes of this complexity is the generation of mode-independent\nentangled multiphoton states. In addition, we study the dynamics of the\ncorrelations of the superradiating multilevel atom ensembles, and demonstrate a\ncase where they exhibit beating in steady-state due to the aforementioned\nvirtual transitions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13655v3",
    "published": "2024-10-17T15:19:54+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13654v1",
    "title": "Red and blue language: Word choices in the Trump & Harris 2024 presidential debate",
    "authors": [
      "Philipp Wicke",
      "Marianna M. Bolognesi"
    ],
    "abstract": "Political debates are a peculiar type of political discourse, in which\ncandidates directly confront one another, addressing not only the the\nmoderator's questions, but also their opponent's statements, as well as the\nconcerns of voters from both parties and undecided voters. Therefore, language\nis adjusted to meet specific expectations and achieve persuasion. We analyse\nhow the language of Trump and Harris during the debate (September 10th 2024)\ndiffers in relation to the following semantic and pragmatic features, for which\nwe formulated targeted hypotheses: framing values and ideology, appealing to\nemotion, using words with different degrees of concreteness and specificity,\naddressing others through singular or plural pronouns. Our findings include:\ndifferences in the use of figurative frames (Harris often framing issues around\nrecovery and empowerment, Trump often focused on crisis and decline); similar\nuse of emotional language, with Trump showing a slight higher tendency toward\nnegativity and toward less subjective language compared to Harris; no\nsignificant difference in the specificity of candidates' responses; similar use\nof abstract language, with Trump showing more variability than Harris,\ndepending on the subject discussed; differences in addressing the opponent,\nwith Trump not mentioning Harris by name, while Harris referring to Trump\nfrequently; different uses of pronouns, with Harris using both singular and\nplural pronouns equally, while Trump using more singular pronouns. The results\nare discussed in relation to previous literature on Red and Blue language,\nwhich refers to distinct linguistic patterns associated with conservative (Red)\nand liberal (Blue) political ideologies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13654v1",
    "published": "2024-10-17T15:19:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13653v2",
    "title": "Sheaf Theoretic Approach to Lefschetz Calculus",
    "authors": [
      "Alejandro O. Majadas-Moure",
      "David Mosquera-Lois"
    ],
    "abstract": "We lift the Lefschetz number from an algebraic invariant of maps between\nspaces to an invariant of morphisms of data over the spaces.",
    "pdf_url": "http://arxiv.org/pdf/2410.13653v2",
    "published": "2024-10-17T15:16:52+00:00",
    "categories": [
      "math.AT"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13652v2",
    "title": "Tropicalizing binary geometries",
    "authors": [
      "Shelby Cox",
      "Igor Makhlin"
    ],
    "abstract": "The type A cluster configuration space, commonly known as $\\mathcal M_{0,n}$,\nis the very affine part of the binary geometry associated with the\nassociahedron. The tropicalization of $\\mathcal M_{0,n}$ can be realized as the\nspace of phylogenetic trees and its signed tropicalizations as the\ndual-associahedron subfans. We give a concise overview of this construction and\npropose an extension to type C. The type C cluster configuration space\n$\\mathcal M_{\\mathrm C_l}$ arises from the binary geometry associated with the\ncyclohedron. We define a space of axially symmetric phylogenetic trees\ncontaining many dual-associahedron and dual-cyclohedron subfans. We\nconjecturally realize the tropicalization of $\\mathcal M_{\\mathrm C_l}$ as the\ndefined space and its signed tropicalizations as the aforementioned subfans.",
    "pdf_url": "http://arxiv.org/pdf/2410.13652v2",
    "published": "2024-10-17T15:16:14+00:00",
    "categories": [
      "math.AG",
      "math.CO"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13651v1",
    "title": "Help Me Identify: Is an LLM+VQA System All We Need to Identify Visual Concepts?",
    "authors": [
      "Shailaja Keyur Sampat",
      "Maitreya Patel",
      "Yezhou Yang",
      "Chitta Baral"
    ],
    "abstract": "An ability to learn about new objects from a small amount of visual data and\nproduce convincing linguistic justification about the presence/absence of\ncertain concepts (that collectively compose the object) in novel scenarios is\nan important characteristic of human cognition. This is possible due to\nabstraction of attributes/properties that an object is composed of e.g. an\nobject `bird' can be identified by the presence of a beak, feathers, legs,\nwings, etc. Inspired by this aspect of human reasoning, in this work, we\npresent a zero-shot framework for fine-grained visual concept learning by\nleveraging large language model and Visual Question Answering (VQA) system.\nSpecifically, we prompt GPT-3 to obtain a rich linguistic description of visual\nobjects in the dataset. We convert the obtained concept descriptions into a set\nof binary questions. We pose these questions along with the query image to a\nVQA system and aggregate the answers to determine the presence or absence of an\nobject in the test images. Our experiments demonstrate comparable performance\nwith existing zero-shot visual classification methods and few-shot concept\nlearning approaches, without substantial computational overhead, yet being\nfully explainable from the reasoning perspective.",
    "pdf_url": "http://arxiv.org/pdf/2410.13651v1",
    "published": "2024-10-17T15:16:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13650v1",
    "title": "Millisecond pulsars phenomenology under the light of graph theory",
    "authors": [
      "C. R. García",
      "G. Illiano",
      "D. F. Torres",
      "A. Papitto",
      "F. Coti Zelati",
      "D. de Martino",
      "A. Patruno"
    ],
    "abstract": "We compute and apply the minimum spanning tree (MST) of the binary\nmillisecond pulsar population, and discuss aspects of the known phenomenology\nof these systems in this context. We find that the MST effectively separates\ndifferent classes of spider pulsars, eclipsing radio pulsars in tight binary\nsystems either with a companion with a mass in the range of approximately\n0.1-0.8 solar masses (redbacks) or with a companion of less than or\napproximately 0.06 solar masses (black widows), into distinct branches. The MST\nalso separates black widows located in globular clusters from those found in\nthe field and groups other pulsar classes of interest, including transitional\nmillisecond pulsars. Using the MST and a defined ranking for similarity, we\nidentify possible candidates likely to belong to these pulsar classes. In\nparticular, based on this approach, we propose the black widows' classification\nof J1300+1240, J1630+3550, J1317-0157, J1221-0633, J1627+3219, J1737-0314A, and\nJ1701-3006F, discuss that of J1908+2105, and analyze J1723-2837, J1431-4715,\nand J1902-5105 as possible transitional systems. We introduce an algorithm that\nquickly locates where new pulsars fall within the MST and use this to examine\nthe positions of the transitional millisecond pulsar IGR J18245-2452 (PSR\nJ1824-2452I), the transitional millisecond pulsar candidate 3FGL J1544.6-1125,\nand the accreting millisecond X-ray pulsar SAX J1808.4-3658. Assessing the\npositions of these sources in the MST assuming a range for their unknown\nvariables (e.g., the spin period derivative of PSR J1824-2452I) we can\neffectively narrow down the parameter space necessary for searching and\ndetermining key pulsar parameters through targeted observations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13650v1",
    "published": "2024-10-17T15:16:03+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13649v2",
    "title": "A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks",
    "authors": [
      "Tianyi Zhang",
      "Atta Norouzian",
      "Aanchan Mohan",
      "Frederick Ducatelle"
    ],
    "abstract": "In virtual assistant (VA) systems it is important to reject or redirect user\nqueries that fall outside the scope of the system. One of the most accurate\napproaches for out-of-scope (OOS) rejection is to combine it with the task of\nintent classification on in-scope queries, and to use methods based on the\nsimilarity of embeddings produced by transformer-based sentence encoders.\nTypically, such encoders are fine-tuned for the intent-classification task,\nusing cross-entropy loss. Recent work has shown that while this produces\nsuitable embeddings for the intent-classification task, it also tends to\ndisperse in-scope embeddings over the full sentence embedding space. This\ncauses the in-scope embeddings to potentially overlap with OOS embeddings,\nthereby making OOS rejection difficult. This is compounded when OOS data is\nunknown. To mitigate this issue our work proposes to regularize the\ncross-entropy loss with an in-scope embedding reconstruction loss learned using\nan auto-encoder. Our method achieves a 1-4% improvement in the area under the\nprecision-recall curve for rejecting out-of-sample (OOS) instances, without\ncompromising intent classification performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13649v2",
    "published": "2024-10-17T15:15:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13648v1",
    "title": "SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs",
    "authors": [
      "Yuling Gu",
      "Oyvind Tafjord",
      "Hyunwoo Kim",
      "Jared Moore",
      "Ronan Le Bras",
      "Peter Clark",
      "Yejin Choi"
    ],
    "abstract": "While prior work has explored whether large language models (LLMs) possess a\n\"theory of mind\" (ToM) - the ability to attribute mental states to oneself and\nothers - there has been little work testing whether LLMs can implicitly apply\nsuch knowledge to predict behavior, or to judge whether an observed behavior is\nrational. Such skills are critical for appropriate interaction in social\nenvironments. We create a new dataset, SimpleTom, containing concise, diverse\nstories (e.g., \"The can of Pringles has moldy chips in it. Mary picks up the\ncan in the supermarket and walks to the cashier.\"), each with three questions\nthat test different degrees of ToM reasoning, asking models to predict (a)\nmental state (\"Is Mary aware of the mold?\"), (b) behavior (\"Will Mary pay for\nthe chips or report the mold?\"), and (c) judgment (\"Mary paid for the chips.\nWas that reasonable?\"). To our knowledge, SimpleToM is the first dataset to\nsystematically explore downstream reasoning requiring knowledge of mental\nstates in realistic scenarios. Our experimental results are intriguing: While\nmost models can reliably predict mental state on our dataset (a), they often\nfail to correctly predict the behavior (b), and fare even worse at judging\nwhether given behaviors are reasonable (c), despite being correctly aware of\nthe protagonist's mental state should make such secondary predictions obvious.\nWe further show that we can help models do better at (b) and (c) via\ninterventions such as reminding the model of its earlier mental state answer\nand mental-state-specific chain-of-thought prompting, raising the action\nprediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment\naccuracies (e.g., from 15.3% to 94.7% in GPT-4o). While this shows that models\ncan be coaxed to perform well, it requires task-specific interventions, and the\nnatural model performances remain low, a cautionary tale for LLM deployment.",
    "pdf_url": "http://arxiv.org/pdf/2410.13648v1",
    "published": "2024-10-17T15:15:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13647v1",
    "title": "Multimodal growth and development assessment model",
    "authors": [
      "Ying Li",
      "Zichen Song",
      "Zijie Gong",
      "Sitan Huang",
      "Jiewei Ge"
    ],
    "abstract": "With the development of social economy and the improvement of people's\nattention to health, the growth and development of children and adolescents has\nbecome an important indicator to measure the level of national health.\nTherefore, accurate and timely assessment of children's growth and development\nhas become increasingly important. At the same time, global health\ninequalities, especially child malnutrition and stunting in developing\ncountries, urgently require effective assessment tools to monitor and\nintervene. In recent years, the rapid development of technologies such as big\ndata, artificial intelligence, and cloud computing, and the cross-integration\nof multiple disciplines such as biomedicine, statistics, and computer science\nhave promoted the rapid development of large-scale models for growth and\ndevelopment assessment. However, there are still problems such as too single\nevaluation factors, inaccurate diagnostic results, and inability to give\naccurate and reasonable recommendations. The multi-modal growth and development\nassessment model uses the public data set of RSNA ( North American College of\nRadiology ) as the training set, and the data set of the Department of\nPediatrics of Huaibei People's Hospital as the open source test set. The\nembedded ICL module enables the model to quickly adapt and identify the tasks\nthat need to be done to ensure that under the premise of considering multiple\nevaluation factors, accurate diagnosis results and reasonable medical\nrecommendations are given, so as to provide solutions to the above problems and\npromote the development of the medical field.",
    "pdf_url": "http://arxiv.org/pdf/2410.13647v1",
    "published": "2024-10-17T15:13:26+00:00",
    "categories": [
      "cs.CE",
      "cs.MM"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13646v2",
    "title": "Certifying steady-state properties of open quantum systems",
    "authors": [
      "Luke Mortimer",
      "Donato Farina",
      "Grazia Di Bello",
      "David Jansen",
      "Andreas Leitherer",
      "Pere Mujal",
      "Antonio Acín"
    ],
    "abstract": "Estimating the steady-state properties of open many-body quantum systems is a\nfundamental challenge in quantum science and technologies. In this work, we\npresent a scalable approach based on semi-definite programming to derive\ncertified bounds on the expectation value of an arbitrary observable in the\nsteady state of Lindbladian dynamics. We illustrate our method on a series of\nmany-body systems, including paradigmatic spin-1/2 chains and two-dimensional\nladders, considering both equilibrium and nonequilibrium steady-states. We\nbenchmark our method with state-of-the-art tensor-network approaches that,\nunlike our method, are only able to provide estimates, with no guarantee, on\nsteady-state quantities. For the tested models, only modest computational\neffort is needed to obtain certified non-trivial bounds for system sizes\nintractable by exact methods. Our method introduces the first general numerical\ntool for bounding steady-state properties of open quantum dynamics, opening a\nnew avenue in the understanding of stable configurations in many-body systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13646v2",
    "published": "2024-10-17T15:13:12+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13645v1",
    "title": "Automated Model Discovery for Tensional Homeostasis: Constitutive Machine Learning in Growth and Remodeling",
    "authors": [
      "Hagen Holthusen",
      "Tim Brepols",
      "Kevin Linka",
      "Ellen Kuhl"
    ],
    "abstract": "Soft biological tissues exhibit a tendency to maintain a preferred state of\ntensile stress, known as tensional homeostasis, which is restored even after\nexternal mechanical stimuli. This macroscopic behavior can be described using\nthe theory of kinematic growth, where the deformation gradient is\nmultiplicatively decomposed into an elastic part and a part related to growth\nand remodeling. Recently, the concept of homeostatic surfaces was introduced to\ndefine the state of homeostasis and the evolution equations for inelastic\ndeformations.\n  However, identifying the optimal model and material parameters to accurately\ncapture the macroscopic behavior of inelastic materials can only be\naccomplished with significant expertise, is often time-consuming, and prone to\nerror, regardless of the specific inelastic phenomenon. To address this\nchallenge, built-in physics machine learning algorithms offer significant\npotential.\n  In this work, we extend our inelastic Constitutive Artificial Neural Networks\n(iCANNs) by incorporating kinematic growth and homeostatic surfaces to discover\nthe scalar model equations, namely the Helmholtz free energy and the pseudo\npotential. The latter describes the state of homeostasis in a smeared sense. We\nevaluate the ability of the proposed network to learn from experimentally\nobtained tissue equivalent data at the material point level, assess its\npredictive accuracy beyond the training regime, and discuss its current\nlimitations when applied at the structural level.\n  Our source code, data, examples, and an implementation of the corresponding\nmaterial subroutine are made accessible to the public at\nhttps://doi.org/10.5281/zenodo.13946282.",
    "pdf_url": "http://arxiv.org/pdf/2410.13645v1",
    "published": "2024-10-17T15:12:55+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.CE",
      "65, 74",
      "I.6; J.2"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13644v1",
    "title": "Analysing the Onset of Cometary Activity by the Jupiter-Family Comet 2023 RN3",
    "authors": [
      "Matthew M. Dobson",
      "Megan E. Schwamb",
      "Alan Fitzsimmons",
      "Michael S. P. Kelley",
      "Carrie E. Holt",
      "Joseph Murtagh",
      "Henry H. Hsieh",
      "Larry Denneau",
      "Nicolas Erasmus",
      "A. N. Heinze",
      "Luke J. Shingles",
      "Robert J. Siverd",
      "Ken W. Smith",
      "John L. Tonry",
      "Henry Weiland",
      "David. R. Young",
      "Tim Lister",
      "Edward Gomez",
      "Joey Chatelain",
      "Sarah Greenstreet"
    ],
    "abstract": "We utilize serendipitous observations from the Asteroid Terrestrial-impact\nLast Alert System (ATLAS) and the Zwicky Transient Facility (ZTF) in addition\nto targeted follow-up observations from the Las Cumbres Observatory (LCO) and\nLiverpool Telescope to analyze the first observed instance of cometary activity\nby the newly-discovered Jupiter-family comet C/2023 RN3 (ATLAS), whose orbital\ndynamics place it close to residing on a Centaur-like orbit. Across our 7-month\nbaseline, we observe an epoch of cometary activity commencing in August 2023\nwith an increase in brightness of >5.4 mag. The lightcurve of 2023 RN3\nindicates the presence of continuous cometary activity across our observations,\nsuggesting the onset of a new period of sustained activity. We find no evidence\nof any outbursts on top of the observed brightening, nor do we find any\nsignificant color evolution across our observations. 2023 RN3 is visibly\nextended in LCO and Liverpool Telescope observations, indicating the presence\nof a spatially-extended coma. Numerical integration of 2023 RN3's orbit reveals\nthe comet to have recently undergone a slight increase in semimajor axis due to\na planetary encounter with Jupiter, however whether this orbital change could\ntrigger 2023 RN3's cometary activity is unclear. Our estimate for the maximum\ndust production metric of Afrho ~400 cm is consistent with previous\nmeasurements for the Jupiter-family comet and Centaur populations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13644v1",
    "published": "2024-10-17T15:12:45+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13643v2",
    "title": "Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design",
    "authors": [
      "Chenyu Wang",
      "Masatoshi Uehara",
      "Yichun He",
      "Amy Wang",
      "Tommaso Biancalani",
      "Avantika Lal",
      "Tommi Jaakkola",
      "Sergey Levine",
      "Hanchen Wang",
      "Aviv Regev"
    ],
    "abstract": "Recent studies have demonstrated the strong empirical performance of\ndiffusion models on discrete sequences across domains from natural language to\nbiological sequence generation. For example, in the protein inverse folding\ntask, conditional diffusion models have achieved impressive results in\ngenerating natural-like sequences that fold back into the original structure.\nHowever, practical design tasks often require not only modeling a conditional\ndistribution but also optimizing specific task objectives. For instance, we may\nprefer protein sequences with high stability. To address this, we consider the\nscenario where we have pre-trained discrete diffusion models that can generate\nnatural-like sequences, as well as reward models that map sequences to task\nobjectives. We then formulate the reward maximization problem within discrete\ndiffusion models, analogous to reinforcement learning (RL), while minimizing\nthe KL divergence against pretrained diffusion models to preserve naturalness.\nTo solve this RL problem, we propose a novel algorithm, DRAKES, that enables\ndirect backpropagation of rewards through entire trajectories generated by\ndiffusion models, by making the originally non-differentiable trajectories\ndifferentiable using the Gumbel-Softmax trick. Our theoretical analysis\nindicates that our approach can generate sequences that are both natural-like\nand yield high rewards. While similar tasks have been recently explored in\ndiffusion models for continuous domains, our work addresses unique algorithmic\nand theoretical challenges specific to discrete diffusion models, which arise\nfrom their foundation in continuous-time Markov chains rather than Brownian\nmotion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA\nand protein sequences that optimize enhancer activity and protein stability,\nrespectively, important tasks for gene therapies and protein-based\ntherapeutics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13643v2",
    "published": "2024-10-17T15:10:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13642v1",
    "title": "Stable-limit partially symmetric Macdonald functions and parabolic flag Hilbert schemes",
    "authors": [
      "Daniel Orr",
      "Milo Bechtloff Weising"
    ],
    "abstract": "The modified Macdonald functions $\\widetilde{H}_{\\mu}$ are fundamental\nobjects in modern algebraic combinatorics. Haiman showed that there is a\ncorrespondence between the $(\\mathbb{C}^{*})^2$-fixed points $I_{\\mu}$ of the\nHilbert schemes $\\mathrm{Hilb}_{n}(\\mathbb{C}^2)$ and the functions\n$\\widetilde{H}_{\\mu}$ realizing a derived equivalence between\n$(\\mathbb{C}^{*})^2$-equivariant coherent sheaves on\n$\\mathrm{Hilb}_{n}(\\mathbb{C}^2)$ and $(\\mathfrak{S}_n \\times\n(\\mathbb{C}^{*})^2)$-equivariant coherent sheaves on $(\\mathbb{C}^2)^n.$\nCarlsson--Gorsky--Mellit introduced a larger family of smooth projective\nvarieties $\\mathrm{PFH}_{n,n-k}$ called the parabolic flag Hilbert schemes.\nThey showed that an algebra $\\mathbb{B}_{q,t}$, directly related to the double\nDyck path algebra $\\mathbb{A}_{q,t}$ employed in Carlsson--Mellit's proof of\nthe Shuffle Theorem, acts naturally on the $(\\mathbb{C}^{*})^2$-equivariant\nK-theory $U_{\\bullet}$ of these spaces and, moreover, there is a\n$\\mathbb{B}_{q,t}$-isomorphism $\\Phi: U_{\\bullet} \\rightarrow V_{\\bullet}$\nwhere $V_{\\bullet}$ is the polynomial representation. The isomorphism $\\Phi:\nU_{\\bullet} \\rightarrow V_{\\bullet}$ is known to extend Haiman's\ncorrespondence. In this paper, we explicitly compute the images\n$\\Phi(H_{\\mu,w})$ of the normalized $(\\mathbb{C}^{*})^2$-fixed point classes\n$H_{\\mu,w}$ of the spaces $\\mathrm{PFH}_{n,n-k}$ and show they agree with the\nmodified partially symmetric Macdonald polynomials\n$\\widetilde{H}_{(\\lambda|\\gamma)}$ introduced by Goodberry-Orr, confirming\ntheir prior conjecture. We use this result to give an explicit formula for the\naction of the involution $\\mathcal{N}$ on $V_{\\bullet}.$",
    "pdf_url": "http://arxiv.org/pdf/2410.13642v1",
    "published": "2024-10-17T15:10:10+00:00",
    "categories": [
      "math.CO",
      "math.QA",
      "math.RT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13641v2",
    "title": "An Active Learning Framework for Inclusive Generation by Large Language Models",
    "authors": [
      "Sabit Hassan",
      "Anthony Sicilia",
      "Malihe Alikhani"
    ],
    "abstract": "Ensuring that Large Language Models (LLMs) generate text representative of\ndiverse sub-populations is essential, particularly when key concepts related to\nunder-represented groups are scarce in the training data. We address this\nchallenge with a novel clustering-based active learning framework, enhanced\nwith knowledge distillation. The proposed framework transforms the intermediate\noutputs of the learner model, enabling effective active learning for generative\ntasks for the first time. Integration of clustering and knowledge distillation\nyields more representative models without prior knowledge of underlying data\ndistribution and overbearing human efforts. We validate our approach in\npractice through case studies in counter-narration and style transfer. We\nconstruct two new datasets in tandem with model training, showing a performance\nimprovement of 2%-10% over baseline models. Our results also show more\nconsistent performance across various data subgroups and increased lexical\ndiversity, underscoring our model's resilience to skewness in available data.\nFurther, our results show that the data acquired via our approach improves the\nperformance of secondary models not involved in the learning loop, showcasing\npractical utility of the framework.",
    "pdf_url": "http://arxiv.org/pdf/2410.13641v2",
    "published": "2024-10-17T15:09:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13640v2",
    "title": "Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation",
    "authors": [
      "Yiming Wang",
      "Pei Zhang",
      "Baosong Yang",
      "Derek F. Wong",
      "Rui Wang"
    ],
    "abstract": "LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensures real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13640v2",
    "published": "2024-10-17T15:09:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13639v2",
    "title": "A Comparative Study on Reasoning Patterns of OpenAI's o1 Model",
    "authors": [
      "Siwei Wu",
      "Zhongyuan Peng",
      "Xinrun Du",
      "Tuney Zheng",
      "Minghao Liu",
      "Jialong Wu",
      "Jiachen Ma",
      "Yizhi Li",
      "Jian Yang",
      "Wangchunshu Zhou",
      "Qunshu Lin",
      "Junbo Zhao",
      "Zhaoxiang Zhang",
      "Wenhao Huang",
      "Ge Zhang",
      "Chenghua Lin",
      "J. H. Liu"
    ],
    "abstract": "Enabling Large Language Models (LLMs) to handle a wider range of complex\ntasks (e.g., coding, math) has drawn great attention from many researchers. As\nLLMs continue to evolve, merely increasing the number of model parameters\nyields diminishing performance improvements and heavy computational costs.\nRecently, OpenAI's o1 model has shown that inference strategies (i.e.,\nTest-time Compute methods) can also significantly enhance the reasoning\ncapabilities of LLMs. However, the mechanisms behind these methods are still\nunexplored. In our work, to investigate the reasoning patterns of o1, we\ncompare o1 with existing Test-time Compute methods (BoN, Step-wise BoN, Agent\nWorkflow, and Self-Refine) by using OpenAI's GPT-4o as a backbone on general\nreasoning benchmarks in three domains (i.e., math, coding, commonsense\nreasoning). Specifically, first, our experiments show that the o1 model has\nachieved the best performance on most datasets. Second, as for the methods of\nsearching diverse responses (e.g., BoN), we find the reward models' capability\nand the search space both limit the upper boundary of these methods. Third, as\nfor the methods that break the problem into many sub-problems, the Agent\nWorkflow has achieved better performance than Step-wise BoN due to the\ndomain-specific system prompt for planning better reasoning processes. Fourth,\nit is worth mentioning that we have summarized six reasoning patterns of o1,\nand provided a detailed analysis on several reasoning benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13639v2",
    "published": "2024-10-17T15:09:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13638v1",
    "title": "Scaling Wearable Foundation Models",
    "authors": [
      "Girish Narayanswamy",
      "Xin Liu",
      "Kumar Ayush",
      "Yuzhe Yang",
      "Xuhai Xu",
      "Shun Liao",
      "Jake Garrison",
      "Shyam Tailor",
      "Jake Sunshine",
      "Yun Liu",
      "Tim Althoff",
      "Shrikanth Narayanan",
      "Pushmeet Kohli",
      "Jiening Zhan",
      "Mark Malhotra",
      "Shwetak Patel",
      "Samy Abdel-Ghaffar",
      "Daniel McDuff"
    ],
    "abstract": "Wearable sensors have become ubiquitous thanks to a variety of health\ntracking features. The resulting continuous and longitudinal measurements from\neveryday life generate large volumes of data; however, making sense of these\nobservations for scientific and actionable insights is non-trivial. Inspired by\nthe empirical success of generative modeling, where large neural networks learn\npowerful representations from vast amounts of text, image, video, or audio\ndata, we investigate the scaling properties of sensor foundation models across\ncompute, data, and model size. Using a dataset of up to 40 million hours of\nin-situ heart rate, heart rate variability, electrodermal activity,\naccelerometer, skin temperature, and altimeter per-minute data from over\n165,000 people, we create LSM, a multimodal foundation model built on the\nlargest wearable-signals dataset with the most extensive range of sensor\nmodalities to date. Our results establish the scaling laws of LSM for tasks\nsuch as imputation, interpolation and extrapolation, both across time and\nsensor modalities. Moreover, we highlight how LSM enables sample-efficient\ndownstream learning for tasks like exercise and activity recognition.",
    "pdf_url": "http://arxiv.org/pdf/2410.13638v1",
    "published": "2024-10-17T15:08:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13637v2",
    "title": "Normalizing self-supervised learning for provably reliable Change Point Detection",
    "authors": [
      "Alexandra Bazarova",
      "Evgenia Romanenkova",
      "Alexey Zaytsev"
    ],
    "abstract": "Change point detection (CPD) methods aim to identify abrupt shifts in the\ndistribution of input data streams. Accurate estimators for this task are\ncrucial across various real-world scenarios. Yet, traditional unsupervised CPD\ntechniques face significant limitations, often relying on strong assumptions or\nsuffering from low expressive power due to inherent model simplicity. In\ncontrast, representation learning methods overcome these drawbacks by offering\nflexibility and the ability to capture the full complexity of the data without\nimposing restrictive assumptions. However, these approaches are still emerging\nin the CPD field and lack robust theoretical foundations to ensure their\nreliability. Our work addresses this gap by integrating the expressive power of\nrepresentation learning with the groundedness of traditional CPD techniques. We\nadopt spectral normalization (SN) for deep representation learning in CPD tasks\nand prove that the embeddings after SN are highly informative for CPD. Our\nmethod significantly outperforms current state-of-the-art methods during the\ncomprehensive evaluation via three standard CPD datasets.",
    "pdf_url": "http://arxiv.org/pdf/2410.13637v2",
    "published": "2024-10-17T15:07:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13636v4",
    "title": "Probing Type-I 2HDM light Higgs in the top-pair-associated diphoton channel",
    "authors": [
      "Yabo Dong",
      "Kun Wang",
      "Jingya Zhu"
    ],
    "abstract": "Motivated by the possible 95 GeV diphoton excess, we investigate the\ncapability of the Type-I Two-Higgs-Doublet Model (2HDM-I) to explain this\nsignal under current theoretical and experimental constraints. Using full Monte\nCarlo (MC) simulations for the process of $pp \\to t(\\to W^+ b)\\bar{t}(\\to W^-\n\\bar{b})h(\\to \\gamma\\gamma)$, we evaluate the discovery potential of a 95 GeV\nHiggs boson at future colliders. Direct Higgs searches strongly constrain the\nparameter $\\alpha$, excluding the region with $\\alpha \\lesssim 0.95$. Monte\nCarlo results indicate that a minimum cross section of 0.3 fb is required to\nachieve a $5\\sigma$ signal statistical significance at the LHC with\n$\\mathcal{L} = 3~\\text{ab}^{-1}$. For the same luminosity, HE-LHC and FCC-hh\nrequire 0.67 fb and 2.36 fb, respectively. At the 14 TeV HL-LHC with an\nintegrated luminosity of $3\\,\\abm$, parameter regions with $\\sin(\\beta-\\alpha)\n\\gtrsim 0.4$ and $\\sin(\\beta-\\alpha) \\gtrsim 0.25$ can be probed at the\n$5\\sigma$ and $2\\sigma$ significance levels, respectively. At the 27 TeV HL-LHC\nwith $L = 10\\,\\abm$, the sensitivity improves to $\\sin(\\beta-\\alpha) \\gtrsim\n0.25$ ($5\\sigma$) and $\\gtrsim 0.15$ ($2\\sigma$). For the 100 TeV FCC-hh with\n$L = 30\\,\\abm$, even regions with $\\sin(\\beta-\\alpha) \\gtrsim 0.1$ or\n$\\sin(\\beta-\\alpha) \\lesssim -0.05$ can be covered at the $5\\sigma$ level.\nParameter regions near $\\sin(\\beta-\\alpha) \\approx 0$ remain challenging to\nprobe in the diphoton channel, even with increased energy or luminosity.",
    "pdf_url": "http://arxiv.org/pdf/2410.13636v4",
    "published": "2024-10-17T15:07:53+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.14744v1",
    "title": "Eliciting Uncertainty in Chain-of-Thought to Mitigate Bias against Forecasting Harmful User Behaviors",
    "authors": [
      "Anthony Sicilia",
      "Malihe Alikhani"
    ],
    "abstract": "Conversation forecasting tasks a model with predicting the outcome of an\nunfolding conversation. For instance, it can be applied in social media\nmoderation to predict harmful user behaviors before they occur, allowing for\npreventative interventions. While large language models (LLMs) have recently\nbeen proposed as an effective tool for conversation forecasting, it's unclear\nwhat biases they may have, especially against forecasting the (potentially\nharmful) outcomes we request them to predict during moderation. This paper\nexplores to what extent model uncertainty can be used as a tool to mitigate\npotential biases. Specifically, we ask three primary research questions: 1) how\ndoes LLM forecasting accuracy change when we ask models to represent their\nuncertainty; 2) how does LLM bias change when we ask models to represent their\nuncertainty; 3) how can we use uncertainty representations to reduce or\ncompletely mitigate biases without many training data points. We address these\nquestions for 5 open-source language models tested on 2 datasets designed to\nevaluate conversation forecasting for social media moderation.",
    "pdf_url": "http://arxiv.org/pdf/2410.14744v1",
    "published": "2024-10-17T15:07:53+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13635v3",
    "title": "SUPG-stabilized time-DG finite and virtual elements for the time-dependent advection-diffusion equation",
    "authors": [
      "Lourenço Beirão Da Veiga",
      "Franco Dassi",
      "Sergio Gómez"
    ],
    "abstract": "We carry out a stability and convergence analysis for the fully discrete\nscheme obtained by combining a finite or virtual element spatial discretization\nwith the upwind-discontinuous Galerkin time-stepping applied to the\ntime-dependent advection-diffusion equation. A space-time streamline-upwind\nPetrov-Galerkin term is used to stabilize the method. More precisely, we show\nthat the method is inf-sup stable with constant independent of the diffusion\ncoefficient, which ensures the robustness of the method in the convection- and\ndiffusion-dominated regimes. Moreover, we prove optimal convergence rates in\nboth regimes for the error in the energy norm. An important feature of the\npresented analysis is the control in the full $L^2(0,T;L^2(\\Omega))$ norm\nwithout the need of introducing an artificial reaction term in the model. We\nfinally present some numerical experiments in $(3 + 1)$-dimensions that\nvalidate our theoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2410.13635v3",
    "published": "2024-10-17T15:05:53+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "35K20, 65M12, 65M15, 65M60"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13634v3",
    "title": "Additional first order equation for infinitesimal bendings of smooth surfaces in the isothermal coordinates",
    "authors": [
      "Victor Alexandrov"
    ],
    "abstract": "The article contributes to the theory of infinitesimal bendings of smooth\nsurfaces in Euclidean 3-space. We derive a linear differential equation of the\nfirst order, which previously did not appear in the literature and which is\nsatisfied by any Darboux rotation field of a smooth surface. We show that, for\nsome surfaces, this additional equation is functionally independent of the\nthree standard equations that the Darboux rotation field satisfies (and by\nwhich it is determined). As a consequence of this additional equation, we prove\nthe maximum principle for the components of the Darboux rotation field for a\nclass of disk-homeomorphic surfaces containing not only surfaces of positive\nGaussian curvature.",
    "pdf_url": "http://arxiv.org/pdf/2410.13634v3",
    "published": "2024-10-17T15:05:35+00:00",
    "categories": [
      "math.DG",
      "53C24, 53A05, 53C18, 52C25"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13633v1",
    "title": "Path integral Monte Carlo in a discrete variable representation with Gibbs sampling: dipolar planar rotor chain",
    "authors": [
      "Wenxue Zhang",
      "Muhammad Shaeer Moeed",
      "Andrew Bright",
      "Tobias Serwatka",
      "Estevao De Oliveira",
      "Pierre-Nicholas Roy"
    ],
    "abstract": "In this work, we propose a Path Integral Monte Carlo (PIMC) approach based on\ndiscretized continuous degrees of freedom and rejection-free Gibbs sampling.\nThe ground state properties of a chain of planar rotors with dipole-dipole\ninteractions are used to illustrate the approach. Energetic and structural\nproperties are computed and compared to exact diagonalization and Numerical\nMatrix Multiplication for $N \\leq 3$ to assess the systematic Trotter\nfactorization error convergence. For larger chains with up to N = 100 rotors,\nDensity Matrix Renormalization Group (DMRG) calculations are used as a\nbenchmark. We show that using Gibbs sampling is advantageous compared to\ntraditional Metroplolis-Hastings rejection importance sampling. Indeed, Gibbs\nsampling leads to lower variance and correlation in the computed observables.",
    "pdf_url": "http://arxiv.org/pdf/2410.13633v1",
    "published": "2024-10-17T15:04:39+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mes-hall",
      "cond-mat.stat-mech",
      "physics.atm-clus",
      "quant-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13632v2",
    "title": "On-Shell Approach to Black Hole Mergers",
    "authors": [
      "Katsuki Aoki",
      "Andrea Cristofoli",
      "Yu-tin Huang"
    ],
    "abstract": "We develop an on-shell approach to study black hole mergers. Since,\nasymptotically, the initial and final states can be described by point-like\nspinning particles, we propose a massive three-point amplitude for the merger\nof two Schwarzschild black holes into a Kerr black hole. This three-point\namplitude and the spectral function of the final state are fully determined by\nkinematics and the model-independent input about the black hole merger which is\ndescribed by a complete absorption process. Using the Kosower-Maybee-O'Connell\n(KMOC) formalism, we then reproduce the classical conservation laws for\nmomentum and angular momentum after the merger. As an application, we use the\nproposed three-point to compute the graviton emission amplitude, from which we\nextract the merger waveform to all orders in spin but leading in gravitational\ncoupling. Up to sub-subleading order in spin, this matches the classical soft\ngraviton theorem. We conclude with a comparison to black hole perturbation\ntheory, which gives complementary amplitudes which are non-perturbative in the\ngravitational coupling but to leading order in the extreme mass ratio limit.\nThis also highlights how boundary conditions on a Schwarzschild background can\nbe used to rederive the proposed on-shell amplitudes for merger processes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13632v2",
    "published": "2024-10-17T15:04:04+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13631v2",
    "title": "Eigenvalue systems for integer orthogonal bases of multi-matrix invariants at finite N",
    "authors": [
      "Adrian Padellaro",
      "Sanjaye Ramgoolam",
      "Ryo Suzuki"
    ],
    "abstract": "Multi-matrix invariants, and in particular the scalar multi-trace operators\nof $\\mathcal{N}=4$ SYM with $U(N)$ gauge symmetry, can be described using\npermutation centraliser algebras (PCA), which are generalisations of the\nsymmetric group algebras and independent of $N$. Free-field two-point functions\ndefine an $N$-dependent inner product on the PCA, and bases of operators have\nbeen constructed which are orthogonal at finite $N$. Two such bases are\nwell-known, the restricted Schur and covariant bases, and both definitions\ninvolve representation-theoretic quantities such as Young diagram labels,\nmultiplicity labels, branching and Clebsch-Gordan coefficients for symmetric\ngroups. The explicit computation of these coefficients grows rapidly in\ncomplexity as the operator length increases. We develop a new method for\nexplicitly constructing all the operators with specified Young diagram labels,\nbased on an $N$-independent integer eigensystem formulated in the PCA. The\neigensystem construction naturally leads to orthogonal basis elements which are\ninteger linear combinations of the multi-trace operators, and the\n$N$-dependence of their norms are simple known dimension factors. We provide\nexamples and give computer codes in SageMath which efficiently implement the\nconstruction for operators of classical dimension up to 14. While the\nrestricted Schur basis relies on the Artin-Wedderburn decomposition of\nsymmetric group algebras, the covariant basis relies on a variant which we\nrefer to as the Kronecker decomposition. Analogous decompositions exist for any\nfinite group algebra and the eigenvalue construction of integer orthogonal\nbases extends to the group algebra of any finite group with rational\ncharacters.",
    "pdf_url": "http://arxiv.org/pdf/2410.13631v2",
    "published": "2024-10-17T15:03:41+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.CO",
      "math.GR",
      "math.MP",
      "math.RT"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13630v7",
    "title": "FEQIS: A free-boundary equilibrium solver for integrated modeling of tokamak plasmas",
    "authors": [
      "E. Fable",
      "G. Tardini",
      "L. Giannone",
      "the ASDEX Upgrade Team"
    ],
    "abstract": "A new axisymmetric equilibrium solver has been written, called FEQIS\n(Flexible EQuIlibrium Solver), which purpose is to be used inside integrated\nmodeling of tokamak plasmas. The FEQIS code solves the Grad-Shafranov equation\nand the \"circuit\" equations for the external coils and passive conducting\nstructures that are toroidally connected. The code has been specifically\nequipped with flexibility in choice of circuit connections, and a stripped-down\nnumerical scheme for the solution of the Grad-Shafranov equation through a\nstructure of multi-level simplifications which can be tested against the\nrequired accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2410.13630v7",
    "published": "2024-10-17T15:01:17+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13629v2",
    "title": "Phenotype structuring in collective cell migration:a tutorial of mathematical models and methods",
    "authors": [
      "Tommaso Lorenzi",
      "Kevin J Painter",
      "Chiara Villa"
    ],
    "abstract": "Populations are heterogeneous, deviating in numerous ways. Phenotypic\ndiversity refers to the range of traits or characteristics across a population,\nwhere for cells this could be the levels of signalling, movement and growth\nactivity, etc. Clearly, the phenotypic distribution -- and how this changes\nover time and space -- could be a major determinant of population-level\ndynamics. For instance, across a cancerous population, variations in movement,\ngrowth, and ability to evade death may determine its growth trajectory and\nresponse to therapy. In this review, we discuss how classical partial\ndifferential equation (PDE) approaches for modelling cellular systems and\ncollective cell migration can be extended to include phenotypic structuring.\nThe resulting non-local models -- which we refer to as phenotype-structured\npartial integro-differential equations (PS-PIDEs) -- form a sophisticated class\nof models with rich dynamics. We set the scene through a brief history of\nstructured population modelling, and then review the extension of several\nclassic movement models -- including the Fisher-KPP and Keller-Segel equations\n-- into a PS-PIDE form. We proceed with a tutorial-style section on derivation,\nanalysis, and simulation techniques. First, we show a method to formally derive\nthese models from underlying agent-based models. Second, we recount travelling\nwaves in PDE models of spatial spread dynamics and concentration phenomena in\nnon-local PDE models of evolutionary dynamics, and combine the two to deduce\nphenotypic structuring across travelling waves in PS-PIDE models. Third, we\ndiscuss numerical methods to simulate PS-PIDEs, illustrating with a simple\nscheme based on the method of lines and noting the finer points of\nconsideration. We conclude with a discussion of future modelling and\nmathematical challenges.",
    "pdf_url": "http://arxiv.org/pdf/2410.13629v2",
    "published": "2024-10-17T15:00:40+00:00",
    "categories": [
      "q-bio.CB",
      "math.AP",
      "35C07, 35R09, 92B05, 92C17, 92D25"
    ],
    "primary_category": "q-bio.CB"
  },
  {
    "id": "http://arxiv.org/abs/2410.13628v2",
    "title": "Ultrafast pulse propagation time-domain dynamics in dispersive one-dimensional photonic waveguides",
    "authors": [
      "Ahmet Oguz Sakin",
      "Ali Murat Demirtas",
      "Hamza Kurt",
      "Mehmet Unlu"
    ],
    "abstract": "Ultrafast pulses, particularly those with durations under 100 femtoseconds,\nare crucial in achieving unprecedented precision and control in light-matter\ninteractions. However, conventional on-chip photonic platforms are not\ninherently designed for ultrafast time-domain operations, posing a significant\nchallenge in achieving essential parameters such as high peak power and high\ntemporal resolution. This challenge is particularly pronounced when propagating\nthrough dispersive integrated waveguides, unlike classical applications where\ndispersion is typically near-zero or linear. In addressing this challenge, we\npresent a design methodology for ultrafast pulse propagation in dispersive\nintegrated waveguides, specifically focused on enhancing the time-domain\ncharacteristics of one-dimensional grating waveguides (1DGWs). The proposed\nmethodology aims to determine the optimal structural parameters for achieving\nmaximum peak power, enhanced temporal resolution, and extended pulse storage\nduration during ultrafast pulse propagation. To validate this approach, we\ndesign and fabricate two specialized 1DGWs on a silicon-on-insulator (SOI)\nplatform. A digital finite impulse response (FIR) model, trained with both\ntransmission and phase measurement data, is employed to obtain ultrafast\ntime-domain characteristics, enabling easy extraction of these results. Our\napproach achieves a 2.78-fold increase in peak power and reduces pulse\nbroadening by 24%, resulting in a smaller sacrifice in temporal resolution.\nThese results can possibly pave the way for advanced light-matter interactions\nwithin dispersive integrated waveguides.",
    "pdf_url": "http://arxiv.org/pdf/2410.13628v2",
    "published": "2024-10-17T15:00:35+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13626v1",
    "title": "Higher Time Derivative Theories From Integrable Models",
    "authors": [
      "Bethan Turner"
    ],
    "abstract": "Higher Time Derivative Theories are generated by considering space-time\nrotated KdV and mKdV systems. These systems are then studied to see if/how\ninstabilities, usually associated with higher time derivative theories,\nmanifest on the classical level by presenting both analytic and numerical\nsolutions. For a linearised version of these space-time rotated systems we\npresent a detailed quantisation of the theory that highlights the known dilemma\non higher time derivative theories, that we have either negative norm states or\nthe Hamiltonian being unbounded from below.",
    "pdf_url": "http://arxiv.org/pdf/2410.13626v1",
    "published": "2024-10-17T15:00:27+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13625v1",
    "title": "lightcurver: A Python Pipeline for Precise Photometry of Multiple-Epoch Wide-Field Images",
    "authors": [
      "Frédéric Dux"
    ],
    "abstract": "lightcurver is a photometric pipeline for time series astronomical imaging\ndata, designed for the semi-automatic extraction of precise light curves from\nsmall, blended targets. Such targets include, but are not limited to, lensed\nquasars, supernovae, or Cepheids in crowded fields. lightcurver leverages\nSTARRED (Michalewicz et al., 2023; Millon et al., 2024) to generate\nstate-of-the-art empirical point spread function (PSF) models for each image.\nIt then determines the relative zeropoints between epochs by combining the\nPSF-photometry fluxes of several stars in the field of view. Subsequently,\nSTARRED is used again to simultaneously model the calibrated pixels of the\nregion of interest across all epochs. This process yields light curves of the\npoint sources and a high-resolution image model of the region of interest,\ncumulating the signal from all epochs. lightcurver aims to be maintainable,\nfast, and incremental in its processing approach. As such, it can enable the\ndaily photometric analysis of a large number of blended targets in the context\nof the upcoming Rubin Observatory Legacy Survey of Space and Time.",
    "pdf_url": "http://arxiv.org/pdf/2410.13625v1",
    "published": "2024-10-17T15:00:20+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13624v1",
    "title": "Optimal MEV Extraction Using Absolute Commitments",
    "authors": [
      "Daji Landis",
      "Nikolaj I. Schwartzbach"
    ],
    "abstract": "We propose a new, more potent attack on decentralized exchanges. This attack\nleverages absolute commitments, which are commitments that can condition on the\nstrategies made by other agents. This attack allows an adversary to charge\nmonopoly prices by committing to undercut those other miners that refuse to\ncharge an even higher fee. This allows the miner to extract the maximum\npossible price from the user, potentially through side channels that evade the\ninefficiencies and fees usually incurred. This is considerably more efficient\nthan the prevailing strategy of `sandwich attacks', wherein the adversary\ninduces and profits from fluctuations in the market price to the detriment of\nusers. The attack we propose can, in principle, be realized by the irrevocable\nand self-executing nature of smart contracts, which are readily available on\nmany major blockchains. Thus, the attack could potentially be used against a\ndecentralized exchange and could drastically reduce the utility of the affected\nexchange.",
    "pdf_url": "http://arxiv.org/pdf/2410.13624v1",
    "published": "2024-10-17T15:00:01+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2411.00786v2",
    "title": "Interpret and Control Dense Retrieval with Sparse Latent Features",
    "authors": [
      "Hao Kang",
      "Tevin Wang",
      "Chenyan Xiong"
    ],
    "abstract": "Dense embeddings deliver strong retrieval performance but often lack\ninterpretability and controllability. This paper introduces a novel approach\nusing sparse autoencoders (SAE) to interpret and control dense embeddings via\nthe learned latent sparse features. Our key contribution is the development of\na retrieval-oriented contrastive loss, which ensures the sparse latent features\nremain effective for retrieval tasks and thus meaningful to interpret.\nExperimental results demonstrate that both the learned latent sparse features\nand their reconstructed embeddings retain nearly the same retrieval accuracy as\nthe original dense vectors, affirming their faithfulness. Our further\nexamination of the sparse latent space reveals interesting features underlying\nthe dense embeddings and we can control the retrieval behaviors via\nmanipulating the latent sparse features, for example, prioritizing documents\nfrom specific perspectives in the retrieval results.",
    "pdf_url": "http://arxiv.org/pdf/2411.00786v2",
    "published": "2024-10-17T14:59:48+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13623v1",
    "title": "Neural Correlates of Augmented Reality Safety Warnings: EEG Analysis of Situational Awareness and Cognitive Performance in Roadway Work Zones",
    "authors": [
      "Fatemeh Banani Ardecani",
      "Amit Kumar",
      "Sepehr Sabeti",
      "Omidreza Shoghli"
    ],
    "abstract": "Despite the research and implementation efforts involving various safety\nstrategies, protocols, and technologies, work zone crashes and fatalities\ncontinue to occur at an alarming rate each year. This study investigates the\nneurophysiological responses to Augmented Reality safety warnings in roadway\nwork zones under varying workload conditions. Using electroencephalogram (EEG)\ntechnology, we objectively assessed situational awareness, attention, and\ncognitive load in simulated low-intensity (LA) and moderate-intensity (MA) work\nactivities. The research analyzed key EEG indicators including beta, gamma,\nalpha, and theta waves, as well as various combined wave ratios. Results\nrevealed that AR warnings effectively triggered neurological responses\nassociated with increased situational awareness and attention across both\nworkload conditions. However, significant differences were observed in the\ntiming and intensity of these responses. In the LA condition, peak responses\noccurred earlier (within 125 ms post-warning) and were more pronounced,\nsuggesting a more robust cognitive response when physical demands were lower.\nConversely, the MA condition showed delayed peak responses (125-250 ms\npost-warning) and more gradual changes, indicating a potential impact of\nincreased physical activity on cognitive processing speed. These findings\nunderscore the importance of considering physical workload when designing\nAR-based safety systems for roadway work zones. The research contributes to the\nunderstanding of how AR can enhance worker safety and provides insights for\ndeveloping more effective, context-aware safety interventions in high-risk work\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13623v1",
    "published": "2024-10-17T14:56:44+00:00",
    "categories": [
      "cs.HC",
      "cs.ET"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13621v4",
    "title": "EP-SAM: Weakly Supervised Histopathology Segmentation via Enhanced Prompt with Segment Anything",
    "authors": [
      "Joonhyeon Song",
      "Seohwan Yun",
      "Seongho Yoon",
      "Joohyeok Kim",
      "Sangmin Lee"
    ],
    "abstract": "This work proposes a novel approach beyond supervised learning for effective\npathological image analysis, addressing the challenge of limited robust labeled\ndata. Pathological diagnosis of diseases like cancer has conventionally relied\non the evaluation of morphological features by physicians and pathologists.\nHowever, recent advancements in compute-aided diagnosis (CAD) systems are\ngaining significant attention as diagnostic support tools. Although the\nadvancement of deep learning has improved CAD significantly, segmentation\nmodels typically require large pixel-level annotated dataset, and such labeling\nis expensive. Existing studies not based on supervised approaches still\nstruggle with limited generalization, and no practical approach has emerged\nyet. To address this issue, we present a weakly supervised semantic\nsegmentation (WSSS) model by combining class activation map and Segment\nAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adopt\nthe SAM-a foundation model that is pretrained on large datasets and operates in\nzero-shot configurations using only coarse prompts. The proposed approach\ntransfer enhanced Attention Dropout Layer's knowledge to SAM, thereby\ngenerating pseudo-labels. To demonstrate the superiority of the proposed\nmethod, experimental studies are conducted on histopathological breast cancer\ndatasets. The proposed method outperformed other WSSS methods across three\ndatasets, demonstrating its efficiency by achieving this with only 12GB of GPU\nmemory during training. Our code is available at :\nhttps://github.com/QI-NemoSong/EP-SAM",
    "pdf_url": "http://arxiv.org/pdf/2410.13621v4",
    "published": "2024-10-17T14:55:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13620v2",
    "title": "Align-ULCNet: Towards Low-Complexity and Robust Acoustic Echo and Noise Reduction",
    "authors": [
      "Shrishti Saha Shetu",
      "Naveen Kumar Desiraju",
      "Wolfgang Mack",
      "Emanuël A. P. Habets"
    ],
    "abstract": "The successful deployment of deep learning-based acoustic echo and noise\nreduction (AENR) methods in consumer devices has spurred interest in developing\nlow-complexity solutions, while emphasizing the need for robust performance in\nreal-life applications. In this work, we propose a hybrid approach to enhance\nthe state-of-the-art (SOTA) ULCNet model by integrating time alignment and\nparallel encoder blocks for the model inputs, resulting in better echo\nreduction and comparable noise reduction performance to existing SOTA methods.\nWe also propose a channel-wise sampling-based feature reorientation method,\nensuring robust performance across many challenging scenarios, while\nmaintaining overall low computational and memory requirements.",
    "pdf_url": "http://arxiv.org/pdf/2410.13620v2",
    "published": "2024-10-17T14:51:45+00:00",
    "categories": [
      "eess.AS",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.18999v1",
    "title": "On generating $k$-factorable graphic sequences with connected (resp.no connected) $k$-factors",
    "authors": [
      "Asish Mukhopadhyay",
      "Daniel John",
      "Lucas Sarweh"
    ],
    "abstract": "In this note, we consider the problem of generating $k$-factorable graphic\nsequences with connected (resp. no connected) $k$-factors.",
    "pdf_url": "http://arxiv.org/pdf/2410.18999v1",
    "published": "2024-10-17T14:51:40+00:00",
    "categories": [
      "cs.DS",
      "math.CO",
      "E.1; F.2; G.4"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13619v1",
    "title": "Co-designing Transmon devices for control with simple pulses",
    "authors": [
      "Nicolas Wittler",
      "Shai Machnes",
      "Frank K. Wilhelm"
    ],
    "abstract": "In the current NISQ era, there is demand for functional quantum devices to\nsolve relevant computational problems, which motivates a utilitarian\nperspective on device design: The goal is to create a device that is able to\nrun a given algorithm with state-of-the-art performance.\n  In this work, we use optimal control tools to derive the gate set required by\na toy algorithm and, in tandem, explore the model space of superconducting\nquantum computer design, from dispersively coupled to stronger interacting\nqubits, to maximize gate fidelity. We employ perfect entangler theory to\nprovide flexibility in the search for a two-qubit gate on a given platform and\nto compare designs with different entangling mechanisms, e.g.,\n$\\texttt{CPHASE}$ and $\\sqrt{\\texttt{iSWAP}}$. To ensure the applicability of\nour investigation, we limit ourselves to \"simple\" (i.e., sparse\nparametrization) pulses and quantify, where results differ from using the full\ncomplexity of piecewise constant controls.",
    "pdf_url": "http://arxiv.org/pdf/2410.13619v1",
    "published": "2024-10-17T14:51:39+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13618v1",
    "title": "LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning",
    "authors": [
      "Yiming Shi",
      "Jiwei Wei",
      "Yujia Wu",
      "Ran Ran",
      "Chengwei Sun",
      "Shiyuan He",
      "Yang Yang"
    ],
    "abstract": "The rapid growth of model scale has necessitated substantial computational\nresources for fine-tuning. Existing approach such as Low-Rank Adaptation (LoRA)\nhas sought to address the problem of handling the large updated parameters in\nfull fine-tuning. However, LoRA utilize random initialization and optimization\nof low-rank matrices to approximate updated weights, which can result in\nsuboptimal convergence and an accuracy gap compared to full fine-tuning. To\naddress these issues, we propose LoLDU, a Parameter-Efficient Fine-Tuning\n(PEFT) approach that significantly reduces trainable parameters by 2600 times\ncompared to regular PEFT methods while maintaining comparable performance.\nLoLDU leverages Lower-Diag-Upper Decomposition (LDU) to initialize low-rank\nmatrices for faster convergence and orthogonality. We focus on optimizing the\ndiagonal matrix for scaling transformations. To the best of our knowledge,\nLoLDU has the fewest parameters among all PEFT approaches. We conducted\nextensive experiments across 4 instruction-following datasets, 6 natural\nlanguage understanding (NLU) datasets, 8 image classification datasets, and\nimage generation datasets with multiple model types (LLaMA2, RoBERTa, ViT, and\nStable Diffusion), providing a comprehensive and detailed analysis. Our\nopen-source code can be accessed at\n\\href{https://github.com/SKDDJ/LoLDU}{https://github.com/SKDDJ/LoLDU}.",
    "pdf_url": "http://arxiv.org/pdf/2410.13618v1",
    "published": "2024-10-17T14:51:17+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13617v2",
    "title": "Weyl group symmetries of the toric variety associated with Weyl chambers",
    "authors": [
      "Tao Gui",
      "Hongsheng Hu",
      "Minhua Liu"
    ],
    "abstract": "For any crystallographic root system, let $W$ be the associated Weyl group,\nand let $\\mathit{WP}$ be the weight polytope (also known as the\n$W$-permutohedron) associated with an arbitrary strongly dominant weight. The\naction of $W$ on $\\mathit{WP}$ induces an action on the toric variety\n$X(\\mathit{WP})$ associated with the normal fan of $\\mathit{WP}$, and hence an\naction on the rational cohomology ring $H^*\\left(X(\\mathit{WP})\\right)$. Let\n$P$ be the corresponding dominant weight polytope, which is a fundamental\nregion of the $W$-action on $\\mathit{WP}$. We give a type uniform algebraic\nproof that the fixed subring $H^*\\left(X(\\mathit{WP})\\right)^{W}$ is isomorphic\nto the cohomology ring $H^*\\left(X(P)\\right)$ of the toric variety $X(P)$\nassociated with the normal fan of $P$. Notably, our proof applies to all finite\n(not necessarily crystallographic) Coxeter groups, answering a question of\nHoriguchi--Masuda--Shareshian--Song about non-crystallographic root systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13617v2",
    "published": "2024-10-17T14:51:16+00:00",
    "categories": [
      "math.AT",
      "Primary 13A50, Secondary 14M25, 17B22, 52B05"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13616v1",
    "title": "Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring",
    "authors": [
      "Kristina Telegraph",
      "Christos Kyrkou"
    ],
    "abstract": "This work presents advancements in multi-class vehicle detection using UAV\ncameras through the development of spatiotemporal object detection models. The\nstudy introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing\n6, 600 annotated sequential frame images captured by UAVs, enabling\ncomprehensive training and evaluation of algorithms for holistic spatiotemporal\nperception. A YOLO-based object detection algorithm is enhanced to incorporate\ntemporal dynamics, resulting in improved performance over single frame models.\nThe integration of attention mechanisms into spatiotemporal models is shown to\nfurther enhance performance. Experimental validation demonstrates significant\nprogress, with the best spatiotemporal model exhibiting a 16.22% improvement\nover single frame models, while it is demonstrated that attention mechanisms\nhold the potential for additional performance gains.",
    "pdf_url": "http://arxiv.org/pdf/2410.13616v1",
    "published": "2024-10-17T14:49:37+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13615v1",
    "title": "Material Fingerprinting: Identifying and Predicting Perceptual Attributes of Material Appearance",
    "authors": [
      "Jiri Filip",
      "Filip Dechterenko",
      "Filipp Schmidt",
      "Jiri Lukavsky",
      "Veronika Vilimovska",
      "Jan Kotera",
      "Roland W. Fleming"
    ],
    "abstract": "The world is abundant with diverse materials, each possessing unique surface\nappearances that play a crucial role in our daily perception and understanding\nof their properties. Despite advancements in technology enabling the capture\nand realistic reproduction of material appearances for visualization and\nquality control, the interoperability of material property information across\nvarious measurement representations and software platforms remains a complex\nchallenge. A key to overcoming this challenge lies in the automatic\nidentification of materials' perceptual features, enabling intuitive\ndifferentiation of properties stored in disparate material data\nrepresentations. We reasoned that for many practical purposes, a compact\nrepresentation of the perceptual appearance is more useful than an exhaustive\nphysical description.This paper introduces a novel approach to material\nidentification by encoding perceptual features obtained from dynamic visual\nstimuli. We conducted a psychophysical experiment to select and validate 16\nparticularly significant perceptual attributes obtained from videos of 347\nmaterials. We then gathered attribute ratings from over twenty participants for\neach material, creating a 'material fingerprint' that encodes the unique\nperceptual properties of each material. Finally, we trained a multi-layer\nperceptron model to predict the relationship between statistical and deep\nlearning image features and their corresponding perceptual properties. We\ndemonstrate the model's performance in material retrieval and filtering\naccording to individual attributes. This model represents a significant step\ntowards simplifying the sharing and understanding of material properties in\ndiverse digital environments regardless of their digital representation,\nenhancing both the accuracy and efficiency of material identification.",
    "pdf_url": "http://arxiv.org/pdf/2410.13615v1",
    "published": "2024-10-17T14:47:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13614v1",
    "title": "Sensitivity, transitivity and chaos in non-autonomous discrete systems",
    "authors": [
      "Hongbo Zeng"
    ],
    "abstract": "In this paper, we study properties of sensitivity, transitivity and chaos for\nnon-autonomous discrete systems(NDS). Firstly, we present some different\nsufficient conditions for NDS to be chaotic. Then, we relate the transitivity\nwith the sensitivity of NDS and give several sufficient conditions for NDS to\nbe sensitive. We obtain that transitivity and dense periodic points imply\nsensitivity, and that transitive system is either sensitive or almost\nequicontinuous. The results improve and extend some existing ones. Besides, we\ngive some examples to show that there is a significant difference between the\ntheory of ADS and the theory of NDS. We get that almost periodic point and\nminimal point do not imply each other and that two definitions of minimal\nsystem are not equivalent for non-autonomous discrete systems. Finally, we\nintroduce and study weakly sensitivity for non-autonomous discrete systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13614v1",
    "published": "2024-10-17T14:47:35+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13613v3",
    "title": "MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes",
    "authors": [
      "Xinjie Zhang",
      "Zhening Liu",
      "Yifan Zhang",
      "Xingtong Ge",
      "Dailan He",
      "Tongda Xu",
      "Yan Wang",
      "Zehong Lin",
      "Shuicheng Yan",
      "Jun Zhang"
    ],
    "abstract": "4D Gaussian Splatting (4DGS) has recently emerged as a promising technique\nfor capturing complex dynamic 3D scenes with high fidelity. It utilizes a 4D\nGaussian representation and a GPU-friendly rasterizer, enabling rapid rendering\nspeeds. Despite its advantages, 4DGS faces significant challenges, notably the\nrequirement of millions of 4D Gaussians, each with extensive associated\nattributes, leading to substantial memory and storage cost. This paper\nintroduces a memory-efficient framework for 4DGS. We streamline the color\nattribute by decomposing it into a per-Gaussian direct color component with\nonly 3 parameters and a shared lightweight alternating current color predictor.\nThis approach eliminates the need for spherical harmonics coefficients, which\ntypically involve up to 144 parameters in classic 4DGS, thereby creating a\nmemory-efficient 4D Gaussian representation. Furthermore, we introduce an\nentropy-constrained Gaussian deformation technique that uses a deformation\nfield to expand the action range of each Gaussian and integrates an\nopacity-based entropy loss to limit the number of Gaussians, thus forcing our\nmodel to use as few Gaussians as possible to fit a dynamic scene well. With\nsimple half-precision storage and zip compression, our framework achieves a\nstorage reduction by approximately 190$\\times$ and 125$\\times$ on the\nTechnicolor and Neural 3D Video datasets, respectively, compared to the\noriginal 4DGS. Meanwhile, it maintains comparable rendering speeds and scene\nrepresentation quality, setting a new standard in the field. Code is available\nat https://github.com/Xinjie-Q/MEGA.",
    "pdf_url": "http://arxiv.org/pdf/2410.13613v3",
    "published": "2024-10-17T14:47:08+00:00",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13612v1",
    "title": "Automatic Navigation and Voice Cloning Technology Deployment on a Humanoid Robot",
    "authors": [
      "Dongkun Han",
      "Boyuan Shao"
    ],
    "abstract": "Mobile robots have shown immense potential and are expected to be widely used\nin the service industry. The importance of automatic navigation and voice\ncloning cannot be overstated as they enable functional robots to provide\nhigh-quality services. The objective of this work is to develop a control\nalgorithm for the automatic navigation of a humanoid mobile robot called Cruzr,\nwhich is a service robot manufactured by Ubtech. Initially, a virtual\nenvironment is constructed in the simulation software Gazebo using Simultaneous\nLocalization And Mapping (SLAM), and global path planning is carried out by\nmeans of local path tracking. The two-wheel differential chassis kinematics\nmodel is employed to ensure autonomous dynamic obstacle avoidance for the robot\nchassis. Furthermore, the mapping and trajectory generation algorithms\ndeveloped in the simulation environment are successfully implemented on the\nreal robot Cruzr. The performance of automatic navigation is compared between\nthe Dynamic Window Approach (DWA) and Model Predictive Control (MPC)\nalgorithms. Additionally, a mobile application for voice cloning is created\nbased on a Hidden Markov Model, and the proposed Chatbot is also tested and\ndeployed on Cruzr.",
    "pdf_url": "http://arxiv.org/pdf/2410.13612v1",
    "published": "2024-10-17T14:46:37+00:00",
    "categories": [
      "cs.RO",
      "00-02"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13611v1",
    "title": "H2OVL-Mississippi Vision Language Models Technical Report",
    "authors": [
      "Shaikat Galib",
      "Shanshan Wang",
      "Guanshuo Xu",
      "Pascal Pfeiffer",
      "Ryan Chesler",
      "Mark Landry",
      "Sri Satish Ambati"
    ],
    "abstract": "Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13611v1",
    "published": "2024-10-17T14:46:34+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13610v3",
    "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling",
    "authors": [
      "Yakun Zhu",
      "Shaohang Wei",
      "Xu Wang",
      "Kui Xue",
      "Xiaofan Zhang",
      "Shaoting Zhang"
    ],
    "abstract": "Integrating tools into Large Language Models (LLMs) has facilitated the\nwidespread application. Despite this, in specialized downstream task contexts,\nreliance solely on tools is insufficient to fully address the complexities of\nthe real world. This particularly restricts the effective deployment of LLMs in\nfields such as medicine. In this paper, we focus on the downstream tasks of\nmedical calculators, which use standardized tests to assess an individual's\nhealth status. We introduce MeNTi, a universal agent architecture for LLMs.\nMeNTi integrates a specialized medical toolkit and employs meta-tool and nested\ncalling mechanisms to enhance LLM tool utilization. Specifically, it achieves\nflexible tool selection and nested tool calling to address practical issues\nfaced in intricate medical scenarios, including calculator selection, slot\nfilling, and unit conversion. To assess the capabilities of LLMs for\nquantitative assessment throughout the clinical process of calculator\nscenarios, we introduce CalcQA. This benchmark requires LLMs to use medical\ncalculators to perform calculations and assess patient health status. CalcQA is\nconstructed by professional physicians and includes 100 case-calculator pairs,\ncomplemented by a toolkit of 281 medical tools. The experimental results\ndemonstrate significant performance improvements with our framework. This\nresearch paves new directions for applying LLMs in demanding scenarios of\nmedicine.",
    "pdf_url": "http://arxiv.org/pdf/2410.13610v3",
    "published": "2024-10-17T14:46:22+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13609v2",
    "title": "All models are wrong, some are useful: Model Selection with Limited Labels",
    "authors": [
      "Patrik Okanovic",
      "Andreas Kirsch",
      "Jannes Kasper",
      "Torsten Hoefler",
      "Andreas Krause",
      "Nezihe Merve Gürel"
    ],
    "abstract": "We introduce MODEL SELECTOR, a framework for label-efficient selection of\npretrained classifiers. Given a pool of unlabeled target data, MODEL SELECTOR\nsamples a small subset of highly informative examples for labeling, in order to\nefficiently identify the best pretrained model for deployment on this target\ndataset. Through extensive experiments, we demonstrate that MODEL SELECTOR\ndrastically reduces the need for labeled data while consistently picking the\nbest or near-best performing model. Across 18 model collections on 16 different\ndatasets, comprising over 1,500 pretrained models, MODEL SELECTOR reduces the\nlabeling cost by up to 94.15% to identify the best model compared to the cost\nof the strongest baseline. Our results further highlight the robustness of\nMODEL SELECTOR in model selection, as it reduces the labeling cost by up to\n72.41% when selecting a near-best model, whose accuracy is only within 1% of\nthe best model.",
    "pdf_url": "http://arxiv.org/pdf/2410.13609v2",
    "published": "2024-10-17T14:45:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13608v1",
    "title": "An Adaptive Finite Difference Method for Total Variation Minimization",
    "authors": [
      "Thomas Jacumin",
      "Andreas Langer"
    ],
    "abstract": "In this paper, we propose an adaptive finite difference scheme in order to\nnumerically solve total variation type problems for image processing tasks. The\nautomatic generation of the grid relies on indicators derived from a local\nestimation of the primal-dual gap error. This process leads in general to a\nnon-uniform grid for which we introduce an adjusted finite difference method.\nFurther we quantify the impact of the grid refinement on the respective\ndiscrete total variation. In particular, it turns out that a finer\ndiscretization may lead to a higher value of the discrete total variation for a\ngiven function. To compute a numerical solution on non-uniform grids we derive\na semi-smooth Newton algorithm in 2D for scalar and vector-valued total\nvariation minimization. We present numerical experiments for image denoising\nand the estimation of motion in image sequences to demonstrate the\napplicability of our adaptive scheme.",
    "pdf_url": "http://arxiv.org/pdf/2410.13608v1",
    "published": "2024-10-17T14:45:25+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13924v2",
    "title": "ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding",
    "authors": [
      "Guangda Ji",
      "Silvan Weder",
      "Francis Engelmann",
      "Marc Pollefeys",
      "Hermann Blum"
    ],
    "abstract": "Neural network performance scales with both model size and data volume, as\nshown in both language and image processing. This requires scaling-friendly\narchitectures and large datasets. While transformers have been adapted for 3D\nvision, a `GPT-moment' remains elusive due to limited training data. We\nintroduce ARKit LabelMaker, a large-scale real-world 3D dataset with dense\nsemantic annotation that is more than three times larger than prior largest\ndataset. Specifically, we extend ARKitScenes with automatically generated dense\n3D labels using an extended LabelMaker pipeline, tailored for large-scale\npre-training. Training on our dataset improves accuracy across architectures,\nachieving state-of-the-art 3D semantic segmentation scores on ScanNet and\nScanNet200, with notable gains on tail classes. Our code is available at\nhttps://labelmaker.org and our dataset at\nhttps://huggingface.co/datasets/labelmaker/arkit_labelmaker.",
    "pdf_url": "http://arxiv.org/pdf/2410.13924v2",
    "published": "2024-10-17T14:44:35+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.14743v1",
    "title": "Efficient Deep Learning Board: Training Feedback Is Not All You Need",
    "authors": [
      "Lina Gong",
      "Qi Gao",
      "Peng Li",
      "Mingqiang Wei",
      "Fei Wu"
    ],
    "abstract": "Current automatic deep learning (i.e., AutoDL) frameworks rely on training\nfeedback from actual runs, which often hinder their ability to provide quick\nand clear performance predictions for selecting suitable DL systems. To address\nthis issue, we propose EfficientDL, an innovative deep learning board designed\nfor automatic performance prediction and component recommendation. EfficientDL\ncan quickly and precisely recommend twenty-seven system components and predict\nthe performance of DL models without requiring any training feedback. The magic\nof no training feedback comes from our proposed comprehensive,\nmulti-dimensional, fine-grained system component dataset, which enables us to\ndevelop a static performance prediction model and comprehensive optimized\ncomponent recommendation algorithm (i.e., {\\alpha}\\b{eta}-BO search), removing\nthe dependency on actually running parameterized models during the traditional\noptimization search process. The simplicity and power of EfficientDL stem from\nits compatibility with most DL models. For example, EfficientDL operates\nseamlessly with mainstream models such as ResNet50, MobileNetV3,\nEfficientNet-B0, MaxViT-T, Swin-B, and DaViT-T, bringing competitive\nperformance improvements. Besides, experimental results on the CIFAR-10 dataset\nreveal that EfficientDL outperforms existing AutoML tools in both accuracy and\nefficiency (approximately 20 times faster along with 1.31% Top-1 accuracy\nimprovement than the cutting-edge methods). Source code, pretrained models, and\ndatasets are available at https://github.com/OpenSELab/EfficientDL.",
    "pdf_url": "http://arxiv.org/pdf/2410.14743v1",
    "published": "2024-10-17T14:43:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13607v2",
    "title": "DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering",
    "authors": [
      "Jiahao Lu",
      "Jiacheng Deng",
      "Ruijie Zhu",
      "Yanzhe Liang",
      "Wenfei Yang",
      "Tianzhu Zhang",
      "Xu Zhou"
    ],
    "abstract": "Dynamic scenes rendering is an intriguing yet challenging problem. Although\ncurrent methods based on NeRF have achieved satisfactory performance, they\nstill can not reach real-time levels. Recently, 3D Gaussian Splatting (3DGS)\nhas garnered researchers attention due to their outstanding rendering quality\nand real-time speed. Therefore, a new paradigm has been proposed: defining a\ncanonical 3D gaussians and deforming it to individual frames in deformable\nfields. However, since the coordinates of canonical 3D gaussians are filled\nwith noise, which can transfer noise into the deformable fields, and there is\ncurrently no method that adequately considers the aggregation of 4D\ninformation. Therefore, we propose Denoised Deformable Network with\nTemporal-Spatial Aggregation for Dynamic Scene Rendering (DN-4DGS).\nSpecifically, a Noise Suppression Strategy is introduced to change the\ndistribution of the coordinates of the canonical 3D gaussians and suppress\nnoise. Additionally, a Decoupled Temporal-Spatial Aggregation Module is\ndesigned to aggregate information from adjacent points and frames. Extensive\nexperiments on various real-world datasets demonstrate that our method achieves\nstate-of-the-art rendering quality under a real-time level.",
    "pdf_url": "http://arxiv.org/pdf/2410.13607v2",
    "published": "2024-10-17T14:43:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13606v2",
    "title": "Arthur packets for metaplectic groups",
    "authors": [
      "Wen-Wei Li"
    ],
    "abstract": "For metaplectic groups over a local field of characteristic zero, we define\nthe Arthur packet attached to any Arthur parameter $\\psi$ as a multi-set of\nunitary genuine irreducible representations, characterized by endoscopic\ncharacter relations. Over number fields, we obtain a multiplicity formula for\nthe genuine discrete $L^2$-automorphic spectrum in terms of global Arthur\nparameters and $\\epsilon$-factors, by leveraging the trace formula for\nmetaplectic groups. This confirms a conjecture of Gan, and extends earlier\nresults of Gan-Ichino on the Shimura-Waldspurger correspondences, whereas their\nworks play a critical role in our proof. Furthermore, all these are shown to be\ncompatible with existing results in rank one (Waldspurger) and two\n(Gan-Ichino).",
    "pdf_url": "http://arxiv.org/pdf/2410.13606v2",
    "published": "2024-10-17T14:43:05+00:00",
    "categories": [
      "math.RT",
      "math.NT",
      "22E50 (Primary) 11F70, 11F72 (Secondary)"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13605v1",
    "title": "Transformer-Based Approaches for Sensor-Based Human Activity Recognition: Opportunities and Challenges",
    "authors": [
      "Clayton Souza Leite",
      "Henry Mauranen",
      "Aziza Zhanabatyrova",
      "Yu Xiao"
    ],
    "abstract": "Transformers have excelled in natural language processing and computer\nvision, paving their way to sensor-based Human Activity Recognition (HAR).\nPrevious studies show that transformers outperform their counterparts\nexclusively when they harness abundant data or employ compute-intensive\noptimization algorithms. However, neither of these scenarios is viable in\nsensor-based HAR due to the scarcity of data in this field and the frequent\nneed to perform training and inference on resource-constrained devices. Our\nextensive investigation into various implementations of transformer-based\nversus non-transformer-based HAR using wearable sensors, encompassing more than\n500 experiments, corroborates these concerns. We observe that transformer-based\nsolutions pose higher computational demands, consistently yield inferior\nperformance, and experience significant performance degradation when quantized\nto accommodate resource-constrained devices. Additionally, transformers\ndemonstrate lower robustness to adversarial attacks, posing a potential threat\nto user trust in HAR.",
    "pdf_url": "http://arxiv.org/pdf/2410.13605v1",
    "published": "2024-10-17T14:39:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13604v1",
    "title": "Large Language Models as Narrative-Driven Recommenders",
    "authors": [
      "Lukas Eberhard",
      "Thorsten Ruprechter",
      "Denis Helic"
    ],
    "abstract": "Narrative-driven recommenders aim to provide personalized suggestions for\nuser requests expressed in free-form text such as \"I want to watch a thriller\nwith a mind-bending story, like Shutter Island.\" Although large language models\n(LLMs) have been shown to excel in processing general natural language queries,\ntheir effectiveness for handling such recommendation requests remains\nrelatively unexplored. To close this gap, we compare the performance of 38\nopen- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in\na movie recommendation setting. For this, we utilize a gold-standard,\ncrowdworker-annotated dataset of posts from reddit's movie suggestion community\nand employ various prompting strategies, including zero-shot, identity, and\nfew-shot prompting. Our findings demonstrate the ability of LLMs to generate\ncontextually relevant movie recommendations, significantly outperforming other\nstate-of-the-art approaches, such as doc2vec. While we find that closed-source\nand large-parameterized models generally perform best, medium-sized open-source\nmodels remain competitive, being only slightly outperformed by their more\ncomputationally expensive counterparts. Furthermore, we observe no significant\ndifferences across prompting strategies for most models, underscoring the\neffectiveness of simple approaches such as zero-shot prompting for\nnarrative-driven recommendations. Overall, this work offers valuable insights\nfor recommender system researchers as well as practitioners aiming to integrate\nLLMs into real-world recommendation tools.",
    "pdf_url": "http://arxiv.org/pdf/2410.13604v1",
    "published": "2024-10-17T14:39:24+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13603v1",
    "title": "Terahertz resonant emission by optically excited infrared-active shear phonons in KY(MoO4)2",
    "authors": [
      "D. Kamenskyi",
      "K. Vasin",
      "L. Prodan",
      "K. Kutko",
      "V. Khrustalyov",
      "S. G. Pavlov",
      "H. -W. Hübers"
    ],
    "abstract": "Generation of the monochromatic electromagnetic radiation in the terahertz\n(THz) range of frequencies for many decades remanes a chellenging task. Here we\ndemonstrate the emission of monochromatic sub-THz radiation by coherent optical\nphonons in dielectric material KY(MoO4)2. The layered crystal structure of\nKY(MoO4)2 leads to infrared-active shear lattice vibrations with energies below\n3.7 meV, which corresponds to the frequencies low than 900 GHz where\nsolid-state compounds based monochromatic radiation sources are rare. Coherent\ninfrared-active optical phonons are excited by broadband THz pulses lasting for\ntens of picoseconds and re-emit narrow-band subTHz radiation pulses with a\ndecay time of 33 picoseconds, which is exceptionally long for the oscillators\nwith frequencies below 1 THz. Such a long coherent emission allows for the\ndetection of more than 50 periods of radiation with frequencies of 568 and 860\nGHz. The remarkably long decay time together with the chemical stability of the\nemployed materials suggest a variety of possible applications in THz laser\ntechnology.",
    "pdf_url": "http://arxiv.org/pdf/2410.13603v1",
    "published": "2024-10-17T14:39:05+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13602v2",
    "title": "Towards Satellite Non-IID Imagery: A Spectral Clustering-Assisted Federated Learning Approach",
    "authors": [
      "Luyao Zou",
      "Yu Min Park",
      "Chu Myaet Thwal",
      "Yan Kyaw Tun",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "abstract": "Low Earth orbit (LEO) satellites are capable of gathering abundant Earth\nobservation data (EOD) to enable different Internet of Things (IoT)\napplications. However, to accomplish an effective EOD processing mechanism, it\nis imperative to investigate: 1) the challenge of processing the observed data\nwithout transmitting those large-size data to the ground because the connection\nbetween the satellites and the ground stations is intermittent, and 2) the\nchallenge of processing the non-independent and identically distributed\n(non-IID) satellite data. In this paper, to cope with those challenges, we\npropose an orbit-based spectral clustering-assisted clustered federated\nself-knowledge distillation (OSC-FSKD) approach for each orbit of an LEO\nsatellite constellation, which retains the advantage of FL that the observed\ndata does not need to be sent to the ground. Specifically, we introduce\nnormalized Laplacian-based spectral clustering (NLSC) into federated learning\n(FL) to create clustered FL in each round to address the challenge resulting\nfrom non-IID data. Particularly, NLSC is adopted to dynamically group clients\ninto several clusters based on cosine similarities calculated by model updates.\nIn addition, self-knowledge distillation is utilized to construct each local\nclient, where the most recent updated local model is used to guide current\nlocal model training. Experiments demonstrate that the observation accuracy\nobtained by the proposed method is separately 1.01x, 2.15x, 1.10x, and 1.03x\nhigher than that of pFedSD, FedProx, FedAU, and FedALA approaches using the\nSAT4 dataset. The proposed method also shows superiority when using other\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2410.13602v2",
    "published": "2024-10-17T14:36:58+00:00",
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13601v1",
    "title": "The Logarithmic Sobolev inequality on non-compact self-shrinkers",
    "authors": [
      "Guofang Wang",
      "Chao Xia",
      "Xiqiang Zhang"
    ],
    "abstract": "In the paper we establish an optimal logarithmic Sobolev inequality for\ncomplete, non-compact, properly embedded self-shrinkers in the Euclidean space,\nwhich generalizes a recent result of Brendle \\cite{Brendle22} for closed\nself-shrinkers. We first provide a proof for the logarithmic Sobolev inequality\nin the Euclidean space by using the Alexandrov-Bakelman-Pucci (ABP) method.\nThen we use this approach to show an optimal logarithmic Sobolev inequality for\ncomplete, non-compact, properly embedded self-shrinkers in the Euclidean space,\nwhich is a sharp version of the result of Ecker in \\cite{Ecker}. The proof is a\nnoncompact modification of Brendle's proof for closed submanifolds and has a\nbig potential to provide new inequalities in noncompact manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2410.13601v1",
    "published": "2024-10-17T14:35:52+00:00",
    "categories": [
      "math.AP",
      "math.DG"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13600v1",
    "title": "A negative answer to a Bahturin-Regev conjecture about regular algebras in positive characteristic",
    "authors": [
      "Lucio Centrone",
      "Plamen Koshlukov",
      "Kauê Pereira"
    ],
    "abstract": "Let $A=A_1\\oplus\\cdots\\oplus A_r$ be a decomposition of the algebra $A$ as a\ndirect sum of vector subspaces. If for every choice of the indices $1\\le i_j\\le\nr$ there exist $a_{i_j}\\in A_{i_j}$ such that the product $a_{i_1}\\cdots\na_{i_n}\\ne 0$, and for every $1\\le i,j\\le r$ there is a constant $\\beta(i,j)\\ne\n0$ with $a_ia_j=\\beta(i,j) a_ja_i$ for $a_i\\in A_i$, $a_j\\in A_j$, the above\ndecomposition is regular. Bahturin and Regev raised the following conjecture:\nsuppose the regular decomposition comes from a group grading on $A$, and form\nthe $r\\times r$ matrix whose $(i,j)$th entry equals $\\beta(i,j)$. Then this\nmatrix is invertible if and only if the decomposition is minimal (that is one\ncannot get a regular decomposition of $A$ by coarsening the decomposition).\nAljadeff and David proved that the conjecture is true in the case the base\nfield is of characteristic 0. We prove that the conjecture does not hold for\nalgebras over fields of positive characteristic, by constructing algebras with\nminimal regular decompositions such that the associated matrix is singular.",
    "pdf_url": "http://arxiv.org/pdf/2410.13600v1",
    "published": "2024-10-17T14:35:04+00:00",
    "categories": [
      "math.RA",
      "16R10, 16R50, 16W55, 16T05"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13599v1",
    "title": "GAN-Based Speech Enhancement for Low SNR Using Latent Feature Conditioning",
    "authors": [
      "Shrishti Saha Shetu",
      "Emanuël A. P. Habets",
      "Andreas Brendel"
    ],
    "abstract": "Enhancing speech quality under adverse SNR conditions remains a significant\nchallenge for discriminative deep neural network (DNN)-based approaches. In\nthis work, we propose DisCoGAN, which is a time-frequency-domain generative\nadversarial network (GAN) conditioned by the latent features of a\ndiscriminative model pre-trained for speech enhancement in low SNR scenarios.\nOur proposed method achieves superior performance compared to state-of-the-arts\ndiscriminative methods and also surpasses end-to-end (E2E) trained GAN models.\nWe also investigate the impact of various configurations for conditioning the\nproposed GAN model with the discriminative model and assess their influence on\nenhancing speech quality",
    "pdf_url": "http://arxiv.org/pdf/2410.13599v1",
    "published": "2024-10-17T14:31:46+00:00",
    "categories": [
      "eess.AS",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13598v1",
    "title": "Let Me Finish My Sentence: Video Temporal Grounding with Holistic Text Understanding",
    "authors": [
      "Jongbhin Woo",
      "Hyeonggon Ryu",
      "Youngjoon Jang",
      "Jae Won Cho",
      "Joon Son Chung"
    ],
    "abstract": "Video Temporal Grounding (VTG) aims to identify visual frames in a video clip\nthat match text queries. Recent studies in VTG employ cross-attention to\ncorrelate visual frames and text queries as individual token sequences.\nHowever, these approaches overlook a crucial aspect of the problem: a holistic\nunderstanding of the query sentence. A model may capture correlations between\nindividual word tokens and arbitrary visual frames while possibly missing out\non the global meaning. To address this, we introduce two primary contributions:\n(1) a visual frame-level gate mechanism that incorporates holistic textual\ninformation, (2) cross-modal alignment loss to learn the fine-grained\ncorrelation between query and relevant frames. As a result, we regularize the\neffect of individual word tokens and suppress irrelevant visual frames. We\ndemonstrate that our method outperforms state-of-the-art approaches in VTG\nbenchmarks, indicating that holistic text understanding guides the model to\nfocus on the semantically important parts within the video.",
    "pdf_url": "http://arxiv.org/pdf/2410.13598v1",
    "published": "2024-10-17T14:31:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13597v2",
    "title": "Text-Guided Multi-Property Molecular Optimization with a Diffusion Language Model",
    "authors": [
      "Yida Xiong",
      "Kun Li",
      "Jiameng Chen",
      "Hongzhi Zhang",
      "Di Lin",
      "Yan Che",
      "Wenbin Hu"
    ],
    "abstract": "Molecular optimization (MO) is a crucial stage in drug discovery in which\ntask-oriented generated molecules are optimized to meet practical industrial\nrequirements. Existing mainstream MO approaches primarily utilize external\nproperty predictors to guide iterative property optimization. However, learning\nall molecular samples in the vast chemical space is unrealistic for predictors.\nAs a result, errors and noise are inevitably introduced during property\nprediction due to the nature of approximation. This leads to discrepancy\naccumulation, generalization reduction and suboptimal molecular candidates. In\nthis paper, we propose a text-guided multi-property molecular optimization\nmethod utilizing transformer-based diffusion language model (TransDLM).\nTransDLM leverages standardized chemical nomenclature as semantic\nrepresentations of molecules and implicitly embeds property requirements into\ntextual descriptions, thereby mitigating error propagation during diffusion\nprocess. By fusing physically and chemically detailed textual semantics with\nspecialized molecular representations, TransDLM effectively integrates diverse\ninformation sources to guide precise optimization, which enhances the model's\nability to balance structural retention and property enhancement. Additionally,\nthe success of a case study further demonstrates TransDLM's ability to solve\npractical problems. Experimentally, our approach surpasses state-of-the-art\nmethods in maintaining molecular structural similarity and enhancing chemical\nproperties on the benchmark dataset. The code is available at:\nhttps://github.com/Cello2195/TransDLM.",
    "pdf_url": "http://arxiv.org/pdf/2410.13597v2",
    "published": "2024-10-17T14:30:27+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13596v3",
    "title": "Quantum nonlinear effects in the number-conserving analogue gravity of Bose-Einstein condensates",
    "authors": [
      "Kunal Pal",
      "Uwe R. Fischer"
    ],
    "abstract": "We consider the quantum dynamics of Bose-Einstein condensates at absolute\nzero, and demonstrate that an analogue gravity model going beyond the standard\nlinearized analogue gravity paradigm \\`a la Unruh must take into account the\nbackreaction of quasiparticle excitations onto the condensate background. This\nrequires that one expands to second order in perturbation amplitude and thus\ntakes the intrinsic nonlinearity of the theory into account. It is shown that,\nas a result, significant modifications of the standard paradigm occur. In\nparticular, to obtain a fully Lorentz-covariant equation in curved spacetime\nfor second-order perturbations, we demonstrate that it is necessary to\nintroduce, to leading order in powers of the formal mean-field expansion\nparameter $N^{-1/2}$ (where $N$ is total particle number), a\nquantum-fluctuation-renormalized spacetime metric which substantially differs\nfrom the Unruh acoustic spacetime metric and, to subleading order $1/N$, two\nemergent vector fields and a mass term. Both the renormalized metric as well as\nthe vector fields and the mass then keep track of the backreaction of the\nquasiparticles onto the condensate up to the order in powers of $N^{-1/2}$\nconsidered. Finally, we apply our formalism to an analogue-cosmological\nFriedmann-Lema\\^{i}tre-Robertson-Walker metric and establish its renormalized\nform due to the quantum many-body backreaction exerted by the excitation cloud.",
    "pdf_url": "http://arxiv.org/pdf/2410.13596v3",
    "published": "2024-10-17T14:29:11+00:00",
    "categories": [
      "gr-qc",
      "cond-mat.quant-gas"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13595v1",
    "title": "Connection between Non-Axisymmetric Structures and Neutral Gas Distribution in Disk Galaxies",
    "authors": [
      "Ze-Zhong Liang",
      "Jing Wang",
      "Hua Gao",
      "Luis C. Ho",
      "E. Athanassoula"
    ],
    "abstract": "Non-axisymmetric structures, such as bars and spiral arms, are known to\nconcentrate molecular gas and star formation in galaxy centers, actively\nbuilding up the pseudo-bulges. However, a direct link between the neutral\n(i.e., molecular and atomic) gas distribution and the exerted torque forces\nover a broader radial range of galactic disks still remains to be explored. In\nthe present work, we investigate this link by carefully evaluating the torque\nforce field using the $3.6\\, \\mathrm{\\mu m}$ images for 17 The H I Nearby\nGalaxy Survey (THINGS) galaxies, and measuring neutral gas distribution on\nresolved atomic and molecular line maps. We find that galaxies with stronger\ntorque forces show a more concentrated neutral gas distribution over the\ndisk-scale, defined as half the isophotal radius at $25.5\\, \\mathrm{mag\\,\narcsec^{-2}}$. The correlation holds regardless of whether the neutral gas\nfraction, or the effective stellar mass surface density is controlled for. In\naddition, $\\mathrm{kpc}$-scale neutral gas over-densities tend to be located\nclose to the local maxima of torque forces. Most of these correlations\ninvolving the torque forces are comparatively stronger than those using the\ntraditional Fourier amplitudes to quantify the non-axisymmetric structures.\nThese results are consistent with the scenario that non-axisymmetric structures\nexert torque forces, and trigger dissipative processes to transport gas inward,\nnot only to build the pseudo-bulges, but also fuel the inner disk growth. In\nthis regard, non-axisymmetric structures inducing stronger torque forces appear\nto be more efficient in these processes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13595v1",
    "published": "2024-10-17T14:29:01+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13594v1",
    "title": "Deep-learning recognition and tracking of individual nanotubes in low-contrast microscopy videos",
    "authors": [
      "Vladimir Pimonov",
      "Said Tahir",
      "Vincent Jourdain"
    ],
    "abstract": "This study addresses the challenge of analyzing the growth kinetics of carbon\nnanotubes using in-situ homodyne polarization microscopy (HPM) by developing an\nautomated deep learning (DL) approach. A Mask-RCNN architecture, enhanced with\na ResNet-50 backbone, was employed to recognize and track individual nanotubes\nin microscopy videos, significantly improving the efficiency and\nreproducibility of kinetic data extraction. The method involves a series of\nvideo processing steps to enhance contrast and used differential treatment\ntechniques to manage low signal and fast kinetics. The DL model demonstrates\nconsistency with manual measurements and increased throughput, laying the\nfoundation for statistical studies of nanotube growth. The approach can be\nadapted for other types of in-situ microscopy studies, emphasizing the\nimportance of automation in high-throughput data acquisition for research on\nindividual nano-objects.",
    "pdf_url": "http://arxiv.org/pdf/2410.13594v1",
    "published": "2024-10-17T14:28:11+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cs.CV",
      "eess.IV",
      "I.5.4"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13593v1",
    "title": "Conjectures for cutting pizza with Coxeter arrangements",
    "authors": [
      "Richard Ehrenborg"
    ],
    "abstract": "We are interested in conjecturing the sign of the pizza quantity P(H,B(a,R))\nfor the irreducible Coxeter arrangements H of type A_n, where n=2,3 bmod 4, and\ntype D_n, where n is odd. Our approach is to express the pizza quantity in\nterms of the pizza quantity of subarrangements known as 2-structures, and we\nobtain the first non-zero term in the multivariate Taylor expansion.",
    "pdf_url": "http://arxiv.org/pdf/2410.13593v1",
    "published": "2024-10-17T14:25:50+00:00",
    "categories": [
      "math.CO",
      "Primary 20F55, 51F15, Secondary 51M20, 51M25"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13592v1",
    "title": "OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope",
    "authors": [
      "Wei Liu",
      "Kerem Delikoyun",
      "Qianyu Chen",
      "Alperen Yildiz",
      "Si Ko Myo",
      "Win Sen Kuan",
      "John Tshon Yit Soong",
      "Matthew Edward Cove",
      "Oliver Hayden",
      "Hweekuan Lee"
    ],
    "abstract": "Off-axis digital holographic microscopy is a high-throughput, label-free\nimaging technology that provides three-dimensional, high-resolution information\nabout samples, particularly useful in large-scale cellular imaging. However,\nthe hologram reconstruction process poses a significant bottleneck for timely\ndata analysis. To address this challenge, we propose a novel reconstruction\napproach that integrates deep learning with the physical principles of off-axis\nholography. We initialized part of the network weights based on the physical\nprinciple and then fine-tuned them via weakly supersized learning. Our off-axis\nhologram network (OAH-Net) retrieves phase and amplitude images with errors\nthat fall within the measurement error range attributable to hardware, and its\nreconstruction speed significantly surpasses the microscope's acquisition rate.\nCrucially, OAH-Net demonstrates remarkable external generalization capabilities\non unseen samples with distinct patterns and can be seamlessly integrated with\nother models for downstream tasks to achieve end-to-end real-time hologram\nanalysis. This capability further expands off-axis holography's applications in\nboth biological and medical studies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13592v1",
    "published": "2024-10-17T14:25:18+00:00",
    "categories": [
      "physics.optics",
      "cs.AI"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13591v1",
    "title": "Galactic calibration and its long-term stability for the Auger Engineering Radio Array",
    "authors": [
      "D. C. dos Santos"
    ],
    "abstract": "The Auger Engineering Radio Array (AERA), part of the Pierre Auger\nObservatory, is a facility designed to detect radio emissions from extensive\nair showers at high energies. Consisting of 153 autonomous radio-detector\nstations spread over 17 km$^2$, it detects radio waves in the frequency range\nof 30 to 80 MHz. Accurate characterization of the detector response is\nessential for correct data interpretation, previously achieved through\nlaboratory measurements of the analog chain and measurements of the antenna's\ndirectional response. In this study, we perform an absolute calibration using\nthe continuously monitored sidereal modulation of the diffuse Galactic radio\nemission. Calibration is done by comparing the average spectra recorded by the\nstations with seven different models of the full radio sky propagated through\nthe system response, including antennas, filters, and amplifiers. The Galactic\ncalibration is in good agreement with the original laboratory calibration. In\naddition, we analyze the time-dependence of the calibration constants over a\nperiod of seven years. No aging effects are observed in AERA stations over a\ntimescale of a decade, which shows that radio detectors could help monitor\npossible aging effects of other detector systems during long-term operations\nand highlight their importance in determining an absolute cosmic-ray energy\nscale.",
    "pdf_url": "http://arxiv.org/pdf/2410.13591v1",
    "published": "2024-10-17T14:24:58+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13590v1",
    "title": "Algebraic curves with a large cyclic automorphism group",
    "authors": [
      "Arianna Dionigi",
      "Massimo Giulietti",
      "Marco Timpanella"
    ],
    "abstract": "The study of algebraic curves $\\cX$ with numerous automorphisms in relation\nto their genus $g(\\cX)$ is a well-established area in Algebraic Geometry. In\n1995, Irokawa and Sasaki \\cite{Sasaki} gave a complete classification of curves\nover $\\mathbb{C}$ with an automorphism of order $N \\geq 2g(\\mathcal{X}) + 1$.\nPrecisely, such curves are either hyperelliptic with $N=2g(\\cX)+2$ with\n$g(\\cX)$ even, or are quotients of the Fermat curve of degree $N$ by a cyclic\ngroup of order $N$. Such a classification does not hold in positive\ncharacteristic $p$, the curve with equation $y^2=x^p-x$ being a well-studied\ncounterexample. This paper successfully classifies curves with a cyclic\nautomorphism group of order $N$ at least $2g(\\mathcal{X}) + 1$ in positive\ncharacteristic $p \\neq 2$, offering the positive characteristic counterpart to\nthe Irokawa-Sasaki result. The possibility of wild ramification in positive\ncharacteristic has presented a few challenges to the investigation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13590v1",
    "published": "2024-10-17T14:24:42+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13589v1",
    "title": "Undecidability of the spectral gap in rotationally symmetric Hamiltonians",
    "authors": [
      "Laura Castilla-Castellano",
      "Angelo Lucia"
    ],
    "abstract": "The problem of determining the existence of a spectral gap in a lattice\nquantum spin system was previously shown to be undecidable for one [J. Bausch\net al., \"Undecidability of the spectral gap in one dimension\", Physical Review\nX 10 (2020)] or more dimensions [T. S. Cubitt et al., \"Undecidability of the\nspectral gap\", Nature 528 (2015)]. In these works, families of nearest-neighbor\ninteractions are constructed whose spectral gap depends on the outcome of a\nTuring machine Halting problem, therefore making it impossible for an algorithm\nto predict its existence. While these models are translationally invariant,\nthey are not invariant under the other symmetries of the lattice, a property\nwhich is commonly found in physically relevant cases, posing the question of\nwhether the spectral gap is still an undecidable problem for Hamiltonians with\nstronger symmetry constraints. We give a positive answer to this question, in\nthe case of models with 4-body (plaquette) interactions on the square lattice\nsatisfying rotation, but not reflection, symmetry: rotational symmetry is not\nenough to make the problem decidable.",
    "pdf_url": "http://arxiv.org/pdf/2410.13589v1",
    "published": "2024-10-17T14:23:58+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13588v1",
    "title": "Cross-Domain Sequential Recommendation via Neural Process",
    "authors": [
      "Haipeng Li",
      "Jiangxia Cao",
      "Yiwen Gao",
      "Yunhuai Liu",
      "Shuchao Pang"
    ],
    "abstract": "Cross-Domain Sequential Recommendation (CDSR) is a hot topic in\nsequence-based user interest modeling, which aims at utilizing a single model\nto predict the next items for different domains. To tackle the CDSR, many\nmethods are focused on domain overlapped users' behaviors fitting, which\nheavily relies on the same user's different-domain item sequences collaborating\nsignals to capture the synergy of cross-domain item-item correlation. Indeed,\nthese overlapped users occupy a small fraction of the entire user set only,\nwhich introduces a strong assumption that the small group of domain overlapped\nusers is enough to represent all domain user behavior characteristics. However,\nintuitively, such a suggestion is biased, and the insufficient learning\nparadigm in non-overlapped users will inevitably limit model performance.\nFurther, it is not trivial to model non-overlapped user behaviors in CDSR\nbecause there are no other domain behaviors to collaborate with, which causes\nthe observed single-domain users' behavior sequences to be hard to contribute\nto cross-domain knowledge mining. Considering such a phenomenon, we raise a\nchallenging and unexplored question: How to unleash the potential of\nnon-overlapped users' behaviors to empower CDSR?",
    "pdf_url": "http://arxiv.org/pdf/2410.13588v1",
    "published": "2024-10-17T14:22:57+00:00",
    "categories": [
      "cs.IR",
      "cs.SI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13587v1",
    "title": "A Sequential Game Framework for Target Tracking",
    "authors": [
      "Daniel Leal",
      "Ngoc Hung Nguyen",
      "Alex Skvortsov",
      "Sanjeev Arulampalam",
      "Mahendra Piraveenan"
    ],
    "abstract": "This paper investigates the application of game-theoretic principles combined\nwith advanced Kalman filtering techniques to enhance maritime target tracking\nsystems. Specifically, the paper presents a two-player, imperfect information,\nnon-cooperative, sequential game framework for optimal decision making for a\ntracker and an evader. The paper also investigates the effectiveness of this\ngame-theoretic decision making framework by comparing it with single-objective\noptimisation methods based on minimising tracking uncertainty. Rather than\nmodelling a zero-sum game between the tracker and the evader, which presupposes\nthe availability of perfect information, in this paper we model both the\ntracker and the evader as playing separate zero-sum games at each time step\nwith an internal (and imperfect) model of the other player. The study defines\nmulti-faceted winning criteria for both tracker and evader, and computes\nwinning percentages for both by simulating their interaction for a range of\nspeed ratios. The results indicate that game theoretic decision making improves\nthe win percentage of the tracker compared to traditional covariance\nminimization procedures in all cases, regardless of the speed ratios and the\nactions of the evader. In the case of the evader, we find that a simpler linear\nescape action is most effective for the evader in most scenarios. Overall, the\nresults indicate that the presented sequential-game based decision making\nframework significantly improves win percentages for a player in scenarios\nwhere that player does not have inherent advantages in terms of starting\nposition, speed ratio, or available time (to track / escape), highlighting that\ngame theoretic decision making is particularly useful in scenarios where\nwinning by using more traditional decision making procedures is highly\nunlikely.",
    "pdf_url": "http://arxiv.org/pdf/2410.13587v1",
    "published": "2024-10-17T14:22:51+00:00",
    "categories": [
      "cs.GT",
      "91A80"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13586v2",
    "title": "Preference Aligned Diffusion Planner for Quadrupedal Locomotion Control",
    "authors": [
      "Xinyi Yuan",
      "Zhiwei Shang",
      "Zifan Wang",
      "Chenkai Wang",
      "Zhao Shan",
      "Meixin Zhu",
      "Chenjia Bai",
      "Xuelong Li",
      "Weiwei Wan",
      "Kensuke Harada"
    ],
    "abstract": "Diffusion models demonstrate superior performance in capturing complex\ndistributions from large-scale datasets, providing a promising solution for\nquadrupedal locomotion control. However, the robustness of the diffusion\nplanner is inherently dependent on the diversity of the pre-collected datasets.\nTo mitigate this issue, we propose a two-stage learning framework to enhance\nthe capability of the diffusion planner under limited dataset\n(reward-agnostic). Through the offline stage, the diffusion planner learns the\njoint distribution of state-action sequences from expert datasets without using\nreward labels. Subsequently, we perform the online interaction in the\nsimulation environment based on the trained offline planner, which\nsignificantly diversified the original behavior and thus improves the\nrobustness. Specifically, we propose a novel weak preference labeling method\nwithout the ground-truth reward or human preferences. The proposed method\nexhibits superior stability and velocity tracking accuracy in pacing, trotting,\nand bounding gait under different speeds and can perform a zero-shot transfer\nto the real Unitree Go1 robots. The project website for this paper is at\nhttps://shangjaven.github.io/preference-aligned-diffusion-legged.",
    "pdf_url": "http://arxiv.org/pdf/2410.13586v2",
    "published": "2024-10-17T14:21:32+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13585v1",
    "title": "Pseudo Dataset Generation for Out-of-Domain Multi-Camera View Recommendation",
    "authors": [
      "Kuan-Ying Lee",
      "Qian Zhou",
      "Klara Nahrstedt"
    ],
    "abstract": "Multi-camera systems are indispensable in movies, TV shows, and other media.\nSelecting the appropriate camera at every timestamp has a decisive impact on\nproduction quality and audience preferences. Learning-based view recommendation\nframeworks can assist professionals in decision-making. However, they often\nstruggle outside of their training domains. The scarcity of labeled\nmulti-camera view recommendation datasets exacerbates the issue. Based on the\ninsight that many videos are edited from the original multi-camera videos, we\npropose transforming regular videos into pseudo-labeled multi-camera view\nrecommendation datasets. Promisingly, by training the model on pseudo-labeled\ndatasets stemming from videos in the target domain, we achieve a 68% relative\nimprovement in the model's accuracy in the target domain and bridge the\naccuracy gap between in-domain and never-before-seen domains.",
    "pdf_url": "http://arxiv.org/pdf/2410.13585v1",
    "published": "2024-10-17T14:21:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13584v3",
    "title": "Holographic Non-Hermitian Lattices and Junctions and their RG Flows",
    "authors": [
      "Daniel Arean",
      "David Garcia-Fariña"
    ],
    "abstract": "We construct and study inhomogeneous non-Hermitian strongly coupled\nholographic field theories. We consider two models: a lattice where in each\nsite there is some inflow/outflow of matter and a\nHermitian/non-Hermitian/Hermitian junction. By tuning a complex external gauge\nfield, we find a non-Hermitian model which can be mapped to a Hermitian one via\na complexified U(1) gauge transformation. On the other hand, in the absence of\nthe gauge field we find non-Hermitian solutions with a purely imaginary\ncurrent. Despite this, all expectation values respect PT symmetry and thus we\nexpect the system to feature unitary time evolution. Nonetheless, we have not\nfound a map bringing these solutions to a Hermitian description. We study the\nRG flows of solutions with imaginary current finding that in the IR they can be\nmapped to a Hermitian conformal fixed point via a complexified U(1)\ntransformation. Remarkably, we also obtain solutions where the null energy\ncondition is violated near the boundary of the dual geometry.",
    "pdf_url": "http://arxiv.org/pdf/2410.13584v3",
    "published": "2024-10-17T14:20:26+00:00",
    "categories": [
      "hep-th",
      "cond-mat.str-el",
      "hep-ph",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13583v3",
    "title": "Competitive equilibria in trading",
    "authors": [
      "Neil A. Chriss"
    ],
    "abstract": "This is the third paper in a series concerning the game-theoretic aspects of\nposition-building while in competition. The first paper set forth foundations\nand laid out the essential goal, which is to minimize implementation costs in\nlight of how other traders are likely to trade. The majority of results in that\npaper center on the two traders in competition and equilibrium results are\npresented. The second paper, introduces computational methods based on Fourier\nSeries which allows the introduction of a broad range of constraints into the\noptimal strategies derived. The current paper returns to the unconstrained case\nand provides a complete solution to finding equilibrium strategies in\ncompetition and handles completely arbitrary situations. As a result we present\na detailed analysis of the value (or not) of trade centralization and we show\nthat firms who naively centralize trades do not generally benefit and\nsometimes, in fact, lose. On the other hand, firms that strategically\ncentralize their trades generally will be able to benefit.",
    "pdf_url": "http://arxiv.org/pdf/2410.13583v3",
    "published": "2024-10-17T14:19:47+00:00",
    "categories": [
      "q-fin.TR"
    ],
    "primary_category": "q-fin.TR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13582v1",
    "title": "Co-Segmentation without any Pixel-level Supervision with Application to Large-Scale Sketch Classification",
    "authors": [
      "Nikolaos-Antonios Ypsilantis",
      "Ondřej Chum"
    ],
    "abstract": "This work proposes a novel method for object co-segmentation, i.e.\npixel-level localization of a common object in a set of images, that uses no\npixel-level supervision for training. Two pre-trained Vision Transformer (ViT)\nmodels are exploited: ImageNet classification-trained ViT, whose features are\nused to estimate rough object localization through intra-class token relevance,\nand a self-supervised DINO-ViT for intra-image token relevance. On recent\nchallenging benchmarks, the method achieves state-of-the-art performance among\nmethods trained with the same level of supervision (image labels) while being\ncompetitive with methods trained with pixel-level supervision (binary masks).\nThe benefits of the proposed co-segmentation method are further demonstrated in\nthe task of large-scale sketch recognition, that is, the classification of\nsketches into a wide range of categories. The limited amount of hand-drawn\nsketch training data is leveraged by exploiting readily available\nimage-level-annotated datasets of natural images containing a large number of\nclasses. To bridge the domain gap, the classifier is trained on a sketch-like\nproxy domain derived from edges detected on natural images. We show that sketch\nrecognition significantly benefits when the classifier is trained on\nsketch-like structures extracted from the co-segmented area rather than from\nthe full image. Code: https://github.com/nikosips/CBNC .",
    "pdf_url": "http://arxiv.org/pdf/2410.13582v1",
    "published": "2024-10-17T14:16:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13581v1",
    "title": "Dynamic Range Compression and Its Effect on Music Genre Classification",
    "authors": [
      "Arlyn Reese Madsen III"
    ],
    "abstract": "This paper investigates the impact of dynamic range compression (DRC) on\nmusic genre classification accuracy. By applying various compression settings\nto the test set of 200 songs, we aim to determine if compression can enhance\nthe classifier's ability to discern distinct musical genres. A support vector\nmachine (SVM) classifier was trained on the original, uncompressed dataset. The\nstudy explored the influence of threshold, ratio, knee width, attack time,\nrelease time, and makeup gain on classification performance. Our findings\nindicate that applying compression to the test set can indeed improve music\ngenre classification accuracy on average by 3.1%. The optimal compression\nsettings varied across experiments, suggesting that the effectiveness of\ncompression depends on the training data of the model. A table of the top\ncompression settings over 1000 train and test splits is provided. In\nconclusion, this research demonstrates that dynamic range compression can serve\nas a valuable preprocessing technique for enhancing music genre classification.\nThe insights gained from this study can inform the development of more accurate\nand robust music recommendation systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13581v1",
    "published": "2024-10-17T14:15:32+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13580v3",
    "title": "EFX Exists for Three Types of Agents",
    "authors": [
      "Vishwa Prakash HV",
      "Pratik Ghosal",
      "Prajakta Nimbhorkar",
      "Nithin Varma"
    ],
    "abstract": "We study the problem of finding an envy-free allocation of indivisible goods\namong agents with additive valuations. We focus on the fairness notion of\nenvy-freeness up to any good (EFX). A central open question in fair division is\nwhether EFX allocations always exist for any number of agents. While EFX has\nbeen established for three agents [CGM24] and for any number of agents with at\nmost two distinct valuations [Mah23], its existence in more general settings\nremains open.\n  In this paper, we make significant progress by proving that EFX allocations\nexist for any number of agents when there are at most three distinct additive\nvaluations. This result simultaneously generalizes both the three-agent case\nand the two-type case, settling an open question in the field (see [Mah23]).",
    "pdf_url": "http://arxiv.org/pdf/2410.13580v3",
    "published": "2024-10-17T14:15:08+00:00",
    "categories": [
      "cs.GT",
      "cs.DS",
      "cs.MA"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13579v1",
    "title": "Towards Better Performance in Incomplete LDL: Addressing Data Imbalance",
    "authors": [
      "Zhiqiang Kou",
      "Haoyuan Xuan",
      "Jing Wang",
      "Yuheng Jia",
      "Xin Geng"
    ],
    "abstract": "Label Distribution Learning (LDL) is a novel machine learning paradigm that\naddresses the problem of label ambiguity and has found widespread applications.\nObtaining complete label distributions in real-world scenarios is challenging,\nwhich has led to the emergence of Incomplete Label Distribution Learning\n(InLDL). However, the existing InLDL methods overlook a crucial aspect of LDL\ndata: the inherent imbalance in label distributions. To address this\nlimitation, we propose \\textbf{Incomplete and Imbalance Label Distribution\nLearning (I\\(^2\\)LDL)}, a framework that simultaneously handles incomplete\nlabels and imbalanced label distributions. Our method decomposes the label\ndistribution matrix into a low-rank component for frequent labels and a sparse\ncomponent for rare labels, effectively capturing the structure of both head and\ntail labels. We optimize the model using the Alternating Direction Method of\nMultipliers (ADMM) and derive generalization error bounds via Rademacher\ncomplexity, providing strong theoretical guarantees. Extensive experiments on\n15 real-world datasets demonstrate the effectiveness and robustness of our\nproposed framework compared to existing InLDL methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13579v1",
    "published": "2024-10-17T14:12:57+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13578v1",
    "title": "A further study on the mass formula for linear codes with prescribed hull dimension",
    "authors": [
      "Shitao Li",
      "Minjia Shi",
      "Yang Li",
      "San Ling"
    ],
    "abstract": "Finding a mass formula for a given class of linear codes is a fundamental\nproblem in combinatorics and coding theory. In this paper, we consider the\naction of the unitary (resp. symplectic) group on the set of all Hermitian\n(resp. symplectic) linear complementary dual (LCD) codes, prove that all\nHermitian (resp. symplectic) LCD codes are on a unique orbit under this action,\nand determine the formula for the size of the orbit. Based on this, we develop\na general technique to obtain a closed mass formula for linear codes with\nprescribed Hermitian (resp. symplectic) hull dimension, and further obtain some\nasymptotic results.",
    "pdf_url": "http://arxiv.org/pdf/2410.13578v1",
    "published": "2024-10-17T14:12:39+00:00",
    "categories": [
      "cs.IT",
      "math.CO",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13577v3",
    "title": "Generalization Bounds via Meta-Learned Model Representations: PAC-Bayes and Sample Compression Hypernetworks",
    "authors": [
      "Benjamin Leblanc",
      "Mathieu Bazinet",
      "Nathaniel D'Amours",
      "Alexandre Drouin",
      "Pascal Germain"
    ],
    "abstract": "Both PAC-Bayesian and Sample Compress learning frameworks are instrumental\nfor deriving tight (non-vacuous) generalization bounds for neural networks. We\nleverage these results in a meta-learning scheme, relying on a hypernetwork\nthat outputs the parameters of a downstream predictor from a dataset input. The\noriginality of our approach lies in the investigated hypernetwork architectures\nthat encode the dataset before decoding the parameters: (1) a PAC-Bayesian\nencoder that expresses a posterior distribution over a latent space, (2) a\nSample Compress encoder that selects a small sample of the dataset input along\nwith a message from a discrete set, and (3) a hybrid between both approaches\nmotivated by a new Sample Compress theorem handling continuous messages. The\nlatter theorem exploits the pivotal information transiting at the\nencoder-decoder junction in order to compute generalization guarantees for each\ndownstream predictor obtained by our meta-learning scheme.",
    "pdf_url": "http://arxiv.org/pdf/2410.13577v3",
    "published": "2024-10-17T14:12:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13576v3",
    "title": "Generating function for quantum depletion of Bose-Einstein condensates",
    "authors": [
      "Simone Rademacher"
    ],
    "abstract": "We consider a Bose gas on the unit torus at zero temperature in the\nGross-Pitaevskii regime, known to perform Bose-Einstein condensation: a\nmacroscopic fraction of the bosons occupy the same quantum state, called\ncondensate. We study the Bose gas' quantum depletion, that is the number of\nbosons outside the condensate, and derive an explicit asymptotic formula of its\ngenerating function. Moreover, we prove an upper bound for the tails of the\nquantum depletion.",
    "pdf_url": "http://arxiv.org/pdf/2410.13576v3",
    "published": "2024-10-17T14:12:02+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13575v1",
    "title": "Third moments of qudit Clifford orbits and 3-designs based on magic orbits",
    "authors": [
      "Huangjun Zhu",
      "Chengsi Mao",
      "Changhao Yi"
    ],
    "abstract": "When the local dimension $d$ is an odd prime, the qudit Clifford group is\nonly a 2-design, but not a 3-design, unlike the qubit counterpart. This\ndistinction and its extension to Clifford orbits have profound implications for\nmany applications in quantum information processing. In this work we\nsystematically delve into general qudit Clifford orbits with a focus on the\nthird moments and potential applications in shadow estimation. First, we\nintroduce the shadow norm to quantify the deviations of Clifford orbits from\n3-designs and clarify its properties. Then, we show that the third normalized\nframe potential and shadow norm are both $\\mathcal{O}(d)$ for any Clifford\norbit, including the orbit of stabilizer states, although the operator norm of\nthe third normalized moment operator may increase exponentially with the number\n$n$ of qudits when $d\\neq 2\\mod 3$. Moreover, we prove that the shadow norm of\nany magic orbit is upper bounded by the constant $15/2$, so a single magic gate\ncan already eliminate the $\\mathcal{O}(d)$ overhead in qudit shadow estimation\nand bridge the gap between qudit systems and qubit systems. Furthermore, we\npropose simple recipes for constructing approximate and exact 3-designs (with\nrespect to three figures of merit simultaneously) from one or a few Clifford\norbits. Notably, accurate approximate 3-designs can be constructed from only\ntwo Clifford orbits. For an infinite family of local dimensions, exact\n3-designs can be constructed from two or four Clifford orbits. In the course of\nstudy, we clarify the key properties of the commutant of the third Clifford\ntensor power and the underlying mathematical structures.",
    "pdf_url": "http://arxiv.org/pdf/2410.13575v1",
    "published": "2024-10-17T14:11:37+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13574v2",
    "title": "Mathematically tractable models of random phylogenetic networks: an overview of some recent developments",
    "authors": [
      "François Bienvenu"
    ],
    "abstract": "Models of random phylogenetic networks have been used since the inception of\nthe field, but the introduction and rigorous study of mathematically tractable\nmodels is a much more recent topic that has gained momentum in the last 5\nyears. This manuscript discusses some recent developments in the field through\na selection of examples. The emphasis is on the techniques rather than on the\nresults themselves, and on probabilistic tools rather than on combinatorial\nones.",
    "pdf_url": "http://arxiv.org/pdf/2410.13574v2",
    "published": "2024-10-17T14:11:11+00:00",
    "categories": [
      "q-bio.PE",
      "math.CO",
      "math.PR",
      "92D15, 05C80 (Primary) 92B05, 92B10 (Secondary)"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13573v1",
    "title": "SPF-EMPC Planner: A real-time multi-robot trajectory planner for complex environments with uncertainties",
    "authors": [
      "Peng Liu",
      "Pengming Zhu",
      "Zhiwen Zeng",
      "Xuekai Qiu",
      "Yu Wang",
      "Huimin Lu"
    ],
    "abstract": "In practical applications, the unpredictable movement of obstacles and the\nimprecise state observation of robots introduce significant uncertainties for\nthe swarm of robots, especially in cluster environments. However, existing\nmethods are difficult to realize safe navigation, considering uncertainties,\ncomplex environmental structures, and robot swarms. This paper introduces an\nextended state model predictive control planner with a safe probability field\nto address the multi-robot navigation problem in complex, dynamic, and\nuncertain environments. Initially, the safe probability field offers an\ninnovative approach to model the uncertainty of external dynamic obstacles,\ncombining it with an unconstrained optimization method to generate safe\ntrajectories for multi-robot online. Subsequently, the extended state model\npredictive controller can accurately track these generated trajectories while\nconsidering the robots' inherent model constraints and state uncertainty, thus\nensuring the practical feasibility of the planned trajectories. Simulation\nexperiments show a success rate four times higher than that of state-of-the-art\nalgorithms. Physical experiments demonstrate the method's ability to operate in\nreal-time, enabling safe navigation for multi-robot in uncertain environments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13573v1",
    "published": "2024-10-17T14:09:51+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13572v2",
    "title": "Qudit Shadow Estimation Based on the Clifford Group and the Power of a Single Magic Gate",
    "authors": [
      "Chengsi Mao",
      "Changhao Yi",
      "Huangjun Zhu"
    ],
    "abstract": "Shadow estimation is a sample-efficient protocol for learning the properties\nof a quantum system using randomized measurements, but the current\nunderstanding of qudit shadow estimation is quite limited compared with the\nqubit setting. Here we clarify the sample complexity of qudit shadow estimation\nbased on the Clifford group, where the local dimension $d$ is an odd prime.\nNotably, we show that the overhead of qudit shadow estimation over the qubit\ncounterpart is only $\\mathcal{O}(d)$, independent of the qudit number $n$,\nalthough the set of stabilizer states may deviate exponentially from a 3-design\nwith respect to the third moment operator. Furthermore, by adding one layer of\nmagic gates, we propose a simple circuit that can significantly boost the\nefficiency. Actually, a single magic gate can already eliminate the\n$\\mathcal{O}(d)$ overhead in qudit shadow estimation and bridge the gap from\nthe qubit setting.",
    "pdf_url": "http://arxiv.org/pdf/2410.13572v2",
    "published": "2024-10-17T14:08:05+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13571v3",
    "title": "DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation",
    "authors": [
      "Guosheng Zhao",
      "Chaojun Ni",
      "Xiaofeng Wang",
      "Zheng Zhu",
      "Xueyang Zhang",
      "Yida Wang",
      "Guan Huang",
      "Xinze Chen",
      "Boyuan Wang",
      "Youyi Zhang",
      "Wenjun Mei",
      "Xingang Wang"
    ],
    "abstract": "Closed-loop simulation is essential for advancing end-to-end autonomous\ndriving systems. Contemporary sensor simulation methods, such as NeRF and 3DGS,\nrely predominantly on conditions closely aligned with training data\ndistributions, which are largely confined to forward-driving scenarios.\nConsequently, these methods face limitations when rendering complex maneuvers\n(e.g., lane change, acceleration, deceleration). Recent advancements in\nautonomous-driving world models have demonstrated the potential to generate\ndiverse driving videos. However, these approaches remain constrained to 2D\nvideo generation, inherently lacking the spatiotemporal coherence required to\ncapture intricacies of dynamic driving environments. In this paper, we\nintroduce DriveDreamer4D, which enhances 4D driving scene representation\nleveraging world model priors. Specifically, we utilize the world model as a\ndata machine to synthesize novel trajectory videos, where structured conditions\nare explicitly leveraged to control the spatial-temporal consistency of traffic\nelements. Besides, the cousin data training strategy is proposed to facilitate\nmerging real and synthetic data for optimizing 4DGS. To our knowledge,\nDriveDreamer4D is the first to utilize video generation models for improving 4D\nreconstruction in driving scenarios. Experimental results reveal that\nDriveDreamer4D significantly enhances generation quality under novel trajectory\nviews, achieving a relative improvement in FID by 32.1%, 46.4%, and 16.3%\ncompared to PVG, S3Gaussian, and Deformable-GS. Moreover, DriveDreamer4D\nmarkedly enhances the spatiotemporal coherence of driving agents, which is\nverified by a comprehensive user study and the relative increases of 22.6%,\n43.5%, and 15.6% in the NTA-IoU metric.",
    "pdf_url": "http://arxiv.org/pdf/2410.13571v3",
    "published": "2024-10-17T14:07:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13570v1",
    "title": "RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging",
    "authors": [
      "Tobias Czempiel",
      "Alfie Roddan",
      "Maria Leiloglou",
      "Zepeng Hu",
      "Kevin O'Neill",
      "Giulio Anichini",
      "Danail Stoyanov",
      "Daniel Elson"
    ],
    "abstract": "This study investigates the reconstruction of hyperspectral signatures from\nRGB data to enhance surgical imaging, utilizing the publicly available\nHeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery\ndataset. Various architectures based on convolutional neural networks (CNNs)\nand transformer models are evaluated using comprehensive metrics. Transformer\nmodels exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by\neffectively integrating spatial information to predict accurate spectral\nprofiles, encompassing both visible and extended spectral ranges. Qualitative\nassessments demonstrate the capability to predict spectral profiles critical\nfor informed surgical decision-making during procedures. Challenges associated\nwith capturing both the visible and extended hyperspectral ranges are\nhighlighted using the MAE, emphasizing the complexities involved. The findings\nopen up the new research direction of hyperspectral reconstruction for surgical\napplications and clinical use cases in real-time surgical environments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13570v1",
    "published": "2024-10-17T14:05:41+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13568v1",
    "title": "Measurement-free, scalable and fault-tolerant universal quantum computing",
    "authors": [
      "Friederike Butt",
      "David F. Locher",
      "Katharina Brechtelsbauer",
      "Hans Peter Büchler",
      "Markus Müller"
    ],
    "abstract": "Reliable execution of large-scale quantum algorithms requires robust\nunderlying operations and this challenge is addressed by quantum error\ncorrection (QEC). Most modern QEC protocols rely on measurements and\nfeed-forward operations, which are experimentally demanding, and often slow and\nprone to high error rates. Additionally, no single error-correcting code\nintrinsically supports the full set of logical operations required for\nuniversal quantum computing, resulting in an increased operational overhead. In\nthis work, we present a complete toolbox for fault-tolerant universal quantum\ncomputing without the need for measurements during algorithm execution by\ncombining the strategies of code switching and concatenation. To this end, we\ndevelop new fault-tolerant, measurement-free protocols to transfer encoded\ninformation between 2D and 3D color codes, which offer complementary and in\ncombination universal sets of robust logical gates. We identify experimentally\nrealistic regimes where these protocols surpass state-of-the-art\nmeasurement-based approaches. Moreover, we extend the scheme to higher-distance\ncodes by concatenating the 2D color code with itself and by integrating code\nswitching for operations that lack a natively fault-tolerant implementation.\nOur measurement-free approach thereby provides a practical and scalable pathway\nfor universal quantum computing on state-of-the-art quantum processors.",
    "pdf_url": "http://arxiv.org/pdf/2410.13568v1",
    "published": "2024-10-17T14:04:14+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13567v3",
    "title": "CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models",
    "authors": [
      "Yujian Zhao",
      "Chengru Wu",
      "Yinong Xu",
      "Xuanzheng Du",
      "Ruiyu Li",
      "Guanglin Niu"
    ],
    "abstract": "Cloth-changing person re-identification (CC-ReID), also known as Long-Term\nPerson Re-Identification (LT-ReID) is a critical and challenging research topic\nin computer vision that has recently garnered significant attention. However,\ndue to the high cost of constructing CC-ReID data, the existing data-driven\nmodels are hard to train efficiently on limited data, causing overfitting\nissue. To address this challenge, we propose a low-cost and efficient pipeline\nfor generating controllable and high-quality synthetic data simulating the\nsurveillance of real scenarios specific to the CC-ReID task. Particularly, we\nconstruct a new self-annotated CC-ReID dataset named Cloth-Changing Unreal\nPerson (CCUP), containing 6,000 IDs, 1,179,976 images, 100 cameras, and 26.5\noutfits per individual. Based on this large-scale dataset, we introduce an\neffective and scalable pretrain-finetune framework for enhancing the\ngeneralization capabilities of the traditional CC-ReID models. The extensive\nexperiments demonstrate that two typical models namely TransReID and FIRe^2,\nwhen integrated into our framework, outperform other state-of-the-art models\nafter pretraining on CCUP and finetuning on the benchmarks such as PRCC,\nVC-Clothes and NKUP. The CCUP is available at:\nhttps://github.com/yjzhao1019/CCUP.",
    "pdf_url": "http://arxiv.org/pdf/2410.13567v3",
    "published": "2024-10-17T14:04:02+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13566v1",
    "title": "360U-Former: HDR Illumination Estimation with Panoramic Adapted Vision Transformers",
    "authors": [
      "Jack Hilliard",
      "Adrian Hilton",
      "Jean-Yves Guillemaut"
    ],
    "abstract": "Recent illumination estimation methods have focused on enhancing the\nresolution and improving the quality and diversity of the generated textures.\nHowever, few have explored tailoring the neural network architecture to the\nEquirectangular Panorama (ERP) format utilised in image-based lighting.\nConsequently, high dynamic range images (HDRI) results usually exhibit a seam\nat the side borders and textures or objects that are warped at the poles. To\naddress this shortcoming we propose a novel architecture, 360U-Former, based on\na U-Net style Vision-Transformer which leverages the work of PanoSWIN, an\nadapted shifted window attention tailored to the ERP format. To the best of our\nknowledge, this is the first purely Vision-Transformer model used in the field\nof illumination estimation. We train 360U-Former as a GAN to generate HDRI from\na limited field of view low dynamic range image (LDRI). We evaluate our method\nusing current illumination estimation evaluation protocols and datasets,\ndemonstrating that our approach outperforms existing and state-of-the-art\nmethods without the artefacts typically associated with the use of the ERP\nformat.",
    "pdf_url": "http://arxiv.org/pdf/2410.13566v1",
    "published": "2024-10-17T14:03:53+00:00",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13923v1",
    "title": "Mathematical modelling to inform outbreak response vaccination",
    "authors": [
      "Manjari Shankar",
      "Anna-Maria Hartner",
      "Callum R. K. Arnold",
      "Ezra Gayawan",
      "Hyolim Kang",
      "Jong-Hoon Kim",
      "Gemma Nedjati Gilani",
      "Anne Cori",
      "Han Fu",
      "Mark Jit",
      "Rudzani Muloiwa",
      "Allison Portnoy",
      "Caroline Trotter",
      "Katy A. M. Gaythorpe"
    ],
    "abstract": "Mathematical models are established tools to assist in outbreak response.\nThey help characterise complex patterns in disease spread, simulate control\noptions to assist public health authorities in decision-making, and longer-term\noperational and financial planning. In the context of vaccine-preventable\ndiseases (VPDs), vaccines are one of the most-cost effective outbreak response\ninterventions, with the potential to avert significant morbidity and mortality\nthrough timely delivery. Models can contribute to the design of vaccine\nresponse by investigating the importance of timeliness, identifying high-risk\nareas, prioritising the use of limited vaccine supply, highlighting\nsurveillance gaps and reporting, and determining the short- and long-term\nbenefits. In this review, we examine how models have been used to inform\nvaccine response for 10 VPDs, and provide additional insights into the\nchallenges of outbreak response modelling, such as data gaps, key\nvaccine-specific considerations, and communication between modellers and\nstakeholders. We illustrate that while models are key to policy-oriented\noutbreak vaccine response, they can only be as good as the surveillance data\nthat inform them.",
    "pdf_url": "http://arxiv.org/pdf/2410.13923v1",
    "published": "2024-10-17T14:01:08+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13564v1",
    "title": "Generative Location Modeling for Spatially Aware Object Insertion",
    "authors": [
      "Jooyeol Yun",
      "Davide Abati",
      "Mohamed Omran",
      "Jaegul Choo",
      "Amirhossein Habibian",
      "Auke Wiggers"
    ],
    "abstract": "Generative models have become a powerful tool for image editing tasks,\nincluding object insertion. However, these methods often lack spatial\nawareness, generating objects with unrealistic locations and scales, or\nunintentionally altering the scene background. A key challenge lies in\nmaintaining visual coherence, which requires both a geometrically suitable\nobject location and a high-quality image edit. In this paper, we focus on the\nformer, creating a location model dedicated to identifying realistic object\nlocations. Specifically, we train an autoregressive model that generates\nbounding box coordinates, conditioned on the background image and the desired\nobject class. This formulation allows to effectively handle sparse placement\nannotations and to incorporate implausible locations into a preference dataset\nby performing direct preference optimization. Our extensive experiments\ndemonstrate that our generative location model, when paired with an inpainting\nmethod, substantially outperforms state-of-the-art instruction-tuned models and\nlocation modeling baselines in object insertion tasks, delivering accurate and\nvisually coherent results.",
    "pdf_url": "http://arxiv.org/pdf/2410.13564v1",
    "published": "2024-10-17T14:00:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13563v3",
    "title": "Ornstein-Uhlenbeck Adaptation as a Mechanism for Learning in Brains and Machines",
    "authors": [
      "Jesus Garcia Fernandez",
      "Nasir Ahmad",
      "Marcel van Gerven"
    ],
    "abstract": "Learning is a fundamental property of intelligent systems, observed across\nbiological organisms and engineered systems. While modern intelligent systems\ntypically rely on gradient descent for learning, the need for exact gradients\nand complex information flow makes its implementation in biological and\nneuromorphic systems challenging. This has motivated the exploration of\nalternative learning mechanisms that can operate locally and do not rely on\nexact gradients. In this work, we introduce a novel approach that leverages\nnoise in the parameters of the system and global reinforcement signals. Using\nan Ornstein-Uhlenbeck process with adaptive dynamics, our method balances\nexploration and exploitation during learning, driven by deviations from error\npredictions, akin to reward prediction error. Operating in continuous time,\nOrstein-Uhlenbeck adaptation (OUA) is proposed as a general mechanism for\nlearning dynamic, time-evolving environments. We validate our approach across\ndiverse tasks, including supervised learning and reinforcement learning in\nfeedforward and recurrent systems. Additionally, we demonstrate that it can\nperform meta-learning, adjusting hyper-parameters autonomously. Our results\nindicate that OUA provides a viable alternative to traditional gradient-based\nmethods, with potential applications in neuromorphic computing. It also hints\nat a possible mechanism for noise-driven learning in the brain, where\nstochastic neurotransmitter release may guide synaptic adjustments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13563v3",
    "published": "2024-10-17T14:00:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13562v1",
    "title": "Enhancing Fact Retrieval in PLMs through Truthfulness",
    "authors": [
      "Paul Youssef",
      "Jörg Schlötterer",
      "Christin Seifert"
    ],
    "abstract": "Pre-trained Language Models (PLMs) encode various facts about the world at\ntheir pre-training phase as they are trained to predict the next or missing\nword in a sentence. There has a been an interest in quantifying and improving\nthe amount of facts that can be extracted from PLMs, as they have been\nenvisioned to act as soft knowledge bases, which can be queried in natural\nlanguage. Different approaches exist to enhance fact retrieval from PLM. Recent\nwork shows that the hidden states of PLMs can be leveraged to determine the\ntruthfulness of the PLMs' inputs. Leveraging this finding to improve factual\nknowledge retrieval remains unexplored. In this work, we investigate the use of\na helper model to improve fact retrieval. The helper model assesses the\ntruthfulness of an input based on the corresponding hidden states\nrepresentations from the PLMs. We evaluate this approach on several masked PLMs\nand show that it enhances fact retrieval by up to 33\\%. Our findings highlight\nthe potential of hidden states representations from PLMs in improving their\nfactual knowledge retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2410.13562v1",
    "published": "2024-10-17T14:00:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13561v1",
    "title": "Pushchino multibeam pulsar search -- V. The bright FRB 20190203 detected at 111 MHz",
    "authors": [
      "S. A. Tyul'bashev",
      "V. A. Samodurov",
      "A. S. Pozanenko",
      "E. A. Brylyakova",
      "S. A. Grebenev",
      "I. V. Chelovekov",
      "P. Yu. Minaev",
      "E. A. Isaev",
      "M. V. Barkov"
    ],
    "abstract": "We report the discovery of a bright pulse having a dispersion measure (DM)\nequal to 134.4 \\pm 2 pc cm^{-3}, a peak flux density (S_p) equal to 20 \\pm 4 Jy\nand a half-width (W_e) equal to 211 \\pm 6 ms. The excessive DM of the pulse,\nafter taking into account the Milky Way contribution, is 114 pc cm^{-3} that\nindicates its extragalactic origin. Such value of DM corresponds to the\nluminosity distance 713 Mpc. The above parameters make the pulse to be a\nreliable candidate to the fast radio burst (FRB) event, and then it is the\nsecond FRB detected at such a large \\lambda \\sim 2.7 m wavelength and the first\none among non-repeating FRBs. The normalized luminosity L_\\nu of the event,\nwhich we have designated as FRB 20190203, estimated under assumption that the\nwhole excessive DM is determined by the intergalactic environment toward the\nhost galaxy, is equal to \\simeq 10^{34} erg s^{-1} Hz{-1}. In addition to the\nstudy of radio data we analyzed data from the quasi-simultaneous observations\nof the sky in the high energy (\\ge 80 keV) band by the omnidirectional detector\nSPI/ACS aboard the INTEGRAL orbital observatory (in order to look for a\npossible gamma-ray counterpart of FRB 20190203). We did not detect any\ntransient events exceeding the background at a statistically significant level.\nIn the INTEGRAL archive, the FRB 20190203 localization region has been observed\nmany times with a total exposure of \\sim 73.2 days. We have analyzed the data\nbut were unable to find any reliable short gamma-ray bursts from the FRB\n20190203 position. Finally we note that the observed properties of FRB 20190203\ncan be reproduced well in the framework of a maser synchrotron model operating\nin the far reverse shock (at a distance of \\sim 10^{15} cm) of a magnetar.\nHowever, triggering the burst requires a high conversion efficiency (at the\nlevel of 1%) of the shock wave energy into the radio emission.",
    "pdf_url": "http://arxiv.org/pdf/2410.13561v1",
    "published": "2024-10-17T13:59:06+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13559v2",
    "title": "On estimating the trace of quantum state powers",
    "authors": [
      "Yupan Liu",
      "Qisheng Wang"
    ],
    "abstract": "We investigate the computational complexity of estimating the trace of\nquantum state powers $\\text{tr}(\\rho^q)$ for an $n$-qubit mixed quantum state\n$\\rho$, given its state-preparation circuit of size $\\text{poly}(n)$. This\nquantity is closely related to and often interchangeable with the Tsallis\nentropy $\\text{S}_q(\\rho) = \\frac{1-\\text{tr}(\\rho^q)}{q-1}$, where $q = 1$\ncorresponds to the von Neumann entropy. For any non-integer $q \\geq 1 +\n\\Omega(1)$, we provide a quantum estimator for $\\text{S}_q(\\rho)$ with time\ncomplexity $\\text{poly}(n)$, exponentially improving the prior best results of\n$\\exp(n)$ due to Acharya, Issa, Shende, and Wagner (ISIT 2019), Wang, Guan,\nLiu, Zhang, and Ying (TIT 2024), and Wang, Zhang, and Li (TIT 2024), and Wang\nand Zhang (ESA 2024). Our speedup is achieved by introducing efficiently\ncomputable uniform approximations of positive power functions into quantum\nsingular value transformation.\n  Our quantum algorithm reveals a sharp phase transition between the case of\n$q=1$ and constant $q>1$ in the computational complexity of the Quantum\n$q$-Tsallis Entropy Difference Problem (TsallisQED$_q$), particularly deciding\nwhether the difference $\\text{S}_q(\\rho_0) - \\text{S}_q(\\rho_1)$ is at least\n$0.001$ or at most $-0.001$:\n  - For any $1+\\Omega(1) \\leq q \\leq 2$, TsallisQED$_q$ is\n$\\mathsf{BQP}$-complete, which implies that Purity Estimation is also\n$\\mathsf{BQP}$-complete.\n  - For any $1 \\leq q \\leq 1 + \\frac{1}{n-1}$, TsallisQED$_q$ is\n$\\mathsf{QSZK}$-hard, leading to hardness of approximating the von Neumann\nentropy because $\\text{S}_q(\\rho) \\leq \\text{S}(\\rho)$, as long as\n$\\mathsf{BQP} \\subsetneq \\mathsf{QSZK}$.\n  The hardness results are derived from reductions based on new inequalities\nfor the quantum $q$-Jensen-(Shannon-)Tsallis divergence with $1\\leq q \\leq 2$,\nwhich are of independent interest.",
    "pdf_url": "http://arxiv.org/pdf/2410.13559v2",
    "published": "2024-10-17T13:57:13+00:00",
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.DS"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13558v1",
    "title": "An explicit formula for zonal polynomials",
    "authors": [
      "Haoming Wang"
    ],
    "abstract": "The derivation of zonal polynomials involves evaluating the integral \\[\n\\exp\\left( - \\frac{1}{2} \\operatorname{tr} D_{\\beta} Q D_{l} Q \\right) \\] with\nrespect to orthogonal matrices \\(Q\\), where \\(D_{\\beta}\\) and \\(D_{l}\\) are\ndiagonal matrices. The integral is expressed through a polynomial expansion in\nterms of the traces of these matrices, leading to the identification of zonal\npolynomials as symmetric, homogeneous functions of the variables \\(l_1, l_2,\n\\ldots, l_n\\). The coefficients of these polynomials are derived systematically\nfrom the structure of the integrals, revealing relationships between them and\nillustrating the significance of symmetry in their formulation. Furthermore,\nproperties such as the uniqueness up to normalization are established,\nreinforcing the foundational role of zonal polynomials in statistical and\nmathematical applications involving orthogonal matrices.",
    "pdf_url": "http://arxiv.org/pdf/2410.13558v1",
    "published": "2024-10-17T13:57:06+00:00",
    "categories": [
      "math.RT",
      "math.CO",
      "05E05, 15B10, 32A50"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13557v1",
    "title": "Nijenhuis operators on Banach homogeneous spaces",
    "authors": [
      "Tomasz Goliński",
      "Gabriel Larotonda",
      "Alice Barbora Tumpach"
    ],
    "abstract": "For a Banach--Lie group $G$ and an embedded Lie subgroup $K$ we consider the\nhomogeneous Banach manifold $\\mathcal M=G/K$. In this context we establish the\nmost general conditions for a bounded operator $N$ acting on $Lie(G)$ to define\na homogeneous vector bundle map $\\mathcal N:T\\mathcal M\\to T\\mathcal M$. In\nparticular our considerations extend all previous settings on the matter and\nare well-suited for the case where $Lie(K)$ is not complemented in $Lie(G)$. We\nshow that the vanishing of the Nijenhuis torsion for a homogeneous vector\nbundle map $\\mathcal N:T\\mathcal M\\to T\\mathcal M$ (defined by an admissible\nbounded operator $N$ on $Lie(G)$) is equivalent to the Nijenhuis torsion of $N$\nhaving values in $Lie(K)$. As an application, we consider the question of\nintegrability of an almost complex structure $\\mathcal J$ on $\\mathcal M$\ninduced by an admissible bounded operator $J$, and we give a simple\ncharacterization of integrability in terms of certain subspaces of the\ncomplexification of $Lie(G)$ (which are not eigenspaces of the complex\nextension of $J$).",
    "pdf_url": "http://arxiv.org/pdf/2410.13557v1",
    "published": "2024-10-17T13:55:52+00:00",
    "categories": [
      "math.DG",
      "math.FA",
      "58B12, 53C30, 32Q60, 58B20, 53C15"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13556v1",
    "title": "Co-creation and evaluation of an app to support reminiscence therapy interventions for older people with dementia",
    "authors": [
      "Iván De-Rosende-Celeiro",
      "Virginia Francisco-Gilmartín",
      "Susana Bautista-Blasco",
      "Adriana Ávila-Álvarez"
    ],
    "abstract": "Objective: The objectives encompassed (1) the creation of Recuerdame, a\ndigital app specifically designed for occupational therapists, aiming to\nsupport these professionals in the processes of planning, organizing,\ndeveloping, and documenting reminiscence therapies for older people with\ndementia, and (2) the evaluation of the designed prototype through a\nparticipatory and user-centered design approach, exploring the perceptions of\nend-users. Methods: This exploratory research used a mixed-methods design. The\napp was developed in two phases. In the first phase, the research team\nidentified the requirements and designed a prototype. In the second phase,\nexperienced occupational therapists evaluated the prototype. Results: The\nresearch team determined the app's required functionalities, grouped into eight\nmajor themes: register related persons and caregivers; record the patient's\nlife story memories; prepare a reminiscence therapy session; conduct a session;\nend a session; assess the patient; automatically generate a life story; other\nrequirements. The first phase ended with the development of a prototype. In the\nsecond phase, eight occupational therapists performed a series of tasks using\nall the application's functionalities. Most of these tasks were very easy\n(Single Ease Question). The level of usability was considered excellent (System\nUsability Scale). Participants believed that the app would save practitioners\ntime, enrich therapy sessions and improve their effectiveness. The qualitative\nresults were summarized in two broad themes: (a) acceptability of the app; and\n(b) areas for improvement.ConclusionsParticipating occupational therapists\ngenerally agreed that the co-designed app appears to be a versatile tool that\nempowers these professionals to manage reminiscence interventions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13556v1",
    "published": "2024-10-17T13:55:32+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13555v1",
    "title": "On a product of three theta functions and the number of representations of integers as mixed ternary sums involving squares, triangular, pentagonal and octagonal numbers",
    "authors": [
      "N. A. S. Bulkhali",
      "G. Kavya Keerthana",
      "Ranganatha Dasappa"
    ],
    "abstract": "In this paper, we derive a general formula to express the product of three\ntheta functions as a linear combination of other products of three theta\nfunctions. Moreover, we use the main formula to deduce a general formula for\nthe product of two theta functions. Furthermore, as applications, we extract\nseveral theorems in the theory of representation of integers as mixed ternary\nsums involving squares, triangular numbers, generalized pentagonal numbers and\ngeneralized octagonal numbers",
    "pdf_url": "http://arxiv.org/pdf/2410.13555v1",
    "published": "2024-10-17T13:54:50+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13554v1",
    "title": "Residue polytopes",
    "authors": [
      "Omid Amini",
      "Eduardo Esteves",
      "Eduardo Garcez"
    ],
    "abstract": "A level graph is the data of a pair $(G,\\pi)$ consisting of a finite graph\n$G$ and an ordered partition $\\pi$ on the set of vertices of $G$. To each level\ngraph on $n$ vertices we associate a polytope in $\\mathbb R^n$ called its\nresidue polytope. We show that residue polytopes are compatible with each other\nin the sense that if $\\pi'$ is a coarsening of $\\pi$, then the polytope\nassociated to $(G,\\pi)$ is a face of the one associated to $(G,\\pi')$.\nMoreover, they form all the faces of the residue polytope of $G$, defined as\nthe polytope associated to the level graph with the trivial ordered partition.\nThe results are used in a companion work to describe limits of spaces of\nAbelian differentials on families of Riemann surfaces approaching a stable\nRiemann surface on the boundary of the moduli space.",
    "pdf_url": "http://arxiv.org/pdf/2410.13554v1",
    "published": "2024-10-17T13:53:08+00:00",
    "categories": [
      "math.CO",
      "math.AG"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13553v2",
    "title": "SynapticRAG: Enhancing Temporal Memory Retrieval in Large Language Models through Synaptic Mechanisms",
    "authors": [
      "Yuki Hou",
      "Haruki Tamoto",
      "Qinghua Zhao",
      "Homei Miyashita"
    ],
    "abstract": "Existing retrieval methods in Large Language Models show degradation in\naccuracy when handling temporally distributed conversations, primarily due to\ntheir reliance on simple similarity-based retrieval. Unlike existing memory\nretrieval methods that rely solely on semantic similarity, we propose\nSynapticRAG, which uniquely combines temporal association triggers with\nbiologically-inspired synaptic propagation mechanisms. Our approach uses\ntemporal association triggers and synaptic-like stimulus propagation to\nidentify relevant dialogue histories. A dynamic leaky integrate-and-fire\nmechanism then selects the most contextually appropriate memories. Experiments\non four datasets of English, Chinese and Japanese show that compared to\nstate-of-the-art memory retrieval methods, SynapticRAG achieves consistent\nimprovements across multiple metrics up to 14.66% points. This work bridges the\ngap between cognitive science and language model development, providing a new\nframework for memory management in conversational systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13553v2",
    "published": "2024-10-17T13:51:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13552v1",
    "title": "Hairy black holes and other compact objects in theories of gravity",
    "authors": [
      "Romain Gervalle"
    ],
    "abstract": "In the realm of spacetimes governed by Einstein's general relativity and\ncontaining only Maxwell's electromagnetic field, stationary black holes are\nfully characterized by their mass, electric or magnetic charge, and angular\nmomentum -- a property encapsulated in a version of the no-hair theorem.\nHowever, the validity of this theorem is contingent on certain assumptions, and\nwhen these are relaxed, new solutions describing hairy black holes arise. To\ndate, astronomical observations have not provided concrete evidence of any type\nof black hole hair. Nevertheless, the development of increasingly precise\ngravitational wave detectors has sparked renewed interest in hairy black holes.\nIn this thesis, we delve into two approaches to circumvent the no-hair theorem.\nThe first option consists in describing the spacetime metric by an alternative\ntheory of gravitation. We investigate the dynamical stability of hairy black\nholes in a vacuum spacetime described by the theory of massive bigravity. We\nshow that hairy black holes in bigravity can describe both stellar black holes\nand supermassive black holes. The second approach is to keep Einstein's\nequations but to consider a different material content than Maxwell's\nelectromagnetic field. For this we choose the fields of the electroweak theory.\nIn the absence of gravitation, this theory describes magnetic monopoles with\ninfinite mass. General relativity allows for their regularization by concealing\ntheir Coulombian singularity within an event horizon. After providing a\ndetailed analysis of the internal structure of monopoles in flat space, we\ninvestigate how their properties generalize to the black hole case. Lastly, we\nstudy a particular example of soliton -- boson stars -- arising when a complex\nscalar field is coupled to general relativity. We construct chains of boson\nstars by solving the elliptic field equations using the finite element method.",
    "pdf_url": "http://arxiv.org/pdf/2410.13552v1",
    "published": "2024-10-17T13:49:09+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13551v2",
    "title": "Wetting Transition on Trees I: Percolation With Clustering",
    "authors": [
      "Aser Cortines",
      "Itamar Harel",
      "Dmitry Ioffe",
      "Oren Louidor"
    ],
    "abstract": "A new ``Percolation with Clustering'' (PWC) model is introduced, where (the\nprobabilities of) site percolation configurations on the leaf set of a binary\ntree are rewarded exponentially according to a generic function, which measures\nthe degree of clustering in the configuration. Conditions on such ``clustering\nfunction'' are given for the existence of a limiting free energy and a wetting\ntransition, namely the existence of a non-trivial percolation parameter\nthreshold above and only above which the set of ``dry'' (open) sites have an\nasymptotic density. Several examples of clustering functions are given and\nstudied using the general theory. The results here will be used in a sequel\npaper to study the wetting transition for the discrete Gaussian free field on\nthe tree subject to a hard wall constraint.",
    "pdf_url": "http://arxiv.org/pdf/2410.13551v2",
    "published": "2024-10-17T13:49:07+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP",
      "82B41, 82B26, 82B05"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13550v1",
    "title": "Graphendofullerene: a novel molecular two-dimensional ferromagnet",
    "authors": [
      "Diego López-Alcalá",
      "Ziqi Hu",
      "José J. Baldoví"
    ],
    "abstract": "Carbon chemistry has attracted a lot of attention by chemists, physicists and\nmaterial scientists in the last decades. The recent discovery of graphullerene\nprovides a promising platform for many applications due to its exceptional\nelectronic properties and the possibility to host molecules or clusters inside\nthe fullerene units. Herein, we introduce graphendofullerene, a novel\nmolecular-based two-dimensional (2D) magnetic material formed by trimetallic\nnitrides clusters encapsulated on graphullerene. Through first-principles\ncalculations, we demonstrate the successful incorporation of the molecules into\nthe 2D network formed by C$_{80}$ fullerenes, which leads to a robust\nlong-range ferromagnetic order with a Curie temperature (Tc) of 38 K.\nAdditionally, we achieve a 45% increase in Tc by strain engineering. These\nfindings open the way for a new family of molecular 2D magnets based on\ngraphendofullerene for advanced technologies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13550v1",
    "published": "2024-10-17T13:44:30+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13549v2",
    "title": "Quasi-quantum states and the quasi-quantum PCP theorem",
    "authors": [
      "Itai Arad",
      "Miklos Santha"
    ],
    "abstract": "We introduce $k$-local quasi-quantum states: a superset of the regular\nquantum states, defined by relaxing the positivity constraint. We show that a\n$k$-local quasi-quantum state on $n$ qubits can be 1-1 mapped to a distribution\nof assignments over $n$ variables with an alphabet of size $4$, which is\nsubject to non-linear constraints over its $k$-local marginals. Therefore,\nsolving the $k$-local Hamiltonian over the quasi-quantum states is equivalent\nto optimizing a distribution of assignment over a classical $k$-local CSP. We\nshow that this optimization problem is essentially classical by proving it is\nNP-complete. Crucially, just as ordinary quantum states, these distributions\nlack a simple tensor-product structure and are therefore not determined\nstraightforwardly by their local marginals. Consequently, our classical\noptimization problem shares some unique aspects of Hamiltonian complexity: it\nlacks an easy search-to-decision reduction, and it is not clear that its 1D\nversion can be solved with dynamical programming (i.e., it could remain\nNP-hard).\n  Our main result is a PCP theorem for the $k$-local Hamiltonian over the\nquasi-quantum states in the form of a hardness-of-approximation result. The\nproof suggests the existence of a subtle promise-gap amplification procedure in\na model that shares many similarities with the quantum local Hamiltonian\nproblem, thereby providing insights on the quantum PCP conjecture.",
    "pdf_url": "http://arxiv.org/pdf/2410.13549v2",
    "published": "2024-10-17T13:43:18+00:00",
    "categories": [
      "quant-ph",
      "cs.CC"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13548v2",
    "title": "Adaptive and oblivious statistical adversaries are equivalent",
    "authors": [
      "Guy Blanc",
      "Gregory Valiant"
    ],
    "abstract": "We resolve a fundamental question about the ability to perform a statistical\ntask, such as learning, when an adversary corrupts the sample. Such adversaries\nare specified by the types of corruption they can make and their level of\nknowledge about the sample. The latter distinguishes between sample-adaptive\nadversaries which know the contents of the sample when choosing the corruption,\nand sample-oblivious adversaries, which do not. We prove that for all types of\ncorruptions, sample-adaptive and sample-oblivious adversaries are\n\\emph{equivalent} up to polynomial factors in the sample size. This resolves\nthe main open question introduced by [BLMT22] and further explored in [CHL+23].\n  Specifically, consider any algorithm $A$ that solves a statistical task even\nwhen a sample-oblivious adversary corrupts its input. We show that there is an\nalgorithm $A'$ that solves the same task when the corresponding sample-adaptive\nadversary corrupts its input. The construction of $A'$ is simple and maintains\nthe computational efficiency of $A$: It requests a polynomially larger sample\nthan $A$ uses and then runs $A$ on a uniformly random subsample.",
    "pdf_url": "http://arxiv.org/pdf/2410.13548v2",
    "published": "2024-10-17T13:42:56+00:00",
    "categories": [
      "cs.LG",
      "cs.CC",
      "cs.DS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13547v2",
    "title": "Topological quantum computing",
    "authors": [
      "Fabian Hassler"
    ],
    "abstract": "These lecture notes offer a pedagogical yet concise introduction to\ntopological quantum computing. The material focuses on topological\nsuperconductors and Majorana qubits. It concludes with a discussion of more\ngeneral braiding phenomena. In particular, the notes delve into the non-Abelian\nbraiding statistics of Ising and Fibonacci anyons. Although not comprehensive,\nthis set provides a solid entry point for students and researchers interested\nin the field.",
    "pdf_url": "http://arxiv.org/pdf/2410.13547v2",
    "published": "2024-10-17T13:42:52+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.00785v1",
    "title": "IGOR: Image-GOal Representations are the Atomic Control Units for Foundation Models in Embodied AI",
    "authors": [
      "Xiaoyu Chen",
      "Junliang Guo",
      "Tianyu He",
      "Chuheng Zhang",
      "Pushi Zhang",
      "Derek Cathera Yang",
      "Li Zhao",
      "Jiang Bian"
    ],
    "abstract": "We introduce Image-GOal Representations (IGOR), aiming to learn a unified,\nsemantically consistent action space across human and various robots. Through\nthis unified latent action space, IGOR enables knowledge transfer among\nlarge-scale robot and human activity data. We achieve this by compressing\nvisual changes between an initial image and its goal state into latent actions.\nIGOR allows us to generate latent action labels for internet-scale video data.\nThis unified latent action space enables the training of foundation policy and\nworld models across a wide variety of tasks performed by both robots and\nhumans. We demonstrate that: (1) IGOR learns a semantically consistent action\nspace for both human and robots, characterizing various possible motions of\nobjects representing the physical interaction knowledge; (2) IGOR can \"migrate\"\nthe movements of the object in the one video to other videos, even across human\nand robots, by jointly using the latent action model and world model; (3) IGOR\ncan learn to align latent actions with natural language through the foundation\npolicy model, and integrate latent actions with a low-level policy model to\nachieve effective robot control. We believe IGOR opens new possibilities for\nhuman-to-robot knowledge transfer and control.",
    "pdf_url": "http://arxiv.org/pdf/2411.00785v1",
    "published": "2024-10-17T13:41:16+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13546v2",
    "title": "Biharmonic Hypersurfaces in Euclidean Spaces",
    "authors": [
      "Hiba Bibi",
      "Marc Soret",
      "Marina Ville"
    ],
    "abstract": "An isometric immersion $X: \\Sigma^n \\longrightarrow \\mathbb{E}^{n+1}$ is\nbiharmonic if $\\Delta^2 X = 0$, i.e. if $\\Delta H =0$, where $\\Delta$ and $H$\nare the metric Laplacian and the mean curvature vector field of $\\Sigma^n$\nrespectively. More generally, biconservative hypersurfaces (BCH) are isometric\nimmersions for which only the tangential part of the biharmonic equation\nvanishes. We study and construct BCH that are holonomic, i.e. for which the\nprincipal curvature directions define an integrable net, and we deduce that\n$\\Sigma^n$ is a holonomic biharmonic hypersurface iff it is minimal.",
    "pdf_url": "http://arxiv.org/pdf/2410.13546v2",
    "published": "2024-10-17T13:41:01+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13545v1",
    "title": "Three-Input Ciphertext Multiplication for Homomorphic Encryption",
    "authors": [
      "Sajjad Akherati",
      "Yok Jye Tang",
      "Xinmiao Zhang"
    ],
    "abstract": "Homomorphic encryption (HE) allows computations to be directly carried out on\nciphertexts and is essential to privacy-preserving computing, such as neural\nnetwork inference, medical diagnosis, and financial data analysis. Only\naddition and 2-input multiplication are defined over ciphertexts in popular HE\nschemes. However, many HE applications involve non-linear functions and they\nneed to be approximated using high-order polynomials to maintain precision. To\nreduce the complexity of these computations, this paper proposes 3-input\nciphertext multiplication. One extra evaluation key is introduced to carry out\nthe relinearization step of ciphertext multiplication, and new formulas are\nproposed to combine computations and share intermediate results. Compared to\nusing two consecutive 2- input multiplications, computing the product of three\nciphertexts utilizing the proposed scheme leads to almost a half of the\nlatency, 29% smaller silicon area, and lower noise without scarifying the\nthroughput.",
    "pdf_url": "http://arxiv.org/pdf/2410.13545v1",
    "published": "2024-10-17T13:40:49+00:00",
    "categories": [
      "cs.CR",
      "cs.AR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13544v1",
    "title": "Subgroups of braid groups generated by Birman-Ko-Lee generators",
    "authors": [
      "Anya Nordskova",
      "Michel Van den Bergh"
    ],
    "abstract": "We define a Young subgroup of the braid group as a subgroup generated by an\narbitrary subset of the Birman-Ko-Lee generators. We give an intrinsic\ndescription of such subgroups which yields, in particular, an easy criterion to\ndecide membership. We also give an algorithm to write an element of a Young\nsubgroup as a product of the generators. Our methods are based on analyzing the\nHurwitz action on tuples over free groups via a diagrammatic approach.",
    "pdf_url": "http://arxiv.org/pdf/2410.13544v1",
    "published": "2024-10-17T13:39:58+00:00",
    "categories": [
      "math.GR",
      "math.RA",
      "20F36"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13543v2",
    "title": "Limit canonical series",
    "authors": [
      "Omid Amini",
      "Eduardo Esteves",
      "Eduardo Garcez"
    ],
    "abstract": "We describe the limits of canonical series along families of curves\ndegenerating to a nodal curve which is general for its topology, in the weak\nsense that the branches over nodes on each of its components are in general\nposition. We define a fan structure on the space of edge lengths on the dual\ngraph of the limit curve, and construct a projective variety parametrizing the\nlimits, organized in strata associated to the cones of this fan. This extends\nto all topologies the works by Eisenbud-Harris (Invent. Math. 87: 496-515,\n1987) on curves of compact type and Esteves-Medeiros (Invent. Math. 149:\n267-338, 2002) on two-component curves.",
    "pdf_url": "http://arxiv.org/pdf/2410.13543v2",
    "published": "2024-10-17T13:33:27+00:00",
    "categories": [
      "math.AG",
      "math.CO"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13542v1",
    "title": "LLM-based Unit Test Generation via Property Retrieval",
    "authors": [
      "Zhe Zhang",
      "Xingyu Liu",
      "Yuanzhang Lin",
      "Xiang Gao",
      "Hailong Sun",
      "Yuan Yuan"
    ],
    "abstract": "Automated unit test generation has been widely studied, with Large Language\nModels (LLMs) recently showing significant potential. Moreover, in the context\nof unit test generation, these tools prioritize high code coverage, often at\nthe expense of practical usability, correctness, and maintainability. In\nresponse, we propose Property-Based Retrieval Augmentation, a novel mechanism\nthat extends LLM-based Retrieval-Augmented Generation (RAG) beyond basic\nvector, text similarity, and graph-based methods. Our approach considers\ntask-specific context and introduces a tailored property retrieval mechanism.\nSpecifically, in the unit test generation task, we account for the unique\nstructure of unit tests by dividing the test generation process into Given,\nWhen, and Then phases. When generating tests for a focal method, we not only\nretrieve general context for the code under test but also consider\ntask-specific context such as pre-existing tests of other methods, which can\nprovide valuable insights for any of the Given, When, and Then phases. This\nforms property relationships between focal method and other methods, thereby\nexpanding the scope of retrieval beyond traditional RAG. We implement this\napproach in a tool called APT, which sequentially performs preprocessing,\nproperty retrieval, and unit test generation, using an iterative strategy where\nnewly generated tests guide the creation of subsequent ones. We evaluated APT\non 12 open-source projects with 1515 methods, and the results demonstrate that\nAPT consistently outperforms existing tools in terms of correctness,\ncompleteness, and maintainability of the generated tests. Moreover, we\nintroduce a novel code-context-aware retrieval mechanism for LLMs beyond\ngeneral context, offering valuable insights and potential applications for\nother code-related tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13542v1",
    "published": "2024-10-17T13:33:12+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13541v1",
    "title": "DualQuat-LOAM: LiDAR Odometry and Mapping parametrized on Dual Quaternions",
    "authors": [
      "Edison P. Velasco-Sánchez",
      "Luis F. Recalde",
      "Guanrui Li",
      "Francisco A. Candelas-Herias",
      "Santiago T. Puente-Mendez",
      "Fernando Torres-Medina"
    ],
    "abstract": "This paper reports on a novel method for LiDAR odometry estimation, which\ncompletely parameterizes the system with dual quaternions. To accomplish this,\nthe features derived from the point cloud, including edges, surfaces, and\nStable Triangle Descriptor (STD), along with the optimization problem, are\nexpressed in the dual quaternion set. This approach enables the direct\ncombination of translation and orientation errors via dual quaternion\noperations, greatly enhancing pose estimation, as demonstrated in comparative\nexperiments against other state-of-the-art methods. Our approach reduced drift\nerror compared to other LiDAR-only-odometry methods, especially in scenarios\nwith sharp curves and aggressive movements with large angular displacement.\nDualQuat-LOAM is benchmarked against several public datasets. In the KITTI\ndataset it has a translation and rotation error of 0.79% and 0.0039{\\deg}/m,\nwith an average run time of 53 ms.",
    "pdf_url": "http://arxiv.org/pdf/2410.13541v1",
    "published": "2024-10-17T13:32:13+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13540v1",
    "title": "Interlayer Magnetic Coupling in FePS$_{3}$ and NiPS$_{3}$ Stacked Bilayers",
    "authors": [
      "Andrea León",
      "Beatriz Costa",
      "Thomas Heine",
      "Thomas Brumme"
    ],
    "abstract": "Single layers of transition-metal thiophosphates (2D-TMPS$_{3}$) van der\nWaals magnets are an ideal platform for studying antiferromagnetic interactions\nin two dimensions. However, the magnetic coupling mechanism between two or more\nindividual layers of these materials remains mostly unexplored. This study\npresents a density-functional based analysis and analytical models to describe\nthe magnetic configurations of FePS$_{3}$ and NiPS$_{3}$ stacked bilayers. We\nexplore the interplay between magnetic configurations and stacking shift,\ntherefore identifying the mechanisms that result in either ferromagnetic or\nantiferromagnetic coupling between layers. Our findings indicate that the\nstacking with the lowest energy is metal-dependent, and the interlayer magnetic\nconfiguration (ferromagnetic or antiferromagnetic) varies based on the stacking\ntype and the metal involved. Using an Ising-Hamiltonian model and a\ntight-binding model based on Wannier functions, we show that interlayer\nexchange interactions must be considered up to the third nearest neighbor and\nto elucidate the superexchange mechanism for the NiPS$_{3}$ system.",
    "pdf_url": "http://arxiv.org/pdf/2410.13540v1",
    "published": "2024-10-17T13:31:22+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13539v2",
    "title": "Design of Unitless Normalized Measure of Nonlinearity for State Estimation",
    "authors": [
      "Ondřej Straka",
      "Jindřich Havlík"
    ],
    "abstract": "The paper deals with measures of nonlinearity. In state estimation, they are\nutilized i) to select a suitable state estimation algorithm by assessing the\nnonlinearity of a system model, ii) to adapt the estimation algorithm structure\nor parameters, or iii) to indicate the possible effect of strong nonlinearity\nthat leads to estimate credibility loss. This paper summarizes the state of the\nart of nonlinearity measures, focusing on the mean-square-error-based measure\nof nonlinearity. Its weak point related to unit selection is illustrated, and\nbased on this, requirements for a new measure of nonlinearity are formulated. A\nnew nonlinearity measure that is both unitless and normalized is designed. Its\nproperties are demonstrated using numerical tracking experiments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13539v2",
    "published": "2024-10-17T13:30:16+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13538v2",
    "title": "Magnetic moments of $\\frac{1}{2}^-$ baryon resonances in hot and dense strange hadronic matter",
    "authors": [
      "Abhinaba Upadhyay",
      "Arvind Kumar",
      "Harleen Dahiya",
      "Suneel Dutt"
    ],
    "abstract": "This work primarily focusses on determining the magnetic moments of\n$\\frac{1}{2}^-$ baryon resonances in the presence of hot and dense hadronic\nmatter. In the chiral $SU(3)$ quark mean field model approach, we have\nessentially accounted for the effects on in-medium scalar meson fields to\ninvestigate the impact of high densities on the in-medium baryon masses and\ntheir constituent quarks. In light of chiral constituent quark model $\\chi$CQM,\nwe have calculated the magnetic moments of $\\frac{1}{2}^-$ baryon resonances\nand scrutinized the effects due to its internal constituents: the valence\nquarks, sea quarks and the orbital moment of sea quarks. Furthermore, we have\ninvestigated the effective baryonic magnetic moments for the finite magnitudes\nof isospin asymmetry and strangeness fraction.",
    "pdf_url": "http://arxiv.org/pdf/2410.13538v2",
    "published": "2024-10-17T13:29:07+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13537v2",
    "title": "A Local Method for Compact and Non-compact Yamabe Problems",
    "authors": [
      "Jie Xu"
    ],
    "abstract": "Let $ (M, g) $ be a compact manifold or a complete non-compact manifold\nwithout boundary, $ \\dim M \\geqslant 4 $, and not locally conformally flat. In\nthis article, we introduce a new local method to resolve the Yamabe problem on\ncompact manifold for dimensions at least $ 4 $, and the Yamabe problem on\nnon-compact complete manifolds without boundary, which are pointwise conformal\nto subsets of some compact manifolds. In particular, the new local method\napplies to the hard cases--the Yamabe constants are positive. Our local method\nalso generalizes Brezis and Nirenberg's nonlinear eigenvalue problem to subsets\nof manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2410.13537v2",
    "published": "2024-10-17T13:28:55+00:00",
    "categories": [
      "math.DG",
      "58J05, 35J60, 53C18"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13536v1",
    "title": "A Simple Partially Embedded Planarity Test Based on Vertex-Addition",
    "authors": [
      "Simon D. Fink",
      "Ignaz Rutter",
      "Sandhya T. P"
    ],
    "abstract": "In the Partially Embedded Planarity problem, we are given a graph $G$\ntogether with a topological drawing of a subgraph $H$ of $G$. The task is to\ndecide whether the drawing can be extended to a drawing of the whole graph such\nthat no two edges cross. Angelini et al. gave a linear-time algorithm for\nsolving this problem in 2010 (SODA '10). While their paper constitutes a\nsignificant result, the algorithm described therein is highly complex: it uses\nseveral layers of decompositions according to connectivity of both $G$ and $H$,\nits description spans more than 30 pages, and can hardly be considered\nimplementable. We give an independent linear-time algorithm that works along\nthe well-known vertex-addition planarity test by Booth and Lueker. We modify\nthe PC-tree as underlying data structure used for representing all planar\ndrawing possibilities in a natural way to also respect the restrictions given\nby the prescribed drawing of the subgraph $H$. The testing algorithm and its\nproof of correctness only require small adaptations from the comparatively much\nsimpler generic planarity test, of which several implementations exist. If the\ntest succeeds, an embedding can be constructed using the same approaches that\nare used for the generic planarity test.",
    "pdf_url": "http://arxiv.org/pdf/2410.13536v1",
    "published": "2024-10-17T13:27:20+00:00",
    "categories": [
      "cs.CG"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13535v2",
    "title": "Million-atom heat transport simulations of polycrystalline graphene approaching first-principles accuracy enabled by neuroevolution potential on desktop GPUs",
    "authors": [
      "Xiaoye Zhou",
      "Yuqi Liu",
      "Benrui Tang",
      "Junyuan Wang",
      "Haikuan Dong",
      "Xiaoming Xiu",
      "Shunda Chen",
      "Zheyong Fan"
    ],
    "abstract": "First-principles molecular dynamics simulations of heat transport in systems\nwith large-scale structural features are challenging due to their high\ncomputational cost. Here, using polycrystalline graphene as a case study, we\ndemonstrate the feasibility of simulating heat transport with near\nfirst-principles accuracy in systems containing over 1.4 million atoms,\nachievable even with consumer desktop GPUs. This is enabled by the highly\nefficient neuroevolution potential (NEP) approach, as implemented in the\nopen-source GPUMD package. Leveraging the NEP model's accuracy and efficiency,\nwe quantify the reduction in thermal conductivity of polycrystalline graphene\ndue to grain boundaries with varying grain sizes, resolving contributions from\nin-plane and out-of-plane (flexural) phonon modes. Additionally, we find that\ngrain boundaries can lead to finite thermal conductivity even under significant\ntensile strain, in contrast to the divergent behavior observed in pristine\ngraphene under similar conditions, indicating that grain boundaries may play a\ncrucial role in thermal transport in low-dimensional momentum-conserving\nsystems. These findings could offer insights for interpreting experimental\nobservations, given the widespread presence of both large-scale grain\nboundaries and external strains in real materials. The demonstrated ability to\nsimulate millions of atoms with near-first-principles accuracy on consumer\ndesktop GPUs using the NEP approach will help make large-scale high-fidelity\natomistic simulations more accessible to the broader research community.",
    "pdf_url": "http://arxiv.org/pdf/2410.13535v2",
    "published": "2024-10-17T13:25:28+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13534v8",
    "title": "Derived categories of bifiltered complexes",
    "authors": [
      "Yukiyoshi Nakkajima"
    ],
    "abstract": "We construct a fundamental theory of the derived category of non-finite\nbi-filtered complexes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13534v8",
    "published": "2024-10-17T13:24:31+00:00",
    "categories": [
      "math.KT"
    ],
    "primary_category": "math.KT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13533v2",
    "title": "Memory of rotation in residual stress of paste",
    "authors": [
      "Hiroki Matsuda",
      "Michio Otsuki"
    ],
    "abstract": "We numerically investigate the stress distribution in pastes after horizontal\nrotation by using an elasto-plastic model. Residual stress remains as a memory\nof rotation. The stress in the circumferential direction increases after the\nrotation, whereas that in the radial direction decreases. The residual stress\nis analytically related to the plastic deformation induced by the rotation.\nBased on the time evolution of plastic deformation, we theoretically describe\nthe mechanism of the changes in the stress distribution.",
    "pdf_url": "http://arxiv.org/pdf/2410.13533v2",
    "published": "2024-10-17T13:21:46+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13532v1",
    "title": "RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object Detection in Remote Sensing Images",
    "authors": [
      "Kejun Ren",
      "Xin Wu",
      "Lianming Xu",
      "Li Wang"
    ],
    "abstract": "Unmanned aerial vehicle (UAV) remote sensing is widely applied in fields such\nas emergency response, owing to its advantages of rapid information acquisition\nand low cost. However, due to the effects of shooting distance and imaging\nmechanisms, the objects in the images present challenges such as small size,\ndense distribution, and low inter-class differentiation. To this end, we\npropose a multimodal remote sensing detection network that employs a\nquad-directional selective scanning fusion strategy called RemoteDet-Mamba.\nRemoteDet-Mamba simultaneously facilitates the learning of single-modal local\nfeatures and the integration of patch-level global features across modalities,\nenhancing the distinguishability for small objects and utilizing local\ninformation to improve discrimination between different classes. Additionally,\nthe use of Mamba's serial processing significantly increases detection speed.\nExperimental results on the DroneVehicle dataset demonstrate the effectiveness\nof RemoteDet-Mamba, which achieves superior detection accuracy compared to\nstate-of-the-art methods while maintaining computational efficiency and\nparameter count.",
    "pdf_url": "http://arxiv.org/pdf/2410.13532v1",
    "published": "2024-10-17T13:20:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13531v1",
    "title": "Exploring the role of polarization in fiber-based quantum sources",
    "authors": [
      "Carla M. Brunner",
      "Nicolas Y. Joly"
    ],
    "abstract": "Optical fibers constitute an attractive platform for the realization of\nnonlinear and quantum optics processes. Here we show, through theoretical\nconsiderations, how polarization effects of both third-order parametric\ndown-conversion and four-wave-mixing in optical fibers may be exploited to\nenhance detection schemes. We apply our general framework specifically to the\ncase of tapered fibers for photon triplet generation, a long-standing goal\nwithin quantum optics, and obtain explicit expectation values for its\nefficiency. A quantitative investigation of four-wave-mixing in a\nmicrostructured solid-core fiber provides significant consequences for the role\nof polarization in experimental design.",
    "pdf_url": "http://arxiv.org/pdf/2410.13531v1",
    "published": "2024-10-17T13:19:35+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13530v1",
    "title": "L3DG: Latent 3D Gaussian Diffusion",
    "authors": [
      "Barbara Roessle",
      "Norman Müller",
      "Lorenzo Porzi",
      "Samuel Rota Bulò",
      "Peter Kontschieder",
      "Angela Dai",
      "Matthias Nießner"
    ],
    "abstract": "We propose L3DG, the first approach for generative 3D modeling of 3D\nGaussians through a latent 3D Gaussian diffusion formulation. This enables\neffective generative 3D modeling, scaling to generation of entire room-scale\nscenes which can be very efficiently rendered. To enable effective synthesis of\n3D Gaussians, we propose a latent diffusion formulation, operating in a\ncompressed latent space of 3D Gaussians. This compressed latent space is\nlearned by a vector-quantized variational autoencoder (VQ-VAE), for which we\nemploy a sparse convolutional architecture to efficiently operate on room-scale\nscenes. This way, the complexity of the costly generation process via diffusion\nis substantially reduced, allowing higher detail on object-level generation, as\nwell as scalability to large scenes. By leveraging the 3D Gaussian\nrepresentation, the generated scenes can be rendered from arbitrary viewpoints\nin real-time. We demonstrate that our approach significantly improves visual\nquality over prior work on unconditional object-level radiance field synthesis\nand showcase its applicability to room-scale scene generation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13530v1",
    "published": "2024-10-17T13:19:32+00:00",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.18998v1",
    "title": "DamFormer: Generalizing Morphologies in Dam Break Simulations Using Transformer Model",
    "authors": [
      "Zhaoyang Mul",
      "Aoming Liang",
      "Mingming Ge",
      "Dashuai Chen",
      "Dixia Fan",
      "Minyi Xu"
    ],
    "abstract": "The interaction of waves with structural barriers such as dams breaking plays\na critical role in flood defense and tsunami disasters. In this work, we\nexplore the dynamic changes in wave surfaces impacting various structural\nshapes, e.g., circle, triangle, and square, by using deep learning techniques.\nWe introduce the DamFormer, a novel transformer-based model designed to learn\nand simulate these complex interactions. The model was trained and tested on\nsimulated data representing the three structural forms.",
    "pdf_url": "http://arxiv.org/pdf/2410.18998v1",
    "published": "2024-10-17T13:18:13+00:00",
    "categories": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2410.13529v1",
    "title": "A Construction of Evolving $3$-threshold Secret Sharing Scheme with Perfect Security and Smaller Share Size",
    "authors": [
      "Qi Cheng",
      "Hongru Cao",
      "Sian-Jheng Lin"
    ],
    "abstract": "The evolving $k$-threshold secret sharing scheme allows the dealer to\ndistribute the secret to many participants such that only no less than $k$\nshares together can restore the secret. In contrast to the conventional secret\nsharing scheme, the evolving scheme allows the number of participants to be\nuncertain and even ever-growing. In this paper, we consider the evolving secret\nsharing scheme with $k=3$. First, we point out that the prior approach has\nrisks in the security. To solve this issue, we then propose a new evolving\n$3$-threshold scheme with perfect security. Given a $\\ell$-bit secret, the\n$t$-th share of the proposed scheme has $\\lceil\\log_2 t\\rceil +O({\\lceil \\log_4\n\\log_2 t\\rceil}^2)+\\log_2 p(2\\lceil \\log_4 \\log_2 t\\rceil-1)$ bits, where $p$\nis a prime. Compared with the prior result $2 \\lfloor\\log_2\nt\\rfloor+O(\\lfloor\\log_2 t\\rfloor)+\\ell$, the proposed scheme reduces the\nleading constant from $2$ to $1$. Finally, we propose a conventional\n$3$-threshold secret sharing scheme over a finite field. Based on this model of\nthe revised scheme and the proposed conventional $3$-threshold scheme, we\npresent a brand-new and more concise evolving $3$-threshold secret sharing\nscheme.",
    "pdf_url": "http://arxiv.org/pdf/2410.13529v1",
    "published": "2024-10-17T13:17:11+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13528v2",
    "title": "AI-based 3-Lead to 12-Lead ECG Reconstruction: Towards Smartphone-based Public Healthcare",
    "authors": [
      "Aditya Mallick",
      "Rahul L R",
      "Albert Shaiju",
      "Satya Deepika Neelapala",
      "Lopamudra Giri",
      "Rahuldeb Sarkar",
      "Soumya Jana"
    ],
    "abstract": "Clinicians generally diagnose cardiovascular diseases (CVDs) using standard\n12-Lead electrocardiogram (ECG). However, for smartphone-based public\nhealthcare systems, a reduced 3-lead system may be preferred because of (i)\nincreased portability, and (ii) reduced requirement for power, storage and\nbandwidth. Subsequently, clinicians require accurate 3-lead to 12-Lead ECG\nreconstruction, which has so far been studied only in the personalized setting.\nWhen each device is dedicated to one individual, artificial intelligence (AI)\nmethods such as temporal long short-term memory (LSTM) and a further improved\nspatio-temporal LSTM-UNet combine have proven effective. In contrast, in the\ncurrent smartphone-based public health setting where a common device is shared\nby many, developing an AI lead-reconstruction model that caters to the\nextensive ECG signal variability in the general population appears a far\ngreater challenge. In this direction, we take a first step, and observe that\nthe performance improvement achieved by a generative model, specifically, 1D\nPix2Pix GAN (generative adversarial network), over LSTM-UNet is encouraging.",
    "pdf_url": "http://arxiv.org/pdf/2410.13528v2",
    "published": "2024-10-17T13:16:00+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13527v1",
    "title": "Connect-while-in-range: modelling the impact of spatial constraints on dynamic communication network structures",
    "authors": [
      "Niek Kerssies",
      "Jose Segovia Martin",
      "James Winters"
    ],
    "abstract": "Like other social animals and biological systems, human groups constantly\nexchange information. Network models provide a way of quantifying this process\nby representing the pathways of information propagation between individuals.\nExisting approaches to studying these networks largely hypothesize network\nformation to be a result of cognitive biases and choices about who to connect\nto. Observational data suggests, however, that physical proximity plays a major\nrole in shaping the formation of communication networks in human groups. Here\nwe report results from a series of agent-based simulations in which agents move\naround at random in a bounded 2D space and connect while within communication\nrange. Comparing the results to a non-spatial model, we show how including\nspatial constraints impacts our predictions of network structure: ranged\nnetworks are more clustered, with slightly higher degree, higher average\nshortest path length, a lower number of connected components and a higher\nsmall-world index. We find two important drivers of network structure in\nrange-constrained dynamic networks: communication range relative to environment\nsize, and population density. These results show that neglecting spatial\nconstraints in models of network formation makes a difference for predicted\nnetwork structures. Our simulation model quantifies this part of the process of\nnetwork formation, realized by simply situating individuals in an environment.\nThe model also provides a tool to include spatial constraints in other models\nof human communication, as well as dynamic models of network formation more\ngenerally.",
    "pdf_url": "http://arxiv.org/pdf/2410.13527v1",
    "published": "2024-10-17T13:15:04+00:00",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13526v1",
    "title": "Generative Adversarial Synthesis of Radar Point Cloud Scenes",
    "authors": [
      "Muhammad Saad Nawaz",
      "Thomas Dallmann",
      "Torsten Schoen",
      "Dirk Heberling"
    ],
    "abstract": "For the validation and verification of automotive radars, datasets of\nrealistic traffic scenarios are required, which, how ever, are laborious to\nacquire. In this paper, we introduce radar scene synthesis using GANs as an\nalternative to the real dataset acquisition and simulation-based approaches. We\ntrain a PointNet++ based GAN model to generate realistic radar point cloud\nscenes and use a binary classifier to evaluate the performance of scenes\ngenerated using this model against a test set of real scenes. We demonstrate\nthat our GAN model achieves similar performance (~87%) to the real scenes test\nset.",
    "pdf_url": "http://arxiv.org/pdf/2410.13526v1",
    "published": "2024-10-17T13:14:25+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13525v1",
    "title": "Static and Dynamic Electronic Properties of Weyl Semimetal NbP -- A Single Crystal $^{93}$Nb-NMR Study",
    "authors": [
      "Tetsuro Kubo",
      "Hiroshi Yasuoka",
      "Deepa Kasinathan",
      "K. M. Ranjith",
      "Marcus Schmidt",
      "Michael Baenitz"
    ],
    "abstract": "Nuclear magnetic resonance (NMR) techniques have been used to study the\nstatic and dynamic microscopic properties of the Weyl semimetal NbP. From a\ncomplete analysis of the angular dependence of the $^{93}$Nb-NMR spectra in a\nsingle crystal, the parameters for the electric quadrupole interactions and the\nmagnetic hyperfine interactions were determined to be $\\nu_{\\rm Q} =\n0.61$\\,MHz, $\\eta = 0.20$, $(K_{XX}, K_{YY}, K_{ZZ}) = (- 0.06, 0.11, -\n0.11)$\\% at 4.5\\,K. The temperature and field dependence of the $^{93}$Nb\nKnight shift revealed a characteristic feature of the shape of the density of\nstates with nearly massless fermions. We clearly observed a quantum oscillation\nof the Knight shift associated with the band structure, whose frequency was in\ngood agreement with the previous bulk measurements. The temperature dependence\nof the spin-lattice relaxation rate, $1 / T_{1} T$, showed an almost constant\nbehavior for $30 < T < 180$\\,K, while a weak temperature dependence was\nobserved below $\\sim 30$\\,K. This contrasts with the behavior observed in TaP\nand TaAs, where the $1 / T_{1} T$ measured by the $^{181}$Ta nuclear quadrupole\nresonance (NQR) shows $1 / T_{1} T \\propto T^{2}$ and $T^{4}$ above\napproximately 30\\,K. In TaP, the temperature dependent orbital hyperfine\ninteraction plays a signficant role in nuclear relaxation, whereas this\ncontribution is not observed in TaAs. Two-component spin echo oscillations were\nobserved. The shorter-period oscillation is attributed to the origin of\nquadrupole coupling, while the longer-period oscillation indicates the presence\nof indirect nuclear spin-spin coupling, as discussed in other Weyl semimetal\nlike TaP.",
    "pdf_url": "http://arxiv.org/pdf/2410.13525v1",
    "published": "2024-10-17T13:14:15+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13524v2",
    "title": "Improving the Estimation of Attenuation in Q/V Band Systems with a Kalman-Based Scintillation Filter",
    "authors": [
      "Justin Cano",
      "Julien Queyrel",
      "Laurent Castanet",
      "Michel Bousquet"
    ],
    "abstract": "This paper presents the design and implementation of the Scintillation Filter\nby Kalman-colored algorithm (SciFi), which is used to remove tropospheric\nscintillation from Q/V bands total attenuation data series. In contrast to the\nclassical methods using low-pass filters, the SciFi algorithm allows to\nestimate both the attenuation, its slope and a confidence interval. Moreover,\nthe linear observer structure of the Kalman filter allows it to operate in real\ntime. Therefore, the states and uncertainties estimated by SciFi can be used as\ninput for Fade Mitigation Techniques (FMT) such as Adaptive Coding and\nModulation (ACM) or Site Diversity (SD). In this article, we propose a method\nto tune the noise level based on recommendations approved by the ITU-R.\nFinally, some results of filtering on Alphasat experimental data are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2410.13524v2",
    "published": "2024-10-17T13:11:27+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13523v2",
    "title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?",
    "authors": [
      "Che Liu",
      "Zhongwei Wan",
      "Haozhe Wang",
      "Yinda Chen",
      "Talha Qaiser",
      "Chen Jin",
      "Fariba Yousefi",
      "Nikolay Burlutskiy",
      "Rossella Arcucci"
    ],
    "abstract": "Medical Vision-Language Pre-training (MedVLP) has made significant progress\nin enabling zero-shot tasks for medical image understanding. However, training\nMedVLP models typically requires large-scale datasets with paired, high-quality\nimage-text data, which are scarce in the medical domain. Recent advancements in\nLarge Language Models (LLMs) and diffusion models have made it possible to\ngenerate large-scale synthetic image-text pairs. This raises the question: \"Can\nMedVLP succeed using purely synthetic data?\" To address this, we use\noff-the-shelf generative models to create synthetic radiology reports and\npaired Chest X-ray (CXR) images, and propose an automated pipeline to build a\ndiverse, high-quality synthetic dataset, enabling a rigorous study that\nisolates model and training settings, focusing entirely from the data\nperspective. Our results show that MedVLP models trained exclusively on\nsynthetic data outperform those trained on real data by 3.8% in averaged AUC on\nzero-shot classification. Moreover, using a combination of synthetic and real\ndata leads to a further improvement of 9.07%. Additionally, MedVLP models\ntrained on synthetic or mixed data consistently outperform those trained on\nreal data in zero-shot grounding, as well as in fine-tuned classification and\nsegmentation tasks. Our analysis suggests MedVLP trained on well-designed\nsynthetic data can outperform models trained on real datasets, which may be\nlimited by low-quality samples and long-tailed distributions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13523v2",
    "published": "2024-10-17T13:11:07+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13522v2",
    "title": "Fair comparisons of causal parameters with many treatments and positivity violations",
    "authors": [
      "Alec McClean",
      "Yiting Li",
      "Sunjae Bae",
      "Mara A. McAdams-DeMarco",
      "Iván Díaz",
      "Wenbo Wu"
    ],
    "abstract": "Comparing outcomes across treatments is essential in medicine and public\npolicy. To do so, researchers typically estimate a set of parameters, possibly\ncounterfactual, with each targeting a different treatment. Treatment-specific\nmeans (TSMs) are commonly used, but their identification requires a positivity\nassumption -- that every subject has a non-zero probability of receiving each\ntreatment. This assumption is often implausible, especially when treatment can\ntake many values. Causal parameters based on dynamic stochastic interventions\ncan be robust to positivity violations. However, comparing these parameters may\nbe unfair because they may depend on outcomes under non-target treatments. To\naddress this, and clarify when fair comparisons are possible, we propose a\nfairness criterion: if the conditional TSM for one treatment is greater than\nthat for another, then the corresponding causal parameter should also be\ngreater. We derive two intuitive properties equivalent to this criterion and\nshow that only a mild positivity assumption is needed to identify fair\nparameters. We then provide examples that satisfy this criterion and are\nidentifiable under the milder positivity assumption. These parameters are\nnon-smooth, making standard nonparametric efficiency theory inapplicable, so we\npropose smooth approximations of them. We then develop doubly robust-style\nestimators that attain parametric convergence rates under nonparametric\nconditions. We illustrate our methods with an analysis of dialysis providers in\nNew York State.",
    "pdf_url": "http://arxiv.org/pdf/2410.13522v2",
    "published": "2024-10-17T13:10:04+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13521v1",
    "title": "Methodologies for offshore wind power plants stability analysis",
    "authors": [
      "Germano R. Mugambi",
      "Nicolae Darii",
      "Hesam Khazraj",
      "Oscar S. Romano",
      "Alin G. Raducu",
      "Ranjan Sharma",
      "Nicolaos A. Cutululis"
    ],
    "abstract": "The development of larger Offshore Wind Power Plants (OWPPs) is moving\ntowards multi-vendor setups, ultimately aiming to establish Energy hubs. These\nstructures are characterized by installations from different vendors sharing\nthe same connection or closely interconnected points. Control interactions\namong Wind Turbine (WT) converters and power systems have been detected, and\nthis critical phenomenon can significantly impact the dynamic stability of the\nsystem. Various stability analysis methods have been proposed to analyze the\ninteractions between OWPPs at the Point-of-Connection (PoC) and the power\nsystem. However, stability studies rarely consider the complex offshore\ntransmission system behind the PoC. Generally, the overall OWPP is blamed for\nthe instability. However, since it is a complex system, it is important to\nunderstand which part of the OWPP behind the PoC is causing the problem or is\nlikely to become unstable under certain conditions. Therefore, this paper\nprovides a detailed overview of the advantages and limitations of the current\nsystem screening indexes used to design the OWPP, and the stability analysis\nmethods. Each method is discussed, and the appropriate methods, depending on\nOWPP structure, are evaluated and discussed. The analysis indicates that a\ncombination of time domain and frequency domain methods is necessary for\nenhancing the definition of stability boundaries.",
    "pdf_url": "http://arxiv.org/pdf/2410.13521v1",
    "published": "2024-10-17T13:09:24+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13520v1",
    "title": "Contracting With a Reinforcement Learning Agent by Playing Trick or Treat",
    "authors": [
      "Matteo Bollini",
      "Francesco Bacchiocchi",
      "Matteo Castiglioni",
      "Alberto Marchesi",
      "Nicola Gatti"
    ],
    "abstract": "We study principal-agent problems where a farsighted agent takes costly\nactions in an MDP. The core challenge in these settings is that agent's actions\nare hidden to the principal, who can only observe their outcomes, namely state\ntransitions and their associated rewards. Thus, the principal's goal is to\ndevise a policy that incentives the agent to take actions leading to desirable\noutcomes. This is accomplished by committing to a payment scheme (a.k.a.\ncontract) at each step, specifying a monetary transfer from the principal to\nthe agent for every possible outcome. Interestingly, we show that Markovian\npolicies are unfit in these settings, as they do not allow to achieve the\noptimal principal's utility and are constitutionally intractable. Thus,\naccounting for history in unavoidable, and this begets considerable additional\nchallenges compared to standard MDPs. Nevertheless, we design an efficient\nalgorithm to compute an optimal policy, leveraging a compact way of\nrepresenting histories for this purpose. Unfortunately, the policy produced by\nsuch an algorithm cannot be readily implemented, as it is only approximately\nincentive compatible, meaning that the agent is incentivized to take the\ndesired actions only approximately. To fix this, we design an efficient method\nto make such a policy incentive compatible, by only introducing a negligible\nloss in principal's utility. This method can be generally applied to any\napproximately-incentive-compatible policy, and it generalized a related\napproach that has already been discovered for classical principal-agent\nproblems to more general settings in MDPs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13520v1",
    "published": "2024-10-17T13:09:08+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13519v2",
    "title": "Schubert cells and Whittaker functionals for $\\text{GL}(n,\\mathbb{R})$ part I: Combinatorics",
    "authors": [
      "Doyon Kim"
    ],
    "abstract": "We give a formula for a birational map on the Schubert cell associated to\neach Weyl group element of $G=\\text{GL}(n)$. The map simplifies the UDL\ndecomposition of matrices, providing structural insight into the Schubert cell\ndecomposition of the flag variety $G/B$, where $B$ is a Borel subgroup. An\napplication of the formula includes a new proof of the existence of Whittaker\nfunctionals for principal series representations of $\\text{GL}(n,\\mathbb{R})$\nvia integration by parts. In this paper, we establish combinatorial properties\nof the birational map and prove auxiliary results.",
    "pdf_url": "http://arxiv.org/pdf/2410.13519v2",
    "published": "2024-10-17T13:08:26+00:00",
    "categories": [
      "math.RT",
      "math.NT",
      "11F70 (Primary), 05E14 (Secondary)"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2411.02401v1",
    "title": "A Civilian Astronomer's Guide to UAP Research",
    "authors": [
      "Beatriz Villarroel",
      "Kevin Krisciunas"
    ],
    "abstract": "Unidentified Anomalous Phenomena (UAP) have historically been stigmatized and\nregarded as pseudoscience due to a general lack of robust evidence. Recently,\nhowever, the subject has gained interest among astronomers and the military.\nThis review explores how astronomers can enhance our understanding of these\nenigmatic phenomena by focusing on empirical tests of specific hypotheses (e.g.\nthe hypothesis of extraterrestrial visitations) rather than solely collecting\nand categorizing data. We compare the investigation of UAP to the process of\ncalibration and interpretations of astronomical discoveries and propose a toy\nmodel involving a network of neuro-interface extraterrestrial probes to model\nexotic UAP. This model aids in predicting probe signatures and behaviour,\nimproving detection methods, and addressing ethical concerns in UAP research.",
    "pdf_url": "http://arxiv.org/pdf/2411.02401v1",
    "published": "2024-10-17T13:07:40+00:00",
    "categories": [
      "astro-ph.IM",
      "physics.pop-ph",
      "physics.soc-ph"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13518v1",
    "title": "Proton internal pressure from deeply virtual Compton scattering on collider kinematics",
    "authors": [
      "Hervé Dutrieux",
      "Thibaud Meisgny",
      "Cédric Mezrag",
      "Hervé Moutarde"
    ],
    "abstract": "The unique experimental connection to the QCD energy-momentum tensor offered\nby generalised parton distributions has been strongly highlighted in the past\nfew years with attempts to extract the pressure and shear forces distributions\nwithin the nucleon. If, in principle, this can be performed in a model\nindependent way from experimental data, in practice, the current limited\nprecision and kinematic coverage make such an extraction very challenging.\nMoreover, the limitation to a leading-order description in the strong coupling\nof the data has provided only an indirect and weakly sensitive access to gluon\ndegrees of freedoms, solely through their mixing to quarks via evolution. In\nthis paper we address this issue by pro viding a next-to-leading order\nformalism allowing a reanalysis of global fits with genuine gluonic degrees of\nfreedom. In addition, we provide an estimate of the reduction in uncertainty\nthat could stem from the extended kinematic range relevant for the future\nElectron Ion Collider. Finally, we stress the connection between the analysis\nof the dispersion relation in terms of generalised parton distributions and the\ndeconvolution problem.",
    "pdf_url": "http://arxiv.org/pdf/2410.13518v1",
    "published": "2024-10-17T13:06:50+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.00009v1",
    "title": "New Interferometric Testing Utility (NITU) : A Python Package for Interferometric Data Analysis and Visualization",
    "authors": [
      "Meghdoot Biswas",
      "Daewook Kim"
    ],
    "abstract": "New Interferometric Testing Utility (NITU) is a newly developed Python\npackage for analyzing and visualizing interferometric data. It provides Zernike\ndecomposition, interactive visualization, time series analysis, and additional\nfeatures for optical manufacturing and testing.",
    "pdf_url": "http://arxiv.org/pdf/2411.00009v1",
    "published": "2024-10-17T13:06:30+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13517v2",
    "title": "Bias in the Mirror: Are LLMs opinions robust to their own adversarial attacks ?",
    "authors": [
      "Virgile Rennard",
      "Christos Xypolopoulos",
      "Michalis Vazirgiannis"
    ],
    "abstract": "Large language models (LLMs) inherit biases from their training data and\nalignment processes, influencing their responses in subtle ways. While many\nstudies have examined these biases, little work has explored their robustness\nduring interactions. In this paper, we introduce a novel approach where two\ninstances of an LLM engage in self-debate, arguing opposing viewpoints to\npersuade a neutral version of the model. Through this, we evaluate how firmly\nbiases hold and whether models are susceptible to reinforcing misinformation or\nshifting to harmful viewpoints. Our experiments span multiple LLMs of varying\nsizes, origins, and languages, providing deeper insights into bias persistence\nand flexibility across linguistic and cultural contexts.",
    "pdf_url": "http://arxiv.org/pdf/2410.13517v2",
    "published": "2024-10-17T13:06:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13516v1",
    "title": "PORTAL: Scalable Tabular Foundation Models via Content-Specific Tokenization",
    "authors": [
      "Marco Spinaci",
      "Marek Polewczyk",
      "Johannes Hoffart",
      "Markus C. Kohler",
      "Sam Thelin",
      "Tassilo Klein"
    ],
    "abstract": "Self-supervised learning on tabular data seeks to apply advances from natural\nlanguage and image domains to the diverse domain of tables. However, current\ntechniques often struggle with integrating multi-domain data and require data\ncleaning or specific structural requirements, limiting the scalability of\npre-training datasets. We introduce PORTAL (Pretraining One-Row-at-a-Time for\nAll tabLes), a framework that handles various data modalities without the need\nfor cleaning or preprocessing. This simple yet powerful approach can be\neffectively pre-trained on online-collected datasets and fine-tuned to match\nstate-of-the-art methods on complex classification and regression tasks. This\nwork offers a practical advancement in self-supervised learning for large-scale\ntabular data.",
    "pdf_url": "http://arxiv.org/pdf/2410.13516v1",
    "published": "2024-10-17T13:05:44+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13515v2",
    "title": "Observation of a rare beta decay of the charmed baryon with a Graph Neural Network",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "O. Afedulidis",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "I. Balossino",
      "Y. Ban",
      "H. -R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "J. F. Chang",
      "G. R. Che",
      "G. Chelkov",
      "C. Chen",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "Z. Y. Chen",
      "S. K. Choi",
      "G. Cibinetto",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "Z. H. Duan",
      "P. Egorov",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "X. B. Gao",
      "Y. N. Gao",
      "Yang Gao",
      "S. Garbolino",
      "I. Garzia",
      "L. Ge",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "A. Gilman",
      "K. Goetzen",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "Y. T. Gu",
      "C. Y. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "J. Gutierrez",
      "K. L. Han",
      "T. T. Han",
      "F. Hanisch",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. H. Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "T. Holtmann",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "B. Y. Hu",
      "H. M. Hu",
      "J. F. Hu",
      "S. L. Hu",
      "T. Hu",
      "Y. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "T. Hussain",
      "F. Hölzken",
      "N. Hüsken",
      "N. in der Wiesche",
      "J. Jackson",
      "S. Janchiv",
      "J. H. Jeong",
      "Q. Ji",
      "Q. P. Ji",
      "W. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "X. Q. Jia",
      "Z. K. Jia",
      "D. Jiang",
      "H. B. Jiang",
      "P. C. Jiang",
      "S. S. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "J. K. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "X. M. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "M. Kavatsyuk",
      "B. C. Ke",
      "V. Khachatryan",
      "A. Khoukaz",
      "R. Kiuchi",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "N. Kumar",
      "A. Kupsc",
      "W. Kühn",
      "J. J. Lane",
      "P. Larin",
      "L. Lavezzi",
      "T. T. Lei",
      "Z. H. Lei",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "Cheng Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "K. Li",
      "L. J. Li",
      "L. K. Li",
      "Lei Li",
      "M. H. Li",
      "P. R. Li",
      "Q. M. Li",
      "Q. X. Li",
      "R. Li",
      "S. X. Li",
      "T. Li",
      "W. D. Li",
      "W. G. Li",
      "X. Li",
      "X. H. Li",
      "X. L. Li",
      "X. Y. Li",
      "X. Z. Li",
      "Y. G. Li",
      "Z. J. Li",
      "Z. Y. Li",
      "C. Liang",
      "H. Liang",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "L. Z. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "C. C. Lin",
      "D. X. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. Liu",
      "F. H. Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. B. Liu",
      "H. H. Liu",
      "H. M. Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. Y. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. Liu",
      "L. C. Liu",
      "Lu Liu",
      "M. H. Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "X. Liu",
      "X. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. D. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "X. L. Lu",
      "Y. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "J. R. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "X. R. Lyu",
      "Y. F. Lyu",
      "F. C. Ma",
      "H. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "M. M. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "T. Ma",
      "X. T. Ma",
      "X. Y. Ma",
      "Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "M. Maggiora",
      "S. Malde",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "Z. X. Meng",
      "J. G. Messchendorp",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "B. Moses",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "L. S. Nie",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Q. L. Niu",
      "W. D. Niu",
      "Y. Niu",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "P. Patteri",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "Y. Y. Peng",
      "K. Peters",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "V. Prasad",
      "F. Z. Qi",
      "H. Qi",
      "H. R. Qi",
      "M. Qi",
      "T. Y. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "X. K. Qiao",
      "J. J. Qin",
      "L. Q. Qin",
      "L. Y. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "Z. H. Qu",
      "C. F. Redmer",
      "K. J. Ren",
      "A. Rivetti",
      "M. Rolo",
      "G. Rong",
      "Ch. Rosner",
      "S. N. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Schoenning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "Z. J. Shang",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. Shi",
      "H. C. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "Q. Q. Shi",
      "S. Y. Shi",
      "X. Shi",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. J. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "W. Y. Sun",
      "Y. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. Q. Sun",
      "Z. T. Sun",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "M. Tang",
      "Y. A. Tang",
      "L. Y. Tao",
      "Q. T. Tao",
      "M. Tat",
      "J. X. Teng",
      "V. Thoren",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "Y. Wan",
      "S. J. Wang",
      "B. Wang",
      "B. L. Wang",
      "Bo Wang",
      "D. Y. Wang",
      "F. Wang",
      "H. J. Wang",
      "J. J. Wang",
      "J. P. Wang",
      "K. Wang",
      "L. L. Wang",
      "M. Wang",
      "N. Y. Wang",
      "S. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "X. N. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. L. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "Yaqian Wang",
      "Yi Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. Y. Wang",
      "Ziyi Wang",
      "D. H. Wei",
      "F. Weidner",
      "S. P. Wen",
      "Y. R. Wen",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "L. Wollenberg",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. Wu",
      "Y. H. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "B. H. Xiang",
      "T. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "S. Y. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "H. Y. Xu",
      "M. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "W. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. C. Xu",
      "Z. P. Xu",
      "Z. S. Xu",
      "F. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "T. Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. F. Yang",
      "Y. X. Yang",
      "Z. W. Yang",
      "Z. P. Yao",
      "M. Ye",
      "M. H. Ye",
      "J. H. Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "T. Yu",
      "X. D. Yu",
      "Y. C. Yu",
      "C. Z. Yuan",
      "J. Yuan",
      "J. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "A. A. Zafar",
      "F. R. Zeng",
      "S. H. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. C. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. Zhang",
      "H. C. Zhang",
      "H. H. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. R. Zhang",
      "H. Y. Zhang",
      "J. Zhang",
      "J. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. S. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "L. M. Zhang",
      "Lei Zhang",
      "P. Zhang",
      "Q. Y. Zhang",
      "R. Y. Zhang",
      "S. H. Zhang",
      "Shulei Zhang",
      "X. D. Zhang",
      "X. M. Zhang",
      "X. Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Y. M. Zhang",
      "Yan Zhang",
      "Z. D. Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "Z. Z. Zhang",
      "G. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "L. Zhao",
      "Lei Zhao",
      "M. G. Zhao",
      "N. Zhao",
      "R. P. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "B. M. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "X. Zhong",
      "H. Zhou",
      "J. Y. Zhou",
      "L. P. Zhou",
      "S. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. Z. Zhou",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "K. S. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "S. Q. Zhu",
      "T. J. Zhu",
      "W. D. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "The beta decay of the lightest charmed baryon $\\Lambda_c^+$ provides unique\ninsights into the fundamental mechanism of strong and electro-weak\ninteractions, serving as a testbed for investigating non-perturbative quantum\nchromodynamics and constraining the Cabibbo-Kobayashi-Maskawa (CKM) matrix\nparameters. This article presents the first observation of the\nCabibbo-suppressed decay $\\Lambda_c^+ \\rightarrow n e^+ \\nu_{e}$, utilizing\n$4.5~\\mathrm{fb}^{-1}$ of electron-positron annihilation data collected with\nthe BESIII detector. A novel Graph Neural Network based technique effectively\nseparates signals from dominant backgrounds, notably $\\Lambda_c^+ \\rightarrow\n\\Lambda e^+ \\nu_{e}$, achieving a statistical significance exceeding\n$10\\sigma$. The absolute branching fraction is measured to be\n$(3.57\\pm0.34_{\\mathrm{stat.}}\\pm0.14_{\\mathrm{syst.}})\\times 10^{-3}$. For the\nfirst time, the CKM matrix element $\\left|V_{cd}\\right|$ is extracted via a\ncharmed baryon decay as $0.208\\pm0.011_{\\rm exp.}\\pm0.007_{\\rm\nLQCD}\\pm0.001_{\\tau_{\\Lambda_c^+}}$. This work highlights a new approach to\nfurther understand fundamental interactions in the charmed baryon sector, and\nshowcases the power of modern machine learning techniques in experimental\nhigh-energy physics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13515v2",
    "published": "2024-10-17T13:03:54+00:00",
    "categories": [
      "hep-ex",
      "hep-lat",
      "hep-ph",
      "nucl-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2410.13514v2",
    "title": "GraphSCENE: On-Demand Critical Scenario Generation for Autonomous Vehicles in Simulation",
    "authors": [
      "Efimia Panagiotaki",
      "Georgi Pramatarov",
      "Lars Kunze",
      "Daniele De Martini"
    ],
    "abstract": "Testing and validating Autonomous Vehicle (AV) performance in safety-critical\nand diverse scenarios is crucial before real-world deployment. However,\nmanually creating such scenarios in simulation remains a significant and\ntime-consuming challenge. This work introduces a novel method that generates\ndynamic temporal scene graphs corresponding to diverse traffic scenarios,\non-demand, tailored to user-defined preferences, such as AV actions, sets of\ndynamic agents, and criticality levels. A temporal Graph Neural Network (GNN)\nmodel learns to predict relationships between ego-vehicle, agents, and static\nstructures, guided by real-world spatiotemporal interaction patterns and\nconstrained by an ontology that restricts predictions to semantically valid\nlinks. Our model consistently outperforms the baselines in accurately\ngenerating links corresponding to the requested scenarios. We render the\npredicted scenarios in simulation to further demonstrate their effectiveness as\ntesting environments for AV agents.",
    "pdf_url": "http://arxiv.org/pdf/2410.13514v2",
    "published": "2024-10-17T13:02:06+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13513v1",
    "title": "Geometry-influenced cooling performance of lithium-ion battery",
    "authors": [
      "Dwijendra Dubey",
      "A. Mishra",
      "Subrata Ghosh",
      "M. V. Reddy",
      "Ramesh Pandey"
    ],
    "abstract": "Battery geometry (shape and size) is one of the important parameters which\ngoverns the battery capacity and thermal behavior. In the dynamic conditions or\nduring the operation, the performance of batteries become much more complex.\nHerein, the changes in thermal behavior of lithium-ion battery (LIB)by altering\nthe geometry i.e., length to diameter ratio (l/d), is investigated. The\ngeometries considered are named as large geometry (LG), datum geometry (DG) and\nsmall geometry (SG) with the l/d ratio of 5.25, 3.61, and 2.38, respectively. A\nthree-dimensional (3D) multi-partition thermal model is adopted, and the\nnumerical results are validated by the published experimental data. For three\ndifferent cooling approaches such as radial, both-tab and mixed cooling, the\naverage battery temperature and temperature heterogeneity are thoroughly\nexamined considering the heat transfer coefficients (h) of50 and 100 W/m2K at\ndischarge rates of 1, 2 and 3C. Amongst, the minimum average battery\ntemperature is exhibited by DG, the minimum radial temperature heterogeneity is\nobtained from LG, and substantial outperformance in terms of faster cooling\nrate is identified for SG, irrespective of the cooling approach employed",
    "pdf_url": "http://arxiv.org/pdf/2410.13513v1",
    "published": "2024-10-17T13:01:02+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13512v1",
    "title": "A Proposal for Uncovering Hidden Social Bots via Genetic Similarity",
    "authors": [
      "Edoardo Allegrini",
      "Edoardo Di Paolo",
      "Marinella Petrocchi",
      "Angelo Spognardi"
    ],
    "abstract": "Social media platforms face an ongoing challenge in combating the\nproliferation of social bots, automated accounts that are also known to distort\npublic opinion and support the spread of disinformation. Over the years, social\nbots have evolved greatly, often becoming indistinguishable from real users,\nand more recently, families of bots have been identified that are powered by\nLarge Language Models to produce content for posting. We suggest an idea to\nclassify social users as bots or not using genetic similarity algorithms. These\nalgorithms provide an adaptive method for analyzing user behavior, allowing for\nthe continuous evolution of detection criteria in response to the ever-changing\ntactics of social bots. Our proposal involves an initial clustering of social\nusers into distinct macro species based on the similarities of their timelines.\nMacro species are then classified as either bot or genuine based on genetic\ncharacteristics. The preliminary idea we present, once fully developed, will\nallow existing detection applications based on timeline equality alone to be\nextended to detect bots. By incorporating new metrics, our approach will\nsystematically classify non-trivial accounts into appropriate categories,\neffectively peeling back layers to reveal non-obvious species.",
    "pdf_url": "http://arxiv.org/pdf/2410.13512v1",
    "published": "2024-10-17T13:01:00+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13511v2",
    "title": "Friezes from surfaces and Farey triangulation",
    "authors": [
      "Anna Felikson",
      "Pavel Tumarkin"
    ],
    "abstract": "We provide a classification of positive integral friezes on marked bordered\nsurfaces. The classification is similar to the Conway--Coxeter's one: positive\nintegral friezes are in one-to-one correspondence with ideal triangulations\nsupplied with a collection of rescaling constants assigned to punctures. For\nevery triangulation the set of the collections of constants is finite and is\ncompletely determined by the valencies of vertices in the triangulation. In\nparticular, it follows that the number of non-equivalent friezes on bordered\nsurfaces is finite, and all friezes on unpunctured surfaces are unitary.",
    "pdf_url": "http://arxiv.org/pdf/2410.13511v2",
    "published": "2024-10-17T12:59:20+00:00",
    "categories": [
      "math.CO",
      "math.GT",
      "math.RA",
      "13F60, 32G15, 05E10"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13510v1",
    "title": "GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models",
    "authors": [
      "Aditya Sharma",
      "Aman Dalmia",
      "Mehran Kazemi",
      "Amal Zouaq",
      "Christopher J. Pal"
    ],
    "abstract": "Geometry problem-solving demands advanced reasoning abilities to process\nmultimodal inputs and employ mathematical knowledge effectively.\nVision-language models (VLMs) have made significant progress in various\nmultimodal tasks. Yet, they still struggle with geometry problems and are\nsignificantly limited by their inability to perform mathematical operations not\nseen during pre-training, such as calculating the cosine of an arbitrary angle,\nand by difficulties in correctly applying relevant geometry formulas. To\novercome these challenges, we present GeoCoder, which leverages modular\ncode-finetuning to generate and execute code using a predefined geometry\nfunction library. By executing the code, we achieve accurate and deterministic\ncalculations, contrasting the stochastic nature of autoregressive token\nprediction, while the function library minimizes errors in formula usage. We\nalso propose a multimodal retrieval-augmented variant of GeoCoder, named\nRAG-GeoCoder, which incorporates a non-parametric memory module for retrieving\nfunctions from the geometry library, thereby reducing reliance on parametric\nmemory. Our modular code-finetuning approach enhances the geometric reasoning\ncapabilities of VLMs, yielding an average improvement of over 16% across\nvarious question complexities on the GeomVerse dataset compared to other\nfinetuning methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13510v1",
    "published": "2024-10-17T12:56:52+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.19810v1",
    "title": "Training Compute-Optimal Vision Transformers for Brain Encoding",
    "authors": [
      "Sana Ahmadi",
      "Francois Paugam",
      "Tristan Glatard",
      "Pierre Lune Bellec"
    ],
    "abstract": "The optimal training of a vision transformer for brain encoding depends on\nthree factors: model size, data size, and computational resources. This study\ninvestigates these three pillars, focusing on the effects of data scaling,\nmodel scaling, and high-performance computing on brain encoding results. Using\nVideoGPT to extract efficient spatiotemporal features from videos and training\na Ridge model to predict brain activity based on these features, we conducted\nbenchmark experiments with varying data sizes (10k, 100k, 1M, 6M) and different\nmodel configurations of GPT-2, including hidden layer dimensions, number of\nlayers, and number of attention heads. We also evaluated the effects of\ntraining models with 32-bit vs 16-bit floating point representations. Our\nresults demonstrate that increasing the hidden layer dimensions significantly\nimproves brain encoding performance, as evidenced by higher Pearson correlation\ncoefficients across all subjects. In contrast, the number of attention heads\ndoes not have a significant effect on the encoding results. Additionally,\nincreasing the number of layers shows some improvement in brain encoding\ncorrelations, but the trend is not as consistent as that observed with hidden\nlayer dimensions. The data scaling results show that larger training datasets\nlead to improved brain encoding performance, with the highest Pearson\ncorrelation coefficients observed for the largest dataset size (6M). These\nfindings highlight that the effects of data scaling are more significant\ncompared to model scaling in enhancing brain encoding performance. Furthermore,\nwe explored the impact of floating-point precision by comparing 32-bit and\n16-bit representations. Training with 16-bit precision yielded the same brain\nencoding accuracy as 32-bit, while reducing training time by 1.17 times,\ndemonstrating its efficiency for high-performance computing tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.19810v1",
    "published": "2024-10-17T12:54:50+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13509v2",
    "title": "RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards",
    "authors": [
      "Xinze Li",
      "Sen Mei",
      "Zhenghao Liu",
      "Yukun Yan",
      "Shuo Wang",
      "Shi Yu",
      "Zheni Zeng",
      "Hao Chen",
      "Ge Yu",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Chenyan Xiong"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has proven its effectiveness in\nmitigating hallucinations in Large Language Models (LLMs) by retrieving\nknowledge from external resources. To adapt LLMs for the RAG systems, current\napproaches use instruction tuning to optimize LLMs, improving their ability to\nutilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses\non equipping LLMs to handle diverse RAG tasks using different instructions.\nHowever, it trains RAG modules to overfit training signals and overlooks the\nvarying data preferences among agents within the RAG system. In this paper, we\npropose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG\nsystems by aligning data preferences between different RAG modules. DDR works\nby collecting the rewards to optimize each agent in the RAG system with the\nrollout method, which prompts agents to sample some potential responses as\nperturbations, evaluates the impact of these perturbations on the whole RAG\nsystem, and subsequently optimizes the agent to produce outputs that improve\nthe performance of the RAG system. Our experiments on various\nknowledge-intensive tasks demonstrate that DDR significantly outperforms the\nSFT method, particularly for LLMs with smaller-scale parameters that depend\nmore on the retrieved knowledge. Additionally, DDR exhibits a stronger\ncapability to align the data preference between RAG modules. The DDR method\nmakes the generation module more effective in extracting key information from\ndocuments and mitigating conflicts between parametric memory and external\nknowledge. All codes are available at https://github.com/OpenMatch/RAG-DDR.",
    "pdf_url": "http://arxiv.org/pdf/2410.13509v2",
    "published": "2024-10-17T12:53:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13508v1",
    "title": "Formalizing Hyperspaces and Operations on Subsets of Polish spaces over Abstract Exact Real Numbers",
    "authors": [
      "Michal Konečný",
      "Sewon Park",
      "Holger Thies"
    ],
    "abstract": "Building on our prior work on axiomatization of exact real computation by\nformalizing nondeterministic first-order partial computations over real and\ncomplex numbers in a constructive dependent type theory, we present a framework\nfor certified computation on hyperspaces of subsets by formalizing various\nhigher-order data types and operations. We first define open, closed, compact\nand overt subsets for generic spaces in an abstract topological way that allows\nshort and elegant proofs with computational content coinciding with standard\ndefinitions in computable analysis and constructive mathematics. From these\nproofs we can extract programs for testing inclusion, overlapping of sets, et\ncetera. To enhance the efficiency of the extracted programs, we then focus on\nPolish spaces, where we give more efficient encodings based on metric\nproperties of the space. As various computational properties depend on the\ncontinuity of the encoding functions, we introduce a nondeterministic version\nof a continuity principle which is natural in our formalization and valid under\nthe standard type-2 realizability interpretation. Using this principle we\nfurther derive the computational equivalence between the generic and the metric\nencodings. Our theory is fully implemented in the Coq proof assistant. From\nproofs in this Coq formalization, we can extract certified programs for\nerror-free operations on subsets. As an application, we provide a function that\nconstructs fractals in Euclidean space, such as the Sierpinski triangle, from\niterated function systems using the limit operation. The resulting programs can\nbe used to draw such fractals up to any desired resolution.",
    "pdf_url": "http://arxiv.org/pdf/2410.13508v1",
    "published": "2024-10-17T12:52:54+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13507v2",
    "title": "Non-commutative friezes and their determinants, the non-commutative Laurent phenomenon for weak friezes, and frieze gluing",
    "authors": [
      "Michael Cuntz",
      "Thorsten Holm",
      "Peter Jorgensen"
    ],
    "abstract": "This paper studies a non-commutative generalisation of Coxeter friezes due to\nBerenstein and Retakh. It generalises several earlier results to this\nsituation: A formula for frieze determinants, a $T$-path formula expressing the\nLaurent phenomenon, and results on gluing friezes together. One of our tools is\na non-commutative version of the weak friezes introduced by Canakci and\nJorgensen.",
    "pdf_url": "http://arxiv.org/pdf/2410.13507v2",
    "published": "2024-10-17T12:51:56+00:00",
    "categories": [
      "math.CO",
      "05E99, 13F60, 51M20"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13506v1",
    "title": "Development of a New Type of Vortex Bladeless Wind Turbine for Urban Energy Systems",
    "authors": [
      "Dongkun Han",
      "Shihan Huang",
      "Pak Kei Abia Hui",
      "Yue Chen"
    ],
    "abstract": "Innovation and development of renewable energy devices are crucial for\nreaching a sustainable and environmentally conscious future. This work focuses\non the development of a new type of renewable energy devices in the context of\nSmart Garden at the Chinese University of Hong Kong, which aims to design a\nbladeless wind turbine for urban areas, addressing the pressing need for clean\nenergy locally and globally. Traditional wind turbines have been widely adopted\nin recent decades, while bladeless wind turbines have also displayed their\nadvantages and uniqueness in urban areas. A Vortex Bladeless Wind Turbine\n(VBWT) is modeled by using Fusion 360 to optimize wind energy generation in\nurban settings with limited space and buildings-dominated landscape. Optimal\nparameters of the VBWT were obtained by comparing the results of drag force,\nlift force and deflection, via the simulations in Ansys. Hardware of proposed\nbladeless wind turbine has been assembled and developed by 3-dimensional\nprinting. Additional tests and adjustments on hardware further improve the\nperformance of the developed wind turbine. The outcomes of this work have the\npotential to contribute to future renewable energy initiatives and devote the\nsustainability efforts in urban energy systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13506v1",
    "published": "2024-10-17T12:51:11+00:00",
    "categories": [
      "cs.CE",
      "00-02"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13505v1",
    "title": "Microsphere-assisted generation of localized optical emitters in 2D hexagonal boron nitride",
    "authors": [
      "Xiliang Yang",
      "Dong Hoon Shin",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Peter G. Steeneken",
      "Sabina Caneva"
    ],
    "abstract": "Crystal defects in hexagonal boron nitride (hBN) are emerging as versatile\nnanoscale optical probes with a wide application profile, spanning the fields\nof nanophotonics, biosensing, bioimaging and quantum information processing.\nHowever, generating these crystal defects as reliable optical emitters remains\nchallenging due to the need for deterministic defect placement and precise\ncontrol of the emission area. Here, we demonstrate an approach that integrates\nmicrospheres (MS) with hBN optical probes to enhance both defect generation and\noptical signal readout. This technique harnesses MS to amplify light-matter\ninteractions at the nanoscale through 2 two mechanisms: focused femtosecond\n(fs) laser irradiation into a photonic nanojet for highly localized defect\ngeneration, and enhanced light collection via the whispering gallery mode\neffect. Our MS-assisted defect generation method reduces the emission area by a\nfactor of 5 and increases the fluorescence collection efficiency by\napproximately 10 times compared to MS-free samples. These advancements in\ndefect generation precision and signal collection efficiency open new\npossibilities for optical emitter manipulation in hBN, with potential\napplications in quantum technologies and nanoscale sensing.",
    "pdf_url": "http://arxiv.org/pdf/2410.13505v1",
    "published": "2024-10-17T12:50:59+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13504v2",
    "title": "Local Intertwining Relations and Co-tempered $A$-packets of Classical Groups",
    "authors": [
      "Hiraku Atobe",
      "Wee Teck Gan",
      "Atsushi Ichino",
      "Tasho Kaletha",
      "Alberto Mínguez",
      "Sug Woo Shin"
    ],
    "abstract": "The local intertwining relation is an identity that gives precise information\nabout the action of normalized intertwining operators on parabolically induced\nrepresentations. We prove several instances of the local intertwining relation\nfor quasi-split classical groups and the twisted general linear group, as they\nare required in the inductive proof of the endoscopic classification for\nquasi-split classical groups due to Arthur and Mok. In addition, we construct\nthe co-tempered local $A$-packets by Aubert duality and verify their key\nproperties by purely local means, which provide the seed cases needed as an\ninput to the inductive proof. Together with further technical results that we\nestablish, this makes the endoscopic classification conditional only on the\nvalidity of the twisted weighted fundamental lemma.",
    "pdf_url": "http://arxiv.org/pdf/2410.13504v2",
    "published": "2024-10-17T12:49:57+00:00",
    "categories": [
      "math.NT",
      "math.RT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13503v1",
    "title": "NePHIM: A Neural Physics-Based Head-Hand Interaction Model",
    "authors": [
      "Nicolas Wagner",
      "Mario Botsch",
      "Ulrich Schwanecke"
    ],
    "abstract": "Due to the increasing use of virtual avatars, the animation of head-hand\ninteractions has recently gained attention. To this end, we present a novel\nvolumetric and physics-based interaction simulation. In contrast to previous\nwork, our simulation incorporates temporal effects such as collision paths,\nrespects anatomical constraints, and can detect and simulate skin pulling. As a\nresult, we can achieve more natural-looking interaction animations and take a\nstep towards greater realism. However, like most complex and computationally\nexpensive simulations, ours is not real-time capable even on high-end machines.\nTherefore, we train small and efficient neural networks as accurate\napproximations that achieve about 200 FPS on consumer GPUs, about 50 FPS on\nCPUs, and are learned in less than four hours for one person. In general, our\nfocus is not to generalize the approximation networks to low-resolution head\nmodels but to adapt them to more detailed personalized avatars. Nevertheless,\nwe show that these networks can learn to approximate our head-hand interaction\nmodel for multiple identities while maintaining computational efficiency.\n  Since the quality of the simulations can only be judged subjectively, we\nconducted a comprehensive user study which confirms the improved realism of our\napproach. In addition, we provide extensive visual results and inspect the\nneural approximations quantitatively. All data used in this work has been\nrecorded with a multi--view camera rig and will be made available upon\npublication. We will also publish relevant implementations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13503v1",
    "published": "2024-10-17T12:48:39+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13502v3",
    "title": "MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs",
    "authors": [
      "Andreas Opedal",
      "Haruki Shirakami",
      "Bernhard Schölkopf",
      "Abulhair Saparov",
      "Mrinmaya Sachan"
    ],
    "abstract": "Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to more complex\nproblems. This is difficult to study, as (i) much of the available evaluation\ndata has already been seen by the most capable models during training, and (ii)\nexisting benchmarks do not capture how problem proofs may be arbitrarily\ncomplex in various ways. In this paper, we present a data-generation framework\nfor evaluating LLMs on problems with arbitrarily complex arithmetic proofs,\ncalled MathGAP. MathGAP generates problem statements and chain-of-thought\nreasoning traces according to specifications about their arithmetic proof\nstructure, enabling systematic studies on easy-to-hard generalization with\nrespect to complexity of proof trees. Using MathGAP, we find that LLMs show a\nsignificant decrease in performance as proofs get deeper and wider. This effect\nis more pronounced in complex, nonlinear proof structures, which are\nchallenging even for the most capable models. The models are also sensitive to\nsimple changes in sentence ordering. However, they remain capable of solving\nsome complex problems, suggesting that reasoning generalization is noisy.",
    "pdf_url": "http://arxiv.org/pdf/2410.13502v3",
    "published": "2024-10-17T12:48:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13501v1",
    "title": "Integrating Large Language Models and Reinforcement Learning for Non-Linear Reasoning",
    "authors": [
      "Yoav Alon",
      "Cristina David"
    ],
    "abstract": "Large Language Models (LLMs) were shown to struggle with long-term planning,\nwhich may be caused by the limited way in which they explore the space of\npossible solutions. We propose an architecture where a Reinforcement Learning\n(RL) Agent guides an LLM's space exploration: (1) the Agent has access to\ndomain-specific information, and can therefore make decisions about the quality\nof candidate solutions based on specific and relevant metrics, which were not\nexplicitly considered by the LLM's training objective; (2) the LLM can focus on\ngenerating immediate next steps, without the need for long-term planning. We\nallow non-linear reasoning by exploring alternative paths and backtracking. We\nevaluate this architecture on the program equivalence task, and compare it\nagainst Chain of Thought (CoT) and Tree of Thoughts (ToT). We assess both the\ndownstream task, denoting the binary classification, and the intermediate\nreasoning steps. Our approach compares positively against CoT and ToT.",
    "pdf_url": "http://arxiv.org/pdf/2410.13501v1",
    "published": "2024-10-17T12:47:31+00:00",
    "categories": [
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13500v1",
    "title": "SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote Sensing Image Data",
    "authors": [
      "Dominik Hirner",
      "Friedrich Fraundorfer"
    ],
    "abstract": "Stereo estimation has made many advancements in recent years with the\nintroduction of deep-learning. However the traditional supervised approach to\ndeep-learning requires the creation of accurate and plentiful ground-truth\ndata, which is expensive to create and not available in many situations. This\nis especially true for remote sensing applications, where there is an excess of\navailable data without proper ground truth. To tackle this problem, we propose\na self-supervised CNN with self-improving adaptive abilities. In the first\niteration, the created disparity map is inaccurate and noisy. Leveraging the\nleft-right consistency check, we get a sparse but more accurate disparity map\nwhich is used as an initial pseudo ground-truth. This pseudo ground-truth is\nthen adapted and updated after every epoch in the training step of the network.\nWe use the sum of inconsistent points in order to track the network\nconvergence. The code for our method is publicly available at:\nhttps://github.com/thedodo/SAda-Net}{https://github.com/thedodo/SAda-Net",
    "pdf_url": "http://arxiv.org/pdf/2410.13500v1",
    "published": "2024-10-17T12:46:26+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13499v1",
    "title": "Super-activating quantum memory by entanglement-breaking channels",
    "authors": [
      "Gelo Noel M. Tabia",
      "Chung-Yun Hsieh"
    ],
    "abstract": "Entanglement is an essential resource for various quantum-information tasks.\nWhen a target system shares entanglement with another memory system and is\nstored reliably, one can use entanglement at a later time -- this is quantum\nmemory. In practice, entanglement can be exceedingly fragile during a system's\nevolution. In particular, no entanglement can survive when a so-called\nentanglement-breaking channel acts on the target system. Are\nentanglement-breaking channels really useless for maintaining entanglement? As\na single channel, this is certainly the case; it cannot be useful for quantum\nmemory. However, in this work, we show that putting together two\nentanglement-breaking channels in a broadcasting scenario can activate their\nability to maintain entanglement -- the channel's quantum memory resource can\nbe super-activated.",
    "pdf_url": "http://arxiv.org/pdf/2410.13499v1",
    "published": "2024-10-17T12:45:25+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13498v2",
    "title": "Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum Learning, Semi-Supervised Training, and Advanced Optimization Techniques",
    "authors": [
      "Rahimanuddin Shaik",
      "Katikela Sreeharsha Kishore"
    ],
    "abstract": "Text generation is the automated process of producing written or spoken\nlanguage using computational methods. It involves generating coherent and\ncontextually relevant text based on predefined rules or learned patterns.\nHowever, challenges in text generation arise from maintaining coherence,\nensuring diversity and creativity, and avoiding biases or inappropriate\ncontent. This research paper developed a novel approach to improve text\ngeneration in the context of joint Natural Language Generation (NLG) and\nNatural Language Understanding (NLU) learning. The data is prepared by\ngathering and preprocessing annotated datasets, including cleaning,\ntokenization, stemming, and stop-word removal. Feature extraction techniques\nsuch as POS tagging, Bag of words, and Term Frequency-Inverse Document\nFrequency (TF-IDF) are applied. Transformer-based encoders and decoders,\ncapturing long range dependencies and improving source-target sequence\nmodelling. Pre-trained language models like Optimized BERT are incorporated,\nalong with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).\nReinforcement learning with policy gradient techniques, semi-supervised\ntraining, improved attention mechanisms, and differentiable approximations like\nstraight-through Gumbel SoftMax estimator are employed to fine-tune the models\nand handle complex linguistic tasks effectively. The proposed model is\nimplemented using Python.",
    "pdf_url": "http://arxiv.org/pdf/2410.13498v2",
    "published": "2024-10-17T12:43:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13497v2",
    "title": "Repetition Neurons: How Do Language Models Produce Repetitions?",
    "authors": [
      "Tatsuya Hiraoka",
      "Kentaro Inui"
    ],
    "abstract": "This paper introduces repetition neurons, regarded as skill neurons\nresponsible for the repetition problem in text generation tasks. These neurons\nare progressively activated more strongly as repetition continues, indicating\nthat they perceive repetition as a task to copy the previous context\nrepeatedly, similar to in-context learning. We identify these repetition\nneurons by comparing activation values before and after the onset of repetition\nin texts generated by recent pre-trained language models. We analyze the\nrepetition neurons in three English and one Japanese pre-trained language\nmodels and observe similar patterns across them.",
    "pdf_url": "http://arxiv.org/pdf/2410.13497v2",
    "published": "2024-10-17T12:43:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13496v1",
    "title": "State Estimation Transformers for Agile Legged Locomotion",
    "authors": [
      "Chen Yu",
      "Yichu Yang",
      "Tianlin Liu",
      "Yangwei You",
      "Mingliang Zhou",
      "Diyun Xiang"
    ],
    "abstract": "We propose a state estimation method that can accurately predict the robot's\nprivileged states to push the limits of quadruped robots in executing advanced\nskills such as jumping in the wild. In particular, we present the State\nEstimation Transformers (SET), an architecture that casts the state estimation\nproblem as conditional sequence modeling. SET outputs the robot states that are\nhard to obtain directly in the real world, such as the body height and\nvelocities, by leveraging a causally masked Transformer. By conditioning an\nautoregressive model on the robot's past states, our SET model can predict\nthese privileged observations accurately even in highly dynamic locomotions. We\nevaluate our methods on three tasks -- running jumping, running backflipping,\nand running sideslipping -- on a low-cost quadruped robot, Cyberdog2. Results\nshow that SET can outperform other methods in estimation accuracy and\ntransferability in the simulation as well as success rates of jumping and\ntriggering a recovery controller in the real world, suggesting the superiority\nof such a Transformer-based explicit state estimator in highly dynamic\nlocomotion tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13496v1",
    "published": "2024-10-17T12:43:14+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13922v1",
    "title": "Oscillatory equilibrium in asymmetric evolutionary games: Generalizing evolutionarily stable strategy",
    "authors": [
      "Vikash Kumar Dubey",
      "Suman Chakraborty",
      "Sagar Chakraborty"
    ],
    "abstract": "The concept of evolutionarily stability and its relation with the fixed\npoints of the replicator equation are important aspects of evolutionary game\ndynamics. In the light of the fact that oscillating state of a population and\nindividuals (or players) of different roles are quite natural occurrences, we\nask the question how the concept of evolutionarily stability can be generalized\nso as to associate game-theoretic meaning to oscillatory behaviours of players\nasymmetrically interacting, i.e., if there are both intraspecific and\ninterspecific interactions between two subpopulations in the population. We\nguide our scheme of generalization such that the evolutionary stability is\nrelated to the dynamic stability of the corresponding periodic orbits of a\ntime-discrete replicator dynamics. We name the generalization of evolutionarily\nstable state as two-species heterogeneity stable orbit. Furthermore, we invoke\nthe principle of decrease of relative entropy in order to associate the\ngeneralization of evolutionary stability with an information-theoretic meaning.\nThis particular generalization is aptly termed as two-species information\nstable orbit.",
    "pdf_url": "http://arxiv.org/pdf/2410.13922v1",
    "published": "2024-10-17T12:41:20+00:00",
    "categories": [
      "q-bio.PE",
      "nlin.AO"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13495v1",
    "title": "On uniqueness of the set of k-means",
    "authors": [
      "Javier Cárcamo",
      "Antonio Cuevas",
      "Luis A. Rodríguez"
    ],
    "abstract": "We provide necessary and sufficient conditions for the uniqueness of the\nk-means set of a probability distribution. This uniqueness problem is related\nto the choice of k: depending on the underlying distribution, some values of\nthis parameter could lead to multiple sets of k-means, which hampers the\ninterpretation of the results and/or the stability of the algorithms. We give a\ngeneral assessment on consistency of the empirical k-means adapted to the\nsetting of non-uniqueness and determine the asymptotic distribution of the\nwithin cluster sum of squares (WCSS). We also provide statistical\ncharacterizations of k-means uniqueness in terms of the asymptotic behavior of\nthe empirical WCSS. As a consequence, we derive a bootstrap test for uniqueness\nof the set of k-means. The results are illustrated with examples of different\ntypes of non-uniqueness and we check by simulations the performance of the\nproposed methodology.",
    "pdf_url": "http://arxiv.org/pdf/2410.13495v1",
    "published": "2024-10-17T12:40:56+00:00",
    "categories": [
      "math.ST",
      "stat.ME",
      "stat.ML",
      "stat.TH",
      "62H30, 62E20 (primary), 62G20 (secondary)"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2410.13494v1",
    "title": "Analyzing the acceleration time and reflectance of light sails made from homogeneous and core-shell spheres",
    "authors": [
      "Mitchell R. Whittam",
      "Lukas Rebholz",
      "Benedikt Zerulla",
      "Carsten Rockstuhl"
    ],
    "abstract": "Deciding on appropriate materials and designs for use in light sails, like\nthe one proposed in the Breakthrough Starshot Initiative, is a topic that\nrequires much care and forethought. Here, we offer a feasible option in the\nform of metasurfaces made of periodically arranged homogeneous and core-shell\nspheres. Using the re-normalized T-matrix from Mie theory, we explore the\nreflectance, absorptance, and acceleration time of such metasurfaces. We focus\non spheres made from aluminum, silicon, silicon dioxide, and combinations\nthereof. Since the light sails are foreseen to be accelerated using Earth-based\nlaser arrays to 20% of the speed of light, one needs to account for\nrelativistic effects. As a result, a high broadband reflectance is essential\nfor effective propulsion. We identify metasurfaces that offer such properties\ncombined with a low absorptance to reduce heating and deformation. We highlight\na promising extension to the case of a metasurface made from homogeneous\nsilicon spheres, as already discussed in the literature, by adding a layer of\nsilicon dioxide. The high broadband reflectance of the silicon and silicon\ndioxide combination is explained by the favorable interference of the\nmultipolar contributions of the outgoing field up to quadrupolar order. We also\nconsider the impact of an embedding material characterized by different\nrefractive indices. Refractive indices up to 1.13 maintain over 90% reflectance\nwithout re-optimizing the light sail.",
    "pdf_url": "http://arxiv.org/pdf/2410.13494v1",
    "published": "2024-10-17T12:38:22+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13493v1",
    "title": "Deep Reinforcement Learning for Online Optimal Execution Strategies",
    "authors": [
      "Alessandro Micheli",
      "Mélodie Monod"
    ],
    "abstract": "This paper tackles the challenge of learning non-Markovian optimal execution\nstrategies in dynamic financial markets. We introduce a novel actor-critic\nalgorithm based on Deep Deterministic Policy Gradient (DDPG) to address this\nissue, with a focus on transient price impact modeled by a general decay\nkernel. Through numerical experiments with various decay kernels, we show that\nour algorithm successfully approximates the optimal execution strategy.\nAdditionally, the proposed algorithm demonstrates adaptability to evolving\nmarket conditions, where parameters fluctuate over time. Our findings also show\nthat modern reinforcement learning algorithms can provide a solution that\nreduces the need for frequent and inefficient human intervention in optimal\nexecution tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13493v1",
    "published": "2024-10-17T12:38:08+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13492v2",
    "title": "Recovery of contour nodes in interdependent directed networks",
    "authors": [
      "Ignacio A. Perez",
      "Cristian E. La Rocca"
    ],
    "abstract": "Extensive research has focused on studying the robustness of interdependent\nnon-directed networks and the design of mitigation strategies aimed at reducing\ndisruptions caused by cascading failures. However, real systems such as power\nand communication networks are directed, which underscores the necessity of\nbroadening the analysis by including directed networks. In this work, we\ndevelop an analytical framework to study a recovery strategy in two\ninterdependent directed networks in which a fraction $q$ of nodes in each\nnetwork have single dependencies with nodes in the other network. Following the\nrandom failure of nodes that leaves a fraction $p$ intact, we repair a fraction\nof nodes that are neighbors of the giant strongly connected component of each\nnetwork with probability or recovery success rate $\\gamma$. Our analysis\nreveals an abrupt transition between total system collapse and complete\nrecovery as $p$ is increased. As a consequence, we identify three distinct\nphases in the $(p, \\gamma)$ parameter space: collapse despite intervention,\nrecovery enabled by the strategy, and resilience without intervention.\nMoreover, we demonstrate our strategy on a system built from empirical data and\nfind that it can save resources compared to a random recovery strategy. Our\nfindings underscore the potential of targeted recovery strategies to enhance\nthe robustness of real interdependent directed networks against cascading\nfailures.",
    "pdf_url": "http://arxiv.org/pdf/2410.13492v2",
    "published": "2024-10-17T12:38:02+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13491v2",
    "title": "Progenitor diversity in the accreted stellar halos of Milky Way-like galaxies",
    "authors": [
      "Sy-Yun Pu",
      "Andrew P. Cooper",
      "Robert J. J. Grand",
      "Facundo A. Gómez",
      "Antonela Monachesi"
    ],
    "abstract": "Ongoing large stellar spectroscopic surveys of the Milky Way seek to\nreconstruct the major events in the assembly history of the Galaxy. Chemical\nand kinematic observations can be used to separate the contributions of\ndifferent progenitor galaxies to the present-day stellar halo. Here we compute\nthe number of progenitors that contribute to the accreted stellar halos of\nsimulated Milky Way-like galaxies as a function of radius (the radial\ndiversity) in three suites of models: Bullock & Johnston, Aquarius and Auriga.\nWe show that there are significant differences between the predictions of these\nthree models, beyond the halo-to-halo scatter expected in $\\Lambda$CDM.\nPredictions of diversity from numerical simulations are sensitive to\nmodel-dependent assumptions regarding the efficiency of star formation in dwarf\ngalaxies. We compare, at face value, to current constraints on the radial\ndiversity of the Milky Way's accreted halo. These constraints imply that the\nhalo of our Galaxy is dominated by $\\sim2$ progenitors in the range\n$8-45\\,\\mathrm{kpc}$, in contrast to averages of $7$ progenitors in the Bullock\n& Johnston models, $3.5$ in Aquarius and $4.2$ in Auriga over the same region.\nWe additionally find that the models with radial diversity most similar to that\nof the Milky Way are predominantly those with ongoing merger events. The Milky\nWay therefore appears unusual in having an accreted stellar halo dominated by a\nsmall number of progenitors accreted at very early times.",
    "pdf_url": "http://arxiv.org/pdf/2410.13491v2",
    "published": "2024-10-17T12:35:45+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13490v1",
    "title": "Novelty-based Sample Reuse for Continuous Robotics Control",
    "authors": [
      "Ke Duan",
      "Kai Yang",
      "Houde Liu",
      "Xueqian Wang"
    ],
    "abstract": "In reinforcement learning, agents collect state information and rewards\nthrough environmental interactions, essential for policy refinement. This\nprocess is notably time-consuming, especially in complex robotic simulations\nand real-world applications. Traditional algorithms usually re-engage with the\nenvironment after processing a single batch of samples, thereby failing to\nfully capitalize on historical data. However, frequently observed states, with\nreliable value estimates, require minimal updates; in contrast, rare observed\nstates necessitate more intensive updates for achieving accurate value\nestimations. To address uneven sample utilization, we propose Novelty-guided\nSample Reuse (NSR). NSR provides extra updates for infrequent, novel states and\nskips additional updates for frequent states, maximizing sample use before\ninteracting with the environment again. Our experiments show that NSR improves\nthe convergence rate and success rate of algorithms without significantly\nincreasing time consumption. Our code is publicly available at\nhttps://github.com/ppksigs/NSR-DDPG-HER.",
    "pdf_url": "http://arxiv.org/pdf/2410.13490v1",
    "published": "2024-10-17T12:34:37+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13489v2",
    "title": "Breaking Bad: How Compilers Break Constant-Time Implementations",
    "authors": [
      "Moritz Schneider",
      "Daniele Lain",
      "Ivan Puddu",
      "Nicolas Dutly",
      "Srdjan Capkun"
    ],
    "abstract": "The implementations of most hardened cryptographic libraries use defensive\nprogramming techniques for side-channel resistance. These techniques are\nusually specified as guidelines to developers on specific code patterns to use\nor avoid. Examples include performing arithmetic operations to choose between\ntwo variables instead of executing a secret-dependent branch. However, such\ntechniques are only meaningful if they persist across compilation. In this\npaper, we investigate how optimizations used by modern compilers break the\nprotections introduced by defensive programming techniques. Specifically, how\ncompilers break high-level constant-time implementations used to mitigate\ntiming side-channel attacks. We run a large-scale experiment to see if such\ncompiler-induced issues manifest in state-of-the-art cryptographic libraries.\nWe develop a tool that can profile virtually any architecture, and we use it to\nrun trace-based dynamic analysis on 44,604 different targets. Particularly, we\nfocus on the most widely deployed cryptographic libraries, which aim to provide\nside-channel resistance. We are able to evaluate whether their claims hold\nacross various CPU architectures, including x86-64, x86-i386, armv7, aarch64,\nRISC-V, and MIPS-32. Our large-scale study reveals that several\ncompiler-induced secret-dependent operations occur within some of the most\nhighly regarded hardened cryptographic libraries. To the best of our knowledge,\nsuch findings represent the first time these issues have been observed in the\nwild. One of the key takeaways of this paper is that the state-of-the-art\ndefensive programming techniques employed for side-channel resistance are still\ninadequate, incomplete, and bound to fail when paired with the optimizations\nthat compilers continuously introduce.",
    "pdf_url": "http://arxiv.org/pdf/2410.13489v2",
    "published": "2024-10-17T12:34:02+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13488v1",
    "title": "Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes",
    "authors": [
      "Dibyanayan Bandyopadhyay",
      "Mohammed Hasanuzzaman",
      "Asif Ekbal"
    ],
    "abstract": "Detecting offensive memes is crucial, yet standard deep neural network\nsystems often remain opaque. Various input attribution-based methods attempt to\ninterpret their behavior, but they face challenges with implicitly offensive\nmemes and non-causal attributions. To address these issues, we propose a\nframework based on a Structural Causal Model (SCM). In this framework,\nVisualBERT is trained to predict the class of an input meme based on both meme\ninput and causal concepts, allowing for transparent interpretation. Our\nqualitative evaluation demonstrates the framework's effectiveness in\nunderstanding model behavior, particularly in determining whether the model was\nright due to the right reason, and in identifying reasons behind\nmisclassification. Additionally, quantitative analysis assesses the\nsignificance of proposed modelling choices, such as de-confounding, adversarial\nlearning, and dynamic routing, and compares them with input attribution\nmethods. Surprisingly, we find that input attribution methods do not guarantee\ncausality within our framework, raising questions about their reliability in\nsafety-critical applications. The project page is at:\nhttps://newcodevelop.github.io/causality_adventure/",
    "pdf_url": "http://arxiv.org/pdf/2410.13488v1",
    "published": "2024-10-17T12:32:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13487v1",
    "title": "Automated Reasoning in Systems Biology: a Necessity for Precision Medicine",
    "authors": [
      "Pedro Zuidberg Dos Martires",
      "Vincent Derkinderen",
      "Luc De Raedt",
      "Marcus Krantz"
    ],
    "abstract": "Recent developments in AI have reinvigorated pursuits to advance the (life)\nsciences using AI techniques, thereby creating a renewed opportunity to bridge\ndifferent fields and find synergies. Headlines for AI and the life sciences\nhave been dominated by data-driven techniques, for instance, to solve protein\nfolding with next to no expert knowledge. In contrast to this, we argue for the\nnecessity of a formal representation of expert knowledge - either to develop\nexplicit scientific theories or to compensate for the lack of data.\nSpecifically, we argue that the fields of knowledge representation (KR) and\nsystems biology (SysBio) exhibit important overlaps that have been largely\nignored so far. This, in turn, means that relevant scientific questions are\nready to be answered using the right domain knowledge (SysBio), encoded in the\nright way (SysBio/KR), and by combining it with modern automated reasoning\ntools (KR). Hence, the formal representation of domain knowledge is a natural\nmeeting place for SysBio and KR. On the one hand, we argue that such an\ninterdisciplinary approach will advance the field SysBio by exposing it to\nindustrial-grade reasoning tools and thereby allowing novel scientific\nquestions to be tackled. On the other hand, we see ample opportunities to move\nthe state-of-the-art in KR by tailoring KR methods to the field of SysBio,\nwhich comes with challenging problem characteristics, e.g. scale, partial\nknowledge, noise, or sub-symbolic data. We stipulate that this proposed\ninterdisciplinary research is necessary to attain a prominent long-term goal in\nthe health sciences: precision medicine.",
    "pdf_url": "http://arxiv.org/pdf/2410.13487v1",
    "published": "2024-10-17T12:31:59+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13486v1",
    "title": "SemSim: Revisiting Weak-to-Strong Consistency from a Semantic Similarity Perspective for Semi-supervised Medical Image Segmentation",
    "authors": [
      "Shiao Xie",
      "Hongyi Wang",
      "Ziwei Niu",
      "Hao Sun",
      "Shuyi Ouyang",
      "Yen-Wei Chen",
      "Lanfen Lin"
    ],
    "abstract": "Semi-supervised learning (SSL) for medical image segmentation is a\nchallenging yet highly practical task, which reduces reliance on large-scale\nlabeled dataset by leveraging unlabeled samples. Among SSL techniques, the\nweak-to-strong consistency framework, popularized by FixMatch, has emerged as a\nstate-of-the-art method in classification tasks. Notably, such a simple\npipeline has also shown competitive performance in medical image segmentation.\nHowever, two key limitations still persist, impeding its efficient adaptation:\n(1) the neglect of contextual dependencies results in inconsistent predictions\nfor similar semantic features, leading to incomplete object segmentation; (2)\nthe lack of exploitation of semantic similarity between labeled and unlabeled\ndata induces considerable class-distribution discrepancy. To address these\nlimitations, we propose a novel semi-supervised framework based on FixMatch,\nnamed SemSim, powered by two appealing designs from semantic similarity\nperspective: (1) rectifying pixel-wise prediction by reasoning about the\nintra-image pair-wise affinity map, thus integrating contextual dependencies\nexplicitly into the final prediction; (2) bridging labeled and unlabeled data\nvia a feature querying mechanism for compact class representation learning,\nwhich fully considers cross-image anatomical similarities. As the reliable\nsemantic similarity extraction depends on robust features, we further introduce\nan effective spatial-aware fusion module (SFM) to explore distinctive\ninformation from multiple scales. Extensive experiments show that SemSim yields\nconsistent improvements over the state-of-the-art methods across three public\nsegmentation benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13486v1",
    "published": "2024-10-17T12:31:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13485v2",
    "title": "Lattice thermal conductivity in the anharmonic overdamped regime",
    "authors": [
      "Đorđe Dangić",
      "Giovanni Caldarelli",
      "Raffaello Bianco",
      "Ivana Savić",
      "Ion Errea"
    ],
    "abstract": "In crystalline materials, low lattice thermal conductivity is often\nassociated with strong anharmonicity, which can cause significant deviations\nfrom the expected Lorentzian lineshape of phonon spectral functions. These\ndeviations, occurring in an overdamped regime, raise questions about the\napplicability of the Boltzmann transport equation. Furthermore, strong\nanharmonicity can trigger structural phase transitions with temperature, which\ncannot be adequately described by the standard harmonic approximation. To\naddress these challenges, we propose a novel approach for computing the lattice\nthermal conductivity. Our method combines the Green-Kubo linear response theory\nwith the stochastic self-consistent harmonic approximation. The latter allows\nus to describe the temperature-dependent evolution of the crystal structure,\nincluding first- and second-order phase transitions, as well as the vibrational\nproperties in highly anharmonic materials. The Green-Kubo method considers the\nentire lineshapes of phonon spectral functions in the calculation of the\nlattice thermal conductivity, thus eliminating the questionable use of phonon\nlifetimes in the overdamped regime, as well as naturally including coherent\ntransport effects. Additionally, we extend our theory to model complex\ndynamical lattice thermal conductivity, enhancing our understanding of\ntime-dependent thermoreflectance experiments. As a practical application, we\nemploy this approach to calculate the lattice thermal conductivity of\nCsPbBr$_3$, a complex crystal known for its anomalous thermal transport\nbehavior with a complex phase diagram. Our method is able to determine the\nthermal conductivity across different phases in good agreement with\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13485v2",
    "published": "2024-10-17T12:29:58+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13484v1",
    "title": "Exploring the supernova remnant contribution to the first LHAASO source catalog via passively illuminated interstellar clouds",
    "authors": [
      "A. M. W. Mitchell",
      "S. Celli"
    ],
    "abstract": "Supernova remnants (SNRs) are considered as the most promising source class\nto account for the bulk of the Galactic cosmic-ray flux. Yet amongst the\npopulation of ultra-high energy (UHE) sources that has recently emerged, due to\nhigh-altitude particle detector experiments such as LHAASO and HAWC, remarkably\nfew are associated with known SNRs. These observations might well indicate that\nthe highest energy particles would escape the remnant early during the shock\nevolution as a result of its reduced confinement capabilities. This flux of\nescaping particles may then encounter dense targets (gas and dust) for hadronic\ninteractions in the form of both atomic and molecular material such as\ninterstellar clouds, thereby generating a UHE gamma-ray flux. We explore such a\nscenario here, considering known SNRs in a physically driven model for particle\nescape, and as coupled to molecular clouds in the Galaxy. Our analysis allows\nthe investigation of SNR-illuminated clouds in coincidence with sources\ndetected in the first LHAASO catalogue. Indeed, the illuminated interstellar\nclouds may contribute to the total gamma-ray flux from several unidentified\nsources, as we discuss here. Yet we nevertheless find that further detailed\nstudies will be necessary to verify or refute this scenario of passive UHE\ngamma-ray sources in future.",
    "pdf_url": "http://arxiv.org/pdf/2410.13484v1",
    "published": "2024-10-17T12:28:24+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13483v1",
    "title": "The S$^4$G-WISE View of Global Star Formation in the Nearby Universe",
    "authors": [
      "M. E. Cluver",
      "T. H. Jarrett",
      "D. A. Dale",
      "J. -D. T. Smith",
      "M. J. I. Brown",
      "W. van Kempen",
      "E. Lengerer",
      "R. Incoll",
      "C. Davey",
      "R. Holloway",
      "J. Cameron",
      "K. Sheth"
    ],
    "abstract": "In this work we present source-tailored WISE mid-infrared photometry (at\n3.4$\\mu$m, 4.6$\\mu$m, 12$\\mu$m, and 23$\\mu$m) of 2812 galaxies in the extended\nSpitzer Survey of Stellar Structure in Galaxies (S$^4$G) sample, and\ncharacterise the mid-infrared colors and dust properties of this legacy nearby\ngalaxy data set. Informed by the relative emission between W3 (12$\\mu$ m) and\nW4 (23$\\mu$ m), we re-derive star formation rate (SFR) scaling relations\ncalibrated to L$_{\\rm TIR}$, which results in improved agreement between the\ntwo tracers. By inverse-variance weighting the W3 and W4-derived SFRs, we\ngenerate a combined mid-infrared SFR that is a broadly robust measure of star\nformation activity in dusty, star-forming galaxies in the nearby Universe. In\naddition, we investigate the use of a W3-derived dust density metric,\n$\\Sigma_{\\rm 12\\mu m}$ (L$_\\odot$/kpc$^2$), to estimate the SFR deficit of low\nmass, low dust galaxies. This is achieved by combining WISE with existing GALEX\nultraviolet (UV) photometry, which we further use to explore the relationship\nbetween dust and UV emission as a function of morphology. Finally, we use our\nderived SFR prescriptions to examine the location of galaxies in the log SFR -\nlog M$_\\textrm{stellar}$ plane, as a function of morphological type, which\nunderscores the complexity of dust-derived properties seen in galaxies of\nprogressively earlier type.",
    "pdf_url": "http://arxiv.org/pdf/2410.13483v1",
    "published": "2024-10-17T12:28:07+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2411.00008v2",
    "title": "Growth of Science and Women: Methodological Challenges of Using Structured Big Data",
    "authors": [
      "Marek Kwiek",
      "Lukasz Szymula"
    ],
    "abstract": "In this research, we quantify an inflow of women into science in the past\nthree decades. Structured Big Data allow us to estimate the contribution of\nwomen scientists to the growth of science by disciplines (N = STEMM 14\ndisciplines) and over time (1990-2023). A monolithic segment of STEMM science\nemerges from this research as divided between the disciplines in which the\ngrowth was powerfully driven by women - and the disciplines in which the role\nof women was marginal. There are four disciplines in which 50% of currently\npublishing scientists are women; and five disciplines in which more than 50% of\ncurrently young scientists are women. But there is also a cluster of four\nhighly mathematized disciplines (MATH, COMP, PHYS, and ENG) in which the growth\nof science is only marginally driven by women. Digital traces left by\nscientists in their publications indexed in global datasets open two new\ndimensions in large-scale academic profession studies: time and gender. The\ngrowth of science in Europe was accompanied by growth in the number of women\nscientists, but with powerful cross-disciplinary and cross-generational\ndifferentiations. We examined the share of women scientists coming from ten\ndifferent age cohorts for 32 European and four comparator countries (the USA,\nCanada, Australia, and Japan). Our study sample was N = 1,740,985 scientists\n(including 39.40% women scientists). Three critical methodological challenges\nof using structured Big Data of the bibliometric type were discussed: gender\ndetermination, academic age determination, and discipline determination.",
    "pdf_url": "http://arxiv.org/pdf/2411.00008v2",
    "published": "2024-10-17T12:26:08+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.DL"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13482v1",
    "title": "Architecting a reliable quantum operating system: microkernel, message passing and supercomputing",
    "authors": [
      "Alexandru Paler"
    ],
    "abstract": "A quantum operating system (QCOS) is a classic software running on classic\nhardware. The QCOS is preparing, starting, controlling and managing quantum\ncomputations. The reliable execution of fault-tolerant quantum computations\nwill require the QCOS to be as reliable and fault-tolerant as the computation\nitself. In the following, we discuss why a QCOS should be architected according\nto the following principles: 1) using a microkernel; 2) the components are\nworking in an aggregated, non-stacked manner and communicate by message\npassing; 3) the components are executed by default on supercomputers, unless\nthere are very good reasons not to. These principles can guarantee that the\nexecution of error-corrected, fault-tolerant quantum computation is not\nvulnerable to the failures of the QCOS.",
    "pdf_url": "http://arxiv.org/pdf/2410.13482v1",
    "published": "2024-10-17T12:24:55+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13481v3",
    "title": "Faces in girth-saturated graphs on surfaces",
    "authors": [
      "Maria Axenovich",
      "Leon Kießle",
      "Arsenii Sagdeev",
      "Maksim Zhukovskii"
    ],
    "abstract": "What is the maximum length ${\\rm f}_{\\rm max}(\\ell, \\Sigma)$ of a facial\ncycle of an inclusion-maximal graph with girth at least $\\ell$ embedded on a\ngiven surface $\\Sigma$? If $\\Sigma=\\mathcal{P}$ is a plane, we show that\n$3\\ell-11\\leq {\\rm f}_{\\rm max}(\\ell, \\mathcal{P})\\leq 8\\ell-13$. We also prove\nthat ${\\rm f}_{\\rm max}(\\ell, \\Sigma)$ is bounded for any integer $\\ell$ and\nany closed surface $\\Sigma$. For a fixed $\\Sigma$, we show that $\\Omega(\\ell)\n={\\rm f}_{\\rm max}(\\ell, \\Sigma) = O(\\ell^2)$, while for a fixed $\\ell\\ge 6$,\n${\\rm f}_{\\rm max}(\\ell, \\Sigma)=\\Theta(g)$, where $g$ is the genus of\n$\\Sigma$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13481v3",
    "published": "2024-10-17T12:24:00+00:00",
    "categories": [
      "math.CO",
      "05C10, 05C35, 57M15"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13480v1",
    "title": "Broken Windows: Exploring the Applicability of a Controversial Theory on Code Quality",
    "authors": [
      "Diomidis Spinellis",
      "Panos Louridas",
      "Maria Kechagia",
      "Tushar Sharma"
    ],
    "abstract": "Is the quality of existing code correlated with the quality of subsequent\nchanges? According to the (controversial) broken windows theory, which inspired\nthis study, disorder sets descriptive norms and signals behavior that further\nincreases it. From a large code corpus, we examine whether code history does\nindeed affect the evolution of code quality. We examine C code quality metrics\nand Java code smells in specific files, and see whether subsequent commits by\ndevelopers continue on that path. We check whether developers tailor the\nquality of their commits based on the quality of the file they commit to. Our\nresults show that history matters, that developers behave differently depending\non some aspects of the code quality they encounter, and that programming style\ninconsistency is not necessarily related to structural qualities. These\nfindings have implications for both software practice and research. Software\npractitioners can emphasize current quality practices as these influence the\ncode that will be developed in the future. Researchers in the field may\nreplicate and extend the study to improve our understanding of the theory and\nits practical implications on artifacts, processes, and people.",
    "pdf_url": "http://arxiv.org/pdf/2410.13480v1",
    "published": "2024-10-17T12:16:35+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13479v1",
    "title": "Computing measures of weak-MSO definable sets of trees",
    "authors": [
      "Damian Niwiński",
      "Marcin Przybyłko",
      "Michał Skrzypczak"
    ],
    "abstract": "his work addresses the problem of computing measures of recognisable sets of\ninfinite trees. An algorithm is provided to compute the probability measure of\na tree language recognisable by a weak alternating automaton, or equivalently\ndefinable in weak monadic second-order logic. The measure is the uniform\ncoin-flipping measure or more generally it is generated by a~branching\nstochastic process. The class of tree languages in consideration, although\nsmaller than all regular tree languages, comprises in particular the languages\ndefinable in the alternation-free mu-calculus or in temporal logic CTL. Thus,\nthe new algorithm may enhance the toolbox of probabilistic model checking.",
    "pdf_url": "http://arxiv.org/pdf/2410.13479v1",
    "published": "2024-10-17T12:14:53+00:00",
    "categories": [
      "cs.FL"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13478v1",
    "title": "Observation of $χ_{c0}\\toΣ^{+}\\barΣ^{-}η$ and evidence for $χ_{c1,2}\\toΣ^{+}\\barΣ^{-}η$",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "O. Afedulidis",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "I. Balossino",
      "Y. Ban",
      "H. -R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "J. F. Chang",
      "G. R. Che",
      "G. Chelkov",
      "C. Chen",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "Z. Y. Chen",
      "S. K. Choi",
      "G. Cibinetto",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "Z. H. Duan",
      "P. Egorov",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "X. B. Gao",
      "Y. N. Gao",
      "Yang Gao",
      "S. Garbolino",
      "I. Garzia",
      "L. Ge",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "A. Gilman",
      "K. Goetzen",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "Y. T. Gu",
      "C. Y. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "J. Gutierrez",
      "K. L. Han",
      "T. T. Han",
      "F. Hanisch",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. H. Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "T. Holtmann",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "B. Y. Hu",
      "H. M. Hu",
      "J. F. Hu",
      "S. L. Hu",
      "T. Hu",
      "Y. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "Y. S. Huang",
      "T. Hussain",
      "F. Hölzken",
      "N. Hüsken",
      "N. in der Wiesche",
      "J. Jackson",
      "S. Janchiv",
      "J. H. Jeong",
      "Q. Ji",
      "Q. P. Ji",
      "W. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "X. Q. Jia",
      "Z. K. Jia",
      "D. Jiang",
      "H. B. Jiang",
      "P. C. Jiang",
      "S. S. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "J. K. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "X. M. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "M. Kavatsyuk",
      "B. C. Ke",
      "V. Khachatryan",
      "A. Khoukaz",
      "R. Kiuchi",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "N. Kumar",
      "A. Kupsc",
      "W. Kühn",
      "J. J. Lane",
      "L. Lavezzi",
      "T. T. Lei",
      "Z. H. Lei",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "Cheng Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "K. Li",
      "L. J. Li",
      "L. K. Li",
      "Lei Li",
      "M. H. Li",
      "P. R. Li",
      "Q. M. Li",
      "Q. X. Li",
      "R. Li",
      "S. X. Li",
      "T. Li",
      "W. D. Li",
      "W. G. Li",
      "X. Li",
      "X. H. Li",
      "X. L. Li",
      "X. Y. Li",
      "X. Z. Li",
      "Y. G. Li",
      "Z. J. Li",
      "Z. Y. Li",
      "C. Liang",
      "H. Liang",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "C. C. Lin",
      "D. X. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. Liu",
      "F. H. Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. B. Liu",
      "H. H. Liu",
      "H. M. Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. Y. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. Liu",
      "L. C. Liu",
      "Lu Liu",
      "M. H. Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "X. Liu",
      "X. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. D. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "X. L. Lu",
      "Y. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "J. R. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "X. R. Lyu",
      "Y. F. Lyu",
      "F. C. Ma",
      "H. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "M. M. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "T. Ma",
      "X. T. Ma",
      "X. Y. Ma",
      "Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "M. Maggiora",
      "S. Malde",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "Z. X. Meng",
      "J. G. Messchendorp",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "B. Moses",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "L. S. Nie",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Q. L. Niu",
      "W. D. Niu",
      "Y. Niu",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "Y. Y. Peng",
      "K. Peters",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "V. Prasad",
      "F. Z. Qi",
      "H. Qi",
      "H. R. Qi",
      "M. Qi",
      "T. Y. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "X. K. Qiao",
      "J. J. Qin",
      "L. Q. Qin",
      "L. Y. Qin",
      "X. P. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "Z. H. Qu",
      "C. F. Redmer",
      "K. J. Ren",
      "A. Rivetti",
      "M. Rolo",
      "G. Rong",
      "Ch. Rosner",
      "S. N. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Schoenning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "Z. J. Shang",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. Shi",
      "H. C. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "Q. Q. Shi",
      "S. Y. Shi",
      "X. Shi",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. J. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "W. Y. Sun",
      "Y. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. Q. Sun",
      "Z. T. Sun",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "M. Tang",
      "Y. A. Tang",
      "L. Y. Tao",
      "Q. T. Tao",
      "M. Tat",
      "J. X. Teng",
      "V. Thoren",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "Y. Wan",
      "S. J. Wang",
      "B. Wang",
      "B. L. Wang",
      "Bo Wang",
      "D. Y. Wang",
      "F. Wang",
      "H. J. Wang",
      "J. J. Wang",
      "J. P. Wang",
      "K. Wang",
      "L. L. Wang",
      "M. Wang",
      "N. Y. Wang",
      "S. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "X. N. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. L. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "Yaqian Wang",
      "Yi Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. Y. Wang",
      "Ziyi Wang",
      "D. H. Wei",
      "F. Weidner",
      "S. P. Wen",
      "Y. R. Wen",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "L. Wollenberg",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. Wu",
      "Y. H. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "B. H. Xiang",
      "T. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "S. Y. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "H. Y. Xu",
      "M. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "W. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. C. Xu",
      "Z. S. Xu",
      "F. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "T. Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. F. Yang",
      "Y. X. Yang",
      "Z. W. Yang",
      "Z. P. Yao",
      "M. Ye",
      "M. H. Ye",
      "J. H. Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "T. Yu",
      "X. D. Yu",
      "Y. C. Yu",
      "C. Z. Yuan",
      "J. Yuan",
      "J. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "A. A. Zafar",
      "F. R. Zeng",
      "S. H. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. C. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. Zhang",
      "H. C. Zhang",
      "H. H. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. R. Zhang",
      "H. Y. Zhang",
      "J. Zhang",
      "J. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. S. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "L. M. Zhang",
      "Lei Zhang",
      "P. Zhang",
      "Q. Y. Zhang",
      "R. Y. Zhang",
      "S. H. Zhang",
      "Shulei Zhang",
      "X. D. Zhang",
      "X. M. Zhang",
      "X. Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Y. M. Zhang",
      "Yan Zhang",
      "Z. D. Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "Z. Z. Zhang",
      "G. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "L. Zhao",
      "Lei Zhao",
      "M. G. Zhao",
      "N. Zhao",
      "R. P. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "B. M. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "X. Zhong",
      "H. Zhou",
      "J. Y. Zhou",
      "L. P. Zhou",
      "S. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. Z. Zhou",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "K. S. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "T. J. Zhu",
      "W. D. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "Using $(27.12\\pm 0.14)\\times10^{8}$ $\\psi(3686)$ events collected with the\nBESIII detector, the decay $\\chi_{c0}\\to\\Sigma^{+}\\bar{\\Sigma}^{-}\\eta$ is\nobserved for the first time with a statistical significance of $7.0\\sigma$, and\nevidence for $\\chi_{c1}\\to\\Sigma^{+}\\bar{\\Sigma}^{-}\\eta$ and\n$\\chi_{c2}\\to\\Sigma^{+}\\bar{\\Sigma}^{-}\\eta$ is found with statistical\nsignificances of $4.3\\sigma$ and $4.6\\sigma$, respectively. The branching\nfractions are determined to be\n$\\mathcal{B}(\\chi_{c0}\\to\\Sigma^{+}\\bar{\\Sigma}^{-}\\eta)=({1.26 \\pm 0.20 \\pm\n0.13}) \\times 10^{-4},\n~\\mathcal{B}(\\chi_{c1}\\to\\Sigma^{+}\\bar{\\Sigma}^{-}\\eta)=({5.10 \\pm 1.21 \\pm\n0.67}) \\times 10^{-5}$, and\n$\\mathcal{B}(\\chi_{c2}\\to\\Sigma^{+}\\bar{\\Sigma}^{-}\\eta)=({5.46 \\pm 1.18 \\pm\n0.50}) \\times 10^{-5}$, where the first uncertainties are statistical, and the\nsecond ones are systematic.",
    "pdf_url": "http://arxiv.org/pdf/2410.13478v1",
    "published": "2024-10-17T12:11:07+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2410.13477v1",
    "title": "Advocate -- Trustworthy Evidence in Cloud Systems",
    "authors": [
      "Sebastian Werner",
      "Sepideh Masoudi",
      "Fernando Castillo",
      "Fabian Piper",
      "Jonathan Heiss"
    ],
    "abstract": "The rapid evolution of cloud-native applications, characterized by dynamic,\ninterconnected services, presents significant challenges for maintaining\ntrustworthy and auditable systems, especially in sensitive contexts, such as\nfinance or healthcare. Traditional methods of verification and certification\nare often inadequate due to the fast-past and dynamic development practices\ncommon in cloud computing. This paper introduces Advocate, a novel agent-based\nsystem designed to generate verifiable evidence of cloud-native application\noperations. By integrating with existing infrastructure tools, such as\nKubernetes and distributed tracing systems, Advocate captures, authenticates,\nand stores evidence trails in a tamper-resistant manner. This approach not only\nsupports the auditing process but also allows for privacy-preserving evidence\naggregation. Advocate's extensible architecture facilitates its deployment in\ndiverse environments, enabling the verification and adherence to policies and\nenhance trust in cloud services.",
    "pdf_url": "http://arxiv.org/pdf/2410.13477v1",
    "published": "2024-10-17T12:09:26+00:00",
    "categories": [
      "cs.DC",
      "cs.CR",
      "C.2.4; D.2"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13476v2",
    "title": "Focal Curves of Closed Toroidal Curves",
    "authors": [
      "C. L. Dinkova",
      "R. P. Encheva",
      "A. A. Ali"
    ],
    "abstract": "Geometric constructions are widely used in computer graphics and engineering\ndrawing. A right generalized cylinder is a ruled surface whose base curve is a\nplane curve perpendicular to the rulings. The paper discusses relations between\nthe base curve and the non-planar space curve on the right generalized\ncylinder. Based on these relations, a method for obtaining a new space curve\nfrom a given plane curve parameterized about an arbitrary parameter is\npresented. At first, we define a non-planar space curve on the right\ngeneralized cylinder whose base curve is the considered plane curve,\nparameterized about an arbitrary parameter. Later on, we examine the focal\ncurve of the obtained cylindrical curve which is also a non-planar curve. The\nFrenet-Seret system of the cylindrical curve and its focal curve are expressed\nin terms of the signed curvature of the abovementioned plane curve and its\nderivatives. Finally, we obtained the parametric representation of orthogonal\nprojection of the focal curve onto the Euclidean plane via before mentioned\nplane curve and its derivatives. That curve is called generalized focal curve\nof a plane curve. The proposed method is demonstrated for several closed plane\ncurves used in engineering practice. These curves include: epicycloid,\nhypocycloid and a curve that is orthogonal projection of toroidal helix onto\nthe Euclidean plane.",
    "pdf_url": "http://arxiv.org/pdf/2410.13476v2",
    "published": "2024-10-17T12:07:17+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13475v2",
    "title": "Reply to Comment on \"Neutrino oscillations originate from virtual excitation of Z bosons\" and \"Neutrinos produced from $β$ decays of neutrons cannot be in coherent superpositions of different mass eigenstates\"",
    "authors": [
      "Shi-Biao Zheng"
    ],
    "abstract": "In this reply, I point out that the comment by Cline (arXiv:2410.05826) on my\nmanuscripts (arXiv:2407.00954 and arXiv:2410.03133) has overlooked the critical\nfact that the quantum entanglement between the neutrino's mass and other\ndegrees of freedom would destroy the quantum coherence between the mass\neigenstates.",
    "pdf_url": "http://arxiv.org/pdf/2410.13475v2",
    "published": "2024-10-17T12:06:15+00:00",
    "categories": [
      "hep-ph",
      "quant-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13474v1",
    "title": "Non-uniform Fourier Domain Stretching method for ultra-wide-angle wave propagation",
    "authors": [
      "Tomasz Kozacki",
      "Juan Martinez-Carranza",
      "Maksymilian Chlipala",
      "Rafal Kukolowicz",
      "Moncy S. Idicula"
    ],
    "abstract": "Numerical inspection of wide-angle (WA) or ultra-wide-angle (UWA)\ncomputer-generated holograms (CGH) is a computationally demanding task. To\nsurpass this limitation, we propose a novel computational approach for fast and\naccurate WA-CGH reconstruction based on Fast Fourier transform Fresnel\ndiffraction (FrT) and non-uniform frequency hologram magnification. This novel\nalgorithm, referred to as the non-uniform Fourier Domain Stretching (NU-FDS)\nmethod, is based on approximating a spherical wave coming from any object point\nwith a parabolic wave, with the points of convergence of the two waves being\ndifferent. It is supported by a mathematical solution developed using\nphase-space to determine the frequency distribution needed to find the\ndistribution of non-uniform magnification. It corrects the axial distance of a\nparabolic wave so the FrT solution can be applied for WA-CGH reconstruction.\nThe NU-FDS algorithm also allows the reconstruction of a partial view with\nfreedom of position and size selection, reducing computation time. In this way,\nthe NU-FDS method enables fast and accurate quantitative assessment of the 3D\ninformation coded into the CGH. The presented evidence shows that the NU-FDS\nalgorithm can accurately and efficiently reconstruct large and highly detailed\n3D objects from WA and UWA CGH of FoV and resolution up to 120{\\deg} and 16K,\nrespectively.",
    "pdf_url": "http://arxiv.org/pdf/2410.13474v1",
    "published": "2024-10-17T12:05:18+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13473v1",
    "title": "Optimal Quantum Overlapping Tomography",
    "authors": [
      "Chao Wei",
      "Tao Xin"
    ],
    "abstract": "Partial tomography, which focuses on reconstructing reduced density matrices\n(RDMs), has emerged as a promising approach for characterizing complex quantum\nsystems, particularly when full state tomography is impractical. Recently,\noverlapping tomography has been proposed as an efficient method for determining\nall $k$-qubit RDMs using logarithmic polynomial measurements, though it has not\nyet reached the ultimate limit. Here, we introduce a unified framework for\noptimal quantum overlapping tomography by mapping the problem to the clique\ncover model. This framework provides the most efficient and experimentally\nfeasible measurement schemes to date, significantly reducing the measurement\ncosts. Our approach is also applicable to determining RDMs with different\ntopological structures. Moreover, we experimentally validate the feasibility of\nour schemes on practical nuclear spin processor using average measurements and\nfurther apply our method to noisy data from a superconducting quantum processor\nemploying projection measurements. The results highlight the strong power of\noverlapping tomography, paving the way for advanced quantum system\ncharacterization and state property learning in the future.",
    "pdf_url": "http://arxiv.org/pdf/2410.13473v1",
    "published": "2024-10-17T12:03:43+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13472v2",
    "title": "Day-Night Adaptation: An Innovative Source-free Adaptation Framework for Medical Image Segmentation",
    "authors": [
      "Ziyang Chen",
      "Yiwen Ye",
      "Yongsheng Pan",
      "Jingfeng Zhang",
      "Yanning Zhang",
      "Yong Xia"
    ],
    "abstract": "Distribution shifts widely exist in medical images acquired from different\nmedical centres, hindering the deployment of semantic segmentation models\ntrained on one centre (source domain) to another (target domain). While\nunsupervised domain adaptation has shown significant promise in mitigating\nthese shifts, it poses privacy risks due to sharing data between centres. To\nfacilitate adaptation while preserving data privacy, source-free domain\nadaptation (SFDA) and test-time adaptation (TTA) have emerged as effective\nparadigms, relying solely on target domain data. However, SFDA requires a\npre-collected target domain dataset before deployment. TTA insufficiently\nexploit the potential value of test data, as it processes the test data only\nonce. Considering that most medical centres operate during the day and remain\ninactive at night in clinical practice, we propose a novel adaptation framework\ncalled Day-Night Adaptation (DyNA) with above insights, which performs\nadaptation through day-night cycles without requiring access to source data.\nDuring the day, a low-frequency prompt is trained to adapt the frozen model to\neach test sample. We construct a memory bank for prompt initialization and\ndevelop a warm-up mechanism to enhance prompt training. During the night, we\nreuse test data collected from the day and introduce a global student model to\nbridge the knowledge between teacher and student models, facilitating model\nfine-tuning while ensuring training stability. Extensive experiments\ndemonstrate that our DyNA outperforms existing TTA and SFDA methods on two\nbenchmark medical image segmentation tasks. Code will be available after the\npaper is published.",
    "pdf_url": "http://arxiv.org/pdf/2410.13472v2",
    "published": "2024-10-17T12:02:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13471v3",
    "title": "SiamSeg: Self-Training with Contrastive Learning for Unsupervised Domain Adaptation Semantic Segmentation in Remote Sensing",
    "authors": [
      "Bin Wang",
      "Fei Deng",
      "Shuang Wang",
      "Wen Luo",
      "Zhixuan Zhang",
      "Peifan Jiang"
    ],
    "abstract": "Semantic segmentation of remote sensing (RS) images is a challenging yet\nessential task with broad applications. While deep learning, particularly\nsupervised learning with large-scale labeled datasets, has significantly\nadvanced this field, the acquisition of high-quality labeled data remains\ncostly and time-intensive. Unsupervised domain adaptation (UDA) provides a\npromising alternative by enabling models to learn from unlabeled target domain\ndata while leveraging labeled source domain data. Recent self-training (ST)\napproaches employing pseudo-label generation have shown potential in mitigating\ndomain discrepancies. However, the application of ST to RS image segmentation\nremains underexplored. Factors such as variations in ground sampling distance,\nimaging equipment, and geographic diversity exacerbate domain shifts, limiting\nmodel performance across domains. In that case, existing ST methods, due to\nsignificant domain shifts in cross-domain RS images, often underperform. To\naddress these challenges, we propose integrating contrastive learning into UDA,\nenhancing the model's ability to capture semantic information in the target\ndomain by maximizing the similarity between augmented views of the same image.\nThis additional supervision improves the model's representational capacity and\nsegmentation performance in the target domain. Extensive experiments conducted\non RS datasets, including Potsdam, Vaihingen, and LoveDA, demonstrate that our\nmethod, SimSeg, outperforms existing approaches, achieving state-of-the-art\nresults. Visualization and quantitative analyses further validate SimSeg's\nsuperior ability to learn from the target domain. The code is publicly\navailable at https://github.com/woldier/SiamSeg.",
    "pdf_url": "http://arxiv.org/pdf/2410.13471v3",
    "published": "2024-10-17T11:59:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13470v2",
    "title": "High Rate Multivariate Polynomial Evaluation Codes",
    "authors": [
      "Swastik Kopparty",
      "Mrinal Kumar",
      "Harry Sha"
    ],
    "abstract": "The classical Reed-Muller codes over a finite field $\\mathbb{F}_q$ are based\non evaluations of $m$-variate polynomials of degree at most $d$ over a product\nset $U^m$, for some $d$ less than $|U|$. Because of their good distance\nproperties, as well as the ubiquity and expressive power of polynomials, these\ncodes have played an influential role in coding theory and complexity theory.\nThis is especially so in the setting of $U$ being ${\\mathbb{F}}_q$ where they\npossess deep locality properties. However, these Reed-Muller codes have a\nsignificant limitation in terms of the rate achievable -- the rate cannot be\nmore than $\\frac{1}{m{!}} = \\exp(-m \\log m)$.\n  In this work, we give the first constructions of multivariate polynomial\nevaluation codes which overcome the rate limitation -- concretely, we give\nexplicit evaluation domains $S \\subseteq \\mathbb{F}_q^m$ on which evaluating\n$m$-variate polynomials of degree at most $d$ gives a good code. For $m= O(1)$,\nthese new codes have relative distance $\\Omega(1)$ and rate $1 - \\epsilon$ for\nany $\\epsilon > 0$. In fact, we give two quite different constructions, and for\nboth we develop efficient decoding algorithms for these codes that can decode\nfrom half the minimum distance.\n  The first of these codes is based on evaluating multivariate polynomials on\nsimplex-like sets whereas the second construction is more algebraic, and\nsurprisingly (to us), has some strong locality properties, specifically, we\nshow that they are locally testable.",
    "pdf_url": "http://arxiv.org/pdf/2410.13470v2",
    "published": "2024-10-17T11:58:34+00:00",
    "categories": [
      "cs.IT",
      "cs.CC",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13469v1",
    "title": "Interpreting Temporal Graph Neural Networks with Koopman Theory",
    "authors": [
      "Michele Guerra",
      "Simone Scardapane",
      "Filippo Maria Bianchi"
    ],
    "abstract": "Spatiotemporal graph neural networks (STGNNs) have shown promising results in\nmany domains, from forecasting to epidemiology. However, understanding the\ndynamics learned by these models and explaining their behaviour is\nsignificantly more complex than for models dealing with static data. Inspired\nby Koopman theory, which allows a simpler description of intricate, nonlinear\ndynamical systems, we introduce an explainability approach for temporal graphs.\nWe present two methods to interpret the STGNN's decision process and identify\nthe most relevant spatial and temporal patterns in the input for the task at\nhand. The first relies on dynamic mode decomposition (DMD), a Koopman-inspired\ndimensionality reduction method. The second relies on sparse identification of\nnonlinear dynamics (SINDy), a popular method for discovering governing\nequations, which we use for the first time as a general tool for\nexplainability. We show how our methods can correctly identify interpretable\nfeatures such as infection times and infected nodes in the context of\ndissemination processes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13469v1",
    "published": "2024-10-17T11:56:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13468v1",
    "title": "Dispersion of compressible rotating Euler equations with low Mach and Rossby numbers",
    "authors": [
      "Pengcheng Mu"
    ],
    "abstract": "In this paper, we consider the low Mach and Rossby number singular limits and\nlongtime existence of strong solution to the initial value problem of 3D\ncompressible rotating Euler equations with ill-prepared initial data. We\nestablish the Strichartz decay estimates that are uniform to the Mach number,\nthe Rossby number, and the ratio of these two parameters for the associated\nlinear propagator without any restrictions on the frequency. In particular,\ndifficulties arisen from the degeneracy of the phase function and the vanishing\nof the ratio of the two parameters are addressed by elaborately designed\nsplitting techniques and discussions for each frequencies. Using the decay\nestimates, we prove the longtime existence and obtain a rate of convergence to\nzero of strong solution to the compressible rotating Euler equations with\ninitial data of finite energy in $\\mathbb{R}^3$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13468v1",
    "published": "2024-10-17T11:55:17+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13467v1",
    "title": "Optomechanical micro-rheology of complex fluids at ultra-high frequency",
    "authors": [
      "H. Neshasteh",
      "I. Shlesinger",
      "M. Ravaro",
      "M. Gély",
      "G. Jourdan",
      "S. Hentz",
      "I. Favero"
    ],
    "abstract": "We present an optomechanical method for locally measuring the rheological\nproperties of complex fluids in the ultra-high frequency range (UHF). A\nmechanical disk of microscale volume is used as a small-amplitude oscillating\nprobe that monitors the fluid at rest in thermal equilibrium, while the\noscillation is detected by optomechanical transduction within a sub-millisecond\nmeasurement time, thanks to an optimized signal collection. An original\nanalytical model for fluid-structure interactions is used to extract from these\nmeasurements the rheological properties of liquids over the frequency range 100\nMHz - 1 GHz. This new micro-rheology method is calibrated by measurements on\nliquid water, in which we observe pronounced compressibility effects above 500\nMHz, but which we show remains Newtonian all over the explored range. In\ncontrast, measurements reveal that liquid 1-decanol exhibits a non-Newtonian\nbehavior, with a frequency-dependent viscosity associated to several relaxation\nfrequencies in the UHF. Our data agree well with an extended Maxwell model for\nthe viscosity of this alcohol, involving two relaxation times of 797 and 151\npicoseconds, which are respectively analyzed as supramolecular and\nintramolecular relaxation processes. A shear elastic response of the liquid\nappears at the highest frequencies, compatible with the entropic elasticity of\nmolecules as they attempt to uncurl, and whose value enables estimating the\nvolume of a single molecule of liquid. UHF optomechanical micro-rheology\ndemonstrates here a direct mechanical access to the fast molecular dynamics at\nplay in a liquid, in a quantitative manner and in a short time.",
    "pdf_url": "http://arxiv.org/pdf/2410.13467v1",
    "published": "2024-10-17T11:53:01+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.optics"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13466v2",
    "title": "Comparing Methodological Variations in Seizure Onset Localisation Algorithms using intracranial EEG",
    "authors": [
      "Sarah J. Gascoigne",
      "Manel Vila-Vidal",
      "Nathan Evans",
      "Christopher Thornton",
      "Heather Woodhouse",
      "Billy Smith",
      "Anderson Brito Da Silva",
      "Rhys H. Thomas",
      "Kevin Wilson",
      "Peter N. Taylor",
      "Adria Tauste Campo",
      "Yujiang Wang"
    ],
    "abstract": "During clinical treatment for epilepsy, the area of the brain thought to be\nresponsible for pathological activity is identified. This identification is\ntypically performed through visual assessment of EEG recordings; however, this\nis time consuming and prone to subjective inconsistency. Automated onset\nlocalisation algorithms provide objective identification of the onset location\nby highlighting changes in signal features associated with seizure onset. In\nthis work we investigate how methodological differences in such algorithms can\nresult in different onset locations being identified.\n  We analysed ictal intracranial EEG (icEEG) recordings in 16 subjects (100\nseizures) with drug-resistant epilepsy from the SWEZ-ETHZ public database. We\nidentified a series of key methodological differences that must be considered\nwhen designing or selecting an onset localisation algorithm. These differences\nwere demonstrated using three distinct algorithms that capture different, but\ncomplementary, seizure onset features: Imprint, Epileptogenicity Index, and Low\nEntropy Map. We assessed methodological differences (or Decision Points), and\ntheir impact on the identified onset locations.\n  Our independent application of all three algorithms to the same ictal icEEG\ndataset revealed low agreement between them: 27-60% of onset channels showed\nminimal or no overlap. Therefore, we investigated the effect of three key\ndifferences: (i) how to define a baseline, (ii) whether low-frequency\ncomponents are considered, and finally (iii) whether electrodecrement is\nconsidered. Changes at each Decision Point were found to substantially\ninfluence resultant onset channels (r>0.3).\n  Our results demonstrate how seemingly small methodological changes can result\nin large differences in onset locations. We propose that key Decision Points\nmust be considered when using or designing an onset localisation algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2410.13466v2",
    "published": "2024-10-17T11:51:19+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13465v1",
    "title": "Object Pose Estimation Using Implicit Representation For Transparent Objects",
    "authors": [
      "Varun Burde",
      "Artem Moroz",
      "Vit Zeman",
      "Pavel Burget"
    ],
    "abstract": "Object pose estimation is a prominent task in computer vision. The object\npose gives the orientation and translation of the object in real-world space,\nwhich allows various applications such as manipulation, augmented reality, etc.\nVarious objects exhibit different properties with light, such as reflections,\nabsorption, etc. This makes it challenging to understand the object's structure\nin RGB and depth channels. Recent research has been moving toward\nlearning-based methods, which provide a more flexible and generalizable\napproach to object pose estimation utilizing deep learning. One such approach\nis the render-and-compare method, which renders the object from multiple views\nand compares it against the given 2D image, which often requires an object\nrepresentation in the form of a CAD model. We reason that the synthetic texture\nof the CAD model may not be ideal for rendering and comparing operations. We\nshowed that if the object is represented as an implicit (neural) representation\nin the form of Neural Radiance Field (NeRF), it exhibits a more realistic\nrendering of the actual scene and retains the crucial spatial features, which\nmakes the comparison more versatile. We evaluated our NeRF implementation of\nthe render-and-compare method on transparent datasets and found that it\nsurpassed the current state-of-the-art results.",
    "pdf_url": "http://arxiv.org/pdf/2410.13465v1",
    "published": "2024-10-17T11:51:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13464v1",
    "title": "IterSelectTune: An Iterative Training Framework for Efficient Instruction-Tuning Data Selection",
    "authors": [
      "Jielin Song",
      "Siyu Liu",
      "Bin Zhu",
      "Yanghui Rao"
    ],
    "abstract": "As large language models (LLMs) continue to advance, instruction tuning has\nbecome critical for improving their ability to generate accurate and\ncontextually appropriate responses. Although numerous instruction-tuning\ndatasets have been developed to enhance LLM performance, selecting high-quality\ninstruction data from large source datasets typically demands significant human\neffort. In this work, we introduce $\\textbf{IterSelectTune}$, an efficient,\ncost-effective iterative training policy for selecting high-quality instruction\ndata with no human involvement and limited reliance on GPT-4. By fine-tuning on\napproximately 20\\% of the source data, our method consistently outperforms\nmodels fine-tuned on the full dataset across multiple benchmarks and public\ntest datasets. These results highlight the effectiveness of our approach in\nenhancing LLM performance while reducing the computational resources required\nfor instruction tuning.",
    "pdf_url": "http://arxiv.org/pdf/2410.13464v1",
    "published": "2024-10-17T11:48:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13463v1",
    "title": "Truncating Trajectories in Monte Carlo Policy Evaluation: an Adaptive Approach",
    "authors": [
      "Riccardo Poiani",
      "Nicole Nobili",
      "Alberto Maria Metelli",
      "Marcello Restelli"
    ],
    "abstract": "Policy evaluation via Monte Carlo (MC) simulation is at the core of many MC\nReinforcement Learning (RL) algorithms (e.g., policy gradient methods). In this\ncontext, the designer of the learning system specifies an interaction budget\nthat the agent usually spends by collecting trajectories of fixed length within\na simulator. However, is this data collection strategy the best option? To\nanswer this question, in this paper, we propose as a quality index a surrogate\nof the mean squared error of a return estimator that uses trajectories of\ndifferent lengths, i.e., \\emph{truncated}. Specifically, this surrogate shows\nthe sub-optimality of the fixed-length trajectory schedule. Furthermore, it\nsuggests that adaptive data collection strategies that spend the available\nbudget sequentially can allocate a larger portion of transitions in timesteps\nin which more accurate sampling is required to reduce the error of the final\nestimate. Building on these findings, we present an adaptive algorithm called\nRobust and Iterative Data collection strategy Optimization (RIDO). The main\nintuition behind RIDO is to split the available interaction budget into\nmini-batches. At each round, the agent determines the most convenient schedule\nof trajectories that minimizes an empirical and robust version of the surrogate\nof the estimator's error. After discussing the theoretical properties of our\nmethod, we conclude by assessing its performance across multiple domains. Our\nresults show that RIDO can adapt its trajectory schedule toward timesteps where\nmore sampling is required to increase the quality of the final estimation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13463v1",
    "published": "2024-10-17T11:47:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13462v1",
    "title": "EOSpython Version 0.0.11: A Framework for Scenario Generation and a Solution System for the Agile Earth Observation Satellite Scheduling Problem",
    "authors": [
      "Alex Elkjær Vasegaard",
      "Andreas Kühne Larsen"
    ],
    "abstract": "EOSpython is a PyPI published Python package that encompass everything within\na centralized earth observation satellite scheduling system in terms of\ncustomer database setup, scenario generation, pre-processing, problem setup,\nscheduling solution approach, decision maker preference integration, and\nvisualization. The package is tailored to easily configure internal parameters\nand contribute with other solution approaches.",
    "pdf_url": "http://arxiv.org/pdf/2410.13462v1",
    "published": "2024-10-17T11:47:26+00:00",
    "categories": [
      "math.OC",
      "astro-ph.IM",
      "cs.ET",
      "cs.NA",
      "math.NA",
      "05, 15, 65, 68, 90",
      "G.1; G.2; I.6; J.2"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13461v2",
    "title": "Progressive Mixed-Precision Decoding for Efficient LLM Inference",
    "authors": [
      "Hao Mark Chen",
      "Fuwen Tan",
      "Alexandros Kouris",
      "Royson Lee",
      "Hongxiang Fan",
      "Stylianos I. Venieris"
    ],
    "abstract": "In spite of the great potential of large language models (LLMs) across\nvarious tasks, their deployment on resource-constrained devices remains\nchallenging due to their excessive computational and memory demands.\nQuantization has emerged as an effective solution by storing weights in reduced\nprecision. However, utilizing low precisions (i.e.~2/3-bit) to substantially\nalleviate the memory-boundedness of LLM decoding, still suffers from\nprohibitive performance drop. In this work, we argue that existing approaches\nfail to explore the diversity in computational patterns, redundancy, and\nsensitivity to approximations of the different phases of LLM inference,\nresorting to a uniform quantization policy throughout. Instead, we propose a\nnovel phase-aware method that selectively allocates precision during different\nphases of LLM inference, achieving both strong context extraction during\nprefill and efficient memory bandwidth utilization during decoding. To further\naddress the memory-boundedness of the decoding phase, we introduce Progressive\nMixed-Precision Decoding (PMPD), a technique that enables the gradual lowering\nof precision deeper in the generated sequence, together with a spectrum of\nprecision-switching schedulers that dynamically drive the precision-lowering\ndecisions in either task-adaptive or prompt-adaptive manner. Extensive\nevaluation across diverse language tasks shows that when targeting Nvidia GPUs,\nPMPD achieves 1.4$-$12.2$\\times$ speedup in matrix-vector multiplications over\nfp16 models, while when targeting an LLM-optimized NPU, our approach delivers a\nthroughput gain of 3.8$-$8.0$\\times$ over fp16 models and up to 1.54$\\times$\nover uniform quantization approaches while preserving the output quality.",
    "pdf_url": "http://arxiv.org/pdf/2410.13461v2",
    "published": "2024-10-17T11:46:33+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.02400v2",
    "title": "Decomposition Dilemmas: Does Claim Decomposition Boost or Burden Fact-Checking Performance?",
    "authors": [
      "Qisheng Hu",
      "Quanyu Long",
      "Wenya Wang"
    ],
    "abstract": "Fact-checking pipelines increasingly adopt the Decompose-Then-Verify\nparadigm, where texts are broken down into smaller claims for individual\nverification and subsequently combined for a veracity decision. While\ndecomposition is widely-adopted in such pipelines, its effects on final\nfact-checking performance remain underexplored. Some studies have reported\nimprovements from decompostition, while others have observed performance\ndeclines, indicating its inconsistent impact. To date, no comprehensive\nanalysis has been conducted to understand this variability. To address this\ngap, we present an in-depth analysis that explicitly examines the impact of\ndecomposition on downstream verification performance. Through error case\ninspection and experiments, we introduce a categorization of decomposition\nerrors and reveal a trade-off between accuracy gains and the noise introduced\nthrough decomposition. Our analysis provides new insights into understanding\ncurrent system's instability and offers guidance for future studies toward\nimproving claim decomposition in fact-checking pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2411.02400v2",
    "published": "2024-10-17T11:45:59+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13460v2",
    "title": "From Citations to Criticality: Predicting Legal Decision Influence in the Multilingual Swiss Jurisprudence",
    "authors": [
      "Ronja Stern",
      "Ken Kawamura",
      "Matthias Stürmer",
      "Ilias Chalkidis",
      "Joel Niklaus"
    ],
    "abstract": "Many court systems are overwhelmed all over the world, leading to huge\nbacklogs of pending cases. Effective triage systems, like those in emergency\nrooms, could ensure proper prioritization of open cases, optimizing time and\nresource allocation in the court system. In this work, we introduce the\nCriticality Prediction dataset, a novel resource for evaluating case\nprioritization. Our dataset features a two-tier labeling system: (1) the binary\nLD-Label, identifying cases published as Leading Decisions (LD), and (2) the\nmore granular Citation-Label, ranking cases by their citation frequency and\nrecency, allowing for a more nuanced evaluation. Unlike existing approaches\nthat rely on resource-intensive manual annotations, we algorithmically derive\nlabels leading to a much larger dataset than otherwise possible. We evaluate\nseveral multilingual models, including both smaller fine-tuned models and large\nlanguage models in a zero-shot setting. Our results show that the fine-tuned\nmodels consistently outperform their larger counterparts, thanks to our large\ntraining set. Our results highlight that for highly domain-specific tasks like\nours, large training sets are still valuable.",
    "pdf_url": "http://arxiv.org/pdf/2410.13460v2",
    "published": "2024-10-17T11:43:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2; I.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13459v1",
    "title": "Tropical Split Jacobians of genus 2 and optimal covers",
    "authors": [
      "Lou-Jean Leila Cobigo"
    ],
    "abstract": "We explore connections between the category of tropical abelian varieties\n(tav), $\\mathbb{T}\\mathcal{A}$, and the the category of tropical curves,\n$\\mathbb{T}\\mathcal{C}$, first in a broader context and then specifically by\nstudying the phenomenon of tropical split Jacobians. Jacobians of genus $2$\ncurves are two-dimensional tav and as such more complicated than their\none-dimensional cousins. Whenever $\\Gamma$, however, is a covering of an\nelliptic curve, it so happens that $Jac(\\Gamma)$ splits into simpler objects,\nthe direct sum of elliptic curves. This relation is pathological in essentially\ntwo ways, the splitting of $Jac(\\Gamma)$ is not unique, and it is a priori not\nclear how to compute it. Similar to algebraic geometry, optimal coverings offer\na remedy for both: They resolve indeterminacy as they provide us with a\ncanonical choice. They resolve indeterminability as they provide us with an\nalgorithmic approach. Our methods build on theory developed by Len, Mikhalkin,\nR\\\"ohrle, Ulirsch, Zakharov, Zharkov and many more. In accordance with this\nheritage, we want to put forth tropical geometry as a setting in which we can\nsee abstraction at work. This means pairing \"abstract machinery\" with a\nconstructive/algorithmic approach.",
    "pdf_url": "http://arxiv.org/pdf/2410.13459v1",
    "published": "2024-10-17T11:42:26+00:00",
    "categories": [
      "math.AG",
      "math.CO"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13458v1",
    "title": "MedINST: Meta Dataset of Biomedical Instructions",
    "authors": [
      "Wenhan Han",
      "Meng Fang",
      "Zihan Zhang",
      "Yu Yin",
      "Zirui Song",
      "Ling Chen",
      "Mykola Pechenizkiy",
      "Qingyu Chen"
    ],
    "abstract": "The integration of large language model (LLM) techniques in the field of\nmedical analysis has brought about significant advancements, yet the scarcity\nof large, diverse, and well-annotated datasets remains a major challenge.\nMedical data and tasks, which vary in format, size, and other parameters,\nrequire extensive preprocessing and standardization for effective use in\ntraining LLMs. To address these challenges, we introduce MedINST, the Meta\nDataset of Biomedical Instructions, a novel multi-domain, multi-task\ninstructional meta-dataset. MedINST comprises 133 biomedical NLP tasks and over\n7 million training samples, making it the most comprehensive biomedical\ninstruction dataset to date. Using MedINST as the meta dataset, we curate\nMedINST32, a challenging benchmark with different task difficulties aiming to\nevaluate LLMs' generalization ability. We fine-tune several LLMs on MedINST and\nevaluate on MedINST32, showcasing enhanced cross-task generalization.",
    "pdf_url": "http://arxiv.org/pdf/2410.13458v1",
    "published": "2024-10-17T11:38:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13457v1",
    "title": "Large Interferometer For Exoplanets (LIFE). XIV. Finding terrestrial protoplanets in the galactic neighborhood",
    "authors": [
      "Lorenzo Cesario",
      "Tim Lichtenberg",
      "Eleonora Alei",
      "Óscar Carrión-González",
      "Felix A. Dannert",
      "Denis Defrère",
      "Steve Ertel",
      "Andrea Fortier",
      "A. García Muñoz",
      "Adrian M. Glauser",
      "Jonah T. Hansen",
      "Ravit Helled",
      "Philipp A. Huber",
      "Michael J. Ireland",
      "Jens Kammerer",
      "Romain Laugier",
      "Jorge Lillo-Box",
      "Franziska Menti",
      "Michael R. Meyer",
      "Lena Noack",
      "Sascha P. Quanz",
      "Andreas Quirrenbach",
      "Sarah Rugheimer",
      "Floris van der Tak",
      "Haiyang S. Wang",
      "Marius Anger",
      "Olga Balsalobre-Ruza",
      "Surendra Bhattarai",
      "Marrick Braam",
      "Amadeo Castro-González",
      "Charles S. Cockell",
      "Tereza Constantinou",
      "Gabriele Cugno",
      "Jeanne Davoult",
      "Manuel Güdel",
      "Nina Hernitschek",
      "Sasha Hinkley",
      "Satoshi Itoh",
      "Markus Janson",
      "Anders Johansen",
      "Hugh R. A. Jones",
      "Stephen R. Kane",
      "Tim A. van Kempen",
      "Kristina G. Kislyakova",
      "Judith Korth",
      "Andjelka B. Kovacevic",
      "Stefan Kraus",
      "Rolf Kuiper",
      "Joice Mathew",
      "Taro Matsuo",
      "Yamila Miguel",
      "Michiel Min",
      "Ramon Navarro",
      "Ramses M. Ramirez",
      "Heike Rauer",
      "Berke Vow Ricketti",
      "Amedeo Romagnolo",
      "Martin Schlecker",
      "Evan L. Sneed",
      "Vito Squicciarini",
      "Keivan G. Stassun",
      "Motohide Tamura",
      "Daniel Viudez-Moreiras",
      "Robin D. Wordsworth",
      "the LIFE Collaboration"
    ],
    "abstract": "The increased brightness temperature of young rocky protoplanets during their\nmagma ocean epoch makes them potentially amenable to atmospheric\ncharacterization to distances from the solar system far greater than thermally\nequilibrated terrestrial exoplanets, offering observational opportunities for\nunique insights into the origin of secondary atmospheres and the near surface\nconditions of prebiotic environments. The Large Interferometer For Exoplanets\n(LIFE) mission will employ a space-based mid-infrared nulling interferometer to\ndirectly measure the thermal emission of terrestrial exoplanets. Here, we seek\nto assess the capabilities of various instrumental design choices of the LIFE\nmission concept for the detection of cooling protoplanets with transient\nhigh-temperature magma ocean atmospheres, in young stellar associations in\nparticular. Using the LIFE mission instrument simulator (LIFEsim) we assess how\nspecific instrumental parameters and design choices, such as wavelength\ncoverage, aperture diameter, and photon throughput, facilitate or disadvantage\nthe detection of protoplanets. We focus on the observational sensitivities of\ndistance to the observed planetary system, protoplanet brightness temperature\nusing a blackbody assumption, and orbital distance of the potential\nprotoplanets around both G- and M-dwarf stars. Our simulations suggest that\nLIFE will be able to detect (S/N $\\geq$ 7) hot protoplanets in young stellar\nassociations up to distances of $\\approx$100 pc from the solar system for\nreasonable integration times (up to $\\sim$hours). Detection of an Earth-sized\nprotoplanet orbiting a solar-sized host star at 1 AU requires less than 30\nminutes of integration time. M-dwarfs generally need shorter integration times.\nThe contribution from wavelength regions $<$6 $\\mu$m is important for\ndecreasing the detection threshold and discriminating emission temperatures.",
    "pdf_url": "http://arxiv.org/pdf/2410.13457v1",
    "published": "2024-10-17T11:38:21+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "physics.geo-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13456v1",
    "title": "Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland",
    "authors": [
      "Luca Rolshoven",
      "Vishvaksenan Rasiah",
      "Srinanda Brügger Bose",
      "Matthias Stürmer",
      "Joel Niklaus"
    ],
    "abstract": "Legal research is a time-consuming task that most lawyers face on a daily\nbasis. A large part of legal research entails looking up relevant caselaw and\nbringing it in relation to the case at hand. Lawyers heavily rely on summaries\n(also called headnotes) to find the right cases quickly. However, not all\ndecisions are annotated with headnotes and writing them is time-consuming.\nAutomated headnote creation has the potential to make hundreds of thousands of\ndecisions more accessible for legal research in Switzerland alone. To kickstart\nthis, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a\nnovel cross-lingual resource featuring 18K court rulings from the Swiss Federal\nSupreme Court (SFSC), in German, French, and Italian, along with German\nheadnotes. We fine-tune and evaluate three mT5 variants, along with proprietary\nmodels. Our analysis highlights that while proprietary models perform well in\nzero-shot and one-shot settings, fine-tuned smaller models still provide a\nstrong competitive edge. We publicly release the dataset to facilitate further\nresearch in multilingual legal summarization and the development of assistive\ntechnologies for legal professionals",
    "pdf_url": "http://arxiv.org/pdf/2410.13456v1",
    "published": "2024-10-17T11:34:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2; I.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13455v1",
    "title": "Performance Analysis of a Photovoltaic System with Thermoelectric Generator and Phase Change Material; An Experimental Approach",
    "authors": [
      "Tobechukwu Okamkpa",
      "Joshua Okechukwu",
      "Divine Mbachu",
      "Chigbo Mgbemene"
    ],
    "abstract": "This study explores the integration of thermoelectric generators (TEGs) and\nphase change materials (PCMs) to enhance the efficiency of photovoltaic (PV)\npanels in high-temperature conditions. An AP-PM-20 Polycrystalline PV panel,\nSP-1848-27145 Bismuth Telluride TEG, and paraffin wax PCM in an aluminum\ncontainer were used. Four configurations were tested: standalone PV, PV-PCM,\nPV-TEG-PCM, and PV-PCM-TEG, under identical conditions from 10:30 AM to 6:00 PM\nat 25-minute intervals. Data on PV and TEG voltage, current, and solar\nirradiance were collected and analyzed. The results show significant\nperformance improvements: the PV-PCM configuration boosted power output by\n68.04%, while PV-PCM-TEG and PV-TEG-PCM configurations improved efficiency by\n43.06% and 37.51%, respectively. Efficiency gains relative to the standalone PV\nsystem were 33.33% for PV-PCM, 25.76% for PV-PCM-TEG, and 21.21% for\nPV-TEG-PCM, demonstrating the effectiveness of PCMs and TEGs in enhancing PV\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13455v1",
    "published": "2024-10-17T11:31:24+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13454v1",
    "title": "Byzantine-Resilient Output Optimization of Multiagent via Self-Triggered Hybrid Detection Approach",
    "authors": [
      "Chenhang Yan",
      "Liping Yan",
      "Yuezu Lv",
      "Bolei Dong",
      "Yuanqing Xia"
    ],
    "abstract": "How to achieve precise distributed optimization despite unknown attacks,\nespecially the Byzantine attacks, is one of the critical challenges for\nmultiagent systems. This paper addresses a distributed resilient optimization\nfor linear heterogeneous multi-agent systems faced with adversarial threats. We\nestablish a framework aimed at realizing resilient optimization for\ncontinuous-time systems by incorporating a novel self-triggered hybrid\ndetection approach. The proposed hybrid detection approach is able to identify\nattacks on neighbors using both error thresholds and triggering intervals,\nthereby optimizing the balance between effective attack detection and the\nreduction of excessive communication triggers. Through using an edge-based\nadaptive self-triggered approach, each agent can receive its neighbors'\ninformation and determine whether these information is valid. If any neighbor\nprove invalid, each normal agent will isolate that neighbor by disconnecting\ncommunication along that specific edge. Importantly, our adaptive algorithm\nguarantees the accuracy of the optimization solution even when an agent is\nisolated by its neighbors.",
    "pdf_url": "http://arxiv.org/pdf/2410.13454v1",
    "published": "2024-10-17T11:31:22+00:00",
    "categories": [
      "eess.SY",
      "cs.MA",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13453v4",
    "title": "Adaptive Augmentation Policy Optimization with LLM Feedback",
    "authors": [
      "Ant Duru",
      "Alptekin Temizel"
    ],
    "abstract": "Data augmentation is a critical component of deep learning pipelines,\nenhancing model generalization by increasing dataset diversity. Traditional\naugmentation strategies rely on manually designed transformations, stochastic\nsampling, or automated search-based approaches. Although automated methods\nimprove performance, they often require extensive computational resources and\nare specifically designed for certain datasets. In this work, we propose a\nLarge Language Model (LLM)-guided augmentation optimization strategy that\nrefines augmentation policies based on model performance feedback. We propose\ntwo approaches: (1) LLM-Guided Augmentation Policy Optimization, where\naugmentation policies selected by LLM are refined iteratively across training\ncycles, and (2) Adaptive LLM-Guided Augmentation Policy Optimization, which\nadjusts policies at each iteration based on performance metrics. This\nin-training approach eliminates the need for full model retraining before\ngetting LLM feedback, reducing computational costs while increasing\nperformance. Our methodology employs an LLM to dynamically select augmentation\ntransformations based on dataset characteristics, model architecture, and prior\ntraining performance. Leveraging LLMs' contextual knowledge, especially in\ndomain-specific tasks like medical imaging, our method selects augmentations\ntailored to dataset characteristics and model performance. Experiments across\ndomain-specific image classification datasets show consistent accuracy\nimprovements over traditional methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13453v4",
    "published": "2024-10-17T11:26:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13452v2",
    "title": "A.I. go by many names: towards a sociotechnical definition of artificial intelligence",
    "authors": [
      "Johannes Dahlke"
    ],
    "abstract": "Defining artificial intelligence (AI) is a persistent challenge, often\nmuddied by technical ambiguity and varying interpretations. Commonly used\ndefinitions heavily emphasize technical properties of AI but neglect the human\npurpose of it. This essay makes a case for a sociotechnical definition of AI,\nwhich is essential for researchers who require clarity in their work. It\nexplores two primary approaches to define AI: the rationalistic, which focuses\non AI as systems that think and act rationally, and the humanistic, which\nframes AI in terms of its ability to emulate human intelligence. By reconciling\nthese approaches and contrasting them with landmark definitions, the essay\nproposes a sociotechnical definition that includes the three central aspects of\ni) technical functions, ii) human purpose, and iii) dynamic expectations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13452v2",
    "published": "2024-10-17T11:25:50+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13451v2",
    "title": "Parallel and Distributed Expander Decomposition: Simple, Fast, and Near-Optimal",
    "authors": [
      "Daoyuan Chen",
      "Simon Meierhans",
      "Maximilian Probst Gutenberg",
      "Thatchaphol Saranurak"
    ],
    "abstract": "Expander decompositions have become one of the central frameworks in the\ndesign of fast algorithms. For an undirected graph $G=(V,E)$, a near-optimal\n$\\phi$-expander decomposition is a partition $V_1, V_2, \\ldots, V_k$ of the\nvertex set $V$ where each subgraph $G[V_i]$ is a $\\phi$-expander, and only an\n$\\widetilde{O}(\\phi)$-fraction of the edges cross between partition sets.\n  In this article, we give the first near-optimal parallel algorithm to compute\n$\\phi$-expander decompositions in near-linear work $\\widetilde{O}(m/\\phi^2)$\nand near-constant span $\\widetilde{O}(1/\\phi^4)$. Our algorithm is very simple\nand likely practical. Our algorithm can also be implemented in the distributed\nCongest model in $\\tilde{O}(1/\\phi^4)$ rounds.\n  Our results surpass the theoretical guarantees of the current\nstate-of-the-art parallel algorithms [Chang-Saranurak PODC'19, Chang-Saranurak\nFOCS'20], while being the first to ensure that only an $\\tilde{O}(\\phi)$\nfraction of edges cross between partition sets. In contrast, previous\nalgorithms [Chang-Saranurak PODC'19, Chang-Saranurak FOCS'20] admit at least an\n$O(\\phi^{1/3})$ fraction of crossing edges, a polynomial loss in quality\ninherent to their random-walk-based techniques. Our algorithm, instead,\nleverages flow-based techniques and extends the popular sequential algorithm\npresented in [Saranurak-Wang SODA'19].",
    "pdf_url": "http://arxiv.org/pdf/2410.13451v2",
    "published": "2024-10-17T11:25:44+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13450v1",
    "title": "An Itô-type formula for some measure-valued processes and its application on controlled superprocesses",
    "authors": [
      "Shang Li"
    ],
    "abstract": "We derive an It\\^o-type formula for a measure-valued process that has a\ndecomposition analogous to a classical semimartingale. The derivation begins\nwith a time partitioning approach similar to the classical proof of It\\^o's\nformula. To address the new challenges arising from the measure-valued setting,\nwe employ symmetric polynomials to approximate the second-order linear\nderivative of the functional on finite measures, alongside certain localization\ntechniques.\n  A controlled superprocess with a binary branching mechanism can be\ninterpreted as a weak solution to a controlled stochastic partial differential\nequation (SPDE), which naturally leads to such a decomposition. Consequently,\nthis It\\^o-type formula makes it possible to derive the Hamilton-Jacobi-Bellman\n(HJB) equation and the verification theorem for controlled superprocesses with\na binary branching mechanism. Additionally, we propose a heuristic definition\nfor the viscosity solution of an equation involving derivatives on finite\nmeasures. We prove that a continuous value function is a viscosity solution in\nthis sense and demonstrate the uniqueness of the viscosity solution when the\nsecond-order derivative term on the measure vanishes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13450v1",
    "published": "2024-10-17T11:23:55+00:00",
    "categories": [
      "math.PR",
      "math.OC"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13449v1",
    "title": "Characterizing the support of semiclassical measures for higher-dimensional cat maps",
    "authors": [
      "Elena Kim",
      "Theresa C. Anderson",
      "Robert J. Lemke Oliver"
    ],
    "abstract": "Quantum cat maps are toy models in quantum chaos associated to hyperbolic\nsymplectic matrices $A\\in \\operatorname{Sp}(2n,\\mathbb{Z})$. The macroscopic\nlimits of sequences of eigenfunctions of a quantum cat map are characterized by\nsemiclassical measures on the torus $\\mathbb{R}^{2n}/\\mathbb{Z}^{2n}$. We show\nthat if the characteristic polynomial of every power $A^k$ is irreducible over\nthe rationals, then every semiclassical measure has full support. The proof\nuses an earlier strategy of Dyatlov-J\\'ez\\'equel [arXiv:2108.10463] and the\nhigher-dimensional fractal uncertainty principle of Cohen [arXiv:2305.05022].\nOur irreducibility condition is generically true, in fact we show that\nasymptotically for $100\\%$ of matrices $A$, the Galois group of the\ncharacteristic polynomial of $A$ is $S_2 \\wr S_n$.\n  When the irreducibility condition does not hold, we show that a semiclassical\nmeasure cannot be supported on a finite union of parallel non-coisotropic\nsubtori. On the other hand, we give examples of semiclassical measures\nsupported on the union of two transversal symplectic subtori for $n=2$,\ninspired by the work of Faure-Nonnenmacher-De Bi\\`evre [arXiv:nlin/0207060] in\nthe case $n=1$. This is complementary to the examples by Kelmer\n[arXiv:math-ph/0510079] of semiclassical measures supported on a single\ncoisotropic subtorus.",
    "pdf_url": "http://arxiv.org/pdf/2410.13449v1",
    "published": "2024-10-17T11:22:13+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "math.NT",
      "math.SP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13448v2",
    "title": "Fast Estimation of Partial Dependence Functions using Trees",
    "authors": [
      "Jinyang Liu",
      "Tessa Steensgaard",
      "Marvin N. Wright",
      "Niklas Pfister",
      "Munir Hiabu"
    ],
    "abstract": "Many existing interpretation methods are based on Partial Dependence (PD)\nfunctions that, for a pre-trained machine learning model, capture how a subset\nof the features affects the predictions by averaging over the remaining\nfeatures.\n  Notable methods include Shapley additive explanations (SHAP) which computes\nfeature contributions based on a game theoretical interpretation and PD plots\n(i.e., 1-dim PD functions) that capture average marginal main effects. Recent\nwork has connected these approaches using a functional decomposition and argues\nthat SHAP values can be misleading since they merge main and interaction\neffects into a single local effect. However, a major advantage of SHAP compared\nto other PD-based interpretations has been the availability of fast estimation\ntechniques, such as \\texttt{TreeSHAP}.\n  In this paper, we propose a new tree-based estimator, \\texttt{FastPD}, which\nefficiently estimates arbitrary PD functions.\n  We show that \\texttt{FastPD} consistently estimates the desired population\nquantity -- in contrast to path-dependent \\texttt{TreeSHAP} which is\ninconsistent when features are correlated.\n  For moderately deep trees, \\texttt{FastPD} improves the complexity of\nexisting methods from quadratic to linear in the number of observations.\n  By estimating PD functions for arbitrary feature subsets, \\texttt{FastPD} can\nbe used to extract PD-based interpretations such as SHAP, PD plots and\nhigher-order interaction effects.",
    "pdf_url": "http://arxiv.org/pdf/2410.13448v2",
    "published": "2024-10-17T11:21:47+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13447v1",
    "title": "Coarsening in the Long-range Ising Model with Conserved Dynamics",
    "authors": [
      "Soumik Ghosh",
      "Subir K. Das"
    ],
    "abstract": "While the kinetics of domain growth, even for conserved order-parameter\ndynamics, is widely studied for short-range inter-particle interactions,\nsystems having long-range interactions are receiving attention only recently.\nHere we present results, for such dynamics, from a Monte Carlo (MC) study of\nthe two-dimensional long-range Ising model, with critical compositions of up\nand down spins. The order parameter in the MC simulations was conserved via the\nincorporation of the Kawasaki spin-exchange method. The simulation results for\ndomain growth, following quenches of the homogeneous systems to temperatures\nbelow the critical values $T_c$, were analyzed via finite-size scaling and\nother advanced methods. The outcomes reveal that the growths follow power-laws,\nwith the exponent having interesting dependence on the range of interaction.\nQuite interstingly, when the range is above a cut-off, the exponent, for any\ngiven range, changes from a larger value to a smaller one, during the evolution\nprocess. While the corresponding values at late times match with certain\ntheoretical predictions for the conserved order-parameter dynamics, the ones at\nthe early times appear surprisingly high, quite close to the theoretical values\nfor the nonconserved case.",
    "pdf_url": "http://arxiv.org/pdf/2410.13447v1",
    "published": "2024-10-17T11:21:18+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2410.13446v1",
    "title": "Joint Antenna Selection and Covariance Matrix Optimization for ISAC Systems",
    "authors": [
      "Michail Palaiologos",
      "Mario H. Castãneda García",
      "Tobias Laas",
      "Richard A. Stirling-Gallacher",
      "Giuseppe Caire"
    ],
    "abstract": "We consider an integrated sensing and communication (ISAC) system with a\nsingle communication user and multiple targets. For the communication\nfunctionality, the achievable rate is employed as the performance metric, while\nfor sensing, we focus on minimizing the mean squared error (MSE) between the\ndesigned beampattern and a desired one for tracking the targets. Towards this,\nand by assuming that there are fewer radiofrequency (RF) chains than antenna\nelements at the transmitter (Tx), we focus on the joint antenna selection (AS)\nand covariance matrix (CM) optimization at the Tx. This is a mixed-integer\noptimization problem, yet we demonstrate that it can be efficiently solved, in\npolynomial time, by combining convex optimization tools with dynamic\nprogramming (DP). By introducing an adjustable trade-off parameter, we\nformulate a joint objective function that captures both the communication and\nsensing metric. In this way, different ISAC solutions can be obtained,\nconsidering the trade-off among the two functionalities. It is shown that\nselecting the active antennas with our proposed method is superior than\nassuming a uniform Tx array with fixed antenna positions. Notably, by\nindividually considering the optimization of either the sensing or the\ncommunication system alone, our proposed algorithm outperforms the literature\nproposals, by incurring only a small increase in complexity.",
    "pdf_url": "http://arxiv.org/pdf/2410.13446v1",
    "published": "2024-10-17T11:20:16+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13445v1",
    "title": "Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR",
    "authors": [
      "Abhishek Gupta",
      "Amruta Parulekar",
      "Sameep Chattopadhyay",
      "Preethi Jyothi"
    ],
    "abstract": "Automatic speech recognition (ASR) for low-resource languages remains a\nchallenge due to the scarcity of labeled training data. Parameter-efficient\nfine-tuning and text-only adaptation are two popular methods that have been\nused to address such low-resource settings. In this work, we investigate how\nthese techniques can be effectively combined using a multilingual multimodal\nmodel like SeamlessM4T. Multimodal models are able to leverage unlabeled text\nvia text-only adaptation with further parameter-efficient ASR fine-tuning, thus\nboosting ASR performance. We also show cross-lingual transfer from a\nhigh-resource language, achieving up to a relative 17% WER reduction over a\nbaseline in a zero-shot setting without any labeled speech.",
    "pdf_url": "http://arxiv.org/pdf/2410.13445v1",
    "published": "2024-10-17T11:19:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13444v2",
    "title": "Three state random energy model",
    "authors": [
      "Sumedha",
      "Matteo Marsili"
    ],
    "abstract": "We introduce a spin-1 version of the random energy model with crystal field.\nCrystal field controls the density of 0 spins in the system. We solve the model\nin the micro-canonincal ensemble. The model has a spin-glass transition at a\nfinite temperature for all strengths of the crystal field. By introducing the\nmagnetic field we also obtain the de Almeida Thouless line for the model. The\nspin-glass transition persists in the presence of external field. We also find\nthat the magnetisation shows non-monotonic behaviour for high positive crystal\nfield strengths. The zero magnetic field specific heat and magnetic\nsusceptibility also exhibit a cusp beyond a threshold value of the crystal\nfield.",
    "pdf_url": "http://arxiv.org/pdf/2410.13444v2",
    "published": "2024-10-17T11:19:38+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2410.13443v1",
    "title": "NLIP_Lab-IITH Multilingual MT System for WAT24 MT Shared Task",
    "authors": [
      "Maharaj Brahma",
      "Pramit Sahoo",
      "Maunendra Sankar Desarkar"
    ],
    "abstract": "This paper describes NLIP Lab's multilingual machine translation system for\nthe WAT24 shared task on multilingual Indic MT task for 22 scheduled languages\nbelonging to 4 language families. We explore pre-training for Indic languages\nusing alignment agreement objectives. We utilize bi-lingual dictionaries to\nsubstitute words from source sentences. Furthermore, we fine-tuned language\ndirection-specific multilingual translation models using small and high-quality\nseed data. Our primary submission is a 243M parameters multilingual translation\nmodel covering 22 Indic languages. In the IN22-Gen benchmark, we achieved an\naverage chrF++ score of 46.80 and 18.19 BLEU score for the En-Indic direction.\nIn the Indic-En direction, we achieved an average chrF++ score of 56.34 and\n30.82 BLEU score. In the In22-Conv benchmark, we achieved an average chrF++\nscore of 43.43 and BLEU score of 16.58 in the En-Indic direction, and in the\nIndic-En direction, we achieved an average of 52.44 and 29.77 for chrF++ and\nBLEU respectively. Our model\\footnote{Our code and models are available at\n\\url{https://github.com/maharajbrahma/WAT2024-MultiIndicMT}} is competitive\nwith IndicTransv1 (474M parameter model).",
    "pdf_url": "http://arxiv.org/pdf/2410.13443v1",
    "published": "2024-10-17T11:18:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13442v1",
    "title": "Heavy-light Pseudoscalar Mesons: Light-Front Wave Functions and Generalized Parton Distributions",
    "authors": [
      "B. Almeida-Zamora",
      "J. J. Cobos-Martínez",
      "A. Bashir",
      "K. Raya",
      "J. Rodríguez-Quintero",
      "J. Segovia"
    ],
    "abstract": "The internal structure of the lowest-lying pseudo-scalar mesons with\nheavy-light quark content is thoroughly studied using an algebraic model that\nhas been successfully applied to similar physical observables of pseudoscalar\nand vector mesons with hidden-flavor quark content, ranging from light to heavy\nquark sectors. This model is based on constructing simple and evidence-based\nans\\\"atze for the mesons' Bethe-Salpeter amplitude (BSA) and quark propagator,\nallowing the Bethe-Salpeter wave function (BSWF) to be computed algebraically.\nIts projection onto the light front yields the corresponding light-front wave\nfunction (LFWF), which provides easy access to the valence-quark Parton\nDistribution Amplitude (PDA) by integrating over the transverse momentum\nsquared. We leverage our current knowledge of the PDAs of the lowest-lying\npseudo-scalar heavy-light mesons to compute their Generalized Parton\nDistributions (GPDs) via the overlap representation of the LFWFs. From this\nthree-dimensional information, various limits and projections allow us to\ndeduce the related Parton Distribution Functions (PDFs), Electromagnetic Form\nFactors (EFFs), and Impact Parameter Space GPDs (IPS-GPDs). Whenever possible,\nwe make explicit comparisons with available experimental results and previous\ntheoretical predictions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13442v1",
    "published": "2024-10-17T11:17:56+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-lat",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13441v1",
    "title": "Instruction-Driven Game Engine: A Poker Case Study",
    "authors": [
      "Hongqiu Wu",
      "Xingyuan Liu",
      "Yan Wang",
      "Hai Zhao"
    ],
    "abstract": "The Instruction-Driven Game Engine (IDGE) project aims to democratize game\ndevelopment by enabling a large language model (LLM) to follow free-form game\ndescriptions and generate game-play processes. The IDGE allows users to create\ngames simply by natural language instructions, which significantly lowers the\nbarrier for game development. We approach the learning process for IDGEs as a\nNext State Prediction task, wherein the model autoregressively predicts the\ngame states given player actions. The computation of game states must be\nprecise; otherwise, slight errors could corrupt the game-play experience. This\nis challenging because of the gap between stability and diversity. To address\nthis, we train the IDGE in a curriculum manner that progressively increases its\nexposure to complex scenarios. Our initial progress lies in developing an IDGE\nfor Poker, which not only supports a wide range of poker variants but also\nallows for highly individualized new poker games through natural language\ninputs. This work lays the groundwork for future advancements in transforming\nhow games are created and played.",
    "pdf_url": "http://arxiv.org/pdf/2410.13441v1",
    "published": "2024-10-17T11:16:27+00:00",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13440v1",
    "title": "From outskirts to core: the suppression and activation of radio AGN around galaxy clusters",
    "authors": [
      "K de Vos",
      "N. A. Hatch",
      "M. R. Merrifield"
    ],
    "abstract": "To investigate how the radio-identified active galactic nuclei (AGN) fraction\nvaries with cluster-centric radius, we present the projected and de-projected\ndistributions of a large sample of LOFAR-identified radio AGN out to\n$30R_{500}$ around galaxy clusters. The AGN fraction experiences a $\\sim 25\\%$\nincrease above the field fraction in the cluster outskirts at around\n$10R_{500}$, a $\\sim 20\\%$ decrease around $\\sim 0.5R_{500}$, and an increase\nof over three times the field fraction value in the very cluster core. We label\nthese three radial windows the outer, intermediate and inner regions\nrespectively, and investigate how these radial trends might arise due to\nintrinsic properties of the AGN population. The only difference seen in host\ngalaxy stellar mass is in the inner region, where there is a much higher\nfraction of massive host galaxies. Analysing AGN radio luminosity, regions with\na higher AGN fraction tend to have more radio luminous AGN, and vice versa. We\ndiscuss the physical mechanisms that might be responsible for these results\nwith reference to the literature.",
    "pdf_url": "http://arxiv.org/pdf/2410.13440v1",
    "published": "2024-10-17T11:14:43+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13439v4",
    "title": "Similarity-Dissimilarity Loss for Multi-label Supervised Contrastive Learning",
    "authors": [
      "Guangming Huang",
      "Yunfei Long",
      "Cunjin Luo"
    ],
    "abstract": "Supervised contrastive learning has achieved remarkable success by leveraging\nlabel information; however, determining positive samples in multi-label\nscenarios remains a critical challenge. In multi-label supervised contrastive\nlearning (MSCL), multi-label relations are not yet fully defined, leading to\nambiguity in identifying positive samples and formulating contrastive loss\nfunctions to construct the representation space. To address these challenges,\nwe: (i) first define five distinct multi-label relations in MSCL to\nsystematically identify positive samples, (ii) introduce a novel\nSimilarity-Dissimilarity Loss that dynamically re-weights samples through\ncomputing the similarity and dissimilarity factors between positive samples and\ngiven anchors based on multi-label relations, and (iii) further provide\ntheoretical grounded proofs for our method through rigorous mathematical\nanalysis that supports the formulation and effectiveness of the proposed loss\nfunction. We conduct the experiments across both image and text modalities, and\nextend the evaluation to medical domain. The results demonstrate that our\nmethod consistently outperforms baselines in a comprehensive evaluation,\nconfirming its effectiveness and robustness. Code is available at:\nhttps://github.com/guangminghuang/similarity-dissimilarity-loss.",
    "pdf_url": "http://arxiv.org/pdf/2410.13439v4",
    "published": "2024-10-17T11:12:55+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13921v1",
    "title": "Epidemic waves for a two-group SIRS model with double nonlocal effects in a patchy environment",
    "authors": [
      "Chufen Wu",
      "Yonghui Xia",
      "Jianshe Yu"
    ],
    "abstract": "We propose a lattice dynamical system that arises in a discrete diffusive\ntwo-group epidemic model with latency in a patchy environment. The model\nconsiders the SIS form and latency of the disease in group 1, while the SIR\nform without latency of the disease in group 2. The system includes double\nnonlocal effects, one effect is the nonlocal diffusion of individuals in\nisolated patches or niches, while the other effect is the distributed\ntransmission delay representing the incubation of the disease. We demonstrate\nthat there is a threshold value $c^*$ that can determine the persistence or\ndisappearance of the disease. If $c\\geq c^*$, then there is an epidemic wave\nconnecting the disease-free equilibrium and endemic equilibrium. In this case,\nthe disease will evolve to endemic. If $0<c<c^*$, then the disease will die\nout.",
    "pdf_url": "http://arxiv.org/pdf/2410.13921v1",
    "published": "2024-10-17T11:09:20+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13438v1",
    "title": "Universal multipliers for Sub-Hardy Hilbert spaces",
    "authors": [
      "Bartosz Malman",
      "Daniel Seco"
    ],
    "abstract": "To every non-extreme point $b$ of the unit ball of $\\hil^\\infty$ of the unit\ndisk there corresponds a Pythagorean mate, a bounded outer function $a$\nsatisfying the equation $|a|^2 + |b|^2 = 1$ on the boundary of the disk. We\nstudy universal, i.e., simultaneous multipliers for families of de\nBranges-Rovnyak spaces $\\hb$, and develop a general framework for this purpose.\nOur main results include a new proof of the Davis-McCarthy universal multiplier\ntheorem for the class of all non-extreme spaces $\\hb$, a characterization of\nthe Lipschitz classes as the universal multipliers for spaces $\\hb$ for which\nthe quotient $b/a$ is contained in a Hardy space, and a similar\ncharacterization of the Gevrey classes as the universal multipliers for spaces\n$\\hb$ for which $b/a$ is contained in a Privalov class.",
    "pdf_url": "http://arxiv.org/pdf/2410.13438v1",
    "published": "2024-10-17T11:08:08+00:00",
    "categories": [
      "math.FA",
      "math.CV",
      "Primary 30H45, Secondary 47B32"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13437v1",
    "title": "Temporal-Enhanced Multimodal Transformer for Referring Multi-Object Tracking and Segmentation",
    "authors": [
      "Changcheng Xiao",
      "Qiong Cao",
      "Yujie Zhong",
      "Xiang Zhang",
      "Tao Wang",
      "Canqun Yang",
      "Long Lan"
    ],
    "abstract": "Referring multi-object tracking (RMOT) is an emerging cross-modal task that\naims to locate an arbitrary number of target objects and maintain their\nidentities referred by a language expression in a video. This intricate task\ninvolves the reasoning of linguistic and visual modalities, along with the\ntemporal association of target objects. However, the seminal work employs only\nloose feature fusion and overlooks the utilization of long-term information on\ntracked objects. In this study, we introduce a compact Transformer-based\nmethod, termed TenRMOT. We conduct feature fusion at both encoding and decoding\nstages to fully exploit the advantages of Transformer architecture.\nSpecifically, we incrementally perform cross-modal fusion layer-by-layer during\nthe encoding phase. In the decoding phase, we utilize language-guided queries\nto probe memory features for accurate prediction of the desired objects.\nMoreover, we introduce a query update module that explicitly leverages temporal\nprior information of the tracked objects to enhance the consistency of their\ntrajectories. In addition, we introduce a novel task called Referring\nMulti-Object Tracking and Segmentation (RMOTS) and construct a new dataset\nnamed Ref-KITTI Segmentation. Our dataset consists of 18 videos with 818\nexpressions, and each expression averages 10.7 masks, which poses a greater\nchallenge compared to the typical single mask in most existing referring video\nsegmentation datasets. TenRMOT demonstrates superior performance on both the\nreferring multi-object tracking and the segmentation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13437v1",
    "published": "2024-10-17T11:07:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13436v3",
    "title": "Multi-frame Detection via Graph Neural Networks: A Link Prediction Approach",
    "authors": [
      "Zhihao Lin",
      "Chang Gao",
      "Junkun Yan",
      "Qingfu Zhang",
      "Bo Chen",
      "Hongwei Liu"
    ],
    "abstract": "Multi-frame detection algorithms can effectively utilize the correlation\nbetween consecutive echoes to improve the detection performance of weak\ntargets. Existing efficient multi-frame detection algorithms are typically\nbased on three sequential steps: plot extraction via a relative low primary\nthreshold, track search and track detection. However, these three-stage\nprocessing algorithms may result in a notable loss of detection performance and\ndo not fully leverage the available echo information across frames. As to\napplying graph neural networks in multi-frame detection, the algorithms are\nprimarily based on node classification tasks, which cannot directly output\ntarget tracks. In this paper, we reformulate the multi-frame detection problem\nas a link prediction task in graphs. First, we perform a rough association of\nmulti-frame observations that exceed the low threshold to construct observation\nassociation graphs. Subsequently, a multi-feature link prediction network is\ndesigned based on graph neural networks, which integrates multi-dimensional\ninformation, including echo structure, Doppler information, and spatio-temporal\ncoupling of plots. By leveraging the principle of link prediction, we unifies\nthe processes of track search and track detection into one step to reduce\nperformance loss and directly output target tracks. Experimental results\nindicate that, compared with traditional single-frame and multi-frame detection\nalgorithms, the proposed algorithm improves the detection performance of weak\ntargets while suppressing false alarms. Additionally, interpretable analysis\nshows that the designed network effectively integrates the utilized features,\nallowing for accurate associations between targets and false alarms.",
    "pdf_url": "http://arxiv.org/pdf/2410.13436v3",
    "published": "2024-10-17T11:06:06+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13435v1",
    "title": "Microscopic description of spontaneous fission based on a Gogny energy density functional including tensor contributions",
    "authors": [
      "R. Rodríguez-Guzmán",
      "L. M. Robledo",
      "R. N. Bernard"
    ],
    "abstract": "This paper extends previous studies on the impact of tensor forces in fission\ndynamics of neutron-deficient Thorium isotopes to other isotopic chains of\nheavy actinides and low-mass super-heavy nuclei. Calculations are carried out\nwithin a mean-field framework based on the Gogny-D1S parametrization\nsupplemented with the D1ST2a perturbative tensor term as driving force. Fission\nbarrier heights and spontaneous fission half-lives are used as benchmarks to\nanalyze the impact of the tensor term. A significant reduction of fission\nbarrier heights and half-lives is associated to the tensor component of the\nforce.",
    "pdf_url": "http://arxiv.org/pdf/2410.13435v1",
    "published": "2024-10-17T11:05:54+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13434v1",
    "title": "Phase Separation in the Putative Fractional Quantum Hall A phases",
    "authors": [
      "Steven H. Simon",
      "Ajit C. Balram"
    ],
    "abstract": "We use several techniques to probe the wave functions proposed to describe\nthe ${\\cal A}$ phases by Das, Das, and Mandal [Phys. Rev. Lett. 131, 056202\n(2023); Phys. Rev. Lett. 132, 106501 (2024); Phys. Rev. B 110, L121303\n(2024).]. As opposed to representing fractional quantum Hall liquids, we find\nthese wave functions to describe states that clearly display strong phase\nseparation. In the process of exploring these wave functions, we have also\nconstructed several new methods for diagnosing phase separation and generating\nsuch wave functions numerically. Finally, we uncover a new property of\nentanglement spectra that can be used as a check for the accuracy of numerics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13434v1",
    "published": "2024-10-17T11:05:49+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13433v1",
    "title": "Normal Families of Holomorphic Curves and Sharing of Moving Hyperplanes Wandering on $\\mathbb{P}^n$",
    "authors": [
      "Gopal Datt",
      "Naveen Gupta",
      "Nikhil Khanna",
      "Ritesh Pal"
    ],
    "abstract": "In this paper, we extend a result of Schwick concerning normality and sharing\nvalues in one complex variable for families of holomorphic curves taking values\nin $\\mathbb{P}^n$. We consider wandering moving hyperplanes (i.e., depending on\nthe respective holomorphic curve in the family under consideration), and\nestablish a sufficient condition of normality concerning shared hyperplanes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13433v1",
    "published": "2024-10-17T10:55:19+00:00",
    "categories": [
      "math.CV",
      "32A19, 30D45"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13432v2",
    "title": "Strong regularization by noise for a class of kinetic SDEs driven by symmetric α-stable processes",
    "authors": [
      "Giacomo Lucertini",
      "Stéphane Menozzi",
      "Stefano Pagliarani"
    ],
    "abstract": "We establish strong well-posedness for a class of degenerate SDEs of kinetic\ntype with autonomous diffusion driven by a symmetric $\\alpha$-stable process\nunder H\\\"older regularity conditions for the drift term. We partially recover\nthe thresholds for the H\\\"older regularity that are optimal for weak\nuniqueness. In general dimension, we only consider $\\alpha = 2$ and need an\nadditional integrability assumption for the gradient of the drift: this\ncondition is satisfied by Peano-type functions. In the one-dimensional case we\ndo not need any additional assumption. In the multi-dimensional case, the proof\nis based on a first-order Zvonkin transform/PDE, while for the one-dimensional\ncase we use a second-order Zvonkin/PDE transform together with a\nWatanabe-Yamada technique.",
    "pdf_url": "http://arxiv.org/pdf/2410.13432v2",
    "published": "2024-10-17T10:55:09+00:00",
    "categories": [
      "math.PR",
      "60H30, 60H10, 60H50"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13431v1",
    "title": "Solving Prior Distribution Mismatch in Diffusion Models via Optimal Transport",
    "authors": [
      "Zhanpeng Wang",
      "Shenghao Li",
      "Chen Wang",
      "Shuting Cao",
      "Na Lei",
      "Zhongxuan Luo"
    ],
    "abstract": "In recent years, the knowledge surrounding diffusion models(DMs) has grown\nsignificantly, though several theoretical gaps remain. Particularly noteworthy\nis prior error, defined as the discrepancy between the termination distribution\nof the forward process and the initial distribution of the reverse process. To\naddress these deficiencies, this paper explores the deeper relationship between\noptimal transport(OT) theory and DMs with discrete initial distribution.\nSpecifically, we demonstrate that the two stages of DMs fundamentally involve\ncomputing time-dependent OT. However, unavoidable prior error result in\ndeviation during the reverse process under quadratic transport cost. By proving\nthat as the diffusion termination time increases, the probability flow\nexponentially converges to the gradient of the solution to the classical\nMonge-Amp\\`ere equation, we establish a vital link between these fields.\nTherefore, static OT emerges as the most intrinsic single-step method for\nbridging this theoretical potential gap. Additionally, we apply these insights\nto accelerate sampling in both unconditional and conditional generation\nscenarios. Experimental results across multiple image datasets validate the\neffectiveness of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2410.13431v1",
    "published": "2024-10-17T10:54:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13430v1",
    "title": "One variable Generalization of five entries of Ramanujan and their finite analogue",
    "authors": [
      "Archit Agarwal"
    ],
    "abstract": "Ramanujan recorded five $q$-series identities at the end of his second\nnotebook and an unified generalization of these identities obtained by Bhoria,\nEyyunni and Maji. Recently, Dixit and Patel gave a finite analogue of the\nidentity of Bhoria et. al. which in turn gives finite analogue of all the\naforementioned identities of Ramanujan. In this paper, one of our main goals is\nto obtain a one-variable generalization of the identity of Bhoria et. al. along\nwith its finite analogue, which naturally generalizes the result of Dixit and\nPatel. Utilizing these newly established identities, we derive one-variable\ngeneralizations for each of the five entries by Ramanujan and their\ncorresponding finite analogues.",
    "pdf_url": "http://arxiv.org/pdf/2410.13430v1",
    "published": "2024-10-17T10:54:46+00:00",
    "categories": [
      "math.NT",
      "Primary 11P81, 33D15, Secondary 11P84, 05A17"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13429v2",
    "title": "Towards Formal Verification of Federated Learning Orchestration Protocols on Satellites",
    "authors": [
      "Miroslav Popovic",
      "Marko Popovic",
      "Miodrag Djukic",
      "Ilija Basicevic"
    ],
    "abstract": "Python Testbed for Federated Learning Algorithms (PTB-FLA) is a simple FL\nframework targeting smart Internet of Things in edge systems that provides both\ngeneric centralized and decentralized FL algorithms, which implement the\ncorresponding FL orchestration protocols that were formally verified using the\nprocess algebra CSP. This approach is appropriate for systems with stationary\nnodes but cannot be applied to systems with moving nodes. In this paper, we use\ncelestial mechanics to model spacecraft movement, and timed automata (TA) to\nformalize and verify the centralized FL orchestration protocol, in two phases.\nIn the first phase, we created a conventional TA model to prove traditional\nproperties, namely deadlock freeness and termination. In the second phase, we\ncreated a stochastic TA model to prove timing correctness and to estimate\ntermination probability.",
    "pdf_url": "http://arxiv.org/pdf/2410.13429v2",
    "published": "2024-10-17T10:52:16+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13428v3",
    "title": "Generate and Instantiate What You Prefer: Text-Guided Diffusion for Sequential Recommendation",
    "authors": [
      "Guoqing Hu",
      "Zhengyi Yang",
      "Zhibo Cai",
      "An Zhang",
      "Xiang Wang"
    ],
    "abstract": "Recent advancements in generative recommendation systems, particularly in the\nrealm of sequential recommendation tasks, have shown promise in enhancing\ngeneralization to new items. Among these approaches, diffusion-based generative\nrecommendation has emerged as an effective tool, leveraging its ability to\ncapture data distributions and generate high-quality samples. Despite\neffectiveness, two primary challenges have been identified: 1) the lack of\nconsistent modeling of data distribution for oracle items; and 2) the\ndifficulty in scaling to more informative control signals beyond historical\ninteractions. These issues stem from the uninformative nature of ID embeddings,\nwhich necessitate random initialization and limit the incorporation of\nadditional control signals. To address these limitations, we propose iDreamRec\nto involve more concrete prior knowledge to establish item embeddings,\nparticularly through detailed item text descriptions and advanced Text\nEmbedding Models (TEM). More importantly, by converting item descriptions into\nembeddings aligned with TEM, we enable the integration of intention\ninstructions as control signals to guide the generation of oracle items.\nExperimental results on four datasets demonstrate that iDreamRec not only\noutperforms existing diffusion-based generative recommenders but also\nfacilitates the incorporation of intention instructions for more precise and\neffective recommendation generation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13428v3",
    "published": "2024-10-17T10:51:34+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13427v1",
    "title": "Unsupervised Skull Segmentation via Contrastive MR-to-CT Modality Translation",
    "authors": [
      "Kamil Kwarciak",
      "Mateusz Daniol",
      "Daria Hemmerling",
      "Marek Wodzinski"
    ],
    "abstract": "The skull segmentation from CT scans can be seen as an already solved\nproblem. However, in MR this task has a significantly greater complexity due to\nthe presence of soft tissues rather than bones. Capturing the bone structures\nfrom MR images of the head, where the main visualization objective is the\nbrain, is very demanding. The attempts that make use of skull stripping seem to\nnot be well suited for this task and fail to work in many cases. On the other\nhand, supervised approaches require costly and time-consuming skull\nannotations. To overcome the difficulties we propose a fully unsupervised\napproach, where we do not perform the segmentation directly on MR images, but\nwe rather perform a synthetic CT data generation via MR-to-CT translation and\nperform the segmentation there. We address many issues associated with\nunsupervised skull segmentation including the unpaired nature of MR and CT\ndatasets (contrastive learning), low resolution and poor quality\n(super-resolution), and generalization capabilities. The research has a\nsignificant value for downstream tasks requiring skull segmentation from MR\nvolumes such as craniectomy or surgery planning and can be seen as an important\nstep towards the utilization of synthetic data in medical imaging.",
    "pdf_url": "http://arxiv.org/pdf/2410.13427v1",
    "published": "2024-10-17T10:51:08+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13426v1",
    "title": "A simple proof of the formula of Solov'ev--Nielsen--Blom for the expected waiting time",
    "authors": [
      "Yuuya Yoshida"
    ],
    "abstract": "Solov'ev (1966), Nielsen (1973), and Blom (1982) independently showed a\nformula for the expected waiting time until a given finite pattern first occurs\nin random data. In this paper, we give a simple and combinatorial proof of the\nformula.",
    "pdf_url": "http://arxiv.org/pdf/2410.13426v1",
    "published": "2024-10-17T10:49:51+00:00",
    "categories": [
      "math.PR",
      "math.CO",
      "60E05 68R15"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13425v1",
    "title": "Touching Loop Patterns with Cellular Automata",
    "authors": [
      "Rolf Hoffmann"
    ],
    "abstract": "The objective is the design of a Cellular Automata rule that can form\npatterns with 'touching' loops. A loop is defined as a closed path of 1-cells\nin a 2D grid on a zero background and with a zero border. A path cell is\nconnected with two of its adjacent neighbors. In touching loops a path cell is\nalso allowed to touch another on a diagonal. A CA rule was designed that can\nevolve stable touching loop patterns. The rule tries to cover the 2D space by\noverlapping tiles. The rule uses so-called templates, 5 x 5 matching patterns\nwhich are systematically derived from the given set of 3 x 3 tiles. The rule\nchecks the pattern being evolved against a list of templates. If the outer\nneighbors of a template match, then the cell's state is set to the template's\ncenter value. Noise is injected if there is no matching template, or the tiles\nare not properly assembled. Thereby the evolution is driven to the desired loop\npatterns.",
    "pdf_url": "http://arxiv.org/pdf/2410.13425v1",
    "published": "2024-10-17T10:47:23+00:00",
    "categories": [
      "nlin.CG",
      "math.GT"
    ],
    "primary_category": "nlin.CG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13424v1",
    "title": "Problems of dark atom cosmology",
    "authors": [
      "V. A. Beylin",
      "M. Yu. Khlopov",
      "D. O. Sopin"
    ],
    "abstract": "The dark atoms $XHe$ are the composite Thomson like atomic dark matter\ncandidates. We address two cosmological problems of this model. The excess of\nnew superheavy particles with even negative charge $X^{-2n}$ over the\ncorresponding antiparticles is balanced by sphaleron transitions with baryon\nasymmetry and the mass range of $X$ particles should be specified at which this\nexcess can provide dominance of dark atoms in the dark matter density. The\nother problem is possible capture of light nuclei by dark atoms, which can lead\nto formation of anomalous isotopes. The possibility of formation of multi dark\natom systems at the nucleosynthesis stage is also studied. We approach these\nopen questions of dark atom cosmology in the present work.",
    "pdf_url": "http://arxiv.org/pdf/2410.13424v1",
    "published": "2024-10-17T10:46:25+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13423v1",
    "title": "Kernels and integration cycles in complex Langevin simulations",
    "authors": [
      "Michael Mandl",
      "Michael W. Hansen",
      "Erhard Seiler",
      "Dénes Sexty"
    ],
    "abstract": "The method of complex Langevin simulations is a tool that can be used to\ntackle the complex-action problem encountered, for instance, in finite-density\nlattice quantum chromodynamics or real-time lattice field theories. The method\nis based on a stochastic evolution of the dynamical degrees of freedom via\n(complex) Langevin equations, which, however, sometimes converge to the wrong\nequilibrium distributions. While the convergence properties of the evolution\ncan to some extent be assessed by studying so-called boundary terms, we\ndemonstrate in this contribution that boundary terms on their own are not\nsufficient as a correctness criterion. Indeed, in their absence complex\nLangevin simulation results might still be spoiled by unwanted so-called\nintegration cycles. In particular, we elaborate on how the introduction of a\nkernel into the complex Langevin equation can - in principle - be used to\ncontrol which integration cycles are sampled in a simulation such that correct\nconvergence is restored.",
    "pdf_url": "http://arxiv.org/pdf/2410.13423v1",
    "published": "2024-10-17T10:46:16+00:00",
    "categories": [
      "hep-lat",
      "hep-th"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2410.13422v1",
    "title": "Cooperative Visual Convex Area Coverage using a Tessellation-free Strategy",
    "authors": [
      "Sotiris Papatheodorou",
      "Anthony Tzes"
    ],
    "abstract": "The objective in this article is to develop a control strategy for coverage\npurposes of a convex region by a fleet of Mobile Aerial Agents (MAAs). Each MAA\nis equipped with a downward facing camera that senses a convex portion of the\narea while its altitude flight is constrained. Rather than relying on typical\nVoronoi-like tessellations of the area to be covered, a scheme focusing on the\nassignment to each MAA of certain parts of the mosaic of the current covered\narea is proposed. A gradient ascent algorithm is then employed to increase in a\nmonotonic manner the covered area by the MAA-fleet. Simulation studies are\noffered to illustrate the effectiveness of the proposed scheme.",
    "pdf_url": "http://arxiv.org/pdf/2410.13422v1",
    "published": "2024-10-17T10:45:51+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13421v1",
    "title": "Performance of Gaussian Mixture Model Classifiers on Embedded Feature Spaces",
    "authors": [
      "Jeremy Chopin",
      "Rozenn Dahyot"
    ],
    "abstract": "Data embeddings with CLIP and ImageBind provide powerful features for the\nanalysis of multimedia and/or multimodal data. We assess their performance here\nfor classification using a Gaussian Mixture models (GMMs) based layer as an\nalternative to the standard Softmax layer. GMMs based classifiers have recently\nbeen shown to have interesting performances as part of deep learning pipelines\ntrained end-to-end. Our first contribution is to investigate GMM based\nclassification performance taking advantage of the embedded spaces CLIP and\nImageBind. Our second contribution is in proposing our own GMM based classifier\nwith a lower parameters count than previously proposed. Our findings are, that\nin most cases, on these tested embedded spaces, one gaussian component in the\nGMMs is often enough for capturing each class, and we hypothesize that this may\nbe due to the contrastive loss used for training these embedded spaces that\nnaturally concentrates features together for each class. We also observed that\nImageBind often provides better performance than CLIP for classification of\nimage datasets even when these embedded spaces are compressed using PCA.",
    "pdf_url": "http://arxiv.org/pdf/2410.13421v1",
    "published": "2024-10-17T10:43:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13420v3",
    "title": "Spatial Proportional Hazards Model with Differential Regularization",
    "authors": [
      "Lorenzo Tedesco"
    ],
    "abstract": "This paper presents a semiparametric proportional hazards model designed to\nhandle spatially varying covariate functions, applicable to both geostatistical\nand areal data observed on irregular spatial domains. The model is estimated\nthrough the maximization of a penalized partial likelihood, with a roughness\npenalty term based on a differential of the spatial field over the target\ndomain. The finite element method is employed for efficient estimation,\nenabling a piecewise polynomial surface representation of the spatial field. We\napply this method to analyze response time data from the London Fire Brigade.",
    "pdf_url": "http://arxiv.org/pdf/2410.13420v3",
    "published": "2024-10-17T10:43:33+00:00",
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13419v1",
    "title": "MeloTrans: A Text to Symbolic Music Generation Model Following Human Composition Habit",
    "authors": [
      "Yutian Wang",
      "Wanyin Yang",
      "Zhenrong Dai",
      "Yilong Zhang",
      "Kun Zhao",
      "Hui Wang"
    ],
    "abstract": "At present, neural network models show powerful sequence prediction ability\nand are used in many automatic composition models. In comparison, the way\nhumans compose music is very different from it. Composers usually start by\ncreating musical motifs and then develop them into music through a series of\nrules. This process ensures that the music has a specific structure and\nchanging pattern. However, it is difficult for neural network models to learn\nthese composition rules from training data, which results in a lack of\nmusicality and diversity in the generated music. This paper posits that\nintegrating the learning capabilities of neural networks with human-derived\nknowledge may lead to better results. To archive this, we develop the\nPOP909$\\_$M dataset, the first to include labels for musical motifs and their\nvariants, providing a basis for mimicking human compositional habits. Building\non this, we propose MeloTrans, a text-to-music composition model that employs\nprinciples of motif development rules. Our experiments demonstrate that\nMeloTrans excels beyond existing music generation models and even surpasses\nLarge Language Models (LLMs) like ChatGPT-4. This highlights the importance of\nmerging human insights with neural network capabilities to achieve superior\nsymbolic music generation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13419v1",
    "published": "2024-10-17T10:41:52+00:00",
    "categories": [
      "cs.SD",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13418v1",
    "title": "Interactive Navigation with Adaptive Non-prehensile Mobile Manipulation",
    "authors": [
      "Cunxi Dai",
      "Xiaohan Liu",
      "Koushil Sreenath",
      "Zhongyu Li",
      "Ralph Hollis"
    ],
    "abstract": "This paper introduces a framework for interactive navigation through adaptive\nnon-prehensile mobile manipulation. A key challenge in this process is handling\nobjects with unknown dynamics, which are difficult to infer from visual\nobservation. To address this, we propose an adaptive dynamics model for common\nmovable indoor objects via learned SE(2) dynamics representations. This model\nis integrated into Model Predictive Path Integral (MPPI) control to guide the\nrobot's interactions. Additionally, the learned dynamics help inform\ndecision-making when navigating around objects that cannot be manipulated.Our\napproach is validated in both simulation and real-world scenarios,\ndemonstrating its ability to accurately represent object dynamics and\neffectively manipulate various objects. We further highlight its success in the\nNavigation Among Movable Objects (NAMO) task by deploying the proposed\nframework on a dynamically balancing mobile robot, Shmoobot. Project website:\nhttps://cmushmoobot.github.io/AdaptivePushing/.",
    "pdf_url": "http://arxiv.org/pdf/2410.13418v1",
    "published": "2024-10-17T10:40:31+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13417v3",
    "title": "W*-superrigidity for groups with infinite center",
    "authors": [
      "Milan Donvil",
      "Stefaan Vaes"
    ],
    "abstract": "We construct discrete groups $G$ with infinite center that are nevertheless\nW*-superrigid, meaning that the group von Neumann algebra $L(G)$ fully\nremembers the group $G$. We obtain these rigidity results both up to\nisomorphisms and up to virtual isomorphisms of the groups and their von Neumann\nalgebras. Our methods combine rigidity results for the quotient of these groups\nby their center with rigidity results for their 2-cohomology.",
    "pdf_url": "http://arxiv.org/pdf/2410.13417v3",
    "published": "2024-10-17T10:37:20+00:00",
    "categories": [
      "math.OA",
      "math.GR"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13416v1",
    "title": "Partially Trained Graph Convolutional Networks Resist Oversmoothing",
    "authors": [
      "Dimitrios Kelesis",
      "Dimitris Fotakis",
      "Georgios Paliouras"
    ],
    "abstract": "In this work we investigate an observation made by Kipf \\& Welling, who\nsuggested that untrained GCNs can generate meaningful node embeddings. In\nparticular, we investigate the effect of training only a single layer of a GCN,\nwhile keeping the rest of the layers frozen. We propose a basis on which the\neffect of the untrained layers and their contribution to the generation of\nembeddings can be predicted. Moreover, we show that network width influences\nthe dissimilarity of node embeddings produced after the initial node features\npass through the untrained part of the model. Additionally, we establish a\nconnection between partially trained GCNs and oversmoothing, showing that they\nare capable of reducing it. We verify our theoretical results experimentally\nand show the benefits of using deep networks that resist oversmoothing, in a\n``cold start'' scenario, where there is a lack of feature information for\nunlabeled nodes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13416v1",
    "published": "2024-10-17T10:35:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13415v3",
    "title": "Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting",
    "authors": [
      "Mikael Rinkinen",
      "Lauri Koskinen",
      "Olli Silven",
      "Mehdi Safarpour"
    ],
    "abstract": "Reduced voltage operation is an effective technique for substantial energy\nefficiency improvement in digital circuits. This brief introduces a simple\napproach for enabling reduced voltage operation of Deep Neural Network (DNN)\naccelerators by mere software modifications. Conventional approaches for\nenabling reduced voltage operation e.g., Timing Error Detection (TED) systems,\nincur significant development costs and overheads, while not being applicable\nto the off-the-shelf components. Contrary to those, the solution proposed in\nthis paper relies on algorithm-based error detection, and hence, is implemented\nwith low development costs, does not require any circuit modifications, and is\neven applicable to commodity devices. By showcasing the solution through\nexperimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we\ndemonstrate 18% to 25% energy saving with no accuracy loss of the models and\nnegligible throughput compromise (< 3.9%), considering the overheads from\nintegration of the error detection schemes into the DNN. The integration of\npresented algorithmic solution into the design is simpler when compared\nconventional TED based techniques that require extensive circuit-level\nmodifications, cell library characterizations or special support from the\ndesign tools.",
    "pdf_url": "http://arxiv.org/pdf/2410.13415v3",
    "published": "2024-10-17T10:29:15+00:00",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13414v2",
    "title": "Regularization of matrices in the covariant derivative interpretation of matrix models",
    "authors": [
      "Keiichiro Hattori",
      "Yuki Mizuno",
      "Asato Tsuchiya"
    ],
    "abstract": "We study regularization of matrices in the covariant derivative\ninterpretation of matrix models, a typical example of which is the type IIB\nmatrix model. The covariant derivative interpretation provides a possible way\nin which curved spacetimes are described by matrices, which are viewed as\ndifferential operators. One needs to regularize the operators as matrices with\nfinite size in order to apply the interpretation to nonperturbative\ncalculations such as numerical simulations. We develop a regularization of the\ncovariant derivatives in two dimensions by using the Berezin-Toeplitz\nquantization. As examples, we examine the cases of $S^2$ and $T^2$ in details.",
    "pdf_url": "http://arxiv.org/pdf/2410.13414v2",
    "published": "2024-10-17T10:27:38+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13413v1",
    "title": "Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models",
    "authors": [
      "Chengyu Du",
      "Jinyi Han",
      "Yizhou Ying",
      "Aili Chen",
      "Qianyu He",
      "Haokun Zhao",
      "Sirui Xia",
      "Haoran Guo",
      "Jiaqing Liang",
      "Zulong Chen",
      "Liangyue Li",
      "Yanghua Xiao"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated that\nprogressive refinement, rather than providing a single answer, results in more\naccurate and thoughtful outputs. However, existing methods often rely heavily\non supervision signals to evaluate previous responses, making it difficult to\nassess output quality in more open-ended scenarios effectively. Additionally,\nthese methods are typically designed for specific tasks, which limits their\ngeneralization to new domains. To address these limitations, we propose\nProgressive Thought Refinement (PTR), a framework that enables LLMs to refine\ntheir responses progressively. PTR operates in two phases: (1) Thought data\nconstruction stage: We propose a weak and strong model collaborative selection\nstrategy to build a high-quality progressive refinement dataset to ensure\nlogical consistency from thought to answers, and the answers are gradually\nrefined in each round. (2) Thought-Mask Fine-Tuning Phase: We design a training\nstructure to mask the \"thought\" and adjust loss weights to encourage LLMs to\nrefine prior thought, teaching them to implicitly understand \"how to improve\"\nrather than \"what is correct.\" Experimental results show that PTR significantly\nenhances LLM performance across ten diverse tasks (avg. from 49.6% to 53.5%)\nwithout task-specific fine-tuning. Notably, in more open-ended tasks, LLMs also\ndemonstrate substantial improvements in the quality of responses beyond mere\naccuracy, suggesting that PTR truly teaches LLMs to self-improve over time.",
    "pdf_url": "http://arxiv.org/pdf/2410.13413v1",
    "published": "2024-10-17T10:23:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13920v1",
    "title": "The Bernoulli structure of discrete distributions",
    "authors": [
      "Roberto Fontana",
      "Patrizia Semeraro"
    ],
    "abstract": "Any discrete distribution with support on $\\{0,\\ldots, d\\}$ can be\nconstructed as the distribution of sums of Bernoulli variables. We prove that\nthe class of $d$-dimensional Bernoulli variables $\\boldsymbol{X}=(X_1,\\ldots,\nX_d)$ whose sums $\\sum_{i=1}^dX_i$ have the same distribution $p$ is a convex\npolytope $\\mathcal{P}(p)$ and we analytically find its extremal points. Our\nmain result is to prove that the Hausdorff measure of the polytopes\n$\\mathcal{P}(p), p\\in \\mathcal{D}_d,$ is a continuous function $l(p)$ over\n$\\mathcal{D}_d$ and it is the density of a finite measure $\\mu_s$ on\n$\\mathcal{D}_d$ that is Hausdorff absolutely continuous. We also prove that the\nmeasure $\\mu_s$ normalized over the simplex $\\mathcal{D}$ belongs to the class\nof Dirichlet distributions. We observe that the symmetric binomial distribution\nis the mean of the Dirichlet distribution on $\\mathcal{D}$ and that when $d$\nincreases it converges to the mode.",
    "pdf_url": "http://arxiv.org/pdf/2410.13920v1",
    "published": "2024-10-17T10:22:31+00:00",
    "categories": [
      "math.PR",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13412v2",
    "title": "RAMPA: Robotic Augmented Reality for Machine Programming by DemonstrAtion",
    "authors": [
      "Fatih Dogangun",
      "Serdar Bahar",
      "Yigit Yildirim",
      "Bora Toprak Temir",
      "Emre Ugur",
      "Mustafa Doga Dogan"
    ],
    "abstract": "This paper introduces Robotic Augmented Reality for Machine Programming by\nDemonstration (RAMPA), the first ML-integrated, XR-driven end-to-end robotic\nsystem, allowing training and deployment of ML models such as ProMPs on the\nfly, and utilizing the capabilities of state-of-the-art and commercially\navailable AR headsets, e.g., Meta Quest 3, to facilitate the application of\nProgramming by Demonstration (PbD) approaches on industrial robotic arms, e.g.,\nUniversal Robots UR10. Our approach enables in-situ data recording,\nvisualization, and fine-tuning of skill demonstrations directly within the\nuser's physical environment. RAMPA addresses critical challenges of PbD, such\nas safety concerns, programming barriers, and the inefficiency of collecting\ndemonstrations on the actual hardware. The performance of our system is\nevaluated against the traditional method of kinesthetic control in teaching\nthree different robotic manipulation tasks and analyzed with quantitative\nmetrics, measuring task performance and completion time, trajectory smoothness,\nsystem usability, user experience, and task load using standardized surveys.\nOur findings indicate a substantial advancement in how robotic tasks are taught\nand refined, promising improvements in operational safety, efficiency, and user\nengagement in robotic programming.",
    "pdf_url": "http://arxiv.org/pdf/2410.13412v2",
    "published": "2024-10-17T10:21:28+00:00",
    "categories": [
      "cs.RO",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13411v1",
    "title": "STCON System for the CHiME-8 Challenge",
    "authors": [
      "Anton Mitrofanov",
      "Tatiana Prisyach",
      "Tatiana Timofeeva",
      "Sergei Novoselov",
      "Maxim Korenevsky",
      "Yuri Khokhlov",
      "Artem Akulov",
      "Alexander Anikin",
      "Roman Khalili",
      "Iurii Lezhenin",
      "Aleksandr Melnikov",
      "Dmitriy Miroshnichenko",
      "Nikita Mamaev",
      "Ilya Odegov",
      "Olga Rudnitskaya",
      "Aleksei Romanenko"
    ],
    "abstract": "This paper describes the STCON system for the CHiME-8 Challenge Task 1 (DASR)\naimed at distant automatic speech transcription and diarization with multiple\nrecording devices. Our main attention was paid to carefully trained and tuned\ndiarization pipeline and speaker counting. This allowed to significantly reduce\ndiarization error rate (DER) and obtain more reliable segments for speech\nseparation and recognition. To improve source separation, we designed a Guided\nTarget speaker Extraction (G-TSE) model and used it in conjunction with the\ntraditional Guided Source Separation (GSS) method. To train various parts of\nour pipeline, we investigated several data augmentation and generation\ntechniques, which helped us to improve the overall system quality.",
    "pdf_url": "http://arxiv.org/pdf/2410.13411v1",
    "published": "2024-10-17T10:20:53+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13410v1",
    "title": "One-sided type-D metrics with aligned Einstein-Maxwell",
    "authors": [
      "Paul Tod"
    ],
    "abstract": "We consider four-dimensional, Riemannian metrics for which one or other of\nthe self-dual or anti-self-dual Weyl tensors is type-D and which satisfy the\nEinstein-Maxwell equations with the corresponding Maxwell field aligned with\nthe type-D Weyl spinor, in the sense of sharing the same Principal Null\nDirections (or PNDs). Such metrics always have a valence-2 Killing spinor, and\ntherefore a Hermitian structure and at least one Killing vector. We rederive\nthe results of Araneda (\\cite{ba}), that these metrics can all be given in\nterms of a solution of the $SU(\\infty)$-Toda field equation, and show that,\nwhen there is a second Killing vector commuting with the first, the method of\nWard can be applied to show that the metrics can also be given in terms of a\npair of axisymmetric solutions of the flat three-dimensional Laplacian. Thus in\nparticular the field equations linearise.\n  Some examples of the constructions are given.",
    "pdf_url": "http://arxiv.org/pdf/2410.13410v1",
    "published": "2024-10-17T10:18:13+00:00",
    "categories": [
      "gr-qc",
      "math.DG"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.14742v3",
    "title": "ArrivalNet: Predicting City-wide Bus/Tram Arrival Time with Two-dimensional Temporal Variation Modeling",
    "authors": [
      "Zirui Li",
      "Patrick Wolf",
      "Meng Wang"
    ],
    "abstract": "Accurate arrival time prediction (ATP) of buses and trams plays a crucial\nrole in public transport operations. Current methods focused on modeling\none-dimensional temporal information but overlooked the latent periodic\ninformation within time series. Moreover, most studies developed algorithms for\nATP based on a single or a few routes of public transport, which reduces the\ntransferability of the prediction models and their applicability in public\ntransport management systems. To this end, this paper proposes\n\\textit{ArrivalNet}, a two-dimensional temporal variation-based multi-step ATP\nfor buses and trams. It decomposes the one-dimensional temporal sequence into\nintra-periodic and inter-periodic variations, which can be recast into\ntwo-dimensional tensors (2D blocks). Each row of a tensor contains the time\npoints within a period, and each column involves the time points at the same\nintra-periodic index across various periods. The transformed 2D blocks in\ndifferent frequencies have an image-like feature representation that enables\neffective learning with computer vision backbones (e.g., convolutional neural\nnetwork). Drawing on the concept of residual neural network, the 2D block\nmodule is designed as a basic module for flexible aggregation. Meanwhile,\ncontextual factors like workdays, peak hours, and intersections, are also\nutilized in the augmented feature representation to improve the performance of\nprediction. 125 days of public transport data from Dresden were collected for\nmodel training and validation. Experimental results show that the root mean\nsquare error, mean absolute error, and mean absolute percentage error of the\nproposed predictor decrease by at least 6.1\\%, 14.7\\%, and 34.2\\% compared with\nstate-of-the-art baseline methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.14742v3",
    "published": "2024-10-17T10:17:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13409v2",
    "title": "Attr-Int: A Simple and Effective Entity Alignment Framework for Heterogeneous Knowledge Graphs",
    "authors": [
      "Linyan Yang",
      "Jingwei Cheng",
      "Chuanhao Xu",
      "Xihao Wang",
      "Jiayi Li",
      "Fu Zhang"
    ],
    "abstract": "Entity alignment (EA) refers to the task of linking entities in different\nknowledge graphs (KGs). Existing EA methods rely heavily on structural\nisomorphism. However, in real-world KGs, aligned entities usually have\nnon-isomorphic neighborhood structures, which paralyses the application of\nthese structure-dependent methods. In this paper, we investigate and tackle the\nproblem of entity alignment between heterogeneous KGs. First, we propose two\nnew benchmarks to closely simulate real-world EA scenarios of heterogeneity.\nThen we conduct extensive experiments to evaluate the performance of\nrepresentative EA methods on the new benchmarks. Finally, we propose a simple\nand effective entity alignment framework called Attr-Int, in which innovative\nattribute information interaction methods can be seamlessly integrated with any\nembedding encoder for entity alignment, improving the performance of existing\nentity alignment techniques. Experiments demonstrate that our framework\noutperforms the state-of-the-art approaches on two new benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13409v2",
    "published": "2024-10-17T10:16:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13408v2",
    "title": "MoR: Mixture of Ranks for Low-Rank Adaptation Tuning",
    "authors": [
      "Chuanyu Tang",
      "Yilong Chen",
      "Zhenyu Zhang",
      "Junyuan Shang",
      "Wenyuan Zhang",
      "Yong Huang",
      "Tingwen Liu"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) drives research to align its performance with full\nfine-tuning. However, significant challenges remain: (1) Simply increasing the\nrank size of LoRA does not effectively capture high-rank information, which\nleads to a performance bottleneck.(2) MoE-style LoRA methods substantially\nincrease parameters and inference latency, contradicting the goals of efficient\nfine-tuning and ease of application. To address these challenges, we introduce\nMixture of Ranks (MoR), which learns rank-specific information for different\ntasks based on input and efficiently integrates multi-rank information. We\nfirstly propose a new framework that equates the integration of multiple LoRAs\nto expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA\nalready captures sufficient intrinsic information, and MoR can derive high-rank\ninformation through mathematical transformations of the low-rank components.\nThus, MoR can reduces the learning difficulty of LoRA and enhances its\nmulti-task capabilities. MoR achieves impressive results, with MoR delivering a\n1.31\\% performance improvement while using only 93.93\\% of the parameters\ncompared to baseline methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13408v2",
    "published": "2024-10-17T10:14:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13407v1",
    "title": "BestMan: A Modular Mobile Manipulator Platform for Embodied AI with Unified Simulation-Hardware APIs",
    "authors": [
      "Kui Yang",
      "Nieqing Cao",
      "Yan Ding",
      "Chao Chen"
    ],
    "abstract": "Embodied Artificial Intelligence (Embodied AI) emphasizes agents' ability to\nperceive, understand, and act in physical environments. Simulation platforms\nplay a crucial role in advancing this field by enabling the validation and\noptimization of algorithms. However, existing platforms face challenges such as\nmultilevel technical integration complexity, insufficient modularity, interface\nheterogeneity, and adaptation to diverse hardware. We present BestMan, a\nsimulation platform based on PyBullet, designed to address these issues.\nBestMan introduces an integrated multilevel skill chain for seamless\ncoordination across perception, planning, and control; a highly modular\narchitecture for flexible algorithm integration; unified interfaces for smooth\nsimulation-to-reality transfer; and a hardware-agnostic approach for adapting\nto various mobile manipulator configurations. These features collectively\nsimplify development and enhance platform expandability, making BestMan a\nvaluable tool for Embodied AI research.",
    "pdf_url": "http://arxiv.org/pdf/2410.13407v1",
    "published": "2024-10-17T10:09:44+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13406v1",
    "title": "Distinguishability of a naked singularity from a black hole in dynamics and radiative signatures",
    "authors": [
      "Indu K. Dihingia",
      "Akhil Uniyal",
      "Yosuke Mizuno"
    ],
    "abstract": "Can a naked singularity (NkS) be distinguished from a black hole (BH)? We\nhave investigated it with cutting-edge general relativistic\nmagneto-hydrodynamic (GRMHD) simulations, followed by general relativistic\nradiation transfer (GRRT) calculation for magnetized accretion flow around NkS\nand BH. Based on our simulations, the accreting matter close enough to the\nsingularity repels due to effective potential. This prevents matter from\nreaching a NkS and forms a quasi-spherical symmetric density distribution\naround it, unlike the accretion flows around a BH. We observe an order of\nmagnitude higher mass flux through the jet and much stronger wind from a NkS\nthan a BH. We found that the jet launching mechanism in a NkS differs\nsignificantly from that in a BH. In the horizon-scale images, a NKs shows a\nphoton arc instead of a photon ring that is shown around a BH. In summary, the\nflow dynamics and radiative properties around an NkS are distinctly different\nfrom a BH. These properties would be useful to either confirm or rule out such\nexotic compact objects through future observations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13406v1",
    "published": "2024-10-17T10:07:38+00:00",
    "categories": [
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13405v1",
    "title": "Trinity: A General Purpose FHE Accelerator",
    "authors": [
      "Xianglong Deng",
      "Shengyu Fan",
      "Zhicheng Hu",
      "Zhuoyu Tian",
      "Zihao Yang",
      "Jiangrui Yu",
      "Dingyuan Cao",
      "Dan Meng",
      "Rui Hou",
      "Meng Li",
      "Qian Lou",
      "Mingzhe Zhang"
    ],
    "abstract": "In this paper, we present the first multi-modal FHE accelerator based on a\nunified architecture, which efficiently supports CKKS, TFHE, and their\nconversion scheme within a single accelerator. To achieve this goal, we first\nanalyze the theoretical foundations of the aforementioned schemes and highlight\ntheir composition from a finite number of arithmetic kernels. Then, we\ninvestigate the challenges for efficiently supporting these kernels within a\nunified architecture, which include 1) concurrent support for NTT and FFT, 2)\nmaintaining high hardware utilization across various polynomial lengths, and 3)\nensuring consistent performance across diverse arithmetic kernels. To tackle\nthese challenges, we propose a novel FHE accelerator named Trinity, which\nincorporates algorithm optimizations, hardware component reuse, and dynamic\nworkload scheduling to enhance the acceleration of CKKS, TFHE, and their\nconversion scheme. By adaptive select the proper allocation of components for\nNTT and MAC, Trinity maintains high utilization across NTTs with various\npolynomial lengths and imbalanced arithmetic workloads. The experiment results\nshow that, for the pure CKKS and TFHE workloads, the performance of our Trinity\noutperforms the state-of-the-art accelerator for CKKS (SHARP) and TFHE\n(Morphling) by 1.49x and 4.23x, respectively. Moreover, Trinity achieves 919.3x\nperformance improvement for the FHE-conversion scheme over the CPU-based\nimplementation. Notably, despite the performance improvement, the hardware\noverhead of Trinity is only 85% of the summed circuit areas of SHARP and\nMorphling.",
    "pdf_url": "http://arxiv.org/pdf/2410.13405v1",
    "published": "2024-10-17T10:02:38+00:00",
    "categories": [
      "cs.AR",
      "cs.CR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13404v1",
    "title": "Predicting Breast Cancer Survival: A Survival Analysis Approach Using Log Odds and Clinical Variables",
    "authors": [
      "Opeyemi Sheu Alamu",
      "Bismar Jorge Gutierrez Choque",
      "Syed Wajeeh Abbs Rizvi",
      "Samah Badr Hammed",
      "Isameldin Elamin Medani",
      "Md Kamrul Siam",
      "Waqar Ahmad Tahir"
    ],
    "abstract": "Breast cancer remains a significant global health challenge, with prognosis\nand treatment decisions largely dependent on clinical characteristics. Accurate\nprediction of patient outcomes is crucial for personalized treatment\nstrategies. This study employs survival analysis techniques, including Cox\nproportional hazards and parametric survival models, to enhance the prediction\nof the log odds of survival in breast cancer patients. Clinical variables such\nas tumor size, hormone receptor status, HER2 status, age, and treatment history\nwere analyzed to assess their impact on survival outcomes. Data from 1557\nbreast cancer patients were obtained from a publicly available dataset provided\nby the University College Hospital, Ibadan, Nigeria. This dataset was\npreprocessed and analyzed using both univariate and multivariate approaches to\nevaluate survival outcomes. Kaplan-Meier survival curves were generated to\nvisualize survival probabilities, while the Cox proportional hazards model\nidentified key risk factors influencing mortality. The results showed that\nolder age, larger tumor size, and HER2-positive status were significantly\nassociated with an increased risk of mortality. In contrast, estrogen receptor\npositivity and breast-conserving surgery were linked to better survival\noutcomes. The findings suggest that integrating these clinical variables into\npredictive models improvesthe accuracy of survival predictions, helping to\nidentify high-risk patients who may benefit from more aggressive interventions.\nThis study demonstrates the potential of survival analysis in optimizing breast\ncancer care, particularly in resource-limited settings. Future research should\nfocus on integrating genomic data and real-world clinical outcomes to further\nrefine these models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13404v1",
    "published": "2024-10-17T10:01:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13403v2",
    "title": "Hilbert irreducibility for integral points on punctured linear algebraic groups",
    "authors": [
      "Cedric Luger"
    ],
    "abstract": "Let $K$ be a number field, let $X$ be a smooth integral variety over $K$, and\nassume that there exists a finite set of finite places $S$ of $K$ such that the\n$S$-integral points on $X$ are dense. Then the combined conjectures of Campana\nand Corvaja-Zannier predict that, for every closed subscheme $Z$ of $X$ of\ncodimension at least two, there exists a finite extension $L$ of $K$ and a\nfinite set of finite places $T$ of $L$ such that the $T$-integral points on\n$(X\\setminus Z)_L$ are not strongly thin. The main goal of the present paper is\nto show that this property holds for all connected linear algebraic groups. Our\nresult builds mainly on recent work on a Hilbert irreducibility type theorem\nfor connected algebraic groups, the purity of strong approximation for\nsemi-simple simply connected quasi-split linear algebraic groups, and the\nrelation between integral strong approximation and the Hilbert property.",
    "pdf_url": "http://arxiv.org/pdf/2410.13403v2",
    "published": "2024-10-17T09:57:52+00:00",
    "categories": [
      "math.AG",
      "Primary: 14G99. Secondary: 14G05, 14G40, 20G30"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13402v1",
    "title": "Monte Carlo Simulation of Angular Response of GRID Detectors for GRID Mission",
    "authors": [
      "Qize Liu",
      "Xiaofan Pan",
      "Xutao Zheng",
      "Huaizhong Gao",
      "Longhao Li",
      "Qidong Wang",
      "Zirui Yang",
      "Chenchong Tang",
      "Wenxuan Wu",
      "Jianping Cheng",
      "Zhi Zeng",
      "Ming Zeng",
      "Hua Feng",
      "Binbin Zhang",
      "Zhonghai Wang",
      "Rong Zhou",
      "Yuanyuan Liu",
      "Lin Lin",
      "Jiayong Zhong",
      "Jianyong Jiang",
      "Wentao Han",
      "Yang Tian",
      "Benda Xu",
      "GRID Collaboration"
    ],
    "abstract": "The Gamma-Ray Integrated Detectors (GRID) are a space science mission that\nemploys compact gamma-ray detectors mounted on NanoSats in low Earth orbit\n(LEO) to monitor the transient gamma-ray sky. Owing to the unpredictability of\nthe time and location of gamma-ray bursts (GRBs), obtaining the photon\nresponses of gamma-ray detectors at various incident angles is important for\nthe scientific analysis of GRB data captured by GRID detectors. For this\npurpose, a dedicated Monte Carlo simulation framework has been developed for\nGRID detectors. By simulating each GRID detector and the NanoSat carrying it,\nthe spectral energy response, detection efficiency, and other angular responses\nof each detector for photons with different incident angles and energies can be\nobtained within this framework. The accuracy of these simulations has been\ncorroborated through on-ground calibration, and the derived angular responses\nhave been successfully applied to the data analysis of recorded GRBs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13402v1",
    "published": "2024-10-17T09:57:44+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13401v1",
    "title": "Coherent Phonons, Localization and Slow Polaron Formation in Lead-free Gold Perovskite",
    "authors": [
      "Sankaran Ramesh",
      "Yonghong Wang",
      "Pavel Chabera",
      "Rafael Araujo",
      "Mustafa Aboulsaad",
      "Tomas Edvinsson",
      "Feng Gao",
      "Tönu Pullerits"
    ],
    "abstract": "Lead-free metal halide perovskites are emerging as less-toxic alternatives to\ntheir lead-based counterparts. However, their applicability in optoelectronic\ndevices is limited, and the charge transport dynamics remain poorly understood.\nUnderstanding photo-induced charge and structural dynamics is critical for\nunlocking the potential of these novel systems. In this work, we employ\nultrafast optical and Raman spectroscopy combined with band structure\ncalculations to investigate the coupled electronic and vibrational dynamics in\nCaesium gold bromide, a promising lead-free perovskite. We find that the\nband-edge charge transfer states are strongly coupled to Au-Br stretching\nphonon modes, leading to frequency modulation of absorption by impulsively\nexcited coherent phonons. Early-stage relaxation is characterized by dynamics\nof delocalized charge transfer excitation and slowly decaying coherent phonons.\nThe electronic and vibrational relaxation reveals a slow formation of a\nlocalized polaronic state in the 10-20 ps timescale. Using a displaced harmonic\noscillator model, the polaronic binding energy is estimated to be ~80 meV\nfollowing lattice relaxation along the phonon modes. Strong exciton-phonon\ncoupling and slow polaron formation via coupling to lattice modes make this\nmaterial a promising testbed for the control of coherent phonons and localized\npolaronic states using light.",
    "pdf_url": "http://arxiv.org/pdf/2410.13401v1",
    "published": "2024-10-17T09:56:54+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13400v1",
    "title": "Towards Hybrid Intelligence in Journalism: Findings and Lessons Learnt from a Collaborative Analysis of Greek Political Rhetoric by ChatGPT and Humans",
    "authors": [
      "Thanasis Troboukis",
      "Kelly Kiki",
      "Antonis Galanopoulos",
      "Pavlos Sermpezis",
      "Stelios Karamanidis",
      "Ilias Dimitriadis",
      "Athena Vakali"
    ],
    "abstract": "This chapter introduces a research project titled \"Analyzing the Political\nDiscourse: A Collaboration Between Humans and Artificial Intelligence\", which\nwas initiated in preparation for Greece's 2023 general elections. The project\nfocused on the analysis of political leaders' campaign speeches, employing\nArtificial Intelligence (AI), in conjunction with an interdisciplinary team\ncomprising journalists, a political scientist, and data scientists. The chapter\ndelves into various aspects of political discourse analysis, including\nsentiment analysis, polarization, populism, topic detection, and Named Entities\nRecognition (NER). This experimental study investigates the capabilities of\nlarge language model (LLMs), and in particular OpenAI's ChatGPT, for analyzing\npolitical speech, evaluates its strengths and weaknesses, and highlights the\nessential role of human oversight in using AI in journalism projects and\npotentially other societal sectors. The project stands as an innovative example\nof human-AI collaboration (known also as \"hybrid intelligence\") within the\nrealm of digital humanities, offering valuable insights for future initiatives.",
    "pdf_url": "http://arxiv.org/pdf/2410.13400v1",
    "published": "2024-10-17T09:54:54+00:00",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13399v2",
    "title": "Heisenberg scaling based on population coding",
    "authors": [
      "Masahito Hayashi"
    ],
    "abstract": "We study Heisenberg scaling of quantum metrology in the viewpoint of\npopulation coding. Although Fisher information has been used for a figure of\nmerit to characterize Heisenberg scaling in quantum metrology, several studies\npointed out it does not work as a figure of merit because it does not reflect\nthe global structure. As an alternative figure of merit, we propose the mutual\ninformation, which connects the number of distinguishable elements of the\nparameter space in the viewpoint of population coding. We show that several\nunitary models achieve Heisenberg scaling in this context.",
    "pdf_url": "http://arxiv.org/pdf/2410.13399v2",
    "published": "2024-10-17T09:53:52+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13398v1",
    "title": "Wireless Large Object Transmission Under Safety Constraints (LOTUS)",
    "authors": [
      "Alex Bendrick",
      "Daniel Tappe",
      "Rolf Ernst"
    ],
    "abstract": "Future autonomous mobile systems will greatly benefit from cooperation and\nreal-time sensor data exchange using V2X communication. In such applications,\nwireless communication has to cope with stringent real-time and safety\nconstraints, a huge challenge given the inherently lossy wireless communication\nwith highly dynamic channel and error conditions. To meet the safety and\nreal-time goals, the use of state-of-the-art (5G and 802.11) V2X technologies\nfocuses on reliable exchange of small data objects, as in URLLC. In contrast,\nreliable low-latency exchange of large data, such as camera frames, has\nreceived little attention, despite its predicted benefits in safe perception\nand cooperation. The LOTUS project, outlined in this paper, exploits the\nspecific properties of large application data objects to develop novel,\napplication-aware mechanisms for low-latency reliable large data exchange on\ntop of existing and future V2X technologies. Evaluation with statistical\nanalysis, simulation, and physical prototypes demonstrates the feasibility of\nlow-latency large data object exchange at unprecedented levels of reliability.",
    "pdf_url": "http://arxiv.org/pdf/2410.13398v1",
    "published": "2024-10-17T09:50:55+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13397v2",
    "title": "Quantum digital signature based on single-qubit without a trusted third-party",
    "authors": [
      "Wusheng Wang",
      "Masahito Hayashi"
    ],
    "abstract": "Digital signatures are a powerful cryptographic tool widely employed across\nvarious industries for securely authenticating the identity of a signer during\ncommunication between signers and verifiers. While quantum digital signatures\nhave been extensively studied, the security still depends on a trusted\nthird-party. To address this limitation and enhance the applicability in\nreal-world scenarios, here we propose a novel quantum digital signature\nprotocol without a trusted third-party to further improve the security. We note\nthat a quantum one-way function can work appropriately in digital signature due\nto the intrinsic non-cloning property for quantum states. Secret keys in the\nprotocol are constituted by classical private keys and quantum public keys\nbecause we assume that no user is trusted in the protocol. We prove that the\nprotocol has information-theoretical unforgeability. Moreover, it satisfies\nother important secure properties, including asymmetry, undeniability, and\nexpandability.",
    "pdf_url": "http://arxiv.org/pdf/2410.13397v2",
    "published": "2024-10-17T09:49:29+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13396v2",
    "title": "Linguistically Grounded Analysis of Language Models using Shapley Head Values",
    "authors": [
      "Marcell Fekete",
      "Johannes Bjerva"
    ],
    "abstract": "Understanding how linguistic knowledge is encoded in language models is\ncrucial for improving their generalisation capabilities. In this paper, we\ninvestigate the processing of morphosyntactic phenomena, by leveraging a\nrecently proposed method for probing language models via Shapley Head Values\n(SHVs). Using the English language BLiMP dataset, we test our approach on two\nwidely used models, BERT and RoBERTa, and compare how linguistic constructions\nsuch as anaphor agreement and filler-gap dependencies are handled. Through\nquantitative pruning and qualitative clustering analysis, we demonstrate that\nattention heads responsible for processing related linguistic phenomena cluster\ntogether. Our results show that SHV-based attributions reveal distinct patterns\nacross both models, providing insights into how language models organize and\nprocess linguistic information. These findings support the hypothesis that\nlanguage models learn subnetworks corresponding to linguistic theory, with\npotential implications for cross-linguistic model analysis and interpretability\nin Natural Language Processing (NLP).",
    "pdf_url": "http://arxiv.org/pdf/2410.13396v2",
    "published": "2024-10-17T09:48:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13395v1",
    "title": "Reverse Quantile-RK and its Application to Quantile-RK",
    "authors": [
      "Emeric Battaglia",
      "Anna Ma"
    ],
    "abstract": "When solving linear systems $Ax=b$, $A$ and $b$ are given, but the\nmeasurements $b$ often contain corruptions. Inspired by recent work on the\nquantile-randomized Kaczmarz method, we propose an acceleration of the\nrandomized Kaczmarz method using quantile information. We show that the\nproposed acceleration converges faster than the randomized Kaczmarz algorithm.\nIn addition, we show that our proposed approach can be used in conjunction with\nthe quantile-randomized Kaczamrz algorithm, without adding additional\ncomputational complexity, to produce both a fast and robust iterative method\nfor solving large, sparsely corrupted linear systems. Our extensive\nexperimental results support the use of the revised algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2410.13395v1",
    "published": "2024-10-17T09:46:12+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13394v2",
    "title": "Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs",
    "authors": [
      "Sumanth Doddapaneni",
      "Mohammed Safi Ur Rahman Khan",
      "Dilip Venkatesh",
      "Raj Dabre",
      "Anoop Kunchukuttan",
      "Mitesh M. Khapra"
    ],
    "abstract": "Evaluating machine-generated text remains a significant challenge in NLP,\nespecially for non-English languages. Current methodologies, including\nautomated metrics, human assessments, and LLM-based evaluations, predominantly\nfocus on English, revealing a significant gap in multilingual evaluation\nframeworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an\nextensible framework that includes evaluator LLMs (Hercule) and a novel test\nset (Recon) specifically designed for multilingual evaluation. Our test set\nfeatures 500 human-annotated instructions spanning various task capabilities\nalong with human judgment scores across six languages. This would enable\nbenchmarking of general-purpose multilingual LLMs and facilitate\nmeta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a\ncross-lingual evaluation model that addresses the scarcity of reference answers\nin the target language by learning to assign scores to responses based on\neasily available reference answers in English. Our experiments demonstrate that\nHercule aligns more closely with human judgments compared to proprietary\nmodels, demonstrating the effectiveness of such cross-lingual evaluation in low\nresource scenarios. Further, it is also effective in zero-shot evaluation on\nunseen languages. This study is the first comprehensive examination of\ncross-lingual evaluation using LLMs, presenting a scalable and effective\napproach for multilingual assessment. All code, datasets, and models will be\npublicly available to enable further research in this important area.",
    "pdf_url": "http://arxiv.org/pdf/2410.13394v2",
    "published": "2024-10-17T09:45:32+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13393v1",
    "title": "Fabrication of functional 3D nanoarchitectures via atomic layer deposition on DNA origami crystals",
    "authors": [
      "Arthur Ermatov",
      "Melisande Kost",
      "Xin Yin",
      "Paul Butler",
      "Mihir Dass",
      "Ian D. Sharp",
      "Tim Liedl",
      "Thomas Bein",
      "Gregor Posnjak"
    ],
    "abstract": "While DNA origami is a powerful bottom-up fabrication technique, the physical\nand chemical stability of DNA nanostructures is generally limited to aqueous\nbuffer conditions. Wet chemical silicification can stabilise these structures\nbut does not add further functionality. Here, we demonstrate a versatile 3D\nnanofabrication technique to conformally coat micrometre-sized DNA origami\ncrystals with functional metal oxides via atomic layer deposition (ALD). In\naddition to depositing homogenous and conformal nanometre-thin ZnO, TiO2, and\nIrO2 (multi)layers inside SiO2-stablised crystals, we establish a method to\ndirectly coat bare DNA crystals with ALD layers while maintaining the crystal\nintegrity, enabled by critical point drying and low ALD process temperatures.\nAs a proof-of-concept application, we demonstrate electrocatalytic water\noxidation using ALD IrO2-coated DNA origami crystals, resulting in improved\nperformance relative to planar films. Overall, our coating strategy establishes\na tool set for designing custom-made 3D nanomaterials with precisely defined\ntopologies and material compositions, combining the unique advantages of DNA\norigami and atomically controlled deposition of functional inorganic materials.",
    "pdf_url": "http://arxiv.org/pdf/2410.13393v1",
    "published": "2024-10-17T09:45:30+00:00",
    "categories": [
      "physics.app-ph",
      "cond-mat.mtrl-sci",
      "physics.bio-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13392v3",
    "title": "Judgment of Learning: A Human Ability Beyond Generative Artificial Intelligence",
    "authors": [
      "Markus Huff",
      "Elanur Ulakçı"
    ],
    "abstract": "Large language models (LLMs) increasingly mimic human cognition in various\nlanguage-based tasks. However, their capacity for metacognition - particularly\nin predicting memory performance - remains unexplored. Here, we introduce a\ncross-agent prediction model to assess whether ChatGPT-based LLMs align with\nhuman judgments of learning (JOL), a metacognitive measure where individuals\npredict their own future memory performance. We tested humans and LLMs on pairs\nof sentences, one of which was a garden-path sentence - a sentence that\ninitially misleads the reader toward an incorrect interpretation before\nrequiring reanalysis. By manipulating contextual fit (fitting vs. unfitting\nsentences), we probed how intrinsic cues (i.e., relatedness) affect both LLM\nand human JOL. Our results revealed that while human JOL reliably predicted\nactual memory performance, none of the tested LLMs (GPT-3.5-turbo, GPT-4-turbo,\nand GPT-4o) demonstrated comparable predictive accuracy. This discrepancy\nemerged regardless of whether sentences appeared in fitting or unfitting\ncontexts. These findings indicate that, despite LLMs' demonstrated capacity to\nmodel human cognition at the object-level, they struggle at the meta-level,\nfailing to capture the variability in individual memory predictions. By\nidentifying this shortcoming, our study underscores the need for further\nrefinements in LLMs' self-monitoring abilities, which could enhance their\nutility in educational settings, personalized learning, and human-AI\ninteractions. Strengthening LLMs' metacognitive performance may reduce the\nreliance on human oversight, paving the way for more autonomous and seamless\nintegration of AI into tasks requiring deeper cognitive awareness.",
    "pdf_url": "http://arxiv.org/pdf/2410.13392v3",
    "published": "2024-10-17T09:42:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13391v1",
    "title": "The ESRF dark-field x-ray microscope at ID03",
    "authors": [
      "H. Isern",
      "T. Brochard",
      "T. Dufrane",
      "P. Brumund",
      "E. Papillon",
      "D. Scortani",
      "R. Hino",
      "C. Yildirim",
      "R. Rodriguez Lamas",
      "Y. Li",
      "M. Sarkis",
      "C. Detlefs"
    ],
    "abstract": "Dark Field X-ray Microscopy (DFXM) is a full-field imaging technique for\nnon-destructive 3D mapping of orientation and strain in crystalline elements.\nThe new DFXM beamline at ID03, developed as part of the ESRF Phase II Upgrade\nProject (EBSL2), was designed to provide cutting-edge capabilities for studying\nembedded microstructures. The project relocated and upgraded the end station\nfrom ID06-HXM to ID03, integrating new X-ray optics, radiation hutches, and a\nsource device optimized for this advanced technique. Notable improvements\ninclude a near-field camera, a new goniometer, and a high-resolution far-field\ncamera. The conceptual design was completed in September 2019, followed by the\ntechnical design in March 2021, with first users welcomed in April 2024.\nBuilding on the success of the original instrument, the ID03 beamline offers\nenhanced multi-scale and multi-modal mapping of microstructures with high\nresolution, enabling in-situ exploration of complex phenomena. Applications\nrange from strain and orientation mapping in metals to studies of functional\nmaterials, semiconductors, biominerals, and energy systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13391v1",
    "published": "2024-10-17T09:42:24+00:00",
    "categories": [
      "physics.app-ph",
      "cond-mat.mtrl-sci",
      "physics.ins-det"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13390v1",
    "title": "A Self-Constructing Multi-Expert Fuzzy System for High-dimensional Data Classification",
    "authors": [
      "Yingtao Ren",
      "Yu-Cheng Chang",
      "Thomas Do",
      "Zehong Cao",
      "Chin-Teng Lin"
    ],
    "abstract": "Fuzzy Neural Networks (FNNs) are effective machine learning models for\nclassification tasks, commonly based on the Takagi-Sugeno-Kang (TSK) fuzzy\nsystem. However, when faced with high-dimensional data, especially with noise,\nFNNs encounter challenges such as vanishing gradients, excessive fuzzy rules,\nand limited access to prior knowledge. To address these challenges, we propose\na novel fuzzy system, the Self-Constructing Multi-Expert Fuzzy System\n(SOME-FS). It combines two learning strategies: mixed structure learning and\nmulti-expert advanced learning. The former enables each base classifier to\neffectively determine its structure without requiring prior knowledge, while\nthe latter tackles the issue of vanishing gradients by enabling each rule to\nfocus on its local region, thereby enhancing the robustness of the fuzzy\nclassifiers. The overall ensemble architecture enhances the stability and\nprediction performance of the fuzzy system. Our experimental results\ndemonstrate that the proposed SOME-FS is effective in high-dimensional tabular\ndata, especially in dealing with uncertainty. Moreover, our stable rule mining\nprocess can identify concise and core rules learned by the SOME-FS.",
    "pdf_url": "http://arxiv.org/pdf/2410.13390v1",
    "published": "2024-10-17T09:41:54+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13389v3",
    "title": "Dynamic Input Mapping Inversion to Eliminate Algebraic Loops in Hydraulic Actuator Control",
    "authors": [
      "Alessio Dallabona",
      "Patrik Schermann",
      "Mogens Blanke",
      "Dimitrios Papageorgiou"
    ],
    "abstract": "The application of nonlinear control schemes to electro-hydraulic actuators\noften requires several alterations in the design of the controllers during\ntheir implementation. This is to overcome challenges that frequently arise in\nsuch control algorithms owing to model nonlinearities. Moreover, advanced\ncontrol solutions for this type of systems often introduce input algebraic\nloops that pose significant design and tuning difficulties. Conventional\nmethods to avoid such loops introduce chatter, which considerably degrade\ntracking performance and has oil degradation and wear as side effects. This\nstudy presents a nonlinear control architecture for hydraulic actuators that\ncomprises low-complexity modules that facilitate robust high performance in\ntracking and avoids the drawbacks of chatter. The salient feature is a dynamic\ninput-mapping inversion module that avoids algebraic loops in the control input\nand is followed by dedicated position control. The stability of the closed-loop\nsystem is analyzed using arguments from Lyapunov theory for cascaded\nnon-autonomous nonlinear systems. The effectiveness of the proposed solution is\nevaluated on a high-fidelity simulator of a wind turbine pitch system, and\nvalidated on a full-scale laboratory setup that includes a hydraulic pitch\nsystem and blade bearing. Appropriate quantitative metrics are used to evaluate\nthe closed-loop system performance in comparison to a state-of-the-art\nnonlinear design.",
    "pdf_url": "http://arxiv.org/pdf/2410.13389v3",
    "published": "2024-10-17T09:39:32+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13388v1",
    "title": "A graph product and its Application",
    "authors": [
      "Bishal Sonar",
      "Ravi Srivastava"
    ],
    "abstract": "The spectrum of Laplacian and signless Laplacian matrix for a graph product\nis obtained, where both underlying graphs are regular. As an application of\nthis, we have been able to generate the Kirchhoff Index and Wiener Index and\ndetermine the number of spanning trees. Additionally, we derived the conditions\nnecessary for obtaining a Laplacian and signless Laplacian integral product\ngraph.",
    "pdf_url": "http://arxiv.org/pdf/2410.13388v1",
    "published": "2024-10-17T09:39:17+00:00",
    "categories": [
      "math.CO",
      "05C76, 05C50, 05C22"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13387v3",
    "title": "CLEAR: Towards Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation for Large Language Model Applications",
    "authors": [
      "Chaoran Chen",
      "Daodao Zhou",
      "Yanfang Ye",
      "Toby Jia-jun Li",
      "Yaxing Yao"
    ],
    "abstract": "The rise of end-user applications powered by large language models (LLMs),\nincluding both conversational interfaces and add-ons to existing graphical user\ninterfaces (GUIs), introduces new privacy challenges. However, many users\nremain unaware of the risks. This paper explores methods to increase user\nawareness of privacy risks associated with LLMs in end-user applications. We\nconducted five co-design workshops to uncover user privacy concerns and their\ndemand for contextual privacy information within LLMs. Based on these insights,\nwe developed CLEAR (Contextual LLM-Empowered Privacy Policy Analysis and Risk\nGeneration), a just-in-time contextual assistant designed to help users\nidentify sensitive information, summarize relevant privacy policies, and\nhighlight potential risks when sharing information with LLMs. We evaluated the\nusability and usefulness of CLEAR across two example domains: ChatGPT and the\nGemini plugin in Gmail. Our findings demonstrated that CLEAR is easy to use and\nimproves users' understanding of data practices and privacy risks. We also\ndiscussed LLM's duality in posing and mitigating privacy risks, offering design\nand policy implications.",
    "pdf_url": "http://arxiv.org/pdf/2410.13387v3",
    "published": "2024-10-17T09:39:10+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13386v1",
    "title": "Graph Exploration: The Impact of a Distance Constraint",
    "authors": [
      "Stéphane Devismes",
      "Yoann Dieudonné",
      "Arnaud Labourel"
    ],
    "abstract": "A mobile agent, starting from a node $s$ of a simple undirected connected\ngraph $G=(V,E)$, has to explore all nodes and edges of $G$ using the minimum\nnumber of edge traversals. To do so, the agent uses a deterministic algorithm\nthat allows it to gain information on $G$ as it traverses its edges. During its\nexploration, the agent must always respect the constraint of knowing a path of\nlength at most $D$ to go back to node $s$. The upper bound $D$ is fixed as\nbeing equal to $(1+\\alpha)r$, where $r$ is the eccentricity of node $s$ (i.e.,\nthe maximum distance from $s$ to any other node) and $\\alpha$ is any positive\nreal constant. This task has been introduced by Duncan et al. [ACM Trans.\nAlgorithms 2006] and is known as \\emph{distance-constrained exploration}.\n  The \\emph{penalty} of an exploration algorithm running in $G$ is the number\nof edge traversals made by the agent in excess of $|E|$. Panaite and Pelc [J.\nAlgorithms 1999] gave an algorithm for solving exploration without any\nconstraint on the moves that is guaranteed to work in every graph $G$ with a\n(small) penalty in $\\mathcal{O}(|V|)$. Hence, a natural question is whether we\ncould obtain a distance-constrained exploration algorithm with the same\nguarantee as well.\n  In this paper, we provide a negative answer to this question. We also observe\nthat an algorithm working in every graph $G$ with a linear penalty in $|V|$\ncannot be obtained for the task of \\emph{fuel-constrained exploration}, another\nvariant studied in the literature.\n  This solves an open problem posed by Duncan et al. [ACM Trans. Algorithms\n2006] and shows a fundamental separation with the task of exploration without\nconstraint on the moves.",
    "pdf_url": "http://arxiv.org/pdf/2410.13386v1",
    "published": "2024-10-17T09:38:12+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13385v1",
    "title": "On the Use of Audio to Improve Dialogue Policies",
    "authors": [
      "Daniel Roncel",
      "Federico Costa",
      "Javier Hernando"
    ],
    "abstract": "With the significant progress of speech technologies, spoken goal-oriented\ndialogue systems are becoming increasingly popular. One of the main modules of\na dialogue system is typically the dialogue policy, which is responsible for\ndetermining system actions. This component usually relies only on audio\ntranscriptions, being strongly dependent on their quality and ignoring very\nimportant extralinguistic information embedded in the user's speech. In this\npaper, we propose new architectures to add audio information by combining\nspeech and text embeddings using a Double Multi-Head Attention component. Our\nexperiments show that audio embedding-aware dialogue policies outperform\ntext-based ones, particularly in noisy transcription scenarios, and that how\ntext and audio embeddings are combined is crucial to improve performance. We\nobtained a 9.8% relative improvement in the User Request Score compared to an\nonly-text-based dialogue system on the DSTC2 dataset.",
    "pdf_url": "http://arxiv.org/pdf/2410.13385v1",
    "published": "2024-10-17T09:37:20+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13384v1",
    "title": "RescueADI: Adaptive Disaster Interpretation in Remote Sensing Images with Autonomous Agents",
    "authors": [
      "Zhuoran Liu",
      "Danpei Zhao",
      "Bo Yuan"
    ],
    "abstract": "Current methods for disaster scene interpretation in remote sensing images\n(RSIs) mostly focus on isolated tasks such as segmentation, detection, or\nvisual question-answering (VQA). However, current interpretation methods often\nfail at tasks that require the combination of multiple perception methods and\nspecialized tools. To fill this gap, this paper introduces Adaptive Disaster\nInterpretation (ADI), a novel task designed to solve requests by planning and\nexecuting multiple sequentially correlative interpretation tasks to provide a\ncomprehensive analysis of disaster scenes. To facilitate research and\napplication in this area, we present a new dataset named RescueADI, which\ncontains high-resolution RSIs with annotations for three connected aspects:\nplanning, perception, and recognition. The dataset includes 4,044 RSIs, 16,949\nsemantic masks, 14,483 object bounding boxes, and 13,424 interpretation\nrequests across nine challenging request types. Moreover, we propose a new\ndisaster interpretation method employing autonomous agents driven by large\nlanguage models (LLMs) for task planning and execution, proving its efficacy in\nhandling complex disaster interpretations. The proposed agent-based method\nsolves various complex interpretation requests such as counting, area\ncalculation, and path-finding without human intervention, which traditional\nsingle-task approaches cannot handle effectively. Experimental results on\nRescueADI demonstrate the feasibility of the proposed task and show that our\nmethod achieves an accuracy 9% higher than existing VQA methods, highlighting\nits advantages over conventional disaster interpretation approaches. The\ndataset will be publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2410.13384v1",
    "published": "2024-10-17T09:36:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13383v2",
    "title": "Railway LiDAR semantic segmentation based on intelligent semi-automated data annotation",
    "authors": [
      "Florian Wulff",
      "Bernd Schaeufele",
      "Julian Pfeifer",
      "Ilja Radusch"
    ],
    "abstract": "Automated vehicles rely on an accurate and robust perception of the\nenvironment. Similarly to automated cars, highly automated trains require an\nenvironmental perception. Although there is a lot of research based on either\ncamera or LiDAR sensors in the automotive domain, very few contributions for\nthis task exist yet for automated trains. Additionally, no public dataset or\ndescribed approach for a 3D LiDAR semantic segmentation in the railway\nenvironment exists yet. Thus, we propose an approach for a point-wise 3D\nsemantic segmentation based on the 2DPass network architecture using scans and\nimages jointly. In addition, we present a semi-automated intelligent data\nannotation approach, which we use to efficiently and accurately label the\nrequired dataset recorded on a railway track in Germany. To improve performance\ndespite a still small number of labeled scans, we apply an active learning\napproach to intelligently select scans for the training dataset. Our\ncontributions are threefold: We annotate rail data including camera and LiDAR\ndata from the railway environment, transfer label the raw LiDAR point clouds\nusing an image segmentation network, and train a state-of-the-art 3D LiDAR\nsemantic segmentation network efficiently leveraging active learning. The\ntrained network achieves good segmentation results with a mean IoU of 71.48% of\n9 classes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13383v2",
    "published": "2024-10-17T09:36:19+00:00",
    "categories": [
      "cs.CV",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.17284v1",
    "title": "American society keeps a lid on the number of deaths from guns and car accidents but not from mass shootings",
    "authors": [
      "Theodore Modis"
    ],
    "abstract": "The number of deaths from car accidents and from the unlawful use of guns can\nbe described by logistic growth curves. The annual rates of both have traced\ncompleted logistic trajectories following which they have been self-regulated\nfor many decades at what seems to be a homeostatic equilibrium level through\nlegislative actions. Exception constitutes the number of deaths from mass\nshootings, which has been so far tracing an exponential trajectory. Despite the\nfact that mass-shooting deaths represent only 0.1 percent of all gun deaths\ntoday, they are poised to continue growing exponentially until they become the\nmajor cause of gun deaths, short of unprecedented action by society.",
    "pdf_url": "http://arxiv.org/pdf/2410.17284v1",
    "published": "2024-10-17T09:36:07+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13382v1",
    "title": "Spectra of eccentricity matrix of $H$-join of graphs",
    "authors": [
      "S. Balamoorthy",
      "T. Kavaskar"
    ],
    "abstract": "Let $\\varepsilon(G)$ be the eccentricity matrix of a graph $G$ and\n$Spec(\\varepsilon(G))$ be the eccentricity spectrum of $G$. Let\n$H[G_1,G_2,\\ldots, G_k]$ be the $H$-join of graphs $G_1,G_2,\\ldots, G_k$ and\nlet $H[G]$ be lexicographic product of $H$ and $G$. This paper finds the\neccentricity matrix of a $H$-join of graphs. Using this result, we find (i)\n$Spec(\\varepsilon(H[G]))$ in terms of $Spec(\\varepsilon(H))$ if the radius\n$(rad(H))$ of $H$ is at least three; (ii) $Spec(\\varepsilon(K_k[G_1,G_2,\\ldots,\nG_k]))$ if $\\Delta(G_i)\\leq |V(G_i)|-2$ which generalises some of the results\nin \\cite{Mahato1}; (iii) $Spec(\\varepsilon(H[G_1,G_2,\\ldots, G_k]))$ if\n$rad(H)\\geq 2$ and $G_i$ is complete whenever $e_H(i)=2$, which generalises\nsome of the results in \\cite{Mahato1} and \\cite{Wang1}. Finally, we find the\ncharacteristic polynomial of $\\varepsilon(K_{1,m}[G_0,G_1,\\ldots, G_m])$ if\n$G_i$'s are regular. As a result, we deduce some of the results in \\cite{Li},\n\\cite{Mahato1}, \\cite{Patel} and \\cite{Wang}.",
    "pdf_url": "http://arxiv.org/pdf/2410.13382v1",
    "published": "2024-10-17T09:36:02+00:00",
    "categories": [
      "math.CO",
      "05C50, 05C12"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13381v2",
    "title": "Learning Counterfactual Distributions via Kernel Nearest Neighbors",
    "authors": [
      "Kyuseong Choi",
      "Jacob Feitelberg",
      "Caleb Chin",
      "Anish Agarwal",
      "Raaz Dwivedi"
    ],
    "abstract": "Consider a setting with multiple units (e.g., individuals, cohorts,\ngeographic locations) and outcomes (e.g., treatments, times, items), where the\ngoal is to learn a multivariate distribution for each unit-outcome entry, such\nas the distribution of a user's weekly spend and engagement under a specific\nmobile app version. A common challenge is the prevalence of missing not at\nrandom data, where observations are available only for certain unit-outcome\ncombinations and the observation availability can be correlated with the\nproperties of distributions themselves, i.e., there is unobserved confounding.\nAn additional challenge is that for any observed unit-outcome entry, we only\nhave a finite number of samples from the underlying distribution. We tackle\nthese two challenges by casting the problem into a novel distributional matrix\ncompletion framework and introduce a kernel based distributional generalization\nof nearest neighbors to estimate the underlying distributions. By leveraging\nmaximum mean discrepancies and a suitable factor model on the kernel mean\nembeddings of the underlying distributions, we establish consistent recovery of\nthe underlying distributions even when data is missing not at random and\npositivity constraints are violated. Furthermore, we demonstrate that our\nnearest neighbors approach is robust to heteroscedastic noise, provided we have\naccess to two or more measurements for the observed unit-outcome entries, a\nrobustness not present in prior works on nearest neighbors with single\nmeasurements.",
    "pdf_url": "http://arxiv.org/pdf/2410.13381v2",
    "published": "2024-10-17T09:36:01+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13380v1",
    "title": "QuL: Programming Library for Computational Cooling of Qubits",
    "authors": [
      "Giuliano Difranco",
      "Lindsay Bassman Oftelie"
    ],
    "abstract": "A key hurdle to the success of quantum computers is the ability to initialize\nqubits into a pure state, which can be achieved by cooling qubits down to very\nlow temperatures. Computational cooling of qubits, whereby a subset of the\nqubits is cooled at the expense of heating the other qubits via the application\nof special sets of logic gates, offers a route to effectively cool qubits.\nHere, we present QuL, a programming library which can be used to generate,\nanalyze, and test quantum circuits for various computational cooling protocols.\nIn its most basic usage, QuL enables a novice user to easily produce cooling\ncircuits with minimal input or knowledge required. The programming library,\nhowever, offers flexibility to more advanced users to finely tune the cooling\nprotocol used to generate the quantum circuit. Finally, QuL offers methods to\nassess and compare various cooling protocols for users interested in studying\noptimal implementation of computational cooling in general, or on specific\nquantum backends. It is our hope that QuL will not only facilitate the\nexecution of computational cooling on current quantum computers, but also serve\nas a tool to investigate open questions in the optimal implementation of\ncomputational cooling.",
    "pdf_url": "http://arxiv.org/pdf/2410.13380v1",
    "published": "2024-10-17T09:32:02+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.23304v1",
    "title": "Approximation of length metrics by conformally flat Riemannian metrics",
    "authors": [
      "Andres A. Contreras Hip",
      "Ewain Gwynne"
    ],
    "abstract": "We present a proof of the folklore result that any length metric on $\\mathbb\nR^d$ can be approximated by conformally flat Riemannian distance functions in\nthe uniform distance. This result is used to study Liouville quantum gravity in\nanother paper by the same authors.",
    "pdf_url": "http://arxiv.org/pdf/2410.23304v1",
    "published": "2024-10-17T09:31:34+00:00",
    "categories": [
      "math.DG",
      "math.MG",
      "math.PR"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13379v1",
    "title": "ChannelGPT: A Large Model to Generate Digital Twin Channel for 6G Environment Intelligence",
    "authors": [
      "Li Yu",
      "Lianzheng Shi",
      "Jianhua Zhang",
      "Jialin Wang",
      "Zhen Zhang",
      "Yuxiang Zhang",
      "Guangyi Liu"
    ],
    "abstract": "6G is envisaged to provide multimodal sensing, pervasive intelligence, global\ncoverage, global coverage, etc., which poses extreme intricacy and new\nchallenges to the network design and optimization. As the core part of 6G,\nwireless channel is the carrier and enabler for the flourishing technologies\nand novel services, which intrinsically determines the ultimate system\nperformance. However, how to describe and utilize the complicated and\nhigh-dynamic characteristics of wireless channel accurately and effectively\nstill remains great hallenges. To tackle this, digital twin is envisioned as a\npowerful technology to migrate the physical entities to virtual and\ncomputational world. In this article, we propose a large model driven digital\ntwin channel generator (ChannelGPT) embedded with environment intelligence (EI)\nto enable pervasive intelligence paradigm for 6G network. EI is an iterative\nand interactive procedure to boost the system performance with online\nenvironment adaptivity. Firstly, ChannelGPT is capable of utilization the\nmultimodal data from wireless channel and corresponding physical environment\nwith the equipped sensing ability. Then, based on the fine-tuned large model,\nChannelGPT can generate multi-scenario channel parameters, associated map\ninformation and wireless knowledge simultaneously, in terms of each task\nrequirement. Furthermore, with the support of online multidimensional channel\nand environment information, the network entity will make accurate and\nimmediate decisions for each 6G system layer. In practice, we also establish a\nChannelGPT prototype to generate high-fidelity channel data for varied\nscenarios to validate the accuracy and generalization ability based on\nenvironment intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2410.13379v1",
    "published": "2024-10-17T09:30:54+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13378v3",
    "title": "A modified Hegselmann-Krause model for interacting voters and political parties",
    "authors": [
      "Patrick H. Cahill",
      "Georg A. Gottwald"
    ],
    "abstract": "The Hegselmann--Krause model is a prototypical model for opinion dynamics. It\nmodels the stochastic time evolution of an agent's or voter's opinion in\nresponse to the opinion of other like-minded agents. The Hegselmann--Krause\nmodel only considers the opinions of voters; we extend it here by incorporating\nthe dynamics of political parties which influence and are influenced by the\nvoters. We show in numerical simulations for $1$- and $2$-dimensional opinion\nspaces that, as for the original Hegselmann--Krause model, the modified model\nexhibits opinion cluster formation as well as a phase transition from\ndisagreement to consensus. We provide an analytical sufficient condition for\nthe formation of unanimous consensus in which voters and parties collapse to\nthe same point in opinion space in the deterministic case. Using mean-field\ntheory, we further derive an approximation for the critical noise strength\ndelineating consensus from non-consensus in the stochastically driven modified\nHegselmann--Krause model. We compare our analytical findings with simulations\nof the modified Hegselmann--Krause model.",
    "pdf_url": "http://arxiv.org/pdf/2410.13378v3",
    "published": "2024-10-17T09:29:35+00:00",
    "categories": [
      "physics.soc-ph",
      "nlin.AO"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13377v1",
    "title": "Active-hydraulic flows solve the 6-vertex model (and vice versa)",
    "authors": [
      "Camille Jorge",
      "Denis Bartolo"
    ],
    "abstract": "By confining colloidal active fluids in microchannel networks, we demonstrate\nthat their degenerate flows corresponds to the configurations of the six-vertex\nmodel. We use this quantitative correspondence to control and explain the\nactive flows that emerge in square grid networks. In particular, we show that\nthe Lagrangian trajectories of active particles realize the Baxter-Kelland-Wu\nmapping and form completely packed loops, whose geometry can be exactly\npredicted and explained. We then go beyond the square-grid geometry and\nintroduce a general framework for predicting the geometry of active-hydraulic\nflows in arbitrary networks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13377v1",
    "published": "2024-10-17T09:28:28+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13376v1",
    "title": "Data-Augmented Predictive Deep Neural Network: Enhancing the extrapolation capabilities of non-intrusive surrogate models",
    "authors": [
      "Shuwen Sun",
      "Lihong Feng",
      "Peter Benner"
    ],
    "abstract": "Numerically solving a large parametric nonlinear dynamical system is\nchallenging due to its high complexity and the high computational costs. In\nrecent years, machine-learning-aided surrogates are being actively researched.\nHowever, many methods fail in accurately generalizing in the entire time\ninterval $[0, T]$, when the training data is available only in a training time\ninterval $[0, T_0]$, with $T_0<T$.\n  To improve the extrapolation capabilities of the surrogate models in the\nentire time domain, we propose a new deep learning framework, where kernel\ndynamic mode decomposition (KDMD) is employed to evolve the dynamics of the\nlatent space generated by the encoder part of a convolutional autoencoder\n(CAE). After adding the KDMD-decoder-extrapolated data into the original data\nset, we train the CAE along with a feed-forward deep neural network using the\naugmented data. The trained network can predict future states outside the\ntraining time interval at any out-of-training parameter samples. The proposed\nmethod is tested on two numerical examples: a FitzHugh-Nagumo model and a model\nof incompressible flow past a cylinder. Numerical results show accurate and\nfast prediction performance in both the time and the parameter domain.",
    "pdf_url": "http://arxiv.org/pdf/2410.13376v1",
    "published": "2024-10-17T09:26:14+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13919v2",
    "title": "LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild",
    "authors": [
      "Reworr",
      "Dmitrii Volkov"
    ],
    "abstract": "Attacks powered by Large Language Model (LLM) agents represent a growing\nthreat to modern cybersecurity. To address this concern, we present LLM\nHoneypot, a system designed to monitor autonomous AI hacking agents. By\naugmenting a standard SSH honeypot with prompt injection and time-based\nanalysis techniques, our framework aims to distinguish LLM agents among all\nattackers. Over a trial deployment of about three months in a public\nenvironment, we collected 8,130,731 hacking attempts and 8 potential AI agents.\nOur work demonstrates the emergence of AI-driven threats and their current\nlevel of usage, serving as an early warning of malicious LLM agents in the\nwild.",
    "pdf_url": "http://arxiv.org/pdf/2410.13919v2",
    "published": "2024-10-17T09:25:28+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13375v3",
    "title": "Dissipation enables robust extensive scaling of multipartite correlations",
    "authors": [
      "Krzysztof Ptaszynski",
      "Massimiliano Esposito"
    ],
    "abstract": "We investigate the multipartite mutual information between $N$ discrete-state\nstochastic units interacting in a network that is invariant under unit\npermutations. We show that when the system relaxes to fixed point attractors,\nmultipartite correlations in the stationary state either do not scale\nextensively with $N$, or the extensive scaling is not robust to arbitrarily\nsmall perturbations of the system dynamics. In particular, robust extensive\nscaling cannot occur in thermodynamic equilibrium. In contrast, mutual\ninformation scales extensively when the system relaxes to time-dependent\nattractors (e.g., limit cycles), which can occur only far from equilibrium.\nThis demonstrates the essential role of dissipation in the generation and\nmaintenance of multipartite correlations. We illustrate our theory with the\nnonequilibrium Potts model.",
    "pdf_url": "http://arxiv.org/pdf/2410.13375v3",
    "published": "2024-10-17T09:24:49+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2410.13374v1",
    "title": "Context-aware adaptive personalised recommendation: a meta-hybrid",
    "authors": [
      "Peter Tibensky",
      "Michal Kompan"
    ],
    "abstract": "Recommenders take place on a wide scale of e-commerce systems, reducing the\nproblem of information overload. The most common approach is to choose a\nrecommender used by the system to make predictions. However, users vary from\neach other; thus, a one-fits-all approach seems to be sub-optimal. In this\npaper, we propose a meta-hybrid recommender that uses machine learning to\npredict an optimal algorithm. In this way, the best-performing recommender is\nused for each specific session and user. This selection depends on contextual\nand preferential information collected about the user. We use standard\nMovieLens and The Movie DB datasets for offline evaluation. We show that based\non the proposed model, it is possible to predict which recommender will provide\nthe most precise recommendations to a user. The theoretical performance of our\nmeta-hybrid outperforms separate approaches by 20-50% in normalized Discounted\nGain and Root Mean Square Error metrics. However, it is hard to obtain the\noptimal performance based on widely-used standard information stored about\nusers.",
    "pdf_url": "http://arxiv.org/pdf/2410.13374v1",
    "published": "2024-10-17T09:24:40+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13373v2",
    "title": "Addressing Graph Heterogeneity and Heterophily from A Spectral Perspective",
    "authors": [
      "Kangkang Lu",
      "Yanhua Yu",
      "Zhiyong Huang",
      "Yunshan Ma",
      "Xiao Wang",
      "Meiyu Liang",
      "Yuling Wang",
      "Yimeng Ren",
      "Tat-Seng Chua"
    ],
    "abstract": "Graph neural networks (GNNs) have demonstrated excellent performance in\nsemi-supervised node classification tasks. Despite this, two primary challenges\npersist: heterogeneity and heterophily. Each of these two challenges can\nsignificantly hinder the performance of GNNs. Heterogeneity refers to a graph\nwith multiple types of nodes or edges, while heterophily refers to the fact\nthat connected nodes are more likely to have dissimilar attributes or labels.\nAlthough there have been few works studying heterogeneous heterophilic graphs,\nthey either only consider the heterophily of specific meta-paths and lack\nexpressiveness, or have high expressiveness but fail to exploit high-order\nneighbors. In this paper, we propose a Heterogeneous Heterophilic Spectral\nGraph Neural Network (H2SGNN), which employs two modules: local independent\nfiltering and global hybrid filtering. Local independent filtering adaptively\nlearns node representations under different homophily, while global hybrid\nfiltering exploits high-order neighbors to learn more possible meta-paths.\nExtensive experiments are conducted on four datasets to validate the\neffectiveness of the proposed H2SGNN, which achieves superior performance with\nfewer parameters and memory consumption. The code is available at the GitHub\nrepo: https://github.com/Lukangkang123/H2SGNN/.",
    "pdf_url": "http://arxiv.org/pdf/2410.13373v2",
    "published": "2024-10-17T09:23:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13372v1",
    "title": "High-temperature ferromagnetism and ferroelasticity in ultraflexible atomically thin square-shaped lattices",
    "authors": [
      "Xinyuan Huang",
      "Yueqiao Qu",
      "Yu Liao",
      "Qian Zheng",
      "Ran Liu",
      "Yu Chen",
      "Liang Liu",
      "Junzhong Wang",
      "Gang Yao"
    ],
    "abstract": "The coexistence of high-temperature intrinsic ferromagnetic ordering, large\nmagnetic anisotropy, along with novel mechanical properties such as\nferroelasticity and flexibility, in experimental feasible two-dimensional (2D)\ncrystals is greatly appealing for nanoscale spintronics. However, the progress\nin identifying such materials is limited. Here, by first-principles\ncalculations, we report the findings of an extraordinary combination of the\nabove qualities for the first time in a new 2D exfoliated FeSi nanosheet in the\nP4/nmm space group. Due to the strong anion-mediated superexchange interaction,\nthe monolayer FeSi (ML-FeSi) exhibits a Curie temperature Tc as high as 830 K,\nsurpassing the current experimental record (344 K for ML-Cr3Te4). Furthermore,\nincluding FeSi, such isostructural lattices all demonstrate exceptional\nsoftness, as evidenced by their ultra-low in-plane stiffness. Remarkably, the\ntransition metal atom and square-shaped crystal form work together to give this\nfamily of ML materials unique properties that can transition from Ising-like 2D\nferromagnets in FeSi, MnP, MnAs, CrP, FeI, and VAs to 2D-XY ones in CrAs, VP,\nand multiferroic MnGe and TiTe. Overall, our work highlights such 2D lattices\nas promising candidates in emerging multifunctional device applications and\nnontrivial topological spintronics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13372v1",
    "published": "2024-10-17T09:23:51+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13371v3",
    "title": "Rotating-star Pattern for Camera Calibration",
    "authors": [
      "Zezhun Shi"
    ],
    "abstract": "Camera calibration is fundamental to 3D vision, and the choice of calibration\npattern greatly affects the accuracy. To address aberration issue, star-shaped\npattern has been proposed as alternatives to traditional checkerboard. However,\nsuch pattern suffers from aliasing artifacts. In this paper, we present a novel\nsolution by employing a series of checkerboard patterns rotated around a\ncentral point instead of a single star-shaped pattern. We further propose a\ncomplete feature extraction algorithm tailored for this design. Experimental\nresults demonstrate that our approach offers improved accuracy over the\nconventional star-shaped pattern and achieves high stability across varying\nexposure levels.",
    "pdf_url": "http://arxiv.org/pdf/2410.13371v3",
    "published": "2024-10-17T09:23:30+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13370v3",
    "title": "MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models",
    "authors": [
      "Donghao Zhou",
      "Jiancheng Huang",
      "Jinbin Bai",
      "Jiaze Wang",
      "Hao Chen",
      "Guangyong Chen",
      "Xiaowei Hu",
      "Pheng-Ann Heng"
    ],
    "abstract": "Text-to-image diffusion models can generate high-quality images but lack\nfine-grained control of visual concepts, limiting their creativity. Thus, we\nintroduce component-controllable personalization, a new task that enables users\nto customize and reconfigure individual components within concepts. This task\nfaces two challenges: semantic pollution, where undesired elements disrupt the\ntarget concept, and semantic imbalance, which causes disproportionate learning\nof the target concept and component. To address these, we design MagicTailor, a\nframework that uses Dynamic Masked Degradation to adaptively perturb unwanted\nvisual semantics and Dual-Stream Balancing for more balanced learning of\ndesired visual semantics. The experimental results show that MagicTailor\nachieves superior performance in this task and enables more personalized and\ncreative image generation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13370v3",
    "published": "2024-10-17T09:22:53+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13369v2",
    "title": "A Neutron Capture Explanation for the 10 MeV Emission Line Seen in GRB 221009A",
    "authors": [
      "Jiahuan Zhu",
      "Hua Feng",
      "Tong Liu"
    ],
    "abstract": "The brightest ever gamma-ray burst (GRB) 221009A displays a significant\nemission line component around 10 MeV. As the GRB central engine is\nneutron-rich, we propose that the emission line could be originally due to the\n2.223 MeV gamma-rays following neutron capture with protons. The measured line\nprofile can be adequately fitted with a neutron capture model that involves\nthermal broadening and a bulk Doppler shift. The spectral modeling reveals a\nDoppler factor varying from 5.1 to 2.1 for the neutron-rich component, along\nwith a temperature increase from 300 keV to about 900 keV, during the time\ninterval of 280--360 s since the trigger, with about $10^{-2}$ $M_\\odot$\ndeuteriums produced in the process. We argue that the neutron capture can take\nplace in the outer shell of a structure jet. Disk winds could be another\npossible site.",
    "pdf_url": "http://arxiv.org/pdf/2410.13369v2",
    "published": "2024-10-17T09:22:13+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13368v1",
    "title": "Observation of the Singly Cabibbo-Suppressed Decay $Λ_c^{+}\\to pπ^0$",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "O. Afedulidis",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "I. Balossino",
      "Y. Ban",
      "H. -R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "J. F. Chang",
      "G. R. Che",
      "G. Chelkov",
      "C. Chen",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "Z. Y. Chen",
      "S. K. Choi",
      "G. Cibinetto",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "Z. H. Duan",
      "P. Egorov",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "X. B. Gao",
      "Y. N. Gao",
      "Yang Gao",
      "S. Garbolino",
      "I. Garzia",
      "L. Ge",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "A. Gilman",
      "K. Goetzen",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "Y. T. Gu",
      "C. Y. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "J. Gutierrez",
      "K. L. Han",
      "T. T. Han",
      "F. Hanisch",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. H. Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "T. Holtmann",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "B. Y. Hu",
      "H. M. Hu",
      "J. F. Hu",
      "S. L. Hu",
      "T. Hu",
      "Y. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "Y. S. Huang",
      "T. Hussain",
      "F. Hölzken",
      "N. Hüsken",
      "N. in der Wiesche",
      "J. Jackson",
      "S. Janchiv",
      "J. H. Jeong",
      "Q. Ji",
      "Q. P. Ji",
      "W. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "X. Q. Jia",
      "Z. K. Jia",
      "D. Jiang",
      "H. B. Jiang",
      "P. C. Jiang",
      "S. S. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "J. K. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "X. M. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "M. Kavatsyuk",
      "B. C. Ke",
      "V. Khachatryan",
      "A. Khoukaz",
      "R. Kiuchi",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "N. Kumar",
      "A. Kupsc",
      "W. Kühn",
      "J. J. Lane",
      "L. Lavezzi",
      "T. T. Lei",
      "Z. H. Lei",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "Cheng Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "K. Li",
      "L. J. Li",
      "L. K. Li",
      "Lei Li",
      "M. H. Li",
      "P. R. Li",
      "Q. M. Li",
      "Q. X. Li",
      "R. Li",
      "S. X. Li",
      "T. Li",
      "W. D. Li",
      "W. G. Li",
      "X. Li",
      "X. H. Li",
      "X. L. Li",
      "X. Y. Li",
      "X. Z. Li",
      "Y. G. Li",
      "Z. J. Li",
      "Z. Y. Li",
      "C. Liang",
      "H. Liang",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "C. C. Lin",
      "D. X. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. Liu",
      "F. H. Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. B. Liu",
      "H. H. Liu",
      "H. M. Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. Y. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. Liu",
      "L. C. Liu",
      "Lu Liu",
      "M. H. Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "X. Liu",
      "X. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. D. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "X. L. Lu",
      "Y. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "J. R. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "X. R. Lyu",
      "Y. F. Lyu",
      "F. C. Ma",
      "H. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "L. R. Ma",
      "M. M. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "T. Ma",
      "X. T. Ma",
      "X. Y. Ma",
      "Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "M. Maggiora",
      "S. Malde",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "Z. X. Meng",
      "J. G. Messchendorp",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "B. Moses",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "L. S. Nie",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Q. L. Niu",
      "W. D. Niu",
      "Y. Niu",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "Y. Y. Peng",
      "K. Peters",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "V. Prasad",
      "F. Z. Qi",
      "H. Qi",
      "H. R. Qi",
      "M. Qi",
      "T. Y. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "X. K. Qiao",
      "J. J. Qin",
      "L. Q. Qin",
      "L. Y. Qin",
      "X. P. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "Z. H. Qu",
      "C. F. Redmer",
      "K. J. Ren",
      "A. Rivetti",
      "M. Rolo",
      "G. Rong",
      "Ch. Rosner",
      "S. N. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Schoenning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "Z. J. Shang",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. Shi",
      "H. C. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "Q. Q. Shi",
      "S. Y. Shi",
      "X. Shi",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. J. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "W. Y. Sun",
      "Y. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. Q. Sun",
      "Z. T. Sun",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "M. Tang",
      "Y. A. Tang",
      "L. Y. Tao",
      "Q. T. Tao",
      "M. Tat",
      "J. X. Teng",
      "V. Thoren",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "Y. Wan",
      "S. J. Wang",
      "B. Wang",
      "B. L. Wang",
      "Bo Wang",
      "D. Y. Wang",
      "F. Wang",
      "H. J. Wang",
      "J. J. Wang",
      "J. P. Wang",
      "K. Wang",
      "L. L. Wang",
      "M. Wang",
      "N. Y. Wang",
      "S. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "X. N. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. L. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "Yaqian Wang",
      "Yi Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. Y. Wang",
      "Ziyi Wang",
      "D. H. Wei",
      "F. Weidner",
      "S. P. Wen",
      "Y. R. Wen",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "L. Wollenberg",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. Wu",
      "Y. H. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "B. H. Xiang",
      "T. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "S. Y. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "H. Y. Xu",
      "M. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "W. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. C. Xu",
      "Z. S. Xu",
      "F. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "T. Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. F. Yang",
      "Y. X. Yang",
      "Z. W. Yang",
      "Z. P. Yao",
      "M. Ye",
      "M. H. Ye",
      "J. H. Yin",
      "Junhao Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "T. Yu",
      "X. D. Yu",
      "Y. C. Yu",
      "C. Z. Yuan",
      "J. Yuan",
      "J. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "A. A. Zafar",
      "F. R. Zeng",
      "S. H. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. C. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. Zhang",
      "H. C. Zhang",
      "H. H. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. R. Zhang",
      "H. Y. Zhang",
      "J. Zhang",
      "J. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. S. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "L. M. Zhang",
      "Lei Zhang",
      "P. Zhang",
      "Q. Y. Zhang",
      "R. Y. Zhang",
      "S. H. Zhang",
      "Shulei Zhang",
      "X. D. Zhang",
      "X. M. Zhang",
      "X. Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Y. M. Zhang",
      "Yan Zhang",
      "Z. D. Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "Z. Z. Zhang",
      "G. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "L. Zhao",
      "Lei Zhao",
      "M. G. Zhao",
      "N. Zhao",
      "R. P. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "B. M. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "X. Zhong",
      "H. Zhou",
      "J. Y. Zhou",
      "L. P. Zhou",
      "S. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. Z. Zhou",
      "A. N. Zhu",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "K. S. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "T. J. Zhu",
      "W. D. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "Utilizing 4.5${~\\rm{fb}}^{-1}$ of $e^+e^-$ annihilation data collected with\nthe BESIII detector at the BEPCII collider at center-of-mass energies between\n4.600 and 4.699 GeV, the first observation of the singly Cabibbo-suppressed\ndecay $\\Lambda_c^{+}\\to p\\pi^0$ is presented, with a statistical significance\nof $5.4\\sigma$. The ratio of the branching fractions of $\\Lambda_c^{+}\\to\np\\pi^0$ and $\\Lambda_c^{+}\\to p\\eta$ is measured as\n$\\mathcal{B}(\\Lambda_c^{+}\\to p\\pi^0)/\\mathcal{B}(\\Lambda_c^{+}\\to\np\\eta)=(0.120\\pm0.026_{\\rm stat.}\\pm0.007_{\\rm syst.})$. This result resolves\nthe longstanding discrepancy between earlier experimental searches, providing\nboth a decisive conclusion and valuable input for QCD-inspired theoretical\nmodels. A sophisticated deep learning approach using a Transformer-based\narchitecture is employed to distinguish the signal from the prevalent hadronic\nbackgrounds, complemented by thorough validation and systematic uncertainty\nquantification.",
    "pdf_url": "http://arxiv.org/pdf/2410.13368v1",
    "published": "2024-10-17T09:21:28+00:00",
    "categories": [
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2410.13367v1",
    "title": "Wavelet analysis of low-frequency quasi-periodic oscillations in MAXI J1803$-$298 observed with Insight-HXMT and NICER",
    "authors": [
      "Y. J. Jin",
      "X. Chen",
      "H. F. Zhu",
      "Z. J. Jiang",
      "L. Zhang",
      "W. Wang"
    ],
    "abstract": "With data observed by the Hard X-ray Modulation Telescope\n(\\textit{Insight}-HXMT) and the Neutron star Interior Composition Explorer\n(\\textit {NICER}), we study low-frequency quasi-periodic oscillations (LFQPOs)\nof the black hole candidate MAXI J1803$-$298 during the 2021 outburst. Based on\nhardness intensity diagram and difference of the QPOs properties, Type-C and\nType-B QPOs are found in the low-hard state and soft intermediate state,\nrespectively. After searching for and classifying QPOs in Fourier domains, we\nextract the QPO component and study it with wavelet analysis. The QPO and\nno-QPO time intervals are separated by the confidence level, so that the\nS-factor, which is defined as the ratio of the QPO time interval to the total\nlength of good time interval, is calculated. We found S-factors decrease with\nQPOs frequency for Type-C QPOs but stay stable around zero for Type-B QPOs. The\nrelation of S-factor of Type-C QPOs and photon energy, the correlation of\nS-factor and counts are also studied. Different correlation of S-factor and\ncounts for different energy bands indicates different origins of QPOs in high\nenergy and low energy bands, which may be due to a dual-corona scenario.",
    "pdf_url": "http://arxiv.org/pdf/2410.13367v1",
    "published": "2024-10-17T09:20:37+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13366v1",
    "title": "Robustness in the Poisson Boolean model with convex grains",
    "authors": [
      "Peter Gracar",
      "Marilyn Korfhage",
      "Peter Mörters"
    ],
    "abstract": "We study the Poisson Boolean model where the grains are random convex bodies\nwith a rotation-invariant distribution. We say that a grain distribution is\ndense if the union of the grains covers the entire space and robust if the\nunion of the grains has an unbounded connected component irrespective of the\nintensity of the underlying Poisson process. If the grains are balls of random\nradius, then density and robustness are equivalent, but in general this is not\nthe case. We show that in any dimension $d\\ge2$ there are grain distributions\nthat are robust but not dense, and give general criteria for density,\nrobustness and non-robustness of a grain distribution. We give examples which\nshow that our criteria are sharp in many instances.",
    "pdf_url": "http://arxiv.org/pdf/2410.13366v1",
    "published": "2024-10-17T09:19:11+00:00",
    "categories": [
      "math.PR",
      "05C80 (Primary), 60K35 (Secondary)"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13365v3",
    "title": "Zero external magnetic field quantum standard of resistance at the 10-9 level",
    "authors": [
      "D. K. Patel",
      "K. M. Fijalkowski",
      "M. Kruskopf",
      "N. Liu",
      "M. Götz",
      "E. Pesel",
      "M. Jaime",
      "M. Klement",
      "S. Schreyeck",
      "K. Brunner",
      "C. Gould",
      "L. W. Molenkamp",
      "H. Scherer"
    ],
    "abstract": "The quantum anomalous Hall effect holds promise as a disruptive innovation in\ncondensed matter physics and metrology, as it gives access to Hall resistance\nquantization in terms of the von-Klitzing constant RK = h/e2 at zero external\nmagnetic field. In this work, we study the accuracy of Hall resistance\nquantization in a device based on the magnetic topological insulator material\n(V,Bi,Sb)2Te3. We show that the relative deviation of the Hall resistance from\nRK at zero external magnetic field is (4.4 +/- 8.7) nohm/ohm when extrapolated\nto zero measurement current, and (8.6 +/- 6.7) nohm/ohm when extrapolated to\nzero longitudinal resistivity (each with combined standard uncertainty, k = 1),\nwhich sets a new benchmark for the quantization accuracy in topological matter.\nThis precision and accuracy at the nohm/ohm level (or 10-9 of relative\nuncertainty) achieve the thresholds for relevant metrological applications and\nestablish a zero external magnetic field quantum standard of resistance - an\nimportant step towards the integration of quantum-based voltage and resistance\nstandards into a single universal quantum electrical reference.",
    "pdf_url": "http://arxiv.org/pdf/2410.13365v3",
    "published": "2024-10-17T09:18:26+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13364v3",
    "title": "Truncating Dyson-Schwinger Equations Based on Lefschetz Thimble Decomposition and Borel Resummation",
    "authors": [
      "Feiyu Peng",
      "Hongfei Shu"
    ],
    "abstract": "We study the zero-dimensional prototype of the path integrals in quantum\nmechanics and quantum field theory, with the action $S(\\phi)=\\frac{\\sigma\n}{2}\\phi^{2}+\\frac{\\lambda}{4}\\phi^{4}$. Using the Lefschetz thimble\ndecomposition and the saddle point expansion, we derive multiple asymptotic\nformal series of the correlation function associated with the perturbative and\nnon-perturbative saddle points. Furthermore, we reconstruct the exact\ncorrelation function employing the Borel resummation. We then consider how to\ntruncate the Dyson-Schwinger (DS) equations beginning with the perturbation\nexpansion of the correlation functions, analogous to the one obtained from the\nFeynmann diagram in higher dimensions. For the case $\\sigma<0$, we find that\nalthough the asymptotic series around the perturbative saddle point is Borel\nsummable, it does not capture the full information. Consequently, contributions\nfrom non-perturbative saddle points must be included to ensure a complete\ntruncation procedure.",
    "pdf_url": "http://arxiv.org/pdf/2410.13364v3",
    "published": "2024-10-17T09:15:46+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13363v1",
    "title": "Statistical testing on generative AI anomaly detection tools in Alzheimer's Disease diagnosis",
    "authors": [
      "Rosemary He",
      "Ichiro Takeuchi"
    ],
    "abstract": "Alzheimer's Disease is challenging to diagnose due to our limited\nunderstanding of its mechanism and large heterogeneity among patients.\nNeurodegeneration is studied widely as a biomarker for clinical diagnosis,\nwhich can be measured from time series MRI progression. On the other hand,\ngenerative AI has shown promise in anomaly detection in medical imaging and\nused for tasks including tumor detection. However, testing the reliability of\nsuch data-driven methods is non-trivial due to the issue of double-dipping in\nhypothesis testing. In this work, we propose to solve this issue with selective\ninference and develop a reliable generative AI method for Alzheimer's\nprediction. We show that compared to traditional statistical methods with\nhighly inflated p-values, selective inference successfully controls the false\ndiscovery rate under the desired alpha level while retaining statistical power.\nIn practice, our pipeline could assist clinicians in Alzheimer's diagnosis and\nearly intervention.",
    "pdf_url": "http://arxiv.org/pdf/2410.13363v1",
    "published": "2024-10-17T09:15:09+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13362v1",
    "title": "Bumpified Haar Wavelets and Tsirelson's Bound: Some Mathematical Properties and Insights from Block Toeplitz Matrices",
    "authors": [
      "David Dudal",
      "Ken Vandermeersch"
    ],
    "abstract": "This paper investigates a recent construction using bumpified Haar wavelets\nto demonstrate explicit violations of the Bell-Clauser-Horne-Shimony-Holt\ninequality within the vacuum state in quantum field theory. The construction\nwas tested for massless spinor fields in $(1+1)$-dimensional Minkowski\nspacetime and is claimed to achieve violations arbitrarily close to an upper\nbound known as Tsirelson's bound. We show that this claim can be reduced to a\nmathematical conjecture involving the maximal eigenvalue of a sequence of\nsymmetric matrices composed of integrals of Haar wavelet products. More\nprecisely, the asymptotic eigenvalue of this sequence should approach $\\pi$. We\npresent a formal argument using a subclass of wavelets, allowing us to reach\n$3.11052$. Although a complete proof remains elusive, we present further\ncompelling numerical evidence to support it.",
    "pdf_url": "http://arxiv.org/pdf/2410.13362v1",
    "published": "2024-10-17T09:14:39+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13361v1",
    "title": "On the new and accurate (Goudsmit-Saunderson) model for describing e-/e+ multiple Coulomb scattering (Geant4 Technical Note)",
    "authors": [
      "Mihaly Novak"
    ],
    "abstract": "A new model, for the accurate simulation of multiple Coulomb scattering (MSC)\nof e-/e+, has been implemented in Geant4 recently and made available with\nversion Geant4-10.4. The model is based on Goudsmit-Saunderson (GS) angular\ndistributions computed by utilising the screen Rutherford (SR) DCS and follows\nvery closely the formulation developed by Kawrakow [1, 2] and utilised in the\nEGSnrc toolkit [3]. Corrections, for taking into accountenergy loss [2]\nneglected by the GS theory, spin-relativistic effects [3] not included in the\nSR but might be accounted on the basis of Mott DCS as well as the so-called\nscattering power correction [4], i.e. appropriately incorporating deflections\ndue to sub-threshold delta ray productions, are all included similarly to the\nEGSnrc model [3]. Furthermore, an accurate electron-step algorithm [5, 6, 2] is\nutilised for path length correction, i.e. for calculating the post-step\nposition in each condensed history simulation steps such that the corresponding\nsingle-scattering longitudinal and lateral (post step point) distributions are\nvery well reproduced. An e-/e+ stepping algorithm, including the simulation\nstep-limit due to the MSC and boundary crossing [2]), free from step-size\nartefacts, makes the model complete. Details on this new model, including all\nthe above-mentioned components and corrections, are provided in this Geant4\ntechnical note.\n  It must be noted, that a Goudsmit-Saunderson model for MSC was available\nbefore Geant4-10.4., documented in [7], that has been completely replaced by\nthe model described in this technical note (keeping only the\nG4GoudsmitSaundersonMscModel name of the C++ class from that previous version)",
    "pdf_url": "http://arxiv.org/pdf/2410.13361v1",
    "published": "2024-10-17T09:14:13+00:00",
    "categories": [
      "physics.comp-ph",
      "physics.app-ph",
      "physics.med-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13360v3",
    "title": "RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models",
    "authors": [
      "Haoran Hao",
      "Jiaming Han",
      "Changsheng Li",
      "Yu-Feng Li",
      "Xiangyu Yue"
    ],
    "abstract": "The development of large language models (LLMs) has significantly enhanced\nthe capabilities of multimodal LLMs (MLLMs) as general assistants. However,\nlack of user-specific knowledge still restricts their application in human's\ndaily life. In this paper, we introduce the Retrieval Augmented Personalization\n(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we\nturn it into a personalized assistant in three steps. (a) Remember: We design a\nkey-value database to store user-related information, e.g., user's name, avatar\nand other attributes. (b) Retrieve: When the user initiates a conversation, RAP\nwill retrieve relevant information from the database using a multimodal\nretriever. (c) Generate: The input query and retrieved concepts' information\nare fed into MLLMs to generate personalized, knowledge-augmented responses.\nUnlike previous methods, RAP allows real-time concept editing via updating the\nexternal database. To further improve generation quality and alignment with\nuser-specific information, we design a pipeline for data collection and create\na specialized dataset for personalized training of MLLMs. Based on the dataset,\nwe train a series of MLLMs as personalized multimodal assistants. By\npretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual\nconcepts without additional finetuning. Our models demonstrate outstanding\nflexibility and generation quality across a variety of tasks, such as\npersonalized image captioning, question answering and visual recognition. The\ncode, data and models are available at https://hoar012.github.io/RAP-Project/.",
    "pdf_url": "http://arxiv.org/pdf/2410.13360v3",
    "published": "2024-10-17T09:10:26+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13359v2",
    "title": "Correlated proton disorder in the crystal structure of the double hydroxide perovskite CuSn(OH)$_6$",
    "authors": [
      "Anton A. Kulbakov",
      "Ellen Häußler",
      "Kaushick K. Parui",
      "Aswathi Mannathanath Chakkingal",
      "Nikolai S. Pavlovskii",
      "Vladimir Yu. Pomjakushin",
      "Laura Cañadillas-Delgado",
      "Thomas Hansen",
      "Darren C. Peets",
      "Thomas Doert",
      "Dmytro S. Inosov"
    ],
    "abstract": "CuSn(OH)$_6$ is a quantum spin system from the family of magnetic double\nperovskite hydroxides, having a frustrated magnetic sublattice. It is also\nknown as the natural mineral mushistonite, whose crystal structure has remained\nelusive for decades. Here we employ x-ray and neutron powder diffraction to\nsolve the crystal structure of CuSn(OH)$_6$ and propose a structure model in\nthe orthorhombic space group $Pnnn$ with correlated proton disorder. The\noccupation of the hydrogen sites in the structure is constrained by ``ice\nrules'' similar to those known for water ice. The resulting frustration of the\nhydrogen bonding network is likely to have a complex and interesting interplay\nwith the strong magnetic frustration expected in the face-centred magnetic\nsublattice. Structural distortions, which are quite pronounced in Cu$^{2+}$\ncompounds due to the Jahn-Teller effect, partially alleviate both types of\nfrustration. We also show that hydrostatic pressure tends to suppress proton\ndisorder through a sequence of proton-ordering transitions, as some of the\nsplit hydrogen sites merge already at 1.75 GPa while others show a tendency\ntoward possible merging at higher pressures.",
    "pdf_url": "http://arxiv.org/pdf/2410.13359v2",
    "published": "2024-10-17T09:09:58+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13918v2",
    "title": "FTSmartAudit: A Knowledge Distillation-Enhanced Framework for Automated Smart Contract Auditing Using Fine-Tuned LLMs",
    "authors": [
      "Zhiyuan Wei",
      "Jing Sun",
      "Zijian Zhang",
      "Xianhao Zhang",
      "Meng Li",
      "Mauro Conti"
    ],
    "abstract": "The rise of blockchain technologies has greatly accelerated the development\nand deployment of smart contracts. However, their inherent vulnerabilities and\nsusceptibility to bugs have led to significant financial losses, underscoring\nthe challenges in securing smart contracts. While traditional auditing methods\nare crucial, they often fall short in addressing the increasing complexity and\nvolume of smart contracts. Recent advancements in Large Language Models (LLMs)\noffer promising solutions for enhancing software auditing by automatically\nidentifying security vulnerabilities. Despite their potential, the practical\napplication of these models is hindered by substantial computational demands.\nThis paper investigates the feasibility of using smaller, fine-tuned models to\nachieve comparable or even superior results in smart contract auditing. We\nintroduce the FTSmartAudit framework, which is designed to develop\ncost-effective, specialized models for smart contract auditing through the\nfine-tuning of LLMs. Our contributions include: (1) a single-task learning\nframework that streamlines data preparation, training, evaluation, and\ncontinuous learning; (2) a robust dataset generation method utilizing\ndomain-special knowledge distillation to produce high-quality datasets from\nadvanced models like GPT-4o; (3) an adaptive learning strategy to maintain\nmodel accuracy and robustness; (4) the proven effectiveness of fine-tuned\nmodels in detecting specific vulnerabilities and complex logical errors; and\n(5) a framework that can be extended to other domains requiring LLM solutions.\nOur experimental results demonstrate that smaller models can surpass\nstate-of-the-art commercial models and tools in detecting vulnerabilities in\nsmart contracts.",
    "pdf_url": "http://arxiv.org/pdf/2410.13918v2",
    "published": "2024-10-17T09:09:09+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13358v1",
    "title": "Subspace method based on neural networks for eigenvalue problems",
    "authors": [
      "Xiaoying Dai",
      "Yunying Fan",
      "Zhiqiang Sheng"
    ],
    "abstract": "With the rapid development of machine learning, numerical discretization\nmethods based on deep neural networks have been widely used in many fields,\nespecially in solving high-dimensional problems where traditional methods face\nbottlenecks. However, for low-dimensional problems, existing machine learning\nmethods are not as accurate and efficient as traditional methods. In this\npaper, we propose a subspace method based on neural networks for eigenvalue\nproblems with high accuracy and low cost. Our basic idea is to use neural\nnetwork based basis functions to span a subspace, then calculate the parameters\nof the neural network based basis functions through appropriate training, and\nfinally calculate the Galerkin projection of the eigenvalue problem onto the\nsubspace and obtain an approximate solution. In addition, we reduce the\ndimension of the subspace by applying some dimensionality reduction technique,\nwhich can improve the accuracy of the approximate solution in further.\nNumerical experiments show that we can obtain approximate eigenvalues with\naccuracy of $10^{-11}$ but with less then 400 epochs, which is significantly\nsuperior to other existing neural network based methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13358v1",
    "published": "2024-10-17T09:08:21+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65N25, 65L15, 68T07"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13357v1",
    "title": "Enhancing Crowdsourced Audio for Text-to-Speech Models",
    "authors": [
      "José Giraldo",
      "Martí Llopart-Font",
      "Alex Peiró-Lilja",
      "Carme Armentano-Oller",
      "Gerard Sant",
      "Baybars Külebi"
    ],
    "abstract": "High-quality audio data is a critical prerequisite for training robust\ntext-to-speech models, which often limits the use of opportunistic or\ncrowdsourced datasets. This paper presents an approach to overcome this\nlimitation by implementing a denoising pipeline on the Catalan subset of\nCommonvoice, a crowd-sourced corpus known for its inherent noise and\nvariability. The pipeline incorporates an audio enhancement phase followed by a\nselective filtering strategy. We developed an automatic filtering mechanism\nleveraging Non-Intrusive Speech Quality Assessment (NISQA) models to identify\nand retain the highest quality samples post-enhancement. To evaluate the\nefficacy of this approach, we trained a state of the art diffusion-based TTS\nmodel on the processed dataset. The results show a significant improvement,\nwith an increase of 0.4 in the UTMOS Score compared to the baseline dataset\nwithout enhancement. This methodology shows promise for expanding the utility\nof crowdsourced data in TTS applications, particularly for mid to low resource\nlanguages like Catalan.",
    "pdf_url": "http://arxiv.org/pdf/2410.13357v1",
    "published": "2024-10-17T09:07:57+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13356v1",
    "title": "On the second eigenvalue of the infinity Laplacian with Robin boundary conditions",
    "authors": [
      "Vincenzo Amato",
      "Alba Lia Masiello",
      "Carlo Nitsch",
      "Cristina Trombetti"
    ],
    "abstract": "We study the behaviour, as $p \\to +\\infty$, of the second eigenvalues of the\n$p$-Laplacian with Robin boundary conditions and the limit of the associated\neigenfunctions. We prove that, up to some regularity of the set, the limit of\nthe second eigenvalues is actually the second eigenvalue of the so-called\n$\\infty$-Laplacian.",
    "pdf_url": "http://arxiv.org/pdf/2410.13356v1",
    "published": "2024-10-17T09:07:28+00:00",
    "categories": [
      "math.AP",
      "35J92, 35J94, 35P15"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13355v2",
    "title": "Self-Supervised Scene Flow Estimation with Point-Voxel Fusion and Surface Representation",
    "authors": [
      "Xuezhi Xiang",
      "Xi Wang",
      "Lei Zhang",
      "Denis Ombati",
      "Himaloy Himu",
      "Xiantong Zhen"
    ],
    "abstract": "Scene flow estimation aims to generate the 3D motion field of points between\ntwo consecutive frames of point clouds, which has wide applications in various\nfields. Existing point-based methods ignore the irregularity of point clouds\nand have difficulty capturing long-range dependencies due to the inefficiency\nof point-level computation. Voxel-based methods suffer from the loss of detail\ninformation. In this paper, we propose a point-voxel fusion method, where we\nutilize a voxel branch based on sparse grid attention and the shifted window\nstrategy to capture long-range dependencies and a point branch to capture\nfine-grained features to compensate for the information loss in the voxel\nbranch. In addition, since xyz coordinates are difficult to describe the\ngeometric structure of complex 3D objects in the scene, we explicitly encode\nthe local surface information of the point cloud through the umbrella surface\nfeature extraction (USFE) module. We verify the effectiveness of our method by\nconducting experiments on the Flyingthings3D and KITTI datasets. Our method\noutperforms all other self-supervised methods and achieves highly competitive\nresults compared to fully supervised methods. We achieve improvements in all\nmetrics, especially EPE, which is reduced by 8.51% on the KITTIo dataset and\n10.52% on the KITTIs dataset, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2410.13355v2",
    "published": "2024-10-17T09:05:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13354v1",
    "title": "Emergent spacetime supersymmetry in an interacting Kitaev chain with explicit supersymmetry",
    "authors": [
      "Urei Miura",
      "Keisuke Totsuka"
    ],
    "abstract": "We investigate the emergence of spacetime supersymmetry (SUSY) in an\ninteracting Kitaev chain model with explicit microscopic $\\mathcal{N}=1$\nquantum mechanical SUSY. As the interaction strength is varied, the model\ntransitions from a weak-coupling gapless phase with spontaneously broken SUSY\nto a strong-coupling phase with restored SUSY. In this paper, we numerically\ndetermine the transition point and investigate the phase structure around it.\nThe weak-coupling phase is governed by the Ising conformal field theory (CFT)\nwith central charge $c=1/2$ which agrees with the prediction made in our\nprevious work and that the SUSY restoration transition which borders the\nstrong-coupling gapped phase belongs to the $c=7/10$ tricritical Ising\nuniversality with emergent superconformal invariance. Crucially, the phase\nstructure around the transition closely aligns with the scenario proposed by\nZamolodchikov and others based on the integrable deformation of CFTs. These\nfindings provide a concrete example of a lattice model where explicit\nmicroscopic supersymmetry at criticality, enriches the understanding of phase\ntransitions governed by supersymmetric conformal field theories.",
    "pdf_url": "http://arxiv.org/pdf/2410.13354v1",
    "published": "2024-10-17T09:04:20+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.stat-mech",
      "hep-th"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13353v1",
    "title": "Dynamical resonances in PHANGS galaxies",
    "authors": [
      "Marina Ruiz-García",
      "Miguel Querejeta",
      "Santiago García-Burillo",
      "Eric Emsellem",
      "Sharon E. Meidt",
      "Mattia C. Sormani",
      "Eva Schinnerer",
      "Thomas G. Williams",
      "Zein Bazzi",
      "Dario Colombo",
      "Damian R. Gleis",
      "Oleg Y. Gnedin",
      "Ralf S. Klessen",
      "Adam K. Leroy",
      "Patricia Sánchez-Blázquez",
      "Sophia K. Stuber"
    ],
    "abstract": "Bars are remarkable stellar structures that can transport gas toward centers\nand drive the secular evolution of galaxies. In this context, it is important\nto locate dynamical resonances associated with bars. For this study, we used\n${Spitzer}$ near-infrared images as a proxy for the stellar gravitational\npotential and the ALMA CO(J=2-1) gas distribution from the PHANGS survey to\ndetermine the position of the main dynamical resonances associated with the\nbars in the PHANGS sample of 74 nearby star-forming galaxies. We used the\ngravitational torque method to estimate the location of the bar corotation\nradius ($R_{\\rm CR}$), where stars and gas rotate at the same angular velocity\nas the bar. Of the 46 barred galaxies in PHANGS, we have successfully\ndetermined the corotation (CR) for 38 of them. The mean ratio of the $R_{\\rm\nCR}$ to the bar radius ($R_{\\rm bar}$) is $\\mathcal{R} = R_{\\rm CR}/R_{\\rm bar}\n= 1.12$, with a standard deviation of $0.39$. This is consistent with the\naverage value expected from theory and suggests that bars are predominantly\nfast. We also compared our results with other bar CR measurements from the\nliterature, which employ different methods, and find good agreement ($\\rho =\n0.64$). Finally, using rotation curves, we have estimated other relevant\nresonances such as the inner Lindblad resonance (ILR) and the outer Lindblad\nresonance (OLR), which are often associated with rings. This work provides a\nuseful catalog of resonances for a large sample of nearby galaxies and\nemphasizes the clear connection between bar dynamics and morphology.",
    "pdf_url": "http://arxiv.org/pdf/2410.13353v1",
    "published": "2024-10-17T09:03:55+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13352v1",
    "title": "LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of the European Court of Human Rights",
    "authors": [
      "Odysseas S. Chlapanis",
      "Dimitrios Galanis",
      "Ion Androutsopoulos"
    ],
    "abstract": "We present Legal Argument Reasoning (LAR), a novel task designed to evaluate\nthe legal reasoning capabilities of Large Language Models (LLMs). The task\nrequires selecting the correct next statement (from multiple choice options) in\na chain of legal arguments from court proceedings, given the facts of the case.\nWe constructed a dataset (LAR-ECHR) for this task using cases from the European\nCourt of Human Rights (ECHR). We evaluated seven general-purpose LLMs on\nLAR-ECHR and found that (a) the ranking of the models is aligned with that of\nLegalBench, an established US-based legal reasoning benchmark, even though\nLAR-ECHR is based on EU law, (b) LAR-ECHR distinguishes top models more\nclearly, compared to LegalBench, (c) even the best model (GPT-4o) obtains 75.8%\naccuracy on LAR-ECHR, indicating significant potential for further model\nimprovement. The process followed to construct LAR-ECHR can be replicated with\ncases from other legal systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13352v1",
    "published": "2024-10-17T09:03:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13351v1",
    "title": "Representation Learning of Structured Data for Medical Foundation Models",
    "authors": [
      "Vijay Prakash Dwivedi",
      "Viktor Schlegel",
      "Andy T. Liu",
      "Thanh-Tung Nguyen",
      "Abhinav Ramesh Kashyap",
      "Jeng Wei",
      "Wei-Hsian Yin",
      "Stefan Winkler",
      "Robby T. Tan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious domains, including healthcare. However, their ability to effectively\nrepresent structured non-textual data, such as the alphanumeric medical codes\nused in records like ICD-10 or SNOMED-CT, is limited and has been particularly\nexposed in recent research. This paper examines the challenges LLMs face in\nprocessing medical codes due to the shortcomings of current tokenization\nmethods. As a result, we introduce the UniStruct architecture to design a\nmultimodal medical foundation model of unstructured text and structured data,\nwhich addresses these challenges by adapting subword tokenization techniques\nspecifically for the structured medical codes. Our approach is validated\nthrough model pre-training on both an extensive internal medical database and a\npublic repository of structured medical records. Trained on over 1 billion\ntokens on the internal medical database, the proposed model achieves up to a\n23% improvement in evaluation metrics, with around 2% gain attributed to our\nproposed tokenization. Additionally, when evaluated on the EHRSHOT public\nbenchmark with a 1/1000 fraction of the pre-training data, the UniStruct model\nimproves performance on over 42% of the downstream tasks. Our approach not only\nenhances the representation and generalization capabilities of patient-centric\nmodels but also bridges a critical gap in representation learning models'\nability to handle complex structured medical data, alongside unstructured text.",
    "pdf_url": "http://arxiv.org/pdf/2410.13351v1",
    "published": "2024-10-17T09:02:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13350v1",
    "title": "Applying the Velocity Gradient Technique in NGC 1333: Comparison with Dust Polarization Observations",
    "authors": [
      "Archana Soam",
      "Ka Ho Yuen",
      "Ian Stephens",
      "Chi Yan Law",
      "Ka Wai Ho",
      "Simon Coudé"
    ],
    "abstract": "Magnetic fields (B-fields) are ubiquitous in the interstellar medium (ISM),\nand they play an essential role in the formation of molecular clouds and\nsubsequent star formation. However, B-fields in interstellar environments\nremain challenging to measure, and their properties typically need to be\ninferred from dust polarization observations over multiple physical scales. In\nthis work, we seek to use a recently proposed approach called the Velocity\nGradient Technique (VGT) to study B-fields in star-forming regions and compare\nthe results with dust polarization observations in different wavelengths. The\nVGT is based on the anisotropic properties of eddies in magnetized turbulence\nto derive B-field properties in the ISM. We investigate that this technique is\nsynergistic with dust polarimetry when applied to a turbulent diffused medium\nfor the purpose of measuring its magnetization. Specifically, we use the VGT on\nmolecular line data toward the NGC~1333 star-forming region ($\\rm ^{12}CO$,\n$\\rm ^{13}CO$, $\\rm C^{18}O$, and $\\rm N_{2}H^{+}$), and we compare the derived\nB-field properties with those inferred from 214 and 850~$\\mu$m dust\npolarization observations of the region using SOFIA/HAWC+ and JCMT/POL-2,\nrespectively. We estimate both the inclination angle and the 3D Alfv\\'enic Mach\nNumber $M_A$ from the molecular line gradients. Crucially, testing this\ntechnique on gravitationally bound, dynamic, and turbulent regions, and\ncomparing the results with those obtained from polarization observations at\ndifferent wavelength, such as the plane-of-the-sky field orientation, is an\nimportant test on the applicability of the VGT in various density regimes of\nthe ISM.",
    "pdf_url": "http://arxiv.org/pdf/2410.13350v1",
    "published": "2024-10-17T09:01:27+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13349v1",
    "title": "GlossyGS: Inverse Rendering of Glossy Objects with 3D Gaussian Splatting",
    "authors": [
      "Shuichang Lai",
      "Letian Huang",
      "Jie Guo",
      "Kai Cheng",
      "Bowen Pan",
      "Xiaoxiao Long",
      "Jiangjing Lyu",
      "Chengfei Lv",
      "Yanwen Guo"
    ],
    "abstract": "Reconstructing objects from posed images is a crucial and complex task in\ncomputer graphics and computer vision. While NeRF-based neural reconstruction\nmethods have exhibited impressive reconstruction ability, they tend to be\ntime-comsuming. Recent strategies have adopted 3D Gaussian Splatting (3D-GS)\nfor inverse rendering, which have led to quick and effective outcomes. However,\nthese techniques generally have difficulty in producing believable geometries\nand materials for glossy objects, a challenge that stems from the inherent\nambiguities of inverse rendering. To address this, we introduce GlossyGS, an\ninnovative 3D-GS-based inverse rendering framework that aims to precisely\nreconstruct the geometry and materials of glossy objects by integrating\nmaterial priors. The key idea is the use of micro-facet geometry segmentation\nprior, which helps to reduce the intrinsic ambiguities and improve the\ndecomposition of geometries and materials. Additionally, we introduce a normal\nmap prefiltering strategy to more accurately simulate the normal distribution\nof reflective surfaces. These strategies are integrated into a hybrid geometry\nand material representation that employs both explicit and implicit methods to\ndepict glossy objects. We demonstrate through quantitative analysis and\nqualitative visualization that the proposed method is effective to reconstruct\nhigh-fidelity geometries and materials of glossy objects, and performs\nfavorably against state-of-the-arts.",
    "pdf_url": "http://arxiv.org/pdf/2410.13349v1",
    "published": "2024-10-17T09:00:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13348v1",
    "title": "Technical Note: Vendor-Specific Approach for Standardized Uptake Value Calculation",
    "authors": [
      "Maksym Fritsak",
      "Hubert S. Gabryś",
      "Preethi Mohan",
      "Matthias Guckenberger",
      "Stephanie Tanadini-Lang"
    ],
    "abstract": "The Standardized Uptake Value (SUV) is a critical metric in positron emission\ntomography (PET) imaging, used to assess metabolic activity. However,\ncalculating SUV from DICOM files presents challenges due to vendor-specific\nDICOM attributes and variations in the encoding of radiotracer accumulation\ntimes. This technical note introduces a robust, vendor-specific SUV calculation\nstrategy that addresses inconsistencies in current methodologies. We also\nintegrate this strategy into an open-source software solution, Z-Rad, capable\nof converting raw PET DICOM data into body-weight normalized SUV NIfTI files.\n  Our SUV calculation strategy was developed by reviewing DICOM conformance\nstatements from GE, Philips, and Siemens. Validation was conducted using\nreal-world PET datasets, and the proposed strategy was compared to existing\nsoftware solutions.\n  Our SUV calculation approach demonstrated improved accuracy, particularly in\nresolving time-related discrepancies in the studied data. Our analysis also\nidentified inconsistencies in the SUV calculation methods used by popular\ncommercial and open-source software solutions, which do not fully account for\nvendor-specific DICOM attributes and PET image acquisition times. These\nlimitations resulted in errors in SUV estimation reaching 33\\% when comparing\nour strategy to studied software.\n  The proposed vendor-specific SUV calculation strategy significantly enhances\naccuracy in PET imaging by addressing key inconsistencies caused by variations\nin DICOM attributes and image acquisition times across different vendors. This\nmethod effectively reduces SUV calculation errors and has been integrated into\nan open-source software, Z-Rad.",
    "pdf_url": "http://arxiv.org/pdf/2410.13348v1",
    "published": "2024-10-17T09:00:10+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13347v1",
    "title": "Geometric spectral optimization on surfaces",
    "authors": [
      "Romain Petrides"
    ],
    "abstract": "We prove the existence of optimal metrics for a wide class of combinations of\nLaplace eigenvalues on closed orientable surfaces of any genus. The optimal\nmetrics are explicitely related to Laplace minimal eigenmaps, defined as\nbranched minimal immersions into ellipsoids parametrized by the eigenvalues of\nthe critical metrics whose coordinates are eigenfunctions with respect to these\neigenvalues. In particular, we prove existence of maximal metrics for the first\nLaplace eigenvalue on orientable surfaces of any genus. In this case, the\ntarget of eigenmaps are spheres. This completes a broad picture, first drawn by\nJ. Hersch, 1970 (sphere), M. Berger 1973, N. Nadirashvili 1996 (tori). Our\nresult is based on the combination of accurate constructions of\nPalais-Smale-like sequences for spectral functionals and on techniques by M.\nKarpukhin, R. Kusner, P. McGrath, D. Stern 2024, developped in the case of an\nequivariant optimization of the first Laplace and Steklov eigenvalues. Their\nresult is significantly extended for two reasons: specific equivariant\noptimizations are not required anymore to obtain existence of maximizers of the\nfirst eigenvalue for any topology and our technique also holds for combinations\nof eigenvalues.",
    "pdf_url": "http://arxiv.org/pdf/2410.13347v1",
    "published": "2024-10-17T08:57:15+00:00",
    "categories": [
      "math.DG",
      "math.AP",
      "math.FA",
      "math.SP"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13346v1",
    "title": "The controlled rotation of entanglement in altermagnets",
    "authors": [
      "M. Kulig",
      "T. Maslowski",
      "K. A. Kouzakov",
      "V. K. Dugaev",
      "P. Kurashvili",
      "S. Wolski",
      "M. Inglot",
      "C. Jasiukiewicz",
      "L. Chotorlishvili"
    ],
    "abstract": "Altermagnetism became very popular because of unique features, namely\ncoupling between magnetic properties and momentum of itinerant electrons. The\nparticular model of the altermagnetic system of our interest has already been\nstudied in recent publications in a different context: Phys. Rev. B\n\\textbf{108}, L140408 (2023). Here, we study the scattering process of an\nitinerant electron from the altermagnetic system on the electron localized in a\nquantum dot. We found a spatially inhomogeneous distribution of quantum\nentanglement in the post-scattering state. An interesting observation is the\ncontrolled rotation of entanglement achieved by means of spin-orbital coupling\nconstant in altermagnetic. We also studied Reny entropy and the effect of\ndisorder in the system leading to randomness in the spin-orbit constant. Our\nmain finding is that due to the unique properties of an altermagnetic system,\ntuning the applied external magnetic field allows tailoring of the desired\nentangled state. Thus, the scattering process, in essence, mimics the\nHadamard-CNOT Gate transformation, converting the initial disentangled state\ninto the entangled state of Bell's state. In particular, we achieved more than\n70 percent fidelity between the post-scattering and Bell's states.",
    "pdf_url": "http://arxiv.org/pdf/2410.13346v1",
    "published": "2024-10-17T08:57:12+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2410.13345v1",
    "title": "Dynamical Analysis of a Predator-Prey Model with Additive Allee Effect and Prey Group Defense",
    "authors": [
      "Resmawan Resmawan",
      "Agus Suryanto",
      "Isnani Darti",
      "Hasan S Panigoro"
    ],
    "abstract": "In this article, we develop a predator-prey model with Allee effect and prey\ngroup defense. The model has three equilibrium points i.e. the trivial point,\nthe predator extinction point, and the coexistence point. All equilibrium\npoints are locally asymptotically stable under certain conditions. The Allee\neffect in this model influences the stability of the equilibrium point. If the\nAllee effect is weak, then the trivial equilibrium point is unstable.\nMeanwhile, if the Allee effect is strong, then the trivial equilibrium point is\nlocally asymptotically stable. Those mean that a strong Allee effect can lead\nto the extinction of both populations. Moreover, under weak Allee condition,\nforward bifurcation and Hopf bifurcation occur at the predator extinction\nequilibrium point. Meanwhile, a strong Allee effect may induce bistability at\nboth the trivial equilibrium point and the predator extinction equilibrium\npoint. Those mean that prey can survive without the presence of predators, but\na strong Allee effect can lead to prey extinction if the population size is\nvery small. To support our analytical findings, we perform some numerical\nsimulations in the final section.",
    "pdf_url": "http://arxiv.org/pdf/2410.13345v1",
    "published": "2024-10-17T08:56:06+00:00",
    "categories": [
      "math.DS",
      "physics.soc-ph"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13344v1",
    "title": "Cerberus: Efficient Inference with Adaptive Parallel Decoding and Sequential Knowledge Enhancement",
    "authors": [
      "Yuxuan Liu",
      "Wenyuan Li",
      "Laizhong Cui",
      "Hailiang Yang"
    ],
    "abstract": "Large language models (LLMs) often face a bottleneck in inference speed due\nto their reliance on auto-regressive decoding. Recently, parallel decoding has\nshown significant promise in enhancing inference efficiency. However, we have\nidentified two key issues with existing parallel decoding frameworks: (1)\ndecoding heads fail to balance prediction accuracy and the parallelism of\nexecution, and (2) parallel decoding is not a universal solution, as it can\nbring unnecessary overheads at some challenging decoding steps. To address\nthese issues, we propose Cerberus, an adaptive parallel decoding framework\nintroduces the gating mechanism to enable the LLMs to adaptively choose\nappropriate decoding approaches at each decoding step, along with introducing a\nnew paradigm of decoding heads that introduce the sequential knowledge while\nmaintaining execution parallelism. The experiment results demonstrate that the\nCerberus can achieve up to 2.12x speed up compared to auto-regressive decoding,\nand outperforms one of the leading parallel decoding frameworks, Medusa, with a\n10% - 30% increase in acceleration and superior generation quality.",
    "pdf_url": "http://arxiv.org/pdf/2410.13344v1",
    "published": "2024-10-17T08:55:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.18127v1",
    "title": "Optimizing Preference Alignment with Differentiable NDCG Ranking",
    "authors": [
      "Jiacong Zhou",
      "Xianyun Wang",
      "Jun Yu"
    ],
    "abstract": "Aligning large language models with human preferences improves interaction\nquality and safety by ensuring outputs better reflect human values. A promising\nstrategy involves Reinforcement Learning from Human Feedback (RLHF), starting\nwith collecting and ranking responses generated by a supervised fine-tuning\nmodel to refine alignment. Current methods (DPO) focus on learning from\npairwise preference data, categorizing responses into preferred and less\npreferred pairs, and optimizing by maximizing pairwise margins. Recent studies\nhave uncovered a substantial discrepancy between the theoretical aspirations of\npreference learning and its real-world results. Current preference alignment\ntechniques underperform expectations, with ranking accuracies below $60\\%$ on\nstandard datasets. This suggests existing methods inadequately capture ideal\npreference relationships within sequences. To address this challenge, this\npaper introduces \\underline{D}irect \\underline{R}anking \\underline{P}reference\n\\underline{O}ptimization (DRPO), a novel method that views human preference\nalignment as a Learning-to-Rank (LTR) task. DRPO leverages NDCG, a widely used\nLTR metric, to optimize the ranking of responses within lists based on\npreference data, thereby enhancing ranking accuracies. Due to the\nnondifferentiability of NDCG, we propose diffNDCG loss, a differentiable\napproximation facilitated by a sorting network to simulate NDCG. Furthermore,\nto improve the quality of generated response, we propose a novel margin-based\nAdaptive Rank Policy Score. Extensive experiments have shown that DRPO\noutperforms existing baseline methods, enhancing the quality of the generated\nresponses.",
    "pdf_url": "http://arxiv.org/pdf/2410.18127v1",
    "published": "2024-10-17T08:54:57+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13343v1",
    "title": "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models",
    "authors": [
      "Yu Yuan",
      "Lili Zhao",
      "Kai Zhang",
      "Guangting Zheng",
      "Qi Liu"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in various\nnatural language processing tasks. However, LLMs may rely on dataset biases as\nshortcuts for prediction, which can significantly impair their robustness and\ngeneralization capabilities. This paper presents Shortcut Suite, a\ncomprehensive test suite designed to evaluate the impact of shortcuts on LLMs'\nperformance, incorporating six shortcut types, five evaluation metrics, and\nfour prompting strategies. Our extensive experiments yield several key\nfindings: 1) LLMs demonstrate varying reliance on shortcuts for downstream\ntasks, significantly impairing their performance. 2) Larger LLMs are more\nlikely to utilize shortcuts under zero-shot and few-shot in-context learning\nprompts. 3) Chain-of-thought prompting notably reduces shortcut reliance and\noutperforms other prompting strategies, while few-shot prompts generally\nunderperform compared to zero-shot prompts. 4) LLMs often exhibit\noverconfidence in their predictions, especially when dealing with datasets that\ncontain shortcuts. 5) LLMs generally have a lower explanation quality in\nshortcut-laden datasets, with errors falling into three types: distraction,\ndisguised comprehension, and logical fallacy. Our findings offer new insights\nfor evaluating robustness and generalization in LLMs and suggest potential\ndirections for mitigating the reliance on shortcuts. The code is available at\n\\url {https://github.com/yyhappier/ShortcutSuite.git}.",
    "pdf_url": "http://arxiv.org/pdf/2410.13343v1",
    "published": "2024-10-17T08:52:52+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13342v1",
    "title": "DART: Disentanglement of Accent and Speaker Representation in Multispeaker Text-to-Speech",
    "authors": [
      "Jan Melechovsky",
      "Ambuj Mehrish",
      "Berrak Sisman",
      "Dorien Herremans"
    ],
    "abstract": "Recent advancements in Text-to-Speech (TTS) systems have enabled the\ngeneration of natural and expressive speech from textual input. Accented TTS\naims to enhance user experience by making the synthesized speech more relatable\nto minority group listeners, and useful across various applications and\ncontext. Speech synthesis can further be made more flexible by allowing users\nto choose any combination of speaker identity and accent, resulting in a wide\nrange of personalized speech outputs. Current models struggle to disentangle\nspeaker and accent representation, making it difficult to accurately imitate\ndifferent accents while maintaining the same speaker characteristics. We\npropose a novel approach to disentangle speaker and accent representations\nusing multi-level variational autoencoders (ML-VAE) and vector quantization\n(VQ) to improve flexibility and enhance personalization in speech synthesis.\nOur proposed method addresses the challenge of effectively separating speaker\nand accent characteristics, enabling more fine-grained control over the\nsynthesized speech. Code and speech samples are publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2410.13342v1",
    "published": "2024-10-17T08:51:46+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13341v2",
    "title": "Limits to scalable evaluation at the frontier: LLM as Judge won't beat twice the data",
    "authors": [
      "Florian E. Dorner",
      "Vivian Y. Nastl",
      "Moritz Hardt"
    ],
    "abstract": "High quality annotations are increasingly a bottleneck in the explosively\ngrowing machine learning ecosystem. Scalable evaluation methods that avoid\ncostly annotation have therefore become an important research ambition. Many\nhope to use strong existing models in lieu of costly labels to provide cheap\nmodel evaluations. Unfortunately, this method of using models as judges\nintroduces biases, such as self-preferencing, that can distort model\ncomparisons. An emerging family of debiasing tools promises to fix these issues\nby using a few high quality labels to debias a large number of model judgments.\nIn this paper, we study how far such debiasing methods, in principle, can go.\nOur main result shows that when the judge is no more accurate than the\nevaluated model, no debiasing method can decrease the required amount of ground\ntruth labels by more than half. Our result speaks to the severe limitations of\nthe LLM-as-a-judge paradigm at the evaluation frontier where the goal is to\nassess newly released models that are possibly better than the judge. Through\nan empirical evaluation, we demonstrate that the sample size savings achievable\nin practice are even more modest than what our theoretical limit suggests.\nAlong the way, our work provides new observations about debiasing methods for\nmodel evaluation, and points out promising avenues for future work.",
    "pdf_url": "http://arxiv.org/pdf/2410.13341v2",
    "published": "2024-10-17T08:49:42+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13340v1",
    "title": "Negative moments as the signature of the radial density at small distances",
    "authors": [
      "M. Atoui",
      "M. Hoballah",
      "M. Lassaut",
      "J. Van de Wiele"
    ],
    "abstract": "The present paper proposes a robust evaluation of any radial density at small\ndistances using negative-order radial moments evaluated in momentum space. This\nevaluation provides a valuable insight into the behavior of a given radial\ndensity in the vicinity of $r=0$, and puts strong emphasis on the importance of\nmeasuring form factors at large squared four-momentum transfer, a domain\nessential for the determination of negative order moments. A specific attention\nis paid to the regularization scheme directly affecting the numerical\ndetermination of the radial density's parametrization. The proposed method is\napplied to non-relativistic study cases of the nucleon electric ($G_{En},\nG_{Ep}$), and proton magnetic $G_{Mp}$ form factors. The validation is\nperformed through comparison of the results of the approach to the analytically\ndetermined Maclaurin expansion - in the vicinity of $r=0$ - of the radial\ndensity function. The method is also applied to the relativistic Dirac form\nfactor $F_1$ of the proton. In such a non-trivial case, the Maclaurin\ndevelopment might not exist for the radial density, rendering the determination\nfrom the proposed method extremely important.",
    "pdf_url": "http://arxiv.org/pdf/2410.13340v1",
    "published": "2024-10-17T08:49:32+00:00",
    "categories": [
      "nucl-th",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13339v2",
    "title": "Probing-RAG: Self-Probing to Guide Language Models in Selective Document Retrieval",
    "authors": [
      "Ingeol Baek",
      "Hwan Chang",
      "Byeongjeong Kim",
      "Jimin Lee",
      "Hwanhee Lee"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enhances language models by retrieving\nand incorporating relevant external knowledge. However, traditional\nretrieve-and-generate processes may not be optimized for real-world scenarios,\nwhere queries might require multiple retrieval steps or none at all. In this\npaper, we propose a Probing-RAG, which utilizes the hidden state\nrepresentations from the intermediate layers of language models to adaptively\ndetermine the necessity of additional retrievals for a given query. By\nemploying a pre-trained prober, Probing-RAG effectively captures the model's\ninternal cognition, enabling reliable decision-making about retrieving external\ndocuments. Experimental results across five open-domain QA datasets demonstrate\nthat Probing-RAG outperforms previous methods while reducing the number of\nredundant retrieval steps.",
    "pdf_url": "http://arxiv.org/pdf/2410.13339v2",
    "published": "2024-10-17T08:48:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13338v2",
    "title": "SSD-TS: Exploring the Potential of Linear State Space Models for Diffusion Models in Time Series Imputation",
    "authors": [
      "Hongfan Gao",
      "Wangmeng Shen",
      "Xiangfei Qiu",
      "Ronghui Xu",
      "Jilin Hu",
      "Bin Yang"
    ],
    "abstract": "Probabilistic time series imputation has been widely applied in real-world\nscenarios due to its ability for uncertainty estimation and denoising diffusion\nprobabilistic models~(DDPMs) have achieved great success in probabilistic time\nseries imputation tasks with its power to model complex distributions. However,\ncurrent DDPM-based probabilistic time series imputation methodologies are\nconfronted with two types of challenges: 1)\\textit{The backbone modules of the\ndenoising parts are not capable of achieving sequence modeling with low time\ncomplexity.} 2)~\\textit{The architecture of denoising modules can not handle\nthe dependencies in the time series data effectively.} To address the first\nchallenge, we explore the potential of state space model, namely Mamba, as the\nbackbone denoising module for DDPMs. To tackle the second challenge, we\ncarefully devise several SSM-based blocks for time series data modeling.\nExperimental results demonstrate that our approach can achieve state-of-the-art\ntime series imputation results on multiple real-world datasets. Our datasets\nand code are available at\n\\href{https://github.com/decisionintelligence/SSD-TS/}{https://github.com/decisionintelligence/SSD-TS/}",
    "pdf_url": "http://arxiv.org/pdf/2410.13338v2",
    "published": "2024-10-17T08:48:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14741v1",
    "title": "CAKD: A Correlation-Aware Knowledge Distillation Framework Based on Decoupling Kullback-Leibler Divergence",
    "authors": [
      "Zao Zhang",
      "Huaming Chen",
      "Pei Ning",
      "Nan Yang",
      "Dong Yuan"
    ],
    "abstract": "In knowledge distillation, a primary focus has been on transforming and\nbalancing multiple distillation components. In this work, we emphasize the\nimportance of thoroughly examining each distillation component, as we observe\nthat not all elements are equally crucial. From this perspective,we decouple\nthe Kullback-Leibler (KL) divergence into three unique elements: Binary\nClassification Divergence (BCD), Strong Correlation Divergence (SCD), and Weak\nCorrelation Divergence (WCD). Each of these elements presents varying degrees\nof influence. Leveraging these insights, we present the Correlation-Aware\nKnowledge Distillation (CAKD) framework. CAKD is designed to prioritize the\nfacets of the distillation components that have the most substantial influence\non predictions, thereby optimizing knowledge transfer from teacher to student\nmodels. Our experiments demonstrate that adjusting the effect of each element\nenhances the effectiveness of knowledge transformation. Furthermore, evidence\nshows that our novel CAKD framework consistently outperforms the baseline\nacross diverse models and datasets. Our work further highlights the importance\nand effectiveness of closely examining the impact of different parts of\ndistillation process.",
    "pdf_url": "http://arxiv.org/pdf/2410.14741v1",
    "published": "2024-10-17T08:48:20+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13337v1",
    "title": "On Quantum Programming Languages",
    "authors": [
      "Benoît Valiron"
    ],
    "abstract": "This thesis (Habilitation \\`a diriger des recherches) presents some of my\nresearch contributions since my Ph.D defense in 2008. I have had the chance to\nparticipate in the development of quantum programming languages since their\nearly developments: the presentation aims to present my point of view on the\nevolution of the subject, my contributions, and the current research trends in\nthe community. The target audience is a graduate student interested in pointers\nto the field of quantum programming languages.",
    "pdf_url": "http://arxiv.org/pdf/2410.13337v1",
    "published": "2024-10-17T08:48:10+00:00",
    "categories": [
      "cs.LO",
      "cs.PL"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13336v1",
    "title": "On the Sensing Performance of OFDM-based ISAC under the Influence of Oscillator Phase Noise",
    "authors": [
      "Lucas Giroto de Oliveira",
      "Yueheng Li",
      "Benedikt Geiger",
      "Laurent Schmalen",
      "Thomas Zwick",
      "Benjamin Nuss"
    ],
    "abstract": "Integrated sensing and communication (ISAC) is a novel capability expected\nfor sixth generation (6G) cellular networks. To that end, several challenges\nmust be addressed to enable both mono- and bistatic sensing in existing\ndeployments. A common impairment in both architectures is oscillator phase\nnoise (PN), which not only degrades communication performance, but also\nseverely impairs radar sensing. To enable a broader understanding of\northogonal-frequency division multiplexing (OFDM)-based sensing impaired by PN,\nthis article presents an analysis of sensing peformance in OFDM-based ISAC for\ndifferent waveform parameter choices and settings in both mono- and bistatic\narchitectures. In this context, the distortion of the adopted digital\nconstellation modulation is analyzed and the resulting PN-induced effects in\nrange-Doppler radar images are investigated both without and with PN\ncompensation. These effects include peak power loss of target reflections and\nhigher sidelobe levels, especially in the Doppler shift direction. In the\nconducted analysis, these effects are measured by the peak power loss ratio,\npeak-to-sidelobe level ratio, and integrated sidelobe level ratio parameters,\nthe two latter being evaluated in both range and Doppler shift directions. In\naddition, the signal-to-interference ratio is analyzed to allow not only\nquantifying the distortion of a target reflection, but also measuring the\ninterference floor level in a radar image. The achieved results allow to\nquantify not only the PN-induced impairments to a single target, but also how\nthe induced degradation may impair the sensing performance of OFDM-based ISAC\nsystems in multi-target scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2410.13336v1",
    "published": "2024-10-17T08:47:54+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13335v1",
    "title": "Asymptotic behaviour of the heat equation in an exterior domain with general boundary conditions II. The case of bounded and of $L^{p}$ data",
    "authors": [
      "Joaquín Domínguez-de-Tena",
      "Aníbal Rodríguez-Bernal"
    ],
    "abstract": "In this work, we study the asymptotic behaviour of solutions to the heat\nequation in exterior domains, i.e., domains which are the complement of a\nsmooth compact set in $\\mathbb{R}^N$. Different homogeneous boundary conditions\nare considered, including Dirichlet, Robin, and Neumann ones. In this second\npart of our work, we consider the case of bounded initial data and prove that,\nafter some correction term, the solutions become close to the solutions in the\nwhole space and show how complex behaviours appear. We also analyse the case of\ninitial data in $L^p$ with $1<p<\\infty$ where all solutions essentially decay\nto $0$ and the convergence rate could be arbitrarily slow.",
    "pdf_url": "http://arxiv.org/pdf/2410.13335v1",
    "published": "2024-10-17T08:47:50+00:00",
    "categories": [
      "math.AP",
      "35K05, 35B40, 35B30, 35E15"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13334v3",
    "title": "BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in Large Language Models",
    "authors": [
      "Isack Lee",
      "Haebin Seong"
    ],
    "abstract": "Although large language models (LLMs) demonstrate impressive proficiency in\nvarious tasks, they present potential safety risks, such as `jailbreaks', where\nmalicious inputs can coerce LLMs into generating harmful content bypassing\nsafety alignments. In this paper, we delve into the ethical biases in LLMs and\nexamine how those biases could be exploited for jailbreaks. Notably, these\nbiases result in a jailbreaking success rate in GPT-4o models that differs by\n20\\% between non-binary and cisgender keywords and by 16\\% between white and\nblack keywords, even when the other parts of the prompts are identical. We\nintroduce the concept of BiasJailbreak, highlighting the inherent risks posed\nby these safety-induced biases. BiasJailbreak generates biased keywords\nautomatically by asking the target LLM itself, and utilizes the keywords to\ngenerate harmful output. Additionally, we propose an efficient defense method\nBiasDefense, which prevents jailbreak attempts by injecting defense prompts\nprior to generation. BiasDefense stands as an appealing alternative to Guard\nModels, such as Llama-Guard, that require additional inference cost after text\ngeneration. Our findings emphasize that ethical biases in LLMs can actually\nlead to generating unsafe output, and suggest a method to make the LLMs more\nsecure and unbiased. To enable further research and improvements, we\nopen-source our code and artifacts of BiasJailbreak, providing the community\nwith tools to better understand and mitigate safety-induced biases in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13334v3",
    "published": "2024-10-17T08:46:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13333v3",
    "title": "Malleus: Straggler-Resilient Hybrid Parallel Training of Large-scale Models via Malleable Data and Model Parallelization",
    "authors": [
      "Haoyang Li",
      "Fangcheng Fu",
      "Hao Ge",
      "Sheng Lin",
      "Xuanyu Wang",
      "Jiawen Niu",
      "Yujie Wang",
      "Hailin Zhang",
      "Xiaonan Nie",
      "Bin Cui"
    ],
    "abstract": "As the scale of models and training data continues to grow, there is an\nexpanding reliance on more GPUs to train large-scale models, which inevitably\nincreases the likelihood of encountering dynamic stragglers that some devices\nlag behind in performance occasionally. However, hybrid parallel training, one\nof the de facto paradigms to train large models, is typically sensitive to the\nstragglers.\n  This paper presents Malleus, a straggler-resilient hybrid parallel training\nframework for large-scale models. Malleus quantifies the stragglers at the\nnuanced, per-GPU granularity during training, and develops a novel planning\nalgorithm to deduce the optimal parallelization of GPU devices, pipeline\nstages, model layers, and training data, maximizing training efficiency when\nstragglers exist. In addition, once a shift in the straggler situation is\ndetected, Malleus adaptively adjusts the parallelization via a re-planning\nprocess, and seamlessly and efficiently migrates the model states on the fly,\nwithout sacrificing the stability of the training tasks. Empirical results on\nlarge language models with up to 110B parameters show that Malleus consistently\noutperforms existing parallel training frameworks under various straggler\nsituations, delivering on average 2.63-5.28 times of efficiency improvement.",
    "pdf_url": "http://arxiv.org/pdf/2410.13333v3",
    "published": "2024-10-17T08:45:15+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13332v1",
    "title": "Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification",
    "authors": [
      "Zeren Shui",
      "Petros Karypis",
      "Daniel S. Karls",
      "Mingjian Wen",
      "Saurav Manchanda",
      "Ellad B. Tadmor",
      "George Karypis"
    ],
    "abstract": "Citation intention Classification (CIC) tools classify citations by their\nintention (e.g., background, motivation) and assist readers in evaluating the\ncontribution of scientific literature. Prior research has shown that pretrained\nlanguage models (PLMs) such as SciBERT can achieve state-of-the-art performance\non CIC benchmarks. PLMs are trained via self-supervision tasks on a large\ncorpus of general text and can quickly adapt to CIC tasks via moderate\nfine-tuning on the corresponding dataset. Despite their advantages, PLMs can\neasily overfit small datasets during fine-tuning. In this paper, we propose a\nmulti-task learning (MTL) framework that jointly fine-tunes PLMs on a dataset\nof primary interest together with multiple auxiliary CIC datasets to take\nadvantage of additional supervision signals. We develop a data-driven task\nrelation learning (TRL) method that controls the contribution of auxiliary\ndatasets to avoid negative transfer and expensive hyper-parameter tuning. We\nconduct experiments on three CIC datasets and show that fine-tuning with\nadditional datasets can improve the PLMs' generalization performance on the\nprimary dataset. PLMs fine-tuned with our proposed framework outperform the\ncurrent state-of-the-art models by 7% to 11% on small datasets while aligning\nwith the best-performing model on a large dataset.",
    "pdf_url": "http://arxiv.org/pdf/2410.13332v1",
    "published": "2024-10-17T08:45:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13331v1",
    "title": "Improving Discrete Optimisation Via Decoupled Straight-Through Gumbel-Softmax",
    "authors": [
      "Rushi Shah",
      "Mingyuan Yan",
      "Michael Curtis Mozer",
      "Dianbo Liu"
    ],
    "abstract": "Discrete representations play a crucial role in many deep learning\narchitectures, yet their non-differentiable nature poses significant challenges\nfor gradient-based optimization. To address this issue, various gradient\nestimators have been developed, including the Straight-Through Gumbel-Softmax\n(ST-GS) estimator, which combines the Straight-Through Estimator (STE) and the\nGumbel-based reparameterization trick. However, the performance of ST-GS is\nhighly sensitive to temperature, with its selection often compromising gradient\nfidelity. In this work, we propose a simple yet effective extension to ST-GS by\nemploying decoupled temperatures for forward and backward passes, which we\nrefer to as \"Decoupled ST-GS\". We show that our approach significantly enhances\nthe original ST-GS through extensive experiments across multiple tasks and\ndatasets. We further investigate the impact of our method on gradient fidelity\nfrom multiple perspectives, including the gradient gap and the bias-variance\ntrade-off of estimated gradients. Our findings contribute to the ongoing effort\nto improve discrete optimization in deep learning, offering a practical\nsolution that balances simplicity and effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2410.13331v1",
    "published": "2024-10-17T08:44:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13330v1",
    "title": "Assessing the techno-economic benefits of LEMs for different grid topologies and prosumer shares",
    "authors": [
      "Markus Doepfert",
      "Soner Candas",
      "Hermann Kraus",
      "Peter Tzscheutschler",
      "Thomas Hamacher"
    ],
    "abstract": "The shift towards decentralized and renewable energy sources has introduced\nsignificant challenges to traditional power systems, necessitating innovative\nmarket designs. Local energy markets present a viable solution for integrating\ndistributed energy resources such as photovoltaic systems, electric vehicles,\nand heat pumps within various grid topologies. This study investigates the\ntechno-economic benefits of local energy markets compared to conventional\nmarket designs, focusing on their impact on average energy prices and\noperational peak power, using a self-developed agent-based energy system\nsimulation tool. Through comprehensive simulations across the countryside,\nrural, suburban, and urban grid topologies with varying penetration levels of\nthe distributed energy resources, totaling 400 simulation setups, we\ndemonstrate that local energy markets can enhance economic efficiency and grid\nstability with 99 % of the scenarios boasting lower average energy prices and\n80 % lower operational peak power levels. Our findings suggest that local\nenergy markets can play a role in the future energy system, especially in areas\nwith high shares of PV and HP, provided that additional infrastructure,\nmanagement costs, and bureaucratic complexity are kept to a minimum.",
    "pdf_url": "http://arxiv.org/pdf/2410.13330v1",
    "published": "2024-10-17T08:39:51+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13329v2",
    "title": "Scaling limits for a population model with growth, division and cross-diffusion",
    "authors": [
      "Marie Doumic",
      "Sophie Hecht",
      "Marc Hoffmann",
      "Diane Peurichard"
    ],
    "abstract": "Originally motivated by the morphogenesis of bacterial microcolonies, the aim\nof this article is to explore models through different scales for a spatial\npopulation of interacting, growing and dividing particles. We start from a\nmicroscopic stochastic model, write the corresponding stochastic differential\nequation satisfied by the empirical measure, and rigorously derive its\nmesoscopic (mean-field) limit. Under smoothness and symmetry assumptions for\nthe interaction kernel, we then obtain entropy estimates, which provide us with\na localization limit at the macroscopic level. Finally, we perform a thorough\nnumerical study in order to compare the three modeling scales.",
    "pdf_url": "http://arxiv.org/pdf/2410.13329v2",
    "published": "2024-10-17T08:39:06+00:00",
    "categories": [
      "math.AP",
      "math.PR"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13328v1",
    "title": "Enhancing 1-Second 3D SELD Performance with Filter Bank Analysis and SCConv Integration in CST-Former",
    "authors": [
      "Zhehui Zhang"
    ],
    "abstract": "Recent SELD research has predominantly focused on long-time segment scenarios\n(typically 5 to 10 seconds, occasionally 2 seconds), improving benchmark\nperformance but lacking the temporal granularity needed for real-world\napplications. To bridge this gap, this paper investigates SELD with distance\nestimation (3D SELD) systems under short-time segments, specifically targeting\na 1-second window, establishing a new baseline for practical 3D SELD\napplicability. We further explore the impact of different filter banks -- Bark,\nMel, and Gammatone for audio feature extraction, and experimental results\ndemonstrate that the Gammatone filter achieves the highest overall accuracy in\nthis context. Finally, we propose replacing the convolutional modules within\nthe CST-Former, a competitive SELD architecture, with the SCConv module. This\nadjustment yields measurable F-score gains in short-segment scenarios,\nunderscoring SCConv's potential to improve spatial and channel feature\nrepresentation. The experimental results highlight our approach as a\nsignificant step towards the real-world deployment of 3D SELD systems under\nlow-latency constraints.",
    "pdf_url": "http://arxiv.org/pdf/2410.13328v1",
    "published": "2024-10-17T08:38:36+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13327v1",
    "title": "Cryogenic Digital Image Correlation as a Probe of Strain in Iron-Based Superconductors",
    "authors": [
      "Ziye Mo",
      "Chunyi Li",
      "Wenting Zhang",
      "Chang Liu",
      "Yongxin Sun",
      "Ruixian Liu",
      "Xingye Lu"
    ],
    "abstract": "Uniaxial strain is a powerful tuning parameter that can control symmetry and\nanisotropic electronic properties in iron-based superconductors. However,\naccurately characterizing anisotropic strain can be challenging and complex.\nHere, we utilize a cryogenic optical system equipped with a\nhigh-spatial-resolution microscope to characterize surface strains in\niron-based superconductors using the digital image correlation method. Compared\nwith other methods such as high-resolution X-ray diffraction, strain gauge, and\ncapacitive sensor, digital image correlation offers a non-contact, full-field\nmeasurement approach, acting as an optical virtual strain gauge that provides\nhigh spatial resolution. The results measured on detwinned {\\BFA} are\nquantitatively consistent with the distortion measured by X-ray diffraction and\nneutron Larmor diffraction. These findings highlight the potential of cryogenic\ndigital image correlation as an effective and accessible tool for probing the\nisotropic and anisotropic strains, facilitating the application of uniaxial\nstrain tuning in the study of quantum materials.",
    "pdf_url": "http://arxiv.org/pdf/2410.13327v1",
    "published": "2024-10-17T08:37:57+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2410.13326v1",
    "title": "Comparing the Utility, Preference, and Performance of Course Material Search Functionality and Retrieval-Augmented Generation Large Language Model (RAG-LLM) AI Chatbots in Information-Seeking Tasks",
    "authors": [
      "Leonardo Pasquarelli",
      "Charles Koutcheme",
      "Arto Hellas"
    ],
    "abstract": "Providing sufficient support for students requires substantial resources,\nespecially considering the growing enrollment numbers. Students need help in a\nvariety of tasks, ranging from information-seeking to requiring support with\ncourse assignments. To explore the utility of recent large language models\n(LLMs) as a support mechanism, we developed an LLM-powered AI chatbot that\naugments the answers that are produced with information from the course\nmaterials. To study the effect of the LLM-powered AI chatbot, we conducted a\nlab-based user study (N=14), in which the participants worked on tasks from a\nweb software development course. The participants were divided into two groups,\nwhere one of the groups first had access to the chatbot and then to a more\ntraditional search functionality, while another group started with the search\nfunctionality and was then given the chatbot. We assessed the participants'\nperformance and perceptions towards the chatbot and the search functionality\nand explored their preferences towards the support functionalities. Our\nfindings highlight that both support mechanisms are seen as useful and that\nsupport mechanisms work well for specific tasks, while less so for other tasks.\nWe also observe that students tended to prefer the second support mechanism\nmore, where students who were first given the chatbot tended to prefer the\nsearch functionality and vice versa.",
    "pdf_url": "http://arxiv.org/pdf/2410.13326v1",
    "published": "2024-10-17T08:37:25+00:00",
    "categories": [
      "cs.CY",
      "cs.IR",
      "K.3; H.3.3"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.14740v2",
    "title": "Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching",
    "authors": [
      "Jie Peng",
      "Zhang Cao",
      "Huaizhi Qu",
      "Zhengyu Zhang",
      "Chang Guo",
      "Yanyong Zhang",
      "Zhichao Cao",
      "Tianlong Chen"
    ],
    "abstract": "Although Large Language Models (LLMs) have demonstrated remarkable\ncapabilities, their massive parameter counts and associated extensive computing\nmake LLMs' deployment the main part of carbon emission from nowadays AI\napplications. Compared to modern GPUs like H$100$, it would be significantly\ncarbon-sustainable if we could leverage old-fashioned GPUs such as M$40$ (as\nshown in Figure 1, M$40$ only has one third carbon emission of H$100$'s) for\nLLM servings. However, the limited High Bandwidth Memory (HBM) available on\nsuch GPU often cannot support the loading of LLMs due to the gigantic model\nsize and intermediate activation data, making their serving challenging. For\ninstance, a LLaMA2 model with $70$B parameters typically requires $128$GB for\ninference, which substantially surpasses $24$GB HBM in a $3090$ GPU and remains\ninfeasible even considering the additional $64$GB DRAM. To address this\nchallenge, this paper proposes a mixed-precision with a model modularization\nalgorithm to enable LLM inference on outdated hardware with resource\nconstraints. (The precision denotes the numerical precision like FP16, INT8,\nINT4) and multi-level caching (M2Cache).)\n  Specifically, our M2Cache first modulizes neurons in LLM and creates their\nimportance ranking. Then, it adopts a dynamic sparse mixed-precision\nquantization mechanism in weight space to reduce computational demands and\ncommunication overhead at each decoding step. It collectively lowers the\noperational carbon emissions associated with LLM inference. Moreover, M2Cache\nintroduces a three-level cache management system with HBM, DRAM, and SSDs that\ncomplements the dynamic sparse mixed-precision inference. To enhance\ncommunication efficiency, M2Cache maintains a neuron-level mixed-precision LRU\ncache in HBM, a larger layer-aware cache in DRAM, and a full model in SSD.",
    "pdf_url": "http://arxiv.org/pdf/2410.14740v2",
    "published": "2024-10-17T08:33:39+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13325v1",
    "title": "Inner ear morphology in wild versus laboratory house mice",
    "authors": [
      "Sabrina Renaud",
      "Léa Amar",
      "Pascale Chevret",
      "Caroline Romestaing",
      "Jean-Pierre Quéré",
      "Corinne Régis",
      "Renaud Lebrun"
    ],
    "abstract": "The semicircular canals of the inner ear are involved in balance and velocity\ncontrol. Being crucial to ensure efficient mobility, their morphology exhibits\nan evolutionary conservatism attributed to stabilizing selection. Release of\nselection in slow-moving animals has been argued to lead to morphological\ndivergence and increased inter-individual variation. In its natural habitat,\nthe house mouse Mus musculus moves in a tridimensional space where efficient\nbalance is required. In contrast, laboratory mice in standard cages are\nseverely restricted in their ability to move, which possibly reduces selection\non the inner ear morphology. This effect was tested by comparing four groups of\nmice: several populations of wild mice trapped in commensal habitats in France;\ntheir second-generation laboratory offspring, to assess plastic effects related\nto breeding conditions; a standard laboratory strain (Swiss) that evolved for\nmany generations in a regime of mobility reduction; and hybrids between wild\noffspring and Swiss mice. The morphology of the semicircular canals was\nquantified using a set of 3D landmarks and semi-landmarks analyzed using\ngeometric morphometric protocols. Levels of inter-population, inter-individual\n(disparity) and intra-individual (asymmetry) variation were compared. All wild\nmice shared a similar inner ear morphology, in contrast to the important\ndivergence of the Swiss strain. The release of selection in the laboratory\nstrain obviously allowed for an important and rapid drift in the otherwise\nconserved structure. Shared traits between the inner ear of the lab strain and\ndomestic pigs suggested a common response to mobility reduction in captivity.\nThe lab-bred offspring of wild mice also differed from their wild relatives,\nsuggesting plastic response related to maternal locomotory behavior, since\ninner ear morphology matures before birth in mammals. The signature observed in\nlab-bred wild mice and the lab strain was however not congruent, suggesting\nthat plasticity did not participate to the divergence of the laboratory strain.\nHowever, contrary to the expectation, wild mice displayed slightly higher\nlevels of inter-individual variation than laboratory mice, possibly due to the\nhigher levels of genetic variance within and among wild populations compared to\nthe lab strain. Differences in fluctuating asymmetry levels were detected, with\nthe laboratory strain occasionally displaying higher asymmetry scores than its\nwild relatives. This suggests that there may indeed be a release of selection\nand/or a decrease in developmental stability in the laboratory strain.",
    "pdf_url": "http://arxiv.org/pdf/2410.13325v1",
    "published": "2024-10-17T08:32:03+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13324v1",
    "title": "Investigation of the anatase-to-rutile transition for TiO$_2$ sol-gel coatings with refractive index up to 2.7",
    "authors": [
      "Martin O'Byrne",
      "Badre Kerzabi",
      "Marco Abbarchi",
      "Alejo Lifschitz",
      "Tony Zamora",
      "Victor Malgras",
      "Anthony Gourdin",
      "Mehrnaz Modaresialam",
      "David Grosso",
      "Magali Putero"
    ],
    "abstract": "This work describes the elaboration of rutile titanium dioxide films with\nhigh refractive indices and low scattering by sol-gel process and controlled\ncrystallization. The evolutions of the optical properties and crystalline\nstructure of sol-gel processed titania coatings on fused silica were\ninvestigated for different thermal budgets of the annealing post-treatment\nusing ellipsometry, spectrophotometry, X-ray diffraction and electronic\nmicroscopy. It reveals that anatase and rutile coatings with refractive indices\nof 2.5 and 2.7 can be prepared with associated optical loss of 0.5% and 1%,\nrespectively, which are excellent compromise for applications in integrated\nphotonics. These evolutions are associated to the thermally induced mass\ntransfer and phase transitions occurring during thermal annealing that involves\nfirst the nucleation growth and sintering of anatase polyoriented nanocrystals,\nfollowed by the transformation into rutile polyoriented nanocrystals.\nConcomitantly, rutile crystals with (110) faces parallel to the surface consume\nsurrounding anatase and rutile nanocrystals by diffusive sintering to yield\nmicron-size rutile monocrystalline and monooriented platelets patchwork,\nexhibiting refractive index of 2.73 and 1.2% optical loss. The formation of\nthese platelets is governed by surface energies and is responsible for the\nincrease in optical loss.",
    "pdf_url": "http://arxiv.org/pdf/2410.13324v1",
    "published": "2024-10-17T08:30:58+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13323v1",
    "title": "A Critical Review of Proton Exchange Membrane Fuel Cells Matter Transports and Voltage Polarisation for Modelling",
    "authors": [
      "Raphaël Gass",
      "Zhongliang Li",
      "Rachid Outbib",
      "Samir Jemei",
      "Daniel Hissel"
    ],
    "abstract": "Technologies based on the use of hydrogen are promising for future energy\nrequirements in a more sustainable world. Consequently, modelling fuel cells is\ncrucial, for instance, to optimize their control to achieve excellent\nperformance, to test new materials and configurations on a limited budget, or\nto consider their degradation for improved lifespan. To develop such models, a\ncomprehensive study is required, encompassing both well-established and the\nlatest governing laws on matter transport and voltage polarisation for Proton\nExchange Membrane Fuel Cells (PEMFCs). Recent articles often rely on outdated\nor inappropriate equations, lacking clear explanations regarding their\nbackground. Indeed, inconsistent understanding of theoretical and experimental\nchoices or model requirements hinders comprehension and contributes to the\nmisuse of these equations. Additionally, specific researches are needed to\nconstruct more accurate models. This study aims to offer a comprehensive\nunderstanding of the current state-of-the-art in PEMFC modeling. It clarifies\nthe corresponding governing equations, their usage conditions, and assumptions,\nthus serving as a foundation for future developments. The presented laws and\nequations are applicable in most multi-dimensional, dynamic, and two-phase\nPEMFC models.",
    "pdf_url": "http://arxiv.org/pdf/2410.13323v1",
    "published": "2024-10-17T08:27:56+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13322v2",
    "title": "Arc-Length-Based Warping for Robot Skill Synthesis from Multiple Demonstrations",
    "authors": [
      "Giovanni Braglia",
      "Davide Tebaldi",
      "André Eugenio Lazzaretti",
      "Luigi Biagiotti"
    ],
    "abstract": "In robotics, Learning from Demonstration (LfD) aims to transfer skills to\nrobots by using multiple demonstrations of the same task. These demonstrations\nare recorded and processed to extract a consistent skill representation. This\nprocess typically requires temporal alignment through techniques such as\nDynamic Time Warping (DTW). In this paper, we consider a novel algorithm, named\nSpatial Sampling (SS), specifically designed for robot trajectories, that\nenables time-independent alignment of the trajectories by providing an\narc-length parametrization of the signals. This approach eliminates the need\nfor temporal alignment, enhancing the accuracy and robustness of skill\nrepresentation, especially when recorded movements are subject to intermittent\nmotions or extremely variable speeds, a common characteristic of operations\nbased on kinesthetic teaching, where the operator may encounter difficulties in\nguiding the end-effector smoothly. To prove this, we built a custom publicly\navailable dataset of robot recordings to test real-world movements, where the\nuser tracks the same geometric path multiple times, with motion laws that vary\ngreatly and are subject to starting and stopping. The SS demonstrates better\nperformances against state-of-the-art algorithms in terms of (i) trajectory\nsynchronization and (ii) quality of the extracted skill.",
    "pdf_url": "http://arxiv.org/pdf/2410.13322v2",
    "published": "2024-10-17T08:25:44+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13321v3",
    "title": "Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding",
    "authors": [
      "Kyungmin Min",
      "Minbeom Kim",
      "Kang-il Lee",
      "Dongryeol Lee",
      "Kyomin Jung"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) demonstrate impressive capabilities in\ngenerating detailed and coherent responses from visual inputs. However, they\nare prone to generate hallucinations due to an over-reliance on language\npriors. To address this issue, we investigate the language priors in LVLMs and\nmake two key observations: (1) Even when predicting the tokens associated with\nimage-related part-of-speech (POS), models increasingly rely on linguistic\npriors as the token sequences grow, thereby amplifying hallucinations. (2)\nMethods that directly calibrate LVLM's output distribution to mitigate language\npriors can lead to a degradation in text quality or even exacerbate\nhallucinations. Based on these findings, we propose a novel method,\nSummary-Guided Decoding (SumGD). This method naturally encourages the model to\nfocus more on image information by reducing the text context through summaries,\nwhile controlling only the image-related POS tokens to maintain text quality.\nThrough experiments, we demonstrate that SumGD achieves state-of-the-art\nperformance on object hallucination benchmarks. Furthermore, in terms of the\ntrade-off between precision and recall, SumGD achieves Pareto optimality among\nthe existing methods. Lastly, we observe that although existing methods\nstruggle to balance the reduction of object hallucinations with maintaining\ntext quality, SumGD demonstrates robustness in handling this challenge.",
    "pdf_url": "http://arxiv.org/pdf/2410.13321v3",
    "published": "2024-10-17T08:24:27+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13320v1",
    "title": "Inadequate contrast ratio of road markings as an indicator for ADAS failure",
    "authors": [
      "Novel Certad",
      "Cristina Olaverri-Monreal",
      "Friedrich Wiesinger",
      "Tomasz E. Burghardt"
    ],
    "abstract": "Road markings were reported as critical road safety features, equally needed\nfor both human drivers and for machine vision technologies utilised by advanced\ndriver assistance systems (ADAS) and in driving automation. Visibility of road\nmarkings is achieved because of their colour contrasting with the roadway\nsurface. During recent testing of an open-source camera-based ADAS under\nseveral visibility conditions (day, night, rain, glare), significant failures\nin trajectory planning were recorded and quantified. Consistently, better ADAS\nreliability under poor visibility conditions was achieved with Type II road\nmarkings (i.e. structured markings, facilitating moisture drainage) as compared\nto Type I road marking (i.e. flat lines). To further understand these failures,\nanalysis of contrast ratio of road markings, which the tested ADAS was\ndetecting for traffic lane recognition, was performed. The highest contrast\nratio (greater than 0.5, calculated per Michelson equation) was measured at\nnight in the absence of confounding factors, with statistically significant\ndifference of 0.1 in favour of Type II road markings over Type I. Under\ndaylight conditions, contrast ratio was reduced, with slightly higher values\nmeasured with Type I. The presence of rain or wet roads caused the\ndeterioration of the contrast ratio, with Type II road markings exhibiting\nsignificantly higher contrast ratio than Type I, even though the values were\nlow (less than 0.1). These findings matched the output of the ADAS related to\ntraffic lane detection and underlined the importance of road marking\nvisibility. Inadequate lane recognition by ADAS was associated with very low\ncontrast ratio of road markings indeed. Importantly, specific minimum contrast\nratio value could not be found, which was due to the complexity of ADAS\nalgorithms...",
    "pdf_url": "http://arxiv.org/pdf/2410.13320v1",
    "published": "2024-10-17T08:23:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13319v2",
    "title": "Evolution of pairing symmetry in FeSe$_{1-x}$S$_x$ as probed by uniaxial-strain tuning of $T_c$",
    "authors": [
      "Ruixian Liu",
      "Qi Tang",
      "Chang Liu",
      "Chunyi Li",
      "Kaijuan Zhou",
      "Qiaoyu Wang",
      "Xingye Lu"
    ],
    "abstract": "In iron-based superconductors (FeSCs), the interplay between electronic\nnematicity and superconductivity is essential for understanding the exotic\nsuperconducting ground state. In the nematic regime, uniaxial-strain\n($\\varepsilon$) tuning of the superconducting transition temperature $T_c$\n[$\\Delta T_c(\\varepsilon)=\\alpha\\varepsilon+\\beta\\varepsilon^2$] offers a\nunique approach to investigating the evolution of pairing symmetry if both $s$\nand $d$ wave pairing instabilities are relevant. Here, we employ uniaxial\nstrain to tune the $T_c$ of FeSe$_{1-x}$S$_x$, in which both nematicity and\nsuperconductivity undergo significant changes with doping. While $T_c$ is\nusually suppressed quadratically with $\\varepsilon$ in optimally doped\nBaFe$_2$As$_2$, $\\Delta T_c(\\varepsilon)$ in FeSe$_{1-x}$S$_x$ dominated by\n$\\Delta T_c(\\varepsilon)=\\beta\\varepsilon^2$ changes its sign from $\\beta$ <\n$0$ in FeSe to $\\beta$ > $0$ in FeSe$_{1-x}$S$_x$ ($x\\gtrsim0.10$), indicating\nan evolution of the pairing symmetry from an $s_{\\pm}$ state towards an $s+d$\nwave state. These findings highlight the $\\Delta T_c(\\varepsilon)$ as a\npowerful probe for elucidating the superconducting pairing symmetry in the\nnematic regime of FeSCs and provide new insights into the evolution of pairing\nsymmetry in FeSCs.",
    "pdf_url": "http://arxiv.org/pdf/2410.13319v2",
    "published": "2024-10-17T08:22:18+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2410.13318v1",
    "title": "Computational Approaches to Arabic-English Code-Switching",
    "authors": [
      "Caroline Sabty"
    ],
    "abstract": "Natural Language Processing (NLP) is a vital computational method for\naddressing language processing, analysis, and generation. NLP tasks form the\ncore of many daily applications, from automatic text correction to speech\nrecognition. While significant research has focused on NLP tasks for the\nEnglish language, less attention has been given to Modern Standard Arabic and\nDialectal Arabic. Globalization has also contributed to the rise of\nCode-Switching (CS), where speakers mix languages within conversations and even\nwithin individual words (intra-word CS). This is especially common in Arab\ncountries, where people often switch between dialects or between dialects and a\nforeign language they master. CS between Arabic and English is frequent in\nEgypt, especially on social media. Consequently, a significant amount of\ncode-switched content can be found online. Such code-switched data needs to be\ninvestigated and analyzed for several NLP tasks to tackle the challenges of\nthis multilingual phenomenon and Arabic language challenges. No work has been\ndone before for several integral NLP tasks on Arabic-English CS data. In this\nwork, we focus on the Named Entity Recognition (NER) task and other tasks that\nhelp propose a solution for the NER task on CS data, e.g., Language\nIdentification. This work addresses this gap by proposing and applying\nstate-of-the-art techniques for Modern Standard Arabic and Arabic-English NER.\nWe have created the first annotated CS Arabic-English corpus for the NER task.\nAlso, we apply two enhancement techniques to improve the NER tagger on CS data\nusing CS contextual embeddings and data augmentation techniques. All methods\nshowed improvements in the performance of the NER taggers on CS data. Finally,\nwe propose several intra-word language identification approaches to determine\nthe language type of a mixed text and identify whether it is a named entity or\nnot.",
    "pdf_url": "http://arxiv.org/pdf/2410.13318v1",
    "published": "2024-10-17T08:20:29+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13317v1",
    "title": "Elementary theory of earthquake source relaxation",
    "authors": [
      "A. V. Guglielmi"
    ],
    "abstract": "The elementary theory of relaxation of the source cooling down after the main\nshock of an earthquake is presented axiomatically. The names of the objects\nunder study are given and the relationships between them are determined. A new\nbasic concept of earthquake source deactivation is introduced and a procedure\nfor calculating the deactivation coefficient from aftershock frequency\nmeasurement data is indicated. An important property of the system is that the\naxioms do not contain statements regarding the actual process of source\nrelaxation. From two simple axioms a number of meaningful statements (theorems)\nlogically follow. A two-stage mode of source relaxation was discovered. The\nsharp transition between stages has the character of a bifurcation. It is shown\nthat the classical Omori law has limited applicability. It describes the\nevolution of aftershocks only at the first stage of relaxation. The well-known\nHirano-Utsu law is not applicable to describe aftershocks either at the first\nor second stages of relaxation. The conclusions of the elementary theory allow\nfor interesting generalizations that expand the possibilities of experimental\nand theoretical study of the source. Keywords: earthquake source, foreshocks,\nmain shock, aftershocks, source state, deactivation coefficient, bifurcation,\nOmori's law, Hirano-Utsu's law.",
    "pdf_url": "http://arxiv.org/pdf/2410.13317v1",
    "published": "2024-10-17T08:18:45+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.00007v1",
    "title": "LARS: Light Augmented Reality System for Swarm",
    "authors": [
      "Mohsen Raoufi",
      "Pawel Romanczuk",
      "Heiko Hamann"
    ],
    "abstract": "We present the Light Augmented Reality System LARS as an open-source and\ncost-effective tool. LARS leverages light-projected visual scenes for indirect\nrobot-robot and human-robot interaction through the real environment. It\noperates in real-time and is compatible with a range of robotic platforms, from\nminiature to middle-sized robots. LARS can support researchers in conducting\nexperiments with increased freedom, reliability, and reproducibility. This XR\ntool makes it possible to enrich the environment with full control by adding\ncomplex and dynamic objects while keeping the properties of robots as realistic\nas they are.",
    "pdf_url": "http://arxiv.org/pdf/2411.00007v1",
    "published": "2024-10-17T08:17:27+00:00",
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13316v2",
    "title": "Linear independence of field equations in the Brans-Dicke theory",
    "authors": [
      "E. Ahmadi-Azar",
      "K. Atazadeh",
      "A. Eghbali"
    ],
    "abstract": "In solving the Brans-Dicke (BD) equations in the BD theory of gravity, their\nlinear independence is important. This is due to fact that in solving these\nequations in cosmology, if the number of unknown quantities is equal to the\nnumber of independent equations, then the unknowns can be uniquely determined.\nIn the BD theory, the tensor field $g_{\\mu \\nu}$ and the BD scalar field\n$\\varphi$ are not two separate fields, but they are coupled together. The\nreason behind this is a corollary that proposed by V. B. Johri and D. Kalyani\nin cosmology, which states that the cosmic scale factor of the universe, $a$,\nand the BD scalar field $\\varphi$ are related by a power law. Therefore, when\nthe principle of least action is used to derive the BD equations, the\nvariations $\\delta g^{\\mu \\nu}$ and $\\delta \\varphi$ should not be considered\nas two independent dynamical variables. So, there is a constraint on $\\delta\ng^{\\mu \\nu}$ and $\\delta \\varphi$ that causes the number of independent BD\nequations to decrease by one unit, in such a way that in the equations that\nhave been known as BD equations, one of them is redundant. In this paper, we\nprove this issue, that is, we show that one of these equations, which we choose\nas the modified Klein-Gordon equation, is not an independent equation, but a\nresult establishing other BD equations, the law of conservation of\nenergy-momentum of matter and Bianchi's identity. Therefore, we should not look\nat the modified Klein-Gordon equation as an independent field equation in the\nBD theory, but rather it is included in the other BD equations and should not\nbe mentioned separately as one of the BD equations once again.",
    "pdf_url": "http://arxiv.org/pdf/2410.13316v2",
    "published": "2024-10-17T08:15:46+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13315v2",
    "title": "Multiplicity of critical orbits to nonlinear, strongly indefinite functionals with sign-changing nonlinear part",
    "authors": [
      "Federico Bernini",
      "Bartosz Bieganowski",
      "Daniel Strzelecki"
    ],
    "abstract": "We show an abstract critical point theorem about existence of infinitely many\ncritical orbits to strongly indefinite functionals with sign-changing nonlinear\npart defined on a dislocation space with a discrete group action. We apply the\nabstract result to a Schr\\\"odinger equation $$ -\\Delta u + V(x) u = f(u) -\n\\lambda g(u) $$ with $0$ in the spectral gap of the Schr\\\"odinger operator\n$-\\Delta + V(x)$, that appears in nonlinear optics, as well as to the equations\nwith singular potentials arising from the study of cylindrically symmetric,\nelectromagnetic waves to the system of Maxwell equations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13315v2",
    "published": "2024-10-17T08:13:58+00:00",
    "categories": [
      "math.AP",
      "35Q55, 35A15, 35J20, 35Q60, 58E05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13314v1",
    "title": "Precipitation Nowcasting Using Diffusion Transformer with Causal Attention",
    "authors": [
      "ChaoRong Li",
      "XuDong Ling",
      "YiLan Xue",
      "Wenjie Luo",
      "LiHong Zhu",
      "FengQing Qin",
      "Yaodong Zhou",
      "Yuanyuan Huang"
    ],
    "abstract": "Short-term precipitation forecasting remains challenging due to the\ndifficulty in capturing long-term spatiotemporal dependencies. Current deep\nlearning methods fall short in establishing effective dependencies between\nconditions and forecast results, while also lacking interpretability. To\naddress this issue, we propose a Precipitation Nowcasting Using Diffusion\nTransformer with Causal Attention model. Our model leverages Transformer and\ncombines causal attention mechanisms to establish spatiotemporal queries\nbetween conditional information (causes) and forecast results (results). This\ndesign enables the model to effectively capture long-term dependencies,\nallowing forecast results to maintain strong causal relationships with input\nconditions over a wide range of time and space. We explore four variants of\nspatiotemporal information interactions for DTCA, demonstrating that global\nspatiotemporal labeling interactions yield the best performance. In addition,\nwe introduce a Channel-To-Batch shift operation to further enhance the model's\nability to represent complex rainfall dynamics. We conducted experiments on two\ndatasets. Compared to state-of-the-art U-Net-based methods, our approach\nimproved the CSI (Critical Success Index) for predicting heavy precipitation by\napproximately 15% and 8% respectively, achieving state-of-the-art performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13314v1",
    "published": "2024-10-17T08:10:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13313v1",
    "title": "Mitigating Biases to Embrace Diversity: A Comprehensive Annotation Benchmark for Toxic Language",
    "authors": [
      "Xinmeng Hou"
    ],
    "abstract": "This study introduces a prescriptive annotation benchmark grounded in\nhumanities research to ensure consistent, unbiased labeling of offensive\nlanguage, particularly for casual and non-mainstream language uses. We\ncontribute two newly annotated datasets that achieve higher inter-annotator\nagreement between human and language model (LLM) annotations compared to\noriginal datasets based on descriptive instructions. Our experiments show that\nLLMs can serve as effective alternatives when professional annotators are\nunavailable. Moreover, smaller models fine-tuned on multi-source LLM-annotated\ndata outperform models trained on larger, single-source human-annotated\ndatasets. These findings highlight the value of structured guidelines in\nreducing subjective variability, maintaining performance with limited data, and\nembracing language diversity.\n  Content Warning: This article only analyzes offensive language for academic\npurposes. Discretion is advised.",
    "pdf_url": "http://arxiv.org/pdf/2410.13313v1",
    "published": "2024-10-17T08:10:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13312v1",
    "title": "Windowed Compressed Spectrum Sensing with Block sparsity",
    "authors": [
      "Huiguang Zhang",
      "Baoguo Liu"
    ],
    "abstract": "Compressed Spectrum Sensing (CSS) is widely employed in spectral analysis due\nto its sampling efficiency. However, conventional CSS assumes a standard sparse\nspectrum, which is affected by Spectral Leakage (SL). Despite the widespread\nuse of CSS, the impact of SL on its performance has not been systematically and\nthoroughly investigated. This study addresses this research gap by analyzing\nthe Restricted Isometry Property (RIP) of windowed Gaussian measurement\nmatrices and proposing a novel block-sparse CSS model.\n  We introduce the Edge Zeroing Coefficient (EZC) to evaluate SL suppression\nand RIP impact, and the Window Scaling Coefficient (WSC) to quantify the effect\non RIP. Our research investigates the influence of Window Function (WF) on\nsignal sparsity and measurement matrices, and presents a block-sparse CSS model\nthat considers component frequency distribution, signal length, windowing, and\nnoise floor. Based on subspace counting theory, we derive sample bound for our\nmodel. The findings demonstrate that while WFs reduce SL, excessively small EZC\nand WSC values can negatively affect RIP quality and cause numerical\ninstability during signal reconstruction. This highlights the delicate balance\nrequired when applying WFs in CSS. Our block-sparse approach enables precise\ncompression and reconstruction, particularly for high noise floor and\nsuper-sparse signals. This study provides a framework for optimizing CSS\nperformance when dealing with SL and sparse signals, offering insights for\nimproving signal reconstruction quality in various applications",
    "pdf_url": "http://arxiv.org/pdf/2410.13312v1",
    "published": "2024-10-17T08:10:18+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13311v1",
    "title": "Enhancing Dataset Distillation via Label Inconsistency Elimination and Learning Pattern Refinement",
    "authors": [
      "Chuhao Zhou",
      "Chenxi Jiang",
      "Yi Xie",
      "Haozhi Cao",
      "Jianfei Yang"
    ],
    "abstract": "Dataset Distillation (DD) seeks to create a condensed dataset that, when used\nto train a model, enables the model to achieve performance similar to that of a\nmodel trained on the entire original dataset. It relieves the model training\nfrom processing massive data and thus reduces the computation resources,\nstorage, and time costs. This paper illustrates our solution that ranks 1st in\nthe ECCV-2024 Data Distillation Challenge (track 1). Our solution, Modified\nDifficulty-Aligned Trajectory Matching (M-DATM), introduces two key\nmodifications to the original state-of-the-art method DATM: (1) the soft labels\nlearned by DATM do not achieve one-to-one correspondence with the counterparts\ngenerated by the official evaluation script, so we remove the soft labels\ntechnique to alleviate such inconsistency; (2) since the removal of soft labels\nmakes it harder for the synthetic dataset to learn late trajectory information,\nparticularly on Tiny ImageNet, we reduce the matching range, allowing the\nsynthetic data to concentrate more on the easier patterns. In the final\nevaluation, our M-DATM achieved accuracies of 0.4061 and 0.1831 on the\nCIFAR-100 and Tiny ImageNet datasets, ranking 1st in the Fixed Images Per Class\n(IPC) Track.",
    "pdf_url": "http://arxiv.org/pdf/2410.13311v1",
    "published": "2024-10-17T08:09:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13310v1",
    "title": "Active inference and deep generative modeling for cognitive ultrasound",
    "authors": [
      "Ruud JG van Sloun"
    ],
    "abstract": "Ultrasound (US) has the unique potential to offer access to medical imaging\nto anyone, everywhere. Devices have become ultra-portable and cost-effective,\nakin to the stethoscope. Nevertheless US image quality and diagnostic efficacy\nare still highly operator- and patient-dependent. In difficult-to-image\npatients, image quality is often insufficient for reliable diagnosis. In this\npaper, we put forth that US imaging systems can be recast as\ninformation-seeking agents that engage in reciprocal interactions with their\nanatomical environment. Such agents autonomously adapt their transmit-receive\nsequences to fully personalize imaging and actively maximize information gain\nin-situ. To that end, we will show that the sequence of pulse-echo experiments\nthat a US system performs can be interpreted as a perception-action loop: the\naction is the data acquisition, probing tissue with acoustic waves and\nrecording reflections at the detection array, and perception is the inference\nof the anatomical and or functional state, potentially including associated\ndiagnostic quantities. We then equip systems with a mechanism to actively\nreduce uncertainty and maximize diagnostic value across a sequence of\nexperiments, treating action and perception jointly using Bayesian inference\ngiven generative models of the environment and action-conditional pulse-echo\nobservations. Since the representation capacity of the generative models\ndictates both the quality of inferred anatomical states and the effectiveness\nof inferred sequences of future imaging actions, we will be greatly leveraging\nthe enormous advances in deep generative modelling that are currently\ndisrupting many fields and society at large. Finally, we show some examples of\ncognitive, closed-loop, US systems that perform active beamsteering and\nadaptive scanline selection, based on deep generative models that track\nanatomical belief states.",
    "pdf_url": "http://arxiv.org/pdf/2410.13310v1",
    "published": "2024-10-17T08:09:14+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13309v1",
    "title": "Phase retrieval from short-time Fourier transform in LCA groups",
    "authors": [
      "Natalia Accomazzo",
      "Daniel Carando",
      "Rocio Nores",
      "Victoria Paternostro",
      "Sebastian Velazquez"
    ],
    "abstract": "We study the short-time Fourier transform phase retrieval problem in locally\ncompact abelian groups. Using probabilistic methods, we show that for a large\nclass of groups $G$ and compact subsets $K\\subseteq G$ there exists a window\nfunction and a uniformly separated set in $G\\times \\widehat{G}$ allowing phase\nretrieval in $L^2(K)$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13309v1",
    "published": "2024-10-17T08:09:00+00:00",
    "categories": [
      "math.CA",
      "43A70, 42C30, 94A20"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13308v1",
    "title": "Phase diagrams of a nonlinear magnetic charged rotating AdS black hole with a quintessence field",
    "authors": [
      "Hayat. Laassiri",
      "Ahmed. Daassou",
      "Rachid. Benbrik"
    ],
    "abstract": "In this paper, we investigate the phase transitions and critical behavior of\na nonlinear magnetically charged rotating AdS black hole, with a particular\nemphasis on the influence of a quintessence field. Our comprehensive\nthermodynamic analysis explores the impact of thermal fluctuations on the black\nhole's properties. We observe that for larger black holes, the corrected\nentropy remains positive, similar to the uncorrected case, which highlights the\nsignificant role of thermal fluctuations in modifying the entropy of smaller\nblack holes. Through a meticulous analysis of various thermodynamic properties,\nwe derive explicit analytical expressions for the critical points. Our findings\ndemonstrate that the quintessence field significantly affects phase\ntransitions, resulting in distinct critical phenomena. Notably, the black\nhole's phase transitions exhibit striking similarities to those observed in van\nder Waals fluids, offering deeper insights into the complex thermodynamic\nbehavior of these systems across different scales.",
    "pdf_url": "http://arxiv.org/pdf/2410.13308v1",
    "published": "2024-10-17T08:07:39+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13307v1",
    "title": "Curling morphology of knitted fabrics: Structure and Mechanics",
    "authors": [
      "Kotone Tajiri",
      "Riki Murakami",
      "Shunsuke Kobayashi",
      "Ryuichi Tarumi",
      "Tomohiko G. Sano"
    ],
    "abstract": "Knitted fabrics are two-dimensional-like structures formed by stitching\none-dimensional yarn into three-dimensional curves. Plain stitch or stockinette\nstitch, one of the most fundamental knitting stitches, consists of periodic\nlattices of bent yarns, where three-dimensional (3D) curling behavior naturally\nemerges at the edges. The elasticity and geometry of knitted fabrics have been\nstudied in previous studies, primarily based on 2D modeling. Still, the\nrelation between 3D geometry and the mechanics of knitted fabrics has not been\nclarified so far. The curling behavior of knits is intricately related to the\nforces and moments acting on the yarns, geometry of the unit knitted loops,\nmechanical properties, and contacts, hence requiring a 3D analysis. Here, we\nshow that the curling of plain knits emerges through the elasticity and\ngeometry of the knitted loops, combining desktop-scale experiments and reduced\nelasticity-based simulations. We find that by changing the horizontal and\nvertical knitting numbers, three types of curl shapes emerge: side curl and\ntop/bottom curl shapes, which are curled only horizontally and vertically, and\ndouble curl shape, in which both curl shapes appear together. The fundamental\nmechanism of intricate shape deformation is clarified through the force and\nmoment balance along yarn whose centerline shape is discretized through the\nB-spline curves where elastic stretching, bending, and contact mechanics are\ntaken into account. We reveal that the 3D structure of the single-knitted loop\nplays a critical role in the curling behavior. Our results imply that the\nchange in shape per a single knitted loop has the potential to control the 3D\nnatural overall shape of knitted fabrics, and could be applied in predicting or\ndesigning more complex 3D shapes made of knitted fabrics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13307v1",
    "published": "2024-10-17T08:07:06+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13306v1",
    "title": "The cloud cover and meteorological parameters at the Lenghu site on the Tibetan Plateau",
    "authors": [
      "Ruiyue Li",
      "Fei He",
      "Licai Deng",
      "Xiaodian Chen",
      "Fan Yang",
      "Yong Zhao",
      "Bo Zhang",
      "Chunguang Zhang",
      "Chen Yang",
      "Tian Lan"
    ],
    "abstract": "The cloud cover and meteorological parameters serve as fundamental criteria\nfor the qualification of an astronomical observatory working in optical and\ninfrared wavelengths. In this paper, we present a systematic assessment of key\nmeteorological parameters at the Lenghu site. The datasets adopted in this\nstudy includes the meteorological parameters collected at the local weather\nstations at the site and in the Lenghu Town, the sky brightness at the local\nzenith acquired by the Sky Quality Meters and night sky all-sky images from a\ndigital camera, the ERA5 reanalysis database and global climate monitoring\ndata. From 2019 to 2023, the fractional observable time of photometric\ncondition is 69.70%, 74.97%, 70.26%, 74.27% and 65.12%, respectively. The\nfractional observing time is inversely correlated with surface air temperature,\nrelative humidity, precipitable water vapor, and dew temperature, demonstrating\nthat the observing conditions are influenced by these meteorological\nparameters. Large-scale air-sea interactions affect the climate at Lenghu site,\nwhich in fact delivers a clue to understand the irregularity of 2023.\nSpecifically, precipitable water vapor at Lenghu site is correlated to both the\nwesterly wind index and the summer North Atlantic Oscillation index, the yearly\naverage temperature of Lenghu site is observed to increase significantly during\nthe occurrence of a strong El Ni\\~no event and the relative humidity anomaly at\nLenghu site is correlated to the Pacific Decadal Oscillation index. The\ndecrease of fractional observing time in 2023 was due to the ongoing strong El\nNi\\~no event and relevant global climate change. We underscore the substantial\nrole of global climate change in regulating astronomical observing conditions\nand the necessity for long-term continuous monitoring of the astronomical\nmeteorological parameters at Lenghu site.",
    "pdf_url": "http://arxiv.org/pdf/2410.13306v1",
    "published": "2024-10-17T08:05:56+00:00",
    "categories": [
      "astro-ph.IM",
      "physics.ao-ph"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13305v3",
    "title": "Reference-Based Post-OCR Processing with LLM for Precise Diacritic Text in Historical Document Recognition",
    "authors": [
      "Thao Do",
      "Dinh Phu Tran",
      "An Vo",
      "Daeyoung Kim"
    ],
    "abstract": "Extracting fine-grained OCR text from aged documents in diacritic languages\nremains challenging due to unexpected artifacts, time-induced degradation, and\nlack of datasets. While standalone spell correction approaches have been\nproposed, they show limited performance for historical documents due to\nnumerous possible OCR error combinations and differences between modern and\nclassical corpus distributions. We propose a method utilizing available\ncontent-focused ebooks as a reference base to correct imperfect OCR-generated\ntext, supported by large language models. This technique generates\nhigh-precision pseudo-page-to-page labels for diacritic languages, where small\nstrokes pose significant challenges in historical conditions. The pipeline\neliminates various types of noise from aged documents and addresses issues such\nas missing characters, words, and disordered sequences. Our post-processing\nmethod, which generated a large OCR dataset of classical Vietnamese books,\nachieved a mean grading score of 8.72 on a 10-point scale. This outperformed\nthe state-of-the-art transformer-based Vietnamese spell correction model, which\nscored 7.03 when evaluated on a sampled subset of the dataset. We also trained\na baseline OCR model to assess and compare it with well-known engines.\nExperimental results demonstrate the strength of our baseline model compared to\nwidely used open-source solutions. The resulting dataset will be released\npublicly to support future studies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13305v3",
    "published": "2024-10-17T08:05:02+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13304v2",
    "title": "Precision tests of third-generation four-quark operators: one- and two-loop matching",
    "authors": [
      "Ulrich Haisch",
      "Luc Schnell"
    ],
    "abstract": "We calculate the one- and two-loop matching corrections in the Standard Model\neffective field theory (SMEFT) that impact electroweak precision measurements\nand flavour physics observables, focusing on the contributions of\nthird-generation four-quark operators. Our results provide a crucial ingredient\nfor a model-independent analysis of constraints on beyond the Standard Model\nphysics that primarily affects the sector of third-generation four-quark\noperators. Concise analytic expressions are provided for all considered\nprecision observables, which should facilitate their inclusion into global\nSMEFT analyses.",
    "pdf_url": "http://arxiv.org/pdf/2410.13304v2",
    "published": "2024-10-17T08:03:29+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13303v1",
    "title": "Hiformer: Hybrid Frequency Feature Enhancement Inverted Transformer for Long-Term Wind Power Prediction",
    "authors": [
      "Chongyang Wan",
      "Shunbo Lei",
      "Yuan Luo"
    ],
    "abstract": "The increasing severity of climate change necessitates an urgent transition\nto renewable energy sources, making the large-scale adoption of wind energy\ncrucial for mitigating environmental impact. However, the inherent uncertainty\nof wind power poses challenges for grid stability, underscoring the need for\naccurate wind energy prediction models to enable effective power system\nplanning and operation. While many existing studies on wind power prediction\nfocus on short-term forecasting, they often overlook the importance of\nlong-term predictions. Long-term wind power forecasting is essential for\neffective power grid dispatch and market transactions, as it requires careful\nconsideration of weather features such as wind speed and direction, which\ndirectly influence power output. Consequently, methods designed for short-term\npredictions may lead to inaccurate results and high computational costs in\nlong-term settings. To adress these limitations, we propose a novel approach\ncalled Hybrid Frequency Feature Enhancement Inverted Transformer (Hiformer).\nHiformer introduces a unique structure that integrates signal decomposition\ntechnology with weather feature extraction technique to enhance the modeling of\ncorrelations between meteorological conditions and wind power generation.\nAdditionally, Hiformer employs an encoder-only architecture, which reduces the\ncomputational complexity associated with long-term wind power forecasting.\nCompared to the state-of-the-art methods, Hiformer: (i) can improve the\nprediction accuracy by up to 52.5\\%; and (ii) can reduce computational time by\nup to 68.5\\%.",
    "pdf_url": "http://arxiv.org/pdf/2410.13303v1",
    "published": "2024-10-17T08:00:36+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13302v1",
    "title": "The Lieb excitations and topological flat mode of spectral function of Tonks-Girardeau gas in Kronig-Penney potential",
    "authors": [
      "Wen-Bin He",
      "Giedrius Žlabys",
      "Hoshu Hiyane",
      "Sarika Sasidharan Nair",
      "Thomas Busch"
    ],
    "abstract": "Lieb excitations are fundamental to the understanding of the low energy\nbehaviour of many-body quantum gases. Here we study the spectral function of a\nTonks-Girardeau gas in a finite sized Kronig-Penney potential and show that the\nLieb-I and Lieb-II excitations can become gapped as a function of the barrier\nheight. Moreover, we reveal the existence of a topological flat mode near the\nFermi energy and at zero momentum and show that this is robust to perturbations\nin the system. Through a scaling analysis, we determine the divergent behaviour\nof the spectral function. Our results provide a significant reference for the\nobservation and understanding of the gapped Lieb excitations and the\ntopological flat mode of quantum gases in experimentally realistic\nsubwavelength optical lattice potentials.",
    "pdf_url": "http://arxiv.org/pdf/2410.13302v1",
    "published": "2024-10-17T08:00:14+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2410.19809v1",
    "title": "ScreenWriter: Automatic Screenplay Generation and Movie Summarisation",
    "authors": [
      "Louis Mahon",
      "Mirella Lapata"
    ],
    "abstract": "The proliferation of creative video content has driven demand for textual\ndescriptions or summaries that allow users to recall key plot points or get an\noverview without watching. The volume of movie content and speed of turnover\nmotivates automatic summarisation, which is nevertheless challenging, requiring\nidentifying character intentions and very long-range temporal dependencies. The\nfew existing methods attempting this task rely heavily on textual screenplays\nas input, greatly limiting their applicability. In this work, we propose the\ntask of automatic screenplay generation, and a method, ScreenWriter, that\noperates only on video and produces output which includes dialogue, speaker\nnames, scene breaks, and visual descriptions. ScreenWriter introduces a novel\nalgorithm to segment the video into scenes based on the sequence of visual\nvectors, and a novel method for the challenging problem of determining\ncharacter names, based on a database of actors' faces. We further demonstrate\nhow these automatic screenplays can be used to generate plot synopses with a\nhierarchical summarisation method based on scene breaks. We test the quality of\nthe final summaries on the recent MovieSum dataset, which we augment with\nvideos, and show that they are superior to a number of comparison models which\nassume access to goldstandard screenplays.",
    "pdf_url": "http://arxiv.org/pdf/2410.19809v1",
    "published": "2024-10-17T07:59:54+00:00",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13301v1",
    "title": "Automating IETF Insights generation with AI",
    "authors": [
      "Jaime Jiménez"
    ],
    "abstract": "This paper presents the IETF Insights project, an automated system that\nstreamlines the generation of comprehensive reports on the activities of the\nInternet Engineering Task Force (IETF) Working Groups. The system collects,\nconsolidates, and analyzes data from various IETF sources, including meeting\nminutes, participant lists, drafts and agendas. The core components of the\nsystem include data preprocessing code and a report generation module that\nproduces high-quality documents in LaTeX or Markdown. By integrating large\nLanguage Models (LLMs) for summaries based on the data as ground truth, the\nIETF Insights project enhances the accessibility and utility of IETF records,\nproviding a valuable overview of the IETF's activities and contributions to the\ncommunity.",
    "pdf_url": "http://arxiv.org/pdf/2410.13301v1",
    "published": "2024-10-17T07:59:05+00:00",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13300v1",
    "title": "A theoretical perspective on mode collapse in variational inference",
    "authors": [
      "Roman Soletskyi",
      "Marylou Gabrié",
      "Bruno Loureiro"
    ],
    "abstract": "While deep learning has expanded the possibilities for highly expressive\nvariational families, the practical benefits of these tools for variational\ninference (VI) are often limited by the minimization of the traditional\nKullback-Leibler objective, which can yield suboptimal solutions. A major\nchallenge in this context is \\emph{mode collapse}: the phenomenon where a model\nconcentrates on a few modes of the target distribution during training, despite\nbeing statistically capable of expressing them all. In this work, we carry a\ntheoretical investigation of mode collapse for the gradient flow on Gaussian\nmixture models. We identify the key low-dimensional statistics characterizing\nthe flow, and derive a closed set of low-dimensional equations governing their\nevolution. Leveraging this compact description, we show that mode collapse is\npresent even in statistically favorable scenarios, and identify two key\nmechanisms driving it: mean alignment and vanishing weight. Our theoretical\nfindings are consistent with the implementation of VI using normalizing flows,\na class of popular generative models, thereby offering practical insights.",
    "pdf_url": "http://arxiv.org/pdf/2410.13300v1",
    "published": "2024-10-17T07:56:30+00:00",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13299v2",
    "title": "LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models",
    "authors": [
      "David Hoffmann",
      "Kailash Budhathoki",
      "Matthaeus Kleindessner"
    ],
    "abstract": "The evolving capabilities of large language models are accompanied by growing\nsizes and deployment costs, necessitating effective inference optimisation\ntechniques. We propose a novel pruning method utilising centrality measures\nfrom graph theory, reducing both the computational requirements and the memory\nfootprint of these models. Specifically, we devise a method for creating a\nweighted directed acyclical graph representation of multilayer perceptrons to\nwhich we apply a modified version of the weighted PageRank centrality measure\nto compute node importance scores. In combination with uniform pruning this\nleads to structured sparsity. We call this pruning method MLPRank. Furthermore\nwe introduce an extension to decoder-only transformer models and call it\nLLMRank. For both variants we demonstrate a strong performance. With MLPRank on\naverage leading to 6.09 % higher accuracy retention than three popular\nbaselines and 13.42 % with LLMRank compared to two popular baselines. Code is\navailable at https://github.com/amazon-science/llm-rank-pruning.",
    "pdf_url": "http://arxiv.org/pdf/2410.13299v2",
    "published": "2024-10-17T07:55:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13298v1",
    "title": "Advancing Large Language Model Attribution through Self-Improving",
    "authors": [
      "Lei Huang",
      "Xiaocheng Feng",
      "Weitao Ma",
      "Liang Zhao",
      "Yuchun Fan",
      "Weihong Zhong",
      "Dongliang Xu",
      "Qing Yang",
      "Hongtao Liu",
      "Bing Qin"
    ],
    "abstract": "Teaching large language models (LLMs) to generate text with citations to\nevidence sources can mitigate hallucinations and enhance verifiability in\ninformation-seeking systems. However, improving this capability requires\nhigh-quality attribution data, which is costly and labor-intensive. Inspired by\nrecent advances in self-improvement that enhance LLMs without manual\nannotation, we present START, a Self-Taught AttRibuTion framework for\niteratively improving the attribution capability of LLMs. First, to prevent\nmodels from stagnating due to initially insufficient supervision signals, START\nleverages the model to self-construct synthetic training data for warming up.\nTo further self-improve the model's attribution ability, START iteratively\nutilizes fine-grained preference supervision signals constructed from its\nsampled responses to encourage robust, comprehensive, and attributable\ngeneration. Experiments on three open-domain question-answering datasets,\ncovering long-form QA and multi-step reasoning, demonstrate significant\nperformance gains of 25.13% on average without relying on human annotations and\nmore advanced models. Further analysis reveals that START excels in aggregating\ninformation across multiple sources.",
    "pdf_url": "http://arxiv.org/pdf/2410.13298v1",
    "published": "2024-10-17T07:55:33+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13297v2",
    "title": "Confined but chirally and chiral spin symmetric hot matter",
    "authors": [
      "L. Ya. Glozman",
      "A. V. Nefediev",
      "R. F. Wagenbrunn"
    ],
    "abstract": "We investigate properties of the quark--antiquark mesons at zero and finite\ntemperature in the framework of a solvable chirally symmetric quark model with\nlinear confining potential. The interquark interaction in the model is\nreminiscent of that derived in Coulomb gauge QCD, with the string tension being\nthe only model parameter. We demonstrate that while the confining interaction\ninduces spontaneous breaking of chiral symmetry at T=0, chiral symmetry gets\nrestored at a temperature Tch ~ 90 MeV for the string tension fixed to provide\nthe phenomenological value of the quark condensate. This temperature is similar\nto Tch ~ 130 MeV observed on the lattice in the chiral limit for N_c=3. The\nphysical mechanism responsible for the chiral symmetry restoration in the\nconfining regime is Pauli blocking of the quark levels, required for the\nexistence of a nonvanishing quark condensate, by the thermal excitations of the\nquarks and antiquarks. Thus, above the chiral restoration temperature, the\nmeson-like states are chirally symmetric and approximately chiral spin\nsymmetric. A crucial property of the confined meson-like light-light states\nabove Tch is their size that exceeds drastically that in the chirally broken\nphase below Tch, in contrast to the heavy-heavy mesons that nearly preserve\ntheir size irrespective of the temperature. This property is a result of Pauli\nblocking of the quark and antiquark levels with small momenta. Furthermore, the\nroot-mean-square radius of the states with J=0,1 diverges in the chiral limit.\nThis unexpected property must be a key to understanding unusual features of the\nhot QCD matter as observed at RHIC and LHC. Consequently, the confining but\nchirally symmetric matter above Tch can be considered as a dense system of very\nlarge and strongly overlapping meson-like states (``strings'').",
    "pdf_url": "http://arxiv.org/pdf/2410.13297v2",
    "published": "2024-10-17T07:53:24+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-lat",
      "hep-th",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13296v1",
    "title": "Fairness-Enhancing Ensemble Classification in Water Distribution Networks",
    "authors": [
      "Janine Strotherm",
      "Barbara Hammer"
    ],
    "abstract": "As relevant examples such as the future criminal detection software [1] show,\nfairness of AI-based and social domain affecting decision support tools\nconstitutes an important area of research. In this contribution, we investigate\nthe applications of AI to socioeconomically relevant infrastructures such as\nthose of water distribution networks (WDNs), where fairness issues have yet to\ngain a foothold. To establish the notion of fairness in this domain, we propose\nan appropriate definition of protected groups and group fairness in WDNs as an\nextension of existing definitions. We demonstrate that typical methods for the\ndetection of leakages in WDNs are unfair in this sense. Further, we thus\npropose a remedy to increase the fairness which can be applied even to\nnon-differentiable ensemble classification methods as used in this context.",
    "pdf_url": "http://arxiv.org/pdf/2410.13296v1",
    "published": "2024-10-17T07:53:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13295v2",
    "title": "PiLocNet: Physics-informed neural network on 3D localization with rotating point spread function",
    "authors": [
      "Mingda Lu",
      "Zitian Ao",
      "Chao Wang",
      "Sudhakar Prasad",
      "Raymond H. Chan"
    ],
    "abstract": "For the 3D localization problem using point spread function (PSF)\nengineering, we propose a novel enhancement of our previously introduced\nlocalization neural network, LocNet. The improved network is a physics-informed\nneural network (PINN) that we call PiLocNet. Previous works on the localization\nproblem may be categorized separately into model-based optimization and neural\nnetwork approaches. Our PiLocNet combines the unique strengths of both\napproaches by incorporating forward-model-based information into the network\nvia a data-fitting loss term that constrains the neural network to yield\nresults that are physically sensible. We additionally incorporate certain\nregularization terms from the variational method, which further improves the\nrobustness of the network in the presence of image noise, as we show for the\nPoisson and Gaussian noise models. This framework accords interpretability to\nthe neural network, and the results we obtain show its superiority. Although\nthe paper focuses on the use of single-lobe rotating PSF to encode the full 3D\nsource location, we expect the method to be widely applicable to other PSFs and\nimaging problems that are constrained by known forward processes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13295v2",
    "published": "2024-10-17T07:49:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "physics.optics"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13294v2",
    "title": "LESS: Label-Efficient and Single-Stage Referring 3D Segmentation",
    "authors": [
      "Xuexun Liu",
      "Xiaoxu Xu",
      "Jinlong Li",
      "Qiudan Zhang",
      "Xu Wang",
      "Nicu Sebe",
      "Lin Ma"
    ],
    "abstract": "Referring 3D Segmentation is a visual-language task that segments all points\nof the specified object from a 3D point cloud described by a sentence of query.\nPrevious works perform a two-stage paradigm, first conducting language-agnostic\ninstance segmentation then matching with given text query. However, the\nsemantic concepts from text query and visual cues are separately interacted\nduring the training, and both instance and semantic labels for each object are\nrequired, which is time consuming and human-labor intensive. To mitigate these\nissues, we propose a novel Referring 3D Segmentation pipeline, Label-Efficient\nand Single-Stage, dubbed LESS, which is only under the supervision of efficient\nbinary mask. Specifically, we design a Point-Word Cross-Modal Alignment module\nfor aligning the fine-grained features of points and textual embedding. Query\nMask Predictor module and Query-Sentence Alignment module are introduced for\ncoarse-grained alignment between masks and query. Furthermore, we propose an\narea regularization loss, which coarsely reduces irrelevant background\npredictions on a large scale. Besides, a point-to-point contrastive loss is\nproposed concentrating on distinguishing points with subtly similar features.\nThrough extensive experiments, we achieve state-of-the-art performance on\nScanRefer dataset by surpassing the previous methods about 3.7% mIoU using only\nbinary labels. Code is available at https://github.com/mellody11/LESS.",
    "pdf_url": "http://arxiv.org/pdf/2410.13294v2",
    "published": "2024-10-17T07:47:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13293v2",
    "title": "SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation",
    "authors": [
      "Prakhar Dixit",
      "Tim Oates"
    ],
    "abstract": "Many students struggle with math word problems (MWPs), often finding it\ndifficult to identify key information and select the appropriate mathematical\noperations. Schema-based instruction (SBI) is an evidence-based strategy that\nhelps students categorize problems based on their structure, improving\nproblem-solving accuracy. Building on this, we propose a Schema-Based\nInstruction Retrieval-Augmented Generation (SBI-RAG) framework that\nincorporates a large language model (LLM). Our approach emphasizes step-by-step\nreasoning by leveraging schemas to guide solution generation. We evaluate its\nperformance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo,\nand introduce a \"reasoning score\" metric to assess solution quality. Our\nfindings suggest that SBI-RAG enhances reasoning clarity and facilitates a more\nstructured problem-solving process potentially providing educational benefits\nfor students.",
    "pdf_url": "http://arxiv.org/pdf/2410.13293v2",
    "published": "2024-10-17T07:46:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.14739v1",
    "title": "Toward a Unified Graph-Based Representation of Medical Data for Precision Oncology Medicine",
    "authors": [
      "Davide Belluomo",
      "Tiziana Calamoneri",
      "Giacomo Paesani",
      "Ivano Salvo"
    ],
    "abstract": "We present a new unified graph-based representation of medical data,\ncombining genetic information and medical records of patients with medical\nknowledge via a unique knowledge graph. This approach allows us to infer\nmeaningful information and explanations that would be unavailable by looking at\neach data set separately. The systematic use of different databases, managed\nthroughout the built knowledge graph, gives new insights toward a better\nunderstanding of oncology medicine. Indeed, we reduce some useful medical tasks\nto well-known problems in theoretical computer science for which efficient\nalgorithms exist.",
    "pdf_url": "http://arxiv.org/pdf/2410.14739v1",
    "published": "2024-10-17T07:43:48+00:00",
    "categories": [
      "cs.AI",
      "68T30",
      "E.1; J.3"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13292v2",
    "title": "Singularities of solutions of nonlocal nonlinear equations",
    "authors": [
      "Minhyun Kim",
      "Se-Chan Lee"
    ],
    "abstract": "We study the local behavior of weak solutions, with possible singularities,\nof nonlocal nonlinear equations. We first prove that sets of capacity zero are\nremovable for weak solutions under certain integrability conditions. We then\ncharacterize the asymptotic behavior of singular solutions near an isolated\nsingularity in terms of the fundamental solution.",
    "pdf_url": "http://arxiv.org/pdf/2410.13292v2",
    "published": "2024-10-17T07:42:05+00:00",
    "categories": [
      "math.AP",
      "35A21, 35B65, 35R09"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13291v2",
    "title": "Impact parameter dependence of the effect of background field on coupling constant in heavy ion collisions",
    "authors": [
      "Cong Li"
    ],
    "abstract": "We investigated the impact parameter dependence of the background field's\neffect on the coupling constant of the $\\gamma \\gamma \\rightarrow l^{+} l^{-}\n\\gamma$ process in heavy-ion collisions. The peripheral electric fields of\nheavy ions collide, and after photon annihilation into lepton pairs, the\nsubsequent emission of radiation photons will be affected by the background\nfield. Numerical estimates indicate that the dependence of this effect on the\nimpact parameter is significant during this process.",
    "pdf_url": "http://arxiv.org/pdf/2410.13291v2",
    "published": "2024-10-17T07:39:43+00:00",
    "categories": [
      "nucl-th",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13290v1",
    "title": "Packing large balanced trees into bipartite graphs",
    "authors": [
      "Cristina G. Fernandes",
      "Tássio Naia",
      "Giovanne Santos",
      "Maya Stein"
    ],
    "abstract": "We prove that for every ${\\gamma > 0}$ there exists $n_0 \\in \\mathbb{N}$ such\nthat for every ${n \\geq n_0}$ any family of up to\n$\\lfloor{n^{\\frac12+\\gamma}}\\rfloor$ trees having at most $(1-\\gamma)n$\nvertices in each bipartition class can be packed into $K_{n,n}$. As a tool for\nour proof, we show an approximate bipartite version of the\nKoml\\'os-S\\'ark\\\"ozy-Szemer\\'edi Theorem, which we believe to be of independent\ninterest.",
    "pdf_url": "http://arxiv.org/pdf/2410.13290v1",
    "published": "2024-10-17T07:37:59+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13289v1",
    "title": "Trans-Bifurcation Prediction of Dynamics in terms of Extreme Learning Machines with Control Inputs",
    "authors": [
      "Satoru Tadokoro",
      "Akihiro Yamaguchi",
      "Takao Namiki",
      "Ichiro Tsuda"
    ],
    "abstract": "By extending the extreme learning machine by additional control inputs, we\nachieved almost complete reproduction of bifurcation structures of dynamical\nsystems. The learning ability of the proposed neural network system is striking\nin that the entire structure of the bifurcations of a target one-parameter\nfamily of dynamical systems can be nearly reproduced by training on transient\ndynamics using only a few parameter values. Moreover, we propose a mechanism to\nexplain this remarkable learning ability and discuss the relationship between\nthe present results and similar results obtained by Kim et al.",
    "pdf_url": "http://arxiv.org/pdf/2410.13289v1",
    "published": "2024-10-17T07:34:23+00:00",
    "categories": [
      "nlin.CD",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13288v1",
    "title": "DurIAN-E 2: Duration Informed Attention Network with Adaptive Variational Autoencoder and Adversarial Learning for Expressive Text-to-Speech Synthesis",
    "authors": [
      "Yu Gu",
      "Qiushi Zhu",
      "Guangzhi Lei",
      "Chao Weng",
      "Dan Su"
    ],
    "abstract": "This paper proposes an improved version of DurIAN-E (DurIAN-E 2), which is\nalso a duration informed attention neural network for expressive and\nhigh-fidelity text-to-speech (TTS) synthesis. Similar with the DurIAN-E model,\nmultiple stacked SwishRNN-based Transformer blocks are utilized as linguistic\nencoders and Style-Adaptive Instance Normalization (SAIN) layers are also\nexploited into frame-level encoders to improve the modeling ability of\nexpressiveness in the proposed the DurIAN-E 2. Meanwhile, motivated by other\nTTS models using generative models such as VITS, the proposed DurIAN-E 2\nutilizes variational autoencoders (VAEs) augmented with normalizing flows and a\nBigVGAN waveform generator with adversarial training strategy, which further\nimprove the synthesized speech quality and expressiveness. Both objective test\nand subjective evaluation results prove that the proposed expressive TTS model\nDurIAN-E 2 can achieve better performance than several state-of-the-art\napproaches besides DurIAN-E.",
    "pdf_url": "http://arxiv.org/pdf/2410.13288v1",
    "published": "2024-10-17T07:34:04+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13287v6",
    "title": "PAK-UCB Contextual Bandit: An Online Learning Approach to Prompt-Aware Selection of Generative Models and LLMs",
    "authors": [
      "Xiaoyan Hu",
      "Ho-fung Leung",
      "Farzan Farnia"
    ],
    "abstract": "Selecting a sample generation scheme from multiple prompt-based generative\nmodels, including large language models (LLMs) and prompt-guided image and\nvideo generation models, is typically addressed by choosing the model that\nmaximizes an averaged evaluation score. However, this score-based selection\noverlooks the possibility that different models achieve the best generation\nperformance for different types of text prompts. An online identification of\nthe best generation model for various input prompts can reduce the costs\nassociated with querying sub-optimal models. In this work, we explore the\npossibility of varying rankings of text-based generative models for different\ntext prompts and propose an online learning framework to predict the best data\ngeneration model for a given input prompt. The proposed PAK-UCB algorithm\naddresses a contextual bandit (CB) setting with shared context variables across\nthe arms, utilizing the generated data to update kernel-based functions that\npredict the score of each model available for unseen text prompts.\nAdditionally, we leverage random Fourier features (RFF) to accelerate the\nonline learning process of PAK-UCB. Our numerical experiments on real and\nsimulated text-to-image and image-to-text generative models show that RFF-UCB\nperforms successfully in identifying the best generation model across different\nsample types. The code is available at:\ngithub.com/yannxiaoyanhu/dgm-online-select.",
    "pdf_url": "http://arxiv.org/pdf/2410.13287v6",
    "published": "2024-10-17T07:33:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13286v2",
    "title": "A Human-in-the-Loop Fairness-Aware Model Selection Framework for Complex Fairness Objective Landscapes",
    "authors": [
      "Jake Robertson",
      "Thorsten Schmidt",
      "Frank Hutter",
      "Noor Awad"
    ],
    "abstract": "Fairness-aware Machine Learning (FairML) applications are often characterized\nby complex social objectives and legal requirements, frequently involving\nmultiple, potentially conflicting notions of fairness. Despite the well-known\nImpossibility Theorem of Fairness and extensive theoretical research on the\nstatistical and socio-technical trade-offs between fairness metrics, many\nFairML tools still optimize or constrain for a single fairness objective.\nHowever, this one-sided optimization can inadvertently lead to violations of\nother relevant notions of fairness. In this socio-technical and empirical\nstudy, we frame fairness as a many-objective (MaO) problem by treating fairness\nmetrics as conflicting objectives. We introduce ManyFairHPO, a\nhuman-in-the-loop, fairness-aware model selection framework that enables\npractitioners to effectively navigate complex and nuanced fairness objective\nlandscapes. ManyFairHPO aids in the identification, evaluation, and balancing\nof fairness metric conflicts and their related social consequences, leading to\nmore informed and socially responsible model-selection decisions. Through a\ncomprehensive empirical evaluation and a case study on the Law School\nAdmissions problem, we demonstrate the effectiveness of ManyFairHPO in\nbalancing multiple fairness objectives, mitigating risks such as\nself-fulfilling prophecies, and providing interpretable insights to guide\nstakeholders in making fairness-aware modeling decisions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13286v2",
    "published": "2024-10-17T07:32:24+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13917v1",
    "title": "GBCT: An Efficient and Adaptive Granular-Ball Clustering Algorithm for Complex Data",
    "authors": [
      "Shuyin Xia",
      "Bolun Shi",
      "Yifan Wang",
      "Jiang Xie",
      "Guoyin Wang",
      "Xinbo Gao"
    ],
    "abstract": "Traditional clustering algorithms often focus on the most fine-grained\ninformation and achieve clustering by calculating the distance between each\npair of data points or implementing other calculations based on points. This\nway is not inconsistent with the cognitive mechanism of \"global precedence\" in\nhuman brain, resulting in those methods' bad performance in efficiency,\ngeneralization ability and robustness. To address this problem, we propose a\nnew clustering algorithm called granular-ball clustering (GBCT) via\ngranular-ball computing. Firstly, GBCT generates a smaller number of\ngranular-balls to represent the original data, and forms clusters according to\nthe relationship between granular-balls, instead of the traditional point\nrelationship. At the same time, its coarse-grained characteristics are not\nsusceptible to noise, and the algorithm is efficient and robust; besides, as\ngranular-balls can fit various complex data, GBCT performs much better in\nnon-spherical data sets than other traditional clustering methods. The\ncompletely new coarse granularity representation method of GBCT and cluster\nformation mode can also used to improve other traditional methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13917v1",
    "published": "2024-10-17T07:32:05+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13285v2",
    "title": "Composing Novel Classes: A Concept-Driven Approach to Generalized Category Discovery",
    "authors": [
      "Chuyu Zhang",
      "Peiyan Gu",
      "Xueyang Yu",
      "Xuming He"
    ],
    "abstract": "We tackle the generalized category discovery (GCD) problem, which aims to\ndiscover novel classes in unlabeled datasets by leveraging the knowledge of\nknown classes. Previous works utilize the known class knowledge through shared\nrepresentation spaces. Despite their progress, our analysis experiments show\nthat novel classes can achieve impressive clustering results on the feature\nspace of a known class pre-trained model, suggesting that existing methods may\nnot fully utilize known class knowledge. To address it, we introduce a novel\nconcept learning framework for GCD, named ConceptGCD, that categorizes concepts\ninto two types: derivable and underivable from known class concepts, and adopts\na stage-wise learning strategy to learn them separately. Specifically, our\nframework first extracts known class concepts by a known class pre-trained\nmodel and then produces derivable concepts from them by a generator layer with\na covariance-augmented loss. Subsequently, we expand the generator layer to\nlearn underivable concepts in a balanced manner ensured by a concept score\nnormalization strategy and integrate a contrastive loss to preserve previously\nlearned concepts. Extensive experiments on various benchmark datasets\ndemonstrate the superiority of our approach over the previous state-of-the-art\nmethods. Code will be available soon.",
    "pdf_url": "http://arxiv.org/pdf/2410.13285v2",
    "published": "2024-10-17T07:30:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13284v3",
    "title": "Learning to Route LLMs with Confidence Tokens",
    "authors": [
      "Yu-Neng Chuang",
      "Prathusha Kameswara Sarma",
      "Parikshit Gopalan",
      "John Boccio",
      "Sara Bolouki",
      "Xia Hu",
      "Helen Zhou"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive performance on\nseveral tasks and are increasingly deployed in real-world applications.\nHowever, especially in high-stakes settings, it becomes vital to know when the\noutput of an LLM may be unreliable. Depending on whether an answer is\ntrustworthy, a system can then choose to route the question to another expert,\nor otherwise fall back on a safe default behavior. In this work, we study the\nextent to which LLMs can reliably indicate confidence in their answers, and how\nthis notion of confidence can translate into downstream accuracy gains. We\npropose Self-Reflection with Error-based Feedback (Self-REF), a lightweight\ntraining strategy to teach LLMs to express confidence in whether their answers\nare correct in a reliable manner. Self-REF introduces confidence tokens into\nthe LLM, from which a confidence score can be extracted. Compared to\nconventional approaches such as verbalizing confidence and examining token\nprobabilities, we demonstrate empirically that confidence tokens show\nsignificant improvements in downstream routing and rejection learning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13284v3",
    "published": "2024-10-17T07:28:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13283v1",
    "title": "Tangle replacements and knot Floer homology torsions",
    "authors": [
      "Eaman Eftekhary"
    ],
    "abstract": "We show that the torsion order $\\mathrm{Ord}(K)$ of a knot $K$ in knot Floer\nhomology gives a lower bound on the minimum number $n$ such that an oriented\n$(n+1)$-tangle replacement unknots $K$. This generalizes earlier results by\nAlishahi and the author and by Juhasz, Miller and Zemke, that $\\mathrm{Ord}(K)$\nis a lower bound for both the unknotting number $u(K)$ and for $br(K)-1$, where\n$br(K)$ denotes the bridge index of $K$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13283v1",
    "published": "2024-10-17T07:22:07+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13282v1",
    "title": "End-to-End Integration of Speech Emotion Recognition with Voice Activity Detection using Self-Supervised Learning Features",
    "authors": [
      "Natsuo Yamashita",
      "Masaaki Yamamoto",
      "Yohei Kawaguchi"
    ],
    "abstract": "Speech Emotion Recognition (SER) often operates on speech segments detected\nby a Voice Activity Detection (VAD) model. However, VAD models may output\nflawed speech segments, especially in noisy environments, resulting in degraded\nperformance of subsequent SER models. To address this issue, we propose an\nend-to-end (E2E) method that integrates VAD and SER using Self-Supervised\nLearning (SSL) features. The VAD module first receives the SSL features as\ninput, and the segmented SSL features are then fed into the SER module. Both\nthe VAD and SER modules are jointly trained to optimize SER performance.\nExperimental results on the IEMOCAP dataset demonstrate that our proposed\nmethod improves SER performance. Furthermore, to investigate the effect of our\nproposed method on the VAD and SSL modules, we present an analysis of the VAD\noutputs and the weights of each layer of the SSL encoder.",
    "pdf_url": "http://arxiv.org/pdf/2410.13282v1",
    "published": "2024-10-17T07:18:19+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13281v4",
    "title": "BanTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla",
    "authors": [
      "Fabiha Haider",
      "Fariha Tanjim Shifat",
      "Md Farhan Ishmam",
      "Deeparghya Dutta Barua",
      "Md Sakib Ul Rahman Sourove",
      "Md Fahim",
      "Md Farhad Alam"
    ],
    "abstract": "The proliferation of transliterated texts in digital spaces has emphasized\nthe need for detecting and classifying hate speech in languages beyond English,\nparticularly in low-resource languages. As online discourse can perpetuate\ndiscrimination based on target groups, e.g. gender, religion, and origin,\nmulti-label classification of hateful content can help in comprehending hate\nmotivation and enhance content moderation. While previous efforts have focused\non monolingual or binary hate classification tasks, no work has yet addressed\nthe challenge of multi-label hate speech classification in transliterated\nBangla. We introduce BanTH, the first multi-label transliterated Bangla hate\nspeech dataset comprising 37.3k samples. The samples are sourced from YouTube\ncomments, where each instance is labeled with one or more target groups,\nreflecting the regional demographic. We establish novel transformer\nencoder-based baselines by further pre-training on transliterated Bangla\ncorpus. We also propose a novel translation-based LLM prompting strategy for\ntransliterated text. Experiments reveal that our further pre-trained encoders\nare achieving state-of-the-art performance on the BanTH dataset, while our\ntranslation-based prompting outperforms other strategies in the zero-shot\nsetting. The introduction of BanTH not only fills a critical gap in hate speech\nresearch for Bangla but also sets the stage for future exploration into\ncode-mixed and multi-label classification challenges in underrepresented\nlanguages.",
    "pdf_url": "http://arxiv.org/pdf/2410.13281v4",
    "published": "2024-10-17T07:15:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13280v1",
    "title": "Hybrid bundle-adjusting 3D Gaussians for view consistent rendering with pose optimization",
    "authors": [
      "Yanan Guo",
      "Ying Xie",
      "Ying Chang",
      "Benkui Zhang",
      "Bo Jia",
      "Lin Cao"
    ],
    "abstract": "Novel view synthesis has made significant progress in the field of 3D\ncomputer vision. However, the rendering of view-consistent novel views from\nimperfect camera poses remains challenging. In this paper, we introduce a\nhybrid bundle-adjusting 3D Gaussians model that enables view-consistent\nrendering with pose optimization. This model jointly extract image-based and\nneural 3D representations to simultaneously generate view-consistent images and\ncamera poses within forward-facing scenes. The effective of our model is\ndemonstrated through extensive experiments conducted on both real and synthetic\ndatasets. These experiments clearly illustrate that our model can effectively\noptimize neural scene representations while simultaneously resolving\nsignificant camera pose misalignments. The source code is available at\nhttps://github.com/Bistu3DV/hybridBA.",
    "pdf_url": "http://arxiv.org/pdf/2410.13280v1",
    "published": "2024-10-17T07:13:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13279v2",
    "title": "Heavy-light quark systems from the QCD instanton vacuum: $N_f=1$ light flavor case",
    "authors": [
      "Ki-Hoon Hong",
      "Hyun-Chul Kim",
      "M. M. Musakhanov",
      "N. Rakhimov"
    ],
    "abstract": "We investigate heavy-light quark systems within the framework of the QCD\ninstanton vacuum, focusing on the $N_f = 1$ light flavor case. We derive an\neffective heavy-light quark interaction from the low-energy QCD partition\nfunction and construct a heavy-meson effective Lagrangian. The physical\nresidual mass of heavy mesons, $\\Lambda$, is determined by employing\ncompositeness and normalization conditions. We calculate the masses of $D$ and\n$B$ mesons and their weak decay constants to the leading order and\nnext-to-leading order in the $1/m_Q$ expansion. The current results for $f_D$\nand $f_B$ are in good agreement with recent lattice QCD data and PDG average\nvalues.",
    "pdf_url": "http://arxiv.org/pdf/2410.13279v2",
    "published": "2024-10-17T07:09:29+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13278v1",
    "title": "Fast Construction of Partitioned Learned Bloom Filter with Theoretical Guarantees",
    "authors": [
      "Atsuki Sato",
      "Yusuke Matsui"
    ],
    "abstract": "Bloom filter is a widely used classic data structure for approximate\nmembership queries. Learned Bloom filters improve memory efficiency by\nleveraging machine learning, with the partitioned learned Bloom filter (PLBF)\nbeing among the most memory-efficient variants. However, PLBF suffers from high\ncomputational complexity during construction, specifically $O(N^3k)$, where $N$\nand $k$ are hyperparameters. In this paper, we propose three methods: fast\nPLBF, fast PLBF++, and fast PLBF#, that reduce the construction complexity to\n$O(N^2k)$, $O(Nk \\log N)$, and $O(Nk \\log k)$, respectively. Fast PLBF\npreserves the original PLBF structure and memory efficiency. Although fast\nPLBF++ and fast PLBF# may have different structures, we theoretically prove\nthey are equivalent to PLBF under ideal data distribution. Furthermore, we\ntheoretically bound the difference in memory efficiency between PLBF and fast\nPLBF++ for non-ideal scenarios. Experiments on real-world datasets demonstrate\nthat fast PLBF, fast PLBF++, and fast PLBF# are up to 233, 761, and 778 times\nfaster to construct than original PLBF, respectively. Additionally, fast PLBF\nmaintains the same data structure as PLBF, and fast PLBF++ and fast PLBF#\nachieve nearly identical memory efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2410.13278v1",
    "published": "2024-10-17T07:09:26+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13277v1",
    "title": "Pricing Factors and TFMs for Scalability-Focused ZK-Rollups",
    "authors": [
      "Stefanos Chaliasos",
      "Nicolas Mohnblatt",
      "Assimakis Kattis",
      "Benjamin Livshits"
    ],
    "abstract": "ZK-Rollups have emerged as a leading solution for blockchain scalability,\nleveraging succinct proofs primarily based on ZKP protocols. This paper\nexplores the design of transaction fee mechanisms (TFMs) for ZK-Rollups,\nfocusing on how key components like sequencing, data availability~(DA), and ZK\nproving interact to influence cost structures. We outline the properties that a\nsuitable TFM should possess, such as incentive compatibility and net\nprofitability. In addition, we propose alternatives for TFMs, discuss\ntrade-offs, and highlight open questions that require further investigation in\nthe context of ZK-Rollups.",
    "pdf_url": "http://arxiv.org/pdf/2410.13277v1",
    "published": "2024-10-17T07:09:18+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13276v4",
    "title": "SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs",
    "authors": [
      "Yizhao Gao",
      "Zhichen Zeng",
      "Dayou Du",
      "Shijie Cao",
      "Peiyuan Zhou",
      "Jiaxing Qi",
      "Junjie Lai",
      "Hayden Kwok-Hay So",
      "Ting Cao",
      "Fan Yang",
      "Mao Yang"
    ],
    "abstract": "Attention is the cornerstone of modern Large Language Models (LLMs). Yet its\nquadratic complexity hinders efficiency and scalability, especially for\nlong-context processing. A promising approach is to leverage sparsity in\nattention. However, existing sparsity-based solutions predominantly rely on\npredefined patterns or heuristics at the attention head level, struggling to\nadapt dynamically to different contexts efficiently.\n  We propose SeerAttention, a simple yet effective attention mechanism that\ndirectly learns the block-level attention sparsity from the LLM itself.\nInspired by the gating mechanism in Mixture of Experts (MoE), SeerAttention\naugments the conventional attention with a learnable gate that selectively\nactivates important blocks within the attention map. Specifically, the gate\nfirst pools the query (Q) and key (K) tensors along the sequence dimension and\nprocesses them through learnable linear layers. The resulting matrices are then\nmultiplied together to produce the gating scores, which are used to predict\nblock-level attention sparsity. Combined with our block-sparse FlashAttention\nkernel, SeerAttention can achieve significant speedup on GPUs. When applied to\npre-trained LLMs, SeerAttention only requires training the gate parameters in a\nlightweight self-distillation manner, allowing rapid convergence. Our\nevaluation results demonstrate that SeerAttention achieves better model\naccuracy and lower latency for long-context pre-filling compared to prior\nmethods. Code is available at: https://github.com/microsoft/SeerAttention",
    "pdf_url": "http://arxiv.org/pdf/2410.13276v4",
    "published": "2024-10-17T07:07:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13275v2",
    "title": "Kneser's theorem for upper Buck density and relative results",
    "authors": [
      "Francois Hennecart"
    ],
    "abstract": "Kneser's theorem in the integers asserts that denoting by $\n\\underline{\\mathrm{d}}$ the lower asymptotic density, if\n$\\underline{\\mathrm{d}}(X_1+\\cdots+X_k)<\\sum_{i=1}^k\\underline{\\mathrm{d}}(X_i)$\nthen the sumset $X_1+\\cdots+X_k$ is \\emph{periodic} for some positive integer\n$q$. In this article we establish a similar statement for upper Buck density\nand compare it with the corresponding result due to Jin involving upper Banach\ndensity. We also provide the construction of sequences verifying\ncounterintuitive properties with respect to Buck density of a sequence $A$ and\nits sumset $A+A$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13275v2",
    "published": "2024-10-17T07:01:01+00:00",
    "categories": [
      "math.NT",
      "11B05, 11B13"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13274v1",
    "title": "Breaking Chains: Unraveling the Links in Multi-Hop Knowledge Unlearning",
    "authors": [
      "Minseok Choi",
      "ChaeHun Park",
      "Dohyun Lee",
      "Jaegul Choo"
    ],
    "abstract": "Large language models (LLMs) serve as giant information stores, often\nincluding personal or copyrighted data, and retraining them from scratch is not\na viable option. This has led to the development of various fast, approximate\nunlearning techniques to selectively remove knowledge from LLMs. Prior research\nhas largely focused on minimizing the probabilities of specific token sequences\nby reversing the language modeling objective. However, these methods still\nleave LLMs vulnerable to adversarial attacks that exploit indirect references.\nIn this work, we examine the limitations of current unlearning techniques in\neffectively erasing a particular type of indirect prompt: multi-hop queries.\nOur findings reveal that existing methods fail to completely remove multi-hop\nknowledge when one of the intermediate hops is unlearned. To address this\nissue, we propose MUNCH, a simple uncertainty-based approach that breaks down\nmulti-hop queries into subquestions and leverages the uncertainty of the\nunlearned model in final decision-making. Empirical results demonstrate the\neffectiveness of our framework, and MUNCH can be easily integrated with\nexisting unlearning techniques, making it a flexible and useful solution for\nenhancing unlearning processes.",
    "pdf_url": "http://arxiv.org/pdf/2410.13274v1",
    "published": "2024-10-17T07:00:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13273v1",
    "title": "Les Houches lecture notes on moduli spaces of Riemann surfaces",
    "authors": [
      "Alessandro Giacchetto",
      "Danilo Lewański"
    ],
    "abstract": "In these lecture notes, we provide an introduction to the moduli space of\nRiemann surfaces, a fundamental concept in the theories of 2D quantum gravity,\ntopological string theory, and matrix models. We begin by reviewing some basic\nresults concerning the recursive boundary structure of the moduli space and the\nassociated cohomology theory. We then present Witten's celebrated conjecture\nand its generalisation, framing it as a recursive computation of cohomological\nfield theory correlators via topological recursion. We conclude with a\ndiscussion of JT gravity in relation to hyperbolic geometry and topological\nstrings. These lecture notes accompanied a series of lectures at the Les\nHouches school \"Quantum Geometry (Mathematical Methods for Gravity, Gauge\nTheories and Non-Perturbative Physics)\" in Summer 2024.",
    "pdf_url": "http://arxiv.org/pdf/2410.13273v1",
    "published": "2024-10-17T07:00:00+00:00",
    "categories": [
      "math.AG",
      "hep-th",
      "math-ph",
      "math.MP",
      "14H10 (Primary) 14H70, 14H81 (Secondary)"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13272v1",
    "title": "FRAG: Toward Federated Vector Database Management for Collaborative and Secure Retrieval-Augmented Generation",
    "authors": [
      "Dongfang Zhao"
    ],
    "abstract": "This paper introduces \\textit{Federated Retrieval-Augmented Generation\n(FRAG)}, a novel database management paradigm tailored for the growing needs of\nretrieval-augmented generation (RAG) systems, which are increasingly powered by\nlarge-language models (LLMs). FRAG enables mutually-distrusted parties to\ncollaboratively perform Approximate $k$-Nearest Neighbor (ANN) searches on\nencrypted query vectors and encrypted data stored in distributed vector\ndatabases, all while ensuring that no party can gain any knowledge about the\nqueries or data of others. Achieving this paradigm presents two key challenges:\n(i) ensuring strong security guarantees, such as Indistinguishability under\nChosen-Plaintext Attack (IND-CPA), under practical assumptions (e.g., we avoid\noverly optimistic assumptions like non-collusion among parties); and (ii)\nmaintaining performance overheads comparable to traditional, non-federated RAG\nsystems. To address these challenges, FRAG employs a single-key homomorphic\nencryption protocol that simplifies key management across mutually-distrusted\nparties. Additionally, FRAG introduces a \\textit{multiplicative caching}\ntechnique to efficiently encrypt floating-point numbers, significantly\nimproving computational performance in large-scale federated environments. We\nprovide a rigorous security proof using standard cryptographic reductions and\ndemonstrate the practical scalability and efficiency of FRAG through extensive\nexperiments on both benchmark and real-world datasets.",
    "pdf_url": "http://arxiv.org/pdf/2410.13272v1",
    "published": "2024-10-17T06:57:29+00:00",
    "categories": [
      "cs.CR",
      "cs.DB"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13271v2",
    "title": "Inductive Gradient Adjustment For Spectral Bias In Implicit Neural Representations",
    "authors": [
      "Kexuan Shi",
      "Hai Chen",
      "Leheng Zhang",
      "Shuhang Gu"
    ],
    "abstract": "Implicit Neural Representations (INRs), as a versatile representation\nparadigm, have achieved success in various computer vision tasks. Due to the\nspectral bias of the vanilla multi-layer perceptrons (MLPs), existing methods\nfocus on designing MLPs with sophisticated architectures or repurposing\ntraining techniques for highly accurate INRs. In this paper, we delve into the\nlinear dynamics model of MLPs and theoretically identify the empirical Neural\nTangent Kernel (eNTK) matrix as a reliable link between spectral bias and\ntraining dynamics. Based on this insight, we propose a practical Inductive\nGradient Adjustment (IGA) method, which could purposefully improve the spectral\nbias via inductive generalization of eNTK-based gradient transformation matrix.\nTheoretical and empirical analyses validate impacts of IGA on spectral bias.\nFurther, we evaluate our method on different INRs tasks with various INR\narchitectures and compare to existing training techniques. The superior and\nconsistent improvements clearly validate the advantage of our IGA. Armed with\nour gradient adjustment method, better INRs with more enhanced texture details\nand sharpened edges can be learned from data by tailored impacts on spectral\nbias.",
    "pdf_url": "http://arxiv.org/pdf/2410.13271v2",
    "published": "2024-10-17T06:51:10+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13270v1",
    "title": "Quantum Coulomb drag mediated by cotunneling of fluxons and Cooper pairs",
    "authors": [
      "Andrew G. Semenov",
      "Alex Latyshev",
      "Andrei D. Zaikin"
    ],
    "abstract": "We predict two novel quantum drag effects which can occur in macroscopically\nquantum coherent Josephson circuits. We demonstrate that biasing one\nresistively shunted Josephson junction by an external current one can induce a\nnon-zero voltage drop across another such junction capacitively coupled to the\nfirst one. This quantum Coulomb drag is caused by cotunneling of magnetic flux\nquanta across both junctions which remain in the \"superconducting\" regime.\nLikewise, Cooper pair cotunneling across a pair of connected in series\nJosephson junctions in the \"insulating\" regime is responsible for another --\ndual -- quantum Coulomb drag effect.",
    "pdf_url": "http://arxiv.org/pdf/2410.13270v1",
    "published": "2024-10-17T06:44:48+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2410.13269v1",
    "title": "Designing tungsten armoured plasma facing components to pulsed heat loads in magnetic fusion machines",
    "authors": [
      "R Mitteau",
      "M Diez",
      "M Firdaouss"
    ],
    "abstract": "A possible design rule for preventing surface damage from thermal transients\nto solid tungsten armour is proposed and formulated for the plasma facing\ncomponents (divertor, first wall) of magnetic fusion machines. The rule is\nbased on combined results from laboratory experiments and operating fusion\nmachines, and fundamental engineering principles such as the heat flux factor\n(FHF) and fatigue usage fraction (FUF). As an example, the rule would allow\n2.10 4 transient heat loads cycles at a FHF of 10\nMJm${}^{-2}$s${}^{-\\frac{1}{2}}$ before the lifetime is considered exhausted.\nThe formulation of the rule using engineering principles allows combining loads\nof different magnitudes and various number of cycles. A practical example of\nthe rule usage is provided, illustrating loads combination and how the rule may\ncontribute to the component geometrical design. The proposed rule is only valid\nfor surface loading conditions, hence is not usable for volumetric loading\nconditions such as runaway electrons. Setting a budget lifetime and a design\nrule does not preclude actual plasma operation beyond the design lifetime. It\nis actually normal that experimental devices explore a larger domain than the\none defined at the time of the design.",
    "pdf_url": "http://arxiv.org/pdf/2410.13269v1",
    "published": "2024-10-17T06:44:38+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.00784v2",
    "title": "FIRE: Fact-checking with Iterative Retrieval and Verification",
    "authors": [
      "Zhuohan Xie",
      "Rui Xing",
      "Yuxia Wang",
      "Jiahui Geng",
      "Hasan Iqbal",
      "Dhruv Sahnan",
      "Iryna Gurevych",
      "Preslav Nakov"
    ],
    "abstract": "Fact-checking long-form text is challenging, and it is therefore common\npractice to break it down into multiple atomic claims. The typical approach to\nfact-checking these atomic claims involves retrieving a fixed number of pieces\nof evidence, followed by a verification step. However, this method is usually\nnot cost-effective, as it underutilizes the verification model's internal\nknowledge of the claim and fails to replicate the iterative reasoning process\nin human search strategies. To address these limitations, we propose FIRE, a\nnovel agent-based framework that integrates evidence retrieval and claim\nverification in an iterative manner. Specifically, FIRE employs a unified\nmechanism to decide whether to provide a final answer or generate a subsequent\nsearch query, based on its confidence in the current judgment. We compare FIRE\nwith other strong fact-checking frameworks and find that it achieves slightly\nbetter performance while reducing large language model (LLM) costs by an\naverage of 7.6 times and search costs by 16.5 times. These results indicate\nthat FIRE holds promise for application in large-scale fact-checking\noperations. Our code is available at https://github.com/mbzuai-nlp/fire.git.",
    "pdf_url": "http://arxiv.org/pdf/2411.00784v2",
    "published": "2024-10-17T06:44:18+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13268v1",
    "title": "Roadmap towards Superhuman Speech Understanding using Large Language Models",
    "authors": [
      "Fan Bu",
      "Yuhao Zhang",
      "Xidong Wang",
      "Benyou Wang",
      "Qun Liu",
      "Haizhou Li"
    ],
    "abstract": "The success of large language models (LLMs) has prompted efforts to integrate\nspeech and audio data, aiming to create general foundation models capable of\nprocessing both textual and non-textual inputs. Recent advances, such as\nGPT-4o, highlight the potential for end-to-end speech LLMs, which preserves\nnon-semantic information and world knowledge for deeper speech understanding.\nTo guide the development of speech LLMs, we propose a five-level roadmap,\nranging from basic automatic speech recognition (ASR) to advanced superhuman\nmodels capable of integrating non-semantic information with abstract acoustic\nknowledge for complex tasks. Moreover, we design a benchmark, SAGI Bechmark,\nthat standardizes critical aspects across various tasks in these five levels,\nuncovering challenges in using abstract acoustic knowledge and completeness of\ncapability. Our findings reveal gaps in handling paralinguistic cues and\nabstract acoustic knowledge, and we offer future directions. This paper\noutlines a roadmap for advancing speech LLMs, introduces a benchmark for\nevaluation, and provides key insights into their current limitations and\npotential.",
    "pdf_url": "http://arxiv.org/pdf/2410.13268v1",
    "published": "2024-10-17T06:44:06+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13267v2",
    "title": "CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages Using Large Language Models",
    "authors": [
      "Shangda Wu",
      "Yashan Wang",
      "Ruibin Yuan",
      "Zhancheng Guo",
      "Xu Tan",
      "Ge Zhang",
      "Monan Zhou",
      "Jing Chen",
      "Xuefeng Mu",
      "Yuejie Gao",
      "Yuanliang Dong",
      "Jiafeng Liu",
      "Xiaobing Li",
      "Feng Yu",
      "Maosong Sun"
    ],
    "abstract": "Challenges in managing linguistic diversity and integrating various musical\nmodalities are faced by current music information retrieval systems. These\nlimitations reduce their effectiveness in a global, multimodal music\nenvironment. To address these issues, we introduce CLaMP 2, a system compatible\nwith 101 languages that supports both ABC notation (a text-based musical\nnotation format) and MIDI (Musical Instrument Digital Interface) for music\ninformation retrieval. CLaMP 2, pre-trained on 1.5 million ABC-MIDI-text\ntriplets, includes a multilingual text encoder and a multimodal music encoder\naligned via contrastive learning. By leveraging large language models, we\nobtain refined and consistent multilingual descriptions at scale, significantly\nreducing textual noise and balancing language distribution. Our experiments\nshow that CLaMP 2 achieves state-of-the-art results in both multilingual\nsemantic search and music classification across modalities, thus establishing a\nnew standard for inclusive and global music information retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2410.13267v2",
    "published": "2024-10-17T06:43:54+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13266v1",
    "title": "Continuous agent-based modeling of adult-child pairs based on a pseudo-energy: Relevance for public safety and egress efficiency",
    "authors": [
      "Chuan-Zhi Thomas Xie",
      "Tie-Qiao Tang",
      "Alexandre Nicolas"
    ],
    "abstract": "Pushes, falls, stampedes, and crushes are safety hazards that emerge from the\ncollective motion of crowds, but might be avoided by better design and\nguidance. While pedestrian dynamics are now getting better understood on the\nwhole, complex heterogeneous flows involvinge.g. adult-child pairs, though\nwidely found at e.g. crowded Chinese training schools, still defy the current\nunderstanding and capabilities of crowd simulation models. We substantially\nextend a recent agent-based model in which each agent's choice of motion\nresults from the minimization ofa sum of intuitive contributions, in order to\nintegrate adult-child pairs. This is achieved by adding a suitably defined\npairing potential. The resulting model captures the relative positions of pair\nmembers in a quantitative fashion, as confirmed by small-scale controlled\nexperiments, and alsosucceeds in describing collision avoidance between pairs.\nThe model is used to simulate mixed adult-child flows at a T-junction and test\nthe sensitivity to the design and pairing strategies. Simulation shows that\nmaking the post-confluence corridor wide enough is critical to avoidfriction in\nthe flow, and that tight hand-holding is advisable for safer evacuations\n(whereas more loosely bound pairs get split at high density) and, more\nmarginally, more efficient egresses in normal conditions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13266v1",
    "published": "2024-10-17T06:41:09+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13265v2",
    "title": "Concentrated Superelliptical Market Maker",
    "authors": [
      "Vasily Tolstikov"
    ],
    "abstract": "An automated market maker where the price can cross the zero bound into the\nnegative price domain with applications in electricity, energy, and derivatives\nmarkets is presented. A unique feature involves the ability to swap both\nnegatively and positively priced assets between one another, which unlike\ntraditional markets requires a numeraire in the form of a currency. Model\nextensions to skew and concentrate liquidity are shown. The liquidity\nfingerprint, payoff, and invariant are compared to the Black-Scholes covered\ncall and the Logarithmic Market Scoring Rule invariants.",
    "pdf_url": "http://arxiv.org/pdf/2410.13265v2",
    "published": "2024-10-17T06:39:34+00:00",
    "categories": [
      "q-fin.TR"
    ],
    "primary_category": "q-fin.TR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13264v1",
    "title": "The Latent Road to Atoms: Backmapping Coarse-grained Protein Structures with Latent Diffusion",
    "authors": [
      "Xu Han",
      "Yuancheng Sun",
      "Kai Chen",
      "Kang Liu",
      "Qiwei Ye"
    ],
    "abstract": "Coarse-grained(CG) molecular dynamics simulations offer computational\nefficiency for exploring protein conformational ensembles and thermodynamic\nproperties. Though coarse representations enable large-scale simulations across\nextended temporal and spatial ranges, the sacrifice of atomic-level details\nlimits their utility in tasks such as ligand docking and protein-protein\ninteraction prediction. Backmapping, the process of reconstructing all-atom\nstructures from coarse-grained representations, is crucial for recovering these\nfine details. While recent machine learning methods have made strides in\nprotein structure generation, challenges persist in reconstructing diverse\natomistic conformations that maintain geometric accuracy and chemical validity.\nIn this paper, we present Latent Diffusion Backmapping (LDB), a novel approach\nleveraging denoising diffusion within latent space to address these challenges.\nBy combining discrete latent encoding with diffusion, LDB bypasses the need for\nequivariant and internal coordinate manipulation, significantly simplifying the\ntraining and sampling processes as well as facilitating better and wider\nexploration in configuration space. We evaluate LDB's state-of-the-art\nperformance on three distinct protein datasets, demonstrating its ability to\nefficiently reconstruct structures with high structural accuracy and chemical\nvalidity. Moreover, LDB shows exceptional versatility in capturing diverse\nprotein ensembles, highlighting its capability to explore intricate\nconformational spaces. Our results position LDB as a powerful and scalable\napproach for backmapping, effectively bridging the gap between CG simulations\nand atomic-level analyses in computational biology.",
    "pdf_url": "http://arxiv.org/pdf/2410.13264v1",
    "published": "2024-10-17T06:38:07+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13263v2",
    "title": "A Simplifying and Learnable Graph Convolutional Attention Network for Unsupervised Knowledge Graphs Alignment",
    "authors": [
      "Weishan Cai",
      "Wenjun Ma",
      "Yuncheng Jiang"
    ],
    "abstract": "The success of current Entity Alignment (EA) task depends largely on the\nsupervision information provided by labeled data. Considering the cost of\nlabeled data, most supervised methods are difficult to apply in practical\nscenarios. Therefore, more and more works based on contrastive learning, active\nlearning or other deep learning techniques have been developed, to solve the\nperformance bottleneck caused by the lack of labeled data. However, the\nexisting unsupervised EA methods still have some limitations, either their\nmodeling complexity is high or they cannot balance the effectiveness and\npracticality of alignment. To overcome these issues, we propose a Simplifying\nand Learnable graph convolutional attention network for Unsupervised Knowledge\nGraphs alignment method (SLU). Specifically, we first introduce LCAT, a new and\nsimple framework as the backbone network to model the graph structure of two\nKGs. Then we design a reconstruction method of relation structure based on\npotential matching relations for efficiently filtering invalid neighborhood\ninformation of aligned entities, to improve the usability and scalability of\nSLU. Impressively, a similarity function based on consistency is proposed to\nbetter measure the similarity of candidate entity pairs. Finally, we conduct\nextensive experiments on three datasets of different sizes (15K and 100K) and\ndifferent types (cross-lingual and monolingual) to verify the superiority of\nSLU. Experimental results show that SLU significantly improves alignment\naccuracy, outperforming 25 supervised or unsupervised methods, and improving\n6.4% in Hits@1 over the best baseline in the best case.",
    "pdf_url": "http://arxiv.org/pdf/2410.13263v2",
    "published": "2024-10-17T06:37:46+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13262v2",
    "title": "Membership Testing for Semantic Regular Expressions",
    "authors": [
      "Yifei Huang",
      "Matin Amini",
      "Alexis Le Glaunec",
      "Konstantinos Mamouras",
      "Mukund Raghothaman"
    ],
    "abstract": "SMORE (Chen et al., 2023) recently proposed the concept of semantic regular\nexpressions that extend the classical formalism with a primitive to query\nexternal oracles such as databases and large language models (LLMs). Such\npatterns can be used to identify lines of text containing references to\nsemantic concepts such as cities, celebrities, political entities, etc. The\nfocus in their paper was on automatically synthesizing semantic regular\nexpressions from positive and negative examples. In this paper, we study the\nmembership testing problem:\n  First, We present a two-pass NFA-based algorithm to determine whether a\nstring $w$ matches a semantic regular expression (SemRE) $r$ in $O(|r|^2 |w|^2\n+ |r| |w|^3)$ time, assuming the oracle responds to each query in unit time. In\ncommon situations, where oracle queries are not nested, we show that this\nprocedure runs in $O(|r|^2 |w|^2)$ time. Experiments with a prototype\nimplementation of this algorithm validate our theoretical analysis, and show\nthat the procedure massively outperforms a dynamic programming-based baseline,\nand incurs a $\\approx 2 \\times$ overhead over the time needed for interaction\nwith the oracle.\n  Next, We establish connections between SemRE membership testing and the\ntriangle finding problem from graph theory, which suggest that developing\nalgorithms which are simultaneously practical and asymptotically faster might\nbe challenging. Furthermore, algorithms for classical regular expressions\nprimarily aim to optimize their time and memory consumption. In contrast, an\nimportant consideration in our setting is to minimize the cost of invoking the\noracle. We demonstrate an $\\Omega(|w|^2)$ lower bound on the number of oracle\nqueries necessary to make this determination.",
    "pdf_url": "http://arxiv.org/pdf/2410.13262v2",
    "published": "2024-10-17T06:33:16+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13261v1",
    "title": "Novel Bayesian algorithms for ARFIMA long-memory processes: a comparison between MCMC and ABC approaches",
    "authors": [
      "James Cohen Gabor",
      "Clara Grazian"
    ],
    "abstract": "This paper presents a comparative study of two Bayesian approaches - Markov\nChain Monte Carlo (MCMC) and Approximate Bayesian Computation (ABC) - for\nestimating the parameters of autoregressive fractionally-integrated moving\naverage (ARFIMA) models, which are widely used to capture long-memory in time\nseries data. We propose a novel MCMC algorithm that filters the time series\ninto distinct long-memory and ARMA components, and benchmarked it against\nstandard approaches. Additionally, a new ABC method is proposed, using three\ndifferent summary statistics used for posterior estimation. The methods are\nimplemented and evaluated through an extensive simulation study, as well as\napplied to a real-world financial dataset, specifically the quarterly U.S.\nGross National Product (GNP) series. The results demonstrate the effectiveness\nof the Bayesian methods in estimating long-memory and short-memory parameters,\nwith the filtered MCMC showing superior performance in various metrics. This\nstudy enhances our understanding of Bayesian techniques in ARFIMA modeling,\nproviding insights into their advantages and limitations when applied to\ncomplex time series data.",
    "pdf_url": "http://arxiv.org/pdf/2410.13261v1",
    "published": "2024-10-17T06:32:37+00:00",
    "categories": [
      "stat.ME",
      "stat.CO"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13260v3",
    "title": "Cyber Attacks Prevention Towards Prosumer-based EV Charging Stations: An Edge-assisted Federated Prototype Knowledge Distillation Approach",
    "authors": [
      "Luyao Zou",
      "Quang Hieu Vo",
      "Kitae Kim",
      "Huy Q. Le",
      "Chu Myaet Thwal",
      "Chaoning Zhang",
      "Choong Seon Hong"
    ],
    "abstract": "In this paper, cyber-attack prevention for the prosumer-based electric\nvehicle (EV) charging stations (EVCSs) is investigated, which covers two\naspects: 1) cyber-attack detection on prosumers' network traffic (NT) data, and\n2) cyber-attack intervention. To establish an effective prevention mechanism,\nseveral challenges need to be tackled, for instance, the NT data per prosumer\nmay be non-independent and identically distributed (non-IID), and the boundary\nbetween benign and malicious traffic becomes blurred. To this end, we propose\nan edge-assisted federated prototype knowledge distillation (E-FPKD) approach,\nwhere each client is deployed on a dedicated local edge server (DLES) and can\nreport its availability for joining the federated learning (FL) process. Prior\nto the E-FPKD approach, to enhance accuracy, the Pearson Correlation\nCoefficient is adopted for feature selection. Regarding the proposed E-FPKD\napproach, we integrate the knowledge distillation and prototype aggregation\ntechnique into FL to deal with the non-IID challenge. To address the boundary\nissue, instead of directly calculating the distance between benign and\nmalicious traffic, we consider maximizing the overall detection correctness of\nall prosumers (ODC), which can mitigate the computational cost compared with\nthe former way. After detection, a rule-based method will be triggered at each\nDLES for cyber-attack intervention. Experimental analysis demonstrates that the\nproposed E-FPKD can achieve the largest ODC on NSL-KDD, UNSW-NB15, and IoTID20\ndatasets in both binary and multi-class classification, compared with\nbaselines. For instance, the ODC for IoTID20 obtained via the proposed method\nis separately 0.3782% and 4.4471% greater than FedProto and FedAU in\nmulti-class classification.",
    "pdf_url": "http://arxiv.org/pdf/2410.13260v3",
    "published": "2024-10-17T06:31:55+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13259v1",
    "title": "From Babbling to Fluency: Evaluating the Evolution of Language Models in Terms of Human Language Acquisition",
    "authors": [
      "Qiyuan Yang",
      "Pengda Wang",
      "Luke D. Plonsky",
      "Frederick L. Oswald",
      "Hanjie Chen"
    ],
    "abstract": "We examine the language capabilities of language models (LMs) from the\ncritical perspective of human language acquisition. Building on classical\nlanguage development theories, we propose a three-stage framework to assess the\nabilities of LMs, ranging from preliminary word understanding to complex\ngrammar and complex logical reasoning. Using this framework, we evaluate the\ngenerative capacities of LMs using methods from linguistic research. Results\nindicate that although recent LMs outperform earlier models in overall\nperformance, their developmental trajectory does not strictly follow the path\nof human language acquisition. Notably, in generation tasks, LMs are more\nsimilar to human performance in areas where information is easier to extract\nfrom the corpus, such as average word length, clauses, and auxiliary verbs.\nNewer LMs did not exhibit significant progress in terms of specific dimensions,\nsuch as clauses and auxiliary verbs, where the variation across corpora is\nrelatively limited. Register theory offers a plausible explanation for these\nobservations, suggesting that the linguistic features of the training data have\na substantial impact on the models' abilities.",
    "pdf_url": "http://arxiv.org/pdf/2410.13259v1",
    "published": "2024-10-17T06:31:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13258v4",
    "title": "How Does Knowledge Selection Help Retrieval Augmented Generation?",
    "authors": [
      "Xiangci Li",
      "Jessica Ouyang"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is a powerful method for enhancing\nnatural language generation by integrating external knowledge into a model's\noutput. While prior work has demonstrated the importance of improving knowledge\nretrieval for boosting generation quality, the role of knowledge selection,\na.k.a. reranking or filtering, remains less clear. This paper empirically\nanalyzes how knowledge selection influences downstream generation performance\nin RAG systems. By simulating different retrieval and selection conditions\nthrough a controlled mixture of gold and distractor knowledge, we assess the\nimpact of these factors on generation outcomes. Our findings indicate that the\ndownstream generator model's capability, as well as the complexity of the task\nand dataset, significantly influence the impact of knowledge selection on the\noverall RAG system performance. In typical scenarios, improving the knowledge\nrecall score is key to enhancing generation outcomes, with the knowledge\nselector providing limited benefit when a strong generator model is used on\nclear, well-defined tasks. For weaker generator models or more ambiguous tasks\nand datasets, the knowledge F1 score becomes a critical factor, and the\nknowledge selector plays a more prominent role in improving overall\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13258v4",
    "published": "2024-10-17T06:30:55+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13257v1",
    "title": "scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers",
    "authors": [
      "Dian Meng",
      "Bohao Xing",
      "Xinlei Huang",
      "Yanran Liu",
      "Yijun Zhou",
      "Yongjun xiao",
      "Zitong Yu",
      "Xubin Zheng"
    ],
    "abstract": "Single-cell multi-omics (scMulti-omics) refers to the paired multimodal data,\nsuch as Cellular Indexing of Transcriptomes and Epitopes by Sequencing\n(CITE-seq), where the regulation of each cell was measured from different\nmodalities, i.e. genes and proteins. scMulti-omics can reveal heterogeneity\ninside tumors and understand the distinct genetic properties of diverse cell\ntypes, which is crucial to targeted therapy. Currently, deep learning methods\nbased on attention structures in the bioinformatics area face two challenges.\nThe first challenge is the vast number of genes in a single cell. Traditional\nattention-based modules struggled to effectively leverage all gene information\ndue to their limited capacity for long-context learning and high-complexity\ncomputing. The second challenge is that genes in the human genome are ordered\nand influence each other's expression. Most of the methods ignored this\nsequential information. The recently introduced Test-Time Training (TTT) layer\nis a novel sequence modeling approach, particularly suitable for handling long\ncontexts like genomics data because TTT layer is a linear complexity sequence\nmodeling structure and is better suited to data with sequential relationships.\nIn this paper, we propose scFusionTTT, a novel method for Single-Cell\nmultimodal omics Fusion with TTT-based masked autoencoder. Of note, we combine\nthe order information of genes and proteins in the human genome with the TTT\nlayer, fuse multimodal omics, and enhance unimodal omics analysis. Finally, the\nmodel employs a three-stage training strategy, which yielded the best\nperformance across most metrics in four multimodal omics datasets and four\nunimodal omics datasets, demonstrating the superior performance of our model.\nThe dataset and code will be available on\nhttps://github.com/DM0815/scFusionTTT.",
    "pdf_url": "http://arxiv.org/pdf/2410.13257v1",
    "published": "2024-10-17T06:29:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13256v1",
    "title": "The Milky Way Radial Metallicity Gradient as an Equilibrium Phenomenon: Why Old Stars are Metal-Rich",
    "authors": [
      "James W. Johnson",
      "David H. Weinberg",
      "Guillermo A. Blanc",
      "Ana Bonaca",
      "Gwen C. Rudie",
      "Yuxi",
      "Lu",
      "Bronwyn Reichardt Chu",
      "Emily J. Griffith",
      "Tawny Sit",
      "Jennifer A. Johnson",
      "Liam O. Dubay",
      "Miqaela K. Weller",
      "Daniel A. Boyea",
      "Jonathan C. Bird"
    ],
    "abstract": "Metallicities of both gas and stars decline toward large radii in spiral\ngalaxies, a trend known as the radial metallicity gradient. We quantify the\nevolution of the metallicity gradient in the Milky Way as traced by APOGEE red\ngiants with age estimates from machine learning algorithms. Stars up to ages of\n$\\sim$9 Gyr follow a similar relation between metallicity and Galactocentric\nradius. This constancy challenges current models of Galactic chemical\nevolution, which typically predict lower metallicities for older stellar\npopulations. Our results favor an equilibrium scenario, in which the gas-phase\ngradient reaches a nearly constant normalization early in the disk lifetime.\nUsing a fiducial choice of parameters, we demonstrate that one possible origin\nof this behavior is an outflow that more readily ejects gas from the\ninterstellar medium with increasing Galactocentric radius. A direct effect of\nthe outflow is that baryons do not remain in the interstellar medium for long,\nwhich causes the ratio of star formation to accretion, $\\dot{\\Sigma}_\\star /\n\\dot{\\Sigma}_\\text{in}$, to quickly become constant. This ratio is closely\nrelated to the local equilibrium metallicity, since its numerator and\ndenominator set the rates of metal production by stars and hydrogen gained\nthrough accretion, respectively. Building in a merger event results in a\nperturbation that evolves back toward the equilibrium state on $\\sim$Gyr\ntimescales. Under the equilibrium scenario, the radial metallicity gradient is\nnot a consequence of the inside-out growth of the disk but instead reflects a\ntrend of declining $\\dot{\\Sigma}_\\star / \\dot{\\Sigma}_\\text{in}$ with\nincreasing Galactocentric radius.",
    "pdf_url": "http://arxiv.org/pdf/2410.13256v1",
    "published": "2024-10-17T06:27:36+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13255v1",
    "title": "Automatic Translation Alignment Pipeline for Multilingual Digital Editions of Literary Works",
    "authors": [
      "Maria Levchenko"
    ],
    "abstract": "This paper investigates the application of translation alignment algorithms\nin the creation of a Multilingual Digital Edition (MDE) of Alessandro Manzoni's\nItalian novel \"I promessi sposi\" (\"The Betrothed\"), with translations in eight\nlanguages (English, Spanish, French, German, Dutch, Polish, Russian and\nChinese) from the 19th and 20th centuries. We identify key requirements for the\nMDE to improve both the reader experience and support for translation studies.\nOur research highlights the limitations of current state-of-the-art algorithms\nwhen applied to the translation of literary texts and outlines an automated\npipeline for MDE creation. This pipeline transforms raw texts into web-based,\nside-by-side representations of original and translated texts with different\nrendering options. In addition, we propose new metrics for evaluating the\nalignment of literary translations and suggest visualization techniques for\nfuture analysis.",
    "pdf_url": "http://arxiv.org/pdf/2410.13255v1",
    "published": "2024-10-17T06:21:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68U15",
      "J.5; I.7.4"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13254v2",
    "title": "Lyman Continuum leakage from massive leaky starbursts: A different class of emitters?",
    "authors": [
      "Namrata Roy",
      "Timothy Heckman",
      "Alaina Henry",
      "John Chisholm",
      "Sophia Flury",
      "Claus Leitherer",
      "Matthew J. Hayes",
      "Anne Jaskot",
      "Zhiyuan Ji",
      "Daniel Schaerer",
      "Bingjie Wang",
      "Sanchayeeta Borthakur",
      "Xinfeng Xu",
      "Göran Östlin"
    ],
    "abstract": "The origin of Lyman Continuum (LyC) photons responsible for reionizing the\nuniverse remains a mystery, with the fraction of escaping LyC photons from\ngalaxies at z$\\sim$ 6 to 12 being highly uncertain. While direct detection of\nLyC photons from this epoch is hindered by absorption from the intergalactic\nmedium, lower redshift analogs offer a promising avenue to study LyC leakage.\nWe present Hubble Space Telescope Cosmic Origins Spectrograph (HST COS)\nobservations of five low redshift (z$\\sim$ 0.3) massive starburst galaxies,\nselected for their high stellar mass and weak [SII] nebular emission - an\nindirect tracer of LyC escape. Three of the five galaxies show LyC leakage,\nhighlighting the reliability of weak [SII] as a tracer, especially in light of\nrecent JWST discoveries of z $>$ 5 galaxies with similarly weak [SII] emission.\nThe dust corrected LyC escape fractions, which represent the LyC photons that\nwould escape in the absence of dust, range from 33% to 84%. However, the\nabsolute escape fractions, which show the LyC photons escaping after passing\nthrough both neutral hydrogen absorption and dust attenuation, are\nsignificantly lower, ranging between 1% and 3%. This suggests that while the\ngalaxies are nearly optically thin to HI, their high dust content significantly\nsuppresses LyC photon escape. These [SII] weak, massive leakers are distinct\nfrom typical low-redshift LyC emitters, showing higher metallicity, lower\nionization states, more dust extinction and higher star formation surface\ndensities. This suggests that these galaxies constitute a distinct population,\nlikely governed by a different mechanism facilitating LyC photon escape. We\npropose that the feedback-driven winds in these compact starbursts create\nionized channels through which LyC photons escape, aligning with a picket-fence\nmodel.",
    "pdf_url": "http://arxiv.org/pdf/2410.13254v2",
    "published": "2024-10-17T06:21:22+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13253v7",
    "title": "Conditional Denoising Meets Polynomial Modeling: A Flexible Decoupled Framework for Time Series Forecasting",
    "authors": [
      "Jintao Zhang",
      "Mingyue Cheng",
      "Xiaoyu Tao",
      "Zhiding Liu",
      "Daoyu Wang"
    ],
    "abstract": "Time series forecasting models are becoming increasingly prevalent due to\ntheir critical role in decision-making across various domains. However, most\nexisting approaches represent the coupled temporal patterns, often neglecting\nthe distinction between their specific components. In particular, fluctuating\npatterns and smooth trends within time series exhibit distinct characteristics.\nIn this work, to model complicated temporal patterns, we propose a Conditional\nDenoising Polynomial Modeling (CDPM) framework, where probabilistic diffusion\nmodels and deterministic linear models are trained end-to-end. Instead of\nmodeling the coupled time series, CDPM decomposes it into trend and seasonal\ncomponents for modeling them separately. To capture the fluctuating seasonal\ncomponent, we employ a probabilistic diffusion model based on statistical\nproperties from the historical window. For the smooth trend component, a module\nis proposed to enhance linear models by incorporating historical dependencies,\nthereby preserving underlying trends and mitigating noise distortion. Extensive\nexperiments conducted on six benchmarks demonstrate the effectiveness of our\nframework, highlighting the potential of combining probabilistic and\ndeterministic models. Our code is available at https://github.com/zjt-gpu/CDPM.",
    "pdf_url": "http://arxiv.org/pdf/2410.13253v7",
    "published": "2024-10-17T06:20:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13252v1",
    "title": "Topological quantum slinky motion in resonant extended Bose-Hubbard model",
    "authors": [
      "H. P. Zhang",
      "Z. Song"
    ],
    "abstract": "We study the one-dimensional Bose-Hubbard model under the resonant condition,\nwhere a series of quantum slinky oscillations occur in a two-site system for\nboson numbers $n\\in \\lbrack 2,\\infty )$. In the strong interaction limit, it\ncan be shown that the quantum slinky motions become the dominant channels for\nboson propagation, which are described by a set of effective non-interacting\nHamiltonians. They are sets of generalized Su-Schrieffer-Heeger chains with an\n$n$-site unit cell, referred to as trimerization, tetramerization, and\npentamerization, etc., possessing non-trivial Zak phases. The corresponding\nedge states are demonstrated by the $n$-boson bound states at the ends of the\nchains. We also investigate the dynamic detection of edge boson clusters\nthrough an analysis of quench dynamics. Numerical results indicate that stable\nedge oscillations clearly manifest the interaction-induced topological features\nwithin the extended Bose-Hubbard model.",
    "pdf_url": "http://arxiv.org/pdf/2410.13252v1",
    "published": "2024-10-17T06:20:09+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13251v1",
    "title": "Controllability and Observability of Heterogeneous Networked Systems with Non-uniform Node Dimensions and Distinct Inner-Coupling Matrices",
    "authors": [
      "Aleena Thomas",
      "Abhijith Ajayakumar",
      "Raju K. George"
    ],
    "abstract": "In this paper we extend the work in the conference paper 'On the\nControllability and Observability of Heterogeneous Networked Systems with\ndistinct node dimensions and inner-coupling matrices' wherein the\ncontrollability and observability of a heterogeneous networked system with\ndistinct node dimensions were studied. This paper adds to the conference paper\na necessary and sufficient condition for controllability of the networked\nsystem. The result demonstrates the dependence of controllability of the\nnetwork on factors like network topology, inner interactions among nodes and\nnodal dynamics. The result is formulated by characterizing the left\neigenvectors of the network state matrix. Another necessary and sufficient\ncondition for controllability, which is a reformulation of the\n\\textit{Popov-Belevitch-Hautus} controllability condition, a necessary and\nsufficient condition for observability of the networked system and certain\nnecessary conditions for controllability of the networked system are the other\nresults established in this paper. Variants of these results under certain\nspecific network topologies like path, cycle, star and wheel are also\ndiscussed.",
    "pdf_url": "http://arxiv.org/pdf/2410.13251v1",
    "published": "2024-10-17T06:18:48+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13250v1",
    "title": "Perceptions of Discriminatory Decisions of Artificial Intelligence: Unpacking the Role of Individual Characteristics",
    "authors": [
      "Soojong Kim"
    ],
    "abstract": "This study investigates how personal differences (digital self-efficacy,\ntechnical knowledge, belief in equality, political ideology) and demographic\nfactors (age, education, and income) are associated with perceptions of\nartificial intelligence (AI) outcomes exhibiting gender and racial bias and\nwith general attitudes towards AI. Analyses of a large-scale experiment dataset\n(N = 1,206) indicate that digital self-efficacy and technical knowledge are\npositively associated with attitudes toward AI, while liberal ideologies are\nnegatively associated with outcome trust, higher negative emotion, and greater\nskepticism. Furthermore, age and income are closely connected to cognitive gaps\nin understanding discriminatory AI outcomes. These findings highlight the\nimportance of promoting digital literacy skills and enhancing digital\nself-efficacy to maintain trust in AI and beliefs in AI usefulness and safety.\nThe findings also suggest that the disparities in understanding problematic AI\noutcomes may be aligned with economic inequalities and generational gaps in\nsociety. Overall, this study sheds light on the socio-technological system in\nwhich complex interactions occur between social hierarchies, divisions, and\nmachines that reflect and exacerbate the disparities.",
    "pdf_url": "http://arxiv.org/pdf/2410.13250v1",
    "published": "2024-10-17T06:18:26+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13249v1",
    "title": "Annealed Stein Variational Gradient Descent for Improved Uncertainty Estimation in Full-Waveform Inversion",
    "authors": [
      "Miguel Corrales",
      "Sean Berti",
      "Bertrand Denel",
      "Paul Williamson",
      "Mattia Aleardi",
      "Matteo Ravasi"
    ],
    "abstract": "In recent years, Full-Waveform Inversion (FWI) has been extensively used to\nderive high-resolution subsurface velocity models from seismic data. However,\ndue to the nonlinearity and ill-posed nature of the problem, FWI requires a\ngood starting model to avoid producing non-physical solutions. Moreover,\nconventional optimization methods fail to quantify the uncertainty associated\nwith the recovered solution, which is critical for decision-making processes.\nBayesian inference offers an alternative approach as it directly or indirectly\nevaluates the posterior probability density function. For example, Markov Chain\nMonte Carlo (MCMC) methods generate multiple sample chains to characterize the\nsolution's uncertainty. Despite their ability to theoretically handle any form\nof distribution, MCMC methods require many sampling steps; this limits their\nusage in high-dimensional problems with computationally intensive forward\nmodeling, as is the FWI case. Variational Inference (VI), on the other hand,\nprovides an approximate solution to the posterior distribution in the form of a\nparametric or non-parametric proposal distribution. Among the various\nalgorithms used in VI, Stein Variational Gradient Descent (SVGD) is recognized\nfor its ability to iteratively refine a set of samples to approximate the\ntarget distribution. However, mode and variance-collapse issues affect SVGD in\nhigh-dimensional inverse problems. This study aims to improve the performance\nof SVGD within the context of FWI by utilizing, for the first time, an annealed\nvariant of SVGD and combining it with a multi-scale strategy. Additionally, we\ndemonstrate that Principal Component Analysis (PCA) can be used to evaluate the\nperformance of the optimization process. Clustering techniques are also\nemployed to provide more rigorous and meaningful statistical analysis of the\nparticles in the presence of multi-modal distributions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13249v1",
    "published": "2024-10-17T06:15:26+00:00",
    "categories": [
      "physics.geo-ph",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13248v2",
    "title": "Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation",
    "authors": [
      "Ryotaro Shimizu",
      "Takashi Wada",
      "Yu Wang",
      "Johannes Kruse",
      "Sean O'Brien",
      "Sai HtaungKham",
      "Linxin Song",
      "Yuya Yoshikawa",
      "Yuki Saito",
      "Fugee Tsung",
      "Masayuki Goto",
      "Julian McAuley"
    ],
    "abstract": "Recent research on explainable recommendation generally frames the task as a\nstandard text generation problem, and evaluates models simply based on the\ntextual similarity between the predicted and ground-truth explanations.\nHowever, this approach fails to consider one crucial aspect of the systems:\nwhether their outputs accurately reflect the users' (post-purchase) sentiments,\ni.e., whether and why they would like and/or dislike the recommended items. To\nshed light on this issue, we introduce new datasets and evaluation methods that\nfocus on the users' sentiments. Specifically, we construct the datasets by\nexplicitly extracting users' positive and negative opinions from their\npost-purchase reviews using an LLM, and propose to evaluate systems based on\nwhether the generated explanations 1) align well with the users' sentiments,\nand 2) accurately identify both positive and negative opinions of users on the\ntarget items. We benchmark several recent models on our datasets and\ndemonstrate that achieving strong performance on existing metrics does not\nensure that the generated explanations align well with the users' sentiments.\nLastly, we find that existing models can provide more sentiment-aware\nexplanations when the users' (predicted) ratings for the target items are\ndirectly fed into the models as input. The datasets and benchmark\nimplementation are available at: https://github.com/jchanxtarov/sent_xrec.",
    "pdf_url": "http://arxiv.org/pdf/2410.13248v2",
    "published": "2024-10-17T06:15:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13247v2",
    "title": "Collaborative AI in Sentiment Analysis: System Architecture, Data Prediction and Deployment Strategies",
    "authors": [
      "Chaofeng Zhang",
      "Jia Hou",
      "Xueting Tan",
      "Gaolei Li",
      "Caijuan Chen"
    ],
    "abstract": "The advancement of large language model (LLM) based artificial intelligence\ntechnologies has been a game-changer, particularly in sentiment analysis. This\nprogress has enabled a shift from highly specialized research environments to\npractical, widespread applications within the industry. However, integrating\ndiverse AI models for processing complex multimodal data and the associated\nhigh costs of feature extraction presents significant challenges. Motivated by\nthe marketing oriented software development +needs, our study introduces a\ncollaborative AI framework designed to efficiently distribute and resolve tasks\nacross various AI systems to address these issues. Initially, we elucidate the\nkey solutions derived from our development process, highlighting the role of\ngenerative AI models like \\emph{chatgpt}, \\emph{google gemini} in simplifying\nintricate sentiment analysis tasks into manageable, phased objectives.\nFurthermore, we present a detailed case study utilizing our collaborative AI\nsystem in edge and cloud, showcasing its effectiveness in analyzing sentiments\nacross diverse online media channels.",
    "pdf_url": "http://arxiv.org/pdf/2410.13247v2",
    "published": "2024-10-17T06:14:34+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13246v2",
    "title": "Atomic Calibration of LLMs in Long-Form Generations",
    "authors": [
      "Caiqi Zhang",
      "Ruihan Yang",
      "Zhisong Zhang",
      "Xinting Huang",
      "Sen Yang",
      "Dong Yu",
      "Nigel Collier"
    ],
    "abstract": "Large language models (LLMs) often suffer from hallucinations, posing\nsignificant challenges for real-world applications. Confidence calibration,\nwhich estimates the underlying uncertainty of model predictions, is essential\nto enhance the LLMs' trustworthiness. Existing research on LLM calibration has\nprimarily focused on short-form tasks, providing a single confidence score at\nthe response level (macro calibration). However, this approach is insufficient\nfor long-form generations, where responses often contain more complex\nstatements and may include both accurate and inaccurate information. Therefore,\nwe introduce atomic calibration, a novel approach that evaluates factuality\ncalibration at a fine-grained level by breaking down long responses into atomic\nclaims. We classify confidence elicitation methods into discriminative and\ngenerative types and demonstrate that their combination can enhance\ncalibration. Our extensive experiments on various LLMs and datasets show that\natomic calibration is well-suited for long-form generation and can also improve\nmacro calibration results. Additionally, atomic calibration reveals insightful\npatterns in LLM confidence throughout the generation process.",
    "pdf_url": "http://arxiv.org/pdf/2410.13246v2",
    "published": "2024-10-17T06:09:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13245v1",
    "title": "A Unified Spectral Approach for Quasinormal Modes of Lee-Wick Black Holes",
    "authors": [
      "Davide Batic",
      "Denys Dutykh",
      "Breno Loureiro Giacchini"
    ],
    "abstract": "In this paper, we undertake a comprehensive examination of quasinormal modes\nlinked to Lee-Wick black holes, delving into scalar, electromagnetic, and\ngravitational perturbations using the spectral method. Such black holes can\ndisplay a rich structure of horizons, and our analysis considers all the\nrepresentative scenarios, including extremal and non-extremal situations. In\nparticular, we show that purely imaginary quasinormal modes emerge for extremal\nand near-extremal configurations, suggesting a rapid return to equilibrium\nwithout oscillation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13245v1",
    "published": "2024-10-17T06:05:57+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2410.13244v1",
    "title": "On statistical signatures of ISM turbulence in dust polarization maps",
    "authors": [
      "Ka Wai Ho",
      "Ka Ho Yuen",
      "Raphael Flauger",
      "Alexei G. Kritsuk"
    ],
    "abstract": "We present results from a high-resolution interstellar turbulence simulation\nand show that it closely reproduces recent $Planck$ measurements. Our model\ncaptures the scaling of $EE$ and $BB$ spectra, and the $EE/BB$ ratio in the\ninertial range. The PDF of the dust polarization fraction is also consistent\nwith observations. The $TE$ cross-correlation is in broad agreement with\nobservations. This simulation provides new insights into the physical origins\nof the observed $E/B$ asymmetry and positive $TE$ signal, facilitating the\ndevelopment of advanced Galactic dust emission models for current and future\nCMB experiments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13244v1",
    "published": "2024-10-17T06:01:50+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13243v1",
    "title": "Investigation on upstream ion events from L1 point observation: New Insights",
    "authors": [
      "Bijoy Dalal",
      "Dibyendu Chakrabarty",
      "Christina M. S. Cohen",
      "Nandita Srivastava"
    ],
    "abstract": "Origin of energetic upstream ions propagating towards the Sun from the\nEarth's bow shock is not understood clearly. In this letter, relationship\nbetween solar wind suprathermal and upstream ions has been investigated by\nanalyzing fluxes of H, 4He, and CNO obtained from multidirectional in-situ\nmeasurements at the first Lagrange point of the Sun-Earth system during\n2012-2014. 49 upstream events have been selected based on flux enhancements of\nthe upstream ions in comparison with the solar wind suprathermal ions. An\nenergy cut-off at less than 300 keV is observed for the upstream events. This\nis attributed to the efficacy of the particle acceleration process near the bow\nshock. Interestingly, spectra of upstream ions soften systematically as\ncompared to the spectra of their solar wind counterpart with decreasing mass of\nelements. The degree of spectral softening increases with decreasing\nmass-to-charge ratio of the species. Since during most of the events the\ninterplanetary magnetic field was radial, we argue that cross-field diffusion\nof upstream ions gives rise to the modulation (spectral softening) of upstream\nions, which is dependent on the mass-to-charge ratio of species. Our work\nindicates towards a systematic change in solar wind suprathermal ions after\ninteraction with the bow shock.",
    "pdf_url": "http://arxiv.org/pdf/2410.13243v1",
    "published": "2024-10-17T05:55:13+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "physics.plasm-ph",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13242v2",
    "title": "Fundus to Fluorescein Angiography Video Generation as a Retinal Generative Foundation Model",
    "authors": [
      "Weiyi Zhang",
      "Jiancheng Yang",
      "Ruoyu Chen",
      "Siyu Huang",
      "Pusheng Xu",
      "Xiaolan Chen",
      "Shanfu Lu",
      "Hongyu Cao",
      "Mingguang He",
      "Danli Shi"
    ],
    "abstract": "Fundus fluorescein angiography (FFA) is crucial for diagnosing and monitoring\nretinal vascular issues but is limited by its invasive nature and restricted\naccessibility compared to color fundus (CF) imaging. Existing methods that\nconvert CF images to FFA are confined to static image generation, missing the\ndynamic lesional changes. We introduce Fundus2Video, an autoregressive\ngenerative adversarial network (GAN) model that generates dynamic FFA videos\nfrom single CF images. Fundus2Video excels in video generation, achieving an\nFVD of 1497.12 and a PSNR of 11.77. Clinical experts have validated the\nfidelity of the generated videos. Additionally, the model's generator\ndemonstrates remarkable downstream transferability across ten external public\ndatasets, including blood vessel segmentation, retinal disease diagnosis,\nsystemic disease prediction, and multimodal retrieval, showcasing impressive\nzero-shot and few-shot capabilities. These findings position Fundus2Video as a\npowerful, non-invasive alternative to FFA exams and a versatile retinal\ngenerative foundation model that captures both static and temporal retinal\nfeatures, enabling the representation of complex inter-modality relationships.",
    "pdf_url": "http://arxiv.org/pdf/2410.13242v2",
    "published": "2024-10-17T05:53:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13241v2",
    "title": "Measuring Non-Hermitian Topological Invariants Directly from Quench Dynamics",
    "authors": [
      "Xiao-Dong Lin",
      "Long Zhang"
    ],
    "abstract": "While non-Hermitian (NH) topological phases and phenomena have been observed\nacross various quantum systems, directly measuring NH topological invariants\nremains a significant challenge. In this study, we present a generic and\nunified framework for the direct measurement of various NH topological\ninvariants in odd-dimensional systems through quench dynamics. We demonstrate\nthat in one-dimensional (1D) NH systems with sublattice symmetry, the line-gap\nwinding number and point-gap braiding degree can be extracted from the winding\npatterns of a dynamically constructed field based on post-quench spin textures.\nSpecifically, line-gap topology is characterized by integer-valued winding,\nwhereas point-gap complex-band braiding is revealed by half-integer or integer\nwinding with abrupt jumps. We also extend our approach to higher-dimensional\nwinding numbers and non-Bloch topological invariants under open-boundary\nconditions. Additionally, we propose a practical cold-atom setup to realize and\ndetect 1D NH topological phases, showing that our dynamical measurement scheme\nis feasible in current experimental settings. This work paves the way for the\ndirect measurement of NH topological invariants in quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13241v2",
    "published": "2024-10-17T05:48:45+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "cond-mat.mes-hall",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2410.19808v1",
    "title": "LocateBench: Evaluating the Locating Ability of Vision Language Models",
    "authors": [
      "Ting-Rui Chiang",
      "Joshua Robinson",
      "Xinyan Velocity Yu",
      "Dani Yogatama"
    ],
    "abstract": "The ability to locate an object in an image according to natural language\ninstructions is crucial for many real-world applications. In this work we\npropose LocateBench, a high-quality benchmark dedicated to evaluating this\nability. We experiment with multiple prompting approaches, and measure the\naccuracy of several large vision language models. We find that even the\naccuracy of the strongest model, GPT-4o, lags behind human accuracy by more\nthan 10%.",
    "pdf_url": "http://arxiv.org/pdf/2410.19808v1",
    "published": "2024-10-17T05:48:24+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13240v1",
    "title": "TRLO: An Efficient LiDAR Odometry with 3D Dynamic Object Tracking and Removal",
    "authors": [
      "Yanpeng Jia",
      "Ting Wang",
      "Xieyuanli Chen",
      "Shiliang Shao"
    ],
    "abstract": "Simultaneous state estimation and mapping is an essential capability for\nmobile robots working in dynamic urban environment. The majority of existing\nSLAM solutions heavily rely on a primarily static assumption. However, due to\nthe presence of moving vehicles and pedestrians, this assumption does not\nalways hold, leading to localization accuracy decreased and maps distorted. To\naddress this challenge, we propose TRLO, a dynamic LiDAR odometry that\nefficiently improves the accuracy of state estimation and generates a cleaner\npoint cloud map. To efficiently detect dynamic objects in the surrounding\nenvironment, a deep learning-based method is applied, generating detection\nbounding boxes. We then design a 3D multi-object tracker based on Unscented\nKalman Filter (UKF) and nearest neighbor (NN) strategy to reliably identify and\nremove dynamic objects. Subsequently, a fast two-stage iterative nearest point\nsolver is employed to solve the state estimation using cleaned static point\ncloud. Note that a novel hash-based keyframe database management is proposed\nfor fast access to search keyframes. Furthermore, all the detected object\nbounding boxes are leveraged to impose posture consistency constraint to\nfurther refine the final state estimation. Extensive evaluations and ablation\nstudies conducted on the KITTI and UrbanLoco datasets demonstrate that our\napproach not only achieves more accurate state estimation but also generates\ncleaner maps, compared with baselines.",
    "pdf_url": "http://arxiv.org/pdf/2410.13240v1",
    "published": "2024-10-17T05:47:45+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13239v1",
    "title": "On a relative dependency formula",
    "authors": [
      "Shashi Ranjan Sinha"
    ],
    "abstract": "Celikbas, Liang and Sadeghi established a one-sided inequality for the\nrelative version of Jorgensen's dependency formula and questioned whether it\nwould be an equality. In this paper, we show that the inequality can be indeed\nstrict, and prove a relative dependency formula. Along the way, we obtain some\nbounds on s(M,N), a notion related to the vanishing of relative homology of\nfinitely generated modules M and N over a local ring R, under specific\nassumptions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13239v1",
    "published": "2024-10-17T05:47:34+00:00",
    "categories": [
      "math.AC",
      "13D02, 13D05, 13D07"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13238v1",
    "title": "Global solvability and unboundedness in a fully parabolic quasilinear chemotaxis model with indirect signal production",
    "authors": [
      "Xuan Mao",
      "Yuxiang Li"
    ],
    "abstract": "This paper is concerned with a quasilinear chemotaxis model with indirect\nsignal production, $u_t = \\nabla\\cdot(D(u)\\nabla u - S(u)\\nabla v)$, $v_t =\n\\Delta v - v + w$ and $w_t = \\Delta w - w + u$, posed on a bounded smooth\ndomain $\\Omega\\subset\\mathbb R^n$, subjected to homogenerous Neumann boundary\nconditions, where nonlinear diffusion $D$ and sensitivity $S$ generalize the\nprototype $D(s) = (s+1)^{-\\alpha}$ and $S(s) = (s+1)^{\\beta-1}s$.\n  Ding and Wang [M.Ding and W.Wang, Discrete Contin. Dyn. Syst. Ser. B, 24\n(2019), 4665-4684.] showed that the system possesses a globally bounded\nclassical solution if $\\alpha + \\beta <\\min\\{1+2/n,4/n\\}$. While for the\nJ\\\"ager-Luckhaus variant of this model, namely the second equation replaced by\n$0=\\Delta v - \\int_\\Omega w/|\\Omega| + w$, Tao and Winkler [2023, preprint]\nannounced that if $\\alpha + \\beta > 4/n$ and $\\beta>2/n$ for $n\\geq3$, with\nradial assumptions, the variant admits occurrence of finite-time blowup.\n  We focus on the case $\\beta<2/n$, and prove that $\\beta < 2/n$ for $n\\geq2$\nis sufficient for global solvability of classical solutions; if $\\alpha + \\beta\n> 4/n$ for $n\\geq4$, then radially symmetric initial data with large negative\nenergy enforce blowup happening in finite or infinite time, both of which imply\nthat the system allows infinite-time blowup if $\\alpha + \\beta > 4/n$ and\n$\\beta < 2/n$ for $n\\geq 4$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13238v1",
    "published": "2024-10-17T05:45:57+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13237v2",
    "title": "Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis",
    "authors": [
      "Yiyi Chen",
      "Qiongxiu Li",
      "Russa Biswas",
      "Johannes Bjerva"
    ],
    "abstract": "Language Confusion is a phenomenon where Large Language Models (LLMs)\ngenerate text that is neither in the desired language, nor in a contextually\nappropriate language. This phenomenon presents a critical challenge in text\ngeneration by LLMs, often appearing as erratic and unpredictable behavior. We\nhypothesize that there are linguistic regularities to this inherent\nvulnerability in LLMs and shed light on patterns of language confusion across\nLLMs. We introduce a novel metric, Language Confusion Entropy, designed to\ndirectly measure and quantify this confusion, based on language distributions\ninformed by linguistic typology and lexical variation. Comprehensive\ncomparisons with the Language Confusion Benchmark (Marchisio et al., 2024)\nconfirm the effectiveness of our metric, revealing patterns of language\nconfusion across LLMs. We further link language confusion to LLM security, and\nfind patterns in the case of multilingual embedding inversion attacks. Our\nanalysis demonstrates that linguistic typology offers theoretically grounded\ninterpretation, and valuable insights into leveraging language similarities as\na prior for LLM alignment and security.",
    "pdf_url": "http://arxiv.org/pdf/2410.13237v2",
    "published": "2024-10-17T05:43:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "I.1.2; I.1.5"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.00783v1",
    "title": "From chalkboards to chatbots: SELAR assists teachers in embracing AI in the curriculum",
    "authors": [
      "Hani Alers",
      "Aleksandra Malinowska",
      "Mathis Mourey",
      "Jasper Waaijer"
    ],
    "abstract": "This paper introduces SELAR, a framework designed to effectively help\nteachers integrate artificial intelligence (AI) into their curriculum. The\nframework was designed by running workshops organized to gather lecturers'\nfeedback. In this paper, we assess the effectiveness of the framework through\nadditional workshops organized with lecturers from the Hague University of\nApplied Sciences. The workshops tested the application of the framework to\nadapt existing courses to leverage generative AI technology. Each participant\nwas tasked to apply SELAR to one of their learning goals in order to evaluate\nAI integration potential and, if successful, to update the teaching methods\naccordingly. Findings show that teachers were able to effectively use the SELAR\nto integrate generative AI into their courses. Future work will focus on\nproviding additional guidance and examples to use the framework more\neffectively.",
    "pdf_url": "http://arxiv.org/pdf/2411.00783v1",
    "published": "2024-10-17T05:40:59+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13236v1",
    "title": "SPIN: Self-Supervised Prompt INjection",
    "authors": [
      "Leon Zhou",
      "Junfeng Yang",
      "Chengzhi Mao"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in a variety of important\napplications, yet their safety and reliability remain as major concerns.\nVarious adversarial and jailbreak attacks have been proposed to bypass the\nsafety alignment and cause the model to produce harmful responses. We introduce\nSelf-supervised Prompt INjection (SPIN) which can detect and reverse these\nvarious attacks on LLMs. As our self-supervised prompt defense is done at\ninference-time, it is also compatible with existing alignment and adds an\nadditional layer of safety for defense. Our benchmarks demonstrate that our\nsystem can reduce the attack success rate by up to 87.9%, while maintaining the\nperformance on benign user requests. In addition, we discuss the situation of\nan adaptive attacker and show that our method is still resilient against\nattackers who are aware of our defense.",
    "pdf_url": "http://arxiv.org/pdf/2410.13236v1",
    "published": "2024-10-17T05:40:54+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13235v1",
    "title": "Bridging Scales: Coupling the galactic nucleus to the larger cosmic environment",
    "authors": [
      "Kung-Yi Su",
      "Priyamvada Natarajan",
      "Hyerin Cho",
      "Ramesh Narayan",
      "Philip F. Hopkins",
      "Daniel Anglés-Alcázar",
      "Ben S. Prather"
    ],
    "abstract": "Coupling black hole (BH) feeding and feedback involves interactions across\nvast spatial and temporal scales that is computationally challenging. Tracking\ngas inflows and outflows from kilo-parsec scales to the event horizon for\nnon-spinning BHs in the presence of strong magnetic fields, Cho et al. (2023,\n2024) report strong suppression of accretion on horizon scales and low (2%)\nfeedback efficiency. In this letter, we explore the impact of these findings\nfor the supermassive BHs M87* and Sgr A*, using high-resolution,\nnon-cosmological, magnetohydrodynamic (MHD) simulations with the Feedback In\nRealistic Environments (FIRE-2) model. With no feedback, we find rapid BH\ngrowth due to \"cooling flows,\" and for 2% efficiency feedback, while accretion\nis suppressed, the rates still remain higher than constraints from Event\nHorizon Telescope (EHT) data (Event Horizon Telescope Collaboration et al.\n2021, 2022) for M87* and Sgr A*. To match EHT observations of M87*, a feedback\nefficiency greater than 15% is required, suggesting the need to include\nenhanced feedback from BH spin. Similarly, a feedback efficiency of $>15\\%$ is\nneeded for Sgr A* to match the estimated observed star formation rate of\n$\\lesssim 2 {\\rm M_\\odot}$ yr$^{-1}$. However, even with 100% feedback\nefficiency, the accretion rate onto Sgr A* matches with EHT data only on rare\noccasions in the simulations, suggesting that Sgr A* is likely in a temporary\nquiescent phase currently. Bridging accretion and feedback across scales, we\nconclude that higher feedback efficiency, possibly due to non-zero BH spin, is\nnecessary to suppress \"cooling flows\" and match observed accretion and star\nformation rates in M87* and Sgr A*.",
    "pdf_url": "http://arxiv.org/pdf/2410.13235v1",
    "published": "2024-10-17T05:39:32+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13234v1",
    "title": "Systematics of supernumerary nuclear rainbow in inelastic $^{16}$O+$^{12}$C scattering",
    "authors": [
      "Nguyen Hoang Phuc",
      "Nguyen Tri Toan Phuc",
      "Do Cong Cuong"
    ],
    "abstract": "We perform a systematic study of inelastic nuclear rainbow scattering for the\n\\oc system to the 2$^+$ (4.44 MeV) state of $^{12}$C at incident energies of\n100--608 MeV with the coupled-channels method. The recently generalized\nnearside-farside decomposition for inelastic scattering was applied in\ncombination with the multichannel deflection function analysis to elucidate the\norigin of the nuclear rainbow phenomenon and the suppression of the primary and\nsupernumerary Airy minima in the inelastic scattering cross section. The\nsystematic evolution of the Airy minima for the excited 2$^+$ (4.44 MeV) state\nof $^{12}$C was unambiguously determined. Our work suggests that there is no\nclear shift in the positions of the first Airy minima and a small shift at low\nenergies for the second and third Airy minima between the inelastic and elastic\nscattering cross sections. Using the $K$-subamplitudes splitting technique\ncombined with the generalized nearside-farside decomposition and deflection\nfunction, the distinct refractive pattern commonly suppressed in the inelastic\nheavy-ion scattering can be interpreted and provides new insights into the\nrelationship between elastic and inelastic nuclear rainbow scattering.",
    "pdf_url": "http://arxiv.org/pdf/2410.13234v1",
    "published": "2024-10-17T05:38:55+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13233v1",
    "title": "Strong convergence of a tamed theta scheme for McKean-Vlasov NSDDEs driven by fractional Brownian motion",
    "authors": [
      "Li Tan",
      "Shengrong Wang"
    ],
    "abstract": "In this article, we propose a tamed theta Euler-Maruyama (EM) scheme for\nsuperlinearly growing neutral McKean-Vlasov stochastic differential delay\nequations driven by fractional Brownian motion with Hurst exponent\n$H\\in(1/2,1)$. The analytical properties including uniqueness and existence,\nboundedness of moment and propagation of chaos are investigated. Moreover, the\nconvergence rate of the numerical scheme is established.",
    "pdf_url": "http://arxiv.org/pdf/2410.13233v1",
    "published": "2024-10-17T05:38:49+00:00",
    "categories": [
      "math.PR",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13232v2",
    "title": "Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation",
    "authors": [
      "Hyungjoo Chae",
      "Namyoung Kim",
      "Kai Tzu-iunn Ong",
      "Minju Gwak",
      "Gwanwoo Song",
      "Jihoon Kim",
      "Sunghwan Kim",
      "Dongha Lee",
      "Jinyoung Yeo"
    ],
    "abstract": "Large language models (LLMs) have recently gained much attention in building\nautonomous agents. However, the performance of current LLM-based web agents in\nlong-horizon tasks is far from optimal, often yielding errors such as\nrepeatedly buying a non-refundable flight ticket. By contrast, humans can avoid\nsuch an irreversible mistake, as we have an awareness of the potential outcomes\n(e.g., losing money) of our actions, also known as the \"world model\". Motivated\nby this, our study first starts with preliminary analyses, confirming the\nabsence of world models in current LLMs (e.g., GPT-4o, Claude-3.5-Sonnet,\netc.). Then, we present a World-model-augmented (WMA) web agent, which\nsimulates the outcomes of its actions for better decision-making. To overcome\nthe challenges in training LLMs as world models predicting next observations,\nsuch as repeated elements across observations and long HTML inputs, we propose\na transition-focused observation abstraction, where the prediction objectives\nare free-form natural language descriptions exclusively highlighting important\nstate differences between time steps. Experiments on WebArena and Mind2Web show\nthat our world models improve agents' policy selection without training and\ndemonstrate our agents' cost- and time-efficiency compared to recent\ntree-search-based agents.",
    "pdf_url": "http://arxiv.org/pdf/2410.13232v2",
    "published": "2024-10-17T05:37:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13231v1",
    "title": "Driven by Brownian motion Cox-Ingersoll-Ross and squared Bessel processes: interaction and phase transition",
    "authors": [
      "Yuliya Mishura",
      "Kostiantyn Ralchenko",
      "Svitlana Kushnirenko"
    ],
    "abstract": "This paper studies two related stochastic processes driven by Brownian\nmotion: the Cox-Ingersoll-Ross (CIR) process and the Bessel process. We\ninvestigate their shared and distinct properties, focusing on time-asymptotic\ngrowth rates, distance between the processes in integral norms, and parameter\nestimation. The squared Bessel process is shown to be a phase transition of the\nCIR process and can be approximated by a sequence of CIR processes. Differences\nin stochastic stability are also highlighted, with the Bessel process\ndisplaying instability, while the CIR process remains ergodic and stable.",
    "pdf_url": "http://arxiv.org/pdf/2410.13231v1",
    "published": "2024-10-17T05:36:44+00:00",
    "categories": [
      "math.PR",
      "60H10"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13230v3",
    "title": "Starbucks-v2: Improved Training for 2D Matryoshka Embeddings",
    "authors": [
      "Shengyao Zhuang",
      "Shuai Wang",
      "Fabio Zheng",
      "Bevan Koopman",
      "Guido Zuccon"
    ],
    "abstract": "2D Matryoshka training enables a single embedding model to generate\nsub-network representations across different layers and embedding dimensions,\noffering adaptability to diverse computational and task constraints. However,\nits effectiveness remains well below that of individually trained models of\nequivalent sizes. To address this, we propose Starbucks, a new training\nstrategy for Matryoshka-style embedding models that combines structured\nfine-tuning with masked autoencoder (MAE) pre-training. During fine-tuning, we\ncompute the loss over a fixed set of layer-dimension pairs, from small to\nlarge, which significantly improves performance over randomly sampled\nsub-networks and matches that of separately trained models. Our MAE-based\npre-training further enhances the representation quality of sub-networks,\nproviding a stronger backbone for downstream tasks. Experiments on both\nin-domain (semantic similarity and passage retrieval) and out-of-domain (BEIR)\nbenchmarks show that Starbucks consistently outperforms 2D Matryoshka models\nand matches or exceeds the performance of individually trained models, while\nmaintaining high efficiency and adaptability. Ablation studies confirm our loss\ndesign choices, the impact of SMAE pre-training and demonstrate the\napplicability of Starbucks across backbones. We further show that depth- and\nwidth-wise Starbucks variants capture complementary information, and that their\nhybridization yields additional performance gains with minimal latency overhead\ndue to parallelization. Code available at https://github.com/ielab/Starbucks",
    "pdf_url": "http://arxiv.org/pdf/2410.13230v3",
    "published": "2024-10-17T05:33:50+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13229v2",
    "title": "Quamba: A Post-Training Quantization Recipe for Selective State Space Models",
    "authors": [
      "Hung-Yueh Chiang",
      "Chi-Chih Chang",
      "Natalia Frumkin",
      "Kai-Chiang Wu",
      "Diana Marculescu"
    ],
    "abstract": "State Space Models (SSMs) have emerged as an appealing alternative to\nTransformers for large language models, achieving state-of-the-art accuracy\nwith constant memory complexity which allows for holding longer context lengths\nthan attention-based networks. The superior computational efficiency of SSMs in\nlong sequence modeling positions them favorably over Transformers in many\nscenarios. However, improving the efficiency of SSMs on request-intensive\ncloud-serving and resource-limited edge applications is still a formidable\ntask. SSM quantization is a possible solution to this problem, making SSMs more\nsuitable for wide deployment, while still maintaining their accuracy.\nQuantization is a common technique to reduce the model size and to utilize the\nlow bit-width acceleration features on modern computing units, yet existing\nquantization techniques are poorly suited for SSMs. Most notably, SSMs have\nhighly sensitive feature maps within the selective scan mechanism (i.e., linear\nrecurrence) and massive outliers in the output activations which are not\npresent in the output of token-mixing in the self-attention modules. To address\nthis issue, we propose a static 8-bit per-tensor SSM quantization method which\nsuppresses the maximum values of the input activations to the selective SSM for\nfiner quantization precision and quantizes the output activations in an\noutlier-free space with Hadamard transform. Our 8-bit weight-activation\nquantized Mamba 2.8B SSM benefits from hardware acceleration and achieves a\n1.72x lower generation latency on an Nvidia Orin Nano 8G, with only a 0.9% drop\nin average accuracy on zero-shot tasks. The experiments demonstrate the\neffectiveness and practical applicability of our approach for deploying\nSSM-based models of all sizes on both cloud and edge platforms.",
    "pdf_url": "http://arxiv.org/pdf/2410.13229v2",
    "published": "2024-10-17T05:32:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13228v2",
    "title": "From PINNs to PIKANs: Recent Advances in Physics-Informed Machine Learning",
    "authors": [
      "Juan Diego Toscano",
      "Vivek Oommen",
      "Alan John Varghese",
      "Zongren Zou",
      "Nazanin Ahmadi Daryakenari",
      "Chenxi Wu",
      "George Em Karniadakis"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a key tool in\nScientific Machine Learning since their introduction in 2017, enabling the\nefficient solution of ordinary and partial differential equations using sparse\nmeasurements. Over the past few years, significant advancements have been made\nin the training and optimization of PINNs, covering aspects such as network\narchitectures, adaptive refinement, domain decomposition, and the use of\nadaptive weights and activation functions. A notable recent development is the\nPhysics-Informed Kolmogorov-Arnold Networks (PIKANS), which leverage a\nrepresentation model originally proposed by Kolmogorov in 1957, offering a\npromising alternative to traditional PINNs. In this review, we provide a\ncomprehensive overview of the latest advancements in PINNs, focusing on\nimprovements in network design, feature expansion, optimization techniques,\nuncertainty quantification, and theoretical insights. We also survey key\napplications across a range of fields, including biomedicine, fluid and solid\nmechanics, geophysics, dynamical systems, heat transfer, chemical engineering,\nand beyond. Finally, we review computational frameworks and software tools\ndeveloped by both academia and industry to support PINN research and\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2410.13228v2",
    "published": "2024-10-17T05:30:59+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.19807v1",
    "title": "Comparing Surface Landmine Object Detection Models on a New Drone Flyby Dataset",
    "authors": [
      "Navin Agrawal-Chung",
      "Zohran Moin"
    ],
    "abstract": "Landmine detection using traditional methods is slow, dangerous and\nprohibitively expensive. Using deep learning-based object detection algorithms\ndrone videos is promising but has multiple challenges due to the small,\nsoda-can size of recently prevalent surface landmines. The literature currently\nlacks scientific evaluation of optimal ML models for this problem since most\nobject detection research focuses on analysis of ground video surveillance\nimages. In order to help train comprehensive models and drive research for\nsurface landmine detection, we first create a custom dataset comprising drone\nimages of POM-2 and POM-3 Russian surface landmines. Using this dataset, we\ntrain, test and compare 4 different computer vision foundation models YOLOF,\nDETR, Sparse-RCNN and VFNet. Generally, all 4 detectors do well with YOLOF\noutperforming other models with a mAP score of 0.89 while DETR, VFNET and\nSparse-RCNN mAP scores are all around 0.82 for drone images taken from 10m AGL.\nYOLOF is also quicker to train consuming 56min of training time on a Nvidia\nV100 compute cluster. Finally, this research contributes landmine image, video\ndatasets and model Jupyter notebooks at https://github.com/UnVeilX/ to enable\nfuture research in surface landmine detection.",
    "pdf_url": "http://arxiv.org/pdf/2410.19807v1",
    "published": "2024-10-17T05:30:00+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13227v1",
    "title": "Latent Image and Video Resolution Prediction using Convolutional Neural Networks",
    "authors": [
      "Rittwika Kansabanik",
      "Adrian Barbu"
    ],
    "abstract": "This paper introduces a Video Quality Assessment (VQA) problem that has\nreceived little attention in the literature, called the latent resolution\nprediction problem. The problem arises when images or videos are upscaled from\ntheir native resolution and are reported as having a higher resolution than\ntheir native resolution. This paper formulates the problem, constructs a\ndataset for training and evaluation, and introduces several machine learning\nalgorithms, including two Convolutional Neural Networks (CNNs), to address this\nproblem. Experiments indicate that some proposed methods can predict the latent\nvideo resolution with about 95% accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2410.13227v1",
    "published": "2024-10-17T05:27:44+00:00",
    "categories": [
      "cs.CV",
      "stat.AP"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13226v2",
    "title": "Research on Travel Route Planing Problems Based on Greedy Algorithm",
    "authors": [
      "Yiquan Wang"
    ],
    "abstract": "The route planning problem based on the greedy algorithm represents a method\nof identifying the optimal or near-optimal route between a given start point\nand end point. In this paper, the PCA method is employed initially to downscale\nthe city evaluation indexes, extract the key principal components, and then\ndownscale the data using the KMO and TOPSIS algorithms, all of which are based\non the MindSpore framework. Secondly, for the dataset that does not pass the\nKMO test, the entropy weight method and TOPSIS method will be employed for\ncomprehensive evaluation. Finally, a route planning algorithm is proposed and\noptimised based on the greedy algorithm, which provides personalised route\ncustomisation according to the different needs of tourists. In addition, the\nlocal travelling efficiency, the time required to visit tourist attractions and\nthe necessary daily breaks are considered in order to reduce the cost and avoid\nfalling into the locally optimal solution.",
    "pdf_url": "http://arxiv.org/pdf/2410.13226v2",
    "published": "2024-10-17T05:17:01+00:00",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13225v2",
    "title": "Twist-3 contribution in the Drell-Yan process with tensor-polarized deuteron",
    "authors": [
      "Si-Yi Qiao",
      "Qin-Tao Song"
    ],
    "abstract": "The tensor-polarized structures of the deuteron can be probed through the\nproton-deuteron Drell-Yan process, where the proton is unpolarized and the\ndeuteron is tensor polarized. This measurement will be conducted at Fermilab in\nthe near future. In this reaction, the twist-3 contribution is not negligible\ncompared to the twist-2 contribution due to the limited invariant mass of the\ndilepton pair. We calculate the twist-3 contribution for the Drell-Yan cross\nsection with a tensor-polarized deuteron target, preserving the U(1)-gauge\ninvariance of the hadronic tensor. The cross sections and weighted cross\nsections are expressed in terms of the tensor-polarized parton distribution\nfunctions (PDFs), thus one can extract the PDFs $f_{1\\scriptscriptstyle{LL}}$,\n$f_{\\scriptscriptstyle{LT}}$, and $f^{(1)}_{\\scriptscriptstyle{1LT}}$ from the\nexperimental measurements of Drell-Yan process. Our study should be helpful to\nsolve the puzzle in the tensor-polarized structures of the deuteron.",
    "pdf_url": "http://arxiv.org/pdf/2410.13225v2",
    "published": "2024-10-17T05:13:35+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13224v1",
    "title": "Proof Flow: Preliminary Study on Generative Flow Network Language Model Tuning for Formal Reasoning",
    "authors": [
      "Matthew Ho",
      "Vincent Zhu",
      "Xiaoyin Chen",
      "Moksh Jain",
      "Nikolay Malkin",
      "Edwin Zhang"
    ],
    "abstract": "Reasoning is a fundamental substrate for solving novel and complex problems.\nDeliberate efforts in learning and developing frameworks around System 2\nreasoning have made great strides, yet problems of sufficient complexity remain\nlargely out of reach for open models. To address this gap, we examine the\npotential of Generative Flow Networks as a fine-tuning method for LLMs to\nunlock advanced reasoning capabilities. In this paper, we present a proof of\nconcept in the domain of formal reasoning, specifically in the Neural Theorem\nProving (NTP) setting, where proofs specified in a formal language such as Lean\ncan be deterministically and objectively verified. Unlike classical\nreward-maximization reinforcement learning, which frequently over-exploits\nhigh-reward actions and fails to effectively explore the state space, GFlowNets\nhave emerged as a promising approach for sampling compositional objects,\nimproving generalization, and enabling models to maintain diverse hypotheses.\nOur early results demonstrate GFlowNet fine-tuning's potential for enhancing\nmodel performance in a search setting, which is especially relevant given the\nparadigm shift towards inference time compute scaling and \"thinking slowly.\"",
    "pdf_url": "http://arxiv.org/pdf/2410.13224v1",
    "published": "2024-10-17T05:10:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13223v1",
    "title": "Coordinated Dispatch of Energy Storage Systems in the Active Distribution Network: A Complementary Reinforcement Learning and Optimization Approach",
    "authors": [
      "Bohan Zhang",
      "Zhongkai Yi",
      "Ying Xu",
      "Zhenghong Tu"
    ],
    "abstract": "The complexity and nonlinearity of active distribution network (ADN), coupled\nwith the fast-changing renewable energy (RE), necessitate advanced real-time\nand safe dispatch approach. This paper proposes a complementary reinforcement\nlearning (RL) and optimization approach, namely SA2CO, to address the\ncoordinated dispatch of the energy storage systems (ESSs) in the ADN. The\nproposed approach leverages RL's capability to make fast decision and address\nthe model inaccuracies, while optimization methods ensure the ADN security.\nFurthermore, a hybrid data-driven and expert-experience auxiliary neural\nnetwork is formulated as a rapid security assessment component in the SA2CO\nalgorithm, enabling dynamic switching between RL and optimization\nmethodologies. Simulation results demonstrate the proposed method's\neffectiveness and scalability in achieving real-time, safe, and economical\ndispatch of multiple ESSs in the ADN, surpassing the performance of the\nstate-of-the-art RL and optimization methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13223v1",
    "published": "2024-10-17T05:08:28+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13222v1",
    "title": "Optimal Covariance Steering of Linear Stochastic Systems with Hybrid Transitions",
    "authors": [
      "Hongzhe Yu",
      "Diana Frias Franco",
      "Aaron M. Johnson",
      "Yongxin Chen"
    ],
    "abstract": "This work addresses the problem of optimally steering the state covariance of\na linear stochastic system from an initial to a target, subject to hybrid\ntransitions. The nonlinear and discontinuous jump dynamics complicate the\ncontrol design for hybrid systems. Under uncertainties, stochastic jump timing\nand state variations further intensify this challenge. This work aims to\nregulate the hybrid system's state trajectory to stay close to a nominal\ndeterministic one, despite uncertainties and noises. We address this problem by\ndirectly controlling state covariances around a mean trajectory, and this\nproblem is termed the Hybrid Covariance Steering (H-CS) problem. The jump\ndynamics are approximated to the first order by leveraging the Saltation\nMatrix. When the jump dynamics are nonsingular, we derive an analytical\nclosed-form solution to the H-CS problem. For general jump dynamics with\npossible singularity and changes in the state dimensions, we reformulate the\nproblem into a convex optimization over path distributions by leveraging\nSchrodinger's Bridge duality to the smooth covariance control problem. The\ncovariance propagation at hybrid events is enforced as equality constraints to\nhandle singularity issues. The proposed convex framework scales linearly with\nthe number of jump events, ensuring efficient, optimal solutions. This work\nthus provides a computationally efficient solution to the general H-CS problem.\nNumerical experiments are conducted to validate the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2410.13222v1",
    "published": "2024-10-17T05:04:10+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13221v1",
    "title": "Investigating Effective Speaker Property Privacy Protection in Federated Learning for Speech Emotion Recognition",
    "authors": [
      "Chao Tan",
      "Sheng Li",
      "Yang Cao",
      "Zhao Ren",
      "Tanja Schultz"
    ],
    "abstract": "Federated Learning (FL) is a privacy-preserving approach that allows servers\nto aggregate distributed models transmitted from local clients rather than\ntraining on user data. More recently, FL has been applied to Speech Emotion\nRecognition (SER) for secure human-computer interaction applications. Recent\nresearch has found that FL is still vulnerable to inference attacks. To this\nend, this paper focuses on investigating the security of FL for SER concerning\nproperty inference attacks. We propose a novel method to protect the property\ninformation in speech data by decomposing various properties in the sound and\nadding perturbations to these properties. Our experiments show that the\nproposed method offers better privacy-utility trade-offs than existing methods.\nThe trade-offs enable more effective attack prevention while maintaining\nsimilar FL utility levels. This work can guide future work on privacy\nprotection methods in speech processing.",
    "pdf_url": "http://arxiv.org/pdf/2410.13221v1",
    "published": "2024-10-17T05:03:34+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13220v1",
    "title": "Chip-scale monolithic optoelectronic voltage boost conversion",
    "authors": [
      "Parthiban Santhanam",
      "Daniel Cui",
      "Jae Seung Hwang",
      "David Abraham",
      "Isabella He",
      "Enzo Watanabe",
      "Aaswath Pattabhi Raman"
    ],
    "abstract": "Voltage conversion is a fundamental electronic process critical to engineered\nsystems across a wide spectrum of applications and spanning many orders of\nmagnitude in scale. Conventional approaches like transformers and charge pumps\nperform well in specific contexts but face fundamental limitations to\nminiaturization, electromagnetic interference, and voltage range. Here we\npresent a chip-scale, fully integrated monolithic, non-switching optoelectronic\nvoltage conversion platform capable of high gain, bootstrap-free boost-mode\noperation across several orders of magnitude in power density and voltage\nscale. Using the bidirectional coupling between LEDs and PV cells with\nidentical active layer materials, our chip-scale, single-die strategy\neliminates Stokes losses while improving key parameters like physical\nfootprint, series resistance, and photon leakage by orders of magnitude over\nimplementations using multiple packaged, discrete components. Moreover, by\nexploiting the large \\'etendue of NIR-transparent semi-insulating InP\nsubstrates and the atomically smooth, void-free interface of lattice-matched\nepitaxial growth, simulations indicate that our InGaAsP architecture's photon\ntransport simultaneously provides a > 60x increase in current density and > 50x\nreduction in non-radiative recombination losses compared with a multiple-die\nsolution while simultaneously reducing fabrication complexity and improving\nmechanical robustness. We experimentally demonstrate a boost gain of 3.8x in an\n8x8 mm$^2$ InGaAs-on-InP chip while validating key aspects of the voltage\nconversion platform.",
    "pdf_url": "http://arxiv.org/pdf/2410.13220v1",
    "published": "2024-10-17T05:01:28+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13219v3",
    "title": "Fundamental Limits of Pulse Based UWB ISAC Systems: A Parameter Estimation Perspective",
    "authors": [
      "Fan Liu",
      "Tingting Zhang",
      "Zenan Zhang",
      "Bin Cao",
      "Yuan Shen",
      "Qinyu Zhang"
    ],
    "abstract": "This paper investigates a bi-static integrated sensing and communication\n(ISAC) system for multi-target scenarios using impulse radio ultra-wideband\n(IR-UWB) signals, which offer fine temporal resolution, low power consumption,\nand strong resistance to multipath interference. Two typical modulation\nschemes, namely pulse position modulation (PPM) and binary phase shift keying\n(BPSK), are considered for communication over the delay and phase domains,\nrespectively. Accordingly, we introduce a pilot-based decoupling approach that\nrelies on known time-delays, as well as a differential decoupling strategy that\nuses a known starting symbol position ({no pilot required}). A key contribution\nof this work is the development of a unified analytical framework based on the\nFisher Information Matrix (FIM), which characterizes the fundamental coupling\nbetween communication and sensing in both delay and Doppler domains. This\ncoupling is examined through the singularity structure of the FIM, providing\nnew theoretical insights into the joint performance limits of UWB-ISAC systems.\nFinally, we assess the sensing and communication performance under various\nmodulation schemes under the constraints of current UWB standards. This\nassessment utilizes the Cramer-Rao Lower Bound (CRLB) for sensing and the data\ntransmission rate for communication, offering theoretical insights into\nchoosing suitable data signal processing methods in real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2410.13219v3",
    "published": "2024-10-17T04:59:16+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13218v2",
    "title": "CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy",
    "authors": [
      "Mian Zhang",
      "Xianjun Yang",
      "Xinlu Zhang",
      "Travis Labrum",
      "Jamie C. Chiu",
      "Shaun M. Eack",
      "Fei Fang",
      "William Yang Wang",
      "Zhiyu Zoey Chen"
    ],
    "abstract": "There is a significant gap between patient needs and available mental health\nsupport today. In this paper, we aim to thoroughly examine the potential of\nusing Large Language Models (LLMs) to assist professional psychotherapy. To\nthis end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation\nof cognitive behavioral therapy (CBT) assistance. We include three levels of\ntasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of\nmultiple-choice questions; II: Cognitive model understanding, with the tasks of\ncognitive distortion classification, primary core belief classification, and\nfine-grained core belief classification; III: Therapeutic response generation,\nwith the task of generating responses to patient speech in CBT therapy\nsessions. These tasks encompass key aspects of CBT that could potentially be\nenhanced through AI assistance, while also outlining a hierarchy of capability\nrequirements, ranging from basic knowledge recitation to engaging in real\ntherapeutic conversations. We evaluated representative LLMs on our benchmark.\nExperimental results indicate that while LLMs perform well in reciting CBT\nknowledge, they fall short in complex real-world scenarios requiring deep\nanalysis of patients' cognitive structures and generating effective responses,\nsuggesting potential future work.",
    "pdf_url": "http://arxiv.org/pdf/2410.13218v2",
    "published": "2024-10-17T04:52:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13217v1",
    "title": "MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records through Hierarchical Guided-Topic Modeling",
    "authors": [
      "Ruohan Wang",
      "Zilong Wang",
      "Ziyang Song",
      "David Buckeridge",
      "Yue Li"
    ],
    "abstract": "Automatic subphenotyping from electronic health records (EHRs)provides\nnumerous opportunities to understand diseases with unique subgroups and enhance\npersonalized medicine for patients. However, existing machine learning\nalgorithms either focus on specific diseases for better interpretability or\nproduce coarse-grained phenotype topics without considering nuanced disease\npatterns. In this study, we propose a guided topic model, MixEHR-Nest, to infer\nsub-phenotype topics from thousands of disease using multi-modal EHR data.\nSpecifically, MixEHR-Nest detects multiple subtopics from each phenotype topic,\nwhose prior is guided by the expert-curated phenotype concepts such as\nPhenotype Codes (PheCodes) or Clinical Classification Software (CCS) codes. We\nevaluated MixEHR-Nest on two EHR datasets: (1) the MIMIC-III dataset consisting\nof over 38 thousand patients from intensive care unit (ICU) from Beth Israel\nDeaconess Medical Center (BIDMC) in Boston, USA; (2) the healthcare\nadministrative database PopHR, comprising 1.3 million patients from Montreal,\nCanada. Experimental results demonstrate that MixEHR-Nest can identify\nsubphenotypes with distinct patterns within each phenotype, which are\npredictive for disease progression and severity. Consequently, MixEHR-Nest\ndistinguishes between type 1 and type 2 diabetes by inferring subphenotypes\nusing CCS codes, which do not differentiate these two subtype concepts.\nAdditionally, MixEHR-Nest not only improved the prediction accuracy of\nshort-term mortality of ICU patients and initial insulin treatment in diabetic\npatients but also revealed the contributions of subphenotypes. For longitudinal\nanalysis, MixEHR-Nest identified subphenotypes of distinct age prevalence under\nthe same phenotypes, such as asthma, leukemia, epilepsy, and depression. The\nMixEHR-Nest software is available at GitHub:\nhttps://github.com/li-lab-mcgill/MixEHR-Nest.",
    "pdf_url": "http://arxiv.org/pdf/2410.13217v1",
    "published": "2024-10-17T04:48:06+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "q-bio.QM",
      "J.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13216v1",
    "title": "Anchored Alignment for Self-Explanations Enhancement",
    "authors": [
      "Luis Felipe Villa-Arenas",
      "Ata Nizamoglu",
      "Qianli Wang",
      "Sebastian Möller",
      "Vera Schmitt"
    ],
    "abstract": "In this work, we introduce a methodology for alignment designed to enhance\nthe ability of large language models (LLMs) to articulate their reasoning\n(self-explanation) even in the absence of annotated rationale explanations. Our\nalignment methodology comprises three key components: explanation quality\nassessment, self-instruction dataset generation, and model alignment.\nAdditionally, we present a novel technique called Alignment with Anchor\nPreference Pairs, which improves the selection of preference pairs by\ncategorizing model outputs into three groups: consistently correct,\nconsistently incorrect, and variable. By applying tailored strategies to each\ncategory, we enhance the effectiveness of Direct Preference Optimization (DPO).\nOur experimental results demonstrate that this approach significantly improves\nexplanation quality while maintaining accuracy compared to other fine-tuning\nstrategies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13216v1",
    "published": "2024-10-17T04:42:48+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13215v2",
    "title": "Balancing Label Quantity and Quality for Scalable Elicitation",
    "authors": [
      "Alex Mallen",
      "Nora Belrose"
    ],
    "abstract": "Scalable oversight studies methods of training and evaluating AI systems in\ndomains where human judgment is unreliable or expensive, such as scientific\nresearch and software engineering in complex codebases. Most work in this area\nhas focused on methods of improving the quality of labels. Recent work by Burns\net al. (2023) considers the complementary problem of training models with\nlow-quality labels, finding that large pretrained models often have an\ninductive bias towards producing correct answers. In practice, however, neither\nlabel quantity nor quality is fixed: practitioners face a quantity-quality\ntradeoff. In this paper, we explore the microeconomics of the quantity-quality\ntradeoff on binary NLP classification tasks used in Burns et al. (2023). While\nsample-efficient learning has been studied extensively, little public research\nhas focused on scalable elicitation: eliciting capabilities from pretrained\nmodels subject to labeling cost constraints. We find that this setting has\nnovel dynamics caused by the tradeoff between label quantity and quality, as\nwell as the model's existing latent capabilities. We observe three regimes of\neliciting classification knowledge from pretrained models using supervised\nfinetuning: quantity-dominant, quality-dominant, and a mixed regime involving\nthe use of low- and high-quality data together to attain higher accuracy at a\nlower cost than using either alone. We explore sample-efficient elicitation\nmethods that make use of two datasets of differing qualities, and establish a\nPareto frontier of scalable elicitation methods that optimally trade off\nlabeling cost and classifier performance. We find that the accuracy of\nsupervised fine-tuning can be improved by up to 5 percentage points at a fixed\nlabeling budget by adding a few-shot prompt to make use of the model's existing\nknowledge of the task.",
    "pdf_url": "http://arxiv.org/pdf/2410.13215v2",
    "published": "2024-10-17T04:39:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13214v1",
    "title": "A Comprehensive Analysis of Routing Vulnerabilities and Defense Strategies in IoT Networks",
    "authors": [
      "Kim Jae-Dong"
    ],
    "abstract": "The rapid expansion of the Internet of Things (IoT) has revolutionized\nvarious domains, offering significant benefits through enhanced\ninterconnectivity and data exchange. However, the security challenges\nassociated with IoT networks have become increasingly prominent owing to their\ninherent vulnerability. This paper provides an in-depth analysis of the network\nlayer in IoT architectures, highlighting the potential risks posed by routing\nattacks, such as blackholes, wormholes, sinkholes, Sybil, and selective\nforwarding attacks. This study explores the unique challenges posed by the\nconstrained resources, heterogeneity, and dynamic topology of IoT networks,\nwhich complicate the implementation of robust security measures. Various\ncountermeasures, including trust-based mechanisms, Intrusion Detection Systems\n(IDS), and routing protocols, are evaluated for their effectiveness in\nmitigating these threats. This study also emphasizes the importance of\nconsidering misbehavior observation, trust management, and lightweight defense\nstrategies in the design of secure IoT networks. These findings contribute to\nthe development of comprehensive defense mechanisms tailored to the specific\nchallenges of IoT environments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13214v1",
    "published": "2024-10-17T04:38:53+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.18126v1",
    "title": "Leveraging Hardware Performance Counters for Predicting Workload Interference in Vector Supercomputers",
    "authors": [
      "Shubham",
      "Keichi Takahashi",
      "Hiroyuki Takizawa"
    ],
    "abstract": "In the rapidly evolving domain of high-performance computing (HPC),\nheterogeneous architectures such as the SX-Aurora TSUBASA (SX-AT) system\narchitecture, which integrate diverse processor types, present both\nopportunities and challenges for optimizing resource utilization. This paper\ninvestigates workload interference within an SX-AT system, with a specific\nfocus on resource contention between Vector Hosts (VHs) and Vector Engines\n(VEs). Through comprehensive empirical analysis, the study identifies key\nfactors contributing to performance degradation, such as cache and memory\nbandwidth contention, when jobs with varying computational demands share\nresources. To address these issues, we develop a predictive model that\nleverages hardware performance counters (HCs) and machine learning (ML)\nalgorithms to classify and predict workload interference. Our results\ndemonstrate that the model accurately forecasts performance degradation,\noffering valuable insights for future research on optimizing job scheduling and\nresource allocation. This approach highlights the importance of adaptive\nresource management strategies in maintaining system efficiency and provides a\nfoundation for future enhancements in heterogeneous supercomputing\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2410.18126v1",
    "published": "2024-10-17T04:37:43+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2410.13213v2",
    "title": "LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch",
    "authors": [
      "Caigao Jiang",
      "Xiang Shu",
      "Hong Qian",
      "Xingyu Lu",
      "Jun Zhou",
      "Aimin Zhou",
      "Yang Yu"
    ],
    "abstract": "Optimization problems are prevalent across various scenarios. Formulating and\nthen solving optimization problems described by natural language often requires\nhighly specialized human expertise, which could block the widespread\napplication of optimization-based decision making. To automate problem\nformulation and solving, leveraging large language models (LLMs) has emerged as\na potential way. However, this kind of approach suffers from the issue of\noptimization generalization. Namely, the accuracy of most current LLM-based\nmethods and the generality of optimization problem types that they can model\nare still limited. In this paper, we propose a unified learning-based framework\ncalled LLMOPT to boost optimization generalization. Starting from the natural\nlanguage descriptions of optimization problems and a pre-trained LLM, LLMOPT\nconstructs the introduced five-element formulation as a universal model for\nlearning to define diverse optimization problem types. Then, LLMOPT employs the\nmulti-instruction tuning to enhance both problem formalization and solver code\ngeneration accuracy and generality. After that, to prevent hallucinations in\nLLMs, such as sacrificing solving accuracy to avoid execution errors, the model\nalignment and self-correction mechanism are adopted in LLMOPT. We evaluate the\noptimization generalization ability of LLMOPT and compared methods across six\nreal-world datasets covering roughly 20 fields such as health, environment,\nenergy and manufacturing, etc. Extensive experiment results show that LLMOPT is\nable to model various optimization problem types such as linear/nonlinear\nprogramming, mixed integer programming, and combinatorial optimization, and\nachieves a notable 11.08% average solving accuracy improvement compared with\nthe state-of-the-art methods. The code is available at\nhttps://github.com/caigaojiang/LLMOPT.",
    "pdf_url": "http://arxiv.org/pdf/2410.13213v2",
    "published": "2024-10-17T04:37:37+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13212v1",
    "title": "AsymKV: Enabling 1-Bit Quantization of KV Cache with Layer-Wise Asymmetric Quantization Configurations",
    "authors": [
      "Qian Tao",
      "Wenyuan Yu",
      "Jingren Zhou"
    ],
    "abstract": "Large language models have shown exceptional capabilities in a wide range of\ntasks, such as text generation and video generation, among others. However, due\nto their massive parameter count, these models often require substantial\nstorage space, imposing significant constraints on the machines deploying LLMs.\nTo overcome this limitation, one research direction proposes to compress the\nmodels using integer replacements for floating-point numbers, in a process\nknown as Quantization. Some recent studies suggest quantizing the key and value\ncache (KV Cache) of LLMs, and designing quantization techniques that treat the\nkey and value matrices equivalently.\n  This work delves deeper into the asymmetric structural roles of KV Cache, a\nphenomenon where the transformer's output loss is more sensitive to the\nquantization of key matrices. We conduct a systematic examination of the\nattention output error resulting from key and value quantization. The\nphenomenon inspires us to propose an asymmetric quantization strategy. Our\napproach allows for 1-bit quantization of the KV cache by implementing distinct\nconfigurations for key and value matrices. We carry out experiments across a\nvariety of datasets, demonstrating that our proposed model allows for the\nquantization of up to 75% decoder layers with 1 bit, while simultaneously\nmaintaining performance levels comparable to those of the models with floating\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2410.13212v1",
    "published": "2024-10-17T04:35:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13211v2",
    "title": "Estimating the Probabilities of Rare Outputs in Language Models",
    "authors": [
      "Gabriel Wu",
      "Jacob Hilton"
    ],
    "abstract": "We consider the problem of low probability estimation: given a machine\nlearning model and a formally-specified input distribution, how can we estimate\nthe probability of a binary property of the model's output, even when that\nprobability is too small to estimate by random sampling? This problem is\nmotivated by the need to improve worst-case performance, which distribution\nshift can make much more likely. We study low probability estimation in the\ncontext of argmax sampling from small transformer language models. We compare\ntwo types of methods: importance sampling, which involves searching for inputs\ngiving rise to the rare output, and activation extrapolation, which involves\nextrapolating a probability distribution fit to the model's logits. We find\nthat importance sampling outperforms activation extrapolation, but both\noutperform naive sampling. Finally, we explain how minimizing the probability\nestimate of an undesirable behavior generalizes adversarial training, and argue\nthat new methods for low probability estimation are needed to provide stronger\nguarantees about worst-case performance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13211v2",
    "published": "2024-10-17T04:31:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13210v1",
    "title": "FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs",
    "authors": [
      "Forrest Sheng Bao",
      "Miaoran Li",
      "Renyi Qu",
      "Ge Luo",
      "Erana Wan",
      "Yujia Tang",
      "Weisi Fan",
      "Manveer Singh Tamber",
      "Suleman Kazi",
      "Vivek Sourabh",
      "Mike Qi",
      "Ruixuan Tu",
      "Chenyu Xu",
      "Matthew Gonzales",
      "Ofer Mendelevitch",
      "Amin Ahmad"
    ],
    "abstract": "Summarization is one of the most common tasks performed by large language\nmodels (LLMs), especially in applications like Retrieval-Augmented Generation\n(RAG). However, existing evaluations of hallucinations in LLM-generated\nsummaries, and evaluations of hallucination detection models both suffer from a\nlack of diversity and recency in the LLM and LLM families considered. This\npaper introduces FaithBench, a summarization hallucination benchmark comprising\nchallenging hallucinations made by 10 modern LLMs from 8 different families,\nwith ground truth annotations by human experts. ``Challenging'' here means\nsummaries on which popular, state-of-the-art hallucination detection models,\nincluding GPT-4o-as-a-judge, disagreed on. Our results show GPT-4o and\nGPT-3.5-Turbo produce the least hallucinations. However, even the best\nhallucination detection models have near 50\\% accuracies on FaithBench,\nindicating lots of room for future improvement. The repo is\nhttps://github.com/vectara/FaithBench",
    "pdf_url": "http://arxiv.org/pdf/2410.13210v1",
    "published": "2024-10-17T04:30:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13209v1",
    "title": "Findings of sub-$T_\\mathrm{g}$ endotherm in vapor-deposited ultrastable phenolphthalein glass",
    "authors": [
      "Soichi Tatsumi",
      "Yutaka Nakamura",
      "Takashi Miyazaki",
      "Tomohiro Kayano",
      "Daiki Kishimoto",
      "Susumu Fujiwara",
      "Haruhiko Yao"
    ],
    "abstract": "We have performed differential scanning calorimetric and synchrotron x-ray\ndiffraction studies to elucidate the nature of vapor-deposited ultrastable\nphenolphthalein glass. As a result, we found that phenolphthalein forms the\nultrastable glass by depositing at 313 K, which is about 0.86 times the ordinal\nglass transition temperature of 361 K. As previous ultrastable glass studies\nreported, this ultrastable state involved an anisotropic structure. In\naddition, we found that a large endotherm (sub-$T_\\mathrm{g}$ endotherm) was\nobserved in the temperature range between deposition and ordinal glass\ntransition temperatures. We have assessed the stability of deposited states\nthermodynamically and found that those states are much more stable than those\ncrystalline states when the deposition rate is small enough. The total\nenthalpies associated with the sub-$T_\\mathrm{g}$ endotherm are roughly\nproportional to the powers of the inversed thickness of the deposited glass.\nDespite the thermodynamical evidence, wide-angle x-ray diffraction of the\nstructure associated with the sub-$T_\\mathrm{g}$ endotherm was unchanged.\nFollowing our findings, we have proposed a scenario in which ultrastable\nvapor-deposited phenolphthalein glass is rooted in locally superstable\nstructure. Our locally oriented scenario would be universal for forming stable\nstructures in other vapor-deposited glasses.",
    "pdf_url": "http://arxiv.org/pdf/2410.13209v1",
    "published": "2024-10-17T04:26:04+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13208v2",
    "title": "Jacobi forms of weight one on $Γ_0(N)$",
    "authors": [
      "Jialin Li",
      "Haowu Wang"
    ],
    "abstract": "Let $J_{1,m}(N)$ be the vector space of Jacobi forms of weight one and index\n$m$ on $\\Gamma_0(N)$. In 1985, Skoruppa proved that $J_{1,m}(1)=0$ for all $m$.\nIn 2007, Ibukiyama and Skoruppa proved that $J_{1,m}(N)=0$ for all $m$ and all\nsquarefree $N$ with $\\mathrm{gcd}(m,N)=1$. This paper aims to extend their\nresults. We determine all levels $N$ separately, such that $J_{1,m}(N)=0$ for\nall $m$; or $J_{1,m}(N)=0$ for all $m$ with $\\mathrm{gcd}(m,N)=1$. We also\nestablish explicit dimension formulas of $J_{1,m}(N)$ when $m$ and $N$ are\nrelatively prime or $m$ is squarefree. These results are obtained by refining\nSkoruppa's method and analyzing local invariants of Weil representations. As\napplications, we prove the vanishing of Siegel modular forms of degree two and\nweight one in some cases.",
    "pdf_url": "http://arxiv.org/pdf/2410.13208v2",
    "published": "2024-10-17T04:25:25+00:00",
    "categories": [
      "math.NT",
      "11F46, 11F50, 11F27"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13207v1",
    "title": "The Theoretical Study of $Σ^{+} p \\toΛa_0^{+} p$ Reaction",
    "authors": [
      "Yan Dai",
      "Aojia Xu",
      "Gang Li",
      "Mao Song",
      "Xuan Luo"
    ],
    "abstract": "We conducted a theoretical study on the process $\\Sigma^{+} p \\to\\Lambda\na_0^{+} p$ based on an effective Lagrangian approach. This model encompasses\nthe excitation of intermediate states leading to the production of\n$\\Delta(1920)$ through $\\pi^{+}$ and $K^{+}$ meson exchanges between the\ninitial $\\Sigma^{+}$ baryon and the initial proton $p$, as well as the\ngeneration of $\\Delta(1940)$ via $\\pi^{+}$ and $\\rho^{+}$ meson exchanges. We\nprovide predictions for the total and differential cross sections and discuss\nthe potential impacts of cutoff parameters, off-shell effects, and branching\nratios on the $\\Delta^{\\ast} \\to a_0 p$ decay. Given the dominance of\n$\\Delta(1940)$ in the region close to the reaction threshold, this reaction is\nconsidered an ideal platform for deeply exploring the unique properties of the\n$\\Delta(1940)$ resonance. Through this approach, we can gain a more precise\nunderstanding of the intrinsic characteristics of this particle.",
    "pdf_url": "http://arxiv.org/pdf/2410.13207v1",
    "published": "2024-10-17T04:24:30+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13916v1",
    "title": "Recursive Work Extraction from Quantum Conditional Information",
    "authors": [
      "Daegene Song"
    ],
    "abstract": "Quantum superposition, a cornerstone of quantum mechanics, enables systems to\nexist in multiple states simultaneously, giving rise to probabilistic outcomes.\nIn quantum information science, conditional entropy has become a key metric for\nquantifying uncertainty in one system given information about another,\nrevealing non-classical correlations that transcend classical physics. This\nstudy examines the nature of quantum conditional entropy and reports two key\nfindings. First, it demonstrates that probabilistic outcomes involving quantum\nsuperposition arise from work based on information about the eigenstate in a\nrecursive process. Second, it proposes that this extractable work constitutes\nthe energy available to living systems-a concept without a classical\nanalogue-counteracting the natural tendency toward disorder.",
    "pdf_url": "http://arxiv.org/pdf/2410.13916v1",
    "published": "2024-10-17T04:24:02+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13206v3",
    "title": "BQA: Body Language Question Answering Dataset for Video Large Language Models",
    "authors": [
      "Shintaro Ozaki",
      "Kazuki Hayashi",
      "Miyu Oba",
      "Yusuke Sakai",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "abstract": "A large part of human communication relies on nonverbal cues such as facial\nexpressions, eye contact, and body language. Unlike language or sign language,\nsuch nonverbal communication lacks formal rules, requiring complex reasoning\nbased on commonsense understanding. Enabling current Video Large Language\nModels (VideoLLMs) to accurately interpret body language is a crucial\nchallenge, as human unconscious actions can easily cause the model to\nmisinterpret their intent. To address this, we propose a dataset, BQA, a body\nlanguage question answering dataset, to validate whether the model can\ncorrectly interpret emotions from short clips of body language comprising 26\nemotion labels of videos of body language. We evaluated various VideoLLMs on\nBQA and revealed that understanding body language is challenging, and our\nanalyses of the wrong answers by VideoLLMs show that certain VideoLLMs made\nsignificantly biased answers depending on the age group and ethnicity of the\nindividuals in the video. The dataset is available.",
    "pdf_url": "http://arxiv.org/pdf/2410.13206v3",
    "published": "2024-10-17T04:19:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13205v1",
    "title": "On the Boltzmann equation with soft potentials: Existence, uniqueness and smoothing effect of mild solutions",
    "authors": [
      "Ling-Bing He",
      "Jie Ji",
      "Wei-Xi Li"
    ],
    "abstract": "We consider the spatially inhomogeneous Boltzmann equation without angular\ncutoff for soft potentials. For any given initial datum such that the mass,\nenergy and entropy densities are bounded and the mass is away from vacuum, we\nestablish the local-in-time existence and uniqueness of mild solutions, and\nfurther provide the first result on sharp smoothing effect in analytic space or\nGevrey space for soft potentials.",
    "pdf_url": "http://arxiv.org/pdf/2410.13205v1",
    "published": "2024-10-17T04:18:20+00:00",
    "categories": [
      "math.AP",
      "35B65, 35Q20"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13204v1",
    "title": "Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations",
    "authors": [
      "Aryan Shrivastava",
      "Jessica Hullman",
      "Max Lamparth"
    ],
    "abstract": "There is an increasing interest in using language models (LMs) for automated\ndecision-making, with multiple countries actively testing LMs to aid in\nmilitary crisis decision-making. To scrutinize relying on LM decision-making in\nhigh-stakes settings, we examine the inconsistency of responses in a crisis\nsimulation (\"wargame\"), similar to reported tests conducted by the US military.\nPrior work illustrated escalatory tendencies and varying levels of aggression\namong LMs but were constrained to simulations with pre-defined actions. This\nwas due to the challenges associated with quantitatively measuring semantic\ndifferences and evaluating natural language decision-making without relying on\npre-defined actions. In this work, we query LMs for free form responses and use\na metric based on BERTScore to measure response inconsistency quantitatively.\nLeveraging the benefits of BERTScore, we show that the inconsistency metric is\nrobust to linguistic variations that preserve semantic meaning in a\nquestion-answering setting across text lengths. We show that all five tested\nLMs exhibit levels of inconsistency that indicate semantic differences, even\nwhen adjusting the wargame setting, anonymizing involved conflict countries, or\nadjusting the sampling temperature parameter $T$. Further qualitative\nevaluation shows that models recommend courses of action that share few to no\nsimilarities. We also study the impact of different prompt sensitivity\nvariations on inconsistency at temperature $T = 0$. We find that inconsistency\ndue to semantically equivalent prompt variations can exceed response\ninconsistency from temperature sampling for most studied models across\ndifferent levels of ablations. Given the high-stakes nature of military\ndeployment, we recommend further consideration be taken before using LMs to\ninform military decisions or other cases of high-stakes decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2410.13204v1",
    "published": "2024-10-17T04:12:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13203v2",
    "title": "TabSeq: A Framework for Deep Learning on Tabular Data via Sequential Ordering",
    "authors": [
      "Al Zadid Sultan Bin Habib",
      "Kesheng Wang",
      "Mary-Anne Hartley",
      "Gianfranco Doretto",
      "Donald A. Adjeroh"
    ],
    "abstract": "Effective analysis of tabular data still poses a significant problem in deep\nlearning, mainly because features in tabular datasets are often heterogeneous\nand have different levels of relevance. This work introduces TabSeq, a novel\nframework for the sequential ordering of features, addressing the vital\nnecessity to optimize the learning process. Features are not always equally\ninformative, and for certain deep learning models, their random arrangement can\nhinder the model's learning capacity. Finding the optimum sequence order for\nsuch features could improve the deep learning models' learning process. The\nnovel feature ordering technique we provide in this work is based on clustering\nand incorporates both local ordering and global ordering. It is designed to be\nused with a multi-head attention mechanism in a denoising autoencoder network.\nOur framework uses clustering to align comparable features and improve data\norganization. Multi-head attention focuses on essential characteristics,\nwhereas the denoising autoencoder highlights important aspects by rebuilding\nfrom distorted inputs. This method improves the capability to learn from\ntabular data while lowering redundancy. Our research, demonstrating improved\nperformance through appropriate feature sequence rearrangement using raw\nantibody microarray and two other real-world biomedical datasets, validates the\nimpact of feature ordering. These results demonstrate that feature ordering can\nbe a viable approach to improved deep learning of tabular data.",
    "pdf_url": "http://arxiv.org/pdf/2410.13203v2",
    "published": "2024-10-17T04:10:36+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13202v1",
    "title": "Anatomy of Thermally Interplayed Spin-Orbit Torque Driven Antiferromagnetic Switching",
    "authors": [
      "Wenlong Cai",
      "Zanhong Chen",
      "Yuzhang Shi",
      "Daoqian Zhu",
      "Guang Yang",
      "Ao Du",
      "Shiyang Lu",
      "Kaihua Cao",
      "Hongxi Liu",
      "Kewen Shi",
      "Weisheng Zhao"
    ],
    "abstract": "Current-induced antiferromagnetic (AFM) switching remains critical in\nspintronics, yet the interplay between thermal effects and spin torques still\nlacks clear clarification. Here we experimentally investigate the thermally\ninterplayed spin-orbit torque induced AFM switching in magnetic tunnel\njunctions via pulse-width dependent reversal and time-resolved measurements. By\nintroducing the Langevin random field into the AFM precession equation, we\nestablish a novel AFM switching model that anatomically explains the\nexperimental observations. Our findings elucidate the currentinduced AFM\nswitching mechanism and offer significant promise for advancements in\nspintronics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13202v1",
    "published": "2024-10-17T04:10:33+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13201v1",
    "title": "Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration",
    "authors": [
      "Yun-Yen Chuang",
      "Hung-Min Hsu",
      "Kevin Lin",
      "Chen-Sheng Gu",
      "Ling Zhen Li",
      "Ray-I Chang",
      "Hung-yi Lee"
    ],
    "abstract": "The diffusion model, a new generative modeling paradigm, has achieved\nsignificant success in generating images, audio, video, and text. It has been\nadapted for sequence-to-sequence text generation (Seq2Seq) through DiffuSeq,\ntermed S2S Diffusion. Existing S2S-Diffusion models predominantly rely on fixed\nor hand-crafted rules to schedule noise during the diffusion and denoising\nprocesses. However, these models are limited by non-contextualized noise, which\nfails to fully consider the characteristics of Seq2Seq tasks. In this paper, we\npropose the Meta-DiffuB framework - a novel scheduler-exploiter S2S-Diffusion\nparadigm designed to overcome the limitations of existing S2S-Diffusion models.\nWe employ Meta-Exploration to train an additional scheduler model dedicated to\nscheduling contextualized noise for each sentence. Our exploiter model, an\nS2S-Diffusion model, leverages the noise scheduled by our scheduler model for\nupdating and generation. Meta-DiffuB achieves state-of-the-art performance\ncompared to previous S2S-Diffusion models and fine-tuned pre-trained language\nmodels (PLMs) across four Seq2Seq benchmark datasets. We further investigate\nand visualize the impact of Meta-DiffuB's noise scheduling on the generation of\nsentences with varying difficulties. Additionally, our scheduler model can\nfunction as a \"plug-and-play\" model to enhance DiffuSeq without the need for\nfine-tuning during the inference stage.",
    "pdf_url": "http://arxiv.org/pdf/2410.13201v1",
    "published": "2024-10-17T04:06:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13200v1",
    "title": "Effects of frequency mixing on Shapiro-step formations in sliding charge-density-waves",
    "authors": [
      "Yu Funami",
      "Kazushi Aoyama"
    ],
    "abstract": "A one-dimensional charge density wave (CDW) is driven to slide by a dc\nelectric field, carrying an electric current. In an additional ac field with\nfrequency ${\\omega}_{\\mathrm{ex}}$, it is known that the sliding CDW can be\nsynchronized to $\\omega_{\\mathrm{ex}}$, leading to the occurrence of Shapiro\nsteps in the $I$-$V$ characteristics. Motivated by a recent experiment where ac\nfields with two frequencies $\\omega_{\\mathrm{ex}}$ and\n$\\omega_{\\mathrm{ex}}^{\\prime}$ are simultaneously applied, we theoretically\ninvestigate the effects of frequency mixing on the Shapiro-step formation.\nBased on the Fukuyama-Lee-Rice model, we show that in addition to the main\nsteps induced by $\\omega_{\\mathrm{ex}}$, satellite steps characterized by\n$\\omega_{\\mathrm{ex}}^{\\prime}$ emerge. It is also found that with increasing\nthe ac-field strength for $\\omega_{\\mathrm{ex}}^{\\prime}$, each step width\nfirst exhibits a damped oscillation as in the one-frequency case, and then,\nexhibits a non-monotonic behavior. The origin of these behaviors and the\nrelevance to the associated experiment are also discussed.",
    "pdf_url": "http://arxiv.org/pdf/2410.13200v1",
    "published": "2024-10-17T04:02:29+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13199v1",
    "title": "A TEM Study of MOCVD-Grown Rutile GeO2 Films",
    "authors": [
      "Imteaz Rahaman",
      "Botong Li",
      "Hunter D. Ellis",
      "Brian Roy Van Devener",
      "Randy C Polson",
      "Kai Fu"
    ],
    "abstract": "Ultrawide bandgap (UWBG) semiconductors are promising for next-generation\npower electronics, largely attributed to their substantial bandgap and\nexceptional breakdown electric field. Rutile GeO2 (r-GeO2) emerges as a\npromising alternative, particularly because of its ambipolar dopability.\nHowever, research on r-GeO2 is still in its infancy, and further investigation\ninto its structural properties is essential for enhancing epilayer quality. In\nour previous work, we identified distinct surface morphologies;\nsquare-patterned and smooth regions of epitaxial r-GeO2 films grown on r-TiO2\n(001) substrates using metal-organic chemical vapor deposition (MOCVD).This\nresearch employs transmission electron microscopy (TEM) to investigate the\nstructural characteristics of the material. The findings indicate that the\nsquare-patterned regions are crystalline, whereas the smooth regions exhibit\namorphous properties. The measured lattice spacing in the (110) plane is 0.324\nnm, slightly exceeding the theoretical value of 0.312 nm. This discrepancy\nsuggests the presence of tensile strain in the r-GeO2 film, resulting from\nlattice mismatch or thermal expansion differences with the substrate. We also\nobserved a threading dislocation density of 1.83*10^9 cm-2, consisting of\n11.76% screw-type, 29.41% edge-type, 55.89% mixed-type dislocations, and 2.94%\nplanar defects. These findings offer valuable insights into the growth\nmechanisms and defect characteristics of r-GeO2.",
    "pdf_url": "http://arxiv.org/pdf/2410.13199v1",
    "published": "2024-10-17T04:01:44+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13198v1",
    "title": "Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation",
    "authors": [
      "Sreyan Ghosh",
      "Mohammad Sadegh Rasooli",
      "Michael Levit",
      "Peidong Wang",
      "Jian Xue",
      "Dinesh Manocha",
      "Jinyu Li"
    ],
    "abstract": "Generative Error Correction (GEC) has emerged as a powerful post-processing\nmethod to enhance the performance of Automatic Speech Recognition (ASR)\nsystems. However, we show that GEC models struggle to generalize beyond the\nspecific types of errors encountered during training, limiting their ability to\ncorrect new, unseen errors at test time, particularly in out-of-domain (OOD)\nscenarios. This phenomenon amplifies with named entities (NEs), where, in\naddition to insufficient contextual information or knowledge about the NEs,\nnovel NEs keep emerging. To address these issues, we propose DARAG (Data- and\nRetrieval-Augmented Generative Error Correction), a novel approach designed to\nimprove GEC for ASR in in-domain (ID) and OOD scenarios. We augment the GEC\ntraining dataset with synthetic data generated by prompting LLMs and\ntext-to-speech models, thereby simulating additional errors from which the\nmodel can learn. For OOD scenarios, we simulate test-time errors from new\ndomains similarly and in an unsupervised fashion. Additionally, to better\nhandle named entities, we introduce retrieval-augmented correction by\naugmenting the input with entities retrieved from a database. Our approach is\nsimple, scalable, and both domain- and language-agnostic. We experiment on\nmultiple datasets and settings, showing that DARAG outperforms all our\nbaselines, achieving 8\\% -- 30\\% relative WER improvements in ID and 10\\% --\n33\\% improvements in OOD settings.",
    "pdf_url": "http://arxiv.org/pdf/2410.13198v1",
    "published": "2024-10-17T04:00:29+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13197v2",
    "title": "Representation of Linear Waves in Inhomogeneous Media",
    "authors": [
      "O. V. Kaptsov"
    ],
    "abstract": "The article explores the acoustic equations in inhomogeneous media and the\nlinearized shallow water equations.\n  Two methods for integrating these equations are proposed. The first method is\nbased on the of the Laplace cascade method, while the second involves reducing\ntwo-dimensional and three-dimensional models to the wave equation. In the case\nof plane waves, solutions to some equations depending on two arbitrary\nfunctions are obtained. In the two-dimensional and three-dimensional cases,\nequations that can be reduced to equations with constant coefficients are\nfound.",
    "pdf_url": "http://arxiv.org/pdf/2410.13197v2",
    "published": "2024-10-17T04:00:21+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "nlin.SI"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13196v2",
    "title": "Context-Enhanced Multi-View Trajectory Representation Learning: Bridging the Gap through Self-Supervised Models",
    "authors": [
      "Tangwen Qian",
      "Junhe Li",
      "Yile Chen",
      "Gao Cong",
      "Tao Sun",
      "Fei Wang",
      "Yongjun Xu"
    ],
    "abstract": "Modeling trajectory data with generic-purpose dense representations has\nbecome a prevalent paradigm for various downstream applications, such as\ntrajectory classification, travel time estimation and similarity computation.\nHowever, existing methods typically rely on trajectories from a single spatial\nview, limiting their ability to capture the rich contextual information that is\ncrucial for gaining deeper insights into movement patterns across different\ngeospatial contexts. To this end, we propose MVTraj, a novel multi-view\nmodeling method for trajectory representation learning. MVTraj integrates\ndiverse contextual knowledge, from GPS to road network and points-of-interest\nto provide a more comprehensive understanding of trajectory data. To align the\nlearning process across multiple views, we utilize GPS trajectories as a bridge\nand employ self-supervised pretext tasks to capture and distinguish movement\npatterns across different spatial views. Following this, we treat trajectories\nfrom different views as distinct modalities and apply a hierarchical\ncross-modal interaction module to fuse the representations, thereby enriching\nthe knowledge derived from multiple sources. Extensive experiments on\nreal-world datasets demonstrate that MVTraj significantly outperforms existing\nbaselines in tasks associated with various spatial views, validating its\neffectiveness and practical utility in spatio-temporal modeling.",
    "pdf_url": "http://arxiv.org/pdf/2410.13196v2",
    "published": "2024-10-17T03:56:12+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13195v3",
    "title": "UniGS: Modeling Unitary 3D Gaussians for Novel View Synthesis from Sparse-view Images",
    "authors": [
      "Jiamin Wu",
      "Kenkun Liu",
      "Yukai Shi",
      "Xiaoke Jiang",
      "Yuan Yao",
      "Lei Zhang"
    ],
    "abstract": "In this work, we introduce UniGS, a novel 3D Gaussian reconstruction and\nnovel view synthesis model that predicts a high-fidelity representation of 3D\nGaussians from arbitrary number of posed sparse-view images. Previous methods\noften regress 3D Gaussians locally on a per-pixel basis for each view and then\ntransfer them to world space and merge them through point concatenation. In\ncontrast, Our approach involves modeling unitary 3D Gaussians in world space\nand updating them layer by layer. To leverage information from multi-view\ninputs for updating the unitary 3D Gaussians, we develop a DETR (DEtection\nTRansformer)-like framework, which treats 3D Gaussians as queries and updates\ntheir parameters by performing multi-view cross-attention (MVDFA) across\nmultiple input images, which are treated as keys and values. This approach\neffectively avoids `ghosting' issue and allocates more 3D Gaussians to complex\nregions. Moreover, since the number of 3D Gaussians used as decoder queries is\nindependent of the number of input views, our method allows arbitrary number of\nmulti-view images as input without causing memory explosion or requiring\nretraining. Extensive experiments validate the advantages of our approach,\nshowcasing superior performance over existing methods quantitatively (improving\nPSNR by 4.2 dB when trained on Objaverse and tested on the GSO benchmark) and\nqualitatively. The code will be released at https://github.com/jwubz123/UNIG.",
    "pdf_url": "http://arxiv.org/pdf/2410.13195v3",
    "published": "2024-10-17T03:48:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13194v2",
    "title": "The Geometry of Numerical Reasoning: Language Models Compare Numeric Properties in Linear Subspaces",
    "authors": [
      "Ahmed Oumar El-Shangiti",
      "Tatsuya Hiraoka",
      "Hilal AlQuabeh",
      "Benjamin Heinzerling",
      "Kentaro Inui"
    ],
    "abstract": "This paper investigates whether large language models (LLMs) utilize\nnumerical attributes encoded in a low-dimensional subspace of the embedding\nspace when answering questions involving numeric comparisons, e.g., Was\nCristiano born before Messi? We first identified, using partial least squares\nregression, these subspaces, which effectively encode the numerical attributes\nassociated with the entities in comparison prompts. Further, we demonstrate\ncausality, by intervening in these subspaces to manipulate hidden states,\nthereby altering the LLM's comparison outcomes. Experiments conducted on three\ndifferent LLMs showed that our results hold across different numerical\nattributes, indicating that LLMs utilize the linearly encoded information for\nnumerical reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2410.13194v2",
    "published": "2024-10-17T03:44:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13193v1",
    "title": "Golyadkin's Torment: Doppelgängers and Adversarial Vulnerability",
    "authors": [
      "George I. Kamberov"
    ],
    "abstract": "Many machine learning (ML) classifiers are claimed to outperform humans, but\nthey still make mistakes that humans do not. The most notorious examples of\nsuch mistakes are adversarial visual metamers. This paper aims to define and\ninvestigate the phenomenon of adversarial Doppelgangers (AD), which includes\nadversarial visual metamers, and to compare the performance and robustness of\nML classifiers to human performance.\n  We find that AD are inputs that are close to each other with respect to a\nperceptual metric defined in this paper. AD are qualitatively different from\nthe usual adversarial examples. The vast majority of classifiers are vulnerable\nto AD and robustness-accuracy trade-offs may not improve them. Some\nclassification problems may not admit any AD robust classifiers because the\nunderlying classes are ambiguous. We provide criteria that can be used to\ndetermine whether a classification problem is well defined or not; describe the\nstructure and attributes of an AD-robust classifier; introduce and explore the\nnotions of conceptual entropy and regions of conceptual ambiguity for\nclassifiers that are vulnerable to AD attacks, along with methods to bound the\nAD fooling rate of an attack. We define the notion of classifiers that exhibit\nhypersensitive behavior, that is, classifiers whose only mistakes are\nadversarial Doppelgangers. Improving the AD robustness of hyper-sensitive\nclassifiers is equivalent to improving accuracy. We identify conditions\nguaranteeing that all classifiers with sufficiently high accuracy are\nhyper-sensitive.\n  Our findings are aimed at significant improvements in the reliability and\nsecurity of machine learning systems.",
    "pdf_url": "http://arxiv.org/pdf/2410.13193v1",
    "published": "2024-10-17T03:42:06+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13192v4",
    "title": "Evaluating Self-Generated Documents for Enhancing Retrieval-Augmented Generation with Large Language Models",
    "authors": [
      "Jiatao Li",
      "Xinyu Hu",
      "Xunjian Yin",
      "Xiaojun Wan"
    ],
    "abstract": "The integration of documents generated by LLMs themselves (Self-Docs)\nalongside retrieved documents has emerged as a promising strategy for\nretrieval-augmented generation systems. However, previous research primarily\nfocuses on optimizing the use of Self-Docs, with their inherent properties\nremaining underexplored. To bridge this gap, we first investigate the overall\neffectiveness of Self-Docs, identifying key factors that shape their\ncontribution to RAG performance (RQ1). Building on these insights, we develop a\ntaxonomy grounded in Systemic Functional Linguistics to compare the influence\nof various Self-Docs categories (RQ2) and explore strategies for combining them\nwith external sources (RQ3). Our findings reveal which types of Self-Docs are\nmost beneficial and offer practical guidelines for leveraging them to achieve\nsignificant improvements in knowledge-intensive question answering tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13192v4",
    "published": "2024-10-17T03:38:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13191v4",
    "title": "MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback",
    "authors": [
      "Zonghai Yao",
      "Aditya Parashar",
      "Huixue Zhou",
      "Won Seok Jang",
      "Feiyun Ouyang",
      "Zhichao Yang",
      "Hong Yu"
    ],
    "abstract": "Automatic question generation (QG) is essential for AI and NLP, particularly\nin intelligent tutoring, dialogue systems, and fact verification. Generating\nmultiple-choice questions (MCQG) for professional exams, like the United States\nMedical Licensing Examination (USMLE), is particularly challenging, requiring\ndomain expertise and complex multi-hop reasoning for high-quality questions.\nHowever, current large language models (LLMs) like GPT-4 struggle with\nprofessional MCQG due to outdated knowledge, hallucination issues, and prompt\nsensitivity, resulting in unsatisfactory quality and difficulty. To address\nthese challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique\nand Correction) framework for converting medical cases into high-quality\nUSMLE-style questions. By integrating expert-driven prompt engineering with\niterative self-critique and self-correction feedback, MCQG-SRefine\nsignificantly enhances human expert satisfaction regarding both the quality and\ndifficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based\nautomatic metric to replace the complex and costly expert evaluation process,\nensuring reliable and expert-aligned assessments.",
    "pdf_url": "http://arxiv.org/pdf/2410.13191v4",
    "published": "2024-10-17T03:38:29+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13190v2",
    "title": "CohEx: A Generalized Framework for Cohort Explanation",
    "authors": [
      "Fanyu Meng",
      "Xin Liu",
      "Zhaodan Kong",
      "Xin Chen"
    ],
    "abstract": "eXplainable Artificial Intelligence (XAI) has garnered significant attention\nfor enhancing transparency and trust in machine learning models. However, the\nscopes of most existing explanation techniques focus either on offering a\nholistic view of the explainee model (global explanation) or on individual\ninstances (local explanation), while the middle ground, i.e., cohort-based\nexplanation, is less explored. Cohort explanations offer insights into the\nexplainee's behavior on a specific group or cohort of instances, enabling a\ndeeper understanding of model decisions within a defined context. In this\npaper, we discuss the unique challenges and opportunities associated with\nmeasuring cohort explanations, define their desired properties, and create a\ngeneralized framework for generating cohort explanations based on supervised\nclustering.",
    "pdf_url": "http://arxiv.org/pdf/2410.13190v2",
    "published": "2024-10-17T03:36:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13189v1",
    "title": "Fast-forwarding quantum algorithms for linear dissipative differential equations",
    "authors": [
      "Dong An",
      "Akwum Onwunta",
      "Gengzhi Yang"
    ],
    "abstract": "We establish improved complexity estimates of quantum algorithms for linear\ndissipative ordinary differential equations (ODEs) and show that the time\ndependence can be fast-forwarded to be sub-linear. Specifically, we show that a\nquantum algorithm based on truncated Dyson series can prepare history states of\ndissipative ODEs up to time $T$ with cost $\\widetilde{\\mathcal{O}}(\\log(T)\n(\\log(1/\\epsilon))^2 )$, which is an exponential speedup over the best previous\nresult. For final state preparation at time $T$, we show that its complexity is\n$\\widetilde{\\mathcal{O}}(\\sqrt{T} (\\log(1/\\epsilon))^2 )$, achieving a\npolynomial speedup in $T$. We also analyze the complexity of simpler\nlower-order quantum algorithms, such as the forward Euler method and the\ntrapezoidal rule, and find that even lower-order methods can still achieve\n$\\widetilde{\\mathcal{O}}(\\sqrt{T})$ cost with respect to time $T$ for preparing\nfinal states of dissipative ODEs. As applications, we show that quantum\nalgorithms can simulate dissipative non-Hermitian quantum dynamics and heat\nprocess with fast-forwarded complexity sub-linear in time.",
    "pdf_url": "http://arxiv.org/pdf/2410.13189v1",
    "published": "2024-10-17T03:33:47+00:00",
    "categories": [
      "quant-ph",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13188v1",
    "title": "Ricci Flows with Nilpotent Symmetry and Zero Bundle Curvature",
    "authors": [
      "Steven Gindi"
    ],
    "abstract": "We use Lott's functional and construct a new functional to derive rigidity\nresults for invariant Ricci flow blowdown limits on nilpotent principal bundles\nwith zero associated curvature. Consequently, we prove that the blowdown limit\nis locally an expanding Ricci soliton when the structure group is the three\ndimensional Heisenberg group. In addition, we classify this soliton when the\nbase manifold is one dimensional. This, together with Lott's work in the\nabelian setting, yields a complete local classification of invariant Ricci flow\nblowdown limits on four dimensional, nilpotent principal bundles.",
    "pdf_url": "http://arxiv.org/pdf/2410.13188v1",
    "published": "2024-10-17T03:33:27+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13187v3",
    "title": "aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Processing",
    "authors": [
      "Siyuan Jiang",
      "Jia Li",
      "He Zong",
      "Huanyu Liu",
      "Hao Zhu",
      "Shukai Hu",
      "Erlu Li",
      "Jiazheng Ding",
      "Yu Han",
      "Wei Ning",
      "Gen Wang",
      "Yihong Dong",
      "Kechi Zhang",
      "Ge Li"
    ],
    "abstract": "Large Language Models (LLMs) have been widely used in code completion, and\nresearchers are focusing on scaling up LLMs to improve their accuracy. However,\nlarger LLMs have lower inference efficiency, affecting developers' experience\nand productivity. In this paper, we propose a lightweight and effective LLM for\ncode completion named aiXcoder-7B. Compared to existing LLMs, aiXcoder-7B\nachieves higher code completion accuracy while having smaller scales (i.e., 7\nbillion parameters). We attribute the superiority of aiXcoder-7B to three key\nfactors: (1) Multi-objective training. We employ three training objectives, one\nof which is our proposed Structured Fill-In-the-Middle (SFIM). SFIM considers\nthe syntax structures in code and effectively improves the performance of LLMs\nfor code. (2) Diverse data sampling strategies. They consider inter-file\nrelationships and enhance the capability of LLMs in understanding cross-file\ncontexts. (3) Extensive high-quality data. We establish a rigorous data\ncollection pipeline and consume a total of 1.2 trillion unique tokens for\ntraining aiXcoder-7B. This vast volume of data enables aiXcoder-7B to learn a\nbroad distribution of code. We evaluate aiXcoder-7B in five popular code\ncompletion benchmarks and a new benchmark collected by this paper. The results\nshow that aiXcoder-7B outperforms the latest six LLMs with similar sizes and\neven surpasses four larger LLMs (e.g., StarCoder2-15B and CodeLlama-34B),\npositioning aiXcoder-7B as a lightweight and effective LLM for academia and\nindustry. Finally, we summarize three valuable insights for helping\npractitioners train the next generations of LLMs for code. aiXcoder-7B has been\nopen-souced and gained significant attention. Until January 2025, aiXcoder-7B\nhas received 2,226 GitHub Stars.",
    "pdf_url": "http://arxiv.org/pdf/2410.13187v3",
    "published": "2024-10-17T03:32:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13186v1",
    "title": "A statistical study on the peak and fluence spectra of Solar Energetic Particles observed over 4 solar cycles",
    "authors": [
      "Yubao Wang",
      "Jingnan Guo"
    ],
    "abstract": "Solar energetic particles (SEPs) are an important space radiation source,\nespecially for the space weather environment in the inner heliosphere. The\nenergy spectrum of SEP events is crucial both for evaluating their radiation\neffects and for understanding their acceleration process at the source region\nand their propagation mechanism. In this work, we investigate the properties of\nthe SEP peak flux spectra and the fluence spectra and their potential formation\nmechanisms using statistical methods. We aim to advance our understanding of\nboth SEPs' acceleration and propagation mechanisms. Employing the dataset of\nEuropean Space Agency's Solar Energetic Particle Environment Modelling (SEPEM)\nprogram, we have obtained and fitted the peak-flux and fluence proton spectra\nof more than a hundred SEP events from 1974 to 2018. We analyzed the\nrelationship among the solar activity, X-ray peak intensity of solar flares and\nthe SEP spectral parameters. Based on the assumption that the initial spectrum\nof accelerated SEPs generally has a power-law distribution and also the\ndiffusion coefficient has a power-law dependence on particle energy, we can\nassess both the source and propagation properties using the observed SEP event\npeak flux and fluence energy spectra. We confirm that SEPs' spectral properties\nare influenced by the solar source and the interplanetary conditions and their\ntransportation process can be influenced by different phases of solar cycle.\nThis study provides an observational perspective on the double power-law\nspectral characteristics of the SEP energy spectra, showing their correlation\nwith the adiabatic cooling and diffusion processes during the particle\npropagation from the Sun to the observer. This contributes to a deeper\nunderstanding of the acceleration and propagation of SEP events, in particular\nthe possible origins of the double-power law.",
    "pdf_url": "http://arxiv.org/pdf/2410.13186v1",
    "published": "2024-10-17T03:26:52+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13185v5",
    "title": "Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents",
    "authors": [
      "Long Li",
      "Weiwen Xu",
      "Jiayan Guo",
      "Ruochen Zhao",
      "Xingxuan Li",
      "Yuqian Yuan",
      "Boqiang Zhang",
      "Yuming Jiang",
      "Yifei Xin",
      "Ronghao Dang",
      "Deli Zhao",
      "Yu Rong",
      "Tian Feng",
      "Lidong Bing"
    ],
    "abstract": "Effective research ideation is a critical step for scientific research.\nHowever, the exponential increase in scientific literature makes it challenging\nfor researchers to stay current with recent advances and identify meaningful\nresearch directions. Recent developments in large language models~(LLMs)\nsuggest a promising avenue for automating the generation of novel research\nideas. However, existing methods for idea generation either trivially prompt\nLLMs or directly expose LLMs to extensive literature without indicating useful\ninformation. Inspired by the research process of human researchers, we propose\na Chain-of-Ideas~(CoI) agent, an LLM-based agent that organizes relevant\nliterature in a chain structure to effectively mirror the progressive\ndevelopment in a research domain. This organization facilitates LLMs to capture\nthe current advancements in research, thereby enhancing their ideation\ncapabilities. Furthermore, we propose Idea Arena, an evaluation protocol that\ncan comprehensively evaluate idea generation methods from different\nperspectives, aligning closely with the preferences of human researchers.\nExperimental results indicate that the CoI agent consistently outperforms other\nmethods and shows comparable quality as humans in research idea generation.\nMoreover, our CoI agent is budget-friendly, with a minimum cost of \\$0.50 to\ngenerate a candidate idea and its corresponding experimental design.",
    "pdf_url": "http://arxiv.org/pdf/2410.13185v5",
    "published": "2024-10-17T03:26:37+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13184v6",
    "title": "Router-Tuning: A Simple and Effective Approach for Enabling Dynamic-Depth in Transformers",
    "authors": [
      "Shwai He",
      "Tao Ge",
      "Guoheng Sun",
      "Bowei Tian",
      "Xiaoyang Wang",
      "Dong Yu"
    ],
    "abstract": "Traditional transformer models often allocate a fixed amount of computational\nresources to every input token, leading to inefficient and unnecessary\ncomputation. To address this, the Mixture of Depths (MoD) was introduced to\ndynamically adjust the computational depth by skipping less important layers.\nDespite its promise, current MoD approaches remain under-explored and face two\nmain challenges: (1) high training costs due to the need to train the entire\nmodel along with the routers that determine which layers to skip, and (2) the\nrisk of performance degradation when important layers are bypassed. In response\nto the first issue, we propose Router-Tuning, a method that fine-tunes only the\nrouter on a small dataset, drastically reducing the computational overhead\nassociated with full model training. For the second challenge, we propose\nMindSkip, which deploys Attention with Dynamic Depths. This method preserves\nthe model's performance while significantly enhancing computational and memory\nefficiency. Extensive experiments demonstrate that our approach delivers\ncompetitive results while dramatically improving the computation efficiency,\ne.g., 21\\% speedup and only a 0.2\\% performance drop. The code is released at\nhttps://github.com/CASE-Lab-UMD/Router-Tuning.",
    "pdf_url": "http://arxiv.org/pdf/2410.13184v6",
    "published": "2024-10-17T03:23:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13183v1",
    "title": "Graded Imbeddings in Finite Dimensional Simple Graded Algebras",
    "authors": [
      "Antonio de França"
    ],
    "abstract": "Let $\\mathbb{F}$ be a field and $\\mathsf{G}$ a group. This work is inspired\nin the following problem: \"{\\it given a division (simple) $\\mathsf{G}$-graded\n$\\mathbb{F}$-algebra, is there any other division (simple) $\\mathsf{G}$-graded\n$\\mathbb{F}$-algebra such that the former can be $\\mathsf{G}$-imbedded in the\nlatter?}\". In this work, we answer this question affirmatively for $\\mathbb{F}$\nalgebraically closed, $\\mathsf{G}$ finite abelian, and associative algebras of\nfinite dimension. To prove this, we apply concepts and properties of Group\nCohomology. We show $\\mathcal{H}^2(H, \\mathbb{F}^*)=\\mathsf{res}^\\mathsf{G}_H\n\\left(\\mathcal{H}^2(\\mathsf{G}, \\mathbb{F}^*)\\right)$, where $H$ is a subgroup\nof $\\mathsf{G}$ and $\\mathsf{res}^\\mathsf{G}_H$ is the restriction\nhomomorphism. Posteriorly, we prove that, given any $H_1,H_2\\leq\\mathsf{G}$ and\n$\\sigma_i\\in\\mathcal{Z}^2(H_i,\\mathbb{F}^*)$, $i=1,2$, are equivalent: i)\n$\\mathbb{F}^{\\sigma_1}[H_1] \\stackrel{\\mathsf{G}}{\\hookrightarrow}\n\\mathbb{F}^{\\sigma_2}[H_2]$; ii) $H_1\\leq H_2$ and\n$[\\sigma_1]=[\\sigma_2]_{H_1}$; iii)\n$\\mathsf{T}^{\\mathsf{G}}(\\mathbb{F}^{\\sigma_2}[H_2])\\subseteq\n\\mathsf{T}^{\\mathsf{G}}(\\mathbb{F}^{\\sigma_1}[H_1])$, where\n$\\mathsf{T}^{\\mathsf{G}}(\\mathbb{F}^{\\sigma_i}[H_i])$ is the\n$\\mathsf{G}$T-ideal of graded identities of $\\mathbb{F}^{\\sigma_i}[H_i]$.\nFurthermore, we prove that, given $\\mathfrak{A}$ and $\\mathfrak{B}$ two finite\ndimensional simple $\\mathsf{G}$-graded $\\mathbb{F}$-algebras, if $\\mathbb{F}$\nis algebraically closed, $\\mathsf{char}(\\mathbb{F}) = 0$ or $\\mathsf{char}\n(\\mathbb{F})$ is coprime with the order of each finite subgroup of\n$\\mathsf{G}$, and any subgroup of $\\mathsf{G}$ is normal, then\n$\\mathsf{T}^{\\mathsf{G}}(\\mathfrak{A})\\subseteq\n\\mathsf{T}^{\\mathsf{G}}(\\mathfrak{B})$ iff $\\mathfrak{B}\n\\stackrel{\\mathsf{G}}{\\hookrightarrow} \\mathfrak{A}$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13183v1",
    "published": "2024-10-17T03:17:04+00:00",
    "categories": [
      "math.RA",
      "Primary 16W50, Secondary 16S35, 16K20, 16R20, 16R10, 20J06, 15B33"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13915v1",
    "title": "A Simulation System Towards Solving Societal-Scale Manipulation",
    "authors": [
      "Maximilian Puelma Touzel",
      "Sneheel Sarangi",
      "Austin Welch",
      "Gayatri Krishnakumar",
      "Dan Zhao",
      "Zachary Yang",
      "Hao Yu",
      "Ethan Kosak-Hine",
      "Tom Gibbs",
      "Andreea Musulan",
      "Camille Thibault",
      "Busra Tugce Gurbuz",
      "Reihaneh Rabbany",
      "Jean-François Godbout",
      "Kellin Pelrine"
    ],
    "abstract": "The rise of AI-driven manipulation poses significant risks to societal trust\nand democratic processes. Yet, studying these effects in real-world settings at\nscale is ethically and logistically impractical, highlighting a need for\nsimulation tools that can model these dynamics in controlled settings to enable\nexperimentation with possible defenses. We present a simulation environment\ndesigned to address this. We elaborate upon the Concordia framework that\nsimulates offline, `real life' activity by adding online interactions to the\nsimulation through social media with the integration of a Mastodon server. We\nimprove simulation efficiency and information flow, and add a set of\nmeasurement tools, particularly longitudinal surveys. We demonstrate the\nsimulator with a tailored example in which we track agents' political positions\nand show how partisan manipulation of agents can affect election results.",
    "pdf_url": "http://arxiv.org/pdf/2410.13915v1",
    "published": "2024-10-17T03:16:24+00:00",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13182v1",
    "title": "Using RLHF to align speech enhancement approaches to mean-opinion quality scores",
    "authors": [
      "Anurag Kumar",
      "Andrew Perrault",
      "Donald S. Williamson"
    ],
    "abstract": "Objective speech quality measures are typically used to assess speech\nenhancement algorithms, but it has been shown that they are sub-optimal as\nlearning objectives because they do not always align well with human subjective\nratings. This misalignment often results in noticeable distortions and\nartifacts that cause speech enhancement to be ineffective. To address these\nissues, we propose a reinforcement learning from human feedback (RLHF)\nframework to fine-tune an existing speech enhancement approach by optimizing\nperformance using a mean-opinion score (MOS)-based reward model. Our results\nshow that the RLHF-finetuned model has the best performance across different\nbenchmarks for both objective and MOS-based speech quality assessment metrics\non the Voicebank+DEMAND dataset. Through ablation studies, we show that both\npolicy gradient loss and supervised MSE loss are important for balanced\noptimization across the different metrics.",
    "pdf_url": "http://arxiv.org/pdf/2410.13182v1",
    "published": "2024-10-17T03:12:13+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13914v5",
    "title": "Exogenous Matching: Learning Good Proposals for Tractable Counterfactual Estimation",
    "authors": [
      "Yikang Chen",
      "Dehui Du",
      "Lili Tian"
    ],
    "abstract": "We propose an importance sampling method for tractable and efficient\nestimation of counterfactual expressions in general settings, named Exogenous\nMatching. By minimizing a common upper bound of counterfactual estimators, we\ntransform the variance minimization problem into a conditional distribution\nlearning problem, enabling its integration with existing conditional\ndistribution modeling approaches. We validate the theoretical results through\nexperiments under various types and settings of Structural Causal Models (SCMs)\nand demonstrate the outperformance on counterfactual estimation tasks compared\nto other existing importance sampling methods. We also explore the impact of\ninjecting structural prior knowledge (counterfactual Markov boundaries) on the\nresults. Finally, we apply this method to identifiable proxy SCMs and\ndemonstrate the unbiasedness of the estimates, empirically illustrating the\napplicability of the method to practical scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2410.13914v5",
    "published": "2024-10-17T03:08:28+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13181v1",
    "title": "AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning",
    "authors": [
      "Hao Sun",
      "Jiayi Wu",
      "Hengyi Cai",
      "Xiaochi Wei",
      "Yue Feng",
      "Bo Wang",
      "Shuaiqiang Wang",
      "Yan Zhang",
      "Dawei Yin"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have been remarkable.\nUsers face a choice between using cloud-based LLMs for generation quality and\ndeploying local-based LLMs for lower computational cost. The former option is\ntypically costly and inefficient, while the latter usually fails to deliver\nsatisfactory performance for reasoning steps requiring deliberate thought\nprocesses. In this work, we propose a novel LLM utilization paradigm that\nfacilitates the collaborative operation of large cloud-based LLMs and smaller\nlocal-deployed LLMs. Our framework comprises two primary modules: the local\nagent instantiated with a relatively smaller LLM, handling less complex\nreasoning steps, and the cloud agent equipped with a larger LLM, managing more\nintricate reasoning steps. This collaborative processing is enabled through an\nadaptive mechanism where the local agent introspectively identifies errors and\nproactively seeks assistance from the cloud agent, thereby effectively\nintegrating the strengths of both locally-deployed and cloud-based LLMs,\nresulting in significant enhancements in task completion performance and\nefficiency. We evaluate AdaSwitch across 7 benchmarks, ranging from\nmathematical reasoning and complex question answering, using various types of\nLLMs to instantiate the local and cloud agents. The empirical results show that\nAdaSwitch effectively improves the performance of the local agent, and\nsometimes achieves competitive results compared to the cloud agent while\nutilizing much less computational overhead.",
    "pdf_url": "http://arxiv.org/pdf/2410.13181v1",
    "published": "2024-10-17T03:07:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13180v1",
    "title": "Secrecy Sum-Rate Maximization for Active IRS-Assisted MIMO-OFDM SWIPT System",
    "authors": [
      "Xingxiang Peng",
      "Peiran Wu",
      "Junhui Zhao",
      "Minghua Xia"
    ],
    "abstract": "The propagation loss of RF signals is a significant issue in simultaneous\nwireless information and power transfer (SWIPT) systems. Additionally, ensuring\ninformation security is crucial due to the broadcasting nature of wireless\nchannels. To address these challenges, we exploit the potential of active\nintelligent reflecting surface (IRS) in a multiple-input and multiple-output\n(MIMO) orthogonal frequency division multiplexing (OFDM) SWIPT system. The\nactive IRS provides better beamforming gain than the passive IRS, reducing the\n\"double-fading\" effect. Moreover, the noise introduced at the active IRS can be\nused as artificial noise (AN) to jam eavesdroppers. This paper formulates a\nsecrecy sum-rate maximization problem related to precoding matrices, power\nsplitting (PS) ratios, and the IRS matrix. Since the problem is highly\nnon-convex, we propose a block coordinate descent (BCD)-based algorithm to find\na sub-optimal solution. Moreover, we develop a heuristic algorithm based on the\nzero-forcing precoding scheme to reduce computational complexity. Simulation\nresults show that the active IRS achieves a higher secrecy sum rate than the\npassive and non-IRS systems, especially when the transmit power is low or the\ndirect link is blocked. Moreover, increasing the power budget at the active IRS\ncan significantly improve the secrecy sum rate.",
    "pdf_url": "http://arxiv.org/pdf/2410.13180v1",
    "published": "2024-10-17T03:03:21+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13179v1",
    "title": "EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning",
    "authors": [
      "Ashish Seth",
      "Ramaneswaran Selvakumar",
      "S Sakshi",
      "Sonal Kumar",
      "Sreyan Ghosh",
      "Dinesh Manocha"
    ],
    "abstract": "In this paper, we present EH-MAM (Easy-to-Hard adaptive Masked Acoustic\nModeling), a novel self-supervised learning approach for speech representation\nlearning. In contrast to the prior methods that use random masking schemes for\nMasked Acoustic Modeling (MAM), we introduce a novel selective and adaptive\nmasking strategy. Specifically, during SSL training, we progressively introduce\nharder regions to the model for reconstruction. Our approach automatically\nselects hard regions and is built on the observation that the reconstruction\nloss of individual frames in MAM can provide natural signals to judge the\ndifficulty of solving the MAM pre-text task for that frame. To identify these\nhard regions, we employ a teacher model that first predicts the frame-wise\nlosses and then decides which frames to mask. By learning to create challenging\nproblems, such as identifying harder frames and solving them simultaneously,\nthe model is able to learn more effective representations and thereby acquire a\nmore comprehensive understanding of the speech. Quantitatively, EH-MAM\noutperforms several state-of-the-art baselines across various low-resource\nspeech recognition and SUPERB benchmarks by 5%-10%. Additionally, we conduct a\nthorough analysis to show that the regions masked by EH-MAM effectively capture\nuseful context across speech frames.",
    "pdf_url": "http://arxiv.org/pdf/2410.13179v1",
    "published": "2024-10-17T02:59:22+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13178v3",
    "title": "GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation",
    "authors": [
      "Ziwei Yang",
      "Zheng Chen",
      "Xin Liu",
      "Rikuto Kotoge",
      "Peng Chen",
      "Yasuko Matsubara",
      "Yasushi Sakurai",
      "Jimeng Sun"
    ],
    "abstract": "Retrieving gene functional networks from knowledge databases presents a\nchallenge due to the mismatch between disease networks and subtype-specific\nvariations. Current solutions, including statistical and deep learning methods,\noften fail to effectively integrate gene interaction knowledge from databases\nor explicitly learn subtype-specific interactions. To address this mismatch, we\npropose GeSubNet, which learns a unified representation capable of predicting\ngene interactions while distinguishing between different disease subtypes.\nGraphs generated by such representations can be considered subtype-specific\nnetworks. GeSubNet is a multi-step representation learning framework with three\nmodules: First, a deep generative model learns distinct disease subtypes from\npatient gene expression profiles. Second, a graph neural network captures\nrepresentations of prior gene networks from knowledge databases, ensuring\naccurate physical gene interactions. Finally, we integrate these two\nrepresentations using an inference loss that leverages graph generation\ncapabilities, conditioned on the patient separation loss, to refine\nsubtype-specific information in the learned representation. GeSubNet\nconsistently outperforms traditional methods, with average improvements of\n30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averaged\nover four cancer datasets. Particularly, we conduct a biological simulation\nexperiment to assess how the behavior of selected genes from over 11,000\ncandidates affects subtypes or patient distributions. The results show that the\ngenerated network has the potential to identify subtype-specific genes with an\n83% likelihood of impacting patient distribution shifts.",
    "pdf_url": "http://arxiv.org/pdf/2410.13178v3",
    "published": "2024-10-17T02:58:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13177v1",
    "title": "Chemical abundances of 20 barium stars from the OHP spectra",
    "authors": [
      "Guochao Yang",
      "Jingkun Zhao",
      "Yanchun Liang",
      "Monique Spite",
      "Francois Spite",
      "Jianrong Shi",
      "Shuai Liu",
      "Nian Liu",
      "Wenyuan Cui",
      "Gang Zhao"
    ],
    "abstract": "Based on the high resolution and high signal-to-noise spectra, we derived the\nchemical abundances of 20 elements for 20 barium (Ba-) stars. For the first\ntime, the detailed abundances of four sample stars, namely HD 92482, HD 150430,\nHD 151101 and HD 177304 have been analyzed. Additionally, Ba element abundance\nhas been measured using high resolution spectra for the first time in six of\nthe other 16 sample stars. Based on the [s/Fe] ratios, the Ba-unknown star HD\n115927 can be classified as a strong Ba-star, while the Ba-likely star HD\n160538 can be categorized into a mild Ba-star. Consequently, our sample\ncomprises three strong and 17 mild Ba-stars. The light odd-Z metal elements and\nFe-peak elements exhibit near-solar abundances. The [{\\alpha}/Fe] ratios\ndemonstrate decreasing trends with increasing metallicity. Moreover, the\nabundances of n-capture elements show significant enhancements in different\ndegrees. Using a threshold of the signed distances to the solar r-process\nabundance pattern ds = 0.6, we find that all of our sample stars are normal\nBa-stars, indicating that the enhancements of s-process elements should be\nattributed to material transfer from their companions. We compare the observed\nn-capture patterns of sample stars with the FRUITY models, and estimate the\nmass of the Thermally-Pulsing Asymptotic Giant Branch stars that previously\ncontaminated the Ba-stars. The models with low masses can successfully explain\nthe observations. From a kinematic point of view, we note that most of our\nsample stars are linked with the thin disk, while HD 130255 may be associated\nwith the thick disk.",
    "pdf_url": "http://arxiv.org/pdf/2410.13177v1",
    "published": "2024-10-17T02:58:48+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13176v2",
    "title": "Quantum-classical correspondence of non-Hermitian spin-orbit coupled bosonic junction",
    "authors": [
      "Xin Yan",
      "Hongzheng Wu",
      "Changwei Fan",
      "Baiyuan Yang",
      "Yu Guo",
      "Xiaobing Luo",
      "Jinpeng Xiao",
      "Zhao-Yun Zeng"
    ],
    "abstract": "We investigate the classical-quantum correspondence of non-Hermitian\nSpin-orbit (SO)-coupled bosonic junctions, where an effective decay term is\nintroduced in one of the two wells. Starting from the normalized two-point\nfunctions, we analytically demonstrate that the mean-field system has a\nclassical Hamiltonian structure, and we successfully derive a non-Hermitian\ndiscrete nonlinear Schr\\\"odinger (Gross-Pitaevskii) equation. We discover that\nnear the symmetry-breaking phase transition point, the correspondence between\nclassical (mean-field) and quantum dynamics is more likely to break down. When\nthe effective spin-orbit coupling (SOC) strength assumes half-integer values,\natomic self-trapping in the non-lossy well definitely occurs, regardless of the\nsystem parameters, and the quantum dynamics is insensitive to the number of\nparticles. Additionally, we reveal that in both the mean-field and\nmany-particle models, the SOC effects can greatly promote the synchronous\nperiodic oscillations between the spin-up and spin-down components, and this\nsynchronization dynamics is protected by a symmetry mechanism.",
    "pdf_url": "http://arxiv.org/pdf/2410.13176v2",
    "published": "2024-10-17T02:58:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13175v2",
    "title": "TCP-Diffusion: A Multi-modal Diffusion Model for Global Tropical Cyclone Precipitation Forecasting with Change Awareness",
    "authors": [
      "Cheng Huang",
      "Pan Mu",
      "Cong Bai",
      "Peter AG Watson"
    ],
    "abstract": "Precipitation from tropical cyclones (TCs) can cause disasters such as\nflooding, mudslides, and landslides. Predicting such precipitation in advance\nis crucial, giving people time to prepare and defend against these\nprecipitation-induced disasters. Developing deep learning (DL) rainfall\nprediction methods offers a new way to predict potential disasters. However,\none problem is that most existing methods suffer from cumulative errors and\nlack physical consistency. Second, these methods overlook the importance of\nmeteorological factors in TC rainfall and their integration with the numerical\nweather prediction (NWP) model. Therefore, we propose Tropical Cyclone\nPrecipitation Diffusion (TCP-Diffusion), a multi-modal model for global\ntropical cyclone precipitation forecasting. It forecasts TC rainfall around the\nTC center for the next 12 hours at 3 hourly resolution based on past rainfall\nobservations and multi-modal environmental variables. Adjacent residual\nprediction (ARP) changes the training target from the absolute rainfall value\nto the rainfall trend and gives our model the ability of rainfall change\nawareness, reducing cumulative errors and ensuring physical consistency.\nConsidering the influence of TC-related meteorological factors and the useful\ninformation from NWP model forecasts, we propose a multi-model framework with\nspecialized encoders to extract richer information from environmental variables\nand results provided by NWP models. The results of extensive experiments show\nthat our method outperforms other DL methods and the NWP method from the\nEuropean Centre for Medium-Range Weather Forecasts (ECMWF).",
    "pdf_url": "http://arxiv.org/pdf/2410.13175v2",
    "published": "2024-10-17T02:58:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13174v2",
    "title": "Scalable Drift Monitoring in Medical Imaging AI",
    "authors": [
      "Jameson Merkow",
      "Felix J. Dorfner",
      "Xiyu Yang",
      "Alexander Ersoy",
      "Giridhar Dasegowda",
      "Mannudeep Kalra",
      "Matthew P. Lungren",
      "Christopher P. Bridge",
      "Ivan Tarapov"
    ],
    "abstract": "The integration of artificial intelligence (AI) into medical imaging has\nadvanced clinical diagnostics but poses challenges in managing model drift and\nensuring long-term reliability. To address these challenges, we develop MMC+,\nan enhanced framework for scalable drift monitoring, building upon the\nCheXstray framework that introduced real-time drift detection for medical\nimaging AI models using multi-modal data concordance. This work extends the\noriginal framework's methodologies, providing a more scalable and adaptable\nsolution for real-world healthcare settings and offers a reliable and\ncost-effective alternative to continuous performance monitoring addressing\nlimitations of both continuous and periodic monitoring methods. MMC+ introduces\ncritical improvements to the original framework, including more robust handling\nof diverse data streams, improved scalability with the integration of\nfoundation models like MedImageInsight for high-dimensional image embeddings\nwithout site-specific training, and the introduction of uncertainty bounds to\nbetter capture drift in dynamic clinical environments. Validated with\nreal-world data from Massachusetts General Hospital during the COVID-19\npandemic, MMC+ effectively detects significant data shifts and correlates them\nwith model performance changes. While not directly predicting performance\ndegradation, MMC+ serves as an early warning system, indicating when AI systems\nmay deviate from acceptable performance bounds and enabling timely\ninterventions. By emphasizing the importance of monitoring diverse data streams\nand evaluating data shifts alongside model performance, this work contributes\nto the broader adoption and integration of AI solutions in clinical settings.",
    "pdf_url": "http://arxiv.org/pdf/2410.13174v2",
    "published": "2024-10-17T02:57:35+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13173v2",
    "title": "Measurement of attenuation length of the muon content in extensive air showers from 0.3 to 30 PeV with LHAASO",
    "authors": [
      "LHAASO collaboration"
    ],
    "abstract": "The attenuation length of the muon content in extensive air showers provides\nimportant information regarding the generation and development of air showers.\nThis information can be used not only to improve the description of such\nshowers but also to test fundamental models of hadronic interactions. Using\ndata from the LHAASO-KM2A experiment, the development of the muon content in\nhigh-energy air showers was studied. The attenuation length of muon content in\nthe air showers was measured from experimental data in the energy range from\n0.3 to 30 PeV using the constant intensity cut method. By comparing the\nattenuation length of the muon content with predictions from high-energy\nhadronic interaction models (QGSJET-II-04, SIBYLL 2.3d, and EPOS-LHC), it is\nevident that LHAASO results are significantly shorter than those predicted by\nthe first two models (QGSJET-II-04 and SIBYLL 2.3d) but relatively close to\nthose predicted by the third model (EPOS-LHC). Thus, the LHAASO data favor the\nEPOS-LHC model over the other two models. The three interaction models\nconfirmed an increasing trend in the attenuation length as the cosmic-ray\nenergy increases.",
    "pdf_url": "http://arxiv.org/pdf/2410.13173v2",
    "published": "2024-10-17T02:57:01+00:00",
    "categories": [
      "hep-ex",
      "astro-ph.HE"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2410.13172v2",
    "title": "Investigating the Limits of Hard X-ray Coherence Length Measurement Employing Young's Double Slit Experiment",
    "authors": [
      "Rielly Castle",
      "Narayan Appathurai",
      "Nicholas Simonson",
      "Yasaman Sigari",
      "Mark Boland",
      "Feizho He",
      "Chithra Karunakaran",
      "Jian Wang",
      "Beatriz D. Moreno",
      "Venkata S. C. Kuppili"
    ],
    "abstract": "Young's double slit experiment has been the most explored technique to gauge\nthe coherence properties of a given system. The limits of this technique in\ncharacterizing spatial coherence properties of high emittance, hard x-ray\nsynchrotron sources have been performed at the BXDS-IVU beamline, Canadian\nLight Source (CLS). High emittance synchrotron sources have always been assumed\nto possess sub-optimal coherence properties, especially in the hard X-ray\nregime. While this is largely true, it is very important to understand the\nlimits of coherence for these existing high emittance sources. We have\ndemonstrated that the Young's double slit experiment has harsher limits than\nwhat is normally expected in the form of inherent ambiguity. We present data\nobtained at multiple energies in both the horizontal and vertical direction\nleading to a thorough understanding of the fundamental limitations of employing\nYoung's double slit experiment to characterize inherently low coherence length\nsystems. We have put forth a novel numerical technique to estimate the source\nsize directly from the Young's double slit interference patterns. With these\nresults, we have demonstrated that CLS has functional coherent beam properties\nin the hard X-ray regime with Spatial coherence lengths ranging from 5.37$\\mu\n\\text{m}$ to 17.61$\\mu \\text{m}$ in the horizontal direction. The same in the\nvertical direction was at least 3 times larger. Finally, we present theoretical\ncalculations showcasing the limits of Young's double slit experiment in\ncharacterizing diffraction limited sources.",
    "pdf_url": "http://arxiv.org/pdf/2410.13172v2",
    "published": "2024-10-17T02:54:51+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13171v1",
    "title": "L1-Regularized ICA: A Novel Method for Analysis of Task-related fMRI Data",
    "authors": [
      "Yusuke Endo",
      "Koujin Takeda"
    ],
    "abstract": "We propose a new method of independent component analysis (ICA) in order to\nextract appropriate features from high-dimensional data. In general, matrix\nfactorization methods including ICA have a problem regarding the\ninterpretability of extracted features. For the improvement of\ninterpretability, it is considered that sparse constraint on a factorized\nmatrix is helpful. With this background, we construct a new ICA method with\nsparsity. In our method, the L1-regularization term is added to the cost\nfunction of ICA, and minimization of the cost function is performed by\ndifference of convex functions algorithm. For the validity of our proposed\nmethod, we apply it to synthetic data and real functional magnetic resonance\nimaging data.",
    "pdf_url": "http://arxiv.org/pdf/2410.13171v1",
    "published": "2024-10-17T02:54:01+00:00",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13170v1",
    "title": "Adaptive LAD-Based Bootstrap Unit Root Tests under Unconditional Heteroskedasticity",
    "authors": [
      "Jilin Wu",
      "Ruike Wu",
      "Zhijie Xiao"
    ],
    "abstract": "This paper explores testing unit roots based on least absolute deviations\n(LAD) regression under unconditional heteroskedasticity. We first derive the\nasymptotic properties of the LAD estimator for a first-order autoregressive\nprocess with the coefficient (local to) unity under unconditional\nheteroskedasticity and weak dependence, revealing that the limiting\ndistribution of the LAD estimator (consequently the derived test statistics) is\nclosely associated with unknown time-varying variances. To conduct feasible\nLAD-based unit root tests under heteroskedasticity and serial dependence, we\ndevelop an adaptive block bootstrap procedure, which accommodates time-varying\nvolatility and serial dependence, both of unknown forms, to compute critical\nvalues for LAD-based tests. The asymptotic validity is established. We then\nextend the testing procedure to allow for deterministic components. Simulation\nresults indicate that, in the presence of unconditional heteroskedasticity and\nserial dependence, the classic LAD-based tests demonstrate severe size\ndistortion, whereas the proposed LAD-based bootstrap tests exhibit good\nsize-control capability. Additionally, the newly developed tests show superior\ntesting power in heavy-tailed distributed cases compared to considered\nbenchmarks. Finally, empirical analysis of real effective exchange rates of 16\nEU countries is conducted to illustrate the applicability of the newly proposed\ntests.",
    "pdf_url": "http://arxiv.org/pdf/2410.13170v1",
    "published": "2024-10-17T02:52:02+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13169v1",
    "title": "Deterministic Creation of Identical Monochromatic Quantum Emitters in Hexagonal Boron Nitride",
    "authors": [
      "Muchuan Hua",
      "Wei-Ying Chen",
      "Hanyu Hou",
      "Venkata Surya Chaitanya Kolluru",
      "Maria K. Y. Chan",
      "HaiHua Liu",
      "Thomas E. Gage",
      "Jian-Min Zuo",
      "Benjamin T. Diroll",
      "Jianguo Wen"
    ],
    "abstract": "Deterministic creation of quantum emitters with high single-photon-purity and\nexcellent indistinguishability is essential for practical applications in\nquantum information science. Many successful attempts have been carried out in\nhexagonal boron nitride showing its capability of hosting room temperature\nquantum emitters. However, most of the existing methods produce emitters with\nheterogeneous optical properties and unclear creation mechanisms. Here, the\nauthors report a deterministic creation of identical room temperature quantum\nemitters using masked-carbon-ion implantation on freestanding hBN flakes.\nQuantum emitters fabricated by our approach showed thermally limited\nmonochromaticity with an emission center wavelength distribution of 590.7 +-\n2.7 nm, a narrow full width half maximum of 7.1 +- 1.7 nm, excellent brightness\n(1MHz emission rate), and extraordinary stability. Our method provides a\nreliable platform for characterization and fabrication research on hBN based\nquantum emitters, helping to reveal the origins of the single-photon-emission\nbehavior in hBN and favoring practical applications, especially the\nindustrial-scale production of quantum technology.",
    "pdf_url": "http://arxiv.org/pdf/2410.13169v1",
    "published": "2024-10-17T02:52:01+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13168v2",
    "title": "On hidden face contributions of configuration space integrals for long embeddings",
    "authors": [
      "Leo Yoshioka"
    ],
    "abstract": "Configuration space integrals are powerful tools for studying the homotopy\ntype of the space of long embeddings in terms of a combinatorial object called\na graph complex. It is unknown whether these integrals give a cochain map due\nto potential obstructions called hidden faces. The purpose of this paper is to\naddress these hidden faces by modifying configuration space integrals: we\nincorporate the acyclic bar complex of some dg algebra into the original graph\ncomplex, without changing its cohomology. Then, we give a cochain map from the\nnew graph complex to the de Rham complex of the space of long embeddings modulo\nimmersions, by combining the original configuration space integrals with Chen's\niterated integrals. As the original complex, we choose quite a modified graph\ncomplex so that it is quasi-isomorphic to both the hairy graph complex and a\ngraph complex introduced in the context of embedding calculus.",
    "pdf_url": "http://arxiv.org/pdf/2410.13168v2",
    "published": "2024-10-17T02:51:25+00:00",
    "categories": [
      "math.AT",
      "math.GT",
      "57K45, 57R40, 57R22, 57K16, 57M15"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13167v1",
    "title": "A Selfish Herd with a Target",
    "authors": [
      "Thomas Stemler",
      "Shannon Dee Algar",
      "Jesse Zhou"
    ],
    "abstract": "One of the most striking phenomena in biological systems is the tendency for\nbiological agents to spatially aggregate, and subsequently display further\ncollective behaviours such as rotational motion. One prominent explanation for\nwhy agents tend to aggregate is known as the selfish herd hypothesis (SHH). The\nSHH proposes that each agent has a \"domain of danger\" whose area is\nproportional to the risk of predation. The SHH proposes that aggregation occurs\nas a result of agents seeking to minimise the area of their domain. Subsequent\nattempts to model the SHH have had varying success in displaying aggregation,\nand have mostly been unable to exhibit further collective behaviours, such as\naligned motion or milling. Here, we introduce a model that seeks to generalise\nthe principles of previous SHH models, by allowing agents to aim for domains of\na specific (possibly non-minimal) area or a range of areas and study the\nresulting collective dynamics. Moreover, the model incorporates the lack of\ninformation that biological agents have by limiting the range of movement and\nvision of the agents. The model shows that the possibility of further\ncollective motion is heavily dependent on the domain area the agents aim for -\nwith several distinct phases of collective behaviour.",
    "pdf_url": "http://arxiv.org/pdf/2410.13167v1",
    "published": "2024-10-17T02:51:15+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13166v4",
    "title": "An Evolved Universal Transformer Memory",
    "authors": [
      "Edoardo Cetin",
      "Qi Sun",
      "Tianyu Zhao",
      "Yujin Tang"
    ],
    "abstract": "Prior methods propose to offset the escalating costs of modern foundation\nmodels by dropping specific parts of their contexts with hand-designed rules,\nwhile attempting to preserve their original performance. We overcome this\ntrade-off with Neural Attention Memory Models (NAMMs), introducing a learned\nnetwork for memory management that improves both the performance and efficiency\nof transformers. We evolve NAMMs atop pre-trained transformers to provide\ndifferent latent contexts focusing on the most relevant information for\nindividual layers and attention heads. NAMMs are universally applicable to any\nmodel using self-attention as they condition exclusively on the values in the\nproduced attention matrices. Learning NAMMs on a small set of problems, we\nachieve substantial performance improvements across multiple long-context\nbenchmarks while cutting the model's input contexts up to a fraction of the\noriginal sizes. We show the generality of our conditioning enables zero-shot\ntransfer of NAMMs trained only on language to entirely new transformer\narchitectures even across input modalities, with their benefits carrying over\nto vision and reinforcement learning.",
    "pdf_url": "http://arxiv.org/pdf/2410.13166v4",
    "published": "2024-10-17T02:47:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13165v1",
    "title": "A unified fourth-order Bhatnagar-Gross-Krook lattice Boltzmann model for high-dimensional linear hyperbolic equations",
    "authors": [
      "Ying Chen",
      "Zhenhua Chai",
      "Baochang Shi"
    ],
    "abstract": "In this work, we first develop a unified Bhatnagar-Gross-Krook lattice\nBoltzmann (BGK-LB) model for the $d$($d\\geq 1$)-dimensional linear hyperbolic\nequation (L-HE), where the natural moments and the D$d$Q$(2d^2+1)$ [($2d^2+1$)\ndiscrete velocities in $d$-dimensional space] lattice structure are considered.\nSubsequently, at the acoustic scaling, we conduct an accuracy analysis on the\ndeveloped BGK-LB model by the direct Taylor expansion (DTE) method, and present\nthe second- and third-order moments of the equilibrium distribution functions\n(EDFs) to ensure that the BGK-LB model can be fourth-order consistent with the\nL-HE. And on this basis, when considering the Dirichlet boundary condition, the\nfourth-order full-way and half-way boundary schemes are proposed to approximate\nthe unknown distribution functions to ensure that the BGK-LB model can be\noverall fourth-order accurate. Thereafter, based on the kinetic entropy theory,\nwe derive the conditions that the fourth-order moments of the EDFs should\nsatisfy to ensure the microscopic entropy stability of the BGK-LB model. In\naddition, with the aid of the von Neumann stability analysis, we also discuss\nthe $L^2$ stability of the BGK-LB model and numerically plot the stability\nregions. In particular, from a numerical perspective, we find that the region\nof microscopic entropy stability is identical to that of $L^2$ stability.\nFinally, we carry out some numerical experiments to test the accuracy and\nstability of the BGK-LB model, and the numerical results are in agreement with\nour theoretical analysis. In addition, we compare the developed full-way and\nhalf-way boundary schemes for the Dirichlet boundary condition, which shows\nthat the full-way boundary scheme is more stable.",
    "pdf_url": "http://arxiv.org/pdf/2410.13165v1",
    "published": "2024-10-17T02:43:13+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13164v1",
    "title": "Markov Random Fields with Proximity Constraints for Spatial Data",
    "authors": [
      "Sudipto Saha",
      "Jonathan R. Bradley"
    ],
    "abstract": "The conditional autoregressive (CAR) model, simultaneous autoregressive (SAR)\nmodel, and its variants have become the predominant strategies for modeling\nregional or areal-referenced spatial data. The overwhelming wide-use of the\nCAR/SAR model motivates the need for new classes of models for areal-referenced\ndata. Thus, we develop a novel class of Markov random fields based on\ntruncating the full-conditional distribution. We define this truncation in two\nways leading to versions of what we call the truncated autoregressive (TAR)\nmodel. First, we truncate the full conditional distribution so that a response\nat one location is close to the average of its neighbors. This strategy\nestablishes relationships between TAR and CAR. Second, we truncate on the joint\ndistribution of the data process in a similar way. This specification leads to\nconnection between TAR and SAR model. Our Bayesian implementation does not use\nMarkov chain Monte Carlo (MCMC) for Bayesian computation, and generates samples\ndirectly from the posterior distribution. Moreover, TAR does not have a range\nparameter that arises in the CAR/SAR models, which can be difficult to learn.\nWe present the results of the proposed truncated autoregressive model on\nseveral simulated datasets and on a dataset of average property prices.",
    "pdf_url": "http://arxiv.org/pdf/2410.13164v1",
    "published": "2024-10-17T02:42:58+00:00",
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13913v1",
    "title": "Newton-Maclaurin type inequalities for linear combinations of elementary symmetric functions",
    "authors": [
      "Shuqi Hu",
      "Changyu Ren",
      "Ziyi Wang"
    ],
    "abstract": "In this paper, we establish Newton-Maclaurin type inequalities for functions\narising from linear combinations of primitively symmetric polynomials. This\ngeneralization extends the classical Newton-Maclaurin inequality to a broader\nclass of functions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13913v1",
    "published": "2024-10-17T02:38:08+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13163v2",
    "title": "Revocable Encryption, Programs, and More: The Case of Multi-Copy Security",
    "authors": [
      "Prabhanjan Ananth",
      "Saachi Mutreja",
      "Alexander Poremba"
    ],
    "abstract": "Fundamental principles of quantum mechanics have inspired many new research\ndirections, particularly in quantum cryptography. One such principle is quantum\nno-cloning which has led to the emerging field of revocable cryptography.\nRoughly speaking, in a revocable cryptographic primitive, a cryptographic\nobject (such as a ciphertext or program) is represented as a quantum state in\nsuch a way that surrendering it effectively translates into losing the\ncapability to use this cryptographic object. All of the revocable cryptographic\nsystems studied so far have a major drawback: the recipient only receives one\ncopy of the quantum state. Worse yet, the schemes become completely insecure if\nthe recipient receives many identical copies of the same quantum state -- a\nproperty that is clearly much more desirable in practice. While multi-copy\nsecurity has been extensively studied for a number of other quantum\ncryptographic primitives, it has so far received only little treatment in\ncontext of unclonable primitives. Our work, for the first time, shows the\nfeasibility of revocable primitives, such as revocable encryption and revocable\nprograms, which satisfy multi-copy security in oracle models. This suggest that\nthe stronger notion of multi-copy security is within reach in unclonable\ncryptography more generally, and therefore could lead to a new research\ndirection in the field.",
    "pdf_url": "http://arxiv.org/pdf/2410.13163v2",
    "published": "2024-10-17T02:37:40+00:00",
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13162v1",
    "title": "First-principles study of the electronic structure, Z2 invariant and quantum oscillation in the kagome material CsV3Sb5",
    "authors": [
      "Shalika R. Bhandari",
      "Mohd Zeeshan",
      "Vivek Gusain",
      "Keshav Shrestha",
      "D. P. Rai"
    ],
    "abstract": "This work presents a detailed study of the electronic structure, phonon\ndispersion, Z2 invariant calculation, and Fermi surface of the newly discovered\nkagome superconductor CsV3Sb5, using density functional theory (DFT). The\nphonon dispersion in the pristine state reveals two negative modes at the M and\nL points of the Brillouin zone, indicating lattice instability. CsV3Sb5\ntransitions into a structurally stable 2x2x1 charge density wave (CDW) phase,\nconfirmed by positive phonon modes. The electronic band structure shows several\nDirac points near the Fermi level, with a narrow gap opening due to spin-orbit\ncoupling (SOC), though the effect of SOC on other bands is minimal. In the\npristine phase, this material exhibits a quasi-2D cylindrical Fermi surface,\nwhich undergoes reconstruction in the CDW phase. We calculated quantum\noscillation frequencies using Onsager's relation, finding good agreement with\nexperimental results in the CDW phase. To explore the topological properties of\nCsV3Sb5, we computed the Z2 invariant in both pristine and CDW phases,\nresulting in a value of (u0; u1u2u3) = (1; 000), suggesting the strong\ntopological nature of this material. Our detailed analysis of phonon\ndispersion, electronic bands, Fermi surface mapping, and Z2 invariant provides\ninsights into the topological properties, CDW order, and unconventional\nsuperconductivity in AV3Sb5 (A = K, Rb, and Cs).",
    "pdf_url": "http://arxiv.org/pdf/2410.13162v1",
    "published": "2024-10-17T02:33:43+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2410.13912v1",
    "title": "A spatiotemporal knowledge graph-based method for identifying individual activity locations from mobile phone data",
    "authors": [
      "Jian Li",
      "Tian Gan",
      "Weifeng Li",
      "Yuhang Liu"
    ],
    "abstract": "In recent years, mobile phone data has been widely used for human mobility\nanalytics. Identifying individual activity locations is the fundamental step\nfor mobile phone data processing. Current methods typically aggregate spatially\nadjacent location records over multiple days to identify activity locations.\nHowever, only considering spatial relationships while overlooking temporal ones\nmay lead to inaccurate activity location identification, and also affect\nactivity pattern analysis. In this study, we propose a spatiotemporal knowledge\ngraph-based (STKG) method for identifying activity locations from mobile phone\ndata. An STKG is designed and constructed to describe individual mobility\ncharacteristics. The spatial and temporal relationships of individual stays are\ninferred and transformed into a spatiotemporal graph. The\nmodularity-optimization community detection algorithm is applied to identify\nstays with dense spatiotemporal relationships, which are considering as\nactivity locations. A case study in Shanghai was conducted to verify the\nperformance of the proposed method. The results show that compared with two\nbaseline methods, the STKG-based method can limit an additional 45% of activity\nlocations with the longest daytime stay within a reasonable spatial range; In\naddition, the STKG-based method exhibit lower variance in the start and end\ntimes of activities across different days, performing approximately 10% to 20%\nbetter than the two baseline methods. Moreover, the STKG-based method\neffectively distinguishes between locations that are geographically close but\nexhibit different temporal patterns. These findings demonstrate the\neffectiveness of STKG-based method in enhancing both spatial precision and\ntemporal consistency.",
    "pdf_url": "http://arxiv.org/pdf/2410.13912v1",
    "published": "2024-10-17T02:32:22+00:00",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13161v1",
    "title": "Continuous normalizing flows for lattice gauge theories",
    "authors": [
      "Mathis Gerdes",
      "Pim de Haan",
      "Roberto Bondesan",
      "Miranda C. N. Cheng"
    ],
    "abstract": "Continuous normalizing flows are known to be highly expressive and flexible,\nwhich allows for easier incorporation of large symmetries and makes them a\npowerful tool for sampling in lattice field theories. Building on previous\nwork, we present a general continuous normalizing flow architecture for matrix\nLie groups that is equivariant under group transformations. We apply this to\nlattice gauge theories in two dimensions as a proof-of-principle and\ndemonstrate competitive performance, showing its potential as a tool for future\nlattice sampling tasks.",
    "pdf_url": "http://arxiv.org/pdf/2410.13161v1",
    "published": "2024-10-17T02:30:44+00:00",
    "categories": [
      "hep-lat",
      "cond-mat.stat-mech",
      "cs.LG",
      "hep-th"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2410.13160v1",
    "title": "Suppressed paramagnetism in amorphous Ta$_2$O$_{5-x}$ oxides and its link to superconducting qubit performance",
    "authors": [
      "P. Graham Pritchard",
      "James M. Rondinelli"
    ],
    "abstract": "Reduced transmon qubit $T_1$ coherence times have been linked to the\namorphous oxide layers formed by thin film capacitors during processing.\nBecause Ta or Ta capped Nb capacitors exhibit overall superior qubit\nperformance to those fabricated with Nb capacitors, it has been hypothesized\nthat the amorphous, non-stoichiometric Ta$_2$O$_{5-x}$ oxide is less lossy than\nits Nb$_2$O$_{5-x}$ counterpart. The origins of what makes amorphous\nTa$_2$O$_{5-x}$ less susceptible to accepted decoherence channels is unknown.\nHere we establish the microscopic features of amorphous Nb$_2$O$_{5-x}$ and\nTa$_2$O$_{5-x}$ using a combination of \\textit{ab initio} molecular dynamics\nand density functional theory calculations. Our simulations establish that\noxygen deficiency is less likely to occur in amorphous Ta$_2$O$_{5-x}$ than in\nNb$_2$O$_{5-x}$ for $0\\le x \\le 0.25$ and that at a given level of oxygen\ndeficiency the formation of metal Ta-Ta bonds is enhanced. These bonds, which\nare accommodated by structural flaws in the amorphous network, capture\nelectrons better than in amorphous Nb$_2$O$_{5-x}$. These thermochemical\ndifferences quench or highly suppress magnetic moments in amorphous\nTa$_2$O$_{5-x}$ and eliminate a potential source of quasiparticles and magnetic\nflux noise. Our calculations also show that hyperfine couplings between Nb\nnuclei and local magnetic moments in Nb$_2$O$_{5-x}$ could form \"two-level\nsystems\" (TLS) or \"two-level fluctuators\" (TLF) with energy splittings of\n100-1000 MHz or higher. This reveals a new TLS mechanism in amorphous\nNb$_2$O$_{5-x}$ oxide layers that is unlikely in Ta$_2$O$_{5-x}$. Our work\nprovides fundamental understanding of the materials chemistry and limitations\nimposed by native oxides of superconducting qubits, which can be used to guide\nmaterials selection and processing.",
    "pdf_url": "http://arxiv.org/pdf/2410.13160v1",
    "published": "2024-10-17T02:29:06+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13159v2",
    "title": "Data Driven Environmental Awareness Using Wireless Signals",
    "authors": [
      "Hossein Nasiri",
      "Seda Dogan-Tusha",
      "Muhammad Iqbal Rochman",
      "Monisha Ghosh"
    ],
    "abstract": "Robust classification of the operational environment of wireless devices is\nbecoming increasingly important for wireless network optimization, particularly\nin a shared spectrum environment. Distinguishing between indoor and outdoor\ndevices can enhance reliability and improve coexistence with existing, outdoor,\nincumbents. For instance, the unlicensed but shared 6 GHz band (5.925 - 7.125\nGHz) enables sharing by imposing lower transmit power for indoor unlicensed\ndevices and a spectrum coordination requirement for outdoor devices. Further,\nindoor devices are prohibited from using battery power, external antennas, and\nweatherization to prevent outdoor operations. As these rules may be\ncircumvented, we propose a robust indoor/outdoor classification method by\nleveraging the fact that the radio-frequency environment faced by a device are\nquite different indoors and outdoors. We first collect signal strength data\nfrom all cellular and Wi-Fi bands that can be received by a smartphone in\nvarious environments (indoor interior, indoor near windows, and outdoors),\nalong with GPS accuracy, and then evaluate three machine learning (ML) methods:\ndeep neural network (DNN), decision tree, and random forest to perform\nclassification into these three categories. Our results indicate that the DNN\nmodel performs the best, particularly in minimizing the most important\nclassification error, that of classifying outdoor devices as indoor interior\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2410.13159v2",
    "published": "2024-10-17T02:28:09+00:00",
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2410.13158v1",
    "title": "Seminormal basis for the cyclotomic Hecke algebra of type $G(r,p,n)$",
    "authors": [
      "Jun Hu",
      "Shixuan Wang"
    ],
    "abstract": "The cyclotomic Hecke algebra $H_{r,p,n}$ of type $G(r,p,n)$ (where $r=pd$)\ncan be realized as the $\\sigma$-fixed point subalgebra of certain cyclotomic\nHecke algebra $H_{r,n}$ of type $G(r,1,n)$ with some special cyclotomic\nparameters, where $\\sigma$ is an automorphism of $H_{r,n}$ of order $p$. In\nthis paper we prove a number of rational properties on the\n$\\gamma$-coefficients arising in the construction of the seminormal basis for\nthe semisimple Hecke algebra $H_{r,n}$. Using these properties, we construct a\nseminormal basis for the semisimple Hecke algebra $H_{r,p,n}$ in terms of the\nseminormal basis for the semisimple Hecke algebra $H_{r,n}$. The proof relies\non some careful and subtle study on some rational and symmetric properties of\nsome quotients and/or products of $\\gamma$-coefficients of $H_{r,n}$. As\napplications, we obtain an explicit basis for the center $Z(H_{r,p,n})$ and an\nexplicit basis for the $\\sigma$-twisted $k$-center $Z(H_{r,n})^{(k)}$ of\n$H_{r,n}$ for each $k\\in\\mathbb{Z}/p\\mathbb{Z}$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13158v1",
    "published": "2024-10-17T02:27:09+00:00",
    "categories": [
      "math.RT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13157v3",
    "title": "Variational Scarring in Graphene Quantum Dots",
    "authors": [
      "J. Keski-Rahkonen",
      "C. Zou",
      "A. M. Graf",
      "Q. Yao",
      "T. Zhu",
      "J. Velasco, Jr.",
      "E. J. Heller"
    ],
    "abstract": "A quantum eigenstate of a classically chaotic system is referred as scarred\nby an unstable periodic orbit if its probability density is concentrated in the\nvicinity of that orbit. Recently, a new class of scarring - variational\nscarring - was discovered in numerical studies of disordered quantum dots,\narising from near-degeneracies in the quantum spectrum associated with\nclassical resonances of the unperturbed system. Despite the increasing body of\ntheoretical evidence on variational scarring, its experimental observation has\nremained out of reach. Motivated by this dearth, we argue and demonstrate that\nvariational scarring can occur in an elliptical quantum dot fabricated on\nmonolayer graphene, and locally perturbed by a nanotip. Then, we further show\nthat the fingerprint of these variational scars can potentially be detected via\nscanning tunneling microscopy, thus offering an attractive experimental pathway\nfor the first validation of this puzzling quantum-chaotic phenomenon.",
    "pdf_url": "http://arxiv.org/pdf/2410.13157v3",
    "published": "2024-10-17T02:26:58+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13156v1",
    "title": "FAMSeC: A Few-shot-sample-based General AI-generated Image Detection Method",
    "authors": [
      "Juncong Xu",
      "Yang Yang",
      "Han Fang",
      "Honggu Liu",
      "Weiming Zhang"
    ],
    "abstract": "The explosive growth of generative AI has saturated the internet with\nAI-generated images, raising security concerns and increasing the need for\nreliable detection methods. The primary requirement for such detection is\ngeneralizability, typically achieved by training on numerous fake images from\nvarious models. However, practical limitations, such as closed-source models\nand restricted access, often result in limited training samples. Therefore,\ntraining a general detector with few-shot samples is essential for modern\ndetection mechanisms. To address this challenge, we propose FAMSeC, a general\nAI-generated image detection method based on LoRA-based Forgery Awareness\nModule and Semantic feature-guided Contrastive learning strategy. To\neffectively learn from limited samples and prevent overfitting, we developed a\nForgery Awareness Module (FAM) based on LoRA, maintaining the generalization of\npre-trained features. Additionally, to cooperate with FAM, we designed a\nSemantic feature-guided Contrastive learning strategy (SeC), making the FAM\nfocus more on the differences between real/fake image than on the features of\nthe samples themselves. Experiments show that FAMSeC outperforms\nstate-of-the-art method, enhancing classification accuracy by 14.55% with just\n0.56% of the training samples.",
    "pdf_url": "http://arxiv.org/pdf/2410.13156v1",
    "published": "2024-10-17T02:21:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13155v2",
    "title": "SLM-Mod: Small Language Models Surpass LLMs at Content Moderation",
    "authors": [
      "Xianyang Zhan",
      "Agam Goyal",
      "Yilun Chen",
      "Eshwar Chandrasekharan",
      "Koustuv Saha"
    ],
    "abstract": "Large language models (LLMs) have shown promise in many natural language\nunderstanding tasks, including content moderation. However, these models can be\nexpensive to query in real-time and do not allow for a community-specific\napproach to content moderation. To address these challenges, we explore the use\nof open-source small language models (SLMs) for community-specific content\nmoderation tasks. We fine-tune and evaluate SLMs (less than 15B parameters) by\ncomparing their performance against much larger open- and closed-sourced models\nin both a zero-shot and few-shot setting. Using 150K comments from 15 popular\nReddit communities, we find that SLMs outperform zero-shot LLMs at content\nmoderation -- 11.5% higher accuracy and 25.7% higher recall on average across\nall communities. Moreover, few-shot in-context learning leads to only a\nmarginal increase in the performance of LLMs, still lacking compared to SLMs.\nWe further show the promise of cross-community content moderation, which has\nimplications for new communities and the development of cross-platform\nmoderation techniques. Finally, we outline directions for future work on\nlanguage model based content moderation. Code and models can be found at\nhttps://github.com/AGoyal0512/SLM-Mod.",
    "pdf_url": "http://arxiv.org/pdf/2410.13155v2",
    "published": "2024-10-17T02:16:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13154v1",
    "title": "Quantum-Inspired Stochastic Modeling and Regularity in Turbulent Fluid Dynamics",
    "authors": [
      "Rômulo Damasclin Chaves dos Santos",
      "Jorge Henrique de Oliveira Sales",
      "Erickson F. M. S. Silva"
    ],
    "abstract": "This paper presents an innovative framework for analyzing the regularity of\nsolutions to the stochastic Navier-Stokes equations by integrating\nSobolev-Besov hybrid spaces with fractional operators and quantum-inspired\ndynamics. We propose new regularity theorems that address the multiscale and\nchaotic nature of fluid flows, offering novel insights into energy dissipation\nmechanisms. The introduction of a Schr\\\"odinger-like operator into the fluid\ndynamics model captures quantum-scale turbulence effects, enhancing our\nunderstanding of energy redistribution across different scales. The results\nalso include the development of anisotropic stochastic models that account for\ndirection-dependent viscosity, improving the representation of real-world\nturbulent flows. These advances in stochastic modeling and regularity analysis\nprovide a comprehensive toolset for tackling complex fluid dynamics problems.\nThe findings are applicable to fields such as engineering, quantum turbulence,\nand environmental sciences. Future directions include the numerical\nimplementation of the proposed models and the use of machine learning\ntechniques to optimize parameters for enhanced simulation accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2410.13154v1",
    "published": "2024-10-17T02:16:34+00:00",
    "categories": [
      "physics.flu-dyn",
      "math-ph",
      "math.AP",
      "math.MP"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2410.13153v1",
    "title": "Better to Ask in English: Evaluation of Large Language Models on English, Low-resource and Cross-Lingual Settings",
    "authors": [
      "Krishno Dey",
      "Prerona Tarannum",
      "Md. Arid Hasan",
      "Imran Razzak",
      "Usman Naseem"
    ],
    "abstract": "Large Language Models (LLMs) are trained on massive amounts of data, enabling\ntheir application across diverse domains and tasks. Despite their remarkable\nperformance, most LLMs are developed and evaluated primarily in English.\nRecently, a few multi-lingual LLMs have emerged, but their performance in\nlow-resource languages, especially the most spoken languages in South Asia, is\nless explored. To address this gap, in this study, we evaluate LLMs such as\nGPT-4, Llama 2, and Gemini to analyze their effectiveness in English compared\nto other low-resource languages from South Asia (e.g., Bangla, Hindi, and\nUrdu). Specifically, we utilized zero-shot prompting and five different prompt\nsettings to extensively investigate the effectiveness of the LLMs in\ncross-lingual translated prompts. The findings of the study suggest that GPT-4\noutperformed Llama 2 and Gemini in all five prompt settings and across all\nlanguages. Moreover, all three LLMs performed better for English language\nprompts than other low-resource language prompts. This study extensively\ninvestigates LLMs in low-resource language contexts to highlight the\nimprovements required in LLMs and language-specific resources to develop more\ngenerally purposed NLP applications.",
    "pdf_url": "http://arxiv.org/pdf/2410.13153v1",
    "published": "2024-10-17T02:12:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13152v1",
    "title": "Scaling limits of random graphs",
    "authors": [
      "Louigi Addario-Berry",
      "Christina Goldschmidt"
    ],
    "abstract": "This work will appear as a chapter in a forthcoming volume titled \"Topics in\nProbabilistic Graph Theory\". A theory of scaling limits for random graphs has\nbeen developed in recent years. This theory gives access to the large-scale\ngeometric structure of these random objects in the limit as their size goes to\ninfinity, with distances appropriately rescaled. We start with the simplest\nsetting of random trees, before turning to various examples of random graphs,\nincluding the critical Erd\\H{o}s--R\\'enyi random graph.",
    "pdf_url": "http://arxiv.org/pdf/2410.13152v1",
    "published": "2024-10-17T02:11:05+00:00",
    "categories": [
      "math.PR",
      "math.CO",
      "05C80, 60C05"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13151v1",
    "title": "Nonlinear smoothing for the periodic dispersion generalized Benjamin-Ono equations with polynomial nonlinearity",
    "authors": [
      "Wangseok Shin"
    ],
    "abstract": "We consider the periodic dispersion generalized Benjamin-Ono equations with\npolynomial nonlinearity. We establish the nonlinear smoothing properties of\nthese equations, according to which the difference between the solution and the\nlinear evolution is smoother than the initial data. In addition, we establish\nnew local well-posedness results for these equations when the dispersion is\nsufficiently large. Our method also improves known local well-posedness results\nfor a class of non-integrable fifth-order KdV equations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13151v1",
    "published": "2024-10-17T02:10:30+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13150v1",
    "title": "A well-quasi-order for continuous functions",
    "authors": [
      "Raphaël Carroy",
      "Yann Pequignot"
    ],
    "abstract": "We prove that continuous reducibility is a well-quasi-order on the class of\ncontinuous functions between separable metrizable spaces with analytic\nzero-dimensional domain. To achieve this, we define scattered functions, which\ngeneralize scattered spaces, and describe exhaustively scattered functions\nbetween zero-dimensional separable metrizable spaces up to continuous\nequivalence.",
    "pdf_url": "http://arxiv.org/pdf/2410.13150v1",
    "published": "2024-10-17T02:08:46+00:00",
    "categories": [
      "math.LO",
      "Primary 03E15, 26A21, 54C05, 03D55, Secondary 06A07"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13149v1",
    "title": "Power in Numbers: Primitive Algorithm for Swarm Robot Navigation in Unknown Environments",
    "authors": [
      "Yusuke Tsunoda",
      "Shoken Otsuka",
      "Kazuki Ito",
      "Runze Xiao",
      "Keisuke Naniwa",
      "Yuichiro Sueoka",
      "Koichi Osuka"
    ],
    "abstract": "Recently, the navigation of mobile robots in unknown environments has become\na particularly significant research topic. Previous studies have primarily\nemployed real-time environmental mapping using cameras and LiDAR, along with\nself-localization and path generation based on those maps. Additionally, there\nis research on Sim-to-Real transfer, where robots acquire behaviors through\npre-trained reinforcement learning and apply these learned actions in\nreal-world navigation. However, strictly the observe action and modelling of\nunknown environments that change unpredictably over time with accuracy and\nprecision is an extremely complex endeavor. This study proposes a simple\nnavigation algorithm for traversing unknown environments by utilizes the number\nof swarm robots. The proposed algorithm assumes that the robot has only the\nsimple function of sensing the direction of the goal and the relative positions\nof the surrounding robots. The robots can navigate an unknown environment by\nsimply continuing towards the goal while bypassing surrounding robots. The\nmethod does not need to sense the environment, determine whether they or other\nrobots are stuck, or do the complicated inter-robot communication. We\nmathematically validate the proposed navigation algorithm, present numerical\nsimulations based on the potential field method, and conduct experimental\ndemonstrations using developed robots based on the sound fields for navigation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13149v1",
    "published": "2024-10-17T02:08:34+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13148v2",
    "title": "Learning Efficient Representations of Neutrino Telescope Events",
    "authors": [
      "Felix J. Yu",
      "Nicholas Kamp",
      "Carlos A. Argüelles"
    ],
    "abstract": "Neutrino telescopes detect rare interactions of particles produced in some of\nthe most extreme environments in the Universe. This is accomplished by\ninstrumenting a cubic-kilometer volume of naturally occurring transparent\nmedium with light sensors. Given their substantial size and the high frequency\nof background interactions, these telescopes amass an enormous quantity of\nlarge variance, high-dimensional data. These attributes create substantial\nchallenges for analyzing and reconstructing interactions, particularly when\nutilizing machine learning (ML) techniques. In this paper, we present a novel\napproach, called om2vec, that employs transformer-based variational\nautoencoders to efficiently represent neutrino telescope events by learning\ncompact and descriptive latent representations. We demonstrate that these\nlatent representations offer enhanced flexibility and improved computational\nefficiency, thereby facilitating downstream tasks in data analysis.",
    "pdf_url": "http://arxiv.org/pdf/2410.13148v2",
    "published": "2024-10-17T02:07:54+00:00",
    "categories": [
      "physics.data-an",
      "astro-ph.IM",
      "cs.LG",
      "hep-ex"
    ],
    "primary_category": "physics.data-an"
  },
  {
    "id": "http://arxiv.org/abs/2410.13147v10",
    "title": "AgentDrug: Utilizing Large Language Models in an Agentic Workflow for Zero-Shot Molecular Optimization",
    "authors": [
      "Khiem Le",
      "Ting Hua",
      "Nitesh V. Chawla"
    ],
    "abstract": "Molecular optimization -- modifying a given molecule to improve desired\nproperties -- is a fundamental task in drug discovery. While LLMs hold the\npotential to solve this task using natural language to drive the optimization,\nstraightforward prompting achieves limited accuracy. In this work, we propose\nAgentDrug, an agentic workflow that leverages LLMs in a structured refinement\nprocess to achieve significantly higher accuracy. AgentDrug defines a nested\nrefinement loop: the inner loop uses feedback from cheminformatics toolkits to\nvalidate molecular structures, while the outer loop guides the LLM with generic\nfeedback and a gradient-based objective to steer the molecule toward property\nimprovement. We evaluate AgentDrug on benchmarks with both single- and\nmulti-property optimization under loose and strict thresholds. Results\ndemonstrate significant performance gains over previous methods. With\nQwen-2.5-3B, AgentDrug improves accuracy by 20.7\\% (loose) and 16.8\\% (strict)\non six single-property tasks, and by 7.0\\% and 5.3\\% on eight multi-property\ntasks. With larger model Qwen-2.5-7B, AgentDrug further improves accuracy on 6\nsingle-property objectives by 28.9\\% (loose) and 29.0\\% (strict), and on 8\nmulti-property objectives by 14.9\\% (loose) and 13.2\\% (strict).",
    "pdf_url": "http://arxiv.org/pdf/2410.13147v10",
    "published": "2024-10-17T02:04:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13146v2",
    "title": "debiaSAE: Benchmarking and Mitigating Vision-Language Model Bias",
    "authors": [
      "Kuleen Sasse",
      "Shan Chen",
      "Jackson Pond",
      "Danielle Bitterman",
      "John Osborne"
    ],
    "abstract": "As Vision Language Models (VLMs) gain widespread use, their fairness remains\nunder-explored. In this paper, we analyze demographic biases across five models\nand six datasets. We find that portrait datasets like UTKFace and CelebA are\nthe best tools for bias detection, finding gaps in performance and fairness for\nboth LLaVa and CLIP models. Scene-based datasets like PATA and VLStereoSet fail\nto be useful benchmarks for bias due to their text prompts allowing the model\nto guess the answer without a picture. As for pronoun-based datasets like\nVisoGender, we receive mixed signals as only some subsets of the data are\nuseful in providing insights. To alleviate these two problems, we introduce a\nmore rigorous evaluation dataset and a debiasing method based on Sparse\nAutoencoders to help reduce bias in models. We find that our data set generates\nmore meaningful errors than the previous data sets. Furthermore, our debiasing\nmethod improves fairness, gaining 5-15 points in performance over the baseline.\nThis study displays the problems with the current benchmarks for measuring\ndemographic bias in Vision Language Models and introduces both a more effective\ndataset for measuring bias and a novel and interpretable debiasing method based\non Sparse Autoencoders.",
    "pdf_url": "http://arxiv.org/pdf/2410.13146v2",
    "published": "2024-10-17T02:03:27+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13145v1",
    "title": "Multihyperuniformity in high entropy MXenes",
    "authors": [
      "Yu Liu",
      "Mohan Chen"
    ],
    "abstract": "MXenes are a large family of two-dimensional transition metal carbides and\nnitrides that possess excellent electrical conductivity, high volumetric\ncapacitance, great mechanical properties, and hydrophilicity. In this work, we\ngeneralize the concept of multihyperuniformity (MH), an exotic state that can\nexist in a disordered multi-component system, to two-dimensional materials\nMXenes. Disordered hyperuniform systems possess an isotropic local structure\nthat lacks traditional translational and orientational order, yet they\ncompletely suppress infinite-wavelength density fluctuations as in perfect\ncrystals and, in this sense, possess a hidden long-range order. In particular,\nwe evaluate the static structure factor of the individual components present in\nthe high entropy (HE) MXene experimental sample TiVCMoCr based on high-solution\nSEM imaging data, which suggests this HE MXene system is at least effectively\nmultihyperuniform. We then devise a packing algorithm to generate\nmultihyperuniform models of HE MXene systems. The MH HE MXenes are predicted to\nbe energetically more stable compared to the prevailing (quasi)random models of\nthe HE MXenes due to the hidden long-range order. Moreover, the MH structure\nexhibits a distinctly smaller lattice distortion, which has a vital effect on\nthe electronic properties of HE MXenes, such as the density of states and\ncharge distribution. This systematic study of HE MXenes strengthens our\nfundamental understanding of these systems, and suggests possible exotic\nphysical properties, as endowed by the multihyperuniformity.",
    "pdf_url": "http://arxiv.org/pdf/2410.13145v1",
    "published": "2024-10-17T02:03:05+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2410.13144v1",
    "title": "A Dynamic Coupling Model of Optical Conductivity in Mixed-Valence Systems",
    "authors": [
      "Kin Yip Wong"
    ],
    "abstract": "Using Linear Response Theory, with appropriate wave functions and energies\nfrom perturbation method, the absorption profiles can be calculated for all\nthree classes of mixed-valence systems as defined by Robin and Day : Class III\n(delocalized), Class I (localized) and Class II (intermediate between III and\nI). Based on these absorption profiles, one can calculate the corresponding\nfrequency-dependent optical conductivity profiles with the following results:\nFor all three classes, the optical conductivity profiles are similar to their\ncorresponding absorption profiles in regard to band shape and polarization,\nexcept peaks of these profiles tend to shift toward higher frequency with\nrespect to the absorption profiles. The charge transfer absorption (CT band) is\nthe major contributors of optical conductivity. Moreover, the CT-induced IR\nband, also contributes to optical conductivity, as it borrows its intensity\nfrom the CT band and the amount of borrowing depends on its proximity to the\nlatter, as in Class II.",
    "pdf_url": "http://arxiv.org/pdf/2410.13144v1",
    "published": "2024-10-17T02:01:20+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2410.13143v2",
    "title": "Azimuthal Correlation Anisotropies in p + p Collisions Simulated by Pythia",
    "authors": [
      "Manuel Sebastian Torres",
      "Yicheng Feng",
      "Fuqiang Wang"
    ],
    "abstract": "Stimulated by the keen interest of possible collective behavior in\nhigh-energy proton-proton and proton-nucleus collisions, we study two-particle\nangular correlations in pseudorapidity and azimuthal differences in simulated p\n+ p interactions by the Pythia 8 event generator. Multi-parton interactions and\ncolor connection are included in these simulations which have been perceived to\nproduce collectivity in final-state particles. Meanwhile, contributions from\ngenuine few-body nonflow correlations, not of collective flow behavior, are\nknown to be severe in those small-system collisions. We present our Pythia\ncorrelation studies in a pedagogical way and report azimuthal harmonic\nanisotropies analyzed by several methods. We observe anisotropies in those\nPythia simulated events qualitatively and semi-quantitatively similar to\nexperimental data. Our findings highlight the delicate nature of azimuthal\nanisotropies in small-system collisions, and provide a benchmark helping\nimprove data analysis and interpret experimental measurements in small-system\ncollisions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13143v2",
    "published": "2024-10-17T02:00:39+00:00",
    "categories": [
      "nucl-th",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2410.13142v3",
    "title": "Agnostic Characterization of Interference in Randomized Experiments",
    "authors": [
      "David Choi"
    ],
    "abstract": "We give an approach for characterizing interference by lower bounding the\nnumber of units whose outcome depends on certain groups of treated individuals,\nsuch as depending on the treatment of others, or others who are at least a\ncertain distance away. The approach is applicable to randomized experiments\nwith binary-valued outcomes. Asymptotically conservative point estimates and\none-sided confidence intervals may be constructed with no assumptions beyond\nthe known randomization design, allowing the approach to be used when\ninterference is poorly understood, or when an observed network might only be a\ncrude proxy for the underlying social mechanisms. Point estimates are equal to\nHajek-weighted comparisons of units with differing levels of treatment\nexposure. Empirically, we find that the size of our interval estimates is\ncompetitive with (and often smaller than) those of the EATE, an assumption-lean\ntreatment effect, suggesting that the proposed estimands may be intrinsically\neasier to estimate than treatment effects.",
    "pdf_url": "http://arxiv.org/pdf/2410.13142v3",
    "published": "2024-10-17T01:59:08+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13141v1",
    "title": "Federated scientific machine learning for approximating functions and solving differential equations with data heterogeneity",
    "authors": [
      "Handi Zhang",
      "Langchen Liu",
      "Lu Lu"
    ],
    "abstract": "By leveraging neural networks, the emerging field of scientific machine\nlearning (SciML) offers novel approaches to address complex problems governed\nby partial differential equations (PDEs). In practical applications, challenges\narise due to the distributed essence of data, concerns about data privacy, or\nthe impracticality of transferring large volumes of data. Federated learning\n(FL), a decentralized framework that enables the collaborative training of a\nglobal model while preserving data privacy, offers a solution to the challenges\nposed by isolated data pools and sensitive data issues. Here, this paper\nexplores the integration of FL and SciML to approximate complex functions and\nsolve differential equations. We propose two novel models: federated\nphysics-informed neural networks (FedPINN) and federated deep operator networks\n(FedDeepONet). We further introduce various data generation methods to control\nthe degree of non-independent and identically distributed (non-iid) data and\nutilize the 1-Wasserstein distance to quantify data heterogeneity in function\napproximation and PDE learning. We systematically investigate the relationship\nbetween data heterogeneity and federated model performance. Additionally, we\npropose a measure of weight divergence and develop a theoretical framework to\nestablish growth bounds for weight divergence in federated learning compared to\ntraditional centralized learning. To demonstrate the effectiveness of our\nmethods, we conducted 10 experiments, including 2 on function approximation, 5\nPDE problems on FedPINN, and 3 PDE problems on FedDeepONet. These experiments\ndemonstrate that proposed federated methods surpass the models trained only\nusing local data and achieve competitive accuracy of centralized models trained\nusing all data.",
    "pdf_url": "http://arxiv.org/pdf/2410.13141v1",
    "published": "2024-10-17T01:57:04+00:00",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13140v1",
    "title": "Let Students Take the Wheel: Introducing Post-Quantum Cryptography with Active Learning",
    "authors": [
      "Ainaz Jamshidi",
      "Khushdeep Kaur",
      "Aryya Gangopadhyay",
      "Lei Zhang"
    ],
    "abstract": "Quantum computing presents a double-edged sword: while it has the potential\nto revolutionize fields such as artificial intelligence, optimization,\nhealthcare, and so on, it simultaneously poses a threat to current\ncryptographic systems, such as public-key encryption. To address this threat,\npost-quantum cryptography (PQC) has been identified as the solution to secure\nexisting software systems, promoting a national initiative to prepare the next\ngeneration with the necessary knowledge and skills. However, PQC is an emerging\ninterdisciplinary topic, presenting significant challenges for educators and\nlearners. This research proposes a novel active learning approach and assesses\nthe best practices for teaching PQC to undergraduate and graduate students in\nthe discipline of information systems.\n  Our contributions are two-fold. First, we compare two instructional methods:\n1) traditional faculty-led lectures and 2) student-led seminars, both\nintegrated with active learning techniques such as hands-on coding exercises\nand Kahoot games. The effectiveness of these methods is evaluated through\nstudent assessments and surveys. Second, we have published our lecture video,\nslides, and findings so that other researchers and educators can reuse the\ncourseware and materials to develop their own PQC learning modules.\n  We employ statistical analysis (e.g., t-test and chi-square test) to compare\nthe learning outcomes and students' feedback between the two learning methods\nin each course. Our findings suggest that student-led seminars significantly\nenhance learning outcomes, particularly for graduate students, where a notable\nimprovement in comprehension and engagement is observed. Moving forward, we aim\nto scale these modules to diverse educational contexts and explore additional\nactive learning and experiential learning strategies for teaching complex\nconcepts of quantum information science.",
    "pdf_url": "http://arxiv.org/pdf/2410.13140v1",
    "published": "2024-10-17T01:52:03+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13139v2",
    "title": "See Behind Walls in Real-time Using Aerial Drones and Augmented Reality",
    "authors": [
      "Sikai Yang",
      "Kang Yang",
      "Yuning Chen",
      "Fan Zhao",
      "Wan Du"
    ],
    "abstract": "This work presents ARD2, a framework that enables real-time through-wall\nsurveillance using two aerial drones and an augmented reality (AR) device. ARD2\nconsists of two main steps: target direction estimation and contour\nreconstruction. In the first stage, ARD2 leverages geometric relationships\nbetween the drones, the user, and the target to project the target's direction\nonto the user's AR display. In the second stage, images from the drones are\nsynthesized to reconstruct the target's contour, allowing the user to visualize\nthe target behind walls. Experimental results demonstrate the system's accuracy\nin both direction estimation and contour reconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2410.13139v2",
    "published": "2024-10-17T01:51:58+00:00",
    "categories": [
      "cs.MA",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13138v1",
    "title": "Data Defenses Against Large Language Models",
    "authors": [
      "William Agnew",
      "Harry H. Jiang",
      "Cella Sum",
      "Maarten Sap",
      "Sauvik Das"
    ],
    "abstract": "Large language models excel at performing inference over text to extract\ninformation, summarize information, or generate additional text. These\ninference capabilities are implicated in a variety of ethical harms spanning\nsurveillance, labor displacement, and IP/copyright theft. While many policy,\nlegal, and technical mitigations have been proposed to counteract these harms,\nthese mitigations typically require cooperation from institutions that move\nslower than technical advances (i.e., governments) or that have few incentives\nto act to counteract these harms (i.e., the corporations that create and profit\nfrom these LLMs). In this paper, we define and build \"data defenses\" -- a novel\nstrategy that directly empowers data owners to block LLMs from performing\ninference on their data. We create data defenses by developing a method to\nautomatically generate adversarial prompt injections that, when added to input\ntext, significantly reduce the ability of LLMs to accurately infer personally\nidentifying information about the subject of the input text or to use\ncopyrighted text in inference. We examine the ethics of enabling such direct\nresistance to LLM inference, and argue that making data defenses that resist\nand subvert LLMs enables the realization of important values such as data\nownership, data sovereignty, and democratic control over AI systems. We verify\nthat our data defenses are cheap and fast to generate, work on the latest\ncommercial and open-source LLMs, resistance to countermeasures, and are robust\nto several different attack settings. Finally, we consider the security\nimplications of LLM data defenses and outline several future research\ndirections in this area. Our code is available at\nhttps://github.com/wagnew3/LLMDataDefenses and a tool for using our defenses to\nprotect text against LLM inference is at\nhttps://wagnew3.github.io/LLM-Data-Defenses/.",
    "pdf_url": "http://arxiv.org/pdf/2410.13138v1",
    "published": "2024-10-17T01:51:56+00:00",
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13137v2",
    "title": "The influence of the cloud virial parameter on the initial mass function",
    "authors": [
      "Sajay Sunny Mathew",
      "Christoph Federrath",
      "Amit Seta"
    ],
    "abstract": "Crucial for star formation is the interplay between gravity and turbulence.\nThe observed cloud virial parameter, $\\alpha_{\\mathrm{vir}}$, which is the\nratio of twice the turbulent kinetic energy to the gravitational energy, is\nfound to vary significantly in different environments, where the scatter among\nindividual star-forming clouds can exceed an order of magnitude. Therefore, a\nstrong dependence of the initial mass function (IMF) on $\\alpha_{\\mathrm{vir}}$\nmay challenge the notion of a universal IMF. To determine the role of\n$\\alpha_{\\mathrm{vir}}$ on the IMF, we compare the star-particle mass functions\nobtained in high-resolution magnetohydrodynamical simulations including jet and\nheating feedback, with $\\alpha_{\\mathrm{vir}}=0.0625$, $0.125$, and $0.5$. We\nfind that varying $\\alpha_{\\mathrm{vir}}$ from $\\alpha_{\\mathrm{vir}}\\sim0.5$\nto $\\alpha_{\\mathrm{vir}}<0.1$ shifts the peak of the IMF to lower masses by a\nfactor of $\\sim2$ and increases the star formation rate by a similar factor.\nThe dependence of the IMF and star formation rate on $\\alpha_{\\mathrm{vir}}$ is\nnon-linear, with the dependence subsiding at $\\alpha_{\\mathrm{vir}}<0.1$. Our\nstudy shows a systematic dependence of the IMF on $\\alpha_{\\mathrm{vir}}$. Yet,\nit may not be measurable easily in observations, considering the uncertainties,\nand the relatively weak dependence found in this study.",
    "pdf_url": "http://arxiv.org/pdf/2410.13137v2",
    "published": "2024-10-17T01:48:23+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13136v1",
    "title": "Unlocking the Capabilities of Masked Generative Models for Image Synthesis via Self-Guidance",
    "authors": [
      "Jiwan Hur",
      "Dong-Jae Lee",
      "Gyojin Han",
      "Jaehyun Choi",
      "Yunho Jeon",
      "Junmo Kim"
    ],
    "abstract": "Masked generative models (MGMs) have shown impressive generative ability\nwhile providing an order of magnitude efficient sampling steps compared to\ncontinuous diffusion models. However, MGMs still underperform in image\nsynthesis compared to recent well-developed continuous diffusion models with\nsimilar size in terms of quality and diversity of generated samples. A key\nfactor in the performance of continuous diffusion models stems from the\nguidance methods, which enhance the sample quality at the expense of diversity.\nIn this paper, we extend these guidance methods to generalized guidance\nformulation for MGMs and propose a self-guidance sampling method, which leads\nto better generation quality. The proposed approach leverages an auxiliary task\nfor semantic smoothing in vector-quantized token space, analogous to the\nGaussian blur in continuous pixel space. Equipped with the parameter-efficient\nfine-tuning method and high-temperature sampling, MGMs with the proposed\nself-guidance achieve a superior quality-diversity trade-off, outperforming\nexisting sampling methods in MGMs with more efficient training and sampling\ncosts. Extensive experiments with the various sampling hyperparameters confirm\nthe effectiveness of the proposed self-guidance.",
    "pdf_url": "http://arxiv.org/pdf/2410.13136v1",
    "published": "2024-10-17T01:48:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13911v2",
    "title": "GraspDiffusion: Synthesizing Realistic Whole-body Hand-Object Interaction",
    "authors": [
      "Patrick Kwon",
      "Chen Chen",
      "Hanbyul Joo"
    ],
    "abstract": "Recent generative models can synthesize high-quality images but often fail to\ngenerate humans interacting with objects using their hands. This arises mostly\nfrom the model's misunderstanding of such interactions, and the hardships of\nsynthesizing intricate regions of the body. In this paper, we propose\nGraspDiffusion, a novel generative method that creates realistic scenes of\nhuman-object interaction. Given a 3D object mesh, GraspDiffusion first\nconstructs life-like whole-body poses with control over the object's location\nrelative to the human body. This is achieved by separately leveraging the\ngenerative priors for 3D body and hand poses, optimizing them into a joint\ngrasping pose. The resulting pose guides the image synthesis to correctly\nreflect the intended interaction, allowing the creation of realistic and\ndiverse human-object interaction scenes. We demonstrate that GraspDiffusion can\nsuccessfully tackle the relatively uninvestigated problem of generating\nfull-bodied human-object interactions while outperforming previous methods.\nCode and models will be available at https://webtoon.github.io/GraspDiffusion",
    "pdf_url": "http://arxiv.org/pdf/2410.13911v2",
    "published": "2024-10-17T01:45:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13135v4",
    "title": "Conservation law for angular momentum based on optical field derivatives: Analysis of optical spin-orbit conversion",
    "authors": [
      "Shun Hashiyada",
      "Yoshito Y. Tanaka"
    ],
    "abstract": "We present a theoretical framework for analyzing the loss of optical angular\nmomentum (AM), including spin (SAM) and orbital (OAM) components, in\nlight-matter interactions. Conventional SAM and OAM conservation laws rely on\ntransverse field components, neglecting longitudinal fields and limiting\napplicability to vacuum. Our approach defines optical AM using time derivatives\nof the electric and magnetic fields, yielding a gauge-invariant formulation\nthat includes both transverse and longitudinal components and explicitly\nincorporates charge and current densities. This enables a more complete\ndescription of AM dissipation in materials. We apply this framework to analyze\nspin-orbit conversion (SOC) in two scenarios: scattering of circularly\npolarized (CP) beams by a gold nanoparticle and focusing of CP and linearly\npolarized optical vortex beams by a lens. The results show that SOC depends on\nparticle size and polarization, with notable OAM loss in larger particles and\nCP beam focusing. This framework enables the evaluation of previously\noverlooked SAM and OAM losses, providing a powerful tool for studying systems\nin which the analysis of AM losses is intrinsically important, such as chiral\nmaterials, as well as for designing photonic devices and exploring light-matter\ninteractions at the nanoscale.",
    "pdf_url": "http://arxiv.org/pdf/2410.13135v4",
    "published": "2024-10-17T01:44:17+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2410.13134v1",
    "title": "Picometer-level quadrangle optical bonding bench for testing interferometric technologies in TianQin",
    "authors": [
      "Hao Yan",
      "Xiang Lin",
      "Siyuan Xie"
    ],
    "abstract": "Interferometric techniques are crucial for space-based gravitational wave\ndetection, requiring a picometer-level stable optical bench, precise\nphasemeter, interstellar transponder low-light phase locking, and laser\nsideband communication. These technologies must be rigorously tested on the\nground before deployment in space. The AEI group has previously developed a\npicometer-stable hexapod optical bench to verify the linearity and precision of\nphase extraction for LISA. In this paper, we introduce a quadrangle\nquasi-monolithic optical bench aimed at simplifying the system and expanding\nthe range of tested interferometric techniques for TianQin. Experimental\nresults demonstrate that the system achieves picometer-level optical pathlength\nstability and phase resolution over a large dynamic range. In the laser\ntransponder link test, the light phase-locked residual noise is lower than\n${\\rm 10^{-4}\\,rad/Hz^{1/2}}$ above millihertz frequency range, and the laser\nsideband modulation has no significant coupling to the measurements in the\n${\\rm mHz-Hz}$ band. These results provide critical technical validation for\nthe implementation of future gravitational wave detection in space.",
    "pdf_url": "http://arxiv.org/pdf/2410.13134v1",
    "published": "2024-10-17T01:40:47+00:00",
    "categories": [
      "physics.ins-det",
      "astro-ph.IM"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2410.13133v1",
    "title": "Exploring Scientific Contributions through Citation Context and Division of Labor",
    "authors": [
      "Liyue Chen",
      "Jielan Ding",
      "Donghuan Song",
      "Zihao Qu"
    ],
    "abstract": "Scientific contributions are a direct reflection of a research paper's value,\nillustrating its impact on existing theories or practices. Existing measurement\nmethods assess contributions based on the authors' perceived or self-identified\ncontributions, while the actual contributions made by the papers are rarely\ninvestigated. This study measures the actual contributions of papers published\nin Nature and Science using 1.53 million citation contexts from citing\nliterature and explores the impact pattern of division of labor (DOL) inputs on\nthe actual contributions of papers from an input-output perspective. Results\nshow that experimental contributions are predominant, contrasting with the\ntheoretical and methodological contributions self-identified by authors. This\nhighlights a notable discrepancy between actual contributions and authors'\nself-perceptions, indicating an 'ideal bias'. There is no significant\ncorrelation between the overall labor input pattern and the actual contribution\npattern of papers, but a positive correlation appears between input and output\nfor specific types of scientific contributions, reflecting a 'more effort, more\ngain' effect. Different types of DOL input in papers exhibit a notable\nco-occurrence trend. However, once the paper reaches the dissemination stage,\nthe co-occurrence of different types of actual contributions becomes weaker,\nindicating that a paper's contributions are often focused on a single type.",
    "pdf_url": "http://arxiv.org/pdf/2410.13133v1",
    "published": "2024-10-17T01:40:42+00:00",
    "categories": [
      "cs.DL",
      "stat.AP"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13132v1",
    "title": "The Gan-Gross-Prasad period of Klingen Eisenstein families over unitary groups",
    "authors": [
      "Ruichen Xu"
    ],
    "abstract": "In this article, we compute the Gan-Gross-Prasad period integral of Klingen\nEisenstein series over the unitary group $\\mathrm{U}(m+1, n+1)$ with a cuspidal\nautomorphic form over $\\mathrm{U}(m+1, n)$, and show that it is related to\ncertain special Rankin-Selberg $L$-values. We $p$-adically interpolate these\nGan-Gross-Prasad period integrals as the Klingen Eisenstein series and the\ncuspidal automorphic form vary in Hida families. As a byproduct, we obtain a\n$p$-adic $L$-function of Rankin-Selberg type over $\\mathrm{U}(m,n) \\times\n\\mathrm{U}(m+1, n)$. The ultimate motivation is to show the $p$-primitive\nproperty of Klingen Eisenstein series over unitary groups, by computing such\nGan-Gross-Prasad period integrals, and this article is a starting point of this\nproject. The $p$-primitivity of Eisenstein series is an essential property in\nthe automorphic method in Iwasawa theory.",
    "pdf_url": "http://arxiv.org/pdf/2410.13132v1",
    "published": "2024-10-17T01:36:55+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13131v1",
    "title": "Study of Weighted Residual Layered Belief Propagation for Decoding of LDPC Codes",
    "authors": [
      "H. Touati",
      "R. C. de Lamare"
    ],
    "abstract": "In this work, we investigate the decoding of Low-Density Parity-Check (LDPC)\ncodes using informed dynamic scheduling algorithms that require a reduced\nnumber of iterations. In particular, we devise the weighted residual layered\nbelief propagation (WR-LBP) decoding algorithm, which exploits the residual\nwithin a structured layer framework to speed the number of required decoding\niterations. The proposed WR-LBP algorithm is assessed against important LDPC\ndecoding algorithms, in terms of the number of iterations required for\nconvergence and the bit error rates.",
    "pdf_url": "http://arxiv.org/pdf/2410.13131v1",
    "published": "2024-10-17T01:35:02+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2410.13130v1",
    "title": "Thin MC left regular bands",
    "authors": [
      "Aram Dermenjian"
    ],
    "abstract": "We define MC left regular bands and study their adjacency graphs. We prove\nthat for thin MC left regular bands, the adjacency graph is particularly nice\nand is represented by edge labeled graphs where every simple cycle has an even\nnumber of edges. Conversely, we define a set of graphs which we call thin LRB\ngraphs which encode rank two thin MC left regular bands. Along the way, we\nprovide a criterion for showing when the face poset of a left regular band is a\nmeet-semilattice.",
    "pdf_url": "http://arxiv.org/pdf/2410.13130v1",
    "published": "2024-10-17T01:34:35+00:00",
    "categories": [
      "math.CO",
      "20M25, 06F05, 05C25, 05C90"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13129v2",
    "title": "Structural properties of a symmetric Toeplitz and Hankel matrices",
    "authors": [
      "Hojin Chu",
      "Homoon Ryu"
    ],
    "abstract": "In this paper, we investigate properties of a symmetric Toeplitz matrix and a\nHankel matrix by studying the components of its graph. To this end, we\nintroduce the notion of ``weighted Toeplitz graph\" and ``weighted Hankel\ngraph\", which are weighted graphs whose adjacency matrix are a symmetric\nToeplitz matrix and a Hankel matrix, respectively. By studying the components\nof a weighted Toeplitz graph, we show that the Frobenius normal form of a\nsymmetric Toeplitz matrix is a direct sum of symmetric irreducible Toeplitz\nmatrices. Similarly, by studying the components of a weighted Hankel matrix, we\nshow that the Frobenius normal form of a Hankel matrix is a direct sum of\nirreducible Hankel matrices.",
    "pdf_url": "http://arxiv.org/pdf/2410.13129v2",
    "published": "2024-10-17T01:34:26+00:00",
    "categories": [
      "math.CO",
      "05C22, 05C50, 15B05"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13128v1",
    "title": "Entropy-Driven Preordering Assists Nucleation in Polyethylene",
    "authors": [
      "Renkuan Cao",
      "Fan Peng",
      "Yunhan Zhang",
      "Hao Sun",
      "Ziwei Liu",
      "Tingyu Xu",
      "Liangbin Li"
    ],
    "abstract": "Non-classical two-step nucleation including preordering and crystal\nnucleation has been widely proposed to challenge the one-step nucleation\nframework in diverse materials, while what drives preordering has not been\nexplicitly resolved yet. With molecular dynamics simulation, we find that\ntwo-step nucleation occurs in polyethylene, during which preordering precedes\nthrough the coupling between intrachain conformation and interchain orientation\norders. Unexpectedly, preordering is driven by entropy rather than enthalpy,\nduring which the interchain translational entropy gain compensates for the\nintrachain conformation entropy loss. This entropy-driven mechanism resolves\nthe longstanding puzzle why flexible polymers with high entropy penalty still\nshow high nucleation rate and opens a new perspective for understanding\nnucleation of synthetic and bio-polymers with conformation and orientation\norders.",
    "pdf_url": "http://arxiv.org/pdf/2410.13128v1",
    "published": "2024-10-17T01:34:06+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2410.13127v2",
    "title": "Energy dissipation near the outflow boundary in the vanishing viscosity limit",
    "authors": [
      "Jincheng Yang",
      "Vincent R. Martinez",
      "Anna L. Mazzucato",
      "Alexis F. Vasseur"
    ],
    "abstract": "We consider the incompressible Navier-Stokes and Euler equations in a bounded\ndomain with non-characteristic boundary condition, and study the energy\ndissipation near the outflow boundary in the zero-viscosity limit. We show that\nin a general setting, the energy dissipation rate is proportional to $\\bar U\n\\bar V ^2$, where $\\bar U$ is the strength of the suction and $\\bar V$ is the\ntangential component of the difference between the Euler and the Navier-Stokes\nsolutions on the outflow boundary. Moreover, we show that the enstrophy within\na layer of order $\\nu / \\bar U$ is comparable with the total enstrophy. The\nrate of enstrophy production near the boundary is inversely proportional to\n$\\nu$.",
    "pdf_url": "http://arxiv.org/pdf/2410.13127v2",
    "published": "2024-10-17T01:30:30+00:00",
    "categories": [
      "math.AP",
      "76D05, 35Q30"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13126v1",
    "title": "ALOHA Unleashed: A Simple Recipe for Robot Dexterity",
    "authors": [
      "Tony Z. Zhao",
      "Jonathan Tompson",
      "Danny Driess",
      "Pete Florence",
      "Kamyar Ghasemipour",
      "Chelsea Finn",
      "Ayzaan Wahid"
    ],
    "abstract": "Recent work has shown promising results for learning end-to-end robot\npolicies using imitation learning. In this work we address the question of how\nfar can we push imitation learning for challenging dexterous manipulation\ntasks. We show that a simple recipe of large scale data collection on the ALOHA\n2 platform, combined with expressive models such as Diffusion Policies, can be\neffective in learning challenging bimanual manipulation tasks involving\ndeformable objects and complex contact rich dynamics. We demonstrate our recipe\non 5 challenging real-world and 3 simulated tasks and demonstrate improved\nperformance over state-of-the-art baselines. The project website and videos can\nbe found at aloha-unleashed.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2410.13126v1",
    "published": "2024-10-17T01:29:49+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13125v1",
    "title": "Transformers4NewsRec: A Transformer-based News Recommendation Framework",
    "authors": [
      "Dairui Liu",
      "Honghui Du",
      "Boming Yang",
      "Neil Hurley",
      "Aonghus Lawlor",
      "Irene Li",
      "Derek Greene",
      "Ruihai Dong"
    ],
    "abstract": "Pre-trained transformer models have shown great promise in various natural\nlanguage processing tasks, including personalized news recommendations. To\nharness the power of these models, we introduce Transformers4NewsRec, a new\nPython framework built on the \\textbf{Transformers} library. This framework is\ndesigned to unify and compare the performance of various news recommendation\nmodels, including deep neural networks and graph-based models.\nTransformers4NewsRec offers flexibility in terms of model selection, data\npreprocessing, and evaluation, allowing both quantitative and qualitative\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2410.13125v1",
    "published": "2024-10-17T01:27:57+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13124v1",
    "title": "Just Add Force for Contact-Rich Robot Policies",
    "authors": [
      "William Xie",
      "Stefan Caldararu",
      "Nikolaus Correll"
    ],
    "abstract": "Robot trajectories used for learning end-to-end robot policies typically\ncontain end-effector and gripper position, workspace images, and language.\nPolicies learned from such trajectories are unsuitable for delicate grasping,\nwhich require tightly coupled and precise gripper force and gripper position.\nWe collect and make publically available 130 trajectories with force feedback\nof successful grasps on 30 unique objects. Our current-based method for sensing\nforce, albeit noisy, is gripper-agnostic and requires no additional hardware.\nWe train and evaluate two diffusion policies: one with (forceful) the collected\nforce feedback and one without (position-only). We find that forceful policies\nare superior to position-only policies for delicate grasping and are able to\ngeneralize to unseen delicate objects, while reducing grasp policy latency by\nnear 4x, relative to LLM-based methods. With our promising results on limited\ndata, we hope to signal to others to consider investing in collecting force and\nother such tactile information in new datasets, enabling more robust,\ncontact-rich manipulation in future robot foundation models. Our data, code,\nmodels, and videos are viewable at https://justaddforce.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2410.13124v1",
    "published": "2024-10-17T01:27:25+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2410.13123v2",
    "title": "Improved Kernelization and Fixed-parameter Algorithms for Bicluster Editing",
    "authors": [
      "Manuel Lafond"
    ],
    "abstract": "Given a bipartite graph $G$, the \\textsc{Bicluster Editing} problem asks for\nthe minimum number of edges to insert or delete in $G$ so that every connected\ncomponent is a bicluster, i.e. a complete bipartite graph. This has several\napplications, including in bioinformatics and social network analysis. In this\nwork, we study the parameterized complexity under the natural parameter $k$,\nwhich is the number of allowed modified edges. We first show that one can\nobtain a kernel with $4.5k$ vertices, an improvement over the previously known\nquadratic kernel. We then propose an algorithm that runs in time\n$O^*(2.581^k)$. Our algorithm has the advantage of being conceptually simple\nand should be easy to implement.",
    "pdf_url": "http://arxiv.org/pdf/2410.13123v2",
    "published": "2024-10-17T01:24:20+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2410.13122v1",
    "title": "Boosting Imperceptibility of Stable Diffusion-based Adversarial Examples Generation with Momentum",
    "authors": [
      "Nashrah Haque",
      "Xiang Li",
      "Zhehui Chen",
      "Yanzhao Wu",
      "Lei Yu",
      "Arun Iyengar",
      "Wenqi Wei"
    ],
    "abstract": "We propose a novel framework, Stable Diffusion-based Momentum Integrated\nAdversarial Examples (SD-MIAE), for generating adversarial examples that can\neffectively mislead neural network classifiers while maintaining visual\nimperceptibility and preserving the semantic similarity to the original class\nlabel. Our method leverages the text-to-image generation capabilities of the\nStable Diffusion model by manipulating token embeddings corresponding to the\nspecified class in its latent space. These token embeddings guide the\ngeneration of adversarial images that maintain high visual fidelity. The\nSD-MIAE framework consists of two phases: (1) an initial adversarial\noptimization phase that modifies token embeddings to produce misclassified yet\nnatural-looking images and (2) a momentum-based optimization phase that refines\nthe adversarial perturbations. By introducing momentum, our approach stabilizes\nthe optimization of perturbations across iterations, enhancing both the\nmisclassification rate and visual fidelity of the generated adversarial\nexamples. Experimental results demonstrate that SD-MIAE achieves a high\nmisclassification rate of 79%, improving by 35% over the state-of-the-art\nmethod while preserving the imperceptibility of adversarial perturbations and\nthe semantic similarity to the original class label, making it a practical\nmethod for robust adversarial evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2410.13122v1",
    "published": "2024-10-17T01:22:11+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13121v1",
    "title": "Trust but Verify: Programmatic VLM Evaluation in the Wild",
    "authors": [
      "Viraj Prabhu",
      "Senthil Purushwalkam",
      "An Yan",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "abstract": "Vision-Language Models (VLMs) often generate plausible but incorrect\nresponses to visual queries. However, reliably quantifying the effect of such\nhallucinations in free-form responses to open-ended queries is challenging as\nit requires visually verifying each claim within the response. We propose\nProgrammatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating\nVLM responses to open-ended queries. To construct PROVE, we provide a large\nlanguage model (LLM) with a high-fidelity scene-graph representation\nconstructed from a hyper-detailed image caption, and prompt it to generate\ndiverse question-answer (QA) pairs, as well as programs that can be executed\nover the scene graph object to verify each QA pair. We thus construct a\nbenchmark of 10.5k challenging but visually grounded QA pairs. Next, to\nevaluate free-form model responses to queries in PROVE, we propose a\nprogrammatic evaluation strategy that measures both the helpfulness and\ntruthfulness of a response within a unified scene graph-based framework. We\nbenchmark the helpfulness-truthfulness trade-offs of a range of VLMs on PROVE,\nfinding that very few are in-fact able to achieve a good balance between the\ntwo. Project page: \\url{https://prove-explorer.netlify.app/}.",
    "pdf_url": "http://arxiv.org/pdf/2410.13121v1",
    "published": "2024-10-17T01:19:18+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13120v1",
    "title": "Choi matrices revisited. III",
    "authors": [
      "Kyung Hoon Han",
      "Seung-Hyeok Kye"
    ],
    "abstract": "We look for all linear isomorphisms from the mapping spaces onto the tensor\nproducts of matrices which send $k$-superpositive maps onto unnormalized\nbi-partite states of Schmidt numbers less than or equal to $k$. They also send\n$k$-positive maps onto $k$-block-positive matrices. We also look for all the\nbilinear pairings between the mapping spaces and tensor products of matrices\nwhich retain the usual duality between $k$-positivity and Schmidt numbers $\\le\nk$. They also retain the duality between $k$-superpositivity and\n$k$-block-positivity.",
    "pdf_url": "http://arxiv.org/pdf/2410.13120v1",
    "published": "2024-10-17T01:18:35+00:00",
    "categories": [
      "quant-ph",
      "math.OA"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13119v1",
    "title": "PGC 44685: A Dwarf Star-forming Lenticular Galaxy with Wolf-Rayet Population",
    "authors": [
      "Shiying Lu",
      "Qiusheng Gu",
      "Yulong Gao",
      "Yong Shi",
      "Luwenjia Zhou",
      "Rubén García-Benito",
      "Xiangdong Li",
      "Jiantong Cui",
      "Xin Li",
      "Liuze Long",
      "Zhengyi Chen"
    ],
    "abstract": "Lenticular galaxies (S0s) are formed mainly from the gas stripping of spirals\nin the cluster. But how S0s form and evolve in the field is still untangled.\nBased on spatially resolved observations from the optical Hispanic Astronomical\nCenter in Andalusia 3.5-m telescope with the PPAK Integral Field Spectroscopy\ninstrument and NOrthern Extended Millimeter Array, we study a dwarf (M*<10^9\nMsun) S0, PGC 44685, with triple star-forming regions in the central region,\nnamely A, B, and C, respectively. In northwest region C, we clearly detect the\nspectral features of Wolf-Rayet (WR) stars and quantify the WR population by\nstacking spectra with high WR significance. Most of the molecular gas is\nconcentrated in the region C(WR), and there is diffuse gas around regions A and\nB. The WR region possesses the strongest intensities of Ha, CO(1-0), and 3mm\ncontinuum, indicating its ongoing violent star formation (gas depletion\ntimescale $\\lesssim$25 Myr) with tentative hundreds (<500) km/s stellar winds\naccompanied by the WR phase. Most (~96%) of three star-forming regions show\nrelatively low metallicity distributions, suggesting possible (minor)\naccretions of metal-poor gas that trigger the subsequent complex star formation\nin a field S0 galaxy. We speculate that PGC 44685 will become quiescent in less\nthan 30 Myr if there is no new molecular gas to provide raw materials for star\nformation. The existence of this dwarf star-forming S0 presents an example of\nstar formation in the low-mass/metallicity S0 galaxy.",
    "pdf_url": "http://arxiv.org/pdf/2410.13119v1",
    "published": "2024-10-17T01:18:22+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2410.13118v1",
    "title": "Retrieval-Enhanced Named Entity Recognition",
    "authors": [
      "Enzo Shiraishi",
      "Raphael Y. de Camargo",
      "Henrique L. P. Silva",
      "Ronaldo C. Prati"
    ],
    "abstract": "When combined with In-Context Learning, a technique that enables models to\nadapt to new tasks by incorporating task-specific examples or demonstrations\ndirectly within the input prompt, autoregressive language models have achieved\ngood performance in a wide range of tasks and applications. However, this\ncombination has not been properly explored in the context of named entity\nrecognition, where the structure of this task poses unique challenges. We\npropose RENER (Retrieval-Enhanced Named Entity Recognition), a technique for\nnamed entity recognition using autoregressive language models based on\nIn-Context Learning and information retrieval techniques. When presented with\nan input text, RENER fetches similar examples from a dataset of training\nexamples that are used to enhance a language model to recognize named entities\nfrom this input text. RENER is modular and independent of the underlying\nlanguage model and information retrieval algorithms. Experimental results show\nthat in the CrossNER collection we achieve state-of-the-art performance with\nthe proposed technique and that information retrieval can increase the F-score\nby up to 11 percentage points.",
    "pdf_url": "http://arxiv.org/pdf/2410.13118v1",
    "published": "2024-10-17T01:12:48+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13117v2",
    "title": "Preference Diffusion for Recommendation",
    "authors": [
      "Shuo Liu",
      "An Zhang",
      "Guoqing Hu",
      "Hong Qian",
      "Tat-seng Chua"
    ],
    "abstract": "Recommender systems predict personalized item rankings based on user\npreference distributions derived from historical behavior data. Recently,\ndiffusion models (DMs) have gained attention in recommendation for their\nability to model complex distributions, yet current DM-based recommenders often\nrely on traditional objectives like mean squared error (MSE) or recommendation\nobjectives, which are not optimized for personalized ranking tasks or fail to\nfully leverage DM's generative potential. To address this, we propose\nPreferDiff, a tailored optimization objective for DM-based recommenders.\nPreferDiff transforms BPR into a log-likelihood ranking objective and\nintegrates multiple negative samples to better capture user preferences.\nSpecifically, we employ variational inference to handle the intractability\nthrough minimizing the variational upper bound and replaces MSE with cosine\nerror to improve alignment with recommendation tasks. Finally, we balance\nlearning generation and preference to enhance the training stability of DMs.\nPreferDiff offers three key benefits: it is the first personalized ranking loss\ndesigned specifically for DM-based recommenders and it improves ranking and\nfaster convergence by addressing hard negatives. We also prove that it is\ntheoretically connected to Direct Preference Optimization which indicates that\nit has the potential to align user preferences in DM-based recommenders via\ngenerative modeling. Extensive experiments across three benchmarks validate its\nsuperior recommendation performance and commendable general sequential\nrecommendation capabilities. Our codes are available at\nhttps://github.com/lswhim/PreferDiff.",
    "pdf_url": "http://arxiv.org/pdf/2410.13117v2",
    "published": "2024-10-17T01:02:04+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13116v2",
    "title": "Learning to Summarize from LLM-generated Feedback",
    "authors": [
      "Hwanjun Song",
      "Taewon Yun",
      "Yuho Lee",
      "Jihwan Oh",
      "Gihun Lee",
      "Jason Cai",
      "Hang Su"
    ],
    "abstract": "Developing effective text summarizers remains a challenge due to issues like\nhallucinations, key information omissions, and verbosity in LLM-generated\nsummaries. This work explores using LLM-generated feedback to improve summary\nquality by aligning the summaries with human preferences for faithfulness,\ncompleteness, and conciseness. We introduce FeedSum, a large-scale dataset\ncontaining multi-dimensional LLM feedback on summaries of varying quality\nacross diverse domains. Our experiments show how feedback quality,\ndimensionality, and granularity influence preference learning, revealing that\nhigh-quality, multi-dimensional, fine-grained feedback significantly improves\nsummary generation. We also compare two methods for using this feedback:\nsupervised fine-tuning and direct preference optimization. Finally, we\nintroduce SummLlama3-8b, a model that outperforms the nearly 10x larger\nLlama3-70b-instruct in generating human-preferred summaries, demonstrating that\nsmaller models can achieve superior performance with appropriate training. The\nfull dataset and SummLlama3-8B model are available at\nhttps://huggingface.co/datasets/DISLab/FeedSum and\nhttps://huggingface.co/DISLab/SummLlama3-8B.",
    "pdf_url": "http://arxiv.org/pdf/2410.13116v2",
    "published": "2024-10-17T01:01:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2410.13115v1",
    "title": "Online conformal inference for multi-step time series forecasting",
    "authors": [
      "Xiaoqian Wang",
      "Rob J Hyndman"
    ],
    "abstract": "We consider the problem of constructing distribution-free prediction\nintervals for multi-step time series forecasting, with a focus on the temporal\ndependencies inherent in multi-step forecast errors. We establish that the\noptimal $h$-step-ahead forecast errors exhibit serial correlation up to lag\n$(h-1)$ under a general non-stationary autoregressive data generating process.\nTo leverage these properties, we propose the Autocorrelated Multi-step\nConformal Prediction (AcMCP) method, which effectively incorporates\nautocorrelations in multi-step forecast errors, resulting in more statistically\nefficient prediction intervals. This method ensures theoretical long-run\ncoverage guarantees for multi-step prediction intervals, though we note that\nincreased forecasting horizons may exacerbate deviations from the target\ncoverage, particularly in the context of limited sample sizes. Additionally, we\nextend several easy-to-implement conformal prediction methods, originally\ndesigned for single-step forecasting, to accommodate multi-step scenarios.\nThrough empirical evaluations, including simulations and applications to data,\nwe demonstrate that AcMCP achieves coverage that closely aligns with the target\nwithin local windows, while providing adaptive prediction intervals that\neffectively respond to varying conditions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13115v1",
    "published": "2024-10-17T00:53:13+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13114v1",
    "title": "Sound Check: Auditing Audio Datasets",
    "authors": [
      "William Agnew",
      "Julia Barnett",
      "Annie Chu",
      "Rachel Hong",
      "Michael Feffer",
      "Robin Netzorg",
      "Harry H. Jiang",
      "Ezra Awumey",
      "Sauvik Das"
    ],
    "abstract": "Generative audio models are rapidly advancing in both capabilities and public\nutilization -- several powerful generative audio models have readily available\nopen weights, and some tech companies have released high quality generative\naudio products. Yet, while prior work has enumerated many ethical issues\nstemming from the data on which generative visual and textual models have been\ntrained, we have little understanding of similar issues with generative audio\ndatasets, including those related to bias, toxicity, and intellectual property.\nTo bridge this gap, we conducted a literature review of hundreds of audio\ndatasets and selected seven of the most prominent to audit in more detail. We\nfound that these datasets are biased against women, contain toxic stereotypes\nabout marginalized communities, and contain significant amounts of copyrighted\nwork. To enable artists to see if they are in popular audio datasets and\nfacilitate exploration of the contents of these datasets, we developed a web\ntool audio datasets exploration tool at https://audio-audit.vercel.app.",
    "pdf_url": "http://arxiv.org/pdf/2410.13114v1",
    "published": "2024-10-17T00:51:27+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CY",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2410.13113v2",
    "title": "A new statistical approach for joint modeling of longitudinal outcomes measured in electronic health records with clinically informative presence and observation processes",
    "authors": [
      "Jiacong Du",
      "Xu Shi",
      "Bhramar Mukherjee"
    ],
    "abstract": "Biobanks with genetics-linked electronic health records (EHR) have opened up\nopportunities to study associations between genetic, social, or environmental\nfactors and longitudinal lab biomarkers. However, in EHRs, the timing of\npatient visits and the recording of lab tests often depend on patient health\nstatus, referred to as informative presence (IP) and informative observation\n(IO), which can bias exposure-biomarker associations. Two gaps remain in\nEHR-based research: (1) the performance of existing IP-aware methods is unclear\nin real-world EHR settings, and (2) no existing methods handle IP and IO\nsimultaneously. To address these challenges, we first conduct extensive\nsimulation studies tailored to EHR-specific IP patterns to assess existing\nmethods. We then propose a joint modeling framework, EHRJoint, that\nsimultaneously models the visiting, observation, and longitudinal biomarker\nprocesses to address both IP and IO. We develop a computationally efficient\nestimation procedure based on estimating equations and provide asymptotically\nvalid inference. Simulations show that EHRJoint yields unbiased exposure effect\nestimates under both IP and IO, while existing methods fail. We apply EHRJoint\nto the Michigan Genomics Initiative data to examine associations between\nrepeated glucose measurements and two exposures: genetic variants and\neducational disadvantage.",
    "pdf_url": "http://arxiv.org/pdf/2410.13113v2",
    "published": "2024-10-17T00:50:44+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2410.13112v2",
    "title": "Distributional Matrix Completion via Nearest Neighbors in the Wasserstein Space",
    "authors": [
      "Jacob Feitelberg",
      "Kyuseong Choi",
      "Anish Agarwal",
      "Raaz Dwivedi"
    ],
    "abstract": "We study the problem of distributional matrix completion: Given a sparsely\nobserved matrix of empirical distributions, we seek to impute the true\ndistributions associated with both observed and unobserved matrix entries. This\nis a generalization of traditional matrix completion, where the observations\nper matrix entry are scalar-valued. To do so, we utilize tools from optimal\ntransport to generalize the nearest neighbors method to the distributional\nsetting. Under a suitable latent factor model on probability distributions, we\nestablish that our method recovers the distributions in the Wasserstein metric.\nWe demonstrate through simulations that our method (i) provides better\ndistributional estimates for an entry compared to using observed samples for\nthat entry alone, (ii) yields accurate estimates of distributional quantities\nsuch as standard deviation and value-at-risk, and (iii) inherently supports\nheteroscedastic distributions. In addition, we demonstrate our method on a\nreal-world dataset of quarterly earnings prediction distributions. We also\nprove novel asymptotic results for Wasserstein barycenters over one-dimensional\ndistributions.",
    "pdf_url": "http://arxiv.org/pdf/2410.13112v2",
    "published": "2024-10-17T00:50:17+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13111v1",
    "title": "Controllable Generation via Locally Constrained Resampling",
    "authors": [
      "Kareem Ahmed",
      "Kai-Wei Chang",
      "Guy Van den Broeck"
    ],
    "abstract": "Autoregressive models have demonstrated an unprecedented ability at modeling\nthe intricacies of natural language. However, they continue to struggle with\ngenerating complex outputs that adhere to logical constraints. Sampling from a\nfully-independent distribution subject to a constraint is hard. Sampling from\nan autoregressive distribution subject to a constraint is doubly hard: We have\nto contend not only with the hardness of the constraint but also the\ndistribution's lack of structure. We propose a tractable probabilistic approach\nthat performs Bayesian conditioning to draw samples subject to a constraint.\nOur approach considers the entire sequence, leading to a more globally optimal\nconstrained generation than current greedy methods. Starting from a model\nsample, we induce a local, factorized distribution which we can tractably\ncondition on the constraint. To generate samples that satisfy the constraint,\nwe sample from the conditional distribution, correct for biases in the samples\nand resample. The resulting samples closely approximate the target distribution\nand are guaranteed to satisfy the constraints. We evaluate our approach on\nseveral tasks, including LLM detoxification and solving Sudoku puzzles. We show\nthat by disallowing a list of toxic expressions our approach is able to steer\nthe model's outputs away from toxic generations, outperforming similar\napproaches to detoxification. We conclude by showing that our approach achieves\na perfect accuracy on Sudoku compared to <50% for GPT4-o and Gemini 1.5.",
    "pdf_url": "http://arxiv.org/pdf/2410.13111v1",
    "published": "2024-10-17T00:49:53+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13110v1",
    "title": "Deep Learning-based Software Engineering: Progress, Challenges, and Opportunities",
    "authors": [
      "Xiangping Chen",
      "Xing Hu",
      "Yuan Huang",
      "He Jiang",
      "Weixing Ji",
      "Yanjie Jiang",
      "Yanyan Jiang",
      "Bo Liu",
      "Hui Liu",
      "Xiaochen Li",
      "Xiaoli Lian",
      "Guozhu Meng",
      "Xin Peng",
      "Hailong Sun",
      "Lin Shi",
      "Bo Wang",
      "Chong Wang",
      "Jiayi Wang",
      "Tiantian Wang",
      "Jifeng Xuan",
      "Xin Xia",
      "Yibiao Yang",
      "Yixin Yang",
      "Li Zhang",
      "Yuming Zhou",
      "Lu Zhang"
    ],
    "abstract": "Researchers have recently achieved significant advances in deep learning\ntechniques, which in turn has substantially advanced other research\ndisciplines, such as natural language processing, image processing, speech\nrecognition, and software engineering. Various deep learning techniques have\nbeen successfully employed to facilitate software engineering tasks, including\ncode generation, software refactoring, and fault localization. Many papers have\nalso been presented in top conferences and journals, demonstrating the\napplications of deep learning techniques in resolving various software\nengineering tasks. However, although several surveys have provided overall\npictures of the application of deep learning techniques in software\nengineering, they focus more on learning techniques, that is, what kind of deep\nlearning techniques are employed and how deep models are trained or fine-tuned\nfor software engineering tasks. We still lack surveys explaining the advances\nof subareas in software engineering driven by deep learning techniques, as well\nas challenges and opportunities in each subarea. To this end, in this paper, we\npresent the first task-oriented survey on deep learning-based software\nengineering. It covers twelve major software engineering subareas significantly\nimpacted by deep learning techniques. Such subareas spread out the through the\nwhole lifecycle of software development and maintenance, including requirements\nengineering, software development, testing, maintenance, and developer\ncollaboration. As we believe that deep learning may provide an opportunity to\nrevolutionize the whole discipline of software engineering, providing one\nsurvey covering as many subareas as possible in software engineering can help\nfuture research push forward the frontier of deep learning-based software\nengineering more systematically.",
    "pdf_url": "http://arxiv.org/pdf/2410.13110v1",
    "published": "2024-10-17T00:46:00+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2410.13109v2",
    "title": "Contextual Bandits with Arm Request Costs and Delays",
    "authors": [
      "Lai Wei",
      "Ambuj Tewari",
      "Michael A. Cianfrocco"
    ],
    "abstract": "We introduce a novel extension of the contextual bandit problem, where new\nsets of arms can be requested with stochastic time delays and associated costs.\nIn this setting, the learner can select multiple arms from a decision set, with\neach selection taking one unit of time. The problem is framed as a special case\nof semi-Markov decision processes (SMDPs). The arm contexts, request times, and\ncosts are assumed to follow an unknown distribution. We consider the regret of\nan online learning algorithm with respect to the optimal policy that achieves\nthe maximum average reward. By leveraging the Bellman optimality equation, we\ndesign algorithms that can effectively select arms and determine the\nappropriate time to request new arms, thereby minimizing their regret. Under\nthe realizability assumption, we analyze the proposed algorithms and\ndemonstrate that their regret upper bounds align with established results in\nthe contextual bandit literature. We validate the algorithms through\nexperiments on simulated data and a movie recommendation dataset, showing that\ntheir performance is consistent with theoretical analyses.",
    "pdf_url": "http://arxiv.org/pdf/2410.13109v2",
    "published": "2024-10-17T00:44:50+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2410.13108v2",
    "title": "Algorithmic Content Selection and the Impact of User Disengagement",
    "authors": [
      "Emilio Calvano",
      "Nika Haghtalab",
      "Ellen Vitercik",
      "Eric Zhao"
    ],
    "abstract": "Digital services face a fundamental trade-off in content selection: they must\nbalance the immediate revenue gained from high-reward content against the\nlong-term benefits of maintaining user engagement. Traditional multi-armed\nbandit models assume that users remain perpetually engaged, failing to capture\nthe possibility that users may disengage when dissatisfied, thereby reducing\nfuture revenue potential.\n  In this work, we introduce a model for the content selection problem that\nexplicitly accounts for variable user engagement and disengagement. In our\nframework, content that maximizes immediate reward is not necessarily optimal\nin terms of fostering sustained user engagement.\n  Our contributions are twofold. First, we develop computational and\nstatistical methods for offline optimization and online learning of content\nselection policies. For users whose engagement patterns are defined by $k$\ndistinct levels, we design a dynamic programming algorithm that computes the\nexact optimal policy in $O(k^2)$ time. Moreover, we derive no-regret learning\nguarantees for an online learning setting in which the platform serves a series\nof users with unknown and potentially adversarial engagement patterns.\n  Second, we introduce the concept of modified demand elasticity which captures\nhow small changes in a user's overall satisfaction affect the platform's\nability to secure long-term revenue. This notion generalizes classical demand\nelasticity by incorporating the dynamics of user re-engagement, thereby\nrevealing key insights into the interplay between engagement and revenue.\nNotably, our analysis uncovers a counterintuitive phenomenon: although higher\nfriction (i.e., a reduced likelihood of re-engagement) typically lowers overall\nrevenue, it can simultaneously lead to higher user engagement under optimal\ncontent selection policies.",
    "pdf_url": "http://arxiv.org/pdf/2410.13108v2",
    "published": "2024-10-17T00:43:06+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13107v2",
    "title": "Wright--Fisher kernels: from linear to non-linear dynamics, ergodicity and McKean--Vlasov scaling limits",
    "authors": [
      "Fernando Cordero",
      "Christian Jorquera",
      "Héctor Olivero",
      "Leonardo Videla"
    ],
    "abstract": "We consider a population of hosts infected by a pathogen that exists in two\nstrains. We use a two-parameter family of Markov kernels on $[0,1]$ to describe\nthe discrete-time evolution of the pathogen type-composition within and across\nindividuals. First, we assume that there is no interaction between pathogen\npopulations across host individuals. For a particular class of parameters, we\nestablish moment duality between the type-frequency process and a process\nreminiscent of the \\emph{Ancestral Selection Graph}. We also show convergence,\nunder appropriate scaling of parameters and time, to a Wright-Fisher diffusion\nwith drift. Next, we assume that pathogen-type compositions are correlated\nacross hosts by their empirical measure. We show a propagation of chaos result\ncomparing the pathogen type-composition of a given host with the evolution of a\nnon-linear chain. Furthermore, we show that under appropriate scaling, the\nnon-linear chain converges to a McKean-Vlasov diffusion. To illustrate our\nresults, we consider a population affected by mutation rates that depend on the\ninstantaneous distribution across multiple hosts. For this example, we study\nthe uniform-in-time propagation of chaos and the ergodicity of the limiting\nMcKean-Vlasov SDE.",
    "pdf_url": "http://arxiv.org/pdf/2410.13107v2",
    "published": "2024-10-17T00:42:31+00:00",
    "categories": [
      "math.PR",
      "60K35, 92D10, 92D15"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13106v3",
    "title": "Cliqueformer: Model-Based Optimization with Structured Transformers",
    "authors": [
      "Jakub Grudzien Kuba",
      "Pieter Abbeel",
      "Sergey Levine"
    ],
    "abstract": "Large neural networks excel at prediction tasks, but their application to\ndesign problems, such as protein engineering or materials discovery, requires\nsolving offline model-based optimization (MBO) problems. While predictive\nmodels may not directly translate to effective design, recent MBO algorithms\nincorporate reinforcement learning and generative modeling approaches.\nMeanwhile, theoretical work suggests that exploiting the target function's\nstructure can enhance MBO performance. We present Cliqueformer, a\ntransformer-based architecture that learns the black-box function's structure\nthrough functional graphical models (FGM), addressing distribution shift\nwithout relying on explicit conservative approaches. Across various domains,\nincluding chemical and genetic design tasks, Cliqueformer demonstrates superior\nperformance compared to existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2410.13106v3",
    "published": "2024-10-17T00:35:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2410.13105v4",
    "title": "AgileRate: Bringing Adaptivity and Robustness to DeFi Lending Markets",
    "authors": [
      "Mahsa Bastankhah",
      "Viraj Nadkarni",
      "Xuechao Wang",
      "Pramod Viswanath"
    ],
    "abstract": "Decentralized Finance (DeFi) has revolutionized lending by replacing\nintermediaries with algorithm-driven liquidity pools. However, existing\nplatforms like Aave and Compound rely on static interest rate curves and\ncollateral requirements that struggle to adapt to rapid market changes, leading\nto inefficiencies in utilization and increased risks of liquidations. In this\nwork, we propose a dynamic model of the lending market based on evolving demand\nand supply curves, alongside an adaptive interest rate controller that responds\nin real-time to shifting market conditions. Using a Recursive Least Squares\nalgorithm, our controller tracks the external market and achieves stable\nutilization, while also controlling default and liquidation risk. We provide\ntheoretical guarantees on the interest rate convergence and utilization\nstability of our algorithm. We establish bounds on the system's vulnerability\nto adversarial manipulation compared to static curves, while quantifying the\ntrade-off between adaptivity and adversarial robustness. We propose two\ncomplementary approaches to mitigating adversarial manipulation: an algorithmic\nmethod that detects extreme demand and supply fluctuations and a market-based\nstrategy that enhances elasticity, potentially via interest rate derivative\nmarkets. Our dynamic curve demand/supply model demonstrates a low best-fit\nerror on Aave data, while our interest rate controller significantly\noutperforms static curve protocols in maintaining optimal utilization and\nminimizing liquidations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13105v4",
    "published": "2024-10-17T00:33:32+00:00",
    "categories": [
      "cs.SI",
      "cs.CE"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2410.19806v2",
    "title": "Learning to Adopt Generative AI",
    "authors": [
      "Lijia Ma",
      "Xingchen Xu",
      "Yumei He",
      "Yong Tan"
    ],
    "abstract": "Recent advancements in generative AI, exemplified by ChatGPT, have\ndramatically transformed how people access information. Despite its powerful\ncapabilities, the benefits it provides may not be equally distributed among\nindividuals - a phenomenon referred to as the digital divide. Building upon\nprior literature, we propose two forms of digital divide in the generative AI\nadoption process: (i) the learning divide, capturing individuals' heterogeneous\nabilities to update their perceived utility of ChatGPT; and (ii) the utility\ndivide, representing differences in individuals' actual utility derived from\nper use of ChatGPT. To evaluate these two divides, we develop a Bayesian\nlearning model that incorporates demographic heterogeneities in both the\nutility and signal functions. Leveraging a six-month clickstream dataset, we\nestimate the model and find significant learning and utility divides across\nvarious demographic attributes. Interestingly, lower-educated and non-white\nindividuals derive higher utility gains from ChatGPT but learn about its\nutility at a slower rate. Furthermore, males, younger individuals, and those\nwith an IT background not only derive higher utility per use from ChatGPT but\nalso learn about its utility more rapidly. Besides, we document a phenomenon\ntermed the belief trap, wherein users underestimate ChatGPT's utility, opt not\nto use the tool, and consequently lack new experiences to update their\nperceptions, leading to continued underutilization. Our simulation further\ndemonstrates that the learning divide can significantly affect the probability\nof falling into the belief trap, another form of the digital divide in adoption\noutcomes (i.e., outcome divide); however, offering training programs can\nalleviate the belief trap and mitigate the divide.",
    "pdf_url": "http://arxiv.org/pdf/2410.19806v2",
    "published": "2024-10-17T00:32:45+00:00",
    "categories": [
      "cs.CY",
      "cs.HC",
      "econ.GN",
      "q-fin.EC",
      "J.4"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13104v1",
    "title": "Cost-Effective Realization of n-Bit Toffoli Gates for IBM Quantum Computers Using the Bloch Sphere Approach and IBM Native Gates",
    "authors": [
      "Ali Al-Bayaty",
      "Marek Perkowski"
    ],
    "abstract": "A cost-effective n-bit Toffoli gate is proposed to be realized (or\ntranspiled) based on the layouts (linear, T-like, and I-like) and the number of\nn physical qubits for IBM quantum computers. This proposed gate is termed the\n\"layout-aware n-bit Toffoli gate\". The layout-aware n-bit Toffoli gate is\ndesigned using the visual approach of the Bloch sphere, from the visual\nrepresentations of the rotational quantum operations for IBM native gates. In\nthis paper, we also proposed a new formula for the quantum cost, which\ncalculates the total number of native gates, the crossing connections, and the\ndepth of the final transpiled quantum circuit. This formula is termed the\n\"transpilation quantum cost\". After transpilation, our proposed layout-aware\nn-bit Toffoli gate always has a much lower transpilation quantum cost than that\nof the conventional n-bit Toffoli gate, where 3 <= n <= 7 qubits, for different\nIBM quantum computers.",
    "pdf_url": "http://arxiv.org/pdf/2410.13104v1",
    "published": "2024-10-17T00:29:29+00:00",
    "categories": [
      "quant-ph",
      "cs.ET"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2410.13103v1",
    "title": "Delegated portfolio management with random default",
    "authors": [
      "Alberto Gennaro",
      "Thibaut Mastrolia"
    ],
    "abstract": "We are considering the problem of optimal portfolio delegation between an\ninvestor and a portfolio manager under a random default time. We focus on a\nnovel variation of the Principal-Agent problem adapted to this framework. We\naddress the challenge of an uncertain investment horizon caused by an exogenous\nrandom default time, after which neither the agent nor the principal can access\nthe market. This uncertainty introduces significant complexities in analyzing\nthe problem, requiring distinct mathematical approaches for two cases: when the\nrandom default time falls within the initial time frame [0,T] and when it\nextends beyond this period. We develop a theoretical framework to model the\nstochastic dynamics of the investment process, incorporating the random default\ntime. We then analyze the portfolio manager's investment decisions and\ncompensation mechanisms for both scenarios. In the first case, where the\ndefault time could be unbounded, we apply traditional results from Backward\nStochastic Differential Equations (BSDEs) and control theory to address the\nagent problem. In the second case, where the default time is within the\ninterval [0,T], the problem becomes more intricate due to the degeneracy of the\nBSDE's driver. For both scenarios, we demonstrate that the contracting problem\ncan be resolved by examining the existence of solutions to integro-partial\nHamilton-Jacobi-Bellman (HJB) equations in both situations. We develop a\ndeep-learning algorithm to solve the problem in high-dimension with no access\nto the optimizer of the Hamiltonian function.",
    "pdf_url": "http://arxiv.org/pdf/2410.13103v1",
    "published": "2024-10-17T00:27:46+00:00",
    "categories": [
      "q-fin.MF",
      "math.OC"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2410.13102v1",
    "title": "Sum Secrecy Rate Maximization for Full Duplex ISAC Systems",
    "authors": [
      "Aleksandar Boljević",
      "Ahmad Bazzi",
      "Marwa Chafii"
    ],
    "abstract": "In integrated sensing and communication (ISAC) systems, the target of\ninterest may \\textit{intentionally disguise itself as an eavesdropper},\nenabling it to intercept and tap into the communication data embedded in the\nISAC waveform. The following paper considers a full duplex (FD)-ISAC system,\nwhich involves multiple malicious targets attempting to intercept both uplink\n(UL) and downlink (DL) communications between the dual-functional radar and\ncommunication (DFRC) base station (BS) and legitimate UL/DL communication users\n(CUs). For this, we formulate an optimization framework that allows\nmaximization of both UL and DL sum secrecy rates, under various power budget\nconstraints for sensing and communications. As the proposed optimization\nproblem is non-convex, we develop a method called Iterative Joint Taylor-Block\ncyclic coordinate descent (IJTB) by proving essential lemmas that transform the\noriginal problem into a more manageable form. In essence, IJTB alternates\nbetween two sub-problems: one yields UL beamformers in closed-form, while the\nother approximates the solution for UL power allocation, artificial noise\ncovariance, and DL beamforming vectors. This is achieved through a series of\nTaylor approximations that effectively \\textit{\"convexify\"} the problem,\nenabling efficient optimization. Simulation results demonstrate the\neffectiveness of the proposed solver when compared with benchmarking ones. Our\nfindings reveal that the IJTB algorithm shows fast convergence, reaching\nstability within approximately $10$ iterations. In addition, all benchmarks\nreveal a substantial decline in the sum secrecy rate, approaching zero as the\neavesdropper distance reaches $17$ meters, underscoring their vulnerability in\ncomparison to IJTB.",
    "pdf_url": "http://arxiv.org/pdf/2410.13102v1",
    "published": "2024-10-17T00:19:51+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2410.13101v1",
    "title": "The Influence of Generative AI on Content Platforms: Supply, Demand, and Welfare Impacts in Two-Sided Markets",
    "authors": [
      "Yukun Zhang"
    ],
    "abstract": "This paper explores how generative artificial intelligence (AI) affects\nonline platforms where both human creators and AI generate content. We develop\na model to understand how generative AI changes supply and demand, impacts\ntraffic distribution, and influences social welfare. Our analysis shows that AI\ncan lead to a huge increase in content supply due to its low cost, which could\ncause oversupply. While AI boosts content variety, it can also create\ninformation overload, lowering user satisfaction and disrupting the market. AI\nalso increases traffic concentration among top creators (the \"winner-takes-all\"\neffect) while expanding opportunities for niche content (the \"long-tail\"\neffect). We assess how these changes affect consumer and producer benefits,\nfinding that the overall impact depends on the quality of AI-generated content\nand the level of information overload. Through simulation experiments, we test\npolicy ideas, such as adjusting platform fees and recommendations, to reduce\nnegative effects and improve social welfare. The results highlight the need for\ncareful management of AI's role in online content platforms to maintain a\nhealthy balance",
    "pdf_url": "http://arxiv.org/pdf/2410.13101v1",
    "published": "2024-10-17T00:14:12+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2410.13910v2",
    "title": "Mitigating the Backdoor Effect for Multi-Task Model Merging via Safety-Aware Subspace",
    "authors": [
      "Jinluan Yang",
      "Anke Tang",
      "Didi Zhu",
      "Zhengyu Chen",
      "Li Shen",
      "Fei Wu"
    ],
    "abstract": "Model merging has gained significant attention as a cost-effective approach\nto integrate multiple single-task fine-tuned models into a unified one that can\nperform well on multiple tasks. However, existing model merging techniques\nprimarily focus on resolving conflicts between task-specific models, they often\noverlook potential security threats, particularly the risk of backdoor attacks\nin the open-source model ecosystem. In this paper, we first investigate the\nvulnerabilities of existing model merging methods to backdoor attacks,\nidentifying two critical challenges: backdoor succession and backdoor transfer.\nTo address these issues, we propose a novel Defense-Aware Merging (DAM)\napproach that simultaneously mitigates task interference and backdoor\nvulnerabilities. Specifically, DAM employs a meta-learning-based optimization\nmethod with dual masks to identify a shared and safety-aware subspace for model\nmerging. These masks are alternately optimized: the Task-Shared mask identifies\ncommon beneficial parameters across tasks, aiming to preserve task-specific\nknowledge while reducing interference, while the Backdoor-Detection mask\nisolates potentially harmful parameters to neutralize security threats. This\ndual-mask design allows us to carefully balance the preservation of useful\nknowledge and the removal of potential vulnerabilities. Compared to existing\nmerging methods, DAM achieves a more favorable balance between performance and\nsecurity, reducing the attack success rate by 2-10 percentage points while\nsacrificing only about 1% in accuracy. Furthermore, DAM exhibits robust\nperformance and broad applicability across various types of backdoor attacks\nand the number of compromised models involved in the merging process. Our codes\nand models are available at https://github.com/Yangjinluan/DAM.",
    "pdf_url": "http://arxiv.org/pdf/2410.13910v2",
    "published": "2024-10-17T00:13:31+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2410.13100v2",
    "title": "Quantifying socio-temporal effects of loan delinquency drivers in microfinance",
    "authors": [
      "Cedric H. A. Koffi",
      "Viani Biatat Djeundje",
      "Olivier Menoukeu Pamen"
    ],
    "abstract": "We develop and evaluate a family of discrete-time logit-link (LLink) models\n(including fixed-effects and frailty extensions) to capture latent\nheterogeneity in repayment behaviour and quantify the effects of socio-temporal\nfactors in microfinance. Our findings highlight the importance of unobserved\nborrower risk, revealing that simple random intercept structures are sufficient\nto model latent heterogeneity in this context. Additionally, socio-temporal\nvariables--such as festive seasons and long school breaks--consistently\nassociate with delinquency transitions, offering key insights into repayment\ndynamics. While LLink models provide clear interpretability, tree-based methods\noutperform them in predictive accuracy, making them suitable for multistate\nclassification tasks. Building on this, we propose an optimised classification\nstrategy based on the Matthews Correlation Coefficient to enhance next-state\nprediction. Overall, our results highlight the benefit of combining\ninterpretable risk modeling with advanced machine learning to support robust,\ndata-driven decision-making in microfinance operations.",
    "pdf_url": "http://arxiv.org/pdf/2410.13100v2",
    "published": "2024-10-17T00:05:17+00:00",
    "categories": [
      "q-fin.RM"
    ],
    "primary_category": "q-fin.RM"
  },
  {
    "id": "http://arxiv.org/abs/2410.13099v1",
    "title": "Adversarial Neural Networks in Medical Imaging Advancements and Challenges in Semantic Segmentation",
    "authors": [
      "Houze Liu",
      "Bo Zhang",
      "Yanlin Xiang",
      "Yuxiang Hu",
      "Aoran Shen",
      "Yang Lin"
    ],
    "abstract": "Recent advancements in artificial intelligence (AI) have precipitated a\nparadigm shift in medical imaging, particularly revolutionizing the domain of\nbrain imaging. This paper systematically investigates the integration of deep\nlearning -- a principal branch of AI -- into the semantic segmentation of brain\nimages. Semantic segmentation serves as an indispensable technique for the\ndelineation of discrete anatomical structures and the identification of\npathological markers, essential for the diagnosis of complex neurological\ndisorders. Historically, the reliance on manual interpretation by radiologists,\nwhile noteworthy for its accuracy, is plagued by inherent subjectivity and\ninter-observer variability. This limitation becomes more pronounced with the\nexponential increase in imaging data, which traditional methods struggle to\nprocess efficiently and effectively. In response to these challenges, this\nstudy introduces the application of adversarial neural networks, a novel AI\napproach that not only automates but also refines the semantic segmentation\nprocess. By leveraging these advanced neural networks, our approach enhances\nthe precision of diagnostic outputs, reducing human error and increasing the\nthroughput of imaging data analysis. The paper provides a detailed discussion\non how adversarial neural networks facilitate a more robust, objective, and\nscalable solution, thereby significantly improving diagnostic accuracies in\nneurological evaluations. This exploration highlights the transformative impact\nof AI on medical imaging, setting a new benchmark for future research and\nclinical practice in neurology.",
    "pdf_url": "http://arxiv.org/pdf/2410.13099v1",
    "published": "2024-10-17T00:05:05+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2410.13098v3",
    "title": "A Little Human Data Goes A Long Way",
    "authors": [
      "Dhananjay Ashok",
      "Jonathan May"
    ],
    "abstract": "Faced with an expensive human annotation process, creators of NLP systems\nincreasingly turn to synthetic data generation. While this method shows\npromise, the extent to which synthetic data can replace human annotation is\npoorly understood. We investigate the use of synthetic data in Fact\nVerification (FV) and Question Answering (QA) by studying the effects of\nincrementally replacing human generated data with synthetic points on eight\ndiverse datasets. Strikingly, replacing up to 90% of the training data only\nmarginally decreases performance, but replacing the final 10% leads to severe\ndeclines. We find that models trained on purely synthetic data can be reliably\nimproved by including as few as 125 human generated data points. We show that\nmatching the performance gain of just a little additional human data (only 200\npoints) requires an order of magnitude more synthetic data and estimate price\nratios at which human annotation would be a more cost-effective solution. Our\nresults suggest that even when human annotation at scale is infeasible, there\nis great value to having a small proportion of the dataset being human\ngenerated.",
    "pdf_url": "http://arxiv.org/pdf/2410.13098v3",
    "published": "2024-10-17T00:04:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  }
]