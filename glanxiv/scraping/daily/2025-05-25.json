[
  {
    "id": "http://arxiv.org/abs/2505.19372v3",
    "title": "Temporal variability in low-frequency radio interference: Insight from high-cadence monitoring at a candidate radio notification zone in Malaysia",
    "authors": [
      "Affan Adly Nazri",
      "Zamri Zainal Abidin",
      "Mohamad Ridhauddin Mat Sabri",
      "Zulfazli Rosli",
      "Mohd Shaiful Rizal Hassan",
      "Mohd Shazwan Mohd Radzi",
      "Ahmad Najwan Zulkiplee",
      "Dalilah Nur Fathiah Hanim Razak",
      "Norsyazwani Asmi",
      "Jinsong Ping",
      "Mingyuan Wang",
      "Liang Dong"
    ],
    "abstract": "Extensive radio frequency interference (RFI) monitoring is essential in the\nsite selection process before constructing radio astronomy observatories,\nfollowed by mitigation strategies to minimize its adverse effects. Malaysia has\nan enormous prospect for radio astronomy due to its prominent location in the\ncentre of Southeast Asia, but is challenged by its relatively high population\ndensity. In this research article, we perform high-cadence, low-frequency RFI\nmonitoring at two sites, each representing an urban and a rural environment.\nUsing modified generalized spectral kurtosis (GSK) as an RFI detection method,\nwe ascertain the suitability of Glami Lemi, a rural area in the centre of\nPeninsular Malaysia previously assigned as a candidate radio notification zone\n(RNZ), as a potential site for radio astronomy observations due to its lower\nRFI contamination in our high-cadence monitoring, especially when compared with\nurban areas. We identified a number of persistent and transient RFI in our\ndataset, associate each of them with their potential origins and, if present,\ncharacterize their temporal evolution. A few types of RFI mitigation strategies\nwere also tested and discussed. This study lays the groundwork for Malaysia's\nendeavours in establishing its first research-grade radio telescope,\nemphasizing the importance of robust RFI detection and mitigation strategies in\noptimizing observational outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2505.19372v3",
    "published": "2025-05-25T23:57:48+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.19371v1",
    "title": "Foundations of Top-$k$ Decoding For Language Models",
    "authors": [
      "Georgy Noarov",
      "Soham Mallick",
      "Tao Wang",
      "Sunay Joshi",
      "Yan Sun",
      "Yangxinyu Xie",
      "Mengxin Yu",
      "Edgar Dobriban"
    ],
    "abstract": "Top-$k$ decoding is a widely used method for sampling from LLMs: at each\ntoken, only the largest $k$ next-token-probabilities are kept, and the next\ntoken is sampled after re-normalizing them to sum to unity. Top-$k$ and other\nsampling methods are motivated by the intuition that true next-token\ndistributions are sparse, and the noisy LLM probabilities need to be truncated.\nHowever, to our knowledge, a precise theoretical motivation for the use of\ntop-$k$ decoding is missing. In this work, we develop a theoretical framework\nthat both explains and generalizes top-$k$ decoding. We view decoding at a\nfixed token as the recovery of a sparse probability distribution. We consider\n\\emph{Bregman decoders} obtained by minimizing a separable Bregman divergence\n(for both the \\emph{primal} and \\emph{dual} cases) with a sparsity-inducing\n$\\ell_0$ regularization. Despite the combinatorial nature of the objective, we\nshow how to optimize it efficiently for a large class of divergences. We show\nthat the optimal decoding strategies are greedy, and further that the loss\nfunction is discretely convex in $k$, so that binary search provably and\nefficiently finds the optimal $k$. We show that top-$k$ decoding arises as a\nspecial case for the KL divergence, and identify new decoding strategies that\nhave distinct behaviors (e.g., non-linearly up-weighting larger probabilities\nafter re-normalization).",
    "pdf_url": "http://arxiv.org/pdf/2505.19371v1",
    "published": "2025-05-25T23:46:34+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19370v1",
    "title": "Structural, magnetic, and nanoacoustic characterization of Co/Pt superlattices",
    "authors": [
      "E. R. Cardozo de Oliveira",
      "C. Xiang",
      "C. Borrazás",
      "S. Sandeep",
      "J. E. Gómez",
      "M. Vásquez Mansilla",
      "N. Findling",
      "L. Largeau",
      "N. D. Lanzillotti-Kimura",
      "M. Granada"
    ],
    "abstract": "Superlattices presenting a spatial modulation of the elastic properties\nappear as a main tool to reach the THz regime in nanoacoustic devices. The\nexploration of alternative materials with multifunctional properties remains a\nfertile domain of research. In this work, we study the structural, magnetic,\nand acoustic characteristics of nanometric superlattices made of Pt/Co.\n  The samples present a well defined periodicity, as determined by X-ray\nreflectometry, whereas scanning transmission electron microscopy with local\ncompositional analysis reveals that the superlattices present a modulation in\ncomposition instead of sharp interfaces. The policrystalline nature of the\nsuperlattices is evidenced both by X ray diffraction and transmission electron\nmicroscopy. Magnetization measurements show a perpendicular magnetic anisotropy\nfor the higher Co concentrations. Picosecond acoustic experiments evidence that\nthe studied samples support short-lived acoustic modes up to 900 GHz, and up to\n7 acoustic echoes at lower frequencies.These are promising results for the\ndevelopment of magnetoacoustic devices working at ultrahigh frequencies.",
    "pdf_url": "http://arxiv.org/pdf/2505.19370v1",
    "published": "2025-05-25T23:43:10+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.19369v1",
    "title": "SETransformer: A Hybrid Attention-Based Architecture for Robust Human Activity Recognition",
    "authors": [
      "Yunbo Liu",
      "Xukui Qin",
      "Yifan Gao",
      "Xiang Li",
      "Chengwei Feng"
    ],
    "abstract": "Human Activity Recognition (HAR) using wearable sensor data has become a\ncentral task in mobile computing, healthcare, and human-computer interaction.\nDespite the success of traditional deep learning models such as CNNs and RNNs,\nthey often struggle to capture long-range temporal dependencies and contextual\nrelevance across multiple sensor channels. To address these limitations, we\npropose SETransformer, a hybrid deep neural architecture that combines\nTransformer-based temporal modeling with channel-wise squeeze-and-excitation\n(SE) attention and a learnable temporal attention pooling mechanism. The model\ntakes raw triaxial accelerometer data as input and leverages global\nself-attention to capture activity-specific motion dynamics over extended time\nwindows, while adaptively emphasizing informative sensor channels and critical\ntime steps.\n  We evaluate SETransformer on the WISDM dataset and demonstrate that it\nsignificantly outperforms conventional models including LSTM, GRU, BiLSTM, and\nCNN baselines. The proposed model achieves a validation accuracy of 84.68\\% and\na macro F1-score of 84.64\\%, surpassing all baseline architectures by a notable\nmargin. Our results show that SETransformer is a competitive and interpretable\nsolution for real-world HAR tasks, with strong potential for deployment in\nmobile and ubiquitous sensing applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.19369v1",
    "published": "2025-05-25T23:39:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19368v1",
    "title": "The spectrum of local dualisable modular representations",
    "authors": [
      "Dave Benson",
      "Srikanth B. Iyengar",
      "Henning Krause",
      "Julia Pevtsova"
    ],
    "abstract": "For a point $\\mathfrak{p}$ in the spectrum of the cohomology ring of a finite\ngroup $G$ over a field $k$, we calculate the spectrum for the subcategory of\ndualisable objects inside the tensor triangulated category of\n$\\mathfrak{p}$-local and $\\mathfrak{p}$-torsion objects in the (big) stable\nmodule category of the group algebra $kG$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19368v1",
    "published": "2025-05-25T23:39:10+00:00",
    "categories": [
      "math.RT",
      "20C20 (primary), 18G80, 20J06 (secondary)"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19367v1",
    "title": "Adaptive Diffusion Guidance via Stochastic Optimal Control",
    "authors": [
      "Iskander Azangulov",
      "Peter Potaptchik",
      "Qinyu Li",
      "Eddie Aamari",
      "George Deligiannidis",
      "Judith Rousseau"
    ],
    "abstract": "Guidance is a cornerstone of modern diffusion models, playing a pivotal role\nin conditional generation and enhancing the quality of unconditional samples.\nHowever, current approaches to guidance scheduling--determining the appropriate\nguidance weight--are largely heuristic and lack a solid theoretical foundation.\nThis work addresses these limitations on two fronts. First, we provide a\ntheoretical formalization that precisely characterizes the relationship between\nguidance strength and classifier confidence. Second, building on this insight,\nwe introduce a stochastic optimal control framework that casts guidance\nscheduling as an adaptive optimization problem. In this formulation, guidance\nstrength is not fixed but dynamically selected based on time, the current\nsample, and the conditioning class, either independently or in combination. By\nsolving the resulting control problem, we establish a principled foundation for\nmore effective guidance in diffusion models.",
    "pdf_url": "http://arxiv.org/pdf/2505.19367v1",
    "published": "2025-05-25T23:34:10+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.19366v1",
    "title": "Kolmogorov-Arnold Networks for Turbulence Anisotropy Mapping",
    "authors": [
      "Nikhila Kalia",
      "Ryley McConkey",
      "Eugene Yee",
      "Fue-Sang Lien"
    ],
    "abstract": "This study evaluates the generalization performance and representation\nefficiency (parsimony) of a previously introduced Tensor Basis\nKolmogorov-Arnold Network (TBKAN) architecture for data-driven turbulence\nmodeling. The TBKAN framework replaces the multi-layer perceptron (MLP) used in\neither the standard or modified Tensor Basis Neural Network (TBNN) with a\nKolmogorov-Arnold network (KAN), which significantly reduces the model\ncomplexity while providing a structure that potentially can be used with\nsymbolic regression to provide a physical interpretability that is not\navailable in a 'black box' MLP. While some prior work demonstrated TBKAN's\nfeasibility for modeling a 'simple' flat plate boundary layer flow, this study\nextends the TBKAN architecture to model more complex benchmark flows, in\nparticular, square duct and periodic hills flows which exhibit strong\nturbulence anisotropy, secondary motion, and flow separation and reattachment.\nA realizability-informed loss function is employed to constrain the model\npredictions, and, for the first time, TBKAN predictions are stably injected\ninto the Reynolds-averaged Navier-Stokes equations to provide it a posteriori\npredictions of the mean velocity field.",
    "pdf_url": "http://arxiv.org/pdf/2505.19366v1",
    "published": "2025-05-25T23:32:54+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.19365v3",
    "title": "Three-dimensional magnetic Schrödinger operator with the potential supported in a tube",
    "authors": [
      "Diana Barseghyan",
      "Juan Bory-Reyes",
      "Baruch Schneider"
    ],
    "abstract": "In this paper, we study the following magnetic Schr\\\"odinger operator in\n$\\mathbb{R}^3$: \\[ H=(i \\nabla +A)^2- \\tilde{V}, \\] where $\\tilde{V}$ is\nnon-negative potential supported over the tube built along a curve which is a\nlocal deformation of a straight one, and $B:=\\mathrm{rot}(A)$ is a non-zero and\nlocal (i.e., a compact supported) magnetic field. Based on some new strategies,\nwe first prove that the magnetic field does not change the essential spectrum\nof this system. Finally, in the last section of this paper, we establish the\nsufficient condition such that the discrete spectrum is empty.",
    "pdf_url": "http://arxiv.org/pdf/2505.19365v3",
    "published": "2025-05-25T23:30:23+00:00",
    "categories": [
      "math.SP",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19364v1",
    "title": "RADEP: A Resilient Adaptive Defense Framework Against Model Extraction Attacks",
    "authors": [
      "Amit Chakraborty",
      "Sayyed Farid Ahamed",
      "Sandip Roy",
      "Soumya Banerjee",
      "Kevin Choi",
      "Abdul Rahman",
      "Alison Hu",
      "Edward Bowen",
      "Sachin Shetty"
    ],
    "abstract": "Machine Learning as a Service (MLaaS) enables users to leverage powerful\nmachine learning models through cloud-based APIs, offering scalability and ease\nof deployment. However, these services are vulnerable to model extraction\nattacks, where adversaries repeatedly query the application programming\ninterface (API) to reconstruct a functionally similar model, compromising\nintellectual property and security. Despite various defense strategies being\nproposed, many suffer from high computational costs, limited adaptability to\nevolving attack techniques, and a reduction in performance for legitimate\nusers. In this paper, we introduce a Resilient Adaptive Defense Framework for\nModel Extraction Attack Protection (RADEP), a multifaceted defense framework\ndesigned to counteract model extraction attacks through a multi-layered\nsecurity approach. RADEP employs progressive adversarial training to enhance\nmodel resilience against extraction attempts. Malicious query detection is\nachieved through a combination of uncertainty quantification and behavioral\npattern analysis, effectively identifying adversarial queries. Furthermore, we\ndevelop an adaptive response mechanism that dynamically modifies query outputs\nbased on their suspicion scores, reducing the utility of stolen models.\nFinally, ownership verification is enforced through embedded watermarking and\nbackdoor triggers, enabling reliable identification of unauthorized model use.\nExperimental evaluations demonstrate that RADEP significantly reduces\nextraction success rates while maintaining high detection accuracy with minimal\nimpact on legitimate queries. Extensive experiments show that RADEP effectively\ndefends against model extraction attacks and remains resilient even against\nadaptive adversaries, making it a reliable security framework for MLaaS models.",
    "pdf_url": "http://arxiv.org/pdf/2505.19364v1",
    "published": "2025-05-25T23:28:05+00:00",
    "categories": [
      "cs.CR",
      "I.2.6; D.4.6; K.6.5"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19363v1",
    "title": "Understanding Plasma Turbulence Through Exact Coherent Structures",
    "authors": [
      "Sidney D. V. Williams",
      "Matthew N. Gudorf",
      "Dmitri M. Orlov"
    ],
    "abstract": "Plasma turbulence is a key challenge in understanding transport phenomena in\nmagnetically confined plasmas. This work presents a novel approach using\nperiodic orbit theory to analyze plasma turbulence, identifying fundamental\nstructures that underpin chaotic motion. By applying numerical optimization\ntechniques to the Kuramoto-Sivashinsky equation - a reduced model for\ndrift-wave-driven trapped particle turbulence - we extract coherent spacetime\npatterns that serve as building blocks of turbulent dynamics. These structures\nprovide a framework to systematically describe turbulence as a composition of\nrecurrent solutions, revealing an underlying order within chaotic plasma\nmotion. Our findings suggest that multi-periodic orbit theory can be\neffectively applied to spatiotemporal turbulence, offering a new method for\npredicting and potentially controlling transport processes in fusion plasmas.\nThis study provides a bridge between nonlinear dynamical systems theory and\nplasma physics, highlighting the relevance of periodic orbit approaches for\nunderstanding complex plasma behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.19363v1",
    "published": "2025-05-25T23:26:24+00:00",
    "categories": [
      "physics.plasm-ph",
      "nlin.CD"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.20349v1",
    "title": "FD-Bench: A Modular and Fair Benchmark for Data-driven Fluid Simulation",
    "authors": [
      "Haixin Wang",
      "Ruoyan Li",
      "Fred Xu",
      "Fang Sun",
      "Kaiqiao Han",
      "Zijie Huang",
      "Guancheng Wan",
      "Ching Chang",
      "Xiao Luo",
      "Wei Wang",
      "Yizhou Sun"
    ],
    "abstract": "Data-driven modeling of fluid dynamics has advanced rapidly with neural PDE\nsolvers, yet a fair and strong benchmark remains fragmented due to the absence\nof unified PDE datasets and standardized evaluation protocols. Although\narchitectural innovations are abundant, fair assessment is further impeded by\nthe lack of clear disentanglement between spatial, temporal and loss modules.\nIn this paper, we introduce FD-Bench, the first fair, modular, comprehensive\nand reproducible benchmark for data-driven fluid simulation. FD-Bench\nsystematically evaluates 85 baseline models across 10 representative flow\nscenarios under a unified experimental setup. It provides four key\ncontributions: (1) a modular design enabling fair comparisons across spatial,\ntemporal, and loss function modules; (2) the first systematic framework for\ndirect comparison with traditional numerical solvers; (3) fine-grained\ngeneralization analysis across resolutions, initial conditions, and temporal\nwindows; and (4) a user-friendly, extensible codebase to support future\nresearch. Through rigorous empirical studies, FD-Bench establishes the most\ncomprehensive leaderboard to date, resolving long-standing issues in\nreproducibility and comparability, and laying a foundation for robust\nevaluation of future data-driven fluid models. The code is open-sourced at\nhttps://anonymous.4open.science/r/FD-Bench-15BC.",
    "pdf_url": "http://arxiv.org/pdf/2505.20349v1",
    "published": "2025-05-25T23:24:18+00:00",
    "categories": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.19362v1",
    "title": "Global Fukaya category II: applications",
    "authors": [
      "Yasha Savelyev"
    ],
    "abstract": "To paraphrase, part I constructs a bundle of $A _{\\infty}$ categories given\nthe input of a Hamiltonian fibration over a smooth manifold. Here we show that\nthis bundle is generally non-trivial by a sample computation. One principal\napplication is differential geometric, and the other is about algebraic\n$K$-theory of the integers and the rationals. We find new curvature constraint\nphenomena for smooth and singular $\\mathcal{G}$-connections on principal\n$\\mathcal{G}$-bundles over $S ^{4}$, where $\\mathcal{G}$ is $\\operatorname {PU}\n(2)$ or $\\operatorname {Ham} (S ^{2} )$. Even for the classical group\n$\\operatorname {PU} (2)$ these phenomena are inaccessible to known techniques\nlike the Yang-Mills theory. The above mentioned computation is the geometric\ncomponent used to show that the categorified algebraic $K$-theory of the\nintegers and the rationals, defined in ~\\cite{cite_SavelyevAlgKtheory}\nfollowing To\\\"en, admits a $\\mathbb{Z} $ injection in degree $4$. This gives a\npath from Floer theory to number theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.19362v1",
    "published": "2025-05-25T23:21:45+00:00",
    "categories": [
      "math.SG"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19361v2",
    "title": "Consistency-based Abductive Reasoning over Perceptual Errors of Multiple Pre-trained Models in Novel Environments",
    "authors": [
      "Mario Leiva",
      "Noel Ngu",
      "Joshua Shay Kricheli",
      "Aditya Taparia",
      "Ransalu Senanayake",
      "Paulo Shakarian",
      "Nathaniel Bastian",
      "John Corcoran",
      "Gerardo Simari"
    ],
    "abstract": "The deployment of pre-trained perception models in novel environments often\nleads to performance degradation due to distributional shifts. Although recent\nartificial intelligence approaches for metacognition use logical rules to\ncharacterize and filter model errors, improving precision often comes at the\ncost of reduced recall. This paper addresses the hypothesis that leveraging\nmultiple pre-trained models can mitigate this recall reduction. We formulate\nthe challenge of identifying and managing conflicting predictions from various\nmodels as a consistency-based abduction problem, building on the idea of\nabductive learning (ABL) but applying it to test-time instead of training. The\ninput predictions and the learned error detection rules derived from each model\nare encoded in a logic program. We then seek an abductive explanation--a subset\nof model predictions--that maximizes prediction coverage while ensuring the\nrate of logical inconsistencies (derived from domain constraints) remains below\na specified threshold. We propose two algorithms for this knowledge\nrepresentation task: an exact method based on Integer Programming (IP) and an\nefficient Heuristic Search (HS). Through extensive experiments on a simulated\naerial imagery dataset featuring controlled, complex distributional shifts, we\ndemonstrate that our abduction-based framework outperforms individual models\nand standard ensemble baselines, achieving, for instance, average relative\nimprovements of approximately 13.6\\% in F1-score and 16.6\\% in accuracy across\n15 diverse test datasets when compared to the best individual model. Our\nresults validate the use of consistency-based abduction as an effective\nmechanism to robustly integrate knowledge from multiple imperfect models in\nchallenging, novel scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.19361v2",
    "published": "2025-05-25T23:17:47+00:00",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19360v1",
    "title": "ChartLens: Fine-grained Visual Attribution in Charts",
    "authors": [
      "Manan Suri",
      "Puneet Mathur",
      "Nedim Lipka",
      "Franck Dernoncourt",
      "Ryan A. Rossi",
      "Dinesh Manocha"
    ],
    "abstract": "The growing capabilities of multimodal large language models (MLLMs) have\nadvanced tasks like chart understanding. However, these models often suffer\nfrom hallucinations, where generated text sequences conflict with the provided\nvisual data. To address this, we introduce Post-Hoc Visual Attribution for\nCharts, which identifies fine-grained chart elements that validate a given\nchart-associated response. We propose ChartLens, a novel chart attribution\nalgorithm that uses segmentation-based techniques to identify chart objects and\nemploys set-of-marks prompting with MLLMs for fine-grained visual attribution.\nAdditionally, we present ChartVA-Eval, a benchmark with synthetic and\nreal-world charts from diverse domains like finance, policy, and economics,\nfeaturing fine-grained attribution annotations. Our evaluations show that\nChartLens improves fine-grained attributions by 26-66%.",
    "pdf_url": "http://arxiv.org/pdf/2505.19360v1",
    "published": "2025-05-25T23:17:32+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19359v1",
    "title": "Nonparametric estimation of sliced inverse regression by the $ k$-nearest neighbors kernel method",
    "authors": [
      "Luran Bengono Mintogo",
      "Emmanuel de Dieu Nkou",
      "Guy Martial Nkiet"
    ],
    "abstract": "We investigate nonparametric estimation of sliced inverse regression (SIR)\nvia the $k$-nearest neighbors approach with a kernel. An estimator of the\ncovariance matrix of the conditional expectation of the explanatory random\nvector given the response is then introduced, thereby allowing to estimate the\neffective dimension reduction (EDR) space. Consistency of the proposed\nestimators is proved through derivation of asymptotic normality. A simulation\nstudy, made in order to assess the finite-sample behaviour of the proposed\nmethod and to compare it to the kernel estimate, is presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.19359v1",
    "published": "2025-05-25T23:15:09+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.19358v1",
    "title": "RoofNet: A Global Multimodal Dataset for Roof Material Classification",
    "authors": [
      "Noelle Law",
      "Yuki Miura"
    ],
    "abstract": "Natural disasters are increasing in frequency and severity, causing hundreds\nof billions of dollars in damage annually and posing growing threats to\ninfrastructure and human livelihoods. Accurate data on roofing materials is\ncritical for modeling building vulnerability to natural hazards such as\nearthquakes, floods, wildfires, and hurricanes, yet such data remain\nunavailable. To address this gap, we introduce RoofNet, the largest and most\ngeographically diverse novel multimodal dataset to date, comprising over 51,500\nsamples from 184 geographically diverse sites pairing high-resolution Earth\nObservation (EO) imagery with curated text annotations for global roof material\nclassification. RoofNet includes geographically diverse satellite imagery\nlabeled with 14 key roofing types -- such as asphalt shingles, clay tiles, and\nmetal sheets -- and is designed to enhance the fidelity of global exposure\ndatasets through vision-language modeling (VLM). We sample EO tiles from\nclimatically and architecturally distinct regions to construct a representative\ndataset. A subset of 6,000 images was annotated in collaboration with domain\nexperts to fine-tune a VLM. We used geographic- and material-aware prompt\ntuning to enhance class separability. The fine-tuned model was then applied to\nthe remaining EO tiles, with predictions refined through rule-based and\nhuman-in-the-loop verification. In addition to material labels, RoofNet\nprovides rich metadata including roof shape, footprint area, solar panel\npresence, and indicators of mixed roofing materials (e.g., HVAC systems).\nRoofNet supports scalable, AI-driven risk assessment and serves as a downstream\nbenchmark for evaluating model generalization across regions -- offering\nactionable insights for insurance underwriting, disaster preparedness, and\ninfrastructure policy planning.",
    "pdf_url": "http://arxiv.org/pdf/2505.19358v1",
    "published": "2025-05-25T23:14:24+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.19357v1",
    "title": "On the Secrecy of RIS-aided THz Wireless System subject to $α-μ$ fading with Pointing Errors",
    "authors": [
      "Faissal El Bouanani",
      "Elmehdi Illi",
      "Marwa Qaraqe",
      "Osamah Badarneh"
    ],
    "abstract": "The study examines the secrecy outage probability (SOP) and intercept\nprobability (IP) of a reflecting intelligent surface (RIS)-enabled THz wireless\nnetwork experiencing $\\alpha-\\mu$ fading with pointing errors. Specifically,\nthe base station (BS) sends information to a legitimate user $\\ell$ via the RIS\nwhile an eavesdropper $e$ tries to overhear the conversation. Furthermore,\nreceive nodes are equipped with a single antenna, and the RIS phase shifts were\nselected to boost the SNR at node $\\ell$. Elementary functions are used to\naccurately approximate the statistical features of channel gain in BS-$\\ell$\nand BS-$e$ links, leading to SOP and IP approximate and asymptotic expressions.\nMonte Carlo simulation validates all analytical findings for different system\nparameters' values.",
    "pdf_url": "http://arxiv.org/pdf/2505.19357v1",
    "published": "2025-05-25T23:14:09+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19356v2",
    "title": "Optimized Text Embedding Models and Benchmarks for Amharic Passage Retrieval",
    "authors": [
      "Kidist Amde Mekonnen",
      "Yosef Worku Alemneh",
      "Maarten de Rijke"
    ],
    "abstract": "Neural retrieval methods using transformer-based pre-trained language models\nhave advanced multilingual and cross-lingual retrieval. However, their\neffectiveness for low-resource, morphologically rich languages such as Amharic\nremains underexplored due to data scarcity and suboptimal tokenization. We\naddress this gap by introducing Amharic-specific dense retrieval models based\non pre-trained Amharic BERT and RoBERTa backbones. Our proposed\nRoBERTa-Base-Amharic-Embed model (110M parameters) achieves a 17.6% relative\nimprovement in MRR@10 and a 9.86% gain in Recall@10 over the strongest\nmultilingual baseline, Arctic Embed 2.0 (568M parameters). More compact\nvariants, such as RoBERTa-Medium-Amharic-Embed (42M), remain competitive while\nbeing over 13x smaller. Additionally, we train a ColBERT-based late interaction\nretrieval model that achieves the highest MRR@10 score (0.843) among all\nevaluated models. We benchmark our proposed models against both sparse and\ndense retrieval baselines to systematically assess retrieval effectiveness in\nAmharic. Our analysis highlights key challenges in low-resource settings and\nunderscores the importance of language-specific adaptation. To foster future\nresearch in low-resource IR, we publicly release our dataset, codebase, and\ntrained models at https://github.com/kidist-amde/amharic-ir-benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19356v2",
    "published": "2025-05-25T23:06:20+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "68T50 (Primary), 68T05 (Secondary)",
      "H.3.3; H.3.1; I.2.7"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19355v1",
    "title": "Estimating Online Influence Needs Causal Modeling! Counterfactual Analysis of Social Media Engagement",
    "authors": [
      "Lin Tian",
      "Marian-Andrei Rizoiu"
    ],
    "abstract": "Understanding true influence in social media requires distinguishing\ncorrelation from causation--particularly when analyzing misinformation spread.\nWhile existing approaches focus on exposure metrics and network structures,\nthey often fail to capture the causal mechanisms by which external temporal\nsignals trigger engagement. We introduce a novel joint treatment-outcome\nframework that leverages existing sequential models to simultaneously adapt to\nboth policy timing and engagement effects. Our approach adapts causal inference\ntechniques from healthcare to estimate Average Treatment Effects (ATE) within\nthe sequential nature of social media interactions, tackling challenges from\nexternal confounding signals. Through our experiments on real-world\nmisinformation and disinformation datasets, we show that our models outperform\nexisting benchmarks by 15--22% in predicting engagement across diverse\ncounterfactual scenarios, including exposure adjustment, timing shifts, and\nvaried intervention durations. Case studies on 492 social media users show our\ncausal effect measure aligns strongly with the gold standard in influence\nestimation, the expert-based empirical influence.",
    "pdf_url": "http://arxiv.org/pdf/2505.19355v1",
    "published": "2025-05-25T23:03:24+00:00",
    "categories": [
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19354v1",
    "title": "GC-KBVQA: A New Four-Stage Framework for Enhancing Knowledge Based Visual Question Answering Performance",
    "authors": [
      "Mohammad Mahdi Moradi",
      "Sudhir Mudur"
    ],
    "abstract": "Knowledge-Based Visual Question Answering (KB-VQA) methods focus on tasks\nthat demand reasoning with information extending beyond the explicit content\ndepicted in the image. Early methods relied on explicit knowledge bases to\nprovide this auxiliary information. Recent approaches leverage Large Language\nModels (LLMs) as implicit knowledge sources. While KB-VQA methods have\ndemonstrated promising results, their potential remains constrained as the\nauxiliary text provided may not be relevant to the question context, and may\nalso include irrelevant information that could misguide the answer predictor.\nWe introduce a novel four-stage framework called Grounding Caption-Guided\nKnowledge-Based Visual Question Answering (GC-KBVQA), which enables LLMs to\neffectively perform zero-shot VQA tasks without the need for end-to-end\nmultimodal training. Innovations include grounding question-aware caption\ngeneration to move beyond generic descriptions and have compact, yet detailed\nand context-rich information. This is combined with knowledge from external\nsources to create highly informative prompts for the LLM. GC-KBVQA can address\na variety of VQA tasks, and does not require task-specific fine-tuning, thus\nreducing both costs and deployment complexity by leveraging general-purpose,\npre-trained LLMs. Comparison with competing KB-VQA methods shows significantly\nimproved performance. Our code will be made public.",
    "pdf_url": "http://arxiv.org/pdf/2505.19354v1",
    "published": "2025-05-25T23:00:30+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19353v1",
    "title": "Architectures of Error: A Philosophical Inquiry into AI and Human Code Generation",
    "authors": [
      "Camilo Chacón Sartori"
    ],
    "abstract": "With the rise of generative AI (GenAI), Large Language Models are\nincreasingly employed for code generation, becoming active co-authors alongside\nhuman programmers. Focusing specifically on this application domain, this paper\narticulates distinct ``Architectures of Error'' to ground an epistemic\ndistinction between human and machine code generation. Examined through their\nshared vulnerability to error, this distinction reveals fundamentally different\ncausal origins: human-cognitive versus artificial-stochastic. To develop this\nframework and substantiate the distinction, the analysis draws critically upon\nDennett's mechanistic functionalism and Rescher's methodological pragmatism. I\nargue that a systematic differentiation of these error profiles raises critical\nphilosophical questions concerning semantic coherence, security robustness,\nepistemic limits, and control mechanisms in human-AI collaborative software\ndevelopment. The paper also utilizes Floridi's levels of abstraction to provide\na nuanced understanding of how these error dimensions interact and may evolve\nwith technological advancements. This analysis aims to offer philosophers a\nstructured framework for understanding GenAI's unique epistemological\nchallenges, shaped by these architectural foundations, while also providing\nsoftware engineers a basis for more critically informed engagement.",
    "pdf_url": "http://arxiv.org/pdf/2505.19353v1",
    "published": "2025-05-25T22:49:36+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.SE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19352v1",
    "title": "Beyond Editing Pairs: Fine-Grained Instructional Image Editing via Multi-Scale Learnable Regions",
    "authors": [
      "Chenrui Ma",
      "Xi Xiao",
      "Tianyang Wang",
      "Yanning Shen"
    ],
    "abstract": "Current text-driven image editing methods typically follow one of two\ndirections: relying on large-scale, high-quality editing pair datasets to\nimprove editing precision and diversity, or exploring alternative dataset-free\ntechniques. However, constructing large-scale editing datasets requires\ncarefully designed pipelines, is time-consuming, and often results in\nunrealistic samples or unwanted artifacts. Meanwhile, dataset-free methods may\nsuffer from limited instruction comprehension and restricted editing\ncapabilities. Faced with these challenges, the present work develops a novel\nparadigm for instruction-driven image editing that leverages widely available\nand enormous text-image pairs, instead of relying on editing pair datasets. Our\napproach introduces a multi-scale learnable region to localize and guide the\nediting process. By treating the alignment between images and their textual\ndescriptions as supervision and learning to generate task-specific editing\nregions, our method achieves high-fidelity, precise, and instruction-consistent\nimage editing. Extensive experiments demonstrate that the proposed approach\nattains state-of-the-art performance across various tasks and benchmarks, while\nexhibiting strong adaptability to various types of generative models.",
    "pdf_url": "http://arxiv.org/pdf/2505.19352v1",
    "published": "2025-05-25T22:40:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.23791v1",
    "title": "Evaluating Query Efficiency and Accuracy of Transfer Learning-based Model Extraction Attack in Federated Learning",
    "authors": [
      "Sayyed Farid Ahamed",
      "Sandip Roy",
      "Soumya Banerjee",
      "Marc Vucovich",
      "Kevin Choi",
      "Abdul Rahman",
      "Alison Hu",
      "Edward Bowen",
      "Sachin Shetty"
    ],
    "abstract": "Federated Learning (FL) is a collaborative learning framework designed to\nprotect client data, yet it remains highly vulnerable to Intellectual Property\n(IP) threats. Model extraction (ME) attacks pose a significant risk to Machine\nLearning as a Service (MLaaS) platforms, enabling attackers to replicate\nconfidential models by querying black-box (without internal insight) APIs.\nDespite FL's privacy-preserving goals, its distributed nature makes it\nparticularly susceptible to such attacks. This paper examines the vulnerability\nof FL-based victim models to two types of model extraction attacks. For various\nfederated clients built under the NVFlare platform, we implemented ME attacks\nacross two deep learning architectures and three image datasets. We evaluate\nthe proposed ME attack performance using various metrics, including accuracy,\nfidelity, and KL divergence. The experiments show that for different FL\nclients, the accuracy and fidelity of the extracted model are closely related\nto the size of the attack query set. Additionally, we explore a transfer\nlearning based approach where pretrained models serve as the starting point for\nthe extraction process. The results indicate that the accuracy and fidelity of\nthe fine-tuned pretrained extraction models are notably higher, particularly\nwith smaller query sets, highlighting potential advantages for attackers.",
    "pdf_url": "http://arxiv.org/pdf/2505.23791v1",
    "published": "2025-05-25T22:40:10+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "I.2.6; D.4.6"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19351v1",
    "title": "Squared Linear Models",
    "authors": [
      "Hannah Friedman",
      "Bernd Sturmfels",
      "Maximilian Wiesmann"
    ],
    "abstract": "We study statistical models that are parametrized by squares of linear forms.\nAll critical points of the likelihood function are real and positive. There is\none for each region of the projective hyperplane arrangement. We study the\nideal and singular locus of the model, and we give a determinantal presentation\nfor its likelihood correspondence. We characterize tropical degenerations of\nthe MLE, and we describe log-normal polytopes.",
    "pdf_url": "http://arxiv.org/pdf/2505.19351v1",
    "published": "2025-05-25T22:38:58+00:00",
    "categories": [
      "math.AC",
      "math.AG",
      "math.ST",
      "stat.TH",
      "13P25, 62R01, 14Q30"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19350v1",
    "title": "FlashMD: long-stride, universal prediction of molecular dynamics",
    "authors": [
      "Filippo Bigi",
      "Sanggyu Chong",
      "Agustinus Kristiadi",
      "Michele Ceriotti"
    ],
    "abstract": "Molecular dynamics (MD) provides insights into atomic-scale processes by\nintegrating over time the equations that describe the motion of atoms under the\naction of interatomic forces. Machine learning models have substantially\naccelerated MD by providing inexpensive predictions of the forces, but they\nremain constrained to minuscule time integration steps, which are required by\nthe fast time scale of atomic motion. In this work, we propose FlashMD, a\nmethod to predict the evolution of positions and momenta over strides that are\nbetween one and two orders of magnitude longer than typical MD time steps. We\nincorporate considerations on the mathematical and physical properties of\nHamiltonian dynamics in the architecture, generalize the approach to allow the\nsimulation of any thermodynamic ensemble, and carefully assess the possible\nfailure modes of such a long-stride MD approach. We validate FlashMD's accuracy\nin reproducing equilibrium and time-dependent properties, using both\nsystem-specific and general-purpose models, extending the ability of MD\nsimulation to reach the long time scales needed to model microscopic processes\nof high scientific and technological relevance.",
    "pdf_url": "http://arxiv.org/pdf/2505.19350v1",
    "published": "2025-05-25T22:34:31+00:00",
    "categories": [
      "physics.chem-ph",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19349v2",
    "title": "DECA: A Near-Core LLM Decompression Accelerator Grounded on a 3D Roofline Model",
    "authors": [
      "Gerasimos Gerogiannis",
      "Stijn Eyerman",
      "Evangelos Georganas",
      "Wim Heirman",
      "Josep Torrellas"
    ],
    "abstract": "To alleviate the memory bandwidth bottleneck in Large Language Model (LLM)\ninference workloads, weight matrices are stored in memory in quantized and\nsparsified formats. Hence, before tiles of these matrices can be processed by\nin-core generalized matrix multiplication (GeMM) hardware engines, they need to\nbe dequantized and de-sparsified. This is currently performed in software with\nvector operations. Unfortunately, this approach delivers only modest\nperformance. Moreover, it is hard to understand how to improve the system, as\nthe overall GeMM performance depends on the interaction between memory\nresources, vector units, and hardware matrix engines.\n  To improve the performance of LLM inference in advanced platforms equipped\nwith in-core GeMM engines and HBM, this paper makes three main contributions.\nFirst, it develops an analytical performance model with a 3D visual\nrepresentation that provides insights into how memory resources, vector units,\nand hardware matrix engines interact to deliver compressed GeMM performance.\nSecond, it proposes DECA, a new near-core ML-model decompression accelerator.\nDECA offloads tile de-sparsification and dequantization from the CPU, producing\nready-to-use tiles for in-core GeMM engines. Third, it introduces a new ISA\nextension that enables out-of-order invocation of the near-core accelerator.\nWith this extension, accelerator and core computations can interleave and\noverlap with high-performance. Our evaluation shows that, in a simulated\n56-core Xeon 4 server with HBM, DECA accelerates the execution of compressed\nGeMMs by up to 4x over the use of optimized Intel software kernels. Further,\nDECA reduces the next-token generation time of Llama2-70B and OPT-66B by\n1.6x-2.6x.",
    "pdf_url": "http://arxiv.org/pdf/2505.19349v2",
    "published": "2025-05-25T22:32:35+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.23790v1",
    "title": "Rethinking the Understanding Ability across LLMs through Mutual Information",
    "authors": [
      "Shaojie Wang",
      "Sirui Ding",
      "Na Zou"
    ],
    "abstract": "Recent advances in large language models (LLMs) have revolutionized natural\nlanguage processing, yet evaluating their intrinsic linguistic understanding\nremains challenging. Moving beyond specialized evaluation tasks, we propose an\ninformation-theoretic framework grounded in mutual information (MI) to achieve\nthis. We formalize the understanding as MI between an input sentence and its\nlatent representation (sentence-level MI), measuring how effectively input\ninformation is preserved in latent representation. Given that LLMs learn\nembeddings for individual tokens, we decompose sentence-level MI into\ntoken-level MI between tokens and sentence embeddings, establishing theoretical\nbounds connecting these measures. Based on this foundation, we theoretically\nderive a computable lower bound for token-level MI using Fano's inequality,\nwhich directly relates to token-level recoverability-the ability to predict\noriginal tokens from sentence embedding. We implement this recoverability task\nto comparatively measure MI across different LLMs, revealing that encoder-only\nmodels consistently maintain higher information fidelity than their\ndecoder-only counterparts, with the latter exhibiting a distinctive late-layer\n\"forgetting\" pattern where mutual information is first enhanced and then\ndiscarded. Moreover, fine-tuning to maximize token-level recoverability\nconsistently improves understanding ability of LLMs on tasks without\ntask-specific supervision, demonstrating that mutual information can serve as a\nfoundation for understanding and improving language model capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.23790v1",
    "published": "2025-05-25T22:31:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19348v1",
    "title": "Developing a Numerical Framework for the High-Fidelity Simulation of Contrails: Sensitivity Analysis for Conventional Contrails",
    "authors": [
      "Tânia S. C. Ferreira",
      "Juan J. Alonso",
      "Catherine Gorlé"
    ],
    "abstract": "Contrails have recently gained widespread attention due to their large and\nuncertain estimates of effective radiative forcing, i.e., warming effect on the\nplanet, comparable to those of carbon dioxide. To study this aircraft-induced\ncloud formation in the context of current conventional fuels and future\nalternative fuels, we have developed a numerical framework for simulating the\njet and early vortex interaction phases of contrail formation.\n  Our approach consists of high-fidelity, 3D large-eddy simulations (LES) of an\nEulerian-Lagrangian two-phase flow using the compressible flow solver charLES.\nWe perform temporal simulations of the early contrail formation phases for a\nsingle linear contrail and compare the sensitivity of the results to modeling\nchoices and atmospheric, aircraft, and engine parameters.\n  Specifically, we discuss how these choices and parameters affect the number\nof nucleated ice crystals and estimated net radiative forcing (based on an\noptical depth parameterization). Our simulations show the most significant\nsensitivity to the aircraft size, followed by the soot number emission index\nand fuel consumption. Adding atmospheric aerosol as a precursor for future\nstudies of sustainable fuels evidences a non-linear relation previously\nhighlighted in the literature between number of emitted soot and nucleated ice\ncrystals.",
    "pdf_url": "http://arxiv.org/pdf/2505.19348v1",
    "published": "2025-05-25T22:30:39+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.19347v1",
    "title": "PatentMind: A Multi-Aspect Reasoning Graph for Patent Similarity Evaluation",
    "authors": [
      "Yongmin Yoo",
      "Qiongkai Xu",
      "Longbing Cao"
    ],
    "abstract": "Patent similarity evaluation plays a critical role in intellectual property\nanalysis. However, existing methods often overlook the intricate structure of\npatent documents, which integrate technical specifications, legal boundaries,\nand application contexts. We introduce PatentMind, a novel framework for patent\nsimilarity assessment based on a Multi-Aspect Reasoning Graph (MARG).\nPatentMind decomposes patents into three core dimensions: technical feature,\napplication domain, and claim scope, to compute dimension-specific similarity\nscores. These scores are dynamically weighted through a four-stage reasoning\nprocess which integrates contextual signals to emulate expert-level judgment.\nTo support evaluation, we construct PatentSimBench, a human-annotated benchmark\ncomprising 500 patent pairs. Experimental results demonstrate that PatentMind\nachieves a strong correlation ($r=0.938$) with expert annotations,\nsignificantly outperforming embedding-based models and advanced prompt\nengineering methods.These results highlight the effectiveness of modular\nreasoning frameworks in overcoming key limitations of embedding-based methods\nfor analyzing patent similarity.",
    "pdf_url": "http://arxiv.org/pdf/2505.19347v1",
    "published": "2025-05-25T22:28:27+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19346v1",
    "title": "IsoGeometric Suitable Coupling Methods for Partitioned Multiphysics Simulation with Application to Fluid-Structure Interaction",
    "authors": [
      "Jing-Ya Li",
      "Hugo M. Verhelst",
      "Henk den Besten",
      "Matthias Möller"
    ],
    "abstract": "This paper presents spline-based coupling methods for partitioned\nmultiphysics simulations, specifically designed for isogeometric analysis (IGA)\nbased solvers. Traditional vertex-based coupling approaches face significant\nchallenges when applied to IGA solvers, including geometric accuracy issues,\ninterpolation errors, and substantial communication overhead. The methodology\ndraws on the IGA mathematical framework to deliver coupling solutions that\npreserve high-order continuity and exact geometric representation of splines.\nWe develop two complementary strategies: (1) a spline-vertex coupling method\nenabling efficient interaction between IGA and conventional solvers, and (2) a\nfully isogeometric coupling approach maximizing accuracy for IGA-to-IGA\ncommunication.\n  Both theoretical analysis and extensive numerical experiments demonstrate\nthat our spline-based methods significantly reduce communication overhead\ncompared to traditional approaches while enhancing geometric accuracy through\nexact boundary representation and maintaining higher-order solution continuity\nacross coupled interfaces. We quantitatively confirm communication efficiency\nbenefits through systematic measurements of transfer times and data volumes\nacross various mesh refinement levels. Our benchmark studies demonstrate\ngeometric fidelity advantages while highlighting how splines naturally preserve\nsolution derivatives across interfaces without requiring additional\ncomputation. This work provides efficient coupling strategies tailored to\nIGA-based solvers and establishes a practical bridge between IGA and\ntraditional discretization methods, enabling broader adoption of IGA in\nestablished simulation workflows.",
    "pdf_url": "http://arxiv.org/pdf/2505.19346v1",
    "published": "2025-05-25T22:26:28+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19345v1",
    "title": "PatentScore: Multi-dimensional Evaluation of LLM-Generated Patent Claims",
    "authors": [
      "Yongmin Yoo",
      "Qiongkai Xu",
      "Longbing Cao"
    ],
    "abstract": "Natural language generation (NLG) metrics play a central role in evaluating\ngenerated texts, but are not well suited for the structural and legal\ncharacteristics of patent documents. Large language models (LLMs) offer strong\npotential in automating patent generation, yet research on evaluating\nLLM-generated patents remains limited, especially in evaluating the generation\nquality of patent claims, which are central to defining the scope of\nprotection. Effective claim evaluation requires addressing legal validity,\ntechnical accuracy, and structural compliance. To address this gap, we\nintroduce PatentScore, a multi-dimensional evaluation framework for assessing\nLLM-generated patent claims. PatentScore incorporates: (1) hierarchical\ndecomposition for claim analysis; (2) domain-specific validation patterns based\non legal and technical standards; and (3) scoring across structural, semantic,\nand legal dimensions. Unlike general-purpose NLG metrics, PatentScore reflects\npatent-specific constraints and document structures, enabling evaluation beyond\nsurface similarity. We evaluate 400 GPT-4o-mini generated Claim 1s and report a\nPearson correlation of $r = 0.819$ with expert annotations, outperforming\nexisting NLG metrics. Furthermore, we conduct additional evaluations using open\nmodels such as Claude-3.5-Haiku and Gemini-1.5-flash, all of which show strong\ncorrelations with expert judgments, confirming the robustness and\ngeneralizability of our framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.19345v1",
    "published": "2025-05-25T22:20:11+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19344v1",
    "title": "A relation to a remainder terms in an asymptotic formula for the associated Euler totient function",
    "authors": [
      "Hideto Iwata"
    ],
    "abstract": "H.L.Montgomery proved a relation for error terms in asymptotic formulas for\nthe Euler totient function. J.Kaczorowski defined the associated Euler totient\nfunction which generalizes and obtained an asymptotic formula for it. In this\npaper, we prove a relation on error terms similar to H.L.Montgomery's result\nfor a certain special case of the associated Euler totient function.",
    "pdf_url": "http://arxiv.org/pdf/2505.19344v1",
    "published": "2025-05-25T22:17:45+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19343v1",
    "title": "Handle decompositions and stabilizations of open books",
    "authors": [
      "Chun-Sheng Hsueh"
    ],
    "abstract": "We build handle decompositions of n-manifolds that encode given open book\ndecompositions and describe handle slides that reveal new open book\ndecompositions on the same underlying manifold, for $n \\geq 3$. This recovers\nknown stabilization operations for open books. As an application, we show that\nany open book with trivial monodromy can be stabilized to an open book whose\npage is a boundary connected sum of trivial disk bundles over spheres.",
    "pdf_url": "http://arxiv.org/pdf/2505.19343v1",
    "published": "2025-05-25T22:17:13+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19342v1",
    "title": "Communication-Efficient Multi-Device Inference Acceleration for Transformer Models",
    "authors": [
      "Xiao Liu",
      "Lijun Zhang",
      "Deepak Ganesan",
      "Hui Guan"
    ],
    "abstract": "Transformer models power many AI applications but suffer from high inference\nlatency, limiting their use in real-time settings. Multi-device inference can\nreduce latency by parallelizing computation. Yet, existing methods require high\ninter-device bandwidth, making them impractical for bandwidth-constrained\nenvironments. We propose ASTRA, a communication-efficient framework that\naccelerates Transformer inference through a novel integration of sequence\nparallelism and a Mixed-Precision Attention mechanism designed to minimize\ninter-device communication. ASTRA compresses non-local token embeddings via\nvector quantization and preserves task accuracy through two optimizations,\nNoise-Augmented Quantization and Distributed Class Tokens. Experiments on ViT\nand GPT2 across vision and NLP tasks show that ASTRA achieves up to 2.64X\nspeedups over single-device inference and up to 15.25X speedups over\nstate-of-the-art multi-device inferences, while operating under bandwidths as\nlow as 10 Mbps. ASTRA is open-sourced at https://github.com/xl1990/Astra.",
    "pdf_url": "http://arxiv.org/pdf/2505.19342v1",
    "published": "2025-05-25T22:16:59+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19341v1",
    "title": "Review of point defect structures in hexagonal close packed metals and across the Periodic Table",
    "authors": [
      "Andrew Ralph Warwick",
      "Pui-Wai Ma",
      "Sergei Lvovich Dudarev"
    ],
    "abstract": "We present a comprehensive ab initio dataset of formation energies and\nelastic properties of intrinsic point defects across all the transition and\nrare earth hexagonal close packed (hcp) metals, as well as metalloid elements\nwith hcp crystal structure. Point defect properties appear weakly correlated\nwith the c/a ratio of the hcp lattice. Instead, it is the position of an\nelement in the Periodic Table that primarily defines the relaxation volume\ntensor, elastic dipole tensor and formation energy of a point defect. This\nsuggests that the local variations in the electronic structure and interatomic\nbonding at the core of a defect dominate its properties, as opposed to\nlong-range elastic deformations. Across all the metals, we find that the\nrelaxation volumes of vacancies and self-interstitial defects are correlated\nwith atomic volumes, with values of -0.35 and 1.46 atomic volumes for a vacancy\nand a self-interstitial defect, respectively, providing a universally good\napproximation independent of the crystal structure. This study complements and\ncompletes the existing point defect databases spanning body-centred cubic and\nface-centred cubic metals.",
    "pdf_url": "http://arxiv.org/pdf/2505.19341v1",
    "published": "2025-05-25T22:16:12+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.19340v1",
    "title": "Visibility in graphs under edge and vertex removal",
    "authors": [
      "Pakanun Dokyeesun",
      "Csilla Bujtás"
    ],
    "abstract": "For a connected graph $G$ and $X\\subseteq V(G)$, we say that two vertices\n$u$, $v$ are $X$-visible if there is a shortest $u,v$-path $P$ with $V(P)\\cap X\n\\subseteq \\{u,v\\}$. If every two vertices from $X$ are $X$-visible, then $X$ is\na mutual-visibility set in $G$. The largest cardinality of such a set in $G$ is\nthe mutual-visibility number $\\mu(G)$. When the visibility constraint is\nextended to further types of vertex pairs, we get the definitions of outer,\ndual, and total mutual-visibility sets and the respective graph invariants\n$\\mu_o(G)$, $\\mu_d(G)$, and $\\mu_t(G)$.\n  This work concentrates on the possible changes in the four visibility\ninvariants when an edge $e$ or a vertex $x$ is removed from $G$ and the graph\nremains connected. It is proved that $\\frac{1}{2}\\mu(G) \\le \\mu(G-e) \\le\n2\\mu(G)$ and $\\frac{1}{6}\\mu_o(G) \\le \\mu_o(G-e) \\le 2\\mu_o(G)+1$ hold for\nevery graph. Further general upper bounds established here are $\\mu_t(G-e) \\leq\n\\mu_t(G)+2$ and $\\mu(G-x) \\leq 2\\mu(G)$. For all but one of the remaining\ncases, it is shown that the visibility invariant may increase or decrease\narbitrarily under the considered local operation. For example, neither\n$\\mu_d(G-e)$ nor $\\mu_d(G-x)$ allows lower or upper bounds of the form $a \\cdot\n\\mu_d(G)+b$ with a positive constant $a$. Along the way, the realizability of\nthe four visibility invariants in terms of the order is also characterized in\nthe paper.",
    "pdf_url": "http://arxiv.org/pdf/2505.19340v1",
    "published": "2025-05-25T22:12:39+00:00",
    "categories": [
      "math.CO",
      "05C12, 05C31, 05C69"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19339v1",
    "title": "Towards Humanoid Robot Autonomy: A Dynamic Architecture Integrating Continuous thought Machines (CTM) and Model Context Protocol (MCP)",
    "authors": [
      "Libo Wang"
    ],
    "abstract": "To address the gaps between the static pre-set \"thinking-planning-action\" of\nhumanoid robots in unfamiliar scenarios and the highly programmed \"call\ntool-return result\" due to the lack of autonomous coding capabilities, this\nwork designs a dynamic architecture connecting continuous thought machines\n(CTM) and model context protocol (MCP). It proposes a theoretical parallel\nsolution through tick-slab and uses rank compression to achieve parameter\nsuppression to provide a solution for achieving autonomous actions due to\nautonomous coding. The researcher used a simulation-based experiment using\nOpenAI's o4-mini-high as a tool to build the experimental environment, and\nintroduced the extended SayCan dataset to conduct nine epochs of experiments.\nThe experimental results show that the CTM-MCP architecture is feasible and\neffective through the data results of seven metrics: task success rate (TSR),\nexecution success rate (ESR), average episode length (AEL), ROSCOE, REVEAL,\nproficiency self-assessment (PSA), task effectiveness (TE). In practice, it\nprovides a reference experience for exploring the autonomous dynamic coding of\nhumanoid robots based on continuous thinking to achieve human-like autonomous\nactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.19339v1",
    "published": "2025-05-25T22:12:35+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19338v1",
    "title": "Co-evolutionary Dynamics of Attack and Defence in Cybersecurity",
    "authors": [
      "Adeela Bashir",
      "Zia Ush Shamszaman",
      "Zhao Song",
      "The Anh Han"
    ],
    "abstract": "In the evolving digital landscape, it is crucial to study the dynamics of\ncyberattacks and defences. This study uses an Evolutionary Game Theory (EGT)\nframework to investigate the evolutionary dynamics of attacks and defences in\ncyberspace. We develop a two-population asymmetric game between attacker and\ndefender to capture the essential factors of costs, potential benefits, and the\nprobability of successful defences. Through mathematical analysis and numerical\nsimulations, we find that systems with high defence intensities show stability\nwith minimal attack frequencies, whereas low-defence environments show\ninstability, and are vulnerable to attacks. Furthermore, we find five\nequilibria, where the strategy pair always defend and attack emerged as the\nmost likely stable state as cyber domain is characterised by a continuous\nbattle between defenders and attackers. Our theoretical findings align with\nreal-world data from past cyber incidents, demonstrating the interdisciplinary\nimpact, such as fraud detection, risk management and cybersecurity\ndecision-making. Overall, our analysis suggests that adaptive cybersecurity\nstrategies based on EGT can improve resource allocation, enhance system\nresilience, and reduce the overall risk of cyberattacks. By incorporating\nreal-world data, this study demonstrates the applicability of EGT in addressing\nthe evolving nature of cyber threats and the need for secure digital ecosystems\nthrough strategic planning and proactive defence measures.",
    "pdf_url": "http://arxiv.org/pdf/2505.19338v1",
    "published": "2025-05-25T22:11:24+00:00",
    "categories": [
      "cs.GT",
      "cs.CR",
      "nlin.AO"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19337v2",
    "title": "Prompting Decision Transformers for Zero-Shot Reach-Avoid Policies",
    "authors": [
      "Kevin Li",
      "Marinka Zitnik"
    ],
    "abstract": "Offline goal-conditioned reinforcement learning methods have shown promise\nfor reach-avoid tasks, where an agent must reach a target state while avoiding\nundesirable regions of the state space. Existing approaches typically encode\navoid-region information into an augmented state space and cost function, which\nprevents flexible, dynamic specification of novel avoid-region information at\nevaluation time. They also rely heavily on well-designed reward and cost\nfunctions, limiting scalability to complex or poorly structured environments.\nWe introduce RADT, a decision transformer model for offline, reward-free,\ngoal-conditioned, avoid region-conditioned RL. RADT encodes goals and avoid\nregions directly as prompt tokens, allowing any number of avoid regions of\narbitrary size to be specified at evaluation time. Using only suboptimal\noffline trajectories from a random policy, RADT learns reach-avoid behavior\nthrough a novel combination of goal and avoid-region hindsight relabeling. We\nbenchmark RADT against 3 existing offline goal-conditioned RL models across 11\ntasks, environments, and experimental settings. RADT generalizes in a zero-shot\nmanner to out-of-distribution avoid region sizes and counts, outperforming\nbaselines that require retraining. In one such zero-shot setting, RADT achieves\n35.7% improvement in normalized cost over the best retrained baseline while\nmaintaining high goal-reaching success. We apply RADT to cell reprogramming in\nbiology, where it reduces visits to undesirable intermediate gene expression\nstates during trajectories to desired target states, despite stochastic\ntransitions and discrete, structured state dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.19337v2",
    "published": "2025-05-25T22:00:38+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19336v1",
    "title": "Model-robust standardization in cluster-randomized trials",
    "authors": [
      "Fan Li",
      "Jiaqi Tong",
      "Xi Fang",
      "Chao Cheng",
      "Brennan C. Kahan",
      "Bingkai Wang"
    ],
    "abstract": "In cluster-randomized trials, generalized linear mixed models and generalized\nestimating equations have conventionally been the default analytic methods for\nestimating the average treatment effect as routine practice. However, recent\nstudies have demonstrated that their treatment effect coefficient estimators\nmay correspond to ambiguous estimands when the models are misspecified or when\nthere exists informative cluster sizes. In this article, we present a unified\napproach that standardizes output from a given regression model to ensure\nestimand-aligned inference for the treatment effect parameters in\ncluster-randomized trials. We introduce estimators for both the cluster-average\nand the individual-average treatment effects (marginal estimands) that are\nalways consistent regardless of whether the specified working regression models\nalign with the unknown data generating process. We further explore the use of a\ndeletion-based jackknife variance estimator for inference. The development of\nour approach also motivates a natural test for informative cluster size.\nExtensive simulation experiments are designed to demonstrate the advantage of\nthe proposed estimators under a variety of scenarios. The proposed model-robust\nstandardization methods are implemented in the MRStdCRT R package.",
    "pdf_url": "http://arxiv.org/pdf/2505.19336v1",
    "published": "2025-05-25T21:56:13+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.19335v1",
    "title": "Knoll: Creating a Knowledge Ecosystem for Large Language Models",
    "authors": [
      "Dora Zhao",
      "Diyi Yang",
      "Michael S. Bernstein"
    ],
    "abstract": "Large language models are designed to encode general purpose knowledge about\nthe world from Internet data. Yet, a wealth of information falls outside this\nscope -- ranging from personal preferences to organizational policies, from\ncommunity-specific advice to up-to-date news -- that users want models to\naccess but remains unavailable. In this paper, we propose a knowledge ecosystem\nin which end-users can create, curate, and configure custom knowledge modules\nthat are utilized by language models, such as ChatGPT and Claude. To support\nthis vision, we introduce Knoll, a software infrastructure that allows users to\nmake modules by clipping content from the web or authoring shared documents on\nGoogle Docs and GitHub, add modules that others have made, and rely on the\nsystem to insert relevant knowledge when interacting with an LLM. We conduct a\npublic deployment of Knoll reaching over 200 users who employed the system for\na diverse set of tasks including personalized recommendations, advice-seeking,\nand writing assistance. In our evaluation, we validate that using Knoll\nimproves the quality of generated responses.",
    "pdf_url": "http://arxiv.org/pdf/2505.19335v1",
    "published": "2025-05-25T21:49:14+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.21551v1",
    "title": "WhisperD: Dementia Speech Recognition and Filler Word Detection with Whisper",
    "authors": [
      "Emmanuel Akinrintoyo",
      "Nadine Abdelhalim",
      "Nicole Salomons"
    ],
    "abstract": "Whisper fails to correctly transcribe dementia speech because persons with\ndementia (PwDs) often exhibit irregular speech patterns and disfluencies such\nas pauses, repetitions, and fragmented sentences. It was trained on standard\nspeech and may have had little or no exposure to dementia-affected speech.\nHowever, correct transcription is vital for dementia speech for cost-effective\ndiagnosis and the development of assistive technology. In this work, we\nfine-tune Whisper with the open-source dementia speech dataset (DementiaBank)\nand our in-house dataset to improve its word error rate (WER). The fine-tuning\nalso includes filler words to ascertain the filler inclusion rate (FIR) and F1\nscore. The fine-tuned models significantly outperformed the off-the-shelf\nmodels. The medium-sized model achieved a WER of 0.24, outperforming previous\nwork. Similarly, there was a notable generalisability to unseen data and speech\npatterns.",
    "pdf_url": "http://arxiv.org/pdf/2505.21551v1",
    "published": "2025-05-25T21:48:03+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.19334v1",
    "title": "Likert or Not: LLM Absolute Relevance Judgments on Fine-Grained Ordinal Scales",
    "authors": [
      "Charles Godfrey",
      "Ping Nie",
      "Natalia Ostapuk",
      "David Ken",
      "Shang Gao",
      "Souheil Inati"
    ],
    "abstract": "Large language models (LLMs) obtain state of the art zero shot relevance\nranking performance on a variety of information retrieval tasks. The two most\ncommon prompts to elicit LLM relevance judgments are pointwise scoring (a.k.a.\nrelevance generation), where the LLM sees a single query-document pair and\noutputs a single relevance score, and listwise ranking (a.k.a. permutation\ngeneration), where the LLM sees a query and a list of documents and outputs a\npermutation, sorting the documents in decreasing order of relevance. The\ncurrent research community consensus is that listwise ranking yields superior\nperformance, and significant research effort has been devoted to crafting LLM\nlistwise ranking algorithms. The underlying hypothesis is that LLMs are better\nat making relative relevance judgments than absolute ones. In tension with this\nhypothesis, we find that the gap between pointwise scoring and listwise ranking\nshrinks when pointwise scoring is implemented using a sufficiently large\nordinal relevance label space, becoming statistically insignificant for many\nLLM-benchmark dataset combinations (where ``significant'' means ``95\\%\nconfidence that listwise ranking improves NDCG@10''). Our evaluations span four\nLLMs, eight benchmark datasets from the BEIR and TREC-DL suites, and two\nproprietary datasets with relevance labels collected after the training cut-off\nof all LLMs evaluated.",
    "pdf_url": "http://arxiv.org/pdf/2505.19334v1",
    "published": "2025-05-25T21:41:35+00:00",
    "categories": [
      "cs.LG",
      "cs.IR",
      "H.3.3; I.2.7; H.3.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19333v1",
    "title": "Evaluating Steering Techniques using Human Similarity Judgments",
    "authors": [
      "Zach Studdiford",
      "Timothy T. Rogers",
      "Siddharth Suresh",
      "Kushin Mukherjee"
    ],
    "abstract": "Current evaluations of Large Language Model (LLM) steering techniques focus\non task-specific performance, overlooking how well steered representations\nalign with human cognition. Using a well-established triadic similarity\njudgment task, we assessed steered LLMs on their ability to flexibly judge\nsimilarity between concepts based on size or kind. We found that prompt-based\nsteering methods outperformed other methods both in terms of steering accuracy\nand model-to-human alignment. We also found LLMs were biased towards 'kind'\nsimilarity and struggled with 'size' alignment. This evaluation approach,\ngrounded in human cognition, adds further support to the efficacy of\nprompt-based steering and reveals privileged representational axes in LLMs\nprior to steering.",
    "pdf_url": "http://arxiv.org/pdf/2505.19333v1",
    "published": "2025-05-25T21:40:26+00:00",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19332v1",
    "title": "The Gauge Theory Bootstrap: Predicting pion dynamics from QCD",
    "authors": [
      "Yifei He",
      "Martin Kruczenski"
    ],
    "abstract": "The Gauge Theory Bootstrap [arXiv:2309.12402, arXiv:2403.10772] computes the\nstrongly coupled pion dynamics by considering the most general scattering\nmatrix, form factors and spectral densities and matching them with perturbative\nQCD at high energy and with weakly coupled pions at low energy. In this work,\nwe show that further constraints on the spectral densities significantly reduce\nthe possible solutions to a small set of qualitatively similar ones.\nQuantitatively, the precise solution is controlled by the asymptotic value of\nthe form factors and SVZ sum rules. We also introduce an iterative procedure\nthat, starting from a generic feasible point, converges to a unique solution\nparameterized by the UV input. For the converged solution we compute masses and\nwidths of resonances that appear, scattering lengths and effective ranges of\npartial waves, low energy coefficients in the effective action. Additionally,\nwe use these results to discuss the thermodynamics of a pion gas including pair\ncorrelations of pions with same and opposite charge.",
    "pdf_url": "http://arxiv.org/pdf/2505.19332v1",
    "published": "2025-05-25T21:38:37+00:00",
    "categories": [
      "hep-th",
      "hep-lat",
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.19331v1",
    "title": "Phase Biasing System for Optical Gyroscope Using Passive Non-Reciprocal Polarization Techniques",
    "authors": [
      "Onder Akcaalan",
      "Melike Gumus Akcaalan"
    ],
    "abstract": "Interferometric Fiber Optic Gyroscopes (IFOGs) are widely used in precision\nnavigation systems due to their high sensitivity, robustness, and solid-state\nnature. To ensure linear response and accurate angular velocity measurement, a\nfixed $\\pi/2$ phase bias is typically introduced between the clockwise (CW) and\ncounter-clockwise (CCW) beams using active modulation components. However,\nthese active elements increase system complexity, power consumption, cost, and\nsusceptibility to thermal drift and long-term degradation. In this work, we\npresent a novel IFOG configuration that, to the best of our knowledge, achieves\nfor the first time, simultaneous operation at two quadrature points ($\\pi/2$\nand $3\\pi/2$), providing natural noise suppression without relying on active\ncomponents. This is made possible through the integration of a Non-Reciprocal\nPolarization-Dependent Phase Shifter (NRPPS), which introduces a pure $\\pi/2$\npassive phase shift. We detail the optical architecture and provide theoretical\nmodeling using Jones calculus to demonstrate how the NRPPS element introduces\npassive quadrature biasing. Simulation results show that the proposed\nNRPPS-IFOG achieves significantly improved sensitivity, with Angular Random\nWalk (ARW) values up to 40x lower than those of conventional IFOGs, depending\non the fiber coil length. The design further leverages quadrature-phase signal\ndetection and adjustable temporal offsets between photodetectors to enhance\nnoise suppression. This passive biasing approach eliminates the need for active\nmodulation, offering reduced power consumption, improved stability, and\nenhanced long-term reliability.",
    "pdf_url": "http://arxiv.org/pdf/2505.19331v1",
    "published": "2025-05-25T21:36:10+00:00",
    "categories": [
      "physics.app-ph",
      "physics.optics"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19330v1",
    "title": "Deriving The Fundamental Equation of Earthmoving and Configuring Vortex Studio Earthmoving Simulation for Soil Property Estimation Experimentation",
    "authors": [
      "W. Jacob Wagner"
    ],
    "abstract": "This document serves as supplementary material for two International Society\nfor Terrain-Vehicle Systems conference publications regarding in situ soil\nproperty estimation by Wagner et al. in 2023 and 2025. It covers the derivation\nof the fundamental equation of earthmoving for a flat blade moving through\nsloped soil and provides some information regarding the advanced configuration\nof Vortex Studio's soil-tool interaction simulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19330v1",
    "published": "2025-05-25T21:35:14+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19329v1",
    "title": "Deployable 3D mesoscale structures through wafer fabrication, geometric frustration and bistable auxeticity",
    "authors": [
      "Yue Wang",
      "Kelvin Shum",
      "Yuyang Song",
      "Tian Chen"
    ],
    "abstract": "Transforming planar mesoscale devices into precise 3-D architectures is vital\nfor next-generation flexible electronics, implants, and adaptive optics, yet\nwafer-based manufacturing to free-standing 3-D structures remain elusive. We\nfabricate polyimide architected 2-D precursors whose bistable unit cells deploy\ninto stable 3-D mesoscale structures. Target Gaussian curvature is encoded by\nconformally flattening the desired mesh and locally tuning each cell so its\nsecond equilibrium matches the required scaling factor, aided by a computed\nlibrary of isotropically expanding, bistable microstructures. The resulting\nheterogeneous tessellations uniquely morph into complex shapes. A flat disk\ndeploys into a hemispherical dome with sub-millimeter accuracy and retains its\nshape after indentation. The same process yields positive- and\nnegative-curvature geometries and tunable-focus paraboloidal mirrors whose\nreflected laser patterns coincide with geometric optics calculations. Our\nwafer-compatible, generative algorithm extends far beyond flexible substrates,\nenabling truly deployable, high-performance electronics and optical devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.19329v1",
    "published": "2025-05-25T21:31:02+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19328v2",
    "title": "BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Behavioural Change",
    "authors": [
      "Manuela González-González",
      "Soufiane Belharbi",
      "Muhammad Osama Zeeshan",
      "Masoumeh Sharafi",
      "Muhammad Haseeb Aslam",
      "Marco Pedersoli",
      "Alessandro Lameiras Koerich",
      "Simon L Bacon",
      "Eric Granger"
    ],
    "abstract": "Recognizing complex emotions linked to ambivalence and hesitancy (A/H) can\nplay a critical role in the personalization and effectiveness of digital\nbehaviour change interventions. These subtle and conflicting emotions are\nmanifested by a discord between multiple modalities, such as facial and vocal\nexpressions, and body language. Although experts can be trained to identify\nA/H, integrating them into digital interventions is costly and less effective.\nAutomatic learning systems provide a cost-effective alternative that can adapt\nto individual users, and operate seamlessly within real-time, and\nresource-limited environments. However, there are currently no datasets\navailable for the design of ML models to recognize A/H. This paper introduces a\nfirst Behavioural Ambivalence/Hesitancy (BAH) dataset collected for\nsubject-based multimodal recognition of A/H in videos. It contains videos from\n224 participants captured across 9 provinces in Canada, with different age, and\nethnicity. Through our web platform, we recruited participants to answer 7\nquestions, some of which were designed to elicit A/H while recording themselves\nvia webcam with microphone. BAH amounts to 1,118 videos for a total duration of\n8.26 hours with 1.5 hours of A/H. Our behavioural team annotated timestamp\nsegments to indicate where A/H occurs, and provide frame- and video-level\nannotations with the A/H cues. Video transcripts and their timestamps are also\nincluded, along with cropped and aligned faces in each frame, and a variety of\nparticipants meta-data. We include results baselines for BAH at frame- and\nvideo-level recognition in multi-modal setups, in addition to zero-shot\nprediction, and for personalization using unsupervised domain adaptation. The\nlimited performance of baseline models highlights the challenges of recognizing\nA/H in real-world videos. The data, code, and pretrained weights are available.",
    "pdf_url": "http://arxiv.org/pdf/2505.19328v2",
    "published": "2025-05-25T21:29:00+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19327v1",
    "title": "Paying Alignment Tax with Contrastive Learning",
    "authors": [
      "Buse Sibel Korkmaz",
      "Rahul Nair",
      "Elizabeth M. Daly",
      "Antonio del Rio Chanona"
    ],
    "abstract": "Current debiasing approaches often result a degradation in model capabilities\nsuch as factual accuracy and knowledge retention. Through systematic evaluation\nacross multiple benchmarks, we demonstrate that existing debiasing methods face\nfundamental trade-offs, particularly in smaller models, leading to reduced\ntruthfulness, knowledge loss, or unintelligible outputs. To address these\nlimitations, we propose a contrastive learning framework that learns through\ncarefully constructed positive and negative examples. Our approach introduces\ncontrast computation and dynamic loss scaling to balance bias mitigation with\nfaithfulness preservation. Experimental results across multiple model scales\ndemonstrate that our method achieves substantial improvements in both toxicity\nreduction and faithfulness preservation. Most importantly, we show that our\nframework is the first to consistently improve both metrics simultaneously,\navoiding the capability degradation characteristic of existing approaches.\nThese results suggest that explicit modeling of both positive and negative\nexamples through contrastive learning could be a promising direction for\nreducing the alignment tax in language model debiasing.",
    "pdf_url": "http://arxiv.org/pdf/2505.19327v1",
    "published": "2025-05-25T21:26:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19326v2",
    "title": "Quantum limits of the Martinet sub-Laplacian",
    "authors": [
      "Víctor Arnaiz"
    ],
    "abstract": "In this article we study the semiclassical asymptotics of the Martinet\nsub-Laplacian on the flat toroidal cylinder $M = \\mathbb{R} \\times\n\\mathbb{T}^2$. We describe the asymptotic distribution of sequences of\neigenfunctions oscillating at different scales prefixed by Rothschild-Stein\nestimates via the introduction of adapted two-microlocal semiclassical\nmeasures. We obtain concentration and invariance properties of these measures\nin terms of effective dynamics governed by harmonic or an-harmonic oscillators\ndepending on the regime, and we show additional regularity properties with\nrespect to critical points of the eigenvalues of the Montgomery family of\nquartic oscillators.",
    "pdf_url": "http://arxiv.org/pdf/2505.19326v2",
    "published": "2025-05-25T21:24:16+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "math.SP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19325v1",
    "title": "What do Blind and Low-Vision People Really Want from Assistive Smart Devices? Comparison of the Literature with a Focus Study",
    "authors": [
      "Bhanuka Gamage",
      "Thanh-Toan Do",
      "Nicholas Seow Chiang Price",
      "Arthur Lowery",
      "Kim Marriott"
    ],
    "abstract": "Over the last decade there has been considerable research into how artificial\nintelligence (AI), specifically computer vision, can assist people who are\nblind or have low-vision (BLV) to understand their environment. However, there\nhas been almost no research into whether the tasks (object detection, image\ncaptioning, text recognition etc.) and devices (smartphones, smart-glasses\netc.) investigated by researchers align with the needs and preferences of BLV\npeople. We identified 646 studies published in the last two and a half years\nthat have investigated such assistive AI techniques. We analysed these papers\nto determine the task, device and participation by BLV individuals. We then\ninterviewed 24 BLV people and asked for their top five AI-based applications\nand to rank the applications found in the literature. We found only a weak\npositive correlation between BLV participants' perceived importance of tasks\nand researchers' focus and that participants prefer conversational agent\ninterface and head-mounted devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.19325v1",
    "published": "2025-05-25T21:23:38+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19324v1",
    "title": "Topological Complexity of symplectic CW-complexes",
    "authors": [
      "Luca Sandrock",
      "Thomas Schick"
    ],
    "abstract": "A cohomology class u of a topological space X is atoroidal if its pullback to\nthe torus vanishes for every map from a torus to X. Furthermore, X is\natoroidally symplectic if there is an atoroidal cohomology class $u\\in\nH^2(X;F)$ such that $u^n$ is non-zero. We prove that every atoroidally\nsymplectic CW-complex X of dimension 2n has topological complexity 4n.\n  This generalizes a result of Grant and Mescher who prove the corresponding\nstatement in the case where X is an atoroidally c-symplectic manifold and u is\na de Rham cohomology class. Using this generalisation, we obtain new\ncalculations of topological complexity, including for many products of\n3-manifolds and of group presentation complexes.",
    "pdf_url": "http://arxiv.org/pdf/2505.19324v1",
    "published": "2025-05-25T21:21:40+00:00",
    "categories": [
      "math.AT",
      "math.GT",
      "math.KT"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19323v1",
    "title": "A Real-Analytic Approach to Differential-Algebraic Dynamic Logic",
    "authors": [
      "Jonathan Hellwig",
      "André Platzer"
    ],
    "abstract": "This paper introduces a proof calculus for real-analytic\ndifferential-algebraic dynamic logic, enabling correct transformations of\ndifferential-algebraic equations. Applications include index reductions from\ndifferential-algebraic equations to ordinary differential equations. The\ncalculus ensures compatibility between differential-algebraic equation proof\nprinciples and (differential-form) differential dynamic logic for hybrid\nsystems. One key contribution is ghost switching which establishes precise\nconditions that decompose multi-modal systems into hybrid systems, thereby\ncorrectly hybridizing sophisticated differential-algebraic dynamics. The\ncalculus is demonstrated in a proof of equivalence for a Euclidean pendulum to\nindex reduced form.",
    "pdf_url": "http://arxiv.org/pdf/2505.19323v1",
    "published": "2025-05-25T21:15:07+00:00",
    "categories": [
      "cs.LO",
      "F.3.1; F.4.1"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19322v1",
    "title": "NextG-GPT: Leveraging GenAI for Advancing Wireless Networks and Communication Research",
    "authors": [
      "Ahmad M. Nazar",
      "Mohamed Y. Selim",
      "Daji Qiao",
      "Hongwei Zhang"
    ],
    "abstract": "Artificial intelligence (AI) and wireless networking advancements have\ncreated new opportunities to enhance network efficiency and performance. In\nthis paper, we introduce Next-Generation GPT (NextG-GPT), an innovative\nframework that integrates retrieval-augmented generation (RAG) and large\nlanguage models (LLMs) within the wireless systems' domain. By leveraging\nstate-of-the-art LLMs alongside a domain-specific knowledge base, NextG-GPT\nprovides context-aware real-time support for researchers, optimizing wireless\nnetwork operations. Through a comprehensive evaluation of LLMs, including\nMistral-7B, Mixtral-8x7B, LLaMa3.1-8B, and LLaMa3.1-70B, we demonstrate\nsignificant improvements in answer relevance, contextual accuracy, and overall\ncorrectness. In particular, LLaMa3.1-70B achieves a correctness score of 86.2%\nand an answer relevancy rating of 90.6%. By incorporating diverse datasets such\nas ORAN-13K-Bench, TeleQnA, TSpec-LLM, and Spec5G, we improve NextG-GPT's\nknowledge base, generating precise and contextually aligned responses. This\nwork establishes a new benchmark in AI-driven support for next-generation\nwireless network research, paving the way for future innovations in intelligent\ncommunication systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.19322v1",
    "published": "2025-05-25T21:13:23+00:00",
    "categories": [
      "cs.ET"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.19321v1",
    "title": "Formation of supermassive stars in the first stellar clusters: Dependence on the gas temperature",
    "authors": [
      "P. A. Solar",
      "B. Reinoso",
      "D. R. G. Schleicher",
      "R. S. Klessen",
      "Robi Banerjee"
    ],
    "abstract": "The origin of supermassive black holes is an open question that has been\nexplored considering gas- and collision-based formation channels to explain the\nhigh number of quasars observed in the early Universe. According to numerical\nsimulations, supermassive stars can be formed in atomic cooling halos when\nprotostars reach accretion rates greater than $\\sim\n10^{-2}~\\mathrm{M_{\\odot}~yr^{-1}}$ and fragmentation is inhibited on parsec\nscales. It remains uncertain, however, whether fragmentation on smaller scales\nleads to the formation of a star cluster instead of a supermassive star in the\npresence of possible cooling mechanisms. We explored the formation of a central\nmassive object through collisions and the accretion of Population III stars in\na primordial gas cloud in a gravitationally unstable system by varying the gas\ntemperature and the degree of gravitational instability. We performed\nmultiphysics simulations in the AMUSE framework with a hydrodynamical gas\ntreatment through Smoothed-particle hydrodynamics and $N$-body dynamics for the\nprotostars represented through sink particles. Our results show that central\nmassive objects with masses $\\sim 10^4~\\mathrm{M_{\\odot}}$ can be formed by\naccretion and collisions at different temperatures and that the most massive\nobject can reach efficiencies of $\\sim 0.61$ for atomic cooling conditions and\n$\\sim 0.95$ for more unstable conditions. We observe a quasi-disk formation for\nwarmer temperatures and a higher contribution through collisions to the mass of\na central massive object. Our results show that the embedded cluster is in a\nsupercompetitive accretion regime in which it obtains mass by accretion that is\nregulated by self-gravity. Our results suggest that in more unstable conditions\nwith lower gas temperatures, a more massive supermassive black hole seed can\nform.",
    "pdf_url": "http://arxiv.org/pdf/2505.19321v1",
    "published": "2025-05-25T21:12:22+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19320v1",
    "title": "PIGPVAE: Physics-Informed Gaussian Process Variational Autoencoders",
    "authors": [
      "Michail Spitieris",
      "Massimiliano Ruocco",
      "Abdulmajid Murad",
      "Alessandro Nocente"
    ],
    "abstract": "Recent advances in generative AI offer promising solutions for synthetic data\ngeneration but often rely on large datasets for effective training. To address\nthis limitation, we propose a novel generative model that learns from limited\ndata by incorporating physical constraints to enhance performance.\nSpecifically, we extend the VAE architecture by incorporating physical models\nin the generative process, enabling it to capture underlying dynamics more\neffectively. While physical models provide valuable insights, they struggle to\ncapture complex temporal dependencies present in real-world data. To bridge\nthis gap, we introduce a discrepancy term to account for unmodeled dynamics,\nrepresented within a latent Gaussian Process VAE (GPVAE). Furthermore, we apply\nregularization to ensure the generated data aligns closely with observed data,\nenhancing both the diversity and accuracy of the synthetic samples. The\nproposed method is applied to indoor temperature data, achieving\nstate-of-the-art performance. Additionally, we demonstrate that PIGPVAE can\nproduce realistic samples beyond the observed distribution, highlighting its\nrobustness and usefulness under distribution shifts.",
    "pdf_url": "http://arxiv.org/pdf/2505.19320v1",
    "published": "2025-05-25T21:12:01+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.19319v3",
    "title": "Holistic White-light Polyp Classification via Alignment-free Dense Distillation of Auxiliary Optical Chromoendoscopy",
    "authors": [
      "Qiang Hu",
      "Qimei Wang",
      "Jia Chen",
      "Xuantao Ji",
      "Mei Liu",
      "Qiang Li",
      "Zhiwei Wang"
    ],
    "abstract": "White Light Imaging (WLI) and Narrow Band Imaging (NBI) are the two main\ncolonoscopic modalities for polyp classification. While NBI, as optical\nchromoendoscopy, offers valuable vascular details, WLI remains the most common\nand often the only available modality in resource-limited settings. However,\nWLI-based methods typically underperform, limiting their clinical\napplicability. Existing approaches transfer knowledge from NBI to WLI through\nglobal feature alignment but often rely on cropped lesion regions, which are\nsusceptible to detection errors and neglect contextual and subtle diagnostic\ncues. To address this, this paper proposes a novel holistic classification\nframework that leverages full-image diagnosis without requiring polyp\nlocalization. The key innovation lies in the Alignment-free Dense Distillation\n(ADD) module, which enables fine-grained cross-domain knowledge distillation\nregardless of misalignment between WLI and NBI images. Without resorting to\nexplicit image alignment, ADD learns pixel-wise cross-domain affinities to\nestablish correspondences between feature maps, guiding the distillation along\nthe most relevant pixel connections. To further enhance distillation\nreliability, ADD incorporates Class Activation Mapping (CAM) to filter\ncross-domain affinities, ensuring the distillation path connects only those\nsemantically consistent regions with equal contributions to polyp diagnosis.\nExtensive results on public and in-house datasets show that our method achieves\nstate-of-the-art performance, relatively outperforming the other approaches by\nat least 2.5% and 16.2% in AUC, respectively. Code is available at:\nhttps://github.com/Huster-Hq/ADD.",
    "pdf_url": "http://arxiv.org/pdf/2505.19319v3",
    "published": "2025-05-25T21:09:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19318v1",
    "title": "Plasma fireball sheath dynamics: A brief review and meta-analysis",
    "authors": [
      "Subham Dutta",
      "Ahmed Atteya",
      "Pralay Kumar Karmakar"
    ],
    "abstract": "We present a comprehensive overview of the formation mechanism of plasma\nfireball sheath (PFS) structures, sheath-induced collective phenomena,\nassociated relevant instabilities, and corresponding onset conditions. It\nincludes an optimum set of self-illustrative schematic figures, relevantly\nmanifesting the instability triggering dynamics, various involved metastable\nstages, and parametric threshold conditions. The possible damping mechanisms of\nexcited instabilities in the usual PFS systems are also highlighted. An\nup-to-date experimental glimpse of both the regular fireball (RFB) and inverted\nfireball (IFB) classes is specifically presented. We explicitly offer\nillustrative appendices showing the main distinctions between (a) RFB and IFB,\n(b) laboratory and astrocosmic fireballs, and (c) RFB sheath and IFB sheath\nformations. It provides a panoptic glimpse of the current RFB and IFB studies\nwith a special mention to both laboratory and astrospace plasmas. A holistic\noutline on the chronological development of the PFS research investigations,\nsince the inception of plasma-electrode coupling studies, is outlined. A clear\nindication of the future fireball scope in both theoretic and applied\nperspectives is finally emphasized.",
    "pdf_url": "http://arxiv.org/pdf/2505.19318v1",
    "published": "2025-05-25T21:07:48+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19317v4",
    "title": "Effort-aware Fairness: Incorporating a Philosophy-informed, Human-centered Notion of Effort into Algorithmic Fairness Metrics",
    "authors": [
      "Tin Trung Nguyen",
      "Jiannan Xu",
      "Zora Che",
      "Phuong-Anh Nguyen-Le",
      "Rushil Dandamudi",
      "Donald Braman",
      "Furong Huang",
      "Hal Daumé III",
      "Zubin Jelveh"
    ],
    "abstract": "Although popularized AI fairness metrics, e.g., demographic parity, have\nuncovered bias in AI-assisted decision-making outcomes, they do not consider\nhow much effort one has spent to get to where one is today in the input feature\nspace. However, the notion of effort is important in how Philosophy and humans\nunderstand fairness. We propose a philosophy-informed approach to conceptualize\nand evaluate Effort-aware Fairness (EaF), grounded in the concept of Force,\nwhich represents the temporal trajectory of predictive features coupled with\ninertia. Besides theoretical formulation, our empirical contributions include:\n(1) a pre-registered human subjects experiment, which shows that for both\nstages of the (individual) fairness evaluation process, people consider the\ntemporal trajectory of a predictive feature more than its aggregate value; (2)\npipelines to compute Effort-aware Individual/Group Fairness in the criminal\njustice and personal finance contexts. Our work may enable AI model auditors to\nuncover and potentially correct unfair decisions against individuals who have\nspent significant efforts to improve but are still stuck with systemic\ndisadvantages outside their control.",
    "pdf_url": "http://arxiv.org/pdf/2505.19317v4",
    "published": "2025-05-25T21:07:13+00:00",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19316v2",
    "title": "Making Teams and Influencing Agents: Efficiently Coordinating Decision Trees for Interpretable Multi-Agent Reinforcement Learning",
    "authors": [
      "Rex Chen",
      "Stephanie Milani",
      "Zhicheng Zhang",
      "Norman Sadeh",
      "Fei Fang"
    ],
    "abstract": "Poor interpretability hinders the practical applicability of multi-agent\nreinforcement learning (MARL) policies. Deploying interpretable surrogates of\nuninterpretable policies enhances the safety and verifiability of MARL for\nreal-world applications. However, if these surrogates are to interact directly\nwith the environment within human supervisory frameworks, they must be both\nperformant and computationally efficient. Prior work on interpretable MARL has\neither sacrificed performance for computational efficiency or computational\nefficiency for performance. To address this issue, we propose HYDRAVIPER, a\ndecision tree-based interpretable MARL algorithm. HYDRAVIPER coordinates\ntraining between agents based on expected team performance, and adaptively\nallocates budgets for environment interaction to improve computational\nefficiency. Experiments on standard benchmark environments for multi-agent\ncoordination and traffic signal control show that HYDRAVIPER matches the\nperformance of state-of-the-art methods using a fraction of the runtime, and\nthat it maintains a Pareto frontier of performance for different interaction\nbudgets.",
    "pdf_url": "http://arxiv.org/pdf/2505.19316v2",
    "published": "2025-05-25T21:05:48+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19315v1",
    "title": "Demand Selection for VRP with Emission Quota",
    "authors": [
      "Farid Najar",
      "Dominique Barth",
      "Yann Strozecki"
    ],
    "abstract": "Combinatorial optimization (CO) problems are traditionally addressed using\nOperations Research (OR) methods, including metaheuristics. In this study, we\nintroduce a demand selection problem for the Vehicle Routing Problem (VRP) with\nan emission quota, referred to as QVRP. The objective is to minimize the number\nof omitted deliveries while respecting the pollution quota. We focus on the\ndemand selection part, called Maximum Feasible Vehicle Assignment (MFVA), while\nthe construction of a routing for the VRP instance is solved using classical OR\nmethods. We propose several methods for selecting the packages to omit, both\nfrom machine learning (ML) and OR. Our results show that, in this static\nproblem setting, classical OR-based methods consistently outperform ML-based\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.19315v1",
    "published": "2025-05-25T21:04:38+00:00",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.19314v3",
    "title": "SoloSpeech: Enhancing Intelligibility and Quality in Target Speech Extraction through a Cascaded Generative Pipeline",
    "authors": [
      "Helin Wang",
      "Jiarui Hai",
      "Dongchao Yang",
      "Chen Chen",
      "Kai Li",
      "Junyi Peng",
      "Thomas Thebaud",
      "Laureano Moro Velazquez",
      "Jesus Villalba",
      "Najim Dehak"
    ],
    "abstract": "Target Speech Extraction (TSE) aims to isolate a target speaker's voice from\na mixture of multiple speakers by leveraging speaker-specific cues, typically\nprovided as auxiliary audio (a.k.a. cue audio). Although recent advancements in\nTSE have primarily employed discriminative models that offer high perceptual\nquality, these models often introduce unwanted artifacts, reduce naturalness,\nand are sensitive to discrepancies between training and testing environments.\nOn the other hand, generative models for TSE lag in perceptual quality and\nintelligibility. To address these challenges, we present SoloSpeech, a novel\ncascaded generative pipeline that integrates compression, extraction,\nreconstruction, and correction processes. SoloSpeech features a\nspeaker-embedding-free target extractor that utilizes conditional information\nfrom the cue audio's latent space, aligning it with the mixture audio's latent\nspace to prevent mismatches. Evaluated on the widely-used Libri2Mix dataset,\nSoloSpeech achieves the new state-of-the-art intelligibility and quality in\ntarget speech extraction while demonstrating exceptional generalization on\nout-of-domain data and real-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.19314v3",
    "published": "2025-05-25T21:00:48+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.19313v1",
    "title": "Concept Reachability in Diffusion Models: Beyond Dataset Constraints",
    "authors": [
      "Marta Aparicio Rodriguez",
      "Xenia Miscouridou",
      "Anastasia Borovykh"
    ],
    "abstract": "Despite significant advances in quality and complexity of the generations in\ntext-to-image models, prompting does not always lead to the desired outputs.\nControlling model behaviour by directly steering intermediate model activations\nhas emerged as a viable alternative allowing to reach concepts in latent space\nthat may otherwise remain inaccessible by prompt. In this work, we introduce a\nset of experiments to deepen our understanding of concept reachability. We\ndesign a training data setup with three key obstacles: scarcity of concepts,\nunderspecification of concepts in the captions, and data biases with tied\nconcepts. Our results show: (i) concept reachability in latent space exhibits a\ndistinct phase transition, with only a small number of samples being sufficient\nto enable reachability, (ii) where in the latent space the intervention is\nperformed critically impacts reachability, showing that certain concepts are\nreachable only at certain stages of transformation, and (iii) while prompting\nability rapidly diminishes with a decrease in quality of the dataset, concepts\noften remain reliably reachable through steering. Model providers can leverage\nthis to bypass costly retraining and dataset curation and instead innovate with\nuser-facing control mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.19313v1",
    "published": "2025-05-25T21:00:28+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19312v2",
    "title": "DocMMIR: A Framework for Document Multi-modal Information Retrieval",
    "authors": [
      "Zirui Li",
      "Siwei Wu",
      "Xingyu Wang",
      "Yi Zhou",
      "Yizhi Li",
      "Chenghua Lin"
    ],
    "abstract": "The rapid advancement of unsupervised representation learning and large-scale\npre-trained vision-language models has significantly improved cross-modal\nretrieval tasks. However, existing multi-modal information retrieval (MMIR)\nstudies lack a comprehensive exploration of document-level retrieval and suffer\nfrom the absence of cross-domain datasets at this granularity. To address this\nlimitation, we introduce DocMMIR, a novel multi-modal document retrieval\nframework designed explicitly to unify diverse document formats and domains,\nincluding Wikipedia articles, scientific papers (arXiv), and presentation\nslides, within a comprehensive retrieval scenario. We construct a large-scale\ncross-domain multimodal benchmark, comprising 450K samples, which\nsystematically integrates textual and visual information. Our comprehensive\nexperimental analysis reveals substantial limitations in current\nstate-of-the-art MLLMs (CLIP, BLIP2, SigLIP-2, ALIGN) when applied to our\ntasks, with only CLIP demonstrating reasonable zero-shot performance.\nFurthermore, we conduct a systematic investigation of training strategies,\nincluding cross-modal fusion methods and loss functions, and develop a tailored\napproach to train CLIP on our benchmark. This results in a +31% improvement in\nMRR@10 compared to the zero-shot baseline. All our data and code are released\nin https://github.com/J1mL1/DocMMIR.",
    "pdf_url": "http://arxiv.org/pdf/2505.19312v2",
    "published": "2025-05-25T20:58:58+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19311v1",
    "title": "Passive Vibration Control of a 3-D Printer Gantry",
    "authors": [
      "Maharshi A. Sharma",
      "Albert E. Patterson"
    ],
    "abstract": "Improved additive manufacturing capabilities are vital for the future\ndevelopment and improvement of ubiquitous robotic systems. These machines can\nbe integrated into existing robotic systems to allow manufacturing and repair\nof components, as well as fabrication of custom parts for the robots\nthemselves. The fused filament fabrication (FFF) process is one of the most\ncommon and well-developed AM processes but suffers from the effects of\nvibration-induced position error, particularly as the printing speed is raised.\nThis project adapted and expanded a dynamic model of an FFF gantry system to\ninclude a passive spring-mass-damper system controller attached to the extruder\ncarriage and tuned using optimal parameters. A case study was conducted to\ndemonstrate the effects and generate recommendations for implementation. This\nwork is also valuable for other mechatronic systems which operate using an\nopen-loop control system and which suffer from vibration, including numerous\nrobotic systems, pick-and-place machines, positioners, and similar.",
    "pdf_url": "http://arxiv.org/pdf/2505.19311v1",
    "published": "2025-05-25T20:52:44+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19310v1",
    "title": "Retrieval-Augmented Generation for Service Discovery: Chunking Strategies and Benchmarking",
    "authors": [
      "Robin D. Pesl",
      "Jerin G. Mathew",
      "Massimo Mecella",
      "Marco Aiello"
    ],
    "abstract": "Integrating multiple (sub-)systems is essential to create advanced\nInformation Systems. Difficulties mainly arise when integrating dynamic\nenvironments, e.g., the integration at design time of not yet existing\nservices. This has been traditionally addressed using a registry that provides\nthe API documentation of the endpoints. Large Language Models have shown to be\ncapable of automatically creating system integrations (e.g., as service\ncomposition) based on this documentation but require concise input due to input\noken limitations, especially regarding comprehensive API descriptions.\nCurrently, it is unknown how best to preprocess these API descriptions. In the\npresent work, we (i) analyze the usage of Retrieval Augmented Generation for\nendpoint discovery and the chunking, i.e., preprocessing, of state-of-practice\nOpenAPIs to reduce the input oken length while preserving the most relevant\ninformation. To further reduce the input token length for the composition\nprompt and improve endpoint retrieval, we propose (ii) a Discovery Agent that\nonly receives a summary of the most relevant endpoints nd retrieves\nspecification details on demand. We evaluate RAG for endpoint discovery using\n(iii) a proposed novel service discovery benchmark SOCBench-D representing a\ngeneral setting across numerous domains and the real-world RestBench enchmark,\nfirst, for the different chunking possibilities and parameters measuring the\nendpoint retrieval accuracy. Then, we assess the Discovery Agent using the same\ntest data set. The prototype shows how to successfully employ RAG for endpoint\ndiscovery to reduce the token count. Our experiments show that endpoint-based\napproaches outperform naive chunking methods for preprocessing. Relying on an\nagent significantly improves precision while being prone to decrease recall,\ndisclosing the need for further reasoning capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.19310v1",
    "published": "2025-05-25T20:49:39+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.19309v1",
    "title": "Fractional-Boundary-Regularized Deep Galerkin Method for Variational Inequalities in Mixed Optimal Stopping and Control",
    "authors": [
      "Yun Zhao",
      "Harry Zheng"
    ],
    "abstract": "Mixed optimal stopping and stochastic control problems define variational\ninequalities with non-linear Hamilton-Jacobi-Bellman (HJB) operators, whose\nnumerical solution is notoriously difficult and lack of reliable benchmarks. We\nfirst use the dual approach to transform it into a linear operator, and then\nintroduce a Fractional-Boundary-Regularized Deep Galerkin Method (FBR-DGM) that\naugments the classical $L^2$ loss with Sobolev-Slobodeckij norms on the\nparabolic boundary, enforcing regularity and yielding consistent improvements\nin the network approximation and its derivatives. The improved accuracy allows\nthe network to be converted back to the original solution using the dual\ntransform. The self-consistency and stability of the network can be tested by\nchecking the primal-dual relationship among optimal value, optimal wealth, and\noptimal control, offering innovative benchmarks in the absence of analytical\nsolutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.19309v1",
    "published": "2025-05-25T20:49:00+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "65K15, 68T07, 93E20, 60G40",
      "I.2.6"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19308v1",
    "title": "XMM-Newton Publications from 2000-2024",
    "authors": [
      "J. U. Ness",
      "N. Schartel",
      "M. Santos-Lleo"
    ],
    "abstract": "Novel studies are presented demonstrating that the data of ESA's XMM-Newton\nmission are efficiently used by an engaged and productive community. 87% of the\navailable time budget during the reference period 2000-2024 of 556Ms was used\nin at least one of 8486 publications (84% of 16894 observations) with a re-use\nof a factor up to 15 in dedicated publications. The duration between\nobservations and first publication peaks around 2 years with a second peak at 3\nyears. The publication rate remains stable at ~400 refereed articles per year.\nSince 2010, the annual number of first-time as well as last-time authors has\nremained constant at ~100 authors per year yielding ~4300 scientists engaged in\nresearch utilising XMM-Newton data including 570 lead (first) authors. We find\n51% of first authors to have published for one year, 24% were active for up to\nsix years, and 25% are permanently active yielding a core community of ~120\nscientists. The considerable number of time-limited activities may indicate a\nhigh level of utilisation within the context of university education. All\nstudied trends indicate a vital community with positive perspectives to\ncontinue their active interest in XMM-Newton for the future.",
    "pdf_url": "http://arxiv.org/pdf/2505.19308v1",
    "published": "2025-05-25T20:45:34+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.19307v1",
    "title": "Aligning Web Query Generation with Ranking Objectives via Direct Preference Optimization",
    "authors": [
      "João Coelho",
      "Bruno Martins",
      "João Magalhães",
      "Chenyan Xiong"
    ],
    "abstract": "Neural retrieval models excel in Web search, but their training requires\nsubstantial amounts of labeled query-document pairs, which are costly to\nobtain. With the widespread availability of Web document collections like\nClueWeb22, synthetic queries generated by large language models offer a\nscalable alternative. Still, synthetic training queries often vary in quality,\nwhich leads to suboptimal downstream retrieval performance. Existing methods\ntypically filter out noisy query-document pairs based on signals from an\nexternal re-ranker. In contrast, we propose a framework that leverages Direct\nPreference Optimization (DPO) to integrate ranking signals into the query\ngeneration process, aiming to directly optimize the model towards generating\nhigh-quality queries that maximize downstream retrieval effectiveness.\nExperiments show higher ranker-assessed relevance between query-document pairs\nafter DPO, leading to stronger downstream performance on the MS~MARCO benchmark\nwhen compared to baseline models trained with synthetic data.",
    "pdf_url": "http://arxiv.org/pdf/2505.19307v1",
    "published": "2025-05-25T20:34:12+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19306v1",
    "title": "From Single Images to Motion Policies via Video-Generation Environment Representations",
    "authors": [
      "Weiming Zhi",
      "Ziyong Ma",
      "Tianyi Zhang",
      "Matthew Johnson-Roberson"
    ],
    "abstract": "Autonomous robots typically need to construct representations of their\nsurroundings and adapt their motions to the geometry of their environment.\nHere, we tackle the problem of constructing a policy model for collision-free\nmotion generation, consistent with the environment, from a single input RGB\nimage. Extracting 3D structures from a single image often involves monocular\ndepth estimation. Developments in depth estimation have given rise to large\npre-trained models such as DepthAnything. However, using outputs of these\nmodels for downstream motion generation is challenging due to frustum-shaped\nerrors that arise. Instead, we propose a framework known as Video-Generation\nEnvironment Representation (VGER), which leverages the advances of large-scale\nvideo generation models to generate a moving camera video conditioned on the\ninput image. Frames of this video, which form a multiview dataset, are then\ninput into a pre-trained 3D foundation model to produce a dense point cloud. We\nthen introduce a multi-scale noise approach to train an implicit representation\nof the environment structure and build a motion generation model that complies\nwith the geometry of the representation. We extensively evaluate VGER over a\ndiverse set of indoor and outdoor environments. We demonstrate its ability to\nproduce smooth motions that account for the captured geometry of a scene, all\nfrom a single RGB input image.",
    "pdf_url": "http://arxiv.org/pdf/2505.19306v1",
    "published": "2025-05-25T20:30:25+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19305v2",
    "title": "Leveraging Large Language Models to Contextualize Network Measurements",
    "authors": [
      "Roman Beltiukov",
      "Karthik Bhattaram",
      "Evania Cheng",
      "Vinod Kanigicherla",
      "Akul Singh",
      "Ken Thampiratwong",
      "Arpit Gupta"
    ],
    "abstract": "With the worldwide growth of remote communication and telepresence, network\nmeasurements form a cornerstone of effective performance assessment and\ndiagnostics for Internet users. Most often, users seek for overall connection\nperformance measurement using publicly available tools (also known as `speed\ntests') that provide an overview of their connection's throughput and latency.\nHowever, extracting meaningful insights from these measurements remains a\nchallenging task for a non-technical audience. Interpreting network measurement\ndata often requires considerable domain expertise to account not only for\nsubtle variations of the connection stability and metrics, but even for simpler\nconcepts such as latency under load or packet loss influence towards connection\nperformance. In the absence of proper expertise, common misconceptions can\neasily arise. To address these issues, researchers should recognize the\nimportance of making network measurements not only more comprehensive but also\nmore accessible for wider audience without deep technical knowledge. A\npromising direction to achieve this goal involves leveraging recent\nadvancements in large language models (LLMs), which have demonstrated\ncapabilities in conducting an analysis of complex data in other fields, such as\nlaboratory test results interpretation, news summarization, and personal\nassistance.\n  In this paper, we describe an ongoing effort to apply large language models\nand historical data to enhance the interpretation of network measurements in\nreal-world environments. We aim to automate the translation of low-level metric\ndata into accessible explanations, allowing non-experts to make more informed\ndecisions regarding network performance and reliability.",
    "pdf_url": "http://arxiv.org/pdf/2505.19305v2",
    "published": "2025-05-25T20:28:40+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19304v1",
    "title": "f4ncgb: High Performance Gröbner Basis Computations in Free Algebras",
    "authors": [
      "Maximilian Heisinger",
      "Clemens Hofstadler"
    ],
    "abstract": "We present f4ncgb, a new open-source C++ library for Gr\\\"obner basis\ncomputations in free algebras, which transfers recent advancements in\ncommutative Gr\\\"obner basis software to the noncommutative setting. As our\nexperiments show, f4ncgb establishes a new state-of-the-art for noncommutative\nGr\\\"obner basis computations. We also discuss implementation details and design\nchoices.",
    "pdf_url": "http://arxiv.org/pdf/2505.19304v1",
    "published": "2025-05-25T20:24:22+00:00",
    "categories": [
      "cs.MS",
      "cs.SC"
    ],
    "primary_category": "cs.MS"
  },
  {
    "id": "http://arxiv.org/abs/2505.19303v1",
    "title": "Dynamical Frames and Hyperinvariant Subspaces",
    "authors": [
      "Victor Bailey",
      "Deguang Han",
      "Keri Kornelson",
      "David Larson",
      "Rui Liu"
    ],
    "abstract": "The theory of dynamical frames evolved from practical problems in dynamical\nsampling where the initial state of a vector needs to be recovered from the\nspace-time samples of evolutions of the vector. This leads to the investigation\nof structured frames obtained from the orbits of evolution operators. One of\nthe basic problems in dynamical frame theory is to determine the semigroup\nrepresentations, which we will call central frame representations, whose frame\ngenerators are unique (up to equivalence). Recently, Christensen, Hasannasab,\nand Philipp proved that all frame representations of the semigroup\n$\\Bbb{Z}_{+}$ have this property. Their proof of this result relies on the\ncharacterization of the structure of shift-invariant subspaces in\n$H^2(\\mathbb{D})$ due to Beurling. In this paper we settle the general\nuniqueness problem by presenting a characterization of central frame\nrepresentations for any semigroup in terms of the co-hyperinvariant subspaces\nof the left regular representation of the semigroup. This result is not only\nconsistent with the known result of Han-Larson in 2000 for group representation\nframes, but also proves that all the frame generators of a semigroup generated\nby any $k$-tuple $(A_1, ... A_k)$ of commuting bounded linear operators on a\nseparable Hilbert space $H$ are equivalent, a case where the structure of\nshift-invariant subspaces, or submodules, of the Hardy Space on polydisks\n$H^{2}(\\Bbb{D}^k)$ is still not completely characterized.",
    "pdf_url": "http://arxiv.org/pdf/2505.19303v1",
    "published": "2025-05-25T20:22:36+00:00",
    "categories": [
      "math.FA",
      "46C99, 47A99"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19302v1",
    "title": "ODIN: A NL2SQL Recommender to Handle Schema Ambiguity",
    "authors": [
      "Kapil Vaidya",
      "Abishek Sankararaman",
      "Jialin Ding",
      "Chuan Lei",
      "Xiao Qin",
      "Balakrishnan Narayanaswamy",
      "Tim Kraska"
    ],
    "abstract": "NL2SQL (natural language to SQL) systems translate natural language into SQL\nqueries, allowing users with no technical background to interact with databases\nand create tools like reports or visualizations. While recent advancements in\nlarge language models (LLMs) have significantly improved NL2SQL accuracy,\nschema ambiguity remains a major challenge in enterprise environments with\ncomplex schemas, where multiple tables and columns with semantically similar\nnames often co-exist. To address schema ambiguity, we introduce ODIN, a NL2SQL\nrecommendation engine. Instead of producing a single SQL query given a natural\nlanguage question, ODIN generates a set of potential SQL queries by accounting\nfor different interpretations of ambiguous schema components. ODIN dynamically\nadjusts the number of suggestions based on the level of ambiguity, and ODIN\nlearns from user feedback to personalize future SQL query recommendations. Our\nevaluation shows that ODIN improves the likelihood of generating the correct\nSQL query by 1.5-2$\\times$ compared to baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.19302v1",
    "published": "2025-05-25T20:22:32+00:00",
    "categories": [
      "cs.DB",
      "cs.CL"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.19301v2",
    "title": "A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized Authentication and Fine-Grained Access Control",
    "authors": [
      "Ken Huang",
      "Vineeth Sai Narajala",
      "John Yeoh",
      "Jason Ross",
      "Ramesh Raskar",
      "Youssef Harkati",
      "Jerry Huang",
      "Idan Habler",
      "Chris Hughes"
    ],
    "abstract": "Traditional Identity and Access Management (IAM) systems, primarily designed\nfor human users or static machine identities via protocols such as OAuth,\nOpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the\ndynamic, interdependent, and often ephemeral nature of AI agents operating at\nscale within Multi Agent Systems (MAS), a computational system composed of\nmultiple interacting intelligent agents that work collectively.\n  This paper posits the imperative for a novel Agentic AI IAM framework: We\ndeconstruct the limitations of existing protocols when applied to MAS,\nillustrating with concrete examples why their coarse-grained controls,\nsingle-entity focus, and lack of context-awareness falter. We then propose a\ncomprehensive framework built upon rich, verifiable Agent Identities (IDs),\nleveraging Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs),\nthat encapsulate an agents capabilities, provenance, behavioral scope, and\nsecurity posture.\n  Our framework includes an Agent Naming Service (ANS) for secure and\ncapability-aware discovery, dynamic fine-grained access control mechanisms, and\ncritically, a unified global session management and policy enforcement layer\nfor real-time control and consistent revocation across heterogeneous agent\ncommunication protocols. We also explore how Zero-Knowledge Proofs (ZKPs)\nenable privacy-preserving attribute disclosure and verifiable policy\ncompliance.\n  We outline the architecture, operational lifecycle, innovative contributions,\nand security considerations of this new IAM paradigm, aiming to establish the\nfoundational trust, accountability, and security necessary for the burgeoning\nfield of agentic AI and the complex ecosystems they will inhabit.",
    "pdf_url": "http://arxiv.org/pdf/2505.19301v2",
    "published": "2025-05-25T20:21:55+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19300v1",
    "title": "SituatedThinker: Grounding LLM Reasoning with Real-World through Situated Thinking",
    "authors": [
      "Junnan Liu",
      "Linhao Luo",
      "Thuy-Trang Vu",
      "Gholamreza Haffari"
    ],
    "abstract": "Recent advances in large language models (LLMs) demonstrate their impressive\nreasoning capabilities. However, the reasoning confined to internal parametric\nspace limits LLMs' access to real-time information and understanding of the\nphysical world. To overcome this constraint, we introduce SituatedThinker, a\nnovel framework that enables LLMs to ground their reasoning in real-world\ncontexts through situated thinking, which adaptively combines both internal\nknowledge and external information with predefined interfaces. By utilizing\nreinforcement learning, SituatedThinker incentivizes deliberate reasoning with\nthe real world to acquire information and feedback, allowing LLMs to surpass\ntheir knowledge boundaries and enhance reasoning. Experimental results\ndemonstrate significant performance improvements on multi-hop\nquestion-answering and mathematical reasoning benchmarks. Furthermore,\nSituatedThinker demonstrates strong performance on unseen tasks, such as KBQA,\nTableQA, and text-based games, showcasing the generalizable real-world grounded\nreasoning capability. Our codes are available at\nhttps://github.com/jnanliu/SituatedThinker.",
    "pdf_url": "http://arxiv.org/pdf/2505.19300v1",
    "published": "2025-05-25T20:20:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19299v1",
    "title": "A Necessary Step toward Faithfulness: Measuring and Improving Consistency in Free-Text Explanations",
    "authors": [
      "Lingjun Zhao",
      "Hal Daumé III"
    ],
    "abstract": "Faithful free-text explanations are important to ensure transparency in\nhigh-stakes AI decision-making contexts, but they are challenging to generate\nby language models and assess by humans. In this paper, we present a measure\nfor Prediction-EXplanation (PEX) consistency, by extending the concept of\nweight of evidence. This measure quantifies how much a free-text explanation\nsupports or opposes a prediction, serving as an important aspect of explanation\nfaithfulness. Our analysis reveals that more than 62% explanations generated by\nlarge language models lack this consistency. We show that applying direct\npreference optimization improves the consistency of generated explanations\nacross three model families, with improvement ranging from 43.1% to 292.3%.\nFurthermore, we demonstrate that optimizing this consistency measure can\nimprove explanation faithfulness by up to 9.7%.",
    "pdf_url": "http://arxiv.org/pdf/2505.19299v1",
    "published": "2025-05-25T20:18:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19298v1",
    "title": "Market Clearing with Semi-fungible Assets",
    "authors": [
      "Theo Diamandis",
      "Tarun Chitra",
      "Guillermo Angeris"
    ],
    "abstract": "As markets have digitized, the number of tradable products has skyrocketed.\nAlgorithmically constructed portfolios of these assets now dominate public and\nprivate markets, resulting in a combinatorial explosion of tradable assets. In\nthis paper, we provide a simple means to compute market clearing prices for\nsemi-fungible assets which have a partial ordering between them. Such assets\nare increasingly found in traditional markets (bonds, commodities, ETFs),\nprivate markets (private credit, compute markets), and in decentralized\nfinance. We formulate the market clearing problem as an optimization problem\nover a directed acyclic graph that represents participant preferences.\nSubsequently, we use convex duality to efficiently estimate market clearing\nprices, which correspond to particular dual variables. We then describe\ndominant strategy incentive compatible payment and allocation rules for\nclearing these markets. We conclude with examples of how this framework can\nconstruct prices for a variety of algorithmically constructed, semi-fungible\nportfolios of practical importance.",
    "pdf_url": "http://arxiv.org/pdf/2505.19298v1",
    "published": "2025-05-25T20:12:04+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19297v1",
    "title": "Alchemist: Turning Public Text-to-Image Data into Generative Gold",
    "authors": [
      "Valerii Startsev",
      "Alexander Ustyuzhanin",
      "Alexey Kirillov",
      "Dmitry Baranchuk",
      "Sergey Kastryulin"
    ],
    "abstract": "Pre-training equips text-to-image (T2I) models with broad world knowledge,\nbut this alone is often insufficient to achieve high aesthetic quality and\nalignment. Consequently, supervised fine-tuning (SFT) is crucial for further\nrefinement. However, its effectiveness highly depends on the quality of the\nfine-tuning dataset. Existing public SFT datasets frequently target narrow\ndomains (e.g., anime or specific art styles), and the creation of high-quality,\ngeneral-purpose SFT datasets remains a significant challenge. Current curation\nmethods are often costly and struggle to identify truly impactful samples. This\nchallenge is further complicated by the scarcity of public general-purpose\ndatasets, as leading models often rely on large, proprietary, and poorly\ndocumented internal data, hindering broader research progress. This paper\nintroduces a novel methodology for creating general-purpose SFT datasets by\nleveraging a pre-trained generative model as an estimator of high-impact\ntraining samples. We apply this methodology to construct and release Alchemist,\na compact (3,350 samples) yet highly effective SFT dataset. Experiments\ndemonstrate that Alchemist substantially improves the generative quality of\nfive public T2I models while preserving diversity and style. Additionally, we\nrelease the fine-tuned models' weights to the public.",
    "pdf_url": "http://arxiv.org/pdf/2505.19297v1",
    "published": "2025-05-25T20:08:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19296v1",
    "title": "Exploring Self-Organized Criticality through Memory-Driven Random Walks on Complex Networks",
    "authors": [
      "Mohammad Jafari"
    ],
    "abstract": "We present a stochastic model of memory-driven random walks on complex\nnetworks, where a single walker explores the network through a combination of\nlocal random walks and memory-based resetting. The walker either moves to a\nneighboring node or resets to a previously visited node with a probability\nproportional to the visitation history.Each node in the network accumulates\nstress with every visit, and once the accumulated stress exceeds a threshold,\nthe node topples, redistributing the stress to its neighbors. This\nredistribution can trigger cascading avalanches across the network. We\ndemonstrate that this simple memory-driven mechanism, combined with local\nstress dynamics, leads to the emergence of self-organized criticality (SOC)\nacross various network topologies, including Small-World and BA networks.The\nresulting avalanche size distributions follow power-law statistics, with\nexponents that are consistent with those found in classical SOC systems. Our\nmodel requires no fine-tuning of parameters to achieve criticality and offers a\nnovel insight into how memory, network structure, and local stress interactions\ncan give rise to emergent critical phenomena. These findings have implications\nfor understanding cascading failures in infrastructure, neural avalanches in\nbrain dynamics, and information spread in complex networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19296v1",
    "published": "2025-05-25T20:06:26+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.19295v3",
    "title": "On Isotropy Groups of Quantum Plane",
    "authors": [
      "Adriano De Santana",
      "Rene Baltazar",
      "Robson Vinciguerra",
      "Wilian De Araujo"
    ],
    "abstract": "This paper investigates the isotropy groups of derivations on the Quantum\nPlane $\\Bbbk_q[x, y]$, defined by the relation $yx = qxy$, where $q \\in\n\\Bbbk^*$, with $q^2\\neq 1$. The main goal is to determine the automorphisms of\nthe Quantum Plane that commutes with a fixed derivation $\\delta$. We describe\nconditions under which the isotropy group $\\text{Aut}_\\delta(A)$ is trivial,\nfinite, or infinite, depending on the structure of $\\delta$ and whether $q$ is\na root of unity: additionally, we present the structure of the group in the\nfinite case. A key tool is the analysis of polynomial equations of the form\n$\\mu_1^a \\mu_2^b = 1$, arising from monomials in the inner part of $\\delta$. We\nalso make explicit which finite subgroups of $Aut(\\Bbbk_q[x, y])$ are isotropy\ngroups of some derivation: either $q$ root of unity or not. Techniques from\nalgebraic geometry, such as intersection multiplicity, are also employed in the\nclassification of the finite case.",
    "pdf_url": "http://arxiv.org/pdf/2505.19295v3",
    "published": "2025-05-25T20:05:11+00:00",
    "categories": [
      "math.RA"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19294v1",
    "title": "Towards Reliable Large Audio Language Model",
    "authors": [
      "Ziyang Ma",
      "Xiquan Li",
      "Yakun Song",
      "Wenxi Chen",
      "Chenpeng Du",
      "Jian Wu",
      "Yuanzhe Chen",
      "Zhuo Chen",
      "Yuping Wang",
      "Yuxuan Wang",
      "Xie Chen"
    ],
    "abstract": "Recent advancements in large audio language models (LALMs) have demonstrated\nimpressive results and promising prospects in universal understanding and\nreasoning across speech, music, and general sound. However, these models still\nlack the ability to recognize their knowledge boundaries and refuse to answer\nquestions they don't know proactively. While there have been successful\nattempts to enhance the reliability of LLMs, reliable LALMs remain largely\nunexplored. In this paper, we systematically investigate various approaches\ntowards reliable LALMs, including training-free methods such as multi-modal\nchain-of-thought (MCoT), and training-based methods such as supervised\nfine-tuning (SFT). Besides, we identify the limitations of previous evaluation\nmetrics and propose a new metric, the Reliability Gain Index (RGI), to assess\nthe effectiveness of different reliable methods. Our findings suggest that both\ntraining-free and training-based methods enhance the reliability of LALMs to\ndifferent extents. Moreover, we find that awareness of reliability is a \"meta\nability\", which can be transferred across different audio modalities, although\nsignificant structural and content differences exist among sound, music, and\nspeech.",
    "pdf_url": "http://arxiv.org/pdf/2505.19294v1",
    "published": "2025-05-25T20:00:31+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "cs.HC",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.19293v1",
    "title": "100-LongBench: Are de facto Long-Context Benchmarks Literally Evaluating Long-Context Ability?",
    "authors": [
      "Wang Yang",
      "Hongye Jin",
      "Shaochen Zhong",
      "Song Jiang",
      "Qifan Wang",
      "Vipin Chaudhary",
      "Xiaotian Han"
    ],
    "abstract": "Long-context capability is considered one of the most important abilities of\nLLMs, as a truly long context-capable LLM enables users to effortlessly process\nmany originally exhausting tasks -- e.g., digesting a long-form document to\nfind answers vs. directly asking an LLM about it. However, existing\nreal-task-based long-context evaluation benchmarks have two major shortcomings.\nFirst, benchmarks like LongBench often do not provide proper metrics to\nseparate long-context performance from the model's baseline ability, making\ncross-model comparison unclear. Second, such benchmarks are usually constructed\nwith fixed input lengths, which limits their applicability across different\nmodels and fails to reveal when a model begins to break down. To address these\nissues, we introduce a length-controllable long-context benchmark and a novel\nmetric that disentangles baseline knowledge from true long-context\ncapabilities. Experiments demonstrate the superiority of our approach in\neffectively evaluating LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.19293v1",
    "published": "2025-05-25T19:58:31+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19292v2",
    "title": "A likelihood-based Bayesian inference framework for the calibration of and selection between stochastic velocity-jump models",
    "authors": [
      "Arianna Ceccarelli",
      "Alexander P. Browning",
      "Tai Chaiamarit",
      "Ilan Davis",
      "Ruth E. Baker"
    ],
    "abstract": "Advances in experimental techniques allow the collection of high-resolution\nspatio-temporal data that track individual motile entities. These tracking data\ncan be used to calibrate mathematical models describing the motility of\nindividual entities. The challenges in calibrating models for single-agent\nmotion derive from the intrinsic characteristics of experimental data,\ncollected at discrete time steps and with measurement noise. We consider motion\nof individual agents that can be described by velocity-jump models in one\nspatial dimension. These agents transition between a network of \\textit{n}\nstates, in which each state is associated with a fixed velocity and fixed rates\nof switching to every other state. Exploiting approximate solutions to the\nresultant stochastic process, we develop a Bayesian inference framework to\ncalibrate these models to discrete-time noisy data. We first demonstrate that\nthe framework can be used to effectively recover the model parameters of data\nsimulated from two-state and three-state models. Finally, we explore the\nquestion of model selection first using simulated data and then using\nexperimental data tracking mRNA transport inside \\textit{Drosophila} neurons.\nOverall, our results demonstrate that the framework is effective and efficient\nin calibrating and selecting between velocity-jump models and it can be applied\nto a range of motion processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.19292v2",
    "published": "2025-05-25T19:54:37+00:00",
    "categories": [
      "stat.ME",
      "q-bio.QM"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.19291v2",
    "title": "TextDiffuser-RL: Efficient and Robust Text Layout Optimization for High-Fidelity Text-to-Image Synthesis",
    "authors": [
      "Kazi Mahathir Rahman",
      "Showrin Rahman",
      "Sharmin Sultana Srishty"
    ],
    "abstract": "Text-embedded image generation plays a critical role in industries such as\ngraphic design, advertising, and digital content creation. Text-to-Image\ngeneration methods leveraging diffusion models, such as TextDiffuser-2, have\ndemonstrated promising results in producing images with embedded text.\nTextDiffuser-2 effectively generates bounding box layouts that guide the\nrendering of visual text, achieving high fidelity and coherence. However,\nexisting approaches often rely on resource-intensive processes and are limited\nin their ability to run efficiently on both CPU and GPU platforms. To address\nthese challenges, we propose a novel two-stage pipeline that integrates\nreinforcement learning (RL) for rapid and optimized text layout generation with\na diffusion-based image synthesis model. Our RL-based approach significantly\naccelerates the bounding box prediction step while reducing overlaps, allowing\nthe system to run efficiently on both CPUs and GPUs. Extensive evaluations\ndemonstrate that our framework maintains or surpasses TextDiffuser-2's quality\nin text placement and image synthesis, with markedly faster runtime and\nincreased flexibility. Extensive evaluations demonstrate that our framework\nmaintains or surpasses TextDiffuser-2's quality in text placement and image\nsynthesis, with markedly faster runtime and increased flexibility. Our approach\nhas been evaluated on the MARIOEval benchmark, achieving OCR and CLIPScore\nmetrics close to state-of-the-art models, while being 97.64% more faster and\nrequiring only 2MB of memory to run.",
    "pdf_url": "http://arxiv.org/pdf/2505.19291v2",
    "published": "2025-05-25T19:52:04+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19290v1",
    "title": "Evaluation and Performance Analysis of the Ryu Controller in Various Network Scenarios",
    "authors": [
      "Ahmadreza Montazerolghaem",
      "Somaye Imanpour"
    ],
    "abstract": "Software-defined networking (SDN) represents a revolutionary shift in network\ntechnology by decoupling the data plane from the control plane.}In this\narchitecture, all network decision-making processes are centralized in a\ncontroller, meaning each switch receives routing information from the\ncontroller and forwards network packets accordingly. This clearly highlights\nthe crucial role that controllers play in the overall performance of SDN. Ryu\nis one of the most widely used SDN controllers, known for its ease of use in\nresearch due to its support for Python programming. This makes Ryu a suitable\noption for experimental and academic studies. In this research, we evaluate the\nperformance of the Ryu controller based on various network metrics and across\ndifferent network topologies. For experimental analysis, we use Mininet, a\npowerful network emulation tool that enables the creation of diverse network\nstructures and the connection of switches to controllers. To facilitate the\nexperiments, we developed a Python-based script that executes various network\nscenarios, connects to different controllers, and captures and stores the\nresults. This study not only provides a comprehensive performance evaluation of\nthe Ryu controller but also paves the way for evaluating other SDN controllers\nin future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.19290v1",
    "published": "2025-05-25T19:51:08+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19289v1",
    "title": "Some remarks on Campanato Theorem and the Anisotropic Bessel Spaces",
    "authors": [
      "H. Hajaiej",
      "R. Leitao"
    ],
    "abstract": "In this paper, we establish an anisotropic version of Campanato Theorem and\nshow that the anisotropic Bessel spaces are continuously embedded in the spaces\nof Holder continuous functions. As an application of this embedding, we build\nfundamental solutions for a class of anisotropic fractional Laplacian\noperators.",
    "pdf_url": "http://arxiv.org/pdf/2505.19289v1",
    "published": "2025-05-25T19:49:05+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19288v2",
    "title": "Hypercube-Based Retrieval-Augmented Generation for Scientific Question-Answering",
    "authors": [
      "Jimeng Shi",
      "Sizhe Zhou",
      "Bowen Jin",
      "Wei Hu",
      "Runchu Tian",
      "Shaowen Wang",
      "Giri Narasimhan",
      "Jiawei Han"
    ],
    "abstract": "Large language models (LLMs) often need to incorporate external knowledge to\nsolve theme-specific problems. Retrieval-augmented generation (RAG) has shown\nits high promise, empowering LLMs to generate more qualified responses with\nretrieved external data and knowledge. However, most RAG methods retrieve\nrelevant documents based on either sparse or dense retrieval methods or their\ncombinations, which overlooks the essential, multi-dimensional, and structured\nsemantic information present in documents. This structured information plays a\ncritical role in finding concise yet highly relevant information for domain\nknowledge-intensive tasks, such as scientific question-answering (QA). In this\nwork, we introduce a multi-dimensional (cube) structure, Hypercube, which can\nindex and allocate documents in a pre-defined multi-dimensional space. Built on\nthe hypercube, we further propose Hypercube-RAG, a novel RAG framework for\nprecise and efficient retrieval. Given a query, Hypercube-RAG first decomposes\nit based on its entities, phrases, and topics along with pre-defined hypercube\ndimensions, and then retrieves relevant documents from cubes by aligning these\ndecomposed components with corresponding dimensions. Experiments on three\ndatasets across different domains demonstrate that our method improves response\naccuracy by 3.7% and retrieval accuracy by 5.3% over the strongest RAG\nbaseline. It also boosts retrieval efficiency (speed) by one or two magnitudes\nfaster than graph-based RAG. Notably, our Hypercube-RAG inherently offers\nexplainability by revealing those underlying dimensions used for retrieval. The\ncode and data are available at https://github.com/JimengShi/Hypercube-RAG.",
    "pdf_url": "http://arxiv.org/pdf/2505.19288v2",
    "published": "2025-05-25T19:42:06+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19287v1",
    "title": "svc: An R package for Spatially Varying Coefficient Models",
    "authors": [
      "Justice Akuoko-Frimpong",
      "Edward Shao",
      "Jonathan Ta"
    ],
    "abstract": "Traditional regression models assume stationary relationships between\npredictors and responses, failing to capture the spatial heterogeneity present\nin many environmental, epidemiological, and ecological processes. To address\nthis limitation, we develop a scalable Bayesian framework for spatially varying\ncoefficient (SVC) models, implemented in the \\pkg{svc} R package (available at\nhttps://github.com/jdta95/svc), which allows regression coefficients to vary\nsmoothly over space. Our approach combines three key computational innovations:\n(1) a subset Gaussian process approximation that reduces the computational\nburden from $O(n^3)$ to $O(m^3)$ with $m<n$, while maintaining predictive\naccuracy; (2) a robust adaptive Metropolis (RAM) algorithm that automatically\ntunes proposal distributions for efficient MCMC sampling of spatial range\nparameters; and (3) optimized linear algebra operations leveraging precomputed\ndistance matrices and Cholesky decompositions to accelerate covariance\ncalculations. We present the model's theoretical foundation, prior\nspecification, and Gibbs sampling algorithm, with a focus on practical\nimplementation for large spatial datasets. Simulation studies demonstrate that\nour method outperforms existing approaches in computational efficiency while\nmaintaining competitive estimation accuracy. We illustrate its application in\nan analysis of land surface temperature (LST) data, revealing spatially varying\neffects of vegetation and emissivity that would be obscured by traditional\nregression techniques. The \\pkg{svc} package provides researchers with a\nflexible, efficient tool for uncovering and quantifying nonstationary spatial\nrelationships across diverse scientific domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.19287v1",
    "published": "2025-05-25T19:39:18+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.19286v2",
    "title": "A Graph Perspective to Probe Structural Patterns of Knowledge in Large Language Models",
    "authors": [
      "Utkarsh Sahu",
      "Zhisheng Qi",
      "Yongjia Lei",
      "Ryan A. Rossi",
      "Franck Dernoncourt",
      "Nesreen K. Ahmed",
      "Mahantesh M Halappanavar",
      "Yao Ma",
      "Yu Wang"
    ],
    "abstract": "Large language models have been extensively studied as neural knowledge bases\nfor their knowledge access, editability, reasoning, and explainability.\nHowever, few works focus on the structural patterns of their knowledge.\nMotivated by this gap, we investigate these structural patterns from a graph\nperspective. We quantify the knowledge of LLMs at both the triplet and entity\nlevels, and analyze how it relates to graph structural properties such as node\ndegree. Furthermore, we uncover the knowledge homophily, where topologically\nclose entities exhibit similar levels of knowledgeability, which further\nmotivates us to develop graph machine learning models to estimate entity\nknowledge based on its local neighbors. This model further enables valuable\nknowledge checking by selecting triplets less known to LLMs. Empirical results\nshow that using selected triplets for fine-tuning leads to superior\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2505.19286v2",
    "published": "2025-05-25T19:34:15+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19285v1",
    "title": "A comparison problem for abelian surfaces and descent for symplectic orbital integrals",
    "authors": [
      "Thomas Rüd"
    ],
    "abstract": "To answer a question about the distribution of products of elliptic curves in\nisogeny classes of abelian surfaces defined over finite fields, we compute\nspecific orbital integrals in the group $\\mathrm{GSp}_4$. More precisely, we\ncompute integrals over the orbits of elements in the subgroup\n$\\mathrm{GL}_2\\times_{\\det} \\mathrm{GL}_2$. As a first step towards a complete\nsolution of the problem, this article contains explicit computations for\narbitrary orbital integrals of spherical functions over this subgroup, and also\ncompute orbital integrals over $\\mathrm{GSp}_4$ in a large number of cases.",
    "pdf_url": "http://arxiv.org/pdf/2505.19285v1",
    "published": "2025-05-25T19:32:05+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19284v1",
    "title": "RankLLM: A Python Package for Reranking with LLMs",
    "authors": [
      "Sahel Sharifymoghaddam",
      "Ronak Pradeep",
      "Andre Slavescu",
      "Ryan Nguyen",
      "Andrew Xu",
      "Zijian Chen",
      "Yilin Zhang",
      "Yidi Chen",
      "Jasper Xian",
      "Jimmy Lin"
    ],
    "abstract": "The adoption of large language models (LLMs) as rerankers in multi-stage\nretrieval systems has gained significant traction in academia and industry.\nThese models refine a candidate list of retrieved documents, often through\ncarefully designed prompts, and are typically used in applications built on\nretrieval-augmented generation (RAG). This paper introduces RankLLM, an\nopen-source Python package for reranking that is modular, highly configurable,\nand supports both proprietary and open-source LLMs in customized reranking\nworkflows. To improve usability, RankLLM features optional integration with\nPyserini for retrieval and provides integrated evaluation for multi-stage\npipelines. Additionally, RankLLM includes a module for detailed analysis of\ninput prompts and LLM responses, addressing reliability concerns with LLM APIs\nand non-deterministic behavior in Mixture-of-Experts (MoE) models. This paper\npresents the architecture of RankLLM, along with a detailed step-by-step guide\nand sample code. We reproduce results from RankGPT, LRL, RankVicuna,\nRankZephyr, and other recent models. RankLLM integrates with common inference\nframeworks and a wide range of LLMs. This compatibility allows for quick\nreproduction of reported results, helping to speed up both research and\nreal-world applications. The complete repository is available at rankllm.ai,\nand the package can be installed via PyPI.",
    "pdf_url": "http://arxiv.org/pdf/2505.19284v1",
    "published": "2025-05-25T19:29:27+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19283v1",
    "title": "BSAGIoT: A Bayesian Security Aspect Graph for Internet of Things (IoT)",
    "authors": [
      "Zeinab Lashkaripour",
      "Masoud Khosravi-Farmad",
      "AhmadReza Montazerolghaem",
      "Razieh Rezaee"
    ],
    "abstract": "IoT is a dynamic network of interconnected things that communicate and\nexchange data, where security is a significant issue. Previous studies have\nmainly focused on attack classifications and open issues rather than presenting\na comprehensive overview on the existing threats and vulnerabilities. This\nknowledge helps analyzing the network in the early stages even before any\nattack takes place. In this paper, the researchers have proposed different\nsecurity aspects and a novel Bayesian Security Aspects Dependency Graph for IoT\n(BSAGIoT) to illustrate their relations. The proposed BSAGIoT is a generic\nmodel applicable to any IoT network and contains aspects from five categories\nnamed data, access control, standard, network, and loss. This proposed Bayesian\nSecurity Aspect Graph (BSAG) presents an overview of the security aspects in\nany given IoT network. The purpose of BSAGIoT is to assist security experts in\nanalyzing how a successful compromise and/or a failed breach could impact the\noverall security and privacy of the respective IoT network. In addition, root\ncause identification of security challenges, how they affect one another, their\nimpact on IoT networks via topological sorting, and risk assessment could be\nachieved. Hence, to demonstrate the feasibility of the proposed method,\nexperimental results with various scenarios has been presented, in which the\nsecurity aspects have been quantified based on the network configurations. The\nresults indicate the impact of the aspects on each other and how they could be\nutilized to mitigate and/or eliminate the security and privacy deficiencies in\nIoT networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19283v1",
    "published": "2025-05-25T19:27:56+00:00",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19282v1",
    "title": "Rapid Development of Efficient Participant-Specific Computational Models of the Wrist",
    "authors": [
      "Thor E. Andreassen",
      "Taylor P. Trentadue",
      "Andrew R. Thoreson",
      "Kai-Nan An",
      "Sanjeev Kakar",
      "Kristin D. Zhao"
    ],
    "abstract": "While computational modeling may help to develop new treatment options for\nhand and wrist injuries, at present, few models exist. The time and expertise\nrequired to develop and use these models is considerable. Moreover, most do not\nallow for variation of material properties, instead relying on literature\nreported averages. We have developed a novel automated workflow combining\nnon-linear morphing techniques with various algorithmic techniques to create\nparticipant-specific finite element models. Using this workflow, three\nparticipant-specific models were created from our existing four-dimensional\ncomputed tomography (4DCT) data. These were then used to perform two analyses\nto demonstrate the usefulness of the models to investigate clinical questions,\nnamely optimization of ligament properties to participant-specific kinematics,\nand Monte Carlo (MC) analysis of the impacts of ligament injury on joint\ncontact pressure, as an analogue for joint injury that may lead to\nosteoarthritis. Participant-specific models can be created in 2 hours and\nindividual simulations performed in 45 seconds. This work lays the groundwork\nfor future patient-specific modeling of the hand and wrist.",
    "pdf_url": "http://arxiv.org/pdf/2505.19282v1",
    "published": "2025-05-25T19:26:00+00:00",
    "categories": [
      "q-bio.QM",
      "cs.CE",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.19281v1",
    "title": "A Snapshot of Influence: A Local Data Attribution Framework for Online Reinforcement Learning",
    "authors": [
      "Yuzheng Hu",
      "Fan Wu",
      "Haotian Ye",
      "David Forsyth",
      "James Zou",
      "Nan Jiang",
      "Jiaqi W. Ma",
      "Han Zhao"
    ],
    "abstract": "Online reinforcement learning (RL) excels in complex, safety-critical\ndomains, yet it faces challenges such as sample inefficiency, training\ninstability, and a lack of interpretability. Data attribution offers a\nprincipled way to trace model behavior back to individual training samples.\nHowever, in online RL, each training sample not only drives policy updates but\nalso influences future data collection, violating the fixed dataset assumption\nin existing attribution methods. In this paper, we initiate the study of data\nattribution for online RL, focusing on the widely used Proximal Policy\nOptimization (PPO) algorithm. We start by establishing a local attribution\nframework, interpreting model checkpoints with respect to the records in the\nrecent training buffer. We design two target functions, capturing agent action\nand cumulative return respectively, and measure each record's contribution\nthrough gradient similarity between its training loss and these targets. We\ndemonstrate the power of this framework through three concrete applications:\ndiagnosis of learning, temporal analysis of behavior formation, and targeted\nintervention during training. Leveraging this framework, we further propose an\nalgorithm, iterative influence-based filtering (IIF), for online RL training\nthat iteratively performs experience filtering to refine policy updates. Across\nstandard RL benchmarks (classic control, navigation, locomotion) to RLHF for\nlarge language models, IIF reduces sample complexity, speeds up training, and\nachieves higher returns. Overall, these results advance interpretability,\nefficiency, and effectiveness of online RL.",
    "pdf_url": "http://arxiv.org/pdf/2505.19281v1",
    "published": "2025-05-25T19:25:57+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19280v1",
    "title": "C-BerryANC: A first-principle C++ code to calculate Berry Curvature dependent anomalous Nernst conductivity in any material",
    "authors": [
      "Vivek Pandey",
      "Sudhir K. Pandey"
    ],
    "abstract": "The anomalous Nernst conductivity (ANC) is a key transport property in\nmagnetic and topological materials, arising from the Berry curvature\n($\\boldsymbol\\Omega$) of electronic bands. It offers deep insight into the\nunderlying topology and thermoelectric behavior. While Wannier interpolation\nhave become popular for calculating ANC due to their computational efficiency,\ntheir accuracy critically depends on the quality of the Wannierization, which\ncan be challenging for entangled bands or materials with complex band\ncrossings. These limitations highlight the need for a direct first-principles\napproach to reliably compute ANC from ab-initio electronic structures. Here, we\npresent a C++ based code named C-BerryANC that calculates\n$\\boldsymbol\\Omega$-dependent ANC by directly using the eigenvalues and\nmomentum-matrices obtained from DFT calculations. Presently, the code is\ninterfaced with WIEN2k package which uses all-electron approach and\nfull-potential linearized augmented plane wave (FP-LAPW) based method. For\nefficiently handling dense k-mesh, calculation of $\\boldsymbol\\Omega$ is made\nparallel over k-points using the OpenMP method. Additionally, the code stores\nband-resolved components of $\\boldsymbol\\Omega$ in binary files thereby\nreducing the memory occupancy and providing fast post-process option to compute\nANC for any range of chemical potential and temperature values. Also, as\ncompilation of C++ modules produce executable files which are in machine level\nlanguage, computational speed of C-BerryANC is very fast. The code is\nbenchmarked over some well-known materials exhibiting ANC. These includes- Pd,\nFe$_3$Al & Co$_2$FeAl. The obtained values of ANC is found to in good agreement\nwith the previously reported data. This highlights the accuracy, efficieny and\nreliability of the C-BerryANC code.",
    "pdf_url": "http://arxiv.org/pdf/2505.19280v1",
    "published": "2025-05-25T19:24:45+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.19279v1",
    "title": "First Demonstration of Resonant Pitch-Angle Scattering of Relativistic Electrons by Externally-Launched Helicon Waves",
    "authors": [
      "H. Choudhury",
      "A. Battey",
      "C. Paz-Soldan",
      "J. Lestz",
      "N. Leuthold",
      "A. Lvovskiy",
      "C. Marini",
      "J. Barr",
      "W. Heidbrink",
      "D. Spong",
      "S. Tang",
      "B. Van Compernolle",
      "Q. Zhang",
      "Y. Zhang",
      "X. Tang"
    ],
    "abstract": "Helicon waves satisfying the normal wave-particle cyclotron resonance are\nobserved to limit the growth and maximum energy of relativistic electrons (REs)\nin low-density Ohmic DIII-D tokamak plasmas. Following the application of\nhelicon waves, pitch-angle scattering of high-energy REs causes an increase in\nboth synchrotron and electron-cyclotron emissions. The hard x-ray emission, a\nproxy for the RE population, ceases to grow; and energy-resolved hard x-ray\nmeasurements also show a striking decrease in the number of high-energy REs\n(above the resonance at approximately \\SI{8}{MeV}) to below the noise floor.\nThis occurs despite the toroidal electric field remaining high enough to drive\nexponential RE growth in the absence of helicon waves. These results open new\ndirections for limiting the maximum energy of RE populations in laboratory and\nfusion plasmas.",
    "pdf_url": "http://arxiv.org/pdf/2505.19279v1",
    "published": "2025-05-25T19:22:32+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19278v1",
    "title": "Moment Relaxations for Data-Driven Wasserstein Distributionally Robust Optimization",
    "authors": [
      "Shixuan Zhang",
      "Suhan Zhong"
    ],
    "abstract": "We propose moment relaxations for data-driven Wasserstein distributionally\nrobust optimization problems. Conditions are identified to ensure asymptotic\nconsistency of such relaxations for both single-stage and two-stage problems,\ntogether with examples that illustrate their necessity. Numerical experiments\nare also included to illustrate the proposed relaxations.",
    "pdf_url": "http://arxiv.org/pdf/2505.19278v1",
    "published": "2025-05-25T19:20:41+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19277v1",
    "title": "Next Token Prediction Is a Dead End for Creativity",
    "authors": [
      "Ibukun Olatunji",
      "Mark Sheppard"
    ],
    "abstract": "This paper argues that token prediction is fundamentally misaligned with real\ncreativity. While next-token models have enabled impressive advances in\nlanguage generation, their architecture favours surface-level coherence over\nspontaneity, originality, and improvisational risk. We use battle rap as a case\nstudy to expose the limitations of predictive systems, demonstrating that they\ncannot truly engage in adversarial or emotionally resonant exchanges. By\nreframing creativity as an interactive process rather than a predictive output,\nwe offer a vision for AI systems that are more expressive, responsive, and\naligned with human creative practice.",
    "pdf_url": "http://arxiv.org/pdf/2505.19277v1",
    "published": "2025-05-25T19:18:11+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "J.5; I.2.0; I.2.7"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19276v1",
    "title": "A General Theory of Risk Sharing",
    "authors": [
      "Vasily Melnikov"
    ],
    "abstract": "We introduce a new paradigm for risk sharing that generalizes earlier models\nbased on discrete agents and extends them to allow for sharing risk within a\ncontinuum of agents. Agents are represented by points of a measure space and\nhave potentially heterogeneous risk preferences modeled by risk measures. The\nexistence of risk minimizing allocations is proved when constrained to satisfy\neconomically convincing conditions. In the unconstrained case, we derive the\ndual representation of the value function using a Strassen-type theorem for the\nweak-star topology. These results are illustrated by explicit formulas when\nrisk preferences are within the family of entropic and expected shortfall risk\nmeasures.",
    "pdf_url": "http://arxiv.org/pdf/2505.19276v1",
    "published": "2025-05-25T19:17:53+00:00",
    "categories": [
      "q-fin.RM",
      "econ.TH",
      "q-fin.MF",
      "91B05, 91G70"
    ],
    "primary_category": "q-fin.RM"
  },
  {
    "id": "http://arxiv.org/abs/2505.19275v3",
    "title": "Agentic Information Theory: Ergodicity and Intrinsic Semantics of Information Processes",
    "authors": [
      "James P. Crutchfield",
      "Alexandra Jurgens"
    ],
    "abstract": "We develop information theory for the temporal behavior of memoryful agents\nmoving through complex -- structured, stochastic -- environments. We introduce\nand explore information processes -- stochastic processes produced by cognitive\nagents in real-time as they interact with and interpret incoming stimuli. We\nprovide basic results on the ergodicity and semantics of the resulting time\nseries of Shannon information measures that monitor an agent's adapting view of\nuncertainty and structural correlation in its environment.",
    "pdf_url": "http://arxiv.org/pdf/2505.19275v3",
    "published": "2025-05-25T19:12:05+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cs.IT",
      "cs.MA",
      "math.IT",
      "nlin.AO"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.19274v1",
    "title": "Conventional Contrastive Learning Often Falls Short: Improving Dense Retrieval with Cross-Encoder Listwise Distillation and Synthetic Data",
    "authors": [
      "Manveer Singh Tamber",
      "Suleman Kazi",
      "Vivek Sourabh",
      "Jimmy Lin"
    ],
    "abstract": "We investigate improving the retrieval effectiveness of embedding models\nthrough the lens of corpus-specific fine-tuning. Prior work has shown that\nfine-tuning with queries generated using a dataset's retrieval corpus can boost\nretrieval effectiveness for the dataset. However, we find that surprisingly,\nfine-tuning using the conventional InfoNCE contrastive loss often reduces\neffectiveness in state-of-the-art models. To overcome this, we revisit\ncross-encoder listwise distillation and demonstrate that, unlike using\ncontrastive learning alone, listwise distillation can help more consistently\nimprove retrieval effectiveness across multiple datasets. Additionally, we show\nthat synthesizing more training data using diverse query types (such as claims,\nkeywords, and questions) yields greater effectiveness than using any single\nquery type alone, regardless of the query type used in evaluation. Our findings\nfurther indicate that synthetic queries offer comparable utility to\nhuman-written queries for training. We use our approach to train an embedding\nmodel that achieves state-of-the-art effectiveness among BERT embedding models.\nWe release our model and both query generation and training code to facilitate\nfurther research.",
    "pdf_url": "http://arxiv.org/pdf/2505.19274v1",
    "published": "2025-05-25T19:06:19+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19273v1",
    "title": "Eta-WavLM: Efficient Speaker Identity Removal in Self-Supervised Speech Representations Using a Simple Linear Equation",
    "authors": [
      "Giuseppe Ruggiero",
      "Matteo Testa",
      "Jurgen Van de Walle",
      "Luigi Di Caro"
    ],
    "abstract": "Self-supervised learning (SSL) has reduced the reliance on expensive labeling\nin speech technologies by learning meaningful representations from unannotated\ndata. Since most SSL-based downstream tasks prioritize content information in\nspeech, ideal representations should disentangle content from unwanted\nvariations like speaker characteristics in the SSL representations. However,\nremoving speaker information often degrades other speech components, and\nexisting methods either fail to fully disentangle speaker identity or require\nresource-intensive models. In this paper, we propose a novel disentanglement\nmethod that linearly decomposes SSL representations into speaker-specific and\nspeaker-independent components, effectively generating speaker disentangled\nrepresentations. Comprehensive experiments show that our approach achieves\nspeaker independence and as such, when applied to content-driven tasks such as\nvoice conversion, our representations yield significant improvements over\nstate-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.19273v1",
    "published": "2025-05-25T19:05:26+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.19272v1",
    "title": "Spin-qubit readout analysis based on a Hidden Markov Model",
    "authors": [
      "Maria Spethmann",
      "Peter Stano",
      "Daniel Loss"
    ],
    "abstract": "Across most qubit platforms, the readout fidelities do not keep up with the\ngate fidelities, and new ways to increase the readout fidelities are searched\nfor. For semiconductor spin qubits, a typical qubit-readout signal consists of\na finite stretch of a digitized charge-sensor output. Such a signal trace is\nusually analyzed by compressing it into a single value, either maximum or sum.\nThe binary measurement result follows by comparing the single value to a\ndecision threshold fixed in advance. This threshold method, while simple and\nfast, omits information that could potentially improve the readout fidelity.\nHere, we analyze what can be achieved by more sophisticated signal-trace\nprocessing using the Hidden Markov Model (HMM). The HMM is a natural choice,\nbeing the optimal statistical processing if the noise is white. It also has a\ncomputationally efficient implementation, known as the forward-backward\nalgorithm, making HMM processing practical. However, unlike in many\ncomputer-simulation studies, in real experiments the noise is correlated. How\nthis change affects the HMM implementation and reliability is our subject. We\nfind that the HMM using white noise as the system statistical model is\nsurprisingly sensitive to correlations; it only tolerates very small\ncorrelation times. We suggest alleviating this deficiency by a signal\npre-filtering. The correlations have a similar strongly negative impact on the\nHMM model calibration (the Baum-Welch algorithm). Besides studying the effects\nof noise correlations, as a specific application of the HMM we calculate the\nreadout fidelity at elevated temperatures, relevant to recent experimental\npursuits of `hot' spin qubits.",
    "pdf_url": "http://arxiv.org/pdf/2505.19272v1",
    "published": "2025-05-25T19:04:02+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19271v1",
    "title": "VerifyThisBench: Generating Code, Specifications, and Proofs All at Once",
    "authors": [
      "Xun Deng",
      "Sicheng Zhong",
      "Andreas Veneris",
      "Fan Long",
      "Xujie Si"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable progress in code\ngeneration, but many existing benchmarks are approaching saturation and offer\nlittle guarantee on the trustworthiness of the generated programs, offering\nlimited insight into deeper reasoning capabilities. We introduce\nVerifyThisBench, a new benchmark designed to evaluate LLMs on end-to-end\nprogram verification tasks that require interpreting natural language problem\ndescriptions, formulating formal specifications, generating code, and\nconstructing correctness proofs. Our evaluation reveals that even\nstate-of-the-art (SOTA) models, such as o3-mini, achieve a pass rate of less\nthan 4%, with many outputs failing to compile. To reduce task complexity, we\nfurther propose VerifyThisBenchXS, a variant in which partial implementations\nor proofs are provided. We systematically assess SOTA models on both\nbenchmarks, uncovering key strengths and limitations in their formal reasoning\nand verification capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.19271v1",
    "published": "2025-05-25T19:00:52+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.19270v2",
    "title": "Effect of noise and topologies on multi-photon quantum protocols",
    "authors": [
      "Nitin Jha",
      "Abhishek Parakh",
      "Mahadevan Subramaniam"
    ],
    "abstract": "Quantum-augmented networks aim to use quantum phenomena to improve detection\nand protection against malicious actors in a classical communication network.\nThis may include multiplexing quantum signals into classical fiber optical\nchannels and incorporating purely quantum links alongside classical links in\nthe network. In such hybrid networks, quantum protocols based on single photons\nbecome a bottleneck for transmission distances and data speeds, thereby\nreducing entire network performance. Furthermore, many of the security\nassumptions of the single-photon protocols do not hold up in practice because\nof the impossibility of manufacturing single-photon emitters. Multi-photon\nquantum protocols, on the other hand, are designed to operate under practical\nassumptions and do not require single photon emitters. As a result, they\nprovide higher levels of security guarantees and longer transmission distances.\nHowever, the effect of channel and device noise on multiphoton protocols in\nterms of security, transmission distances, and bit rates has not been\ninvestigated. In this paper, we focus on channel noise and present our\nobservations on the effect of various types of noise on multi-photon protocols.\nWe also investigate the effect of topologies such as ring, star, and torus on\nthe noise characteristics of the multi-photon protocols. Our results show the\npossible advantages of switching to multi-photon protocols and give insights\ninto the repeater placement and topology choice for quantum-augmented networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19270v2",
    "published": "2025-05-25T18:59:54+00:00",
    "categories": [
      "quant-ph",
      "cs.CR",
      "cs.NI"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19269v2",
    "title": "Quantum Wasserstein distances for quantum permutation groups",
    "authors": [
      "Anshu",
      "David Jekel",
      "Therese Basa Landry"
    ],
    "abstract": "We seek an analog for the quantum permutation group $S_n^+$ of the normalized\nHamming distance for permutations. We define three distances on the tracial\nstate space of $C(S_n^+)$ that generalize the $L^1$-Wasserstein distance of\nprobability measures on $S_n$ equipped with the normalized Hamming metric, for\nwhich we demonstrate basic metric properties, subadditivity under convolution,\nand density of the Lipschitz elements in the $\\mathrm{C}^{\\ast}$-algebra.",
    "pdf_url": "http://arxiv.org/pdf/2505.19269v2",
    "published": "2025-05-25T18:59:33+00:00",
    "categories": [
      "math.OA",
      "Primary: 46L67, 49Q22, Secondary: 46L89, 81R60"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19268v1",
    "title": "On Heegaard Floer minimal knots in sutured manifolds",
    "authors": [
      "Fraser Binns"
    ],
    "abstract": "Li-Xie-Zhang classified instanton Floer minimal knots in balanced sutured\nmanifolds subject to a condition on the fundamental group. In this paper, we\ngive a similar classification in the Heegaard Floer homology setting. Since our\nclassifications agree when they are both applicable, this provides further\nevidence for the conjecture of Kronheimer-Mrowka that instanton Floer homology\nand Heegaard Floer homology are isomorphic. We also study link Floer homology\nbotany question in $S^1\\times S^2$, showing that link Floer homology detects\nspherical braid closures among homologically nontrivial links.",
    "pdf_url": "http://arxiv.org/pdf/2505.19268v1",
    "published": "2025-05-25T18:49:16+00:00",
    "categories": [
      "math.GT",
      "57K31"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19267v1",
    "title": "QMIO: A tightly integrated hybrid HPCQC system",
    "authors": [
      "Javier Cacheiro",
      "Álvaro C Sánchez",
      "Russell Rundle",
      "George B Long",
      "Gavin Dold",
      "Jamie Friel",
      "Andrés Gómez"
    ],
    "abstract": "High-Performance Computing (HPC) systems are the most powerful tools that we\ncurrently have to solve complex scientific simulations. Quantum computing (QC)\nhas the potential to enhance HPC systems by accelerating the execution of\nspecific kernels that can be offloaded to a Quantum Processing Unit (QPU),\ngranting them new capabilities, improving the speed of computation, or reducing\nenergy consumption. In this paper, we present QMIO: a state-of-the-art hybrid\nHPCQC system, which tightly integrates HPC and QC. We describe its hardware and\nsoftware components, the integration middleware, and the lessons learned during\nthe design, implementation, and operation of the system.",
    "pdf_url": "http://arxiv.org/pdf/2505.19267v1",
    "published": "2025-05-25T18:46:25+00:00",
    "categories": [
      "quant-ph",
      "cs.DC",
      "cs.ET"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19266v1",
    "title": "Using Large Language Models to Assess Teachers' Pedagogical Content Knowledge",
    "authors": [
      "Yaxuan Yang",
      "Shiyu Wang",
      "Xiaoming Zhai"
    ],
    "abstract": "Assessing teachers' pedagogical content knowledge (PCK) through\nperformance-based tasks is both time and effort-consuming. While large language\nmodels (LLMs) offer new opportunities for efficient automatic scoring, little\nis known about whether LLMs introduce construct-irrelevant variance (CIV) in\nways similar to or different from traditional machine learning (ML) and human\nraters. This study examines three sources of CIV -- scenario variability, rater\nseverity, and rater sensitivity to scenario -- in the context of video-based\nconstructed-response tasks targeting two PCK sub-constructs: analyzing student\nthinking and evaluating teacher responsiveness. Using generalized linear mixed\nmodels (GLMMs), we compared variance components and rater-level scoring\npatterns across three scoring sources: human raters, supervised ML, and LLM.\nResults indicate that scenario-level variance was minimal across tasks, while\nrater-related factors contributed substantially to CIV, especially in the more\ninterpretive Task II. The ML model was the most severe and least sensitive\nrater, whereas the LLM was the most lenient. These findings suggest that the\nLLM contributes to scoring efficiency while also introducing CIV as human\nraters do, yet with varying levels of contribution compared to supervised ML.\nImplications for rater training, automated scoring design, and future research\non model interpretability are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.19266v1",
    "published": "2025-05-25T18:45:53+00:00",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19265v1",
    "title": "Evaluation of theapplicability of Schrödinger-variant equations for classical fluid dynamics",
    "authors": [
      "Yi-Sian Ciou"
    ],
    "abstract": "The artificial fluid model known as \"Schr\\\"odinger flow\" (SF) can represent\nrotational flow with dissipative effects, and has attracted attention despite\nits gap from real-world fluid behavior. To address the structural discrepancy\narising from the incomplete transition from quantum hydrodynamics to classical\nfluid dynamics, we propose a variant of the hydrodynamic Schr\\\"odinger equation\n(HSE) that better aligns with classical formulations. We then revisit an\nalternative method for eliminating the quantum potential (referred to in this\nwork as the \"cancellation approach\") in light of the known non-universality of\nthe classical limit. Beyond examining conservation laws via Lagrangian field\ntheory, we identify its deeper connection to a generalized Lagrangian field\ntheory, which offers a more straightforward route to constructing a Lagrangian\ndensity in terms of the components of a two-component wave function for\nrotational inviscid flow. Finally, we discuss the completeness of Clebsch\nparameterization, concluding our evaluation of the applicability of the\nproposed SF-variant formulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19265v1",
    "published": "2025-05-25T18:43:35+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.19264v1",
    "title": "Improving Novel view synthesis of 360$^\\circ$ Scenes in Extremely Sparse Views by Jointly Training Hemisphere Sampled Synthetic Images",
    "authors": [
      "Guangan Chen",
      "Anh Minh Truong",
      "Hanhe Lin",
      "Michiel Vlaminck",
      "Wilfried Philips",
      "Hiep Luong"
    ],
    "abstract": "Novel view synthesis in 360$^\\circ$ scenes from extremely sparse input views\nis essential for applications like virtual reality and augmented reality. This\npaper presents a novel framework for novel view synthesis in extremely\nsparse-view cases. As typical structure-from-motion methods are unable to\nestimate camera poses in extremely sparse-view cases, we apply DUSt3R to\nestimate camera poses and generate a dense point cloud. Using the poses of\nestimated cameras, we densely sample additional views from the upper hemisphere\nspace of the scenes, from which we render synthetic images together with the\npoint cloud. Training 3D Gaussian Splatting model on a combination of reference\nimages from sparse views and densely sampled synthetic images allows a larger\nscene coverage in 3D space, addressing the overfitting challenge due to the\nlimited input in sparse-view cases. Retraining a diffusion-based image\nenhancement model on our created dataset, we further improve the quality of the\npoint-cloud-rendered images by removing artifacts. We compare our framework\nwith benchmark methods in cases of only four input views, demonstrating\nsignificant improvement in novel view synthesis under extremely sparse-view\nconditions for 360$^\\circ$ scenes.",
    "pdf_url": "http://arxiv.org/pdf/2505.19264v1",
    "published": "2025-05-25T18:42:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19263v1",
    "title": "Cellular Traffic Prediction via Byzantine-robust Asynchronous Federated Learning",
    "authors": [
      "Hui Ma",
      "Kai Yang",
      "Yang Jiao"
    ],
    "abstract": "Network traffic prediction plays a crucial role in intelligent network\noperation. Traditional prediction methods often rely on centralized training,\nnecessitating the transfer of vast amounts of traffic data to a central server.\nThis approach can lead to latency and privacy concerns. To address these\nissues, federated learning integrated with differential privacy has emerged as\na solution to improve data privacy and model robustness in distributed\nsettings. Nonetheless, existing federated learning protocols are vulnerable to\nByzantine attacks, which may significantly compromise model robustness.\nDeveloping a robust and privacy-preserving prediction model in the presence of\nByzantine clients remains a significant challenge. To this end, we propose an\nasynchronous differential federated learning framework based on\ndistributionally robust optimization. The proposed framework utilizes multiple\nclients to train the prediction model collaboratively with local differential\nprivacy. In addition, regularization techniques have been employed to further\nimprove the Byzantine robustness of the models. We have conducted extensive\nexperiments on three real-world datasets, and the results elucidate that our\nproposed distributed algorithm can achieve superior performance over existing\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.19263v1",
    "published": "2025-05-25T18:38:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19262v1",
    "title": "Universal dissipators for driven open quantum systems and the correction to linear response",
    "authors": [
      "Lorenzo Bernazzani",
      "Balázs Gulácsi",
      "Guido Burkard"
    ],
    "abstract": "We investigate in parallel two common pictures used to describe quantum\nsystems interacting with their surrounding environment, i.e., the stochastic\nHamiltonian description, where the environment is implicitly included in the\nfluctuating internal parameters of the system, and the explicit inclusion of\nthe environment via the time-convolutionless projection operator method.\nUtilizing these two different frameworks, we show that the dissipator\ncharacterizing the dynamics of the reduced system, determined up to second\norder in the noise strength or bath-system coupling, is universal. That is, it\nkeeps the same form regardless of the drive term, as long as the drive is weak.\nWe thoroughly discuss the assumptions on which this treatment is based and its\nlimitations. By considering the first non-vanishing higher-order term in our\nexpansion, we also derive the linear response correction due to memory-mediated\nenvironmental effects in driven-dissipative systems. We demonstrate this\ntechnique to be highly accurate for the problems of dephasing in a driven qubit\nand for the theory of pseudomodes for quantum environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.19262v1",
    "published": "2025-05-25T18:33:51+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19261v1",
    "title": "Enhancing Text-to-Image Diffusion Transformer via Split-Text Conditioning",
    "authors": [
      "Yu Zhang",
      "Jialei Zhou",
      "Xinchen Li",
      "Qi Zhang",
      "Zhongwei Wan",
      "Tianyu Wang",
      "Duoqian Miao",
      "Changwei Wang",
      "Longbing Cao"
    ],
    "abstract": "Current text-to-image diffusion generation typically employs complete-text\nconditioning. Due to the intricate syntax, diffusion transformers (DiTs)\ninherently suffer from a comprehension defect of complete-text captions.\nOne-fly complete-text input either overlooks critical semantic details or\ncauses semantic confusion by simultaneously modeling diverse semantic primitive\ntypes. To mitigate this defect of DiTs, we propose a novel split-text\nconditioning framework named DiT-ST. This framework converts a complete-text\ncaption into a split-text caption, a collection of simplified sentences, to\nexplicitly express various semantic primitives and their interconnections. The\nsplit-text caption is then injected into different denoising stages of DiT-ST\nin a hierarchical and incremental manner. Specifically, DiT-ST leverages Large\nLanguage Models to parse captions, extracting diverse primitives and\nhierarchically sorting out and constructing these primitives into a split-text\ninput. Moreover, we partition the diffusion denoising process according to its\ndifferential sensitivities to diverse semantic primitive types and determine\nthe appropriate timesteps to incrementally inject tokens of diverse semantic\nprimitive types into input tokens via cross-attention. In this way, DiT-ST\nenhances the representation learning of specific semantic primitive types\nacross different stages. Extensive experiments validate the effectiveness of\nour proposed DiT-ST in mitigating the complete-text comprehension defect.",
    "pdf_url": "http://arxiv.org/pdf/2505.19261v1",
    "published": "2025-05-25T18:33:05+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19260v1",
    "title": "ALRPHFS: Adversarially Learned Risk Patterns with Hierarchical Fast \\& Slow Reasoning for Robust Agent Defense",
    "authors": [
      "Shiyu Xiang",
      "Tong Zhang",
      "Ronghao Chen"
    ],
    "abstract": "LLM Agents are becoming central to intelligent systems. However, their\ndeployment raises serious safety concerns. Existing defenses largely rely on\n\"Safety Checks\", which struggle to capture the complex semantic risks posed by\nharmful user inputs or unsafe agent behaviors - creating a significant semantic\ngap between safety checks and real-world risks. To bridge this gap, we propose\na novel defense framework, ALRPHFS (Adversarially Learned Risk Patterns with\nHierarchical Fast & Slow Reasoning). ALRPHFS consists of two core components:\n(1) an offline adversarial self-learning loop to iteratively refine a\ngeneralizable and balanced library of risk patterns, substantially enhancing\nrobustness without retraining the base LLM, and (2) an online hierarchical fast\n& slow reasoning engine that balances detection effectiveness with\ncomputational efficiency. Experimental results demonstrate that our approach\nachieves superior overall performance compared to existing baselines, achieving\na best-in-class average accuracy of 80% and exhibiting strong generalizability\nacross agents and tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19260v1",
    "published": "2025-05-25T18:31:48+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19259v2",
    "title": "Towards Large Reasoning Models for Agriculture",
    "authors": [
      "Hossein Zaremehrjerdi",
      "Shreyan Ganguly",
      "Ashlyn Rairdin",
      "Elizabeth Tranel",
      "Benjamin Feuer",
      "Juan Ignacio Di Salvo",
      "Srikanth Panthulugiri",
      "Hernan Torres Pacin",
      "Victoria Moser",
      "Sarah Jones",
      "Joscif G Raigne",
      "Yanben Shen",
      "Heidi M. Dornath",
      "Aditya Balu",
      "Adarsh Krishnamurthy",
      "Asheesh K Singh",
      "Arti Singh",
      "Baskar Ganapathysubramanian",
      "Chinmay Hegde",
      "Soumik Sarkar"
    ],
    "abstract": "Agricultural decision-making involves complex, context-specific reasoning,\nwhere choices about crops, practices, and interventions depend heavily on\ngeographic, climatic, and economic conditions. Traditional large language\nmodels (LLMs) often fall short in navigating this nuanced problem due to\nlimited reasoning capacity. We hypothesize that recent advances in large\nreasoning models (LRMs) can better handle such structured, domain-specific\ninference. To investigate this, we introduce AgReason, the first expert-curated\nopen-ended science benchmark with 100 questions for agricultural reasoning.\nEvaluations across thirteen open-source and proprietary models reveal that LRMs\noutperform conventional ones, though notable challenges persist, with the\nstrongest Gemini-based baseline achieving 36% accuracy. We also present\nAgThoughts, a large-scale dataset of 44.6K question-answer pairs generated with\nhuman oversight and equipped with synthetically generated reasoning traces.\nUsing AgThoughts, we develop AgThinker, a suite of small reasoning models that\ncan be run on consumer-grade GPUs, and show that our dataset can be effective\nin unlocking agricultural reasoning abilities in LLMs. Our project page is\nhere: https://baskargroup.github.io/Ag_reasoning/",
    "pdf_url": "http://arxiv.org/pdf/2505.19259v2",
    "published": "2025-05-25T18:28:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19258v2",
    "title": "Towards a Spatiotemporal Fusion Approach to Precipitation Nowcasting",
    "authors": [
      "Felipe Curcio",
      "Pedro Castro",
      "Augusto Fonseca",
      "Rafaela Castro",
      "Raquel Franco",
      "Eduardo Ogasawara",
      "Victor Stepanenko",
      "Fabio Porto",
      "Mariza Ferro",
      "Eduardo Bezerra"
    ],
    "abstract": "With the increasing availability of meteorological data from various sensors,\nnumerical models and reanalysis products, the need for efficient data\nintegration methods has become paramount for improving weather forecasts and\nhydrometeorological studies. In this work, we propose a data fusion approach\nfor precipitation nowcasting by integrating data from meteorological and rain\ngauge stations in Rio de Janeiro metropolitan area with ERA5 reanalysis data\nand GFS numerical weather prediction. We employ the spatiotemporal deep\nlearning architecture called STConvS2S, leveraging a structured dataset\ncovering a 9 x 11 grid. The study spans from January 2011 to October 2024, and\nwe evaluate the impact of integrating three surface station systems. Among the\ntested configurations, the fusion-based model achieves an F1-score of 0.2033\nfor forecasting heavy precipitation events (greater than 25 mm/h) at a one-hour\nlead time. Additionally, we present an ablation study to assess the\ncontribution of each station network and propose a refined inference strategy\nfor precipitation nowcasting, integrating the GFS numerical weather prediction\n(NWP) data with in-situ observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.19258v2",
    "published": "2025-05-25T18:27:19+00:00",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19257v1",
    "title": "Existence of Conical Higher cscK Metrics on a Minimal Ruled Surface",
    "authors": [
      "Rajas Sandeep Sompurkar"
    ],
    "abstract": "A `higher extremal K\\\"ahler metric' is defined (motivated by analogy with the\ndefinition of an extremal K\\\"ahler metric) as a K\\\"ahler metric whose top Chern\nform and volume form ``differ'' by a smooth function whose gradient is a\nholomorphic vector field. A special case of this kind of metric is a `higher\nconstant scalar curvature K\\\"ahler (higher cscK) metric' which is defined\n(again by analogy with the definition of a constant scalar curvature K\\\"ahler\n(cscK) metric) as a K\\\"ahler metric whose top Chern form is a real constant\nmultiple of its volume form or equivalently whose top Chern form is harmonic.\nIn our previous paper on higher extremal K\\\"ahler metrics we had looked at a\nspecial class of minimal ruled surfaces called as `pseudo-Hirzebruch surfaces'\nall of which contain two special divisors (viz. the zero and infinity divisors)\nand have got some nice symmetries which enable the use of the momentum\nconstruction method for finding explicit examples of these kinds of\n``canonical'' metrics. We had proven that every K\\\"ahler class on such a\nsurface admits a higher extremal K\\\"ahler metric which is not higher cscK and\nwe had further proven that higher cscK metrics do not exist in any K\\\"ahler\nclass on such a surface. In this paper we will see that if we allow our metrics\nto develop `conical singularities' along at least one of the two divisors then\nwe do get `conical higher cscK metrics' in each K\\\"ahler class of the surface\nby the momentum construction method. We will show that our constructed metrics\nare ``genuine'' conical K\\\"ahler metrics and we will interpret the conical\nhigher cscK equation globally on the surface in terms of currents. We will then\nintroduce and employ the `top $\\log$ Bando-Futaki invariant' to obtain the\nlinear relationship between the cone angles of the conical singularities of our\nconstructed metrics along the zero and infinity divisors.",
    "pdf_url": "http://arxiv.org/pdf/2505.19257v1",
    "published": "2025-05-25T18:25:40+00:00",
    "categories": [
      "math.DG",
      "math.CV",
      "2020: 53C55 (Primary), 53C25, 58J60, 58J90, 32U40, 32U05, 32Q15,\n  32J27, 32J15, 34B30, 34B60, 35R01 (Secondary)"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19256v3",
    "title": "PolyPose: Localizing Deformable Anatomy in 3D from Sparse 2D X-ray Images using Polyrigid Transforms",
    "authors": [
      "Vivek Gopalakrishnan",
      "Neel Dey",
      "Polina Golland"
    ],
    "abstract": "Determining the 3D pose of a patient from a limited set of 2D X-ray images is\na critical task in interventional settings. While preoperative volumetric\nimaging (e.g., CT and MRI) provides precise 3D localization and visualization\nof anatomical targets, these modalities cannot be acquired during procedures,\nwhere fast 2D imaging (X-ray) is used instead. To integrate volumetric guidance\ninto intraoperative procedures, we present PolyPose, a simple and robust method\nfor deformable 2D/3D registration. PolyPose parameterizes complex 3D\ndeformation fields as a composition of rigid transforms, leveraging the\nbiological constraint that individual bones do not bend in typical motion.\nUnlike existing methods that either assume no inter-joint movement or fail\noutright in this under-determined setting, our polyrigid formulation enforces\nanatomically plausible priors that respect the piecewise rigid nature of human\nmovement. This approach eliminates the need for expensive deformation\nregularizers that require patient- and procedure-specific hyperparameter\noptimization. Across extensive experiments on diverse datasets from orthopedic\nsurgery and radiotherapy, we show that this strong inductive bias enables\nPolyPose to successfully align the patient's preoperative volume to as few as\ntwo X-ray images, thereby providing crucial 3D guidance in challenging\nsparse-view and limited-angle settings where current registration methods fail.",
    "pdf_url": "http://arxiv.org/pdf/2505.19256v3",
    "published": "2025-05-25T18:24:18+00:00",
    "categories": [
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19255v3",
    "title": "VTool-R1: VLMs Learn to Think with Images via Reinforcement Learning on Multimodal Tool Use",
    "authors": [
      "Mingyuan Wu",
      "Jingcheng Yang",
      "Jize Jiang",
      "Meitang Li",
      "Kaizhuo Yan",
      "Hanchao Yu",
      "Minjia Zhang",
      "Chengxiang Zhai",
      "Klara Nahrstedt"
    ],
    "abstract": "Reinforcement Learning Finetuning (RFT) has significantly advanced the\nreasoning capabilities of large language models (LLMs) by enabling long chains\nof thought, self-correction, and effective tool use. While recent works attempt\nto extend RFT to vision-language models (VLMs), these efforts largely produce\ntext-only reasoning conditioned on static image inputs, falling short of true\nmultimodal reasoning in the response. In contrast, test-time methods like\nVisual Sketchpad incorporate visual steps but lack training mechanisms.\n  We introduce VTool-R1, the first framework that trains VLMs to generate\nmultimodal chains of thought by interleaving text and intermediate visual\nreasoning steps. VTool-R1 integrates Python-based visual editing tools into the\nRFT process, enabling VLMs to learn when and how to generate visual reasoning\nsteps that benefit final reasoning. Trained with outcome-based rewards tied to\ntask accuracy, our approach elicits strategic visual tool use for reasoning\nwithout relying on process-based supervision. Experiments on structured visual\nquestion answering over charts and tables show that VTool-R1 enhances reasoning\nperformance by teaching VLMs to \"think with images\" and generate multimodal\nchain of thoughts with tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.19255v3",
    "published": "2025-05-25T18:23:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19254v1",
    "title": "Unveiling Dual Quality in Product Reviews: An NLP-Based Approach",
    "authors": [
      "Rafał Poświata",
      "Marcin Michał Mirończuk",
      "Sławomir Dadas",
      "Małgorzata Grębowiec",
      "Michał Perełkiewicz"
    ],
    "abstract": "Consumers often face inconsistent product quality, particularly when\nidentical products vary between markets, a situation known as the dual quality\nproblem. To identify and address this issue, automated techniques are needed.\nThis paper explores how natural language processing (NLP) can aid in detecting\nsuch discrepancies and presents the full process of developing a solution.\nFirst, we describe in detail the creation of a new Polish-language dataset with\n1,957 reviews, 540 highlighting dual quality issues. We then discuss\nexperiments with various approaches like SetFit with sentence-transformers,\ntransformer-based encoders, and LLMs, including error analysis and robustness\nverification. Additionally, we evaluate multilingual transfer using a subset of\nopinions in English, French, and German. The paper concludes with insights on\ndeployment and practical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.19254v1",
    "published": "2025-05-25T18:23:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19253v2",
    "title": "DeepResearchGym: A Free, Transparent, and Reproducible Evaluation Sandbox for Deep Research",
    "authors": [
      "João Coelho",
      "Jingjie Ning",
      "Jingyuan He",
      "Kangrui Mao",
      "Abhijay Paladugu",
      "Pranav Setlur",
      "Jiahe Jin",
      "Jamie Callan",
      "João Magalhães",
      "Bruno Martins",
      "Chenyan Xiong"
    ],
    "abstract": "Deep research systems represent an emerging class of agentic information\nretrieval methods that generate comprehensive and well-supported reports to\ncomplex queries. However, most existing frameworks rely on dynamic commercial\nsearch APIs, which pose reproducibility and transparency challenges in addition\nto their cost. To address these limitations, we introduce DeepResearchGym, an\nopen-source sandbox that combines a reproducible search API with a rigorous\nevaluation protocol for benchmarking deep research systems. The API indexes\nlarge-scale public web corpora, namely ClueWeb22 and FineWeb, using a\nstate-of-the-art dense retriever and approximate nearest neighbor search via\nDiskANN. It achieves lower latency than popular commercial APIs while ensuring\nstable document rankings across runs, and is freely available for research use.\nTo evaluate deep research systems' outputs, we extend the Researchy Questions\nbenchmark with automatic metrics through LLM-as-a-judge assessments to measure\nalignment with users' information needs, retrieval faithfulness, and report\nquality. Experimental results show that systems integrated with DeepResearchGym\nachieve performance comparable to those using commercial APIs, with performance\nrankings remaining consistent across evaluation metrics. A human evaluation\nstudy further confirms that our automatic protocol aligns with human\npreferences, validating the framework's ability to help support controlled\nassessment of deep research systems. Our code and API documentation are\navailable at https://www.deepresearchgym.ai.",
    "pdf_url": "http://arxiv.org/pdf/2505.19253v2",
    "published": "2025-05-25T18:16:13+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19252v1",
    "title": "Learning-Augmented Online Bipartite Fractional Matching",
    "authors": [
      "Davin Choo",
      "Billy Jin",
      "Yongho Shin"
    ],
    "abstract": "Online bipartite matching is a fundamental problem in online optimization,\nextensively studied both in its integral and fractional forms due to its\ntheoretical significance and practical applications, such as online advertising\nand resource allocation. Motivated by recent progress in learning-augmented\nalgorithms, we study online bipartite fractional matching when the algorithm is\ngiven advice in the form of a suggested matching in each iteration. We develop\nalgorithms for both the vertex-weighted and unweighted variants that provably\ndominate the naive \"coin flip\" strategy of randomly choosing between the\nadvice-following and advice-free algorithms. Moreover, our algorithm for the\nvertex-weighted setting extends to the AdWords problem under the small bids\nassumption, yielding a significant improvement over the seminal work of\nMahdian, Nazerzadeh, and Saberi (EC 2007, TALG 2012). Complementing our\npositive results, we establish a hardness bound on the robustness-consistency\ntradeoff that is attainable by any algorithm. We empirically validate our\nalgorithms through experiments on synthetic and real-world data.",
    "pdf_url": "http://arxiv.org/pdf/2505.19252v1",
    "published": "2025-05-25T18:15:29+00:00",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.19251v3",
    "title": "Skein theory for the Links-Gould polynomial",
    "authors": [
      "Stavros Garoufalidis",
      "Matthew Harper",
      "Rinat Kashaev",
      "Ben-Michael Kohli",
      "Jiebo Song",
      "Guillaume Tahar"
    ],
    "abstract": "Building further on work of Marin and Wagner, we give a cubic braid-type\nskein theory of the Links--Gould polynomial invariant of oriented links and\nprove that it can be used to evaluate any oriented link, adding this polynomial\nto the list of polynomial invariants that can be computed by skein theory. As a\nconsequence, we prove that this skein theory is also shared by the\n$V_1$-polynomial defined by two of the authors, deducing the equality of the\ntwo link polynomials. This implies specialization properties of the\n$V_1$-polynomial to the Alexander polynomial and to the\n$\\mathrm{ADO}_3$-invariant, the fact that it is a Vassiliev power series\ninvariant, as well as a Seifert genus bound for knots.",
    "pdf_url": "http://arxiv.org/pdf/2505.19251v3",
    "published": "2025-05-25T17:58:55+00:00",
    "categories": [
      "math.GT",
      "math.QA",
      "57K14 (Primary) 57K16 (Secondary)"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19250v1",
    "title": "PATS: Process-Level Adaptive Thinking Mode Switching",
    "authors": [
      "Yi Wang",
      "Junxiao Liu",
      "Shimao Zhang",
      "Jiajun Chen",
      "Shujian Huang"
    ],
    "abstract": "Current large-language models (LLMs) typically adopt a fixed reasoning\nstrategy, either simple or complex, for all questions, regardless of their\ndifficulty. This neglect of variation in task and reasoning process complexity\nleads to an imbalance between performance and efficiency. Existing methods\nattempt to implement training-free fast-slow thinking system switching to\nhandle problems of varying difficulty, but are limited by coarse-grained\nsolution-level strategy adjustments. To address this issue, we propose a novel\nreasoning paradigm: Process-Level Adaptive Thinking Mode Switching (PATS),\nwhich enables LLMs to dynamically adjust their reasoning strategy based on the\ndifficulty of each step, optimizing the balance between accuracy and\ncomputational efficiency. Our approach integrates Process Reward Models (PRMs)\nwith Beam Search, incorporating progressive mode switching and bad-step penalty\nmechanisms. Experiments on diverse mathematical benchmarks demonstrate that our\nmethodology achieves high accuracy while maintaining moderate token usage. This\nstudy emphasizes the significance of process-level, difficulty-aware reasoning\nstrategy adaptation, offering valuable insights into efficient inference for\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.19250v1",
    "published": "2025-05-25T17:58:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19249v1",
    "title": "RGC-Bent: A Novel Dataset for Bent Radio Galaxy Classification",
    "authors": [
      "Mir Sazzat Hossain",
      "Khan Muhammad Bin Asad",
      "Payaswini Saikia",
      "Adrita Khan",
      "Md Akil Raihan Iftee",
      "Rakibul Hasan Rajib",
      "Arshad Momen",
      "Md Ashraful Amin",
      "Amin Ahsan Ali",
      "AKM Mahbubur Rahman"
    ],
    "abstract": "We introduce a novel machine learning dataset tailored for the classification\nof bent radio active galactic nuclei (AGN) in astronomical observations. Bent\nradio AGN, distinguished by their curved jet structures, provide critical\ninsights into galaxy cluster dynamics, interactions within the intracluster\nmedium, and the broader physics of AGN. Despite their astrophysical\nsignificance, the classification of bent radio AGN remains a challenge due to\nthe scarcity of specialized datasets and benchmarks. To address this, we\npresent a dataset, derived from a well-recognized radio astronomy survey, that\nis designed to support the classification of NAT (Narrow-Angle Tail) and WAT\n(Wide-Angle Tail) categories, along with detailed data processing steps. We\nfurther evaluate the performance of state-of-the-art deep learning models on\nthe dataset, including Convolutional Neural Networks (CNNs), and\ntransformer-based architectures. Our results demonstrate the effectiveness of\nadvanced machine learning models in classifying bent radio AGN, with ConvNeXT\nachieving the highest F1-scores for both NAT and WAT sources. By sharing this\ndataset and benchmarks, we aim to facilitate the advancement of research in AGN\nclassification, galaxy cluster environments and galaxy evolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.19249v1",
    "published": "2025-05-25T17:57:47+00:00",
    "categories": [
      "astro-ph.GA",
      "cs.CV"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19248v2",
    "title": "100 Proof: HI Observations of 100 Nearby Dwarf Galaxies with the 100-meter Green Bank Telescope",
    "authors": [
      "Aleksandra E. Nazarova",
      "John M. Cannon",
      "Igor D. Karachentsev",
      "Dmitry I. Makarov",
      "Maksim I. Chazov",
      "Lila Schisgal",
      "William St. John"
    ],
    "abstract": "We describe the results of observations with the 100m Robert C. Byrd Green\nBank Telescope (GBT) in the HI line of 105 nearby dwarf galaxies, 60 of which\nwere discovered recently in the DESI Legacy Imaging Surveys. Of 105 objects\nobserved, we detected 77 galaxies with the following median parameters: an\nHI-flux of 0.69 Jy km/s, a heliocentric velocity of 732 km/s, and a $W_{50}$\nline width of 32 km/s. 70 are isolated late-type objects and 35 are new\nprobable satellites of nearby spiral galaxies (NGC 628, NGC 2787, NGC 3556, NGC\n4490, NGC 4594 and NGC 5055). The detected galaxies are predominantly gas-rich\nsystems with a median gas-to-stellar-mass ratio of 1.87. In general, they\nfollow the classic Tully-Fisher relation obtained for large disk-dominated\nspiral galaxies if their $M_{21}$ magnitudes are used instead of B-magnitudes.",
    "pdf_url": "http://arxiv.org/pdf/2505.19248v2",
    "published": "2025-05-25T17:54:51+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19247v1",
    "title": "Improving Value Estimation Critically Enhances Vanilla Policy Gradient",
    "authors": [
      "Tao Wang",
      "Ruipeng Zhang",
      "Sicun Gao"
    ],
    "abstract": "Modern policy gradient algorithms, such as TRPO and PPO, outperform vanilla\npolicy gradient in many RL tasks. Questioning the common belief that enforcing\napproximate trust regions leads to steady policy improvement in practice, we\nshow that the more critical factor is the enhanced value estimation accuracy\nfrom more value update steps in each iteration. To demonstrate, we show that by\nsimply increasing the number of value update steps per iteration, vanilla\npolicy gradient itself can achieve performance comparable to or better than PPO\nin all the standard continuous control benchmark environments. Importantly,\nthis simple change to vanilla policy gradient is significantly more robust to\nhyperparameter choices, opening up the possibility that RL algorithms may still\nbecome more effective and easier to use.",
    "pdf_url": "http://arxiv.org/pdf/2505.19247v1",
    "published": "2025-05-25T17:54:32+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19246v2",
    "title": "On the transmission of texts: written cultures as complex systems",
    "authors": [
      "Jean-Baptiste Camps",
      "Julien Randon-Furling",
      "Ulysse Godreau"
    ],
    "abstract": "Our knowledge of past cultures relies considerably on written material. For\ncenturies, texts have been copied, altered, then transmitted or lost -\neventually, from surviving documents, philologists attempt to reconstruct text\nphylogenies (\"stemmata\"), and past written cultures. Nonetheless, fundamental\nquestions on the extent of losses, representativeness of surviving artefacts,\nand the dynamics of text genealogies have remained open since the earliest days\nof philology. To address these, we radically rethink the study of text\ntransmission through a complexity science approach, integrating stochastic\nmodelling, computer simulations, and data analysis, in a parsimonious mindset\nakin to statistical physics and evolutionary biology. Thus, we design models\nthat are simple and general, while accounting for diachrony and other key\naspects of the dynamical process underlying text phylogenies, such as the\nextinction of entire branches or trees. On the well-known case study of\nMedieval French chivalric literature, we find that up to 60% of texts and 99%\nof manuscripts were lost (consistent with recent synchronic \"biodiversity\"\nanalyses). We also settle a hundred-year-old controversy on the bifidity of\nstemmata. Further, our null model suggests that pure chance (\"drift\") is not\nthe only mechanism at play, and we provide a theoretical and empirical\nframework for future investigation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19246v2",
    "published": "2025-05-25T17:54:28+00:00",
    "categories": [
      "physics.soc-ph",
      "cond-mat.dis-nn",
      "math.PR"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19245v1",
    "title": "To CoT or To Loop? A Formal Comparison Between Chain-of-Thought and Looped Transformers",
    "authors": [
      "Kevin Xu",
      "Issei Sato"
    ],
    "abstract": "Chain-of-Thought (CoT) and Looped Transformers have been shown to empirically\nimprove performance on reasoning tasks and to theoretically enhance\nexpressivity by recursively increasing the number of computational steps.\nHowever, their comparative capabilities are still not well understood. In this\npaper, we provide a formal analysis of their respective strengths and\nlimitations. We show that Looped Transformers can efficiently simulate parallel\ncomputations for deterministic tasks, which we formalize as evaluation over\ndirected acyclic graphs. In contrast, CoT with stochastic decoding excels at\napproximate inference for compositional structures, namely self-reducible\nproblems. These separations suggest the tasks for which depth-driven recursion\nis more suitable, thereby offering practical cues for choosing between\nreasoning paradigms.",
    "pdf_url": "http://arxiv.org/pdf/2505.19245v1",
    "published": "2025-05-25T17:49:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19244v2",
    "title": "Large structural VARs with multiple linear shock and impact inequality restrictions",
    "authors": [
      "Lukas Berend",
      "Jan Prüser"
    ],
    "abstract": "We propose a high-dimensional structural vector autoregression framework that\nfeatures a factor structure in the error terms and accommodates a large number\nof linear inequality restrictions on impact impulse responses, structural\nshocks, and their element-wise products. In particular, we demonstrate that\nnarrative restrictions can be imposed via constraints on the structural shocks,\nwhich can be used to sharpen inference and disentangle structurally\ninterpretable shocks. To estimate the model, we develop a highly efficient\nsampling algorithm that scales well with both the model dimension and the\nnumber of inequality restrictions on impact responses and structural shocks. It\nremains computationally feasible even in settings where existing algorithms may\nbreak down. To illustrate the practical utility of our approach, we identify\nfive structural shocks and examine the dynamic responses of thirty\nmacroeconomic variables, highlighting the model's flexibility and feasibility\nin complex empirical applications. We provide empirical evidence that financial\nshocks are the most important driver of business cycle dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.19244v2",
    "published": "2025-05-25T17:49:23+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2505.19243v1",
    "title": "Comparative analysis of financial data differentiation techniques using LSTM neural network",
    "authors": [
      "Dominik Stempień",
      "Janusz Gajda"
    ],
    "abstract": "We compare traditional approach of computing logarithmic returns with the\nfractional differencing method and its tempered extension as methods of data\npreparation before their usage in advanced machine learning models.\nDifferencing parameters are estimated using multiple techniques. The empirical\ninvestigation is conducted on data from four major stock indices covering the\nmost recent 10-year period. The set of explanatory variables is additionally\nextended with technical indicators. The effectiveness of the differencing\nmethods is evaluated using both forecast error metrics and risk-adjusted return\ntrading performance metrics. The findings suggest that fractional\ndifferentiation methods provide a suitable data transformation technique,\nimproving the predictive model forecasting performance. Furthermore, the\ngenerated predictions appeared to be effective in constructing profitable\ntrading strategies for both individual assets and a portfolio of stock indices.\nThese results underline the importance of appropriate data transformation\ntechniques in financial time series forecasting, supporting the application of\nmemory-preserving techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.19243v1",
    "published": "2025-05-25T17:49:10+00:00",
    "categories": [
      "q-fin.ST",
      "econ.EM",
      "q-fin.CP",
      "q-fin.TR"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.19242v1",
    "title": "Deformable Attentive Visual Enhancement for Referring Segmentation Using Vision-Language Model",
    "authors": [
      "Alaa Dalaq",
      "Muzammil Behzad"
    ],
    "abstract": "Image segmentation is a fundamental task in computer vision, aimed at\npartitioning an image into semantically meaningful regions. Referring image\nsegmentation extends this task by using natural language expressions to\nlocalize specific objects, requiring effective integration of visual and\nlinguistic information. In this work, we propose SegVLM, a vision-language\nmodel that incorporates architectural improvements to enhance segmentation\naccuracy and cross-modal alignment. The model integrates squeeze-and-excitation\n(SE) blocks for dynamic feature recalibration, deformable convolutions for\ngeometric adaptability, and residual connections for deep feature learning. We\nalso introduce a novel referring-aware fusion (RAF) loss that balances\nregion-level alignment, boundary precision, and class imbalance. Extensive\nexperiments and ablation studies demonstrate that each component contributes to\nconsistent performance improvements. SegVLM also shows strong generalization\nacross diverse datasets and referring expression scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.19242v1",
    "published": "2025-05-25T17:42:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19241v1",
    "title": "ActiveDPO: Active Direct Preference Optimization for Sample-Efficient Alignment",
    "authors": [
      "Xiaoqiang Lin",
      "Arun Verma",
      "Zhongxiang Dai",
      "Daniela Rus",
      "See-Kiong Ng",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "The recent success of using human preferences to align large language models\n(LLMs) has significantly improved their performance in various downstream tasks\nlike question answering, mathematical reasoning, and code generation. However,3\nachieving effective LLM alignment depends on high-quality human preference\ndatasets. Collecting these datasets requires human preference annotation, which\nis costly and resource-intensive, necessitating efficient active data selection\nmethods. Existing methods either lack a strong theoretical foundation or depend\non restrictive reward function assumptions (e.g., linearity). To this end, we\npropose an algorithm, ActiveDPO, that uses a theoretically grounded data\nselection criterion for non-linear reward functions while directly leveraging\nthe LLM itself to parameterize the reward model that is used for active data\nselection. As a result, ActiveDPO explicitly accounts for the influence of LLM\non data selection, unlike methods that select the data without considering the\nLLM that is being aligned, thereby leading to more effective and efficient data\ncollection. Extensive experiments show that ActiveDPO outperforms existing\nmethods across various models and datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.19241v1",
    "published": "2025-05-25T17:42:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19240v2",
    "title": "LLLMs: A Data-Driven Survey of Evolving Research on Limitations of Large Language Models",
    "authors": [
      "Aida Kostikova",
      "Zhipin Wang",
      "Deidamea Bajri",
      "Ole Pütz",
      "Benjamin Paaßen",
      "Steffen Eger"
    ],
    "abstract": "Large language model (LLM) research has grown rapidly, along with increasing\nconcern about their limitations such as failures in reasoning, hallucinations,\nand limited multilingual capability. While prior reviews have addressed these\nissues, they often focus on individual limitations or consider them within the\nbroader context of evaluating overall model performance. This survey addresses\nthe gap by presenting a data-driven, semi-automated review of research on\nlimitations of LLMs (LLLMs) from 2022 to 2025, using a bottom-up approach. From\na corpus of 250,000 ACL and arXiv papers, we extract 14,648 relevant limitation\npapers using keyword filtering and LLM-based classification, validated against\nexpert labels. Using topic clustering (via two approaches, HDBSCAN+BERTopic and\nLlooM), we identify between 7 and 15 prominent types of limitations discussed\nin recent LLM research across the ACL and arXiv datasets. We find that\nLLM-related research increases nearly sixfold in ACL and nearly fifteenfold in\narXiv between 2022 and 2025, while LLLMs research grows even faster, by a\nfactor of over 12 in ACL and nearly 28 in arXiv. Reasoning remains the most\nstudied limitation, followed by generalization, hallucination, bias, and\nsecurity. The distribution of topics in the ACL dataset stays relatively stable\nover time, while arXiv shifts toward safety and controllability (with topics\nlike security risks, alignment, hallucinations, knowledge editing), and\nmultimodality between 2022 and 2025. We offer a quantitative view of trends in\nLLM limitations research and release a dataset of annotated abstracts and a\nvalidated methodology, available at:\nhttps://github.com/a-kostikova/LLLMs-Survey.",
    "pdf_url": "http://arxiv.org/pdf/2505.19240v2",
    "published": "2025-05-25T17:38:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19239v1",
    "title": "DriveX: Omni Scene Modeling for Learning Generalizable World Knowledge in Autonomous Driving",
    "authors": [
      "Chen Shi",
      "Shaoshuai Shi",
      "Kehua Sheng",
      "Bo Zhang",
      "Li Jiang"
    ],
    "abstract": "Data-driven learning has advanced autonomous driving, yet task-specific\nmodels struggle with out-of-distribution scenarios due to their narrow\noptimization objectives and reliance on costly annotated data. We present\nDriveX, a self-supervised world model that learns generalizable scene dynamics\nand holistic representations (geometric, semantic, and motion) from large-scale\ndriving videos. DriveX introduces Omni Scene Modeling (OSM), a module that\nunifies multimodal supervision-3D point cloud forecasting, 2D semantic\nrepresentation, and image generation-to capture comprehensive scene evolution.\nTo simplify learning complex dynamics, we propose a decoupled latent world\nmodeling strategy that separates world representation learning from future\nstate decoding, augmented by dynamic-aware ray sampling to enhance motion\nmodeling. For downstream adaptation, we design Future Spatial Attention (FSA),\na unified paradigm that dynamically aggregates spatiotemporal features from\nDriveX's predictions to enhance task-specific inference. Extensive experiments\ndemonstrate DriveX's effectiveness: it achieves significant improvements in 3D\nfuture point cloud prediction over prior work, while attaining state-of-the-art\nresults on diverse tasks including occupancy prediction, flow estimation, and\nend-to-end driving. These results validate DriveX's capability as a\ngeneral-purpose world model, paving the way for robust and unified autonomous\ndriving frameworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19239v1",
    "published": "2025-05-25T17:27:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19238v1",
    "title": "Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees",
    "authors": [
      "Sourav Ganguly",
      "Arnob Ghosh",
      "Kishan Panaganti",
      "Adam Wierman"
    ],
    "abstract": "Constrained decision-making is essential for designing safe policies in\nreal-world control systems, yet simulated environments often fail to capture\nreal-world adversities. We consider the problem of learning a policy that will\nmaximize the cumulative reward while satisfying a constraint, even when there\nis a mismatch between the real model and an accessible simulator/nominal model.\nIn particular, we consider the robust constrained Markov decision problem\n(RCMDP) where an agent needs to maximize the reward and satisfy the constraint\nagainst the worst possible stochastic model under the uncertainty set centered\naround an unknown nominal model. Primal-dual methods, effective for standard\nconstrained MDP (CMDP), are not applicable here because of the lack of the\nstrong duality property. Further, one cannot apply the standard robust\nvalue-iteration based approach on the composite value function either as the\nworst case models may be different for the reward value function and the\nconstraint value function. We propose a novel technique that effectively\nminimizes the constraint value function--to satisfy the constraints; on the\nother hand, when all the constraints are satisfied, it can simply maximize the\nrobust reward value function. We prove that such an algorithm finds a policy\nwith at most $\\epsilon$ sub-optimality and feasible policy after\n$O(\\epsilon^{-2})$ iterations. In contrast to the state-of-the-art method, we\ndo not need to employ a binary search, thus, we reduce the computation time by\nat least 4x for smaller value of discount factor ($\\gamma$) and by at least 6x\nfor larger value of $\\gamma$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19238v1",
    "published": "2025-05-25T17:27:06+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19237v1",
    "title": "Sensorimotor features of self-awareness in multimodal large language models",
    "authors": [
      "Iñaki Dellibarda Varela",
      "Pablo Romero-Sorozabal",
      "Diego Torricelli",
      "Gabriel Delgado-Oleas",
      "Jose Ignacio Serrano",
      "Maria Dolores del Castillo Sobrino",
      "Eduardo Rocon",
      "Manuel Cebrian"
    ],
    "abstract": "Self-awareness - the ability to distinguish oneself from the surrounding\nenvironment - underpins intelligent, autonomous behavior. Recent advances in AI\nachieve human-like performance in tasks integrating multimodal information,\nparticularly in large language models, raising interest in the embodiment\ncapabilities of AI agents on nonhuman platforms such as robots. Here, we\nexplore whether multimodal LLMs can develop self-awareness solely through\nsensorimotor experiences. By integrating a multimodal LLM into an autonomous\nmobile robot, we test its ability to achieve this capacity. We find that the\nsystem exhibits robust environmental awareness, self-recognition and predictive\nawareness, allowing it to infer its robotic nature and motion characteristics.\nStructural equation modeling reveals how sensory integration influences\ndistinct dimensions of self-awareness and its coordination with past-present\nmemory, as well as the hierarchical internal associations that drive\nself-identification. Ablation tests of sensory inputs identify critical\nmodalities for each dimension, demonstrate compensatory interactions among\nsensors and confirm the essential role of structured and episodic memory in\ncoherent reasoning. These findings demonstrate that, given appropriate sensory\ninformation about the world and itself, multimodal LLMs exhibit emergent\nself-awareness, opening the door to artificial embodied cognitive systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.19237v1",
    "published": "2025-05-25T17:26:28+00:00",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19236v1",
    "title": "Evaluating Text Creativity across Diverse Domains: A Dataset and Large Language Model Evaluator",
    "authors": [
      "Qian Cao",
      "Xiting Wang",
      "Yuzhuo Yuan",
      "Yahui Liu",
      "Fang Luo",
      "Ruihua Song"
    ],
    "abstract": "Creativity evaluation remains a challenging frontier for large language\nmodels (LLMs). Current evaluations heavily rely on inefficient and costly human\njudgments, hindering progress in enhancing machine creativity. While automated\nmethods exist, ranging from psychological testing to heuristic- or\nprompting-based approaches, they often lack generalizability or alignment with\nhuman judgment. To address these issues, in this paper, we propose a novel\npairwise-comparison framework for assessing textual creativity, leveraging\nshared contextual instructions to improve evaluation consistency. We introduce\nCreataSet, a large-scale dataset with 100K+ human-level and 1M+ synthetic\ncreative instruction-response pairs spanning diverse open-domain tasks. Through\ntraining on CreataSet, we develop an LLM-based evaluator named CrEval. CrEval\ndemonstrates remarkable superiority over existing methods in alignment with\nhuman judgments. Experimental results underscore the indispensable significance\nof integrating both human-generated and synthetic data in training highly\nrobust evaluators, and showcase the practical utility of CrEval in boosting the\ncreativity of LLMs. We will release all data, code, and models publicly soon to\nsupport further research.",
    "pdf_url": "http://arxiv.org/pdf/2505.19236v1",
    "published": "2025-05-25T17:25:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.05362v2",
    "title": "Crushing, Comminution and Fracture: Extreme Particle Deformation in Three-Dimensional Granular Aggregates",
    "authors": [
      "Debdeep Bhattacharya",
      "Davood Damircheli",
      "Robert P. Lipton"
    ],
    "abstract": "We present a high-fidelity three dimensional computational framework for\nsimulating the bulk mechanical behavior of granular aggregates composed of\ndeformable brittle grains. Departing from classical discrete element methods\n(DEM), our approach captures both inter-particle and intra-particle deformation\nusing a nonlocal continuum formulation based on peridynamics. Each grain is\nindividually meshed from level-set representations, enabling accurate modeling\nof elastic response and autonomous fracture evolution without requiring\nexplicit crack tracking or fragment reconstruction. We validate the method\nthrough benchmark simulations, including the Kalthoff-Winkler fracture test,\ncrushing of hollow spheres, and compound impact-crushing scenarios. The\nframework is further applied to large aggregates of up to 1000 sand grains of\nirregular shapes reconstructed from three dimensional X-ray computed\ntomography. Simulations reveal convergence of bulk stress response under\ncompression, suggesting the feasibility of constructing representative volume\nelements (RVEs) for multiscale modeling. Finally, we investigate the role of\ngrain geometry and topology on the macroscopic strength of the aggregate,\nproviding insight into microstructure-driven failure mechanisms. The framework\nexhibits excellent strong and weak scaling behavior, with simulations executed\non up to 1600 cores, demonstrating its suitability for high-performance\ncomputing environments and large-scale modeling.",
    "pdf_url": "http://arxiv.org/pdf/2506.05362v2",
    "published": "2025-05-25T17:19:15+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.19235v1",
    "title": "CoreMatching: A Co-adaptive Sparse Inference Framework with Token and Neuron Pruning for Comprehensive Acceleration of Vision-Language Models",
    "authors": [
      "Qinsi Wang",
      "Hancheng Ye",
      "Ming-Yu Chung",
      "Yudong Liu",
      "Yueqian Lin",
      "Martin Kuo",
      "Mingyuan Ma",
      "Jianyi Zhang",
      "Yiran Chen"
    ],
    "abstract": "Vision-Language Models (VLMs) excel across diverse tasks but suffer from high\ninference costs in time and memory. Token sparsity mitigates inefficiencies in\ntoken usage, while neuron sparsity reduces high-dimensional computations, both\noffering promising solutions to enhance efficiency. Recently, these two\nsparsity paradigms have evolved largely in parallel, fostering the prevailing\nassumption that they function independently. However, a fundamental yet\nunderexplored question remains: Do they truly operate in isolation, or is there\na deeper underlying interplay that has yet to be uncovered? In this paper, we\nconduct the first comprehensive investigation into this question. By\nintroducing and analyzing the matching mechanism between Core Neurons and Core\nTokens, we found that key neurons and tokens for inference mutually influence\nand reinforce each other. Building on this insight, we propose CoreMatching, a\nco-adaptive sparse inference framework, which leverages the synergy between\ntoken and neuron sparsity to enhance inference efficiency. Through theoretical\nanalysis and efficiency evaluations, we demonstrate that the proposed method\nsurpasses state-of-the-art baselines on ten image understanding tasks and three\nhardware devices. Notably, on the NVIDIA Titan Xp, it achieved 5x FLOPs\nreduction and a 10x overall speedup. Code is released at\nhttps://github.com/wangqinsi1/2025-ICML-CoreMatching/tree/main.",
    "pdf_url": "http://arxiv.org/pdf/2505.19235v1",
    "published": "2025-05-25T17:16:34+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19234v1",
    "title": "GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal Graph Modeling",
    "authors": [
      "Jialong Zhou",
      "Lichao Wang",
      "Xiao Yang"
    ],
    "abstract": "The emergence of large language models (LLMs) enables the development of\nintelligent agents capable of engaging in complex and multi-turn dialogues.\nHowever, multi-agent collaboration face critical safety challenges, such as\nhallucination amplification and error injection and propagation. This paper\npresents GUARDIAN, a unified method for detecting and mitigating multiple\nsafety concerns in GUARDing Intelligent Agent collaboratioNs. By modeling the\nmulti-agent collaboration process as a discrete-time temporal attributed graph,\nGUARDIAN explicitly captures the propagation dynamics of hallucinations and\nerrors. The unsupervised encoder-decoder architecture incorporating an\nincremental training paradigm, learns to reconstruct node attributes and graph\nstructures from latent embeddings, enabling the identification of anomalous\nnodes and edges with unparalleled precision. Moreover, we introduce a graph\nabstraction mechanism based on the Information Bottleneck Theory, which\ncompresses temporal interaction graphs while preserving essential patterns.\nExtensive experiments demonstrate GUARDIAN's effectiveness in safeguarding LLM\nmulti-agent collaborations against diverse safety vulnerabilities, achieving\nstate-of-the-art accuracy with efficient resource utilization.",
    "pdf_url": "http://arxiv.org/pdf/2505.19234v1",
    "published": "2025-05-25T17:15:55+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19233v2",
    "title": "RAISE: Realness Assessment for Image Synthesis and Evaluation",
    "authors": [
      "Aniruddha Mukherjee",
      "Spriha Dubey",
      "Somdyuti Paul"
    ],
    "abstract": "The rapid advancement of generative AI has enabled the creation of highly\nphotorealistic visual content, offering practical substitutes for real images\nand videos in scenarios where acquiring real data is difficult or expensive.\nHowever, reliably substituting real visual content with AI-generated\ncounterparts requires robust assessment of the perceived realness of\nAI-generated visual content, a challenging task due to its inherent subjective\nnature. To address this, we conducted a comprehensive human study evaluating\nthe perceptual realness of both real and AI-generated images, resulting in a\nnew dataset, containing images paired with subjective realness scores,\nintroduced as RAISE in this paper. Further, we develop and train multiple\nmodels on RAISE to establish baselines for realness prediction. Our\nexperimental results demonstrate that features derived from deep foundation\nvision models can effectively capture the subjective realness. RAISE thus\nprovides a valuable resource for developing robust, objective models of\nperceptual realness assessment.",
    "pdf_url": "http://arxiv.org/pdf/2505.19233v2",
    "published": "2025-05-25T17:14:43+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19232v1",
    "title": "Numerical Analysis of Damage Evolution in Open Hole CFRP Laminates Modified with Electrospun Self Healing Diels Alder Interleaves",
    "authors": [
      "Marianna Chantzi",
      "Vassilis Kostopoulos",
      "Spyridon Psarras"
    ],
    "abstract": "The study analyzes open hole carbon fiber reinforced polymer CFRP laminates\nmodified with electrospun interleaves containing Diels Alder-based self-healing\nagents. It develops a high-fidelity simulation framework to investigate the\nquasistatic tensile behavior of these composites. The study uses Hashin's\nfailure criteria to capture intralaminar damage and surface-based cohesive\ncontact interactions to model interlaminar delamination. Two interleave\nconfigurations are examined: solution electrospinning (SEP) for full thickness\ncoverage and melt electrospinning (MEP) for localized reinforcement. Results\nshow good agreement with experimental data, capturing key failure mechanisms\nlike matrix cracking, fiber breakage, and delamination. The study emphasizes\nthe importance of spatially resolved cohesive properties and meshing strategies\nin accurately simulating damage progression.",
    "pdf_url": "http://arxiv.org/pdf/2505.19232v1",
    "published": "2025-05-25T17:05:12+00:00",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mtrl-sci",
      "physics.data-an"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19231v1",
    "title": "York time in JT gravity",
    "authors": [
      "Onkar Parrikar",
      "Sunil Kumar Sake"
    ],
    "abstract": "The notion of time in general relativity must arise from an internal clock,\ni.e., a degree of freedom in the gravitational theory internal to the system\nthat can serve the role of a physical clock. One such internal notion of time\nis the York time, corresponding to constant extrinsic curvature slicing of\nspacetime. We study the Hartle-Hawking wavefunction of asymptotically $AdS_2$\nJT gravity as a function of York time. Using both canonical quantization and\nthe JT gravity path integral, we explicitly calculate this wavefunction and\nshow that it satisfies a Schrodinger equation with respect to York time. We\nfind the corresponding York Hamiltonian, which turns out to be manifestly\nHermitian. Our analysis cleanly avoids operator ordering ambiguities. The\ndependence of the wavefunction on York time should be thought of as emerging\nfrom a unitary transformation of the gravitational length basis states, and not\nfrom a physical time evolution of the state in the dual boundary theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.19231v1",
    "published": "2025-05-25T17:03:26+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.19230v1",
    "title": "Validating The Effectiveness of Electrospun Self Healing Diels Alder Interleaves to Mode I fracture resistance by Comparing Simulation Outputs with Experimental Results",
    "authors": [
      "Constantinos Rouvalis",
      "Vassilis Kostopoulos",
      "Spyridon Psarras"
    ],
    "abstract": "The predictive capabilities of the finite element approach were assessed by\ncomparing simulation outputs with experimental results, including\nload-displacement trends, damage initiation points, and delamination evolution.\nThis comparison validated the effectiveness of the self-healing interleaves and\nhighlighted the strengths and limitations of the adopted numerical framework.\nThe simulations not only reproduced key damage characteristics but also\nprovided a deeper understanding of failure mechanisms in the modified\nlaminates. This modeling strategy contributes to the broader goal of developing\nhigh-fidelity virtual testing tools for complex, multifunctional composite\nstructures used in aerospace and related industries.",
    "pdf_url": "http://arxiv.org/pdf/2505.19230v1",
    "published": "2025-05-25T16:55:01+00:00",
    "categories": [
      "physics.comp-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19229v3",
    "title": "Electric dipole polarizability constraints on neutron skin and symmetry energy",
    "authors": [
      "P. von Neumann-Cosel",
      "A. Tamii"
    ],
    "abstract": "We review the experimental knowledge on the dipole polarizability (DP) of\nnuclei and its relation to the neutron skin thickness and properties of the\nneutron-rich matter equation of state (EOS). The discussion focuses on recent\nexperiments using relativistic Coulomb excitation in inelastic proton\nscattering at extreme forward angles covering a mass range from $^{40}$Ca to\n$^{208}$Pb. Constraints on the neutron skins and the density dependence of the\nsymmetry energy are derived from systematic comparison to calculations based on\ndensity functional theory (DFT) and ab initio methods utilizing interactions\nderived from chiral effective field theory ($\\chi$EFT). The results\nconsistently favor a soft EOS around or slightly below the saturation point. An\noutlook is given on possible improvements of the precision achievable in stable\nnuclei and studies of exotic neutron-rich unstable nuclei with upcoming\nexperimental facilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.19229v3",
    "published": "2025-05-25T16:44:49+00:00",
    "categories": [
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.19228v1",
    "title": "Coronal dimmings and what they tell us about solar and stellar coronal mass ejections",
    "authors": [
      "Astrid M. Veronig",
      "Karin Dissauer",
      "Bernhard Kliem",
      "Cooper Downs",
      "Hugh S. Hudson",
      "Meng Jin",
      "Rachel Osten",
      "Tatiana Podladchikova",
      "Avijeet Prasad",
      "Jiong Qiu",
      "Barbara Thompson",
      "Hui Tian",
      "Angelos Vourlidas"
    ],
    "abstract": "Coronal dimmings associated with coronal mass ejections (CME) from the Sun\nhave gained much attention since the late 1990s when they were first observed\nin high-cadence imagery of the SOHO/EIT and Yohkoh/SXT instruments. They appear\nas localized sudden decreases of the coronal emission at extreme ultraviolet\n(EUV) and soft X-ray (SXR) wavelengths, that evolve impulsively during the\nlift-off and early expansion phase of a CME. Coronal dimmings have been\ninterpreted as \"footprints\" of the erupting flux rope and also as indicators of\nthe coronal mass loss by CMEs. However, these are only some aspects of coronal\ndimmings and how they relate to the overall CME/flare process. The goal of this\nreview is to summarize our current understanding and observational findings on\ncoronal dimmings, how they relate to CME simulations, and to discuss how they\ncan be used to provide us with a deeper insight and diagnostics of the\ntriggering of CMEs, the magnetic connectivities and coronal reconfigurations\ndue to the CME as well as the replenishment of the corona after an eruption. In\naddition, we go beyond a pure review by introducing a new, physics-driven\ncategorization of coronal dimmings based on the magnetic flux systems involved\nin the eruption process. Finally, we discuss the recent progress in studying\ncoronal dimmings on solar-like and late-type stars, and to use them as a\ndiagnostics for stellar coronal mass ejections and their properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.19228v1",
    "published": "2025-05-25T16:44:19+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19227v1",
    "title": "Scaling Laws for Gradient Descent and Sign Descent for Linear Bigram Models under Zipf's Law",
    "authors": [
      "Frederik Kunstner",
      "Francis Bach"
    ],
    "abstract": "Recent works have highlighted optimization difficulties faced by gradient\ndescent in training the first and last layers of transformer-based language\nmodels, which are overcome by optimizers such as Adam. These works suggest that\nthe difficulty is linked to the heavy-tailed distribution of words in text\ndata, where the frequency of the $k$th most frequent word $\\pi_k$ is\nproportional to $1/k$, following Zipf's law. To better understand the impact of\nthe data distribution on training performance, we study a linear bigram model\nfor next-token prediction when the tokens follow a power law $\\pi_k \\propto\n1/k^\\alpha$ parameterized by the exponent $\\alpha > 0$. We derive optimization\nscaling laws for deterministic gradient descent and sign descent as a proxy for\nAdam as a function of the exponent $\\alpha$. Existing theoretical\ninvestigations in scaling laws assume that the eigenvalues of the data decay as\na power law with exponent $\\alpha > 1$. This assumption effectively makes the\nproblem ``finite dimensional'' as most of the loss comes from a few of the\nlargest eigencomponents. In comparison, we show that the problem is more\ndifficult when the data have heavier tails. The case $\\alpha = 1$ as found in\ntext data is ``worst-case'' for gradient descent, in that the number of\niterations required to reach a small relative error scales almost linearly with\ndimension. While the performance of sign descent also depends on the dimension,\nfor Zipf-distributed data the number of iterations scales only with the\nsquare-root of the dimension, leading to a large improvement for large\nvocabularies.",
    "pdf_url": "http://arxiv.org/pdf/2505.19227v1",
    "published": "2025-05-25T16:43:51+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19226v1",
    "title": "Patient-specific forecasting method for the functionality of a balloon-expandable stent",
    "authors": [
      "Efstathios Stratakos",
      "Vassilis Kostopoulos",
      "Spyridon Psarras"
    ],
    "abstract": "This research aims to develop a method to reduce the time cost and complexity\nof balloon expandable stent simulations in cardiovascular stenting procedures\nfor Peripheral Artery Disease. The study uses stereoscopic images to construct\na cardiovascular stent and validate its mechanical response through Finite\nElement testing. A 3D model of the curved common femoral artery was constructed\nusing Computed Tomography of a patient with Critical Limb Ischemia. The fatigue\nlife cycles of the stent were estimated considering sinusoidal cyclic loading.\nThe crimping process has a negligible influence on the mechanical response,\nwith recoil and foreshortening percentages remaining static with increasing\nstent rings. The numerical results indicate the biomechanical influence of\nstent placement in a realistic vessel and compare it with literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.19226v1",
    "published": "2025-05-25T16:41:00+00:00",
    "categories": [
      "physics.med-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19225v1",
    "title": "MedITok: A Unified Tokenizer for Medical Image Synthesis and Interpretation",
    "authors": [
      "Chenglong Ma",
      "Yuanfeng Ji",
      "Jin Ye",
      "Zilong Li",
      "Chenhui Wang",
      "Junzhi Ning",
      "Wei Li",
      "Lihao Liu",
      "Qiushan Guo",
      "Tianbin Li",
      "Junjun He",
      "Hongming Shan"
    ],
    "abstract": "Advanced autoregressive models have reshaped multimodal AI. However, their\ntransformative potential in medical imaging remains largely untapped due to the\nabsence of a unified visual tokenizer -- one capable of capturing fine-grained\nvisual structures for faithful image reconstruction and realistic image\nsynthesis, as well as rich semantics for accurate diagnosis and image\ninterpretation. To this end, we present MedITok, the first unified tokenizer\ntailored for medical images, encoding both low-level structural details and\nhigh-level clinical semantics within a unified latent space. To balance these\ncompeting objectives, we introduce a novel two-stage training framework: a\nvisual representation alignment stage that cold-starts the tokenizer\nreconstruction learning with a visual semantic constraint, followed by a\ntextual semantic representation alignment stage that infuses detailed clinical\nsemantics into the latent space. Trained on the meticulously collected\nlarge-scale dataset with over 30 million medical images and 2 million\nimage-caption pairs, MedITok achieves state-of-the-art performance on more than\n30 datasets across 9 imaging modalities and 4 different tasks. By providing a\nunified token space for autoregressive modeling, MedITok supports a wide range\nof tasks in clinical diagnostics and generative healthcare applications. Model\nand code will be made publicly available at:\nhttps://github.com/Masaaki-75/meditok.",
    "pdf_url": "http://arxiv.org/pdf/2505.19225v1",
    "published": "2025-05-25T16:39:35+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19224v1",
    "title": "Nano-Raman Spectroscopy Analysis of Nanoprotuberances in MoSe2",
    "authors": [
      "Jane Elisa Guimarães",
      "Rafael Nadas",
      "Rayan Alves",
      "Wenjin Zhang",
      "Takahiko Endo",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Riichiro Saito",
      "Yasumitsu Miyata",
      "Bernardo R. A. Neves",
      "Ado Jorio"
    ],
    "abstract": "Contaminations in the formation of two-dimensional heterostructures can\nhinder or generate desired properties. Recent advancements have highlighted the\npotential of tip-enhanced Raman spectroscopy (TERS) for studying materials in\nthe 2D semiconductor class. In this work, we investigate the influence of\n50-200nm sized nanoprotuberances within a monolayer of MoSe$_2$ deposited on\nhBN using nano-Raman spectroscopy, establishing correlations between the\npresence of localized contaminations and the observed hyperspectral variations.\nA figure of merit is established for the identification of surface impurities,\nbased on MoSe$_2$ peaks ratio. Notably, new spectral peaks were identified,\nwhich are associated with the presence of nanoprotuberances and may indicate\ncontamination and oxidation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19224v1",
    "published": "2025-05-25T16:36:52+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.19223v1",
    "title": "LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language Diffusion Models",
    "authors": [
      "Fengqi Zhu",
      "Rongzhen Wang",
      "Shen Nie",
      "Xiaolu Zhang",
      "Chunwei Wu",
      "Jun Hu",
      "Jun Zhou",
      "Jianfei Chen",
      "Yankai Lin",
      "Ji-Rong Wen",
      "Chongxuan Li"
    ],
    "abstract": "While Masked Diffusion Models (MDMs), such as LLaDA, present a promising\nparadigm for language modeling, there has been relatively little effort in\naligning these models with human preferences via reinforcement learning. The\nchallenge primarily arises from the high variance in Evidence Lower Bound\n(ELBO)-based likelihood estimates required for preference optimization. To\naddress this issue, we propose Variance-Reduced Preference Optimization (VRPO),\na framework that formally analyzes the variance of ELBO estimators and derives\nbounds on both the bias and variance of preference optimization gradients.\nBuilding on this theoretical foundation, we introduce unbiased variance\nreduction strategies, including optimal Monte Carlo budget allocation and\nantithetic sampling, that significantly improve the performance of MDM\nalignment. We demonstrate the effectiveness of VRPO by applying it to LLaDA,\nand the resulting model, LLaDA 1.5, outperforms its SFT-only predecessor\nconsistently and significantly across mathematical (GSM8K +4.7), code\n(HumanEval +3.0, MBPP +1.8), and alignment benchmarks (IFEval +4.0, Arena-Hard\n+4.3). Furthermore, LLaDA 1.5 demonstrates a highly competitive mathematical\nperformance compared to strong language MDMs and ARMs. Project page:\nhttps://ml-gsai.github.io/LLaDA-1.5-Demo/.",
    "pdf_url": "http://arxiv.org/pdf/2505.19223v1",
    "published": "2025-05-25T16:36:20+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19222v1",
    "title": "Asymptotic numerical hypocoercivity of the space-time discontinuous Galerkin method for Kolmogorov equation",
    "authors": [
      "Zhaonan Dong",
      "Emmanuil H. Georgoulis",
      "Philip J. Herbert"
    ],
    "abstract": "We are concerned with discretisations of the classical Kolmogorov equation by\na standard space-time discontinuous Galerkin method. Kolmogorov equation serves\nas simple, yet rich enough in the present context, model problem for a wide\nrange of kinetic-type equations: although it involves diffusion in one of the\ntwo spatial dimensions only, the combined nature of the first order\ntransport/drift term and the degenerate diffusion are sufficient to `propagate\ndissipation' across the spatial domain in its entirety. This is a manifestation\nof the celebrated concept of hypocoercivity, a term coined and studied\nextensively by Villani in [27]. We show that the standard, classical,\nspace-time discontinuous Galerkin method, admits a corresponding hypocoercivity\nproperty at the discrete level, asymptotically for large times. To the best of\nour knowledge, this is the first result of this kind for any standard Galerkin\nscheme. This property is shown by proving one part of a discrete inf-sup-type\nstability result for the method in a family of norms dictated by a modified\nscalar product motivated by the theory in [27]. This family of norms contains\nthe full gradient of the numerical solution, thereby allowing for a full\nspectral gap/Poincar\\'e-type inequality at the discrete level, thus, showcasing\na subtle, discretisation-parameter-dependent, numerical hypocoercivity\nproperty. Further, we show that the space-time discontinuous Galerkin method is\ninf-sup stable in the family of norms containing the full gradient of the\nnumerical solution, which may be a result of independent interest.",
    "pdf_url": "http://arxiv.org/pdf/2505.19222v1",
    "published": "2025-05-25T16:36:09+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19221v1",
    "title": "Silicon nitride PIC beam formers for light sheet fluorescent microscopy",
    "authors": [
      "Alireza Tabatabaei Mashayekh",
      "Jeremy Witzens"
    ],
    "abstract": "Light sheet fluorescence microscopy (LSFM) has transformed the way we\nvisualize biological tissues in three dimensions, offering high-resolution\nimaging while minimizing photo-induced damage to the samples. Recent\nbreakthroughs in tissue-clearing methods have further improved LSFM's\ncapabilities, making it possible to study larger, intact samples in\nunprecedented detail. To overcome limitations like shallow penetration and\nlight diffraction in traditional LSFM setups, advanced beam shaping with\ndevices such as spatial light modulators and digital micromirror arrays has\nbeen utilized. These improve the resolution and the extent of tissues that can\nbe imaged. Advances such as Bessel-beam-based LSFM and lattice light sheet\nmicroscopy increase the field of view that can be imaged with low background\nnoise, but often require complex and bulky equipment. Addressing these\ncomplexities, a new approach builds on silicon nitride photonic integrated\ncircuits to create a structured light sheet in a very compact device. This\nsystem incorporates beam-steering based on wavelength control in a limited\ntuning range and enables the generation of light sheets with optimized\ncharacteristics in regard to thickness and diffraction-length limited\npenetration depth. Simulations include extensive fabrication tolerance analysis\nthat confirm the practicability of the approach, that can be straightforwardly\nextended to dual wavelength excitation. This compact, chip-based LSFM system\ncould make high-quality imaging more accessible and transform biomedical\ninstrumentation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19221v1",
    "published": "2025-05-25T16:35:50+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.19220v1",
    "title": "DeCoDe: Defer-and-Complement Decision-Making via Decoupled Concept Bottleneck Models",
    "authors": [
      "Chengbo He",
      "Bochao Zou",
      "Junliang Xing",
      "Jiansheng Chen",
      "Yuanchun Shi",
      "Huimin Ma"
    ],
    "abstract": "In human-AI collaboration, a central challenge is deciding whether the AI\nshould handle a task, be deferred to a human expert, or be addressed through\ncollaborative effort. Existing Learning to Defer approaches typically make\nbinary choices between AI and humans, neglecting their complementary strengths.\nThey also lack interpretability, a critical property in high-stakes scenarios\nwhere users must understand and, if necessary, correct the model's reasoning.\nTo overcome these limitations, we propose Defer-and-Complement Decision-Making\nvia Decoupled Concept Bottleneck Models (DeCoDe), a concept-driven framework\nfor human-AI collaboration. DeCoDe makes strategy decisions based on\nhuman-interpretable concept representations, enhancing transparency throughout\nthe decision process. It supports three flexible modes: autonomous AI\nprediction, deferral to humans, and human-AI collaborative complementarity,\nselected via a gating network that takes concept-level inputs and is trained\nusing a novel surrogate loss that balances accuracy and human effort. This\napproach enables instance-specific, interpretable, and adaptive human-AI\ncollaboration. Experiments on real-world datasets demonstrate that DeCoDe\nsignificantly outperforms AI-only, human-only, and traditional deferral\nbaselines, while maintaining strong robustness and interpretability even under\nnoisy expert annotations.",
    "pdf_url": "http://arxiv.org/pdf/2505.19220v1",
    "published": "2025-05-25T16:34:45+00:00",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19219v2",
    "title": "Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding",
    "authors": [
      "Shiyue Wang",
      "Haozheng Xu",
      "Yuhan Zhang",
      "Jingran Lin",
      "Changhong Lu",
      "Xiangfeng Wang",
      "Wenhao Li"
    ],
    "abstract": "Multi-Agent Path Finding (MAPF) is a fundamental problem in artificial\nintelligence and robotics, requiring the computation of collision-free paths\nfor multiple agents navigating from their start locations to designated goals.\nAs autonomous systems become increasingly prevalent in warehouses, urban\ntransportation, and other complex environments, MAPF has evolved from a\ntheoretical challenge to a critical enabler of real-world multi-robot\ncoordination. This comprehensive survey bridges the long-standing divide\nbetween classical algorithmic approaches and emerging learning-based methods in\nMAPF research. We present a unified framework that encompasses search-based\nmethods (including Conflict-Based Search, Priority-Based Search, and Large\nNeighborhood Search), compilation-based approaches (SAT, SMT, CSP, ASP, and MIP\nformulations), and data-driven techniques (reinforcement learning, supervised\nlearning, and hybrid strategies). Through systematic analysis of experimental\npractices across 200+ papers, we uncover significant disparities in evaluation\nmethodologies, with classical methods typically tested on larger-scale\ninstances (up to 200 by 200 grids with 1000+ agents) compared to learning-based\napproaches (predominantly 10-100 agents). We provide a comprehensive taxonomy\nof evaluation metrics, environment types, and baseline selections, highlighting\nthe need for standardized benchmarking protocols. Finally, we outline promising\nfuture directions including mixed-motive MAPF with game-theoretic\nconsiderations, language-grounded planning with large language models, and\nneural solver architectures that combine the rigor of classical methods with\nthe flexibility of deep learning. This survey serves as both a comprehensive\nreference for researchers and a practical guide for deploying MAPF solutions in\nincreasingly complex real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.19219v2",
    "published": "2025-05-25T16:28:06+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "math.CO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2508.00830v1",
    "title": "Bike-Bench: A Bicycle Design Benchmark for Generative Models with Objectives and Constraints",
    "authors": [
      "Lyle Regenwetter",
      "Yazan Abu Obaideh",
      "Fabien Chiotti",
      "Ioanna Lykourentzou",
      "Faez Ahmed"
    ],
    "abstract": "We introduce Bike-Bench, an engineering design benchmark for evaluating\ngenerative models on problems with multiple real-world objectives and\nconstraints. As generative AI's reach continues to grow, evaluating its\ncapability to understand physical laws, human guidelines, and hard constraints\ngrows increasingly important. Engineering product design lies at the\nintersection of these difficult tasks, providing new challenges for AI\ncapabilities. Bike-Bench evaluates AI models' capability to generate designs\nthat not only resemble the dataset, but meet specific performance objectives\nand constraints. To do so, Bike-Bench quantifies a variety of human-centered\nand multiphysics performance characteristics, such as aerodynamics, ergonomics,\nstructural mechanics, human-rated usability, and similarity to subjective text\nor image prompts. Supporting the benchmark are several datasets of simulation\nresults, a dataset of 10K human-rated bicycle assessments, and a\nsynthetically-generated dataset of 1.4M designs, each with a parametric,\nCAD/XML, SVG, and PNG representation. Bike-Bench is uniquely configured to\nevaluate tabular generative models, LLMs, design optimization, and hybrid\nalgorithms side-by-side. Our experiments indicate that LLMs and tabular\ngenerative models fall short of optimization and optimization-augmented\ngenerative models in both validity and optimality scores, suggesting\nsignificant room for improvement. We hope Bike-Bench, a first-of-its-kind\nbenchmark, will help catalyze progress in generative AI for constrained\nmulti-objective engineering design problems. Code, data, and other resources\nare published at decode.mit.edu/projects/bikebench/.",
    "pdf_url": "http://arxiv.org/pdf/2508.00830v1",
    "published": "2025-05-25T16:26:08+00:00",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.19218v1",
    "title": "Advancing Video Self-Supervised Learning via Image Foundation Models",
    "authors": [
      "Jingwei Wu",
      "Zhewei Huang",
      "Chang Liu"
    ],
    "abstract": "In the past decade, image foundation models (IFMs) have achieved\nunprecedented progress. However, the potential of directly using IFMs for video\nself-supervised representation learning has largely been overlooked. In this\nstudy, we propose an advancing video self-supervised learning (AdViSe)\napproach, aimed at significantly reducing the training overhead of video\nrepresentation models using pre-trained IFMs. Specifically, we first introduce\ntemporal modeling modules (ResNet3D) to IFMs, constructing a video\nrepresentation model. We then employ a video self-supervised learning approach,\nplayback rate perception, to train temporal modules while freezing the IFM\ncomponents. Experiments on UCF101 demonstrate that AdViSe achieves performance\ncomparable to state-of-the-art methods while reducing training time by\n$3.4\\times$ and GPU memory usage by $8.2\\times$. This study offers fresh\ninsights into low-cost video self-supervised learning based on pre-trained\nIFMs. Code is available at https://github.com/JingwWu/advise-video-ssl.",
    "pdf_url": "http://arxiv.org/pdf/2505.19218v1",
    "published": "2025-05-25T16:25:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19217v1",
    "title": "The Overthinker's DIET: Cutting Token Calories with DIfficulty-AwarE Training",
    "authors": [
      "Weize Chen",
      "Jiarui Yuan",
      "Tailin Jin",
      "Ning Ding",
      "Huimin Chen",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Recent large language models (LLMs) exhibit impressive reasoning but often\nover-think, generating excessively long responses that hinder efficiency. We\nintroduce DIET ( DIfficulty-AwarE Training), a framework that systematically\ncuts these \"token calories\" by integrating on-the-fly problem difficulty into\nthe reinforcement learning (RL) process. DIET dynamically adapts token\ncompression strategies by modulating token penalty strength and conditioning\ntarget lengths on estimated task difficulty, to optimize the\nperformance-efficiency trade-off. We also theoretically analyze the pitfalls of\nnaive reward weighting in group-normalized RL algorithms like GRPO, and propose\nAdvantage Weighting technique, which enables stable and effective\nimplementation of these difficulty-aware objectives. Experimental results\ndemonstrate that DIET significantly reduces token counts while simultaneously\nimproving reasoning performance. Beyond raw token reduction, we show two\ncrucial benefits largely overlooked by prior work: (1) DIET leads to superior\ninference scaling. By maintaining high per-sample quality with fewer tokens, it\nenables better scaling performance via majority voting with more samples under\nfixed computational budgets, an area where other methods falter. (2) DIET\nenhances the natural positive correlation between response length and problem\ndifficulty, ensuring verbosity is appropriately allocated, unlike many existing\ncompression methods that disrupt this relationship. Our analyses provide a\nprincipled and effective framework for developing more efficient, practical,\nand high-performing LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.19217v1",
    "published": "2025-05-25T16:24:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19216v4",
    "title": "Constitutional Consensus",
    "authors": [
      "Idit Keidar",
      "Andrew Lewis-Pye",
      "Ehud Shapiro"
    ],
    "abstract": "Consider people with smartphones operating without external authorities or\nglobal resources other than the network itself. In this setting, high-end\napplications supporting sovereign democratic digital communities, community\nbanks, and digital cooperatives require consensus executed by community\nmembers, which must be reconfigurable to support community dynamics.\n  The Constitutional Consensus protocol aims to address this need by\nintroducing constitutional self-governance to consensus: participants\ndynamically amend the participant set, supermajority threshold, and timeout\nparameter through the consensus protocol itself. We achieve this by enhancing a\nDAG-based protocol (like Cordial Miners) with participant-controlled\nreconfiguration, while also supporting both high- and low-throughput operation\n(like Morpheus), remaining quiescent when idle. This three-way synthesis\nuniquely combines: (1) constitutional amendments for self-governance, (2) a\ncryptographic DAG structure for simplicity, parallelism, and throughput, and\n(3) both high- and low-throughput operation. The protocol achieves consensus in\n$3\\delta$, maintains O(n) amortized communication complexity during high\nthroughput, and seamlessly transitions between modes. The basic protocol\n(without constitutional amendments) realizes these features in 25 lines of\npseudocode, making it one of the most concise consensus protocols for eventual\nsynchrony.",
    "pdf_url": "http://arxiv.org/pdf/2505.19216v4",
    "published": "2025-05-25T16:23:44+00:00",
    "categories": [
      "cs.DC",
      "cs.CR",
      "cs.DS",
      "cs.NI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19215v1",
    "title": "Learning the Contact Manifold for Accurate Pose Estimation During Peg-in-Hole Insertion of Complex Geometries",
    "authors": [
      "Abhay Negi",
      "Omey M. Manyar",
      "Dhanush Kumar Varma Penmetsa",
      "Satyandra K. Gupta"
    ],
    "abstract": "Contact-rich assembly of complex, non-convex parts with tight tolerances\nremains a formidable challenge. Purely model-based methods struggle with\ndiscontinuous contact dynamics, while model-free methods require vast data and\noften lack precision. In this work, we introduce a hybrid framework that uses\nonly contact-state information between a complex peg and its mating hole to\nrecover the full SE(3) pose during assembly. In under 10 seconds of online\nexecution, a sequence of primitive probing motions constructs a local contact\nsubmanifold, which is then aligned to a precomputed offline contact manifold to\nyield sub-mm and sub-degree pose estimates. To eliminate costly k-NN searches,\nwe train a lightweight network that projects sparse contact observations onto\nthe contact manifold and is 95x faster and 18% more accurate. Our method,\nevaluated on three industrially relevant geometries with clearances of 0.1-1.0\nmm, achieves a success rate of 93.3%, a 4.1x improvement compared to\nprimitive-only strategies without state estimation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19215v1",
    "published": "2025-05-25T16:21:54+00:00",
    "categories": [
      "cs.RO",
      "cs.CG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19214v2",
    "title": "Omni-Perception: Omnidirectional Collision Avoidance for Legged Locomotion in Dynamic Environments",
    "authors": [
      "Zifan Wang",
      "Teli Ma",
      "Yufei Jia",
      "Xun Yang",
      "Jiaming Zhou",
      "Wenlong Ouyang",
      "Qiang Zhang",
      "Junwei Liang"
    ],
    "abstract": "Agile locomotion in complex 3D environments requires robust spatial awareness\nto safely avoid diverse obstacles such as aerial clutter, uneven terrain, and\ndynamic agents. Depth-based perception approaches often struggle with sensor\nnoise, lighting variability, computational overhead from intermediate\nrepresentations (e.g., elevation maps), and difficulties with non-planar\nobstacles, limiting performance in unstructured environments. In contrast,\ndirect integration of LiDAR sensing into end-to-end learning for legged\nlocomotion remains underexplored. We propose Omni-Perception, an end-to-end\nlocomotion policy that achieves 3D spatial awareness and omnidirectional\ncollision avoidance by directly processing raw LiDAR point clouds. At its core\nis PD-RiskNet (Proximal-Distal Risk-Aware Hierarchical Network), a novel\nperception module that interprets spatio-temporal LiDAR data for environmental\nrisk assessment. To facilitate efficient policy learning, we develop a\nhigh-fidelity LiDAR simulation toolkit with realistic noise modeling and fast\nraycasting, compatible with platforms such as Isaac Gym, Genesis, and MuJoCo,\nenabling scalable training and effective sim-to-real transfer. Learning\nreactive control policies directly from raw LiDAR data enables the robot to\nnavigate complex environments with static and dynamic obstacles more robustly\nthan approaches relying on intermediate maps or limited sensing. We validate\nOmni-Perception through real-world experiments and extensive simulation,\ndemonstrating strong omnidirectional avoidance capabilities and superior\nlocomotion performance in highly dynamic environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.19214v2",
    "published": "2025-05-25T16:21:19+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19213v1",
    "title": "Improving Medical Reasoning with Curriculum-Aware Reinforcement Learning",
    "authors": [
      "Shaohao Rui",
      "Kaitao Chen",
      "Weijie Ma",
      "Xiaosong Wang"
    ],
    "abstract": "Recent advances in reinforcement learning with verifiable, rule-based rewards\nhave greatly enhanced the reasoning capabilities and out-of-distribution\ngeneralization of VLMs/LLMs, obviating the need for manually crafted reasoning\nchains. Despite these promising developments in the general domain, their\ntranslation to medical imaging remains limited. Current medical reinforcement\nfine-tuning (RFT) methods predominantly focus on close-ended VQA, thereby\nrestricting the model's ability to engage in world knowledge retrieval and\nflexible task adaptation. More critically, these methods fall short of\naddressing the critical clinical demand for open-ended, reasoning-intensive\ndecision-making. To bridge this gap, we introduce \\textbf{MedCCO}, the first\nmultimodal reinforcement learning framework tailored for medical VQA that\nunifies close-ended and open-ended data within a curriculum-driven RFT\nparadigm. Specifically, MedCCO is initially fine-tuned on a diverse set of\nclose-ended medical VQA tasks to establish domain-grounded reasoning\ncapabilities, and is then progressively adapted to open-ended tasks to foster\ndeeper knowledge enhancement and clinical interpretability. We validate MedCCO\nacross eight challenging medical VQA benchmarks, spanning both close-ended and\nopen-ended settings. Experimental results show that MedCCO consistently\nenhances performance and generalization, achieving a 11.4\\% accuracy gain\nacross three in-domain tasks, and a 5.7\\% improvement on five out-of-domain\nbenchmarks. These findings highlight the promise of curriculum-guided RL in\nadvancing robust, clinically-relevant reasoning in medical multimodal language\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.19213v1",
    "published": "2025-05-25T16:20:55+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19212v1",
    "title": "When Ethics and Payoffs Diverge: LLM Agents in Morally Charged Social Dilemmas",
    "authors": [
      "Steffen Backmann",
      "David Guzman Piedrahita",
      "Emanuel Tewolde",
      "Rada Mihalcea",
      "Bernhard Schölkopf",
      "Zhijing Jin"
    ],
    "abstract": "Recent advances in large language models (LLMs) have enabled their use in\ncomplex agentic roles, involving decision-making with humans or other agents,\nmaking ethical alignment a key AI safety concern. While prior work has examined\nboth LLMs' moral judgment and strategic behavior in social dilemmas, there is\nlimited understanding of how they act when moral imperatives directly conflict\nwith rewards or incentives. To investigate this, we introduce Moral Behavior in\nSocial Dilemma Simulation (MoralSim) and evaluate how LLMs behave in the\nprisoner's dilemma and public goods game with morally charged contexts. In\nMoralSim, we test a range of frontier models across both game structures and\nthree distinct moral framings, enabling a systematic examination of how LLMs\nnavigate social dilemmas in which ethical norms conflict with payoff-maximizing\nstrategies. Our results show substantial variation across models in both their\ngeneral tendency to act morally and the consistency of their behavior across\ngame types, the specific moral framing, and situational factors such as\nopponent behavior and survival risks. Crucially, no model exhibits consistently\nmoral behavior in MoralSim, highlighting the need for caution when deploying\nLLMs in agentic roles where the agent's \"self-interest\" may conflict with\nethical expectations. Our code is available at\nhttps://github.com/sbackmann/moralsim.",
    "pdf_url": "http://arxiv.org/pdf/2505.19212v1",
    "published": "2025-05-25T16:19:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19211v1",
    "title": "FedORA: Resource Allocation for Federated Learning in ORAN using Radio Intelligent Controllers",
    "authors": [
      "Abdelaziz Salama",
      "Mohammed M. H. Qazzaz",
      "Syed Danial Ali Shah",
      "Maryam Hafeez",
      "Syed Ali Zaidi"
    ],
    "abstract": "This work proposes an integrated approach for optimising Federated Learning\n(FL) communication in dynamic and heterogeneous network environments.\nLeveraging the modular flexibility of the Open Radio Access Network (ORAN)\narchitecture and multiple Radio Access Technologies (RATs), we aim to enhance\ndata transmission efficiency and mitigate client-server communication\nconstraints within the FL framework. Our system employs a two-stage\noptimisation strategy using ORAN's rApps and xApps. In the first stage,\nReinforcement Learning (RL) based rApp is used to dynamically select each\nuser's optimal Radio Access Technology (RAT), balancing energy efficiency with\nnetwork performance. In the second stage, a model-based xApp facilitates\nnear-real-time resource allocation optimisation through predefined policies to\nachieve optimal network performance. The dynamic RAT selection and resource\nallocation capabilities enabled by ORAN and multi-RAT contribute to robust\ncommunication resilience in dynamic network environments. Our approach\ndemonstrates competitive performance with low power consumption compared to\nother state-of-the-art models, showcasing its potential for real-time\napplications demanding both accuracy and efficiency. This robust and\ncomprehensive framework, enabling clients to utilise available resources\neffectively, highlights the potential for scalable, collaborative learning\napplications prioritising energy efficiency and network performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.19211v1",
    "published": "2025-05-25T16:18:04+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.19210v1",
    "title": "Towards Understanding the Mechanisms of Classifier-Free Guidance",
    "authors": [
      "Xiang Li",
      "Rongrong Wang",
      "Qing Qu"
    ],
    "abstract": "Classifier-free guidance (CFG) is a core technique powering state-of-the-art\nimage generation systems, yet its underlying mechanisms remain poorly\nunderstood. In this work, we begin by analyzing CFG in a simplified linear\ndiffusion model, where we show its behavior closely resembles that observed in\nthe nonlinear case. Our analysis reveals that linear CFG improves generation\nquality via three distinct components: (i) a mean-shift term that approximately\nsteers samples in the direction of class means, (ii) a positive Contrastive\nPrincipal Components (CPC) term that amplifies class-specific features, and\n(iii) a negative CPC term that suppresses generic features prevalent in\nunconditional data. We then verify that these insights in real-world, nonlinear\ndiffusion models: over a broad range of noise levels, linear CFG resembles the\nbehavior of its nonlinear counterpart. Although the two eventually diverge at\nlow noise levels, we discuss how the insights from the linear analysis still\nshed light on the CFG's mechanism in the nonlinear regime.",
    "pdf_url": "http://arxiv.org/pdf/2505.19210v1",
    "published": "2025-05-25T16:16:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19209v1",
    "title": "MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis Discovery via Hierarchical Search",
    "authors": [
      "Zonglin Yang",
      "Wanhao Liu",
      "Ben Gao",
      "Yujie Liu",
      "Wei Li",
      "Tong Xie",
      "Lidong Bing",
      "Wanli Ouyang",
      "Erik Cambria",
      "Dongzhan Zhou"
    ],
    "abstract": "Large language models (LLMs) have shown promise in automating scientific\nhypothesis generation, yet existing approaches primarily yield coarse-grained\nhypotheses lacking critical methodological and experimental details. We\nintroduce and formally define the novel task of fine-grained scientific\nhypothesis discovery, which entails generating detailed, experimentally\nactionable hypotheses from coarse initial research directions. We frame this as\na combinatorial optimization problem and investigate the upper limits of LLMs'\ncapacity to solve it when maximally leveraged. Specifically, we explore four\nfoundational questions: (1) how to best harness an LLM's internal heuristics to\nformulate the fine-grained hypothesis it itself would judge as the most\npromising among all the possible hypotheses it might generate, based on its own\ninternal scoring-thus defining a latent reward landscape over the hypothesis\nspace; (2) whether such LLM-judged better hypotheses exhibit stronger alignment\nwith ground-truth hypotheses; (3) whether shaping the reward landscape using an\nensemble of diverse LLMs of similar capacity yields better outcomes than\ndefining it with repeated instances of the strongest LLM among them; and (4)\nwhether an ensemble of identical LLMs provides a more reliable reward landscape\nthan a single LLM. To address these questions, we propose a hierarchical search\nmethod that incrementally proposes and integrates details into the hypothesis,\nprogressing from general concepts to specific experimental configurations. We\nshow that this hierarchical process smooths the reward landscape and enables\nmore effective optimization. Empirical evaluations on a new benchmark of\nexpert-annotated fine-grained hypotheses from recent chemistry literature show\nthat our method consistently outperforms strong baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.19209v1",
    "published": "2025-05-25T16:13:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19208v1",
    "title": "Domain and Task-Focused Example Selection for Data-Efficient Contrastive Medical Image Segmentation",
    "authors": [
      "Tyler Ward",
      "Aaron Moseley",
      "Abdullah-Al-Zubaer Imran"
    ],
    "abstract": "Segmentation is one of the most important tasks in the medical imaging\npipeline as it influences a number of image-based decisions. To be effective,\nfully supervised segmentation approaches require large amounts of manually\nannotated training data. However, the pixel-level annotation process is\nexpensive, time-consuming, and error-prone, hindering progress and making it\nchallenging to perform effective segmentations. Therefore, models must learn\nefficiently from limited labeled data. Self-supervised learning (SSL),\nparticularly contrastive learning via pre-training on unlabeled data and\nfine-tuning on limited annotations, can facilitate such limited labeled image\nsegmentation. To this end, we propose a novel self-supervised contrastive\nlearning framework for medical image segmentation, leveraging inherent\nrelationships of different images, dubbed PolyCL. Without requiring any\npixel-level annotations or unreasonable data augmentations, our PolyCL learns\nand transfers context-aware discriminant features useful for segmentation from\nan innovative surrogate, in a task-related manner. Additionally, we integrate\nthe Segment Anything Model (SAM) into our framework in two novel ways: as a\npost-processing refinement module that improves the accuracy of predicted masks\nusing bounding box prompts derived from coarse outputs, and as a propagation\nmechanism via SAM 2 that generates volumetric segmentations from a single\nannotated 2D slice. Experimental evaluations on three public computed\ntomography (CT) datasets demonstrate that PolyCL outperforms fully-supervised\nand self-supervised baselines in both low-data and cross-domain scenarios. Our\ncode is available at https://github.com/tbwa233/PolyCL.",
    "pdf_url": "http://arxiv.org/pdf/2505.19208v1",
    "published": "2025-05-25T16:11:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19207v1",
    "title": "Sensing single molecule magnets with nitrogen vacancy centers",
    "authors": [
      "Ariel Smooha",
      "Jitender Kumar",
      "Dan Yudilevich",
      "John W. Rosenberg",
      "Valentin Bayer",
      "Rainer Stöhr",
      "Andrej Denisenko",
      "Tatyana Bendikov",
      "Hengxin Tan",
      "Binghai Yan",
      "Biprajit Sarjar",
      "Joris van Slageren",
      "Amit Finkler"
    ],
    "abstract": "Single-molecule magnets (SMMs) are molecules that can function as tiny\nmagnets, with potential applications such as magnetic memory bits in storage\ndevices. Current research and development of SMMs have shown their ability to\nmaintain magnetization for a considerable amount of time at low temperatures.\nHowever, in magnetic memory applications, the molecules would probably be on a\nsurface at room temperature, and characterizing SMMs under these conditions is\nchallenging and requires specialized techniques. To this end, we use the\nnitrogen-vacancy center in diamond, which can function as a highly sensitive\nsensor of magnetic fields in a broad frequency range at the nanoscale. Here, we\nutilize single NVs to detect the magnetic noise of cobalt-based SMMs' placed on\nthe diamond surface. We investigated the noise at 296K and at 5-8K, observing a\nsignificant influence of the SMMs on the NV center relaxation times at the\ndifferent temperatures from which we infer their magnetic properties - their\nmagnetic noise spectrum density (NSD). Moreover, we witnessed the effect of an\napplied magnetic field on the SMMs' magnetic NSD. The method is useful in\ncharacterizing SMMs as memory units on surfaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.19207v1",
    "published": "2025-05-25T16:11:26+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19206v1",
    "title": "SpeakStream: Streaming Text-to-Speech with Interleaved Data",
    "authors": [
      "Richard He Bai",
      "Zijin Gu",
      "Tatiana Likhomanenko",
      "Navdeep Jaitly"
    ],
    "abstract": "The latency bottleneck of traditional text-to-speech (TTS) systems\nfundamentally hinders the potential of streaming large language models (LLMs)\nin conversational AI. These TTS systems, typically trained and inferenced on\ncomplete utterances, introduce unacceptable delays, even with optimized\ninference speeds, when coupled with streaming LLM outputs. This is particularly\nproblematic for creating responsive conversational agents where low first-token\nlatency is critical. In this paper, we present SpeakStream, a streaming TTS\nsystem that generates audio incrementally from streaming text using a\ndecoder-only architecture. SpeakStream is trained using a next-step prediction\nloss on interleaved text-speech data. During inference, it generates speech\nincrementally while absorbing streaming input text, making it particularly\nsuitable for cascaded conversational AI agents where an LLM streams text to a\nTTS system. Our experiments demonstrate that SpeakStream achieves\nstate-of-the-art latency results in terms of first-token latency while\nmaintaining the quality of non-streaming TTS systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.19206v1",
    "published": "2025-05-25T16:11:10+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19205v2",
    "title": "OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter Optimization",
    "authors": [
      "Meher Bhaskar Madiraju",
      "Meher Sai Preetam Madiraju"
    ],
    "abstract": "Hyperparameter optimization (HPO) is a critical yet challenging aspect of\nmachine learning model development, significantly impacting model performance\nand generalization. Traditional HPO methods often struggle with high\ndimensionality, complex interdependencies, and computational expense. This\npaper introduces OptiMindTune, a novel multi-agent framework designed to\nintelligently and efficiently optimize hyperparameters. OptiMindTune leverages\nthe collaborative intelligence of three specialized AI agents -- a Recommender\nAgent, an Evaluator Agent, and a Decision Agent -- each powered by Google's\nGemini models. These agents address distinct facets of the HPO problem, from\nmodel selection and hyperparameter suggestion to robust evaluation and\nstrategic decision-making. By fostering dynamic interactions and knowledge\nsharing, OptiMindTune aims to converge to optimal hyperparameter configurations\nmore rapidly and robustly than existing single-agent or monolithic approaches.\nOur framework integrates principles from advanced large language models, and\nadaptive search to achieve scalable and intelligent AutoML. We posit that this\nmulti-agent paradigm offers a promising avenue for tackling the increasing\ncomplexity of modern machine learning model tuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.19205v2",
    "published": "2025-05-25T16:05:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19204v3",
    "title": "A many-body marker for three-dimensional topological insulators with inversion symmetry",
    "authors": [
      "Federico Becca",
      "Alberto Parola"
    ],
    "abstract": "We extend the previously defined many-body marker for two-dimensional\n$\\mathbb{Z}_2$ topological insulators [I. Gilardoni {\\it et al.}, Phys. Rev. B\n{\\bf 106}, L161106 (2022)] to distinguish trivial, weak-, and\nstrong-topological insulators in three dimensions, in presence of the inversion\nsymmetry. The marker is written in term of ground-state expectation values of\nposition operators and can be employed to detect topological phases of\ninteracting systems beyond mean-field approximations, e.g., within quantum\nMonte Carlo techniques. Here, we show that the correct results of the\nnon-interacting limit are reproduced by the many-body marker.",
    "pdf_url": "http://arxiv.org/pdf/2505.19204v3",
    "published": "2025-05-25T16:05:25+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.19203v1",
    "title": "EnvSDD: Benchmarking Environmental Sound Deepfake Detection",
    "authors": [
      "Han Yin",
      "Yang Xiao",
      "Rohan Kumar Das",
      "Jisheng Bai",
      "Haohe Liu",
      "Wenwu Wang",
      "Mark D Plumbley"
    ],
    "abstract": "Audio generation systems now create very realistic soundscapes that can\nenhance media production, but also pose potential risks. Several studies have\nexamined deepfakes in speech or singing voice. However, environmental sounds\nhave different characteristics, which may make methods for detecting speech and\nsinging deepfakes less effective for real-world sounds. In addition, existing\ndatasets for environmental sound deepfake detection are limited in scale and\naudio types. To address this gap, we introduce EnvSDD, the first large-scale\ncurated dataset designed for this task, consisting of 45.25 hours of real and\n316.74 hours of fake audio. The test set includes diverse conditions to\nevaluate the generalizability, such as unseen generation models and unseen\ndatasets. We also propose an audio deepfake detection system, based on a\npre-trained audio foundation model. Results on EnvSDD show that our proposed\nsystem outperforms the state-of-the-art systems from speech and singing\ndomains.",
    "pdf_url": "http://arxiv.org/pdf/2505.19203v1",
    "published": "2025-05-25T16:02:56+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.19202v1",
    "title": "Fractional Nonlinear Schrodinger Equation Revisited",
    "authors": [
      "Morteza Nattagh Najafi",
      "Fatemeh Foroughirad"
    ],
    "abstract": "We investigate the space time fractional nonlinear Schrodinger equation\n(FNLSE) incorporating the modified Riemann Liouville derivative introduced by\nJumari. The equation is characterized by two parameters: the fractional\nderivative parameter (alpha, which captures the memory effects) and the non\nlinearity parameter a. We present analytical solutions via three complementary\napproaches: the fractional Riccati method, the Adomian decomposition method,\nand the scaling method. The FNLSE is formulated in terms of generalized\nHamiltonian and momentum operators, allowing a unified framework to explore\nvarious solution structures. A continuity equation is derived, and a general\nclass of solutions based on Mittag Leffler (ML) plane waves is proposed, from\nwhich generalized momentum and energy eigenvalues are systematically\nclassified. Utilizing a generalized Wick rotation, we establish a connection\nbetween the FNLSE and a fractional Fokker Planck equation governing a dual\nstochastic process, revealing links to Q Gaussian statistics. Through\nseparation of variables, we classify a family of solutions including chiral ML\nplane waves. Additionally, we construct Riccati type bright and dark solitons\nand assess their stability using a dynamical distance metric. As alpha changes,\ni.e. the memory effects are tuned, the bright solitons transform to dark\nsolitons, which is equivalent to focusing defocusing transition. A series\nsolution is developed via the Adomian decomposition technique, applied to both\nchiral and plane wave cases. Finally, we reduce the dimensionality of the FNLSE\nusing the scaling arguments, leading to self similar solutions, and find pure\nphase as well as Adomian type solutions. Our results highlight the rich\nanalytical landscape of the FNLSE and provide insights into its underlying\nphysical and mathematical structure.",
    "pdf_url": "http://arxiv.org/pdf/2505.19202v1",
    "published": "2025-05-25T16:02:19+00:00",
    "categories": [
      "nlin.PS",
      "cond-mat.stat-mech"
    ],
    "primary_category": "nlin.PS"
  },
  {
    "id": "http://arxiv.org/abs/2505.19201v2",
    "title": "DREAM: Drafting with Refined Target Features and Entropy-Adaptive Cross-Attention Fusion for Multimodal Speculative Decoding",
    "authors": [
      "Yunhai Hu",
      "Tianhua Xia",
      "Zining Liu",
      "Rahul Raman",
      "Xingyu Liu",
      "Bo Bao",
      "Eric Sather",
      "Vithursan Thangarasa",
      "Sai Qian Zhang"
    ],
    "abstract": "Speculative decoding (SD) has emerged as a powerful method for accelerating\nautoregressive generation in large language models (LLMs), yet its integration\ninto vision-language models (VLMs) remains underexplored. We introduce DREAM, a\nnovel speculative decoding framework tailored for VLMs that combines three key\ninnovations: (1) a cross-attention-based mechanism to inject intermediate\nfeatures from the target model into the draft model for improved alignment, (2)\nadaptive intermediate feature selection based on attention entropy to guide\nefficient draft model training, and (3) visual token compression to reduce\ndraft model latency. DREAM enables efficient, accurate, and parallel multimodal\ndecoding with significant throughput improvement. Experiments across a diverse\nset of recent popular VLMs, including LLaVA, Pixtral, SmolVLM and Gemma3,\ndemonstrate up to 3.6x speedup over conventional decoding and significantly\noutperform prior SD baselines in both inference throughput and speculative\ndraft acceptance length across a broad range of multimodal benchmarks. The code\nis publicly available at: https://github.com/SAI-Lab-NYU/DREAM.git",
    "pdf_url": "http://arxiv.org/pdf/2505.19201v2",
    "published": "2025-05-25T15:56:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19200v1",
    "title": "Running a six-qubit quantum circuit on a silicon spin qubit array",
    "authors": [
      "I. Fernández de Fuentes",
      "E. Raymenants",
      "B. Undseth",
      "O. Pietx-Casas",
      "S. Philips M. Mądzik",
      "S. L. de Snoo",
      "S. V. Amitonov",
      "L. Tryputen",
      "A. T. Schmitz",
      "A. Y. Matsuura",
      "G. Scappucci",
      "L. M. K. Vandersypen"
    ],
    "abstract": "The simplicity of encoding a qubit in the state of a single electron spin and\nthe potential for their integration into industry-standard microchips continue\nto drive the field of semiconductor-based quantum computing. However, after\ndecades of progress, validating universal logic in these platforms has advanced\nlittle beyond first-principles demonstrations of meeting the DiVincenzo\ncriteria. Case in point, and specifically for silicon-based quantum dots,\nthree-qubit algorithms have been the upper limit to date, despite the\navailability of devices containing more qubits. In this work, we fully exploit\nthe capacity of a spin-qubit array and implement a six qubit quantum circuit,\nthe largest utilizing semiconductor quantum technology. By programming the\nquantum processor, we execute quantum circuits across all permutations of\nthree, four, five, and six neighbouring qubits, demonstrating successful\nprogrammable multi-qubit operation throughout the array. The results reveal\nthat, despite the high quality of individual units, errors quickly accumulate\nwhen combining all of them in a quantum circuit. This work highlights the\nnecessity to minimize idling times through simultaneous operations, boost\ndephasing times, and consistently improve state preparation and measurement\nfidelities.",
    "pdf_url": "http://arxiv.org/pdf/2505.19200v1",
    "published": "2025-05-25T15:51:16+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19199v1",
    "title": "Pan-tropical plant functional trait variation from space",
    "authors": [
      "David Schimel",
      "Andres Baresch",
      "Adam Chlus",
      "Phil Townsend",
      "Fabian Schneider",
      "Gaia Vaglio Laurin",
      "Ben Poulter"
    ],
    "abstract": "Plant functional trait variation in tropical forests is central to predicting\necosystem responses to change. Informaiton on traits is limited relative to the\ndiversity of climate, landforms, disturbance regimes and species present. These\ntraits are central to modeled predictions of ecosystem change. We used a new\nspaceborne imagining spectrometer from the Italian Space Agency to sample\nroughly 1% of the tropical moist forest biome for traits along the Leaf\nEconomics Spectrum, as well as data to contrast them with adjacent biomes. we\nused these data to examine LES traits between tropical moist forests on three\ncontinents. Knowledge of trait variation and its environmental controls can\ninform models of ecosystem response in a changing environment, allowing\nbiological detail in models of biophysical and biogeochemical processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.19199v1",
    "published": "2025-05-25T15:47:06+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.19198v1",
    "title": "S-r-$ideals in Commutative Rings",
    "authors": [
      "Abuzer Gündüz",
      "Osama A. Naji",
      "Mehmet Özen"
    ],
    "abstract": "This article introduces the notion of $S-r-$ideals in commutative ring $H$ as\na generalization of $ r-$ideals. Let $S$ be a multiplicatively closed subset\nand $A$ an ideal of $H$ with $S\\cap A= \\emptyset$. $A$ is called $S-r-ideal$ if\n$ \\exists s\\in S$ such that for $w,z\\in H,\\; wz\\in A$ and $Ann(w)=0$, then\n$sz\\in A.$ Basic properties of $S-r-$ideals are given. It is shown that an\n$r-$ideal is always an $S-r-$ideal, and the converse is true under some\nconditions. Various characterizations of $S-r-$ideals are introduced. In\naddition, the $S-r-$ideal concept is examined under ring homomorphism,\nCartesian product, amalgamation, and trivial extension. In conclusion,\n$S-r-$ideals are studied in polynomial rings and it is investigated that when\n$A[x]$ is an $S-r-$ideal of $H[x].$",
    "pdf_url": "http://arxiv.org/pdf/2505.19198v1",
    "published": "2025-05-25T15:47:03+00:00",
    "categories": [
      "math.AC",
      "13C05, 13B30, 13B25"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19197v3",
    "title": "Structuring the Unstructured: A Multi-Agent System for Extracting and Querying Financial KPIs and Guidance",
    "authors": [
      "Chanyeol Choi",
      "Alejandro Lopez-Lira",
      "Yongjae Lee",
      "Jihoon Kwon",
      "Minjae Kim",
      "Juneha Hwang",
      "Minsoo Ha",
      "Chaewoon Kim",
      "Jaeseon Ha",
      "Suyeol Yun",
      "Jin Kim"
    ],
    "abstract": "Extracting structured and quantitative insights from unstructured financial\nfilings is essential in investment research, yet remains time-consuming and\nresource-intensive. Conventional approaches in practice rely heavily on\nlabor-intensive manual processes, limiting scalability and delaying the\nresearch workflow. In this paper, we propose an efficient and scalable method\nfor accurately extracting quantitative insights from unstructured financial\ndocuments, leveraging a multi-agent system composed of large language models.\nOur proposed multi-agent system consists of two specialized agents: the\n\\emph{Extraction Agent} and the \\emph{Text-to-SQL Agent}. The\n\\textit{Extraction Agent} automatically identifies key performance indicators\nfrom unstructured financial text, standardizes their formats, and verifies\ntheir accuracy. On the other hand, the \\textit{Text-to-SQL Agent} generates\nexecutable SQL statements from natural language queries, allowing users to\naccess structured data accurately without requiring familiarity with the\ndatabase schema. Through experiments, we demonstrate that our proposed system\neffectively transforms unstructured text into structured data accurately and\nenables precise retrieval of key information. First, we demonstrate that our\nsystem achieves approximately 95\\% accuracy in transforming financial filings\ninto structured data, matching the performance level typically attained by\nhuman annotators. Second, in a human evaluation of the retrieval task -- where\nnatural language queries are used to search information from structured data --\n91\\% of the responses were rated as correct by human evaluators. In both\nevaluations, our system generalizes well across financial document types,\nconsistently delivering reliable performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.19197v3",
    "published": "2025-05-25T15:45:46+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19196v1",
    "title": "Step-level Reward for Free in RL-based T2I Diffusion Model Fine-tuning",
    "authors": [
      "Xinyao Liao",
      "Wei Wei",
      "Xiaoye Qu",
      "Yu Cheng"
    ],
    "abstract": "Recent advances in text-to-image (T2I) diffusion model fine-tuning leverage\nreinforcement learning (RL) to align generated images with learnable reward\nfunctions. The existing approaches reformulate denoising as a Markov decision\nprocess for RL-driven optimization. However, they suffer from reward sparsity,\nreceiving only a single delayed reward per generated trajectory. This flaw\nhinders precise step-level attribution of denoising actions, undermines\ntraining efficiency. To address this, we propose a simple yet effective credit\nassignment framework that dynamically distributes dense rewards across\ndenoising steps. Specifically, we track changes in cosine similarity between\nintermediate and final images to quantify each step's contribution on\nprogressively reducing the distance to the final image. Our approach avoids\nadditional auxiliary neural networks for step-level preference modeling and\ninstead uses reward shaping to highlight denoising phases that have a greater\nimpact on image quality. Our method achieves 1.25 to 2 times higher sample\nefficiency and better generalization across four human preference reward\nfunctions, without compromising the original optimal policy.",
    "pdf_url": "http://arxiv.org/pdf/2505.19196v1",
    "published": "2025-05-25T15:43:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19195v1",
    "title": "CardioCoT: Hierarchical Reasoning for Multimodal Survival Analysis",
    "authors": [
      "Shaohao Rui",
      "Haoyang Su",
      "Jinyi Xiang",
      "Lian-Ming Wu",
      "Xiaosong Wang"
    ],
    "abstract": "Accurate prediction of major adverse cardiovascular events recurrence risk in\nacute myocardial infarction patients based on postoperative cardiac MRI and\nassociated clinical notes is crucial for precision treatment and personalized\nintervention. Existing methods primarily focus on risk stratification\ncapability while overlooking the need for intermediate robust reasoning and\nmodel interpretability in clinical practice. Moreover, end-to-end risk\nprediction using LLM/VLM faces significant challenges due to data limitations\nand modeling complexity. To bridge this gap, we propose CardioCoT, a novel\ntwo-stage hierarchical reasoning-enhanced survival analysis framework designed\nto enhance both model interpretability and predictive performance. In the first\nstage, we employ an evidence-augmented self-refinement mechanism to guide\nLLM/VLMs in generating robust hierarchical reasoning trajectories based on\nassociated radiological findings. In the second stage, we integrate the\nreasoning trajectories with imaging data for risk model training and\nprediction. CardioCoT demonstrates superior performance in MACE recurrence risk\nprediction while providing interpretable reasoning processes, offering valuable\ninsights for clinical decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2505.19195v1",
    "published": "2025-05-25T15:41:18+00:00",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19194v2",
    "title": "Curvature Dynamic Black-box Attack: revisiting adversarial robustness via dynamic curvature estimation",
    "authors": [
      "Peiran Sun"
    ],
    "abstract": "Adversarial attack reveals the vulnerability of deep learning models. For\nabout a decade, countless attack and defense methods have been proposed,\nleading to robustified classifiers and better understanding of models. Among\nthese methods, curvature-based approaches have attracted attention because it\nis assumed that high curvature may give rise to rough decision boundary.\nHowever, the most commonly used \\textit{curvature} is the curvature of loss\nfunction, scores or other parameters from within the model as opposed to\ndecision boundary curvature, since the former can be relatively easily formed\nusing second order derivative. In this paper, we propose a new query-efficient\nmethod, dynamic curvature estimation(DCE), to estimate the decision boundary\ncurvature in a black-box setting. Our approach is based on CGBA, a black-box\nadversarial attack. By performing DCE on a wide range of classifiers, we\ndiscovered, statistically, a connection between decision boundary curvature and\nadversarial robustness. We also propose a new attack method, curvature dynamic\nblack-box attack(CDBA) with improved performance using the dynamically\nestimated curvature.",
    "pdf_url": "http://arxiv.org/pdf/2505.19194v2",
    "published": "2025-05-25T15:41:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19193v2",
    "title": "Interpretable Graph Learning Over Sets of Temporally-Sparse Data",
    "authors": [
      "Andrea Zerio",
      "Maya Bechler-Speicher",
      "Maor Huri",
      "Marie Vibeke Vestergaard",
      "Ran Gilad-Bachrach",
      "Tine Jess",
      "Samir Bhatt",
      "Aleksejs Sazonovs"
    ],
    "abstract": "Real-world medical data often includes measurements from multiple signals\nthat are collected at irregular and asynchronous time intervals. For example,\ndifferent types of blood tests can be measured at different times and\nfrequencies, resulting in fragmented and unevenly scattered temporal data.\nSimilar issues of irregular sampling of different attributes occur in other\ndomains, such as monitoring of large systems using event log files or the\nspread of fake news on social networks. Effectively learning from such data\nrequires models that can handle sets of temporally sparse and heterogeneous\nsignals. In this paper, we propose Graph Mixing Additive Networks (GMAN), a\nnovel and interpretable-by-design model for learning over irregular sets of\ntemporal signals. Our method achieves state-of-the-art performance in\nreal-world medical tasks, including a 4-point increase in the AUROC score of\nin-hospital mortality prediction, compared to existing methods. We further\nshowcase GMAN's flexibility by applying it to a fake news detection task. We\ndemonstrate how its interpretability capabilities, including node-level,\ngraph-level, and subset-level importance, allow for transition phases detection\nand gaining medical insights with real-world high-stakes implications. Finally,\nwe provide theoretical insights on GMAN expressive power.",
    "pdf_url": "http://arxiv.org/pdf/2505.19193v2",
    "published": "2025-05-25T15:41:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19192v1",
    "title": "Universality of span 2-categories and the construction of 6-functor formalisms",
    "authors": [
      "Bastiaan Cnossen",
      "Tobias Lenz",
      "Sil Linskens"
    ],
    "abstract": "Given an $\\infty$-category $C$ equipped with suitable wide subcategories $I,\nP \\subset E\\subset C$, we show that the $(\\infty,2)$-category\n$\\text{S}{\\scriptstyle\\text{PAN}}_2(C,E)_{P,I}$ of higher (or iterated) spans\ndefined by Haugseng has the universal property that 2-functors\n$\\text{S}{\\scriptstyle\\text{PAN}}_2(C,E)_{P,I} \\to \\mathbb D$ correspond\nprecisely to $(I, P)$-biadjointable functors $C^\\text{op} \\to \\mathbb D$, i.e.\nfunctors $F$ where $F(i)$ for $i \\in I$ admits a left adjoint and $F(p)$ for $p\n\\in P$ admits a right adjoint satisfying various Beck-Chevalley conditions. We\nalso extend this universality to the symmetric monoidal and lax symmetric\nmonoidal settings. This provides a conceptual explanation for - and an\nindependent proof of - the Mann-Liu-Zheng construction of 6-functor formalisms\nfrom suitable functors $C^\\text{op}\\to\\text{CAlg}(\\text{Cat})$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19192v1",
    "published": "2025-05-25T15:36:12+00:00",
    "categories": [
      "math.CT",
      "math.AG",
      "math.AT",
      "18B10 (Primary) 18N60, 18N65, 18N70, 18M05 (Secondary)"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19191v1",
    "title": "Misleading through Inconsistency: A Benchmark for Political Inconsistencies Detection",
    "authors": [
      "Nursulu Sagimbayeva",
      "Ruveyda Betül Bahçeci",
      "Ingmar Weber"
    ],
    "abstract": "Inconsistent political statements represent a form of misinformation. They\nerode public trust and pose challenges to accountability, when left unnoticed.\nDetecting inconsistencies automatically could support journalists in asking\nclarification questions, thereby helping to keep politicians accountable. We\npropose the Inconsistency detection task and develop a scale of inconsistency\ntypes to prompt NLP-research in this direction. To provide a resource for\ndetecting inconsistencies in a political domain, we present a dataset of 698\nhuman-annotated pairs of political statements with explanations of the\nannotators' reasoning for 237 samples. The statements mainly come from voting\nassistant platforms such as Wahl-O-Mat in Germany and Smartvote in Switzerland,\nreflecting real-world political issues. We benchmark Large Language Models\n(LLMs) on our dataset and show that in general, they are as good as humans at\ndetecting inconsistencies, and might be even better than individual humans at\npredicting the crowd-annotated ground-truth. However, when it comes to\nidentifying fine-grained inconsistency types, none of the model have reached\nthe upper bound of performance (due to natural labeling variation), thus\nleaving room for improvement. We make our dataset and code publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.19191v1",
    "published": "2025-05-25T15:35:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19190v1",
    "title": "I2MoE: Interpretable Multimodal Interaction-aware Mixture-of-Experts",
    "authors": [
      "Jiayi Xin",
      "Sukwon Yun",
      "Jie Peng",
      "Inyoung Choi",
      "Jenna L. Ballard",
      "Tianlong Chen",
      "Qi Long"
    ],
    "abstract": "Modality fusion is a cornerstone of multimodal learning, enabling information\nintegration from diverse data sources. However, vanilla fusion methods are\nlimited by (1) inability to account for heterogeneous interactions between\nmodalities and (2) lack of interpretability in uncovering the multimodal\ninteractions inherent in the data. To this end, we propose I2MoE (Interpretable\nMultimodal Interaction-aware Mixture of Experts), an end-to-end MoE framework\ndesigned to enhance modality fusion by explicitly modeling diverse multimodal\ninteractions, as well as providing interpretation on a local and global level.\nFirst, I2MoE utilizes different interaction experts with weakly supervised\ninteraction losses to learn multimodal interactions in a data-driven way.\nSecond, I2MoE deploys a reweighting model that assigns importance scores for\nthe output of each interaction expert, which offers sample-level and\ndataset-level interpretation. Extensive evaluation of medical and general\nmultimodal datasets shows that I2MoE is flexible enough to be combined with\ndifferent fusion techniques, consistently improves task performance, and\nprovides interpretation across various real-world scenarios. Code is available\nat https://github.com/Raina-Xin/I2MoE.",
    "pdf_url": "http://arxiv.org/pdf/2505.19190v1",
    "published": "2025-05-25T15:34:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19189v2",
    "title": "POQD: Performance-Oriented Query Decomposer for Multi-vector retrieval",
    "authors": [
      "Yaoyang Liu",
      "Junlin Li",
      "Yinjun Wu",
      "Zhen Chen"
    ],
    "abstract": "Although Multi-Vector Retrieval (MVR) has achieved the state of the art on\nmany information retrieval (IR) tasks, its performance highly depends on how to\ndecompose queries into smaller pieces, say phrases or tokens. However,\noptimizing query decomposition for MVR performance is not end-to-end\ndifferentiable. Even worse, jointly solving this problem and training the\ndownstream retrieval-based systems, say RAG systems could be highly\ninefficient. To overcome these challenges, we propose Performance-Oriented\nQuery Decomposer (POQD), a novel query decomposition framework for MVR. POQD\nleverages one LLM for query decomposition and searches the optimal prompt with\nan LLM-based optimizer. We further propose an end-to-end training algorithm to\nalternatively optimize the prompt for query decomposition and the downstream\nmodels. This algorithm can achieve superior MVR performance at a reasonable\ntraining cost as our theoretical analysis suggests. POQD can be integrated\nseamlessly into arbitrary retrieval-based systems such as Retrieval-Augmented\nGeneration (RAG) systems. Extensive empirical studies on representative\nRAG-based QA tasks show that POQD outperforms existing query decomposition\nstrategies in both retrieval performance and end-to-end QA accuracy. POQD is\navailable at https://github.com/PKU-SDS-lab/POQD-ICML25.",
    "pdf_url": "http://arxiv.org/pdf/2505.19189v2",
    "published": "2025-05-25T15:31:52+00:00",
    "categories": [
      "cs.IR",
      "cs.DB"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19188v1",
    "title": "Chordless Structure: A Pathway to Simple and Expressive GNNs",
    "authors": [
      "Hongxu Pan",
      "Shuxian Hu",
      "Mo Zhou",
      "Zhibin Wang",
      "Rong Gu",
      "Chen Tian",
      "Kun Yang",
      "Sheng Zhong"
    ],
    "abstract": "Researchers have proposed various methods of incorporating more structured\ninformation into the design of Graph Neural Networks (GNNs) to enhance their\nexpressiveness. However, these methods are either computationally expensive or\nlacking in provable expressiveness. In this paper, we observe that the chords\nincrease the complexity of the graph structure while contributing little useful\ninformation in many cases. In contrast, chordless structures are more efficient\nand effective for representing the graph. Therefore, when leveraging the\ninformation of cycles, we choose to omit the chords. Accordingly, we propose a\nChordless Structure-based Graph Neural Network (CSGNN) and prove that its\nexpressiveness is strictly more powerful than the k-hop GNN (KPGNN) with\npolynomial complexity. Experimental results on real-world datasets demonstrate\nthat CSGNN outperforms existing GNNs across various graph tasks while incurring\nlower computational costs and achieving better performance than the GNNs of\n3-WL expressiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.19188v1",
    "published": "2025-05-25T15:25:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19187v1",
    "title": "LIMOPro: Reasoning Refinement for Efficient and Effective Test-time Scaling",
    "authors": [
      "Yang Xiao",
      "Jiashuo Wang",
      "Ruifeng Yuan",
      "Chunpu Xu",
      "Kaishuai Xu",
      "Wenjie Li",
      "Pengfei Liu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities through test-time scaling approaches, particularly when fine-tuned\nwith chain-of-thought (CoT) data distilled from more powerful large reasoning\nmodels (LRMs). However, these reasoning chains often contain verbose elements\nthat mirror human problem-solving, categorized as progressive reasoning (the\nessential solution development path) and functional elements (verification\nprocesses, alternative solution approaches, and error corrections). While\nprogressive reasoning is crucial, the functional elements significantly\nincrease computational demands during test-time inference. We introduce PIR\n(Perplexity-based Importance Refinement), a principled framework that\nquantitatively evaluates the importance of each reasoning step based on its\nimpact on answer prediction confidence. PIR systematically identifies and\nselectively prunes only low-importance functional steps while preserving\nprogressive reasoning components, creating optimized training data that\nmaintains the integrity of the core solution path while reducing verbosity.\nModels fine-tuned on PIR-optimized data exhibit superior test-time scaling\nproperties, generating more concise reasoning chains while achieving improved\naccuracy (+0.9\\% to +6.6\\%) with significantly reduced token usage (-3\\% to\n-41\\%) across challenging reasoning benchmarks (AIME, AMC, and GPQA Diamond).\nOur approach demonstrates strong generalizability across different model sizes,\ndata sources, and token budgets, offering a practical solution for deploying\nreasoning-capable LLMs in scenarios where efficient test-time scaling, response\ntime, and computational efficiency are valuable constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.19187v1",
    "published": "2025-05-25T15:17:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19186v1",
    "title": "PosePilot: An Edge-AI Solution for Posture Correction in Physical Exercises",
    "authors": [
      "Rushiraj Gadhvi",
      "Priyansh Desai",
      "Siddharth"
    ],
    "abstract": "Automated pose correction remains a significant challenge in AI-driven\nfitness systems, despite extensive research in activity recognition. This work\npresents PosePilot, a novel system that integrates pose recognition with\nreal-time personalized corrective feedback, overcoming the limitations of\ntraditional fitness solutions. Using Yoga, a discipline requiring precise\nspatio-temporal alignment as a case study, we demonstrate PosePilot's ability\nto analyze complex physical movements. Designed for deployment on edge devices,\nPosePilot can be extended to various at-home and outdoor exercises. We employ a\nVanilla LSTM, allowing the system to capture temporal dependencies for pose\nrecognition. Additionally, a BiLSTM with multi-head Attention enhances the\nmodel's ability to process motion contexts, selectively focusing on key limb\nangles for accurate error detection while maintaining computational efficiency.\nAs part of this work, we introduce a high-quality video dataset used for\nevaluating our models. Most importantly, PosePilot provides instant corrective\nfeedback at every stage of a movement, ensuring precise posture adjustments\nthroughout the exercise routine. The proposed approach 1) performs automatic\nhuman posture recognition, 2) provides personalized posture correction feedback\nat each instant which is crucial in Yoga, and 3) offers a lightweight and\nrobust posture correction model feasible for deploying on edge devices in\nreal-world environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.19186v1",
    "published": "2025-05-25T15:13:54+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19185v5",
    "title": "Extending the micro-Hertz detection horizons via orbital resonance effect for geocentric gravitational wave antennas",
    "authors": [
      "Qiong Deng",
      "Minghui Du",
      "Peng Xu",
      "Liang Huang",
      "Ziren Luo"
    ],
    "abstract": "The $\\mu$Hz gravitational wave band holds crucial insights into coalescing\nsupermassive black hole binaries and stochastic backgrounds but remains\ninaccessible due to technical challenges. We demonstrate that geocentric\nspace-based GW detectors (e.g., TianQin, gLISA, GADFLI) can bridge this gap by\nconsidering orbital resonance effects, circumventing the need for prohibitively\nlong baselines. When GW frequencies match with integer multiples of a\nsatellite's orbital frequency, sustained tidal forces induce cumulative orbital\ndeviations through resonant effects, which, combined with orbital modulation,\nimprove detector sensitivity by 1-2 orders of magnitude in the $\\mu$Hz band.\nConsequently, geocentric missions can detect SMBHBs across significantly\nexpanded mass-redshift parameter space and track their inspiral-merger-ringdown\nevolution. Crucially, such observations could synergize with pulsar timing\narray data of the same binaries at earlier inspiral stages, enabling\nunprecedented joint tests of strong-field gravity and binary evolution. Our\nfindings establish geocentric antennas as a cost-effective, near-term precursor\nfor unlocking the $\\mu$Hz GW astronomy.",
    "pdf_url": "http://arxiv.org/pdf/2505.19185v5",
    "published": "2025-05-25T15:13:47+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.IM"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.19184v3",
    "title": "When Two LLMs Debate, Both Think They'll Win",
    "authors": [
      "Pradyumna Shyama Prasad",
      "Minh Nhat Nguyen"
    ],
    "abstract": "Can LLMs accurately adjust their confidence when facing opposition? Building\non previous studies measuring calibration on static fact-based\nquestion-answering tasks, we evaluate Large Language Models (LLMs) in a\ndynamic, adversarial debate setting, uniquely combining two realistic factors:\n(a) a multi-turn format requiring models to update beliefs as new information\nemerges, and (b) a zero-sum structure to control for task-related uncertainty,\nsince mutual high-confidence claims imply systematic overconfidence. We\norganized 60 three-round policy debates among ten state-of-the-art LLMs, with\nmodels privately rating their confidence (0-100) in winning after each round.\nWe observed five concerning patterns: (1) Systematic overconfidence: models\nbegan debates with average initial confidence of 72.9% vs. a rational 50%\nbaseline. (2) Confidence escalation: rather than reducing confidence as debates\nprogressed, debaters increased their win probabilities, averaging 83% by the\nfinal round. (3) Mutual overestimation: in 61.7% of debates, both sides\nsimultaneously claimed >=75% probability of victory, a logical impossibility.\n(4) Persistent self-debate bias: models debating identical copies increased\nconfidence from 64.1% to 75.2%; even when explicitly informed their chance of\nwinning was exactly 50%, confidence still rose (from 50.0% to 57.1%). (5)\nMisaligned private reasoning: models' private scratchpad thoughts sometimes\ndiffered from their public confidence ratings, raising concerns about\nfaithfulness of chain-of-thought reasoning. These results suggest LLMs lack the\nability to accurately self-assess or update their beliefs in dynamic,\nmulti-turn tasks; a major concern as LLMs are now increasingly deployed without\ncareful review in assistant and agentic roles.\n  Code for our experiments is available at\nhttps://github.com/pradyuprasad/llms_overconfidence",
    "pdf_url": "http://arxiv.org/pdf/2505.19184v3",
    "published": "2025-05-25T15:06:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19183v2",
    "title": "Federated Learning: From Theory to Practice",
    "authors": [
      "A. Jung"
    ],
    "abstract": "This book offers a hands-on introduction to building and understanding\nfederated learning (FL) systems. FL enables multiple devices -- such as\nsmartphones, sensors, or local computers -- to collaboratively train machine\nlearning (ML) models, while keeping their data private and local. It is a\npowerful solution when data cannot or should not be centralized due to privacy,\nregulatory, or technical reasons. The book is designed for students, engineers,\nand researchers who want to learn how to design scalable, privacy preserving FL\nsystems. Our main focus is on personalization: enabling each device to train\nits own model while still benefiting from collaboration with relevant devices.\nThis is achieved by leveraging similarities between (the learning tasks\nassociated with) devices that are encoded by the weighted edges (or links) of a\nfederated learning network (FL network). The key idea is to represent\nreal-world FL systems as networks of devices, where nodes correspond to device\nand edges represent communication links and data similarities between them. The\ntraining of personalized models for these devices can be naturally framed as a\ndistributed optimization problem. This optimization problem is referred to as\ngeneralized total variation minimization (GTVMin) and ensures that devices with\nsimilar learning tasks learn similar model parameters. Our approach is both\nmathematically principled and practically motivated. While we introduce some\nadvanced ideas from optimization theory and graph-based learning, we aim to\nkeep the book accessible. Readers are guided through the core ideas step by\nstep, with intuitive explanations.",
    "pdf_url": "http://arxiv.org/pdf/2505.19183v2",
    "published": "2025-05-25T15:05:21+00:00",
    "categories": [
      "cs.LG",
      "stat.ML",
      "F.1.1; I.2.11; I.5.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19182v1",
    "title": "DLF: Enhancing Explicit-Implicit Interaction via Dynamic Low-Order-Aware Fusion for CTR Prediction",
    "authors": [
      "Kefan Wang",
      "Hao Wang",
      "Wei Guo",
      "Yong Liu",
      "Jianghao Lin",
      "Defu Lian",
      "Enhong Chen"
    ],
    "abstract": "Click-through rate (CTR) prediction is a critical task in online advertising\nand recommender systems, relying on effective modeling of feature interactions.\nExplicit interactions capture predefined relationships, such as inner products,\nbut often suffer from data sparsity, while implicit interactions excel at\nlearning complex patterns through non-linear transformations but lack inductive\nbiases for efficient low-order modeling. Existing two-stream architectures\nintegrate these paradigms but face challenges such as limited information\nsharing, gradient imbalance, and difficulty preserving low-order signals in\nsparse CTR data. We propose a novel framework, Dynamic Low-Order-Aware Fusion\n(DLF), which addresses these limitations through two key components: a\nResidual-Aware Low-Order Interaction Network (RLI) and a Network-Aware\nAttention Fusion Module (NAF). RLI explicitly preserves low-order signals while\nmitigating redundancy from residual connections, and NAF dynamically integrates\nexplicit and implicit representations at each layer, enhancing information\nsharing and alleviating gradient imbalance. Together, these innovations balance\nlow-order and high-order interactions, improving model expressiveness.\nExtensive experiments on public datasets demonstrate that DLF achieves\nstate-of-the-art performance in CTR prediction, addressing key limitations of\nexisting models. The implementation is publicly available at\nhttps://github.com/USTC-StarTeam/DLF.",
    "pdf_url": "http://arxiv.org/pdf/2505.19182v1",
    "published": "2025-05-25T15:05:00+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19181v2",
    "title": "Constant Harmonic Mean Curvature Foliation in Asymptotic Schwarzschild Spaces-II",
    "authors": [
      "Yaoting Gui",
      "Yuqiao Li",
      "Jun Sun"
    ],
    "abstract": "This paper extends the results of [GLS24], where the existence of a constant\nharmonic mean curvature foliation was established in the setting of a\n3-dimensional asymptotically Schwarzschild manifold. Here, we generalize this\nconstruction to higher dimensions, proving the existence of foliations by\nconstant harmonic mean curvature hypersurfaces in an asymptotically\nSchwarzschild manifold of arbitrary dimension. Furthermore, in 3 dimensional\ncase, we demonstrate the local uniqueness of this foliation under a stronger\ndecay conditions on the asymptotically Schwarzschild metric",
    "pdf_url": "http://arxiv.org/pdf/2505.19181v2",
    "published": "2025-05-25T15:03:26+00:00",
    "categories": [
      "math.DG",
      "51F99, 31E05"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19180v1",
    "title": "Higher order stray field computation on tensor product domains",
    "authors": [
      "Lukas Exl",
      "Sebastian Schaffer"
    ],
    "abstract": "We present an extension of the tensor grid method for stray field computation\non rectangular domains that incorporates higher-order basis functions. Both the\nmagnetization and the resulting magnetic field are represented using\nhigher-order B-spline bases, which allow for increased accuracy and smoothness.\nThe method employs a super-potential formulation, which circumvents the need to\nconvolve with a singular kernel. The field is represented with high accuracy as\na functional Tucker tensor, leveraging separable expansions on the tensor\nproduct domain and trained via a multilinear extension of the extreme learning\nmachine methodology. Unlike conventional grid-based methods, the proposed\nmesh-free approach allows for continuous field evaluation. Numerical\nexperiments confirm the accuracy and efficiency of the proposed method,\ndemonstrating exponential convergence of the energy and linear computational\nscaling with respect to the multilinear expansion rank.",
    "pdf_url": "http://arxiv.org/pdf/2505.19180v1",
    "published": "2025-05-25T15:01:05+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.NA",
      "math.NA",
      "65Z05"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19179v1",
    "title": "BR-ASR: Efficient and Scalable Bias Retrieval Framework for Contextual Biasing ASR in Speech LLM",
    "authors": [
      "Xun Gong",
      "Anqi Lv",
      "Zhiming Wang",
      "Huijia Zhu",
      "Yanmin Qian"
    ],
    "abstract": "While speech large language models (SpeechLLMs) have advanced standard\nautomatic speech recognition (ASR), contextual biasing for named entities and\nrare words remains challenging, especially at scale. To address this, we\npropose BR-ASR: a Bias Retrieval framework for large-scale contextual biasing\n(up to 200k entries) via two innovations: (1) speech-and-bias contrastive\nlearning to retrieve semantically relevant candidates; (2) dynamic curriculum\nlearning that mitigates homophone confusion which negatively impacts the final\nperformance. The is a general framework that allows seamless integration of the\nretrieved candidates into diverse ASR systems without fine-tuning. Experiments\non LibriSpeech test-clean/-other achieve state-of-the-art (SOTA) biased word\nerror rates (B-WER) of 2.8%/7.1% with 2000 bias words, delivering 45% relative\nimprovement over prior methods. BR-ASR also demonstrates high scalability: when\nexpanding the bias list to 200k where traditional methods generally fail, it\ninduces only 0.3 / 2.9% absolute WER / B-WER degradation with a 99.99% pruning\nrate and only 20ms latency per query on test-other.",
    "pdf_url": "http://arxiv.org/pdf/2505.19179v1",
    "published": "2025-05-25T14:57:57+00:00",
    "categories": [
      "cs.SD",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.19178v1",
    "title": "Saliency-guided Emotion Modeling: Predicting Viewer Reactions from Video Stimuli",
    "authors": [
      "Akhila Yaragoppa",
      "Siddharth"
    ],
    "abstract": "Understanding the emotional impact of videos is crucial for applications in\ncontent creation, advertising, and Human-Computer Interaction (HCI).\nTraditional affective computing methods rely on self-reported emotions, facial\nexpression analysis, and biosensing data, yet they often overlook the role of\nvisual saliency -- the naturally attention-grabbing regions within a video. In\nthis study, we utilize deep learning to introduce a novel saliency-based\napproach to emotion prediction by extracting two key features: saliency area\nand number of salient regions. Using the HD2S saliency model and OpenFace\nfacial action unit analysis, we examine the relationship between video saliency\nand viewer emotions. Our findings reveal three key insights: (1) Videos with\nmultiple salient regions tend to elicit high-valence, low-arousal emotions, (2)\nVideos with a single dominant salient region are more likely to induce\nlow-valence, high-arousal responses, and (3) Self-reported emotions often\nmisalign with facial expression-based emotion detection, suggesting limitations\nin subjective reporting. By leveraging saliency-driven insights, this work\nprovides a computationally efficient and interpretable alternative for emotion\nmodeling, with implications for content creation, personalized media\nexperiences, and affective computing research.",
    "pdf_url": "http://arxiv.org/pdf/2505.19178v1",
    "published": "2025-05-25T14:52:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19177v2",
    "title": "Regularizing effects for an elliptic system of singular equations",
    "authors": [
      "Gabriele Giannone"
    ],
    "abstract": "A system of two singular semi-linear elliptic equations, patterned after the\nSchr\\\"odinger-Maxwell system, is considered. If the reaction term of the first\nequation contains a datum $f\\in L^m$, existence of positive solutions with\nfinite energy is established for suitable ranges of $m$. In particular, the\nresults from the theory of elliptic single equations are improved. At the same\ntime, thanks to an approach based on approximation schemes and a priori\nestimates on the approximated sequences of solutions, it is shown that the\nintegrability assumptions on the datum produce higher integrability of the\nsolutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.19177v2",
    "published": "2025-05-25T14:50:59+00:00",
    "categories": [
      "math.AP",
      "35J75, 35B45 (Primary) 35J57, 35B09 (Secondary)"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19176v2",
    "title": "Assistant-Guided Mitigation of Teacher Preference Bias in LLM-as-a-Judge",
    "authors": [
      "Zhuo Liu",
      "Moxin Li",
      "Xun Deng",
      "Qifan Wang",
      "Fuli Feng"
    ],
    "abstract": "LLM-as-a-Judge employs large language models (LLMs), such as GPT-4, to\nevaluate the quality of LLM-generated responses, gaining popularity for its\ncost-effectiveness and strong alignment with human evaluations. However,\ntraining proxy judge models using evaluation data generated by powerful teacher\nmodels introduces a critical yet previously overlooked issue: teacher\npreference bias, where the proxy judge model learns a biased preference for\nresponses from the teacher model. To tackle this problem, we propose a novel\nsetting that incorporates an additional assistant model, which is not biased\ntoward the teacher model's responses, to complement the training data. Building\non this setup, we introduce AGDe-Judge, a three-stage framework designed to\ndebias from both the labels and feedbacks in the training data. Extensive\nexperiments demonstrate that AGDe-Judge effectively reduces teacher preference\nbias while maintaining strong performance across six evaluation benchmarks.\nCode is available at https://github.com/Liuz233/AGDe-Judge.",
    "pdf_url": "http://arxiv.org/pdf/2505.19176v2",
    "published": "2025-05-25T14:48:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19175v1",
    "title": "Triangle Splatting for Real-Time Radiance Field Rendering",
    "authors": [
      "Jan Held",
      "Renaud Vandeghen",
      "Adrien Deliege",
      "Abdullah Hamdi",
      "Silvio Giancola",
      "Anthony Cioppa",
      "Andrea Vedaldi",
      "Bernard Ghanem",
      "Andrea Tagliasacchi",
      "Marc Van Droogenbroeck"
    ],
    "abstract": "The field of computer graphics was revolutionized by models such as Neural\nRadiance Fields and 3D Gaussian Splatting, displacing triangles as the dominant\nrepresentation for photogrammetry. In this paper, we argue for a triangle\ncomeback. We develop a differentiable renderer that directly optimizes\ntriangles via end-to-end gradients. We achieve this by rendering each triangle\nas differentiable splats, combining the efficiency of triangles with the\nadaptive density of representations based on independent primitives. Compared\nto popular 2D and 3D Gaussian Splatting methods, our approach achieves higher\nvisual fidelity, faster convergence, and increased rendering throughput. On the\nMip-NeRF360 dataset, our method outperforms concurrent non-volumetric\nprimitives in visual fidelity and achieves higher perceptual quality than the\nstate-of-the-art Zip-NeRF on indoor scenes. Triangles are simple, compatible\nwith standard graphics stacks and GPU hardware, and highly efficient: for the\n\\textit{Garden} scene, we achieve over 2,400 FPS at 1280x720 resolution using\nan off-the-shelf mesh renderer. These results highlight the efficiency and\neffectiveness of triangle-based representations for high-quality novel view\nsynthesis. Triangles bring us closer to mesh-based optimization by combining\nclassical computer graphics with modern differentiable rendering frameworks.\nThe project page is https://trianglesplatting.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.19175v1",
    "published": "2025-05-25T14:47:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19174v1",
    "title": "Penetration Testing for System Security: Methods and Practical Approaches",
    "authors": [
      "Wei Zhang",
      "Ju Xing",
      "Xiaoqi Li"
    ],
    "abstract": "Penetration testing refers to the process of simulating hacker attacks to\nevaluate the security of information systems . This study aims not only to\nclarify the theoretical foundations of penetration testing but also to explain\nand demonstrate the complete testing process, including how network system\nadministrators may simulate attacks using various penetration testing methods.\nMethodologically, the paper outlines the five basic stages of a typical\npenetration test: intelligence gathering, vulnerability scanning, vulnerability\nexploitation, privilege escalation, and post-exploitation activities. In each\nphase, specific tools and techniques are examined in detail, along with\npractical guidance on their use. To enhance the practical relevance of the\nstudy, the paper also presents a real-life case study, illustrating how a\ncomplete penetration test is conducted in a real-world environment. Through\nthis case, readers can gain insights into the detailed procedures and applied\ntechniques, thereby deepening their understanding of the practical value of\npenetration testing. Finally, the paper summarizes the importance and necessity\nof penetration testing in securing information systems and maintaining network\nintegrity, and it explores future trends and development directions for the\nfield. Overall, the findings of this paper offer valuable references for both\nresearchers and practitioners, contributing meaningfully to the improvement of\npenetration testing practices and the advancement of cybersecurity as a whole.",
    "pdf_url": "http://arxiv.org/pdf/2505.19174v1",
    "published": "2025-05-25T14:46:00+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19173v1",
    "title": "Investigating Pedagogical Teacher and Student LLM Agents: Genetic Adaptation Meets Retrieval Augmented Generation Across Learning Style",
    "authors": [
      "Debdeep Sanyal",
      "Agniva Maiti",
      "Umakanta Maharana",
      "Dhruv Kumar",
      "Ankur Mali",
      "C. Lee Giles",
      "Murari Mandal"
    ],
    "abstract": "Effective teaching requires adapting instructional strategies to accommodate\nthe diverse cognitive and behavioral profiles of students, a persistent\nchallenge in education and teacher training. While Large Language Models (LLMs)\noffer promise as tools to simulate such complex pedagogical environments,\ncurrent simulation frameworks are limited in two key respects: (1) they often\nreduce students to static knowledge profiles, and (2) they lack adaptive\nmechanisms for modeling teachers who evolve their strategies in response to\nstudent feedback. To address these gaps, \\textbf{we introduce a novel\nsimulation framework that integrates LLM-based heterogeneous student agents\nwith a self-optimizing teacher agent}. The teacher agent's pedagogical policy\nis dynamically evolved using a genetic algorithm, allowing it to discover and\nrefine effective teaching strategies based on the aggregate performance of\ndiverse learners. In addition, \\textbf{we propose Persona-RAG}, a Retrieval\nAugmented Generation module that enables student agents to retrieve knowledge\ntailored to their individual learning styles. Persona-RAG preserves the\nretrieval accuracy of standard RAG baselines while enhancing personalization,\nan essential factor in modeling realistic educational scenarios. Through\nextensive experiments, we demonstrate how our framework supports the emergence\nof distinct and interpretable teaching patterns when interacting with varied\nstudent populations. Our results highlight the potential of LLM-driven\nsimulations to inform adaptive teaching practices and provide a testbed for\ntraining human educators in controlled, data-driven environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.19173v1",
    "published": "2025-05-25T14:45:35+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19172v4",
    "title": "Some inequalities of isoperimetric type for the c-affine surface area",
    "authors": [
      "Shiri Artstein-Avidan",
      "Arnon Chor"
    ],
    "abstract": "We study the c-affine surface area $\\Omega^c$, recently introduced by\nSch\\\"utt, Werner and Yalikun. We show that on the class of ball-bodies,\n$\\Omega^c$ is maximized by a ball of radius $\\frac{n}{n+1}$, and that a\nSantal\\'o-type inequality holds: $\\Omega^c(K) \\Omega^c(K^c) \\leq\n\\Omega^c(\\frac{1}{2} B_2^n)^2$. We also produce some more intricate\ninequalities involving the surface area.",
    "pdf_url": "http://arxiv.org/pdf/2505.19172v4",
    "published": "2025-05-25T14:44:39+00:00",
    "categories": [
      "math.MG",
      "52A40"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19171v1",
    "title": "Computational Inertia as a Conserved Quantity in Frictionless and Damped Learning Dynamics",
    "authors": [
      "Atahan Karagoz"
    ],
    "abstract": "We identify a conserved quantity in continuous-time optimization dynamics,\ntermed computational inertia. Defined as the sum of kinetic energy (parameter\nvelocity) and potential energy (loss), this scalar remains invariant under\nidealized, frictionless training. We formalize this conservation law, derive\nits analytic decay under damping and stochastic perturbations, and demonstrate\nits behavior in a synthetic system. The invariant offers a compact lens for\ninterpreting learning trajectories, and may inform theoretical tools for\nanalyzing convergence, stability, and training geometry.",
    "pdf_url": "http://arxiv.org/pdf/2505.19171v1",
    "published": "2025-05-25T14:43:57+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.20348v2",
    "title": "Cryogenic Microwave Whispering Gallery Mode Spectroscopy of Paramagnetic Impurities in High-Purity Crystalline LiF",
    "authors": [
      "Steven Samuels",
      "William Campbell",
      "Michael E. Tobar",
      "Maxim Goryachev"
    ],
    "abstract": "A low-noise cryogenic microwave spectroscopy experiment was performed on a\nhigh-purity lithium fluoride (LiF) crystal. The spectroscopy data revealed\navoided level crossing interactions in whispering gallery modes, indicative of\nelectron spin resonance (ESR) coupling with paramagnetic impurities. Analysis\nof the interaction spectra identified distinct spin systems corresponding to\n$(S = 3/2, I = 7/2)$, $(S = 1, I = 7/2)$, and $(S = 3/2, I = 0)$. The number of\nhyperfine splittings observed, together with the natural abundance of ions\npossessing the appropriate nuclear spin values, suggest that V$^{2+}$ and\nV$^{3+}$ impurities, exhibiting orthorhombic distortion, are the most likely\nsources of the narrow interaction features. This interpretation is supported by\nearlier ESR studies and established manufacturing records for LiF crystal\ngrowth. Additionally, a separate set of broader interaction points is\nconsistent with an orthorhombic model involving a $(S = 3/2, I = 0)$ spin\nsystem, although the specific impurity responsible for this interaction remains\nunidentified.",
    "pdf_url": "http://arxiv.org/pdf/2505.20348v2",
    "published": "2025-05-25T14:42:02+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19170v1",
    "title": "Efficient isogeometric Boundary Element simulation of elastic domains containing thin inclusions",
    "authors": [
      "Vincenzo Mallardo",
      "Christian Dunser",
      "Gernot Beer"
    ],
    "abstract": "This paper is concerned with the Boundary Element simulation of elastic\ndomains that contain thin inclusions that have elastic material properties,\nwhich are different to the domain. With thin inclusions we mean inclusions with\nextreme aspect ratios, i.e. where one dimension is much smaller than the other\nones. Examples of this are reinforcements in civil/mechanical engineering or\nconcrete linings in underground construction. The fact that an inclusion has an\nextreme aspect ratio poses a challenge to the numerical integration of the\narising singular integrals and novel approaches are presented to deal with it.\nSeveral examples demonstrate the efficiency and accuracy of the proposed\nmethods and show that the results are in good agreement with analytical and\nother numerical solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.19170v1",
    "published": "2025-05-25T14:39:02+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19169v3",
    "title": "EventEgoHands: Event-based Egocentric 3D Hand Mesh Reconstruction",
    "authors": [
      "Ryosei Hara",
      "Wataru Ikeda",
      "Masashi Hatano",
      "Mariko Isogawa"
    ],
    "abstract": "Reconstructing 3D hand mesh is challenging but an important task for\nhuman-computer interaction and AR/VR applications. In particular, RGB and/or\ndepth cameras have been widely used in this task. However, methods using these\nconventional cameras face challenges in low-light environments and during\nmotion blur. Thus, to address these limitations, event cameras have been\nattracting attention in recent years for their high dynamic range and high\ntemporal resolution. Despite their advantages, event cameras are sensitive to\nbackground noise or camera motion, which has limited existing studies to static\nbackgrounds and fixed cameras. In this study, we propose EventEgoHands, a novel\nmethod for event-based 3D hand mesh reconstruction in an egocentric view. Our\napproach introduces a Hand Segmentation Module that extracts hand regions,\neffectively mitigating the influence of dynamic background events. We evaluated\nour approach and demonstrated its effectiveness on the N-HOT3D dataset,\nimproving MPJPE by approximately more than 4.5 cm (43%).",
    "pdf_url": "http://arxiv.org/pdf/2505.19169v3",
    "published": "2025-05-25T14:36:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19168v1",
    "title": "Effective resistance in planar graphs and continued fractions",
    "authors": [
      "Swee Hong Chan",
      "Alex Kontorovich",
      "Igor Pak"
    ],
    "abstract": "For a simple graph $G=(V,E)$ and edge $e\\in E$, the effective resistance is\ndefined as a ratio $\\frac{\\tau(G/e)}{\\tau(G)}$, where $\\tau(G)$ denotes the\nnumber of spanning trees in $G$. We resolve the inverse problem for the\neffective resistance for planar graphs. Namely, we determine (up to a constant)\nthe smallest size of a simple planar graph with a given effective resistance.\nThe results are motivated and closely related to our previous work\narXiv:2411.18782 on Sedl\\'a\\v{c}ek's inverse problem for the number of spanning\ntrees.",
    "pdf_url": "http://arxiv.org/pdf/2505.19168v1",
    "published": "2025-05-25T14:36:42+00:00",
    "categories": [
      "math.CO",
      "math.NT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19167v2",
    "title": "Amplifying Human Creativity and Problem Solving with AI Through Generative Collective Intelligence",
    "authors": [
      "Thomas P. Kehler",
      "Scott E. Page",
      "Alex Pentland",
      "Martin Reeves",
      "John Seely Brown"
    ],
    "abstract": "We propose a general framework for human-AI collaboration that amplifies the\ndistinct capabilities of both types of intelligence. We refer to this as\nGenerative Collective Intelligence (GCI). GCI employs AI in dual roles: as\ninteractive agents and as technology that accumulates, organizes, and leverages\nknowledge. In this second role, AI creates a cognitive bridge between human\nreasoning and AI models. The AI functions as a social and cultural technology\nthat enables groups to solve complex problems through structured collaboration\nthat transcends traditional communication barriers. We argue that GCI can\novercome limitations of purely algorithmic approaches to problem-solving and\ndecision-making. We describe the mathematical foundations of GCI, based on the\nlaw of comparative judgment and minimum regret principles, and briefly\nillustrate its applications across various domains, including climate\nadaptation, healthcare transformation, and civic participation. By combining\nhuman creativity with AI's computational capabilities, GCI offers a promising\napproach to addressing complex societal challenges that neither humans nor\nmachines can solve alone.",
    "pdf_url": "http://arxiv.org/pdf/2505.19167v2",
    "published": "2025-05-25T14:33:49+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19166v2",
    "title": "JEDI: The Force of Jensen-Shannon Divergence in Disentangling Diffusion Models",
    "authors": [
      "Eric Tillmann Bill",
      "Enis Simsar",
      "Thomas Hofmann"
    ],
    "abstract": "We introduce JEDI, a test-time adaptation method that enhances subject\nseparation and compositional alignment in diffusion models without requiring\nretraining or external supervision. JEDI operates by minimizing semantic\nentanglement in attention maps using a novel Jensen-Shannon divergence based\nobjective. To improve efficiency, we leverage adversarial optimization,\nreducing the number of updating steps required. JEDI is model-agnostic and\napplicable to architectures such as Stable Diffusion 1.5 and 3.5, consistently\nimproving prompt alignment and disentanglement in complex scenes. Additionally,\nJEDI provides a lightweight, CLIP-free disentanglement score derived from\ninternal attention distributions, offering a principled benchmark for\ncompositional alignment under test-time conditions. Code and results are\navailable at https://ericbill21.github.io/JEDI/.",
    "pdf_url": "http://arxiv.org/pdf/2505.19166v2",
    "published": "2025-05-25T14:32:24+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19165v3",
    "title": "OrgAccess: A Benchmark for Role Based Access Control in Organization Scale LLMs",
    "authors": [
      "Debdeep Sanyal",
      "Umakanta Maharana",
      "Yash Sinha",
      "Hong Ming Tan",
      "Shirish Karande",
      "Mohan Kankanhalli",
      "Murari Mandal"
    ],
    "abstract": "Role-based access control (RBAC) and hierarchical structures are foundational\nto how information flows and decisions are made within virtually all\norganizations. As the potential of Large Language Models (LLMs) to serve as\nunified knowledge repositories and intelligent assistants in enterprise\nsettings becomes increasingly apparent, a critical, yet under explored,\nchallenge emerges: \\textit{can these models reliably understand and operate\nwithin the complex, often nuanced, constraints imposed by organizational\nhierarchies and associated permissions?} Evaluating this crucial capability is\ninherently difficult due to the proprietary and sensitive nature of real-world\ncorporate data and access control policies. We introduce a synthetic yet\nrepresentative \\textbf{OrgAccess} benchmark consisting of 40 distinct types of\npermissions commonly relevant across different organizational roles and levels.\nWe further create three types of permissions: 40,000 easy (1 permission),\n10,000 medium (3-permissions tuple), and 20,000 hard (5-permissions tuple) to\ntest LLMs' ability to accurately assess these permissions and generate\nresponses that strictly adhere to the specified hierarchical rules,\nparticularly in scenarios involving users with overlapping or conflicting\npermissions. Our findings reveal that even state-of-the-art LLMs struggle\nsignificantly to maintain compliance with role-based structures, even with\nexplicit instructions, with their performance degrades further when navigating\ninteractions involving two or more conflicting permissions. Specifically, even\n\\textbf{GPT-4.1 only achieves an F1-Score of 0.27 on our hardest benchmark}.\nThis demonstrates a critical limitation in LLMs' complex rule following and\ncompositional reasoning capabilities beyond standard factual or STEM-based\nbenchmarks, opening up a new paradigm for evaluating their fitness for\npractical, structured environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.19165v3",
    "published": "2025-05-25T14:30:15+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19164v2",
    "title": "BroadGen: A Framework for Generating Effective and Efficient Advertiser Broad Match Keyphrase Recommendations",
    "authors": [
      "Ashirbad Mishra",
      "Jinyu Zhao",
      "Soumik Dey",
      "Hansi Wu",
      "Binbin Li",
      "Kamesh Madduri"
    ],
    "abstract": "In the domain of sponsored search advertising, the focus of Keyphrase\nrecommendation has largely been on exact match types, which pose issues such as\nhigh management expenses, limited targeting scope, and evolving search query\npatterns. Alternatives like Broad match types can alleviate certain drawbacks\nof exact matches but present challenges like poor targeting accuracy and\nminimal supervisory signals owing to limited advertiser usage. This research\ndefines the criteria for an ideal broad match, emphasizing on both efficiency\nand effectiveness, ensuring that a significant portion of matched queries are\nrelevant. We propose BroadGen, an innovative framework that recommends\nefficient and effective broad match keyphrases by utilizing historical search\nquery data. Additionally, we demonstrate that BroadGen, through token\ncorrespondence modeling, maintains better query stability over time. BroadGen's\ncapabilities allow it to serve daily, millions of sellers at eBay with over 2.3\nbillion items.",
    "pdf_url": "http://arxiv.org/pdf/2505.19164v2",
    "published": "2025-05-25T14:25:52+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21550v1",
    "title": "Collaborative Agentic AI Needs Interoperability Across Ecosystems",
    "authors": [
      "Rishi Sharma",
      "Martijn de Vos",
      "Pradyumna Chari",
      "Ramesh Raskar",
      "Anne-Marie Kermarrec"
    ],
    "abstract": "Collaborative agentic AI is projected to transform entire industries by\nenabling AI-powered agents to autonomously perceive, plan, and act within\ndigital environments. Yet, current solutions in this field are all built in\nisolation, and we are rapidly heading toward a landscape of fragmented,\nincompatible ecosystems. In this position paper, we argue that\ninteroperability, achieved by the adoption of minimal standards, is essential\nto ensure open, secure, web-scale, and widely-adopted agentic ecosystems. To\nthis end, we devise a minimal architectural foundation for collaborative\nagentic AI, named Web of Agents, which is composed of four components:\nagent-to-agent messaging, interaction interoperability, state management, and\nagent discovery. Web of Agents adopts existing standards and reuses existing\ninfrastructure where possible. With Web of Agents, we take the first but\ncritical step toward interoperable agentic systems and offer a pragmatic path\nforward before ecosystem fragmentation becomes the norm.",
    "pdf_url": "http://arxiv.org/pdf/2505.21550v1",
    "published": "2025-05-25T14:25:08+00:00",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19163v1",
    "title": "SpokenNativQA: Multilingual Everyday Spoken Queries for LLMs",
    "authors": [
      "Firoj Alam",
      "Md Arid Hasan",
      "Shammur Absar Chowdhury"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious disciplines and tasks. However, benchmarking their capabilities with\nmultilingual spoken queries remains largely unexplored. In this study, we\nintroduce SpokenNativQA, the first multilingual and culturally aligned spoken\nquestion-answering (SQA) dataset designed to evaluate LLMs in real-world\nconversational settings. The dataset comprises approximately 33,000 naturally\nspoken questions and answers in multiple languages, including low-resource and\ndialect-rich languages, providing a robust benchmark for assessing LLM\nperformance in speech-based interactions. SpokenNativQA addresses the\nlimitations of text-based QA datasets by incorporating speech variability,\naccents, and linguistic diversity. We benchmark different ASR systems and LLMs\nfor SQA and present our findings. We released the data at\n(https://huggingface.co/datasets/QCRI/SpokenNativQA) and the experimental\nscripts at (https://llmebench.qcri.org/) for the research community.",
    "pdf_url": "http://arxiv.org/pdf/2505.19163v1",
    "published": "2025-05-25T14:22:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19162v1",
    "title": "Refining twisted bimodules associated to VOAs",
    "authors": [
      "Shun Xu",
      "Jianzhi Han"
    ],
    "abstract": "Let $V$ be a vertex operator algebra and $g$ an automorphism of $V$ of finite\norder $T$. For any $m, n \\in(1/T) \\mathbb N$, an $A_{g,n}(V)\\!-\\!A_{g,m}(V)$\nbimodule $A_{g,n, m}(V)=V/O_{g,n,m}(V)$ was defined by Dong and Jiang, where\n$O_{g,n,m}(V)$ is the sum of three certain subspaces $O_{g,n, m}^{\\prime}(V),\nO_{g,n, m}^{\\prime \\prime}(V)$ and $O_{g,n, m}^{\\prime \\prime \\prime}(V)$. In\nthis paper, we show that $O_{g,n, m}(V)=O_{g,n, m}^{\\prime}(V)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19162v1",
    "published": "2025-05-25T14:21:44+00:00",
    "categories": [
      "math.QA"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19161v1",
    "title": "Benchmarking Laparoscopic Surgical Image Restoration and Beyond",
    "authors": [
      "Jialun Pei",
      "Diandian Guo",
      "Donghui Yang",
      "Zhixi Li",
      "Yuxin Feng",
      "Long Ma",
      "Bo Du",
      "Pheng-Ann Heng"
    ],
    "abstract": "In laparoscopic surgery, a clear and high-quality visual field is critical\nfor surgeons to make accurate intraoperative decisions. However, persistent\nvisual degradation, including smoke generated by energy devices, lens fogging\nfrom thermal gradients, and lens contamination due to blood or tissue fluid\nsplashes during surgical procedures, severely impair visual clarity. These\ndegenerations can seriously hinder surgical workflow and pose risks to patient\nsafety. To systematically investigate and address various forms of surgical\nscene degradation, we introduce a real-world open-source surgical image\nrestoration dataset covering laparoscopic environments, called SurgClean, which\ninvolves multi-type image restoration tasks, e.g., desmoking, defogging, and\ndesplashing. SurgClean comprises 1,020 images with diverse degradation types\nand corresponding paired reference labels. Based on SurgClean, we establish a\nstandardized evaluation benchmark and provide performance for 22 representative\ngeneric task-specific image restoration approaches, including 12 generic and 10\ntask-specific image restoration approaches. Experimental results reveal\nsubstantial performance gaps relative to clinical requirements, highlighting a\ncritical opportunity for algorithm advancements in intelligent surgical\nrestoration. Furthermore, we explore the degradation discrepancies between\nsurgical and natural scenes from structural perception and semantic\nunderstanding perspectives, providing fundamental insights for domain-specific\nimage restoration research. Our work aims to empower the capabilities of\nrestoration algorithms to increase surgical environments and improve the\nefficiency of clinical procedures.",
    "pdf_url": "http://arxiv.org/pdf/2505.19161v1",
    "published": "2025-05-25T14:17:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19160v1",
    "title": "On certain subclasses of analytic and harmonic mappings",
    "authors": [
      "Raju Biswas"
    ],
    "abstract": "Let $\\mathcal{H}$ be the class of harmonic functions $f=h+\\overline{g}$ in\nthe unit disk $\\mathbb{D}:=\\{z\\in\\mathbb{C}:|z|<1\\}$, where $h$ and $g$ are\nanalytic in $\\mathbb{D}$ with the normalization $h(0)=g(0)=h'(0)-1=0$. Let\n$\\mathcal{D}_{\\mathcal{H}}^0(\\alpha, M)$ denote the class of functions $f=h+\n\\overline{g}\\in\\mathcal{H}$ satisfying the conditions\n$\\left|(1-\\alpha)h'(z)+\\alpha zh''(z)-1+\\alpha\\right|\\leq\nM+\\left|(1-\\alpha)g'(z)+\\alpha zg''(z)\\right|$ with $g'(0)=0$ for\n$z\\in\\mathbb{D}$, $M>0$ and $\\alpha\\in(0,1]$. In this paper, we investigate\nfundamental properties for functions in the class\n$\\mathcal{D}_{\\mathcal{H}}^0(\\alpha, M)$, such as the coefficient bounds,\ngrowth estimates, starlikeness and some other properties. Furthermore, we\nobtain the sharp bound of the second Hankel determinant of inverse logarithmic\ncoefficients for normalized analytic univalent functions $f\\in\\mathcal{P}(M)$\nin $\\mathbb{D}$ satisfying the condition $\\text{Re}\\left(zf''(z)\\right)>-M$ for\n$0<M\\leq 1/\\log4$ and $z\\in\\mathbb{D}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19160v1",
    "published": "2025-05-25T14:17:07+00:00",
    "categories": [
      "math.CV",
      "30C45, 30C50, 30C80, 31A05"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19159v1",
    "title": "A Joint Learning Framework with Feature Reconstruction and Prediction for Incomplete Satellite Image Time Series in Agricultural Semantic Segmentation",
    "authors": [
      "Yuze Wang",
      "Mariana Belgiu",
      "Haiyang Wu",
      "Dandan Zhong",
      "Yangyang Cao",
      "Chao Tao"
    ],
    "abstract": "Satellite Image Time Series (SITS) is crucial for agricultural semantic\nsegmentation. However, Cloud contamination introduces time gaps in SITS,\ndisrupting temporal dependencies and causing feature shifts, leading to\ndegraded performance of models trained on complete SITS. Existing methods\ntypically address this by reconstructing the entire SITS before prediction or\nusing data augmentation to simulate missing data. Yet, full reconstruction may\nintroduce noise and redundancy, while the data-augmented model can only handle\nlimited missing patterns, leading to poor generalization. We propose a joint\nlearning framework with feature reconstruction and prediction to address\nincomplete SITS more effectively. During training, we simulate data-missing\nscenarios using temporal masks. The two tasks are guided by both ground-truth\nlabels and the teacher model trained on complete SITS. The prediction task\nconstrains the model from selectively reconstructing critical features from\nmasked inputs that align with the teacher's temporal feature representations.\nIt reduces unnecessary reconstruction and limits noise propagation. By\nintegrating reconstructed features into the prediction task, the model avoids\nlearning shortcuts and maintains its ability to handle varied missing patterns\nand complete SITS. Experiments on SITS from Hunan Province, Western France, and\nCatalonia show that our method improves mean F1-scores by 6.93% in cropland\nextraction and 7.09% in crop classification over baselines. It also generalizes\nwell across satellite sensors, including Sentinel-2 and PlanetScope, under\nvarying temporal missing rates and model backbones.",
    "pdf_url": "http://arxiv.org/pdf/2505.19159v1",
    "published": "2025-05-25T14:15:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19158v1",
    "title": "Revealing molecule-internal mechanisms that control phonon heat transport through single-molecule junctions by a genetic algorithm",
    "authors": [
      "Matthias Blaschke",
      "Fabian Pauly"
    ],
    "abstract": "Measurements of the thermal conductance of single-molecule junctions have\nrecently been reported for the first time. It is presently unclear, how much\nthe heat transport can be controlled through molecule-internal effects. The\nsearch for molecules with lowest and highest thermal conductance is complicated\nby the gigantic chemical space. Here we describe a systematic search for\nmolecules with a low or a high phononic thermal conductance using a genetic\nalgorithm. Beyond individual structures of well performing molecules, delivered\nby the genetic algorithm, we analyze patterns and identify the different\nphysical and chemical mechanisms to suppress or enhance phonon heat flow. In\ndetail, mechanisms revealed to reduce phonon transport are related to the\nchoice of terminal linker blocks, substituents and corresponding mass disorder\nor destructive interference, meta couplings and molecule-internal twist. For a\nhigh thermal conductance, the molecules should instead be rather uniform and\nchain-like. The identified mechanisms are systematically analyzed at different\nlevels of theory, and their significance is classified. Our findings are\nexpected to be important for the emerging field of molecular phononics.",
    "pdf_url": "http://arxiv.org/pdf/2505.19158v1",
    "published": "2025-05-25T14:15:26+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.19157v2",
    "title": "Efficient and robust solvers for a cell-by-cell dual-poroelasticity problem",
    "authors": [
      "Marius Causemann",
      "Miroslav Kuchta"
    ],
    "abstract": "This paper presents a scalable and robust solver for a cell-by-cell\ndual-poroelasticity model, describing the mechanical interactions between\nbrains cells embedded in extracellular space. Explicitly representing the\ncomplex cellular shapes, the proposed approach models both intracellular and\nextracellular spaces as distinct poroelastic media, separated by a permeable\ncell membrane which allows hydrostatic and osmotic pressure-driven fluid\nexchange. Based on a three-field (displacement, total pressure, and fluid\npressure) formulation, the solver leverages the framework of norm equivalent\npreconditioning and appropriately fitted norms to ensure robustness across all\nmaterial parameters of the model. Scalability for large and complex geometries\nis achieved through efficient Algebraic Multigrid (AMG) approximations of the\npreconditioners' individual blocks. Furthermore, we accommodate diverse\nboundary conditions, including full Dirichlet boundary conditions for\ndisplacement, which we handle efficiently using the Sherman-Morrison-Woodbury\nformula. Our theoretical analysis is complemented by numerical experiments\ndemonstrating the preconditioners' robustness and performance across various\nparameters relevant to realistic scenarios, and a large scale example of\ncellular swelling on a dense reconstruction of the mouse visual cortex\nhighlights the method's potential for investigating complex physiological\nprocesses like cellular volume regulation in detailed biological structures.",
    "pdf_url": "http://arxiv.org/pdf/2505.19157v2",
    "published": "2025-05-25T14:14:45+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65F10, 35B35"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19156v1",
    "title": "Comment on \"An implementation of neural simulation-based inference for parameter estimation in ATLAS''",
    "authors": [
      "Prasanth Shyamsundar"
    ],
    "abstract": "The paper titled \"An implementation of neural simulation-based inference for\nparameter estimation in ATLAS\" by the ATLAS collaboration (arXiv:2412.01600v1\n[hep-ex]) describes the implementation of neural simulation-based inference for\na measurement analysis performed by ATLAS. The uncertainties in the analysis\narising from the finiteness of the simulated datasets are estimated using a\nnovel double-bootstrapping technique described in that work. In the present\ncomment, it is claimed and demonstrated, using a toy example, that the\ndouble-bootstrapping technique does not actually capture the aforementioned\nuncertainties.",
    "pdf_url": "http://arxiv.org/pdf/2505.19156v1",
    "published": "2025-05-25T14:10:38+00:00",
    "categories": [
      "stat.ME",
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.19155v1",
    "title": "Sparse-to-Dense: A Free Lunch for Lossless Acceleration of Video Understanding in LLMs",
    "authors": [
      "Xuan Zhang",
      "Cunxiao Du",
      "Sicheng Yu",
      "Jiawei Wu",
      "Fengzhuo Zhang",
      "Wei Gao",
      "Qian Liu"
    ],
    "abstract": "Due to the auto-regressive nature of current video large language models\n(Video-LLMs), the inference latency increases as the input sequence length\ngrows, posing challenges for the efficient processing of video sequences that\nare usually very long. We observe that during decoding, the attention scores of\nmost tokens in Video-LLMs tend to be sparse and concentrated, with only certain\ntokens requiring comprehensive full attention. Based on this insight, we\nintroduce Sparse-to-Dense (StD), a novel decoding strategy that integrates two\ndistinct modules: one leveraging sparse top-K attention and the other employing\ndense full attention. These modules collaborate to accelerate Video-LLMs\nwithout loss. The fast (sparse) model speculatively decodes multiple tokens,\nwhile the slow (dense) model verifies them in parallel. StD is a tuning-free,\nplug-and-play solution that achieves up to a 1.94$\\times$ walltime speedup in\nvideo processing. It maintains model performance while enabling a seamless\ntransition from a standard Video-LLM to a sparse Video-LLM with minimal code\nmodifications.",
    "pdf_url": "http://arxiv.org/pdf/2505.19155v1",
    "published": "2025-05-25T14:09:28+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19154v1",
    "title": "FHGS: Feature-Homogenized Gaussian Splatting",
    "authors": [
      "Q. G. Duan",
      "Benyun Zhao",
      "Mingqiao Han Yijun Huang",
      "Ben M. Chen"
    ],
    "abstract": "Scene understanding based on 3D Gaussian Splatting (3DGS) has recently\nachieved notable advances. Although 3DGS related methods have efficient\nrendering capabilities, they fail to address the inherent contradiction between\nthe anisotropic color representation of gaussian primitives and the isotropic\nrequirements of semantic features, leading to insufficient cross-view feature\nconsistency. To overcome the limitation, we proposes $\\textit{FHGS}$\n(Feature-Homogenized Gaussian Splatting), a novel 3D feature fusion framework\ninspired by physical models, which can achieve high-precision mapping of\narbitrary 2D features from pre-trained models to 3D scenes while preserving the\nreal-time rendering efficiency of 3DGS. Specifically, our $\\textit{FHGS}$\nintroduces the following innovations: Firstly, a universal feature fusion\narchitecture is proposed, enabling robust embedding of large-scale pre-trained\nmodels' semantic features (e.g., SAM, CLIP) into sparse 3D structures.\nSecondly, a non-differentiable feature fusion mechanism is introduced, which\nenables semantic features to exhibit viewpoint independent isotropic\ndistributions. This fundamentally balances the anisotropic rendering of\ngaussian primitives and the isotropic expression of features; Thirdly, a\ndual-driven optimization strategy inspired by electric potential fields is\nproposed, which combines external supervision from semantic feature fields with\ninternal primitive clustering guidance. This mechanism enables synergistic\noptimization of global semantic alignment and local structural consistency.\nMore interactive results can be accessed on: https://fhgs.cuastro.org/.",
    "pdf_url": "http://arxiv.org/pdf/2505.19154v1",
    "published": "2025-05-25T14:08:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19153v2",
    "title": "On Grothedieck rings of rank $4$ self-dual fusion categories",
    "authors": [
      "Jingcheng Dong"
    ],
    "abstract": "Let $\\C$ be a self-dual fusion category of rank $4$ which has a nontrivial\nproper fusion subcategory. We identify three new families of Grothendieck rings\nfor $\\C$: one of them is completely determined, the other two are parameterized\nby several non-negative integers.",
    "pdf_url": "http://arxiv.org/pdf/2505.19153v2",
    "published": "2025-05-25T14:07:01+00:00",
    "categories": [
      "math.QA",
      "18D10"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2506.15687v1",
    "title": "S$^2$GPT-PINNs: Sparse and Small models for PDEs",
    "authors": [
      "Yajie Ji",
      "Yanlai Chen",
      "Shawn Koohy"
    ],
    "abstract": "We propose S$^2$GPT-PINN, a sparse and small model for solving parametric\npartial differential equations (PDEs). Similar to Small Language Models (SLMs),\nS$^2$GPT-PINN is tailored to domain-specific (families of) PDEs and\ncharacterized by its compact architecture and minimal computational power.\nLeveraging a small amount of extremely high quality data via a mathematically\nrigorous greedy algorithm that is enabled by the large full-order models,\nS$^2$GPT-PINN relies on orders of magnitude less parameters than PINNs to\nachieve extremely high efficiency via two levels of customizations. The first\nis knowledge distillation via task-specific activation functions that are\ntransferred from Pre-Trained PINNs. The second is a judicious down-sampling\nwhen calculating the physics-informed loss of the network compressing the\nnumber of data sites by orders of magnitude to the size of the small model.",
    "pdf_url": "http://arxiv.org/pdf/2506.15687v1",
    "published": "2025-05-25T14:03:10+00:00",
    "categories": [
      "cs.LG",
      "stat.ML",
      "65M70, 65N99, 68U99, 68T07"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19152v1",
    "title": "RIS-Assisted Survivable Fronthaul Design in Cell-Free Massive MIMO System",
    "authors": [
      "Zhenyu Li",
      "Özlem Tuğfe Demir",
      "Emil Björnson",
      "Cicek Cavdar"
    ],
    "abstract": "This paper investigates the application of reconfigurable intelligent\nsurfaces (RISs) to improve fronthaul link survivability in cell-free massive\nMIMO (CF mMIMO) systems. To enhance the fronthaul survivability, two\ncomplementary mechanisms are considered. Firstly, RIS is set to provide\nreliable line-of-sight (LOS) connectivity and enhance the mmWave backup link.\nSecondly, a resource-sharing scheme that leverages redundant cable capacity\nthrough neighboring master access points (APs) to guarantee availability is\nconsidered. We formulate the redundant capacity minimization problem as a\nRIS-assisted multi-user MIMO rate control optimization problem, developing a\nnovel solution that combines a modified weighted minimum mean square error\n(WMMSE) algorithm for precoding design with Riemannian gradient descent for RIS\nphase shift optimization. Our numerical evaluations show that RIS reduces the\nrequired redundant capacity by 65.6% compared to the no RIS case to reach a 99%\nsurvivability. The results show that the most substantial gains of RIS occur\nduring complete outages of the direct disconnected master AP-CPU channel. These\nresults demonstrate RIS's potential to significantly enhance fronthaul\nreliability while minimizing infrastructure costs in next-generation wireless\nnetworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19152v1",
    "published": "2025-05-25T14:00:28+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19151v1",
    "title": "SRDiffusion: Accelerate Video Diffusion Inference via Sketching-Rendering Cooperation",
    "authors": [
      "Shenggan Cheng",
      "Yuanxin Wei",
      "Lansong Diao",
      "Yong Liu",
      "Bujiao Chen",
      "Lianghua Huang",
      "Yu Liu",
      "Wenyuan Yu",
      "Jiangsu Du",
      "Wei Lin",
      "Yang You"
    ],
    "abstract": "Leveraging the diffusion transformer (DiT) architecture, models like Sora,\nCogVideoX and Wan have achieved remarkable progress in text-to-video,\nimage-to-video, and video editing tasks. Despite these advances,\ndiffusion-based video generation remains computationally intensive, especially\nfor high-resolution, long-duration videos. Prior work accelerates its inference\nby skipping computation, usually at the cost of severe quality degradation. In\nthis paper, we propose SRDiffusion, a novel framework that leverages\ncollaboration between large and small models to reduce inference cost. The\nlarge model handles high-noise steps to ensure semantic and motion fidelity\n(Sketching), while the smaller model refines visual details in low-noise steps\n(Rendering). Experimental results demonstrate that our method outperforms\nexisting approaches, over 3$\\times$ speedup for Wan with nearly no quality loss\nfor VBench, and 2$\\times$ speedup for CogVideoX. Our method is introduced as a\nnew direction orthogonal to existing acceleration strategies, offering a\npractical solution for scalable video generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19151v1",
    "published": "2025-05-25T13:58:52+00:00",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19150v3",
    "title": "A High-Quality Thermoelectric Material Database with Self-Consistent ZT Filtering",
    "authors": [
      "Byungki Ryu",
      "Ji Hui Son",
      "Sungjin Park",
      "Jaywan Chung",
      "Hye-Jin Lim",
      "SuJi Park",
      "Yujeong Do",
      "SuDong Park"
    ],
    "abstract": "This study presents a curated thermoelectric material database, teMatDb,\nconstructed by digitizing literature-reported data. It includes\ntemperature-dependent thermoelectric properties (TEPs), Seebeck coefficient,\nelectrical resistivity, thermal conductivity, and figure of merit (ZT), along\nwith metadata on materials and their corresponding publications. A\nself-consistent ZT (Sc-ZT) filter set was developed to measure ZT errors by\ncomparing reported ZT's from figures with ZT's recalculated from digitized\nTEPs. Using this Sc-ZT protocol, we generated tMatDb272, comprising 14,717\ntemperature-property pairs from 272 high-quality TEP sets across 262\npublications. The method identifies various types of ZT errors, such as\nresolution error, publication bias, ZT overestimation, interpolation and\nextrapolation error, and digitization noise, and excludes inconsistent samples\nfrom the dataset. teMatDb272 and the Sc-ZT filtering framework offer a robust\ndataset for data-driven and machine-learning-based materials design, device\nmodeling, and future thermoelectric research.",
    "pdf_url": "http://arxiv.org/pdf/2505.19150v3",
    "published": "2025-05-25T13:56:29+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.19149v1",
    "title": "MIND-Edit: MLLM Insight-Driven Editing via Language-Vision Projection",
    "authors": [
      "Shuyu Wang",
      "Weiqi Li",
      "Qian Wang",
      "Shijie Zhao",
      "Jian Zhang"
    ],
    "abstract": "Recent advances in AI-generated content (AIGC) have significantly accelerated\nimage editing techniques, driving increasing demand for diverse and\nfine-grained edits. Despite these advances, existing image editing methods\nstill face challenges in achieving high precision and semantic accuracy in\ncomplex scenarios. Recent studies address this issue by incorporating\nmultimodal large language models (MLLMs) into image editing pipelines. However,\ncurrent MLLM-based methods mainly rely on interpreting textual instructions,\nleaving the intrinsic visual understanding of large models largely unexplored,\nthus resulting in insufficient alignment between textual semantics and visual\noutcomes. To overcome these limitations, we propose MIND-Edit, an end-to-end\nimage-editing framework integrating pretrained diffusion model with MLLM.\nMIND-Edit introduces two complementary strategies: (1) a text instruction\noptimization strategy that clarifies ambiguous user instructions based on\nsemantic reasoning from the MLLM, and (2) an MLLM insight-driven editing\nstrategy that explicitly leverages the intrinsic visual understanding\ncapability of the MLLM to infer editing intent and guide the diffusion process\nvia generated visual embeddings. Furthermore, we propose a joint training\napproach to effectively integrate both strategies, allowing them to reinforce\neach other for more accurate instruction interpretation and visually coherent\nedits aligned with user intent. Extensive experiments demonstrate that\nMIND-Edit outperforms state-of-the-art image editing methods in both\nquantitative metrics and visual quality, particularly under complex and\nchallenging scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.19149v1",
    "published": "2025-05-25T13:54:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19148v1",
    "title": "DISTA-Net: Dynamic Closely-Spaced Infrared Small Target Unmixing",
    "authors": [
      "Shengdong Han",
      "Shangdong Yang",
      "Xin Zhang",
      "Yuxuan Li",
      "Xiang Li",
      "Jian Yang",
      "Ming-Ming Cheng",
      "Yimian Dai"
    ],
    "abstract": "Resolving closely-spaced small targets in dense clusters presents a\nsignificant challenge in infrared imaging, as the overlapping signals hinder\nprecise determination of their quantity, sub-pixel positions, and radiation\nintensities. While deep learning has advanced the field of infrared small\ntarget detection, its application to closely-spaced infrared small targets has\nnot yet been explored. This gap exists primarily due to the complexity of\nseparating superimposed characteristics and the lack of an open-source\ninfrastructure. In this work, we propose the Dynamic Iterative Shrinkage\nThresholding Network (DISTA-Net), which reconceptualizes traditional sparse\nreconstruction within a dynamic framework. DISTA-Net adaptively generates\nconvolution weights and thresholding parameters to tailor the reconstruction\nprocess in real time. To the best of our knowledge, DISTA-Net is the first deep\nlearning model designed specifically for the unmixing of closely-spaced\ninfrared small targets, achieving superior sub-pixel detection accuracy.\nMoreover, we have established the first open-source ecosystem to foster further\nresearch in this field. This ecosystem comprises three key components: (1)\nCSIST-100K, a publicly available benchmark dataset; (2) CSO-mAP, a custom\nevaluation metric for sub-pixel detection; and (3) GrokCSO, an open-source\ntoolkit featuring DISTA-Net and other models. Our code and dataset are\navailable at https://github.com/GrokCV/GrokCSO.",
    "pdf_url": "http://arxiv.org/pdf/2505.19148v1",
    "published": "2025-05-25T13:52:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19147v2",
    "title": "Shifting AI Efficiency From Model-Centric to Data-Centric Compression",
    "authors": [
      "Xuyang Liu",
      "Zichen Wen",
      "Shaobo Wang",
      "Junjie Chen",
      "Zhishan Tao",
      "Yubo Wang",
      "Xiangqi Jin",
      "Chang Zou",
      "Yiyu Wang",
      "Chenfei Liao",
      "Xu Zheng",
      "Honggang Chen",
      "Weijia Li",
      "Xuming Hu",
      "Conghui He",
      "Linfeng Zhang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) and multi-modal LLMs\n(MLLMs) has historically relied on model-centric scaling through increasing\nparameter counts from millions to hundreds of billions to drive performance\ngains. However, as we approach hardware limits on model size, the dominant\ncomputational bottleneck has fundamentally shifted to the quadratic cost of\nself-attention over long token sequences, now driven by ultra-long text\ncontexts, high-resolution images, and extended videos. In this position paper,\n\\textbf{we argue that the focus of research for efficient AI is shifting from\nmodel-centric compression to data-centric compression}. We position token\ncompression as the new frontier, which improves AI efficiency via reducing the\nnumber of tokens during model training or inference. Through comprehensive\nanalysis, we first examine recent developments in long-context AI across\nvarious domains and establish a unified mathematical framework for existing\nmodel efficiency strategies, demonstrating why token compression represents a\ncrucial paradigm shift in addressing long-context overhead. Subsequently, we\nsystematically review the research landscape of token compression, analyzing\nits fundamental benefits and identifying its compelling advantages across\ndiverse scenarios. Furthermore, we provide an in-depth analysis of current\nchallenges in token compression research and outline promising future\ndirections. Ultimately, our work aims to offer a fresh perspective on AI\nefficiency, synthesize existing research, and catalyze innovative developments\nto address the challenges that increasing context lengths pose to the AI\ncommunity's advancement.",
    "pdf_url": "http://arxiv.org/pdf/2505.19147v2",
    "published": "2025-05-25T13:51:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19146v2",
    "title": "Design of a Wearable Parallel Electrical Impedance Imaging System for Healthcare",
    "authors": [
      "Bowen Li",
      "Zekun Chen",
      "Xuefei Chen",
      "Luhao Zhang",
      "Shili Liang"
    ],
    "abstract": "A wireless wearable Electrical Impedance Tomography (EIT) system has been\ndeveloped utilizing the AD5933 chip to achieve real-time imaging of lung\nrespiration. The system employs a voltage excitation method tailored to human\nimpedance characteristics, injecting current by applying a known voltage and\nmeasuring the resulting current through the body. Additionally, specific\nmeasures have been implemented to effectively suppress signal oscillations and\nleakage currents caused by parasitic capacitances. To enhance data acquisition\nspeed, the system employs five parallel AD5933 units, with multiple techniques\nimplemented to ensure high synchronization during simultaneous measurements.\nPerformance testing shows that the system achieves a signal-to-noise ratio\ngreater than 50 dB, a relative standard deviation below 0.3%, and a reciprocity\nerror under 0.8%. Imaging experiments using a water tank phantom, human lungs\nduring breathing, and a resting human calf further demonstrate that this\nportable EIT system can accurately measure biological tissues with high\nprecision and low cost.",
    "pdf_url": "http://arxiv.org/pdf/2505.19146v2",
    "published": "2025-05-25T13:46:18+00:00",
    "categories": [
      "physics.med-ph",
      "eess.SP"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19145v2",
    "title": "Do Large Language Models (Really) Need Statistical Foundations?",
    "authors": [
      "Weijie Su"
    ],
    "abstract": "Large language models (LLMs) represent a new paradigm for processing\nunstructured data, with applications across an unprecedented range of domains.\nIn this paper, we address, through two arguments, whether the development and\napplication of LLMs would genuinely benefit from foundational contributions\nfrom the statistics discipline. First, we argue affirmatively, beginning with\nthe observation that LLMs are inherently statistical models due to their\nprofound data dependency and stochastic generation processes, where statistical\ninsights are naturally essential for handling variability and uncertainty.\nSecond, we argue that the persistent black-box nature of LLMs -- stemming from\ntheir immense scale, architectural complexity, and development practices often\nprioritizing empirical performance over theoretical interpretability -- renders\nclosed-form or purely mechanistic analyses generally intractable, thereby\nnecessitating statistical approaches due to their flexibility and often\ndemonstrated effectiveness. To substantiate these arguments, the paper outlines\nseveral research areas -- including alignment, watermarking, uncertainty\nquantification, evaluation, and data mixture optimization -- where statistical\nmethodologies are critically needed and are already beginning to make valuable\ncontributions. We conclude with a discussion suggesting that statistical\nresearch concerning LLMs will likely form a diverse ``mosaic'' of specialized\ntopics rather than deriving from a single unifying theory, and highlighting the\nimportance of timely engagement by our statistics community in LLM research.",
    "pdf_url": "http://arxiv.org/pdf/2505.19145v2",
    "published": "2025-05-25T13:44:47+00:00",
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.19144v1",
    "title": "ADGSyn: Dual-Stream Learning for Efficient Anticancer Drug Synergy Prediction",
    "authors": [
      "Yuxuan Nie",
      "Yutong Song",
      "Hong Peng"
    ],
    "abstract": "Drug combinations play a critical role in cancer therapy by significantly\nenhancing treatment efficacy and overcoming drug resistance. However, the\ncombinatorial space of possible drug pairs grows exponentially, making\nexperimental screening highly impractical. Therefore, developing efficient\ncomputational methods to predict promising drug combinations and guide\nexperimental validation is of paramount importance. In this work, we propose\nADGSyn, an innovative method for predicting drug synergy. The key components of\nour approach include: (1) shared projection matrices combined with attention\nmechanisms to enable cross-drug feature alignment; (2) automatic mixed\nprecision (AMP)-optimized graph operations that reduce memory consumption by\n40\\% while accelerating training speed threefold; and (3) residual pathways\nstabilized by LayerNorm to ensure stable gradient propagation during training.\nEvaluated on the O'Neil dataset containing 13,243 drug--cell line combinations,\nADGSyn demonstrates superior performance over eight baseline methods. Moreover,\nthe framework supports full-batch processing of up to 256 molecular graphs on a\nsingle GPU, setting a new standard for efficiency in drug synergy prediction\nwithin the field of computational oncology.",
    "pdf_url": "http://arxiv.org/pdf/2505.19144v1",
    "published": "2025-05-25T13:40:13+00:00",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.20347v1",
    "title": "SeRL: Self-Play Reinforcement Learning for Large Language Models with Limited Data",
    "authors": [
      "Wenkai Fang",
      "Shunyu Liu",
      "Yang Zhou",
      "Kongcheng Zhang",
      "Tongya Zheng",
      "Kaixuan Chen",
      "Mingli Song",
      "Dacheng Tao"
    ],
    "abstract": "Recent advances have demonstrated the effectiveness of Reinforcement Learning\n(RL) in improving the reasoning capabilities of Large Language Models (LLMs).\nHowever, existing works inevitably rely on high-quality instructions and\nverifiable rewards for effective training, both of which are often difficult to\nobtain in specialized domains. In this paper, we propose Self-play\nReinforcement Learning(SeRL) to bootstrap LLM training with limited initial\ndata. Specifically, SeRL comprises two complementary modules: self-instruction\nand self-rewarding. The former module generates additional instructions based\non the available data at each training step, employing robust online filtering\nstrategies to ensure instruction quality, diversity, and difficulty. The latter\nmodule introduces a simple yet effective majority-voting mechanism to estimate\nresponse rewards for additional instructions, eliminating the need for external\nannotations. Finally, SeRL performs conventional RL based on the generated\ndata, facilitating iterative self-play learning. Extensive experiments on\nvarious reasoning benchmarks and across different LLM backbones demonstrate\nthat the proposed SeRL yields results superior to its counterparts and achieves\nperformance on par with those obtained by high-quality data with verifiable\nrewards. Our code is available at https://github.com/wantbook-book/SeRL.",
    "pdf_url": "http://arxiv.org/pdf/2505.20347v1",
    "published": "2025-05-25T13:28:04+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19143v2",
    "title": "The preduals of Banach space valued Bourgain-Morrey spaces",
    "authors": [
      "Tengfei Bai",
      "Pengfei Guo",
      "Jingshi Xu"
    ],
    "abstract": "Let $X$ be a Banach space such that there exists a Banach space $^\\ast X$ and\n$ ( ^\\ast X )^ \\ast = X $. In this paper, we introduce $X$-valued\nBourgain-Morrey spaces. We show that $^\\ast X$-valued block spaces are the\npredual of $X$-valued Bourgain-Morrey spaces. We obtain the completeness,\ndenseness and Fatou property of $^\\ast X$-valued block spaces. We give a\ndescription of the dual of $X$-valued Bourgain-Morrey spaces and conclude the\nreflexivity of these spaces. The boundedness of powered Hardy-Littlewood\nmaximal operator in vector valued block spaces is obtained.",
    "pdf_url": "http://arxiv.org/pdf/2505.19143v2",
    "published": "2025-05-25T13:23:55+00:00",
    "categories": [
      "math.FA",
      "math.CA",
      "42B25, 42B35, 46E30"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19142v1",
    "title": "Extreme value statistics in a continuous time branching process: a pedagogical primer",
    "authors": [
      "Satya N. Majumdar",
      "Alberto Rosso"
    ],
    "abstract": "We study a continuous time branching process where an individual splits into\ntwo daughters with rate b and dies with rate a, starting from a single\nindividual at t=0. We show that the model can be mapped exactly to a random\nwalk problem where the population size N(t) performs a random walk on a\npositive semi-infinite lattice. The hopping rate of this random walker out of a\nsite labelled n is proportional to n, i.e., the walker gets more and more\n`agitated' as it moves further and further away from the origin--we call this\nan `agitated random walk' (ARW). We demonstrate that this random walk problem\nis particularly suitable to obtain exact explicit results on the extreme value\nstatistics, namely, on the distribution of the maximal population size M(t)=\n\\max_{0\\tau\\le t}[N(\\tau)] up to time t. This extreme value distribution\ndisplays markedly different behaviors in the three phases: (i) subcritical\n(b<a) (ii) critical (b=a) and (iii) supercritical (b>a). In the subcritical and\ncritical phases , Q(L,t) becomes independent of time t for large t and the\nstationary distribution Q(L, \\infty) decays to zero with increasing L,\nrespectively exponentially (subcritical) and algebraically (critical). For\nfinite but large t, the distribution at the critical point exhibits a scaling\nform Q(L,t)\\sim f_c(L/{at})/L^2 where the scaling function f_c(z) has a\nnontrivial shape that we compute analytically. In the supercritical phase, the\ndistribution Q(L,t) has a `fluid' part that becomes independent of t for large\nt and a `condensate' part (a delta peak centered at e^{(b-a)t}) which gets\ndisconnected from the `fluid' part and moves rapidly to \\infty as time\nincreases. We also verify our analytical predictions via numerical simulations\nfinding excellent agreement.",
    "pdf_url": "http://arxiv.org/pdf/2505.19142v1",
    "published": "2025-05-25T13:23:37+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.19141v2",
    "title": "S-unit equations in modules and linear-exponential Diophantine equations",
    "authors": [
      "Ruiwen Dong",
      "Doron Shafrir"
    ],
    "abstract": "Let $T$ be a positive integer, and $\\mathcal{M}$ be a finitely presented\nmodule over the Laurent polynomial ring $\\mathbb{Z}_{/T}[X_1^{\\pm}, \\ldots,\nX_N^{\\pm}]$. We consider S-unit equations over $\\mathcal{M}$: these are\nequations of the form $x_1 m_1 + \\cdots + x_K m_K = m_0$, where the variables\n$x_1, \\ldots, x_K$ range over the set of monomials (with coefficient 1) of\n$\\mathbb{Z}_{/T}[X_1^{\\pm}, \\ldots, X_N^{\\pm}]$. When $T$ is a power of a prime\nnumber $p$, we show that the solution set of an S-unit equation over\n$\\mathcal{M}$ is effectively $p$-normal in the sense of Derksen and Masser\n(2015), generalizing their result on S-unit equations in fields of prime\ncharacteristic. When $T$ is an arbitrary positive integer, we show that\ndeciding whether an S-unit equation over $\\mathcal{M}$ admits a solution is\nTuring equivalent to solving a system of linear-exponential Diophantine\nequations, whose base contains the prime divisors of $T$. Combined with a\nrecent result of Karimov, Luca, Nieuwveld, Ouaknine and Worrell (2025), this\nyields decidability when $T$ has at most two distinct prime divisors. This also\nshows that proving either decidability or undecidability in the case of\narbitrary $T$ would entail major breakthroughs in number theory.\n  We mention some potential applications of our results, such as deciding\nSubmonoid Membership in wreath products of the form $\\mathbb{Z}_{/p^a q^b} \\wr\n\\mathbb{Z}^d$, as well as progressing towards solving the Skolem problem in\nrings whose additive group is torsion. More connections in these directions\nwill be explored in follow up papers.",
    "pdf_url": "http://arxiv.org/pdf/2505.19141v2",
    "published": "2025-05-25T13:22:39+00:00",
    "categories": [
      "math.NT",
      "cs.FL"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19139v1",
    "title": "The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework",
    "authors": [
      "Feiran Liu",
      "Yuzhe Zhang",
      "Xinyi Huang",
      "Yinan Peng",
      "Xinfeng Li",
      "Lixu Wang",
      "Yutong Shen",
      "Ranjie Duan",
      "Simeng Qin",
      "Xiaojun Jia",
      "Qingsong Wen",
      "Wei Dong"
    ],
    "abstract": "Our research reveals a new privacy risk associated with the vision-language\nmodel (VLM) agentic framework: the ability to infer sensitive attributes (e.g.,\nage and health information) and even abstract ones (e.g., personality and\nsocial traits) from a set of personal images, which we term \"image private\nattribute profiling.\" This threat is particularly severe given that modern apps\ncan easily access users' photo albums, and inference from image sets enables\nmodels to exploit inter-image relations for more sophisticated profiling.\nHowever, two main challenges hinder our understanding of how well VLMs can\nprofile an individual from a few personal photos: (1) the lack of benchmark\ndatasets with multi-image annotations for private attributes, and (2) the\nlimited ability of current multimodal large language models (MLLMs) to infer\nabstract attributes from large image collections. In this work, we construct\nPAPI, the largest dataset for studying private attribute profiling in personal\nimages, comprising 2,510 images from 251 individuals with 3,012 annotated\nprivacy attributes. We also propose HolmesEye, a hybrid agentic framework that\ncombines VLMs and LLMs to enhance privacy inference. HolmesEye uses VLMs to\nextract both intra-image and inter-image information and LLMs to guide the\ninference process as well as consolidate the results through forensic analysis,\novercoming existing limitations in long-context visual reasoning. Experiments\nreveal that HolmesEye achieves a 10.8% improvement in average accuracy over\nstate-of-the-art baselines and surpasses human-level performance by 15.0% in\npredicting abstract attributes. This work highlights the urgency of addressing\nprivacy risks in image-based profiling and offers both a new dataset and an\nadvanced framework to guide future research in this area.",
    "pdf_url": "http://arxiv.org/pdf/2505.19139v1",
    "published": "2025-05-25T13:22:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19140v1",
    "title": "Contribution to the 2025 Gravitation session of the 59th Rencontres de Moriond: Limits on the Ejecta Mass During the Search for Kilonovae Associated with Neutron Star-Black Hole Mergers",
    "authors": [
      "Marion Pillas"
    ],
    "abstract": "This study evaluates ejecta properties from multi-messenger observations to\nunderstand the absence of detectable KN associated to the four NSBH candidates\nfrom May 2023 to July 2024: we use GW public information and joint observations\ntaken from 05.2023 to 07.2024 (LVK, ATLAS, DECam, GECKO, GOTO, GRANDMA,\nSAGUARO, TESS, WINTER, ZTF) in the followup of S230518h, GW230529, S230627c and\nS240422ed. First, our analysis on follow-up observation strategies shows that,\non average, more than 50\\% of the simulated KNe associated with NSBH mergers\nreach their peak luminosity around one day after merger in the $g,r,i$- bands,\nwhich is not necessarily covered for each NSBH GW candidate. We also analyze\nthe trade-off between observation efficiency and the intrinsic properties of\nthe KN emission, to understand the impact on how these constraints affect our\nability to detect the KN, and underlying ejecta properties for each GW\ncandidate.",
    "pdf_url": "http://arxiv.org/pdf/2505.19140v1",
    "published": "2025-05-25T13:22:10+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.19138v1",
    "title": "Veta-GS: View-dependent deformable 3D Gaussian Splatting for thermal infrared Novel-view Synthesis",
    "authors": [
      "Myeongseok Nam",
      "Wongi Park",
      "Minsol Kim",
      "Hyejin Hur",
      "Soomok Lee"
    ],
    "abstract": "Recently, 3D Gaussian Splatting (3D-GS) based on Thermal Infrared (TIR)\nimaging has gained attention in novel-view synthesis, showing real-time\nrendering. However, novel-view synthesis with thermal infrared images suffers\nfrom transmission effects, emissivity, and low resolution, leading to floaters\nand blur effects in rendered images. To address these problems, we introduce\nVeta-GS, which leverages a view-dependent deformation field and a Thermal\nFeature Extractor (TFE) to precisely capture subtle thermal variations and\nmaintain robustness. Specifically, we design view-dependent deformation field\nthat leverages camera position and viewing direction, which capture thermal\nvariations. Furthermore, we introduce the Thermal Feature Extractor (TFE) and\nMonoSSIM loss, which consider appearance, edge, and frequency to maintain\nrobustness. Extensive experiments on the TI-NSD benchmark show that our method\nachieves better performance over existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.19138v1",
    "published": "2025-05-25T13:20:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.15686v2",
    "title": "Learning from M-Tuple Dominant Positive and Unlabeled Data",
    "authors": [
      "Jiahe Qin",
      "Junpeng Li",
      "Changchun Hua",
      "Yana Yang"
    ],
    "abstract": "Label Proportion Learning (LLP) addresses the classification problem where\nmultiple instances are grouped into bags and each bag contains information\nabout the proportion of each class. However, in practical applications,\nobtaining precise supervisory information regarding the proportion of instances\nin a specific class is challenging. To better align with real-world application\nscenarios and effectively leverage the proportional constraints of instances\nwithin tuples, this paper proposes a generalized learning framework\n\\emph{MDPU}. Specifically, we first mathematically model the distribution of\ninstances within tuples of arbitrary size, under the constraint that the number\nof positive instances is no less than that of negative instances. Then we\nderive an unbiased risk estimator that satisfies risk consistency based on the\nempirical risk minimization (ERM) method. To mitigate the inevitable\noverfitting issue during training, a risk correction method is introduced,\nleading to the development of a corrected risk estimator. The generalization\nerror bounds of the unbiased risk estimator theoretically demonstrate the\nconsistency of the proposed method. Extensive experiments on multiple datasets\nand comparisons with other relevant baseline methods comprehensively validate\nthe effectiveness of the proposed learning framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.15686v2",
    "published": "2025-05-25T13:20:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19137v1",
    "title": "Matrix Multiplication in the MPC Model",
    "authors": [
      "Atharv Chhabra",
      "Arya Deshmukh",
      "Chetan Gupta",
      "Lakshya Joshi"
    ],
    "abstract": "In this paper, we study the matrix multiplication problem in the MPC model.\nWe have two matrices, and the task is to compute their product. These matrices\nare evenly distributed over $P$ processors. Each processor has $M$ memory such\nthat $P \\cdot M \\geq $ (size of the matrices). The computation proceeds in\nsynchronous rounds. In a communication round, a processor can send and receive\nmessages to(from) any other processor, with the total size of messages sent or\nreceived being $O(M)$. We give an almost complete characterisation of the\nproblem in various settings. We prove tight upper bounds and lower bounds for\nthe problems in three different settings--when the given input matrices are (i)\ngeneral square matrices, (ii) rectangular matrices, and (iii) sparse square\nmatrices (that is, each row and column contains a bounded number of nonzero\nelements). In particular, we prove the following results:\n  1. Multiplication of two $n \\times n$ matrices in the MPC model with\n$n^\\alpha$ processors each with $O(n^{2-\\alpha})$ memory, requires\n$\\Theta(n^{\\frac{\\alpha}{2}})$ rounds in semirings.\n  2. Multiplication of two rectangular matrices of size $n \\times d$ and $d\n\\times n$ (where $d \\leq n$) respectively, with $n$ processors of $O(n)$ memory\nrequires $\\Theta(\\frac{d}{\\sqrt{n}})$ rounds in semirings.\n  3. Multiplication of two rectangular matrices of size $d \\times n$ and $n\n\\times d$ ( where $d \\leq n$) respectively requires\n  i. $\\Theta(\\sqrt{d} + \\log_d n)$ rounds with $n$ processors and $O(d)$ memory\nper processor in semirings\n  ii. $\\Theta (\\frac{d}{\\sqrt{n}})$ rounds with $d$ processors and $O(n)$\nmemory per processor in semirings.\n  4. Multiplication of two $d$-sparse matrices (each row and column of the\nmatrices contains at most $d$-nonzero elements) with $n$ processors and $O(d)$\nmemory per processor can be done in $O(d^{0.9})$ rounds in semirings.",
    "pdf_url": "http://arxiv.org/pdf/2505.19137v1",
    "published": "2025-05-25T13:18:37+00:00",
    "categories": [
      "cs.CC",
      "cs.DC"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19136v1",
    "title": "Uncertainty Quantification for Physics-Informed Neural Networks with Extended Fiducial Inference",
    "authors": [
      "Frank Shih",
      "Zhenghao Jiang",
      "Faming Liang"
    ],
    "abstract": "Uncertainty quantification (UQ) in scientific machine learning is\nincreasingly critical as neural networks are widely adopted to tackle complex\nproblems across diverse scientific disciplines. For physics-informed neural\nnetworks (PINNs), a prominent model in scientific machine learning, uncertainty\nis typically quantified using Bayesian or dropout methods. However, both\napproaches suffer from a fundamental limitation: the prior distribution or\ndropout rate required to construct honest confidence sets cannot be determined\nwithout additional information. In this paper, we propose a novel method within\nthe framework of extended fiducial inference (EFI) to provide rigorous\nuncertainty quantification for PINNs. The proposed method leverages a\nnarrow-neck hyper-network to learn the parameters of the PINN and quantify\ntheir uncertainty based on imputed random errors in the observations. This\napproach overcomes the limitations of Bayesian and dropout methods, enabling\nthe construction of honest confidence sets based solely on observed data. This\nadvancement represents a significant breakthrough for PINNs, greatly enhancing\ntheir reliability, interpretability, and applicability to real-world scientific\nand engineering challenges. Moreover, it establishes a new theoretical\nframework for EFI, extending its application to large-scale models, eliminating\nthe need for sparse hyper-networks, and significantly improving the\nautomaticity and robustness of statistical inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.19136v1",
    "published": "2025-05-25T13:18:13+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.19135v1",
    "title": "Weighted Bourgain-Morrey-Besov type and Triebel-Lizorkin type spaces associated with operators",
    "authors": [
      "Tengfei Bai",
      "Pengfei Guo",
      "Jingshi Xu"
    ],
    "abstract": "Let $(X,\\mu)$ be a space of homogeneous type satisfying $\\mu(X) =\\infty$, the\ndoubling property and the reverse doubling condition. Let $L$ be a nonnegative\nself-adjoint operator on $L^2(X)$ whose heat kernel enjoys a Gaussian upper\nbound. We introduce the weighted homogeneous Bourgain-Morrey-Besov type spaces\nand Triebel-Lizorkin type spaces associated with the operator $L$. We obtain\ntheir continuous characterizations in terms of Peetre maximal functions,\nnoncompactly supported functional calculus, heat kernel. Atomic and molecular\ndecompositions of weighted homogeneous Bourgain-Morrey-Besov type spaces and\nTriebel-Lizorkin type spaces are also given. As an application, we obtain the\nboundedness of the fractional power of $L$, the spectral multiplier of $L$ on\nBourgain-Morrey-Besov type spaces and Triebel-Lizorkin type spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.19135v1",
    "published": "2025-05-25T13:17:53+00:00",
    "categories": [
      "math.FA",
      "math.CA",
      "46E36, 46F05, 47B38"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.23789v1",
    "title": "Conversational Exploration of Literature Landscape with LitChat",
    "authors": [
      "Mingyu Huang",
      "Shasha Zhou",
      "Yuxuan Chen",
      "Ke Li"
    ],
    "abstract": "We are living in an era of \"big literature\", where the volume of digital\nscientific publications is growing exponentially. While offering new\nopportunities, this also poses challenges for understanding literature\nlandscapes, as traditional manual reviewing is no longer feasible. Recent large\nlanguage models (LLMs) have shown strong capabilities for literature\ncomprehension, yet they are incapable of offering \"comprehensive, objective,\nopen and transparent\" views desired by systematic reviews due to their limited\ncontext windows and trust issues like hallucinations. Here we present LitChat,\nan end-to-end, interactive and conversational literature agent that augments\nLLM agents with data-driven discovery tools to facilitate literature\nexploration. LitChat automatically interprets user queries, retrieves relevant\nsources, constructs knowledge graphs, and employs diverse data-mining\ntechniques to generate evidence-based insights addressing user needs. We\nillustrate the effectiveness of LitChat via a case study on AI4Health,\nhighlighting its capacity to quickly navigate the users through large-scale\nliterature landscape with data-based evidence that is otherwise infeasible with\ntraditional means.",
    "pdf_url": "http://arxiv.org/pdf/2505.23789v1",
    "published": "2025-05-25T13:15:09+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.15685v1",
    "title": "Ignition Phase : Standard Training for Fast Adversarial Robustness",
    "authors": [
      "Wang Yu-Hang",
      "Liu ying",
      "Fang liang",
      "Wang Xuelin",
      "Junkang Guo",
      "Shiwei Li",
      "Lei Gao",
      "Jian Liu",
      "Wenfei Yin"
    ],
    "abstract": "Adversarial Training (AT) is a cornerstone defense, but many variants\noverlook foundational feature representations by primarily focusing on stronger\nattack generation. We introduce Adversarial Evolution Training (AET), a simple\nyet powerful framework that strategically prepends an Empirical Risk\nMinimization (ERM) phase to conventional AT. We hypothesize this initial ERM\nphase cultivates a favorable feature manifold, enabling more efficient and\neffective robustness acquisition. Empirically, AET achieves comparable or\nsuperior robustness more rapidly, improves clean accuracy, and cuts training\ncosts by 8-25\\%. Its effectiveness is shown across multiple datasets,\narchitectures, and when augmenting established AT methods. Our findings\nunderscore the impact of feature pre-conditioning via standard training for\ndeveloping more efficient, principled robust defenses. Code is available in the\nsupplementary material.",
    "pdf_url": "http://arxiv.org/pdf/2506.15685v1",
    "published": "2025-05-25T13:12:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19134v1",
    "title": "Incentivizing High-Quality Human Annotations with Golden Questions",
    "authors": [
      "Shang Liu",
      "Zhongze Cai",
      "Hanzhao Wang",
      "Zhongyao Ma",
      "Xiaocheng Li"
    ],
    "abstract": "Human-annotated data plays a vital role in training large language models\n(LLMs), such as supervised fine-tuning and human preference alignment. However,\nit is not guaranteed that paid human annotators produce high-quality data. In\nthis paper, we study how to incentivize human annotators to do so. We start\nfrom a principal-agent model to model the dynamics between the company (the\nprincipal) and the annotator (the agent), where the principal can only monitor\nthe annotation quality by examining $n$ samples. We investigate the maximum\nlikelihood estimators (MLE) and the corresponding hypothesis testing to\nincentivize annotators: the agent is given a bonus if the MLE passes the test.\nBy analyzing the variance of the outcome, we show that the strategic behavior\nof the agent makes the hypothesis testing very different from traditional ones:\nUnlike the exponential rate proved by the large deviation theory, the\nprincipal-agent model's hypothesis testing rate is of $\\Theta(1/\\sqrt{n \\log\nn})$. Our theory implies two criteria for the \\emph{golden questions} to\nmonitor the performance of the annotators: they should be of (1) high certainty\nand (2) similar format to normal ones. In that light, we select a set of golden\nquestions in human preference data. By doing incentive-compatible experiments,\nwe find out that the annotators' behavior is better revealed by those golden\nquestions, compared to traditional survey techniques such as instructed\nmanipulation checks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19134v1",
    "published": "2025-05-25T13:11:55+00:00",
    "categories": [
      "cs.GT",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19133v2",
    "title": "Fast and Accurate Power Load Data Completion via Regularization-optimized Low-Rank Factorization",
    "authors": [
      "Yan Xia",
      "Hao Feng",
      "Hongwei Sun",
      "Junjie Wang",
      "Qicong Hu"
    ],
    "abstract": "Low-rank representation learning has emerged as a powerful tool for\nrecovering missing values in power load data due to its ability to exploit the\ninherent low-dimensional structures of spatiotemporal measurements. Among\nvarious techniques, low-rank factorization models are favoured for their\nefficiency and interpretability. However, their performance is highly sensitive\nto the choice of regularization parameters, which are typically fixed or\nmanually tuned, resulting in limited generalization capability or slow\nconvergence in practical scenarios. In this paper, we propose a\nRegularization-optimized Low-Rank Factorization, which introduces a\nProportional-Integral-Derivative controller to adaptively adjust the\nregularization coefficient. Furthermore, we provide a detailed algorithmic\ncomplexity analysis, showing that our method preserves the computational\nefficiency of stochastic gradient descent while improving adaptivity.\nExperimental results on real-world power load datasets validate the superiority\nof our method in both imputation accuracy and training efficiency compared to\nexisting baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.19133v2",
    "published": "2025-05-25T13:07:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19132v1",
    "title": "Reducible Riemannian manifolds with conformal product structures",
    "authors": [
      "Andrei Moroianu",
      "Mihaela Pilca"
    ],
    "abstract": "We study conformal product structures on compact reducible Riemannian\nmanifolds, and show that under a suitable technical assumption, the underlying\nRiemannian mani\\-folds are either conformally flat, or triple products,\n\\emph{i.e.} locally isometric to Riemannian manifolds of the form $(M,g)$ with\n$M=M_1\\times M_2\\times M_3$ and $g=e^{2f}g_1+g_2+g_3$, where $g_i$ is a\nRiemannian metric on $M_i$, for $i\\in\\{1,2,3\\}$, and $f\\in C^\\infty(M_1\\times\nM_2)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19132v1",
    "published": "2025-05-25T12:59:46+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19131v1",
    "title": "Two-component controller design to safeguard data-driven predictive control",
    "authors": [
      "Lea Bold",
      "Lukas Lanza",
      "Karl Worthmann"
    ],
    "abstract": "We design a two-component controller to achieve reference tracking with\noutput constraints - exemplified on systems of relative degree two. One\ncomponent is a data-driven or learning-based predictive controller, which uses\ndata samples to learn a model and predict the future behavior of the system. We\nexemplify this component concisely by data-enabled predictive control (DeePC)\nand by model predictive control based on extended dynamic mode decomposition\n(EDMD). The second component is a model-free high-gain feedback controller,\nwhich ensures satisfaction of the output constraints if that cannot be\nguaranteed by the predictive controller. This may be the case, for example, if\ntoo little data has been collected for learning or no (sufficient) guarantees\non the approximation accuracy derived. In particular, the reactive/adaptive\nfeedback controller can be used to support the learning process by leading\nsafely through the state space to collect suitable data, e.g., to ensure a\nsufficiently-small fill distance. Numerical examples are provided to illustrate\nthe combination of EDMD-based model predictive control and a safeguarding\nfeedback for the set-point transitions including the transition between the set\npoints within prescribed bounds.",
    "pdf_url": "http://arxiv.org/pdf/2505.19131v1",
    "published": "2025-05-25T12:58:28+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19130v1",
    "title": "Bourgain-Morrey-Lorentz spaces and operators on them",
    "authors": [
      "Tengfei Bai",
      "Pengfei Guo",
      "Jingshi Xu"
    ],
    "abstract": "We introduce Bourgain-Morrey-Lorentz spaces and give a description of the\npredual of Bourgain-Morrey-Lorentz spaces via the block spaces. As an\napplication of duality, we obtain the boundedness of Hardy-Littlewood maximal\noperator, sharp maximal operator, Calder\\'on-Zygmund operator, fractional\nintegral operator, commutator on Bourgain-Morrey-Lorentz spaces. Moreover, we\nobtain a weak Hardy factorization terms of Calder\\'on-Zygmund operator in\nBourgain-Morrey-Lorentz spaces. Using this result, we obtain a characterization\nof functions in $\\BMO$ (the functions of ``bounded mean oscillation'') via the\nboundedness of commutators generated by them and a homogeneous\nCalder\\'on-Zygmund operator. In the last, we show that the commutator generated\nby a function $b$ and a homogeneous Calder\\'on-Zygmund operator is a compact\noperator on Bourgain-Morrey-Lorentz spaces if and only if $b$ is the limit of\ncompactly supported smooth functions in $\\BMO$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19130v1",
    "published": "2025-05-25T12:56:23+00:00",
    "categories": [
      "math.FA",
      "math.CA",
      "42B35, 42B20, 46E30, 46A20"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19129v2",
    "title": "A novel and application-oriented inverse nodal problem for Sturm-Liouville operators",
    "authors": [
      "Yuchao He",
      "Mengda Wu",
      "Yonghui Xia",
      "Meirong Zhang"
    ],
    "abstract": "This paper develops a methodological framework for addressing a novel and\napplication-oriented inverse nodal problem in Sturm-Liouville operators, having\nsignificant applications in seismic wave analysis and submarine underwater\nradar (sonar) detection. By utilizing a given finite set of nodal data, we\npropose an optimization framework to find the potential $\\hat q$ that is most\nclosely approximating a predefined target potential $q_0$. The inverse nodal\noptimization problem is reformulated as a solvability problem for a class of\nnonlinear Schr\\\"odinger equations, enabling systematic investigation of the\ninverse nodal problem. {As an example, when the constant target potential $q_0$\nis considered, we find that the Schr\\\"odinger equations are completely\nintegrable and conclude that the potential $\\hat q$ is `periodic' in a certain\nsense. Furthermore, the reconstruction of $\\hat q$ is reduced to solving a\nsystem of three featured parameters, thereby establishing an explicit\nquantitative relationship between $\\|\\hat q\\|_{Lp}$ and $T_*$. Of importance,\nwe prove the uniqueness of the potential $\\hat q$ when $p>3/2$. These new\nfindings represent a substantial advancement in this field of study. Our\nmethodology also bridges theoretical rigor with practical applicability,\naddressing scenarios where only partial nodal information is available.",
    "pdf_url": "http://arxiv.org/pdf/2505.19129v2",
    "published": "2025-05-25T12:53:54+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19128v1",
    "title": "RetrieveAll: A Multilingual Named Entity Recognition Framework with Large Language Models",
    "authors": [
      "Jin Zhang",
      "Fan Gao",
      "Linyu Li",
      "Yongbin Yu",
      "Xiangxiang Wang",
      "Nyima Tashi",
      "Gadeng Luosang"
    ],
    "abstract": "The rise of large language models has led to significant performance\nbreakthroughs in named entity recognition (NER) for high-resource languages,\nyet there remains substantial room for improvement in low- and medium-resource\nlanguages. Existing multilingual NER methods face severe language interference\nduring the multi-language adaptation process, manifested in feature conflicts\nbetween different languages and the competitive suppression of low-resource\nlanguage features by high-resource languages. Although training a dedicated\nmodel for each language can mitigate such interference, it lacks scalability\nand incurs excessive computational costs in real-world applications. To address\nthis issue, we propose RetrieveAll, a universal multilingual NER framework\nbased on dynamic LoRA. The framework decouples task-specific features across\nlanguages and demonstrates efficient dynamic adaptability. Furthermore, we\nintroduce a cross-granularity knowledge augmented method that fully exploits\nthe intrinsic potential of the data without relying on external resources. By\nleveraging a hierarchical prompting mechanism to guide knowledge injection,\nthis approach advances the paradigm from \"prompt-guided inference\" to\n\"prompt-driven learning.\" Experimental results show that RetrieveAll\noutperforms existing baselines; on the PAN-X dataset, it achieves an average F1\nimprovement of 12.1 percent.",
    "pdf_url": "http://arxiv.org/pdf/2505.19128v1",
    "published": "2025-05-25T12:52:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19127v1",
    "title": "Active Matter under Cyclic Stretch: Modeling Microtubule Alignment and Bundling",
    "authors": [
      "Takumi Tagaki",
      "Seiya Nishikawa",
      "Shuji Ishihara"
    ],
    "abstract": "We investigate the behavior of self-propelled particles under cyclic\nstretching, inspired by the characteristic pattern dynamics observed in\nmicrotubule (MT) motility assays subjected to uniaxial cyclic substrate\nstretching. We develop a self-propelled particle model that incorporates the\nelastic energy acting on the filaments due to substrate deformation,\nsuccessfully reproducing the experimentally observed MT patterns. Additionally,\nthe general framework of the model enables systematic exploration of collective\nresponses to various substrate deformations, offering potential applications in\nthe manipulation of MT patterns and other active matter systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.19127v1",
    "published": "2025-05-25T12:49:29+00:00",
    "categories": [
      "cond-mat.soft",
      "q-bio.BM",
      "q-bio.SC"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.19126v1",
    "title": "MMATH: A Multilingual Benchmark for Mathematical Reasoning",
    "authors": [
      "Wenyang Luo",
      "Wayne Xin Zhao",
      "Jing Sha",
      "Shijin Wang",
      "Ji-Rong Wen"
    ],
    "abstract": "The advent of large reasoning models, such as OpenAI o1 and DeepSeek R1, has\nsignificantly advanced complex reasoning tasks. However, their capabilities in\nmultilingual complex reasoning remain underexplored, with existing efforts\nlargely focused on simpler tasks like MGSM. To address this gap, we introduce\nMMATH, a benchmark for multilingual complex reasoning spanning 374 high-quality\nmath problems across 10 typologically diverse languages. Using MMATH, we\nobserve that even advanced models like DeepSeek R1 exhibit substantial\nperformance disparities across languages and suffer from a critical off-target\nissue-generating responses in unintended languages. To address this, we explore\nstrategies including prompting and training, demonstrating that reasoning in\nEnglish and answering in target languages can simultaneously enhance\nperformance and preserve target-language consistency. Our findings offer new\ninsights and practical strategies for advancing the multilingual reasoning\ncapabilities of large language models. Our code and data could be found at\nhttps://github.com/RUCAIBox/MMATH.",
    "pdf_url": "http://arxiv.org/pdf/2505.19126v1",
    "published": "2025-05-25T12:47:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19125v1",
    "title": "RTime-QA: A Benchmark for Atomic Temporal Event Understanding in Large Multi-modal Models",
    "authors": [
      "Yuqi Liu",
      "Qin Jin",
      "Tianyuan Qu",
      "Xuan Liu",
      "Yang Du",
      "Bei Yu",
      "Jiaya Jia"
    ],
    "abstract": "Understanding accurate atomic temporal event is essential for video\ncomprehension. However, current video-language benchmarks often fall short to\nevaluate Large Multi-modal Models' (LMMs) temporal event understanding\ncapabilities, as they can be effectively addressed using image-language models.\nIn this paper, we introduce RTime-QA, a novel benchmark specifically designed\nto assess the atomic temporal event understanding ability of LMMs. RTime-QA\ncomprises 822 high-quality, carefully-curated video-text questions, each\nmeticulously annotated by human experts. Each question features a video\ndepicting an atomic temporal event, paired with both correct answers and\ntemporal negative descriptions, specifically designed to evaluate temporal\nunderstanding. To advance LMMs' temporal event understanding ability, we\nfurther introduce RTime-IT, a 14k instruction-tuning dataset that employs a\nsimilar annotation process as RTime-QA. Extensive experimental analysis\ndemonstrates that RTime-QA presents a significant challenge for LMMs: the\nstate-of-the-art model Qwen2-VL achieves only 34.6 on strict-ACC metric,\nsubstantially lagging behind human performance. Furthermore, our experiments\nreveal that RTime-IT effectively enhance LMMs' capacity in temporal\nunderstanding. By fine-tuning on RTime-IT, our Qwen2-VL achieves 65.9 on\nRTime-QA.",
    "pdf_url": "http://arxiv.org/pdf/2505.19125v1",
    "published": "2025-05-25T12:44:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19124v1",
    "title": "Asymptotic Efficiency Analysis of the Recursive Least-Squares Algorithm for ARX Systems Without Projection",
    "authors": [
      "Xingrui Liu",
      "Jieming Ke",
      "Yanlong Zhao"
    ],
    "abstract": "This paper investigates the optimality analysis of the recursive\nleast-squares (RLS) algorithm for autoregressive systems with exogenous inputs\n(ARX systems). A key challenge in analyzing is managing the potential\nunboundedness of the parameter estimates, which may diverge to infinity.\nPrevious approaches addressed this issue by assuming that both the true\nparameter and the RLS estimates remain confined within a known compact set,\nthereby ensuring uniform boundedness throughout the analysis. In contrast, we\npropose a new analytical framework that eliminates the need for such a\nboundness assumption. Specifically, we establish a quantitative relationship\nbetween the bounded moment conditions of quasi-stationary input/output signals\nand the convergence rate of the tail probability of the RLS estimation error.\nBased on this technique, we prove that when system inputs/outputs have bounded\ntwentieth-order moments, the RLS algorithm achieves asymptotic normality and\nthe covariance matrix of the RLS algorithm converges to the Cram\\'er-Rao lower\nbound (CRLB), confirming its asymptotic efficiency. These results demonstrate\nthat the RLS algorithm is an asymptotically optimal identification algorithm\nfor ARX systems, even without the projection operators to ensure that parameter\nestimates reside within a prior known compact set.",
    "pdf_url": "http://arxiv.org/pdf/2505.19124v1",
    "published": "2025-05-25T12:39:29+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19123v1",
    "title": "Estimating of CP Violation in $B_{c}\\rightarrow B K^{0}+B {\\bar{K}}^0\\rightarrow B π^{\\pm} e^{\\mp} ν_{e}$ Decays",
    "authors": [
      "Xiao-Dong Cheng",
      "Zhen-Lu Weng",
      "Ying-Ying Fan",
      "Ru-Min Wang \\\\"
    ],
    "abstract": "In this paper, we investigate the CP asymmetries ${\\mathcal A}_{CP}^{pm}$ and\n${\\mathcal A}_{CP}^{mp}$ in $B_{c}^{\\pm}\\rightarrow B^{\\pm} K^{0}+B^{\\pm}\n{\\bar{K}}^0\\rightarrow B^{\\pm} \\pi^{\\pm} e^{\\mp} \\nu_{e}$ and\n$B_{c}^{\\pm}\\rightarrow B^{\\pm} K^{0}+B^{\\pm} {\\bar{K}}^0\\rightarrow B^{\\pm}\n\\pi^{\\mp} e^{\\pm} \\nu_{e}$ decays, both of them consist of three parts: the\nindirect CP violations in $K^0 -\\bar{K}^0$ mixing $A_{CP,mix}^{pm}$ and\n$A_{CP,mix}^{mp}$, the direct CP violations in $B_{c}$ decay $A_{CP,dir}^{pm}$\nand $A_{CP,dir}^{mp}$, the new CP violation effects $A_{CP,int}^{pm}$ and\n$A_{CP,int}^{mp}$, which originate from the interference between the amplitude\nof the $B_{c}^{-}\\rightarrow B^{-} K^{0} ({\\bar{K}}^0) \\rightarrow B^{-}\n\\pi^{-} e^{+} \\nu_{e}(\\pi^{+} e^{-} \\bar{\\nu}_{e})$ decay with the difference\nbetween the oscillating effect of $K^0\\rightarrow {\\bar{K}}^0$ and that of\n${\\bar{K}}^0\\rightarrow K^0 $. The strong phase differences of the direct CP\nasymmetries $A_{CP,dir}^{pm}$ and $A_{CP,dir}^{mp}$ arising from\n$K^0-\\bar{K}^0$ mixing parameters. ${\\mathcal A}_{CP}^{pm}$ and ${\\mathcal\nA}_{CP}^{mp}$ are of the order $\\mathcal{O}(10^{-4})$ and\n$\\mathcal{O}(10^{-3})$, respectively. The new CP violation effect ${\\mathcal\nA}_{CP,int}^{pm}$ plays a dominant role in ${\\mathcal A}_{CP}^{pm}$, the CP\nasymmetry ${\\mathcal A}_{CP}^{mp}$ is dominated by the indirect CP violation\n${\\mathcal A}_{CP,mix}^{mp}$, so the CP asymmetry ${\\mathcal A}_{CP}^{pm}$\nprovides an ideal place to study the new CP violation effect. We derive another\ntwo asymmetry observables ${\\mathcal A}_{CP}^{pp}$ and ${\\mathcal\nA}_{CP}^{mm}$, which are dominated by $K^0-\\bar{K}^0$ mixing. The observables\n${\\mathcal A}_{CP}^{pm}$, ${\\mathcal A}_{CP}^{mp}$, ${\\mathcal A}_{CP}^{pp}$\nand ${\\mathcal A}_{CP}^{mm}$ are hopefully to be marginally observed at the LHC\nexperiment and the HL-LHC experiment.",
    "pdf_url": "http://arxiv.org/pdf/2505.19123v1",
    "published": "2025-05-25T12:31:45+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19122v1",
    "title": "Exploring Magnitude Preservation and Rotation Modulation in Diffusion Transformers",
    "authors": [
      "Eric Tillman Bill",
      "Cristian Perez Jensen",
      "Sotiris Anagnostidis",
      "Dimitri von Rütte"
    ],
    "abstract": "Denoising diffusion models exhibit remarkable generative capabilities, but\nremain challenging to train due to their inherent stochasticity, where\nhigh-variance gradient estimates lead to slow convergence. Previous works have\nshown that magnitude preservation helps with stabilizing training in the U-net\narchitecture. This work explores whether this effect extends to the Diffusion\nTransformer (DiT) architecture. As such, we propose a magnitude-preserving\ndesign that stabilizes training without normalization layers. Motivated by the\ngoal of maintaining activation magnitudes, we additionally introduce rotation\nmodulation, which is a novel conditioning method using learned rotations\ninstead of traditional scaling or shifting. Through empirical evaluations and\nablation studies on small-scale models, we show that magnitude-preserving\nstrategies significantly improve performance, notably reducing FID scores by\n$\\sim$12.8%. Further, we show that rotation modulation combined with scaling is\ncompetitive with AdaLN, while requiring $\\sim$5.4% fewer parameters. This work\nprovides insights into conditioning strategies and magnitude control. We will\npublicly release the implementation of our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.19122v1",
    "published": "2025-05-25T12:25:50+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19121v2",
    "title": "Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models",
    "authors": [
      "Seunguk Yu",
      "Juhwan Choi",
      "Youngbin Kim"
    ],
    "abstract": "Despite the recent strides in large language models, studies have underscored\nthe existence of social biases within these systems. In this paper, we delve\ninto the validation and comparison of the ethical biases of LLMs concerning\nglobally discussed and potentially sensitive topics, hypothesizing that these\nbiases may arise from language-specific distinctions. Introducing the\nMultilingual Sensitive Questions & Answers Dataset (MSQAD), we collected news\narticles from Human Rights Watch covering 17 topics, and generated socially\nsensitive questions along with corresponding responses in multiple languages.\nWe scrutinized the biases of these responses across languages and topics,\nemploying two statistical hypothesis tests. The results showed that the null\nhypotheses were rejected in most cases, indicating biases arising from\ncross-language differences. It demonstrates that ethical biases in responses\nare widespread across various languages, and notably, these biases were\nprevalent even among different LLMs. By making the proposed MSQAD openly\navailable, we aim to facilitate future research endeavors focused on examining\ncross-language biases in LLMs and their variant models.",
    "pdf_url": "http://arxiv.org/pdf/2505.19121v2",
    "published": "2025-05-25T12:25:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.23788v1",
    "title": "Nine Ways to Break Copyright Law and Why Our LLM Won't: A Fair Use Aligned Generation Framework",
    "authors": [
      "Aakash Sen Sharma",
      "Debdeep Sanyal",
      "Priyansh Srivastava",
      "Sundar Atreya H.",
      "Shirish Karande",
      "Mohan Kankanhalli",
      "Murari Mandal"
    ],
    "abstract": "Large language models (LLMs) commonly risk copyright infringement by\nreproducing protected content verbatim or with insufficient transformative\nmodifications, posing significant ethical, legal, and practical concerns.\nCurrent inference-time safeguards predominantly rely on restrictive\nrefusal-based filters, often compromising the practical utility of these\nmodels. To address this, we collaborated closely with intellectual property\nexperts to develop FUA-LLM (Fair Use Aligned Language Models), a\nlegally-grounded framework explicitly designed to align LLM outputs with\nfair-use doctrine. Central to our method is FairUseDB, a carefully constructed\ndataset containing 18,000 expert-validated examples covering nine realistic\ninfringement scenarios. Leveraging this dataset, we apply Direct Preference\nOptimization (DPO) to fine-tune open-source LLMs, encouraging them to produce\nlegally compliant and practically useful alternatives rather than resorting to\nblunt refusal. Recognizing the shortcomings of traditional evaluation metrics,\nwe propose new measures: Weighted Penalty Utility and Compliance Aware Harmonic\nMean (CAH) to balance infringement risk against response utility. Extensive\nquantitative experiments coupled with expert evaluations confirm that FUA-LLM\nsubstantially reduces problematic outputs (up to 20\\%) compared to\nstate-of-the-art approaches, while preserving real-world usability.",
    "pdf_url": "http://arxiv.org/pdf/2505.23788v1",
    "published": "2025-05-25T12:23:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19120v1",
    "title": "Freqformer: Image-Demoiréing Transformer via Efficient Frequency Decomposition",
    "authors": [
      "Xiaoyang Liu",
      "Bolin Qiu",
      "Jiezhang Cao",
      "Zheng Chen",
      "Yulun Zhang",
      "Xiaokang Yang"
    ],
    "abstract": "Image demoir\\'eing remains a challenging task due to the complex interplay\nbetween texture corruption and color distortions caused by moir\\'e patterns.\nExisting methods, especially those relying on direct image-to-image\nrestoration, often fail to disentangle these intertwined artifacts effectively.\nWhile wavelet-based frequency-aware approaches offer a promising direction,\ntheir potential remains underexplored. In this paper, we present Freqformer, a\nTransformer-based framework specifically designed for image demoir\\'eing\nthrough targeted frequency separation. Our method performs an effective\nfrequency decomposition that explicitly splits moir\\'e patterns into\nhigh-frequency spatially-localized textures and low-frequency scale-robust\ncolor distortions, which are then handled by a dual-branch architecture\ntailored to their distinct characteristics. We further propose a learnable\nFrequency Composition Transform (FCT) module to adaptively fuse the\nfrequency-specific outputs, enabling consistent and high-fidelity\nreconstruction. To better aggregate the spatial dependencies and the\ninter-channel complementary information, we introduce a Spatial-Aware Channel\nAttention (SA-CA) module that refines moir\\'e-sensitive regions without\nincurring high computational cost. Extensive experiments on various\ndemoir\\'eing benchmarks demonstrate that Freqformer achieves state-of-the-art\nperformance with a compact model size. The code is publicly available at\nhttps://github.com/xyLiu339/Freqformer.",
    "pdf_url": "http://arxiv.org/pdf/2505.19120v1",
    "published": "2025-05-25T12:23:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19119v1",
    "title": "CloneShield: A Framework for Universal Perturbation Against Zero-Shot Voice Cloning",
    "authors": [
      "Renyuan Li",
      "Zhibo Liang",
      "Haichuan Zhang",
      "Tianyu Shi",
      "Zhiyuan Cheng",
      "Jia Shi",
      "Carl Yang",
      "Mingjie Tang"
    ],
    "abstract": "Recent breakthroughs in text-to-speech (TTS) voice cloning have raised\nserious privacy concerns, allowing highly accurate vocal identity replication\nfrom just a few seconds of reference audio, while retaining the speaker's vocal\nauthenticity. In this paper, we introduce CloneShield, a universal time-domain\nadversarial perturbation framework specifically designed to defend against\nzero-shot voice cloning. Our method provides protection that is robust across\nspeakers and utterances, without requiring any prior knowledge of the\nsynthesized text. We formulate perturbation generation as a multi-objective\noptimization problem, and propose Multi-Gradient Descent Algorithm (MGDA) to\nensure the robust protection across diverse utterances. To preserve natural\nauditory perception for users, we decompose the adversarial perturbation via\nMel-spectrogram representations and fine-tune it for each sample. This design\nensures imperceptibility while maintaining strong degradation effects on\nzero-shot cloned outputs. Experiments on three state-of-the-art zero-shot TTS\nsystems, five benchmark datasets and evaluations from 60 human listeners\ndemonstrate that our method preserves near-original audio quality in protected\ninputs (PESQ = 3.90, SRS = 0.93) while substantially degrading both speaker\nsimilarity and speech quality in cloned samples (PESQ = 1.07, SRS = 0.08).",
    "pdf_url": "http://arxiv.org/pdf/2505.19119v1",
    "published": "2025-05-25T12:22:00+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.19118v1",
    "title": "Attraction-Induced Cluster Fragmentation and Local Alignment in Active Particle Systems",
    "authors": [
      "Sota Shimamura",
      "Nen Saito",
      "Shuji Ishihara"
    ],
    "abstract": "We numerically studied active Brownian particles with attractive\ninteractions. Contrary to our intuition, the attractive force between particles\ndisrupts the formation of a single cluster observed in motility-induced phase\nseparation, giving rise to a multi-cluster state characterized by a power-law\ndistribution of cluster sizes. Remarkably, the self-propulsion directions\nspontaneously align within each cluster, resulting in enhanced cluster motility\ndespite the absence of alignment interactions. This study revealed the\nintricate role of attractive interactions in the aggregation of motile systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.19118v1",
    "published": "2025-05-25T12:18:37+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.19117v1",
    "title": "Tunable Fujita-Miyazawa-Type Three-Body Force in Ultracold Atoms",
    "authors": [
      "Hiroyuki Tajima",
      "Eiji Nakano",
      "Kei Iida"
    ],
    "abstract": "We show how a Fujita-Miyazawa-type three-body force emerges among three\nimpurity atoms immersed in an atomic Bose-Einstein condensate near an\ninterspecies Feshbach resonance. As a result of thermal average over\nexcitations in the medium and impurities as well as expansion with respect to\nthe impurity-medium and Feshbach resonance couplings, two superfluid phonons\nand a closed channel resonance play a role in producing an effective three-body\nforce, as in the original three-nucleon case in which two pions and a $\\Delta$\nresonance are involved. The proposed Fujita-Miyazawa-type three-body force can\nbe enhanced by tuning the closed-channel energy level via an external magnetic\nfield, and moreover, its strength can be confirmed experimentally by measuring\nthe impurity equation of state. Our result gives a new insight into an analogy\nbetween atomic polarons and nuclear few-body systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.19117v1",
    "published": "2025-05-25T12:18:13+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "physics.atom-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.19116v2",
    "title": "Controlling Language Confusion in Multilingual LLMs",
    "authors": [
      "Nahyun Lee",
      "Yeongseo Woo",
      "Hyunwoo Ko",
      "Guijin Son"
    ],
    "abstract": "Large language models often suffer from language confusion, a phenomenon in\nwhich responses are partially or entirely generated in unintended languages.\nThis critically degrades the user experience, especially in low-resource\nsettings. We hypothesize that this issue stems from limitations in conventional\nfine-tuning objectives, such as supervised learning, which optimize the\nlikelihood of correct tokens without explicitly penalizing undesired outputs\nsuch as cross-lingual mixing. Analysis of loss trajectories during pretraining\nfurther reveals that models fail to distinguish between monolingual and\nlanguage-mixed texts, highlighting the absence of inherent pressure to avoid\nsuch confusion. In this work, we apply ORPO, which adds penalties for unwanted\noutput styles to standard SFT, effectively suppressing language-confused\ngenerations. ORPO maintains strong language consistency, even under high\ndecoding temperatures, while preserving general QA performance. Our findings\nsuggest that incorporating appropriate penalty terms can effectively mitigate\nlanguage confusion in multilingual models, particularly in low-resource\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.19116v2",
    "published": "2025-05-25T12:15:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19115v2",
    "title": "FP4 All the Way: Fully Quantized Training of LLMs",
    "authors": [
      "Brian Chmiel",
      "Maxim Fishman",
      "Ron Banner",
      "Daniel Soudry"
    ],
    "abstract": "We demonstrate, for the first time, fully quantized training (FQT) of large\nlanguage models (LLMs) using predominantly 4-bit floating-point (FP4) precision\nfor weights, activations, and gradients on datasets up to 200 billion tokens.\nWe extensively investigate key design choices for FP4, including block sizes,\nscaling formats, and rounding methods. Our analysis shows that the NVFP4\nformat, where each block of 16 FP4 values (E2M1) shares a scale represented in\nE4M3, provides optimal results. We use stochastic rounding for backward and\nupdate passes and round-to-nearest for the forward pass to enhance stability.\nAdditionally, we identify a theoretical and empirical threshold for effective\nquantized training: when the gradient norm falls below approximately $\\sqrt{3}$\ntimes the quantization noise, quantized training becomes less effective.\nLeveraging these insights, we successfully train a 7-billion-parameter model on\n256 Intel Gaudi2 accelerators. The resulting FP4-trained model achieves\ndownstream task performance comparable to a standard BF16 baseline, confirming\nthat FP4 training is a practical and highly efficient approach for large-scale\nLLM training. A reference implementation is supplied in\nhttps://github.com/Anonymous1252022/fp4-all-the-way .",
    "pdf_url": "http://arxiv.org/pdf/2505.19115v2",
    "published": "2025-05-25T12:14:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19114v2",
    "title": "CreatiDesign: A Unified Multi-Conditional Diffusion Transformer for Creative Graphic Design",
    "authors": [
      "Hui Zhang",
      "Dexiang Hong",
      "Maoke Yang",
      "Yutao Cheng",
      "Zhao Zhang",
      "Jie Shao",
      "Xinglong Wu",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "abstract": "Graphic design plays a vital role in visual communication across advertising,\nmarketing, and multimedia entertainment. Prior work has explored automated\ngraphic design generation using diffusion models, aiming to streamline creative\nworkflows and democratize design capabilities. However, complex graphic design\nscenarios require accurately adhering to design intent specified by multiple\nheterogeneous user-provided elements (\\eg images, layouts, and texts), which\npose multi-condition control challenges for existing methods. Specifically,\nprevious single-condition control models demonstrate effectiveness only within\ntheir specialized domains but fail to generalize to other conditions, while\nexisting multi-condition methods often lack fine-grained control over each\nsub-condition and compromise overall compositional harmony. To address these\nlimitations, we introduce CreatiDesign, a systematic solution for automated\ngraphic design covering both model architecture and dataset construction.\nFirst, we design a unified multi-condition driven architecture that enables\nflexible and precise integration of heterogeneous design elements with minimal\narchitectural modifications to the base diffusion model. Furthermore, to ensure\nthat each condition precisely controls its designated image region and to avoid\ninterference between conditions, we propose a multimodal attention mask\nmechanism. Additionally, we develop a fully automated pipeline for constructing\ngraphic design datasets, and introduce a new dataset with 400K samples\nfeaturing multi-condition annotations, along with a comprehensive benchmark.\nExperimental results show that CreatiDesign outperforms existing models by a\nclear margin in faithfully adhering to user intent.",
    "pdf_url": "http://arxiv.org/pdf/2505.19114v2",
    "published": "2025-05-25T12:14:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19113v1",
    "title": "Heat kernel estimate on weighted Riemannian manifolds under lower $N$-Ricci curvature bounds with $ε$-range and it's application",
    "authors": [
      "Wen-Qi Li",
      "Zhikai Zhang"
    ],
    "abstract": "In this paper, we establish a parabolic Harnack inequality for positive\nsolutions of the $\\phi$-heat equation and prove Gaussian upper and lower bounds\nfor the $\\phi$-heat kernel on weighted Riemannian manifolds under lower\n$N$-Ricci curvature bound with $\\varepsilon$-range. Building on these results,\nwe demonstrate: The $L^1_\\phi$-Liouville theorem for $\\phi$-subharmonic\nfunctions, $L^1_\\phi$-uniqueness property for solutions of the $\\phi$-heat\nequation and lower bounds for eigenvalues of the weighted Laplacian\n$\\Delta_\\phi$.\n  Furthermore, leveraging the Gaussian upper bound of the weighted heat kernel,\nwe construct a Li-Yau-type gradient estimate for the positive solution of\nweighted heat equation under a weighted $L^p(\\mu)$-norm constraint on\n$|\\nabla\\phi|^2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19113v1",
    "published": "2025-05-25T12:13:52+00:00",
    "categories": [
      "math.DG",
      "math.AP"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19112v1",
    "title": "Self-Critique Guided Iterative Reasoning for Multi-hop Question Answering",
    "authors": [
      "Zheng Chu",
      "Huiming Fan",
      "Jingchang Chen",
      "Qianyu Wang",
      "Mingda Yang",
      "Jiafeng Liang",
      "Zhongjie Wang",
      "Hao Li",
      "Guo Tang",
      "Ming Liu",
      "Bing Qin"
    ],
    "abstract": "Although large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities, they still face challenges in knowledge-intensive multi-hop\nreasoning. Recent work explores iterative retrieval to address complex\nproblems. However, the lack of intermediate guidance often results in\ninaccurate retrieval and flawed intermediate reasoning, leading to incorrect\nreasoning. To address these, we propose Self-Critique Guided Iterative\nReasoning (SiGIR), which uses self-critique feedback to guide the iterative\nreasoning process. Specifically, through end-to-end training, we enable the\nmodel to iteratively address complex problems via question decomposition.\nAdditionally, the model is able to self-evaluate its intermediate reasoning\nsteps. During iterative reasoning, the model engages in branching exploration\nand employs self-evaluation to guide the selection of promising reasoning\ntrajectories. Extensive experiments on three multi-hop reasoning datasets\ndemonstrate the effectiveness of our proposed method, surpassing the previous\nSOTA by $8.6\\%$. Furthermore, our thorough analysis offers insights for future\nresearch. Our code, data, and models are available at Github:\nhttps://github.com/zchuz/SiGIR-MHQA.",
    "pdf_url": "http://arxiv.org/pdf/2505.19112v1",
    "published": "2025-05-25T12:10:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19111v2",
    "title": "Remote Sensing Image Classification with Decoupled Knowledge Distillation",
    "authors": [
      "Yaping He",
      "Jianfeng Cai",
      "Qicong Hu",
      "Peiqing Wang"
    ],
    "abstract": "To address the challenges posed by the large number of parameters in existing\nremote sensing image classification models, which hinder deployment on\nresource-constrained devices, this paper proposes a lightweight classification\nmethod based on knowledge distillation. Specifically, G-GhostNet is adopted as\nthe backbone network, leveraging feature reuse to reduce redundant parameters\nand significantly improve inference efficiency. In addition, a decoupled\nknowledge distillation strategy is employed, which separates target and\nnon-target classes to effectively enhance classification accuracy. Experimental\nresults on the RSOD and AID datasets demonstrate that, compared with the\nhigh-parameter VGG-16 model, the proposed method achieves nearly equivalent\nTop-1 accuracy while reducing the number of parameters by 6.24 times. This\napproach strikes an excellent balance between model size and classification\nperformance, offering an efficient solution for deployment on resource-limited\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2505.19111v2",
    "published": "2025-05-25T12:06:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19110v2",
    "title": "An Interpretable Representation Learning Approach for Diffusion Tensor Imaging",
    "authors": [
      "Vishwa Mohan Singh",
      "Alberto Gaston Villagran Asiares",
      "Luisa Sophie Schuhmacher",
      "Kate Rendall",
      "Simon Weißbrod",
      "David Rügamer",
      "Inga Körte"
    ],
    "abstract": "Diffusion Tensor Imaging (DTI) tractography offers detailed insights into the\nstructural connectivity of the brain, but presents challenges in effective\nrepresentation and interpretation in deep learning models. In this work, we\npropose a novel 2D representation of DTI tractography that encodes tract-level\nfractional anisotropy (FA) values into a 9x9 grayscale image. This\nrepresentation is processed through a Beta-Total Correlation Variational\nAutoencoder with a Spatial Broadcast Decoder to learn a disentangled and\ninterpretable latent embedding. We evaluate the quality of this embedding using\nsupervised and unsupervised representation learning strategies, including\nauxiliary classification, triplet loss, and SimCLR-based contrastive learning.\nCompared to the 1D Group deep neural network (DNN) baselines, our approach\nimproves the F1 score in a downstream sex classification task by 15.74% and\nshows a better disentanglement than the 3D representation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19110v2",
    "published": "2025-05-25T11:55:02+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19109v2",
    "title": "On Distributed Colouring of Hyperbolic Random Graphs",
    "authors": [
      "Yannic Maus",
      "Janosch Ruff"
    ],
    "abstract": "We analyse the performance of simple distributed colouring algorithms under\nthe assumption that the input graph is a hyperbolic random graph (HRG), a\ngenerative model capturing key properties of real-world networks such as\npower-law degree distributions and large clustering coefficients. Motivated by\nthe shift from worst-case analysis to more realistic network models, we study\nthe number of rounds and size of the colour space required to colour HRGs in\nthe distributed setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.19109v2",
    "published": "2025-05-25T11:54:49+00:00",
    "categories": [
      "cs.DS",
      "68W15"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.19108v1",
    "title": "CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models",
    "authors": [
      "Yongheng Zhang",
      "Xu Liu",
      "Ruoxi Zhou",
      "Qiguang Chen",
      "Hao Fei",
      "Wenpeng Lu",
      "Libo Qin"
    ],
    "abstract": "Investigating hallucination issues in large language models (LLMs) within\ncross-lingual and cross-modal scenarios can greatly advance the large-scale\ndeployment in real-world applications. Nevertheless, the current studies are\nlimited to a single scenario, either cross-lingual or cross-modal, leaving a\ngap in the exploration of hallucinations in the joint cross-lingual and\ncross-modal scenarios. Motivated by this, we introduce a novel joint\nCross-lingual and Cross-modal Hallucinations benchmark (CCHall) to fill this\ngap. Specifically, CCHall simultaneously incorporates both cross-lingual and\ncross-modal hallucination scenarios, which can be used to assess the\ncross-lingual and cross-modal capabilities of LLMs. Furthermore, we conduct a\ncomprehensive evaluation on CCHall, exploring both mainstream open-source and\nclosed-source LLMs. The experimental results highlight that current LLMs still\nstruggle with CCHall. We hope CCHall can serve as a valuable resource to assess\nLLMs in joint cross-lingual and cross-modal scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.19108v1",
    "published": "2025-05-25T11:54:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19107v1",
    "title": "Optimization-Inspired Few-Shot Adaptation for Large Language Models",
    "authors": [
      "Boyan Gao",
      "Xin Wang",
      "Yibo Yang",
      "David Clifton"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in\nreal-world applications. However, adapting LLMs to novel tasks via fine-tuning\noften requires substantial training data and computational resources that are\nimpractical in few-shot scenarios. Existing approaches, such as in-context\nlearning and Parameter-Efficient Fine-Tuning (PEFT), face key limitations:\nin-context learning introduces additional inference computational overhead with\nlimited performance gains, while PEFT models are prone to overfitting on the\nfew demonstration examples. In this work, we reinterpret the forward pass of\nLLMs as an optimization process, a sequence of preconditioned gradient descent\nsteps refining internal representations. Based on this connection, we propose\nOptimization-Inspired Few-Shot Adaptation (OFA), integrating a parameterization\nthat learns preconditioners without introducing additional trainable\nparameters, and an objective that improves optimization efficiency by learning\npreconditioners based on a convergence bound, while simultaneously steering the\noptimization path toward the flat local minimum. Our method overcomes both\nissues of ICL-based and PEFT-based methods, and demonstrates superior\nperformance over the existing methods on a variety of few-shot adaptation tasks\nin experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.19107v1",
    "published": "2025-05-25T11:54:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19106v1",
    "title": "An Ultra-Low Power and Fast Ising Machine using Voltage-Controlled Magnetoresistive Random Access Memory",
    "authors": [
      "Yihao Zhang",
      "Sai Li",
      "Albert Lee",
      "Zheng Zhu",
      "Lang Zeng",
      "Peng Wang",
      "Lei Gao",
      "Di Wu",
      "Weisheng Zhao"
    ],
    "abstract": "Physics-inspired computing paradigms, such as Ising machines, are emerging as\npromising hardware alternatives to traditional von Neumann architectures for\ntackling computationally intensive combinatorial optimization problems (COPs).\nWhile quantum, optical, and electronic devices have garnered significant\nattention for their potential in realizing Ising machines, their translation\ninto practical systems for industry-relevant applications remains challenging,\nwith each approach facing specific limitations in power consumption and speed.\nTo address this challenge, we report the first chip-level spintronic Ising\nmachine using voltage-controlled magnetoresistive random access memory. The\ncore of our design leverages magnetic tunnel junctions (MTJs) driven by the\nvoltage-controlled magnetic anisotropy effect to realize the probabilistic\nupdate of Ising spins through a new mechanism. It enables a latency below 1 ns\nand an energy consumption under 40 fJ per spin update, achieving a 1000-times\nimprovement over previous current-driven MTJ-based implementations. We map two\nreal-world COPs in electronic design automation-global routing and layer\nassignment-onto the Ising model and demonstrate high-quality results with an\nenergy efficiency of 25000 solutions per second per watt. This outperforms\nstate-of-the-art quantum and graphics processing units by six and seven orders\nof magnitude, respectively. These results establish voltage-controlled\nspintronics as a compelling route towards next-generation physics-inspired\nmachine intelligence, offering a paradigm for ultra-low-power, high-speed, and\nscalable computation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19106v1",
    "published": "2025-05-25T11:51:34+00:00",
    "categories": [
      "physics.app-ph",
      "cond-mat.dis-nn"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19105v2",
    "title": "Latent Mamba Operator for Partial Differential Equations",
    "authors": [
      "Karn Tiwari",
      "Niladri Dutta",
      "N M Anoop Krishnan",
      "Prathosh A P"
    ],
    "abstract": "Neural operators have emerged as powerful data-driven frameworks for solving\nPartial Differential Equations (PDEs), offering significant speedups over\nnumerical methods. However, existing neural operators struggle with scalability\nin high-dimensional spaces, incur high computational costs, and face challenges\nin capturing continuous and long-range dependencies in PDE dynamics. To address\nthese limitations, we introduce the Latent Mamba Operator (LaMO), which\nintegrates the efficiency of state-space models (SSMs) in latent space with the\nexpressive power of kernel integral formulations in neural operators. We also\nestablish a theoretical connection between state-space models (SSMs) and the\nkernel integral of neural operators. Extensive experiments across diverse PDE\nbenchmarks on regular grids, structured meshes, and point clouds covering solid\nand fluid physics datasets, LaMOs achieve consistent state-of-the-art (SOTA)\nperformance, with a 32.3% improvement over existing baselines in solution\noperator approximation, highlighting its efficacy in modeling complex PDE\nsolutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.19105v2",
    "published": "2025-05-25T11:51:31+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19104v1",
    "title": "Distributional Limit Theory for Optimal Transport",
    "authors": [
      "Eustasio del Barrio",
      "Alberto González-Sanz",
      "Jean-Michel Loubes",
      "David Rodríguez-Vítores"
    ],
    "abstract": "Optimal Transport (OT) is a resource allocation problem with applications in\nbiology, data science, economics and statistics, among others. In some of the\napplications, practitioners have access to samples which approximate the\ncontinuous measure. Hence the quantities of interest derived from OT -- plans,\nmaps and costs -- are only available in their empirical versions. Statistical\ninference on OT aims at finding confidence intervals of the population plans,\nmaps and costs. In recent years this topic gained an increasing interest in the\nstatistical community. In this paper we provide a comprehensive review of the\nmost influential results on this research field, underlying the some of the\napplications. Finally, we provide a list of open problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.19104v1",
    "published": "2025-05-25T11:45:36+00:00",
    "categories": [
      "math.ST",
      "stat.TH",
      "62G05, 62R10, 62G30"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.19103v1",
    "title": "WHISTRESS: Enriching Transcriptions with Sentence Stress Detection",
    "authors": [
      "Iddo Yosha",
      "Dorin Shteyman",
      "Yossi Adi"
    ],
    "abstract": "Spoken language conveys meaning not only through words but also through\nintonation, emotion, and emphasis. Sentence stress, the emphasis placed on\nspecific words within a sentence, is crucial for conveying speaker intent and\nhas been extensively studied in linguistics. In this work, we introduce\nWHISTRESS, an alignment-free approach for enhancing transcription systems with\nsentence stress detection. To support this task, we propose TINYSTRESS-15K, a\nscalable, synthetic training data for the task of sentence stress detection\nwhich resulted from a fully automated dataset creation process. We train\nWHISTRESS on TINYSTRESS-15K and evaluate it against several competitive\nbaselines. Our results show that WHISTRESS outperforms existing methods while\nrequiring no additional input priors during training or inference. Notably,\ndespite being trained on synthetic data, WHISTRESS demonstrates strong\nzero-shot generalization across diverse benchmarks. Project page:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/whistress.",
    "pdf_url": "http://arxiv.org/pdf/2505.19103v1",
    "published": "2025-05-25T11:45:08+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19102v1",
    "title": "Statistical inference for Linear Stochastic Approximation with Markovian Noise",
    "authors": [
      "Sergey Samsonov",
      "Marina Sheshukova",
      "Eric Moulines",
      "Alexey Naumov"
    ],
    "abstract": "In this paper we derive non-asymptotic Berry-Esseen bounds for Polyak-Ruppert\naveraged iterates of the Linear Stochastic Approximation (LSA) algorithm driven\nby the Markovian noise. Our analysis yields $\\mathcal{O}(n^{-1/4})$ convergence\nrates to the Gaussian limit in the Kolmogorov distance. We further establish\nthe non-asymptotic validity of a multiplier block bootstrap procedure for\nconstructing the confidence intervals, guaranteeing consistent inference under\nMarkovian sampling. Our work provides the first non-asymptotic guarantees on\nthe rate of convergence of bootstrap-based confidence intervals for stochastic\napproximation with Markov noise. Moreover, we recover the classical rate of\norder $\\mathcal{O}(n^{-1/8})$ up to logarithmic factors for estimating the\nasymptotic variance of the iterates of the LSA algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.19102v1",
    "published": "2025-05-25T11:43:28+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "math.ST",
      "stat.TH",
      "60F05, 62L20, 62E20"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.19101v2",
    "title": "Agentic Visualization: Extracting Agent-based Design Patterns from Visualization Systems",
    "authors": [
      "Vaishali Dhanoa",
      "Anton Wolter",
      "Gabriela Molina León",
      "Hans-Jörg Schulz",
      "Niklas Elmqvist"
    ],
    "abstract": "Autonomous agents powered by Large Language Models are transforming AI,\ncreating an imperative for the visualization field to embrace agentic\nframeworks. However, our field's focus on a human in the sensemaking loop\nraises critical questions about autonomy, delegation, and coordination for such\n\\textit{agentic visualization} that preserve human agency while amplifying\nanalytical capabilities. This paper addresses these questions by reinterpreting\nexisting visualization systems with semi-automated or fully automatic AI\ncomponents through an agentic lens. Based on this analysis, we extract a\ncollection of design patterns for agentic visualization, including agentic\nroles, communication and coordination. These patterns provide a foundation for\nfuture agentic visualization systems that effectively harness AI agents while\nmaintaining human insight and control.",
    "pdf_url": "http://arxiv.org/pdf/2505.19101v2",
    "published": "2025-05-25T11:40:38+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19100v1",
    "title": "ASPO: Adaptive Sentence-Level Preference Optimization for Fine-Grained Multimodal Reasoning",
    "authors": [
      "Yeyuan Wang",
      "Dehong Gao",
      "Rujiao Long",
      "Lei Yi",
      "Linbo Jin",
      "Libin Yang",
      "Xiaoyan Cai"
    ],
    "abstract": "Direct Preference Optimization (DPO) has gained significant attention for its\nsimplicity and computational efficiency in aligning large language models\n(LLMs). Recent advancements have extended DPO to multimodal scenarios,\nachieving strong performance. However, traditional DPO relies on binary\npreference optimization, rewarding or penalizing entire responses without\nconsidering fine-grained segment correctness, leading to suboptimal solutions.\nThe root of this issue lies in the absence of fine-grained supervision during\nthe optimization process. To address this, we propose Adaptive Sentence-level\nPreference Optimization (ASPO), which evaluates individual sentences for more\nprecise preference optimization. By dynamically calculating adaptive rewards at\nthe sentence level based on model predictions, ASPO enhances response content\nassessment without additional models or parameters. This significantly improves\nthe alignment of multimodal features. Extensive experiments show that ASPO\nsubstantially enhances the overall performance of multimodal models.",
    "pdf_url": "http://arxiv.org/pdf/2505.19100v1",
    "published": "2025-05-25T11:33:08+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19099v6",
    "title": "SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning",
    "authors": [
      "Kun Xiang",
      "Heng Li",
      "Terry Jingchen Zhang",
      "Yinya Huang",
      "Zirong Liu",
      "Peixin Qu",
      "Jixi He",
      "Jiaqi Chen",
      "Yu-Jie Yuan",
      "Jianhua Han",
      "Hang Xu",
      "Hanhui Li",
      "Mrinmaya Sachan",
      "Xiaodan Liang"
    ],
    "abstract": "We present SeePhys, a large-scale multimodal benchmark for LLM reasoning\ngrounded in physics questions ranging from middle school to PhD qualifying\nexams. The benchmark covers 7 fundamental domains spanning the physics\ndiscipline, incorporating 21 categories of highly heterogeneous diagrams. In\ncontrast to prior works where visual elements mainly serve auxiliary purposes,\nour benchmark features a substantial proportion of vision-essential problems\n(75%) that mandate visual information extraction for correct solutions. Through\nextensive evaluation, we observe that even the most advanced visual reasoning\nmodels (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60% accuracy on our\nbenchmark. These results reveal fundamental challenges in current large\nlanguage models' visual understanding capabilities, particularly in: (i)\nestablishing rigorous coupling between diagram interpretation and physics\nreasoning, and (ii) overcoming their persistent reliance on textual cues as\ncognitive shortcuts.",
    "pdf_url": "http://arxiv.org/pdf/2505.19099v6",
    "published": "2025-05-25T11:28:34+00:00",
    "categories": [
      "cs.AI",
      "physics.ed-ph",
      "physics.pop-ph"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19098v2",
    "title": "SPADE: Towards Scalable Path Planning Architecture on Actionable Multi-Domain 3D Scene Graphs",
    "authors": [
      "Vignesh Kottayam Viswanathan",
      "Akash Patel",
      "Mario Alberto Valdes Saucedo",
      "Sumeet Satpute",
      "Christoforos Kanellakis",
      "George Nikolakopoulos"
    ],
    "abstract": "In this work, we introduce SPADE, a path planning framework designed for\nautonomous navigation in dynamic environments using 3D scene graphs. SPADE\ncombines hierarchical path planning with local geometric awareness to enable\ncollision-free movement in dynamic scenes. The framework bifurcates the\nplanning problem into two: (a) solving the sparse abstract global layer plan\nand (b) iterative path refinement across denser lower local layers in step with\nlocal geometric scene navigation. To ensure efficient extraction of a feasible\nroute in a dense multi-task domain scene graphs, the framework enforces\ninformed sampling of traversable edges prior to path-planning. This removes\nextraneous information not relevant to path-planning and reduces the overall\nplanning complexity over a graph. Existing approaches address the problem of\npath planning over scene graphs by decoupling hierarchical and geometric path\nevaluation processes. Specifically, this results in an inefficient replanning\nover the entire scene graph when encountering path obstructions blocking the\noriginal route. In contrast, SPADE prioritizes local layer planning coupled\nwith local geometric scene navigation, enabling navigation through dynamic\nscenes while maintaining efficiency in computing a traversable route. We\nvalidate SPADE through extensive simulation experiments and real-world\ndeployment on a quadrupedal robot, demonstrating its efficacy in handling\ncomplex and dynamic scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.19098v2",
    "published": "2025-05-25T11:23:06+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19097v2",
    "title": "Towards Robust Influence Functions with Flat Validation Minima",
    "authors": [
      "Xichen Ye",
      "Yifan Wu",
      "Weizhong Zhang",
      "Cheng Jin",
      "Yifan Chen"
    ],
    "abstract": "The Influence Function (IF) is a widely used technique for assessing the\nimpact of individual training samples on model predictions. However, existing\nIF methods often fail to provide reliable influence estimates in deep neural\nnetworks, particularly when applied to noisy training data. This issue does not\nstem from inaccuracies in parameter change estimation, which has been the\nprimary focus of prior research, but rather from deficiencies in loss change\nestimation, specifically due to the sharpness of validation risk. In this work,\nwe establish a theoretical connection between influence estimation error,\nvalidation set risk, and its sharpness, underscoring the importance of flat\nvalidation minima for accurate influence estimation. Furthermore, we introduce\na novel estimation form of Influence Function specifically designed for flat\nvalidation minima. Experimental results across various tasks validate the\nsuperiority of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.19097v2",
    "published": "2025-05-25T11:20:28+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2507.21065v2",
    "title": "AI Pedagogy: Dialogic Social Learning for Artificial Agents",
    "authors": [
      "Sabrina Patania",
      "Luca Annese",
      "Cansu Koyuturk",
      "Azzurra Ruggeri",
      "Dimitri Ognibene"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nprocessing extensive offline datasets. However, they often face challenges in\nacquiring and integrating complex, knowledge online. Traditional AI training\nparadigms, predominantly based on supervised learning or reinforcement\nlearning, mirror a 'Piagetian' model of independent exploration. These\napproaches typically rely on large datasets and sparse feedback signals,\nlimiting the models' ability to learn efficiently from interactions. Drawing\ninspiration from Vygotsky's sociocultural theory, this study explores the\npotential of socially mediated learning paradigms to address these limitations.\n  We introduce a dynamic environment, termed the 'AI Social Gym', where an AI\nlearner agent engages in dyadic pedagogical dialogues with knowledgeable AI\nteacher agents. These interactions emphasize external, structured dialogue as a\ncore mechanism for knowledge acquisition, contrasting with methods that depend\nsolely on internal inference or pattern recognition.\n  Our investigation focuses on how different pedagogical strategies impact the\nAI learning process in the context of ontology acquisition. Empirical results\nindicate that such dialogic approaches-particularly those involving\nmixed-direction interactions combining top-down explanations with\nlearner-initiated questioning-significantly enhance the LLM's ability to\nacquire and apply new knowledge, outperforming both unidirectional\ninstructional methods and direct access to structured knowledge, formats\ntypically present in training datasets.\n  These findings suggest that integrating pedagogical and psychological\ninsights into AI and robot training can substantially improve post-training\nknowledge acquisition and response quality. This approach offers a\ncomplementary pathway to existing strategies like prompt engineering",
    "pdf_url": "http://arxiv.org/pdf/2507.21065v2",
    "published": "2025-05-25T11:19:48+00:00",
    "categories": [
      "cs.CL",
      "cs.HC",
      "cs.LG",
      "cs.RO",
      "I.2.7, I.2.9, j.4,"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19096v1",
    "title": "Enable Lightweight and Precision-Scalable Posit/IEEE-754 Arithmetic in RISC-V Cores for Transprecision Computing",
    "authors": [
      "Qiong Li",
      "Chao Fang",
      "Longwei Huang",
      "Jun Lin",
      "Zhongfeng Wang"
    ],
    "abstract": "While posit format offers superior dynamic range and accuracy for\ntransprecision computing, its adoption in RISC-V processors is hindered by the\nlack of a unified solution for lightweight, precision-scalable, and IEEE-754\narithmetic compatible hardware implementation. To address these challenges, we\nenhance RISC-V processors by 1) integrating dedicated posit codecs into the\noriginal FPU for lightweight implementation, 2) incorporating\nmulti/mixed-precision support with dynamic exponent size for\nprecision-scalability, and 3) reusing and customizing ISA extensions for\nIEEE-754 compatible posit operations. Our comprehensive evaluation spans the\nmodified FPU, RISC-V core, and SoC levels. It demonstrates that our\nimplementation achieves 47.9% LUTs and 57.4% FFs reduction compared to\nstate-of-the-art posit-enabled RISC-V processors, while achieving up to\n2.54$\\times$ throughput improvement in various GEMM kernels.",
    "pdf_url": "http://arxiv.org/pdf/2505.19096v1",
    "published": "2025-05-25T11:16:16+00:00",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19095v1",
    "title": "ScreenExplorer: Training a Vision-Language Model for Diverse Exploration in Open GUI World",
    "authors": [
      "Runliang Niu",
      "Jinglong Ji",
      "Yi Chang",
      "Qi Wang"
    ],
    "abstract": "The rapid progress of large language models (LLMs) has sparked growing\ninterest in building Artificial General Intelligence (AGI) within Graphical\nUser Interface (GUI) environments. However, existing GUI agents based on LLMs\nor vision-language models (VLMs) often fail to generalize to novel environments\nand rely heavily on manually curated, diverse datasets. To overcome these\nlimitations, we introduce ScreenExplorer, a VLM trained via Group Relative\nPolicy Optimization(GRPO) in real, dynamic, and open-ended GUI environments.\nInnovatively, we introduced a world-model-based curiosity reward function to\nhelp the agent overcome the cold-start phase of exploration. Additionally,\ndistilling experience streams further enhances the model's exploration\ncapabilities. Our training framework enhances model exploration in open GUI\nenvironments, with trained models showing better environmental adaptation and\nsustained exploration compared to static deployment models. Our findings offer\na scalable pathway toward AGI systems with self-improving capabilities in\ncomplex interactive settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.19095v1",
    "published": "2025-05-25T11:13:03+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19094v1",
    "title": "SATORI-R1: Incentivizing Multimodal Reasoning with Spatial Grounding and Verifiable Rewards",
    "authors": [
      "Chuming Shen",
      "Wei Wei",
      "Xiaoye Qu",
      "Yu Cheng"
    ],
    "abstract": "DeepSeek-R1 has demonstrated powerful reasoning capabilities in the text\ndomain through stable reinforcement learning (RL). Recently, in the multimodal\ndomain, works have begun to directly apply RL to generate R1-like free-form\nreasoning for Visual Question Answering (VQA) tasks. However, multimodal tasks\nshare an intrinsically different nature from textual tasks, which heavily rely\non the understanding of the input image to solve the problem. Therefore, such\nfree-form reasoning faces two critical limitations in the VQA task: (1)\nExtended reasoning chains diffuse visual focus away from task-critical regions,\ndegrading answer accuracy. (2) Unverifiable intermediate steps amplify\npolicy-gradient variance and computational costs overhead. To address these\nissues, in this paper, we introduce SATORI ($\\textbf{S}patially$\n$\\textbf{A}nchored$ $\\textbf{T}ask$ $\\textbf{O}ptimization$ with\n$\\textbf{R}e\\textbf{I}nforcement$ Learning), which decomposes VQA into three\nverifiable stages, including global image captioning, region localization, and\nanswer prediction, each supplying explicit reward signals. Furthermore, we also\nintroduce VQA-Verify, a 12k dataset annotated with answer-aligned captions and\nbounding-boxes to facilitate training. Experiments demonstrate consistent\nperformance improvements across seven VQA benchmarks, achieving up to $15.7\\%$\nimprovement in accuracy in accuracy compared to the R1-like baseline. Our\nanalysis of the attention map confirms enhanced focus on critical regions,\nwhich brings improvements in accuracy. Our code is available at\nhttps://github.com/justairr/SATORI-R1.",
    "pdf_url": "http://arxiv.org/pdf/2505.19094v1",
    "published": "2025-05-25T11:11:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19093v1",
    "title": "A Unified Framework for Variable Selection in Model-Based Clustering with Missing Not at Random",
    "authors": [
      "Binh H. Ho",
      "Long Nguyen Chi",
      "TrungTin Nguyen",
      "Binh T. Nguyen",
      "Van Ha Hoang",
      "Christopher Drovandi"
    ],
    "abstract": "Model-based clustering integrated with variable selection is a powerful tool\nfor uncovering latent structures within complex data. However, its\neffectiveness is often hindered by challenges such as identifying relevant\nvariables that define heterogeneous subgroups and handling data that are\nmissing not at random, a prevalent issue in fields like transcriptomics. While\nseveral notable methods have been proposed to address these problems, they\ntypically tackle each issue in isolation, thereby limiting their flexibility\nand adaptability. This paper introduces a unified framework designed to address\nthese challenges simultaneously. Our approach incorporates a data-driven\npenalty matrix into penalized clustering to enable more flexible variable\nselection, along with a mechanism that explicitly models the relationship\nbetween missingness and latent class membership. We demonstrate that, under\ncertain regularity conditions, the proposed framework achieves both asymptotic\nconsistency and selection consistency, even in the presence of missing data.\nThis unified strategy significantly enhances the capability and efficiency of\nmodel-based clustering, advancing methodologies for identifying informative\nvariables that define homogeneous subgroups in the presence of complex missing\ndata patterns. The performance of the framework, including its computational\nefficiency, is evaluated through simulations and demonstrated using both\nsynthetic and real-world transcriptomic datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.19093v1",
    "published": "2025-05-25T11:08:43+00:00",
    "categories": [
      "stat.ME",
      "cs.LG",
      "math.ST",
      "stat.AP",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.19092v1",
    "title": "Reinforced Latent Reasoning for LLM-based Recommendation",
    "authors": [
      "Yang Zhang",
      "Wenxin Xu",
      "Xiaoyan Zhao",
      "Wenjie Wang",
      "Fuli Feng",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning\ncapabilities in complex problem-solving tasks, sparking growing interest in\ntheir application to preference reasoning in recommendation systems. Existing\nmethods typically rely on fine-tuning with explicit chain-of-thought (CoT)\ndata. However, these methods face significant practical limitations due to (1)\nthe difficulty of obtaining high-quality CoT data in recommendation and (2) the\nhigh inference latency caused by generating CoT reasoning. In this work, we\nexplore an alternative approach that shifts from explicit CoT reasoning to\ncompact, information-dense latent reasoning. This approach eliminates the need\nfor explicit CoT generation and improves inference efficiency, as a small set\nof latent tokens can effectively capture the entire reasoning process. Building\non this idea, we propose $\\textit{\\underline{R}einforced \\underline{Latent}\n\\underline{R}easoning for \\underline{R}ecommendation}$ (LatentR$^3$), a novel\nend-to-end training framework that leverages reinforcement learning (RL) to\noptimize latent reasoning without relying on any CoT data.LatentR$^3$ adopts a\ntwo-stage training strategy: first, supervised fine-tuning to initialize the\nlatent reasoning module, followed by pure RL training to encourage exploration\nthrough a rule-based reward design. Our RL implementation is based on a\nmodified GRPO algorithm, which reduces computational overhead during training\nand introduces continuous reward signals for more efficient learning. Extensive\nexperiments demonstrate that LatentR$^3$ enables effective latent reasoning\nwithout any direct supervision of the reasoning process, significantly\nimproving performance when integrated with different LLM-based recommendation\nmethods. Our codes are available at https://anonymous.4open.science/r/R3-A278/.",
    "pdf_url": "http://arxiv.org/pdf/2505.19092v1",
    "published": "2025-05-25T11:03:45+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19091v1",
    "title": "ReadBench: Measuring the Dense Text Visual Reading Ability of Vision-Language Models",
    "authors": [
      "Benjamin Clavié",
      "Florian Brand"
    ],
    "abstract": "Recent advancements in Large Vision-Language Models (VLMs), have greatly\nenhanced their capability to jointly process text and images. However, despite\nextensive benchmarks evaluating visual comprehension (e.g., diagrams, color\nschemes, OCR tasks...), there is limited assessment of VLMs' ability to read\nand reason about text-rich images effectively. To fill this gap, we introduce\nReadBench, a multimodal benchmark specifically designed to evaluate the reading\ncomprehension capabilities of VLMs. ReadBench transposes contexts from\nestablished text-only benchmarks into images of text while keeping textual\nprompts and questions intact. Evaluating leading VLMs with ReadBench, we find\nminimal-but-present performance degradation on short, text-image inputs, while\nperformance sharply declines for longer, multi-page contexts. Our experiments\nfurther reveal that text resolution has negligible effects on multimodal\nperformance. These findings highlight needed improvements in VLMs, particularly\ntheir reasoning over visually presented extensive textual content, a capability\ncritical for practical applications. ReadBench is available at\nhttps://github.com/answerdotai/ReadBench .",
    "pdf_url": "http://arxiv.org/pdf/2505.19091v1",
    "published": "2025-05-25T11:02:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19090v1",
    "title": "CMoS: Rethinking Time Series Prediction Through the Lens of Chunk-wise Spatial Correlations",
    "authors": [
      "Haotian Si",
      "Changhua Pei",
      "Jianhui Li",
      "Dan Pei",
      "Gaogang Xie"
    ],
    "abstract": "Recent advances in lightweight time series forecasting models suggest the\ninherent simplicity of time series forecasting tasks. In this paper, we present\nCMoS, a super-lightweight time series forecasting model. Instead of learning\nthe embedding of the shapes, CMoS directly models the spatial correlations\nbetween different time series chunks. Additionally, we introduce a Correlation\nMixing technique that enables the model to capture diverse spatial correlations\nwith minimal parameters, and an optional Periodicity Injection technique to\nensure faster convergence. Despite utilizing as low as 1% of the lightweight\nmodel DLinear's parameters count, experimental results demonstrate that CMoS\noutperforms existing state-of-the-art models across multiple datasets.\nFurthermore, the learned weights of CMoS exhibit great interpretability,\nproviding practitioners with valuable insights into temporal structures within\nspecific application scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.19090v1",
    "published": "2025-05-25T11:01:53+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19089v1",
    "title": "Plug-and-Play Context Feature Reuse for Efficient Masked Generation",
    "authors": [
      "Xuejie Liu",
      "Anji Liu",
      "Guy Van den Broeck",
      "Yitao Liang"
    ],
    "abstract": "Masked generative models (MGMs) have emerged as a powerful framework for\nimage synthesis, combining parallel decoding with strong bidirectional context\nmodeling. However, generating high-quality samples typically requires many\niterative decoding steps, resulting in high inference costs. A straightforward\nway to speed up generation is by decoding more tokens in each step, thereby\nreducing the total number of steps. However, when many tokens are decoded\nsimultaneously, the model can only estimate the univariate marginal\ndistributions independently, failing to capture the dependency among them. As a\nresult, reducing the number of steps significantly compromises generation\nfidelity. In this work, we introduce ReCAP (Reused Context-Aware Prediction), a\nplug-and-play module that accelerates inference in MGMs by constructing\nlow-cost steps via reusing feature embeddings from previously decoded context\ntokens. ReCAP interleaves standard full evaluations with lightweight steps that\ncache and reuse context features, substantially reducing computation while\npreserving the benefits of fine-grained, iterative generation. We demonstrate\nits effectiveness on top of three representative MGMs (MaskGIT, MAGE, and MAR),\nincluding both discrete and continuous token spaces and covering diverse\narchitectural designs. In particular, on ImageNet256 class-conditional\ngeneration, ReCAP achieves up to 2.4x faster inference than the base model with\nminimal performance drop, and consistently delivers better efficiency-fidelity\ntrade-offs under various generation settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.19089v1",
    "published": "2025-05-25T10:57:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19088v1",
    "title": "Three integers whose sum, product and the sum of the products of the integers, taken two at a time, are perfect squares",
    "authors": [
      "Ajai Choudhry"
    ],
    "abstract": "Euler had considered the problem of finding three integers whose sum,\nproduct, and also the sum of the products of the integers, taken two at a time,\nare all perfect squares. Euler's methods of solving the problem lead to\nparametric solutions in terms of polynomials of high degrees and his numerical\nsolutions consisted of very large integers. We obtain, by a new method, several\nparametric solutions given by polynomials of much smaller degrees and thus we\nget a number of numerically small solutions of the problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.19088v1",
    "published": "2025-05-25T10:56:19+00:00",
    "categories": [
      "math.NT",
      "11D25"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19087v1",
    "title": "Temperature is All You Need for Generalization in Langevin Dynamics and other Markov Processes",
    "authors": [
      "Itamar Harel",
      "Yonathan Wolanowsky",
      "Gal Vardi",
      "Nathan Srebro",
      "Daniel Soudry"
    ],
    "abstract": "We analyze the generalization gap (gap between the training and test errors)\nwhen training a potentially over-parametrized model using a Markovian\nstochastic training algorithm, initialized from some distribution $\\theta_0\n\\sim p_0$. We focus on Langevin dynamics with a positive temperature\n$\\beta^{-1}$, i.e. gradient descent on a training loss $L$ with infinitesimal\nstep size, perturbed with $\\beta^{-1}$-variances Gaussian noise, and lightly\nregularized or bounded. There, we bound the generalization gap, at any time\nduring training, by $\\sqrt{(\\beta\\mathbb{E} L (\\theta_0) + \\log(1/\\delta))/N}$\nwith probability $1-\\delta$ over the dataset, where $N$ is the sample size, and\n$\\mathbb{E} L (\\theta_0) =O(1)$ with standard initialization scaling. In\ncontrast to previous guarantees, we have no dependence on either training time\nor reliance on mixing, nor a dependence on dimensionality, gradient norms, or\nany other properties of the loss or model. This guarantee follows from a\ngeneral analysis of any Markov process-based training that has a Gibbs-style\nstationary distribution. The proof is surprisingly simple, once we observe that\nthe marginal distribution divergence from initialization remains bounded, as\nimplied by a generalized second law of thermodynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.19087v1",
    "published": "2025-05-25T10:49:09+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19086v1",
    "title": "MaskedManipulator: Versatile Whole-Body Control for Loco-Manipulation",
    "authors": [
      "Chen Tessler",
      "Yifeng Jiang",
      "Erwin Coumans",
      "Zhengyi Luo",
      "Gal Chechik",
      "Xue Bin Peng"
    ],
    "abstract": "Humans interact with their world while leveraging precise full-body control\nto achieve versatile goals. This versatility allows them to solve long-horizon,\nunderspecified problems, such as placing a cup in a sink, by seamlessly\nsequencing actions like approaching the cup, grasping, transporting it, and\nfinally placing it in the sink. Such goal-driven control can enable new\nprocedural tools for animation systems, enabling users to define partial\nobjectives while the system naturally ``fills in'' the intermediate motions.\nHowever, while current methods for whole-body dexterous manipulation in\nphysics-based animation achieve success in specific interaction tasks, they\ntypically employ control paradigms (e.g., detailed kinematic motion tracking,\ncontinuous object trajectory following, or direct VR teleoperation) that offer\nlimited versatility for high-level goal specification across the entire coupled\nhuman-object system. To bridge this gap, we present MaskedManipulator, a\nunified and generative policy developed through a two-stage learning approach.\nFirst, our system trains a tracking controller to physically reconstruct\ncomplex human-object interactions from large-scale human mocap datasets. This\ntracking controller is then distilled into MaskedManipulator, which provides\nusers with intuitive control over both the character's body and the manipulated\nobject. As a result, MaskedManipulator enables users to specify complex\nloco-manipulation tasks through intuitive high-level objectives (e.g., target\nobject poses, key character stances), and MaskedManipulator then synthesizes\nthe necessary full-body actions for a physically simulated humanoid to achieve\nthese goals, paving the way for more interactive and life-like virtual\ncharacters.",
    "pdf_url": "http://arxiv.org/pdf/2505.19086v1",
    "published": "2025-05-25T10:46:14+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19085v1",
    "title": "Semantic-enhanced Co-attention Prompt Learning for Non-overlapping Cross-Domain Recommendation",
    "authors": [
      "Lei Guo",
      "Chenlong Song",
      "Feng Guo",
      "Xiaohui Han",
      "Xiaojun Chang",
      "Lei Zhu"
    ],
    "abstract": "Non-overlapping Cross-domain Sequential Recommendation (NCSR) is the task\nthat focuses on domain knowledge transfer without overlapping entities.\nCompared with traditional Cross-domain Sequential Recommendation (CSR), NCSR\nposes several challenges: 1) NCSR methods often rely on explicit item IDs,\noverlooking semantic information among entities. 2) Existing CSR mainly relies\non domain alignment for knowledge transfer, risking semantic loss during\nalignment. 3) Most previous studies do not consider the many-to-one\ncharacteristic, which is challenging because of the utilization of multiple\nsource domains. Given the above challenges, we introduce the prompt learning\ntechnique for Many-to-one Non-overlapping Cross-domain Sequential\nRecommendation (MNCSR) and propose a Text-enhanced Co-attention Prompt Learning\nParadigm (TCPLP). Specifically, we capture semantic meanings by representing\nitems through text rather than IDs, leveraging natural language universality to\nfacilitate cross-domain knowledge transfer. Unlike prior works that need to\nconduct domain alignment, we directly learn transferable domain information,\nwhere two types of prompts, i.e., domain-shared and domain-specific prompts,\nare devised, with a co-attention-based network for prompt encoding. Then, we\ndevelop a two-stage learning strategy, i.e., pre-train & prompt-tuning\nparadigm, for domain knowledge pre-learning and transferring, respectively. We\nconduct extensive experiments on three datasets and the experimental results\ndemonstrate the superiority of our TCPLP. Our source codes have been publicly\nreleased.",
    "pdf_url": "http://arxiv.org/pdf/2505.19085v1",
    "published": "2025-05-25T10:45:19+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19084v1",
    "title": "Jodi: Unification of Visual Generation and Understanding via Joint Modeling",
    "authors": [
      "Yifeng Xu",
      "Zhenliang He",
      "Meina Kan",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "abstract": "Visual generation and understanding are two deeply interconnected aspects of\nhuman intelligence, yet they have been traditionally treated as separate tasks\nin machine learning. In this paper, we propose Jodi, a diffusion framework that\nunifies visual generation and understanding by jointly modeling the image\ndomain and multiple label domains. Specifically, Jodi is built upon a linear\ndiffusion transformer along with a role switch mechanism, which enables it to\nperform three particular types of tasks: (1) joint generation, where the model\nsimultaneously generates images and multiple labels; (2) controllable\ngeneration, where images are generated conditioned on any combination of\nlabels; and (3) image perception, where multiple labels can be predicted at\nonce from a given image. Furthermore, we present the Joint-1.6M dataset, which\ncontains 200,000 high-quality images collected from public sources, automatic\nlabels for 7 visual domains, and LLM-generated captions. Extensive experiments\ndemonstrate that Jodi excels in both generation and understanding tasks and\nexhibits strong extensibility to a wider range of visual domains. Code is\navailable at https://github.com/VIPL-GENUN/Jodi.",
    "pdf_url": "http://arxiv.org/pdf/2505.19084v1",
    "published": "2025-05-25T10:40:52+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19083v1",
    "title": "Geometric Determinations Of Characteristic Redshifts From DESI-DR2 BAO and DES-SN5YR Observations: Hints For New Expansion Rate Anomalies",
    "authors": [
      "Purba Mukherjee",
      "Anjan A Sen"
    ],
    "abstract": "In this work, we perform a model-agnostic reconstruction of the cosmic\nexpansion history by combining DESI-DR2 BAO and DES-SN5YR data, with a focus on\ngeometric determination of characteristic redshifts where notable tensions in\nthe expansion rate are found to emerge. Employing Gaussian process regression\nalongside knot-based spline techniques, we reconstruct cosmic distances and\ntheir derivatives to pinpoint these characteristic redshifts and infer $E(z)$.\nOur analysis reveals significant deviations of approximately 4 to 5$\\sigma$\nfrom the Planck 2018 $\\Lambda$CDM predictions, particularly pronounced in the\nredshift range $z \\sim 0.35-0.55$. These anomalies are consistently observed\nacross both reconstruction methods and combined datasets, indicating robust\nlate-time departures that could signal new physics beyond the standard\ncosmological framework. The joint use of BAO and SN probes enhances the\nprecision of our constraints, allowing us to isolate these deviations without\nreliance on specific cosmological assumptions. Our findings underscore the role\nof characteristic redshifts as sensitive indicators of expansion rate anomalies\nand motivate further scrutiny with forthcoming datasets from DESI-5YR BAO,\nEuclid, and LSST. These future surveys will tighten constraints and help\ndistinguish whether these late-time anomalies arise from new fundamental\nphysics or unresolved systematics in the data.",
    "pdf_url": "http://arxiv.org/pdf/2505.19083v1",
    "published": "2025-05-25T10:40:02+00:00",
    "categories": [
      "astro-ph.CO",
      "cs.LG",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19082v1",
    "title": "A classification of rational 3-tangles",
    "authors": [
      "Bo-hyun Kwon"
    ],
    "abstract": "In this paper, we define the \\textit{normal form} and \\textit{normal\ncoordinate} of a rational 3-tangle $T$ with respect to $\\partial E_1$, where\n$E_1$ is the fixed two punctured disk in $\\Sigma_{0,6}$. Among all normal\ncoordinates of $T$ with respect to $\\partial E_1$, we investigate the\ncollection of \\textit{minimal} normal coordinates of $T$. We show that the\nsimplicial complex constructed with normal forms of the rational 3-tangle is\ncontractible. As an effectiveness of the contractibility of the simplicial\ncomplex by normal forms of $T$, we would choose a minimal normal coordinate of\n$T$ with a certain rule for the representative for the rational $3$-tangle $T$.\nThis classifies rational $3$-tangles up to isotopy.",
    "pdf_url": "http://arxiv.org/pdf/2505.19082v1",
    "published": "2025-05-25T10:38:51+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19081v2",
    "title": "Towards Generalized Proactive Defense against Face Swapping with Contour-Hybrid Watermark",
    "authors": [
      "Ruiyang Xia",
      "Dawei Zhou",
      "Decheng Liu",
      "Lin Yuan",
      "Jie Li",
      "Nannan Wang",
      "Xinbo Gao"
    ],
    "abstract": "Face swapping, recognized as a privacy and security concern, has prompted\nconsiderable defensive research. With the advancements in AI-generated content,\nthe discrepancies between the real and swapped faces have become nuanced.\nConsidering the difficulty of forged traces detection, we shift the focus to\nthe face swapping purpose and proactively embed elaborate watermarks against\nunknown face swapping techniques. Given that the constant purpose is to swap\nthe original face identity while preserving the background, we concentrate on\nthe regions surrounding the face to ensure robust watermark generation, while\nembedding the contour texture and face identity information to achieve\nprogressive image determination. The watermark is located in the facial contour\nand contains hybrid messages, dubbed the contour-hybrid watermark (CMark). Our\napproach generalizes face swapping detection without requiring any swapping\ntechniques during training and the storage of large-scale messages in advance.\nExperiments conducted across 8 face swapping techniques demonstrate the\nsuperiority of our approach compared with state-of-the-art passive and\nproactive detectors while achieving a favorable balance between the image\nquality and watermark robustness.",
    "pdf_url": "http://arxiv.org/pdf/2505.19081v2",
    "published": "2025-05-25T10:29:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19080v1",
    "title": "ReFineVLA: Reasoning-Aware Teacher-Guided Transfer Fine-Tuning",
    "authors": [
      "Tuan Van Vo",
      "Tan Quang Nguyen",
      "Khang Minh Nguyen",
      "Duy Ho Minh Nguyen",
      "Minh Nhat Vu"
    ],
    "abstract": "Vision-Language-Action (VLA) models have gained much attention from the\nresearch community thanks to their strength in translating multimodal\nobservations with linguistic instructions into robotic actions. Despite their\nrecent advancements, VLAs often overlook the explicit reasoning and only learn\nthe functional input-action mappings, omitting these crucial logical steps for\ninterpretability and generalization for complex, long-horizon manipulation\ntasks. In this work, we propose \\textit{ReFineVLA}, a multimodal\nreasoning-aware framework that fine-tunes VLAs with teacher-guided reasons. We\nfirst augment robotic datasets with reasoning rationales generated by an expert\nteacher model, guiding VLA models to learn to reason about their actions. Then,\nwe use \\textit{ReFineVLA} to fine-tune pre-trained VLAs with the\nreasoning-enriched datasets, while maintaining their inherent generalization\nabilities and boosting reasoning capabilities. In addition, we conduct an\nattention map visualization to analyze the alignment among visual attention,\nlinguistic prompts, and to-be-executed actions of \\textit{ReFineVLA},\nshowcasing its ability to focus on relevant tasks and actions. Through the\nlatter step, we explore that \\textit{ReFineVLA}-trained models exhibit a\nmeaningful attention shift towards relevant objects, highlighting the enhanced\nmultimodal understanding and improved generalization.\n  Evaluated across manipulation tasks, \\textit{ReFineVLA} outperforms the\nstate-of-the-art baselines. Specifically, it achieves an average increase of\n$5.0\\%$ success rate on SimplerEnv WidowX Robot tasks, improves by an average\nof $8.6\\%$ in variant aggregation settings, and by $1.7\\%$ in visual matching\nsettings for SimplerEnv Google Robot tasks. The source code will be publicly\navailable.",
    "pdf_url": "http://arxiv.org/pdf/2505.19080v1",
    "published": "2025-05-25T10:24:44+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19079v1",
    "title": "Non-Hermitian effects on the quantum parameter estimation in pseudo-Hermitian systems",
    "authors": [
      "L. H. Wei",
      "H. J. Xing",
      "L. B. Fu",
      "H. D. Liu"
    ],
    "abstract": "Quantum Fisher Information (QFI) is a fundamental quantity in quantum\nparameter estimation theory, characterizing the ultimate precision bound of\nparameter estimation. In this work, we investigate QFI for quantum states in\nnon-Hermitian systems. By employing the projected Hilbert space method and\nspectral decomposition, we derive an explicit expression for the QFI in terms\nof the density matrix and parameter generators. This formulation not only\nrecovers the well-known results in the Hermitian case but also captures the\nnon-Hermitian effects induced by the time-dependent norm of the state. To\nvalidate our theoretical framework, we analyze a single-qubit pseudo-Hermitian\nsystem and apply Naimark dilation theory to embed it into an equivalent\nHermitian system. The comparison between the original and dilated systems\ndemonstrates the consistency and applicability of the proposed QFI formula in\nnon-Hermitian settings. In addition, we investigate a $\\mathcal{PT}$-symmetric\nsystem to further explore the influence of non-Hermiticity on QFI. Our findings\noffer a new perspective for analyzing and enhancing QFI in non-Hermitian\nsystems, paving the way for promising applications in non-Hermitian quantum\nmetrology and sensing.",
    "pdf_url": "http://arxiv.org/pdf/2505.19079v1",
    "published": "2025-05-25T10:23:57+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19078v1",
    "title": "Proceedings 16th International Workshop on Programming Language Approaches to Concurrency and Communication-cEntric Software",
    "authors": [
      "Farzaneh Derakhshan",
      "Jan Hoffmann"
    ],
    "abstract": "This volume contains the proceedings of PLACES 2025, the 16th edition of the\nWorkshop on Programming Language Approaches to Concurrency and\nCommunication-cEntric Software. The workshop is scheduled to take place in\nHamilton, Canada, on May 4, 2025, as a satellite event of ETAPS, the European\nJoint Conferences on Theory and Practice of Software. PLACES offers a forum for\nexchanging new ideas on how to address the challenges of concurrent and\ndistributed programming and how to improve the foundations of modern and future\ncomputer applications. PLACES welcomes researchers from various fields, and its\ntopics include the design of new programming languages, models for concurrent\nand distributed systems, type systems, program verification, and applications\nin various areas (e.g., microservices, sensor networks, blockchains, event\nprocessing, business process management).",
    "pdf_url": "http://arxiv.org/pdf/2505.19078v1",
    "published": "2025-05-25T10:23:50+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19077v1",
    "title": "An Autocovariance Least-Squares-Based Data-Driven Kalman Filter for Unknown Systems",
    "authors": [
      "Suyang Hu",
      "Xiaoxu Lyu",
      "Peihu Duan",
      "Dawei Shi",
      "Ling Shi"
    ],
    "abstract": "This article investigates the problem of data-driven state estimation for\nlinear systems with both unknown system dynamics and noise covariances. We\npropose an Autocovariance Least-squares-based Data-driven Kalman Filter (ADKF),\nwhich provides a unified framework for simultaneous system identification and\nstate estimation by utilizing pre-collected input-output trajectories and\nestimated initial states. Specifically, we design a SDP-based algorithm for\nestimating the noise covariances. We quantify the impact of model inaccuracy on\nnoise covariances estimation using this identification algorithm, and introduce\na feedback control mechanism for data collection to enhance the accuracy and\nstability of noise covariance estimation. The estimated noise covariances\naccount for model inaccuracy, which are shown to be more suitable for state\nestimation. We also quantify the performance gap between the ADKF and the\ntraditional Kalman filter with known system dynamics and noise covariances,\nshowing that this gap decreases as the number and length of pre-collected\ntrajectories increase. Finally, numerical simulations validate the robustness\nand effectiveness of the proposed ADKF.",
    "pdf_url": "http://arxiv.org/pdf/2505.19077v1",
    "published": "2025-05-25T10:21:38+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.19076v1",
    "title": "ChartSketcher: Reasoning with Multimodal Feedback and Reflection for Chart Understanding",
    "authors": [
      "Muye Huang",
      "Lingling Zhang",
      "Jie Ma",
      "Han Lai",
      "Fangzhi Xu",
      "Yifei Li",
      "Wenjun Wu",
      "Yaqiang Wu",
      "Jun Liu"
    ],
    "abstract": "Charts are high-density visualization carriers for complex data, serving as a\ncrucial medium for information extraction and analysis. Automated chart\nunderstanding poses significant challenges to existing multimodal large\nlanguage models (MLLMs) due to the need for precise and complex visual\nreasoning. Current step-by-step reasoning models primarily focus on text-based\nlogical reasoning for chart understanding. However, they struggle to refine or\ncorrect their reasoning when errors stem from flawed visual understanding, as\nthey lack the ability to leverage multimodal interaction for deeper\ncomprehension. Inspired by human cognitive behavior, we propose ChartSketcher,\na multimodal feedback-driven step-by-step reasoning method designed to address\nthese limitations. ChartSketcher is a chart understanding model that employs\nSketch-CoT, enabling MLLMs to annotate intermediate reasoning steps directly\nonto charts using a programmatic sketching library, iteratively feeding these\nvisual annotations back into the reasoning process. This mechanism enables the\nmodel to visually ground its reasoning and refine its understanding over\nmultiple steps. We employ a two-stage training strategy: a cold start phase to\nlearn sketch-based reasoning patterns, followed by off-policy reinforcement\nlearning to enhance reflection and generalization. Experiments demonstrate that\nChartSketcher achieves promising performance on chart understanding benchmarks\nand general vision tasks, providing an interactive and interpretable approach\nto chart comprehension.",
    "pdf_url": "http://arxiv.org/pdf/2505.19076v1",
    "published": "2025-05-25T10:21:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19075v2",
    "title": "Universal Reasoner: A Single, Composable Plug-and-Play Reasoner for Frozen LLMs",
    "authors": [
      "Jaemin Kim",
      "Hangeol Chang",
      "Hyunmin Hwang",
      "Choonghan Kim",
      "Jong Chul Ye"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable general\ncapabilities, but enhancing skills such as reasoning often demands substantial\ncomputational resources and may compromise their generalization. While\nParameter-Efficient Fine-Tuning (PEFT) methods offer a more resource-conscious\nalternative, they typically requires retraining for each LLM backbone due to\narchitectural dependencies. To address these challenges, here we propose\nUniversal Reasoner (UniR) - a single, lightweight, composable, and\nplug-and-play reasoning module that can be used with any frozen LLM to endow it\nwith specialized reasoning capabilities. Specifically, UniR decomposes the\nreward into a standalone reasoning module that is trained independently using\npredefined rewards, effectively translating trajectory-level signals into\ntoken-level guidance. Once trained, UniR can be combined with any frozen LLM at\ninference time by simply adding its output logits to those of the LLM backbone.\nThis additive structure naturally enables modular composition: multiple UniR\nmodules trained for different tasks can be jointly applied by summing their\nlogits, enabling complex reasoning via composition. Experimental results on\nmathematical reasoning and machine translation tasks show that UniR\nsignificantly outperforms existing baseline fine-tuning methods using the\nLlama3.2 model. Furthermore, UniR demonstrates strong weak-to-strong\ngeneralization: reasoning modules trained on smaller models effectively guide\nmuch larger LLMs. This makes UniR a cost-efficient, adaptable, and robust\nsolution for enhancing reasoning in LLMs without compromising their core\ncapabilities. Code is open-sourced at https://github.com/hangeol/UniR",
    "pdf_url": "http://arxiv.org/pdf/2505.19075v2",
    "published": "2025-05-25T10:19:10+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19074v1",
    "title": "Uniqueness and nonuniqueness of $p$-harmonic Green functions on weighted $\\mathbf{R}^n$ and metric spaces",
    "authors": [
      "Anders Björn",
      "Jana Björn",
      "Sylvester Eriksson-Bique",
      "Xiaodan Zhou"
    ],
    "abstract": "We study uniqueness of $p$-harmonic Green functions in domains $\\Omega$ in a\ncomplete metric space equipped with a doubling measure supporting a\n$p$-Poincar\\'e inequality, with $1<p<\\infty$. For bounded domains in unweighted\n$\\mathbf{R}^n$, the uniqueness was shown for the $p$-Laplace operator\n$\\Delta_p$ and all $p$ by Kichenassamy--V\\'eron (Math. Ann. 275 (1986),\n599-615), while for $p=2$ it is an easy consequence of the linearity of the\nLaplace operator $\\Delta$. Beyond that, uniqueness is only known in some\nparticular cases, such as in Ahlfors $p$-regular spaces, as shown by\nBonk--Capogna--Zhou (arXiv:2211.11974). When the singularity $x_0$ has positive\n$p$-capacity, the Green function is a particular multiple of the capacitary\npotential for $\\text{cap}_p(\\{x_0\\},\\Omega)$ and is therefore unique. Here we\ngive a sufficient condition for uniqueness in metric spaces, and provide an\nexample showing that the range of $p$ for which it holds (while $x_0$ has zero\n$p$-capacity) can be a nondegenerate interval. In the opposite direction, we\ngive the first example showing that uniqueness can fail in metric spaces, even\nfor $p=2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.19074v1",
    "published": "2025-05-25T10:18:17+00:00",
    "categories": [
      "math.AP",
      "Primary: 35J08, Secondary: 30L99, 31C45, 31E05, 35J92, 49Q20"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19073v2",
    "title": "Towards Harmonized Uncertainty Estimation for Large Language Models",
    "authors": [
      "Rui Li",
      "Jing Long",
      "Muge Qi",
      "Heming Xia",
      "Lei Sha",
      "Peiyi Wang",
      "Zhifang Sui"
    ],
    "abstract": "To facilitate robust and trustworthy deployment of large language models\n(LLMs), it is essential to quantify the reliability of their generations\nthrough uncertainty estimation. While recent efforts have made significant\nadvancements by leveraging the internal logic and linguistic features of LLMs\nto estimate uncertainty scores, our empirical analysis highlights the pitfalls\nof these methods to strike a harmonized estimation between indication, balance,\nand calibration, which hinders their broader capability for accurate\nuncertainty estimation. To address this challenge, we propose CUE (Corrector\nfor Uncertainty Estimation): A straightforward yet effective method that\nemploys a lightweight model trained on data aligned with the target LLM's\nperformance to adjust uncertainty scores. Comprehensive experiments across\ndiverse models and tasks demonstrate its effectiveness, which achieves\nconsistent improvements of up to 60% over existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.19073v2",
    "published": "2025-05-25T10:17:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19072v1",
    "title": "Hybrid Grothendieck polynomials",
    "authors": [
      "Peter L. Guo",
      "Mingyang Kang",
      "Jiaji Liu"
    ],
    "abstract": "For a skew shape $\\lambda/\\mu$, we define the hybrid Grothendieck polynomial\n$${G}_{\\lambda/\\mu}(\\textbf{x};\\textbf{t};\\textbf{w}) =\\sum_{T\\in\n\\mathrm{SVRPP}(\\lambda/\\mu)}\n\\textbf{x}^{\\mathrm{ircont}(T)}\\textbf{t}^{\\mathrm{ceq}\n(T)}\\textbf{w}^{\\mathrm{ex}(T)}$$ as a weight generating function over\nset-valued reverse plane partitions of shape $\\lambda/\\mu$. It specializes to\n\\begin{itemize}\n  \\item[(1)] the refined\n  stable Grothendieck polynomial introduced by Chan--Pflueger by setting all\n$t_i=0$;\n  \\item[(2)] the refined dual stable Grothendieck polynomial introduced by\nGalashin--Grinberg--Liu by setting all $w_i=0$. \\end{itemize}\n  We show that ${G}_{\\lambda/\\mu}(\\textbf{x};\\textbf{t};\\textbf{w})$ is\nsymmetric in the $\\textbf{x}$ variables. By building a crystal structure on\nset-valued reverse plane partitions, we obtain the expansion of\n${G}_{\\lambda/\\mu}(\\textbf{x};\\textbf{t};\\textbf{w})$ in the basis of Schur\nfunctions, extending previous work by Monical--Pechenik--Scrimshaw and\nGalashin. Based on the Schur expansion, we deduce that hybrid Grothendieck\npolynomials of straight shapes have saturated Newton polytopes. Finally, using\nFomin--Greene's theory on noncommutative Schur functions, we give a\ncombinatorial formula for the image of\n${G}_{\\lambda/\\mu}(\\textbf{x};\\textbf{t};\\textbf{w})$ (in the case $t_i=\\alpha$\nand $w_i=\\beta$) under the omega involution on symmetric functions. The formula\nunifies the structures of weak set-valued tableaux and valued-set tableaux\nintroduced by Lam--Pylyavskyy. Several problems and conjectures are motivated\nand discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.19072v1",
    "published": "2025-05-25T10:10:30+00:00",
    "categories": [
      "math.CO",
      "math.AG",
      "math.RT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19071v1",
    "title": "Coherence, Transport, and Chaos in 1D Bose-Hubbard Model: Disorder vs. Stark Potential",
    "authors": [
      "Asad Ali",
      "M. I. Hussain",
      "Saif Al-Kuwari",
      "M. T. Rahim",
      "H. Kuniyil",
      "Seyed Mohammad Hosseiny",
      "Jamileh Seyed-Yazdi",
      "Hamid Arian Zad",
      "Saeed Haddadi"
    ],
    "abstract": "We study quantum coherence and phase transitions in a finite-size\none-dimensional Bose-Hubbard model using exact numerical diagonalization. The\nsystem is investigated under the competing effects of thermal fluctuations, a\nStark potential, and a disorder term. We compute several observables, including\nthe condensate fraction, superfluid fraction, visibility, number fluctuations,\nand the $\\ell_1$-norm of quantum coherence, to characterize the transition from\nthe Mott insulator to the superfluid phase. In the standard Bose-Hubbard model,\nground-state properties exhibit signatures of a quantum phase transition under\nopen boundary conditions. While finite-size effects preclude an exact\nrealization of the thermodynamic transition, our findings serve as indicators\nof the underlying quantum critical behavior of the disordered Bose-Hubbard\nmodel. At finite temperatures, this critical point shifts to a smooth\ncrossover, reflecting the suppression of long-range coherence typical of larger\nsystems. A nonzero Stark potential delays this crossover, promoting\nlocalization and the formation of non-superfluid condensates. In contrast,\nthermal fluctuations can induce unexpected coherence through fluctuation-driven\ntunneling. Disorder disrupts superfluidity but preserves local coherence, with\nthermal states exhibiting an enhanced $\\ell_1$-norm of coherence within the\nBose glass regime. Our results highlight how disorder, tilt, and temperature\njointly reshape the coherence landscape, and offer valuable insights for\nquantum simulation and the characterization of quantum phases in strongly\ncorrelated systems. Non-ergodic behavior is observed in the clean system where\nthe mean gap ratio stays below Poisson and Gaussian orthogonal ensemble (GOE)\nvalues. With a Stark potential, level statistics shift from Poisson-like to\nnear-GOE as tunneling increases, which indicates a crossover to semi-ergodic\ndynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.19071v1",
    "published": "2025-05-25T10:08:24+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.19070v1",
    "title": "Quantum phase transition in a 2D atomic Bose gas with a g-wave Feshbach resonance",
    "authors": [
      "Fan Zhang",
      "Lan Yin"
    ],
    "abstract": "Recent repoet on the formation of two-dimensional Bose-Einstein condensates\n(BECs) of spinning g-wave molecules is surprise. Here we study quantum phase\ntransition in the quasi-2D atomic Bose gas with a g-wave Feshbach resonance,\nand show that there are two phase transitions in this system: from a phase with\nonly a atomic Bose-Einstein condensate to a phase with coexistence of atomic\nand molecular condensation and from the coexistence phase to a phase with only\na molecular Bose-Einstein condensate. We show that the g-wave resonance\nFeshbach has two features in the phase transitions, a phase with only a atomic\nBose-Einstein condensate is no longer forbidden and resonance effects appear\nonly at levels beyond the mean-field. We determine the T=0 beyond mean-field\nphase diagram of the gas as a function of magnetic field and molecular\ncondensation density. We also detemine the ratio of atomic to molecular\ncondensation in the coexistence phase, which can be tested in experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.19070v1",
    "published": "2025-05-25T10:07:11+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19069v1",
    "title": "Failure divergence refinement for Event-B",
    "authors": [
      "Sebastian Stock",
      "Michael Leuschel",
      "Atif Mashkoor"
    ],
    "abstract": "When validating formal models, sizable effort goes into ensuring two types of\nproperties: safety properties (nothing bad happens) and liveness properties\n(something good occurs eventually. Event-B supports checking safety properties\nall through the refinement chain. The same is not valid for liveness\nproperties. Liveness properties are commonly validated with additional\ntechniques like animation, and results do not transfer quickly, leading to\nre-doing the validation process at every refinement stage. This paper promotes\nearly validation by providing failure divergence refinement semantics for\nEvent-B. We show that failure divergence refinement preserves trace properties,\nwhich comprise many liveness properties, under certain natural conditions.\nConsequently, re-validation of those properties becomes unnecessary. Our result\nbenefits data refinements, where no abstract behavior should be removed during\nrefinement. Furthermore, we lay out an algorithm and provide a tool for\nautomatic failure divergence refinement checking, significantly decreasing the\nmodeler's workload. The tool is compared and evaluated in the context of\nsizable case studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.19069v1",
    "published": "2025-05-25T10:07:09+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19068v2",
    "title": "Recalibrating binary probabilistic classifiers",
    "authors": [
      "Dirk Tasche"
    ],
    "abstract": "Recalibration of binary probabilistic classifiers to a target prior\nprobability is an important task in areas like credit risk management. We\nanalyse methods for recalibration from a distribution shift perspective.\nDistribution shift assumptions linked to the area under the curve (AUC) of a\nprobabilistic classifier are found to be useful for the design of meaningful\nrecalibration methods. Two new methods called parametric covariate shift with\nposterior drift (CSPD) and ROC-based quasi moment matching (QMM) are proposed\nand tested together with some other methods in an example setting. The outcomes\nof the test suggest that the QMM methods discussed in the paper can provide\nappropriately conservative results in evaluations with concave functionals like\nfor instance risk weights functions for credit risk.",
    "pdf_url": "http://arxiv.org/pdf/2505.19068v2",
    "published": "2025-05-25T10:04:46+00:00",
    "categories": [
      "cs.LG",
      "q-fin.RM",
      "68T09, 91G40",
      "I.5.1; G.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19067v1",
    "title": "Revisiting the infrared/X-ray correlation of GX 339-4 based on a jet model",
    "authors": [
      "Chang-Yin Huang",
      "Yi Xie"
    ],
    "abstract": "The infrared (IR)/X-ray correlation of GX 339$-$4 is investigated based on a\njet model with a modification by linking the magnetic field at the jet base to\nthe accretion rate of the inner accretion flow though the the equilibrium\nbetween magnetic pressure at horizon and the ram pressure of the accretion\nflow. The IR flux is attributed to the synchrotron radiation of the jet, and\nthe X-ray flux is attributed to the advective dominated accretion flow (ADAF),\nsynchrotron radiation of the jet and synchrotron self-Compton scattering (SSC)\nof the jet, respectively. We find that the observed IR/X-ray correlation with a\nbreak is well reproduced with the variation of the accretion rate if the X-ray\nflux originates from SSC of the jet. Either a conical ballistic jet with the\nmagnetic field parallel to the jet axis or a conical adiabatic jet with an\nisotropic field can account for the correlation. The power-law index of the\nenergy distribution of electrons $p\\sim3$, the minimum Lorentz factor of the\nelectrons $\\gamma_{\\rm min}\\sim60$, the magnetic field $B_0\\sim10^5\\ {\\rm G}$\nand the jet radius $R_0\\sim10^{10}\\ {\\rm cm}$ at the jet base are required for\nboth the ballistic jet and the adiabatic jet. This study helps us clarify the\ncomplex interaction between the accretion and jet in GX 339$-$4, as well as the\nproperties and geometric structure of the jet, laying the groundwork for\nexploring similar astrophysical systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.19067v1",
    "published": "2025-05-25T09:55:29+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.19066v1",
    "title": "Bootstrapping the Cosmological Collider with Resonant Features",
    "authors": [
      "Dong-Gang Wang",
      "Bowei Zhang"
    ],
    "abstract": "Signatures of heavy particles during inflation are exponentially suppressed\nby the Boltzmann factor when the masses are far above the Hubble scale. In more\nrealistic scenarios, however, scale-dependent features may change this\nconventional picture and boost the cosmological collider signals. In this\npaper, we compute cosmological correlators of the primordial curvature\nperturbations exchanging an intermediate heavy field with periodically varying\ncouplings. The basic setup corresponds to inflation scenarios with globally\noscillating features that enjoy a discrete shift symmetry. Adopting the\nbootstrap approach, we derive and solve the boundary differential equations\nthat are satisfied by the massive-exchange three-point functions. The presence\nof the oscillatory couplings leads to resonance-enhanced cosmological collider\nsignals for heavy fields when the oscillating frequency exceeds the field\nmasses. Meanwhile, the forms of these differential equations are modified,\nwhich generates new shapes of primordial non-Gaussianity as a combination of\nresonant features and collider signals. Based on these computations, we revisit\nthe string-inspired model of axion monodromy inflation and point out that the\ncosmological correlators can become sensitive to heavy moduli fields of flux\ncompactifications. This finding suggests a breakdown of the conventional\nsingle-field description, as the heavy moduli may not be simply integrated out\nbut yield detectably large signals in the primordial bispectrum.",
    "pdf_url": "http://arxiv.org/pdf/2505.19066v1",
    "published": "2025-05-25T09:50:16+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.19065v1",
    "title": "MMP-2K: A Benchmark Multi-Labeled Macro Photography Image Quality Assessment Database",
    "authors": [
      "Jiashuo Chang",
      "Zhengyi Li",
      "Jianxun Lou",
      "Zhen Qiu",
      "Hanhe Lin"
    ],
    "abstract": "Macro photography (MP) is a specialized field of photography that captures\nobjects at an extremely close range, revealing tiny details. Although an\naccurate macro photography image quality assessment (MPIQA) metric can benefit\nmacro photograph capturing, which is vital in some domains such as scientific\nresearch and medical applications, the lack of MPIQA data limits the\ndevelopment of MPIQA metrics. To address this limitation, we conducted a\nlarge-scale MPIQA study. Specifically, to ensure diversity both in content and\nquality, we sampled 2,000 MP images from 15,700 MP images, collected from three\npublic image websites. For each MP image, 17 (out of 21 after outlier removal)\nquality ratings and a detailed quality report of distortion magnitudes, types,\nand positions are gathered by a lab study. The images, quality ratings, and\nquality reports form our novel multi-labeled MPIQA database, MMP-2k.\nExperimental results showed that the state-of-the-art generic IQA metrics\nunderperform on MP images. The database and supplementary materials are\navailable at https://github.com/Future-IQA/MMP-2k.",
    "pdf_url": "http://arxiv.org/pdf/2505.19065v1",
    "published": "2025-05-25T09:47:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19064v1",
    "title": "Thermoelectric performance of Ni-Au metallic alloys determined by resonant scattering",
    "authors": [
      "Kacper Pryga",
      "Bartlomiej Wiendlocha"
    ],
    "abstract": "This work presents a theoretical study of the electronic structure and\ntransport properties of Ni-Au alloys, recently identified as excellent\nthermoelectric metals with a power factor significantly exceeding that of\nconventional semiconductor thermoelectrics. Using first-principles calculations\nbased on the Korringa-Kohn-Rostoker method combined with the coherent-potential\napproximation (KKR-CPA) and the Kubo-Greenwood formalism, we demonstrate the\nkey role of resonant scattering in determining the thermoelectric properties of\nthese alloys. This is supported by calculated densities of states, Bloch\nspectral functions, electrical conductivity, and thermopower. Alloying Ni with\nAu not only induces resonant scattering but also leads to the formation of a\nflat band below the Fermi level. The combination of these two features results\nin high thermopower, arising from a transition between resonant and weak\nscattering regimes near the Fermi level. Our findings are further compared with\nanalogous calculations for constantan, a Ni-Cu alloy long regarded as a\nreference thermoelectric metal. We show that differences between the Ni-Au and\nNi-Cu systems explain why Ni-Au exhibits nearly twice the thermopower of Ni-Cu.\nFinally, we simulate the effect of lattice parameter variation on the\nthermoelectric performance of Ni-Au and suggest that this is a promising\npathway for further enhancement, for example through additional alloying or\nlayer deposition.",
    "pdf_url": "http://arxiv.org/pdf/2505.19064v1",
    "published": "2025-05-25T09:44:53+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.19063v2",
    "title": "Training-free Stylized Text-to-Image Generation with Fast Inference",
    "authors": [
      "Xin Ma",
      "Yaohui Wang",
      "Xinyuan Chen",
      "Tien-Tsin Wong",
      "Cunjian Chen"
    ],
    "abstract": "Although diffusion models exhibit impressive generative capabilities,\nexisting methods for stylized image generation based on these models often\nrequire textual inversion or fine-tuning with style images, which is\ntime-consuming and limits the practical applicability of large-scale diffusion\nmodels. To address these challenges, we propose a novel stylized image\ngeneration method leveraging a pre-trained large-scale diffusion model without\nrequiring fine-tuning or any additional optimization, termed as OmniPainter.\nSpecifically, we exploit the self-consistency property of latent consistency\nmodels to extract the representative style statistics from reference style\nimages to guide the stylization process. Additionally, we then introduce the\nnorm mixture of self-attention, which enables the model to query the most\nrelevant style patterns from these statistics for the intermediate output\ncontent features. This mechanism also ensures that the stylized results align\nclosely with the distribution of the reference style images. Our qualitative\nand quantitative experimental results demonstrate that the proposed method\noutperforms state-of-the-art approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.19063v2",
    "published": "2025-05-25T09:38:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19062v1",
    "title": "State-based nested iteration solution of optimal control problems with PDE constraints",
    "authors": [
      "Ulrich Langer",
      "Richard Löscher",
      "Olaf Steinbach",
      "Huidong Yang"
    ],
    "abstract": "We consider an abstract framework for the numerical solution of optimal\ncontrol problems (OCPs) subject to partial differential equations (PDEs).\nExamples include not only the distributed control of elliptic PDEs such as the\nPoisson equation discussed in this paper in detail but also parabolic and\nhyperbolic equations. The approach covers the standard $L^2$ setting as well as\nthe more recent energy regularization, also including state and control\nconstraints. We discretize OCPs subject to parabolic or hyperbolic PDEs by\nmeans of space-time finite elements similar as in the elliptic case. We discuss\nregularization and finite element error estimates, and derive an optimal\nrelation between the regularization parameter and the finite element mesh size\nin order to balance the accuracy, and the energy costs for the corresponding\ncontrol. Finally, we also discuss the efficient solution of the resulting\nsystems of algebraic equations, and their use in a state-based nested iteration\nprocedure that allows us to compute finite element approximations to the state\nand the control in asymptotically optimal complexity. The numerical results\nillustrate the theoretical findings quantitatively.",
    "pdf_url": "http://arxiv.org/pdf/2505.19062v1",
    "published": "2025-05-25T09:37:37+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "49J20, 49M05, 35J05, 65M60, 65N22, 65F10"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19061v1",
    "title": "Adversarial Bandit over Bandits: Hierarchical Bandits for Online Configuration Management",
    "authors": [
      "Chen Avin",
      "Zvi Lotker",
      "Shie Mannor",
      "Gil Shabat",
      "Hanan Shteingart",
      "Roey Yadgar"
    ],
    "abstract": "Motivated by dynamic parameter optimization in finite, but large action\n(configurations) spaces, this work studies the nonstochastic multi-armed bandit\n(MAB) problem in metric action spaces with oblivious Lipschitz adversaries. We\npropose ABoB, a hierarchical Adversarial Bandit over Bandits algorithm that can\nuse state-of-the-art existing \"flat\" algorithms, but additionally clusters\nsimilar configurations to exploit local structures and adapt to changing\nenvironments. We prove that in the worst-case scenario, such clustering\napproach cannot hurt too much and ABoB guarantees a standard worst-case regret\nbound of $O\\left(k^{\\frac{1}{2}}T^{\\frac{1}{2}}\\right)$, where $T$ is the\nnumber of rounds and $k$ is the number of arms, matching the traditional flat\napproach. However, under favorable conditions related to the algorithm\nproperties, clusters properties, and certain Lipschitz conditions, the regret\nbound can be improved to $O\\left(k^{\\frac{1}{4}}T^{\\frac{1}{2}}\\right)$.\nSimulations and experiments on a real storage system demonstrate that ABoB,\nusing standard algorithms like EXP3 and Tsallis-INF, achieves lower regret and\nfaster convergence than the flat method, up to 50% improvement in known\nprevious setups, nonstochastic and stochastic, as well as in our settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.19061v1",
    "published": "2025-05-25T09:30:47+00:00",
    "categories": [
      "cs.LG",
      "cs.MA",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19060v1",
    "title": "UNCERTAINTY-LINE: Length-Invariant Estimation of Uncertainty for Large Language Models",
    "authors": [
      "Roman Vashurin",
      "Maiya Goloburda",
      "Preslav Nakov",
      "Maxim Panov"
    ],
    "abstract": "Large Language Models (LLMs) have become indispensable tools across various\napplications, making it more important than ever to ensure the quality and the\ntrustworthiness of their outputs. This has led to growing interest in\nuncertainty quantification (UQ) methods for assessing the reliability of LLM\noutputs. Many existing UQ techniques rely on token probabilities, which\ninadvertently introduces a bias with respect to the length of the output. While\nsome methods attempt to account for this, we demonstrate that such biases\npersist even in length-normalized approaches. To address the problem, here we\npropose UNCERTAINTY-LINE: (Length-INvariant Estimation), a simple debiasing\nprocedure that regresses uncertainty scores on output length and uses the\nresiduals as corrected, length-invariant estimates. Our method is post-hoc,\nmodel-agnostic, and applicable to a range of UQ measures. Through extensive\nevaluation on machine translation, summarization, and question-answering tasks,\nwe demonstrate that UNCERTAINTY-LINE: consistently improves over even nominally\nlength-normalized UQ methods uncertainty estimates across multiple metrics and\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.19060v1",
    "published": "2025-05-25T09:30:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19059v1",
    "title": "An Initial Exploration of Fine-tuning Small Language Models for Smart Contract Reentrancy Vulnerability Detection",
    "authors": [
      "Ignacio Mariano Andreozzi Pofcher",
      "Joshua Ellul"
    ],
    "abstract": "Large Language Models (LLMs) are being used more and more for various coding\ntasks, including to help coders identify bugs and are a promising avenue to\nsupport coders in various tasks including vulnerability detection --\nparticularly given the flexibility of such generative AI models and tools. Yet\nfor many tasks it may not be suitable to use LLMs, for which it may be more\nsuitable to use smaller language models that can fit and easily execute and\ntrain on a developer's computer. In this paper we explore and evaluate whether\nsmaller language models can be fine-tuned to achieve reasonable results for a\nniche area: vulnerability detection -- specifically focusing on detecting the\nreentrancy bug in Solidity smart contracts.",
    "pdf_url": "http://arxiv.org/pdf/2505.19059v1",
    "published": "2025-05-25T09:28:33+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02007v2",
    "title": "eACGM: Non-instrumented Performance Tracing and Anomaly Detection towards Machine Learning Systems",
    "authors": [
      "Ruilin Xu",
      "Zongxuan Xie",
      "Pengfei Chen"
    ],
    "abstract": "We present eACGM, a full-stack AI/ML system monitoring framework based on\neBPF. eACGM collects real-time performance data from key hardware components,\nincluding the GPU and network communication layer, as well as from key software\nstacks such as CUDA, Python, and PyTorch, all without requiring any code\ninstrumentation or modifications. Additionally, it leverages libnvml to gather\nprocess-level GPU resource usage information. By applying a Gaussian Mixture\nModel (GMM) to the collected multidimensional performance metrics for\nstatistical modeling and clustering analysis, eACGM effectively identifies\ncomplex failure modes, such as latency anomalies, hardware failures, and\ncommunication inefficiencies, enabling rapid diagnosis of system bottlenecks\nand abnormal behaviors.\n  To evaluate eACGM's effectiveness and practicality, we conducted extensive\nempirical studies and case analyses in multi-node distributed training\nscenarios. The results demonstrate that eACGM, while maintaining a\nnon-intrusive and low-overhead profile, successfully captures critical\nperformance anomalies during model training and inference. Its stable anomaly\ndetection performance and comprehensive monitoring capabilities validate its\napplicability and scalability in real-world production environments, providing\nstrong support for performance optimization and fault diagnosis in large-scale\nAI/ML systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.02007v2",
    "published": "2025-05-25T09:25:39+00:00",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19058v1",
    "title": "Distributionally Robust Deep Q-Learning",
    "authors": [
      "Chung I Lu",
      "Julian Sester",
      "Aijia Zhang"
    ],
    "abstract": "We propose a novel distributionally robust $Q$-learning algorithm for the\nnon-tabular case accounting for continuous state spaces where the state\ntransition of the underlying Markov decision process is subject to model\nuncertainty. The uncertainty is taken into account by considering the\nworst-case transition from a ball around a reference probability measure. To\ndetermine the optimal policy under the worst-case state transition, we solve\nthe associated non-linear Bellman equation by dualising and regularising the\nBellman operator with the Sinkhorn distance, which is then parameterized with\ndeep neural networks. This approach allows us to modify the Deep Q-Network\nalgorithm to optimise for the worst case state transition.\n  We illustrate the tractability and effectiveness of our approach through\nseveral applications, including a portfolio optimisation task based on\nS\\&{P}~500 data.",
    "pdf_url": "http://arxiv.org/pdf/2505.19058v1",
    "published": "2025-05-25T09:22:06+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "q-fin.PM",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19057v1",
    "title": "Less is More: Efficient Point Cloud Reconstruction via Multi-Head Decoders",
    "authors": [
      "Pedro Alonso",
      "Tianrui Li",
      "Chongshou Li"
    ],
    "abstract": "We challenge the common assumption that deeper decoder architectures always\nyield better performance in point cloud reconstruction. Our analysis reveals\nthat, beyond a certain depth, increasing decoder complexity leads to\noverfitting and degraded generalization. Additionally, we propose a novel\nmulti-head decoder architecture that exploits the inherent redundancy in point\nclouds by reconstructing complete shapes from multiple independent heads, each\noperating on a distinct subset of points. The final output is obtained by\nconcatenating the predictions from all heads, enhancing both diversity and\nfidelity. Extensive experiments on ModelNet40 and ShapeNetPart demonstrate that\nour approach achieves consistent improvements across key metrics--including\nChamfer Distance (CD), Hausdorff Distance (HD), Earth Mover's Distance (EMD),\nand F1-score--outperforming standard single-head baselines. Our findings\nhighlight that output diversity and architectural design can be more critical\nthan depth alone for effective and efficient point cloud reconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2505.19057v1",
    "published": "2025-05-25T09:19:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19056v1",
    "title": "An Embarrassingly Simple Defense Against LLM Abliteration Attacks",
    "authors": [
      "Harethah Abu Shairah",
      "Hasan Abed Al Kader Hammoud",
      "Bernard Ghanem",
      "George Turkiyyah"
    ],
    "abstract": "Large language models (LLMs) are typically aligned to comply with safety\nguidelines by refusing harmful instructions. A recent attack, termed\nabliteration, isolates and suppresses the single latent direction most\nresponsible for refusal behavior, enabling the model to generate unethical\ncontent. We propose a defense that modifies how models generate refusals. We\nconstruct an extended-refusal dataset that contains harmful prompts with a full\nresponse that justifies the reason for refusal. We then fine-tune\nLlama-2-7B-Chat and Qwen2.5-Instruct (1.5B and 3B parameters) on our\nextended-refusal dataset, and evaluate the resulting systems on a set of\nharmful prompts. In our experiments, extended-refusal models maintain high\nrefusal rates, dropping at most by 10%, whereas baseline models' refusal rates\ndrop by 70-80% after abliteration. A broad evaluation of safety and utility\nshows that extended-refusal fine-tuning neutralizes the abliteration attack\nwhile preserving general performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.19056v1",
    "published": "2025-05-25T09:18:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19055v1",
    "title": "Testing cosmological principle under Copernican principle",
    "authors": [
      "Xin Wang",
      "Zhiqi Huang"
    ],
    "abstract": "Recent observational analyses have revealed potential evidence for a\npreferred spatial direction in cosmological data. Such directional\nparameterization inherently places observers at a privileged spatial position,\nthereby conflicting with the Copernican principle and suffering from the\nlook-elsewhere effect. To restore the Copernican principle which is the\nfoundation of modern astronomy, we propose a stochastic framework for\ncosmological principle violations. The almost uniform temperature of cosmic\nmicrowave background suggests that the deviation of isotropy is negligible\n($\\lesssim 10^{-5}$ level) on the last scattering surface, which can be used as\na zero boundary condition to construct an orthogonal basis below the redshift\nof recombination. The relative deviation from Hubble diagram of isotropic\n($\\Lambda$CDM or $w_0w_a$CDM) models is expanded with the orthogonal basis with\na hierarchy of increasing resolution. Using this new approach, we test\ncosmological principle with type Ia supernovae, strong lens time delay, and\ngravitational-wave standard siren. The data sets are consistent with\nstatistical isotropy on large scales.",
    "pdf_url": "http://arxiv.org/pdf/2505.19055v1",
    "published": "2025-05-25T09:18:07+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th",
      "83F05",
      "J.2"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19054v1",
    "title": "Reduce Computational Cost In Deep Reinforcement Learning Via Randomized Policy Learning",
    "authors": [
      "Zhuochen Liu",
      "Rahul Jain",
      "Quan Nguyen"
    ],
    "abstract": "Recent advancements in reinforcement learning (RL) have leveraged neural\nnetworks to achieve state-of-the-art performance across various control tasks.\nHowever, these successes often come at the cost of significant computational\nresources, as training deep neural networks requires substantial time and data.\nIn this paper, we introduce an actor-critic algorithm that utilizes randomized\nneural networks to drastically reduce computational costs while maintaining\nstrong performance. Despite its simple architecture, our method effectively\nsolves a range of control problems, including the locomotion control of a\nhighly dynamic 12-motor quadruped robot, and achieves results comparable to\nleading algorithms such as Proximal Policy Optimization (PPO). Notably, our\napproach does not outperform other algorithms in terms of sample efficnency but\nrather in terms of wall-clock training time. That is, although our algorithm\nrequires more timesteps to converge to an optimal policy, the actual time\nrequired for training turns out to be lower.",
    "pdf_url": "http://arxiv.org/pdf/2505.19054v1",
    "published": "2025-05-25T09:17:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19053v1",
    "title": "Structured Reinforcement Learning for Combinatorial Decision-Making",
    "authors": [
      "Heiko Hoppe",
      "Léo Baty",
      "Louis Bouvier",
      "Axel Parmentier",
      "Maximilian Schiffer"
    ],
    "abstract": "Reinforcement learning (RL) is increasingly applied to real-world problems\ninvolving complex and structured decisions, such as routing, scheduling, and\nassortment planning. These settings challenge standard RL algorithms, which\nstruggle to scale, generalize, and exploit structure in the presence of\ncombinatorial action spaces. We propose Structured Reinforcement Learning\n(SRL), a novel actor-critic framework that embeds combinatorial optimization\nlayers into the actor neural network. We enable end-to-end learning of the\nactor via Fenchel-Young losses and provide a geometric interpretation of SRL as\na primal-dual algorithm in the dual of the moment polytope. Across six\nenvironments with exogenous and endogenous uncertainty, SRL matches or\nsurpasses the performance of unstructured RL and imitation learning on static\ntasks and improves over these baselines by up to 92% on dynamic problems, with\nimproved stability and convergence speed.",
    "pdf_url": "http://arxiv.org/pdf/2505.19053v1",
    "published": "2025-05-25T09:17:10+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19052v2",
    "title": "Probing Time-Varying Dark Energy with DESI: The Crucial Role of Precision Matter Density ($Ω_{m0}$) Measurements",
    "authors": [
      "Seokcheon Lee"
    ],
    "abstract": "Accurate measurements of fundamental cosmological parameters, especially the\nHubble constant ($H_0$) and present-day matter density ($\\Omega_{m0}$), are\ncrucial for constraining dark energy (DE) evolution. We analyze the\nsensitivities of cosmological observables ($H(z)$, $D_L(z)$, $\\EG$) to\n$\\Omega_{m0}$, $\\omega_0$, and $\\omega_a$ under different parametrizations. Our\nresults show observables are far more sensitive to $\\Omega_{m0}$ than to DE\nequation of state parameters (e.g., at $z \\sim 0.5$, $H(z)$'s $\\Omega_{m0}$\nsensitivity is $\\sim 0.7$ vs. $\\omega_a$'s $\\sim 0.04$). This hierarchy\nmandates high-precision $\\Omega_{m0}$ measurements to accurately constrain\ntime-varying DE. We also find DE parameter sensitivity highly depends on\nparametrization; the standard CPL form shows low sensitivity to $\\omega_a$, but\n$\\omega(z) = \\omega_0 + \\omega_a \\ln(1+z)$ significantly enhances it. Our\nanalysis of DESI DR1/DR2 data confirms these theoretical limits: standalone\nDESI data primarily provides only upper limits for $\\omega_a$, underscoring\ninsufficient constraining power for a definitive time-varying DE detection.\nWhile combined datasets offer tighter constraints, interpretation requires\ncaution due to parametrization influence. In conclusion, improving\n$\\Omega_{m0}$ precision and adopting optimized parametrizations are imperative\nfor future surveys like DESI to fully probe dark energy's nature.",
    "pdf_url": "http://arxiv.org/pdf/2505.19052v2",
    "published": "2025-05-25T09:13:58+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19051v1",
    "title": "Efficient Data Selection at Scale via Influence Distillation",
    "authors": [
      "Mahdi Nikdan",
      "Vincent Cohen-Addad",
      "Dan Alistarh",
      "Vahab Mirrokni"
    ],
    "abstract": "Effective data selection is critical for efficient training of modern Large\nLanguage Models (LLMs). This paper introduces Influence Distillation, a novel,\nmathematically-justified framework for data selection that employs second-order\ninformation to optimally weight training samples. By distilling each sample's\ninfluence on a target distribution, our method assigns model-specific weights\nthat are used to select training data for LLM fine-tuning, guiding it toward\nstrong performance on the target domain. We derive these optimal weights for\nboth Gradient Descent and Adam optimizers. To ensure scalability and reduce\ncomputational cost, we propose a $\\textit{landmark-based approximation}$:\ninfluence is precisely computed for a small subset of \"landmark\" samples and\nthen efficiently propagated to all other samples to determine their weights. We\nvalidate Influence Distillation by applying it to instruction tuning on the\nTulu V2 dataset, targeting a range of tasks including GSM8k, SQuAD, and MMLU,\nacross several models from the Llama and Qwen families. Experiments show that\nInfluence Distillation matches or outperforms state-of-the-art performance\nwhile achieving up to $3.5\\times$ faster selection.",
    "pdf_url": "http://arxiv.org/pdf/2505.19051v1",
    "published": "2025-05-25T09:08:00+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19050v1",
    "title": "On Strongly $Δ$-Clean Rings",
    "authors": [
      "Ahmad Moussavi",
      "Peter Danchev",
      "Arash Javan",
      "Omid Hasanzadeh"
    ],
    "abstract": "This study explores in-depth the structure and properties of the so-called\n{\\it strongly $\\Delta$-clean rings}, that is a novel class of rings in which\neach ring element decomposes into a sum of a commuting idempotent and an\nelement from the subset $\\Delta(R)$. Here, $\\Delta(R)$ stands for the extension\nof the Jacobson radical and is defined as the maximal subring of $J(R)$\ninvariant under the unit multiplication. We present a systematic framework for\nthese rings by detailing their foundational characteristics and algebraic\nbehavior under standard constructions, as well as we explore their key\nrelationships with other well-established ring classes. Our findings\ndemonstrate that all strongly $\\Delta$-clean rings are inherently strongly\nclean and $\\Delta U$, but under centrality constraints they refine the category\nof uniquely clean rings. Additionally, we derive criteria for the strong\n$\\Delta$-clean property in triangular matrix rings, their skew analogs, trivial\nextensions, and group rings. The analysis reveals deep ties to boolean rings,\nlocal rings, and quasi-duo rings by offering new structural insights in their\nalgebraic characterization.",
    "pdf_url": "http://arxiv.org/pdf/2505.19050v1",
    "published": "2025-05-25T09:04:22+00:00",
    "categories": [
      "math.RA",
      "math.RT",
      "16N40, 16S50, 16U99"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19049v1",
    "title": "Disentangled Human Body Representation Based on Unsupervised Semantic-Aware Learning",
    "authors": [
      "Lu Wang",
      "Xishuai Peng",
      "S. Kevin Zhou"
    ],
    "abstract": "In recent years, more and more attention has been paid to the learning of 3D\nhuman representation. However, the complexity of lots of hand-defined human\nbody constraints and the absence of supervision data limit that the existing\nworks controllably and accurately represent the human body in views of\nsemantics and representation ability. In this paper, we propose a human body\nrepresentation with controllable fine-grained semantics and high precison of\nreconstruction in an unsupervised learning framework. In particularly, we\ndesign a whole-aware skeleton-grouped disentangle strategy to learn a\ncorrespondence between geometric semantical measurement of body and latent\ncodes, which facilitates the control of shape and posture of human body by\nmodifying latent coding paramerers. With the help of skeleton-grouped\nwhole-aware encoder and unsupervised disentanglement losses, our representation\nmodel is learned by an unsupervised manner. Besides, a based-template residual\nlearning scheme is injected into the encoder to ease of learning human body\nlatent parameter in complicated body shape and pose spaces. Because of the\ngeometrically meaningful latent codes, it can be used in a wide range of\napplications, from human body pose transfer to bilinear latent code\ninterpolation. Further more, a part-aware decoder is utlized to promote the\nlearning of controllable fine-grained semantics. The experimental results on\npublic 3D human datasets show that the method has the ability of precise\nreconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2505.19049v1",
    "published": "2025-05-25T09:03:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19048v1",
    "title": "Movable-Element STARS-Assisted Near-Field Wideband Communications",
    "authors": [
      "Guangyu Zhu",
      "Xidong Mu",
      "Li Guo",
      "Ao Huang",
      "Shibiao Xu"
    ],
    "abstract": "A novel movable-element simultaneously transmitting and reflecting surface\n(ME-STARS)-assisted near-field wideband communication framework is proposed. In\nparticular, the position of each STARS element can be adjusted to combat the\nsignificant wideband beam squint issue in the near field instead of using\ncostly true-time delay components. Four practical ME-STARS element movement\nmodes are proposed, namely region-based (RB), horizontal-based (HB),\nvertical-based (VB), and diagonal-based (DB) modes. Based on this, a near-field\nwideband multi-user downlink communication scenario is considered, where a sum\nrate maximization problem is formulated by jointly optimizing the base station\n(BS) precoding, ME-STARS beamforming, and element positions. To solve this\nintractable problem, a two-layer algorithm is developed. For the inner layer,\nthe block coordinate descent optimization framework is utilized to solve the BS\nprecoding and ME-STARS beamforming in an iterative manner. For the outer layer,\nthe particle swarm optimization-based heuristic search method is employed to\ndetermine the desired element positions. Numerical results show that:1) the\nME-STARSs can effectively address the beam squint for near-field wideband\ncommunications compared to conventional STARSs with fixed element positions; 2)\nthe RB mode achieves the most efficient beam squint effect mitigation, while\nthe DB mode achieves the best trade-off between performance gain and hardware\noverhead; and 3) an increase in the number of ME-STARS elements or BS\nsubcarriers substantially improves the system performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.19048v1",
    "published": "2025-05-25T08:57:29+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19047v1",
    "title": "A Systematic Classification of Vulnerabilities in MoveEVM Smart Contracts (MWC)",
    "authors": [
      "Selçuk Topal"
    ],
    "abstract": "We introduce the MoveEVM Weakness Classification (MWC) system -- a dedicated\nvulnerability taxonomy for smart contracts built with Move and executed in\nEVM-compatible environments. While Move was originally designed to prevent\ncommon security flaws via linear resource types and strict ownership, its\nintegration with EVM bytecode introduces novel hybrid vulnerabilities not\ncaptured by existing systems like the SWC registry. Our taxonomy spans 37\ncategorized vulnerability types (MWC-100 to MWC-136) across six semantic\nframes, addressing issues such as hybrid gas metering, capability misuse,\nmeta-transaction spoofing, and AI-integrated logic. Through analysis of\nreal-world contracts from Aptos and Sui, we demonstrate that current\nverification tools often miss these hybrid risks. We also explore how formal\nmethods and LLM-based audit agents can operationalize this classification,\nenabling scalable, logic-aware smart contract auditing. MWC lays the foundation\nfor more secure and verifiable contracts in next-generation blockchain systems.\n(Shortened Abstract)",
    "pdf_url": "http://arxiv.org/pdf/2505.19047v1",
    "published": "2025-05-25T08:53:23+00:00",
    "categories": [
      "cs.CR",
      "68M14"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19046v1",
    "title": "When Models Don't Collapse: On the Consistency of Iterative MLE",
    "authors": [
      "Daniel Barzilai",
      "Ohad Shamir"
    ],
    "abstract": "The widespread use of generative models has created a feedback loop, in which\neach generation of models is trained on data partially produced by its\npredecessors. This process has raised concerns about \\emph{model collapse}: A\ncritical degradation in performance caused by repeated training on synthetic\ndata. However, different analyses in the literature have reached different\nconclusions as to the severity of model collapse. As such, it remains unclear\nhow concerning this phenomenon is, and under which assumptions it can be\navoided. To address this, we theoretically study model collapse for maximum\nlikelihood estimation (MLE), in a natural setting where synthetic data is\ngradually added to the original data set. Under standard assumptions (similar\nto those long used for proving asymptotic consistency and normality of MLE), we\nestablish non-asymptotic bounds showing that collapse can be avoided even as\nthe fraction of real data vanishes. On the other hand, we prove that some\nassumptions (beyond MLE consistency) are indeed necessary: Without them, model\ncollapse can occur arbitrarily quickly, even when the original data is still\npresent in the training set. To the best of our knowledge, these are the first\nrigorous examples of iterative generative modeling with accumulating data that\nrapidly leads to model collapse.",
    "pdf_url": "http://arxiv.org/pdf/2505.19046v1",
    "published": "2025-05-25T08:50:46+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.19045v1",
    "title": "A General Theory of Growth, Employment, and Technological Change: Experiential Matrix Theory and the Transition from GDP to Humanist Experiential Growth in the Age of Artificial Intelligence",
    "authors": [
      "Christian Callaghan"
    ],
    "abstract": "This paper introduces Experiential Matrix Theory (EMT), a general theory of\ngrowth, employment, and technological change for the age of artificial\nintelligence (AI). EMT redefines utility as the alignment between production\nand an evolving, infinite-dimensional matrix of human experiential needs,\nthereby extending classical utility frameworks and integrating ideas from the\ncapabilities approach of Sen and Nussbaum into formal economic optimisation\nmodelling. We model the economy as a dynamic control system in which AI\ncollapses ideation and coordination costs, transforming production into a\nreal-time vector of experience-aligned outputs. Under this structure, the\nproduction function becomes a continuously learning map from goods to\nexperiential utility, and economic success is redefined as convergence toward\nan asymptotic utility frontier. Using Pontryagin's Maximum Principle in an\ninfinite-dimensional setting, we derive conditions under which AI-aligned\noutput paths are asymptotically optimal, and prove that unemployment is\nPareto-inefficient wherever unmet needs and idle human capacities persist. On\nthis foundation, we establish Alignment Economics as a new research field\ndedicated to understanding and designing economic systems in which\ntechnological, institutional, and ethical architectures co-evolve. EMT thereby\nreframes policy, welfare, and coordination as problems of dynamic alignment,\nnot static allocation, and provides a mathematically defensible framework for\nrealigning economic production with human flourishing. As ideation costs\ncollapse and new experiential needs become addressable, EMT shows that economic\ngrowth can evolve into an inclusive, meaning-centred process -- formally\ngrounded, ethically structured, and AI-enabled.",
    "pdf_url": "http://arxiv.org/pdf/2505.19045v1",
    "published": "2025-05-25T08:50:17+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.19044v1",
    "title": "Bayesian sparse modeling for interpretable prediction of hydroxide ion conductivity in anion-conductive polymer membranes",
    "authors": [
      "Ryo Murakami",
      "Kenji Miyatake",
      "Ahmed Mohamed Ahmed Mahmoud",
      "Hideki Yoshikawa",
      "Kenji Nagata"
    ],
    "abstract": "Anion-conductive polymer membranes have attracted considerable attention as\nsolid electrolytes for alkaline fuel cells and electrolysis cells. Their\nhydroxide ion conductivity varies depending on factors such as the type and\ndistribution of quaternary ammonium groups, as well as the structure and\nconnectivity of hydrophilic and hydrophobic domains. In particular, the size\nand connectivity of hydrophilic domains significantly influence the mobility of\nhydroxide ions; however, this relationship has remained largely qualitative. In\nthis study, we calculated the number of key constituent elements in the\nhydrophilic and hydrophobic units based on the copolymer composition, and\ninvestigated their relationship with hydroxide ion conductivity by using\nBayesian sparse modeling. As a result, we successfully identified\ncomposition-derived features that are critical for accurately predicting\nhydroxide ion conductivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.19044v1",
    "published": "2025-05-25T08:46:32+00:00",
    "categories": [
      "cond-mat.soft",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.19043v1",
    "title": "Offline Clustering of Linear Bandits: Unlocking the Power of Clusters in Data-Limited Environments",
    "authors": [
      "Jingyuan Liu",
      "Zeyu Zhang",
      "Xuchuang Wang",
      "Xutong Liu",
      "John C. S. Lui",
      "Mohammad Hajiesmaili",
      "Carlee Joe-Wong"
    ],
    "abstract": "Contextual linear multi-armed bandits are a learning framework for making a\nsequence of decisions, e.g., advertising recommendations for a sequence of\narriving users. Recent works have shown that clustering these users based on\nthe similarity of their learned preferences can significantly accelerate the\nlearning. However, prior work has primarily focused on the online setting,\nwhich requires continually collecting user data, ignoring the offline data\nwidely available in many applications. To tackle these limitations, we study\nthe offline clustering of bandits (Off-ClusBand) problem, which studies how to\nuse the offline dataset to learn cluster properties and improve decision-making\nacross multiple users. The key challenge in Off-ClusBand arises from data\ninsufficiency for users: unlike the online case, in the offline case, we have a\nfixed, limited dataset to work from and thus must determine whether we have\nenough data to confidently cluster users together. To address this challenge,\nwe propose two algorithms: Off-C$^2$LUB, which we analytically show performs\nwell for arbitrary amounts of user data, and Off-CLUB, which is prone to bias\nwhen data is limited but, given sufficient data, matches a theoretical lower\nbound that we derive for the offline clustered MAB problem. We experimentally\nvalidate these results on both real and synthetic datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.19043v1",
    "published": "2025-05-25T08:43:40+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19042v1",
    "title": "Experimental investigation of ridge-induced secondary motions in turbulent channel flows",
    "authors": [
      "Mattias Nilsson-Takeuchi",
      "Bharathram Ganapathisubramani"
    ],
    "abstract": "Many engineering and environmental surfaces exhibit spatial heterogeneity in\nthe spanwise direction and encompass multiple surface length scales. When the\ndominant spanwise length scale is on the order of the largest flow scales\n(e.g., the boundary layer thickness or channel half-height, delta), localized\ndelta-scale secondary flows can form. These secondary-flow generating\nheterogeneous surfaces are typically classified as \"ridge-type\" (with spanwise\nvariation in surface elevation) and \"strip-type\" (spanwise variation in\nskin-friction including through variation in roughness characteristics). Both\ntypes of surfaces have been explored in previous studies at high Reynolds\nnumbers using experiments with focus on a variety of characteristics such as\nmean flow, turbulent statistics and structure, while lower Reynolds number\nstudies in channels have examined influence on skin-friction in addition to\nflow characteristics and mechanisms. In this work, we augment the previous work\nthrough experiments on ridge-type roughness in turbulent channel flows over a\nlarge range of Reynolds numbers. Our findings reveal that the global skin\nfriction, as inferred through pressure drop in the channel along the streamwise\ndirection, of these surfaces exhibits a log-linear asymptotic behaviour that is\ncharacteristic of a fully-rough surface at sufficiently high Reynolds numbers.\nYet, the roughness function where this is observed is \"low\" compared to other\nestablished homogeneous rough surfaces. Moreover, the mean flow, turbulent\nstatistics, and two-point correlation analyses indicate that the secondary flow\nstructure, spatial extent, and magnitude remain largely invariant over the\nReynolds number range considered. These findings have important implications on\npredicting drag of these heterogeneous surfaces as well as developing new\nmodels for the flow structure.",
    "pdf_url": "http://arxiv.org/pdf/2505.19042v1",
    "published": "2025-05-25T08:43:27+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.19041v1",
    "title": "A directed continuous-wave search from neutron stars in binary systems with the five-vector resampling technique",
    "authors": [
      "Francesco Amicucci",
      "Paola Leaci",
      "Pia Astone",
      "Sabrina D'Antonio",
      "Stefano Dal Pra",
      "Matteo Di Giovanni",
      "Luca D'Onofrio",
      "Federico Muciaccia",
      "Cristiano Palomba",
      "Lorenzo Pierini",
      "Akshat Singhal"
    ],
    "abstract": "Continuous gravitational-wave signals (CWs), which are typically emitted by\nrapidly rotating neutron stars with non-axisymmetric deformations, represent\nparticularly intriguing targets for the Advanced LIGO-Virgo-KAGRA detectors.\nThese detectors operate within sensitivity bands that encompass more than half\nof the known pulsars in our galaxy existing in binary systems, which are the\ntargeted sources of this paper. However, the detection of these faint signals\nis especially challenged by the Doppler modulation due to the source's orbital\nmotion, typically described by five Keplerian parameters, which must be\ndetermined with high precision to effectively detect the signal. This\nmodulation spreads the signal across multiple frequency bins, resulting in a\nnotable reduction of signal-to-noise ratio and potentially hindering signal\ndetection. To overcome this issue, a robust five-vector resampling\ndata-analysis algorithm has been developed to conduct thorough\ndirected/narrowband CW searches at an affordable computational cost. We employ\nthis methodology for the first time to search for CWs from Scorpius X-1, using\npublicly available data from the third observing run of the Advanced\nLIGO-Virgo-KAGRA detectors. No statistically significant CW signals can be\nclaimed. Hence, we proceeded setting 95% confidence-level upper limits in\nselected frequency bands and orbital parameter ranges, while also evaluating\noverall sensitivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.19041v1",
    "published": "2025-05-25T08:42:53+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.19040v1",
    "title": "Smart Waste Management System for Makkah City using Artificial Intelligence and Internet of Things",
    "authors": [
      "Rawabi S. Al Qurashi",
      "Maram M. Almnjomi",
      "Teef L. Alghamdi",
      "Amjad H. Almalki",
      "Shahad S. Alharthi",
      "Shahad M. althobuti",
      "Alanoud S. Alharthi",
      "Maha A. Thafar"
    ],
    "abstract": "Waste management is a critical global issue with significant environmental\nand public health implications. It has become more destructive during\nlarge-scale events such as the annual pilgrimage to Makkah, Saudi Arabia, one\nof the world's largest religious gatherings. This event's popularity has\nattracted millions worldwide, leading to significant and un-predictable\naccumulation of waste. Such a tremendous number of visitors leads to in-creased\nwaste management issues at the Grand Mosque and other holy sites, highlighting\nthe need for an effective solution other than traditional methods based on\nrigid collection schedules.\n  To address this challenge, this research proposed an innovative solution that\nis context-specific and tailored to the unique requirements of pilgrimage\nseason: a Smart Waste Management System, called TUHR, that utilizes the\nInternet of Things and Artificial Intelligence. This system encompasses\nultrasonic sensors that monitor waste levels in each container at the\nperformance sites. Once the container reaches full capacity, the sensor\ncommunicates with the microcontroller, which alerts the relevant authorities.\nMoreover, our system can detect harmful substances such as gas from the gas\ndetector sensor. Such a proactive and dynamic approach promises to mitigate the\nenvironmental and health risks associated with waste accumulation and enhance\nthe cleanliness of these sites. It also delivers economic benefits by reducing\nunnecessary gasoline consumption and optimizing waste management resources.\nImportantly, this research aligns with the principles of smart cities and\nexemplifies the innovative, sustainable, and health-conscious approach that\nSaudi Arabia is implementing as part of its Vision 2030 initiative.",
    "pdf_url": "http://arxiv.org/pdf/2505.19040v1",
    "published": "2025-05-25T08:42:13+00:00",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.19039v1",
    "title": "Origins of Supermassive Black Holes in Galactic Centers",
    "authors": [
      "Ke-Jung Chen"
    ],
    "abstract": "Direct imaging of black hole shadow halos has firmly confirmed the existence\nof supermassive black holes (SMBHs), with millions of solar masses, residing at\nthe centers of the Milky Way and M87 galaxies. These groundbreaking discoveries\nrepresent a monumental success of Einstein's theory of general relativity and\nhave revealed the hidden \"monsters\" lurking at the centers of galaxies.\nMoreover, observations of active galactic nuclei (AGNs) indicate that SMBHs\nwith billions of solar masses were already in place within the first billion\nyears after the Big Bang. However, the origins of these SMBHs, as well as their\nco-evolution with host galaxies, remain poorly understood. This review focuses\non the origin of SMBHs, particularly on the formation of their seed black\nholes. We also highlight several outstanding challenges in modeling seed\nformation and discuss possible observational signatures. These signatures may\nbe testable with current and future facilities, including the James Webb Space\nTelescope (JWST) and the upcoming gravitational wave observatory, the Laser\nInterferometer Space Antenna (LISA).",
    "pdf_url": "http://arxiv.org/pdf/2505.19039v1",
    "published": "2025-05-25T08:39:10+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19038v2",
    "title": "Turb-L1: Achieving Long-term Turbulence Tracing By Tackling Spectral Bias",
    "authors": [
      "Hao Wu",
      "Yuan Gao",
      "Ruiqi Shu",
      "Zean Han",
      "Fan Xu",
      "Zhihong Zhu",
      "Qingsong Wen",
      "Xian Wu",
      "Kun Wang",
      "Xiaomeng Huang"
    ],
    "abstract": "Accurately predicting the long-term evolution of turbulence is crucial for\nadvancing scientific understanding and optimizing engineering applications.\nHowever, existing deep learning methods face significant bottlenecks in\nlong-term autoregressive prediction, which exhibit excessive smoothing and fail\nto accurately track complex fluid dynamics. Our extensive experimental and\nspectral analysis of prevailing methods provides an interpretable explanation\nfor this shortcoming, identifying Spectral Bias as the core obstacle.\nConcretely, spectral bias is the inherent tendency of models to favor\nlow-frequency, smooth features while overlooking critical high-frequency\ndetails during training, thus reducing fidelity and causing physical\ndistortions in long-term predictions. Building on this insight, we propose\nTurb-L1, an innovative turbulence prediction method, which utilizes a\nHierarchical Dynamics Synthesis mechanism within a multi-grid architecture to\nexplicitly overcome spectral bias. It accurately captures cross-scale\ninteractions and preserves the fidelity of high-frequency dynamics, enabling\nreliable long-term tracking of turbulence evolution. Extensive experiments on\nthe 2D turbulence benchmark show that Turb-L1 demonstrates excellent\nperformance: (I) In long-term predictions, it reduces Mean Squared Error (MSE)\nby $80.3\\%$ and increases Structural Similarity (SSIM) by over $9\\times$\ncompared to the SOTA baseline, significantly improving prediction fidelity.\n(II) It effectively overcomes spectral bias, accurately reproducing the full\nenstrophy spectrum and maintaining physical realism in high-wavenumber regions,\nthus avoiding the spectral distortions or spurious energy accumulation seen in\nother methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.19038v2",
    "published": "2025-05-25T08:38:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.09254v2",
    "title": "Machine learning-based correlation analysis of decadal cyclone intensity with sea surface temperature: data and tutorial",
    "authors": [
      "Jingyang Wu",
      "Rohitash Chandra"
    ],
    "abstract": "The rising number of extreme climate events in the past decades has motivated\nthe need for a thorough consideration of tropical cyclone genesis and\nintensity, given the sea-surface temperature (SST). In this paper, we present\nan analysis of the relationship between the increasing global SST with cyclone\ngenesis using linear regression machine learning models. We extract and curate\na dataset of tropical cyclones across selected ocean basins with their\nassociated SST over the past 40 years. We provide correlation analysis using\nlinear regression and visualisation strategies. Our preliminary results show a\nstrong positive correlation between SST and high wind speed across selected\nocean basins via linear regression and machine learning models. Our dataset and\navailable open-source code offer a novel perspective for the investigation of\nthe genesis and intensity of tropical cyclones. Alongside the time and position\nof each cyclone, we also provide the related Saffir-Simpson category, season,\nwind speed, and SST for 15 days before and after the tropical cyclone genesis.",
    "pdf_url": "http://arxiv.org/pdf/2506.09254v2",
    "published": "2025-05-25T08:38:25+00:00",
    "categories": [
      "physics.ao-ph",
      "stat.AP"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.19037v1",
    "title": "Speech-IFEval: Evaluating Instruction-Following and Quantifying Catastrophic Forgetting in Speech-Aware Language Models",
    "authors": [
      "Ke-Han Lu",
      "Chun-Yi Kuan",
      "Hung-yi Lee"
    ],
    "abstract": "We introduce Speech-IFeval, an evaluation framework designed to assess\ninstruction-following capabilities and quantify catastrophic forgetting in\nspeech-aware language models (SLMs). Recent SLMs integrate speech perception\nwith large language models (LLMs), often degrading textual capabilities due to\nspeech-centric training. Existing benchmarks conflate speech perception with\ninstruction-following, hindering evaluation of these distinct skills. To\naddress this gap, we provide a benchmark for diagnosing the\ninstruction-following abilities of SLMs. Our findings show that most SLMs\nstruggle with even basic instructions, performing far worse than text-based\nLLMs. Additionally, these models are highly sensitive to prompt variations,\noften yielding inconsistent and unreliable outputs. We highlight core\nchallenges and provide insights to guide future research, emphasizing the need\nfor evaluation beyond task-level metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.19037v1",
    "published": "2025-05-25T08:37:55+00:00",
    "categories": [
      "eess.AS",
      "cs.CL"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.19036v2",
    "title": "Weak Physics Informed Neural Networks for Geometry Compatible Hyperbolic Conservation Laws on Manifolds",
    "authors": [
      "Hanfei Zhou",
      "Lei Shi"
    ],
    "abstract": "Physics-informed neural networks (PINNs), owing to their mesh-free nature,\noffer a powerful approach for solving high-dimensional partial differential\nequations (PDEs) in complex geometries, including irregular domains. This\ncapability effectively circumvents the challenges of mesh generation that\ntraditional numerical methods face in high-dimensional or geometrically\nintricate settings. While recent studies have extended PINNs to manifolds, the\ntheoretical foundations remain scarce. Existing theoretical analyses of PINNs\nin Euclidean space often rely on smoothness assumptions for the solutions.\nHowever, recent empirical evidence indicates that PINNs may struggle to\napproximate solutions with low regularity, such as those arising from nonlinear\nhyperbolic equations. In this paper, we develop a framework for PINNs tailored\nto the efficient approximation of weak solutions, particularly nonlinear\nhyperbolic equations defined on manifolds. We introduce a novel weak PINN\n(wPINN) formulation on manifolds that leverages the well-posedness theory to\napproximate entropy solutions of geometry-compatible hyperbolic conservation\nlaws on manifolds. Employing tools from approximation theory, we establish a\nconvergence analysis of the algorithm, including an analysis of approximation\nerrors for time-dependent entropy solutions. This analysis provides insight\ninto the accumulation of approximation errors over long time horizons. Notably,\nthe network complexity depends only on the intrinsic dimension, independent of\nthe ambient space dimension. Our results match the minimax rate in the\nd-dimensional Euclidean space, demonstrating that PINNs can alleviate the curse\nof dimensionality in the context of low-dimensional manifolds. Finally, we\nvalidate the performance of the proposed wPINN framework through numerical\nexperiments, confirming its ability to efficiently approximate entropy\nsolutions on manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2505.19036v2",
    "published": "2025-05-25T08:36:56+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "stat.ML"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19035v1",
    "title": "A New Characterization of Semi-Tripotent Rings",
    "authors": [
      "Ahmad Moussavi",
      "Peter Danchev",
      "Arash Javan",
      "Omid Hasanzadeh"
    ],
    "abstract": "We give a comprehensive study of the so-called \\textit{semi-tripotent rings}\nobtaining their new and non-trivial characterization as well as a complete\ndescription in terms of sums and products of some special elements.\nParticularly, we explore in-depth when a group ring is semi-tripotent. Our\nresults somewhat supply those established by Ko$\\c{s}$an et al. in Can. Math.\nBull. (2019).",
    "pdf_url": "http://arxiv.org/pdf/2505.19035v1",
    "published": "2025-05-25T08:36:53+00:00",
    "categories": [
      "math.RA",
      "math.RT",
      "16N40, 16S50, 16U99"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19034v2",
    "title": "The influence of data gaps and outliers on resilience indicators",
    "authors": [
      "Teng Liu",
      "Andreas Morr",
      "Sebastian Bathiany",
      "Lana L. Blaschke",
      "Zhen Qian",
      "Chan Diao",
      "Taylor Smith",
      "Niklas Boers"
    ],
    "abstract": "The resilience, or stability, of major Earth system components is\nincreasingly threatened by anthropogenic pressures, demanding reliable early\nwarning signals for abrupt and irreversible regime shifts. Widely used\ndata-driven resilience indicators based on variance and autocorrelation detect\n`critical slowing down', a signature of decreasing stability. However, the\ninterpretation of these indicators is hampered by poorly understood\ninterdependencies and their susceptibility to common data issues such as\nmissing values and outliers. Here, we establish a rigorous mathematical\nanalysis of the statistical dependency between variance- and\nautocorrelation-based resilience indicators, revealing that their agreement is\nfundamentally driven by the time series' initial data point. Using synthetic\nand empirical data, we demonstrate that missing values substantially weaken\nindicator agreement, while outliers introduce systematic biases that lead to\noverestimation of resilience based on temporal autocorrelation. Our results\nprovide a necessary and rigorous foundation for preprocessing strategies and\naccuracy assessments across the growing number of disciplines that use\nreal-world data to infer changes in system resilience.",
    "pdf_url": "http://arxiv.org/pdf/2505.19034v2",
    "published": "2025-05-25T08:34:09+00:00",
    "categories": [
      "nlin.AO",
      "nlin.CD",
      "physics.data-an",
      "physics.geo-ph"
    ],
    "primary_category": "nlin.AO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19033v1",
    "title": "Optimal Conformal Prediction under Epistemic Uncertainty",
    "authors": [
      "Alireza Javanmardi",
      "Soroush H. Zargarbashi",
      "Santo M. A. R. Thies",
      "Willem Waegeman",
      "Aleksandar Bojchevski",
      "Eyke Hüllermeier"
    ],
    "abstract": "Conformal prediction (CP) is a popular frequentist framework for representing\nuncertainty by providing prediction sets that guarantee coverage of the true\nlabel with a user-adjustable probability. In most applications, CP operates on\nconfidence scores coming from a standard (first-order) probabilistic predictor\n(e.g., softmax outputs). Second-order predictors, such as credal set predictors\nor Bayesian models, are also widely used for uncertainty quantification and are\nknown for their ability to represent both aleatoric and epistemic uncertainty.\nDespite their popularity, there is still an open question on ``how they can be\nincorporated into CP''. In this paper, we discuss the desiderata for CP when\nvalid second-order predictions are available. We then introduce Bernoulli\nprediction sets (BPS), which produce the smallest prediction sets that ensure\nconditional coverage in this setting. When given first-order predictions, BPS\nreduces to the well-known adaptive prediction sets (APS). Furthermore, when the\nvalidity assumption on the second-order predictions is compromised, we apply\nconformal risk control to obtain a marginal coverage guarantee while still\naccounting for epistemic uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2505.19033v1",
    "published": "2025-05-25T08:32:44+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.19032v1",
    "title": "Subsonic Euler-Poisson flows with nonzero vorticity in convergent nozzles",
    "authors": [
      "Yuanyuan Xing",
      "Zihao Zhang"
    ],
    "abstract": "This paper concerns subsonic Euler-Poisson flows in a two-dimensional\nconvergent nozzle of finite length. Due to the geometry of the nozzle, we first\nintroduce new variable to prove the existence of radially symmetric subsonic\nflows to the steady Euler-Poisson system. We then investigate the structural\nstability of the background subsonic flow under perturbations of suitable\nboundary conditions, and establish the existence and uniqueness of smooth\nsubsonic Euler-Poisson flows with nonzero vorticity. The solution shares the\nsame regularity for the velocity, the pressure, the entropy and the electric\npotential. The deformation-curl-Poisson decomposition is utilized to\nreformulate the steady Euler-Poisson system as a deformation-curl-Poisson\nsystem together with several transport equations. The key point lies on the\nanalysis of the well-posedness of the boundary value problem for the associated\nlinearized elliptic system, which is established by using a special structure\nof the system to derive a priori estimates. The result also indicates that the\nelectric field force in compressible flows can counteract the geometric effects\nof the convergent nozzle to stabilize certain physical features of the flow.",
    "pdf_url": "http://arxiv.org/pdf/2505.19032v1",
    "published": "2025-05-25T08:31:57+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19031v1",
    "title": "Medical Large Vision Language Models with Multi-Image Visual Ability",
    "authors": [
      "Xikai Yang",
      "Juzheng Miao",
      "Yuchen Yuan",
      "Jiaze Wang",
      "Qi Dou",
      "Jinpeng Li",
      "Pheng-Ann Heng"
    ],
    "abstract": "Medical large vision-language models (LVLMs) have demonstrated promising\nperformance across various single-image question answering (QA) benchmarks, yet\ntheir capability in processing multi-image clinical scenarios remains\nunderexplored. Unlike single image based tasks, medical tasks involving\nmultiple images often demand sophisticated visual understanding capabilities,\nsuch as temporal reasoning and cross-modal analysis, which are poorly supported\nby current medical LVLMs. To bridge this critical gap, we present the Med-MIM\ninstruction dataset, comprising 83.2K medical multi-image QA pairs that span\nfour types of multi-image visual abilities (temporal understanding, reasoning,\ncomparison, co-reference). Using this dataset, we fine-tune Mantis and\nLLaVA-Med, resulting in two specialized medical VLMs: MIM-LLaVA-Med and\nMed-Mantis, both optimized for multi-image analysis. Additionally, we develop\nthe Med-MIM benchmark to comprehensively evaluate the medical multi-image\nunderstanding capabilities of LVLMs. We assess eight popular LVLMs, including\nour two models, on the Med-MIM benchmark. Experimental results show that both\nMed-Mantis and MIM-LLaVA-Med achieve superior performance on the held-in and\nheld-out subsets of the Med-MIM benchmark, demonstrating that the Med-MIM\ninstruction dataset effectively enhances LVLMs' multi-image understanding\ncapabilities in the medical domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.19031v1",
    "published": "2025-05-25T08:31:22+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19030v3",
    "title": "RECAST: Strengthening LLMs' Complex Instruction Following with Constraint-Verifiable Data",
    "authors": [
      "Zhengkang Guo",
      "Wenhao Liu",
      "Mingchen Xie",
      "Jingwen Xu",
      "Zisu Huang",
      "Muzhao Tian",
      "Jianhan Xu",
      "Muling Wu",
      "Xiaohua Wang",
      "Changze Lv",
      "He-Da Wang",
      "Hu Yao",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "abstract": "Large language models (LLMs) are increasingly expected to tackle complex\ntasks, driven by their expanding applications and users' growing proficiency in\ncrafting sophisticated prompts. However, as the number of explicitly stated\nrequirements increases (particularly more than 10 constraints), LLMs often\nstruggle to accurately follow such complex instructions. To address this\nchallenge, we propose RECAST, a novel framework for synthesizing datasets where\neach example incorporates far more constraints than those in existing\nbenchmarks. These constraints are extracted from real-world prompt-response\npairs to ensure practical relevance. RECAST enables automatic verification of\nconstraint satisfaction via rule-based validators for quantitative constraints\nand LLM-based validators for qualitative ones. Using this framework, we\nconstruct RECAST-30K, a large-scale, high-quality dataset comprising 30k\ninstances spanning 15 constraint types. Experimental results demonstrate that\nmodels fine-tuned on RECAST-30K show substantial improvements in following\ncomplex instructions. Moreover, the verifiability provided by RECAST enables\nthe design of reward functions for reinforcement learning, which further boosts\nmodel performance on complex and challenging tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19030v3",
    "published": "2025-05-25T08:31:08+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19029v1",
    "title": "On the Pipeline Dependence of DESI Dynamical Dark Energy",
    "authors": [
      "Eoin Ó Colgáin",
      "Saeed Pourojaghi",
      "M. M. Sheikh-Jabbari"
    ],
    "abstract": "We continue scientific scrutiny of the DESI dynamical dark energy (DE) claim\nby explicitly demonstrating that the result depends on the analysis pipeline.\nConcretely, we define a likelihood that converts the $w_0 w_a$CDM model back\ninto the flat $\\Lambda$CDM model, which we fit to DESI constraints on the flat\n$\\Lambda$CDM model from DR1 Full-Shape (FS) modelling and BAO. We further\nincorporate CMB constraints. Throughout, we find that $w_0$ and $w_a$ are\nwithin $1 \\sigma$ of the flat $\\Lambda$CDM Model. Our work makes it explicit\nthat, in contrast to DR1 and DR2 BAO, there is no dynamical DE signal in FS\nmodelling, even when combined with BAO and CMB. Moreover, one confirms\nlate-time accelerated expansion today $(q_0 < 0)$ at $ \\gtrsim 3.4 \\sigma$ in\nFS modelling+BAO. On the contrary, DR1 and DR2 BAO fail to confirm $q_0 < 0$\nunder similar assumptions. Our analyses highlight the fact that trustable\nscientific results should be independent of the analysis pipeline.",
    "pdf_url": "http://arxiv.org/pdf/2505.19029v1",
    "published": "2025-05-25T08:29:55+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19028v3",
    "title": "InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts",
    "authors": [
      "Minzhi Lin",
      "Tianchi Xie",
      "Mengchen Liu",
      "Yilin Ye",
      "Changjian Chen",
      "Shixia Liu"
    ],
    "abstract": "Understanding infographic charts with design-driven visual elements (e.g.,\npictograms, icons) requires both visual recognition and reasoning, posing\nchallenges for multimodal large language models (MLLMs). However, existing\nvisual-question answering benchmarks fall short in evaluating these\ncapabilities of MLLMs due to the lack of paired plain charts and\nvisual-element-based questions. To bridge this gap, we introduce InfoChartQA, a\nbenchmark for evaluating MLLMs on infographic chart understanding. It includes\n5,642 pairs of infographic and plain charts, each sharing the same underlying\ndata but differing in visual presentations. We further design\nvisual-element-based questions to capture their unique visual designs and\ncommunicative intent. Evaluation of 20 MLLMs reveals a substantial performance\ndecline on infographic charts, particularly for visual-element-based questions\nrelated to metaphors. The paired infographic and plain charts enable\nfine-grained error analysis and ablation studies, which highlight new\nopportunities for advancing MLLMs in infographic chart understanding. We\nrelease InfoChartQA at https://github.com/CoolDawnAnt/InfoChartQA.",
    "pdf_url": "http://arxiv.org/pdf/2505.19028v3",
    "published": "2025-05-25T08:28:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19027v1",
    "title": "High Throughput QC-LDPC Decoder With Optimized Schedule Policy in Layered Decoding",
    "authors": [
      "Dongxu Chang",
      "Qingqing Peng",
      "Guanghui Wang",
      "Guiying Yan"
    ],
    "abstract": "In this study, a scheduling policy of layered decoding for quasi-cycle (QC)\nlow-density parity-check (LDPC) codes with high throughput and good performance\nis designed. The influence of scheduling on the delay of the decoder's hardware\nimplementation and on the decoding performance are considered simultaneously.\nSpecifically, we analyze the idle time required under various scheduling\nsequences within a pipelined decoding architecture and formulate the problem as\na traveling salesman problem (TSP) aiming at minimizing idle time. Furthermore,\nconsidering that different scheduling sequences can affect decoding\nperformance, we refine the graph used to solve the TSP based on scheduling\ncharacteristics that promote improved decoding outcomes. Simulation results\ndemonstrate that the identified scheduling sequence achieves a low number of\nhardware delays while maintaining excellent decoding performance for 5G New\nRadio (NR) LDPC codes.",
    "pdf_url": "http://arxiv.org/pdf/2505.19027v1",
    "published": "2025-05-25T08:27:54+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.19026v3",
    "title": "Staircase Recognition and Location Based on Polarization Vision",
    "authors": [
      "Weifeng Kong",
      "Zhiying Tan"
    ],
    "abstract": "Staircase is one of the most common structures in artificial scenes. However,\nit is difficult for humanoid robots and people with lower limb disabilities or\nvisual impairment to cross the scene without the help of sensors and\nintelligent algorithms. Staircase scene perception technology is a prerequisite\nfor recognition and localization. This technology is of great significance for\nthe mode switching of the robot and the calculation of the footprint position\nto adapt to the discontinuous terrain. However, there are still many problems\nthat constrain the application of this technology, such as low recognition\naccuracy, high initial noise from sensors, unstable output signals and high\ncomputational requirements. In terms of scene reconstruction, the binocular and\ntime of flight (TOF) reconstruction of the scene can be easily affected by\nenvironmental light and the surface material of the target object. In contrast,\ndue to the special structure of the polarizer, the polarization can selectively\ntransmit polarized light in a specific direction and this reconstruction method\nrelies on the polarization information of the object surface. So the advantages\nof polarization reconstruction are reflected, which are less affected by\nenvironmental light and not dependent on the texture information of the object\nsurface. In this paper, in order to achieve the detection of staircase, this\npaper proposes a contrast enhancement algorithm that integrates polarization\nand light intensity information, and integrates point cloud segmentation based\non YOLOv11. To realize the high-quality reconstruction, we proposed a method of\nfusing polarized binocular and TOF depth information to realize the\nthree-dimensional (3D) reconstruction of the staircase. Besides, it also\nproposes a joint calibration algorithm of monocular camera and TOF camera based\non ICP registration and improved gray wolf optimization algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.19026v3",
    "published": "2025-05-25T08:27:09+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19025v1",
    "title": "SQUiD: Synthesizing Relational Databases from Unstructured Text",
    "authors": [
      "Mushtari Sadia",
      "Zhenning Yang",
      "Yunming Xiao",
      "Ang Chen",
      "Amrita Roy Chowdhury"
    ],
    "abstract": "Relational databases are central to modern data management, yet most data\nexists in unstructured forms like text documents. To bridge this gap, we\nleverage large language models (LLMs) to automatically synthesize a relational\ndatabase by generating its schema and populating its tables from raw text. We\nintroduce SQUiD, a novel neurosymbolic framework that decomposes this task into\nfour stages, each with specialized techniques. Our experiments show that SQUiD\nconsistently outperforms baselines across diverse datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.19025v1",
    "published": "2025-05-25T08:20:49+00:00",
    "categories": [
      "cs.DB",
      "cs.CL"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.19024v1",
    "title": "Learn Beneficial Noise as Graph Augmentation",
    "authors": [
      "Siqi Huang",
      "Yanchen Xu",
      "Hongyuan Zhang",
      "Xuelong Li"
    ],
    "abstract": "Although graph contrastive learning (GCL) has been widely investigated, it is\nstill a challenge to generate effective and stable graph augmentations.\nExisting methods often apply heuristic augmentation like random edge dropping,\nwhich may disrupt important graph structures and result in unstable GCL\nperformance. In this paper, we propose Positive-incentive Noise driven Graph\nData Augmentation (PiNGDA), where positive-incentive noise (pi-noise)\nscientifically analyzes the beneficial effect of noise under the information\ntheory. To bridge the standard GCL and pi-noise framework, we design a Gaussian\nauxiliary variable to convert the loss function to information entropy. We\nprove that the standard GCL with pre-defined augmentations is equivalent to\nestimate the beneficial noise via the point estimation. Following our analysis,\nPiNGDA is derived from learning the beneficial noise on both topology and\nattributes through a trainable noise generator for graph augmentations, instead\nof the simple estimation. Since the generator learns how to produce beneficial\nperturbations on graph topology and node attributes, PiNGDA is more reliable\ncompared with the existing methods. Extensive experimental results validate the\neffectiveness and stability of PiNGDA.",
    "pdf_url": "http://arxiv.org/pdf/2505.19024v1",
    "published": "2025-05-25T08:20:34+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19023v1",
    "title": "A Smart Healthcare System for Monkeypox Skin Lesion Detection and Tracking",
    "authors": [
      "Huda Alghoraibi",
      "Nuha Alqurashi",
      "Sarah Alotaibi",
      "Renad Alkhudaydi",
      "Bdoor Aldajani",
      "Lubna Alqurashi",
      "Jood Batweel",
      "Maha A. Thafar"
    ],
    "abstract": "Monkeypox is a viral disease characterized by distinctive skin lesions and\nhas been reported in many countries. The recent global outbreak has emphasized\nthe urgent need for scalable, accessible, and accurate diagnostic solutions to\nsupport public health responses.\n  In this study, we developed ITMAINN, an intelligent, AI-driven healthcare\nsystem specifically designed to detect Monkeypox from skin lesion images using\nadvanced deep learning techniques. Our system consists of three main\ncomponents. First, we trained and evaluated several pretrained models using\ntransfer learning on publicly available skin lesion datasets to identify the\nmost effective models. For binary classification (Monkeypox vs. non-Monkeypox),\nthe Vision Transformer, MobileViT, Transformer-in-Transformer, and VGG16\nachieved the highest performance, each with an accuracy and F1-score of 97.8%.\nFor multiclass classification, which contains images of patients with Monkeypox\nand five other classes (chickenpox, measles, hand-foot-mouth disease, cowpox,\nand healthy), ResNetViT and ViT Hybrid models achieved 92% accuracy, with F1\nscores of 92.24% and 92.19%, respectively. The best-performing and most\nlightweight model, MobileViT, was deployed within the mobile application. The\nsecond component is a cross-platform smartphone application that enables users\nto detect Monkeypox through image analysis, track symptoms, and receive\nrecommendations for nearby healthcare centers based on their location. The\nthird component is a real-time monitoring dashboard designed for health\nauthorities to support them in tracking cases, analyzing symptom trends,\nguiding public health interventions, and taking proactive measures.\n  This system is fundamental in developing responsive healthcare infrastructure\nwithin smart cities. Our solution, ITMAINN, is part of revolutionizing public\nhealth management.",
    "pdf_url": "http://arxiv.org/pdf/2505.19023v1",
    "published": "2025-05-25T08:17:21+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19022v1",
    "title": "Rethinking Metrics and Benchmarks of Video Anomaly Detection",
    "authors": [
      "Zihao Liu",
      "Xiaoyu Wu",
      "Wenna Li",
      "Linlin Yang"
    ],
    "abstract": "Video Anomaly Detection (VAD), which aims to detect anomalies that deviate\nfrom expectation, has attracted increasing attention in recent years. Existing\nadvancements in VAD primarily focus on model architectures and training\nstrategies, while devoting insufficient attention to evaluation metrics and\nbenchmarks. In this paper, we rethink VAD evaluation protocols through\ncomprehensive experimental analyses, revealing three critical limitations in\ncurrent practices: 1) existing metrics are significantly influenced by single\nannotation bias; 2) current metrics fail to reward early detection of\nanomalies; 3) available benchmarks lack the capability to evaluate scene\noverfitting. To address these limitations, we propose three novel evaluation\nmethods: first, we establish averaged AUC/AP metrics over multi-round\nannotations to mitigate single annotation bias; second, we develop a\nLatency-aware Average Precision (LaAP) metric that rewards early and accurate\nanomaly detection; and finally, we introduce two hard normal benchmarks\n(UCF-HN, MSAD-HN) with videos specifically designed to evaluate scene\noverfitting. We report performance comparisons of ten state-of-the-art VAD\napproaches using our proposed evaluation methods, providing novel perspectives\nfor future VAD model development.",
    "pdf_url": "http://arxiv.org/pdf/2505.19022v1",
    "published": "2025-05-25T08:09:42+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19021v1",
    "title": "Local asymptotics for singular solutions to critical Hartree equations",
    "authors": [
      "João Henrique Andrade",
      "Tao Feng",
      "Paolo Piccione",
      "Minbo Yang"
    ],
    "abstract": "We investigate the qualitative properties of a critical Hartree equation\ndefined on punctured domains.\n  Our study has two main objectives: analyzing the asymptotic behavior near\nisolated singularities and establishing radial symmetry of positive singular\nsolutions.\n  First, employing asymptotic analysis, we characterize the local behavior of\nsolutions near the singularity.\n  Specifically, we show that, within a punctured ball, solutions behave like\nthe blow-up limit profile.\n  This is achieved through classification results for entire bubble solutions,\na standard blow-up procedure, and a removable singularity theorem, yielding\nsharp upper and lower bounds near the origin.\n  To run the blow-up analysis, we develop an asymptotic integral version of the\nmoving spheres technique, a technique of independent interest.\n  Second, we establish the radial symmetry of blow-up limit solutions using an\nintegral moving spheres method.\n  On the technical level, we apply the integral dual method from Jin, Li, Xiong\n\\cite{MR3694645, arxiv:1901.01678} to provide local asymptotic estimates within\nthe punctured ball and to prove that solutions in the entire punctured space\nare radially symmetric with respect to the origin.\n  Our results extend seminal theorems of Caffarelli, Gidas, and Spruck\n\\cite{MR982351} to the setting of Hartree equations.",
    "pdf_url": "http://arxiv.org/pdf/2505.19021v1",
    "published": "2025-05-25T08:01:21+00:00",
    "categories": [
      "math.AP",
      "35J60, 35B09, 35J30, 35B40"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19020v1",
    "title": "HGCL: Hierarchical Graph Contrastive Learning for User-Item Recommendation",
    "authors": [
      "Jiawei Xue",
      "Zhen Yang",
      "Haitao Lin",
      "Ziji Zhang",
      "Luzhu Wang",
      "Yikun Gu",
      "Yao Xu",
      "Xin Li"
    ],
    "abstract": "Graph Contrastive Learning (GCL), which fuses graph neural networks with\ncontrastive learning, has evolved as a pivotal tool in user-item\nrecommendations. While promising, existing GCL methods often lack explicit\nmodeling of hierarchical item structures, which represent item similarities\nacross varying resolutions. Such hierarchical item structures are ubiquitous in\nvarious items (e.g., online products and local businesses), and reflect their\ninherent organizational properties that serve as critical signals for enhancing\nrecommendation accuracy. In this paper, we propose Hierarchical Graph\nContrastive Learning (HGCL), a novel GCL method that incorporates hierarchical\nitem structures for user-item recommendations. First, HGCL pre-trains a GCL\nmodule using cross-layer contrastive learning to obtain user and item\nrepresentations. Second, HGCL employs a representation compression and\nclustering method to construct a two-hierarchy user-item bipartite graph.\nUltimately, HGCL fine-tunes user and item representations by learning on the\nhierarchical graph, and then provides recommendations based on user-item\ninteraction scores. Experiments on three widely adopted benchmark datasets\nranging from 70K to 382K nodes confirm the superior performance of HGCL over\nexisting baseline models, highlighting the contribution of hierarchical item\nstructures in enhancing GCL methods for recommendation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.19020v1",
    "published": "2025-05-25T07:56:56+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19019v1",
    "title": "Querying Kernel Methods Suffices for Reconstructing their Training Data",
    "authors": [
      "Daniel Barzilai",
      "Yuval Margalit",
      "Eitan Gronich",
      "Gilad Yehudai",
      "Meirav Galun",
      "Ronen Basri"
    ],
    "abstract": "Over-parameterized models have raised concerns about their potential to\nmemorize training data, even when achieving strong generalization. The privacy\nimplications of such memorization are generally unclear, particularly in\nscenarios where only model outputs are accessible. We study this question in\nthe context of kernel methods, and demonstrate both empirically and\ntheoretically that querying kernel models at various points suffices to\nreconstruct their training data, even without access to model parameters. Our\nresults hold for a range of kernel methods, including kernel regression,\nsupport vector machines, and kernel density estimation. Our hope is that this\nwork can illuminate potential privacy concerns for such models.",
    "pdf_url": "http://arxiv.org/pdf/2505.19019v1",
    "published": "2025-05-25T07:53:03+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19018v1",
    "title": "CrosGrpsABS: Cross-Attention over Syntactic and Semantic Graphs for Aspect-Based Sentiment Analysis in a Low-Resource Language",
    "authors": [
      "Md. Mithun Hossain",
      "Md. Shakil Hossain",
      "Sudipto Chaki",
      "Md. Rajib Hossain",
      "Md. Saifur Rahman",
      "A. B. M. Shawkat Ali"
    ],
    "abstract": "Aspect-Based Sentiment Analysis (ABSA) is a fundamental task in natural\nlanguage processing, offering fine-grained insights into opinions expressed in\ntext. While existing research has largely focused on resource-rich languages\nlike English which leveraging large annotated datasets, pre-trained models, and\nlanguage-specific tools. These resources are often unavailable for low-resource\nlanguages such as Bengali. The ABSA task in Bengali remains poorly explored and\nis further complicated by its unique linguistic characteristics and a lack of\nannotated data, pre-trained models, and optimized hyperparameters. To address\nthese challenges, this research propose CrosGrpsABS, a novel hybrid framework\nthat leverages bidirectional cross-attention between syntactic and semantic\ngraphs to enhance aspect-level sentiment classification. The CrosGrpsABS\ncombines transformerbased contextual embeddings with graph convolutional\nnetworks, built upon rule-based syntactic dependency parsing and semantic\nsimilarity computations. By employing bidirectional crossattention, the model\neffectively fuses local syntactic structure with global semantic context,\nresulting in improved sentiment classification performance across both low- and\nhigh-resource settings. We evaluate CrosGrpsABS on four low-resource Bengali\nABSA datasets and the high-resource English SemEval 2014 Task 4 dataset. The\nCrosGrpsABS consistently outperforms existing approaches, achieving notable\nimprovements, including a 0.93% F1-score increase for the Restaurant domain and\na 1.06% gain for the Laptop domain in the SemEval 2014 Task 4 benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2505.19018v1",
    "published": "2025-05-25T07:42:32+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.19017v1",
    "title": "WorldEval: World Model as Real-World Robot Policies Evaluator",
    "authors": [
      "Yaxuan Li",
      "Yichen Zhu",
      "Junjie Wen",
      "Chaomin Shen",
      "Yi Xu"
    ],
    "abstract": "The field of robotics has made significant strides toward developing\ngeneralist robot manipulation policies. However, evaluating these policies in\nreal-world scenarios remains time-consuming and challenging, particularly as\nthe number of tasks scales and environmental conditions change. In this work,\nwe demonstrate that world models can serve as a scalable, reproducible, and\nreliable proxy for real-world robot policy evaluation. A key challenge is\ngenerating accurate policy videos from world models that faithfully reflect the\nrobot actions. We observe that directly inputting robot actions or using\nhigh-dimensional encoding methods often fails to generate action-following\nvideos. To address this, we propose Policy2Vec, a simple yet effective approach\nto turn a video generation model into a world simulator that follows latent\naction to generate the robot video. We then introduce WorldEval, an automated\npipeline designed to evaluate real-world robot policies entirely online.\nWorldEval effectively ranks various robot policies and individual checkpoints\nwithin a single policy, and functions as a safety detector to prevent dangerous\nactions by newly developed robot models. Through comprehensive paired\nevaluations of manipulation policies in real-world environments, we demonstrate\na strong correlation between policy performance in WorldEval and real-world\nscenarios. Furthermore, our method significantly outperforms popular methods\nsuch as real-to-sim approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.19017v1",
    "published": "2025-05-25T07:41:39+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.19016v2",
    "title": "A geometric approximation of non-local interface and boundary conditions",
    "authors": [
      "Pavel Exner",
      "Andrii Khrabustovskyi"
    ],
    "abstract": "We analyze an approximation of a Laplacian subject to non-local interface\nconditions of a $\\delta'$-type by Neumann Laplacians on a family of Riemannian\nmanifolds with a sieve-like structure. We establish a (kind of) resolvent\nconvergence for such operators, which in turn implies the convergence of\nspectra and eigenspaces, and demonstrate convergence of the corresponding\nsemigroups. Moreover, we provide an explicit example of a manifold allowing to\nrealize any prescribed integral kernel appearing in that interface conditions.\nFinally, we extend the discussion to similar approximations for the Laplacian\nwith non-local Robin-type boundary conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.19016v2",
    "published": "2025-05-25T07:41:17+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "math.SP",
      "35B27, 35B40, 35P05, 47A55"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19015v2",
    "title": "Can Multimodal Large Language Models Understand Spatial Relations?",
    "authors": [
      "Jingping Liu",
      "Ziyan Liu",
      "Zhedong Cen",
      "Yan Zhou",
      "Yinan Zou",
      "Weiyan Zhang",
      "Haiyun Jiang",
      "Tong Ruan"
    ],
    "abstract": "Spatial relation reasoning is a crucial task for multimodal large language\nmodels (MLLMs) to understand the objective world. However, current benchmarks\nhave issues like relying on bounding boxes, ignoring perspective substitutions,\nor allowing questions to be answered using only the model's prior knowledge\nwithout image understanding. To address these issues, we introduce SpatialMQA,\na human-annotated spatial relation reasoning benchmark based on COCO2017, which\nenables MLLMs to focus more on understanding images in the objective world. To\nensure data quality, we design a well-tailored annotation procedure, resulting\nin SpatialMQA consisting of 5,392 samples. Based on this benchmark, a series of\nclosed- and open-source MLLMs are implemented and the results indicate that the\ncurrent state-of-the-art MLLM achieves only 48.14% accuracy, far below the\nhuman-level accuracy of 98.40%. Extensive experimental analyses are also\nconducted, suggesting the future research directions. The benchmark and codes\nare available at https://github.com/ziyan-xiaoyu/SpatialMQA.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.19015v2",
    "published": "2025-05-25T07:37:34+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19014v2",
    "title": "Tokenizing Electron Cloud in Protein-Ligand Interaction Learning",
    "authors": [
      "Haitao Lin",
      "Odin Zhang",
      "Jia Xu",
      "Yunfan Liu",
      "Zheng Cheng",
      "Lirong Wu",
      "Yufei Huang",
      "Zhifeng Gao",
      "Stan Z. Li"
    ],
    "abstract": "The affinity and specificity of protein-molecule binding directly impact\nfunctional outcomes, uncovering the mechanisms underlying biological regulation\nand signal transduction. Most deep-learning-based prediction approaches focus\non structures of atoms or fragments. However, quantum chemical properties, such\nas electronic structures, are the key to unveiling interaction patterns but\nremain largely underexplored. To bridge this gap, we propose ECBind, a method\nfor tokenizing electron cloud signals into quantized embeddings, enabling their\nintegration into downstream tasks such as binding affinity prediction. By\nincorporating electron densities, ECBind helps uncover binding modes that\ncannot be fully represented by atom-level models. Specifically, to remove the\nredundancy inherent in electron cloud signals, a structure-aware transformer\nand hierarchical codebooks encode 3D binding sites enriched with electron\nstructures into tokens. These tokenized codes are then used for specific tasks\nwith labels. To extend its applicability to a wider range of scenarios, we\nutilize knowledge distillation to develop an electron-cloud-agnostic prediction\nmodel. Experimentally, ECBind demonstrates state-of-the-art performance across\nmultiple tasks, achieving improvements of 6.42\\% and 15.58\\% in per-structure\nPearson and Spearman correlation coefficients, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.19014v2",
    "published": "2025-05-25T07:36:50+00:00",
    "categories": [
      "cs.LG",
      "physics.chem-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19013v1",
    "title": "Faithful Group Shapley Value",
    "authors": [
      "Kiljae Lee",
      "Ziqi Liu",
      "Weijing Tang",
      "Yuan Zhang"
    ],
    "abstract": "Data Shapley is an important tool for data valuation, which quantifies the\ncontribution of individual data points to machine learning models. In practice,\ngroup-level data valuation is desirable when data providers contribute data in\nbatch. However, we identify that existing group-level extensions of Data\nShapley are vulnerable to shell company attacks, where strategic group\nsplitting can unfairly inflate valuations. We propose Faithful Group Shapley\nValue (FGSV) that uniquely defends against such attacks. Building on original\nmathematical insights, we develop a provably fast and accurate approximation\nalgorithm for computing FGSV. Empirical experiments demonstrate that our\nalgorithm significantly outperforms state-of-the-art methods in computational\nefficiency and approximation accuracy, while ensuring faithful group-level\nvaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.19013v1",
    "published": "2025-05-25T07:32:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19012v1",
    "title": "A Derivative-Free Position Optimization Approach for Movable Antenna Multi-User Communication Systems",
    "authors": [
      "Xianlong Zeng",
      "Jun Fang",
      "Peilan Wang",
      "Weidong Mei",
      "Ying-Chang Liang"
    ],
    "abstract": "Movable antennas (MAs) have emerged as a disruptive technology in wireless\ncommunications for enhancing spatial degrees of freedom through continuous\nantenna repositioning within predefined regions, thereby creating favorable\nchannel propagation conditions. In this paper, we study the problem of position\noptimization for MA-enabled multi-user MISO systems, where a base station (BS),\nequipped with multiple MAs, communicates with multiple users each equipped with\na single fixed-position antenna (FPA). To circumvent the difficulty of\nacquiring the channel state information (CSI) from the transmitter to the\nreceiver over the entire movable region, we propose a derivative-free approach\nfor MA position optimization. The basic idea is to treat position optimization\nas a closed-box optimization problem and calculate the gradient of the unknown\nobjective function using zeroth-order (ZO) gradient approximation techniques.\nSpecifically, the proposed method does not need to explicitly estimate the\nglobal CSI. Instead, it adaptively refines its next movement based on previous\nmeasurements such that it eventually converges to an optimum or stationary\nsolution. Simulation results show that the proposed derivative-free approach is\nable to achieve higher sample and computational efficiencies than the CSI\nestimation-based position optimization approach, particularly for challenging\nscenarios where the number of multi-path components (MPCs) is large or the\nnumber of pilot signals is limited.",
    "pdf_url": "http://arxiv.org/pdf/2505.19012v1",
    "published": "2025-05-25T07:31:19+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.19011v1",
    "title": "Fermi-liquid transport beyond the upper critical field in superconducting La$_2$PrNi$_2$O$_7$ thin films",
    "authors": [
      "Yu-Te Hsu",
      "Yidi Liu",
      "Yoshimitsu Kohama",
      "Tommy Kotte",
      "Vikash Sharma",
      "Yaoju Tarn",
      "Yijun Yu",
      "Harold Y. Hwang"
    ],
    "abstract": "Unconventional superconductivity typically emerges out of a strongly\ncorrelated normal state, manifesting as a Fermi liquid with highly enhanced\neffective mass or a strange metal with $T$-linear resistivity in the\nzero-temperature limit. In Ruddlesden-Popper bilayer nickelates\n$R_3$Ni$_2$O$_7$, superconductivity with a critical temperature ($T_{\\rm c}$)\nexceeding 80 and 40 K has been respectively realised in bulk crystals under\nhigh pressure and thin films under compressive strain. These advancements\ncreate new materials platforms to study the nature of high-$T_{\\rm c}$\nsuperconductivity, calling for the characterisation of fundamental normal-state\nand superconducting parameters therein. Here we report detailed\nmagnetotransport experiments on superconducting La$_2$PrNi$_2$O$_7$ (LPNO) thin\nfilms under pulsed magnetic fields up to 64 T and access the normal-state\nbehaviour over a wide temperature range between 1.5 and 300 K. We find that the\nnormal state of LPNO exhibits the hallmarks of Fermi liquid transport,\nincluding $T^2$ temperature dependence of resistivity and Hall angle, and $H^2$\nmagnetoresistance obeying Kohler scaling. Using the empirical Kadowaki-Woods\nratio relating the transport coefficient and electronic specific heat, we\nestimate a quasiparticle effective mass $m^*/m_e \\simeq 10$ in PLNO, thereby\nrevealing the highly renormalized Fermi liquid state which hosts the\nhigh-temperature nickelate superconductivity. Our results demonstrate that LPNO\nfollows the same $T_{\\rm c}/T_{\\rm F}^*$ scaling observed across a wide variety\nof strongly correlated superconductors and provide crucial constraints for a\nviable model for superconductivity in bilayer nickelates.",
    "pdf_url": "http://arxiv.org/pdf/2505.19011v1",
    "published": "2025-05-25T07:27:12+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.19010v2",
    "title": "Co-AttenDWG: Co-Attentive Dimension-Wise Gating and Expert Fusion for Multi-Modal Offensive Content Detection",
    "authors": [
      "Md. Mithun Hossain",
      "Md. Shakil Hossain",
      "Sudipto Chaki",
      "M. F. Mridha"
    ],
    "abstract": "Multi-modal learning has emerged as a crucial research direction, as\nintegrating textual and visual information can substantially enhance\nperformance in tasks such as classification, retrieval, and scene\nunderstanding. Despite advances with large pre-trained models, existing\napproaches often suffer from insufficient cross-modal interactions and rigid\nfusion strategies, failing to fully harness the complementary strengths of\ndifferent modalities. To address these limitations, we propose Co-AttenDWG,\nco-attention with dimension-wise gating, and expert fusion. Our approach first\nprojects textual and visual features into a shared embedding space, where a\ndedicated co-attention mechanism enables simultaneous, fine-grained\ninteractions between modalities. This is further strengthened by a\ndimension-wise gating network, which adaptively modulates feature contributions\nat the channel level to emphasize salient information. In parallel, dual-path\nencoders independently refine modality-specific representations, while an\nadditional cross-attention layer aligns the modalities further. The resulting\nfeatures are aggregated via an expert fusion module that integrates learned\ngating and self-attention, yielding a robust unified representation.\nExperimental results on the MIMIC and SemEval Memotion 1.0 datasets show that\nCo-AttenDWG achieves state-of-the-art performance and superior cross-modal\nalignment, highlighting its effectiveness for diverse multi-modal applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.19010v2",
    "published": "2025-05-25T07:26:00+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19009v1",
    "title": "Capturing Aperiodic Temporal Dynamics of EEG Signals through Stochastic Fluctuation Modeling",
    "authors": [
      "Yuhao Sun",
      "Zhiyuan Ma",
      "Xinke Shen",
      "Jinhao Li",
      "Guan Wang",
      "Sen Song"
    ],
    "abstract": "Electrophysiological brain signals, such as electroencephalography (EEG),\nexhibit both periodic and aperiodic components, with the latter often modeled\nas 1/f noise and considered critical to cognitive and neurological processes.\nAlthough various theoretical frameworks have been proposed to account for\naperiodic activity, its scale-invariant and long-range temporal dependency\nremain insufficiently explained. Drawing on neural fluctuation theory, we\npropose a novel framework that parameterizes intrinsic stochastic neural\nfluctuations to account for aperiodic dynamics. Within this framework, we\nintroduce two key parameters-self-similarity and scale factor-to characterize\nthese fluctuations. Our findings reveal that EEG fluctuations exhibit\nself-similar and non-stable statistical properties, challenging the assumptions\nof conventional stochastic models in neural dynamical modeling. Furthermore,\nthe proposed parameters enable the reconstruction of EEG-like signals that\nfaithfully replicate the aperiodic spectrum, including the characteristic 1/f\nspectral profile, and long range dependency. By linking structured neural\nfluctuations to empirically observed aperiodic EEG activity, this work offers\ndeeper mechanistic insights into brain dynamics, resulting in a more robust\nbiomarker candidate than the traditional 1/f slope, and provides a\ncomputational methodology for generating biologically plausible\nneurophysiological signals.",
    "pdf_url": "http://arxiv.org/pdf/2505.19009v1",
    "published": "2025-05-25T07:23:47+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.19008v2",
    "title": "Four paths from birational geometry to the elliptic genus",
    "authors": [
      "Andrzej Weber"
    ],
    "abstract": "The article presents four reasons why the elliptic genus is the most general\ncharacteristic class that admits a generalization to singular spaces. We prove\nthat the elliptic characteristic class (with an additional factor) is\nessentially the only characteristic class invariant under certain\nmodifications, such as the Atiyah flop, Grassmannian flops, and modifications\nof Bott-Samelson resolutions.This result confirms and extends Totaro's result\nconcerning the cobordism ring modulo classical flops. However, our approach is\nbased on local calculus in equivariant cohomology.",
    "pdf_url": "http://arxiv.org/pdf/2505.19008v2",
    "published": "2025-05-25T07:23:16+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19007v1",
    "title": "Off-diagonal bloom weighted estimates for bilinear commutators",
    "authors": [
      "Yunan Zeng"
    ],
    "abstract": "We prove the off-diagonal estimates of the bilinear iterated commutators in\nthe two-weight setting. The upper bound is established via sparse domination,\nand the lower bound is proved by the median method. Our methods are so flexible\nso that it can be easily extended to the multilinear scenario.",
    "pdf_url": "http://arxiv.org/pdf/2505.19007v1",
    "published": "2025-05-25T07:21:34+00:00",
    "categories": [
      "math.CA",
      "math.FA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.19006v1",
    "title": "A quantitative notion of economic security for smart contract compositions",
    "authors": [
      "Emily Priyadarshini",
      "Massimo Bartoletti"
    ],
    "abstract": "Decentralized applications are often composed of multiple interconnected\nsmart contracts. This is especially evident in DeFi, where protocols are\nheavily intertwined and rely on a variety of basic building blocks such as\ntokens, decentralized exchanges and lending protocols. A crucial security\nchallenge in this setting arises when adversaries target individual components\nto cause systemic economic losses. Existing security notions focus on\ndetermining the existence of these attacks, but fail to quantify the effect of\nmanipulating individual components on the overall economic security of the\nsystem. In this paper, we introduce a quantitative security notion that\nmeasures how an attack on a single component can amplify economic losses of the\noverall system. We study the fundamental properties of this notion and apply it\nto assess the security of key compositions. In particular, we analyse\nunder-collateralized loan attacks in systems made of lending protocols and\ndecentralized exchanges.",
    "pdf_url": "http://arxiv.org/pdf/2505.19006v1",
    "published": "2025-05-25T07:10:55+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21549v4",
    "title": "Distill CLIP (DCLIP): Enhancing Image-Text Retrieval via Cross-Modal Transformer Distillation",
    "authors": [
      "Daniel Csizmadia",
      "Andrei Codreanu",
      "Victor Sim",
      "Vighnesh Prabhu",
      "Michael Lu",
      "Kevin Zhu",
      "Sean O'Brien",
      "Vasu Sharma"
    ],
    "abstract": "We present Distill CLIP (DCLIP), a fine-tuned variant of the CLIP model that\nenhances multimodal image-text retrieval while preserving the original model's\nstrong zero-shot classification capabilities. CLIP models are typically\nconstrained by fixed image resolutions and limited context, which can hinder\ntheir effectiveness in retrieval tasks that require fine-grained cross-modal\nunderstanding. DCLIP addresses these challenges through a meta teacher-student\ndistillation framework, where a cross-modal transformer teacher is fine-tuned\nto produce enriched embeddings via bidirectional cross-attention between\nYOLO-extracted image regions and corresponding textual spans. These\nsemantically and spatially aligned global representations guide the training of\na lightweight student model using a hybrid loss that combines contrastive\nlearning and cosine similarity objectives. Despite being trained on only\n~67,500 samples curated from MSCOCO, Flickr30k, and Conceptual Captions-just a\nfraction of CLIP's original dataset-DCLIP significantly improves image-text\nretrieval metrics (Recall@K, MAP), while retaining approximately 94% of CLIP's\nzero-shot classification performance. These results demonstrate that DCLIP\neffectively mitigates the trade-off between task specialization and\ngeneralization, offering a resource-efficient, domain-adaptive, and\ndetail-sensitive solution for advanced vision-language tasks. Code available at\nhttps://anonymous.4open.science/r/DCLIP-B772/README.md.",
    "pdf_url": "http://arxiv.org/pdf/2505.21549v4",
    "published": "2025-05-25T07:08:07+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.19005v1",
    "title": "Strain-induced magnetic damping anomaly in La$_{1-x}$Sr$_{x}$MnO$_{3}$ ($x=0.3$-$0.5$) thin films",
    "authors": [
      "Ryotaro Arakawa",
      "Sachio Komori",
      "Tomoyasu Taniyama"
    ],
    "abstract": "Magnetic properties of La$_{1-x}$Sr$_x$MnO$_{3}$ (LSMO) are highly sensitive\nto various factors such as the Sr doping level $x$, lattice strain, and oxygen\nstoichiometry due to the strongly correlated nature of $3d$ electrons. For the\ndevelopment of energy-efficient spintronic devices with ultra-low magnetic\ndamping of LSMO, a thorough understanding of its complex magnetization dynamics\nis of great importance. In this work, we have measured ferromagnetic resonance\nof LSMO thin films on Nb-doped SrTiO$_3$ (Nb-STO) substrates over a wide\ntemperature and frequency range and observed an anomalous increase in the\nGilbert damping constant and a decrease in the effective saturation\nmagnetization at temperatures below 100 K. The anomalies become more pronounced\nas the LSMO thickness decreases while they are not observed for LSMO on\n(LaAlO$_3$)$_{0.3}$(Sr$_2$TaAlO$_6$)$_{0.7}$ substrates with relatively small\nepitaxial strain. The results suggest that the epitaxial strain-induced\nmagnetically dead layer at the LSMO/Nb-STO interface acts as a spin sink and\nleads to the anomalies in the magnetization dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.19005v1",
    "published": "2025-05-25T07:05:55+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.19004v1",
    "title": "Secure IVSHMEM: End-to-End Shared-Memory Protocol with Hypervisor-CA Handshake and In-Kernel Access Control",
    "authors": [
      "Hyunwoo Kim",
      "Jaeseong Lee",
      "Sunpyo Hong",
      "Changmin Han"
    ],
    "abstract": "In-host shared memory (IVSHMEM) enables high-throughput, zero-copy\ncommunication between virtual machines, but today's implementations lack any\nsecurity control, allowing any application to eavesdrop or tamper with the\nIVSHMEM region. This paper presents Secure IVSHMEM, a protocol that provides\nend-to-end mutual authentication and fine-grained access enforcement with\nnegligible performance cost. We combine three techniques to ensure security:\n(1) channel separation and kernel module access control, (2)hypervisor-mediated\nhandshake for end-to-end service authentication, and (3)application-level\nintegration for abstraction and performance mitigation. In microbenchmarks,\nSecure IVSHMEM completes its one-time handshake in under 200ms and sustains\ndata-plane round-trip latencies within 5\\% of the unmodified baseline, with\nnegligible bandwidth overhead. We believe this design is ideally suited for\nsafety and latency-critical in-host domains, such as automotive systems, where\nboth performance and security are paramount.",
    "pdf_url": "http://arxiv.org/pdf/2505.19004v1",
    "published": "2025-05-25T07:02:41+00:00",
    "categories": [
      "cs.CR",
      "C.2.4; D.4.6"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.19003v1",
    "title": "Aligning LLM with human travel choices: a persona-based embedding learning approach",
    "authors": [
      "Tianming Liu",
      "Manzi Li",
      "Yafeng Yin"
    ],
    "abstract": "The advent of large language models (LLMs) presents new opportunities for\ntravel demand modeling. However, behavioral misalignment between LLMs and\nhumans presents obstacles for the usage of LLMs, and existing alignment methods\nare frequently inefficient or impractical given the constraints of typical\ntravel demand data. This paper introduces a novel framework for aligning LLMs\nwith human travel choice behavior, tailored to the current travel demand data\nsources. Our framework uses a persona inference and loading process to\ncondition LLMs with suitable prompts to enhance alignment. The inference step\nestablishes a set of base personas from empirical data, and a learned persona\nloading function driven by behavioral embeddings guides the loading process. We\nvalidate our framework on the Swissmetro mode choice dataset, and the results\nshow that our proposed approach significantly outperformed baseline choice\nmodels and LLM-based simulation models in predicting both aggregate mode choice\nshares and individual choice outcomes. Furthermore, we showcase that our\nframework can generate insights on population behavior through interpretable\nparameters. Overall, our research offers a more adaptable, interpretable, and\nresource-efficient pathway to robust LLM-based travel behavior simulation,\npaving the way to integrate LLMs into travel demand modeling practice in the\nfuture.",
    "pdf_url": "http://arxiv.org/pdf/2505.19003v1",
    "published": "2025-05-25T06:54:01+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.19002v1",
    "title": "Semi-pessimistic Reinforcement Learning",
    "authors": [
      "Jin Zhu",
      "Xin Zhou",
      "Jiaang Yao",
      "Gholamali Aminian",
      "Omar Rivasplata",
      "Simon Little",
      "Lexin Li",
      "Chengchun Shi"
    ],
    "abstract": "Offline reinforcement learning (RL) aims to learn an optimal policy from\npre-collected data. However, it faces challenges of distributional shift, where\nthe learned policy may encounter unseen scenarios not covered in the offline\ndata. Additionally, numerous applications suffer from a scarcity of labeled\nreward data. Relying on labeled data alone often leads to a narrow state-action\ndistribution, further amplifying the distributional shift, and resulting in\nsuboptimal policy learning. To address these issues, we first recognize that\nthe volume of unlabeled data is typically substantially larger than that of\nlabeled data. We then propose a semi-pessimistic RL method to effectively\nleverage abundant unlabeled data. Our approach offers several advantages. It\nconsiderably simplifies the learning process, as it seeks a lower bound of the\nreward function, rather than that of the Q-function or state transition\nfunction. It is highly flexible, and can be integrated with a range of\nmodel-free and model-based RL algorithms. It enjoys the guaranteed improvement\nwhen utilizing vast unlabeled data, but requires much less restrictive\nconditions. We compare our method with a number of alternative solutions, both\nanalytically and numerically, and demonstrate its clear competitiveness. We\nfurther illustrate with an application to adaptive deep brain stimulation for\nParkinson's disease.",
    "pdf_url": "http://arxiv.org/pdf/2505.19002v1",
    "published": "2025-05-25T06:47:36+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.19001v2",
    "title": "DARTH: Declarative Recall Through Early Termination for Approximate Nearest Neighbor Search",
    "authors": [
      "Manos Chatzakis",
      "Yannis Papakonstantinou",
      "Themis Palpanas"
    ],
    "abstract": "Approximate Nearest Neighbor Search (ANNS) presents an inherent tradeoff\nbetween performance and recall (i.e., result quality). Each ANNS algorithm\nprovides its own algorithm-dependent parameters to allow applications to\ninfluence the recall/performance tradeoff of their searches. This situation is\ndoubly problematic. First, the application developers have to experiment with\nthese algorithm-dependent parameters to fine-tune the parameters that produce\nthe desired recall for each use case. This process usually takes a lot of\neffort. Even worse, the chosen parameters may produce good recall for some\nqueries, but bad recall for hard queries. To solve these problems, we present\nDARTH, a method that uses target declarative recall. DARTH uses a novel method\nfor providing target declarative recall on top of an ANNS index by employing an\nadaptive early termination strategy integrated into the search algorithm.\nThrough a wide range of experiments, we demonstrate that DARTH effectively\nmeets user-defined recall targets while achieving significant speedups, up to\n14.6x (average: 6.8x; median: 5.7x) faster than the search without early\ntermination for HNSW and up to 41.8x (average: 13.6x; median: 8.1x) for IVF.\nThis paper appeared in ACM SIGMOD 2026.",
    "pdf_url": "http://arxiv.org/pdf/2505.19001v2",
    "published": "2025-05-25T06:45:53+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.19000v1",
    "title": "VerIPO: Cultivating Long Reasoning in Video-LLMs via Verifier-Gudied Iterative Policy Optimization",
    "authors": [
      "Yunxin Li",
      "Xinyu Chen",
      "Zitao Li",
      "Zhenyu Liu",
      "Longyue Wang",
      "Wenhan Luo",
      "Baotian Hu",
      "Min Zhang"
    ],
    "abstract": "Applying Reinforcement Learning (RL) to Video Large Language Models\n(Video-LLMs) shows significant promise for complex video reasoning. However,\npopular Reinforcement Fine-Tuning (RFT) methods, such as outcome-based Group\nRelative Policy Optimization (GRPO), are limited by data preparation\nbottlenecks (e.g., noise or high cost) and exhibit unstable improvements in the\nquality of long chain-of-thoughts (CoTs) and downstream performance.To address\nthese limitations, we propose VerIPO, a Verifier-guided Iterative Policy\nOptimization method designed to gradually improve video LLMs' capacity for\ngenerating deep, long-term reasoning chains. The core component is\nRollout-Aware Verifier, positioned between the GRPO and Direct Preference\nOptimization (DPO) training phases to form the GRPO-Verifier-DPO training loop.\nThis verifier leverages small LLMs as a judge to assess the reasoning logic of\nrollouts, enabling the construction of high-quality contrastive data, including\nreflective and contextually consistent CoTs. These curated preference samples\ndrive the efficient DPO stage (7x faster than GRPO), leading to marked\nimprovements in reasoning chain quality, especially in terms of length and\ncontextual consistency. This training loop benefits from GRPO's expansive\nsearch and DPO's targeted optimization. Experimental results demonstrate: 1)\nSignificantly faster and more effective optimization compared to standard GRPO\nvariants, yielding superior performance; 2) Our trained models exceed the\ndirect inference of large-scale instruction-tuned Video-LLMs, producing long\nand contextually consistent CoTs on diverse video reasoning tasks; and 3) Our\nmodel with one iteration outperforms powerful LMMs (e.g., Kimi-VL) and long\nreasoning models (e.g., Video-R1), highlighting its effectiveness and\nstability.",
    "pdf_url": "http://arxiv.org/pdf/2505.19000v1",
    "published": "2025-05-25T06:41:28+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18999v1",
    "title": "Lightweight Embeddings with Graph Rewiring for Collaborative Filtering",
    "authors": [
      "Xurong Liang",
      "Tong Chen",
      "Wei Yuan",
      "Hongzhi Yin"
    ],
    "abstract": "As recommendation services scale rapidly and their deployment now commonly\ninvolves resource-constrained edge devices, GNN-based recommender systems face\nsignificant challenges, including high embedding storage costs and runtime\nlatency from graph propagations. Our previous work, LEGCF, effectively reduced\nembedding storage costs but struggled to maintain recommendation performance\nunder stricter storage limits. Additionally, LEGCF did not address the\nextensive runtime computation costs associated with graph propagation, which\ninvolves heavy multiplication and accumulation operations (MACs). These\nchallenges consequently hinder effective training and inference on\nresource-constrained edge devices. To address these limitations, we propose\nLightweight Embeddings with Rewired Graph for Graph Collaborative Filtering\n(LERG), an improved extension of LEGCF. LERG retains LEGCFs compositional\ncodebook structure but introduces quantization techniques to reduce the storage\ncost, enabling the inclusion of more meta-embeddings within the same storage.\nTo optimize graph propagation, we pretrain the quantized compositional\nembedding table using the full interaction graph on resource-rich servers,\nafter which a fine-tuning stage is engaged to identify and prune\nlow-contribution entities via a gradient-free binary integer programming\napproach, constructing a rewired graph that excludes these entities (i.e.,\nuser/item nodes) from propagating signals. The quantized compositional\nembedding table with selective embedding participation and sparse rewired graph\nare transferred to edge devices which significantly reduce computation memory\nand inference time. Experiments on three public benchmark datasets, including\nan industry-scale dataset, demonstrate that LERG achieves superior\nrecommendation performance while dramatically reducing storage and computation\ncosts for graph-based recommendation services.",
    "pdf_url": "http://arxiv.org/pdf/2505.18999v1",
    "published": "2025-05-25T06:39:20+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.18998v1",
    "title": "Property Directed Reachability with Extended Resolution",
    "authors": [
      "Andrew Luka",
      "Yakir Vizel"
    ],
    "abstract": "Property Directed Reachability (\\textsc{Pdr}), also known as IC3, is a\nstate-of-the-art model checking algorithm widely used for verifying safety\nproperties. While \\textsc{Pdr} is effective in finding inductive invariants,\nits underlying proof system, Resolution, limits its ability to construct short\nproofs for certain verification problems.\n  This paper introduces \\textsc{PdrER}, a novel generalization of \\textsc{Pdr}\nthat uses Extended Resolution (ER), a proof system exponentially stronger than\nResolution, when constructing a proof of correctness. \\PdrEV leverages ER to\nconstruct shorter bounded proofs of correctness, enabling it to discover more\ncompact inductive invariants. While \\PdrEV is based on \\textsc{Pdr}, it\nincludes algorithmic enhancements that had to be made in order to efficiently\nuse ER in the context of model checking.\n  We implemented \\textsc{PdrER} in a new open-source verification framework and\nevaluated it on the Hardware Model Checking Competition benchmarks from 2019,\n2020 and 2024. Our experimental evaluation demonstrates that \\textsc{PdrER}\noutperforms \\textsc{Pdr}, solving more instances in less time and uniquely\nsolving problems that \\textsc{Pdr} cannot solve within a given time limit. We\nargue that this paper represents a significant step toward making strong proof\nsystems practically usable in model checking.",
    "pdf_url": "http://arxiv.org/pdf/2505.18998v1",
    "published": "2025-05-25T06:37:41+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.18997v1",
    "title": "Probing Quantum Gravity in Stellar Spacetimes: Phenomenological Insights",
    "authors": [
      "Reggie C. Pantig",
      "Ali Ovgun",
      "Gaetano Lambiase"
    ],
    "abstract": "We explore the weak-field phenomenology of a compact star spacetime modified\nby quantum gravitational corrections derived from the effective field\ntheoretical (EFT) approach by Calmet et al. [1]. These corrections, encoded in\nnon-local curvature-squared terms, distinguish matter-supported geometries from\nvacuum solutions by contributing nontrivial modifications at second order in G.\nUsing the corrected metric, we analytically derive expressions for the\ndeflection of light and time-like particles via the Gauss-Bonnet theorem. We\nfurther compute the perihelion advance of Mercury, Shapiro time delay, and\ngravitational redshift within this framework. Each classical observable\nacquires quantum corrections that, though exceedingly small represent potential\nimprints of quantum gravity. The Shapiro delay and redshift likewise exhibit\nfinite, source-dependent deviations from their general relativistic predictions\ndue to the modified temporal metric component. While current observational\ncapabilities remain insufficient to detect these minute effects, the analysis\ndemonstrates that quantum gravitational signatures are embedded even in\nweak-field observables. Last, we study massless scalar perturbations in static,\nspherically symmetric spacetimes by analyzing their quasinormal modes (QNMs)\nand greybody factors using the WKB method and Pade resummation. Our findings\ndemonstrate that increasing the coupling parameter enhances spacetime stability\nand significantly influences emission spectra through frequency-dependent\ntransparency. Moreover, the results underscore that quantum-corrected star\nmetrics yield phenomenological distinctions from classical black holes,\nparticularly near the Planck scale, where vacuum solutions lose validity.",
    "pdf_url": "http://arxiv.org/pdf/2505.18997v1",
    "published": "2025-05-25T06:36:34+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.18996v1",
    "title": "Automatic and Structure-Aware Sparsification of Hybrid Neural ODEs",
    "authors": [
      "Bob Junyi Zou",
      "Lu Tian"
    ],
    "abstract": "Hybrid neural ordinary differential equations (neural ODEs) integrate\nmechanistic models with neural ODEs, offering strong inductive bias and\nflexibility, and are particularly advantageous in data-scarce healthcare\nsettings. However, excessive latent states and interactions from mechanistic\nmodels can lead to training inefficiency and over-fitting, limiting practical\neffectiveness of hybrid neural ODEs. In response, we propose a new hybrid\npipeline for automatic state selection and structure optimization in\nmechanistic neural ODEs, combining domain-informed graph modifications with\ndata-driven regularization to sparsify the model for improving predictive\nperformance and stability while retaining mechanistic plausibility. Experiments\non synthetic and real-world data show improved predictive performance and\nrobustness with desired sparsity, establishing an effective solution for hybrid\nmodel reduction in healthcare applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.18996v1",
    "published": "2025-05-25T06:36:30+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18995v1",
    "title": "FiLLM -- A Filipino-optimized Large Language Model based on Southeast Asia Large Language Model (SEALLM)",
    "authors": [
      "Carlos Jude G. Maminta",
      "Isaiah Job Enriquez",
      "Deandre Nigel Nunez",
      "Michael B. Dela Fuente"
    ],
    "abstract": "This study presents FiLLM, a Filipino-optimized large language model,\ndesigned to enhance natural language processing (NLP) capabilities in the\nFilipino language. Built upon the SeaLLM-7B 2.5 model, FiLLM leverages Low-Rank\nAdaptation (LoRA) fine-tuning to optimize memory efficiency while maintaining\ntask-specific performance. The model was trained and evaluated on diverse\nFilipino datasets to address key NLP tasks, including Named Entity Recognition\n(NER), Part-of-Speech (POS) tagging, Dependency Parsing, and Text\nSummarization. Performance comparisons with the CalamanCy model were conducted\nusing F1 Score, Precision, Recall, Compression Rate, and Keyword Overlap\nmetrics. Results indicate that Calamancy outperforms FILLM in several aspects,\ndemonstrating its effectiveness in processing Filipino text with improved\nlinguistic comprehension and adaptability. This research contributes to the\nadvancement of Filipino NLP applications by providing an optimized, efficient,\nand scalable language model tailored for local linguistic needs.",
    "pdf_url": "http://arxiv.org/pdf/2505.18995v1",
    "published": "2025-05-25T06:36:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18994v1",
    "title": "Designing Pin-pression Gripper and Learning its Dexterous Grasping with Online In-hand Adjustment",
    "authors": [
      "Hewen Xiao",
      "Xiuping Liu",
      "Hang Zhao",
      "Jian Liu",
      "Kai Xu"
    ],
    "abstract": "We introduce a novel design of parallel-jaw grippers drawing inspiration from\npin-pression toys. The proposed pin-pression gripper features a distinctive\nmechanism in which each finger integrates a 2D array of pins capable of\nindependent extension and retraction. This unique design allows the gripper to\ninstantaneously customize its finger's shape to conform to the object being\ngrasped by dynamically adjusting the extension/retraction of the pins. In\naddition, the gripper excels in in-hand re-orientation of objects for enhanced\ngrasping stability again via dynamically adjusting the pins. To learn the\ndynamic grasping skills of pin-pression grippers, we devise a dedicated\nreinforcement learning algorithm with careful designs of state representation\nand reward shaping. To achieve a more efficient grasp-while-lift grasping mode,\nwe propose a curriculum learning scheme. Extensive evaluations demonstrate that\nour design, together with the learned skills, leads to highly flexible and\nrobust grasping with much stronger generality to unseen objects than\nalternatives. We also highlight encouraging physical results of sim-to-real\ntransfer on a physically manufactured pin-pression gripper, demonstrating the\npractical significance of our novel gripper design and grasping skill.\nDemonstration videos for this paper are available at\nhttps://github.com/siggraph-pin-pression-gripper/pin-pression-gripper-video.",
    "pdf_url": "http://arxiv.org/pdf/2505.18994v1",
    "published": "2025-05-25T06:32:56+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00029v1",
    "title": "Characterization of atomization and delivery efficiency of exogenous surfactant in preterm infant lungs using an ex vivo respiratory model",
    "authors": [
      "Ghalia Kaouane",
      "Jean-François Berret",
      "Yannick Cremillieux",
      "Noël Pinaud",
      "Fanny Munsch",
      "Bei Zhang",
      "Michael Fayon",
      "Rémy Gérard",
      "Eric Dumas De La Roque",
      "Sophie Perinel-Ragey",
      "Lara Leclerc",
      "Jérémie Pourchez"
    ],
    "abstract": "Administration of pulmonary surfactant is crucial for the treatment of\nrespiratory distress syndrome (RDS) in preterm infants. The aim of this study\nis to evaluate the potential of Curosurf atomization via the Endosurf device, a\nrecently developed spray technology, as a promising approach for surfactant\ndelivery in infants with RDS. A comprehensive analysis was performed to\nevaluate the physicochemical properties of atomized Curosurf, including its\nsurface tension and rheology. The size distribution of Curosurf vesicles was\nalso investigated. An ex vivo respiratory model based on rabbit lungs breathing\nthrough an instrumented hypobaric chamber representing the thorax of a preterm\ninfant was developed to provide proof of concept for regional aerosol\ndeposition of atomized Curosurf. The atomization of Curosurf with the\ninnovative Endosurf device did not significantly alter surface tension, but\nreduced vesicle size and promoted homogeneous distribution of Curosurf in the\nlungs. Rheological measurements showed the viscoelastic complexity of atomized\nCurosurf. This preliminary study confirmed the promising potential of Curosurf\natomization via the Endosurf device for the distribution of surfactant in the\nlungs of infants with RDS. These advances could help to improve the treatment\nof RDS in preterm infants and offer new perspectives for healthcare\nprofessionals and affected families.",
    "pdf_url": "http://arxiv.org/pdf/2506.00029v1",
    "published": "2025-05-25T06:30:18+00:00",
    "categories": [
      "physics.med-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.18993v1",
    "title": "A high-efficiency neuroevolution potential for tobermorite and calcium silicate hydrate systems with ab initio accuracy",
    "authors": [
      "Xiao Xu",
      "Shijie Wang",
      "Haifeng Qin",
      "Zhiqiang Zhao",
      "Zheyong Fan",
      "Zhuhua Zhang",
      "Hang Yin"
    ],
    "abstract": "Tobermorite and Calcium Silicate Hydrate (C-S-H) systems are indispensable\ncement materials but still lack a satisfactory interatomic potential with both\nhigh accuracy and high computational efficiency for better understanding their\nmechanical performance. Here, we develop a Neuroevolution Machine Learning\nPotential (NEP) with Ziegler-Biersack-Littmark hybrid framework for tobermorite\nand C-S-H systems, which conveys unprecedented efficiency in molecular dynamics\nsimulations with substantially reduced training datasets. Our NEP model\nachieves prediction accuracy comparable to DFT calculations using just around\n300 training structures, significantly fewer than other existing machine\nlearning potentials trained for tobermorite. Critically, the GPU-accelerated\nNEP computations enable scalable simulations of large tobermorite systems,\nreaching several thousand atoms per GPU card with high efficiency. We\ndemonstrate the NEP's versatility by accurately predicting mechanical\nproperties, phonon density of states, and thermal conductivity of tobermorite.\nFurthermore, we extend the NEP application to large-scale simulations of\namorphous C-S-H, highlighting its potential for comprehensive analysis of\nstructural and mechanical behaviors under various realistic conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.18993v1",
    "published": "2025-05-25T06:30:17+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.18992v1",
    "title": "VPGS-SLAM: Voxel-based Progressive 3D Gaussian SLAM in Large-Scale Scenes",
    "authors": [
      "Tianchen Deng",
      "Wenhua Wu",
      "Junjie He",
      "Yue Pan",
      "Xirui Jiang",
      "Shenghai Yuan",
      "Danwei Wang",
      "Hesheng Wang",
      "Weidong Chen"
    ],
    "abstract": "3D Gaussian Splatting has recently shown promising results in dense visual\nSLAM. However, existing 3DGS-based SLAM methods are all constrained to\nsmall-room scenarios and struggle with memory explosion in large-scale scenes\nand long sequences. To this end, we propose VPGS-SLAM, the first 3DGS-based\nlarge-scale RGBD SLAM framework for both indoor and outdoor scenarios. We\ndesign a novel voxel-based progressive 3D Gaussian mapping method with multiple\nsubmaps for compact and accurate scene representation in large-scale and\nlong-sequence scenes. This allows us to scale up to arbitrary scenes and\nimproves robustness (even under pose drifts). In addition, we propose a 2D-3D\nfusion camera tracking method to achieve robust and accurate camera tracking in\nboth indoor and outdoor large-scale scenes. Furthermore, we design a 2D-3D\nGaussian loop closure method to eliminate pose drift. We further propose a\nsubmap fusion method with online distillation to achieve global consistency in\nlarge-scale scenes when detecting a loop. Experiments on various indoor and\noutdoor datasets demonstrate the superiority and generalizability of the\nproposed framework. The code will be open source on\nhttps://github.com/dtc111111/vpgs-slam.",
    "pdf_url": "http://arxiv.org/pdf/2505.18992v1",
    "published": "2025-05-25T06:27:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18991v1",
    "title": "Kernel Space Diffusion Model for Efficient Remote Sensing Pansharpening",
    "authors": [
      "Hancong Jin",
      "Zihan Cao",
      "Liangjian Deng"
    ],
    "abstract": "Pansharpening is a fundamental task in remote sensing that integrates\nhigh-resolution panchromatic imagery (PAN) with low-resolution multispectral\nimagery (LRMS) to produce an enhanced image with both high spatial and spectral\nresolution. Despite significant progress in deep learning-based approaches,\nexisting methods often fail to capture the global priors inherent in remote\nsensing data distributions. Diffusion-based models have recently emerged as\npromising solutions due to their powerful distribution mapping capabilities;\nhowever, they suffer from significant inference latency, which limits their\npractical applicability. In this work, we propose the Kernel Space Diffusion\nModel (KSDiff), a novel approach that leverages diffusion processes in a latent\nspace to generate convolutional kernels enriched with global contextual\ninformation, thereby improving pansharpening quality while enabling faster\ninference. Specifically, KSDiff constructs these kernels through the\nintegration of a low-rank core tensor generator and a unified factor generator,\norchestrated by a structure-aware multi-head attention mechanism. We further\nintroduce a two-stage training strategy tailored for pansharpening, enabling\nKSDiff to serve as a framework for enhancing existing pansharpening\narchitectures. Experiments on three widely used datasets, including\nWorldView-3, GaoFen-2, and QuickBird, demonstrate the superior performance of\nKSDiff both qualitatively and quantitatively. Code will be released upon\npossible acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2505.18991v1",
    "published": "2025-05-25T06:25:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18990v1",
    "title": "Room-temperature spin-lifetime anisotropy exceeding 60 in bilayer graphene spin valves proximity coupled to WSe$_2$",
    "authors": [
      "Timo Bisswanger",
      "Anne Schmidt",
      "Frank Volmer",
      "Christoph Stampfer",
      "Bernd Beschoten"
    ],
    "abstract": "A spin lifetime anisotropy between in-plane and out-of-plane spins in bilayer\ngraphene (BLG) can be achieved by spin-orbit proximity coupling of graphene to\ntransition metal dichalcogenides. This coupling reduces the in-plane spin\nlifetime due to proximity-induced spin scattering, while the out-of-plane spin\nlifetime remains largely unaffected. We show that at room temperature spin\nlifetime anisotropy exceeds 60 in a bilayer graphene lateral spin valve\nproximity coupled to WSe$_2$. The out-of-plane spin lifetime of about 250 ps\nclosely matches that of a BLG reference region not in contact with WSe$_2$. In\ncontrast, the estimated in-plane spin lifetime of less than 4 ps leads to a\ncomplete suppression of the in-plane spin signal at the ferromagnetic Co/MgO\nspin detector. The proximity coupling of WSe$_2$ to BLG is particularly\npromising, as it does not compromise the charge carrier mobility within the\ngraphene channel.",
    "pdf_url": "http://arxiv.org/pdf/2505.18990v1",
    "published": "2025-05-25T06:24:29+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.18989v1",
    "title": "SPARS: Self-Play Adversarial Reinforcement Learning for Segmentation of Liver Tumours",
    "authors": [
      "Catalina Tan",
      "Yipeng Hu",
      "Shaheer U. Saeed"
    ],
    "abstract": "Accurate tumour segmentation is vital for various targeted diagnostic and\ntherapeutic procedures for cancer, e.g., planning biopsies or tumour ablations.\nManual delineation is extremely labour-intensive, requiring substantial expert\ntime. Fully-supervised machine learning models aim to automate such\nlocalisation tasks, but require a large number of costly and often subjective\n3D voxel-level labels for training. The high-variance and subjectivity in such\nlabels impacts model generalisability, even when large datasets are available.\nHistopathology labels may offer more objective labels but the infeasibility of\nacquiring pixel-level annotations to develop tumour localisation methods based\non histology remains challenging in-vivo. In this work, we propose a novel\nweakly-supervised semantic segmentation framework called SPARS (Self-Play\nAdversarial Reinforcement Learning for Segmentation), which utilises an object\npresence classifier, trained on a small number of image-level binary cancer\npresence labels, to localise cancerous regions on CT scans. Such binary labels\nof patient-level cancer presence can be sourced more feasibly from biopsies and\nhistopathology reports, enabling a more objective cancer localisation on\nmedical images. Evaluating with real patient data, we observed that SPARS\nyielded a mean dice score of $77.3 \\pm 9.4$, which outperformed other\nweakly-supervised methods by large margins. This performance was comparable\nwith recent fully-supervised methods that require voxel-level annotations. Our\nresults demonstrate the potential of using SPARS to reduce the need for\nextensive human-annotated labels to detect cancer in real-world healthcare\nsettings.",
    "pdf_url": "http://arxiv.org/pdf/2505.18989v1",
    "published": "2025-05-25T06:14:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18988v1",
    "title": "NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results",
    "authors": [
      "Varun Jain",
      "Zongwei Wu",
      "Quan Zou",
      "Louis Florentin",
      "Henrik Turbell",
      "Sandeep Siddhartha",
      "Radu Timofte",
      "others"
    ],
    "abstract": "This paper presents a comprehensive review of the 1st Challenge on Video\nQuality Enhancement for Video Conferencing held at the NTIRE workshop at CVPR\n2025, and highlights the problem statement, datasets, proposed solutions, and\nresults. The aim of this challenge was to design a Video Quality Enhancement\n(VQE) model to enhance video quality in video conferencing scenarios by (a)\nimproving lighting, (b) enhancing colors, (c) reducing noise, and (d) enhancing\nsharpness - giving a professional studio-like effect. Participants were given a\ndifferentiable Video Quality Assessment (VQA) model, training, and test videos.\nA total of 91 participants registered for the challenge. We received 10 valid\nsubmissions that were evaluated in a crowdsourced framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.18988v1",
    "published": "2025-05-25T05:53:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18987v1",
    "title": "Error estimates for the interpolation and approximation of gradients and vector fields on protected Delaunay meshes in $\\mathbb{R}^d$",
    "authors": [
      "David M. Williams",
      "Mathijs Wintraecken"
    ],
    "abstract": "One frequently needs to interpolate or approximate gradients on simplicial\nmeshes. Unfortunately, there are very few explicit mathematical results\ngoverning the interpolation or approximation of vector-valued functions on\nDelaunay meshes in more than two dimensions. Most of the existing results are\ntailored towards interpolation with piecewise linear polynomials. In contrast,\ninterpolation with piecewise high-order polynomials is not well understood. In\nparticular, the results in this area are sometimes difficult to immediately\ninterpret, or to specialize to the Delaunay setting. In order to address this\nissue, we derive explicit error estimates for high-order, piecewise polynomial\ngradient interpolation and approximation on protected Delaunay meshes. In\naddition, we generalize our analysis beyond gradients, and obtain error\nestimates for sufficiently-smooth vector fields. Throughout the paper, we show\nthat the quality of interpolation and approximation often depends (in part) on\nthe minimum thickness of simplices in the mesh. Fortunately, the minimum\nthickness can be precisely controlled on protected Delaunay meshes in\n$\\mathbb{R}^d$.",
    "pdf_url": "http://arxiv.org/pdf/2505.18987v1",
    "published": "2025-05-25T05:50:37+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65N50, 65N15, 65N30"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.13992v1",
    "title": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science",
    "authors": [
      "An Luo",
      "Xun Xian",
      "Jin Du",
      "Fangqiao Tian",
      "Ganghua Wang",
      "Ming Zhong",
      "Shengchun Zhao",
      "Xuan Bi",
      "Zirui Liu",
      "Jiawei Zhou",
      "Jayanth Srinivasa",
      "Ashish Kundu",
      "Charles Fleming",
      "Mingyi Hong",
      "Jie Ding"
    ],
    "abstract": "Large language models (LLMs) have advanced the automation of data science\nworkflows. Yet it remains unclear whether they can critically leverage external\ndomain knowledge as human data scientists do in practice. To answer this\nquestion, we introduce AssistedDS (Assisted Data Science), a benchmark designed\nto systematically evaluate how LLMs handle domain knowledge in tabular\nprediction tasks. AssistedDS features both synthetic datasets with explicitly\nknown generative mechanisms and real-world Kaggle competitions, each\naccompanied by curated bundles of helpful and adversarial documents. These\ndocuments provide domain-specific insights into data cleaning, feature\nengineering, and model selection. We assess state-of-the-art LLMs on their\nability to discern and apply beneficial versus harmful domain knowledge,\nevaluating submission validity, information recall, and predictive performance.\nOur results demonstrate three key findings: (1) LLMs frequently exhibit an\nuncritical adoption of provided information, significantly impairing their\npredictive performance when adversarial content is introduced, (2) helpful\nguidance is often insufficient to counteract the negative influence of\nadversarial information, and (3) in Kaggle datasets, LLMs often make errors in\nhandling time-series data, applying consistent feature engineering across\ndifferent folds, and interpreting categorical variables correctly. These\nfindings highlight a substantial gap in current models' ability to critically\nevaluate and leverage expert knowledge, underscoring an essential research\ndirection for developing more robust, knowledge-aware automated data science\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2506.13992v1",
    "published": "2025-05-25T05:50:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ME",
      "62-07, 62-08, 68T05, 68T07, 68T01, 68T50",
      "I.2.0; I.2.6; I.2.7; I.5.1; I.5.4; H.2.8; G.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18986v1",
    "title": "VL-SAM-V2: Open-World Object Detection with General and Specific Query Fusion",
    "authors": [
      "Zhiwei Lin",
      "Yongtao Wang"
    ],
    "abstract": "Current perception models have achieved remarkable success by leveraging\nlarge-scale labeled datasets, but still face challenges in open-world\nenvironments with novel objects. To address this limitation, researchers\nintroduce open-set perception models to detect or segment arbitrary test-time\nuser-input categories. However, open-set models rely on human involvement to\nprovide predefined object categories as input during inference. More recently,\nresearchers have framed a more realistic and challenging task known as\nopen-ended perception that aims to discover unseen objects without requiring\nany category-level input from humans at inference time. Nevertheless,\nopen-ended models suffer from low performance compared to open-set models. In\nthis paper, we present VL-SAM-V2, an open-world object detection framework that\nis capable of discovering unseen objects while achieving favorable performance.\nTo achieve this, we combine queries from open-set and open-ended models and\npropose a general and specific query fusion module to allow different queries\nto interact. By adjusting queries from open-set models, we enable VL-SAM-V2 to\nbe evaluated in the open-set or open-ended mode. In addition, to learn more\ndiverse queries, we introduce ranked learnable queries to match queries with\nproposals from open-ended models by sorting. Moreover, we design a denoising\npoint training strategy to facilitate the training process. Experimental\nresults on LVIS show that our method surpasses the previous open-set and\nopen-ended methods, especially on rare objects.",
    "pdf_url": "http://arxiv.org/pdf/2505.18986v1",
    "published": "2025-05-25T05:44:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.20346v1",
    "title": "PDFBench: A Benchmark for De novo Protein Design from Function",
    "authors": [
      "Jiahao Kuang",
      "Nuowei Liu",
      "Changzhi Sun",
      "Tao Ji",
      "Yuanbin Wu"
    ],
    "abstract": "In recent years, while natural language processing and multimodal learning\nhave seen rapid advancements, the field of de novo protein design has also\nexperienced significant growth. However, most current methods rely on\nproprietary datasets and evaluation rubrics, making fair comparisons between\ndifferent approaches challenging. Moreover, these methods often employ\nevaluation metrics that capture only a subset of the desired properties of\ndesigned proteins, lacking a comprehensive assessment framework. To address\nthese, we introduce PDFBench, the first comprehensive benchmark for evaluating\nde novo protein design from function. PDFBench supports two tasks:\ndescription-guided design and keyword-guided design. To ensure fair and\nmultifaceted evaluation, we compile 22 metrics covering sequence plausibility,\nstructural fidelity, and language-protein alignment, along with measures of\nnovelty and diversity. We evaluate five state-of-the-art baselines, revealing\ntheir respective strengths and weaknesses across tasks. Finally, we analyze\ninter-metric correlations, exploring the relationships between four categories\nof metrics, and offering guidelines for metric selection. PDFBench establishes\na unified framework to drive future advances in function-driven de novo protein\ndesign.",
    "pdf_url": "http://arxiv.org/pdf/2505.20346v1",
    "published": "2025-05-25T05:40:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18985v1",
    "title": "STRICT: Stress Test of Rendering Images Containing Text",
    "authors": [
      "Tianyu Zhang",
      "Xinyu Wang",
      "Zhenghan Tai",
      "Lu Li",
      "Jijun Chi",
      "Jingrui Tian",
      "Hailin He",
      "Suyuchen Wang"
    ],
    "abstract": "While diffusion models have revolutionized text-to-image generation with\ntheir ability to synthesize realistic and diverse scenes, they continue to\nstruggle to generate consistent and legible text within images. This\nshortcoming is commonly attributed to the locality bias inherent in\ndiffusion-based generation, which limits their ability to model long-range\nspatial dependencies. In this paper, we introduce $\\textbf{STRICT}$, a\nbenchmark designed to systematically stress-test the ability of diffusion\nmodels to render coherent and instruction-aligned text in images. Our benchmark\nevaluates models across multiple dimensions: (1) the maximum length of readable\ntext that can be generated; (2) the correctness and legibility of the generated\ntext, and (3) the ratio of not following instructions for generating text. We\nevaluate several state-of-the-art models, including proprietary and open-source\nvariants, and reveal persistent limitations in long-range consistency and\ninstruction-following capabilities. Our findings provide insights into\narchitectural bottlenecks and motivate future research directions in multimodal\ngenerative modeling. We release our entire evaluation pipeline at\nhttps://github.com/tianyu-z/STRICT-Bench.",
    "pdf_url": "http://arxiv.org/pdf/2505.18985v1",
    "published": "2025-05-25T05:37:08+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18984v1",
    "title": "Self-supervised learning method using multiple sampling strategies for general-purpose audio representation",
    "authors": [
      "Ibuki Kuroyanagi",
      "Tatsuya Komatsu"
    ],
    "abstract": "We propose a self-supervised learning method using multiple sampling\nstrategies to obtain general-purpose audio representation. Multiple sampling\nstrategies are used in the proposed method to construct contrastive losses from\ndifferent perspectives and learn representations based on them. In this study,\nin addition to the widely used clip-level sampling strategy, we introduce two\nnew strategies, a frame-level strategy and a task-specific strategy. The\nproposed multiple strategies improve the performance of frame-level\nclassification and other tasks like pitch detection, which are not the focus of\nthe conventional single clip-level sampling strategy. We pre-trained the method\non a subset of Audioset and applied it to a downstream task with frozen\nweights. The proposed method improved clip classification, sound event\ndetection, and pitch detection performance by 25%, 20%, and 3.6%.",
    "pdf_url": "http://arxiv.org/pdf/2505.18984v1",
    "published": "2025-05-25T05:36:26+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.18724v1",
    "title": "Towards Real-time Structural Dynamics Simulation with Graph-based Digital Twin Modelling",
    "authors": [
      "Jun Zhang",
      "Tong Zhang",
      "Ying Wang"
    ],
    "abstract": "Precise and timely simulation of a structure's dynamic behavior is crucial\nfor evaluating its performance and assessing its health status. Traditional\nnumerical methods are often limited by high computational costs and low\nefficiency, while deep learning approaches offer a promising alternative.\nHowever, these data-driven methods still face challenges, such as limited\nphysical interpretability and difficulty in adapting to diverse structural\nconfigurations. To address these issues, this study proposes a graph-based\ndigital twin modelling (GDTM) framework to simulate structural dynamic\nresponses across various spatial topologies. In this framework, the adjacency\nmatrix explicitly represents the spatial relationships between structural\nvertices, enhancing the model's physical interpretability. The effectiveness of\nthe proposed framework was validated through comprehensive numerical and\nexperimental studies. The results demonstrate that the framework accurately\nsimulated structural dynamics across different topological configurations, with\nNormalized Mean-Squared Error (NMSE) values consistently below 0.005 in\nnumerical simulations and 0.0015 in experimental validations. Furthermore, the\nframework achieved over 80-fold improvements in computational efficiency\ncompared to traditional finite element methods (FEM). This research promotes\nthe practical application of graph-based structural dynamics modelling, which\nhas the potential to significantly advance structural performance evaluation\nand health monitoring.",
    "pdf_url": "http://arxiv.org/pdf/2506.18724v1",
    "published": "2025-05-25T05:32:58+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.18983v1",
    "title": "AmorLIP: Efficient Language-Image Pretraining via Amortization",
    "authors": [
      "Haotian Sun",
      "Yitong Li",
      "Yuchen Zhuang",
      "Niao He",
      "Hanjun Dai",
      "Bo Dai"
    ],
    "abstract": "Contrastive Language-Image Pretraining (CLIP) has demonstrated strong\nzero-shot performance across diverse downstream text-image tasks. Existing CLIP\nmethods typically optimize a contrastive objective using negative samples drawn\nfrom each minibatch. To achieve robust representation learning, these methods\nrequire extremely large batch sizes and escalate computational demands to\nhundreds or even thousands of GPUs. Prior approaches to mitigate this issue\noften compromise downstream performance, prolong training duration, or face\nscalability challenges with very large datasets. To overcome these limitations,\nwe propose AmorLIP, an efficient CLIP pretraining framework that amortizes\nexpensive computations involved in contrastive learning through lightweight\nneural networks, which substantially improves training efficiency and\nperformance. Leveraging insights from a spectral factorization of energy-based\nmodels, we introduce novel amortization objectives along with practical\ntechniques to improve training stability. Extensive experiments across 38\ndownstream tasks demonstrate the superior zero-shot classification and\nretrieval capabilities of AmorLIP, consistently outperforming standard CLIP\nbaselines with substantial relative improvements of up to 12.24%.",
    "pdf_url": "http://arxiv.org/pdf/2505.18983v1",
    "published": "2025-05-25T05:30:37+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18982v1",
    "title": "Serial-OE: Anomalous sound detection based on serial method with outlier exposure capable of using small amounts of anomalous data for training",
    "authors": [
      "Ibuki Kuroyanagi",
      "Tomoki Hayashi",
      "Kazuya Takeda",
      "Tomoki Toda"
    ],
    "abstract": "We introduce Serial-OE, a new approach to anomalous sound detection (ASD)\nthat leverages small amounts of anomalous data to improve the performance.\nConventional ASD methods rely primarily on the modeling of normal data, due to\nthe cost of collecting anomalous data from various possible types of equipment\nbreakdowns. Our method improves upon existing ASD systems by implementing an\noutlier exposure framework that utilizes normal and pseudo-anomalous data for\ntraining, with the capability to also use small amounts of real anomalous data.\nA comprehensive evaluation using the DCASE2020 Task2 dataset shows that our\nmethod outperforms state-of-the-art ASD models. We also investigate the impact\non performance of using a small amount of anomalous data during training, of\nusing data without machine ID information, and of using contaminated training\ndata. Our experimental results reveal the potential of using a very limited\namount of anomalous data during training to address the limitations of existing\nmethods using only normal data for training due to the scarcity of anomalous\ndata. This study contributes to the field by presenting a method that can be\ndynamically adapted to include anomalous data during the operational phase of\nan ASD system, paving the way for more accurate ASD.",
    "pdf_url": "http://arxiv.org/pdf/2505.18982v1",
    "published": "2025-05-25T05:28:58+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.18981v1",
    "title": "FedSKC: Federated Learning with Non-IID Data via Structural Knowledge Collaboration",
    "authors": [
      "Huan Wang",
      "Haoran Li",
      "Huaming Chen",
      "Jun Yan",
      "Lijuan Wang",
      "Jiahua Shi",
      "Shiping Chen",
      "Jun Shen"
    ],
    "abstract": "With the advancement of edge computing, federated learning (FL) displays a\nbright promise as a privacy-preserving collaborative learning paradigm.\nHowever, one major challenge for FL is the data heterogeneity issue, which\nrefers to the biased labeling preferences among multiple clients, negatively\nimpacting convergence and model performance. Most previous FL methods attempt\nto tackle the data heterogeneity issue locally or globally, neglecting\nunderlying class-wise structure information contained in each client. In this\npaper, we first study how data heterogeneity affects the divergence of the\nmodel and decompose it into local, global, and sampling drift sub-problems. To\nexplore the potential of using intra-client class-wise structural knowledge in\nhandling these drifts, we thus propose Federated Learning with Structural\nKnowledge Collaboration (FedSKC). The key idea of FedSKC is to extract and\ntransfer domain preferences from inter-client data distributions, offering\ndiverse class-relevant knowledge and a fair convergent signal. FedSKC comprises\nthree components: i) local contrastive learning, to prevent weight divergence\nresulting from local training; ii) global discrepancy aggregation, which\naddresses the parameter deviation between the server and clients; iii) global\nperiod review, correcting for the sampling drift introduced by the server\nrandomly selecting devices. We have theoretically analyzed FedSKC under\nnon-convex objectives and empirically validated its superiority through\nextensive experimental results.",
    "pdf_url": "http://arxiv.org/pdf/2505.18981v1",
    "published": "2025-05-25T05:24:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18980v1",
    "title": "Improving Anomalous Sound Detection through Pseudo-anomalous Set Selection and Pseudo-label Utilization under Unlabeled Conditions",
    "authors": [
      "Ibuki Kuroyanagi",
      "Takuya Fujimura",
      "Kazuya Takeda",
      "Tomoki Toda"
    ],
    "abstract": "This paper addresses performance degradation in anomalous sound detection\n(ASD) when neither sufficiently similar machine data nor operational state\nlabels are available. We present an integrated pipeline that combines three\ncomplementary components derived from prior work and extends them to the\nunlabeled ASD setting. First, we adapt an anomaly score based selector to\ncurate external audio data resembling the normal sounds of the target machine.\nSecond, we utilize triplet learning to assign pseudo-labels to unlabeled data,\nenabling finer classification of operational sounds and detection of subtle\nanomalies. Third, we employ iterative training to refine both the\npseudo-anomalous set selection and pseudo-label assignment, progressively\nimproving detection accuracy. Experiments on the DCASE2022-2024 Task 2 datasets\ndemonstrate that, in unlabeled settings, our approach achieves an average AUC\nincrease of over 6.6 points compared to conventional methods. In labeled\nsettings, incorporating external data from the pseudo-anomalous set further\nboosts performance. These results highlight the practicality and robustness of\nour methods in scenarios with scarce machine data and labels, facilitating ASD\ndeployment across diverse industrial settings with minimal annotation effort.",
    "pdf_url": "http://arxiv.org/pdf/2505.18980v1",
    "published": "2025-05-25T05:20:54+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.20345v1",
    "title": "Strong edge-coloring of graphs with maximum edge weight seven",
    "authors": [
      "Runze Wang"
    ],
    "abstract": "A strong edge-coloring of a graph $G$ is an edge-coloring such that any two\nedges of distance at most two receive distinct colors. The minimum number of\ncolors we need in order to give $G$ a strong edge-coloring is called the strong\nchromatic index of $G$, denoted by $\\chi_s'(G)$. The maximum edge weight of $G$\nis defined to be $\\max\\{d(u)+d(v):\\ uv\\in E(G)\\}$. In this paper, using the\ndischarging method, we prove that if $G$ is a graph with maximum edge weight\n$7$ and maximum average degree less than $\\frac{28}{9}$, then $\\chi_s'(G)\\le\n13$.",
    "pdf_url": "http://arxiv.org/pdf/2505.20345v1",
    "published": "2025-05-25T05:18:16+00:00",
    "categories": [
      "math.CO",
      "05C15"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.18979v1",
    "title": "GhostPrompt: Jailbreaking Text-to-image Generative Models based on Dynamic Optimization",
    "authors": [
      "Zixuan Chen",
      "Hao Lin",
      "Ke Xu",
      "Xinghao Jiang",
      "Tanfeng Sun"
    ],
    "abstract": "Text-to-image (T2I) generation models can inadvertently produce\nnot-safe-for-work (NSFW) content, prompting the integration of text and image\nsafety filters. Recent advances employ large language models (LLMs) for\nsemantic-level detection, rendering traditional token-level perturbation\nattacks largely ineffective. However, our evaluation shows that existing\njailbreak methods are ineffective against these modern filters. We introduce\nGhostPrompt, the first automated jailbreak framework that combines dynamic\nprompt optimization with multimodal feedback. It consists of two key\ncomponents: (i) Dynamic Optimization, an iterative process that guides a large\nlanguage model (LLM) using feedback from text safety filters and CLIP\nsimilarity scores to generate semantically aligned adversarial prompts; and\n(ii) Adaptive Safety Indicator Injection, which formulates the injection of\nbenign visual cues as a reinforcement learning problem to bypass image-level\nfilters. GhostPrompt achieves state-of-the-art performance, increasing the\nShieldLM-7B bypass rate from 12.5\\% (Sneakyprompt) to 99.0\\%, improving CLIP\nscore from 0.2637 to 0.2762, and reducing the time cost by $4.2 \\times$.\nMoreover, it generalizes to unseen filters including GPT-4.1 and successfully\njailbreaks DALLE 3 to generate NSFW images in our evaluation, revealing\nsystemic vulnerabilities in current multimodal defenses. To support further\nresearch on AI safety and red-teaming, we will release code and adversarial\nprompts under a controlled-access protocol.",
    "pdf_url": "http://arxiv.org/pdf/2505.18979v1",
    "published": "2025-05-25T05:13:06+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18978v1",
    "title": "AI4Math: A Native Spanish Benchmark for University-Level Mathematical Reasoning in Large Language Models",
    "authors": [
      "Miguel Angel Peñaloza Perez",
      "Bruno Lopez Orozco",
      "Jesus Tadeo Cruz Soto",
      "Michelle Bruno Hernandez",
      "Miguel Angel Alvarado Gonzalez",
      "Sandra Malagon"
    ],
    "abstract": "Existing mathematical reasoning benchmarks are predominantly English only or\ntranslation-based, which can introduce semantic drift and mask languagespecific\nreasoning errors. To address this, we present AI4Math, a benchmark of 105\noriginal university level math problems natively authored in Spanish. The\ndataset spans seven advanced domains (Algebra, Calculus, Geometry, Probability,\nNumber Theory, Combinatorics, and Logic), and each problem is accompanied by a\nstep by step human solution. We evaluate six large language models GPT 4o, GPT\n4o mini, o3 mini, LLaMA 3.3 70B, DeepSeek R1 685B, and DeepSeek V3 685B under\nfour configurations: zero shot and chain of thought, each in Spanish and\nEnglish. The top models (o3 mini, DeepSeek R1 685B, DeepSeek V3 685B) achieve\nover 70% accuracy, whereas LLaMA 3.3 70B and GPT-4o mini remain below 40%. Most\nmodels show no significant performance drop between languages, with GPT 4o even\nperforming better on Spanish problems in the zero shot setting. Geometry,\nCombinatorics, and Probability questions remain persistently challenging for\nall models. These results highlight the need for native-language benchmarks and\ndomain-specific evaluations to reveal reasoning failures not captured by\nstandard metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.18978v1",
    "published": "2025-05-25T05:08:25+00:00",
    "categories": [
      "cs.CL",
      "68",
      "I.2"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18977v1",
    "title": "On properness of moduli stacks of $D^{\\times}$-shtukas over ramified legs",
    "authors": [
      "Yong-Gyu Choi",
      "Wansu Kim",
      "Junyeong Park"
    ],
    "abstract": "Given a maximal order $D$ of a central division algebra over a global\nfunction field $F$, we prove an explicit sufficient condition for moduli stacks\nof $D^\\times$-shtukas to be proper over a finite field in terms of the local\ninvariants of $D$ and bounds. Our proof is a refinement of E.~Lau's result\n(Duke Math. J. 140 (2007)), which showed the properness of the leg morphism (or\ncharacteristic morphism) away from the ramification locus of $D$. We also\nestablish non-emptiness of Newton and Kottwitz--Rapoport strata for moduli\nstacks of $B^\\times$-shtukas, where $B$ is a maximal order of a central simple\nalgebra over $F$.",
    "pdf_url": "http://arxiv.org/pdf/2505.18977v1",
    "published": "2025-05-25T05:04:08+00:00",
    "categories": [
      "math.NT",
      "math.AG",
      "14H60, 14D23, 14G35"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.18976v1",
    "title": "GraSS: Scalable Influence Function with Sparse Gradient Compression",
    "authors": [
      "Pingbang Hu",
      "Joseph Melkonian",
      "Weijing Tang",
      "Han Zhao",
      "Jiaqi W. Ma"
    ],
    "abstract": "Gradient-based data attribution methods, such as influence functions, are\ncritical for understanding the impact of individual training samples without\nrequiring repeated model retraining. However, their scalability is often\nlimited by the high computational and memory costs associated with per-sample\ngradient computation. In this work, we propose GraSS, a novel gradient\ncompression algorithm and its variants FactGraSS for linear layers\nspecifically, that explicitly leverage the inherent sparsity of per-sample\ngradients to achieve sub-linear space and time complexity. Extensive\nexperiments demonstrate the effectiveness of our approach, achieving\nsubstantial speedups while preserving data influence fidelity. In particular,\nFactGraSS achieves up to 165% faster throughput on billion-scale models\ncompared to the previous state-of-the-art baselines. Our code is publicly\navailable at https://github.com/TRAIS-Lab/GraSS.",
    "pdf_url": "http://arxiv.org/pdf/2505.18976v1",
    "published": "2025-05-25T04:58:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18975v4",
    "title": "FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization",
    "authors": [
      "Aotao Wang",
      "Haikuo Shao",
      "Shaobo Ma",
      "Zhongfeng Wang"
    ],
    "abstract": "State Space Models (SSMs), like recent Mamba2, have achieved remarkable\nperformance and received extensive attention. However, deploying Mamba2 on\nresource-constrained edge devices encounters many problems: severe outliers\nwithin the linear layer challenging the quantization, diverse and irregular\nelement-wise tensor operations, and hardware-unfriendly nonlinear functions in\nthe SSM block. To address these issues, this paper presents FastMamba, a\ndedicated accelerator on FPGA with hardware-algorithm co-design to promote the\ndeployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit\nquantization for linear layers through Hadamard transformation to eliminate\noutliers. Moreover, a hardware-friendly and fine-grained power-of-two\nquantization framework is presented for the SSM block and convolution layer,\nand a first-order linear approximation is developed to optimize the nonlinear\nfunctions. Based on the accurate algorithm quantization, we propose an\naccelerator that integrates parallel vector processing units, pipelined\nexecution dataflow, and an efficient SSM Nonlinear Approximation Unit, which\nenhances computational efficiency and reduces hardware complexity. Finally, we\nevaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on\nMamba2-130M, FastMamba achieves 68.80\\times and 8.90\\times speedup over Intel\nXeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode\nexperiment with Mamba2-2.7B, FastMamba attains 6\\times higher energy efficiency\nthan RTX 3090 GPU.",
    "pdf_url": "http://arxiv.org/pdf/2505.18975v4",
    "published": "2025-05-25T04:54:53+00:00",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.18974v1",
    "title": "Sparse domination for singular integral operators and their commutators in Dunkl setting with applications",
    "authors": [
      "Yanping Chen",
      "Xueting Han"
    ],
    "abstract": "In this paper, we establish sparse dominations for the\nDunkl-Calder\\'on-Zygmund operators and their commutators in the Dunkl setting.\nAs applications, we first define the Dunkl-Muckenhoupt $A_p$ weight and obtain\nthe weighted bounds for the Dunkl-Calder\\'on-Zygmund operators, as well as the\ntwo-weight bounds for their commutators. Moreover, we also obtain the\nboundedness of the Dunkl-Calder\\'on-Zygmund operators on the extrapolation\nspace of a family of Banach function spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.18974v1",
    "published": "2025-05-25T04:50:15+00:00",
    "categories": [
      "math.CA",
      "Primary: 42B35. Secondary: 42B25, 42B20"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.18973v2",
    "title": "Hierarchical Mamba Meets Hyperbolic Geometry: A New Paradigm for Structured Language Embeddings",
    "authors": [
      "Sarang Patil",
      "Ashish Parmanand Pandey",
      "Ioannis Koutis",
      "Mengjia Xu"
    ],
    "abstract": "Selective state-space models have achieved great success in long-sequence\nmodeling. However, their capacity for language representation, especially in\ncomplex hierarchical reasoning tasks, remains underexplored. Most large\nlanguage models rely on flat Euclidean embeddings, limiting their ability to\ncapture latent hierarchies. To address this limitation, we propose Hierarchical\nMamba (HiM), integrating efficient Mamba2 with exponential growth and curved\nnature of hyperbolic geometry to learn hierarchy-aware language embeddings for\ndeeper linguistic understanding. Mamba2-processed sequences are projected to\nthe Poincare ball (via tangent-based mapping) or Lorentzian manifold (via\ncosine and sine-based mapping) with \"learnable\" curvature, optimized with a\ncombined hyperbolic loss. Our HiM model facilitates the capture of relational\ndistances across varying hierarchical levels, enabling effective long-range\nreasoning. This makes it well-suited for tasks like mixed-hop prediction and\nmulti-hop inference in hierarchical classification. We evaluated our HiM with\nfour linguistic and medical datasets for mixed-hop prediction and multi-hop\ninference tasks. Experimental results demonstrated that: 1) Both HiM models\neffectively capture hierarchical relationships for four ontological datasets,\nsurpassing Euclidean baselines. 2) HiM-Poincare captures fine-grained semantic\ndistinctions with higher h-norms, while HiM-Lorentz provides more stable,\ncompact, and hierarchy-preserving embeddings favoring robustness over detail.",
    "pdf_url": "http://arxiv.org/pdf/2505.18973v2",
    "published": "2025-05-25T04:45:06+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18972v1",
    "title": "Revival with Voice: Multi-modal Controllable Text-to-Speech Synthesis",
    "authors": [
      "Minsu Kim",
      "Pingchuan Ma",
      "Honglie Chen",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "abstract": "This paper explores multi-modal controllable Text-to-Speech Synthesis (TTS)\nwhere the voice can be generated from face image, and the characteristics of\noutput speech (e.g., pace, noise level, distance, tone, place) can be\ncontrollable with natural text description. Specifically, we aim to mitigate\nthe following three challenges in face-driven TTS systems. 1) To overcome the\nlimited audio quality of audio-visual speech corpora, we propose a training\nmethod that additionally utilizes high-quality audio-only speech corpora. 2) To\ngenerate voices not only from real human faces but also from artistic\nportraits, we propose augmenting the input face image with stylization. 3) To\nconsider one-to-many possibilities in face-to-voice mapping and ensure\nconsistent voice generation at the same time, we propose to first employ\nsampling-based decoding and then use prompting with generated speech samples.\nExperimental results validate the proposed model's effectiveness in face-driven\nvoice synthesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.18972v1",
    "published": "2025-05-25T04:43:17+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.18971v1",
    "title": "Is Architectural Complexity Overrated? Competitive and Interpretable Knowledge Graph Completion with RelatE",
    "authors": [
      "Abhijit Chakraborty",
      "Chahana Dahal",
      "Ashutosh Balasubramaniam",
      "Tejas Anvekar",
      "Vivek Gupta"
    ],
    "abstract": "We revisit the efficacy of simple, real-valued embedding models for knowledge\ngraph completion and introduce RelatE, an interpretable and modular method that\nefficiently integrates dual representations for entities and relations. RelatE\nemploys a real-valued phase-modulus decomposition, leveraging sinusoidal phase\nalignments to encode relational patterns such as symmetry, inversion, and\ncomposition. In contrast to recent approaches based on complex-valued\nembeddings or deep neural architectures, RelatE preserves architectural\nsimplicity while achieving competitive or superior performance on standard\nbenchmarks. Empirically, RelatE outperforms prior methods across several\ndatasets: on YAGO3-10, it achieves an MRR of 0.521 and Hit@10 of 0.680,\nsurpassing all baselines. Additionally, RelatE offers significant efficiency\ngains, reducing training time by 24%, inference latency by 31%, and peak GPU\nmemory usage by 22% compared to RotatE. Perturbation studies demonstrate\nimproved robustness, with MRR degradation reduced by up to 61% relative to\nTransE and by up to 19% compared to RotatE under structural edits such as edge\nremovals and relation swaps. Formal analysis further establishes the model's\nfull expressiveness and its capacity to represent essential first-order logical\ninference patterns. These results position RelatE as a scalable and\ninterpretable alternative to more complex architectures for knowledge graph\ncompletion.",
    "pdf_url": "http://arxiv.org/pdf/2505.18971v1",
    "published": "2025-05-25T04:36:52+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18970v2",
    "title": "Learning to Explain: Prototype-Based Surrogate Models for LLM Classification",
    "authors": [
      "Bowen Wei",
      "Mehrdad Fazli",
      "Ziwei Zhu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive performance on\nnatural language tasks, but their decision-making processes remain largely\nopaque. Existing explanation methods either suffer from limited faithfulness to\nthe model's reasoning or produce explanations that humans find difficult to\nunderstand. To address these challenges, we propose \\textbf{ProtoSurE}, a novel\nprototype-based surrogate framework that provides faithful and\nhuman-understandable explanations for LLMs. ProtoSurE trains an\ninterpretable-by-design surrogate model that aligns with the target LLM while\nutilizing sentence-level prototypes as human-understandable concepts. Extensive\nexperiments show that ProtoSurE consistently outperforms SOTA explanation\nmethods across diverse LLMs and datasets. Importantly, ProtoSurE demonstrates\nstrong data efficiency, requiring relatively few training examples to achieve\ngood performance, making it practical for real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.18970v2",
    "published": "2025-05-25T04:25:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18969v1",
    "title": "Machine Psychophysics: Cognitive Control in Vision-Language Models",
    "authors": [
      "Dezhi Luo",
      "Maijunxian Wang",
      "Bingyang Wang",
      "Tianwei Zhao",
      "Yijiang Li",
      "Hokin Deng"
    ],
    "abstract": "Cognitive control refers to the ability to flexibly coordinate thought and\naction in pursuit of internal goals. A standard method for assessing cognitive\ncontrol involves conflict tasks that contrast congruent and incongruent trials,\nmeasuring the ability to prioritize relevant information while suppressing\ninterference. We evaluate 108 vision-language models on three classic conflict\ntasks and their more demanding \"squared\" variants across 2,220 trials. Model\nperformance corresponds closely to human behavior under resource constraints\nand reveals individual differences. These results indicate that some form of\nhuman-like executive function have emerged in current multi-modal foundational\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.18969v1",
    "published": "2025-05-25T04:23:28+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.18968v1",
    "title": "Dynamics of Poro-viscoelastic Wetting with Large Swelling",
    "authors": [
      "B. X. Zheng",
      "T. S. Chan",
      "E. H. van Brummelen",
      "J. H. Snoeijer"
    ],
    "abstract": "The deposition of droplets onto a swollen polymer network induces the\nformation of a wetting ridge at the contact line. Current models typically\nconsider either viscoelastic effects or poroelastic effects, while polymeric\ngels often exhibit both properties. In this study, we investigate the growth of\nthe wetting ridge using a comprehensive large deformation theory that\nintegrates both dissipative mechanisms - viscoelasticity and poroelasticity. In\nthe purely poroelastic case, following an initial instantaneous incompressible\ndeformation, the growth dynamics exhibit scale-free behavior, independent of\nthe elastocapillary length or system size. A boundary layer of solvent\nimbibition between the solid surface (in contact with the reservoir) and the\nregion of minimal chemical potential is created. At later times, the ridge\nequilibrates on the diffusion timescale given by the elastocapillary length.\nWhen viscoelastic properties are incorporated, our findings show that, during\nthe early stages (prior to the viscoelastic relaxation timescale), viscoelastic\neffects dominate the growth dynamics of the ridge and solvent transport is\nsignificantly suppressed. Beyond the relaxation time, the late-time dynamics\nclosely resemble those of the purely poroelastic case. These findings are\ndiscussed in light of recent experiments, showing how our approach offers a new\ninterpretation framework for wetting of polymer networks of increasing\ncomplexity.",
    "pdf_url": "http://arxiv.org/pdf/2505.18968v1",
    "published": "2025-05-25T04:17:33+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.18967v1",
    "title": "Beyond endoscopy for $\\mathsf{GL}_2$ over $\\mathbb{Q}$ with ramification: Poisson summation",
    "authors": [
      "Yuhao Cheng"
    ],
    "abstract": "At the beginning of this century, Langlands introduced a strategy known as\n\\emph{Beyond Endoscopy} to attack the principle of functoriality. Altu\\u{g}\nstudied $\\mathsf{GL}_2$ over $\\mathbb{Q}$ in the unramified setting. The first\nstep involves isolating specific representations, especially the residual part\nof the spectral side, in the elliptic part of the geometric side of the trace\nformula. We generalize this step to the case with ramification at\n$S=\\{\\infty,q_1,\\dots,q_r\\}$ with $2\\in S$, thereby fully resolving the problem\nof isolating these representations over $\\mathbb{Q}$ which remained unresolved\nfor over a decade. Such a formula that isolates the specific representations is\nderived by modifying Altu\\u{g}'s approach. We use the approximate functional\nequation to ensure the validity of the Poisson summation formula. Then, we\ncompute the residues of specific functions to isolate the desired\nrepresentations.",
    "pdf_url": "http://arxiv.org/pdf/2505.18967v1",
    "published": "2025-05-25T04:01:31+00:00",
    "categories": [
      "math.NT",
      "math.RT",
      "11F72"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.20344v1",
    "title": "Genetic Influences on Brain Aging: Analyzing Sex Differences in the UK Biobank using Structural MRI",
    "authors": [
      "Karen Ardila",
      "Aashka Mohite",
      "Abdoljalil Addeh",
      "Amanda V. Tyndall",
      "Cindy K. Barha",
      "Quan Long",
      "M. Ethan MacDonald"
    ],
    "abstract": "Brain aging trajectories differ between males and females, yet the genetic\nfactors underlying these differences remain underexplored. Using structural MRI\nand genotyping data from 40,940 UK Biobank participants (aged 45-83), we\ncomputed Brain Age Gap Estimates (BrainAGE) for total brain, hippocampal, and\nventricular volumes. We conducted sex-stratified genome-wide association\nstudies (GWAS) and Post-GWAS analyses to identify genetic variants associated\nwith accelerated brain aging. Distinct gene sets emerged by sex: in females,\nneurotransmitter transport and mitochondrial stress response genes were\nimplicated; in males, immune and inflammation-related genes dominated. Shared\ngenes, including GMNC and OSTN, were consistently linked to brain volumes\nacross sexes, suggesting core roles in neurostructural maintenance. Tissue\nexpression analyses revealed sex-specific enrichment in pathways tied to\nneurodegeneration. These findings highlight the importance of sex-stratified\napproaches in aging research and suggest genetic targets for personalized\ninterventions against age-related cognitive decline.",
    "pdf_url": "http://arxiv.org/pdf/2505.20344v1",
    "published": "2025-05-25T03:59:00+00:00",
    "categories": [
      "q-bio.GN",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.04237v1",
    "title": "A Comprehensive Survey on the Risks and Limitations of Concept-based Models",
    "authors": [
      "Sanchit Sinha",
      "Aidong Zhang"
    ],
    "abstract": "Concept-based Models are a class of inherently explainable networks that\nimprove upon standard Deep Neural Networks by providing a rationale behind\ntheir predictions using human-understandable `concepts'. With these models\nbeing highly successful in critical applications like medical diagnosis and\nfinancial risk prediction, there is a natural push toward their wider adoption\nin sensitive domains to instill greater trust among diverse stakeholders.\nHowever, recent research has uncovered significant limitations in the structure\nof such networks, their training procedure, underlying assumptions, and their\nsusceptibility to adversarial vulnerabilities. In particular, issues such as\nconcept leakage, entangled representations, and limited robustness to\nperturbations pose challenges to their reliability and generalization.\nAdditionally, the effectiveness of human interventions in these models remains\nan open question, raising concerns about their real-world applicability. In\nthis paper, we provide a comprehensive survey on the risks and limitations\nassociated with Concept-based Models. In particular, we focus on aggregating\ncommonly encountered challenges and the architecture choices mitigating these\nchallenges for Supervised and Unsupervised paradigms. We also examine recent\nadvances in improving their reliability and discuss open problems and promising\navenues of future research in this domain.",
    "pdf_url": "http://arxiv.org/pdf/2506.04237v1",
    "published": "2025-05-25T03:53:26+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18966v1",
    "title": "Protein Design with Dynamic Protein Vocabulary",
    "authors": [
      "Nuowei Liu",
      "Jiahao Kuang",
      "Yanting Liu",
      "Changzhi Sun",
      "Tao Ji",
      "Yuanbin Wu",
      "Man Lan"
    ],
    "abstract": "Protein design is a fundamental challenge in biotechnology, aiming to design\nnovel sequences with specific functions within the vast space of possible\nproteins. Recent advances in deep generative models have enabled function-based\nprotein design from textual descriptions, yet struggle with structural\nplausibility. Inspired by classical protein design methods that leverage\nnatural protein structures, we explore whether incorporating fragments from\nnatural proteins can enhance foldability in generative models. Our empirical\nresults show that even random incorporation of fragments improves foldability.\nBuilding on this insight, we introduce ProDVa, a novel protein design approach\nthat integrates a text encoder for functional descriptions, a protein language\nmodel for designing proteins, and a fragment encoder to dynamically retrieve\nprotein fragments based on textual functional descriptions. Experimental\nresults demonstrate that our approach effectively designs protein sequences\nthat are both functionally aligned and structurally plausible. Compared to\nstate-of-the-art models, ProDVa achieves comparable function alignment using\nless than 0.04% of the training data, while designing significantly more\nwell-folded proteins, with the proportion of proteins having pLDDT above 70\nincreasing by 7.38% and those with PAE below 10 increasing by 9.6%.",
    "pdf_url": "http://arxiv.org/pdf/2505.18966v1",
    "published": "2025-05-25T03:50:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18965v1",
    "title": "G-type Antiferromagnetic BiFeO$_3$ is a Multiferroic $g$-wave Altermagnet",
    "authors": [
      "Andrea Urru",
      "Daniel Seleznev",
      "Yujia Teng",
      "Se Young Park",
      "Sebastian E. Reyes-Lillo",
      "Karin M. Rabe"
    ],
    "abstract": "G-type antiferromagnetic BiFeO$_3$ is shown to be an altermagnet. We present\nthe band structure using an unconventional scheme designed to highlight the\ndistinctive spin splitting which is characteristic of altermagnets. We define\nand show plots of the spin-splitting function in reciprocal space. We show that\nthe nodal surfaces of the spin-splitting function that follow from symmetry can\nbe classified into two types, which we call symmetry-enforced and\ncontinuity-enforced. We describe the spin-splitting function with a simple\nparametrization in a basis of symmetry-adapted plane waves. Using group-theory\nanalysis based on irreducible representations of the crystallographic Laue\ngroup, we confirm that the altermagnetism of G-type BiFeO$_3$ is $g$-wave and\npresent a complete classification table for the general three-dimensional case.\nFinally, we discuss the effect of ferroelectric switching on the altermagnetic\norder, and identify three classes of ferroelectric altermagnets.",
    "pdf_url": "http://arxiv.org/pdf/2505.18965v1",
    "published": "2025-05-25T03:49:47+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.18964v2",
    "title": "Formation of Supersonic Turbulence in the Primordial Star-forming Cloud",
    "authors": [
      "Ke-Jung Chen",
      "Meng-Yuan Ho",
      "Pei-Cheng Tung"
    ],
    "abstract": "We present new simulations of the formation and evolution of the first\nstar-forming cloud within a massive minihalo of mass of $1.05 \\times 10^7\\,\nM_{\\odot}$, carried out using the GIZMO code with detailed modeling of\nprimordial gas cooling and chemistry. Unlike previous studies that simulated\nthe formation of the first stars within a smaller cosmological boxsize of $\\sim\n1-2$ Mpc, our work adopts initial conditions from the large-scale cosmological\nsimulations, IllustrisTNG spanning $\\sim 50$ Mpc to study the formation of\nprimordial clouds that give birth to the first stars. We increase the original\nresolution of IllustrisTNG by a factor of $\\sim10^5$ using a particle-splitting\ntechnique, achieving an extremely high resolution that allows us to resolve\nturbulence driven by gravitational collapse during early structure formation.\nWe find that strong supersonic turbulence with a characteristic Mach number of\n$\\sim 5.2$ naturally develops within the collapsing halo. This turbulence\nefficiently stirs the gas, promoting fragmentation of the star-forming cloud\ninto multiple dense clumps. Among them, we identify a gravitationally bound\ncore with a mass of $8.07\\,M_{\\odot}$ and a size of $0.03$ pc, which exceeds\nits local Jeans mass and is on the verge of collapsing into a star. Our results\nindicate that supersonic turbulence may be common in primordial halos and can\nplay a crucial role in cloud-scale fragmentation, potentially lowering the\ncharacteristic mass scale of the first stars.",
    "pdf_url": "http://arxiv.org/pdf/2505.18964v2",
    "published": "2025-05-25T03:46:14+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.18963v1",
    "title": "MGD$^3$: Mode-Guided Dataset Distillation using Diffusion Models",
    "authors": [
      "Jeffrey A. Chan-Santiago",
      "Praveen Tirupattur",
      "Gaurav Kumar Nayak",
      "Gaowen Liu",
      "Mubarak Shah"
    ],
    "abstract": "Dataset distillation has emerged as an effective strategy, significantly\nreducing training costs and facilitating more efficient model deployment.\nRecent advances have leveraged generative models to distill datasets by\ncapturing the underlying data distribution. Unfortunately, existing methods\nrequire model fine-tuning with distillation losses to encourage diversity and\nrepresentativeness. However, these methods do not guarantee sample diversity,\nlimiting their performance. We propose a mode-guided diffusion model leveraging\na pre-trained diffusion model without the need to fine-tune with distillation\nlosses. Our approach addresses dataset diversity in three stages: Mode\nDiscovery to identify distinct data modes, Mode Guidance to enhance intra-class\ndiversity, and Stop Guidance to mitigate artifacts in synthetic samples that\naffect performance. Our approach outperforms state-of-the-art methods,\nachieving accuracy gains of 4.4%, 2.9%, 1.6%, and 1.6% on ImageNette, ImageIDC,\nImageNet-100, and ImageNet-1K, respectively. Our method eliminates the need for\nfine-tuning diffusion models with distillation losses, significantly reducing\ncomputational costs. Our code is available on the project webpage:\nhttps://jachansantiago.github.io/mode-guided-distillation/",
    "pdf_url": "http://arxiv.org/pdf/2505.18963v1",
    "published": "2025-05-25T03:40:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18962v3",
    "title": "System-1.5 Reasoning: Traversal in Language and Latent Spaces with Dynamic Shortcuts",
    "authors": [
      "Xiaoqiang Wang",
      "Suyuchen Wang",
      "Yun Zhu",
      "Bang Liu"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning enables large language models (LLMs) to move\nbeyond fast System-1 responses and engage in deliberative System-2 reasoning.\nHowever, this comes at the cost of significant inefficiency due to verbose\nintermediate output. Recent latent-space reasoning methods improve efficiency\nby operating on hidden states without decoding into language, yet they treat\nall steps uniformly, failing to distinguish critical deductions from auxiliary\nsteps and resulting in suboptimal use of computational resources. In this\npaper, we propose System-1.5 Reasoning, an adaptive reasoning framework that\ndynamically allocates computation across reasoning steps through shortcut paths\nin latent space. Specifically, System-1.5 Reasoning introduces two types of\ndynamic shortcuts. The model depth shortcut (DS) adaptively reasons along the\nvertical depth by early exiting non-critical tokens through lightweight adapter\nbranches, while allowing critical tokens to continue through deeper Transformer\nlayers. The step shortcut (SS) reuses hidden states across the decoding steps\nto skip trivial steps and reason horizontally in latent space. Training\nSystem-1.5 Reasoning involves a two-stage self-distillation process: first\ndistilling natural language CoT into latent-space continuous thought, and then\ndistilling full-path System-2 latent reasoning into adaptive shortcut paths\n(System-1.5 Reasoning). Experiments on reasoning tasks demonstrate the superior\nperformance of our method. For example, on GSM8K, System-1.5 Reasoning achieves\nreasoning performance comparable to traditional CoT fine-tuning methods while\naccelerating inference by over 20x and reducing token generation by 92.31% on\naverage.",
    "pdf_url": "http://arxiv.org/pdf/2505.18962v3",
    "published": "2025-05-25T03:35:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.14782v2",
    "title": "Integrating Dynamical Systems Learning with Foundational Models: A Meta-Evolutionary AI Framework for Clinical Trials",
    "authors": [
      "Joseph Geraci",
      "Bessi Qorri",
      "Christian Cumbaa",
      "Mike Tsay",
      "Paul Leonczyk",
      "Luca Pani"
    ],
    "abstract": "Artificial intelligence (AI) has evolved into an ecosystem of specialized\n\"species,\" each with unique strengths. We analyze two: DeepSeek-V3, a\n671-billion-parameter Mixture of Experts large language model (LLM)\nexemplifying scale-driven generality, and NetraAI, a dynamical system-based\nframework engineered for stability and interpretability on small clinical trial\ndatasets. We formalize NetraAI's foundations, combining contraction mappings,\ninformation geometry, and evolutionary algorithms to identify predictive\npatient cohorts. Features are embedded in a metric space and iteratively\ncontracted toward stable attractors that define latent subgroups. A\npseudo-temporal embedding and long-range memory enable exploration of\nhigher-order feature interactions, while an internal evolutionary loop selects\ncompact, explainable 2-4-variable bundles (\"Personas\").\n  To guide discovery, we introduce an LLM Strategist as a meta-evolutionary\nlayer that observes Persona outputs, prioritizes promising variables, injects\ndomain knowledge, and assesses robustness. This two-tier architecture mirrors\nthe human scientific process: NetraAI as experimentalist, the LLM as theorist,\nforming a self-improving loop.\n  In case studies (schizophrenia, depression, pancreatic cancer), NetraAI\nuncovered small, high-effect-size subpopulations that transformed weak baseline\nmodels (AUC ~0.50-0.68) into near-perfect classifiers using only a few\nfeatures. We position NetraAI at the intersection of dynamical systems,\ninformation geometry, and evolutionary learning, aligned with emerging\nconcept-level reasoning paradigms such as LeCun's Joint Embedding Predictive\nArchitecture (JEPA). By prioritizing reliable, explainable knowledge, NetraAI\noffers a new generation of adaptive, self-reflective AI to accelerate clinical\ndiscovery.",
    "pdf_url": "http://arxiv.org/pdf/2506.14782v2",
    "published": "2025-05-25T03:34:33+00:00",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18961v1",
    "title": "Weaver: Interweaving SQL and LLM for Table Reasoning",
    "authors": [
      "Rohit Khoja",
      "Devanshu Gupta",
      "Yanjie Fu",
      "Dan Roth",
      "Vivek Gupta"
    ],
    "abstract": "Querying tables with unstructured data is challenging due to the presence of\ntext (or image), either embedded in the table or in external paragraphs, which\ntraditional SQL struggles to process, especially for tasks requiring semantic\nreasoning. While Large Language Models (LLMs) excel at understanding context,\nthey face limitations with long input sequences. Existing approaches that\ncombine SQL and LLMs typically rely on rigid, predefined work-flows, limiting\ntheir adaptability to complex queries. To address these issues, we introduce\nWeaver , a modular pipeline that dynamically integrates SQL and LLMs for\ntable-based question answering (TableQA). Weaver generates a flexible,\nstep-by-step plan that combines SQL for structured data retrieval with LLMs for\nsemantic processing. By decomposing complex queries into manageable subtasks,\nWeaver improves accuracy and generalization. Our experiments show that Weaver\nconsistently outperforms state-of-the-art methods across four TableQA datasets,\nreducing both API calls and error rates.",
    "pdf_url": "http://arxiv.org/pdf/2505.18961v1",
    "published": "2025-05-25T03:27:37+00:00",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.18960v1",
    "title": "Coupled shape and spin evolution of small near spherical asteroids due to global regolith motion",
    "authors": [
      "Kumar Gaurav",
      "Deepayan Banik",
      "Ishan Sharma"
    ],
    "abstract": "Recent space missions have provided substantial evidence of regolith movement\non the surfaces of near Earth asteroids. To investigate this phenomenon, we\npresent a continuum-based model that describes regolith motion on nearly\nspherical asteroids. The theoretical framework employs a depth averaged\napproach, traditionally used for simulating terrestrial landslides, and is\nextended to include additional terms that account for spherical geometry,\nshallow topography and the asteroids rotation. The governing equations couple\nthe resurfacing process with the asteroids spin evolution through angular\nmomentum conservation. The axisymmetric form of these equations is then\nemployed to study the transition of an initially spherical asteroid into a\ntop-shaped.",
    "pdf_url": "http://arxiv.org/pdf/2505.18960v1",
    "published": "2025-05-25T03:27:31+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.18959v1",
    "title": "Dirac fermions on a surface with localized strain",
    "authors": [
      "Samuel B. B. Almeida",
      "J. E. G. Silva",
      "C. A. S. Almeida"
    ],
    "abstract": "We study the influence of a localized Gaussian deformation on massless Dirac\nfermions confined to a two-dimensional curved surface. Both in-plane and\nout-of-plane displacements are considered within the framework of elasticity\ntheory. These deformations couple to the Dirac spinors via the spin connection\nand the vielbeins, leading to a position-dependent Fermi velocity and an\neffective geometric potential. We show that the spin connection contributes an\nattractive potential centered on the deformation and explore how this\ninfluences the fermionic density of states. Analytical and numerical solutions\nreveal the emergence of bound states near the deformation and demonstrate how\nthe Lam\\'{e} coefficients affect curvature and state localization. Upon\nintroducing an external magnetic field, the effective potential becomes\nconfining at large distances, producing localized Landau levels that\nconcentrate near the deformation. A geometric Aharonov-Bohm phase is identified\nthrough the spinor holonomy. These results contribute to the understanding of\nstrain-induced electronic effects in Dirac materials, such as graphene.",
    "pdf_url": "http://arxiv.org/pdf/2505.18959v1",
    "published": "2025-05-25T03:26:06+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "hep-th"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.18958v2",
    "title": "CDPDNet: Integrating Text Guidance with Hybrid Vision Encoders for Medical Image Segmentation",
    "authors": [
      "Jiong Wu",
      "Yang Xing",
      "Boxiao Yu",
      "Wei Shao",
      "Kuang Gong"
    ],
    "abstract": "Most publicly available medical segmentation datasets are only partially\nlabeled, with annotations provided for a subset of anatomical structures. When\nmultiple datasets are combined for training, this incomplete annotation poses\nchallenges, as it limits the model's ability to learn shared anatomical\nrepresentations among datasets. Furthermore, vision-only frameworks often fail\nto capture complex anatomical relationships and task-specific distinctions,\nleading to reduced segmentation accuracy and poor generalizability to unseen\ndatasets. In this study, we proposed a novel CLIP-DINO Prompt-Driven\nSegmentation Network (CDPDNet), which combined a self-supervised vision\ntransformer with CLIP-based text embedding and introduced task-specific text\nprompts to tackle these challenges. Specifically, the framework was constructed\nupon a convolutional neural network (CNN) and incorporated DINOv2 to extract\nboth fine-grained and global visual features, which were then fused using a\nmulti-head cross-attention module to overcome the limited long-range modeling\ncapability of CNNs. In addition, CLIP-derived text embeddings were projected\ninto the visual space to help model complex relationships among organs and\ntumors. To further address the partial label challenge and enhance inter-task\ndiscriminative capability, a Text-based Task Prompt Generation (TTPG) module\nthat generated task-specific prompts was designed to guide the segmentation.\nExtensive experiments on multiple medical imaging datasets demonstrated that\nCDPDNet consistently outperformed existing state-of-the-art segmentation\nmethods. Code and pretrained model are available at:\nhttps://github.com/wujiong-hub/CDPDNet.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.18958v2",
    "published": "2025-05-25T03:23:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18957v1",
    "title": "The universality class of the first levels in low-dimensional gravity",
    "authors": [
      "Alexander Altland",
      "Jeremy van der Heijden",
      "Tobias Micklitz",
      "Moshe Rozali",
      "Joaquim Telles de Miranda"
    ],
    "abstract": "We investigate the physics of a small group of quantum states defined above\nthe sharply defined ground state of a chaotic ensemble. This `universality\nclass of the first levels' (UFL) is realized in the majority of `synthetic'\nrandom matrix models but, for all we know, in only one microscopically defined\nsystem: low-dimensional gravity. We discuss the physical properties of these\nstates, notably their exceptional rigidity against external perturbations, as\nquantified by the so-called quantum state fidelity. Examining these structures\nthrough the lenses of random matrix and string theory, we highlight their\nrelevance to the physics of low-dimensional holographic principles.",
    "pdf_url": "http://arxiv.org/pdf/2505.18957v1",
    "published": "2025-05-25T03:20:57+00:00",
    "categories": [
      "hep-th",
      "cond-mat.dis-nn",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.18956v2",
    "title": "How Do Images Align and Complement LiDAR? Towards a Harmonized Multi-modal 3D Panoptic Segmentation",
    "authors": [
      "Yining Pan",
      "Qiongjie Cui",
      "Xulei Yang",
      "Na Zhao"
    ],
    "abstract": "LiDAR-based 3D panoptic segmentation often struggles with the inherent\nsparsity of data from LiDAR sensors, which makes it challenging to accurately\nrecognize distant or small objects. Recently, a few studies have sought to\novercome this challenge by integrating LiDAR inputs with camera images,\nleveraging the rich and dense texture information provided by the latter. While\nthese approaches have shown promising results, they still face challenges, such\nas misalignment during data augmentation and the reliance on post-processing\nsteps. To address these issues, we propose Image-Assists-LiDAR (IAL), a novel\nmulti-modal 3D panoptic segmentation framework. In IAL, we first introduce a\nmodality-synchronized data augmentation strategy, PieAug, to ensure alignment\nbetween LiDAR and image inputs from the start. Next, we adopt a transformer\ndecoder to directly predict panoptic segmentation results. To effectively fuse\nLiDAR and image features into tokens for the decoder, we design a\nGeometric-guided Token Fusion (GTF) module. Additionally, we leverage the\ncomplementary strengths of each modality as priors for query initialization\nthrough a Prior-based Query Generation (PQG) module, enhancing the decoder's\nability to generate accurate instance masks. Our IAL framework achieves\nstate-of-the-art performance compared to previous multi-modal 3D panoptic\nsegmentation methods on two widely used benchmarks. Code and models are\npublicly available at <https://github.com/IMPL-Lab/IAL.git>.",
    "pdf_url": "http://arxiv.org/pdf/2505.18956v2",
    "published": "2025-05-25T03:01:28+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18955v1",
    "title": "Co-PatcheR: Collaborative Software Patching with Component(s)-specific Small Reasoning Models",
    "authors": [
      "Yuheng Tang",
      "Hongwei Li",
      "Kaijie Zhu",
      "Michael Yang",
      "Yangruibo Ding",
      "Wenbo Guo"
    ],
    "abstract": "Motivated by the success of general-purpose large language models (LLMs) in\nsoftware patching, recent works started to train specialized patching models.\nMost works trained one model to handle the end-to-end patching pipeline\n(including issue localization, patch generation, and patch validation).\nHowever, it is hard for a small model to handle all tasks, as different\nsub-tasks have different workflows and require different expertise. As such, by\nusing a 70 billion model, SOTA methods can only reach up to 41% resolved rate\non SWE-bench-Verified. Motivated by the collaborative nature, we propose\nCo-PatcheR, the first collaborative patching system with small and specialized\nreasoning models for individual components. Our key technique novelties are the\nspecific task designs and training recipes. First, we train a model for\nlocalization and patch generation. Our localization pinpoints the suspicious\nlines through a two-step procedure, and our generation combines patch\ngeneration and critique. We then propose a hybrid patch validation that\nincludes two models for crafting issue-reproducing test cases with and without\nassertions and judging patch correctness, followed by a majority vote-based\npatch selection. Through extensive evaluation, we show that Co-PatcheR achieves\n46% resolved rate on SWE-bench-Verified with only 3 x 14B models. This makes\nCo-PatcheR the best patcher with specialized models, requiring the least\ntraining resources and the smallest models. We conduct a comprehensive ablation\nstudy to validate our recipes, as well as our choice of training data number,\nmodel size, and testing-phase scaling strategy.",
    "pdf_url": "http://arxiv.org/pdf/2505.18955v1",
    "published": "2025-05-25T02:58:30+00:00",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.18954v2",
    "title": "Efficient SRAM-PIM Co-design by Joint Exploration of Value-Level and Bit-Level Sparsity",
    "authors": [
      "Cenlin Duan",
      "Jianlei Yang",
      "Yikun Wang",
      "Yiou Wang",
      "Yingjie Qi",
      "Xiaolin He",
      "Bonan Yan",
      "Xueyan Wang",
      "Xiaotao Jia",
      "Weisheng Zhao"
    ],
    "abstract": "Processing-in-memory (PIM) is a transformative architectural paradigm\ndesigned to overcome the Von Neumann bottleneck. Among PIM architectures,\ndigital SRAM-PIM emerges as a promising solution, offering significant\nadvantages by directly integrating digital logic within the SRAM array.\nHowever, rigid crossbar architecture and full array activation pose challenges\nin efficiently utilizing traditional value-level sparsity. Moreover, neural\nnetwork models exhibit a high proportion of zero bits within non-zero values,\nwhich remain underutilized due to architectural constraints. To overcome these\nlimitations, we present Dyadic Block PIM (DB-PIM), a groundbreaking\nalgorithm-architecture co-design framework to harness both value-level and\nbit-level sparsity. At the algorithm level, our hybrid-grained pruning\ntechnique, combined with a novel sparsity pattern, enables effective sparsity\nmanagement. Architecturally, DB-PIM incorporates a sparse network and\ncustomized digital SRAM-PIM macros, including input pre-processing unit (IPU),\ndyadic block multiply units (DBMUs), and Canonical Signed Digit (CSD)-based\nadder trees. It circumvents structured zero values in weights and bypasses\nunstructured zero bits within non-zero weights and block-wise all-zero bit\ncolumns in input features. As a result, the DB-PIM framework skips a majority\nof unnecessary computations, thereby driving significant gains in computational\nefficiency. Results demonstrate that our DB-PIM framework achieves up to 8.01x\nspeedup and 85.28% energy savings, significantly boosting computational\nefficiency in digital SRAM-PIM systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.18954v2",
    "published": "2025-05-25T02:57:40+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.18953v2",
    "title": "Evaluating AI for Finance: Is AI Credible at Assessing Investment Risk?",
    "authors": [
      "Divij Chawla",
      "Ashita Bhutada",
      "Do Duc Anh",
      "Abhinav Raghunathan",
      "Vinod SP",
      "Cathy Guo",
      "Dar Win Liew",
      "Prannaya Gupta",
      "Rishabh Bhardwaj",
      "Rajat Bhardwaj",
      "Soujanya Poria"
    ],
    "abstract": "We assess whether AI systems can credibly evaluate investment risk appetite-a\ntask that must be thoroughly validated before automation. Our analysis was\nconducted on proprietary systems (GPT, Claude, Gemini) and open-weight models\n(LLaMA, DeepSeek, Mistral), using carefully curated user profiles that reflect\nreal users with varying attributes such as country and gender. As a result, the\nmodels exhibit significant variance in score distributions when user\nattributes-such as country or gender-that should not influence risk computation\nare changed. For example, GPT-4o assigns higher risk scores to Nigerian and\nIndonesian profiles. While some models align closely with expected scores in\nthe Low- and Mid-risk ranges, none maintain consistent scores across regions\nand demographics, thereby violating AI and finance regulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.18953v2",
    "published": "2025-05-25T02:56:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18952v1",
    "title": "Online Knowledge Distillation with Reward Guidance",
    "authors": [
      "Chen Jia"
    ],
    "abstract": "This work studies knowledge distillation (KD) for large language models\n(LLMs) through preference optimization. We propose a reward-guided imitation\nlearning framework for sequential KD, formulating a min-max optimization\nproblem between the policy and reward model (RM) to minimize the performance\ngap between the student and teacher policies. Specifically, the reward\noptimization is constrained to achieve near-optimality within a confidence set\nfor preference alignment. For preference data construction, we explore both\noffline and online preference-based KD. Additionally, we reformulate the RM\nusing the $Q$-value function and extend the framework to white-box KD, where\nthe teacher policy's predicted probabilities are accessible. Theoretical\nanalysis and empirical results demonstrate the effectiveness of the proposed\nframework.",
    "pdf_url": "http://arxiv.org/pdf/2505.18952v1",
    "published": "2025-05-25T02:56:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18951v1",
    "title": "BnMMLU: Measuring Massive Multitask Language Understanding in Bengali",
    "authors": [
      "Saman Sarker Joy"
    ],
    "abstract": "The Massive Multitask Language Understanding (MMLU) benchmark has been widely\nused to evaluate language models across various domains. However, existing MMLU\ndatasets primarily focus on high-resource languages such as English, which\nleaves low-resource languages like Bengali underrepresented. In this paper, we\nintroduce BnMMLU, a benchmark to evaluate the multitask language understanding\ncapabilities of Bengali in language models. The dataset spans 23 domains,\nincluding science, humanities, mathematics and general knowledge and is\nstructured in a multiple-choice format to assess factual knowledge,\napplication-based problem-solving and reasoning abilities of language models.\nIt consists of 138,949 question-option pairs. We benchmark several proprietary\nand open-source large language models (LLMs) on the BnMMLU test set.\nAdditionally, we annotate the test set with three cognitive categories-factual\nknowledge, procedural application and reasoning-to gain deeper insights into\nmodel strengths and weaknesses across various cognitive tasks. The results\nreveal significant performance gaps, highlighting the need for improved\npre-training and fine-tuning strategies tailored to Bengali data. We release\nthe dataset and benchmark results to facilitate further research in this area.",
    "pdf_url": "http://arxiv.org/pdf/2505.18951v1",
    "published": "2025-05-25T02:54:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18950v1",
    "title": "Physics-Informed Deep Learning for Nonlinear Friction Model of Bow-string Interaction",
    "authors": [
      "Xinmeng Luan",
      "Gary Scavone"
    ],
    "abstract": "This study investigates the use of an unsupervised, physics-informed deep\nlearning framework to model a one-degree-of-freedom mass-spring system\nsubjected to a nonlinear friction bow force and governed by a set of ordinary\ndifferential equations. Specifically, it examines the application of\nPhysics-Informed Neural Networks (PINNs) and Physics-Informed Deep Operator\nNetworks (PI-DeepONets). Our findings demonstrate that PINNs successfully\naddress the problem across different bow force scenarios, while PI-DeepONets\nperform well under low bow forces but encounter difficulties at higher forces.\nAdditionally, we analyze the Hessian eigenvalue density and visualize the loss\nlandscape. Overall, the presence of large Hessian eigenvalues and sharp minima\nindicates highly ill-conditioned optimization. These results underscore the\npromise of physics-informed deep learning for nonlinear modelling in musical\nacoustics, while also revealing the limitations of relying solely on\nphysics-based approaches to capture complex nonlinearities. We demonstrate that\nPI-DeepONets, with their ability to generalize across varying parameters, are\nwell-suited for sound synthesis. Furthermore, we demonstrate that the\nlimitations of PI-DeepONets under higher forces can be mitigated by integrating\nobservation data within a hybrid supervised-unsupervised framework. This\nsuggests that a hybrid supervised-unsupervised DeepONets framework could be a\npromising direction for future practical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.18950v1",
    "published": "2025-05-25T02:53:27+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.18949v1",
    "title": "The Price of Format: Diversity Collapse in LLMs",
    "authors": [
      "Longfei Yun",
      "Chenyang An",
      "Zilong Wang",
      "Letian Peng",
      "Jingbo Shang"
    ],
    "abstract": "Instruction-tuned large language models (LLMs) employ structured templates,\nsuch as role markers and special tokens, to enforce format consistency during\ninference. However, we identify a critical limitation of such formatting: it\ninduces a phenomenon we term diversity collapse, where the model generates\nsemantically similar outputs for open-ended inputs, undermining creativity and\nvariability. We systematically evaluate this effect across tasks like story\ncompletion and free-form generation, finding that (1) diversity collapse\npersists even under high-temperature sampling, and (2) structural tokens in\ntemplates significantly constrain the model's output space. To contextualize\nthese findings, we fine-tune the same model using a range of structured prompts\nand then evaluate them across three axes: downstream task performance,\nalignment behavior, and output diversity. Our analysis shows that format\nconsistency between fine-tuning and inference is crucial for\nstructure-sensitive tasks (e.g., GSM8K, IFEval), but has marginal influence on\nknowledge-heavy tasks (e.g., MMLU, WebQuestions). In contrast, output diversity\nis primarily governed by the presence or absence of structural tokens, with\nminimal formatting yielding the most diverse outputs. These findings reveal\nthat current prompting conventions, while beneficial for alignment, may\ninadvertently suppress output diversity, underscoring the need for\ndiversity-aware prompt design and instruction tuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.18949v1",
    "published": "2025-05-25T02:52:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18948v1",
    "title": "Exact Expressive Power of Transformers with Padding",
    "authors": [
      "William Merrill",
      "Ashish Sabharwal"
    ],
    "abstract": "Chain of thought is a natural inference-time method for increasing the\ncomputational power of transformer-based large language models (LLMs), but\ncomes at the cost of sequential decoding. Are there more efficient alternatives\nto expand a transformer's expressive power without adding parameters? We\nconsider transformers with padding tokens as a form of parallelizable test-time\ncompute. We show that averaging-hard-attention, masked-pre-norm transformers\nwith polynomial padding converge to precisely the class $\\mathsf{TC}^0$ of\nextremely parallelizable problems. While the $\\mathsf{TC}^0$ upper bound was\nknown, proving a matching lower bound had been elusive. Further, our novel\nanalysis reveals the precise expanded power of padded transformers when coupled\nwith another form of inference-time compute, namely dynamically increasing\ndepth via looping. Our core technical contribution is to show how padding helps\nbring the notions of complete problems and reductions, which have been a\ncornerstone of classical complexity theory, to the formal study of\ntransformers. Armed with this new tool, we prove that padded transformers with\n$O(\\log^d n)$ looping on inputs of length $n$ recognize exactly the class\n$\\mathsf{TC}^d$ of moderately parallelizable problems. Thus, padding and\nlooping together systematically expand transformers' expressive power: with\npolylogarithmic looping, padded transformers converge to the class\n$\\mathsf{NC}$, the best that could be expected without losing parallelism\n(unless $\\mathsf{NC} = \\mathsf{P}$). Our results thus motivate further\nexploration of padding and looping as parallelizable alternatives to chain of\nthought.",
    "pdf_url": "http://arxiv.org/pdf/2505.18948v1",
    "published": "2025-05-25T02:52:15+00:00",
    "categories": [
      "cs.LG",
      "cs.CC",
      "cs.FL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18947v1",
    "title": "OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model",
    "authors": [
      "Zhenhao Zhang",
      "Ye Shi",
      "Lingxiao Yang",
      "Suting Ni",
      "Qi Ye",
      "Jingya Wang"
    ],
    "abstract": "Understanding and synthesizing realistic 3D hand-object interactions (HOI) is\ncritical for applications ranging from immersive AR/VR to dexterous robotics.\nExisting methods struggle with generalization, performing well on closed-set\nobjects and predefined tasks but failing to handle unseen objects or\nopen-vocabulary instructions. We introduce OpenHOI, the first framework for\nopen-world HOI synthesis, capable of generating long-horizon manipulation\nsequences for novel objects guided by free-form language commands. Our approach\nintegrates a 3D Multimodal Large Language Model (MLLM) fine-tuned for joint\naffordance grounding and semantic task decomposition, enabling precise\nlocalization of interaction regions (e.g., handles, buttons) and breakdown of\ncomplex instructions (e.g., \"Find a water bottle and take a sip\") into\nexecutable sub-tasks. To synthesize physically plausible interactions, we\npropose an affordance-driven diffusion model paired with a training-free\nphysics refinement stage that minimizes penetration and optimizes affordance\nalignment. Evaluations across diverse scenarios demonstrate OpenHOI's\nsuperiority over state-of-the-art methods in generalizing to novel object\ncategories, multi-stage tasks, and complex language instructions. Our project\npage at \\href{https://openhoi.github.io}",
    "pdf_url": "http://arxiv.org/pdf/2505.18947v1",
    "published": "2025-05-25T02:48:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18946v1",
    "title": "SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent Cross-Layer Coordination",
    "authors": [
      "Yong Xiao",
      "Haoran Zhou",
      "Xubo Li",
      "Yayu Gao",
      "Guangming Shi",
      "Ping Zhang"
    ],
    "abstract": "Agentic AI networking (AgentNet) is a novel AI-native networking paradigm\nthat relies on a large number of specialized AI agents to collaborate and\ncoordinate for autonomous decision-making, dynamic environmental adaptation,\nand complex goal achievement. It has the potential to facilitate real-time\nnetwork management alongside capabilities for self-configuration,\nself-optimization, and self-adaptation across diverse and complex networking\nenvironments, laying the foundation for fully autonomous networking systems in\nthe future. Despite its promise, AgentNet is still in the early stage of\ndevelopment, and there still lacks an effective networking framework to support\nautomatic goal discovery and multi-agent self-orchestration and task\nassignment. This paper proposes SANNet, a novel semantic-aware agentic AI\nnetworking architecture that can infer the semantic goal of the user and\nautomatically assign agents associated with different layers of a mobile system\nto fulfill the inferred goal. Motivated by the fact that one of the major\nchallenges in AgentNet is that different agents may have different and even\nconflicting objectives when collaborating for certain goals, we introduce a\ndynamic weighting-based conflict-resolving mechanism to address this issue. We\nprove that SANNet can provide theoretical guarantee in both conflict-resolving\nand model generalization performance for multi-agent collaboration in dynamic\nenvironment. We develop a hardware prototype of SANNet based on the open RAN\nand 5GS core platform. Our experimental results show that SANNet can\nsignificantly improve the performance of multi-agent networking systems, even\nwhen agents with conflicting objectives are selected to collaborate for the\nsame goal.",
    "pdf_url": "http://arxiv.org/pdf/2505.18946v1",
    "published": "2025-05-25T02:45:18+00:00",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.NI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.18945v1",
    "title": "Echo Planning for Autonomous Driving: From Current Observations to Future Trajectories and Back",
    "authors": [
      "Jintao Sun",
      "Hu Zhang",
      "Gangyi Ding",
      "Zhedong Zheng"
    ],
    "abstract": "Modern end-to-end autonomous driving systems suffer from a critical\nlimitation: their planners lack mechanisms to enforce temporal consistency\nbetween predicted trajectories and evolving scene dynamics. This absence of\nself-supervision allows early prediction errors to compound catastrophically\nover time. We introduce Echo Planning, a novel self-correcting framework that\nestablishes a closed-loop Current - Future - Current (CFC) cycle to harmonize\ntrajectory prediction with scene coherence. Our key insight is that plausible\nfuture trajectories must be bi-directionally consistent, ie, not only generated\nfrom current observations but also capable of reconstructing them. The CFC\nmechanism first predicts future trajectories from the Bird's-Eye-View (BEV)\nscene representation, then inversely maps these trajectories back to estimate\nthe current BEV state. By enforcing consistency between the original and\nreconstructed BEV representations through a cycle loss, the framework\nintrinsically penalizes physically implausible or misaligned trajectories.\nExperiments on nuScenes demonstrate state-of-the-art performance, reducing L2\nerror by 0.04 m and collision rate by 0.12% compared to one-shot planners.\nCrucially, our method requires no additional supervision, leveraging the CFC\ncycle as an inductive bias for robust planning. This work offers a deployable\nsolution for safety-critical autonomous systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.18945v1",
    "published": "2025-05-25T02:44:06+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18944v1",
    "title": "Exemplifying Emerging Phishing: QR-based Browser-in-The-Browser (BiTB) Attack",
    "authors": [
      "Muhammad Wahid Akram",
      "Keshav Sood",
      "Muneeb Ul Hassan",
      "Basant Subba"
    ],
    "abstract": "Lately, cybercriminals constantly formulate productive approaches to exploit\nindividuals. This article exemplifies an innovative attack, namely QR-based\nBrowser-in-The-Browser (BiTB), using proficiencies of Large Language Model\n(LLM) i.e. Google Gemini. The presented attack is a fusion of two emerging\nattacks: BiTB and Quishing (QR code phishing). Our study underscores attack's\nsimplistic implementation utilizing malicious prompts provided to Gemini-LLM.\nMoreover, we presented a case study to highlight a lucrative attack method, we\nalso performed an experiment to comprehend the attack execution on victims'\ndevice. The findings of this work obligate the researchers' contributions in\nconfronting this type of phishing attempts through LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.18944v1",
    "published": "2025-05-25T02:39:15+00:00",
    "categories": [
      "cs.CR",
      "cs.ET"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.18943v1",
    "title": "MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems",
    "authors": [
      "Xuanming Zhang",
      "Yuxuan Chen",
      "Min-Hsuan Yeh",
      "Yixuan Li"
    ],
    "abstract": "Human social interactions depend on the ability to infer others' unspoken\nintentions, emotions, and beliefs-a cognitive skill grounded in the\npsychological concept of Theory of Mind (ToM). While large language models\n(LLMs) excel in semantic understanding tasks, they struggle with the ambiguity\nand contextual nuance inherent in human communication. To bridge this gap, we\nintroduce MetaMind, a multi-agent framework inspired by psychological theories\nof metacognition, designed to emulate human-like social reasoning. MetaMind\ndecomposes social understanding into three collaborative stages: (1) a\nTheory-of-Mind Agent generates hypotheses user mental states (e.g., intent,\nemotion), (2) a Domain Agent refines these hypotheses using cultural norms and\nethical constraints, and (3) a Response Agent generates contextually\nappropriate responses while validating alignment with inferred intent. Our\nframework achieves state-of-the-art performance across three challenging\nbenchmarks, with 35.7% improvement in real-world social scenarios and 6.2% gain\nin ToM reasoning. Notably, it enables LLMs to match human-level performance on\nkey ToM tasks for the first time. Ablation studies confirm the necessity of all\ncomponents, which showcase the framework's ability to balance contextual\nplausibility, social appropriateness, and user adaptation. This work advances\nAI systems toward human-like social intelligence, with applications in\nempathetic dialogue and culturally sensitive interactions. Code is available at\nhttps://github.com/XMZhangAI/MetaMind.",
    "pdf_url": "http://arxiv.org/pdf/2505.18943v1",
    "published": "2025-05-25T02:32:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18942v2",
    "title": "Language Models Surface the Unwritten Code of Science and Society",
    "authors": [
      "Honglin Bao",
      "Siyang Wu",
      "Jiwoong Choi",
      "Yingrong Mao",
      "James A. Evans"
    ],
    "abstract": "This paper calls on the research community not only to investigate how human\nbiases are inherited by large language models (LLMs) but also to explore how\nthese biases in LLMs can be leveraged to make society's \"unwritten code\" - such\nas implicit stereotypes and heuristics - visible and accessible for critique.\nWe introduce a conceptual framework through a case study in science: uncovering\nhidden rules in peer review - the factors that reviewers care about but rarely\nstate explicitly due to normative scientific expectations. The idea of the\nframework is to push LLMs to speak out their heuristics through generating\nself-consistent hypotheses - why one paper appeared stronger in reviewer\nscoring - among paired papers submitted to 45 computer science conferences,\nwhile iteratively searching deeper hypotheses from remaining pairs where\nexisting hypotheses cannot explain. We observed that LLMs' normative priors\nabout the internal characteristics of good science extracted from their\nself-talk, e.g. theoretical rigor, were systematically updated toward\nposteriors that emphasize storytelling about external connections, such as how\nthe work is positioned and connected within and across literatures. This shift\nreveals the primacy of scientific myths about intrinsic properties driving\nscientific excellence rather than extrinsic contextualization and storytelling\nthat influence conceptions of relevance and significance. Human reviewers tend\nto explicitly reward aspects that moderately align with LLMs' normative priors\n(correlation = 0.49) but avoid articulating contextualization and storytelling\nposteriors in their review comments (correlation = -0.14), despite giving\nimplicit reward to them with positive scores. We discuss the broad\napplicability of the framework, leveraging LLMs as diagnostic tools to surface\nthe tacit codes underlying human society, enabling more precisely targeted\nresponsible AI.",
    "pdf_url": "http://arxiv.org/pdf/2505.18942v2",
    "published": "2025-05-25T02:28:40+00:00",
    "categories": [
      "cs.CY",
      "cs.CL",
      "cs.DL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.18941v2",
    "title": "Orbital Decay of the Ultra-Hot Jupiter TOI-2109b: Tidal Constraints and Transit-Timing Analysis",
    "authors": [
      "Jaime A. Alvarado-Montes",
      "Mario Sucerquia",
      "Jorge I. Zuluaga",
      "Christian Schwab"
    ],
    "abstract": "TOI-2109b is the ultra-hot Jupiter with the shortest orbital period\n($\\sim16\\,$hr) yet discovered. At this close distance, strong tidal\ninteractions can produce a significant exchange of angular momentum with the\nstar. Since the orbital period of this planet is shorter than the stellar\nrotation period, TOI-2109b may be an optimal candidate for studying orbital\ndecay. This process depends on how efficiently the star and the planet\ndissipate energy, due mainly to interior mechanisms that are poorly constrained\nin exoplanet systems. In this work, we study for the first time the tidal\nevolution of TOI-2109b under a formalism of inertial waves (IWs) in convective\nenvelopes and internal gravity waves (IGWs) in stellar radiative regions. We\nfind that uncertainties in the age of TOI-2109 ($t_\\mathrm{\\star, age}$)\nsignificantly affect the rate of orbital evolution, as IWs and IGWs interact\ndifferently depending on $t_\\mathrm{\\star, age}$. For an 'old' host star, we\nfind that TOI-2109b would undergo fast orbital decay. Conversely, if TOI-2109b\norbits a 'young' host star, a rather slow decay rate for\n$Q_\\star'>2.3\\times10^7$ would suggest a constant-period orbit. Our calculated\nmid-transit times and transit-timing variations (TTVs) support a 'young' host\nstar with $Q_\\star'>3.7\\times10^7$, suggesting a decay rate $\\dot{P}\\sim4\\,$ms\nyr$^{-1}$ that could lead to mid-transit-time shifts $\\lesssim10\\,$s over three\nyears. Orbital decay and other TTV-inducing effects will be confirmed or ruled\nout with future higher-quality timing data. The results presented here aim at\nconstraining the current modeling of tides and TTVs for TOI-2109b, helping us\nfurther understand light-curve changes associated to the long-term evolution of\nultra-short-period planets.",
    "pdf_url": "http://arxiv.org/pdf/2505.18941v2",
    "published": "2025-05-25T02:20:42+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.18940v1",
    "title": "First principles investigation of zb-TiSn: A promising narrow bandgap semiconductor",
    "authors": [
      "Sudeep R",
      "Sarojini M",
      "Uma Mahendra Kumar Koppolu"
    ],
    "abstract": "We have investigated the structural stability of a binary compound TiSn in\nthe zincblende symmetry. The phonon dispersion studies confirms that, TiSn with\na nominal composition of 1:1 can exist in zincblende form. No imaginary\nfrequencies are observed indicating the stable bonding nature of Ti-Sn. From\nthe First principles calculations based on density functional theory, the\nresulting electronic band structure had revealed that zb-TiSn, is a narrow band\ngap semiconductor with an energy gap of 0.3 eV with GGA- PBE. The bonding\nnature is identified as polar covalent, determined from charge density\ndifference plots and Bader charge analysis. Further more, the linear optical\nproperties of zb-TiSn are derived from the Khon-Sham eigenvalues.",
    "pdf_url": "http://arxiv.org/pdf/2505.18940v1",
    "published": "2025-05-25T02:20:04+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.18939v1",
    "title": "Ground Calibration Result of the Wide-field X-ray Telescope (WXT) onboard the Einstein Probe",
    "authors": [
      "Huaqing Cheng",
      "Chen Zhang",
      "Zhixing Ling",
      "Xiaojin Sun",
      "Shengli Sun",
      "Yuan Liu",
      "Yanfeng Dai",
      "Zhenqing Jia",
      "Haiwu Pan",
      "Wenxin Wang",
      "Donghua Zhao",
      "Yifan Chen",
      "Zhiwei Cheng",
      "Wei Fu",
      "Yixiao Han",
      "Junfei Li",
      "Zhengda Li",
      "Xiaohao Ma",
      "Yulong Xue",
      "Ailiang Yan",
      "Qiang Zhang",
      "Yusa Wang",
      "Xiongtao Yang",
      "Zijian Zhao",
      "Longhui Li",
      "Ge Jin",
      "Weimin Yuan"
    ],
    "abstract": "We report on results of the on-ground X-ray calibration of the Wide-field\nX-ray Telescope (WXT) built from novel lobster-eye micro-pore optics, onboard\nthe Einstein Probe (EP) satellite. To fully characterize the instrumental\nperformance and properties, a series of tests and calibrations have been\ncarried out at different levels of devices, assemblies and the complete module\nbefore the launch of EP. In this paper, we present the calibration results of\nthree flight model modules (FM1, FM5 and FM11) obtained during their end-to-end\nmodule calibration experiments carried out at the 100-m X-ray Test Facility\n(100XF) of IHEP, CAS. Measurements of the Point Spread Function (PSF),\neffective area, and energy response were performed for multiple incident\ndirections and several characteristic X-ray emission line energies.\nSpecifically, the distributions of the PSF and effective areas are found to be\nroughly uniform across the FoV, in large agreement with the prediction of\nlobster-eye optics. Their energy dependence behavior aligns well with\ntheoretical predictions and Monte Carlo simulations. At 1.25 keV, the full\nwidth at half maximum (FWHM) of the focal spot is in range of 3-7 arcmin (a\nmedian of 4.2) and the effective area in range of 2-3 $cm^2$. Noticeably, the\nflight model instruments demonstrate a $\\sim1.5$ arcmin spatial resolution\nimprovement over the previously launched Lobster Eye Imager for Astronomy. The\nproperties of the complementary metal-oxide semiconductor (CMOS) sensors were\nalso calibrated. The gain coefficients are in range of 6.4-6.9 eV/DN. The\nenergy resolutions are in range of 120-140 eV at 1.25 keV, meeting design\nrequirements. These calibration results have been ingested into the first\nversion of calibration database (CALDB) and applied to the analysis of the\nscientific data acquired by WXT after the launch of EP.",
    "pdf_url": "http://arxiv.org/pdf/2505.18939v1",
    "published": "2025-05-25T02:18:16+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.HE",
      "hep-ex",
      "physics.ins-det"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.18938v1",
    "title": "Beyond Replacement or Augmentation: How Creative Workers Reconfigure Division of Labor with Generative AI",
    "authors": [
      "Michael Clarke",
      "Michael Joffe"
    ],
    "abstract": "The introduction of generative AI tools such as ChatGPT into creative\nworkplaces has sparked highly visible, but binary worker replacement and\naugmentation debates. This study reframes this argument by examining how\ncreative professionals re-specify a division of labor with these tools. Through\n17 ethnomethodologically informed interviews with international creative agency\nworkers we demonstrate how roles are assigned to generative AI tools, how their\ncontributions are modified and remediated, and how workers practically manage\ntheir outputs to reflect assumptions of internal and external stakeholders.\nThis paper makes 3 unique contributions to CSCW: (1) we conceptualize\ngenerative AI prompting as a type of workplace situated, reflexive delegation,\n(2) we demonstrate that workers must continuously configure and repair AI role\nboundaries to maintain workplace intelligibility and accountability; and (3) we\nintroduce the notion of interpretive templatized trust, where workers devise\nstrategies to adapt automated generative templates for their setting, and\nreinforce stakeholder trust. This contribution has implications for organizing\nproductive human-AI work in creative and stakeholder centric environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.18938v1",
    "published": "2025-05-25T02:11:55+00:00",
    "categories": [
      "cs.CY",
      "H.5.3; I.2.7"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.18937v2",
    "title": "Examining Quintessence Models with DESI Data",
    "authors": [
      "Zahra Bayat",
      "Mark P. Hertzberg"
    ],
    "abstract": "We examine data from the Dark Energy Spectroscopic Instrument (DESI)\ncollaboration which has implications for the nature of dark energy. We consider\nclasses of models that manifestly obey the null energy condition, with a focus\non quintessence models. We find that hilltop potentials and exponential\npotentials provide modest improvement compared to a cosmological constant, but\nthe statistical evidence is only marginal at this stage. We correct some\nanalyses in the existing literature which attempted to compare some\nquintessence models to the data, giving an overly positive result.",
    "pdf_url": "http://arxiv.org/pdf/2505.18937v2",
    "published": "2025-05-25T02:09:41+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.18936v1",
    "title": "A Computational Approach for Modeling Platelet Adhesion Dynamics on Thrombogenic Surfaces",
    "authors": [
      "Ali Lotfian",
      "Ehsan Roohi"
    ],
    "abstract": "Platelet adhesion and aggregation are essential for primary hemostasis,\nforming a clot that quickly stops initial bleeding. Despite this critical role,\nthe dynamic interactions of platelet receptors with exposed collagen and von\nWillebrand factor (vWF) at the injury site and how these interactions influence\nthrombus formation under varying blood flow conditions are not fully\nunderstood. This study aimed to investigate the mechanisms of platelet adhesion\nand aggregation on collagen- or vWF-coated surfaces numerically. We combined\nthe stochastic Bell's law with a deterministic elastic force featuring a\ntime-dependent coefficient within the context of a dissipative particle\ndynamics (DPD) model to simulate thrombosis formation numerically. Our\nsimulation results revealed that the numerically predicted platelet adhesion\npatterns closely matched experimental observations reported in the literature,\ndemonstrating accurate replication of platelet behavior on collagen- and\nvWF-coated surfaces. Consequently, our deterministic/stochastic force model in\nDPD provides valuable insights into platelet adhesion dynamics under different\nflow conditions. These results contribute to a deeper understanding of platelet\ndynamics and potential therapeutic targets for managing hemostatic disorders.",
    "pdf_url": "http://arxiv.org/pdf/2505.18936v1",
    "published": "2025-05-25T02:08:46+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.18935v1",
    "title": "A concordance coefficient for lattice data: An application to poverty indices in Chile",
    "authors": [
      "Ronny Vallejos",
      "Clemente Ferrer",
      "Jorge Mateu"
    ],
    "abstract": "This paper introduces a novel coefficient for measuring agreement between two\nlattice sequences observed in the same areal units, motivated by the analysis\nof different methodologies for measuring poverty rates in Chile. Building on\nthe multivariate concordance coefficient framework, our approach accounts for\ndependencies in the multivariate lattice process using a non-negative definite\nmatrix of weights, assuming a Multivariate Conditionally Autoregressive (GMCAR)\nprocess. We adopt a Bayesian perspective for inference, using summaries from\nBayesian estimates. The methodology is illustrated through an analysis of\npoverty rates in the Metropolitan and Valpara\\'iso regions of Chile, with High\nPosterior Density (HPD) intervals provided for the poverty rates. This work\naddresses a methodological gap in the understanding of agreement coefficients\nand enhances the usability of these measures in the context of social variables\ntypically assessed in areal units.",
    "pdf_url": "http://arxiv.org/pdf/2505.18935v1",
    "published": "2025-05-25T02:00:18+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.21548v1",
    "title": "Fluent but Culturally Distant: Can Regional Training Teach Cultural Understanding?",
    "authors": [
      "Dhruv Agarwal",
      "Anya Shukla",
      "Sunayana Sitaram",
      "Aditya Vashistha"
    ],
    "abstract": "Large language models (LLMs) are used around the world but exhibit Western\ncultural tendencies. To address this cultural misalignment, many countries have\nbegun developing \"regional\" LLMs tailored to local communities. Yet it remains\nunclear whether these models merely speak the language of their users or also\nreflect their cultural values and practices. Using India as a case study, we\nevaluate five Indic and five global LLMs along two key dimensions: values (via\nthe Inglehart-Welzel map and GlobalOpinionQA) and practices (via CulturalBench\nand NormAd). Across all four tasks, we find that Indic models do not align more\nclosely with Indian cultural norms than global models. In fact, an average\nAmerican person is a better proxy for Indian cultural values than any Indic\nmodel. Even prompting strategies fail to meaningfully improve alignment.\nAblations show that regional fine-tuning does not enhance cultural competence\nand may in fact hurt it by impeding recall of existing knowledge. We trace this\nfailure to the scarcity of high-quality, untranslated, and culturally grounded\npretraining and fine-tuning data. Our study positions cultural evaluation as a\nfirst-class requirement alongside multilingual benchmarks and offers a reusable\nmethodology for developers. We call for deeper investments in culturally\nrepresentative data to build and evaluate truly sovereign LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.21548v1",
    "published": "2025-05-25T01:59:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18934v1",
    "title": "Chi-Square Wavelet Graph Neural Networks for Heterogeneous Graph Anomaly Detection",
    "authors": [
      "Xiping Li",
      "Xiangyu Dong",
      "Xingyi Zhang",
      "Kun Xie",
      "Yuanhao Feng",
      "Bo Wang",
      "Guilin Li",
      "Wuxiong Zeng",
      "Xiujun Shu",
      "Sibo Wang"
    ],
    "abstract": "Graph Anomaly Detection (GAD) in heterogeneous networks presents unique\nchallenges due to node and edge heterogeneity. Existing Graph Neural Network\n(GNN) methods primarily focus on homogeneous GAD and thus fail to address three\nkey issues: (C1) Capturing abnormal signal and rich semantics across diverse\nmeta-paths; (C2) Retaining high-frequency content in HIN dimension alignment;\nand (C3) Learning effectively from difficult anomaly samples with class\nimbalance. To overcome these, we propose ChiGAD, a spectral GNN framework based\non a novel Chi-Square filter, inspired by the wavelet effectiveness in diverse\ndomains. Specifically, ChiGAD consists of: (1) Multi-Graph Chi-Square Filter,\nwhich captures anomalous information via applying dedicated Chi-Square filters\nto each meta-path graph; (2) Interactive Meta-Graph Convolution, which aligns\nfeatures while preserving high-frequency information and incorporates\nheterogeneous messages by a unified Chi-Square Filter; and (3)\nContribution-Informed Cross-Entropy Loss, which prioritizes difficult anomalies\nto address class imbalance. Extensive experiments on public and industrial\ndatasets show that ChiGAD outperforms state-of-the-art models on multiple\nmetrics. Additionally, its homogeneous variant, ChiGNN, excels on seven GAD\ndatasets, validating the effectiveness of Chi-Square filters. Our code is\navailable at https://github.com/HsipingLi/ChiGAD.",
    "pdf_url": "http://arxiv.org/pdf/2505.18934v1",
    "published": "2025-05-25T01:58:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18933v1",
    "title": "REACT: Representation Extraction And Controllable Tuning to Overcome Overfitting in LLM Knowledge Editing",
    "authors": [
      "Haitian Zhong",
      "Yuhuan Liu",
      "Ziyang Xu",
      "Guofan Liu",
      "Qiang Liu",
      "Shu Wu",
      "Zhe Zhao",
      "Liang Wang",
      "Tieniu Tan"
    ],
    "abstract": "Large language model editing methods frequently suffer from overfitting,\nwherein factual updates can propagate beyond their intended scope,\noveremphasizing the edited target even when it's contextually inappropriate. To\naddress this challenge, we introduce REACT (Representation Extraction And\nControllable Tuning), a unified two-phase framework designed for precise and\ncontrollable knowledge editing. In the initial phase, we utilize tailored\nstimuli to extract latent factual representations and apply Principal Component\nAnalysis with a simple learnbale linear transformation to compute a directional\n\"belief shift\" vector for each instance. In the second phase, we apply\ncontrollable perturbations to hidden states using the obtained vector with a\nmagnitude scalar, gated by a pre-trained classifier that permits edits only\nwhen contextually necessary. Relevant experiments on EVOKE benchmarks\ndemonstrate that REACT significantly reduces overfitting across nearly all\nevaluation metrics, and experiments on COUNTERFACT and MQuAKE shows that our\nmethod preserves balanced basic editing performance (reliability, locality, and\ngenerality) under diverse editing scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.18933v1",
    "published": "2025-05-25T01:57:06+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.18932v1",
    "title": "Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency",
    "authors": [
      "Hyunho Ha",
      "Lei Xiao",
      "Christian Richardt",
      "Thu Nguyen-Phuoc",
      "Changil Kim",
      "Min H. Kim",
      "Douglas Lanman",
      "Numair Khan"
    ],
    "abstract": "We introduce a novel geometry-guided online video view synthesis method with\nenhanced view and temporal consistency. Traditional approaches achieve\nhigh-quality synthesis from dense multi-view camera setups but require\nsignificant computational resources. In contrast, selective-input methods\nreduce this cost but often compromise quality, leading to multi-view and\ntemporal inconsistencies such as flickering artifacts. Our method addresses\nthis challenge to deliver efficient, high-quality novel-view synthesis with\nview and temporal consistency. The key innovation of our approach lies in using\nglobal geometry to guide an image-based rendering pipeline. To accomplish this,\nwe progressively refine depth maps using color difference masks across time.\nThese depth maps are then accumulated through truncated signed distance fields\nin the synthesized view's image space. This depth representation is view and\ntemporally consistent, and is used to guide a pre-trained blending network that\nfuses multiple forward-rendered input-view images. Thus, the network is\nencouraged to output geometrically consistent synthesis results across multiple\nviews and time. Our approach achieves consistent, high-quality video synthesis,\nwhile running efficiently in an online manner.",
    "pdf_url": "http://arxiv.org/pdf/2505.18932v1",
    "published": "2025-05-25T01:56:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18931v1",
    "title": "Can Large Language Models Infer Causal Relationships from Real-World Text?",
    "authors": [
      "Ryan Saklad",
      "Aman Chadha",
      "Oleg Pavlov",
      "Raha Moraffah"
    ],
    "abstract": "Understanding and inferring causal relationships from texts is a core aspect\nof human cognition and is essential for advancing large language models (LLMs)\ntowards artificial general intelligence. Existing work primarily focuses on\nsynthetically generated texts which involve simple causal relationships\nexplicitly mentioned in the text. This fails to reflect the complexities of\nreal-world tasks. In this paper, we investigate whether LLMs are capable of\ninferring causal relationships from real-world texts. We develop a benchmark\ndrawn from real-world academic literature which includes diverse texts with\nrespect to length, complexity of relationships (different levels of\nexplicitness, number of events, and causal relationships), and domains and\nsub-domains. To the best of our knowledge, our benchmark is the first-ever\nreal-world dataset for this task. Our experiments on state-of-the-art LLMs\nevaluated on our proposed benchmark demonstrate significant challenges, with\nthe best-performing model achieving an average F1 score of only 0.477. Analysis\nreveals common pitfalls: difficulty with implicitly stated information, in\ndistinguishing relevant causal factors from surrounding contextual details, and\nwith connecting causally relevant information spread across lengthy textual\npassages. By systematically characterizing these deficiencies, our benchmark\noffers targeted insights for further research into advancing LLM causal\nreasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.18931v1",
    "published": "2025-05-25T01:50:05+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.18930v1",
    "title": "WeedNet: A Foundation Model-Based Global-to-Local AI Approach for Real-Time Weed Species Identification and Classification",
    "authors": [
      "Yanben Shen",
      "Timilehin T. Ayanlade",
      "Venkata Naresh Boddepalli",
      "Mojdeh Saadati",
      "Ashlyn Rairdin",
      "Zi K. Deng",
      "Muhammad Arbab Arshad",
      "Aditya Balu",
      "Daren Mueller",
      "Asheesh K Singh",
      "Wesley Everman",
      "Nirav Merchant",
      "Baskar Ganapathysubramanian",
      "Meaghan Anderson",
      "Soumik Sarkar",
      "Arti Singh"
    ],
    "abstract": "Early identification of weeds is essential for effective management and\ncontrol, and there is growing interest in automating the process using computer\nvision techniques coupled with AI methods. However, challenges associated with\ntraining AI-based weed identification models, such as limited expert-verified\ndata and complexity and variability in morphological features, have hindered\nprogress. To address these issues, we present WeedNet, the first global-scale\nweed identification model capable of recognizing an extensive set of weed\nspecies, including noxious and invasive plant species. WeedNet is an end-to-end\nreal-time weed identification pipeline and uses self-supervised learning,\nfine-tuning, and enhanced trustworthiness strategies. WeedNet achieved 91.02%\naccuracy across 1,593 weed species, with 41% species achieving 100% accuracy.\nUsing a fine-tuning strategy and a Global-to-Local approach, the local Iowa\nWeedNet model achieved an overall accuracy of 97.38% for 85 Iowa weeds, most\nclasses exceeded a 90% mean accuracy per class. Testing across intra-species\ndissimilarity (developmental stages) and inter-species similarity (look-alike\nspecies) suggests that diversity in the images collected, spanning all the\ngrowth stages and distinguishable plant characteristics, is crucial in driving\nmodel performance. The generalizability and adaptability of the Global WeedNet\nmodel enable it to function as a foundational model, with the Global-to-Local\nstrategy allowing fine-tuning for region-specific weed communities. Additional\nvalidation of drone- and ground-rover-based images highlights the potential of\nWeedNet for integration into robotic platforms. Furthermore, integration with\nAI for conversational use provides intelligent agricultural and ecological\nconservation consulting tools for farmers, agronomists, researchers, land\nmanagers, and government agencies across diverse landscapes.",
    "pdf_url": "http://arxiv.org/pdf/2505.18930v1",
    "published": "2025-05-25T01:49:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18929v1",
    "title": "Meta-aware Learning in text-to-SQL Large Language Model",
    "authors": [
      "Wenda Zhang"
    ],
    "abstract": "The advancements of Large language models (LLMs) have provided great\nopportunities to text-to-SQL tasks to overcome the main challenges to\nunderstand complex domain information and complex database structures in\nbusiness applications. In this paper, we propose a meta-aware learning\nframework to integrate domain knowledge, database schema, chain-of-thought\nreasoning processes, and metadata relationships to improve the SQL generation\nquality. The proposed framework includes four learning strategies: schema-based\nlearning, Chain-of-Thought (CoT) learning, knowledge-enhanced learning, and key\ninformation tokenization. This approach provides a comprehensive understanding\nof database structure and metadata information towards LLM through fine-tuning\nto improve its performance on SQL generation within business domains. Through\ntwo experimental studies, we have demonstrated the superiority of the proposed\nmethods in execution accuracy, multi-task SQL generation capability, and\nreduction of catastrophic forgetting.",
    "pdf_url": "http://arxiv.org/pdf/2505.18929v1",
    "published": "2025-05-25T01:45:00+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.18928v1",
    "title": "Toward Human Centered Interactive Clinical Question Answering System",
    "authors": [
      "Dina Albassam"
    ],
    "abstract": "Unstructured clinical notes contain essential patient information but are\nchallenging for physicians to search and interpret efficiently. Although large\nlanguage models (LLMs) have shown promise in question answering (QA), most\nexisting systems lack transparency, usability, and alignment with clinical\nworkflows. This work introduces an interactive QA system that enables\nphysicians to query clinical notes via text or voice and receive extractive\nanswers highlighted directly in the note for traceability.\n  The system was built using OpenAI models with zero-shot prompting and\nevaluated across multiple metrics, including exact string match, word overlap,\nSentenceTransformer similarity, and BERTScore. Results show that while exact\nmatch scores ranged from 47 to 62 percent, semantic similarity scores exceeded\n87 percent, indicating strong contextual alignment even when wording varied.\n  To assess usability, the system was also evaluated using simulated clinical\npersonas. Seven diverse physician and nurse personas interacted with the system\nacross scenario-based tasks and provided structured feedback. The evaluations\nhighlighted strengths in intuitive design and answer accessibility, alongside\nopportunities for enhancing explanation clarity.",
    "pdf_url": "http://arxiv.org/pdf/2505.18928v1",
    "published": "2025-05-25T01:31:31+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.05361v1",
    "title": "Scalable Generation of Spatial Transcriptomics from Histology Images via Whole-Slide Flow Matching",
    "authors": [
      "Tinglin Huang",
      "Tianyu Liu",
      "Mehrtash Babadi",
      "Wengong Jin",
      "Rex Ying"
    ],
    "abstract": "Spatial transcriptomics (ST) has emerged as a powerful technology for\nbridging histology imaging with gene expression profiling. However, its\napplication has been limited by low throughput and the need for specialized\nexperimental facilities. Prior works sought to predict ST from whole-slide\nhistology images to accelerate this process, but they suffer from two major\nlimitations. First, they do not explicitly model cell-cell interaction as they\nfactorize the joint distribution of whole-slide ST data and predict the gene\nexpression of each spot independently. Second, their encoders struggle with\nmemory constraints due to the large number of spots (often exceeding 10,000) in\ntypical ST datasets. Herein, we propose STFlow, a flow matching generative\nmodel that considers cell-cell interaction by modeling the joint distribution\nof gene expression of an entire slide. It also employs an efficient slide-level\nencoder with local spatial attention, enabling whole-slide processing without\nexcessive memory overhead. On the recently curated HEST-1k and STImage-1K4M\nbenchmarks, STFlow substantially outperforms state-of-the-art baselines and\nachieves over 18% relative improvements over the pathology foundation models.",
    "pdf_url": "http://arxiv.org/pdf/2506.05361v1",
    "published": "2025-05-25T01:29:19+00:00",
    "categories": [
      "cs.CV",
      "q-bio.GN"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18927v3",
    "title": "Moderating Harm: Benchmarking Large Language Models for Cyberbullying Detection in YouTube Comments",
    "authors": [
      "Amel Muminovic"
    ],
    "abstract": "As online platforms grow, comment sections increasingly host harassment that\nundermines user experience and well-being. This study benchmarks three leading\nlarge language models, OpenAI GPT-4.1, Google Gemini 1.5 Pro, and Anthropic\nClaude 3 Opus, on a corpus of 5,080 YouTube comments sampled from high-abuse\nthreads in gaming, lifestyle, food vlog, and music channels. The dataset\ncomprises 1,334 harmful and 3,746 non-harmful messages in English, Arabic, and\nIndonesian, annotated independently by two reviewers with substantial agreement\n(Cohen's kappa = 0.83). Using a unified prompt and deterministic settings,\nGPT-4.1 achieved the best overall balance with an F1 score of 0.863, precision\nof 0.887, and recall of 0.841. Gemini flagged the highest share of harmful\nposts (recall = 0.875) but its precision fell to 0.767 due to frequent false\npositives. Claude delivered the highest precision at 0.920 and the lowest\nfalse-positive rate of 0.022, yet its recall dropped to 0.720. Qualitative\nanalysis showed that all three models struggle with sarcasm, coded insults, and\nmixed-language slang. These results underscore the need for moderation\npipelines that combine complementary models, incorporate conversational\ncontext, and fine-tune for under-represented languages and implicit abuse. A\nde-identified version of the dataset and full prompts is publicly released to\npromote reproducibility and further progress in automated content moderation.",
    "pdf_url": "http://arxiv.org/pdf/2505.18927v3",
    "published": "2025-05-25T01:28:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18926v1",
    "title": "Hybrid Neural-MPM for Interactive Fluid Simulations in Real-Time",
    "authors": [
      "Jingxuan Xu",
      "Hong Huang",
      "Chuhang Zou",
      "Manolis Savva",
      "Yunchao Wei",
      "Wuyang Chen"
    ],
    "abstract": "We propose a neural physics system for real-time, interactive fluid\nsimulations. Traditional physics-based methods, while accurate, are\ncomputationally intensive and suffer from latency issues. Recent\nmachine-learning methods reduce computational costs while preserving fidelity;\nyet most still fail to satisfy the latency constraints for real-time use and\nlack support for interactive applications. To bridge this gap, we introduce a\nnovel hybrid method that integrates numerical simulation, neural physics, and\ngenerative control. Our neural physics jointly pursues low-latency simulation\nand high physical fidelity by employing a fallback safeguard to classical\nnumerical solvers. Furthermore, we develop a diffusion-based controller that is\ntrained using a reverse modeling strategy to generate external dynamic force\nfields for fluid manipulation. Our system demonstrates robust performance\nacross diverse 2D/3D scenarios, material types, and obstacle interactions,\nachieving real-time simulations at high frame rates (11~29% latency) while\nenabling fluid control guided by user-friendly freehand sketches. We present a\nsignificant step towards practical, controllable, and physically plausible\nfluid simulations for real-time interactive applications. We promise to release\nboth models and data upon acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2505.18926v1",
    "published": "2025-05-25T01:27:18+00:00",
    "categories": [
      "cs.LG",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18925v1",
    "title": "Words as Geometric Features: Estimating Homography using Optical Character Recognition as Compressed Image Representation",
    "authors": [
      "Ross Greer",
      "Alisha Ukani",
      "Katherine Izhikevich",
      "Earlence Fernandes",
      "Stefan Savage",
      "Alex C. Snoeren"
    ],
    "abstract": "Document alignment and registration play a crucial role in numerous\nreal-world applications, such as automated form processing, anomaly detection,\nand workflow automation. Traditional methods for document alignment rely on\nimage-based features like keypoints, edges, and textures to estimate geometric\ntransformations, such as homographies. However, these approaches often require\naccess to the original document images, which may not always be available due\nto privacy, storage, or transmission constraints. This paper introduces a novel\napproach that leverages Optical Character Recognition (OCR) outputs as features\nfor homography estimation. By utilizing the spatial positions and textual\ncontent of OCR-detected words, our method enables document alignment without\nrelying on pixel-level image data. This technique is particularly valuable in\nscenarios where only OCR outputs are accessible. Furthermore, the method is\nrobust to OCR noise, incorporating RANSAC to handle outliers and inaccuracies\nin the OCR data. On a set of test documents, we demonstrate that our OCR-based\napproach even performs more accurately than traditional image-based methods,\noffering a more efficient and scalable solution for document registration\ntasks. The proposed method facilitates applications in document processing, all\nwhile reducing reliance on high-dimensional image data.",
    "pdf_url": "http://arxiv.org/pdf/2505.18925v1",
    "published": "2025-05-25T01:20:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18924v2",
    "title": "LLM-Guided Taxonomy and Hierarchical Uncertainty for 3D Point Cloud Active Learning",
    "authors": [
      "Chenxi Li",
      "Nuo Chen",
      "Fengyun Tan",
      "Yantong Chen",
      "Bochun Yuan",
      "Tianrui Li",
      "Chongshou Li"
    ],
    "abstract": "We present a novel active learning framework for 3D point cloud semantic\nsegmentation that, for the first time, integrates large language models (LLMs)\nto construct hierarchical label structures and guide uncertainty-based sample\nselection. Unlike prior methods that treat labels as flat and independent, our\napproach leverages LLM prompting to automatically generate multi-level semantic\ntaxonomies and introduces a recursive uncertainty projection mechanism that\npropagates uncertainty across hierarchy levels. This enables spatially diverse,\nlabel-aware point selection that respects the inherent semantic structure of 3D\nscenes. Experiments on S3DIS and ScanNet v2 show that our method achieves up to\n4% mIoU improvement under extremely low annotation budgets (e.g., 0.02%),\nsubstantially outperforming existing baselines. Our results highlight the\nuntapped potential of LLMs as knowledge priors in 3D vision and establish\nhierarchical uncertainty modeling as a powerful paradigm for efficient point\ncloud annotation.",
    "pdf_url": "http://arxiv.org/pdf/2505.18924v2",
    "published": "2025-05-25T01:10:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18923v1",
    "title": "Graph-Based Operator Learning from Limited Data on Irregular Domains",
    "authors": [
      "Yile Li",
      "Shandian Zhe"
    ],
    "abstract": "Operator learning seeks to approximate mappings from input functions to\noutput solutions, particularly in the context of partial differential equations\n(PDEs). While recent advances such as DeepONet and Fourier Neural Operator\n(FNO) have demonstrated strong performance, they often rely on regular grid\ndiscretizations, limiting their applicability to complex or irregular domains.\nIn this work, we propose a Graph-based Operator Learning with Attention (GOLA)\nframework that addresses this limitation by constructing graphs from\nirregularly sampled spatial points and leveraging attention-enhanced Graph\nNeural Netwoks (GNNs) to model spatial dependencies with global information. To\nimprove the expressive capacity, we introduce a Fourier-based encoder that\nprojects input functions into a frequency space using learnable complex\ncoefficients, allowing for flexible embeddings even with sparse or nonuniform\nsamples. We evaluated our approach across a range of 2D PDEs, including Darcy\nFlow, Advection, Eikonal, and Nonlinear Diffusion, under varying sampling\ndensities. Our method consistently outperforms baselines, particularly in\ndata-scarce regimes, demonstrating strong generalization and efficiency on\nirregular domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.18923v1",
    "published": "2025-05-25T01:06:32+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18922v1",
    "title": "Ab Initio Prediction of Large Thermoelectric Effect in Distorted Heusler Alloy Ti-Fe-Sb Compound",
    "authors": [
      "Rifky Syariati",
      "Athorn Vora-ud",
      "Fumiyuki Ishii",
      "Tosawat Seetawan"
    ],
    "abstract": "The thermoelectric figure of merit of the Heusler alloy TiFe$_{1.5}$Sb was\ninvestigated by first-principles calculations of lattice thermal conductivity.\nThe electronic thermal conductivity, electrical conductivity, and Seebeck\ncoefficient are calculated by semi-classical Boltzmann transport theory.\nTiFe$_{1.5}$Sb was found to be thermally and dynamically stable, as confirmed\nby its phonon dispersion. Additionally, the small phonon band gap between\nacoustic and optical modes enhances phonon scattering, leading to a low lattice\nthermal conductivity of 0.703 W/mK at 300 K. Our study also reveals that\nTiFe$_{1.5}$Sb is a non-magnetic semiconductor. Notably, it demonstrates a\nsignificant longitudinal thermoelectric effect, with a Seebeck coefficient of\n359.4 $\\mu$V/K at 300 K. The combination of low lattice thermal conductivity\nand a high Seebeck coefficient results in a high thermoelectric figure of merit\n(ZT) of 0.88 and 0.91 at 300 K and 500 K, respectively. These findings\nhighlight the considerable potential of TiFe$_{1.5}$Sb as a promising material\nfor thermoelectric device applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.18922v1",
    "published": "2025-05-25T01:05:42+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.18921v1",
    "title": "Microscopic constraints for the equation of state and structure of neutron stars: a Bayesian model mixing framework",
    "authors": [
      "A. C. Semposki",
      "C. Drischler",
      "R. J. Furnstahl",
      "D. R. Phillips"
    ],
    "abstract": "Bayesian model mixing (BMM) is a statistical technique that can combine\nconstraints from different regions of an input space in a principled way. Here\nwe extend our BMM framework for the equation of state (EOS) of strongly\ninteracting matter from symmetric nuclear matter to asymmetric matter,\nspecifically focusing on zero-temperature, charge-neutral, $\\beta$-equilibrated\nmatter. We use Gaussian processes (GPs) to infer constraints on the neutron\nstar matter EOS at intermediate densities from two different microscopic\ntheories: chiral effective field theory ($\\chi$EFT) at baryon densities around\nnuclear saturation, $n_B \\sim n_0$, and perturbative QCD at asymptotically high\nbaryon densities, $n_B \\geqslant 20 n_0$. The uncertainties of the $\\chi$EFT\nand pQCD EOSs are obtained using the BUQEYE truncation error model. We\ndemonstrate the flexibility of our framework through the use of two categories\nof GP kernels: conventional stationary kernels and a non-stationary changepoint\nkernel. We use the latter to explore potential constraints on the dense matter\nEOS by including exogenous data representing theory predictions and heavy-ion\ncollision measurements at densities $\\geqslant 2n_0$. We also use our EOSs to\nobtain neutron star mass-radius relations and their uncertainties. Our\nframework, whose implementation will be available through a GitHub repository,\nprovides a prior distribution for the EOS that can be used in large-scale\nneutron-star inference frameworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.18921v1",
    "published": "2025-05-25T01:04:40+00:00",
    "categories": [
      "nucl-th",
      "astro-ph.HE",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.18920v2",
    "title": "Sensitivity analysis-guided model reduction of a mathematical model of pembrolizumab therapy for de novo metastatic MSI-H/dMMR colorectal cancer",
    "authors": [
      "Georgio Hawi",
      "Peter S. Kim",
      "Peter P. Lee"
    ],
    "abstract": "Colorectal cancer (CRC) is the third most commonly diagnosed cancer worldwide\nand the leading cause of cancer-related deaths in adults under 55, involving a\ncomplex interplay of biological processes such as dendritic cell (DC)\nmaturation and migration, T cell activation and proliferation, cytokine\nproduction, and T cell and natural killer (NK) cell-mediated cancer cell\nkilling. Microsatellite instability-high (MSI-H) CRC and deficient mismatch\nrepair (dMMR) CRC constitute 15% of all CRC, and 4% of metastatic CRC, and\nexhibit remarkable responsiveness to immunotherapy, especially with PD-1\ninhibitors such as pembrolizumab. Mathematical models of the underlying\nimmunobiology and the interactions underpinning immune checkpoint blockade\noffer mechanistic insights into tumour-immune dynamics and provide avenues for\ntreatment optimisation and the identification of novel therapeutic targets. We\nused our data-driven model of de novo metastatic MSI-H/dMMR CRC (dnmMCRC) and\nperformed sensitivity analysis-guided model reduction using the FAST and EFAST\nmethods. In this work, we constructed two simplified models of dnmMCRC: one\nthat faithfully reproduces all of the original model's trajectories, and a\nsecond, minimal model that accurately replicates the original dynamics while\nbeing highly extensible for future inclusion of additional components to\nexplore various aspects of the anti-tumour immune response.",
    "pdf_url": "http://arxiv.org/pdf/2505.18920v2",
    "published": "2025-05-25T00:59:40+00:00",
    "categories": [
      "q-bio.QM",
      "q-bio.CB"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.18919v1",
    "title": "Fair-Count-Min: Frequency Estimation under Equal Group-wise Approximation Factor",
    "authors": [
      "Nima Shahbazi",
      "Stavros Sintos",
      "Abolfazl Asudeh"
    ],
    "abstract": "Frequency estimation in streaming data often relies on sketches like\nCount-Min (CM) to provide approximate answers with sublinear space. However, CM\nsketches introduce additive errors that disproportionately impact low-frequency\nelements, creating fairness concerns across different groups of elements. We\nintroduce Fair-Count-Min, a frequency estimation sketch that guarantees equal\nexpected approximation factors across element groups, thus addressing the\nunfairness issue. We propose a column partitioning approach with group-aware\nsemi-uniform hashing to eliminate collisions between elements from different\ngroups. We provide theoretical guarantees for fairness, analyze the price of\nfairness, and validate our theoretical findings through extensive experiments\non real-world and synthetic datasets. Our experimental results show that\nFair-Count-Min achieves fairness with minimal additional error and maintains\ncompetitive efficiency compared to standard CM sketches.",
    "pdf_url": "http://arxiv.org/pdf/2505.18919v1",
    "published": "2025-05-25T00:56:36+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.18918v2",
    "title": "ALPCAHUS: Subspace Clustering for Heteroscedastic Data",
    "authors": [
      "Javier Salazar Cavazos",
      "Jeffrey A Fessler",
      "Laura Balzano"
    ],
    "abstract": "Principal component analysis (PCA) is a key tool in the field of data\ndimensionality reduction. Various methods have been proposed to extend PCA to\nthe union of subspace (UoS) setting for clustering data that come from multiple\nsubspaces like K-Subspaces (KSS). However, some applications involve\nheterogeneous data that vary in quality due to noise characteristics associated\nwith each data sample. Heteroscedastic methods aim to deal with such mixed data\nquality. This paper develops a heteroscedastic-focused subspace clustering\nmethod, named ALPCAHUS, that can estimate the sample-wise noise variances and\nuse this information to improve the estimate of the subspace bases associated\nwith the low-rank structure of the data. This clustering algorithm builds on\nK-Subspaces (KSS) principles by extending the recently proposed heteroscedastic\nPCA method, named LR-ALPCAH, for clusters with heteroscedastic noise in the UoS\nsetting. Simulations and real-data experiments show the effectiveness of\naccounting for data heteroscedasticity compared to existing clustering\nalgorithms. Code available at https://github.com/javiersc1/ALPCAHUS.",
    "pdf_url": "http://arxiv.org/pdf/2505.18918v2",
    "published": "2025-05-25T00:56:08+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.18917v1",
    "title": "Behavior Injection: Preparing Language Models for Reinforcement Learning",
    "authors": [
      "Zhepeng Cen",
      "Yihang Yao",
      "William Han",
      "Zuxin Liu",
      "Ding Zhao"
    ],
    "abstract": "Reinforcement fine-tuning (RFT) has emerged as a powerful post-training\ntechnique to incentivize the reasoning ability of large language models (LLMs).\nHowever, LLMs can respond very inconsistently to RFT: some show substantial\nperformance gains, while others plateau or even degrade. To understand this\ndivergence, we analyze the per-step influence of the RL objective and identify\ntwo key conditions for effective post-training: (1) RL-informative rollout\naccuracy, and (2) strong data co-influence, which quantifies how much the\ntraining data affects performance on other samples. Guided by these insights,\nwe propose behavior injection, a task-agnostic data-augmentation scheme applied\nprior to RL. Behavior injection enriches the supervised finetuning (SFT) data\nby seeding exploratory and exploitative behaviors, effectively making the model\nmore RL-ready. We evaluate our method across two reasoning benchmarks with\nmultiple base models. The results demonstrate that our theoretically motivated\naugmentation can significantly increases the performance gain from RFT over the\npre-RL model.",
    "pdf_url": "http://arxiv.org/pdf/2505.18917v1",
    "published": "2025-05-25T00:54:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18916v1",
    "title": "SCRum-9: Multilingual Stance Classification over Rumours on Social Media",
    "authors": [
      "Yue Li",
      "Jake Vasilakes",
      "Zhixue Zhao",
      "Carolina Scarton"
    ],
    "abstract": "We introduce SCRum-9, a multilingual dataset for Rumour Stance\nClassification, containing 7,516 tweet-reply pairs from X. SCRum-9 goes beyond\nexisting stance classification datasets by covering more languages (9), linking\nexamples to more fact-checked claims (2.1k), and including complex annotations\nfrom multiple annotators to account for intra- and inter-annotator variability.\nAnnotations were made by at least three native speakers per language, totalling\naround 405 hours of annotation and 8,150 dollars in compensation. Experiments\non SCRum-9 show that it is a challenging benchmark for both state-of-the-art\nLLMs (e.g. Deepseek) as well as fine-tuned pre-trained models, motivating\nfuture work in this area.",
    "pdf_url": "http://arxiv.org/pdf/2505.18916v1",
    "published": "2025-05-25T00:50:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18915v1",
    "title": "Are Vision Language Models Ready for Clinical Diagnosis? A 3D Medical Benchmark for Tumor-centric Visual Question Answering",
    "authors": [
      "Yixiong Chen",
      "Wenjie Xiao",
      "Pedro R. A. S. Bassi",
      "Xinze Zhou",
      "Sezgin Er",
      "Ibrahim Ethem Hamamci",
      "Zongwei Zhou",
      "Alan Yuille"
    ],
    "abstract": "Vision-Language Models (VLMs) have shown promise in various 2D visual tasks,\nyet their readiness for 3D clinical diagnosis remains unclear due to stringent\ndemands for recognition precision, reasoning ability, and domain knowledge. To\nsystematically evaluate these dimensions, we present DeepTumorVQA, a diagnostic\nvisual question answering (VQA) benchmark targeting abdominal tumors in CT\nscans. It comprises 9,262 CT volumes (3.7M slices) from 17 public datasets,\nwith 395K expert-level questions spanning four categories: Recognition,\nMeasurement, Visual Reasoning, and Medical Reasoning. DeepTumorVQA introduces\nunique challenges, including small tumor detection and clinical reasoning\nacross 3D anatomy. Benchmarking four advanced VLMs (RadFM, M3D, Merlin,\nCT-CHAT), we find current models perform adequately on measurement tasks but\nstruggle with lesion recognition and reasoning, and are still not meeting\nclinical needs. Two key insights emerge: (1) large-scale multimodal pretraining\nplays a crucial role in DeepTumorVQA testing performance, making RadFM stand\nout among all VLMs. (2) Our dataset exposes critical differences in VLM\ncomponents, where proper image preprocessing and design of vision modules\nsignificantly affect 3D perception. To facilitate medical multimodal research,\nwe have released DeepTumorVQA as a rigorous benchmark:\nhttps://github.com/Schuture/DeepTumorVQA.",
    "pdf_url": "http://arxiv.org/pdf/2505.18915v1",
    "published": "2025-05-25T00:50:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18914v1",
    "title": "A \"Neural\" Riemann solver for Relativistic Hydrodynamics",
    "authors": [
      "Carlo Musolino"
    ],
    "abstract": "In this paper, we present an approach to solving the Riemann problem in\none-dimensional relativistic hydrodynamics, where the most computationally\nexpensive steps of the exact solver are replaced by compact, highly specialized\nneural networks. The resulting \"neural\" Riemann solver is integrated into a\nhigh-resolution shock-capturing scheme and tested on a range of canonical\nproblems, demonstrating both robustness and efficiency. By constraining the\nlearned components to the root-finding of single-valued functions, the method\nretains physical interpretability while significantly accelerating the\ncomputation. The solver is shown to achieve accuracies comparable to the exact\nalgorithm at a fraction of the cost, suggesting that this approach may offer a\nviable path toward more efficient Riemann solvers for use in large-scale\nnumerical relativity simulations of astrophysical systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.18914v1",
    "published": "2025-05-25T00:44:25+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.18913v1",
    "title": "Quantum Teleportation of a Single Qutrit using Two-Qutrit Entangled States",
    "authors": [
      "Surajit Sen",
      "Tushar Kanti Dey",
      "Anushree Bhattacharjee",
      "Sovik Roy"
    ],
    "abstract": "We demonstrate quantum teleportation of a qutrit system using a complete set\nof two-qutrit entangled states obtained from the representation theory of the\nSU(3) group. All measurement gates essential for end-to-end teleportation are\nsystematically evaluated, and these are found to be non-unitary. Our approach\nextends Bennett's teleportation protocol to the qutrit system with minimal\nmodifications, preserving operational simplicity and underscoring the necessity\nof non-unitary measurement operators in high-dimensional systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.18913v1",
    "published": "2025-05-25T00:40:50+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.18912v2",
    "title": "Robust Stability Analysis of Positive Lure System with Neural Network Feedback",
    "authors": [
      "Hamidreza Montazeri Hedesh",
      "Moh. Kamalul Wafi",
      "Bahram Shafai",
      "Milad Siami"
    ],
    "abstract": "This paper investigates the robustness of the Lur'e problem under positivity\nconstraints, drawing on results from the positive Aizerman conjecture and\nrobustness properties of Metzler matrices. Specifically, we consider a control\nsystem of Lur'e type in which not only the linear part includes parametric\nuncertainty but also the nonlinear sector bound is unknown. We investigate\ntools from positive linear systems to effectively solve the problems in\ncomplicated and uncertain nonlinear systems. By leveraging the positivity\ncharacteristic of the system, we derive an explicit formula for the stability\nradius of Lur'e systems. Furthermore, we extend our analysis to systems with\nneural network (NN) feedback loops. Building on this approach, we also propose\na refinement method for sector bounds of NNs. This study introduces a scalable\nand efficient approach for robustness analysis of both Lur'e and NN-controlled\nsystems. Finally, the proposed results are supported by illustrative examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.18912v2",
    "published": "2025-05-25T00:37:28+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "93D09, 93D20, 93C10, 68T07",
      "B.1.3; G.1; I.2; I.2.3; I.2.8; I.2.1; J.2"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.18911v1",
    "title": "Topological Quenching of Noise in a Free-Running Moebius Microcomb",
    "authors": [
      "Debayan Das",
      "Antonio Cutrona",
      "Andrew C. Cooper",
      "Luana Olivieri",
      "Alexander G. Balanov",
      "Sai Tak Chu",
      "Brent E. Little",
      "Roberto Morandotti",
      "David J. Moss",
      "Juan Sebastian Totero Gongora",
      "Marco Peccianti",
      "Gian-Luca Oppo",
      "Alessia Pasquazi"
    ],
    "abstract": "Microcombs require ultralow-noise repetition rates to enable next-generation\napplications in metrology, high-speed communications, microwave photonics, and\nsensing. Regardless of the stabilisation method, spectral purity ultimately\ndepends on the quality of the free-running spectrum. Traditionally, sources\noperate at 'quiet points' in parameter space, fixed by device and material\nproperties. Creating broad, tuneable low-noise regions-especially in\nself-locked systems-remains an open challenge. Here, inspired by topological\nprotection, we demonstrate a microcomb with intrinsically low phase noise in a\nfully free-running configuration, operating without external referencing or\ncontrol. Using a microresonator-filtered laser, we implement a Moebius geometry\nvia interleaved microcavity modes. Upon formation of a topological Moebius\nsoliton molecule, the free-running laser exhibits over 15 dB of phase noise\nsuppression across 10 Hz to 10 kHz at a 100 GHz repetition rate, yielding -63\ndBc/Hz phase noise at 1 kHz and an Allan deviation of 4 x 10^-10 at 10 s gate\ntime, without any external control. The state persists across dynamical\nregimes, including an Ising-Bloch-like transition, a hallmark of\nnon-equilibrium physics, where the soliton molecule shifts from a resting to a\nmoving state. Parametrisation of the group velocity minimises the repetition\nrate's sensitivity to global system parameters, enabling long-term drift\ncompensation from within the system dynamics. Our results establish a new route\nto intrinsically noise-quenched microcombs, operating in a standalone, fully\nfree-running configuration governed entirely by internal physical principles.\nThis benefits applications such as chip-based microwave generation,\nmetrology-grade optical clocks, and field-deployable systems, where built-in\nlong-term stability and low-noise performance are critical.",
    "pdf_url": "http://arxiv.org/pdf/2505.18911v1",
    "published": "2025-05-25T00:27:47+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.18910v3",
    "title": "Uncovering relationships between the electronic self-energy and coupled-cluster doubles theory",
    "authors": [
      "Christopher J. N. Coveney"
    ],
    "abstract": "We derive the coupled-cluster doubles (CCD) amplitude equations by\nintroduction of the particle-hole-time decoupled electronic self-energy. The\nresulting analysis leads to an expression for the ground state correlation\nenergy that is exactly of the form obtained in coupled-cluster doubles theory.\nWe demonstrate the relationship to the ionization potential/electron affinity\nequation-of-motion coupled-cluster doubles (IP/EA-EOM-CCD) eigenvalue problem\nby coupling the reverse-time self-energy contributions while maintaining\nparticle-hole separability. The formal relationships established are\ndemonstrated by exact solution of the Hubbard dimer.",
    "pdf_url": "http://arxiv.org/pdf/2505.18910v3",
    "published": "2025-05-25T00:26:23+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.18909v1",
    "title": "On the Role of Label Noise in the Feature Learning Process",
    "authors": [
      "Andi Han",
      "Wei Huang",
      "Zhanpeng Zhou",
      "Gang Niu",
      "Wuyang Chen",
      "Junchi Yan",
      "Akiko Takeda",
      "Taiji Suzuki"
    ],
    "abstract": "Deep learning with noisy labels presents significant challenges. In this\nwork, we theoretically characterize the role of label noise from a feature\nlearning perspective. Specifically, we consider a signal-noise data\ndistribution, where each sample comprises a label-dependent signal and\nlabel-independent noise, and rigorously analyze the training dynamics of a\ntwo-layer convolutional neural network under this data setup, along with the\npresence of label noise. Our analysis identifies two key stages. In Stage I,\nthe model perfectly fits all the clean samples (i.e., samples without label\nnoise) while ignoring the noisy ones (i.e., samples with noisy labels). During\nthis stage, the model learns the signal from the clean samples, which\ngeneralizes well on unseen data. In Stage II, as the training loss converges,\nthe gradient in the direction of noise surpasses that of the signal, leading to\noverfitting on noisy samples. Eventually, the model memorizes the noise present\nin the noisy samples and degrades its generalization ability. Furthermore, our\nanalysis provides a theoretical basis for two widely used techniques for\ntackling label noise: early stopping and sample selection. Experiments on both\nsynthetic and real-world setups validate our theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.18909v1",
    "published": "2025-05-25T00:13:28+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.18908v1",
    "title": "Long-Duration Nonthermal Motions in the Supra-Arcade and Loop-Top Region During an Eruptive Solar Flare",
    "authors": [
      "Tingyu Gou",
      "Katharine K. Reeves"
    ],
    "abstract": "Solar flares are widely accepted to be powered by magnetic reconnection that\ninvolves complex dynamics in various scales. The flare supra-arcade and\nloop-top region, directly impacted by fast reconnection downflows, contains a\nwealth of microscopic dynamics, which are, however, difficult to resolve in\nimaging. We present simultaneous spectroscopic and imaging observations of hot\nflaring plasma above the loop tops by IRIS and SDO/AIA. IRIS continuously\nobserved high-temperature Fe XXI 1354.08 A spectral emissions throughout the\nlong-duration gradual phase of the X-class flare. We found weak Doppler blue\nshifts near the loop-top region, indicative of bulk plasma motions from\nchromospheric evaporation based on the 3D flare loop orientation. Strong\nnonthermal velocities are detected at the bottom of the flare supra-arcade\nfan/plasma sheet, suggestive of the presence of turbulence in the flare current\nsheet region. In addition, disorganized nonthermal plasma motions are\nconstantly detected until the very end of the flare, indicating irregular\nunresolved plasma flows in the cusp and loop-top region. The spatial and\ntemporal evolution of spectral parameters follow the dynamics resulting from\non-going magnetic reconnection during the prolonged gradual phase. The\nlong-lasting nonthermal plasma motions may contribute to the high and steady\ntemperature of flaring plasmas above flare loops.",
    "pdf_url": "http://arxiv.org/pdf/2505.18908v1",
    "published": "2025-05-25T00:07:47+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.18907v1",
    "title": "Stronger Enforcement of Instruction Hierarchy via Augmented Intermediate Representations",
    "authors": [
      "Sanjay Kariyappa",
      "G. Edward Suh"
    ],
    "abstract": "Prompt injection attacks are a critical security vulnerability in large\nlanguage models (LLMs), allowing attackers to hijack model behavior by\ninjecting malicious instructions within the input context. Recent defense\nmechanisms have leveraged an Instruction Hierarchy (IH) Signal, often\nimplemented through special delimiter tokens or additive embeddings to denote\nthe privilege level of input tokens. However, these prior works typically\ninject the IH signal exclusively at the initial input layer, which we\nhypothesize limits its ability to effectively distinguish the privilege levels\nof tokens as it propagates through the different layers of the model. To\novercome this limitation, we introduce a novel approach that injects the IH\nsignal into the intermediate token representations within the network. Our\nmethod augments these representations with layer-specific trainable embeddings\nthat encode the privilege information. Our evaluations across multiple models\nand training methods reveal that our proposal yields between $1.6\\times$ and\n$9.2\\times$ reduction in attack success rate on gradient-based prompt injection\nattacks compared to state-of-the-art methods, without significantly degrading\nthe model's utility.",
    "pdf_url": "http://arxiv.org/pdf/2505.18907v1",
    "published": "2025-05-25T00:01:39+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  }
]