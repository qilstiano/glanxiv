[
  {
    "id": "http://arxiv.org/abs/2505.17348v1",
    "title": "DEL-ToM: Inference-Time Scaling for Theory-of-Mind Reasoning via Dynamic Epistemic Logic",
    "authors": [
      "Yuheng Wu",
      "Jianwen Xie",
      "Denghui Zhang",
      "Zhaozhuo Xu"
    ],
    "abstract": "Theory-of-Mind (ToM) tasks pose a unique challenge for small language models\n(SLMs) with limited scale, which often lack the capacity to perform deep social\nreasoning. In this work, we propose DEL-ToM, a framework that improves ToM\nreasoning through inference-time scaling rather than architectural changes. Our\napproach decomposes ToM tasks into a sequence of belief updates grounded in\nDynamic Epistemic Logic (DEL), enabling structured and transparent reasoning.\nWe train a verifier, called the Process Belief Model (PBM), to score each\nbelief update step using labels generated automatically via a DEL simulator.\nDuring inference, candidate belief traces generated by a language model are\nevaluated by the PBM, and the highest-scoring trace is selected. This allows\nSLMs to emulate more deliberate reasoning by allocating additional compute at\ntest time. Experiments across multiple model scales and benchmarks show that\nDEL-ToM consistently improves performance, demonstrating that verifiable belief\nsupervision can significantly enhance ToM abilities of SLMs without retraining.",
    "pdf_url": "http://arxiv.org/pdf/2505.17348v1",
    "published": "2025-05-22T23:52:56+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17347v1",
    "title": "Measuring optical force with a torsion pendulum: a platform for independent student experimentation",
    "authors": [
      "Leland Russell",
      "Ezekiel A. Rein",
      "Anatalya Piatigorsky",
      "Jennifer T. Heath"
    ],
    "abstract": "In this work, the force due to radiation pressure is measured with sub-10 pN\nsensitivity, corresponding to less than 2 mW of optical power. The apparatus\nadds homemade reflectors to a commercial Cavendish balance, which consists of a\ntorsion pendulum with a built-in capacitance position sensor. When driven by\nfour 5 mW laser diodes, with square-wave modulation at the pendulum's natural\nfrequency, the response is strong enough to easily discern in a short time\nseries. The discrete Fourier transform of a longer dataset provides a more\nin-depth analysis, clearly showing the multiple frequency components from the\nsquare-wave driving force. The driving power was controlled by adjusting the\nsquare wave duty cycle, allowing easy automation and avoiding additional optics\nor filters. For a 9-hour dataset, white noise corresponding to about 2 pN was\nobserved, enabling our most sensitive measurements. The pendulum operates in\nair. To minimize convective forces from differential heating and the resulting\ndifferential pressure, we use symmetrical reflectors encased in low-thermal\nconductivity material, namely, two glass-fronted mirrors attached back-to-back.\nThis experiment could be used in a single lab session, allowing the optical\nforce to be quickly and intuitively observed. It also demonstrates the power of\nFourier analysis, builds student intuition about oscillator systems, and\nprovides a compelling platform for student-driven projects.",
    "pdf_url": "http://arxiv.org/pdf/2505.17347v1",
    "published": "2025-05-22T23:44:37+00:00",
    "categories": [
      "physics.ed-ph",
      "physics.ins-det"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17346v1",
    "title": "Use of Bayesian Inference to Diagnose Issues in Experimental Measurements of Mechanical Disk Resonators",
    "authors": [
      "Simon C. Tait",
      "Michael J. Williams",
      "Joseph Bayley",
      "Bryan W. Barr",
      "Iain Martin"
    ],
    "abstract": "Gravitational wave detectors, such as LIGO, are predominantly limited by\ncoating Brownian thermal noise (CTN), arising from mechanical losses in the\nBragg mirror coatings used on test-mass optics. Accurately characterizing and\nminimizing these losses is crucial for enhancing detector sensitivity. This\npaper introduces a general mathematical and statistical framework leveraging\nBayesian inference to precisely analyse mechanical ring-down measurements of\ndisk resonators, a standard method for quantifying mechanical loss in coating\nmaterials. Our approach presents a refined model that fully captures the\nnon-linear behaviour of beam spot motion on split photodiode sensors,\nsignificantly improving upon traditional simplified exponential-decay methods.\nWe achieve superior estimation accuracy for decay constants ($\\tau_1$ and\n$\\tau_2$), especially for measurements exhibiting larger oscillation\namplitudes. Specifically, we observe improvements in estimation accuracy by up\nto 25$\\%$ over traditional methods, with strong Bayesian evidence favouring our\nframework. Our simulations and experimental validations reveal that previously\ndiscarded measurements due to fitting inaccuracies can now be reliably\nanalysed, maximizing the use of available data. This enhanced analytical\ncapability not only provides more precise mechanical loss estimations but also\noffers deeper insights into systematic issues affecting disk resonator\nmeasurements, paving the way toward improved coating materials and ultimately,\nmore sensitive gravitational wave detectors.",
    "pdf_url": "http://arxiv.org/pdf/2505.17346v1",
    "published": "2025-05-22T23:39:10+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.17345v1",
    "title": "Language models should be subject to repeatable, open, domain-contextualized hallucination benchmarking",
    "authors": [
      "Justin D. Norman",
      "Michael U. Rivera",
      "D. Alex Hughes"
    ],
    "abstract": "Plausible, but inaccurate, tokens in model-generated text are widely believed\nto be pervasive and problematic for the responsible adoption of language\nmodels. Despite this concern, there is little scientific work that attempts to\nmeasure the prevalence of language model hallucination in a comprehensive way.\nIn this paper, we argue that language models should be evaluated using\nrepeatable, open, and domain-contextualized hallucination benchmarking. We\npresent a taxonomy of hallucinations alongside a case study that demonstrates\nthat when experts are absent from the early stages of data creation, the\nresulting hallucination metrics lack validity and practical utility.",
    "pdf_url": "http://arxiv.org/pdf/2505.17345v1",
    "published": "2025-05-22T23:36:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17344v1",
    "title": "A Multi-Head Attention Soft Random Forest for Interpretable Patient No-Show Prediction",
    "authors": [
      "Ninda Nurseha Amalina",
      "Kwadwo Boateng Ofori-Amanfo",
      "Heungjo An"
    ],
    "abstract": "Unattended scheduled appointments, defined as patient no-shows, adversely\naffect both healthcare providers and patients' health, disrupting the\ncontinuity of care, operational efficiency, and the efficient allocation of\nmedical resources. Accurate predictive modelling is needed to reduce the impact\nof no-shows. Although machine learning methods, such as logistic regression,\nrandom forest models, and decision trees, are widely used in predicting patient\nno-shows, they often rely on hard decision splits and static feature\nimportance, limiting their adaptability to specific or complex patient\nbehaviors. To address this limitation, we propose a new hybrid Multi-Head\nAttention Soft Random Forest (MHASRF) model that integrates attention\nmechanisms into a random forest model using probabilistic soft splitting\ninstead of hard splitting. The MHASRF model assigns attention weights\ndifferently across the trees, enabling attention on specific patient behaviors.\nThe model exhibited 93.56% accuracy, 93.67% precision, 93.56% recall, and a\n93.59% F1 score, surpassing the performance of decision tree, logistic\nregression, random forest, and naive Bayes models. Furthermore, MHASRF was able\nto identify key predictors of patient no-shows using two levels of feature\nimportance (tree level and attention mechanism level), offering deeper insights\ninto patient no-show predictors. The proposed model is a robust, adaptable, and\ninterpretable method for predicting patient no-shows that will help healthcare\nproviders in optimizing resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.17344v1",
    "published": "2025-05-22T23:34:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.20315v1",
    "title": "Arctic-Text2SQL-R1: Simple Rewards, Strong Reasoning in Text-to-SQL",
    "authors": [
      "Zhewei Yao",
      "Guoheng Sun",
      "Lukasz Borchmann",
      "Zheyu Shen",
      "Minghang Deng",
      "Bohan Zhai",
      "Hao Zhang",
      "Ang Li",
      "Yuxiong He"
    ],
    "abstract": "Translating natural language into SQL (Test2SQL) is a longstanding challenge\nat the intersection of natural language understanding and structured data\naccess. While large language models (LLMs) have significantly improved fluency\nin SQL generation, producing correct and executable SQL--particularly for\ncomplex queries--remains a bottleneck. We present Arctic-Text2SQL-R1, a\nreinforcement learning (RL) framework and model family designed to generate\naccurate, executable SQL using a lightweight reward signal based solely on\nexecution correctness. Our approach avoids brittle intermediate supervision and\ncomplex reward shaping, promoting stable training and alignment with the end\ntask. Combined with carefully curated data, strong supervised initialization,\nand effective training practices, Arctic-Text2SQL-R1 achieves state-of-the-art\nexecution accuracy across six diverse Test2SQL benchmarks, including the top\nposition on the BIRD leaderboard. Notably, our 7B model outperforms prior\n70B-class systems, highlighting the framework's scalability and efficiency. We\nfurther demonstrate inference-time robustness through simple extensions like\nvalue retrieval and majority voting. Extensive experiments and ablation studies\noffer both positive and negative insights, providing practical guidance for\nfuture Test2SQL research.",
    "pdf_url": "http://arxiv.org/pdf/2505.20315v1",
    "published": "2025-05-22T23:33:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17343v2",
    "title": "Ocular Authentication: Fusion of Gaze and Periocular Modalities",
    "authors": [
      "Dillon Lohr",
      "Michael J. Proulx",
      "Mehedi Hasan Raju",
      "Oleg V. Komogortsev"
    ],
    "abstract": "This paper investigates the feasibility of fusing two eye-centric\nauthentication modalities-eye movements and periocular images-within a\ncalibration-free authentication system. While each modality has independently\nshown promise for user authentication, their combination within a unified\ngaze-estimation pipeline has not been thoroughly explored at scale. In this\nreport, we propose a multimodal authentication system and evaluate it using a\nlarge-scale in-house dataset comprising 9202 subjects with an eye tracking (ET)\nsignal quality equivalent to a consumer-facing virtual reality (VR) device. Our\nresults show that the multimodal approach consistently outperforms both\nunimodal systems across all scenarios, surpassing the FIDO benchmark. The\nintegration of a state-of-the-art machine learning architecture contributed\nsignificantly to the overall authentication performance at scale, driven by the\nmodel's ability to capture authentication representations and the complementary\ndiscriminative characteristics of the fused modalities.",
    "pdf_url": "http://arxiv.org/pdf/2505.17343v2",
    "published": "2025-05-22T23:32:08+00:00",
    "categories": [
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.12035v1",
    "title": "MARché: Fast Masked Autoregressive Image Generation with Cache-Aware Attention",
    "authors": [
      "Chaoyi Jiang",
      "Sungwoo Kim",
      "Lei Gao",
      "Hossein Entezari Zarch",
      "Won Woo Ro",
      "Murali Annavaram"
    ],
    "abstract": "Masked autoregressive (MAR) models unify the strengths of masked and\nautoregressive generation by predicting tokens in a fixed order using\nbidirectional attention for image generation. While effective, MAR models\nsuffer from significant computational overhead, as they recompute attention and\nfeed-forward representations for all tokens at every decoding step, despite\nmost tokens remaining semantically stable across steps. We propose a\ntraining-free generation framework MARch\\'e to address this inefficiency\nthrough two key components: cache-aware attention and selective KV refresh.\nCache-aware attention partitions tokens into active and cached sets, enabling\nseparate computation paths that allow efficient reuse of previously computed\nkey/value projections without compromising full-context modeling. But a cached\ntoken cannot be used indefinitely without recomputation due to the changing\ncontextual information over multiple steps. MARch\\'e recognizes this challenge\nand applies a technique called selective KV refresh. Selective KV refresh\nidentifies contextually relevant tokens based on attention scores from newly\ngenerated tokens and updates only those tokens that require recomputation,\nwhile preserving image generation quality. MARch\\'e significantly reduces\nredundant computation in MAR without modifying the underlying architecture.\nEmpirically, MARch\\'e achieves up to 1.7x speedup with negligible impact on\nimage quality, offering a scalable and broadly applicable solution for\nefficient masked transformer generation.",
    "pdf_url": "http://arxiv.org/pdf/2506.12035v1",
    "published": "2025-05-22T23:26:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17342v1",
    "title": "A Survey of Safe Reinforcement Learning and Constrained MDPs: A Technical Survey on Single-Agent and Multi-Agent Safety",
    "authors": [
      "Ankita Kushwaha",
      "Kiran Ravish",
      "Preeti Lamba",
      "Pawan Kumar"
    ],
    "abstract": "Safe Reinforcement Learning (SafeRL) is the subfield of reinforcement\nlearning that explicitly deals with safety constraints during the learning and\ndeployment of agents. This survey provides a mathematically rigorous overview\nof SafeRL formulations based on Constrained Markov Decision Processes (CMDPs)\nand extensions to Multi-Agent Safe RL (SafeMARL). We review theoretical\nfoundations of CMDPs, covering definitions, constrained optimization\ntechniques, and fundamental theorems. We then summarize state-of-the-art\nalgorithms in SafeRL for single agents, including policy gradient methods with\nsafety guarantees and safe exploration strategies, as well as recent advances\nin SafeMARL for cooperative and competitive settings. Additionally, we propose\nfive open research problems to advance the field, with three focusing on\nSafeMARL. Each problem is described with motivation, key challenges, and\nrelated prior work. This survey is intended as a technical guide for\nresearchers interested in SafeRL and SafeMARL, highlighting key concepts,\nmethods, and open future research directions.",
    "pdf_url": "http://arxiv.org/pdf/2505.17342v1",
    "published": "2025-05-22T23:26:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17341v1",
    "title": "TI-DeepONet: Learnable Time Integration for Stable Long-Term Extrapolation",
    "authors": [
      "Dibyajyoti Nayak",
      "Somdatta Goswami"
    ],
    "abstract": "Accurate temporal extrapolation presents a fundamental challenge for neural\noperators in modeling dynamical systems, where reliable predictions must extend\nsignificantly beyond the training time horizon. Conventional Deep Operator\nNetwork (DeepONet) approaches employ two inherently limited training paradigms\n- fixed-horizon rollouts that predict complete spatiotemporal solutions while\ndisregarding temporal causality, and autoregressive formulations that\naccumulate errors through sequential predictions. We introduce TI-DeepONet, a\nframework that integrates neural operators with adaptive numerical\ntime-stepping techniques to preserve the Markovian structure of dynamical\nsystems while mitigating error propagation in extended temporal forecasting.\nOur approach reformulates the learning objective from direct state prediction\nto the approximation of instantaneous time-derivative fields, which are then\nintegrated using established numerical schemes. This architecture supports\ncontinuous-time prediction and enables deployment of higher-precision\nintegrators during inference than those used during training, balancing\ncomputational efficiency with predictive accuracy. We further develop\nTI(L)-DeepONet, which incorporates learnable coefficients for intermediate\nslopes in the integration process, adapting to solution-specific variations and\nenhancing fidelity. Evaluation across three canonical PDEs shows that\nTI(L)-DeepONet marginally outperforms TI-DeepONet, with both reducing relative\nL2 extrapolation errors: approximately 81% over autoregressive and 70% over\nfixed-horizon methods. Notably, both maintain prediction stability for temporal\ndomains extending to about twice the training interval. This research\nestablishes a physics-aware operator learning paradigm that bridges neural\napproximation with numerical analysis while preserving the causal structure of\ndynamical systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17341v1",
    "published": "2025-05-22T23:24:31+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17340v2",
    "title": "Conformal Predictive Distributions for Order Fulfillment Time Forecasting",
    "authors": [
      "Tinghan Ye",
      "Amira Hijazi",
      "Pascal Van Hentenryck"
    ],
    "abstract": "Accurate estimation of order fulfillment time is critical for e-commerce\nlogistics, yet traditional rule-based approaches often fail to capture the\ninherent uncertainties in delivery operations. This paper introduces a novel\nframework for distributional forecasting of order fulfillment time, leveraging\nConformal Predictive Systems and Cross Venn-Abers Predictors -- model-agnostic\ntechniques that provide rigorous coverage or validity guarantees. The proposed\nmachine learning methods integrate granular spatiotemporal features, capturing\nfulfillment location and carrier performance dynamics to enhance predictive\naccuracy. Additionally, a cost-sensitive decision rule is developed to convert\nprobabilistic forecasts into reliable point predictions. Experimental\nevaluation on a large-scale industrial dataset demonstrates that the proposed\nmethods generate competitive distributional forecasts, while machine\nlearning-based point predictions significantly outperform the existing\nrule-based system -- achieving up to 14% higher prediction accuracy and up to\n75% improvement in identifying late deliveries.",
    "pdf_url": "http://arxiv.org/pdf/2505.17340v2",
    "published": "2025-05-22T23:23:52+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17339v1",
    "title": "Changing methodologies in solar physics",
    "authors": [
      "Philip G. Judge"
    ],
    "abstract": "This study attempts to establish a basis for understanding how methods used\nin research in solar physics have evolved since World War II (WWII). The goal\nis to begin to explore if and how the changing research environment affects the\ntraining of young scientists, and the future of solar physics research at our\ninstitutions. A strategy based upon a sample of 650 PhD theses is used to seek\npossible trends over 8 decades, with the aim of uncovering any correlations\nbetween methods used and measures of success. Necessarily subjective, results\ndepend on how methods are defined, and how success is measured. Although a\nbrief justification of the choices made is attempted, trying mainly to avoid\npitfalls such as counting citations, it is clear that further assessment is\nrequired. The statistical analysis is based upon necessarily subjective\ncategorization and the inference of likelihoods of two different distributions\nbeing drawn from the same underlying distribution. The statistics seem to\nreflect historical events, such as the Kennedy Moonshot program and the\nassociated SKYLAB mission, with changes delayed by a few years. The data\nsuggest that impactful advances are becoming more rare. Yet the methods used\nhave changed little barring those related to obvious technological advances\n(e.g. the advent of spacecraft, adaptive optics). A follow-up study to explore\nthe 100,000+ publications in solar physics through machine learning seems\nwarranted.",
    "pdf_url": "http://arxiv.org/pdf/2505.17339v1",
    "published": "2025-05-22T23:19:25+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.17338v1",
    "title": "Render-FM: A Foundation Model for Real-time Photorealistic Volumetric Rendering",
    "authors": [
      "Zhongpai Gao",
      "Meng Zheng",
      "Benjamin Planche",
      "Anwesa Choudhuri",
      "Terrence Chen",
      "Ziyan Wu"
    ],
    "abstract": "Volumetric rendering of Computed Tomography (CT) scans is crucial for\nvisualizing complex 3D anatomical structures in medical imaging. Current\nhigh-fidelity approaches, especially neural rendering techniques, require\ntime-consuming per-scene optimization, limiting clinical applicability due to\ncomputational demands and poor generalizability. We propose Render-FM, a novel\nfoundation model for direct, real-time volumetric rendering of CT scans.\nRender-FM employs an encoder-decoder architecture that directly regresses 6D\nGaussian Splatting (6DGS) parameters from CT volumes, eliminating per-scan\noptimization through large-scale pre-training on diverse medical data. By\nintegrating robust feature extraction with the expressive power of 6DGS, our\napproach efficiently generates high-quality, real-time interactive 3D\nvisualizations across diverse clinical CT data. Experiments demonstrate that\nRender-FM achieves visual fidelity comparable or superior to specialized\nper-scan methods while drastically reducing preparation time from nearly an\nhour to seconds for a single inference step. This advancement enables seamless\nintegration into real-time surgical planning and diagnostic workflows. The\nproject page is: https://gaozhongpai.github.io/renderfm/.",
    "pdf_url": "http://arxiv.org/pdf/2505.17338v1",
    "published": "2025-05-22T23:18:30+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17337v1",
    "title": "PREAMBLE and IMRECEIVING for Improved Large Message Handling in libp2p GossipSub",
    "authors": [
      "Muhammad Umar Farooq",
      "Daniel Kaiser"
    ],
    "abstract": "Large message transmissions in libp2p GossipSub lead to longer than expected\nnetwork-wide message dissemination times and very high bandwidth utilization.\nThis article identifies key issues responsible for this behavior and proposes\nmodifications to the protocol for transmitting large messages. These\nmodifications preserve the GossipSub resilience and fit well into the current\nalgorithm. The proposed changes are rigorously evaluated for performance using\nthe shadow simulator. Results reveal that the suggested changes reduce\nbandwidth utilization by up to 61% and message dissemination time by up to 35%\nunder different traffic conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.17337v1",
    "published": "2025-05-22T23:18:24+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17336v1",
    "title": "Polariton cascade phonon laser",
    "authors": [
      "I. Papuccio-Fernández",
      "A. A. Reynoso",
      "A. E. Bruchhausen",
      "A. S. Kuznetsov",
      "K. Biermann",
      "P. V. Santos",
      "G. Usaj",
      "A. Fainstein"
    ],
    "abstract": "Phonon lasers, as their photon counterparts, rely on the physics of\nstimulated emission. Arguably, because light does not require a material\nsubstrate to propagate, while sound does, the impact of the two technologies\nhas however been highly contrasting, with \"sasers\" (for sound amplification by\nstimulated emission of radiation) mostly remaining as an academic curiosity.\nThis might be changing due to the possibility to use coherent sound generation\nfor on-chip processing of information at ultra-high frequencies, and in the\nquantum realm, in integrated photonic and optomechanical devices. Inspired by\nthe concept of unipolar lasers based on the quantum engineering of states in\nsemiconductor heterostructures, we propose and implement a quantum cascade\nphonon laser (QCPL). A condensate of exciton-photon quasiparticles (polaritons)\nis optically induced in a microstructured semiconductor device to jump down a\nladder of engineered levels. This down-cascade is accompanied by the efficient\nstimulated emission of phonons of $\\sim 20$, $\\sim 60$, and $\\sim 100$~GHz,\nwhich are designed to strongly interact with the polaritons on the same chip.\nThe proposed concept opens the path for the design of integrated high-frequency\noptomechanical devices, as for example for non-reciprocal photon transport and\nmulti-wavelength Brillouin lasers.",
    "pdf_url": "http://arxiv.org/pdf/2505.17336v1",
    "published": "2025-05-22T23:15:58+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall",
      "cond-mat.other"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.17335v2",
    "title": "Secure Parsing and Serializing with Separation Logic Applied to CBOR, CDDL, and COSE",
    "authors": [
      "Tahina Ramananandro",
      "Gabriel Ebner",
      "Guido Martínez",
      "Nikhil Swamy"
    ],
    "abstract": "Incorrect handling of security-critical data formats, particularly in\nlow-level languages, are the root cause of many security vulnerabilities.\nProvably correct parsing and serialization tools that target languages like C\ncan help. Towards this end, we present PulseParse, a library of verified parser\nand serializer combinators for non-malleable binary formats. Specifications and\nproofs in PulseParse are in separation logic, offering a more abstract and\ncompositional interface, with full support for data validation, parsing, and\nserialization. PulseParse also supports a class of recursive formats -- with a\nfocus on security and handling adversarial inputs, we show how to parse such\nformats with only a constant amount of stack space.\n  We use PulseParse at scale by providing the first formalization of CBOR, a\nrecursive, binary data format standard, with growing adoption in various\nindustrial standards. We prove that the deterministic fragment of CBOR is\nnon-malleable and provide EverCBOR, a verified library in both C and Rust to\nvalidate, parse, and serialize CBOR objects implemented using PulseParse. Next,\nwe provide the first formalization of CDDL, a schema definition language for\nCBOR. We identify well-formedness conditions on CDDL definitions that ensure\nthat they yield unambiguous, non-malleable formats, and implement EverCDDL, a\ntool that checks that a CDDL definition is well-formed, and then produces\nverified parsers and serializers for it.\n  To evaluate our work, we use EverCDDL to generate verified parsers and\nserializers for various security-critical applications. Notably, we build a\nformally verified implementation of COSE signing, a standard for\ncryptographically signed objects. We also use our toolchain to generate\nverified code for other standards specified in CDDL, including DICE Protection\nEnvironment, a secure boot protocol standard.",
    "pdf_url": "http://arxiv.org/pdf/2505.17335v2",
    "published": "2025-05-22T23:12:03+00:00",
    "categories": [
      "cs.CR",
      "cs.PL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.14778v3",
    "title": "A Riemannian Characterization of Compact Affine Manifolds with Parallel Volume",
    "authors": [
      "Mihail Cocos"
    ],
    "abstract": "We establish that any affine manifold $(M,\\nabla)$ endowed with a parallel\nvolume form $\\omega,$ admits, in any conformal class of Riemannian metrics, a\nrepresentative $H$ for which $\\nabla$ is the Levi-Civita connection. This\nprovides a constructive proof that such manifolds are necessarily complete,\ngeneralizing the \"if\" direction of Markus' conjecture \\cite{markus1962}.\nMoreover, our result demonstrates that these structures are intrinsically\nRiemannian-flat, a stronger conclusion than the affine completeness asserted by\nMarkus. The metric $H$ arises naturally from the Hessian of volume-normalized\ndistance functions and is shown to be globally smooth and $\\nabla$-parallel,\nextending results of \\cite{goldman1982} and \\cite{benzecri1955} to higher\ndimensions with additional geometric structure. The construction proceeds\nthrough three technically novel steps: (1) local parallel metric normalization\nusing the given volume form, (2) explicit Hessian calculations in adapted\ncoordinates, and (3) gluing via affine transition maps that preserve the\nvolumetric geometry. This approach reveals an unexpected rigidity in flat\naffine manifolds with compatible volume that goes beyond the topological\nconstraints studied in \\cite{fried1980}.",
    "pdf_url": "http://arxiv.org/pdf/2506.14778v3",
    "published": "2025-05-22T23:11:14+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17334v1",
    "title": "The phase-space of tailed radio galaxies in massive clusters",
    "authors": [
      "Stefan van der Jagt",
      "Erik Osinga",
      "Reinout J. van Weeren",
      "George K. Miley",
      "Ian D. Roberts",
      "Andrea Botteon",
      "Alessandro Ignesti"
    ],
    "abstract": "The radio jets of radio galaxies in galaxy clusters are often bent due to the\nram pressure of the intracluster medium. In this paper we start with a\nwell-defined sample of galaxy clusters and subsequently identifying tailed\nradio sources in these known environments. Our sample consists of 81 galaxy\nclusters from the Planck ESZ cluster sample. We present a catalogue of 127\nextended cluster radio sources, including brightest cluster galaxies, obtained\nby visually inspecting Karl G. Jansky Very Large Array (1-2 GHz) observations.\nWe have determined the bending angle of 109 well-structured sources, and\nclassified them accordingly: 84 narrow-angle tailed sources (NATs), 16\nwide-angle tailed sources (WATs), and 9 non-bent radio sources. We find a\nnegative correlation between the bending angle and the distance to the cluster\ncentre (impact radius), and we observe that NATs generally have smaller impact\nradii than the regular galaxy population and WATs. We present a phase-space\ndiagram of tailed radio galaxy velocities and impact radii and find that NATs\nhave a significant excess in the high-velocity and low-impact radius region of\nphase space, indicating they undergo the largest amount of ram pressure\nbending. We compared the results from our sample with those for jellyfish\ngalaxies, and suggest that the mechanism responsible for bending the radio\ntails is similar to the stripping of gas in jellyfish galaxies, although tailed\nradio galaxies are more concentrated in the centre of the phase space. Finally,\nwe find that NATs and WATs have the same occurrence ratio in merging and\nrelaxed clusters. However, their distribution in the phase-space is\nsignificantly different. We report an excess of NATs in the high-velocity and\nlow-impact-radius phase-space region in merging clusters, and an excess of\nrelaxed clusters in the low-velocity and low-impact-radius region.",
    "pdf_url": "http://arxiv.org/pdf/2505.17334v1",
    "published": "2025-05-22T23:04:56+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17333v2",
    "title": "Temporal Differential Fields for 4D Motion Modeling via Image-to-Video Synthesis",
    "authors": [
      "Xin You",
      "Minghui Zhang",
      "Hanxiao Zhang",
      "Jie Yang",
      "Nassir Navab"
    ],
    "abstract": "Temporal modeling on regular respiration-induced motions is crucial to\nimage-guided clinical applications. Existing methods cannot simulate temporal\nmotions unless high-dose imaging scans including starting and ending frames\nexist simultaneously. However, in the preoperative data acquisition stage, the\nslight movement of patients may result in dynamic backgrounds between the first\nand last frames in a respiratory period. This additional deviation can hardly\nbe removed by image registration, thus affecting the temporal modeling. To\naddress that limitation, we pioneeringly simulate the regular motion process\nvia the image-to-video (I2V) synthesis framework, which animates with the first\nframe to forecast future frames of a given length. Besides, to promote the\ntemporal consistency of animated videos, we devise the Temporal Differential\nDiffusion Model to generate temporal differential fields, which measure the\nrelative differential representations between adjacent frames. The prompt\nattention layer is devised for fine-grained differential fields, and the field\naugmented layer is adopted to better interact these fields with the I2V\nframework, promoting more accurate temporal variation of synthesized videos.\nExtensive results on ACDC cardiac and 4D Lung datasets reveal that our approach\nsimulates 4D videos along the intrinsic motion trajectory, rivaling other\ncompetitive methods on perceptual similarity and temporal consistency. Codes\nwill be available soon.",
    "pdf_url": "http://arxiv.org/pdf/2505.17333v2",
    "published": "2025-05-22T23:01:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17332v1",
    "title": "SweEval: Do LLMs Really Swear? A Safety Benchmark for Testing Limits for Enterprise Use",
    "authors": [
      "Hitesh Laxmichand Patel",
      "Amit Agarwal",
      "Arion Das",
      "Bhargava Kumar",
      "Srikant Panda",
      "Priyaranjan Pattnayak",
      "Taki Hasan Rafi",
      "Tejaswini Kumar",
      "Dong-Kyu Chae"
    ],
    "abstract": "Enterprise customers are increasingly adopting Large Language Models (LLMs)\nfor critical communication tasks, such as drafting emails, crafting sales\npitches, and composing casual messages. Deploying such models across different\nregions requires them to understand diverse cultural and linguistic contexts\nand generate safe and respectful responses. For enterprise applications, it is\ncrucial to mitigate reputational risks, maintain trust, and ensure compliance\nby effectively identifying and handling unsafe or offensive language. To\naddress this, we introduce SweEval, a benchmark simulating real-world scenarios\nwith variations in tone (positive or negative) and context (formal or\ninformal). The prompts explicitly instruct the model to include specific swear\nwords while completing the task. This benchmark evaluates whether LLMs comply\nwith or resist such inappropriate instructions and assesses their alignment\nwith ethical frameworks, cultural nuances, and language comprehension\ncapabilities. In order to advance research in building ethically aligned AI\nsystems for enterprise use and beyond, we release the dataset and code:\nhttps://github.com/amitbcp/multilingual_profanity.",
    "pdf_url": "http://arxiv.org/pdf/2505.17332v1",
    "published": "2025-05-22T22:56:58+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "I.2.7; I.2.6"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17331v2",
    "title": "ECHO-LLaMA: Efficient Caching for High-Performance LLaMA Training",
    "authors": [
      "Maryam Dialameh",
      "Rezaul Karim",
      "Hossein Rajabzadeh",
      "Omar Mohamed Awad",
      "Hyock Ju Kwon",
      "Boxing Chen",
      "Walid Ahmed",
      "Yang Liu"
    ],
    "abstract": "This paper introduces ECHO-LLaMA, an efficient LLaMA architecture designed to\nimprove both the training speed and inference throughput of LLaMA architectures\nwhile maintaining its learning capacity. ECHO-LLaMA transforms LLaMA models\ninto shared KV caching across certain layers, significantly reducing KV\ncomputational complexity while maintaining or improving language performance.\nExperimental results demonstrate that ECHO-LLaMA achieves up to 77\\% higher\ntoken-per-second throughput during training, up to 16\\% higher Model FLOPs\nUtilization (MFU), and up to 14\\% lower loss when trained on an equal number of\ntokens. Furthermore, on the 1.1B model, ECHO-LLaMA delivers approximately 7\\%\nhigher test-time throughput compared to the baseline. By introducing a\ncomputationally efficient adaptation mechanism, ECHO-LLaMA offers a scalable\nand cost-effective solution for pretraining and finetuning large language\nmodels, enabling faster and more resource-efficient training without\ncompromising performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.17331v2",
    "published": "2025-05-22T22:54:21+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17330v1",
    "title": "FS-DAG: Few Shot Domain Adapting Graph Networks for Visually Rich Document Understanding",
    "authors": [
      "Amit Agarwal",
      "Srikant Panda",
      "Kulbhushan Pachauri"
    ],
    "abstract": "In this work, we propose Few Shot Domain Adapting Graph (FS-DAG), a scalable\nand efficient model architecture for visually rich document understanding\n(VRDU) in few-shot settings. FS-DAG leverages domain-specific and\nlanguage/vision specific backbones within a modular framework to adapt to\ndiverse document types with minimal data. The model is robust to practical\nchallenges such as handling OCR errors, misspellings, and domain shifts, which\nare critical in real-world deployments. FS-DAG is highly performant with less\nthan 90M parameters, making it well-suited for complex real-world applications\nfor Information Extraction (IE) tasks where computational resources are\nlimited. We demonstrate FS-DAG's capability through extensive experiments for\ninformation extraction task, showing significant improvements in convergence\nspeed and performance compared to state-of-the-art methods. Additionally, this\nwork highlights the ongoing progress in developing smaller, more efficient\nmodels that do not compromise on performance. Code :\nhttps://github.com/oracle-samples/fs-dag",
    "pdf_url": "http://arxiv.org/pdf/2505.17330v1",
    "published": "2025-05-22T22:53:58+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "I.2.7; I.5.4; I.7"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.12034v2",
    "title": "Human-like Forgetting Curves in Deep Neural Networks",
    "authors": [
      "Dylan Kline"
    ],
    "abstract": "This study bridges cognitive science and neural network design by examining\nwhether artificial models exhibit human-like forgetting curves. Drawing upon\nEbbinghaus' seminal work on memory decay and principles of spaced repetition,\nwe propose a quantitative framework to measure information retention in neural\nnetworks. Our approach computes the recall probability by evaluating the\nsimilarity between a network's current hidden state and previously stored\nprototype representations. This retention metric facilitates the scheduling of\nreview sessions, thereby mitigating catastrophic forgetting during deployment\nand enhancing training efficiency by prompting targeted reviews. Our\nexperiments with Multi-Layer Perceptrons reveal human-like forgetting curves,\nwith knowledge becoming increasingly robust through scheduled reviews. This\nalignment between neural network forgetting curves and established human memory\nmodels identifies neural networks as an architecture that naturally emulates\nhuman memory decay and can inform state-of-the-art continual learning\nalgorithms.",
    "pdf_url": "http://arxiv.org/pdf/2506.12034v2",
    "published": "2025-05-22T22:51:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17329v1",
    "title": "Transformer brain encoders explain human high-level visual responses",
    "authors": [
      "Hossein Adeli",
      "Minni Sun",
      "Nikolaus Kriegeskorte"
    ],
    "abstract": "A major goal of neuroscience is to understand brain computations during\nvisual processing in naturalistic settings. A dominant approach is to use\nimage-computable deep neural networks trained with different task objectives as\na basis for linear encoding models. However, in addition to requiring tuning a\nlarge number of parameters, the linear encoding approach ignores the structure\nof the feature maps both in the brain and the models. Recently proposed\nalternatives have focused on decomposing the linear mapping to spatial and\nfeature components but focus on finding static receptive fields for units that\nare applicable only in early visual areas. In this work, we employ the\nattention mechanism used in the transformer architecture to study how\nretinotopic visual features can be dynamically routed to category-selective\nareas in high-level visual processing. We show that this computational motif is\nsignificantly more powerful than alternative methods in predicting brain\nactivity during natural scene viewing, across different feature basis models\nand modalities. We also show that this approach is inherently more\ninterpretable, without the need to create importance maps, by interpreting the\nattention routing signal for different high-level categorical areas. Our\napproach proposes a mechanistic model of how visual information from\nretinotopic maps can be routed based on the relevance of the input content to\ndifferent category-selective regions.",
    "pdf_url": "http://arxiv.org/pdf/2505.17329v1",
    "published": "2025-05-22T22:48:15+00:00",
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.17328v1",
    "title": "Game-invariant Features Through Contrastive and Domain-adversarial Learning",
    "authors": [
      "Dylan Kline"
    ],
    "abstract": "Foundational game-image encoders often overfit to game-specific visual\nstyles, undermining performance on downstream tasks when applied to new games.\nWe present a method that combines contrastive learning and domain-adversarial\ntraining to learn game-invariant visual features. By simultaneously encouraging\nsimilar content to cluster and discouraging game-specific cues via an\nadversarial domain classifier, our approach produces embeddings that generalize\nacross diverse games. Experiments on the Bingsu game-image dataset (10,000\nscreenshots from 10 games) demonstrate that after only a few training epochs,\nour model's features no longer cluster by game, indicating successful\ninvariance and potential for improved cross-game transfer (e.g., glitch\ndetection) with minimal fine-tuning. This capability paves the way for more\ngeneralizable game vision models that require little to no retraining on new\ngames.",
    "pdf_url": "http://arxiv.org/pdf/2505.17328v1",
    "published": "2025-05-22T22:45:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17327v1",
    "title": "GPT Editors, Not Authors: The Stylistic Footprint of LLMs in Academic Preprints",
    "authors": [
      "Soren DeHaan",
      "Yuanze Liu",
      "Johan Bollen",
      "Sa'ul A. Blanco"
    ],
    "abstract": "The proliferation of Large Language Models (LLMs) in late 2022 has impacted\nacademic writing, threatening credibility, and causing institutional\nuncertainty. We seek to determine the degree to which LLMs are used to generate\ncritical text as opposed to being used for editing, such as checking for\ngrammar errors or inappropriate phrasing. In our study, we analyze arXiv papers\nfor stylistic segmentation, which we measure by varying a PELT threshold\nagainst a Bayesian classifier trained on GPT-regenerated text. We find that\nLLM-attributed language is not predictive of stylistic segmentation, suggesting\nthat when authors use LLMs, they do so uniformly, reducing the risk of\nhallucinations being introduced into academic preprints.",
    "pdf_url": "http://arxiv.org/pdf/2505.17327v1",
    "published": "2025-05-22T22:44:27+00:00",
    "categories": [
      "cs.CL",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "68U99",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17326v1",
    "title": "VoxRAG: A Step Toward Transcription-Free RAG Systems in Spoken Question Answering",
    "authors": [
      "Zackary Rackauckas",
      "Julia Hirschberg"
    ],
    "abstract": "We introduce VoxRAG, a modular speech-to-speech retrieval-augmented\ngeneration system that bypasses transcription to retrieve semantically relevant\naudio segments directly from spoken queries. VoxRAG employs silence-aware\nsegmentation, speaker diarization, CLAP audio embeddings, and FAISS retrieval\nusing L2-normalized cosine similarity. We construct a 50-query test set\nrecorded as spoken input by a native English speaker. Retrieval quality was\nevaluated using LLM-as-a-judge annotations. For very relevant segments, cosine\nsimilarity achieved a Recall@10 of 0.34. For somewhat relevant segments,\nRecall@10 rose to 0.60 and nDCG@10 to 0.27, highlighting strong topical\nalignment. Answer quality was judged on a 0--2 scale across relevance,\naccuracy, completeness, and precision, with mean scores of 0.84, 0.58, 0.56,\nand 0.46 respectively. While precision and retrieval quality remain key\nlimitations, VoxRAG shows that transcription-free speech-to-speech retrieval is\nfeasible in RAG systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17326v1",
    "published": "2025-05-22T22:42:40+00:00",
    "categories": [
      "cs.IR",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17325v2",
    "title": "Uniform Turán density -- palette classification",
    "authors": [
      "Daniel Král'",
      "Filip Kučerák",
      "Ander Lamaison",
      "Gábor Tardos"
    ],
    "abstract": "In the 1980s, Erd\\H{o}s and S\\'os initiated the study of Tur\\'an hypergraph\nproblems with a uniformity condition on the distribution of edges, i.e.,\ndetermining density thresholds for the existence of a hypergraph H in a host\nhypergraph with edges uniformly distributed. In particular, Erd\\H{o}s and S\\'os\nasked to determine the uniform Tur\\'an densities of the hypergraphs\n$K_4^{(3)-}$ and $K_4^{(3)}$. After more than 30 years, the former was solved\nby Glebov, Kr\\'al' and Volec [Israel J. Math. 211 (2016), 349-366] and Reiher,\nR\\\"odl and Schacht [J. Eur. Math. Soc. 20 (2018), 1139-1159], while the latter\nstill remains open. In these two cases and several additional cases, the tight\nlower bounds are provided by a so-called palette construction.\n  Lamaison [arXiv:2408.09643] has recently showed that the uniform Tur\\'an\ndensity of a 3-uniform hypergraph H is equal to the supremum of the densities\nof palettes that H is not colorable with. We give a necessary and sufficient\ncondition, which is easy to verify, on the existence of a 3-uniform hypergraph\ncolorable by a set of palettes and not colorable by another given set of\npalettes. We also demonstrate how our result can be used to prove the existence\nof 3-uniform hypergraphs with specific values of the uniform Tur\\'an density.",
    "pdf_url": "http://arxiv.org/pdf/2505.17325v2",
    "published": "2025-05-22T22:37:36+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17324v1",
    "title": "Non-excitonic mechanism for electronic and structural phase transitions in Ta2Ni(Se,S)5",
    "authors": [
      "Weichen Tang",
      "Zhenglu Li",
      "Cheng Chen",
      "Yu He",
      "Steven G. Louie"
    ],
    "abstract": "We present a first-principles study based on density functional theory (DFT)\non the electronic and structural properties of Ta2NiSe5, a layered transition\nmetal chalcogenide that has been considered as a possible candidate for an\nexcitonic insulator. Our systematic DFT results however provide a non-excitonic\nmechanism for the experimentally observed electronic and structural phase\ntransitions in Ta2NiSe5, in particular explaining why sulfur substitution of\nselenium reduces the distortion angle in the low-temperature phase and\npotassium dosing closes the gap in the electronic structure. Moreover, the\ncalculations show that these two effects couple to each other. Further, our\nfirst-principles calculations predict several changes in both the crystal\nstructure and electronic structure under the effects of uniform charge dosing\nand uniaxial strain, which could be tested experimentally.",
    "pdf_url": "http://arxiv.org/pdf/2505.17324v1",
    "published": "2025-05-22T22:26:16+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.18213v2",
    "title": "AIDRIN 2.0: A Framework to Assess Data Readiness for AI",
    "authors": [
      "Kaveen Hiniduma",
      "Dylan Ryan",
      "Suren Byna",
      "Jean Luca Bez",
      "Ravi Madduri"
    ],
    "abstract": "AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve\ndata preparedness for AI applications. It addresses critical data readiness\ndimensions such as data quality, bias, fairness, and privacy. This paper\ndetails enhancements to AIDRIN by focusing on user interface improvements and\nintegration with a privacy-preserving federated learning (PPFL) framework. By\nrefining the UI and enabling smooth integration with decentralized AI\npipelines, AIDRIN becomes more accessible and practical for users with varying\ntechnical expertise. Integrating with an existing PPFL framework ensures that\ndata readiness and privacy are prioritized in federated learning environments.\nA case study involving a real-world dataset demonstrates AIDRIN's practical\nvalue in identifying data readiness issues that impact AI model performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.18213v2",
    "published": "2025-05-22T22:24:31+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.17323v1",
    "title": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)",
    "authors": [
      "Ruaridh Mon-Williams",
      "Max Taylor-Davies",
      "Elizabeth Mieczkowski",
      "Natalia Velez",
      "Neil R. Bramley",
      "Yanwei Wang",
      "Thomas L. Griffiths",
      "Christopher G. Lucas"
    ],
    "abstract": "Humans are remarkably adept at collaboration, able to infer the strengths and\nweaknesses of new partners in order to work successfully towards shared goals.\nTo build AI systems with this capability, we must first understand its building\nblocks: does such flexibility require explicit, dedicated mechanisms for\nmodelling others -- or can it emerge spontaneously from the pressures of\nopen-ended cooperative interaction? To investigate this question, we train\nsimple model-free RNN agents to collaborate with a population of diverse\npartners. Using the `Overcooked-AI' environment, we collect data from thousands\nof collaborative teams, and analyse agents' internal hidden states. Despite a\nlack of additional architectural features, inductive biases, or auxiliary\nobjectives, the agents nevertheless develop structured internal representations\nof their partners' task abilities, enabling rapid adaptation and generalisation\nto novel collaborators. We investigated these internal models through probing\ntechniques, and large-scale behavioural analysis. Notably, we find that\nstructured partner modelling emerges when agents can influence partner\nbehaviour by controlling task allocation. Our results show that partner\nmodelling can arise spontaneously in model-free agents -- but only under\nenvironmental conditions that impose the right kind of social pressure.",
    "pdf_url": "http://arxiv.org/pdf/2505.17323v1",
    "published": "2025-05-22T22:24:12+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.20314v3",
    "title": "$Δ$-Nets: Interaction-Based System for Optimal Parallel $λ$-Reduction",
    "authors": [
      "Daniel Augusto Rizzi Salvadori"
    ],
    "abstract": "I present a model of universal parallel computation called $\\Delta$-Nets, and\na method to translate $\\lambda$-terms into $\\Delta$-nets and back. Together,\nthe model and the method constitute an algorithm for optimal parallel\n$\\lambda$-reduction, solving the longstanding enigma with groundbreaking\nclarity. I show that the $\\lambda$-calculus can be understood as a projection\nof $\\Delta$-Nets$-$one that severely restricts the structure of sharing, among\nother drawbacks. Unhindered by these restrictions, the $\\Delta$-Nets model\nopens the door to new parallel programming language implementations and\ncomputer architectures that are more efficient and performant than previously\npossible.",
    "pdf_url": "http://arxiv.org/pdf/2505.20314v3",
    "published": "2025-05-22T22:23:59+00:00",
    "categories": [
      "cs.LO",
      "cs.AR",
      "cs.DC",
      "cs.PL",
      "68Q04 (Primary) 68Q85, 68Q06 (Secondary)",
      "F.0; F.1.1"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17322v1",
    "title": "From Compression to Expansion: A Layerwise Analysis of In-Context Learning",
    "authors": [
      "Jiachen Jiang",
      "Yuxin Dong",
      "Jinxin Zhou",
      "Zhihui Zhu"
    ],
    "abstract": "In-context learning (ICL) enables large language models (LLMs) to adapt to\nnew tasks without weight updates by learning from demonstration sequences.\nWhile ICL shows strong empirical performance, its internal representational\nmechanisms are not yet well understood. In this work, we conduct a statistical\ngeometric analysis of ICL representations to investigate how task-specific\ninformation is captured across layers. Our analysis reveals an intriguing\nphenomenon, which we term *Layerwise Compression-Expansion*: early layers\nprogressively produce compact and discriminative representations that encode\ntask information from the input demonstrations, while later layers expand these\nrepresentations to incorporate the query and generate the prediction. This\nphenomenon is observed consistently across diverse tasks and a range of\ncontemporary LLM architectures. We demonstrate that it has important\nimplications for ICL performance -- improving with model size and the number of\ndemonstrations -- and for robustness in the presence of noisy examples. To\nfurther understand the effect of the compact task representation, we propose a\nbias-variance decomposition and provide a theoretical analysis showing how\nattention mechanisms contribute to reducing both variance and bias, thereby\nenhancing performance as the number of demonstrations increases. Our findings\nreveal an intriguing layerwise dynamic in ICL, highlight how structured\nrepresentations emerge within LLMs, and showcase that analyzing internal\nrepresentations can facilitate a deeper understanding of model behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.17322v1",
    "published": "2025-05-22T22:22:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17321v1",
    "title": "Control of Renewable Energy Communities using AI and Real-World Data",
    "authors": [
      "Tiago Fonseca",
      "Clarisse Sousa",
      "Ricardo Venâncio",
      "Pedro Pires",
      "Ricardo Severino",
      "Paulo Rodrigues",
      "Pedro Paiva",
      "Luis Lino Ferreira"
    ],
    "abstract": "The electrification of transportation and the increased adoption of\ndecentralized renewable energy generation have added complexity to managing\nRenewable Energy Communities (RECs). Integrating Electric Vehicle (EV) charging\nwith building energy systems like heating, ventilation, air conditioning\n(HVAC), photovoltaic (PV) generation, and battery storage presents significant\nopportunities but also practical challenges. Reinforcement learning (RL),\nparticularly MultiAgent Deep Deterministic Policy Gradient (MADDPG) algorithms,\nhave shown promising results in simulation, outperforming heuristic control\nstrategies. However, translating these successes into real-world deployments\nfaces substantial challenges, including incomplete and noisy data, integration\nof heterogeneous subsystems, synchronization issues, unpredictable occupant\nbehavior, and missing critical EV state-of-charge (SoC) information. This paper\nintroduces a framework designed explicitly to handle these complexities and\nbridge the simulation to-reality gap. The framework incorporates EnergAIze, a\nMADDPG-based multi-agent control strategy, and specifically addresses\nchallenges related to real-world data collection, system integration, and user\nbehavior modeling. Preliminary results collected from a real-world operational\nREC with four residential buildings demonstrate the practical feasibility of\nour approach, achieving an average 9% reduction in daily peak demand and a 5%\ndecrease in energy costs through optimized load scheduling and EV charging\nbehaviors. These outcomes underscore the framework's effectiveness, advancing\nthe practical deployment of intelligent energy management solutions in RECs.",
    "pdf_url": "http://arxiv.org/pdf/2505.17321v1",
    "published": "2025-05-22T22:20:09+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.17320v1",
    "title": "Benchmarking Expressive Japanese Character Text-to-Speech with VITS and Style-BERT-VITS2",
    "authors": [
      "Zackary Rackauckas",
      "Julia Hirschberg"
    ],
    "abstract": "Synthesizing expressive Japanese character speech poses unique challenges due\nto pitch-accent sensitivity and stylistic variability. This paper benchmarks\ntwo open-source text-to-speech models--VITS and Style-BERT-VITS2 JP Extra\n(SBV2JE)--on in-domain, character-driven Japanese speech. Using three\ncharacter-specific datasets, we evaluate models across naturalness (mean\nopinion and comparative mean opinion score), intelligibility (word error rate),\nand speaker consistency. SBV2JE matches human ground truth in naturalness (MOS\n4.37 vs. 4.38), achieves lower WER, and shows slight preference in CMOS.\nEnhanced by pitch-accent controls and a WavLM-based discriminator, SBV2JE\nproves effective for applications like language learning and character dialogue\ngeneration, despite higher computational demands.",
    "pdf_url": "http://arxiv.org/pdf/2505.17320v1",
    "published": "2025-05-22T22:18:55+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17319v1",
    "title": "Normal Singular Geodesics of a Conformally Generic Sub-Riemannian Metric",
    "authors": [
      "Shahriar Aslani"
    ],
    "abstract": "We prove that a Ma\\~n\\'e generic real-analytic $D$-Hamiltonian H, subjected\nto a totally non-holonomic real-analytic distribution $D$, has no non-trivial\nnormal $D$-singular orbits of minimal rank. If $D$ has co-rank 1, this implies\nthat $H + u$, where $u$ is a generic real-analytic potential, does not admit\nnon-trivial normal $D$-singular orbits.",
    "pdf_url": "http://arxiv.org/pdf/2505.17319v1",
    "published": "2025-05-22T22:17:48+00:00",
    "categories": [
      "math.DS",
      "math.DG",
      "53C17, 37J06"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.17318v1",
    "title": "Galaxy-scale lens search in the PEARLS NEP TDF and CEERS JWST fields",
    "authors": [
      "Giovanni Ferrami",
      "Nathan J. Adams",
      "Lewi Westcott",
      "Thomas Harvey",
      "Rolf A. Jansen",
      "Jose M. Diego",
      "Vince Estrada-Carpente",
      "Rogier A. Windhorst",
      "Christopher J. Conselice",
      "Anton M. Koekemoer",
      "Jordan C. J. D'Silva",
      "Christopher Willmer",
      "J. Stuart B. Wyithe",
      "Michael J. Rutkowski",
      "Seth H. Cohen",
      "Brenda L. Frye",
      "Norman A. Grogin"
    ],
    "abstract": "We present four galaxy scale lenses discovered in two JWST blank-fields: the\n~ 54 arcmin^2 of the PEARLS North-Ecliptic-Pole Time-Domain Field (NEP TDF) and\nin the ~ 90 arcmin^2 of CEERS. We perform the search by visual inspection of\nNIRCam photometric data, obtaining an initial list of 16 lens candidates. We\ndown-select this list to 4 high-confidence lens candidates, based on lens\nmodelling of the image configuration and photometric redshift measurements for\nboth the source and the deflector. We compare our results to samples of lenses\nobtained in ground-based and space-based lens searches and theoretical\nexpectations. We expect that JWST observations of field galaxies will yield\napproximately 1 galaxy scale lens every three to five NIRCam pointings of\ncomparable depth to these observations (~ 9 arcmin^2 each). This shows that\nJWST, compared to other lens searches, can yield an extremely high number of\nsecure lenses per unit area, with redshift and size distributions complementary\nto lens samples obtained from ground-based and wide-area surveys. We estimate\nthat a single JWST pure-parallel survey of comparable depth could yield $\\sim\n70$ galaxy scale lenses, with a third of them having z_lens>1 and z_source>3.",
    "pdf_url": "http://arxiv.org/pdf/2505.17318v1",
    "published": "2025-05-22T22:13:58+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.17317v2",
    "title": "Optimizing Image Capture for Computer Vision-Powered Taxonomic Identification and Trait Recognition of Biodiversity Specimens",
    "authors": [
      "Alyson East",
      "Elizabeth G. Campolongo",
      "Luke Meyers",
      "S M Rayeed",
      "Samuel Stevens",
      "Iuliia Zarubiieva",
      "Isadora E. Fluck",
      "Jennifer C. Girón",
      "Maximiliane Jousse",
      "Scott Lowe",
      "Kayla I Perry",
      "Isabelle Betancourt",
      "Noah Charney",
      "Evan Donoso",
      "Nathan Fox",
      "Kim J. Landsbergen",
      "Ekaterina Nepovinnykh",
      "Michelle Ramirez",
      "Parkash Singh",
      "Khum Thapa-Magar",
      "Matthew Thompson",
      "Evan Waite",
      "Tanya Berger-Wolf",
      "Hilmar Lapp",
      "Paula Mabee",
      "Charles Stewart",
      "Graham Taylor",
      "Sydne Record"
    ],
    "abstract": "1) Biological collections house millions of specimens with digital images\nincreasingly available through open-access platforms. However, most imaging\nprotocols were developed for human interpretation without considering automated\nanalysis requirements. As computer vision applications revolutionize taxonomic\nidentification and trait extraction, a critical gap exists between current\ndigitization practices and computational analysis needs. This review provides\nthe first comprehensive practical framework for optimizing biological specimen\nimaging for computer vision applications. 2) Through interdisciplinary\ncollaboration between taxonomists, collection managers, ecologists, and\ncomputer scientists, we synthesized evidence-based recommendations addressing\nfundamental computer vision concepts and practical imaging considerations. We\nprovide immediately actionable implementation guidance while identifying\ncritical areas requiring community standards development. 3) Our framework\nencompasses ten interconnected considerations for optimizing image capture for\ncomputer vision-powered taxonomic identification and trait extraction. We\ntranslate these into practical implementation checklists, equipment selection\nguidelines, and a roadmap for community standards development including\nfilename conventions, pixel density requirements, and cross-institutional\nprotocols. 4)By bridging biological and computational disciplines, this\napproach unlocks automated analysis potential for millions of existing\nspecimens and guides future digitization efforts toward unprecedented\nanalytical capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.17317v2",
    "published": "2025-05-22T22:11:05+00:00",
    "categories": [
      "cs.CV",
      "eess.IV",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17316v1",
    "title": "Analyzing Fine-Grained Alignment and Enhancing Vision Understanding in Multimodal Language Models",
    "authors": [
      "Jiachen Jiang",
      "Jinxin Zhou",
      "Bo Peng",
      "Xia Ning",
      "Zhihui Zhu"
    ],
    "abstract": "Achieving better alignment between vision embeddings and Large Language\nModels (LLMs) is crucial for enhancing the abilities of Multimodal LLMs\n(MLLMs), particularly for recent models that rely on powerful pretrained vision\nencoders and LLMs. A common approach to connect the pretrained vision encoder\nand LLM is through a projector applied after the vision encoder. However, the\nprojector is often trained to enable the LLM to generate captions, and hence\nthe mechanism by which LLMs understand each vision token remains unclear. In\nthis work, we first investigate the role of the projector in compressing vision\nembeddings and aligning them with word embeddings. We show that the projector\nsignificantly compresses visual information, removing redundant details while\npreserving essential elements necessary for the LLM to understand visual\ncontent. We then examine patch-level alignment -- the alignment between each\nvision patch and its corresponding semantic words -- and propose a\n*multi-semantic alignment hypothesis*. Our analysis indicates that the\nprojector trained by caption loss improves patch-level alignment but only to a\nlimited extent, resulting in weak and coarse alignment. To address this issue,\nwe propose *patch-aligned training* to efficiently enhance patch-level\nalignment. Our experiments show that patch-aligned training (1) achieves\nstronger compression capability and improved patch-level alignment, enabling\nthe MLLM to generate higher-quality captions, (2) improves the MLLM's\nperformance by 16% on referring expression grounding tasks, 4% on\nquestion-answering tasks, and 3% on modern instruction-following benchmarks\nwhen using the same supervised fine-tuning (SFT) setting. The proposed method\ncan be easily extended to other multimodal models.",
    "pdf_url": "http://arxiv.org/pdf/2505.17316v1",
    "published": "2025-05-22T22:10:27+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17315v1",
    "title": "Longer Context, Deeper Thinking: Uncovering the Role of Long-Context Ability in Reasoning",
    "authors": [
      "Wang Yang",
      "Zirui Liu",
      "Hongye Jin",
      "Qingyu Yin",
      "Vipin Chaudhary",
      "Xiaotian Han"
    ],
    "abstract": "Recent language models exhibit strong reasoning capabilities, yet the\ninfluence of long-context capacity on reasoning remains underexplored. In this\nwork, we hypothesize that current limitations in reasoning stem, in part, from\ninsufficient long-context capacity, motivated by empirical observations such as\n(1) higher context window length often leads to stronger reasoning performance,\nand (2) failed reasoning cases resemble failed long-context cases. To test this\nhypothesis, we examine whether enhancing a model's long-context ability before\nSupervised Fine-Tuning (SFT) leads to improved reasoning performance.\nSpecifically, we compared models with identical architectures and fine-tuning\ndata but varying levels of long-context capacity. Our results reveal a\nconsistent trend: models with stronger long-context capacity achieve\nsignificantly higher accuracy on reasoning benchmarks after SFT. Notably, these\ngains persist even on tasks with short input lengths, indicating that\nlong-context training offers generalizable benefits for reasoning performance.\nThese findings suggest that long-context modeling is not just essential for\nprocessing lengthy inputs, but also serves as a critical foundation for\nreasoning. We advocate for treating long-context capacity as a first-class\nobjective in the design of future language models.",
    "pdf_url": "http://arxiv.org/pdf/2505.17315v1",
    "published": "2025-05-22T22:09:47+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17314v1",
    "title": "The Role of Regularity in (Hyper-)Clique Detection and Implications for Optimizing Boolean CSPs",
    "authors": [
      "Nick Fischer",
      "Marvin Künnemann",
      "Mirza Redžić",
      "Julian Stieß"
    ],
    "abstract": "Is detecting a $k$-clique in $k$-partite regular (hyper-)graphs as hard as in\nthe general case? Intuition suggests yes, but proving this -- especially for\nhypergraphs -- poses notable challenges. Concretely, we consider a strong\nnotion of regularity in $h$-uniform hypergraphs, where we essentially require\nthat any subset of at most $h-1$ is incident to a uniform number of hyperedges.\nSuch notions are studied intensively in the combinatorial block design\nliterature. We show that any $f(k)n^{g(k)}$-time algorithm for detecting\n$k$-cliques in such graphs transfers to an $f'(k)n^{g(k)}$-time algorithm for\nthe general case, establishing a fine-grained equivalence between the\n$h$-uniform hyperclique hypothesis and its natural regular analogue.\n  Equipped with this regularization result, we then fully resolve the\nfine-grained complexity of optimizing Boolean constraint satisfaction problems\nover assignments with $k$ non-zeros. Our characterization depends on the\nmaximum degree $d$ of a constraint function. Specifically, if $d\\le 1$, we\nobtain a linear-time solvable problem, if $d=2$, the time complexity is\nessentially equivalent to $k$-clique detection, and if $d\\ge 3$ the problem\nrequires exhaustive-search time under the 3-uniform hyperclique hypothesis. To\nobtain our hardness results, the regularization result plays a crucial role,\nenabling a very convenient approach when applied carefully. We believe that our\nregularization result will find further applications in the future.",
    "pdf_url": "http://arxiv.org/pdf/2505.17314v1",
    "published": "2025-05-22T22:08:00+00:00",
    "categories": [
      "cs.CC"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2505.17313v1",
    "title": "Stochastic Heat Engine Using a Single Brownian Ellipsoid",
    "authors": [
      "Soham Dutta",
      "Arnab Saha"
    ],
    "abstract": "Optical tweezers can confine position as well as orientation of a Brownian\nparticle by simultaneously exerting restoring force and torque on it. Here we\nhave proposed the theoretical model of a microscopic Stirling engine, using a\npassive Brownian ellipsoid as its working substance. The position and the\norientation degrees of freedom (DoF) of the ellipsoid in two dimensions (2D),\nboth being confined harmonically by the tweezers, are coupled to a hot and a\ncold thermal bath time-periodically. The stiffness of the force confinement is\nalso time-periodic such that it resembles a piston-like protocol which drives\nthe Brownian ellipsoid through the strokes of a Stirling cycle. The ellipsoid\ntakes heat from the hot bath and partially converts it into useful\nthermodynamic work. The extracted work and input heat shows explicit dependence\non the shape of the working substance as well as its orientational bias. The\noperational characteristics of the anisotropic Stirling engine is analyzed\nusing the variance in work and efficiency (in the quasi-static regime), where\nthe latter is bounded by both the Carnot limit as well as the isotropic\nbenchmark. Several ways have been proposed to yield maximum efficiency at a\nminimum fluctuation in the output. The dissipative coupling between the\nposition and orientation of the ellipsoid, that arises due to its\nspherical-asymmetry (or, shape anisotropy) and a finite mean orientation, plays\nan important role to optimize the engine characteristics. Finally, we have\nanalytically explored the slightly anisotropic regime, where the coupling is\nlinearized by suitably tuning the system parameters. The average extracted work\nhas also been calculated in this case, which shows an excellent agreement with\nthe numerical results of the fully anisotropic system, when subjected to the\nstipulated range of parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.17313v1",
    "published": "2025-05-22T22:06:14+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.17312v3",
    "title": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking in Large Language Models",
    "authors": [
      "Xiangqi Wang",
      "Yue Huang",
      "Yanbo Wang",
      "Xiaonan Luo",
      "Kehan Guo",
      "Yujun Zhou",
      "Xiangliang Zhang"
    ],
    "abstract": "LLMs often need effective configurations, like temperature and reasoning\nsteps, to handle tasks requiring sophisticated reasoning and problem-solving,\nranging from joke generation to mathematical reasoning. Existing prompting\napproaches usually adopt general-purpose, fixed configurations that work 'well\nenough' across tasks but seldom achieve task-specific optimality. To address\nthis gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM\nto automate adaptive reasoning configurations for tasks requiring different\ntypes of thinking. AdaReasoner is trained using a reinforcement learning (RL)\nframework, combining a factorized action space with a targeted exploration\nstrategy, along with a pretrained reward model to optimize the policy model for\nreasoning configurations with only a few-shot guide. AdaReasoner is backed by\ntheoretical guarantees and experiments of fast convergence and a sublinear\npolicy gap. Across six different LLMs and a variety of reasoning tasks, it\nconsistently outperforms standard baselines, preserves out-of-distribution\nrobustness, and yield gains on knowledge-intensive tasks through tailored\nprompts.",
    "pdf_url": "http://arxiv.org/pdf/2505.17312v3",
    "published": "2025-05-22T22:06:11+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.18212v1",
    "title": "Towards medical AI misalignment: a preliminary study",
    "authors": [
      "Barbara Puccio",
      "Federico Castagna",
      "Allan Tucker",
      "Pierangelo Veltri"
    ],
    "abstract": "Despite their staggering capabilities as assistant tools, often exceeding\nhuman performances, Large Language Models (LLMs) are still prone to jailbreak\nattempts from malevolent users. Although red teaming practices have already\nidentified and helped to address several such jailbreak techniques, one\nparticular sturdy approach involving role-playing (which we named `Goofy Game')\nseems effective against most of the current LLMs safeguards. This can result in\nthe provision of unsafe content, which, although not harmful per se, might lead\nto dangerous consequences if delivered in a setting such as the medical domain.\nIn this preliminary and exploratory study, we provide an initial analysis of\nhow, even without technical knowledge of the internal architecture and\nparameters of generative AI models, a malicious user could construct a\nrole-playing prompt capable of coercing an LLM into producing incorrect (and\npotentially harmful) clinical suggestions. We aim to illustrate a specific\nvulnerability scenario, providing insights that can support future advancements\nin the field.",
    "pdf_url": "http://arxiv.org/pdf/2505.18212v1",
    "published": "2025-05-22T22:06:09+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.17311v1",
    "title": "Harnessing EHRs for Diffusion-based Anomaly Detection on Chest X-rays",
    "authors": [
      "Harim Kim",
      "Yuhan Wang",
      "Minkyu Ahn",
      "Heeyoul Choi",
      "Yuyin Zhou",
      "Charmgil Hong"
    ],
    "abstract": "Unsupervised anomaly detection (UAD) in medical imaging is crucial for\nidentifying pathological abnormalities without requiring extensive labeled\ndata. However, existing diffusion-based UAD models rely solely on imaging\nfeatures, limiting their ability to distinguish between normal anatomical\nvariations and pathological anomalies. To address this, we propose Diff3M, a\nmulti-modal diffusion-based framework that integrates chest X-rays and\nstructured Electronic Health Records (EHRs) for enhanced anomaly detection.\nSpecifically, we introduce a novel image-EHR cross-attention module to\nincorporate structured clinical context into the image generation process,\nimproving the model's ability to differentiate normal from abnormal features.\nAdditionally, we develop a static masking strategy to enhance the\nreconstruction of normal-like images from anomalies. Extensive evaluations on\nCheXpert and MIMIC-CXR/IV demonstrate that Diff3M achieves state-of-the-art\nperformance, outperforming existing UAD methods in medical imaging. Our code is\navailable at this http URL https://github.com/nth221/Diff3M",
    "pdf_url": "http://arxiv.org/pdf/2505.17311v1",
    "published": "2025-05-22T22:02:47+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17310v2",
    "title": "Advancing Security with Digital Twins: A Comprehensive Survey",
    "authors": [
      "Blessing Airehenbuwa",
      "Touseef Hasan",
      "Souvika Sarkar",
      "Ujjwal Guin"
    ],
    "abstract": "The proliferation of electronic devices has greatly transformed every aspect\nof human life, such as communication, healthcare, transportation, and energy.\nUnfortunately, the global electronics supply chain is vulnerable to various\nattacks, including piracy of intellectual properties, tampering,\ncounterfeiting, information leakage, side-channel, and fault injection attacks,\ndue to the complex nature of electronic products and vulnerabilities present in\nthem. Although numerous solutions have been proposed to address these threats,\nsignificant gaps remain, particularly in providing scalable and comprehensive\nprotection against emerging attacks. Digital twin, a dynamic virtual replica of\na physical system, has emerged as a promising solution to address these issues\nby providing backward traceability, end-to-end visibility, and continuous\nverification of component integrity and behavior. In this paper, we\ncomprehensively present the latest digital twin-based security implementations,\nincluding their role in cyber-physical systems, Internet of Things,\ncryptographic systems, detection of counterfeit electronics, intrusion\ndetection, fault injection, and side-channel leakage. This work considers these\ncritical security use cases within a single study to offer researchers and\npractitioners a unified reference for securing hardware with digital twins. The\npaper also explores the integration of large language models with digital twins\nfor enhanced security and discusses current challenges, solutions, and future\nresearch directions.",
    "pdf_url": "http://arxiv.org/pdf/2505.17310v2",
    "published": "2025-05-22T22:01:07+00:00",
    "categories": [
      "cs.CR",
      "cs.ET"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17309v2",
    "title": "Decoupling Representation and Learning in Genetic Programming: the LaSER Approach",
    "authors": [
      "Nam H. Le",
      "Josh Bongard"
    ],
    "abstract": "Genetic Programming (GP) has traditionally entangled the evolution of\nsymbolic representations with their performance-based evaluation, often relying\nsolely on raw fitness scores. This tight coupling makes GP solutions more\nfragile and prone to overfitting, reducing their ability to generalize. In this\nwork, we propose LaSER (Latent Semantic Representation Regression)} -- a\ngeneral framework that decouples representation evolution from lifetime\nlearning. At each generation, candidate programs produce features which are\npassed to an external learner to model the target task. This approach enables\nany function approximator, from linear models to neural networks, to serve as a\nlifetime learner, allowing expressive modeling beyond conventional symbolic\nforms.\n  Here we show for the first time that LaSER can outcompete standard GP and GP\nfollowed by linear regression when it employs non-linear methods to fit\ncoefficients to GP-generated equations against complex data sets. Further, we\nexplore how LaSER enables the emergence of innate representations, supporting\nlong-standing hypotheses in evolutionary learning such as the Baldwin Effect.\nBy separating the roles of representation and adaptation, LaSER offers a\nprincipled and extensible framework for symbolic regression and classification.",
    "pdf_url": "http://arxiv.org/pdf/2505.17309v2",
    "published": "2025-05-22T21:59:38+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.17308v1",
    "title": "Repulsive Ensembles for Bayesian Inference in Physics-informed Neural Networks",
    "authors": [
      "Philipp Pilar",
      "Markus Heinonen",
      "Niklas Wahlström"
    ],
    "abstract": "Physics-informed neural networks (PINNs) have proven an effective tool for\nsolving differential equations, in particular when considering non-standard or\nill-posed settings. When inferring solutions and parameters of the differential\nequation from data, uncertainty estimates are preferable to point estimates, as\nthey give an idea about the accuracy of the solution. In this work, we consider\nthe inverse problem and employ repulsive ensembles of PINNs (RE-PINN) for\nobtaining such estimates. The repulsion is implemented by adding a particular\nrepulsive term to the loss function, which has the property that the ensemble\npredictions correspond to the true Bayesian posterior in the limit of infinite\nensemble members. Where possible, we compare the ensemble predictions to Monte\nCarlo baselines. Whereas the standard ensemble tends to collapse to\nmaximum-a-posteriori solutions, the repulsive ensemble produces significantly\nmore accurate uncertainty estimates and exhibits higher sample diversity.",
    "pdf_url": "http://arxiv.org/pdf/2505.17308v1",
    "published": "2025-05-22T21:58:40+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.17307v1",
    "title": "Wavelet Probabilistic Recurrent Convolutional Network for Multivariate Time Series Classification",
    "authors": [
      "Pu Yang",
      "J. A. Barria"
    ],
    "abstract": "This paper presents a Wavelet Probabilistic Recurrent Convolutional Network\n(WPRCN) for Multivariate Time Series Classification (MTSC), especially\neffective in handling non-stationary environments, data scarcity and noise\nperturbations. We introduce a versatile wavelet probabilistic module designed\nto extract and analyse the probabilistic features, which can seamlessly\nintegrate with a variety of neural network architectures. This probabilistic\nmodule comprises an Adaptive Wavelet Probabilistic Feature Generator (AWPG) and\na Channel Attention-based Probabilistic Temporal Convolutional Network (APTCN).\nSuch formulation extends the application of wavelet probabilistic neural\nnetworks to deep neural networks for MTSC. The AWPG constructs an ensemble\nprobabilistic model addressing different data scarcities and non-stationarity;\nit adaptively selects the optimal ones and generates probabilistic features for\nAPTCN. The APTCN analyses the correlations of the features and forms a\ncomprehensive feature space with existing MTSC models for classification. Here,\nwe instantiate the proposed module to work in parallel with a Long Short-Term\nMemory (LSTM) network and a Causal Fully Convolutional Network (C-FCN),\ndemonstrating its broad applicability in time series analysis. The WPRCN is\nevaluated on 30 diverse MTS datasets and outperforms all the benchmark\nalgorithms on average accuracy and rank, exhibiting pronounced strength in\nhandling scarce data and physiological data subject to perturbations and\nnon-stationarities.",
    "pdf_url": "http://arxiv.org/pdf/2505.17307v1",
    "published": "2025-05-22T21:57:50+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17306v1",
    "title": "Refusal Direction is Universal Across Safety-Aligned Languages",
    "authors": [
      "Xinpeng Wang",
      "Mingyang Wang",
      "Yihong Liu",
      "Hinrich Schütze",
      "Barbara Plank"
    ],
    "abstract": "Refusal mechanisms in large language models (LLMs) are essential for ensuring\nsafety. Recent research has revealed that refusal behavior can be mediated by a\nsingle direction in activation space, enabling targeted interventions to bypass\nrefusals. While this is primarily demonstrated in an English-centric context,\nappropriate refusal behavior is important for any language, but poorly\nunderstood. In this paper, we investigate the refusal behavior in LLMs across\n14 languages using PolyRefuse, a multilingual safety dataset created by\ntranslating malicious and benign English prompts into these languages. We\nuncover the surprising cross-lingual universality of the refusal direction: a\nvector extracted from English can bypass refusals in other languages with\nnear-perfect effectiveness, without any additional fine-tuning. Even more\nremarkably, refusal directions derived from any safety-aligned language\ntransfer seamlessly to others. We attribute this transferability to the\nparallelism of refusal vectors across languages in the embedding space and\nidentify the underlying mechanism behind cross-lingual jailbreaks. These\nfindings provide actionable insights for building more robust multilingual\nsafety defenses and pave the way for a deeper mechanistic understanding of\ncross-lingual vulnerabilities in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.17306v1",
    "published": "2025-05-22T21:54:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17305v1",
    "title": "Data-driven Closure Strategies for Parametrized Reduced Order Models via Deep Operator Networks",
    "authors": [
      "Anna Ivagnes",
      "Giovanni Stabile",
      "Gianluigi Rozza"
    ],
    "abstract": "In this paper, we propose an equation-based parametric Reduced Order Model\n(ROM), whose accuracy is improved with data-driven terms added into the reduced\nequations. These additions have the aim of reintroducing contributions that in\nstandard reduced-order approaches are not taken into account. In particular, in\nthis work we focus on a Proper Orthogonal Decomposition (POD)-based formulation\nand our goal is to build a closure or correction model, aimed to re-introduce\nthe contribution of the discarded modes. The approach has been investigated in\nprevious works, and the goal of this manuscript is to extend the model to a\nparametric setting making use of machine learning procedures, and, in\nparticular, of deep operator networks. More in detail, we model the closure\nterms through a deep operator network taking as input the reduced variables and\nthe parameters of the problem. We tested the methods on three test cases with\ndifferent behaviors: the periodic turbulent flow past a circular cylinder, the\nunsteady turbulent flow in a channel-driven cavity, and the\ngeometrically-parametrized backstep flow. The performance of the machine\nlearning-enhanced ROM is deeply studied in different modal regimes, and\nconsiderably improved the pressure and velocity accuracy with respect to the\nstandard POD-Galerkin approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.17305v1",
    "published": "2025-05-22T21:51:23+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.17304v1",
    "title": "Implicit Regularization of Infinitesimally-perturbed Gradient Descent Toward Low-dimensional Solutions",
    "authors": [
      "Jianhao Ma",
      "Geyu Liang",
      "Salar Fattahi"
    ],
    "abstract": "Implicit regularization refers to the phenomenon where local search\nalgorithms converge to low-dimensional solutions, even when such structures are\nneither explicitly specified nor encoded in the optimization problem. While\nwidely observed, this phenomenon remains theoretically underexplored,\nparticularly in modern over-parameterized problems. In this paper, we study the\nconditions that enable implicit regularization by investigating when\ngradient-based methods converge to second-order stationary points (SOSPs)\nwithin an implicit low-dimensional region of a smooth, possibly nonconvex\nfunction. We show that successful implicit regularization hinges on two key\nconditions: $(i)$ the ability to efficiently escape strict saddle points, while\n$(ii)$ maintaining proximity to the implicit region. Existing analyses enabling\nthe convergence of gradient descent (GD) to SOSPs often rely on injecting large\nperturbations to escape strict saddle points. However, this comes at the cost\nof deviating from the implicit region. The central premise of this paper is\nthat it is possible to achieve the best of both worlds: efficiently escaping\nstrict saddle points using infinitesimal perturbations, while controlling\ndeviation from the implicit region via a small deviation rate. We show that\ninfinitesimally perturbed gradient descent (IPGD), which can be interpreted as\nGD with inherent ``round-off errors'', can provably satisfy both conditions. We\napply our framework to the problem of over-parameterized matrix sensing, where\nwe establish formal guarantees for the implicit regularization behavior of\nIPGD. We further demonstrate through extensive experiments that these insights\nextend to a broader class of learning problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17304v1",
    "published": "2025-05-22T21:45:27+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17303v1",
    "title": "UAV Control with Vision-based Hand Gesture Recognition over Edge-Computing",
    "authors": [
      "Sousannah Abdalla",
      "Sabur Baidya"
    ],
    "abstract": "Gesture recognition presents a promising avenue for interfacing with unmanned\naerial vehicles (UAVs) due to its intuitive nature and potential for precise\ninteraction. This research conducts a comprehensive comparative analysis of\nvision-based hand gesture detection methodologies tailored for UAV Control. The\nexisting gesture recognition approaches involving cropping, zooming, and\ncolor-based segmentation, do not work well for this kind of applications in\ndynamic conditions and suffer in performance with increasing distance and\nenvironmental noises. We propose to use a novel approach leveraging hand\nlandmarks drawing and classification for gesture recognition based UAV control.\nWith experimental results we show that our proposed method outperforms the\nother existing methods in terms of accuracy, noise resilience, and efficacy\nacross varying distances, thus providing robust control decisions. However,\nimplementing the deep learning based compute intensive gesture recognition\nalgorithms on the UAV's onboard computer is significantly challenging in terms\nof performance. Hence, we propose to use a edge-computing based framework to\noffload the heavier computing tasks, thus achieving closed-loop real-time\nperformance. With implementation over AirSim simulator as well as over a\nreal-world UAV, we showcase the advantage of our end-to-end gesture recognition\nbased UAV control system.",
    "pdf_url": "http://arxiv.org/pdf/2505.17303v1",
    "published": "2025-05-22T21:39:13+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17302v1",
    "title": "Rigorously Characterizing Dynamics with Machine Learning",
    "authors": [
      "Marcio Gameiro",
      "Brittany Gelb",
      "Konstantin Mischaikow"
    ],
    "abstract": "The identification of dynamics from time series data is a problem of general\ninterest. It is well established that dynamics on the level of invariant sets,\nthe primary objects of interest in the classical theory of dynamical systems,\nis not computable. We recall a coarser characterization of dynamics based on\norder theory and algebraic topology and prove that this characterization can be\nidentified using approximations that can be realized by feedforward neural\nnetworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.17302v1",
    "published": "2025-05-22T21:38:43+00:00",
    "categories": [
      "math.DS",
      "37B30, 68T07"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.17301v1",
    "title": "Confirmation and characterization of Galactic planetary nebulae: insights from a spectroscopic study",
    "authors": [
      "D. A. Beleño-Molina",
      "L. Olguín",
      "L. F. Miranda",
      "M. E. Contreras",
      "R. Vázquez"
    ],
    "abstract": "We present a spectroscopic investigation of 25 objects previously reported as\npossible Planetary Nebulae (PNe) in recent catalogs to obtain their physical\nproperties and to establish their true nature. We found 11 objects showing\nintense emission lines, 11 where it was not possible to measure\n$\\mathrm{H{\\beta}}$, and three where no lines are present. We have used\ndiagnostic diagrams to confirm the true PN nature for eight objects. We\nobtained elemental abundances for three objects whose values are in agreement\nwith the PNe mean values for our Galaxy. Four objects show [N II] $\\lambda$6583\nmore intense than $\\mathrm{H{\\alpha}}$, and for two of them, this can be\nexplained by the presence of shocks in the gas. Finally, we report angular\nsizes based on $\\mathrm{H{\\alpha}}$ and [O III] $\\lambda$5007 emission.",
    "pdf_url": "http://arxiv.org/pdf/2505.17301v1",
    "published": "2025-05-22T21:37:08+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17300v1",
    "title": "Statistical Inference for Online Algorithms",
    "authors": [
      "Selina Carter",
      "Arun K Kuchibhotla"
    ],
    "abstract": "Construction of confidence intervals and hypothesis tests for functionals\nbased on asymptotically normal estimators is a classical topic in statistical\ninference. The simplest and in many cases optimal inference procedure is the\nWald interval or the likelihood ratio test, both of which require an estimator\nand an estimate of the asymptotic variance of the estimator. Estimators\nobtained from online/sequential algorithms forces one to consider the\ncomputational aspects of the inference problem, i.e., one cannot access all of\nthe data as many times as needed. Several works on this topic explored the\nonline estimation of asymptotic variance. In this article, we propose\ncomputationally efficient, rate-optimal, and asymptotically valid confidence\nregions based on the output of online algorithms {\\em without} estimating the\nasymptotic variance. As a special case, this implies inference from any\nalgorithm that yields an asymptotically normal estimator. We focus our efforts\non stochastic gradient descent with Polyak averaging to understand the\npractical performance of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.17300v1",
    "published": "2025-05-22T21:31:49+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.CO",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.17299v2",
    "title": "Fast and Accurate Charge Transfer Excitations via Nested Aufbau Suppressed Coupled Cluster",
    "authors": [
      "Harrison Tuckman",
      "Eric Neuscamman"
    ],
    "abstract": "Modeling charge transfer well can require treating post-excitation orbital\nrelaxations and handling medium to large molecules in realistic environments.\nBy combining a state-specific correlation treatment with such orbital\nrelaxations, Aufbau suppressed coupled cluster has proven accurate for charge\ntransfer, but, like many coupled cluster methods, it struggles with large\nsystem sizes. We derive a low-cost Aufbau suppressed second order perturbation\ntheory and show that, by nesting a small coupled cluster treatment inside of\nit, computational cost and scaling are reduced while accuracy is maintained.\nFormal asymptotic costs are dropped from iterative $N^6$ to non-iterative $N^5$\nplus iterative $N^3$, and we test an initial implementation that can handle\nabout 100 atoms and 800 orbitals on a single computational node. Charge\ntransfer excitation energy errors are typically below 0.1 eV on average, with\nan average 0.25 eV improvement over $N^6$-cost equation of motion coupled\ncluster with singles and doubles.",
    "pdf_url": "http://arxiv.org/pdf/2505.17299v2",
    "published": "2025-05-22T21:28:05+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17298v1",
    "title": "Homogenization of a vertical oscillating Neumann condition",
    "authors": [
      "William M Feldman",
      "Zhonggan Huang"
    ],
    "abstract": "We homogenize the Laplace and heat equations with the Neumann data\noscillating in the ``vertical\" $u$-variable. These are simplified models for\ninterface motion in heterogeneous media, particularly capillary contact lines.\nThe homogenization limit reveals a pinning effect at zero tangential slope,\nleading to a novel singularly anisotropic pinned Neumann condition. The\nsingular pinning creates an unconstrained contact set, generalizing the contact\nset in the classical thin obstacle problem. We establish a comparison principle\nfor the heat equation with this new type of boundary condition. The comparison\nprinciple enables a proof of homogenization via the method of half-relaxed\nlimits from viscosity solution theory. Our work also demonstrates, for the\nfirst time in a PDE problem in multiple dimensions, the emergence of\nrate-independent pinning from gradient flows with wiggly energies. Prior limit\ntheorems of this type, in rate-independent contexts, were limited to ODEs and\nPDEs in one dimension.",
    "pdf_url": "http://arxiv.org/pdf/2505.17298v1",
    "published": "2025-05-22T21:27:16+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.12033v1",
    "title": "EMERGENT: Efficient and Manipulation-resistant Matching using GFlowNets",
    "authors": [
      "Mayesha Tasnim",
      "Erman Acar",
      "Sennay Ghebreab"
    ],
    "abstract": "The design of fair and efficient algorithms for allocating public resources,\nsuch as school admissions, housing, or medical residency, has a profound social\nimpact. In one-sided matching problems, where individuals are assigned to items\nbased on ranked preferences, a fundamental trade-off exists between efficiency\nand strategyproofness. Existing algorithms like Random Serial Dictatorship\n(RSD), Probabilistic Serial (PS), and Rank Minimization (RM) capture only one\nside of this trade-off: RSD is strategyproof but inefficient, while PS and RM\nare efficient but incentivize manipulation. We propose EMERGENT, a novel\napplication of Generative Flow Networks (GFlowNets) to one-sided matching,\nleveraging its ability to sample diverse, high-reward solutions. In our\napproach, efficient and manipulation-resistant matches emerge naturally:\nhigh-reward solutions yield efficient matches, while the stochasticity of\nGFlowNets-based outputs reduces incentives for manipulation. Experiments show\nthat EMERGENT outperforms RSD in rank efficiency while significantly reducing\nstrategic vulnerability compared to matches produced by RM and PS. Our work\nhighlights the potential of GFlowNets for applications involving social choice\nmechanisms, where it is crucial to balance efficiency and manipulability.",
    "pdf_url": "http://arxiv.org/pdf/2506.12033v1",
    "published": "2025-05-22T21:25:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17297v1",
    "title": "On the duality of DW-compact operators and DW-DP operators",
    "authors": [
      "Geraldo Botelho",
      "Ariel Monção"
    ],
    "abstract": "We give a necessary condition and a sufficient condition on the Banach\nlattices E and F so that an operator from E to F is DW-compact whenever its\nadjoint is DW-compact. We do the same, with different conditions, for DW-DP\noperators. Moreover, we characterize the Banach lattices E and F for which the\nadjoint of every DW-compact operator from E to F is DW-compact.",
    "pdf_url": "http://arxiv.org/pdf/2505.17297v1",
    "published": "2025-05-22T21:24:01+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.17296v1",
    "title": "SELF: Self-Extend the Context Length With Logistic Growth Function",
    "authors": [
      "Phat Thanh Dang",
      "Saahil Thoppay",
      "Wang Yang",
      "Qifan Wang",
      "Vipin Chaudhary",
      "Xiaotian Han"
    ],
    "abstract": "Large language models suffer issues when operated on long contexts that are\nlarger than their training context length due to the standard position encoding\nfor tokens in the attention layer. Tokens a long distance apart will rarely\nhave an effect on each other and long prompts yield unexpected results. To\nsolve this problem, we propose SELF (Self-Extend the Context Length With\nLogistic Growth Function): a solution of grouping consecutive tokens at varying\ngroup sizes using a logistic capacity equation combined with a constant group\nsize at smaller relative distances. Our model had an increase in performance of\nup to 12% compared to the LongLM extension method in LEval (specifically on the\nQwen model). On summarization related tasks in LongBench, our model performed\nup to 6.4% better than LongLM (specifically on the Llama-2-7b model). On\nreading comprehension tasks from LEval, our model performed up to 5.4% better\nthan the LongLM. Our code is available at https://github.com/alexeipc/SELF-LLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.17296v1",
    "published": "2025-05-22T21:23:20+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17295v1",
    "title": "ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems",
    "authors": [
      "Zhiling Chen",
      "Yang Zhang",
      "Fardin Jalil Piran",
      "Qianyu Zhou",
      "Jiong Tang",
      "Farhad Imani"
    ],
    "abstract": "We introduce ScanBot, a novel dataset designed for instruction-conditioned,\nhigh-precision surface scanning in robotic systems. In contrast to existing\nrobot learning datasets that focus on coarse tasks such as grasping,\nnavigation, or dialogue, ScanBot targets the high-precision demands of\nindustrial laser scanning, where sub-millimeter path continuity and parameter\nstability are critical. The dataset covers laser scanning trajectories executed\nby a robot across 12 diverse objects and 6 task types, including full-surface\nscans, geometry-focused regions, spatially referenced parts, functionally\nrelevant structures, defect inspection, and comparative analysis. Each scan is\nguided by natural language instructions and paired with synchronized RGB,\ndepth, and laser profiles, as well as robot pose and joint states. Despite\nrecent progress, existing vision-language action (VLA) models still fail to\ngenerate stable scanning trajectories under fine-grained instructions and\nreal-world precision demands. To investigate this limitation, we benchmark a\nrange of multimodal large language models (MLLMs) across the full\nperception-planning-execution loop, revealing persistent challenges in\ninstruction-following under realistic constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.17295v1",
    "published": "2025-05-22T21:22:50+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17294v1",
    "title": "Promoted current-induced spin polarization in inversion symmetry broken topological insulator thin films",
    "authors": [
      "Maryam Heydari",
      "Hanieh Moghaddasi",
      "Mir Vahid Hosseini",
      "Mehdi Askari"
    ],
    "abstract": "We theoretically investigate current-induced spin polarization in disordered\ntopological insulator thin films with broken inversion symmetry under an\napplied in-plane electric field. Utilizing the Kubo formalism within the\nself-consistent Born approximation, and incorporating vertex corrections to\naccount for multiple scattering events, we analyze how disorder, chemical\npotential, the electrostatic potential difference between the top and bottom\nsurfaces, and momentum-dependent hybridization affect the spin susceptibility.\nOur results reveal that the spin susceptibility exhibits nonzero values within\na finite range around a zero gap, and this range broadens as the chemical\npotential increases. A higher hybridization strength induces asymmetry in the\nspin response, and a stronger potential difference, breaking inversion\nsymmetry, significantly enhances polarization, a trend attributable to band\ninversion that is further refined by vertex corrections. These findings provide\na theoretical framework for tuning spin-charge conversion in topological thin\nfilms, with implications for spintronic device applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.17294v1",
    "published": "2025-05-22T21:19:07+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.17293v1",
    "title": "Model-Free Graph Data Selection under Distribution Shift",
    "authors": [
      "Ting-Wei Li",
      "Ruizhong Qiu",
      "Hanghang Tong"
    ],
    "abstract": "Graph domain adaptation (GDA) is a fundamental task in graph machine\nlearning, with techniques like shift-robust graph neural networks (GNNs) and\nspecialized training procedures to tackle the distribution shift problem.\nAlthough these model-centric approaches show promising results, they often\nstruggle with severe shifts and constrained computational resources. To address\nthese challenges, we propose a novel model-free framework, GRADATE (GRAph DATa\nsElector), that selects the best training data from the source domain for the\nclassification task on the target domain. GRADATE picks training samples\nwithout relying on any GNN model's predictions or training recipes, leveraging\noptimal transport theory to capture and adapt to distribution changes. GRADATE\nis data-efficient, scalable and meanwhile complements existing model-centric\nGDA approaches. Through comprehensive empirical studies on several real-world\ngraph-level datasets and multiple covariate shift types, we demonstrate that\nGRADATE outperforms existing selection methods and enhances off-the-shelf GDA\nmethods with much fewer training data.",
    "pdf_url": "http://arxiv.org/pdf/2505.17293v1",
    "published": "2025-05-22T21:18:39+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17292v1",
    "title": "Self-consistent layer-projected scissors operator for band structures of complex 2D van der Waals materials",
    "authors": [
      "Dario A. Leon",
      "Mikael Kuisma",
      "Mikkel Ohm Sauer",
      "Jakob K. Svaneborg",
      "Mark K. Svendsen",
      "Stefano Americo",
      "Kristian Berland",
      "Jens Jørgen Mortensen",
      "Kristian S. Thygesen"
    ],
    "abstract": "We introduce a computationally efficient method to calculate the\nquasiparticle (QP) band structure of general van der Waals (vdW)\nheterostructures. A layer-projected scissors (LAPS) operator, which depends on\nthe one-body density matrix, is added to the density functional theory (DFT)\nHamiltonian. The LAPS operator corrects the band edges of the individual layers\nfor self-energy effects (both intralayer and interlayer) and unphysical strain\nfields stemming from the use of model supercells. The LAPS operator is treated\nself-consistently whereby charge redistribution and interlayer hybridization\noccurring in response to the band energy corrections are properly accounted\nfor. We present several examples illustrating both the qualitative and\nquantitative performance of the method, including MoS$_2$ films with up to 20\nlayers, bilayer MoS$_2$ in an electric field, lattice-matched MoS$_2$/WS$_2$\nand MoSe$_2$/WSe$_2$ bilayers, and MoSe$_2$/WS$_2$ moir\\'e structures. Our work\nopens the way for predictive modeling of electronic, optical, and topological\nproperties of complex and experimentally relevant vdW materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.17292v1",
    "published": "2025-05-22T21:18:06+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2507.12471v1",
    "title": "Modular SAIL: dream or reality?",
    "authors": [
      "Petr Kourzanov",
      "Anmol"
    ],
    "abstract": "In order to truly benefit from RISC-V ISA modularity, the community has to\naddress the issue of compositionality, going beyond modules at the\nspecification level covering larger subsets of the RISC-V development flow\nincluding emulation, simulation and verification. In this paper we introduce\nmodular SAIL, an experiment to inject compositionality into the SAIL-RISCV\ngolden model. We show that it is, in principle, not difficult to adapt the\nSAIL-RISCV flow (and ideally the SAIL compiler itself) to support modules at\nthe emulator level. We back our findings by a comparative study of the\nresulting pluggable emulator's performance using both static and dynamic\nbinding, which both exhibit same functional behavior as the original monolithic\nemulator (aka RISC-V ISS).",
    "pdf_url": "http://arxiv.org/pdf/2507.12471v1",
    "published": "2025-05-22T21:16:23+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17291v1",
    "title": "Optimal Transport with Heterogeneously Missing Data",
    "authors": [
      "Linus Bleistein",
      "Aurélien Bellet",
      "Julie Josse"
    ],
    "abstract": "We consider the problem of solving the optimal transport problem between two\nempirical distributions with missing values. Our main assumption is that the\ndata is missing completely at random (MCAR), but we allow for heterogeneous\nmissingness probabilities across features and across the two distributions. As\na first contribution, we show that the Wasserstein distance between empirical\nGaussian distributions and linear Monge maps between arbitrary distributions\ncan be debiased without significantly affecting the sample complexity.\nSecondly, we show that entropic regularized optimal transport can be estimated\nefficiently and consistently using iterative singular value thresholding\n(ISVT). We propose a validation set-free hyperparameter selection strategy for\nISVT that leverages our estimator of the Bures-Wasserstein distance, which\ncould be of independent interest in general matrix completion problems.\nFinally, we validate our findings on a wide range of numerical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.17291v1",
    "published": "2025-05-22T21:16:22+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.12032v1",
    "title": "Embedding Trust at Scale: Physics-Aware Neural Watermarking for Secure and Verifiable Data Pipelines",
    "authors": [
      "Krti Tallam"
    ],
    "abstract": "We present a robust neural watermarking framework for scientific data\nintegrity, targeting high-dimensional fields common in climate modeling and\nfluid simulations. Using a convolutional autoencoder, binary messages are\ninvisibly embedded into structured data such as temperature, vorticity, and\ngeopotential. Our method ensures watermark persistence under lossy\ntransformations - including noise injection, cropping, and compression - while\nmaintaining near-original fidelity (sub-1\\% MSE). Compared to classical\nsingular value decomposition (SVD)-based watermarking, our approach achieves\n$>$98\\% bit accuracy and visually indistinguishable reconstructions across ERA5\nand Navier-Stokes datasets. This system offers a scalable, model-compatible\ntool for data provenance, auditability, and traceability in high-performance\nscientific workflows, and contributes to the broader goal of securing AI\nsystems through verifiable, physics-aware watermarking. We evaluate on\nphysically grounded scientific datasets as a representative stress-test; the\nframework extends naturally to other structured domains such as satellite\nimagery and autonomous-vehicle perception streams.",
    "pdf_url": "http://arxiv.org/pdf/2506.12032v1",
    "published": "2025-05-22T21:14:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17290v1",
    "title": "Membrane-Associated Self-Assembly for Cellular Decision Making",
    "authors": [
      "Samuel L. Foley",
      "Margaret E. Johnson"
    ],
    "abstract": "Cellular decision-making based on information received from the external\nenvironment is frequently initiated by transmembrane receptors. These receptors\nare known to propagate such information by triggering a series of irreversible,\nenergy-consuming reactions. While this active mechanism ensures switch-like\nresponses, here we show how spontaneous molecular self-assembly on a\ntwo-dimensional substrate can similarly act as a tunable and robust switch for\ndetecting receptors at physiological concentrations. This mechanism is much\nmore sensitive than other passive mechanisms for receptor detection. We derive\nanalytical expressions for critical receptor densities that switch on\nnucleation and growth of assemblies, in close agreement with equilibrium\nstochastic reaction-diffusion simulations. The theory developed provides\ntestable predictions for how each component controls decision thresholds and\nmagnitude of response.",
    "pdf_url": "http://arxiv.org/pdf/2505.17290v1",
    "published": "2025-05-22T21:14:42+00:00",
    "categories": [
      "physics.bio-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17289v1",
    "title": "The Poisson's Problems on graphs",
    "authors": [
      "Diego Alexander Castro Guevara"
    ],
    "abstract": "In this paper we study the problem \\[ \\begin{cases} -\\Delta_d u = \\mu_0\n&\\text{ in } G\\\\ u = 0 &\\text{ on } \\partial G \\end{cases} \\] where, $\\Delta_d$\nrepresent the discret Laplacian, and $\\mu_0$ it is a measure defined in the\nvertex of the graph $G=(V,E)$. Here $V$ defined the vertex of the graph, $E$\nits edges and $\\partial G$ its boundary. We prove that this problem has an\nunique solution by using an adaption of the Perron's method for the graphs by\nusing an idea known as Balayage.",
    "pdf_url": "http://arxiv.org/pdf/2505.17289v1",
    "published": "2025-05-22T21:07:12+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17288v1",
    "title": "Learning to Choose or Choosing to Learn: Best-of-N vs. Supervised Fine-Tuning for Bit String Generation",
    "authors": [
      "Seamus Somerstep",
      "Vinod Raman",
      "Unique Subedi",
      "Yuekai Sun"
    ],
    "abstract": "Using the bit string generation problem as a case study, we theoretically\ncompare two standard methods for adapting large language models to new tasks.\nThe first, referred to as supervised fine-tuning, involves training a new next\ntoken predictor on good generations. The second method, Best-of-N, trains a\nreward model to select good responses from a collection generated by an\nunaltered base model. If the learning setting is realizable, we find that\nsupervised fine-tuning outperforms BoN through a better dependence on the\nresponse length in its rate of convergence. If realizability fails, then\ndepending on the failure mode, BoN can enjoy a better rate of convergence in\neither n or a rate of convergence with better dependence on the response\nlength.",
    "pdf_url": "http://arxiv.org/pdf/2505.17288v1",
    "published": "2025-05-22T21:05:04+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.17287v1",
    "title": "A GPU-Accelerated Sharp Interface Immersed Boundary Solver for Large Scale Flow Simulations",
    "authors": [
      "Sushrut Kumar",
      "Jung-Hee Seo",
      "Rajat Mittal"
    ],
    "abstract": "Immersed boundary methods (IBMs) facilitate the simulation of flows around\nstationary, moving, and deforming bodies on Cartesian grids. However, extending\nthese simulations to the large grid sizes required for realistic flow problems\nremains a significant computational challenge. In this work, we present the\nimplementation and acceleration of \\emph{ViCar3D}, a sharp-interface immersed\nboundary solver, on graphical processing units (GPUs). Using OpenACC, CUDA, and\nCUDA-aware MPI, we port and optimize \\emph{ViCar3D} to multi-GPU architectures.\nVerification and scalability studies are performed for two benchmark cases:\ntwo-dimensional flow past a circular cylinder and direct numerical simulation\n(DNS) of flow past a finite rectangular wing. For the latter, we observe an\napproximately 20$\\times$ speedup (node-to-node comparison) relative to the\nCPU-based implementation. The GPU-accelerated solver is capable of simulating\ncomplex 3D flows with up to 200 million mesh points on a single node equipped\nwith four GPUs, and strong and weak scaling tests demonstrate maximum scaling\nefficiencies of 92\\% and 93\\%, respectively, on multi-GPU systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17287v1",
    "published": "2025-05-22T21:02:55+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.17286v1",
    "title": "On 2-categories of extensions",
    "authors": [
      "D. Kaledin"
    ],
    "abstract": "This is essentially an illustration for the general technology of homotopical\nenhancements developed recently in arxiv:2409.17489. We take the derived\ncategory of an abelian category, and we look at the full subcategory spanned by\ncomplexes of length 2. This has a natural refinement to a 2-category that we\ncall \"the 2-category of extensions\". However, just using the triangulated\nstructure on the derived category is not enough to obtain this refinement. In\nthis short note, we first construct the 2-category of extensions by hand --\nthat is, using abelian category techniques -- and then show how it can be\nrecovered very easily and naturally in the enhanced formalism of\narxiv:2409.17489.",
    "pdf_url": "http://arxiv.org/pdf/2505.17286v1",
    "published": "2025-05-22T21:02:32+00:00",
    "categories": [
      "math.AG",
      "math.CT",
      "math.KT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17285v1",
    "title": "On Fisher Consistency of Surrogate Losses for Optimal Dynamic Treatment Regimes with Multiple Categorical Treatments per Stage",
    "authors": [
      "Nilanjana Laha",
      "Nilson Chapagain",
      "Victoria Cicherski",
      "Aaron Sonabend-W"
    ],
    "abstract": "Patients with chronic diseases often receive treatments at multiple time\npoints, or stages. Our goal is to learn the optimal dynamic treatment regime\n(DTR) from longitudinal patient data. When both the number of stages and the\nnumber of treatment levels per stage are arbitrary, estimating the optimal DTR\nreduces to a sequential, weighted, multiclass classification problem (Kosorok\nand Laber, 2019). In this paper, we aim to solve this classification problem\nsimultaneously across all stages using Fisher consistent surrogate losses.\nAlthough computationally feasible Fisher consistent surrogates exist in special\ncases, e.g., the binary treatment setting, a unified theory of Fisher\nconsistency remains largely unexplored. We establish necessary and sufficient\nconditions for DTR Fisher consistency within the class of non-negative,\nstagewise separable surrogate losses. To our knowledge, this is the first\nresult in the DTR literature to provide necessary conditions for Fisher\nconsistency within a non-trivial surrogate class. Furthermore, we show that\nmany convex surrogate losses fail to be Fisher consistent for the DTR\nclassification problem, and we formally establish this inconsistency for\nsmooth, permutation equivariant, and relative-margin-based convex losses.\nBuilding on this, we propose SDSS (Simultaneous Direct Search with Surrogates),\nwhich uses smooth, non-concave surrogate losses to learn the optimal DTR. We\ndevelop a computationally efficient, gradient-based algorithm for SDSS. When\nthe optimization error is small, we establish a sharp upper bound on SDSS's\nregret decay rate. We evaluate the numerical performance of SDSS through\nsimulations and demonstrate its real-world applicability by estimating optimal\nfluid resuscitation strategies for severe septic patients using electronic\nhealth record data.",
    "pdf_url": "http://arxiv.org/pdf/2505.17285v1",
    "published": "2025-05-22T21:02:16+00:00",
    "categories": [
      "math.ST",
      "stat.TH",
      "62G20",
      "G.3"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.17284v1",
    "title": "Reference solutions for linear radiation transport: the Hohlraum and Lattice benchmarks",
    "authors": [
      "Steffen Schotthöfer",
      "Cory Hauck"
    ],
    "abstract": "Two benchmark problems for linear radiation transport and derived from the\nliterature are presented in detail and several quantities of interest are\ndefined. High-resolution simulations are computed using standard, robust\nnumerical methods and implemented using HPC resources. The goal of these\nsimulations is to provide reference solutions for new discretization\napproaches, to aid in the development of multi-fidelity uncertainty\nquantification and optimization algorithms, to provide data for training\nsurrogates models. The code used to perform the simulations and post-process\nthe data is publicly available, as is the raw data that used to generate the\nresults presented in the paper.",
    "pdf_url": "http://arxiv.org/pdf/2505.17284v1",
    "published": "2025-05-22T21:01:58+00:00",
    "categories": [
      "physics.comp-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17283v1",
    "title": "Deconfounded Warm-Start Thompson Sampling with Applications to Precision Medicine",
    "authors": [
      "Prateek Jaiswal",
      "Esmaeil Keyvanshokooh",
      "Junyu Cao"
    ],
    "abstract": "Randomized clinical trials often require large patient cohorts before drawing\ndefinitive conclusions, yet abundant observational data from parallel studies\nremains underutilized due to confounding and hidden biases. To bridge this gap,\nwe propose Deconfounded Warm-Start Thompson Sampling (DWTS), a practical\napproach that leverages a Doubly Debiased LASSO (DDL) procedure to identify a\nsparse set of reliable measured covariates and combines them with key hidden\ncovariates to form a reduced context. By initializing Thompson Sampling (LinTS)\npriors with DDL-estimated means and variances on these measured features --\nwhile keeping uninformative priors on hidden features -- DWTS effectively\nharnesses confounded observational data to kick-start adaptive clinical trials.\nEvaluated on both a purely synthetic environment and a virtual environment\ncreated using real cardiovascular risk dataset, DWTS consistently achieves\nlower cumulative regret than standard LinTS, showing how offline causal\ninsights from observational data can improve trial efficiency and support more\npersonalized treatment decisions.",
    "pdf_url": "http://arxiv.org/pdf/2505.17283v1",
    "published": "2025-05-22T21:00:19+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "stat.AP"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.17282v3",
    "title": "Attention with Trained Embeddings Provably Selects Important Tokens",
    "authors": [
      "Diyuan Wu",
      "Aleksandr Shevchenko",
      "Samet Oymak",
      "Marco Mondelli"
    ],
    "abstract": "Token embeddings play a crucial role in language modeling but, despite this\npractical relevance, their theoretical understanding remains limited. Our paper\naddresses the gap by characterizing the structure of embeddings obtained via\ngradient descent. Specifically, we consider a one-layer softmax attention model\nwith a linear head for binary classification, i.e., $\\texttt{Softmax}( p^\\top\nE_X^\\top ) E_X v = \\frac{ \\sum_{i=1}^T \\exp(p^\\top E_{x_i}) E_{x_i}^\\top\nv}{\\sum_{j=1}^T \\exp(p^\\top E_{x_{j}}) }$, where $E_X = [ E_{x_1} , \\dots,\nE_{x_T} ]^\\top$ contains the embeddings of the input sequence, $p$ is the\nembedding of the $\\mathrm{\\langle cls \\rangle}$ token and $v$ the output\nvector. First, we show that, already after a single step of gradient training\nwith the logistic loss, the embeddings $E_X$ capture the importance of tokens\nin the dataset by aligning with the output vector $v$ proportionally to the\nfrequency with which the corresponding tokens appear in the dataset. Then,\nafter training $p$ via gradient flow until convergence, the softmax selects the\nimportant tokens in the sentence (i.e., those that are predictive of the\nlabel), and the resulting $\\mathrm{\\langle cls \\rangle}$ embedding maximizes\nthe margin for such a selection. Experiments on real-world datasets (IMDB,\nYelp) exhibit a phenomenology close to that unveiled by our theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.17282v3",
    "published": "2025-05-22T21:00:09+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17281v1",
    "title": "Search Wisely: Mitigating Sub-optimal Agentic Searches By Reducing Uncertainty",
    "authors": [
      "Peilin Wu",
      "Mian Zhang",
      "Xinlu Zhang",
      "Xinya Du",
      "Zhiyu Zoey Chen"
    ],
    "abstract": "Agentic Retrieval-Augmented Generation (RAG) systems enhance Large Language\nModels (LLMs) by enabling dynamic, multi-step reasoning and information\nretrieval. However, these systems often exhibit sub-optimal search behaviors\nlike over-search (retrieving redundant information) and under-search (failing\nto retrieve necessary information), which hinder efficiency and reliability.\nThis work formally defines and quantifies these behaviors, revealing their\nprevalence across multiple QA datasets and agentic RAG systems (e.g., one model\ncould have avoided searching in 27.7% of its search steps). Furthermore, we\ndemonstrate a crucial link between these inefficiencies and the models'\nuncertainty regarding their own knowledge boundaries, where response accuracy\ncorrelates with model's uncertainty in its search decisions. To address this,\nwe propose $\\beta$-GRPO, a reinforcement learning-based training method that\nincorporates confidence threshold to reward high-certainty search decisions.\nExperiments on seven QA benchmarks show that $\\beta$-GRPO enable a 3B model\nwith better agentic RAG ability, outperforming other strong baselines with a 4%\nhigher average exact match score.",
    "pdf_url": "http://arxiv.org/pdf/2505.17281v1",
    "published": "2025-05-22T20:57:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17280v1",
    "title": "Mitigate One, Skew Another? Tackling Intersectional Biases in Text-to-Image Models",
    "authors": [
      "Pushkar Shukla",
      "Aditya Chinchure",
      "Emily Diana",
      "Alexander Tolbert",
      "Kartik Hosanagar",
      "Vineeth N Balasubramanian",
      "Leonid Sigal",
      "Matthew Turk"
    ],
    "abstract": "The biases exhibited by text-to-image (TTI) models are often treated as\nindependent, though in reality, they may be deeply interrelated. Addressing\nbias along one dimension - such as ethnicity or age - can inadvertently affect\nanother, like gender, either mitigating or exacerbating existing disparities.\nUnderstanding these interdependencies is crucial for designing fairer\ngenerative models, yet measuring such effects quantitatively remains a\nchallenge. To address this, we introduce BiasConnect, a novel tool for\nanalyzing and quantifying bias interactions in TTI models. BiasConnect uses\ncounterfactual interventions along different bias axes to reveal the underlying\nstructure of these interactions and estimates the effect of mitigating one bias\naxis on another. These estimates show strong correlation (+0.65) with observed\npost-mitigation outcomes. Building on BiasConnect, we propose InterMit, an\nintersectional bias mitigation algorithm guided by user-defined target\ndistributions and priority weights. InterMit achieves lower bias (0.33 vs.\n0.52) with fewer mitigation steps (2.38 vs. 3.15 average steps), and yields\nsuperior image quality compared to traditional techniques. Although our\nimplementation is training-free, InterMit is modular and can be integrated with\nmany existing debiasing approaches for TTI models, making it a flexible and\nextensible solution.",
    "pdf_url": "http://arxiv.org/pdf/2505.17280v1",
    "published": "2025-05-22T20:56:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17279v1",
    "title": "Bayesian and non-Bayesian multi-fidelity surrogate models for multi-objective aerodynamic optimization under extreme cost imbalance",
    "authors": [
      "Marc Schouler",
      "Anca Belme",
      "Paola Cinnella"
    ],
    "abstract": "Aerodynamic shape optimization in industry still faces challenges related to\nrobustness and scalability. This aspect becomes crucial for advanced\noptimizations that rely on expensive high-fidelity flow solvers, where\ncomputational budget constraints only allow a very limited number of\nsimulations within the optimization loop. To address these challenges, we\ninvestigate strategies based on multi-fidelity surrogate models. In particular,\nwe focus on the case of extreme computational cost imbalance between the high-\nand low-fidelity models, which severely limits the maximum allowable number of\nhigh-fidelity function calls. To maximize the information extracted from the\nhigh-fidelity samples, we generate a reduced representation of the design space\nand use an adaptive infill strategy to smartly place the high-fidelity samples\nwhere they can best guide the optimization. Bayesian co-kriging and\nnon-Bayesian multi-fidelity neural networks are trained by combining low- and\nhigh-fidelity models for a use-case consisting of a low Reynolds linear outlet\nguide vane at subsonic and transitional flow conditions. Coarse-mesh RANS\nsimulations are used as low-fidelity model while RANS simulations with a\ntransition model and automatically (feature-based) adapted meshes are chosen as\nthe high-fidelity one. Each surrogate model is then associated to an infill\nstrategy of its kind and a proper orthogonal decomposition of the shape\nparametrization is used to reduce by half the dimension of the problem. Based\non inverted distance and hypervolume metrics, we find that the simpler\nco-kriging representation in conjunction with Bayesian infill yields better\nperformance than the multi-fidelity neural network and the considered\nnon-Bayesian method.",
    "pdf_url": "http://arxiv.org/pdf/2505.17279v1",
    "published": "2025-05-22T20:54:28+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.17278v1",
    "title": "Construction of an Impedance Control Test Bench",
    "authors": [
      "Elisa G. Vergamini",
      "Leonardo F. Dos Santos",
      "Cícero Zanette",
      "Yecid Moreno",
      "Felix M. Escalante",
      "Thiago Boaventura"
    ],
    "abstract": "Controlling the physical interaction with the environment or objects, as\nhumans do, is a shared requirement across different types of robots. To\neffectively control this interaction, it is necessary to control the power\ndelivered to the load, that is, the interaction force and the interaction\nvelocity. However, it is not possible to control these two quantities\nindependently at the same time. An alternative is to control the relation\nbetween them, with Impedance and Admittance control, for example. The Impedance\nControl 2 Dimensions (IC2D) bench is a test bench designed to allow the\nperformance analysis of different actuators and controllers at the joint level.\nTherefore, it was designed to be as versatile as possible, to allow the\ncombination of linear and/or rotational motions, to use electric and/or\nhydraulic actuators, with loads known and defined by the user. The bench\nadheres to a set of requirements defined by the demands of the research group,\nto be a reliable, backlash-free mechatronic system to validate system dynamics\nmodels and controller designs, as well as a valuable experimental setup for\nbenchmarking electric and hydraulic actuators. This article presents the\nmechanical, electrical, and hydraulic configurations used to ensure the\nrobustness and reliability of the test bench. Benches similar to this one are\ncommonly found in robotics laboratories around the world. However, the IC2D\nstands out for its versatility and reliability, as well as for supporting\nhydraulic and electric actuators.",
    "pdf_url": "http://arxiv.org/pdf/2505.17278v1",
    "published": "2025-05-22T20:53:35+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17277v1",
    "title": "Comparator-Adaptive $Φ$-Regret: Improved Bounds, Simpler Algorithms, and Applications to Games",
    "authors": [
      "Soumita Hait",
      "Ping Li",
      "Haipeng Luo",
      "Mengxiao Zhang"
    ],
    "abstract": "In the classic expert problem, $\\Phi$-regret measures the gap between the\nlearner's total loss and that achieved by applying the best action\ntransformation $\\phi \\in \\Phi$. A recent work by Lu et al., [2025] introduces\nan adaptive algorithm whose regret against a comparator $\\phi$ depends on a\ncertain sparsity-based complexity measure of $\\phi$, (almost) recovering and\ninterpolating optimal bounds for standard regret notions such as external,\ninternal, and swap regret. In this work, we propose a general idea to achieve\nan even better comparator-adaptive $\\Phi$-regret bound via much simpler\nalgorithms compared to Lu et al., [2025]. Specifically, we discover a prior\ndistribution over all possible binary transformations and show that it suffices\nto achieve prior-dependent regret against these transformations. Then, we\npropose two concrete and efficient algorithms to achieve so, where the first\none learns over multiple copies of a prior-aware variant of the Kernelized MWU\nalgorithm of Farina et al., [2022], and the second one learns over multiple\ncopies of a prior-aware variant of the BM-reduction [Blum and Mansour, 2007].\nTo further showcase the power of our methods and the advantages over Lu et al.,\n[2025] besides the simplicity and better regret bounds, we also show that our\nsecond approach can be extended to the game setting to achieve accelerated and\nadaptive convergence rate to $\\Phi$-equilibria for a class of general-sum\ngames. When specified to the special case of correlated equilibria, our bound\nimproves over the existing ones from Anagnostides et al., [2022a,b]",
    "pdf_url": "http://arxiv.org/pdf/2505.17277v1",
    "published": "2025-05-22T20:45:47+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17276v1",
    "title": "Algebraic Varieties in Second Quantization",
    "authors": [
      "Svala Sverrisdóttir"
    ],
    "abstract": "We develop algebraic geometry for coupled cluster theory in second\nquantization. In quantum chemistry, electronic systems are represented by\nelements in the exterior algebra. The creation and annihilation operators of\nparticles generate a Clifford algebra known as the Fermi-Dirac algebra. We\npresent a non-commutative Gr\\\"obner basis giving an alternative proof of Wick's\ntheorem, a foundational result in quantum chemistry. In coupled cluster theory,\nthe Schr\\\"odinger equation is approximated through a hierarchy of polynomial\nequations at various levels of truncation. The exponential parameterization\ngives rise to the Fock space truncation varieties. This reveals well-known\nvarieties, such as the Grassmannian, flag varieties and spinor varieties. We\noffer a detailed study of the truncation varieties and their CC degrees. We\nclassify all cases for when the CC degree is equal to the degree of a graph of\nthe exponential parametrization.",
    "pdf_url": "http://arxiv.org/pdf/2505.17276v1",
    "published": "2025-05-22T20:43:04+00:00",
    "categories": [
      "math.AG",
      "physics.chem-ph"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17275v1",
    "title": "ConvoyNext: A Scalable Testbed Platform for Cooperative Autonomous Vehicle Systems",
    "authors": [
      "Hossein Maghsoumi",
      "Yaser Fallah"
    ],
    "abstract": "The advancement of cooperative autonomous vehicle systems depends heavily on\neffective coordination between multiple agents, aiming to enhance traffic\nefficiency, fuel economy, and road safety. Despite these potential benefits,\nreal-world testing of such systems remains a major challenge and is essential\nfor validating control strategies, trajectory modeling methods, and\ncommunication robustness across diverse environments. To address this need, we\nintroduce ConvoyNext, a scalable, modular, and extensible platform tailored for\nthe real-world evaluation of cooperative driving behaviors. We demonstrate the\ncapabilities of ConvoyNext through a series of experiments involving convoys of\nautonomous vehicles navigating complex trajectories. These tests highlight the\nplatform's robustness across heterogeneous vehicle configurations and its\neffectiveness in assessing convoy behavior under varying communication\nconditions, including intentional packet loss. Our results validate ConvoyNext\nas a comprehensive, open-access testbed for advancing research in cooperative\nautonomous vehicle systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17275v1",
    "published": "2025-05-22T20:42:59+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17274v1",
    "title": "Vehicular Intrusion Detection System for Controller Area Network: A Comprehensive Survey and Evaluation",
    "authors": [
      "Yangyang Liu",
      "Lei Xue",
      "Sishan Wang",
      "Xiapu Luo",
      "Kaifa Zhao",
      "Pengfei Jing",
      "Xiaobo Ma",
      "Yajuan Tang",
      "Haiying Zhou"
    ],
    "abstract": "The progress of automotive technologies has made cybersecurity a crucial\nfocus, leading to various cyber attacks. These attacks primarily target the\nController Area Network (CAN) and specialized Electronic Control Units (ECUs).\nIn order to mitigate these attacks and bolster the security of vehicular\nsystems, numerous defense solutions have been proposed.These solutions aim to\ndetect diverse forms of vehicular attacks. However, the practical\nimplementation of these solutions still presents certain limitations and\nchallenges. In light of these circumstances, this paper undertakes a thorough\nexamination of existing vehicular attacks and defense strategies employed\nagainst the CAN and ECUs. The objective is to provide valuable insights and\ninform the future design of Vehicular Intrusion Detection Systems (VIDS). The\nfindings of our investigation reveal that the examined VIDS primarily\nconcentrate on particular categories of attacks, neglecting the broader\nspectrum of potential threats. Moreover, we provide a comprehensive overview of\nthe significant challenges encountered in implementing a robust and feasible\nVIDS. Additionally, we put forth several defense recommendations based on our\nstudy findings, aiming to inform and guide the future design of VIDS in the\ncontext of vehicular security.",
    "pdf_url": "http://arxiv.org/pdf/2505.17274v1",
    "published": "2025-05-22T20:42:57+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17273v1",
    "title": "The ionization structure and chemical history in isolated H II regions of dwarf galaxies with IFU I. The Sagittarius Dwarf Irregular Galaxy",
    "authors": [
      "A. Andrade",
      "I. Saviane",
      "L. Monaco",
      "M. Gullieuszik"
    ],
    "abstract": "Studying metal-poor galaxies is crucial for understanding the physical\nmechanisms driving the evolution of galaxies. Most observational works in dwarf\ngalaxies employ integral field unit data to investigate gas physics in the\nentire galaxy body. However, previous studies have not explored the detailed\nspatially resolved properties of individual extragalactic HII regions. We study\nthe only known HII region in the SagDIG dIrr, a metal-poor dwarf galaxy of the\nlocal universe, using VIMOS-IFU/VLT and EFOSC2/NTT archival data. We aim to\nprobe the structure of the gaseous nebulae to (i) give insights into the\nphysical processes shaping its gas dynamics, and (ii) relate these mechanisms\nto the low gas-phase metallicity content estimated with the direct method. The\nH$\\beta$ emission line map shows two clumps as a biconic-like structure aligned\nacross the same axis. The [OIII]$\\lambda$5007 map, on the other hand, shows a\nmore symmetric structure. Radial flux density profiles exhibit signatures of\nionized stratification. By comparing the gas structure with the stellar\npopulation in the same region, the young stellar population ($<700$ Myr) are\nfound closer to the edges of the biconic-like structure. We estimate\n12+log(O/H) = $7.23\\pm0.04$ dex with the direct method, considering the whole\nnebula. Temperature fluctuations are detected, as variations of $T_{e}$ from\n$\\sim 23400$K to $\\sim 22000$K, and oxygen abundances from 7.24$\\pm0.05$ to\n7.50$\\pm0.14$ dex, from the centre to the outskirts, respectively. In addition,\nSagDIG is in line with the low-mass end of the MZR. The observed\nstratification, the distribution of young MS stars, and the metal-poor content\nof the HII region suggest that the evolution of SagDIG seems to be actively\nshaped by stellar feedback processes, likely as the result of extragalactic HII\nregions being subject to the same gas physics as HII regions of the Milky-Way.",
    "pdf_url": "http://arxiv.org/pdf/2505.17273v1",
    "published": "2025-05-22T20:42:08+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.17272v1",
    "title": "Zebra-Llama: Towards Extremely Efficient Hybrid Models",
    "authors": [
      "Mingyu Yang",
      "Mehdi Rezagholizadeh",
      "Guihong Li",
      "Vikram Appia",
      "Emad Barsoum"
    ],
    "abstract": "With the growing demand for deploying large language models (LLMs) across\ndiverse applications, improving their inference efficiency is crucial for\nsustainable and democratized access. However, retraining LLMs to meet new\nuser-specific requirements is prohibitively expensive and environmentally\nunsustainable. In this work, we propose a practical and scalable alternative:\ncomposing efficient hybrid language models from existing pre-trained models.\nOur approach, Zebra-Llama, introduces a family of 1B, 3B, and 8B hybrid models\nby combining State Space Models (SSMs) and Multi-head Latent Attention (MLA)\nlayers, using a refined initialization and post-training pipeline to\nefficiently transfer knowledge from pre-trained Transformers. Zebra-Llama\nachieves Transformer-level accuracy with near-SSM efficiency using only 7-11B\ntraining tokens (compared to trillions of tokens required for pre-training) and\nan 8B teacher. Moreover, Zebra-Llama dramatically reduces KV cache size -down\nto 3.9%, 2%, and 2.73% of the original for the 1B, 3B, and 8B variants,\nrespectively-while preserving 100%, 100%, and >97% of average zero-shot\nperformance on LM Harness tasks. Compared to models like MambaInLLaMA,\nX-EcoMLA, Minitron, and Llamba, Zebra-Llama consistently delivers competitive\nor superior accuracy while using significantly fewer tokens, smaller teachers,\nand vastly reduced KV cache memory. Notably, Zebra-Llama-8B surpasses\nMinitron-8B in few-shot accuracy by 7% while using 8x fewer training tokens,\nover 12x smaller KV cache, and a smaller teacher (8B vs. 15B). It also achieves\n2.6x-3.8x higher throughput (tokens/s) than MambaInLlama up to a 32k context\nlength. We will release code and model checkpoints upon acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2505.17272v1",
    "published": "2025-05-22T20:39:57+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17271v1",
    "title": "Distribution through Repeated Market with Buying Rights",
    "authors": [
      "David Sychrovský",
      "Jakub Černý",
      "Martin Loebl"
    ],
    "abstract": "Resource distribution is a fundamental problem in economic and policy design,\nparticularly when demand and supply are not naturally aligned. Without\nregulation, wealthier individuals may monopolize this resource, leaving the\nneeds of others unsatisfied. While centralized distribution can ensure fairer\ndivision, it can struggle to manage logistics efficiently, and adapt to\nchanging conditions, often leading to shortages, surpluses, and bureaucratic\ninefficiencies. Building on previous research on market-based redistribution,\nwe examine a repeated hybrid market that incorporates buying rights. These\nrights, distributed iteratively by a central authority (for instance, as\ndigital tokens), are intended to enhance fairness in the system - a unit of\nright is required to acquire a unit of the resource, but the rights themselves\ncan also be traded alongside the resource in the market. We analyze how this\nregulatory mechanism influences the distribution of the scarce resource in the\nhybrid market over time. Unlike past works that relied on empirical methods, we\nexplore the exact analytical properties of a system in which traders optimize\nover multiple rounds. We identify its market equilibrium, which is a natural\ngeneralization of the free market equilibrium, and show that it is\ncoalition-proof. To assess the fairness in the system, we use the concept of\nfrustration, which measures the gap between the resources a buyer is entitled\nto through their buying rights and what they actually obtain through trading.\nOur main theoretical result shows that using buying rights reduces the\nfrustration by at least half compared to the free market. Empirical evaluations\nfurther support our findings, suggesting the system performs well even beyond\nthe theoretically studied assumptions.",
    "pdf_url": "http://arxiv.org/pdf/2505.17271v1",
    "published": "2025-05-22T20:39:42+00:00",
    "categories": [
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.17270v1",
    "title": "Navigating Polytopes with Safety: A Control Barrier Function Approach",
    "authors": [
      "Tamas G. Molnar"
    ],
    "abstract": "Collision-free motion is a fundamental requirement for many autonomous\nsystems. This paper develops a safety-critical control approach for the\ncollision-free navigation of polytope-shaped agents in polytope-shaped\nenvironments. A systematic method is proposed to generate control barrier\nfunction candidates in closed form that lead to controllers with formal safety\nguarantees. The proposed approach is demonstrated through simulation, with\nobstacle avoidance examples in 2D and 3D, including dynamically changing\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.17270v1",
    "published": "2025-05-22T20:39:07+00:00",
    "categories": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.17269v1",
    "title": "A metapopulation model for the spread of cholera",
    "authors": [
      "Abdramane Annour Saad",
      "Julien Arino",
      "Patrick M Tchepmo Djomegni",
      "Mahamat S Daoussa Haggar"
    ],
    "abstract": "We consider a metapopulation model of cholera describing explicitly the\nmovement of individuals and contaminated water between locations as well as a\nsimple vaccination mechanism. The global stability of the disease-free\nequilibrium point when the location-specific reproduction numbers are all less\nthan unity is established. We then conduct some numerical investigation of the\nmodel.",
    "pdf_url": "http://arxiv.org/pdf/2505.17269v1",
    "published": "2025-05-22T20:30:32+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.17268v2",
    "title": "IAE Optimized PID Tuning via Second Order Step Response Target Matching",
    "authors": [
      "Senol Gulgonul"
    ],
    "abstract": "This paper presents SOSTIAE (Second-Order System Target IAE), a novel PID\ntuning method that combines IAE minimization with explicit transient response\nshaping for practical control applications. The algorithm generates optimal PID\nparameters by matching the closed-loop response to a target second-order system\nwith user-defined settling time (Ts) and percent overshoot (PO), while\nmaintaining the conventional IAE performance metric. Comparative evaluations on\nfirst to third-order systems demonstrate that SOSTIAE consistently outperforms\nMATLAB's proprietary pidtune function, achieving 47-67% lower overshoot and up\nto 26% better IAE performance for higher-order plants. The constrained\noptimization framework ensures physically realizable controllers by enforcing\nnon-negative PID gains and stability criteria, addressing known limitations of\nunconstrained IAE methods. Results indicate that SOSTIAE provides engineers\nwith a systematic alternative for PID tuning when transient specifications and\npractical implementation constraints are critical.",
    "pdf_url": "http://arxiv.org/pdf/2505.17268v2",
    "published": "2025-05-22T20:30:24+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.17267v2",
    "title": "GreekBarBench: A Challenging Benchmark for Free-Text Legal Reasoning and Citations",
    "authors": [
      "Odysseas S. Chlapanis",
      "Dimitrios Galanis",
      "Nikolaos Aletras",
      "Ion Androutsopoulos"
    ],
    "abstract": "We introduce GreekBarBench, a benchmark that evaluates LLMs on legal\nquestions across five different legal areas from the Greek Bar exams, requiring\ncitations to statutory articles and case facts. To tackle the challenges of\nfree-text evaluation, we propose a three-dimensional scoring system combined\nwith an LLM-as-a-judge approach. We also develop a meta-evaluation benchmark to\nassess the correlation between LLM-judges and human expert evaluations,\nrevealing that simple, span-based rubrics improve their alignment. Our\nsystematic evaluation of 13 proprietary and open-weight LLMs shows that even\nthough the best models outperform average expert scores, they fall short of the\n95th percentile of experts.",
    "pdf_url": "http://arxiv.org/pdf/2505.17267v2",
    "published": "2025-05-22T20:24:17+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17266v2",
    "title": "Select2Reason: Efficient Instruction-Tuning Data Selection for Long-CoT Reasoning",
    "authors": [
      "Cehao Yang",
      "Xueyuan Lin",
      "Chengjin Xu",
      "Xuhui Jiang",
      "Xiaojun Wu",
      "Honghao Liu",
      "Hui Xiong",
      "Jian Guo"
    ],
    "abstract": "A practical approach to activate long chain-of-thoughts reasoning ability in\npre-trained large language models is to perform supervised fine-tuning on\ninstruction datasets synthesized by strong Large Reasoning Models such as\nDeepSeek-R1, offering a cost-effective alternative to reinforcement learning.\nHowever, large-scale instruction sets with more than 100k samples incur\nsignificant training overhead, while effective strategies for automatic\nlong-CoT instruction selection still remain unexplored. In this work, we\npropose Select2Reason, a novel and efficient instruction-tuning data selection\nframework for long-CoT reasoning. From the perspective of emergence of\nrethinking behaviors like self-correction and backtracking, we investigate\ncommon metrics that may determine the quality of long-CoT reasoning\ninstructions. Select2Reason leverages a quantifier to estimate difficulty of\nquestion and jointly incorporates a reasoning trace length-based heuristic\nthrough a weighted scheme for ranking to prioritize high-utility examples.\nEmpirical results on OpenR1-Math-220k demonstrate that fine-tuning LLM on only\n10% of the data selected by Select2Reason achieves performance competitive with\nor superior to full-data tuning and open-source baseline OpenR1-Qwen-7B across\nthree competition-level and six comprehensive mathematical benchmarks. Further\nexperiments highlight the scalability in varying data size, efficiency during\ninference, and its adaptability to other instruction pools with minimal cost.",
    "pdf_url": "http://arxiv.org/pdf/2505.17266v2",
    "published": "2025-05-22T20:24:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17265v1",
    "title": "CaseReportBench: An LLM Benchmark Dataset for Dense Information Extraction in Clinical Case Reports",
    "authors": [
      "Xiao Yu Cindy Zhang",
      "Carlos R. Ferreira",
      "Francis Rossignol",
      "Raymond T. Ng",
      "Wyeth Wasserman",
      "Jian Zhu"
    ],
    "abstract": "Rare diseases, including Inborn Errors of Metabolism (IEM), pose significant\ndiagnostic challenges. Case reports serve as key but computationally\nunderutilized resources to inform diagnosis. Clinical dense information\nextraction refers to organizing medical information into structured predefined\ncategories. Large Language Models (LLMs) may enable scalable information\nextraction from case reports but are rarely evaluated for this task. We\nintroduce CaseReportBench, an expert-annotated dataset for dense information\nextraction of case reports, focusing on IEMs. Using this dataset, we assess\nvarious models and prompting strategies, introducing novel approaches such as\ncategory-specific prompting and subheading-filtered data integration. Zero-shot\nchain-of-thought prompting offers little advantage over standard zero-shot\nprompting. Category-specific prompting improves alignment with the benchmark.\nThe open-source model Qwen2.5-7B outperforms GPT-4o for this task. Our\nclinician evaluations show that LLMs can extract clinically relevant details\nfrom case reports, supporting rare disease diagnosis and management. We also\nhighlight areas for improvement, such as LLMs' limitations in recognizing\nnegative findings important for differential diagnosis. This work advances\nLLM-driven clinical natural language processing and paves the way for scalable\nmedical AI applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.17265v1",
    "published": "2025-05-22T20:21:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17264v1",
    "title": "Solving MDPs with LTLf+ and PPLTL+ Temporal Objectives",
    "authors": [
      "Giuseppe De Giacomo",
      "Yong Li",
      "Sven Schewe",
      "Christoph Weinhuber",
      "Pian Yu"
    ],
    "abstract": "The temporal logics LTLf+ and PPLTL+ have recently been proposed to express\nobjectives over infinite traces. These logics are appealing because they match\nthe expressive power of LTL on infinite traces while enabling efficient\nDFA-based techniques, which have been crucial to the scalability of reactive\nsynthesis and adversarial planning in LTLf and PPLTL over finite traces. In\nthis paper, we demonstrate that these logics are also highly effective in the\ncontext of MDPs. Introducing a technique tailored for probabilistic systems, we\nleverage the benefits of efficient DFA-based methods and compositionality. This\napproach is simpler than its non-probabilistic counterparts in reactive\nsynthesis and adversarial planning, as it accommodates a controlled form of\nnondeterminism (``good for MDPs\") in the automata when transitioning from\nfinite to infinite traces. Notably, by exploiting compositionality, our\nsolution is both implementation-friendly and well-suited for straightforward\nsymbolic implementations.",
    "pdf_url": "http://arxiv.org/pdf/2505.17264v1",
    "published": "2025-05-22T20:21:16+00:00",
    "categories": [
      "cs.FL",
      "cs.LO"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17263v1",
    "title": "Instability of the fundamental group for non-collapsed Ricci-limits",
    "authors": [
      "Camillo Brena"
    ],
    "abstract": "We construct two sequences of closed $4$-dimensional manifolds with\nnon-negative Ricci curvature, diameter bounded from above by $1$, and volume\nbounded from below by $v>0$, with different fundamental groups but with the\nsame Gromov-Hausdorff limit. This provides a negative answer to the question\nposed in [J. Pan. Ricci Curvature and Fundamental Groups of Effective Regular\nSets. Journal of Mathematical Study, 58(1):3--21, 2025].",
    "pdf_url": "http://arxiv.org/pdf/2505.17263v1",
    "published": "2025-05-22T20:19:57+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17262v1",
    "title": "A Joint Analysis of Strong Lensing and Type Ia Supernovae to Determine the Hubble Constant",
    "authors": [
      "L. R. Colaço",
      "R. F. L. Holanda",
      "Z. C. Santana",
      "R. Silva"
    ],
    "abstract": "We present a cosmological model-independent determination of the Hubble\nconstant, $H_0$, by combining time-delay measurements from seven TDCOSMO\nsystems, Einstein radius measurements, and Type Ia Supernovae data sourced from\nthe Pantheon+ sample. For each lens of time-delay system, we calculate the\nangular diameter distance $D_{A_l}$ using the product $D^{\\textrm{Obs}}(z_l)\n\\cdot D_{A,\\Delta t}^{\\textrm{Obs}}(z_l, z_s)$, where $D^{\\textrm{Obs}}(z_l)$\nis reconstructed via Gaussian Processes from 99 Einstein radius measurements,\nand $D_{A,\\Delta t}^{\\textrm{Obs}}(z_l,z_s)$ is the time-delay angular\ndistance. We also reconstruct the unanchored luminosity distance $H_0 D_L(z_l)$\nfrom supernova data. By using the cosmic distance duality relation validity, we\nanchor $D_{A_l}$ and $H_0 D_L(z_l)$ to infer $H_0 = 70.55 \\pm 7.44$ km/s/Mpc\n(68\\% CL). Our result, though not resolving the Hubble tension, offers a\ncosmological model-independent consistency check and highlights the potential\nof using strong lensing and supernovae data via the cosmic distance duality\nrelation to constrain $H_0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.17262v1",
    "published": "2025-05-22T20:16:33+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17261v2",
    "title": "Advancing excited-state properties of two-dimensional materials using a dielectric-dependent hybrid functional",
    "authors": [
      "Arghya Ghosh",
      "Subrata Jana",
      "Manoar Hossain",
      "Dimple Rani",
      "Szymon Śmiga",
      "Prasanjit Samal"
    ],
    "abstract": "Predicting accurate band gaps and optical properties of lower-dimensional\nmaterials, including two-dimensional van der Waals (vdW) materials and their\nheterostructures, remains a challenge within density functional theory (DFT)\ndue to their unique screening compared to their bulk counterparts.\nAdditionally, accurate treatment of the dielectric response is crucial for\ndeveloping and applying screened-exchange dielectric-dependent range-separated\nhybrid functionals (SE-DD-RSH) for vdW materials. In this work, we introduce a\nSE-DD-RSH functional to the 2D vdW materials like MoS2, WS2, hBN, black\nphosphorus (BP), and \\b{eta}-InSe. By accounting for in-plane and out-of-plane\ndielectric responses, our method achieves accuracy comparable to advanced\nmany-body techniques like G0 W0 and BSE@G0 W0 at a lower computational cost. We\ndemonstrate improved band gap predictions and optical absorption spectra for\nboth bulk and layered structures, including some heterostructures like MoS2/WS2\n. This approach offers a practical and precise tool for exploring electronic\nand optical phenomena in 2D materials, paving the way for efficient\ncomputational studies of layered systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17261v2",
    "published": "2025-05-22T20:16:12+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.17260v1",
    "title": "The Rise of Parameter Specialization for Knowledge Storage in Large Language Models",
    "authors": [
      "Yihuai Hong",
      "Yiran Zhao",
      "Wei Tang",
      "Yang Deng",
      "Yu Rong",
      "Wenxuan Zhang"
    ],
    "abstract": "Over time, a growing wave of large language models from various series has\nbeen introduced to the community. Researchers are striving to maximize the\nperformance of language models with constrained parameter sizes. However, from\na microscopic perspective, there has been limited research on how to better\nstore knowledge in model parameters, particularly within MLPs, to enable more\neffective utilization of this knowledge by the model. In this work, we analyze\ntwenty publicly available open-source large language models to investigate the\nrelationship between their strong performance and the way knowledge is stored\nin their corresponding MLP parameters. Our findings reveal that as language\nmodels become more advanced and demonstrate stronger knowledge capabilities,\ntheir parameters exhibit increased specialization. Specifically, parameters in\nthe MLPs tend to be more focused on encoding similar types of knowledge. We\nexperimentally validate that this specialized distribution of knowledge\ncontributes to improving the efficiency of knowledge utilization in these\nmodels. Furthermore, by conducting causal training experiments, we confirm that\nthis specialized knowledge distribution plays a critical role in improving the\nmodel's efficiency in leveraging stored knowledge.",
    "pdf_url": "http://arxiv.org/pdf/2505.17260v1",
    "published": "2025-05-22T20:15:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17259v1",
    "title": "Understanding the Algorithm Behind Audio Key Detection",
    "authors": [
      "Henrique Perez G. Silva"
    ],
    "abstract": "The determination of musical key is a fundamental aspect of music theory and\nperception, providing a harmonic context for melodies and chord progressions.\nAutomating this process, known as automatic key detection, is a significant\ntask in the field of Music Information Retrieval (MIR). This article outlines\nan algorithmic methodology for estimating the musical key of an audio recording\nby analyzing its tonal content through digital signal processing techniques and\ncomparison with theoretical key profiles.",
    "pdf_url": "http://arxiv.org/pdf/2505.17259v1",
    "published": "2025-05-22T20:14:53+00:00",
    "categories": [
      "cs.SD",
      "eess.AS",
      "94A12, 00A69, 68T10",
      "H.5.5; I.5.4"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.17258v1",
    "title": "Parallelizing the Circumcentered-Reflection Method",
    "authors": [
      "Pablo Barros",
      "Roger Behling",
      "Vincent Guigues",
      "Luiz-Rafael Santos"
    ],
    "abstract": "This paper introduces the Parallelized Circumcentered Reflection Method\n(P-CRM), a circumcentric approach that parallelizes the Circumcentered\nReflection Method (CRM) for solving Convex Feasibility Problems in affine\nsettings. Beyond feasibility, P-CRM solves the best approximation problem for\nany finite collection of affine subspaces; that is, it not only finds a\nfeasible point but directly computes the projection of an initial point onto\nthe intersection. Within a fully self-contained scheme, we also introduce the\nFramework for the Simultaneous Projection Method (F-SPM) which includes\nCimmino's method as a special case. Theoretical results show that both P-CRM\nand F-SPM achieve linear convergence. Moreover, P-CRM converges at a rate that\nis at least as fast as, and potentially superior to, the best convergence rate\nof F-SPM. As a byproduct, this also yields a new and simplified convergence\nproof for Cimmino's method. Numerical experiments show that P-CRM is\ncompetitive compared to CRM and indicate that it offers a scalable and flexible\nalternative, particularly suited for large-scale problems and modern computing\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.17258v1",
    "published": "2025-05-22T20:14:43+00:00",
    "categories": [
      "math.OC",
      "90C25, 90C30, 90C60"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.17257v3",
    "title": "JanusDNA: A Powerful Bi-directional Hybrid DNA Foundation Model",
    "authors": [
      "Qihao Duan",
      "Bingding Huang",
      "Zhenqiao Song",
      "Irina Lehmann",
      "Lei Gu",
      "Roland Eils",
      "Benjamin Wild"
    ],
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\nand are increasingly applied to other sequential data types, including genetic\nsequences. However, adapting LLMs to genomics presents significant challenges.\nCapturing complex genomic interactions requires modeling long-range\ndependencies within DNA sequences, where interactions often span over 10,000\nbase pairs, even within a single gene, posing substantial computational burdens\nunder conventional model architectures and training paradigms. Moreover,\nstandard LLM training approaches are suboptimal for DNA: autoregressive\ntraining, while efficient, supports only unidirectional understanding. However,\nDNA is inherently bidirectional, e.g., bidirectional promoters regulate\ntranscription in both directions and account for nearly 11% of human gene\nexpression. Masked language models (MLMs) allow bidirectional understanding but\nare inefficient, as only masked tokens contribute to the loss per step. To\naddress these limitations, we introduce JanusDNA, the first bidirectional DNA\nfoundation model built upon a novel pretraining paradigm that combines the\noptimization efficiency of autoregressive modeling with the bidirectional\ncomprehension of masked modeling. JanusDNA adopts a hybrid Mamba, Attention and\nMixture of Experts (MoE) architecture, combining long-range modeling of\nAttention with efficient sequential learning of Mamba. MoE layers further scale\nmodel capacity via sparse activation while keeping computational cost low.\nNotably, JanusDNA processes up to 1 million base pairs at single nucleotide\nresolution on a single 80GB GPU. Extensive experiments and ablations show\nJanusDNA achieves new SOTA results on three genomic representation benchmarks,\noutperforming models with 250x more activated parameters. Code:\nhttps://github.com/Qihao-Duan/JanusDNA",
    "pdf_url": "http://arxiv.org/pdf/2505.17257v3",
    "published": "2025-05-22T20:10:55+00:00",
    "categories": [
      "cs.LG",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17256v1",
    "title": "ExpertGen: Training-Free Expert Guidance for Controllable Text-to-Face Generation",
    "authors": [
      "Liang Shi",
      "Yun Fu"
    ],
    "abstract": "Recent advances in diffusion models have significantly improved text-to-face\ngeneration, but achieving fine-grained control over facial features remains a\nchallenge. Existing methods often require training additional modules to handle\nspecific controls such as identity, attributes, or age, making them inflexible\nand resource-intensive. We propose ExpertGen, a training-free framework that\nleverages pre-trained expert models such as face recognition, facial attribute\nrecognition, and age estimation networks to guide generation with fine control.\nOur approach uses a latent consistency model to ensure realistic and\nin-distribution predictions at each diffusion step, enabling accurate guidance\nsignals to effectively steer the diffusion process. We show qualitatively and\nquantitatively that expert models can guide the generation process with high\nprecision, and multiple experts can collaborate to enable simultaneous control\nover diverse facial aspects. By allowing direct integration of off-the-shelf\nexpert models, our method transforms any such model into a plug-and-play\ncomponent for controllable face generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.17256v1",
    "published": "2025-05-22T20:09:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17255v1",
    "title": "Synchronization of identical oscillators on a sphere: exact results with external forces and higher-order interactions",
    "authors": [
      "Guilherme S. Costa",
      "Marcel Novaes",
      "Ricardo Fariello",
      "Marcus A. M. de Aguiar"
    ],
    "abstract": "We study the dynamics of the Kuramoto model on the sphere under higher-order\ninteractions and an external periodic force. For identical oscillators, we\nintroduce a novel way to incorporate three- and four-body interactions into the\ndynamics of the order parameter, allowing for a full dimensional reduction of\nthis system. We discuss how such reduction can be implemented in two different\nways and how they are related. When restricted to the equator, the dynamics is\nsimilar to that of the usual Kuramoto model, up to an interesting\nrenormalization of the coupling constants. Outside this plane, the motion\nreduces to a two-parameter set of periodic orbits. We also locate the\nbifurcation curves of the system as functions of different parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.17255v1",
    "published": "2025-05-22T20:05:53+00:00",
    "categories": [
      "nlin.AO",
      "physics.soc-ph"
    ],
    "primary_category": "nlin.AO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17254v1",
    "title": "Approach to Finding a Robust Deep Learning Model",
    "authors": [
      "Alexey Boldyrev",
      "Fedor Ratnikov",
      "Andrey Shevelev"
    ],
    "abstract": "The rapid development of machine learning (ML) and artificial intelligence\n(AI) applications requires the training of large numbers of models. This\ngrowing demand highlights the importance of training models without human\nsupervision, while ensuring that their predictions are reliable. In response to\nthis need, we propose a novel approach for determining model robustness. This\napproach, supplemented with a proposed model selection algorithm designed as a\nmeta-algorithm, is versatile and applicable to any machine learning model,\nprovided that it is appropriate for the task at hand. This study demonstrates\nthe application of our approach to evaluate the robustness of deep learning\nmodels. To this end, we study small models composed of a few convolutional and\nfully connected layers, using common optimizers due to their ease of\ninterpretation and computational efficiency. Within this framework, we address\nthe influence of training sample size, model weight initialization, and\ninductive bias on the robustness of deep learning models.",
    "pdf_url": "http://arxiv.org/pdf/2505.17254v1",
    "published": "2025-05-22T20:05:20+00:00",
    "categories": [
      "cs.LG",
      "I.2.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17253v1",
    "title": "Understanding the Security Landscape of Embedded Non-Volatile Memories: A Comprehensive Survey",
    "authors": [
      "Zakia Tamanna Tisha",
      "Ujjwal Guin"
    ],
    "abstract": "The modern semiconductor industry requires memory solutions that can keep\npace with the high-speed demands of high-performance computing. Embedded\nnon-volatile memories (eNVMs) address these requirements by offering faster\naccess to stored data at an improved computational throughput and efficiency.\nFurthermore, these technologies offer numerous appealing features, including\nlimited area-energy-runtime budget and data retention capabilities. Among\nthese, the data retention feature of eNVMs has garnered particular interest\nwithin the semiconductor community. Although this property allows eNVMs to\nretain data even in the absence of a continuous power supply, it also\nintroduces some vulnerabilities, prompting security concerns. These concerns\nhave sparked increased interest in examining the broader security implications\nassociated with eNVM technologies. This paper examines the security aspects of\neNVMs by discussing the reasons for vulnerabilities in specific memories from\nan architectural point of view. Additionally, this paper extensively reviews\neNVM-based security primitives, such as physically unclonable functions and\ntrue random number generators, as well as techniques like logic obfuscation.\nThe paper also explores a broad spectrum of security threats to eNVMs,\nincluding physical attacks such as side-channel attacks, fault injection, and\nprobing, as well as logical threats like information leakage,\ndenial-of-service, and thermal attacks. Finally, the paper presents a study of\npublication trends in the eNVM domain since the early 2000s, reflecting the\nrising momentum and research activity in this field.",
    "pdf_url": "http://arxiv.org/pdf/2505.17253v1",
    "published": "2025-05-22T20:02:48+00:00",
    "categories": [
      "cs.CR",
      "cs.ET"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17252v1",
    "title": "LASSO-ODE: A framework for mechanistic model identifiability and selection in disease transmission modeling",
    "authors": [
      "Jiale Tan",
      "Marisa C. Eisenberg"
    ],
    "abstract": "To be fully useful for public health practice, models for epidemic response\nmust be able to do more than predict -- it is also important to incorporate the\nmechanisms underlying transmission dynamics to enable policymakers and\npractitioners to be able to evaluate what-if scenarios and intervention\noptions. However, most mechanistic models suffer from uncertainty in both the\nparameters (e.g., parameter unidentifiability) and the model structure itself,\nwhich can hinder both successful parameter estimation and model interpretation.\nTo enable rapid development of interpretable and parsimonious mechanistic\nmodels, we use penalized regression and covariate selection methods to\nintegrate parameter identifiability and model selection directly into the\nparameter estimation procedure for (in this case) traditional ordinary\ndifferential equation (ODE) models. For both simulated and real-world\nepidemiological data, we demonstrate that the LASSO-ODE framework is highly\neffective in selecting a parsimonious, identifiable model from larger, more\nrealistic but potentially unidentifiable models, from realistically sparse data\nwith only a single measured compartment and multiple latent (unobserved)\nvariables. While we focus on epidemic models in this paper as a case study,\nthese same approaches are applicable to a wide range of application areas that\nare faced with relatively sparse data but a need for realistic mechanistic\nmodels (e.g. mathematical oncology and mathematical biology more broadly).\nAdditionally, the cross-validation techniques designed for time series data\nintroduced in our study can be used across a range of time series analysis and\nmodeling approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.17252v1",
    "published": "2025-05-22T20:01:58+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.17251v1",
    "title": "Successive Convexification for Passively-Safe Spacecraft Rendezvous on Near Rectilinear Halo Orbit",
    "authors": [
      "Purnanand Elango",
      "Abraham P. Vinod",
      "Kenji Kitamura",
      "Behçet Açıkmeşe",
      "Stefano Di Cairano",
      "Avishai Weiss"
    ],
    "abstract": "We present an optimization-based approach for fuel-efficient spacecraft\nrendezvous to the Gateway, a space station that will be deployed on a near\nrectilinear halo orbit (NRHO) around the Moon. The approach: i) ensures passive\nsafety and satisfies path constraints at all times, ii) meets the\nspecifications for critical decision points along the trajectory, iii) accounts\nfor uncertainties that are common in real-world operation, such as due to\norbital insertion, actuation, and navigation measurement, via chance\nconstraints and utilizes a stabilizing feedback controller to bound the effect\nof uncertainties. We leverage sequential convex programming (SCP) and\nisoperimetric reformulation of path constraints, including passive safety, to\neliminate the risk of inter-sample constraint violations that is common in\nexisting methods. We demonstrate the proposed approach on a realistic\nsimulation of a rendezvous to the Gateway.",
    "pdf_url": "http://arxiv.org/pdf/2505.17251v1",
    "published": "2025-05-22T19:59:47+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.17250v1",
    "title": "ConciseRL: Conciseness-Guided Reinforcement Learning for Efficient Reasoning Models",
    "authors": [
      "Razvan-Gabriel Dumitru",
      "Darius Peteleaza",
      "Vikas Yadav",
      "Liangming Pan"
    ],
    "abstract": "Large language models excel at complex tasks by breaking down problems into\nstructured reasoning steps. However, reasoning traces often extend beyond\nreaching a correct answer, causing wasted computation, reduced readability, and\nhallucinations. To address this, we introduce a novel hyperparameter-free\nconciseness score used as a reward signal within a reinforcement learning\nframework to guide models toward generating correct and concise reasoning\ntraces. This score is evaluated by a large language model acting as a judge,\nenabling dynamic, context-aware feedback beyond simple token length. Our method\nachieves state-of-the-art efficiency-accuracy trade-offs on the MATH dataset,\nreducing token usage by up to 31x on simple problems while improving accuracy\nby 7%, and on the hardest problems, it outperforms full reasoning by +7.5%\naccuracy with up to 3.6x fewer tokens. On TheoremQA, our method improves\naccuracy by +2.2% using 12.5x fewer tokens. We also conduct ablation studies on\nthe judge model, reward composition, and problem difficulty, showing that our\nmethod dynamically adapts reasoning length based on problem difficulty and\nbenefits significantly from stronger judges. The code, model weights, and\ndatasets are open-sourced at https://github.com/RazvanDu/ConciseRL.",
    "pdf_url": "http://arxiv.org/pdf/2505.17250v1",
    "published": "2025-05-22T19:56:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.0"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17249v1",
    "title": "Where You Go is Who You Are: Behavioral Theory-Guided LLMs for Inverse Reinforcement Learning",
    "authors": [
      "Yuran Sun",
      "Susu Xu",
      "Chenguang Wang",
      "Xilei Zhao"
    ],
    "abstract": "Big trajectory data hold great promise for human mobility analysis, but their\nutility is often constrained by the absence of critical traveler attributes,\nparticularly sociodemographic information. While prior studies have explored\npredicting such attributes from mobility patterns, they often overlooked\nunderlying cognitive mechanisms and exhibited low predictive accuracy. This\nstudy introduces SILIC, short for Sociodemographic Inference with LLM-guided\nInverse Reinforcement Learning (IRL) and Cognitive Chain Reasoning (CCR), a\ntheoretically grounded framework that leverages LLMs to infer sociodemographic\nattributes from observed mobility patterns by capturing latent behavioral\nintentions and reasoning through psychological constructs. Particularly, our\napproach explicitly follows the Theory of Planned Behavior (TPB), a\nfoundational behavioral framework in transportation research, to model\nindividuals' latent cognitive processes underlying travel decision-making. The\nLLMs further provide heuristic guidance to improve IRL reward function\ninitialization and update by addressing its ill-posedness and optimization\nchallenges arising from the vast and unstructured reward space. Evaluated in\nthe 2017 Puget Sound Regional Council Household Travel Survey, our method\nsubstantially outperforms state-of-the-art baselines and shows great promise\nfor enriching big trajectory data to support more behaviorally grounded\napplications in transportation planning and beyond.",
    "pdf_url": "http://arxiv.org/pdf/2505.17249v1",
    "published": "2025-05-22T19:56:03+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17248v2",
    "title": "Backdoors in DRL: Four Environments Focusing on In-distribution Triggers",
    "authors": [
      "Chace Ashcraft",
      "Ted Staley",
      "Josh Carney",
      "Cameron Hickert",
      "Kiran Karra",
      "Nathan Drenkow"
    ],
    "abstract": "Backdoor attacks, or trojans, pose a security risk by concealing undesirable\nbehavior in deep neural network models. Open-source neural networks are\ndownloaded from the internet daily, possibly containing backdoors, and\nthird-party model developers are common. To advance research on backdoor attack\nmitigation, we develop several trojans for deep reinforcement learning (DRL)\nagents. We focus on in-distribution triggers, which occur within the agent's\nnatural data distribution, since they pose a more significant security threat\nthan out-of-distribution triggers due to their ease of activation by the\nattacker during model deployment. We implement backdoor attacks in four\nreinforcement learning (RL) environments: LavaWorld, Randomized LavaWorld,\nColorful Memory, and Modified Safety Gymnasium. We train various models, both\nclean and backdoored, to characterize these attacks. We find that\nin-distribution triggers can require additional effort to implement and be more\nchallenging for models to learn, but are nevertheless viable threats in DRL\neven using basic data poisoning attacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.17248v2",
    "published": "2025-05-22T19:52:35+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.23784v1",
    "title": "Learning Normal Patterns in Musical Loops",
    "authors": [
      "Shayan Dadman",
      "Bernt Arild Bremdal",
      "Børre Bang",
      "Rune Dalmo"
    ],
    "abstract": "This paper introduces an unsupervised framework for detecting audio patterns\nin musical samples (loops) through anomaly detection techniques, addressing\nchallenges in music information retrieval (MIR). Existing methods are often\nconstrained by reliance on handcrafted features, domain-specific limitations,\nor dependence on iterative user interaction. We address these limitations\nthrough an architecture combining deep feature extraction with unsupervised\nanomaly detection. Our approach leverages a pre-trained Hierarchical\nToken-semantic Audio Transformer (HTS-AT), paired with a Feature Fusion\nMechanism (FFM), to generate representations from variable-length audio loops.\nThese embeddings are processed using one-class Deep Support Vector Data\nDescription (Deep SVDD), which learns normative audio patterns by mapping them\nto a compact latent hypersphere. Evaluations on curated bass and guitar\ndatasets compare standard and residual autoencoder variants against baselines\nlike Isolation Forest (IF) and and principle component analysis (PCA) methods.\nResults show our Deep SVDD models, especially the residual autoencoder variant,\ndeliver improved anomaly separation, particularly for larger variations. This\nresearch contributes a flexible, fully unsupervised solution for processing\ndiverse audio samples, overcoming previous structural and input limitations\nwhile enabling effective pattern identification through distance-based latent\nspace scoring.",
    "pdf_url": "http://arxiv.org/pdf/2505.23784v1",
    "published": "2025-05-22T19:52:00+00:00",
    "categories": [
      "cs.SD",
      "cs.IR",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.17247v1",
    "title": "Reservoir Designs for Online Paired Experiments",
    "authors": [
      "Tim Morrison"
    ],
    "abstract": "We study the question of how best to stratify units into matched pairs in\nonline experiments, so that units within a pair receive opposite treatment.\nPast work by Bai, Romano, and Shaikh (2022) has demonstrated the asymptotic\nvariance improvement that comes from pairing units with similar covariates in\nthis way. However, their method requires knowing the covariates for all units a\npriori; this is not the case in many A/B testing problems, in which units\narrive one at a time and must have treatment assigned immediately. Inspired by\nthe terminology of Kapelner and Krieger (2014), we thus introduce the notion of\na reservoir design, which maintains a reservoir of unpaired units that can\npotentially be paired with an incoming unit. We construct a particular\nreservoir design that uses a distance-based criterion to determine pairing and,\nvia a packing argument, prove conditions under which it attains the asymptotic\nvariance improvement of Bai, Romano, and Shaikh (2022). We illustrate our\nreservoir design on synthetic and semi-synthetic examples and find improved\nperformance relative to both IID sampling and the design of Kapelner and\nKrieger (2014).",
    "pdf_url": "http://arxiv.org/pdf/2505.17247v1",
    "published": "2025-05-22T19:49:01+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.17246v1",
    "title": "Oort Cloud Formation and Evolution in Star Clusters",
    "authors": [
      "Justine C. Obidowski",
      "Jeremy J. Webb",
      "Simon Portegies Zwart",
      "Maxwell X. Cai"
    ],
    "abstract": "It is unknown if an Oort cloud reaches its maximum mass within its star's\nbirth cluster or millions of years later. Complicating the Oort cloud evolution\nprocess is the fact that comets can be stripped from orbit due to perturbations\nfrom passing stars. We explore how a star's cluster escape time (t$_{ \\rm\nesc}$) and the time its Oort cloud reaches maximum mass (t$_{ \\rm max}$) affect\nthe Oort cloud's ability to survive via $N$-body simulations. In a 14\nM$_\\odot$/pc$^3$ cluster, we identify 50 stars of 1 M$_\\odot$ with a range of\nt$_{ \\rm esc}$ to host Oort clouds, each with 1000 comets at t$_{ \\rm max}$.\nFor each host, we consider Oort clouds that reach maximum mass 0, 50, and 250\nMyr after the cluster's formation. Each Oort cloud's evolution is simulated in\nthe cluster from t$_{ \\rm max}$ to t$_{ \\rm esc}$. Only a fraction of comets\ntend to remain in orbit, with this amount depending on t$_{ \\rm max}$ and t$_{\n\\rm esc}$. We observe that 12%, 22%, and 32% of Oort clouds with a t$_{ \\rm\nmax}$ of 0, 50 and 250 Myr retain >50% of their comets at t$_{ \\rm esc}$,\nrespectively. We find that the fraction of comets stripped has the\nrelationship, $\\rm f=m\\log_{10}(\\frac{t_{ \\rm esc}-t_{ \\rm max}}{Myr})$ where m\n= 0.32$\\pm$0.04, indicating that the longer the Oort cloud remains in the\ncluster, the more comets are stripped, with this fraction increasing\nlogarithmically at approximately the same rate for each t$_{ \\rm max}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.17246v1",
    "published": "2025-05-22T19:48:37+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17245v1",
    "title": "Extending Dataset Pruning to Object Detection: A Variance-based Approach",
    "authors": [
      "Ryota Yagi"
    ],
    "abstract": "Dataset pruning -- selecting a small yet informative subset of training data\n-- has emerged as a promising strategy for efficient machine learning, offering\nsignificant reductions in computational cost and storage compared to\nalternatives like dataset distillation. While pruning methods have shown strong\nperformance in image classification, their extension to more complex computer\nvision tasks, particularly object detection, remains relatively underexplored.\nIn this paper, we present the first principled extension of classification\npruning techniques to the object detection domain, to the best of our\nknowledge. We identify and address three key challenges that hinder this\ntransition: the Object-Level Attribution Problem, the Scoring Strategy Problem,\nand the Image-Level Aggregation Problem. To overcome these, we propose tailored\nsolutions, including a novel scoring method called Variance-based Prediction\nScore (VPS). VPS leverages both Intersection over Union (IoU) and confidence\nscores to effectively identify informative training samples specific to\ndetection tasks. Extensive experiments on PASCAL VOC and MS COCO demonstrate\nthat our approach consistently outperforms prior dataset pruning methods in\nterms of mean Average Precision (mAP). We also show that annotation count and\nclass distribution shift can influence detection performance, but selecting\ninformative examples is a more critical factor than dataset size or balance.\nOur work bridges dataset pruning and object detection, paving the way for\ndataset pruning in complex vision tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.17245v1",
    "published": "2025-05-22T19:46:51+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17244v1",
    "title": "ReasoningShield: Content Safety Detection over Reasoning Traces of Large Reasoning Models",
    "authors": [
      "Changyi Li",
      "Jiayi Wang",
      "Xudong Pan",
      "Geng Hong",
      "Min Yang"
    ],
    "abstract": "Large Reasoning Models (LRMs) are transforming the AI landscape with advanced\nreasoning capabilities. While the generated reasoning traces enhance model\ntransparency, they can still contain unsafe content, even when the final answer\nappears safe. Existing moderation tools, primarily designed for question-answer\n(QA) pairs, are empirically ineffective at detecting hidden risks embedded in\nreasoning traces. After identifying the key challenges, we formally define the\nquestion-thought (QT) moderation task and propose ReasoningShield, the first\nsafety detection model tailored to identify potential risks in the reasoning\ntrace before reaching the final answer. To construct the model, we synthesize a\nhigh-quality reasoning safety detection dataset comprising over 8,000\nquestion-thought pairs spanning ten risk categories and three safety levels.\nOur dataset construction process incorporates a comprehensive human-AI\ncollaborative annotation pipeline, which achieves over 93% annotation accuracy\nwhile significantly reducing human costs. On a diverse set of in-distribution\nand out-of-distribution benchmarks, ReasoningShield outperforms mainstream\ncontent safety moderation models in identifying risks within reasoning traces,\nwith an average F1 score exceeding 0.92. Notably, despite being trained on our\nQT dataset only, ReasoningShield also demonstrates competitive performance in\ndetecting unsafe question-answer pairs on traditional benchmarks, rivaling\nbaselines trained on 10 times larger datasets and base models, which strongly\nvalidates the quality of our dataset. Furthermore, ReasoningShield is built\nupon compact 1B/3B base models to facilitate lightweight deployment and\nprovides human-friendly risk analysis by default. To foster future research, we\npublicly release all the resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.17244v1",
    "published": "2025-05-22T19:44:41+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17243v1",
    "title": "Finite element spaces of double forms",
    "authors": [
      "Yakov Berchenko-Kogan",
      "Evan S. Gawlik"
    ],
    "abstract": "The tensor product of two differential forms of degree $p$ and $q$ is a\nmultilinear form that is alternating in its first $p$ arguments and alternating\nin its last $q$ arguments. These forms, which are known as double forms or\n$(p,q)$-forms, play a central role in certain differential complexes that arise\nwhen studying partial differential equations. We construct piecewise polynomial\nfinite element spaces for all of the natural subspaces of the space of\n$(p,q)$-forms, excluding one subspace which fails to admit a piecewise constant\ndiscretization. As special cases, our construction recovers known finite\nelement spaces for symmetric matrices with tangential-tangential continuity\n(the Regge finite elements), symmetric matrices with normal-normal continuity,\nand trace-free matrices with normal-tangential continuity. It also gives rise\nto new spaces, like a finite element space for tensors possessing the\nsymmetries of the Riemann curvature tensor.",
    "pdf_url": "http://arxiv.org/pdf/2505.17243v1",
    "published": "2025-05-22T19:43:59+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.DG",
      "65N30, 15A69, 58A10, 53A45"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.17242v1",
    "title": "Optimal Policy Minimum Bayesian Risk",
    "authors": [
      "Ramón Fernandez Astudillo",
      "Md Arafat Sultan",
      "Aashka Trivedi",
      "Yousef El-Kurdi",
      "Tahira Naseem",
      "Radu Florian",
      "Salim Roukos"
    ],
    "abstract": "Inference scaling can help LLMs solve complex reasoning problems through\nextended runtime computation. On top of targeted supervision for long\nchain-of-thought (long-CoT) generation, purely inference-time techniques such\nas best-of-N (BoN) sampling, majority voting, or more generally, minimum Bayes\nrisk decoding (MBRD), can further improve LLM accuracy by generating multiple\ncandidate solutions and aggregating over them. These methods typically leverage\nadditional signals in the form of reward models and risk/similarity functions\nthat compare generated samples, e.g., exact match in some normalized space or\nstandard similarity metrics such as Rouge. Here we present a novel method for\nincorporating reward and risk/similarity signals into MBRD. Based on the\nconcept of optimal policy in KL-controlled reinforcement learning, our\nframework provides a simple and well-defined mechanism for leveraging such\nsignals, offering several advantages over traditional inference-time methods:\nhigher robustness, improved accuracy, and well-understood asymptotic behavior.\nIn addition, it allows for the development of a sample-efficient variant of\nMBRD that can adjust the number of samples to generate according to the\ndifficulty of the problem, without relying on majority vote counts. We\nempirically demonstrate the advantages of our approach on math (MATH-$500$) and\ncoding (HumanEval) tasks using recent open-source models. We also present a\ncomprehensive analysis of its accuracy-compute trade-offs.",
    "pdf_url": "http://arxiv.org/pdf/2505.17242v1",
    "published": "2025-05-22T19:43:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17241v1",
    "title": "Generative AI and Creativity: A Systematic Literature Review and Meta-Analysis",
    "authors": [
      "Niklas Holzner",
      "Sebastian Maier",
      "Stefan Feuerriegel"
    ],
    "abstract": "Generative artificial intelligence (GenAI) is increasingly used to support a\nwide range of human tasks, yet empirical evidence on its effect on creativity\nremains scattered. Can GenAI generate ideas that are creative? To what extent\ncan it support humans in generating ideas that are both creative and diverse?\nIn this study, we conduct a meta-analysis to evaluate the effect of GenAI on\nthe performance in creative tasks. For this, we first perform a systematic\nliterature search, based on which we identify n = 28 relevant studies (m = 8214\nparticipants) for inclusion in our meta-analysis. We then compute standardized\neffect sizes based on Hedges' g. We compare different outcomes: (i) how\ncreative GenAI is; (ii) how creative humans augmented by GenAI are; and (iii)\nthe diversity of ideas by humans augmented by GenAI. Our results show no\nsignificant difference in creative performance between GenAI and humans (g =\n-0.05), while humans collaborating with GenAI significantly outperform those\nworking without assistance (g = 0.27). However, GenAI has a significant\nnegative effect on the diversity of ideas for such collaborations between\nhumans and GenAI (g = -0.86). We further analyze heterogeneity across different\nGenAI models (e.g., GPT-3.5, GPT-4), different tasks (e.g., creative writing,\nideation, divergent thinking), and different participant populations (e.g.,\nlaypeople, business, academia). Overall, our results position GenAI as an\naugmentative tool that can support, rather than replace, human\ncreativity-particularly in tasks benefiting from ideation support.",
    "pdf_url": "http://arxiv.org/pdf/2505.17241v1",
    "published": "2025-05-22T19:39:10+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.17240v1",
    "title": "Sequent Calculi for Data-Aware Modal Logics",
    "authors": [
      "Carlos Areces",
      "Valentin Cassano",
      "Danae Dutto",
      "Raul Fervari"
    ],
    "abstract": "This document serves as a companion to the paper of the same title, wherein\nwe introduce a Gentzen-style sequent calculus for HXPathD. It provides full\ntechnical details and proofs from the main paper. As such, it is intended as a\nreference for readers seeking a deeper understanding of the formal results,\nincluding soundness, completeness, invertibility, and cut elimination for the\ncalculus.",
    "pdf_url": "http://arxiv.org/pdf/2505.17240v1",
    "published": "2025-05-22T19:36:07+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17239v1",
    "title": "LiDAR 2.0: Hierarchical Curvy Waveguide Detailed Routing for Large-Scale Photonic Integrated Circuits",
    "authors": [
      "Hongjian Zhou",
      "Haoyu Yang",
      "Ziang Ying",
      "Nicholas Gangi",
      "Zhaoran",
      "Huang",
      "Haoxing Ren",
      "Joaquin Matres",
      "Jiaqi Gu"
    ],
    "abstract": "Driven by innovations in photonic computing and interconnects, photonic\nintegrated circuit (PIC) designs advance and grow in complexity. Traditional\nmanual physical design processes have become increasingly cumbersome. Available\nPIC layout tools are mostly schematic-driven, which has not alleviated the\nburden of manual waveguide planning and layout drawing. Previous research in\nPIC automated routing is largely adapted from electronic design, focusing on\nhigh-level planning and overlooking photonic-specific constraints such as curvy\nwaveguides, bending, and port alignment. As a result, they fail to scale and\ncannot generate DRV-free layouts, highlighting the need for dedicated\nelectronic-photonic design automation tools to streamline PIC physical design.\nIn this work, we present LiDAR, the first automated PIC detailed router for\nlarge-scale designs. It features a grid-based, curvy-aware A* engine with\nadaptive crossing insertion, congestion-aware net ordering, and insertion-loss\noptimization. To enable routing in more compact and complex designs, we further\nextend our router to hierarchical routing as LiDAR 2.0. It introduces\nredundant-bend elimination, crossing space preservation, and routing order\nrefinement for improved conflict resilience. We also develop and open-source a\nYAML-based PIC intermediate representation and diverse benchmarks, including\nTeMPO, GWOR, and Bennes, which feature hierarchical structures and high\ncrossing densities. Evaluations across various benchmarks show that LiDAR 2.0\nconsistently produces DRV-free layouts, achieving up to 16% lower insertion\nloss and 7.69x speedup over prior methods on spacious cases, and 9% lower\ninsertion loss with 6.95x speedup over LiDAR 1.0 on compact cases. Our codes\nare open-sourced at https://github.com/ScopeX-ASU/LiDAR.",
    "pdf_url": "http://arxiv.org/pdf/2505.17239v1",
    "published": "2025-05-22T19:33:48+00:00",
    "categories": [
      "cs.ET",
      "physics.optics"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.17238v2",
    "title": "Personalizing Student-Agent Interactions Using Log-Contextualized Retrieval Augmented Generation (RAG)",
    "authors": [
      "Clayton Cohn",
      "Surya Rayala",
      "Caitlin Snyder",
      "Joyce Fonteles",
      "Shruti Jain",
      "Naveeduddin Mohammed",
      "Umesh Timalsina",
      "Sarah K. Burriss",
      "Ashwin T S",
      "Namrata Srivastava",
      "Menton Deweese",
      "Angela Eeds",
      "Gautam Biswas"
    ],
    "abstract": "Collaborative dialogue offers rich insights into students' learning and\ncritical thinking, which is essential for personalizing pedagogical agent\ninteractions in STEM+C settings. While large language models (LLMs) facilitate\ndynamic pedagogical interactions, hallucinations undermine confidence, trust,\nand instructional value. Retrieval-augmented generation (RAG) grounds LLM\noutputs in curated knowledge but requires a clear semantic link between user\ninput and a knowledge base, which is often weak in student dialogue. We propose\nlog-contextualized RAG (LC-RAG), which enhances RAG retrieval by using\nenvironment logs to contextualize collaborative discourse. Our findings show\nthat LC-RAG improves retrieval over a discourse-only baseline and allows our\ncollaborative peer agent, Copa, to deliver relevant, personalized guidance that\nsupports students' critical thinking and epistemic decision-making in a\ncollaborative computational modeling environment, C2STEM.",
    "pdf_url": "http://arxiv.org/pdf/2505.17238v2",
    "published": "2025-05-22T19:31:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17237v1",
    "title": "Predicting protein folding dynamics using sequence information",
    "authors": [
      "Ezequiel A. Galpern",
      "Federico Caamaño",
      "Diego U. Ferreiro"
    ],
    "abstract": "Natural protein sequences somehow encode the structural forms that these\nmolecules adopt. Recent developments in structure-prediction are agnostic to\nthe mechanisms by which proteins fold and represent them as static objects.\nHowever, the amino acid sequences also encode information about how the folding\nprocess can happen, and how variations in the sequences impact on the\npopulations of the distinct structural forms that proteins acquire. Here we\npresent a method to infer protein folding dynamics based only on sequence\ninformation. For this, we will rely first on the obtention of a precise\n'evolutionary field' from the observed variations in the sequences of\nhomologous proteins. We then show how to map the energetics to a coarse-grained\nfolding model where the protein is treated as a string of foldons that\ninteract. We then describe how, for any given protein sequence of a family, the\nequilibrium folding curve can be computed and how the emergence of protein\nfolding sub-domains can be identified. We finally present protocols to analyze\nhow mutations perturb both the folding stability and the cooperativity, that\nrepresent predictions for a deep-mutational scan of a protein of interest.",
    "pdf_url": "http://arxiv.org/pdf/2505.17237v1",
    "published": "2025-05-22T19:29:55+00:00",
    "categories": [
      "q-bio.BM"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2505.17236v1",
    "title": "LogStamping: A blockchain-based log auditing approach for large-scale systems",
    "authors": [
      "Md Shariful Islam",
      "M. Sohel Rahman"
    ],
    "abstract": "Log management is crucial for ensuring the security, integrity, and\ncompliance of modern information systems. Traditional log management solutions\nface challenges in achieving tamper-proofing, scalability, and real-time\nprocessing in distributed environments. This paper presents a blockchain-based\nlog management framework that addresses these limitations by leveraging\nblockchain's decentralized, immutable, and transparent features. The framework\nintegrates a hybrid on-chain and off-chain storage model, combining\nblockchain's integrity guarantees with the scalability of distributed storage\nsolutions like IPFS. Smart contracts automate log validation and access\ncontrol, while cryptographic techniques ensure privacy and confidentiality.\nWith a focus on real-time log processing, the framework is designed to handle\nthe high-volume log generation typical in large-scale systems, such as data\ncenters and network infrastructure. Performance evaluations demonstrate the\nframework's scalability, low latency, and ability to manage millions of log\nentries while maintaining strong security guarantees. Additionally, the paper\ndiscusses challenges like blockchain storage overhead and energy consumption,\noffering insights for enhancing future systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17236v1",
    "published": "2025-05-22T19:27:44+00:00",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17235v1",
    "title": "CHAOS: Chart Analysis with Outlier Samples",
    "authors": [
      "Omar Moured",
      "Yufan Chen",
      "Ruiping Liu",
      "Simon Reiß",
      "Philip Torr",
      "Jiaming Zhang",
      "Rainer Stiefelhagen"
    ],
    "abstract": "Charts play a critical role in data analysis and visualization, yet\nreal-world applications often present charts with challenging or noisy\nfeatures. However, \"outlier charts\" pose a substantial challenge even for\nMultimodal Large Language Models (MLLMs), which can struggle to interpret\nperturbed charts. In this work, we introduce CHAOS (CHart Analysis with Outlier\nSamples), a robustness benchmark to systematically evaluate MLLMs against chart\nperturbations. CHAOS encompasses five types of textual and ten types of visual\nperturbations, each presented at three levels of severity (easy, mid, hard)\ninspired by the study result of human evaluation. The benchmark includes 13\nstate-of-the-art MLLMs divided into three groups (i.e., general-, document-,\nand chart-specific models) according to the training scope and data.\nComprehensive analysis involves two downstream tasks (ChartQA and\nChart-to-Text). Extensive experiments and case studies highlight critical\ninsights into robustness of models across chart perturbations, aiming to guide\nfuture research in chart understanding domain. Data and code are publicly\navailable at: http://huggingface.co/datasets/omoured/CHAOS.",
    "pdf_url": "http://arxiv.org/pdf/2505.17235v1",
    "published": "2025-05-22T19:26:49+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17234v1",
    "title": "Quantifying Global Networks of Exchange through the Louvain Method",
    "authors": [
      "Aryan Sharma",
      "Jaden Li",
      "Christina Chu",
      "Anna Sisk"
    ],
    "abstract": "Congressional Research Service (CRS) reports provide detailed analyses of\nmajor policy issues to members of the US Congress. We extract and analyze data\nfrom 2,010 CRS reports written between 1996 and 2024 in order to quantify the\nrelationships between countries. The data is processed and converted into a\nweighted graph, representing 172 unique countries as nodes and 4,137 interests\nas bidirectional edges. Through the Louvain method, we use a greedy algorithm\nto extract non-overlapping communities from our network and identify clusters\nwith shared interests. We then compute the eigenvector centrality of countries,\neffectively highlighting their network influence. The results of this work\ncould enable improvements in sourcing evidence for analytic products and\nunderstanding the connectivity of our world.",
    "pdf_url": "http://arxiv.org/pdf/2505.17234v1",
    "published": "2025-05-22T19:17:56+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17233v2",
    "title": "Semantic-Aware Interpretable Multimodal Music Auto-Tagging",
    "authors": [
      "Andreas Patakis",
      "Vassilis Lyberatos",
      "Spyridon Kantarelis",
      "Edmund Dervakos",
      "Giorgos Stamou"
    ],
    "abstract": "Music auto-tagging is essential for organizing and discovering music in\nextensive digital libraries. While foundation models achieve exceptional\nperformance in this domain, their outputs often lack interpretability, limiting\ntrust and usability for researchers and end-users alike. In this work, we\npresent an interpretable framework for music auto-tagging that leverages groups\nof musically meaningful multimodal features, derived from signal processing,\ndeep learning, ontology engineering, and natural language processing. To\nenhance interpretability, we cluster features semantically and employ an\nexpectation maximization algorithm, assigning distinct weights to each group\nbased on its contribution to the tagging process. Our method achieves\ncompetitive tagging performance while offering a deeper understanding of the\ndecision-making process, paving the way for more transparent and user-centric\nmusic tagging systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17233v2",
    "published": "2025-05-22T19:15:48+00:00",
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17232v2",
    "title": "Tunable photogating in a molecular aggregate coupled graphene phototransistor",
    "authors": [
      "Abhinav Raina",
      "Maurizio Sanfilippo",
      "Chang-Ki Moon",
      "Manuel Neubauer",
      "Klaus Meerholz",
      "Malte C. Gather",
      "Klas Lindfors"
    ],
    "abstract": "We present a graphene photodetector coupled to a layer of aggregated organic\nsemiconductor. A graphene phototransistor is covered with a thin film of\nmerocyanine molecules. The aggregation of the molecular layer can be controlled\nby the deposition parameters and post-deposition annealing to obtain films\nranging from amorphous to a highly aggregated state. The molecular layer has a\nuniaxial structure with excitonic transitions whose transition dipole moments\nare well defined. The presence of the molecular layer results in an enormous\nincrease in the response of the phototransistor. We further demonstrate that\nthe signal-enhancement is due to p-photodoping of the graphene. The\nspectroscopic photoresponse suggests that the photodoping via monomers and\nmolecular aggregates takes place differently. Our photodetector is a platform\nto study the influence of molecular aggregation and order on charge transport\nprocesses between aggregated organic semiconductors and two-dimensional\nmaterials.",
    "pdf_url": "http://arxiv.org/pdf/2505.17232v2",
    "published": "2025-05-22T19:14:31+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.17231v1",
    "title": "ExeSQL: Self-Taught Text-to-SQL Models with Execution-Driven Bootstrapping for SQL Dialects",
    "authors": [
      "Jipeng Zhang",
      "Haolin Yang",
      "Kehao Miao",
      "Ruiyuan Zhang",
      "Renjie Pi",
      "Jiahui Gao",
      "Xiaofang Zhou"
    ],
    "abstract": "Recent text-to-SQL models have achieved strong performance, but their\neffectiveness remains largely confined to SQLite due to dataset limitations.\nHowever, real-world applications require SQL generation across multiple\ndialects with varying syntax and specialized features, which remains a\nchallenge for current models. The main obstacle in building a dialect-aware\nmodel lies in acquiring high-quality dialect-specific data. Data generated\npurely through static prompting - without validating SQLs via execution - tends\nto be noisy and unreliable. Moreover, the lack of real execution environments\nin the training loop prevents models from grounding their predictions in\nexecutable semantics, limiting generalization despite surface-level\nimprovements from data filtering. This work introduces ExeSQL, a text-to-SQL\nframework with execution-driven, agentic bootstrapping. The method consists of\niterative query generation, execution-based filtering (e.g., rejection\nsampling), and preference-based training, enabling the model to adapt to new\nSQL dialects through verifiable, feedback-guided learning. Experiments show\nthat ExeSQL bridges the dialect gap in text-to-SQL, achieving average\nimprovements of 15.2%, 10.38%, and 4.49% over GPT-4o on PostgreSQL, MySQL, and\nOracle, respectively, across multiple datasets of varying difficulty.",
    "pdf_url": "http://arxiv.org/pdf/2505.17231v1",
    "published": "2025-05-22T19:13:34+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17230v1",
    "title": "The Backup Program of the Dark Energy Spectroscopic Instrument's Milky Way Survey",
    "authors": [
      "Arjun Dey",
      "Sergey E. Koposov",
      "Joan R. Najita",
      "Andrew P. Cooper",
      "B. T. Gänsicke",
      "Adam D. Myers",
      "A. Raichoor",
      "Daniel J. Eisenstein",
      "E. F. Schlafly",
      "C. Allende Prieto",
      "Leandro Beraldo e Silva",
      "Ting S. Li",
      "M. Valluri",
      "Stéphanie Juneau",
      "Mika Lambert",
      "S. Li",
      "Guillaume F. Thomas",
      "Wenting Wang",
      "Alexander H. Riley",
      "N. Kizhuprakkat",
      "J. Aguilar",
      "S. Ahlen",
      "S. Bailey",
      "D. Bianchi",
      "D. Brooks",
      "T. Claybaugh",
      "A. Cuceu",
      "A. de la Macorra",
      "J. Della Costa",
      "Biprateep Dey",
      "P. Doel",
      "A. Font-Ribera",
      "J. E. Forero-Romero",
      "E. Gaztañaga",
      "S. Gontcho A Gontcho",
      "G. Gutierrez",
      "J. Guy",
      "C. Hahn",
      "K. Honscheid",
      "M. Ishak",
      "J. Jimenez",
      "R. Kehoe",
      "D. Kirkby",
      "T. Kisner",
      "A. Kremin",
      "C. Lamman",
      "M. Landriau",
      "L. Le Guillou",
      "M. E. Levi",
      "M. Manera",
      "P. Martini",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "S. Nadathur",
      "N. Palanque-Delabrouille",
      "W. J. Percival",
      "F. Prada",
      "I. Pérez-Ràfols",
      "G. Rossi",
      "E. Sanchez",
      "M. Schubnell",
      "J. Silber",
      "D. Sprayberry",
      "G. Tarlé",
      "B. A. Weaver",
      "R. H. Wechsler",
      "R. Zhou",
      "H. Zou"
    ],
    "abstract": "The Milky Way Backup Program (MWBP), a survey currently underway with the\nDark Energy Spectroscopic Instrument (DESI) on the Nicholas U. Mayall 4-m\nTelescope, works at the margins of the DESI Main surveys to obtain spectra of\nmillions of additional stars from the Gaia catalog. Efficiently utilizing\ntwilight times (<18 deg) and poor weather conditions, the MWBP extends the\nrange of stellar sources studied to both brighter magnitudes and lower Galactic\nlatitude and declination than the stars studied in DESI's Main Milky Way\nSurvey. While the MWBP prioritizes candidate giant stars selected from the Gaia\ncatalog (using color and parallax criteria), it also includes an unbiased\nsample of bright stars (i.e., 11.2 < G < 16 mag) as well as fainter sources (to\nG < 19 mag). As of March 1, 2025, the survey had obtained spectra of ~7 million\nstars, approximately 1.2 million of which are included in the DESI Data Release\n1. The full survey, when completed, will cover an area of more than 21,000\nsquare degrees and include approximately 10 million Gaia sources, roughly equal\nto the number of stellar spectra obtained through the DESI Main Survey, while\nonly utilizing <9% of all DESI observing time.",
    "pdf_url": "http://arxiv.org/pdf/2505.17230v1",
    "published": "2025-05-22T19:12:47+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17229v1",
    "title": "Modification of the uniform electron gas polarizational stopping power due to the interaction of the projectile with new collective modes at moderate and strong coupling",
    "authors": [
      "S. A. Syzganbayeva",
      "A. V. Filinov",
      "Jesus Ara",
      "A. B. Ashikbayeva",
      "A. Askaruly",
      "L. T. Yerimbetova",
      "M. D. Barriga-Carrasco",
      "Y. V. Arkhipov",
      "I. M. Tkachenko"
    ],
    "abstract": "This paper presents a detailed study of the polarizational stopping power of\na homogeneous electron gas in moderate and strong coupling regimes using the\nself-consistent version of the method of moments as the key theoretical\napproach capable of expressing the dynamic characteristics of the system in\nterms of the static ones, which are the moments. We develop a robust framework\nthat relies on nine sum rules and other exact relationships to analyze\nelectron-electron interactions and their impact on energy-loss processes. We\nderive an expression for the stopping power that takes into account both\nquantum statistical effects and electron correlation phenomena. Our results\ndemonstrate significant deviations from classical stopping power predictions,\nespecially under the strong coupling conditions when electron dynamics is\nhighly dependent on collective behavior and a projectile interacts with the\nsystem collective modes revealed in Phys. Rev. B 107, 195143 (2023). This work\nnot only advances the theoretical understanding of the homogeneous electron gas\nbut also has implications for practical applications in fields such as plasma\nphysics and materials science.",
    "pdf_url": "http://arxiv.org/pdf/2505.17229v1",
    "published": "2025-05-22T19:11:05+00:00",
    "categories": [
      "physics.plasm-ph",
      "quant-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17228v1",
    "title": "Automated Capability Evaluation of Foundation Models",
    "authors": [
      "Arash Afkanpour",
      "Omkar Dige",
      "Fatemeh Tavakoli"
    ],
    "abstract": "Current evaluation frameworks for foundation models rely heavily on fixed,\nmanually curated benchmarks, limiting their ability to capture the full breadth\nof model capabilities. This paper introduces Active learning for Capability\nEvaluation (ACE), a novel framework for scalable, automated, and fine-grained\nevaluation of foundation models. ACE leverages the knowledge embedded in\npowerful language models to decompose a domain into semantically meaningful\ncapabilities and generate diverse evaluation tasks, significantly reducing\nhuman effort. To maximize coverage and efficiency, ACE models a subject model's\nperformance as a capability function over a latent semantic space and uses\nactive learning to prioritize the evaluation of the most informative\ncapabilities. This adaptive evaluation strategy enables cost-effective\ndiscovery of strengths, weaknesses, and failure modes that static benchmarks\nmay miss. Our results suggest that ACE provides a more complete and informative\npicture of model capabilities, which is essential for safe and well-informed\ndeployment of foundation models.",
    "pdf_url": "http://arxiv.org/pdf/2505.17228v1",
    "published": "2025-05-22T19:09:57+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17227v1",
    "title": "Very fast general Electromagnetic Analysis with computational conformal geometry via Conformal Energy Minimization",
    "authors": [
      "Pengcheng Wan",
      "Zhong-Heng Tan",
      "S. T. Chui",
      "Tiexiang Li",
      "S. T. Yau"
    ],
    "abstract": "We recently found that the electromagnetic scattering problem can be very\nfast in an approach expressing the fields in terms of orthonormal basis\nfunctions. In this paper we apply computational conformal geometry with the\nconformal energy minimization (CEM) algorithm to make possible fast solution of\nfinite-frequency electromagnetic problems involving arbitrarily shaped,\nsimply-connected metallic surfaces. The CEM algorithm computes conformal maps\nwith minimal angular distortion, enabling the transformation of arbitrary\nsimply-connected surfaces into a disk, where orthogonal basis functions can be\ndefined and electromagnetic analysis can be significantly simplified. We\ndemonstrate the effectiveness and efficiency of our method by investigating the\nresonance characteristics of two metallic surfaces: a square plate and a\nfour-petal plate. Compared to traditional finite element methods (e.g.,\nCOMSOL), our approach achieves a three-order-of-magnitude improvement in\ncomputational efficiency, requiring only seconds to extract resonant\nfrequencies and fields. Moreover, it reveals low-energy, doubly degenerate\nresonance modes that are elusive to conventional methods. These findings not\nonly provide a powerful tool for analyzing electromagnetic fields on complex\ngeometries but also pave the way for the design of high-performance\nelectromagnetic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.17227v1",
    "published": "2025-05-22T19:08:08+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.17226v2",
    "title": "Secure and Private Federated Learning: Achieving Adversarial Resilience through Robust Aggregation",
    "authors": [
      "Kun Yang",
      "Neena Imam"
    ],
    "abstract": "Federated Learning (FL) enables collaborative machine learning across\ndecentralized data sources without sharing raw data. It offers a promising\napproach to privacy-preserving AI. However, FL remains vulnerable to\nadversarial threats from malicious participants, referred to as Byzantine\nclients, who can send misleading updates to corrupt the global model.\nTraditional aggregation methods, such as simple averaging, are not robust to\nsuch attacks. More resilient approaches, like the Krum algorithm, require prior\nknowledge of the number of malicious clients, which is often unavailable in\nreal-world scenarios. To address these limitations, we propose Average-rKrum\n(ArKrum), a novel aggregation strategy designed to enhance both the resilience\nand privacy guarantees of FL systems. Building on our previous work (rKrum),\nArKrum introduces two key innovations. First, it includes a median-based\nfiltering mechanism that removes extreme outliers before estimating the number\nof adversarial clients. Second, it applies a multi-update averaging scheme to\nimprove stability and performance, particularly when client data distributions\nare not identical. We evaluate ArKrum on benchmark image and text datasets\nunder three widely studied Byzantine attack types. Results show that ArKrum\nconsistently achieves high accuracy and stability. It performs as well as or\nbetter than other robust aggregation methods. These findings demonstrate that\nArKrum is an effective and practical solution for secure FL systems in\nadversarial environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.17226v2",
    "published": "2025-05-22T19:01:09+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17225v1",
    "title": "Reasoning Model is Stubborn: Diagnosing Instruction Overriding in Reasoning Models",
    "authors": [
      "Doohyuk Jang",
      "Yoonjeon Kim",
      "Chanjae Park",
      "Hyun Ryu",
      "Eunho Yang"
    ],
    "abstract": "Large language models have demonstrated remarkable proficiency in long and\ncomplex reasoning tasks. However, they frequently exhibit a problematic\nreliance on familiar reasoning patterns, a phenomenon we term \\textit{reasoning\nrigidity}. Despite explicit instructions from users, these models often\noverride clearly stated conditions and default to habitual reasoning\ntrajectories, leading to incorrect conclusions. This behavior presents\nsignificant challenges, particularly in domains such as mathematics and logic\npuzzle, where precise adherence to specified constraints is critical. To\nsystematically investigate reasoning rigidity, a behavior largely unexplored in\nprior work, we introduce a expert-curated diagnostic set, \\dataset{}. Our\ndataset includes specially modified variants of existing mathematical\nbenchmarks, namely AIME and MATH500, as well as well-known puzzles deliberately\nredesigned to require deviation from familiar reasoning strategies. Using this\ndataset, we identify recurring contamination patterns that occur when models\ndefault to ingrained reasoning. Specifically, we categorize this contamination\ninto three distinctive modes: (i) Interpretation Overload, (ii) Input Distrust,\nand (iii) Partial Instruction Attention, each causing models to ignore or\ndistort provided instructions. We publicly release our diagnostic set to\nfacilitate future research on mitigating reasoning rigidity in language models.",
    "pdf_url": "http://arxiv.org/pdf/2505.17225v1",
    "published": "2025-05-22T19:00:01+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17224v1",
    "title": "Dynamic Encryption-Based Cloud Security Model using Facial Image and Password-based Key Generation for Multimedia Data",
    "authors": [
      "Naima Sultana Ayesha",
      "Mehrin Anannya",
      "Md Biplob Hosen",
      "Rashed Mazumder"
    ],
    "abstract": "In this cloud-dependent era, various security techniques, such as encryption,\nsteganography, and hybrid approaches, have been utilized in cloud computing to\nenhance security, maintain enormous storage capacity, and provide ease of\naccess. However, the absence of data type-specific encryption and decryption\nprocedures renders multimedia data vulnerable. To address this issue, this\nstudy presents a dynamic encryption-based security architecture that adapts\nencryption methods to any file type, using keys generated from facial images\nand passwords. Four diverse datasets are created, each with a consistent size\nof 2GB, containing varying combinations of image, audio (MP3 and MPEG), video,\ntext, CSV, PPT, and PDF files, to implement the proposed methodology. AES is\nused to encrypt image data, AES-CTR is employed for audio or video data to meet\nreal-time streaming needs, and Blowfish is used for other types of data.\nPerformance analysis on all four datasets is conducted using AWS servers, where\nDATASET-1 demonstrates the best performance compared to the others.",
    "pdf_url": "http://arxiv.org/pdf/2505.17224v1",
    "published": "2025-05-22T18:55:45+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17223v1",
    "title": "REACT 2025: the Third Multiple Appropriate Facial Reaction Generation Challenge",
    "authors": [
      "Siyang Song",
      "Micol Spitale",
      "Xiangyu Kong",
      "Hengde Zhu",
      "Cheng Luo",
      "Cristina Palmero",
      "German Barquero",
      "Sergio Escalera",
      "Michel Valstar",
      "Mohamed Daoudi",
      "Tobias Baur",
      "Fabien Ringeval",
      "Andrew Howes",
      "Elisabeth Andre",
      "Hatice Gunes"
    ],
    "abstract": "In dyadic interactions, a broad spectrum of human facial reactions might be\nappropriate for responding to each human speaker behaviour. Following the\nsuccessful organisation of the REACT 2023 and REACT 2024 challenges, we are\nproposing the REACT 2025 challenge encouraging the development and benchmarking\nof Machine Learning (ML) models that can be used to generate multiple\nappropriate, diverse, realistic and synchronised human-style facial reactions\nexpressed by human listeners in response to an input stimulus (i.e.,\naudio-visual behaviours expressed by their corresponding speakers). As a key of\nthe challenge, we provide challenge participants with the first natural and\nlarge-scale multi-modal MAFRG dataset (called MARS) recording 137 human-human\ndyadic interactions containing a total of 2856 interaction sessions covering\nfive different topics. In addition, this paper also presents the challenge\nguidelines and the performance of our baselines on the two proposed\nsub-challenges: Offline MAFRG and Online MAFRG, respectively. The challenge\nbaseline code is publicly available at\nhttps://github.com/reactmultimodalchallenge/baseline_react2025",
    "pdf_url": "http://arxiv.org/pdf/2505.17223v1",
    "published": "2025-05-22T18:55:23+00:00",
    "categories": [
      "cs.CV",
      "68T40"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17222v2",
    "title": "Humans Hallucinate Too: Language Models Identify and Correct Subjective Annotation Errors With Label-in-a-Haystack Prompts",
    "authors": [
      "Georgios Chochlakis",
      "Peter Wu",
      "Arjun Bedi",
      "Marcus Ma",
      "Kristina Lerman",
      "Shrikanth Narayanan"
    ],
    "abstract": "Modeling complex subjective tasks in Natural Language Processing, such as\nrecognizing emotion and morality, is considerably challenging due to\nsignificant variation in human annotations. This variation often reflects\nreasonable differences in semantic interpretations rather than mere noise,\nnecessitating methods to distinguish between legitimate subjectivity and error.\nWe address this challenge by exploring label verification in these contexts\nusing Large Language Models (LLMs). First, we propose a simple In-Context\nLearning binary filtering baseline that estimates the reasonableness of a\ndocument-label pair. We then introduce the Label-in-a-Haystack setting: the\nquery and its label(s) are included in the demonstrations shown to LLMs, which\nare prompted to predict the label(s) again, while receiving task-specific\ninstructions (e.g., emotion recognition) rather than label copying. We show how\nthe failure to copy the label(s) to the output of the LLM are task-relevant and\ninformative. Building on this, we propose the Label-in-a-Haystack Rectification\n(LiaHR) framework for subjective label correction: when the model outputs\ndiverge from the reference gold labels, we assign the generated labels to the\nexample instead of discarding it. This approach can be integrated into\nannotation pipelines to enhance signal-to-noise ratios. Comprehensive analyses,\nhuman evaluations, and ecological validity studies verify the utility of LiaHR\nfor label correction. Code is available at https://github.com/gchochla/liahr.",
    "pdf_url": "http://arxiv.org/pdf/2505.17222v2",
    "published": "2025-05-22T18:55:22+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.23783v1",
    "title": "Boosting In-Context Learning in LLMs Through the Lens of Classical Supervised Learning",
    "authors": [
      "Korel Gundem",
      "Juncheng Dong",
      "Dennis Zhang",
      "Vahid Tarokh",
      "Zhengling Qi"
    ],
    "abstract": "In-Context Learning (ICL) allows Large Language Models (LLMs) to adapt to new\ntasks with just a few examples, but their predictions often suffer from\nsystematic biases, leading to unstable performances in classification. While\ncalibration techniques are proposed to mitigate these biases, we show that, in\nthe logit space, many of these methods are equivalent to merely shifting the\nLLM's decision boundary without having the ability to alter its orientation.\nThis proves inadequate when biases cause the LLM to be severely misdirected. To\naddress these limitations and provide a unifying framework, we propose\nSupervised Calibration (SC), a loss-minimization based framework which learns\nan optimal, per-class affine transformation of the LLM's predictive\nprobabilities in the logit space without requiring external data beyond the\ncontext. By using a more expressive functional class, SC not only subsumes many\nexisting calibration methods in ICL as special cases, but also enables the\nability to alter and even completely reverse the orientation of the LLM's\ndecision boundary. Furthermore, SC's loss-based nature facilitates the seamless\nintegration of two purpose-built regularization techniques: context-invariance\nand directional trust-region. The former is designed to tackle the instability\nissue in ICL, while the latter controls the degree of calibration. Finally, SC\ndelivers state-of-the-art performance over calibration baselines in the 4-shot,\n8-shot, and 16-shot settings across all nine datasets for\nMistral-7B-Instruct-v0.3, LLaMA-2-7B-chat, and Qwen2-7B-Instruct.",
    "pdf_url": "http://arxiv.org/pdf/2505.23783v1",
    "published": "2025-05-22T18:55:06+00:00",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.17221v1",
    "title": "Investigating the 2024 swarm like activity offshore Kefalonia Island aided by Machine Learning algorithms",
    "authors": [
      "V. Anagnostou",
      "E. Papadimitriou",
      "V. Karakostas",
      "T. Back"
    ],
    "abstract": "In March 2024, a swarm like seismic activity occurred north of Kefalonia\nIsland, in the central Ionian Islands area. Following a machine-learning aided\nworkflow, we compiled an enhanced seismic catalog of 2495 low to moderate\nmagnitude earthquakes throughout a 2 month period. Spatiotemporal analysis\nreveals a narrow epicentral distribution of nearly E-W alignment, approximately\n5km long, much longer than the length anticipated by common scaling laws for\nthe aftershock area extension of the stronger earthquakes that did not exceed\nM4.0. The findings of the study indicate that the swarm like activity is\npossibly triggered by a combination of fluid movements and Coulomb stress\nchanges. The strongest earthquakes appear beyond the diffusivity curves that\nare within the expected upper crust values and are possibly triggered by stress\ntransfer by the first strong earthquake. Fluid effects rapidly diminish within\nthe first days, while the changes in the stress field due to the combined\neffect of the two strongest earthquakes promote the triggering of most of the\nweaker earthquakes of the excitation. The findings of this study reinforce the\nidea of swarm-like activity initiating due to interactions between stress\nredistributions and fluid movements in the upper crust. The rapid employment of\nML tools for the compilation of robust seismic catalogs can vastly improve our\nunderstanding of the processes that drive seismicity in highly productive areas\nsuch as the Central Ionian Islands, thus leading to improved seismic hazard\nassessment.",
    "pdf_url": "http://arxiv.org/pdf/2505.17221v1",
    "published": "2025-05-22T18:54:49+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17220v1",
    "title": "On the nature of the black hole information problem",
    "authors": [
      "Thiago T. Bergamaschi"
    ],
    "abstract": "The aim of this work is to present the black hole information problem and\ndiscuss the assumptions and hypotheses necessary for its formulation. As the\nproblem arises in the framework of semiclassical gravity, we first review the\nnecessary notions to describe Lorentzian manifolds equipped with physical\nproperties, as well as the physical concepts of the theory that describes the\ngravitational interaction as the curvature of spacetime, general relativity.\nFrom its classical perspective, we develop the formalism to study the dynamical\naspects of black holes in spacetimes obeying suitable causality conditions.\nEquipped with conjectures that nature censors naked singularities and that\nblack holes reach a stationary configuration after they form, the black hole\nuniqueness theorems allow us to review several relations for the geometrical\nquantities associated with them. Following considerations of the other\nfundamental interactions, which are described by quantum field theory, we\nreview the arguments in the formalism of quantum field theory in curved\nspacetime that give rise to the effective particle creation effect, its\napproximately thermal character, and the concept of black hole evaporation.\nWith a precise quantification of information in quantum mechanics and assuming\nthat the condition for physically acceptable states is given by the Hadamard\ncondition, we review the result that entanglement between causally\ncomplementary regions is an intrinsic feature of quantum field theory. As a\nconsequence, we discuss how the formation and complete evaporation of black\nholes leads to information loss. Conscious that such a prediction follows if no\ndeviations from the semiclassical picture occur at the Planck scale, we discuss\nalternatives to this nonunitary dynamical evolution and formulate the black\nhole information problem. Lastly, we analyze the assumptions and hypotheses\nthat lead to the problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.17220v1",
    "published": "2025-05-22T18:52:50+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17219v1",
    "title": "Compactness of the $L_p$ dual Minkowski problem in $\\mathbb{R}^3$",
    "authors": [
      "Karoly J. Boroczky",
      "Shibing Chen",
      "Weiru Liu",
      "Christos Saroglou"
    ],
    "abstract": "We prove the $C^0$ estimate for the $L_p$ $q$th dual Minkowski problem on\n$S^2$ under fairly general conditions; namely, when $p$ lies in [0,1) and\n$q>2+p$, and the $L_p$ $q$th dual curvarture is bounded and bounded away from\nzero. We note that it is known that the analogous $C^0$ estimate does not hold\nif $p<-1$ and $q=3$. As a corollary of our $C^0$ estimate, we deduce the\nuniqueness of the solution of the near isotropic $q$th $L_p$ dual Minkowski\nproblem on $S^2$ if $q$ is close to 3 and the $q$th $L_p$ dual curvature is\nHolder close to be the constant one function.",
    "pdf_url": "http://arxiv.org/pdf/2505.17219v1",
    "published": "2025-05-22T18:48:51+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17218v1",
    "title": "Effective Reinforcement Learning for Reasoning in Language Models",
    "authors": [
      "Lianghuan Huang",
      "Shuo Li",
      "Sagnik Anupam",
      "Insup Lee",
      "Osbert Bastani"
    ],
    "abstract": "Reinforcement learning (RL) has emerged as a promising strategy for improving\nthe reasoning capabilities of language models (LMs) in domains such as\nmathematics and coding. However, most modern RL algorithms were designed to\ntarget robotics applications, which differ significantly from LM reasoning. We\nanalyze RL algorithm design decisions for LM reasoning, for both accuracy and\ncomputational efficiency, focusing on relatively small models due to\ncomputational constraints. Our findings are: (i) on-policy RL significantly\noutperforms supervised fine-tuning (SFT), (ii) PPO-based off-policy updates\nincrease accuracy instead of reduce variance, and (iii) removing KL divergence\ncan lead to more concise generations and higher accuracy. Furthermore, we find\nthat a key bottleneck to computational efficiency is that the optimal batch\nsizes for inference and backpropagation are different. We propose a novel\nalgorithm, DASH, that performs preemptive sampling (i.e., sample a large batch\nand accumulate gradient updates in small increments), and gradient filtering\n(i.e., drop samples with small advantage estimates). We show that DASH reduces\ntraining time by 83% compared to a standard implementation of GRPO without\nsacrificing accuracy. Our findings provide valuable insights on designing\neffective RL algorithms for LM reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.17218v1",
    "published": "2025-05-22T18:48:09+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17217v2",
    "title": "Mitigating Gender Bias via Fostering Exploratory Thinking in LLMs",
    "authors": [
      "Kangda Wei",
      "Hasnat Md Abdullah",
      "Ruihong Huang"
    ],
    "abstract": "Large Language Models (LLMs) often exhibit gender bias, resulting in unequal\ntreatment of male and female subjects across different contexts. To address\nthis issue, we propose a novel data generation framework that fosters\nexploratory thinking in LLMs. Our approach prompts models to generate story\npairs featuring male and female protagonists in structurally identical, morally\nambiguous scenarios, then elicits and compares their moral judgments. When\ninconsistencies arise, the model is guided to produce balanced, gender-neutral\njudgments. These story-judgment pairs are used to fine-tune or optimize the\nmodels via Direct Preference Optimization (DPO). Experimental results show that\nour method significantly reduces gender bias while preserving or even enhancing\ngeneral model capabilities. We will release the code and generated data. We\nrelease the code and generated data at:\nhttps://github.com/WeiKangda/LLMs-Exploratory-Bias-Mitigation/tree/main.",
    "pdf_url": "http://arxiv.org/pdf/2505.17217v2",
    "published": "2025-05-22T18:46:50+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17216v1",
    "title": "Primitive variable regularization to derive novel Hyperbolic Shallow Water Moment Equations",
    "authors": [
      "Julian Koellermeier"
    ],
    "abstract": "Shallow Water Moment Equations are reduced-order models for free-surface\nflows that employ a vertical velocity expansion and derive additional so-called\nmoment equations for the expansion coefficients. Among desirable analytical\nproperties for such systems of equations are hyperbolicity, accuracy, correct\nmomentum equation, and interpretable steady states. In this paper, we show\nanalytically that existing models fail at different of these properties and we\nderive new models overcoming the disadvantages. This is made possible by\nperforming a hyperbolic regularization not in the convective variables (as done\nin the existing models) but in the primitive variables. Via analytical\ntransformations between the convective and primitive system, we can prove\nhyperbolicity and compute analytical steady states of the new models.\nSimulating a dam-break test case, we demonstrate the accuracy of the new models\nand show that it is essential for accuracy to preserve the momentum equation.",
    "pdf_url": "http://arxiv.org/pdf/2505.17216v1",
    "published": "2025-05-22T18:46:01+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.AP",
      "physics.comp-ph",
      "physics.flu-dyn",
      "35L65, 76B15, 35P15"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.13770v1",
    "title": "CDST: Color Disentangled Style Transfer for Universal Style Reference Customization",
    "authors": [
      "Shiwen Zhang",
      "Zhuowei Chen",
      "Lang Chen",
      "Yanze Wu"
    ],
    "abstract": "We introduce Color Disentangled Style Transfer (CDST), a novel and efficient\ntwo-stream style transfer training paradigm which completely isolates color\nfrom style and forces the style stream to be color-blinded. With one same\nmodel, CDST unlocks universal style transfer capabilities in a tuning-free\nmanner during inference. Especially, the characteristics-preserved style\ntransfer with style and content references is solved in the tuning-free way for\nthe first time. CDST significantly improves the style similarity by\nmulti-feature image embeddings compression and preserves strong editing\ncapability via our new CDST style definition inspired by Diffusion UNet\ndisentanglement law. By conducting thorough qualitative and quantitative\nexperiments and human evaluations, we demonstrate that CDST achieves\nstate-of-the-art results on various style transfer tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.13770v1",
    "published": "2025-05-22T18:44:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17215v1",
    "title": "Smooth critical points of eigenvalues on the torus of magnetic perturbations of graphs",
    "authors": [
      "Lior Alon",
      "Gregory Berkolaiko",
      "Mark Goresky"
    ],
    "abstract": "Motivated by the nodal distribution universality conjecture for discrete\noperators on graphs and by the spectral analysis of their maximal abelian\ncovers, we consider a family of Hermitian matrices $h_{\\alpha}$ obtained by\nvarying the complex phases of individual matrix elements. This family is\nparametrized by a $\\beta$-dimensional torus, where $\\beta$ is the first Betti\nnumber of the underlying graph. The eigenvalues of each matrix are ordered,\nenabling us to treat the $k$-th eigenvalue $\\lambda_k$ as a function on the\ntorus. We classify the smooth critical points of $\\lambda_k$, describe their\nstructure and Morse index in terms of the support and nodal count, that is, the\nnumber of sign changes between adjacent vertices of the corresponding\neigenvector. In general, the families under consideration exhibit critical\nsubmanifolds rather than isolated critical points. These critical manifolds\nappear frequently and cannot be removed through perturbations. We provide an\nalgorithmic way of determining all critical submanifolds by investigating\nfinitely many eigenvalue problems: the $2^\\beta$ real symmetric matrices\n$h_\\alpha$ in the family under consideration as well as their principal minors.",
    "pdf_url": "http://arxiv.org/pdf/2505.17215v1",
    "published": "2025-05-22T18:44:10+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "05C50, 58J50, 81Q10, 81Q35"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17214v1",
    "title": "MEDMKG: Benchmarking Medical Knowledge Exploitation with Multimodal Knowledge Graph",
    "authors": [
      "Xiaochen Wang",
      "Yuan Zhong",
      "Lingwei Zhang",
      "Lisong Dai",
      "Ting Wang",
      "Fenglong Ma"
    ],
    "abstract": "Medical deep learning models depend heavily on domain-specific knowledge to\nperform well on knowledge-intensive clinical tasks. Prior work has primarily\nleveraged unimodal knowledge graphs, such as the Unified Medical Language\nSystem (UMLS), to enhance model performance. However, integrating multimodal\nmedical knowledge graphs remains largely underexplored, mainly due to the lack\nof resources linking imaging data with clinical concepts. To address this gap,\nwe propose MEDMKG, a Medical Multimodal Knowledge Graph that unifies visual and\ntextual medical information through a multi-stage construction pipeline. MEDMKG\nfuses the rich multimodal data from MIMIC-CXR with the structured clinical\nknowledge from UMLS, utilizing both rule-based tools and large language models\nfor accurate concept extraction and relationship modeling. To ensure graph\nquality and compactness, we introduce Neighbor-aware Filtering (NaF), a novel\nfiltering algorithm tailored for multimodal knowledge graphs. We evaluate\nMEDMKG across three tasks under two experimental settings, benchmarking\ntwenty-four baseline methods and four state-of-the-art vision-language\nbackbones on six datasets. Results show that MEDMKG not only improves\nperformance in downstream medical tasks but also offers a strong foundation for\ndeveloping adaptive and robust strategies for multimodal knowledge integration\nin medical artificial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2505.17214v1",
    "published": "2025-05-22T18:41:46+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17213v1",
    "title": "Wind shear and the role of eddy vapor transport in driving water convection on Jupiter",
    "authors": [
      "Ramanakumar Sankar",
      "Michael H Wong",
      "Csaba Palotai",
      "Shawn Brueshaber"
    ],
    "abstract": "Recent observations of convection in the jovian atmosphere have demonstrated\nthat convection is strongly concentrated at specific locations on planet. For\ninstance, observations of lightning show that the cyclonic features (e.g,.\nbelts and folded filamentary regions - FFRs) show increased convective activity\ncompared to anti-cyclonic regions. Meanwhile, the distribution of ammonia and\nwater vapor show a large enrichment near the equator, which is also suggestive\nof strong upwelling and convective activity. Marrying these different\nobservations is challenging due to a lack of data concerning the\ncharacteristics of the deep jovian atmosphere, and a resulting inability to\nobserve the true deep source of the various convective phenomena. To understand\nthe nature of these convective events and \\paperedit{the role of the }\nstructure of the deep atmosphere \\paperedit{in driving convective events}, we\nrun simulations of cloud formation and convection using the Explicit Planetary\nhybrid-Isentropic Coordinate General Circulation Model (EPIC GCM). We vary the\ndynamics of the atmosphere by parameterizing the deep wind shear and studying\nthe resulting effect on the strength, frequency and distribution of convective\nstorms. We find that convection in our model is strongly tied to the local\ndynamics and the deep wind shear. We further decompose the generation of\nconvective available potential energy (CAPE) into three components (thermal,\nmechanical, and moist/chemical), and find that the chemical mechanism is the\nstrongest component, working to advect water vapor from moisture-rich regions\nto moisture-poor regions and to drive convection along a ``moisture front.''",
    "pdf_url": "http://arxiv.org/pdf/2505.17213v1",
    "published": "2025-05-22T18:41:43+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17212v2",
    "title": "Engineering Altermagnetism via Layer Shifts and Spin Order in Bilayer MnPS$_3$",
    "authors": [
      "J. W. González",
      "T. Brumme",
      "E. Suárez Morell",
      "A. M. León"
    ],
    "abstract": "Altermagnetic materials combine compensated magnetic order with\nmomentum-dependent spin splitting, offering a fundamentally new route for\nspintronic functionality beyond conventional ferromagnets and antiferromagnets.\nWhile most studies have focused on three-dimensional compounds, the emergence\nof altermagnetism in few-layer two-dimensional materials remains largely\nunexplored. Here, we demonstrate that bilayer MnPS$_3$, a prototypical 2D van\nder Waals magnet, can host stacking-induced altermagnetic phases. Using\ndensity-functional theory and spin-Laue symmetry analysis, we show that\ninterlayer spin alignment and lateral displacement act as coupled symmetry\ncontrol parameters that switch the system between Type II (collinear AFM) and\nType III (altermagnetic) phases. Our systematic exploration reveals how\nspecific stacking geometries enable momentum-dependent spin polarization\nwithout net magnetization, even in the absence of spin-orbit coupling. These\nresults establish stacking engineering as a powerful, purely structural route\nfor designing tunable altermagnetic states in 2D magnets, opening pathways\ntoward symmetry-driven spintronic and magnetoelectronic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.17212v2",
    "published": "2025-05-22T18:38:39+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.17211v1",
    "title": "Vector Dark Matter in a $U(1)_X$ extended 2HDM",
    "authors": [
      "Nandini Das",
      "Juhi Dutta",
      "Dilip Kumar Ghosh",
      "Santosh Kumar Rai"
    ],
    "abstract": "We investigate the possibility of having a vector boson dark matter in a\n$U(1)_X$ extended two-Higgs-doublet model (2HDM) setup. The gauge boson gains\nmass when a SM singlet complex scalar, which is charged under the dark $U(1)_X$\nsymmetry, acquires vacuum expectation value (\\textit{vev}). This scalar acts as\nthe connection between the SM sector and DM via the Higgs portal. An additional\nexact charge conjugation symmetry inhibits the mixing of this gauge boson with\nthe photon, thereby confirming the stability of DM. On the other hand, 2HDM\nwith Type I $Z_2$ restriction can offer a non-standard Higgs in the lighter\nmass range. This freedom allows us to accommodate dark matter mass in the\n(40-60) GeV regime where the direct detection constraints are strongest. We\nstudy the dark matter phenomenology of such a model while taking care of all\npossible theoretical and experimental constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.17211v1",
    "published": "2025-05-22T18:35:51+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17210v1",
    "title": "Assessing the generalization performance of SAM for ureteroscopy scene understanding",
    "authors": [
      "Martin Villagrana",
      "Francisco Lopez-Tiro",
      "Clement Larose",
      "Gilberto Ochoa-Ruiz",
      "Christian Daul"
    ],
    "abstract": "The segmentation of kidney stones is regarded as a critical preliminary step\nto enable the identification of urinary stone types through machine- or\ndeep-learning-based approaches. In urology, manual segmentation is considered\ntedious and impractical due to the typically large scale of image databases and\nthe continuous generation of new data. In this study, the potential of the\nSegment Anything Model (SAM) -- a state-of-the-art deep learning framework --\nis investigated for the automation of kidney stone segmentation. The\nperformance of SAM is evaluated in comparison to traditional models, including\nU-Net, Residual U-Net, and Attention U-Net, which, despite their efficiency,\nfrequently exhibit limitations in generalizing to unseen datasets. The findings\nhighlight SAM's superior adaptability and efficiency. While SAM achieves\ncomparable performance to U-Net on in-distribution data (Accuracy: 97.68 +\n3.04; Dice: 97.78 + 2.47; IoU: 95.76 + 4.18), it demonstrates significantly\nenhanced generalization capabilities on out-of-distribution data, surpassing\nall U-Net variants by margins of up to 23 percent.",
    "pdf_url": "http://arxiv.org/pdf/2505.17210v1",
    "published": "2025-05-22T18:35:37+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17209v1",
    "title": "LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios",
    "authors": [
      "Huaiyuan Yao",
      "Pengfei Li",
      "Bu Jin",
      "Yupeng Zheng",
      "An Liu",
      "Lisen Mu",
      "Qing Su",
      "Qian Zhang",
      "Yilun Chen",
      "Peng Li"
    ],
    "abstract": "Recent advances in autonomous driving research towards motion planners that\nare robust, safe, and adaptive. However, existing rule-based and data-driven\nplanners lack adaptability to long-tail scenarios, while knowledge-driven\nmethods offer strong reasoning but face challenges in representation, control,\nand real-world evaluation. To address these challenges, we present LiloDriver,\na lifelong learning framework for closed-loop motion planning in long-tail\nautonomous driving scenarios. By integrating large language models (LLMs) with\na memory-augmented planner generation system, LiloDriver continuously adapts to\nnew scenarios without retraining. It features a four-stage architecture\nincluding perception, scene encoding, memory-based strategy refinement, and\nLLM-guided reasoning. Evaluated on the nuPlan benchmark, LiloDriver achieves\nsuperior performance in both common and rare driving scenarios, outperforming\nstatic rule-based and learning-based planners. Our results highlight the\neffectiveness of combining structured memory and LLM reasoning to enable\nscalable, human-like motion planning in real-world autonomous driving. Our code\nis available at https://github.com/Hyan-Yao/LiloDriver.",
    "pdf_url": "http://arxiv.org/pdf/2505.17209v1",
    "published": "2025-05-22T18:33:08+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "68T05",
      "I.2.9; I.2.7; I.2.6"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17208v1",
    "title": "RetroChat: Designing for the Preservation of Past Digital Experiences",
    "authors": [
      "Suifang Zhou",
      "Kexue Fu",
      "Huanmin Yi",
      "Ray Lc"
    ],
    "abstract": "Rapid changes in social networks have transformed the way people express\nthemselves, turning past neologisms, values, and mindsets embedded in these\nexpressions into online heritage. How can we preserve these expressions as\ncultural heritage? Instead of traditional archiving methods for static\nmaterial, we designed an interactive and experiential form of archiving for\nChinese social networks. Using dialogue data from 2000-2010 on early Chinese\nsocial media, we developed a GPT-driven agent within a retro chat interface,\nemulating the language and expression style of the period for interaction.\nResults from a qualitative study with 18 participants show that the design\ncaptures the past chatting experience and evokes memory flashbacks and\nnostalgia feeling through conversation. Participants, particularly those\nfamiliar with the era, adapted their language to match the agent's chatting\nstyle. This study explores how the design of preservation methods for digital\nexperiences can be informed by experiential representations supported by\ngenerative tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.17208v1",
    "published": "2025-05-22T18:33:05+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.17207v1",
    "title": "Content Moderation in TV Search: Balancing Policy Compliance, Relevance, and User Experience",
    "authors": [
      "Adeep Hande",
      "Kishorekumar Sundararajan",
      "Sardar Hamidian",
      "Ferhan Ture"
    ],
    "abstract": "Millions of people rely on search functionality to find and explore content\non entertainment platforms. Modern search systems use a combination of\ncandidate generation and ranking approaches, with advanced methods leveraging\ndeep learning and LLM-based techniques to retrieve, generate, and categorize\nsearch results. Despite these advancements, search algorithms can still surface\ninappropriate or irrelevant content due to factors like model unpredictability,\nmetadata errors, or overlooked design flaws. Such issues can misalign with\nproduct goals and user expectations, potentially harming user trust and\nbusiness outcomes. In this work, we introduce an additional monitoring layer\nusing Large Language Models (LLMs) to enhance content moderation. This\nadditional layer flags content if the user did not intend to search for it.\nThis approach serves as a baseline for product quality assurance, with\ncollected feedback used to refine the initial retrieval mechanisms of the\nsearch model, ensuring a safer and more reliable user experience.",
    "pdf_url": "http://arxiv.org/pdf/2505.17207v1",
    "published": "2025-05-22T18:32:39+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17206v2",
    "title": "FB-RAG: Improving RAG with Forward and Backward Lookup",
    "authors": [
      "Kushal Chawla",
      "Alfy Samuel",
      "Anoop Kumar",
      "Daben Liu"
    ],
    "abstract": "Traditional Retrieval-Augmented Generation (RAG) struggles with complex\nqueries that lack strong signals to retrieve the most relevant context, forcing\na trade-off between choosing a small context that misses key information and a\nlarge context that confuses the LLM. To address this, we propose\nForward-Backward RAG (FB-RAG), a new training-free framework based on a simple\nyet powerful forward-looking strategy. FB-RAG employs a light-weight LLM to\npeek into potential future generations, using evidence from multiple sampled\noutputs to precisely identify the most relevant context for a final, more\npowerful generator. This improves performance without complex finetuning or\nReinforcement Learning common in prior work. Across 9 datasets, FB-RAG\nconsistently delivers strong results. Further, the performance gains can be\nachieved with reduced latency due to a shorter, more focused prompt for the\npowerful generator. On EN.QA dataset, FB-RAG matches the leading baseline with\nover 48% latency reduction or achieves an 8% performance improvement with a 10%\nlatency reduction. Our analysis finds cases where even when the forward-looking\nLLM fails to generate correct answers, its attempts are sufficient to guide the\nfinal model to an accurate response, demonstrating how smaller LLMs can\nsystematically improve the performance and efficiency of larger ones.",
    "pdf_url": "http://arxiv.org/pdf/2505.17206v2",
    "published": "2025-05-22T18:31:52+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17205v1",
    "title": "Reconstructing Cosmic History with Machine Learning: A Study Using CART, MLPR, and SVR",
    "authors": [
      "Agripino Sousa-Neto",
      "Maria Aldinez Dantas"
    ],
    "abstract": "In this work, we reconstruct cosmic history via supervised learning through\nthree methods: Classification and Regression Trees (CART), Multi-layer\nPerceptron Regressor (MLPR), and Support Vector Regression (SVR). For this\npurpose, we use ages of simulated galaxies based on 32 massive, early-time,\npassively evolving galaxies in the range $0.12 < z < 1.85$, with absolute ages\ndetermined. Using this sample, we simulate subsamples of 100, 1000, 2000, 3334,\n6680 points, through the Monte Carlo Method and adopting a Gaussian\ndistribution centering on a spatially flat $\\Lambda$CDM as a fiducial model. We\nfound that the SVR method demonstrates the best performance during the process.\nThe methods MLPR and CART also present satisfactory performance, but their mean\nsquare errors are greater than those found for the SVR. Using the reconstructed\nages, we estimate the matter density parameter and equation of state (EoS) and\nour analysis found the SVR with 600 predict points obtains\n$\\Omega_m=0.329\\pm{}^{0.010}_{0.010}$ and the dark energy EoS parameter\n$\\omega= -1.054\\pm{}^{0.087}_{0.126}$, which are consistent with the values\nfrom the literature. We highlight that we found the most consistent results for\nthe subsample with 2000 points, which returns 600 predicted points and has the\nbest performance, considering its small sample size and high accuracy. We\npresent the reconstructed curves of galaxy ages and the best fits cosmological\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.17205v1",
    "published": "2025-05-22T18:27:29+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.12031v1",
    "title": "Improving Generalization in Heterogeneous Federated Continual Learning via Spatio-Temporal Gradient Matching with Prototypical Coreset",
    "authors": [
      "Minh-Duong Nguyen",
      "Le-Tuan Nguyen",
      "Quoc-Viet Pham"
    ],
    "abstract": "Federated Continual Learning (FCL) has recently emerged as a crucial research\narea, as data from distributed clients typically arrives as a stream, requiring\nsequential learning. This paper explores a more practical and challenging FCL\nsetting, where clients may have unrelated or even conflicting data and tasks.\nIn this scenario, statistical heterogeneity and data noise can create spurious\ncorrelations, leading to biased feature learning and catastrophic forgetting.\nExisting FCL approaches often use generative replay to create pseudo-datasets\nof previous tasks. However, generative replay itself suffers from catastrophic\nforgetting and task divergence among clients, leading to overfitting in FCL.\nExisting FCL approaches often use generative replay to create pseudo-datasets\nof previous tasks. However, generative replay itself suffers from catastrophic\nforgetting and task divergence among clients, leading to overfitting in FCL. To\naddress these challenges, we propose a novel approach called Spatio-Temporal\ngrAdient Matching with network-free Prototype (STAMP). Our contributions are\nthreefold: 1) We develop a model-agnostic method to determine subset of samples\nthat effectively form prototypes when using a prototypical network, making it\nresilient to continual learning challenges; 2) We introduce a spatio-temporal\ngradient matching approach, applied at both the client-side (temporal) and\nserver-side (spatial), to mitigate catastrophic forgetting and data\nheterogeneity; 3) We leverage prototypes to approximate task-wise gradients,\nimproving gradient matching on the client-side. Extensive experiments\ndemonstrate our method's superiority over existing baselines.",
    "pdf_url": "http://arxiv.org/pdf/2506.12031v1",
    "published": "2025-05-22T18:26:51+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68",
      "I.2.11"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17204v1",
    "title": "Liouville PDE-based sliced-Wasserstein flow for fair regression",
    "authors": [
      "Pilhwa Lee",
      "Jayshawn Cooper"
    ],
    "abstract": "The sliced Wasserstein flow (SWF), a nonparametric and implicit generative\ngradient flow, is applied to fair regression. We have improved the SWF in a few\naspects. First, the stochastic diffusive term from the Fokker-Planck\nequation-based Monte Carlo is transformed to Liouville partial differential\nequation (PDE)-based transport with density estimation, however, without the\ndiffusive term. Now, the computation of the Wasserstein barycenter is\napproximated by the SWF barycenter with the prescription of Kantorovich\npotentials for the induced gradient flow to generate its samples. These two\nefforts improve the convergence in training and testing SWF and SWF barycenters\nwith reduced variance. Applying the generative SWF barycenter for fair\nregression demonstrates competent profiles in the accuracy-fairness Pareto\ncurves.",
    "pdf_url": "http://arxiv.org/pdf/2505.17204v1",
    "published": "2025-05-22T18:21:54+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.PR",
      "math.ST",
      "stat.CO",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.17203v1",
    "title": "Transfer Faster, Price Smarter: Minimax Dynamic Pricing under Cross-Market Preference Shift",
    "authors": [
      "Yi Zhang",
      "Elynn Chen",
      "Yujun Yan"
    ],
    "abstract": "We study contextual dynamic pricing when a target market can leverage K\nauxiliary markets -- offline logs or concurrent streams -- whose mean utilities\ndiffer by a structured preference shift. We propose Cross-Market Transfer\nDynamic Pricing (CM-TDP), the first algorithm that provably handles such\nmodel-shift transfer and delivers minimax-optimal regret for both linear and\nnon-parametric utility models.\n  For linear utilities of dimension d, where the difference between source- and\ntarget-task coefficients is $s_{0}$-sparse, CM-TDP attains regret\n$\\tilde{O}((d*K^{-1}+s_{0})\\log T)$. For nonlinear demand residing in a\nreproducing kernel Hilbert space with effective dimension $\\alpha$, complexity\n$\\beta$ and task-similarity parameter $H$, the regret becomes\n$\\tilde{O}\\!(K^{-2\\alpha\\beta/(2\\alpha\\beta+1)}T^{1/(2\\alpha\\beta+1)} +\nH^{2/(2\\alpha+1)}T^{1/(2\\alpha+1)})$, matching information-theoretic lower\nbounds up to logarithmic factors. The RKHS bound is the first of its kind for\ntransfer pricing and is of independent interest.\n  Extensive simulations show up to 50% lower cumulative regret and 5 times\nfaster learning relative to single-market pricing baselines. By bridging\ntransfer learning, robust aggregation, and revenue optimization, CM-TDP moves\ntoward pricing systems that transfer faster, price smarter.",
    "pdf_url": "http://arxiv.org/pdf/2505.17203v1",
    "published": "2025-05-22T18:18:17+00:00",
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.17202v1",
    "title": "CHART-6: Human-Centered Evaluation of Data Visualization Understanding in Vision-Language Models",
    "authors": [
      "Arnav Verma",
      "Kushin Mukherjee",
      "Christopher Potts",
      "Elisa Kreiss",
      "Judith E. Fan"
    ],
    "abstract": "Data visualizations are powerful tools for communicating patterns in\nquantitative data. Yet understanding any data visualization is no small feat --\nsucceeding requires jointly making sense of visual, numerical, and linguistic\ninputs arranged in a conventionalized format one has previously learned to\nparse. Recently developed vision-language models are, in principle, promising\ncandidates for developing computational models of these cognitive operations.\nHowever, it is currently unclear to what degree these models emulate human\nbehavior on tasks that involve reasoning about data visualizations. This gap\nreflects limitations in prior work that has evaluated data visualization\nunderstanding in artificial systems using measures that differ from those\ntypically used to assess these abilities in humans. Here we evaluated eight\nvision-language models on six data visualization literacy assessments designed\nfor humans and compared model responses to those of human participants. We\nfound that these models performed worse than human participants on average, and\nthis performance gap persisted even when using relatively lenient criteria to\nassess model performance. Moreover, while relative performance across items was\nsomewhat correlated between models and humans, all models produced patterns of\nerrors that were reliably distinct from those produced by human participants.\nTaken together, these findings suggest significant opportunities for further\ndevelopment of artificial systems that might serve as useful models of how\nhumans reason about data visualizations. All code and data needed to reproduce\nthese results are available at:\nhttps://osf.io/e25mu/?view_only=399daff5a14d4b16b09473cf19043f18.",
    "pdf_url": "http://arxiv.org/pdf/2505.17202v1",
    "published": "2025-05-22T18:15:04+00:00",
    "categories": [
      "cs.HC",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.17201v1",
    "title": "A Framework for Multi-View Multiple Object Tracking using Single-View Multi-Object Trackers on Fish Data",
    "authors": [
      "Chaim Chai Elchik",
      "Fatemeh Karimi Nejadasl",
      "Seyed Sahand Mohammadi Ziabari",
      "Ali Mohammed Mansoor Alsahag"
    ],
    "abstract": "Multi-object tracking (MOT) in computer vision has made significant\nadvancements, yet tracking small fish in underwater environments presents\nunique challenges due to complex 3D motions and data noise. Traditional\nsingle-view MOT models often fall short in these settings. This thesis\naddresses these challenges by adapting state-of-the-art single-view MOT models,\nFairMOT and YOLOv8, for underwater fish detecting and tracking in ecological\nstudies. The core contribution of this research is the development of a\nmulti-view framework that utilizes stereo video inputs to enhance tracking\naccuracy and fish behavior pattern recognition. By integrating and evaluating\nthese models on underwater fish video datasets, the study aims to demonstrate\nsignificant improvements in precision and reliability compared to single-view\napproaches. The proposed framework detects fish entities with a relative\naccuracy of 47% and employs stereo-matching techniques to produce a novel 3D\noutput, providing a more comprehensive understanding of fish movements and\ninteractions",
    "pdf_url": "http://arxiv.org/pdf/2505.17201v1",
    "published": "2025-05-22T18:12:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17200v1",
    "title": "Resolving Intervalley Gaps and Many-Body Resonances in Moiré Superconductor",
    "authors": [
      "Hyunjin Kim",
      "Gautam Rai",
      "Lorenzo Crippa",
      "Dumitru Călugăru",
      "Haoyu Hu",
      "Youngjoon Choi",
      "Lingyuan Kong",
      "Eli Baum",
      "Yiran Zhang",
      "Ludwig Holleis",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Andrea F. Young",
      "B. Andrei Bernevig",
      "Roser Valentí",
      "Giorgio Sangiovanni",
      "Tim Wehling",
      "Stevan Nadj-Perge"
    ],
    "abstract": "Magic-angle twisted multilayer graphene stands out as a highly tunable class\nof moir\\'e materials that exhibit strong electronic correlations and robust\nsuperconductivity. However, understanding the relations between the\nlow-temperature superconducting phase and the preceding correlated phases\nestablished at higher temperatures remains a challenge. Here, we employ\nscanning tunneling microscopy and spectroscopy to track the formation sequence\nof correlated phases established by the interplay of dynamic correlations,\nintervalley coherence, and superconductivity in magic-angle twisted trilayer\ngraphene (MATTG). We discover the existence of two well-resolved gaps pinned at\nthe Fermi level within the superconducting doping range. While the outer gap,\npreviously associated with pseudogap phase, persists at high temperatures and\nmagnetic fields, the newly revealed inner gap is more fragile in line with\nsuperconductivity MATTG transport experiments. Andreev reflection spectroscopy\ntaken at the same location confirms a clear trend that closely follows the\ndoping behaviour of the inner gap, and not the outer one. Moreover,\nspectroscopy taken at nanoscale domain boundaries further corroborates the\ncontrasting behavior of the two gaps, with the inner gap remaining resilient to\nstructural variations, as expected from the finite superconducting coherence\nlength. By comparing our findings with recent topological heavy-fermion models,\nwe identify that the outer gap originates from the splitting of the\nAbrikosov-Suhl-Kondo resonance due to the breaking of the valley symmetry\narising from correlation-driven effects. Our results suggest an intricate but\ntractable hierarchy of correlated phases in twisted multilayer graphene.",
    "pdf_url": "http://arxiv.org/pdf/2505.17200v1",
    "published": "2025-05-22T18:09:50+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.17199v1",
    "title": "A statistical study of sea ice thickness and coverage in the Canadian Arctic",
    "authors": [
      "Arya Kimiaghalam"
    ],
    "abstract": "The Arctic sea ice cover has significantly declined over the recent decades.\nThe debate on whether this decline is caused by anthropogenic activity or\ninternal cycles is still ongoing. However, despite this uncertainty, some\nphysical factors reinforce this declining trend, one of which is sea ice\nthickness. The thinning of Arctic sea ice facilitates the melting of sea ice by\nreducing the heat capacity of the ice volume. The progression of this thinning\ncan potentially accelerate sea ice loss. In this work, we attempt to understand\nthe broad relationship of sea ice cover levels and average sea ice thickness in\nthe Arctic. First, we attempt to understand whether the trend in the Arctic sea\nice thickness is statistically significant over multi-year and inter-year\nseasonal scales, by using mostly non-parametric trend analysis tools. We\nsubsequently study how sea ice thickness, as well as its momentum and\nfluctuations, are statistically correlated to those of sea ice cover in the\nArctic. For this task, we use publicly available Arctic sea ice cover and\nthickness data from 1979 to 2021, provided by the Pan-Arctic Ice Ocean\nModelling and Assimilation System (PIOMAS) and the National Snow and Ice Data\nCenter (NSIDC).",
    "pdf_url": "http://arxiv.org/pdf/2505.17199v1",
    "published": "2025-05-22T18:07:50+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17198v1",
    "title": "LengthLogD: A Length-Stratified Ensemble Framework for Enhanced Peptide Lipophilicity Prediction via Multi-Scale Feature Integration",
    "authors": [
      "Shuang Wu",
      "Meijie Wang",
      "Lun Yu"
    ],
    "abstract": "Peptide compounds demonstrate considerable potential as therapeutic agents\ndue to their high target affinity and low toxicity, yet their drug development\nis constrained by their low membrane permeability. Molecular weight and peptide\nlength have significant effects on the logD of peptides, which in turn\ninfluences their ability to cross biological membranes. However, accurate\nprediction of peptide logD remains challenging due to the complex interplay\nbetween sequence, structure, and ionization states. This study introduces\nLengthLogD, a predictive framework that establishes specialized models through\nmolecular length stratification while innovatively integrating multi-scale\nmolecular representations. We constructed feature spaces across three\nhierarchical levels: atomic (10 molecular descriptors), structural (1024-bit\nMorgan fingerprints), and topological (3 graph-based features including Wiener\nindex), optimized through stratified ensemble learning. An adaptive weight\nallocation mechanism specifically developed for long peptides significantly\nenhances model generalizability. Experimental results demonstrate superior\nperformance across all categories: short peptides (R^2=0.855), medium peptides\n(R^2=0.816), and long peptides (R^2=0.882), with a 34.7% reduction in\nprediction error for long peptides compared to conventional single-model\napproaches. Ablation studies confirm: 1) The length-stratified strategy\ncontributes 41.2% to performance improvement; 2) Topological features account\nfor 28.5% of predictive importance. Compared to state-of-the-art models, our\nmethod maintains short peptide prediction accuracy while achieving a 25.7%\nincrease in the coefficient of determination (R^2) for long peptides. This\nresearch provides a precise logD prediction tool for peptide drug development,\nparticularly demonstrating unique value in optimizing long peptide lead\ncompounds.",
    "pdf_url": "http://arxiv.org/pdf/2505.17198v1",
    "published": "2025-05-22T18:05:53+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17197v1",
    "title": "Far-ultraviolet flares and variability of the young M dwarf AU Mic: a non-detection of planet c in transit at Lyman-alpha",
    "authors": [
      "Keighley E. Rockcliffe",
      "Elisabeth R. Newton",
      "Allison Youngblood",
      "Girish M. Duvvuri",
      "Emily A. Gilbert",
      "Peter Plavchan",
      "Peter Gao",
      "Hans-R. Müller",
      "Adina D. Feinstein",
      "Thomas Barclay",
      "Eric D. Lopez"
    ],
    "abstract": "Atmospheric escape's potential to shape the exoplanet population motivates\ndetailed observations of systems actively undergoing escape. AU Mic is a young\nand active M dwarf hosting two close-in transiting sub- to Neptune-sized\nplanets. Atmospheric escape was previously detected on the inner planet b, with\nradially-blown neutral hydrogen producing ~30% blue-shifted absorption in\nLyman-alpha. We obtained one HST/STIS transit of the outer planet c, to search\nfor the planet's escaping atmosphere in transmission at Lyman-alpha and compare\nwith AU Mic b. We detected 6 short-duration flares in Si IV and C IV, of which\nonly one corresponded to a Lyman-alpha flare. We identified longer-duration\nstellar variability at the tens of percent level for lines less sensitive to\nstellar activity, including O I, C II and Lyman-alpha, which inhibits detection\nof an exosphere. We do not report absorption associated with an exosphere\ncontaining neutral hydrogen or any metals detectable in the far-ultraviolet,\nand discuss the implications of the non-detection. This work highlights the\nimportance of 1) careful consideration of stellar variability in atmospheric\nescape observations, and 2) the dual-influence of photoionization and stellar\nwind when interpreting and modeling atmospheric escape.",
    "pdf_url": "http://arxiv.org/pdf/2505.17197v1",
    "published": "2025-05-22T18:05:44+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17196v1",
    "title": "Shape it Up! Restoring LLM Safety during Finetuning",
    "authors": [
      "ShengYun Peng",
      "Pin-Yu Chen",
      "Jianfeng Chi",
      "Seongmin Lee",
      "Duen Horng Chau"
    ],
    "abstract": "Finetuning large language models (LLMs) enables user-specific customization\nbut introduces critical safety risks: even a few harmful examples can\ncompromise safety alignment. A common mitigation strategy is to update the\nmodel more strongly on examples deemed safe, while downweighting or excluding\nthose flagged as unsafe. However, because safety context can shift within a\nsingle example, updating the model equally on both harmful and harmless parts\nof a response is suboptimal-a coarse treatment we term static safety shaping.\nIn contrast, we propose dynamic safety shaping (DSS), a framework that uses\nfine-grained safety signals to reinforce learning from safe segments of a\nresponse while suppressing unsafe content. To enable such fine-grained control\nduring finetuning, we introduce a key insight: guardrail models, traditionally\nused for filtering, can be repurposed to evaluate partial responses, tracking\nhow safety risk evolves throughout the response, segment by segment. This leads\nto the Safety Trajectory Assessment of Response (STAR), a token-level signal\nthat enables shaping to operate dynamically over the training sequence.\nBuilding on this, we present STAR-DSS, guided by STAR scores, that robustly\nmitigates finetuning risks and delivers substantial safety improvements across\ndiverse threats, datasets, and model families-all without compromising\ncapability on intended tasks. We encourage future safety research to build on\ndynamic shaping principles for stronger mitigation against evolving finetuning\nrisks.",
    "pdf_url": "http://arxiv.org/pdf/2505.17196v1",
    "published": "2025-05-22T18:05:16+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17195v1",
    "title": "A high-resolution molecular spin-photon interface at telecommunications wavelengths",
    "authors": [
      "Leah R. Weiss",
      "Grant T. Smith",
      "Ryan A. Murphy",
      "Bahman Golesorkhi",
      "José A. Méndez Méndez",
      "Priya Patel",
      "Jens Niklas",
      "Oleg G. Poluektov",
      "Jeffrey R. Long",
      "David D. Awschalom"
    ],
    "abstract": "Optically addressable electronic spins in polyatomic molecules are a\npromising platform for quantum information science with the potential to enable\nscalable qubit design and integration through atomistic tunability and\nnanoscale localization. However, optical state- and site-selection are an open\nchallenge. Here we introduce an organo-erbium spin qubit in which narrow\n(MHz-scale) optical and spin transitions couple to provide high-resolution\naccess to spin degrees of freedom with telecommunications frequency light. This\nspin-photon interface enables demonstration of optical spin polarization and\nreadout that distinguishes between spin states and magnetically inequivalent\nsites in a molecular crystal. Operation at frequencies compatible with mature\nphotonic and microwave devices opens a path for engineering scalable,\nintegrated molecular spin-optical quantum technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.17195v1",
    "published": "2025-05-22T18:04:33+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17194v1",
    "title": "Security of deterministic key distribution with higher-dimensional systems",
    "authors": [
      "Ayan Patra",
      "Abhishek Muhuri",
      "Rivu Gupta",
      "Tamoghna Das",
      "Aditi Sen De"
    ],
    "abstract": "We determine the security aspects of the two-way quantum key distribution\nprotocol designed by M. Lucamarini and S. Mancini in 2005 (in short, the LM05\nprotocol) by employing arbitrary finite-dimensional systems against both\nindividual and collective attacks by the eavesdropper. We explicitly delineate\nthe constituent steps in higher dimensions using the Heisenberg-Weyl operators\nfor the encoding and the measurement operations. For individual attacks, we\nconsider cloning operations by the eavesdropper and demonstrate a dimensional\nadvantage where secret keys can be generated for greater strengths of\ninterception. To analyze security under collective attacks, we employ a\npurification scheme and derive the key rate using entropic uncertainty\nrelations. Further, we exhibit how the protocol is more robust against\neavesdropping with increasing dimension of the systems used, and compare the\nperformance with that of the entangled two-way secure dense coding protocol\nwhen affected by correlated and uncorrelated noise, which models the presence\nof the eavesdropper.",
    "pdf_url": "http://arxiv.org/pdf/2505.17194v1",
    "published": "2025-05-22T18:04:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17193v1",
    "title": "On the distinguishing chromatic number in hereditary graph classes",
    "authors": [
      "Christoph Brause",
      "Rafał Kalinowski",
      "Monika Pilśniak",
      "Ingo Schiemeyer"
    ],
    "abstract": "The distinguishing chromatic number of a graph $G$, denoted $\\chi_D(G)$, is\nthe minimum number of colours in a proper vertex colouring of $G$ that is\npreserved by the identity automorphism only. Collins and Trenk proved that\n$\\chi_D(G)\\le 2\\Delta(G)$ for any connected graph $G$, and the equality holds\nfor complete balanced bipartite graphs $K_{p,p}$ and for $C_6$. In this paper,\nwe show that the upper bound on $\\chi_D(G)$ can be substantially reduced if we\nforbid some small graphs as induced subgraphs of $G$, that is, we study the\ndistinguishing chromatic number in some hereditary graph classes.",
    "pdf_url": "http://arxiv.org/pdf/2505.17193v1",
    "published": "2025-05-22T18:03:55+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17192v2",
    "title": "Unconventional tunnel magnetoresistance scaling with altermagnets",
    "authors": [
      "Zongmeng Yang",
      "Xingyue Yang",
      "Jianhua Wang",
      "Rui Peng",
      "Ching Hua Lee",
      "Lay Kee Ang",
      "Jing Lu",
      "Yee Sin Ang",
      "Shibo Fang"
    ],
    "abstract": "In conventional magnetic tunnel junctions (MTJs), the tunnel\nmagnetoresistance (TMR) typically increases with barrier thickness as electron\ntransmission in the antiparallel configuration decays faster than that of the\nparallel configuration. In this work, we reveal an anomalous scaling effect in\naltermagnetic tunnel junctions (AMTJs), where the TMR decreases anomalously\nwith an increasing barrier thickness. The anomalous scaling originates from the\noverlapping spin-split branches form a transmission path that cannot be\nsuppressed in the antiparallel state. Such phenomena is explained by\nadouble-barrier model and is further demonstrated using ab initio quantum\ntransport simulations in 2D V2Te2O/Cr2Se2O/V2Te2O-based AMTJ, where the TMR\nanomalously decreases from 220% to 40% as the layer number of Cr2Se2O increases\nfrom 1 to 5. Our work identifies a peculiar unexpected transport characteristic\nof AMTJ, providing a fundamental limit on AMTJ device design and illustrating\nthe potential optimal design of AMTJ at the ultrascaled monolayer limit.",
    "pdf_url": "http://arxiv.org/pdf/2505.17192v2",
    "published": "2025-05-22T18:02:37+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.17191v2",
    "title": "An Adaptive-rank Approach with Greedy Sampling for Multi-scale BGK Equations",
    "authors": [
      "William A. Sands",
      "Jing-Mei Qiu",
      "Daniel Hayes",
      "Nanyi Zheng"
    ],
    "abstract": "In this paper, we propose a novel adaptive-rank method for simulating\nmulti-scale BGK equations, based on a greedy sampling strategy. The method\nadaptively selects important rows and columns of the solution matrix and\nupdates them using a local semi-Lagrangian solver. An adaptive cross\napproximation then reconstructs the full solution matrix. This extends our\nprior semi-Lagrangian adaptive-rank framework, developed for the Vlasov-Poisson\nsystem, to nonlinear collisional kinetic equations. Unlike step-and-truncate\nlow-rank integrators, our greedy sampling approach avoids explicit low-rank\ndecompositions of nonlinear terms, such as the local Maxwellian in the BGK\noperator. To ensure conservation, we introduce a locally macroscopic\nconservative correction that implicitly couples the kinetic and macroscopic\nsystems, enforcing mass, momentum, and energy conservation. Through asymptotic\nanalysis, we show that this correction preserves the full-grid scheme's\nasymptotic behavior, and that the proposed method is conditionally\nasymptotic-preserving in the low-rank setting. A key advantage of our approach\nis its use of a local semi-Lagrangian solver, which allows large time steps.\nThis flexibility is retained in the macroscopic solver using high-order stiffly\naccurate diagonally implicit Runge-Kutta methods. The resulting nonlinear\nsystems are solved efficiently using a Jacobian-free Newton-Krylov method,\navoiding the need for preconditioning at modest CFL numbers. Each nonlinear\niteration provides a self-consistent correction to a provisional kinetic\nsolution, which serves as a dynamic closure for the macroscopic model.\nNumerical results demonstrate the method's accuracy in capturing shocks and its\nrobustness across mixed-regime problems with wide-ranging Knudsen numbers.",
    "pdf_url": "http://arxiv.org/pdf/2505.17191v2",
    "published": "2025-05-22T18:02:06+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65M85 (primary), 65M70, 65F30 (secondary)"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.17190v1",
    "title": "Tropical Attention: Neural Algorithmic Reasoning for Combinatorial Algorithms",
    "authors": [
      "Baran Hashemi",
      "Kurt Pasque",
      "Chris Teska",
      "Ruriko Yoshida"
    ],
    "abstract": "Dynamic programming (DP) algorithms for combinatorial optimization problems\nwork with taking maximization, minimization, and classical addition in their\nrecursion algorithms. The associated value functions correspond to convex\npolyhedra in the max plus semiring. Existing Neural Algorithmic Reasoning\nmodels, however, rely on softmax-normalized dot-product attention where the\nsmooth exponential weighting blurs these sharp polyhedral structures and\ncollapses when evaluated on out-of-distribution (OOD) settings. We introduce\nTropical attention, a novel attention function that operates natively in the\nmax-plus semiring of tropical geometry. We prove that Tropical attention can\napproximate tropical circuits of DP-type combinatorial algorithms. We then\npropose that using Tropical transformers enhances empirical OOD performance in\nboth length generalization and value generalization, on algorithmic reasoning\ntasks, surpassing softmax baselines while remaining stable under adversarial\nattacks. We also present adversarial-attack generalization as a third axis for\nNeural Algorithmic Reasoning benchmarking. Our results demonstrate that\nTropical attention restores the sharp, scale-invariant reasoning absent from\nsoftmax.",
    "pdf_url": "http://arxiv.org/pdf/2505.17190v1",
    "published": "2025-05-22T18:01:25+00:00",
    "categories": [
      "cs.LG",
      "math.AG",
      "math.CO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17189v1",
    "title": "Echoes of Love Beyond the Horizon: A Bridge to Recovering Information from Black Holes",
    "authors": [
      "Meysam Motaharfar",
      "Parampreet Singh"
    ],
    "abstract": "We provide further evidence that information is preserved during black hole\nevaporation and may be recoverable, provided quantum gravitational effects\nresolve the singularity. We demonstrate that due to quantum gravity effects,\nblack holes acquire quantum hair, manifested by non-zero tidal Love numbers,\nrevealing a distinct internal structure similar to neutron stars.\nInterestingly, the magnitude of these Love numbers is Planck-scale suppressed,\nimplying significant tidal deformation in the late stage of evaporation.\nDepending on the final state of the black hole, information may be retrieved\nthrough correlations in Hawking radiation, baby universes, or via remnants.",
    "pdf_url": "http://arxiv.org/pdf/2505.17189v1",
    "published": "2025-05-22T18:00:50+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17188v2",
    "title": "The Lyman-$α$ emitter bispectrum as a probe of reionization morphology",
    "authors": [
      "Soumak Maitra",
      "Girish Kulkarni",
      "Shikhar Asthana",
      "James S. Bolton",
      "Martin G. Haehnelt",
      "Laura Keating"
    ],
    "abstract": "Ly$\\alpha$ emitters (LAEs) have now been discovered out to redshift $z=13$,\nand are valuable probes of the reionization history at redshifts beyond the\nreach of other currently available tracers. Most inferences of the neutral\nhydrogen fraction from LAE observations rely on one-point and two-point\nstatistics like the luminosity function and the power spectrum. We present here\nan analysis of the bispectrum of high-redshift LAEs and demonstrate its\nsensitivity to the Epoch of Reionization. We use the Sherwood-Relics suite of\ncosmological hydrodynamical simulations post-processed with the GPU-based\nradiative transfer code ATON-HE to generate realistic LAE mock catalogues for a\nwide range of reionization models, varying the ionization history and the\nsource populations, including contributions of AGN to hydrogen reionization. We\ndemonstrate that the bispectrum provides greater sensitivity than the power\nspectrum to both the timing and spatial morphology of reionization. Using\nreduced-$\\chi^2$ analysis we further show that the bispectrum also responds\nmore strongly to variations in source population and AGN contribution,\napparently more efficiently capturing morphological features missed by\ntwo-point statistics. The redshift evolution of the bispectrum reflects the\nincreased clustering of ionizing sources at earlier epochs. The sensitivity of\nthe bispectrum to peculiar velocities underscores the importance of velocity\ncorrections in comparisons to observations. Our findings demonstrate that the\nLAE bispectrum is a powerful higher-order statistic for probing reionization\nthrough current and future LAE surveys using telescopes such as Subaru and\nJWST.",
    "pdf_url": "http://arxiv.org/pdf/2505.17188v2",
    "published": "2025-05-22T18:00:09+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17185v2",
    "title": "Role of Nonstabilizerness in Quantum Optimization",
    "authors": [
      "Chiara Capecci",
      "Gopal Chandra Santra",
      "Alberto Bottarelli",
      "Emanuele Tirrito",
      "Philipp Hauke"
    ],
    "abstract": "Quantum optimization has emerged as a promising approach for tackling\ncomplicated classical optimization problems using quantum devices. However, the\nextent to which such algorithms harness genuine quantum resources and the role\nof these resources in their success remain open questions. In this work, we\ninvestigate the resource requirements of the Quantum Approximate Optimization\nAlgorithm (QAOA) through the lens of the resource theory of nonstabilizerness.\nWe demonstrate that the nonstabilizerness in QAOA increases with circuit depth\nbefore it reaches a maximum, to fall again during the approach to the final\nsolution state -- creating a barrier that limits the algorithm's capability for\nshallow circuits. We find curves corresponding to different depths to collapse\nunder a simple rescaling, and we reveal a nontrivial relationship between the\nfinal nonstabilizerness and the success probability. Finally, we identify a\nsimilar nonstabilizerness barrier also in adiabatic quantum annealing. Our\nresults provide deeper insights into how quantum resources influence quantum\noptimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.17185v2",
    "published": "2025-05-22T18:00:03+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cond-mat.other"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17186v2",
    "title": "Bound States of the Schwarzschild Black Hole",
    "authors": [
      "Sebastian H. Völkel"
    ],
    "abstract": "Understanding the physical significance and spectral stability of black hole\nquasinormal modes is fundamental to high-precision spectroscopy with future\ngravitational wave detectors. Inspired by Mashhoon's idea of relating\nquasinormal modes of black holes with their equivalent bound states in an\ninverted potential, we investigate, for the first time, energy levels and\neigenfunctions of the Schwarzschild black hole quantitatively. While\nquasinormal modes describe the characteristic damped oscillations of a black\nhole, the bound states of the inverted potential are qualitatively more similar\nto those of the hydrogen atom. Although the physical interpretation of these\nstates may initially be of more academic interest, it furthers our\nunderstanding of open problems related to quasinormal modes in a similar spirit\nto Maggiore's interpretation of the Schwarzschild quasinormal mode spectrum.\nOne surprising insight from the explicit calculation of bound states is that\neigenfunctions corresponding to quasinormal mode overtones become rapidly\ndelocalized and extremely loosely bound. This observation raises immediate\nquestions about the common interpretation of quasinormal modes as excitations\nof the lightring region. Closely related, as a second application, we also\nexplore the spectral stability of bound states and demonstrate that they can\nprovide complementary insights into the quasinormal mode spectrum.",
    "pdf_url": "http://arxiv.org/pdf/2505.17186v2",
    "published": "2025-05-22T18:00:03+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17187v2",
    "title": "Circuit structure-preserving error mitigation for High-Fidelity Quantum Simulations",
    "authors": [
      "Ruizhe Shen",
      "Tianqi Chen",
      "Ching Hua Lee"
    ],
    "abstract": "Developing methods to accurately characterize and mitigate the impact of\nnoise is crucial for enhancing the fidelity of quantum simulations on Noisy\nIntermediate-Scale Quantum (NISQ) devices. In this work, we present a circuit\nstructure-preserving error mitigation framework for parameterized quantum\ncircuits. A key advantage of our approach lies in its ability to retain the\noriginal circuit architecture while effectively characterizing and mitigating\ngate errors, enabling robust and high-fidelity simulations. This makes it\nparticularly well suited for small-scale circuits that require repeated\nexecution at large sampling rates. To demonstrate the effectiveness of our\nmethod, we perform variational quantum simulations of a non-Hermitian\nferromagnetic transverse-field Ising chain on IBM Quantum processors. The\nmitigated result shows excellent agreement with exact theoretical predictions\nacross a range of noise levels. Our strategy offers a practical solution for\naddressing gate-induced errors and significantly broadens the scope of feasible\nquantum simulations on current quantum hardware.",
    "pdf_url": "http://arxiv.org/pdf/2505.17187v2",
    "published": "2025-05-22T18:00:03+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.other"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17181v1",
    "title": "Quantum Mpemba effect without global symmetries",
    "authors": [
      "Tanmay Bhore",
      "Lei Su",
      "Ivar Martin",
      "Aashish A. Clerk",
      "Zlatko Papić"
    ],
    "abstract": "The Mpemba effect, where a system initially farther from equilibrium relaxes\nfaster than one closer to equilibrium, has been extensively studied in\nclassical systems and recently explored in quantum settings. While previous\nstudies of the quantum Mpemba effect (QME) have largely focused on isolated\nsystems with global symmetries, we argue that the QME is ubiquitous in generic,\nnon-integrable many-body systems lacking such symmetries, including U(1) charge\nconservation, spatial symmetries, and even energy conservation. Using\nparadigmatic models such as the quantum Ising model with transverse and\nlongitudinal fields, we show that the QME can be understood through the energy\ndensity of initial states and their inverse participation ratio in the energy\neigenbasis. Our findings provide a unified framework for the QME, linking it\nwith classical thermal relaxation and phenomena such as prethermalization and\nweak ergodicity breaking.",
    "pdf_url": "http://arxiv.org/pdf/2505.17181v1",
    "published": "2025-05-22T18:00:01+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17182v2",
    "title": "Mock Modularity Of Twisted Index In CHL Models",
    "authors": [
      "Nabamita Banerjee",
      "Vedant Bhutra",
      "Ranveer Kumar Singh"
    ],
    "abstract": "We study the twisted partition function of quarter BPS states in CHL models\nand show that for a large class of single-centered black holes, the degeneracy\nof microstates is given by the Fourier coefficients of mock Jacobi forms. Our\nanalysis is a continuation of the programme initiated by Dabholkar, Murthy and\nZagier (DMZ) for $1/4$-BPS dyons in $\\mathcal{N} = 4$ string theory and further\nextended by Bhand, Sen and Singh (BSS) to quarter BPS states in CHL models. We\nalso present the multiplicative lift construction of the partition function and\ncomment on the additive lift of the same.",
    "pdf_url": "http://arxiv.org/pdf/2505.17182v2",
    "published": "2025-05-22T18:00:01+00:00",
    "categories": [
      "hep-th",
      "math.NT",
      "math.QA"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.17183v1",
    "title": "Caught in the act: detections of recoiling supermassive black holes from simulations",
    "authors": [
      "Alexander Rawlings",
      "Peter H. Johansson",
      "Thorsten Naab",
      "Antti Rantala",
      "Jens Thomas",
      "Bianca Neureiter"
    ],
    "abstract": "We study the detectability of supermassive black holes (SMBHs) with masses of\n$M_{\\bullet}\\gtrsim 10^{9}\\,\\mathrm{M}_\\odot$ displaced by gravitational wave\nrecoil kicks $(v_{\\rm kick}=0\\mathrm{-}2000\\,\\mathrm{km\\,s}^{-1})$ in\nsimulations of merging massive $(M_{\\star}>10^{11}\\,\\mathrm{M}_\\odot)$\nearly-type galaxies. The used KETJU code combines the GADGET-4 fast multiple\ngravity solver with accurate regularised integration and post-Newtonian\ncorrections (up to PN3.5) around SMBHs. The ejected SMBHs carry clusters of\nbound stellar material (black hole recoil clusters, BRCs) with masses in the\nrange of $10^6 \\lesssim M_{\\text{BRC}} \\lesssim 10^7\\,\\mathrm{M}_\\odot$ and\nsizes of several $10\\,\\mathrm{pc}$. For recoil velocities up to $60\\%$ of the\ngalaxy escape velocity, the BRCs are detectable in mock photometric images at a\nEuclid-like resolution up to redshift $z \\sim 1.0$. By Monte Carlo sampling the\nobservability for different recoil directions and magnitudes, we predict that\nin $\\sim20\\%$ of instances the BRCs are photometrically detectable, most likely\nfor kicks with SMBH apocentres less than the galaxy effective radius. BRCs\noccupy distinct regions in the stellar mass/velocity dispersion vs. size\nrelations of known star clusters and galaxies. An enhanced velocity dispersion\nin excess of $\\sigma \\sim 600\\,\\mathrm{km\\,s}^{-1}$ coinciding with the SMBH\nposition provides the best evidence for an SMBH-hosting stellar system,\neffectively distinguishing BRCs from other faint stellar systems. BRCs are\npromising candidates to observe the aftermath of the yet-undetected mergers of\nthe most massive SMBHs and we estimate that up to 8000 BRCs might be observable\nbelow $z\\lesssim 0.6$ with large-scale photometric surveys such as Euclid and\nupcoming high-resolution imaging and spectroscopy with the Extremely Large\nTelescope.",
    "pdf_url": "http://arxiv.org/pdf/2505.17183v1",
    "published": "2025-05-22T18:00:01+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.17184v1",
    "title": "The Manakov-Zakharov-Ward model as an integrable decoupling limit of the membrane",
    "authors": [
      "David Osten"
    ],
    "abstract": "A novel decoupling limit of the membrane is proposed, leading to the\n$(1+2)$-dimensional classically integrable model originally introduced by\nManakov, Zakharov, and Ward. This limit can be interpreted as either a\nnon-relativistic or large-wrapping regime of a membrane propagating in a toy\nbackground of the form $\\mathbb{R}_t \\times T^2 \\times G$, where $G$ is a Lie\ngroup and the geometry is supported by a four-form flux. We demonstrate that\nsuch toy backgrounds can arise from consistent eleven-dimensional supergravity\nsolutions, exemplified by the uplift of the pure NSNS AdS$_3 \\times$ S$^3\n\\times$ T$^4$ background.",
    "pdf_url": "http://arxiv.org/pdf/2505.17184v1",
    "published": "2025-05-22T18:00:01+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP",
      "nlin.SI"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.17173v2",
    "title": "Probing the origins. II. Unravelling lithium depletion and stellar motion: Intrinsic stellar properties drive depletion, not kinematics",
    "authors": [
      "M. L. L. Dantas",
      "R. Smiljanic",
      "D. Romano",
      "G. Guiglion",
      "L. Magrini",
      "P. B. Tissera",
      "R. S. de Souza"
    ],
    "abstract": "In Paper I, we classified a stellar sample from the thin disc with a broad\nrange in metallicity as being churned outward or inward, or\nblurred/undisturbed. In this paper (Paper II), we delve deeper by analysing our\nentire metallicity-stratified sample along with their dynamic properties,\nfocusing on the connection between radial migration and Li depletion. We\nanalyse the chemo-dynamics of a set of 1188 thin disc dwarf stars observed by\nthe \\textit{Gaia}-ESO survey, previously classified into six\nmetallicity-stratified groups via Hierarchical Clustering (HC). We examine\nseveral features, such as effective temperatures, masses, and dynamic\nproperties. We also implement a parametric survival analysis using penalised\nsplines (logistic distribution) to quantify how stellar properties and motion\n(or migration) direction jointly influence Li depletion patterns. We find that\nstars in our sample that appear to have churned outward are predominantly\nLi-depleted, regardless of their metallicities. These stars are also the\noldest, coldest, and least massive compared to those in the same HC group that\nhave either churned inward or kept their orbital radii. Our survival analysis\nconfirms temperature as the primary driver of Li depletion, followed by\nmetallicity and age, while migration direction shows negligible influence. The\nincreasing proportion of outward-churned stars with higher metallicity (and\nolder ages) indicates their dominant influence on the overall trend observed in\nthe [Fe/H]-A(Li) space for stellar groups with [Fe/H]>0. The survival model\nreinforces that the observed Li depletion stems primarily from intrinsic\nstellar properties (cool temperatures, higher metallicity, old ages) rather\nthan migration history. This suggests the metallicity-dependent depletion\npattern emerges through stellar evolution rather than Galactic dynamical\nprocesses.",
    "pdf_url": "http://arxiv.org/pdf/2505.17173v2",
    "published": "2025-05-22T18:00:00+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17174v2",
    "title": "A Morphological Model to Separate Resolved-Unresolved Sources in the DESI Legacy Surveys: Application in the LS4 Alert Stream",
    "authors": [
      "Chang Liu",
      "Adam A. Miller",
      "Joshua S. Bloom",
      "Robert A. Knop",
      "Peter E. Nugent"
    ],
    "abstract": "Separating resolved and unresolved sources in large imaging surveys is a\nfundamental step to enable downstream science, such as searching for\nextragalactic transients in wide-field time-domain surveys. Here we present our\nmethod to effectively separate point sources from the resolved, extended\nsources in the Dark Energy Spectroscopic Instrument (DESI) Legacy Surveys (LS).\nWe develop a supervised machine-learning model based on the Gradient Boosting\nalgorithm $\\texttt{XGBoost}$. The features input to the model are purely\nmorphological and are derived from the tabulated LS data products. We train the\nmodel using $\\sim$$2\\times10^5$ LS sources in the COSMOS field with HST\nmorphological labels and evaluate the model performance on LS sources with\nspectroscopic classification from the DESI Data Release 1 ($\\sim$$2\\times10^7$\nobjects) and the Sloan Digital Sky Survey Data Release 17 ($\\sim$$3\\times10^6$\nobjects), as well as on $\\sim$$2\\times10^8$ Gaia stars. A significant fraction\nof LS sources are not observed in every LS filter, and we therefore build a\n''Hybrid'' model as a linear combination of two \\texttt{XGBoost} models, each\ncontaining features combining aperture flux measurements from the ''blue''\n($gr$) and ''red'' ($iz$) filters. The Hybrid model shows a reasonable balance\nbetween sensitivity and robustness, and achieves higher accuracy and\nflexibility compared to the LS morphological typing. With the Hybrid model, we\nprovide classification scores for $\\sim$$3\\times10^9$ LS sources, making this\nthe largest ever machine-learning catalog separating resolved and unresolved\nsources. The catalog has been incorporated into the real-time pipeline of the\nLa Silla Schmidt Southern Survey (LS4), enabling the identification of\nextragalactic transients within the LS4 alert stream.",
    "pdf_url": "http://arxiv.org/pdf/2505.17174v2",
    "published": "2025-05-22T18:00:00+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.17175v1",
    "title": "Lindblad evolution as gradient flow",
    "authors": [
      "Greg Kaplanek",
      "Alexander Maloney",
      "Jason Pollack",
      "Dylan VanAllen"
    ],
    "abstract": "We give a simple argument that, for a large class of jump operators, the\nLindblad evolution can be written as a gradient flow in the space of density\noperators acting on a Hilbert space of dimension $D$. We give explicit\nexpressions for the (matrix-valued) eigenvectors and eigenvalues of the\nLindblad evolution using this formalism. We argue that in many cases the\ninterpretation of the evolution is simplified by passing from the\n$D^2$-dimensional space of density operators to the $D^2-1$-dimensional space\nof Bloch vectors. When jump operators are non-Hermitian the evolution is not in\ngeneral gradient flow, but we show that it nevertheless resembles gradient flow\nin two particular ways. Importantly, the steady states of Lindbladian evolution\nare still determined by the potential in all cases.",
    "pdf_url": "http://arxiv.org/pdf/2505.17175v1",
    "published": "2025-05-22T18:00:00+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "hep-th",
      "math-ph",
      "math.DS",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17176v1",
    "title": "Free Hyperboloidal Evolution of the Einstein-Maxwell-Klein-Gordon System",
    "authors": [
      "João D. Álvares",
      "Alex Vaño-Viñuales"
    ],
    "abstract": "We present simulations of the Einstein-Maxwell-Klein-Gordon system on\ncompactified hyperboloidal slices. To the best of our knowledge, this is the\nfirst time that this setup is evolved with a common formulation like BSSN/Z4.\nHyperboloidal slices smoothly reach future null infinity, the only location in\nspacetime where radiation (such as gravitational waves) is unambiguously\ndefined. We are thus able to reach null infinity and extract signals there. We\nshowcase the capabilities of our implementation in spherical symmetry with the\nevolution of a charged scalar field perturbing a regular spacetime and near an\nelectrically charged black hole. We also present the collapse of a charged\nscalar field into a Reissner-N\\\"ordstrom black hole.",
    "pdf_url": "http://arxiv.org/pdf/2505.17176v1",
    "published": "2025-05-22T18:00:00+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17177v1",
    "title": "Asteroseismology of WD J004917.14-252556.81, the Most Massive Pulsating White Dwarf",
    "authors": [
      "O. Caliskan",
      "M. Uzundag",
      "M. Kilic",
      "F. C. Geronimo",
      "A. Moss",
      "A. H. Corsico",
      "S. G. Parsons",
      "I. Pelisoli",
      "G. Jewett",
      "A. Rebassa-Mansergas",
      "A. J. Brown",
      "V. K. Dhillon",
      "P. Bergeron"
    ],
    "abstract": "We present extensive follow-up time-series photometry of WD J0049$-$2525, the\nmost massive pulsating white dwarf currently known with $T_{\\rm eff} = 13\\,\n020\\,{\\rm K}$ and $\\log{\\it g} = 9.34$ cm s$^{-2}$. The discovery observations\ndetected only two significant pulsation modes. Here, we report the detection of\n13 significant pulsation modes ranging from 170 to 258 s based on 11 nights of\nobservations with the New Technology Telescope, Gemini, and Apache Point\nObservatory telescopes. We use these 13 modes to perform asteroseismology and\nfind that the best-fitting models (under the assumption of an ONe core\ncomposition) have $M_{\\star} \\approx 1.29~M_\\odot$, surface hydrogen layer mass\nof $\\log(M_{\\rm H}/M_{\\star}) \\lesssim -7.5$, and a crystallized core fraction\nof $>99\\%$. An analysis of the period spacing also strongly suggests a very\nhigh mass. The asteroseismic distance derived is in good agreement with the\ndistance provided by Gaia. We also find tentative evidence of a rotation period\nof 0.3 or 0.67 d. This analysis provides the first look at the interior of a\n$\\sim 1.3~M_{\\odot}$ white dwarf.",
    "pdf_url": "http://arxiv.org/pdf/2505.17177v1",
    "published": "2025-05-22T18:00:00+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17178v2",
    "title": "Lepton flavor violation by three units",
    "authors": [
      "Julian Heeck",
      "Mikheil Sokhashvili",
      "Anil Thapa"
    ],
    "abstract": "The conservation of lepton flavor is a prediction of the Standard Model and\nis still an excellent approximate symmetry despite our observation of neutrino\noscillations. Lepton flavor violation by one or two units have been discussed\nfor decades, with several dedicated experiments exploring the vast model\nlandscape but no discoveries so far. Here, we explore operators and processes\nthat violate at least one lepton flavor by three units and identify testable\nsignatures. In the Standard Model effective field theory, such operators\nalready arise at mass dimension 7 and can be tested through their contributions\nto Michel parameters in leptonic decays. True neutrinoless charged-lepton\nflavor violation arises at mass dimension 10 and can realistically only be seen\nin the tau decay channels $\\tau \\to eee\\bar{\\mu}\\bar{\\mu}$ or $\\tau \\to\n\\mu\\mu\\mu\\bar{e}\\bar{e}$, for example in Belle II. Testable rates for these tau\ndecays require light new particles and subsequently predict an avalanche of\nremarkably clean but so-far unconstrained collider signatures.",
    "pdf_url": "http://arxiv.org/pdf/2505.17178v2",
    "published": "2025-05-22T18:00:00+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17179v2",
    "title": "Surface Gauge Invariance, Soft Limits and the Transmutation of Gluons into Scalars",
    "authors": [
      "Jeffrey V. Backus",
      "Carolina Figueiredo"
    ],
    "abstract": "Over the past year, the \"scalar-scaffolding\" formalism has revealed a number\nof new features of gluon amplitudes. In this paper, we leverage these\ndevelopments to study two distinct but related questions, linked by the\nscaffolding statement of gauge invariance. We start by revisiting the soft\nexpansion of gluon amplitudes. The scaffolding picture allows for a precise\ndefinition of the soft limit and a canonical way to expand the amplitude. At\ntree-level, this reproduces the classic Weinberg soft theorem, and at one-loop,\nusing surface kinematics, we derive an extension of this theorem valid at the\nlevel of the loop integrand. We then switch gears and describe a new\nrelationship between gluon and scalar amplitudes. The expression of surface\ngauge invariance naturally suggests a certain differential operator acting on\nindividual external gluons. Remarkably, we find that, both for the tree-level\namplitude and the surface one-loop integrand, repeated applications of this\noperator transmutes gluon amplitudes/integrands into those of Tr$(\\phi^3)$\nscalars. This is an interesting counterpart to the $\\delta$-shift connection\nthat lifts \"stringy\" Tr$(\\phi^3)$ amplitudes to those of gluons.",
    "pdf_url": "http://arxiv.org/pdf/2505.17179v2",
    "published": "2025-05-22T18:00:00+00:00",
    "categories": [
      "hep-th",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.17180v1",
    "title": "Luminosity function of Type II GRBs:differences from long GRBs",
    "authors": [
      "Yan-Kun Qu",
      "Zhong-Xiao Man",
      "Yu-Peng Yang",
      "Shuang-Xi Yi",
      "Fa-Yin Wang"
    ],
    "abstract": "Gamma-ray bursts (GRBs) are generally categorized into long and short bursts\nbased on their duration ($T_{90}$). Recently, it has been proposed that GRBs\ncan also be classified into type I (merger) and type II (collapsar) bursts\nbased on the different origin. From a sample of \\textit{Swift} long\nGRBs~(LGRBs) with a redshift completeness of 60\\% and $P \\geq 2.6 \\, \\text{ph}\n\\, \\text{cm}^{-2} \\, \\text{s}^{-1}$, collected through the end of 2023, we\nidentify a pure sample of 146 Type II GRBs. With this sample, we construct the\nluminosity function (LF) using both the Broken Power Law (BPL) and Triple Power\nLaw (TPL) models. Our results indicate that, similar to LGRBs, a strong\nredshift evolution in either luminosity or density is necessary to accurately\naccount for the observations, regardless of the specific form of the LF\nassumed. The LF of LGRBs remains a topic of debate, with some studies\nsuggesting it follows a BPL form, while others advocate for a TPL form. In our\nstudy, we find that the LF of Type II GRBs tends to favor a BPL model.",
    "pdf_url": "http://arxiv.org/pdf/2505.17180v1",
    "published": "2025-05-22T18:00:00+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.17021v1",
    "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark",
    "authors": [
      "Sara Ghaboura",
      "Ketan More",
      "Wafa Alghallabi",
      "Omkar Thawakar",
      "Jorma Laaksonen",
      "Hisham Cholakkal",
      "Salman Khan",
      "Rao Muhammad Anwer"
    ],
    "abstract": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB",
    "pdf_url": "http://arxiv.org/pdf/2505.17021v1",
    "published": "2025-05-22T17:59:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17022v1",
    "title": "GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning",
    "authors": [
      "Chengqi Duan",
      "Rongyao Fang",
      "Yuqing Wang",
      "Kun Wang",
      "Linjiang Huang",
      "Xingyu Zeng",
      "Hongsheng Li",
      "Xihui Liu"
    ],
    "abstract": "Visual generation models have made remarkable progress in creating realistic\nimages from text prompts, yet struggle with complex prompts that specify\nmultiple objects with precise spatial relationships and attributes. Effective\nhandling of such prompts requires explicit reasoning about the semantic content\nand spatial layout. We present GoT-R1, a framework that applies reinforcement\nlearning to enhance semantic-spatial reasoning in visual generation. Building\nupon the Generation Chain-of-Thought approach, GoT-R1 enables models to\nautonomously discover effective reasoning strategies beyond predefined\ntemplates through carefully designed reinforcement learning. To achieve this,\nwe propose a dual-stage multi-dimensional reward framework that leverages MLLMs\nto evaluate both the reasoning process and final output, enabling effective\nsupervision across the entire generation pipeline. The reward system assesses\nsemantic alignment, spatial accuracy, and visual quality in a unified approach.\nExperimental results demonstrate significant improvements on T2I-CompBench\nbenchmark, particularly in compositional tasks involving precise spatial\nrelationships and attribute binding. GoT-R1 advances the state-of-the-art in\nimage generation by successfully transferring sophisticated reasoning\ncapabilities to the visual generation domain. To facilitate future research, we\nmake our code and pretrained models publicly available at\nhttps://github.com/gogoduan/GoT-R1.",
    "pdf_url": "http://arxiv.org/pdf/2505.17022v1",
    "published": "2025-05-22T17:59:58+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17018v1",
    "title": "SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward",
    "authors": [
      "Kaixuan Fan",
      "Kaituo Feng",
      "Haoming Lyu",
      "Dongzhan Zhou",
      "Xiangyu Yue"
    ],
    "abstract": "Recent advances have shown success in eliciting strong reasoning abilities in\nmultimodal large language models (MLLMs) through rule-based reinforcement\nlearning (RL) with outcome rewards. However, this paradigm typically lacks\nsupervision over the thinking process leading to the final outcome.As a result,\nthe model may learn sub-optimal reasoning strategies, which can hinder its\ngeneralization ability. In light of this, we propose SophiaVL-R1, as an attempt\nto add reward signals for the thinking process in this paradigm. To achieve\nthis, we first train a thinking reward model that evaluates the quality of the\nentire thinking process. Given that the thinking reward may be unreliable for\ncertain samples due to reward hacking, we propose the Trust-GRPO method, which\nassigns a trustworthiness weight to the thinking reward during training. This\nweight is computed based on the thinking reward comparison of responses leading\nto correct answers versus incorrect answers, helping to mitigate the impact of\npotentially unreliable thinking rewards. Moreover, we design an annealing\ntraining strategy that gradually reduces the thinking reward over time,\nallowing the model to rely more on the accurate rule-based outcome reward in\nlater training stages. Experiments show that our SophiaVL-R1 surpasses a series\nof reasoning MLLMs on various benchmarks (e.g., MathVisita, MMMU),\ndemonstrating strong reasoning and generalization capabilities. Notably, our\nSophiaVL-R1-7B even outperforms LLaVA-OneVision-72B on most benchmarks, despite\nthe latter having 10 times more parameters. All code, models, and datasets are\nmade publicly available at https://github.com/kxfan2002/SophiaVL-R1.",
    "pdf_url": "http://arxiv.org/pdf/2505.17018v1",
    "published": "2025-05-22T17:59:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17019v1",
    "title": "Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework",
    "authors": [
      "Chenhao Zhang",
      "Yazhe Niu"
    ],
    "abstract": "Metaphorical comprehension in images remains a critical challenge for AI\nsystems, as existing models struggle to grasp the nuanced cultural, emotional,\nand contextual implications embedded in visual content. While multimodal large\nlanguage models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they\nstruggle with a fundamental limitation on image implication tasks: contextual\ngaps that obscure the relationships between different visual elements and their\nabstract meanings. Inspired by the human cognitive process, we propose Let\nAndroids Dream (LAD), a novel framework for image implication understanding and\nreasoning. LAD addresses contextual missing through the three-stage framework:\n(1) Perception: converting visual information into rich and multi-level textual\nrepresentations, (2) Search: iteratively searching and integrating cross-domain\nknowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment\nimage implication via explicit reasoning. Our framework with the lightweight\nGPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English\nimage implication benchmark and a huge improvement on Chinese benchmark,\nperforming comparable with the GPT-4o model on Multiple-Choice Question (MCQ)\nand outperforms 36.7% on Open-Style Question (OSQ). Additionally, our work\nprovides new insights into how AI can more effectively interpret image\nimplications, advancing the field of vision-language reasoning and human-AI\ninteraction. Our project is publicly available at\nhttps://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.",
    "pdf_url": "http://arxiv.org/pdf/2505.17019v1",
    "published": "2025-05-22T17:59:53+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17020v1",
    "title": "CrossLMM: Decoupling Long Video Sequences from LMMs via Dual Cross-Attention Mechanisms",
    "authors": [
      "Shilin Yan",
      "Jiaming Han",
      "Joey Tsai",
      "Hongwei Xue",
      "Rongyao Fang",
      "Lingyi Hong",
      "Ziyu Guo",
      "Ray Zhang"
    ],
    "abstract": "The advent of Large Multimodal Models (LMMs) has significantly enhanced Large\nLanguage Models (LLMs) to process and interpret diverse data modalities (e.g.,\nimage and video). However, as input complexity increases, particularly with\nlong video sequences, the number of required tokens has grown significantly,\nleading to quadratically computational costs. This has made the efficient\ncompression of video tokens in LMMs, while maintaining performance integrity, a\npressing research challenge. In this paper, we introduce CrossLMM, decoupling\nlong video sequences from LMMs via a dual cross-attention mechanism, which\nsubstantially reduces visual token quantity with minimal performance\ndegradation. Specifically, we first implement a significant token reduction\nfrom pretrained visual encoders through a pooling methodology. Then, within LLM\nlayers, we employ a visual-to-visual cross-attention mechanism, wherein the\npooled visual tokens function as queries against the original visual token set.\nThis module enables more efficient token utilization while retaining\nfine-grained informational fidelity. In addition, we introduce a text-to-visual\ncross-attention mechanism, for which the text tokens are enhanced through\ninteraction with the original visual tokens, enriching the visual comprehension\nof the text tokens. Comprehensive empirical evaluation demonstrates that our\napproach achieves comparable or superior performance across diverse video-based\nLMM benchmarks, despite utilizing substantially fewer computational resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.17020v1",
    "published": "2025-05-22T17:59:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17017v2",
    "title": "Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO",
    "authors": [
      "Chengzhuo Tong",
      "Ziyu Guo",
      "Renrui Zhang",
      "Wenyu Shan",
      "Xinyu Wei",
      "Zhenghao Xing",
      "Hongsheng Li",
      "Pheng-Ann Heng"
    ],
    "abstract": "Recent advancements underscore the significant role of Reinforcement Learning\n(RL) in enhancing the Chain-of-Thought (CoT) reasoning capabilities of large\nlanguage models (LLMs). Two prominent RL algorithms, Direct Preference\nOptimization (DPO) and Group Relative Policy Optimization (GRPO), are central\nto these developments, showcasing different pros and cons. Autoregressive image\ngeneration, also interpretable as a sequential CoT reasoning process, presents\nunique challenges distinct from LLM-based CoT reasoning. These encompass\nensuring text-image consistency, improving image aesthetic quality, and\ndesigning sophisticated reward models, rather than relying on simpler\nrule-based rewards. While recent efforts have extended RL to this domain, these\nexplorations typically lack an in-depth analysis of the domain-specific\nchallenges and the characteristics of different RL strategies. To bridge this\ngap, we provide the first comprehensive investigation of the GRPO and DPO\nalgorithms in autoregressive image generation, evaluating their in-domain\nperformance and out-of-domain generalization, while scrutinizing the impact of\ndifferent reward models on their respective capabilities. Our findings reveal\nthat GRPO and DPO exhibit distinct advantages, and crucially, that reward\nmodels possessing stronger intrinsic generalization capabilities potentially\nenhance the generalization potential of the applied RL algorithms. Furthermore,\nwe systematically explore three prevalent scaling strategies to enhance both\ntheir in-domain and out-of-domain proficiency, deriving unique insights into\nefficiently scaling performance for each paradigm. We hope our study paves a\nnew path for inspiring future work on developing more effective RL algorithms\nto achieve robust CoT reasoning in the realm of autoregressive image\ngeneration. Code is released at\nhttps://github.com/ZiyuGuo99/Image-Generation-CoT",
    "pdf_url": "http://arxiv.org/pdf/2505.17017v2",
    "published": "2025-05-22T17:59:49+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17016v1",
    "title": "Interactive Post-Training for Vision-Language-Action Models",
    "authors": [
      "Shuhan Tan",
      "Kairan Dou",
      "Yue Zhao",
      "Philipp Krähenbühl"
    ],
    "abstract": "We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based\ninteractive post-training paradigm that fine-tunes pretrained\nVision-Language-Action (VLA) models using only sparse binary success rewards.\nExisting VLA training pipelines rely heavily on offline expert demonstration\ndata and supervised imitation, limiting their ability to adapt to new tasks and\nenvironments under low-data regimes. RIPT-VLA addresses this by enabling\ninteractive post-training with a stable policy optimization algorithm based on\ndynamic rollout sampling and leave-one-out advantage estimation.\n  RIPT-VLA has the following characteristics. First, it applies to various VLA\nmodels, resulting in an improvement on the lightweight QueST model by 21.2%,\nand the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it\nis computationally efficient and data-efficient: with only one demonstration,\nRIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success\nrate within 15 iterations. Furthermore, we demonstrate that the policy learned\nby RIPT-VLA generalizes across different tasks and scenarios and is robust to\nthe initial state context. These results highlight RIPT-VLA as a practical and\neffective paradigm for post-training VLA models through minimal supervision.",
    "pdf_url": "http://arxiv.org/pdf/2505.17016v1",
    "published": "2025-05-22T17:59:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17015v1",
    "title": "Multi-SpatialMLLM: Multi-Frame Spatial Understanding with Multi-Modal Large Language Models",
    "authors": [
      "Runsen Xu",
      "Weiyao Wang",
      "Hao Tang",
      "Xingyu Chen",
      "Xiaodong Wang",
      "Fu-Jen Chu",
      "Dahua Lin",
      "Matt Feiszli",
      "Kevin J. Liang"
    ],
    "abstract": "Multi-modal large language models (MLLMs) have rapidly advanced in visual\ntasks, yet their spatial understanding remains limited to single images,\nleaving them ill-suited for robotics and other real-world applications that\nrequire multi-frame reasoning. In this paper, we propose a framework to equip\nMLLMs with robust multi-frame spatial understanding by integrating depth\nperception, visual correspondence, and dynamic perception. Central to our\napproach is the MultiSPA dataset, a novel, large-scale collection of more than\n27 million samples spanning diverse 3D and 4D scenes. Alongside MultiSPA, we\nintroduce a comprehensive benchmark that tests a wide spectrum of spatial tasks\nunder uniform metrics. Our resulting model, Multi-SpatialMLLM, achieves\nsignificant gains over baselines and proprietary systems, demonstrating\nscalable, generalizable multi-frame reasoning. We further observe multi-task\nbenefits and early indications of emergent capabilities in challenging\nscenarios, and showcase how our model can serve as a multi-frame reward\nannotator for robotics.",
    "pdf_url": "http://arxiv.org/pdf/2505.17015v1",
    "published": "2025-05-22T17:59:39+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17014v1",
    "title": "Emergent Gravity from Topological Quantum Field Theory: Stochastic Gradient Flow Perspective away from the Quantum Gravity Problem",
    "authors": [
      "Andrea Addazi",
      "Salvatore Capozziello",
      "Jinglong Liu",
      "Antonino Marciano",
      "Giuseppe Meluccio",
      "Xuan-Lin Su"
    ],
    "abstract": "We propose a scenario according to which the ultraviolet completion of\nGeneral Relativity is realized through a stochastic gradient flow towards a\ntopological BF theory. Specifically, we consider the stochastic gradient flow\nof a pre-geometric theory proposed by Wilczek. Its infrared limit exists, and\ncorresponds to a fixed point where stochastic fluctuations vanish.\nDiffeomorphism symmetries are restored in this limit, where the theory is\nclassical and expressed by the Einstein-Hilbert action. The infrared phase then\ncorresponds to the classical theory of General Relativity, the quantization of\nwhich becomes meaningless. Away from the infrared limit, in the pre-geometric\nphase of the stochastic gradient flow, the relevant fields of the Wilczek\ntheory undergo stochastic fluctuations. The theory can be quantized\nperturbatively, generating corrections to the classical Einstein-Hilbert\naction. The stochastic gradient flow also possesses an ultraviolet fixed point.\nThe theory flows to a topological BF action, to which general non-perturbative\nquantization methods can be applied. Two phase transitions occur along the\nthermal time dynamics, being marked by: i) the breakdown of the topological BF\nsymmetries in the ultraviolet regime, which originates the pre-geometric phase\ndescribed by the Wilczek theory; ii) the breakdown of the parental symmetries\ncharacterizing the Wilczek theory, from which General Relativity emerges. The\nproblem of quantizing the Einstein-Hilbert action of gravity finally becomes\nredundant.",
    "pdf_url": "http://arxiv.org/pdf/2505.17014v1",
    "published": "2025-05-22T17:59:32+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17013v4",
    "title": "When Are Concepts Erased From Diffusion Models?",
    "authors": [
      "Kevin Lu",
      "Nicky Kriplani",
      "Rohit Gandikota",
      "Minh Pham",
      "David Bau",
      "Chinmay Hegde",
      "Niv Cohen"
    ],
    "abstract": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.",
    "pdf_url": "http://arxiv.org/pdf/2505.17013v4",
    "published": "2025-05-22T17:59:09+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17012v1",
    "title": "SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding",
    "authors": [
      "Haoning Wu",
      "Xiao Huang",
      "Yaohui Chen",
      "Ya Zhang",
      "Yanfeng Wang",
      "Weidi Xie"
    ],
    "abstract": "Multimodal large language models (MLLMs) have achieved impressive success in\nquestion-answering tasks, yet their capabilities for spatial understanding are\nless explored. This work investigates a critical question: do existing MLLMs\npossess 3D spatial perception and understanding abilities? Concretely, we make\nthe following contributions in this paper: (i) we introduce VGBench, a\nbenchmark specifically designed to assess MLLMs for visual geometry perception,\ne.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most\ncomprehensive and diverse multimodal spatial understanding benchmark to date,\nintegrating VGBench with relevant data from the other 11 existing datasets.\nThis benchmark comprises 28K samples across various spatial understanding\ntasks, modalities, and QA formats, along with a carefully curated challenging\nsubset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent\nsystem incorporating 9 specialized tools for spatial understanding, supporting\nboth Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive\nevaluations to reveal persistent challenges in spatial reasoning while\ndemonstrating the effectiveness of SpatialAgent. We believe SpatialScore will\noffer valuable insights and serve as a rigorous benchmark for the next\nevolution of MLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.17012v1",
    "published": "2025-05-22T17:59:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17011v1",
    "title": "Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space",
    "authors": [
      "Yan Li",
      "Changyao Tian",
      "Renqiu Xia",
      "Ning Liao",
      "Weiwei Guo",
      "Junchi Yan",
      "Hongsheng Li",
      "Jifeng Dai",
      "Hao Li",
      "Xue Yang"
    ],
    "abstract": "We propose AdapTok, an adaptive temporal causal video tokenizer that can\nflexibly allocate tokens for different frames based on video content. AdapTok\nis equipped with a block-wise masking strategy that randomly drops tail tokens\nof each block during training, and a block causal scorer to predict the\nreconstruction quality of video frames using different numbers of tokens.\nDuring inference, an adaptive token allocation strategy based on integer linear\nprogramming is further proposed to adjust token usage given predicted scores.\nSuch design allows for sample-wise, content-aware, and temporally dynamic token\nallocation under a controllable overall budget. Extensive experiments for video\nreconstruction and generation on UCF-101 and Kinetics-600 demonstrate the\neffectiveness of our approach. Without additional image data, AdapTok\nconsistently improves reconstruction quality and generation performance under\ndifferent token budgets, allowing for more scalable and token-efficient\ngenerative video modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.17011v1",
    "published": "2025-05-22T17:59:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17010v1",
    "title": "Understanding Prompt Tuning and In-Context Learning via Meta-Learning",
    "authors": [
      "Tim Genewein",
      "Kevin Wenliang Li",
      "Jordi Grau-Moya",
      "Anian Ruoss",
      "Laurent Orseau",
      "Marcus Hutter"
    ],
    "abstract": "Prompting is one of the main ways to adapt a pretrained model to target\ntasks. Besides manually constructing prompts, many prompt optimization methods\nhave been proposed in the literature. Method development is mainly empirically\ndriven, with less emphasis on a conceptual understanding of prompting. In this\npaper we discuss how optimal prompting can be understood through a Bayesian\nview, which also implies some fundamental limitations of prompting that can\nonly be overcome by tuning weights. The paper explains in detail how\nmeta-trained neural networks behave as Bayesian predictors over the pretraining\ndistribution, whose hallmark feature is rapid in-context adaptation. Optimal\nprompting can be studied formally as conditioning these Bayesian predictors,\nyielding criteria for target tasks where optimal prompting is and is not\npossible. We support the theory with educational experiments on LSTMs and\nTransformers, where we compare different versions of prefix-tuning and\ndifferent weight-tuning methods. We also confirm that soft prefixes, which are\nsequences of real-valued vectors outside the token alphabet, can lead to very\neffective prompts for trained and even untrained networks by manipulating\nactivations in ways that are not achievable by hard tokens. This adds an\nimportant mechanistic aspect beyond the conceptual Bayesian theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.17010v1",
    "published": "2025-05-22T17:58:53+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17009v2",
    "title": "Topological Phase Transitions and Mixed State Order in a Hubbard Quantum Simulator",
    "authors": [
      "Lin Su",
      "Rahul Sahay",
      "Michal Szurek",
      "Alexander Douglas",
      "Ognjen Markovic",
      "Ceren B. Dag",
      "Ruben Verresen",
      "Markus Greiner"
    ],
    "abstract": "Topological phase transitions challenge conventional paradigms in many-body\nphysics by separating phases that are locally indistinguishable yet globally\ndistinct. Using a quantum simulator of interacting erbium atoms in an optical\nlattice, we observe such a transition between one-dimensional crystalline\nsymmetry-protected topological phases (CSPTs). We detect the critical point\nthrough non-local string order parameters and reveal its connection to the\ntransition predicted between the Mott and Haldane insulators. Moreover, we\ndemonstrate a striking property: stacking two identical systems eliminates the\ntransition, confirming the predicted group structure and invertibility of SPTs.\nFinally, while introducing symmetry-breaking disorder also removes the\ntransition, disorder averaging restores it. Consequently, the adjacent phases\nrealize a form of mixed-state quantum order wherein the criticality between\nthem depends on the observer's information. Our results demonstrate how\ntopology and information influence quantum phase transitions, opening the doors\nto probing novel critical phenomena in programmable quantum matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.17009v2",
    "published": "2025-05-22T17:58:35+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "cond-mat.str-el",
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.17008v1",
    "title": "Deep mineralogical segmentation of thin section images based on QEMSCAN maps",
    "authors": [
      "Jean Pablo Vieira de Mello",
      "Matheus Augusto Alves Cuglieri",
      "Leandro P. de Figueiredo",
      "Fernando Bordignon",
      "Marcelo Ramalho Albuquerque",
      "Rodrigo Surmas",
      "Bruno Cavalcanti de Paula"
    ],
    "abstract": "Interpreting the mineralogical aspects of rock thin sections is an important\ntask for oil and gas reservoirs evaluation. However, human analysis tend to be\nsubjective and laborious. Technologies like QEMSCAN(R) are designed to automate\nthe mineralogical mapping process, but also suffer from limitations like high\nmonetary costs and time-consuming analysis. This work proposes a Convolutional\nNeural Network model for automatic mineralogical segmentation of thin section\nimages of carbonate rocks. The model is able to mimic the QEMSCAN mapping\nitself in a low-cost, generalized and efficient manner. For this, the U-Net\nsemantic segmentation architecture is trained on plane and cross polarized thin\nsection images using the corresponding QEMSCAN maps as target, which is an\napproach not widely explored. The model was instructed to differentiate\noccurrences of Calcite, Dolomite, Mg-Clay Minerals, Quartz, Pores and the\nremaining mineral phases as an unique class named \"Others\", while it was\nvalidated on rock facies both seen and unseen during training, in order to\naddress its generalization capability. Since the images and maps are provided\nin different resolutions, image registration was applied to align then\nspatially. The study reveals that the quality of the segmentation is very much\ndependent on these resolution differences and on the variety of learnable rock\ntextures. However, it shows promising results, especially with regard to the\nproper delineation of minerals boundaries on solid textures and precise\nestimation of the minerals distributions, describing a nearly linear\nrelationship between expected and predicted distributions, with coefficient of\ndetermination (R^2) superior to 0.97 for seen facies and 0.88 for unseen.",
    "pdf_url": "http://arxiv.org/pdf/2505.17008v1",
    "published": "2025-05-22T17:58:34+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17007v1",
    "title": "Broadband Search for Axion Dark Matter via Shift Current",
    "authors": [
      "Dan Kondo",
      "Takahiro Morimoto",
      "Genta Osaki",
      "Thanaporn Sichanugrist"
    ],
    "abstract": "We propose a novel method to detect axion dark matter based on a topological\nphenomenon known as the shift current. We exploit the second-order nonlinearity\nof the shift current by applying a strong oscillating electric field. This\nfield enhances the axion-induced shift current signal and downconverts its\nfrequency to a more accessible range. The non-dissipative nature of the shift\ncurrent allows us to achieve broadband detection via difference frequency\ngeneration. We demonstrate, using Type-I Weyl semimetal TaAs property, the\npossibility of probing the parameter space of the QCD axion in the mass range\nof $\\mathcal{O}(10)$ - $\\mathcal{O}(100) \\ \\rm meV$ corresponding to the photon\ncoupling of $g_{a\\gamma\\gamma}\\simeq$ $\\mathcal{O}(10^{-12})$ -\n$\\mathcal{O}(10^{-11})~\\text{GeV}^{-1}$, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.17007v1",
    "published": "2025-05-22T17:58:29+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17006v1",
    "title": "CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning",
    "authors": [
      "Jiange Yang",
      "Yansong Shi",
      "Haoyi Zhu",
      "Mingyu Liu",
      "Kaijing Ma",
      "Yating Wang",
      "Gangshan Wu",
      "Tong He",
      "Limin Wang"
    ],
    "abstract": "Learning latent motion from Internet videos is crucial for building\ngeneralist robots. However, existing discrete latent action methods suffer from\ninformation loss and struggle with complex and fine-grained dynamics. We\npropose CoMo, which aims to learn more informative continuous motion\nrepresentations from diverse, internet-scale videos. CoMo employs a early\ntemporal feature difference mechanism to prevent model collapse and suppress\nstatic appearance noise, effectively discouraging shortcut learning problem.\nFurthermore, guided by the information bottleneck principle, we constrain the\nlatent motion embedding dimensionality to achieve a better balance between\nretaining sufficient action-relevant information and minimizing the inclusion\nof action-irrelevant appearance noise. Additionally, we also introduce two new\nmetrics for more robustly and affordably evaluating motion and guiding motion\nlearning methods development: (i) the linear probing MSE of action prediction,\nand (ii) the cosine similarity between past-to-current and future-to-current\nmotion embeddings. Critically, CoMo exhibits strong zero-shot generalization,\nenabling it to generate continuous pseudo actions for previously unseen video\ndomains. This capability facilitates unified policy joint learning using pseudo\nactions derived from various action-less video datasets (such as\ncross-embodiment videos and, notably, human demonstration videos), potentially\naugmented with limited labeled robot data. Extensive experiments show that\npolicies co-trained with CoMo pseudo actions achieve superior performance with\nboth diffusion and autoregressive architectures in simulated and real-world\nsettings.",
    "pdf_url": "http://arxiv.org/pdf/2505.17006v1",
    "published": "2025-05-22T17:58:27+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17005v1",
    "title": "R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning",
    "authors": [
      "Huatong Song",
      "Jinhao Jiang",
      "Wenqing Tian",
      "Zhipeng Chen",
      "Yuhuan Wu",
      "Jiahao Zhao",
      "Yingqian Min",
      "Wayne Xin Zhao",
      "Lei Fang",
      "Ji-Rong Wen"
    ],
    "abstract": "Large Language Models (LLMs) are powerful but prone to hallucinations due to\nstatic knowledge. Retrieval-Augmented Generation (RAG) helps by injecting\nexternal information, but current methods often are costly, generalize poorly,\nor ignore the internal knowledge of the model. In this paper, we introduce\nR1-Searcher++, a novel framework designed to train LLMs to adaptively leverage\nboth internal and external knowledge sources. R1-Searcher++ employs a two-stage\ntraining strategy: an initial SFT Cold-start phase for preliminary format\nlearning, followed by RL for Dynamic Knowledge Acquisition. The RL stage uses\noutcome-supervision to encourage exploration, incorporates a reward mechanism\nfor internal knowledge utilization, and integrates a memorization mechanism to\ncontinuously assimilate retrieved information, thereby enriching the model's\ninternal knowledge. By leveraging internal knowledge and external search\nengine, the model continuously improves its capabilities, enabling efficient\nretrieval-augmented reasoning. Our experiments demonstrate that R1-Searcher++\noutperforms previous RAG and reasoning methods and achieves efficient\nretrieval. The code is available at\nhttps://github.com/RUCAIBox/R1-Searcher-plus.",
    "pdf_url": "http://arxiv.org/pdf/2505.17005v1",
    "published": "2025-05-22T17:58:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17004v1",
    "title": "Guided Diffusion Sampling on Function Spaces with Applications to PDEs",
    "authors": [
      "Jiachen Yao",
      "Abbas Mammadov",
      "Julius Berner",
      "Gavin Kerrigan",
      "Jong Chul Ye",
      "Kamyar Azizzadenesheli",
      "Anima Anandkumar"
    ],
    "abstract": "We propose a general framework for conditional sampling in PDE-based inverse\nproblems, targeting the recovery of whole solutions from extremely sparse or\nnoisy measurements. This is accomplished by a function-space diffusion model\nand plug-and-play guidance for conditioning. Our method first trains an\nunconditional discretization-agnostic denoising model using neural operator\narchitectures. At inference, we refine the samples to satisfy sparse\nobservation data via a gradient-based guidance mechanism. Through rigorous\nmathematical analysis, we extend Tweedie's formula to infinite-dimensional\nHilbert spaces, providing the theoretical foundation for our posterior sampling\napproach. Our method (FunDPS) accurately captures posterior distributions in\nfunction spaces under minimal supervision and severe data scarcity. Across five\nPDE tasks with only 3% observation, our method achieves an average 32% accuracy\nimprovement over state-of-the-art fixed-resolution diffusion baselines while\nreducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning\nensures strong cross-resolution generalizability. To the best of our knowledge,\nthis is the first diffusion-based framework to operate independently of\ndiscretization, offering a practical and flexible solution for forward and\ninverse problems in the context of PDEs. Code is available at\nhttps://github.com/neuraloperator/FunDPS",
    "pdf_url": "http://arxiv.org/pdf/2505.17004v1",
    "published": "2025-05-22T17:58:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17003v1",
    "title": "Sufficient conditions for offline reactivation in recurrent neural networks",
    "authors": [
      "Nanda H. Krishna",
      "Colin Bredenberg",
      "Daniel Levenstein",
      "Blake A. Richards",
      "Guillaume Lajoie"
    ],
    "abstract": "During periods of quiescence, such as sleep, neural activity in many brain\ncircuits resembles that observed during periods of task engagement. However,\nthe precise conditions under which task-optimized networks can autonomously\nreactivate the same network states responsible for online behavior is poorly\nunderstood. In this study, we develop a mathematical framework that outlines\nsufficient conditions for the emergence of neural reactivation in circuits that\nencode features of smoothly varying stimuli. We demonstrate mathematically that\nnoisy recurrent networks optimized to track environmental state variables using\nchange-based sensory information naturally develop denoising dynamics, which,\nin the absence of input, cause the network to revisit state configurations\nobserved during periods of online activity. We validate our findings using\nnumerical experiments on two canonical neuroscience tasks: spatial position\nestimation based on self-motion cues, and head direction estimation based on\nangular velocity cues. Overall, our work provides theoretical support for\nmodeling offline reactivation as an emergent consequence of task optimization\nin noisy neural circuits.",
    "pdf_url": "http://arxiv.org/pdf/2505.17003v1",
    "published": "2025-05-22T17:57:59+00:00",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.17002v2",
    "title": "PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association",
    "authors": [
      "Abdul Hannan",
      "Muhammad Arslan Manzoor",
      "Shah Nawaz",
      "Muhammad Irzam Liaqat",
      "Markus Schedl",
      "Mubashir Noman"
    ],
    "abstract": "We study the task of learning association between faces and voices, which is\ngaining interest in the multimodal community lately. These methods suffer from\nthe deliberate crafting of negative mining procedures as well as the reliance\non the distant margin parameter. These issues are addressed by learning a joint\nembedding space in which orthogonality constraints are applied to the fused\nembeddings of faces and voices. However, embedding spaces of faces and voices\npossess different characteristics and require spaces to be aligned before\nfusing them. To this end, we propose a method that accurately aligns the\nembedding spaces and fuses them with an enhanced gated fusion thereby improving\nthe performance of face-voice association. Extensive experiments on the\nVoxCeleb dataset reveals the merits of the proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.17002v2",
    "published": "2025-05-22T17:57:55+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17001v1",
    "title": "Seeing through Satellite Images at Street Views",
    "authors": [
      "Ming Qian",
      "Bin Tan",
      "Qiuyu Wang",
      "Xianwei Zheng",
      "Hanjiang Xiong",
      "Gui-Song Xia",
      "Yujun Shen",
      "Nan Xue"
    ],
    "abstract": "This paper studies the task of SatStreet-view synthesis, which aims to render\nphotorealistic street-view panorama images and videos given any satellite image\nand specified camera positions or trajectories. We formulate to learn neural\nradiance field from paired images captured from satellite and street\nviewpoints, which comes to be a challenging learning problem due to the\nsparse-view natural and the extremely-large viewpoint changes between satellite\nand street-view images. We tackle the challenges based on a task-specific\nobservation that street-view specific elements, including the sky and\nillumination effects are only visible in street-view panoramas, and present a\nnovel approach Sat2Density++ to accomplish the goal of photo-realistic\nstreet-view panoramas rendering by modeling these street-view specific in\nneural networks. In the experiments, our method is testified on both urban and\nsuburban scene datasets, demonstrating that Sat2Density++ is capable of\nrendering photorealistic street-view panoramas that are consistent across\nmultiple views and faithful to the satellite image.",
    "pdf_url": "http://arxiv.org/pdf/2505.17001v1",
    "published": "2025-05-22T17:57:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17000v1",
    "title": "Critical Points of Random Neural Networks",
    "authors": [
      "Simmaco Di Lillo"
    ],
    "abstract": "This work investigates the expected number of critical points of random\nneural networks with different activation functions as the depth increases in\nthe infinite-width limit. Under suitable regularity conditions, we derive\nprecise asymptotic formulas for the expected number of critical points of fixed\nindex and those exceeding a given threshold. Our analysis reveals three\ndistinct regimes depending on the value of the first derivative of the\ncovariance evaluated at 1: the expected number of critical points may converge,\ngrow polynomially, or grow exponentially with depth. The theoretical\npredictions are supported by numerical experiments. Moreover, we provide\nnumerical evidence suggesting that, when the regularity condition is not\nsatisfied (e.g. for neural networks with ReLU as activation function), the\nnumber of critical points increases as the map resolution increases, indicating\na potential divergence in the number of critical points.",
    "pdf_url": "http://arxiv.org/pdf/2505.17000v1",
    "published": "2025-05-22T17:57:30+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.PR",
      "60G60, 62B10, 62M45"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16998v1",
    "title": "Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?",
    "authors": [
      "Jin Jiang",
      "Jianing Wang",
      "Yuchen Yan",
      "Yang Liu",
      "Jianhua Zhu",
      "Mengdi Zhang",
      "Xunliang Cai",
      "Liangcai Gao"
    ],
    "abstract": "Large Language Models (LLMs) have been shown to achieve breakthrough\nperformance on complex logical reasoning tasks. Nevertheless, most existing\nresearch focuses on employing formal language to guide LLMs to derive reliable\nreasoning paths, while systematic evaluations of these capabilities are still\nlimited. In this paper, we aim to conduct a comprehensive evaluation of LLMs\nacross various logical reasoning problems utilizing formal languages. From the\nperspective of three dimensions, i.e., spectrum of LLMs, taxonomy of tasks, and\nformat of trajectories, our key findings are: 1) Thinking models significantly\noutperform Instruct models, especially when formal language is employed; 2) All\nLLMs exhibit limitations in inductive reasoning capability, irrespective of\nwhether they use a formal language; 3) Data with PoT format achieves the best\ngeneralization performance across other languages. Additionally, we also curate\nthe formal-relative training data to further enhance the small language models,\nand the experimental results indicate that a simple rejected fine-tuning method\ncan better enable LLMs to generalize across formal languages and achieve the\nbest overall performance. Our codes and reports are available at\nhttps://github.com/jiangjin1999/FormalEval.",
    "pdf_url": "http://arxiv.org/pdf/2505.16998v1",
    "published": "2025-05-22T17:57:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16999v1",
    "title": "Nonlinear thermal and thermoelectric transport from quantum geometry",
    "authors": [
      "Yuan Fang",
      "Shouvik Sur",
      "Yonglong Xie",
      "Qimiao Si"
    ],
    "abstract": "Quantum geometry may enable the development of quantum phases ranging from\nsuperconductivity to correlated topological states. One powerful probe of\nquantum geometry is the nonlinear Hall response which detects Berry curvature\ndipole in systems with time-reversal invariance and broken inversion symmetry.\nWith broken time-reversal symmetry, this response is also associated with\nquantum metric dipole. Here we investigate nonlinear thermal and thermoelectric\nresponses, which provide a wealth of new information about quantum geometry. In\nparticular, we uncover a web of connections between these quantities that\nparallel the standard Wiedemann-Franz and Mott relations. Implications for the\nstudies of a variety of topological systems, including Weyl-Kondo semimetals\nand Bernal bilayer graphene, are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.16999v1",
    "published": "2025-05-22T17:57:23+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.16997v1",
    "title": "X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs",
    "authors": [
      "Rui Ye",
      "Xiangrui Liu",
      "Qimin Wu",
      "Xianghe Pang",
      "Zhenfei Yin",
      "Lei Bai",
      "Siheng Chen"
    ],
    "abstract": "LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by\nenabling cooperation among multiple specialized agents. However, most existing\nMAS frameworks rely on a single LLM to drive all agents, constraining the\nsystem's intelligence to the limit of that model. This paper explores the\nparadigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by\ndiverse LLMs, elevating the system's potential to the collective intelligence\nof diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to\nevaluate the performance of various LLMs across different domains and\nMAS-related functions. As an extensive empirical study, we assess 27 LLMs\nacross 5 domains (encompassing 21 test sets) and 5 functions, conducting over\n1.7 million evaluations to identify optimal model selections for each\ndomain-function combination. Building on these findings, we demonstrate that\ntransitioning from homogeneous to heterogeneous LLM-driven MAS can\nsignificantly enhance system performance without requiring structural redesign.\nSpecifically, in a chatbot-only MAS scenario, the heterogeneous configuration\nyields up to 8.4\\% performance improvement on the MATH dataset. In a mixed\nchatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable\n47\\% performance boost on the AIME dataset. Our results underscore the\ntransformative potential of heterogeneous LLMs in MAS, highlighting a promising\navenue for advancing scalable, collaborative AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16997v1",
    "published": "2025-05-22T17:56:39+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16996v1",
    "title": "A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations",
    "authors": [
      "Shalev Manor",
      "Mohammad Kohandel"
    ],
    "abstract": "Inverse problems involving differential equations often require identifying\nunknown parameters or functions from data. Existing approaches, such as\nPhysics-Informed Neural Networks (PINNs), Universal Differential Equations\n(UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective\nat isolating either parameters or functions but can face challenges when\napplied simultaneously due to solution non-uniqueness. In this work, we\nintroduce a framework that addresses these limitations by establishing\nconditions under which unique solutions can be guaranteed. To illustrate, we\napply it to examples from biological systems and ecological dynamics,\ndemonstrating accurate and interpretable results. Our approach significantly\nenhances the potential of machine learning techniques in modeling complex\nsystems in science and engineering.",
    "pdf_url": "http://arxiv.org/pdf/2505.16996v1",
    "published": "2025-05-22T17:56:38+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16995v1",
    "title": "DecoupledESC: Enhancing Emotional Support Generation via Strategy-Response Decoupled Preference Optimization",
    "authors": [
      "Chao Zhang",
      "Xin Shi",
      "Xueqiao Zhang",
      "Yifan Zhu",
      "Yi Yang",
      "Yawei Luo"
    ],
    "abstract": "Recent advances in Emotional Support Conversation (ESC) have improved\nemotional support generation by fine-tuning Large Language Models (LLMs) via\nSupervised Fine-Tuning (SFT). However, common psychological errors still\npersist. While Direct Preference Optimization (DPO) shows promise in reducing\nsuch errors through pairwise preference learning, its effectiveness in ESC\ntasks is limited by two key challenges: (1) Entangled data structure: Existing\nESC data inherently entangles psychological strategies and response content,\nmaking it difficult to construct high-quality preference pairs; and (2)\nOptimization ambiguity: Applying vanilla DPO to such entangled pairwise data\nleads to ambiguous training objectives. To address these issues, we introduce\nInferential Preference Mining (IPM) to construct high-quality preference data,\nforming the IPM-PrefDial dataset. Building upon this data, we propose a\nDecoupled ESC framework inspired by Gross's Extended Process Model of Emotion\nRegulation, which decomposes the ESC task into two sequential subtasks:\nstrategy planning and empathic response generation. Each was trained via SFT\nand subsequently enhanced by DPO to align with the psychological preference.\nExtensive experiments demonstrate that our Decoupled ESC framework outperforms\njoint optimization baselines, reducing preference bias and improving response\nquality.",
    "pdf_url": "http://arxiv.org/pdf/2505.16995v1",
    "published": "2025-05-22T17:56:21+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16994v1",
    "title": "$\\text{R}^2\\text{ec}$: Towards Large Recommender Models with Reasoning",
    "authors": [
      "Runyang You",
      "Yongqi Li",
      "Xinyu Lin",
      "Xin Zhang",
      "Wenjie Wang",
      "Wenjie Li",
      "Liqiang Nie"
    ],
    "abstract": "Large recommender models have extended LLMs as powerful recommenders via\nencoding or item generation, and recent breakthroughs in LLM reasoning\nsynchronously motivate the exploration of reasoning in recommendation. Current\nstudies usually position LLMs as external reasoning modules to yield auxiliary\nthought for augmenting conventional recommendation pipelines. However, such\ndecoupled designs are limited in significant resource cost and suboptimal joint\noptimization. To address these issues, we propose \\name, a unified large\nrecommender model with intrinsic reasoning capabilities. Initially, we\nreconceptualize the model architecture to facilitate interleaved reasoning and\nrecommendation in the autoregressive process. Subsequently, we propose RecPO, a\ncorresponding reinforcement learning framework that optimizes \\name\\ both the\nreasoning and recommendation capabilities simultaneously in a single policy\nupdate; RecPO introduces a fused reward scheme that solely leverages\nrecommendation labels to simulate the reasoning capability, eliminating\ndependency on specialized reasoning annotations. Experiments on three datasets\nwith various baselines verify the effectiveness of \\name, showing relative\nimprovements of 68.67\\% in Hit@5 and 45.21\\% in NDCG@20. Code available at\nhttps://github.com/YRYangang/RRec.",
    "pdf_url": "http://arxiv.org/pdf/2505.16994v1",
    "published": "2025-05-22T17:55:43+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17172v2",
    "title": "Einstein Maxwell Scalar Black Hole: Thermodynamic Properties with Logarithmic Barrow Entropy",
    "authors": [
      "Ritabrata Biswas",
      "Satyajit Pal"
    ],
    "abstract": "The thermodynamics of black holes (BHs) within the Einstein Maxwell Scalar\n(EMS) framework, incorporating Barrow entropy and its logarithmic corrections\nto analyze quantum gravity effects is investigated here. A static, spherically\nsymmetric BH solution is obtained by coupling the scalar field nonminimally to\nthe electromagnetic field through a scalar dependent function. The\nthermodynamic properties including temperature, specific heat, and Gibbs free\nenergy are derived and explored in the context of Barrow-modified entropy. We\nidentify phase transitions and critical behavior by analyzing PV criticality\nand uncover the influence of scalar and electric charges on stability.\nFurthermore, the Joule Thomson expansion is examined to understand the\ninversion behavior and thermodynamic responses under adiabatic expansion. Our\nfindings suggest the presence of thermodynamic instabilities, remnants, and\nnontrivial critical phenomena, providing new insights into BH thermodynamics in\nmodified gravity scenarios with quantum corrections.",
    "pdf_url": "http://arxiv.org/pdf/2505.17172v2",
    "published": "2025-05-22T17:55:23+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16993v1",
    "title": "Native Segmentation Vision Transformers",
    "authors": [
      "Guillem Brasó",
      "Aljoša Ošep",
      "Laura Leal-Taixé"
    ],
    "abstract": "Uniform downsampling remains the de facto standard for reducing spatial\nresolution in vision backbones. In this work, we propose an alternative design\nbuilt around a content-aware spatial grouping layer, that dynamically assigns\ntokens to a reduced set based on image boundaries and their semantic content.\nStacking our grouping layer across consecutive backbone stages results in\nhierarchical segmentation that arises natively in the feature extraction\nprocess, resulting in our coined Native Segmentation Vision Transformer. We\nshow that a careful design of our architecture enables the emergence of strong\nsegmentation masks solely from grouping layers, that is, without additional\nsegmentation-specific heads. This sets the foundation for a new paradigm of\nnative, backbone-level segmentation, which enables strong zero-shot results\nwithout mask supervision, as well as a minimal and efficient standalone model\ndesign for downstream segmentation tasks. Our project page is\nhttps://research.nvidia.com/labs/dvl/projects/native-segmentation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16993v1",
    "published": "2025-05-22T17:55:20+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16992v1",
    "title": "PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for Simulation-Coupled Learning Tasks in Fluid Dynamics",
    "authors": [
      "Aleksandra Franz",
      "Hao Wei",
      "Luca Guastoni",
      "Nils Thuerey"
    ],
    "abstract": "Despite decades of advancements, the simulation of fluids remains one of the\nmost challenging areas of in scientific computing. Supported by the necessity\nof gradient information in deep learning, differentiable simulators have\nemerged as an effective tool for optimization and learning in physics\nsimulations. In this work, we present our fluid simulator PICT, a\ndifferentiable pressure-implicit solver coded in PyTorch with\nGraphics-processing-unit (GPU) support. We first verify the accuracy of both\nthe forward simulation and our derived gradients in various established\nbenchmarks like lid-driven cavities and turbulent channel flows before we show\nthat the gradients provided by our solver can be used to learn complicated\nturbulence models in 2D and 3D. We apply both supervised and unsupervised\ntraining regimes using physical priors to match flow statistics. In particular,\nwe learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow\npurely based on reference statistics. The low-resolution corrector trained with\nour solver runs substantially faster than the highly resolved references, while\nkeeping or even surpassing their accuracy. Finally, we give additional insights\ninto the physical interpretation of different solver gradients, and motivate a\nphysically informed regularization technique. To ensure that the full potential\nof PICT can be leveraged, it is published as open source:\nhttps://github.com/tum-pbs/PICT.",
    "pdf_url": "http://arxiv.org/pdf/2505.16992v1",
    "published": "2025-05-22T17:55:10+00:00",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16991v2",
    "title": "An Effective Training Framework for Light-Weight Automatic Speech Recognition Models",
    "authors": [
      "Abdul Hannan",
      "Alessio Brutti",
      "Shah Nawaz",
      "Mubashir Noman"
    ],
    "abstract": "Recent advancement in deep learning encouraged developing large automatic\nspeech recognition (ASR) models that achieve promising results while ignoring\ncomputational and memory constraints. However, deploying such models on low\nresource devices is impractical despite of their favorable performance.\nExisting approaches (pruning, distillation, layer skip etc.) transform the\nlarge models into smaller ones at the cost of significant performance\ndegradation or require prolonged training of smaller models for better\nperformance. To address these issues, we introduce an efficacious two-step\nrepresentation learning based approach capable of producing several small sized\nmodels from a single large model ensuring considerably better performance in\nlimited number of epochs. Comprehensive experimentation on ASR benchmarks\nreveals the efficacy of our approach, achieving three-fold training speed-up\nand up to 12.54% word error rate improvement.",
    "pdf_url": "http://arxiv.org/pdf/2505.16991v2",
    "published": "2025-05-22T17:55:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16990v2",
    "title": "Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding",
    "authors": [
      "Runpeng Yu",
      "Xinyin Ma",
      "Xinchao Wang"
    ],
    "abstract": "In this work, we propose Dimple, the first Discrete Diffusion Multimodal\nLarge Language Model (DMLLM). We observe that training with a purely discrete\ndiffusion approach leads to significant training instability, suboptimal\nperformance, and severe length bias issues. To address these challenges, we\ndesign a novel training paradigm that combines an initial autoregressive phase\nwith a subsequent diffusion phase. This approach yields the Dimple-7B model,\ntrained on the same dataset and using a similar training pipeline as\nLLaVA-NEXT. Dimple-7B ultimately surpasses LLaVA-NEXT in performance by 3.9%,\ndemonstrating that DMLLM can achieve performance comparable to that of\nautoregressive models. To improve inference efficiency, we propose a decoding\nstrategy termed confident decoding, which dynamically adjusts the number of\ntokens generated at each step, significantly reducing the number of generation\niterations. In autoregressive models, the number of forward iterations during\ngeneration equals the response length. With confident decoding, however, the\nnumber of iterations needed by Dimple is even only $\\frac{\\text{response\nlength}}{3}$. We also re-implement the prefilling technique in autoregressive\nmodels and demonstrate that it does not significantly impact performance on\nmost benchmark evaluations, while offering a speedup of 1.5x to 7x.\nAdditionally, we explore Dimple's capability to precisely control its response\nusing structure priors. These priors enable structured responses in a manner\ndistinct from instruction-based or chain-of-thought prompting, and allow\nfine-grained control over response format and length, which is difficult to\nachieve in autoregressive models. Overall, this work validates the feasibility\nand advantages of DMLLM and enhances its inference efficiency and\ncontrollability. Code and models are available at\nhttps://github.com/yu-rp/Dimple.",
    "pdf_url": "http://arxiv.org/pdf/2505.16990v2",
    "published": "2025-05-22T17:55:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16989v1",
    "title": "Spin adaptation of the cumulant expansions of reduced density matrices",
    "authors": [
      "Julia Liebert",
      "Christian Schilling",
      "David A. Mazziotti"
    ],
    "abstract": "We develop a systematic framework for the spin adaptation of the cumulants of\np-particle reduced density matrices (RDMs), with explicit constructions for p =\n1 to 3. These spin-adapted cumulants enable rigorous treatment of both S_z and\nS^2 symmetries in quantum systems, providing a foundation for spin-resolved\nelectronic structure methods. We show that complete spin adaptation -- referred\nto as complete S-representability -- can be enforced by constraining the\nvariances of S_z and S^2, which require the 2-RDM and 4-RDM, respectively.\nImportantly, the cumulants of RDMs scale linearly with system size --\nsize-extensive -- making them a natural object for incorporating spin\nsymmetries in scalable electronic structure theories. The developed formalism\nis applicable to density-based methods (DFT), one-particle RDM functional\ntheories (RDMFT), and two-particle RDM methods. We further extend the approach\nto spin-orbit-coupled systems via total angular momentum adaptation. Beyond\nspin, the framework enables the adaptation of RDM theories to additional\nsymmetries through the construction of suitable irreducible tensor operators.",
    "pdf_url": "http://arxiv.org/pdf/2505.16989v1",
    "published": "2025-05-22T17:54:50+00:00",
    "categories": [
      "physics.chem-ph",
      "physics.comp-ph",
      "quant-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16988v1",
    "title": "MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems",
    "authors": [
      "Rui Ye",
      "Keduan Huang",
      "Qimin Wu",
      "Yuzhu Cai",
      "Tian Jin",
      "Xianghe Pang",
      "Xiangrui Liu",
      "Jiaqi Su",
      "Chen Qian",
      "Bohan Tang",
      "Kaiqu Liang",
      "Jiaao Chen",
      "Yue Hu",
      "Zhenfei Yin",
      "Rongye Shi",
      "Bo An",
      "Yang Gao",
      "Wenjun Wu",
      "Lei Bai",
      "Siheng Chen"
    ],
    "abstract": "LLM-based multi-agent systems (MAS) have demonstrated significant potential\nin enhancing single LLMs to address complex and diverse tasks in practical\napplications. Despite considerable advancements, the field lacks a unified\ncodebase that consolidates existing methods, resulting in redundant\nre-implementation efforts, unfair comparisons, and high entry barriers for\nresearchers. To address these challenges, we introduce MASLab, a unified,\ncomprehensive, and research-friendly codebase for LLM-based MAS. (1) MASLab\nintegrates over 20 established methods across multiple domains, each rigorously\nvalidated by comparing step-by-step outputs with its official implementation.\n(2) MASLab provides a unified environment with various benchmarks for fair\ncomparisons among methods, ensuring consistent inputs and standardized\nevaluation protocols. (3) MASLab implements methods within a shared streamlined\nstructure, lowering the barriers for understanding and extension. Building on\nMASLab, we conduct extensive experiments covering 10+ benchmarks and 8 models,\noffering researchers a clear and comprehensive view of the current landscape of\nMAS methods. MASLab will continue to evolve, tracking the latest developments\nin the field, and invite contributions from the broader open-source community.",
    "pdf_url": "http://arxiv.org/pdf/2505.16988v1",
    "published": "2025-05-22T17:54:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16987v2",
    "title": "Slow convergence of ergodic averages for actions of amenable groups",
    "authors": [
      "Valery V. Ryzhikov"
    ],
    "abstract": "We show slow convergence of weighted ergodic averages for flows and actions\nof countable amenable groups.",
    "pdf_url": "http://arxiv.org/pdf/2505.16987v2",
    "published": "2025-05-22T17:54:36+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16986v1",
    "title": "T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning",
    "authors": [
      "Amartya Chakraborty",
      "Paresh Dashore",
      "Nadia Bathaee",
      "Anmol Jain",
      "Anirban Das",
      "Shi-Xiong Zhang",
      "Sambit Sahu",
      "Milind Naphade",
      "Genta Indra Winata"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities as\nintelligent agents capable of solving complex problems. However, effective\nplanning in scenarios involving dependencies between API or tool\ncalls-particularly in multi-turn conversations-remains a significant challenge.\nTo address this, we introduce T1, a tool-augmented, multi-domain, multi-turn\nconversational dataset specifically designed to capture and manage inter-tool\ndependencies across diverse domains. T1 enables rigorous evaluation of agents'\nability to coordinate tool use across nine distinct domains (4 single domain\nand 5 multi-domain) with the help of an integrated caching mechanism for both\nshort- and long-term memory, while supporting dynamic replanning-such as\ndeciding whether to recompute or reuse cached results. Beyond facilitating\nresearch on tool use and planning, T1 also serves as a benchmark for evaluating\nthe performance of open-source language models. We present results powered by\nT1-Agent, highlighting their ability to plan and reason in complex,\ntool-dependent scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16986v1",
    "published": "2025-05-22T17:54:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16985v1",
    "title": "Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation",
    "authors": [
      "Moru Liu",
      "Hao Dong",
      "Jessica Kelly",
      "Olga Fink",
      "Mario Trapp"
    ],
    "abstract": "Out-of-distribution (OOD) detection and segmentation are crucial for\ndeploying machine learning models in safety-critical applications such as\nautonomous driving and robot-assisted surgery. While prior research has\nprimarily focused on unimodal image data, real-world applications are\ninherently multimodal, requiring the integration of multiple modalities for\nimproved OOD detection. A key challenge is the lack of supervision signals from\nunknown data, leading to overconfident predictions on OOD samples. To address\nthis challenge, we propose Feature Mixing, an extremely simple and fast method\nfor multimodal outlier synthesis with theoretical support, which can be further\noptimized to help the model better distinguish between in-distribution (ID) and\nOOD data. Feature Mixing is modality-agnostic and applicable to various\nmodality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal\ndataset for OOD segmentation, featuring synthetic OOD objects across diverse\nscenes and weather conditions. Extensive experiments on SemanticKITTI,\nnuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that\nFeature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370\n\\times$ speedup. Our source code and dataset will be available at\nhttps://github.com/mona4399/FeatureMixing.",
    "pdf_url": "http://arxiv.org/pdf/2505.16985v1",
    "published": "2025-05-22T17:54:30+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16984v1",
    "title": "UFT: Unifying Supervised and Reinforcement Fine-Tuning",
    "authors": [
      "Mingyang Liu",
      "Gabriele Farina",
      "Asuman Ozdaglar"
    ],
    "abstract": "Post-training has demonstrated its importance in enhancing the reasoning\ncapabilities of large language models (LLMs). The primary post-training methods\ncan be categorized into supervised fine-tuning (SFT) and reinforcement\nfine-tuning (RFT). SFT is efficient and well-suited for small language models,\nbut it may lead to overfitting and limit the reasoning abilities of larger\nmodels. In contrast, RFT generally yields better generalization but depends\nheavily on the strength of the base model. To address the limitations of SFT\nand RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm\nthat unifies SFT and RFT into a single, integrated process. UFT enables the\nmodel to effectively explore solutions while incorporating informative\nsupervision signals, bridging the gap between memorizing and thinking\nunderlying existing methods. Notably, UFT outperforms both SFT and RFT in\ngeneral, regardless of model sizes. Furthermore, we theoretically prove that\nUFT breaks RFT's inherent exponential sample complexity bottleneck, showing for\nthe first time that unified training can exponentially accelerate convergence\non long-horizon reasoning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16984v1",
    "published": "2025-05-22T17:53:57+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16983v2",
    "title": "LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding",
    "authors": [
      "Junlong Tong",
      "Jinlan Fu",
      "Zixuan Lin",
      "Yingqi Fan",
      "Anhao Zhao",
      "Hui Su",
      "Xiaoyu Shen"
    ],
    "abstract": "Large Language Models (LLMs) are primarily designed for batch processing.\nExisting methods for adapting LLMs to streaming rely either on expensive\nre-encoding or specialized architectures with limited scalability. This work\nidentifies three key mismatches in adapting batch-oriented LLMs to streaming:\n(1) input-attention, (2) output-attention, and (3) position-ID mismatches.\nWhile it is commonly assumed that the latter two mismatches require frequent\nre-encoding, our analysis reveals that only the input-attention mismatch\nsignificantly impacts performance, indicating re-encoding outputs is largely\nunnecessary. To better understand this discrepancy with the common assumption,\nwe provide the first comprehensive analysis of the impact of position encoding\non LLMs in streaming, showing that preserving relative positions within source\nand target contexts is more critical than maintaining absolute order. Motivated\nby the above analysis, we introduce a group position encoding paradigm built on\nbatch architectures to enhance consistency between streaming and batch modes.\nExtensive experiments on cross-lingual and cross-modal tasks demonstrate that\nour method outperforms existing approaches. Our method requires no\narchitectural modifications, exhibits strong generalization in both streaming\nand batch modes. The code is available at repository\nhttps://github.com/EIT-NLP/StreamingLLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.16983v2",
    "published": "2025-05-22T17:53:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16982v1",
    "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine",
    "authors": [
      "Adib Bazgir",
      "Amir Habibdoust Lafmajani",
      "Yuwen Zhang"
    ],
    "abstract": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.",
    "pdf_url": "http://arxiv.org/pdf/2505.16982v1",
    "published": "2025-05-22T17:52:59+00:00",
    "categories": [
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17171v1",
    "title": "On the entropy of the massive conformal gravity universe",
    "authors": [
      "F. F. Faria"
    ],
    "abstract": "We find that the total entropy of the massive conformal gravity universe is\nan increasing function of time, and therefore the cosmological model of the\ntheory passes the generalized second law of thermodynamics test.",
    "pdf_url": "http://arxiv.org/pdf/2505.17171v1",
    "published": "2025-05-22T17:52:53+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16981v1",
    "title": "DarkNESS: A skipper-CCD NanoSatellite for Dark Matter Searches",
    "authors": [
      "Phoenix Alpine",
      "Samriddhi Bhatia",
      "Ana M. Botti",
      "Brenda A. Cervantes-Vergara",
      "Claudio R. Chavez",
      "Fernando Chierchie",
      "Alex Drlica-Wagner",
      "Rouven Essig",
      "Juan Estrada",
      "Erez Etzion",
      "Roni Harnik",
      "Terry Kim",
      "Michael Lembeck",
      "Qi Lim",
      "Bernard J. Rauscher",
      "Nathan Saffold",
      "Javier Tiffenberg",
      "Sho Uemura",
      "Hailin Xu"
    ],
    "abstract": "The Dark matter Nanosatellite Equipped with Skipper Sensors (DarkNESS)\ndeploys a recently developed skipper-CCD architecture with sub-electron readout\nnoise in low Earth orbit (LEO) to investigate potential signatures of dark\nmatter (DM). The mission addresses two interaction channels: electron recoils\nfrom strongly interacting sub-GeV DM and X-rays produced through decaying DM.\nOrbital observations avoid attenuation that limits ground-based measurements,\nextending sensitivity reach for both channels. The mission proceeds toward\nlaunch following laboratory validation of the instrument. A launch opportunity\nhas been secured through Firefly Aerospace's DREAM 2.0 program, awarded to the\nUniversity of Illinois Urbana-Champaign (UIUC). This will constitute the first\nuse of skipper-CCDs in space and evaluate their suitability for low-noise X-ray\nand single-photon detection in future space observatories.",
    "pdf_url": "http://arxiv.org/pdf/2505.16981v1",
    "published": "2025-05-22T17:52:52+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16980v1",
    "title": "Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction",
    "authors": [
      "Dong Li",
      "Wenqi Zhong",
      "Wei Yu",
      "Yingwei Pan",
      "Dingwen Zhang",
      "Ting Yao",
      "Junwei Han",
      "Tao Mei"
    ],
    "abstract": "Video virtual try-on aims to seamlessly dress a subject in a video with a\nspecific garment. The primary challenge involves preserving the visual\nauthenticity of the garment while dynamically adapting to the pose and physique\nof the subject. While existing methods have predominantly focused on\nimage-based virtual try-on, extending these techniques directly to videos often\nresults in temporal inconsistencies. Most current video virtual try-on\napproaches alleviate this challenge by incorporating temporal modules, yet\nstill overlook the critical spatiotemporal pose interactions between human and\ngarment. Effective pose interactions in videos should not only consider spatial\nalignment between human and garment poses in each frame but also account for\nthe temporal dynamics of human poses throughout the entire video. With such\nmotivation, we propose a new framework, namely Dynamic Pose Interaction\nDiffusion Models (DPIDM), to leverage diffusion models to delve into dynamic\npose interactions for video virtual try-on. Technically, DPIDM introduces a\nskeleton-based pose adapter to integrate synchronized human and garment poses\ninto the denoising network. A hierarchical attention module is then exquisitely\ndesigned to model intra-frame human-garment pose interactions and long-term\nhuman pose dynamics across frames through pose-aware spatial and temporal\nattention mechanisms. Moreover, DPIDM capitalizes on a temporal regularized\nattention loss between consecutive frames to enhance temporal consistency.\nExtensive experiments conducted on VITON-HD, VVT and ViViD datasets demonstrate\nthe superiority of our DPIDM against the baseline methods. Notably, DPIDM\nachieves VFID score of 0.506 on VVT dataset, leading to 60.5% improvement over\nthe state-of-the-art GPD-VVTO approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.16980v1",
    "published": "2025-05-22T17:52:34+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16979v1",
    "title": "Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design",
    "authors": [
      "Zhenkun Li",
      "Lingyao Li",
      "Shuhang Lin",
      "Yongfeng Zhang"
    ],
    "abstract": "Single-agent LLMs hit hard limits--finite context, role overload, and brittle\ndomain transfer. Conventional multi-agent fixes soften those edges yet expose\nfresh pains: ill-posed decompositions, fuzzy contracts, and verification\noverhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a\nframework that converts domain priors into an algorithmic blueprint hierarchy,\nin which tasks are recursively split into typed, controller-mediated subtasks,\neach solved zero-shot or with the lightest viable boost (e.g.,\nchain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch\ntheorem, KtR trades the chase for a universal prompt for disciplined\ndecomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents\nraise accuracy from 3% zero-shot to 95% on size-5 instances after patching a\nsingle bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a\nsix-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,\nversus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation\nthus turns modest models into reliable collaborators--no ever-larger monoliths\nrequired.",
    "pdf_url": "http://arxiv.org/pdf/2505.16979v1",
    "published": "2025-05-22T17:52:33+00:00",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16978v2",
    "title": "HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation",
    "authors": [
      "Weizhi Tang",
      "Yixuan Li",
      "Chris Sypherd",
      "Elizabeth Polgreen",
      "Vaishak Belle"
    ],
    "abstract": "Grammar plays a critical role in natural language processing and text/code\ngeneration by enabling the definition of syntax, the creation of parsers, and\nguiding structured outputs. Although large language models (LLMs) demonstrate\nimpressive capabilities across domains, their ability to infer and generate\ngrammars has not yet been thoroughly explored. In this paper, we aim to study\nand improve the ability of LLMs for few-shot grammar generation, where grammars\nare inferred from sets of a small number of positive and negative examples and\ngenerated in Backus-Naur Form. To explore this, we introduced a novel dataset\ncomprising 540 structured grammar generation challenges, devised 6 metrics, and\nevaluated 8 various LLMs against it. Our findings reveal that existing LLMs\nperform sub-optimally in grammar generation. To address this, we propose an\nLLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar\ngeneration. HyGenar achieves substantial improvements in both the syntactic and\nsemantic correctness of generated grammars across LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16978v2",
    "published": "2025-05-22T17:52:31+00:00",
    "categories": [
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16977v1",
    "title": "Incorporating Visual Correspondence into Diffusion Model for Virtual Try-On",
    "authors": [
      "Siqi Wan",
      "Jingwen Chen",
      "Yingwei Pan",
      "Ting Yao",
      "Tao Mei"
    ],
    "abstract": "Diffusion models have shown preliminary success in virtual try-on (VTON)\ntask. The typical dual-branch architecture comprises two UNets for implicit\ngarment deformation and synthesized image generation respectively, and has\nemerged as the recipe for VTON task. Nevertheless, the problem remains\nchallenging to preserve the shape and every detail of the given garment due to\nthe intrinsic stochasticity of diffusion model. To alleviate this issue, we\nnovelly propose to explicitly capitalize on visual correspondence as the prior\nto tame diffusion process instead of simply feeding the whole garment into UNet\nas the appearance reference. Specifically, we interpret the fine-grained\nappearance and texture details as a set of structured semantic points, and\nmatch the semantic points rooted in garment to the ones over target person\nthrough local flow warping. Such 2D points are then augmented into 3D-aware\ncues with depth/normal map of target person. The correspondence mimics the way\nof putting clothing on human body and the 3D-aware cues act as semantic point\nmatching to supervise diffusion model training. A point-focused diffusion loss\nis further devised to fully take the advantage of semantic point matching.\nExtensive experiments demonstrate strong garment detail preservation of our\napproach, evidenced by state-of-the-art VTON performances on both VITON-HD and\nDressCode datasets. Code is publicly available at:\nhttps://github.com/HiDream-ai/SPM-Diff.",
    "pdf_url": "http://arxiv.org/pdf/2505.16977v1",
    "published": "2025-05-22T17:52:13+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16976v1",
    "title": "Creatively Upscaling Images with Global-Regional Priors",
    "authors": [
      "Yurui Qian",
      "Qi Cai",
      "Yingwei Pan",
      "Ting Yao",
      "Tao Mei"
    ],
    "abstract": "Contemporary diffusion models show remarkable capability in text-to-image\ngeneration, while still being limited to restricted resolutions (e.g., 1,024 X\n1,024). Recent advances enable tuning-free higher-resolution image generation\nby recycling pre-trained diffusion models and extending them via regional\ndenoising or dilated sampling/convolutions. However, these models struggle to\nsimultaneously preserve global semantic structure and produce creative regional\ndetails in higher-resolution images. To address this, we present C-Upscale, a\nnew recipe of tuning-free image upscaling that pivots on global-regional priors\nderived from given global prompt and estimated regional prompts via Multimodal\nLLM. Technically, the low-frequency component of low-resolution image is\nrecognized as global structure prior to encourage global semantic consistency\nin high-resolution generation. Next, we perform regional attention control to\nscreen cross-attention between global prompt and each region during regional\ndenoising, leading to regional attention prior that alleviates object\nrepetition issue. The estimated regional prompts containing rich descriptive\ndetails further act as regional semantic prior to fuel the creativity of\nregional detail generation. Both quantitative and qualitative evaluations\ndemonstrate that our C-Upscale manages to generate ultra-high-resolution images\n(e.g., 4,096 X 4,096 and 8,192 X 8,192) with higher visual fidelity and more\ncreative regional details.",
    "pdf_url": "http://arxiv.org/pdf/2505.16976v1",
    "published": "2025-05-22T17:51:50+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16975v2",
    "title": "SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development",
    "authors": [
      "Yaxin Du",
      "Yuzhu Cai",
      "Yifan Zhou",
      "Cheng Wang",
      "Yu Qian",
      "Xianghe Pang",
      "Qian Liu",
      "Yue Hu",
      "Siheng Chen"
    ],
    "abstract": "Large Language Models (LLMs) have shown strong capability in diverse software\nengineering tasks, e.g. code completion, bug fixing, and document generation.\nHowever, feature-driven development (FDD), a highly prevalent real-world task\nthat involves developing new functionalities for large, existing codebases,\nremains underexplored. We therefore introduce SWE-Dev, the first large-scale\ndataset (with 14,000 training and 500 test samples) designed to evaluate and\ntrain autonomous coding systems on real-world feature development tasks. To\nensure verifiable and diverse training, SWE-Dev uniquely provides all instances\nwith a runnable environment and its developer-authored executable unit tests.\nThis collection not only provides high-quality data for Supervised Fine-Tuning\n(SFT), but also enables Reinforcement Learning (RL) by delivering accurate\nreward signals from executable unit tests. Our extensive evaluations on\nSWE-Dev, covering 17 chatbot LLMs, 10 reasoning models, and 10 Multi-Agent\nSystems (MAS), reveal that FDD is a profoundly challenging frontier for current\nAI (e.g., Claude-3.7-Sonnet achieves only 22.45\\% Pass@3 on the hard test\nsplit). Crucially, we demonstrate that SWE-Dev serves as an effective platform\nfor model improvement: fine-tuning on training set enabled a 7B model\ncomparable to GPT-4o on \\textit{hard} split, underscoring the value of its\nhigh-quality training data. Code is available here\n\\href{https://github.com/DorothyDUUU/SWE-Dev}{https://github.com/DorothyDUUU/SWE-Dev}.",
    "pdf_url": "http://arxiv.org/pdf/2505.16975v2",
    "published": "2025-05-22T17:51:49+00:00",
    "categories": [
      "cs.SE",
      "cs.CL"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16974v2",
    "title": "OpenSeg-R: Improving Open-Vocabulary Segmentation via Step-by-Step Visual Reasoning",
    "authors": [
      "Zongyan Han",
      "Jiale Cao",
      "Shuo Chen",
      "Tong Wang",
      "Jorma Laaksonen",
      "Rao Muhammad Anwer"
    ],
    "abstract": "Open-Vocabulary Segmentation (OVS) has drawn increasing attention for its\ncapacity to generalize segmentation beyond predefined categories. However,\nexisting methods typically predict segmentation masks with simple forward\ninference, lacking explicit reasoning and interpretability. This makes it\nchallenging for OVS model to distinguish similar categories in open-world\nsettings due to the lack of contextual understanding and discriminative visual\ncues. To address this limitation, we propose a step-by-step visual reasoning\nframework for open-vocabulary segmentation, named OpenSeg-R. The proposed\nOpenSeg-R leverages Large Multimodal Models (LMMs) to perform hierarchical\nvisual reasoning before segmentation. Specifically, we generate both generic\nand image-specific reasoning for each image, forming structured triplets that\nexplain the visual reason for objects in a coarse-to-fine manner. Based on\nthese reasoning steps, we can compose detailed description prompts, and feed\nthem to the segmentor to produce more accurate segmentation masks. To the best\nof our knowledge, OpenSeg-R is the first framework to introduce explicit\nstep-by-step visual reasoning into OVS. Experimental results demonstrate that\nOpenSeg-R significantly outperforms state-of-the-art methods on open-vocabulary\nsemantic segmentation across five benchmark datasets. Moreover, it achieves\nconsistent gains across all metrics on open-vocabulary panoptic segmentation.\nQualitative results further highlight the effectiveness of our reasoning-guided\nframework in improving both segmentation precision and interpretability. Our\ncode is publicly available at https://github.com/Hanzy1996/OpenSeg-R.",
    "pdf_url": "http://arxiv.org/pdf/2505.16974v2",
    "published": "2025-05-22T17:51:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16973v2",
    "title": "VeriFastScore: Speeding up long-form factuality evaluation",
    "authors": [
      "Rishanth Rajendhran",
      "Amir Zadeh",
      "Matthew Sarte",
      "Chuan Li",
      "Mohit Iyyer"
    ],
    "abstract": "Metrics like FactScore and VeriScore that evaluate long-form factuality\noperate by decomposing an input response into atomic claims and then\nindividually verifying each claim. While effective and interpretable, these\nmethods incur numerous LLM calls and can take upwards of 100 seconds to\nevaluate a single response, limiting their practicality in large-scale\nevaluation and training scenarios. To address this, we propose VeriFastScore,\nwhich leverages synthetic data to fine-tune Llama3.1 8B for simultaneously\nextracting and verifying all verifiable claims within a given text based on\nevidence from Google Search. We show that this task cannot be solved via\nfew-shot prompting with closed LLMs due to its complexity: the model receives\n~4K tokens of evidence on average and needs to concurrently decompose claims,\njudge their verifiability, and verify them against noisy evidence. However, our\nfine-tuned VeriFastScore model demonstrates strong correlation with the\noriginal VeriScore pipeline at both the example level (r=0.80) and system level\n(r=0.94) while achieving an overall speedup of 6.6x (9.9x excluding evidence\nretrieval) over VeriScore. To facilitate future factuality research, we\npublicly release our VeriFastScore model and synthetic datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.16973v2",
    "published": "2025-05-22T17:51:25+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16972v1",
    "title": "From Tens of Hours to Tens of Thousands: Scaling Back-Translation for Speech Recognition",
    "authors": [
      "Tianduo Wang",
      "Lu Xu",
      "Wei Lu",
      "Shanbo Cheng"
    ],
    "abstract": "Recent advances in Automatic Speech Recognition (ASR) have been largely\nfueled by massive speech corpora. However, extending coverage to diverse\nlanguages with limited resources remains a formidable challenge. This paper\nintroduces Speech Back-Translation, a scalable pipeline that improves\nmultilingual ASR models by converting large-scale text corpora into synthetic\nspeech via off-the-shelf text-to-speech (TTS) models. We demonstrate that just\ntens of hours of real transcribed speech can effectively train TTS models to\ngenerate synthetic speech at hundreds of times the original volume while\nmaintaining high quality. To evaluate synthetic speech quality, we develop an\nintelligibility-based assessment framework and establish clear thresholds for\nwhen synthetic data benefits ASR training. Using Speech Back-Translation, we\ngenerate more than 500,000 hours of synthetic speech in ten languages and\ncontinue pre-training Whisper-large-v3, achieving average transcription error\nreductions of over 30\\%. These results highlight the scalability and\neffectiveness of Speech Back-Translation for enhancing multilingual ASR\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16972v1",
    "published": "2025-05-22T17:51:05+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16971v1",
    "title": "UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation",
    "authors": [
      "Himangi Mittal",
      "Peiye Zhuang",
      "Hsin-Ying Lee",
      "Shubham Tulsiani"
    ],
    "abstract": "We propose UniPhy, a common latent-conditioned neural constitutive model that\ncan encode the physical properties of diverse materials. At inference UniPhy\nallows `inverse simulation' i.e. inferring material properties by optimizing\nthe scene-specific latent to match the available observations via\ndifferentiable simulation. In contrast to existing methods that treat such\ninference as system identification, UniPhy does not rely on user-specified\nmaterial type information. Compared to prior neural constitutive modeling\napproaches which learn instance specific networks, the shared training across\nmaterials improves both, robustness and accuracy of the estimates. We train\nUniPhy using simulated trajectories across diverse geometries and materials --\nelastic, plasticine, sand, and fluids (Newtonian & non-Newtonian). At\ninference, given an object with unknown material properties, UniPhy can infer\nthe material properties via latent optimization to match the motion\nobservations, and can then allow re-simulating the object under diverse\nscenarios. We compare UniPhy against prior inverse simulation methods, and show\nthat the inference from UniPhy enables more accurate replay and re-simulation\nunder novel conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16971v1",
    "published": "2025-05-22T17:50:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16970v1",
    "title": "Horospherically Convex Optimization on Hadamard Manifolds Part I: Analysis and Algorithms",
    "authors": [
      "Christopher Criscitiello",
      "Jungbin Kim"
    ],
    "abstract": "Geodesic convexity (g-convexity) is a natural generalization of convexity to\nRiemannian manifolds. However, g-convexity lacks many desirable properties\nsatisfied by Euclidean convexity. For instance, the natural notions of\nhalf-spaces and affine functions are themselves not g-convex. Moreover, recent\nstudies have shown that the oracle complexity of geodesically convex\noptimization necessarily depends on the curvature of the manifold (Criscitiello\nand Boumal, 2022; Criscitiello and Boumal, 2023; Hamilton and Moitra, 2021), a\ncomputational bottleneck for several problems, e.g., tensor scaling. Recently,\nLewis et al. (2024) addressed this challenge by proving curvature-independent\nconvergence of subgradient descent, assuming horospherical convexity of the\nobjective's sublevel sets. Using a similar idea, we introduce a generalization\nof convex functions to Hadamard manifolds, utilizing horoballs and Busemann\nfunctions as building blocks (as proxies for half-spaces and affine functions).\nWe refer to this new notion as horospherical convexity (h-convexity). We\nprovide algorithms for both nonsmooth and smooth h-convex optimization, which\nhave curvature-independent guarantees exactly matching those from Euclidean\nspace; this includes generalizations of subgradient descent and Nesterov's\naccelerated method. Motivated by applications, we extend these algorithms and\ntheir convergence rates to minimizing a sum of horospherically convex\nfunctions, assuming access to a weighted-Fr\\'echet-mean oracle.",
    "pdf_url": "http://arxiv.org/pdf/2505.16970v1",
    "published": "2025-05-22T17:50:10+00:00",
    "categories": [
      "math.OC",
      "cs.NA",
      "math.DG",
      "math.NA"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16969v2",
    "title": "3D Equivariant Visuomotor Policy Learning via Spherical Projection",
    "authors": [
      "Boce Hu",
      "Dian Wang",
      "David Klee",
      "Heng Tian",
      "Xupeng Zhu",
      "Haojie Huang",
      "Robert Platt",
      "Robin Walters"
    ],
    "abstract": "Equivariant models have recently been shown to improve the data efficiency of\ndiffusion policy by a significant margin. However, prior work that explored\nthis direction focused primarily on point cloud inputs generated by multiple\ncameras fixed in the workspace. This type of point cloud input is not\ncompatible with the now-common setting where the primary input modality is an\neye-in-hand RGB camera like a GoPro. This paper closes this gap by\nincorporating into the diffusion policy model a process that projects features\nfrom the 2D RGB camera image onto a sphere. This enables us to reason about\nsymmetries in SO(3) without explicitly reconstructing a point cloud. We perform\nextensive experiments in both simulation and the real world that demonstrate\nthat our method consistently outperforms strong baselines in terms of both\nperformance and sample efficiency. Our work is the first SO(3)-equivariant\npolicy learning framework for robotic manipulation that works using only\nmonocular RGB inputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16969v2",
    "published": "2025-05-22T17:49:10+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16968v3",
    "title": "CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark",
    "authors": [
      "Ahmed Heakl",
      "Sarim Hashmi",
      "Gustavo Bertolo Stahl",
      "Seung Hun Eddie Han",
      "Salman Khan",
      "Abdulrahman Mahmoud"
    ],
    "abstract": "We introduce CASS, the first large-scale dataset and model suite for\ncross-architecture GPU code transpilation, targeting both source-level (CUDA\n<--> HIP) and assembly-level (Nvidia SASS <--> AMD RDNA3) translation. The\ndataset comprises 70k verified code pairs across host and device, addressing a\ncritical gap in low-level GPU code portability. Leveraging this resource, we\ntrain the CASS family of domain-specific language models, achieving 95% source\ntranslation accuracy and 37.5% assembly translation accuracy, substantially\noutperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our\ngenerated code matches native performance in over 85% of test cases, preserving\nruntime and memory behavior. To support rigorous evaluation, we introduce\nCASS-Bench, a curated benchmark spanning 16 GPU domains with ground-truth\nexecution. All data, models, and evaluation tools are released as open source\nto foster progress in GPU compiler tooling, binary compatibility, and\nLLM-guided hardware translation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16968v3",
    "published": "2025-05-22T17:48:53+00:00",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17170v1",
    "title": "Simulating Time Dependent and Nonlinear Classical Oscillators through Nonlinear Schrödingerization",
    "authors": [
      "Abhinav Muraleedharan",
      "Nathan Wiebe"
    ],
    "abstract": "We present quantum algorithms for simulating the dynamics of a broad class of\nclassical oscillator systems containing $2^n$ coupled oscillators (Eg: $2^n$\nmasses coupled by springs), including those with time-dependent forces,\ntime-varying stiffness matrices, and weak nonlinear interactions. This\ngeneralization of the Harmonic oscillator simulation algorithm is achieved\nthrough an approach that we call ``Nonlinear Schr\\\"{o}dingerization'', which\ninvolves reduction of the dynamical system to a nonlinear Schr\\\"{o}dinger\nequation and then reduced to a time-independent Schrodinger Equation through\nperturbative techniques. The linearization of the equation is performed using\nan approach that allows the dynamics of a nonlinear Schr\\\"odinger equation to\nbe approximated as a linear Schr\\\"odinger equation in a higher dimensional\nspace. This allows Hamiltonian Simulation algorithms to be applied to simulate\nthe dynamics of resulting system. When the properties of the classical\ndynamical systems can be efficiently queried, and when the initial state can be\nefficiently prepared, the complexity of our quantum algorithm is polynomial in\n$n$, and almost linear in evolution time for most dynamical systems. Our work\nextends the applicability of quantum algorithms to simulate the dynamics of\nnon-conservative and nonlinear classical systems, addressing key limitations in\nprevious approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.17170v1",
    "published": "2025-05-22T17:48:42+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16967v1",
    "title": "Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval",
    "authors": [
      "Nandan Thakur",
      "Crystina Zhang",
      "Xueguang Ma",
      "Jimmy Lin"
    ],
    "abstract": "Training robust retrieval and reranker models typically relies on large-scale\nretrieval datasets; for example, the BGE collection contains 1.6 million\nquery-passage pairs sourced from various data sources. However, we find that\ncertain datasets can negatively impact model effectiveness -- pruning 8 out of\n15 datasets from the BGE collection reduces the training set size by\n2.35$\\times$ and increases nDCG@10 on BEIR by 1.0 point. This motivates a\ndeeper examination of training data quality, with a particular focus on \"false\nnegatives\", where relevant passages are incorrectly labeled as irrelevant. We\npropose a simple, cost-effective approach using cascading LLM prompts to\nidentify and relabel hard negatives. Experimental results show that relabeling\nfalse negatives with true positives improves both E5 (base) and Qwen2.5-7B\nretrieval models by 0.7-1.4 nDCG@10 on BEIR and by 1.7-1.8 nDCG@10 on zero-shot\nAIR-Bench evaluation. Similar gains are observed for rerankers fine-tuned on\nthe relabeled data, such as Qwen2.5-3B on BEIR. The reliability of the\ncascading design is further supported by human annotation results, where we\nfind judgment by GPT-4o shows much higher agreement with humans than\nGPT-4o-mini.",
    "pdf_url": "http://arxiv.org/pdf/2505.16967v1",
    "published": "2025-05-22T17:47:57+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16966v1",
    "title": "Modeling Inequality in Complex Networks of Strategic Agents using Iterative Game-Theoretic Transactions",
    "authors": [
      "Mayank Kejriwal",
      "Yuesheng Luo"
    ],
    "abstract": "Transactions are an important aspect of human social life, and represent\ndynamic flow of information, intangible values, such as trust, as well as\nmonetary and social capital. Although much research has been conducted on the\nnature of transactions in fields ranging from the social sciences to game\ntheory, the systemic effects of different types of agents transacting in\nreal-world social networks (often following a scale-free distribution) are not\nfully understood. A particular systemic measure that has not received adequate\nattention in the complex networks and game theory communities, is the Gini\nCoefficient, which is widely used in economics to quantify and understand\nwealth inequality. In part, the problem is a lack of experimentation using a\nreplicable algorithm and publicly available data. Motivated by this problem,\nthis article proposes a model and simulation algorithm, based on game theory,\nfor quantifying the evolution of inequality in complex networks of strategic\nagents. Our results shed light on several complex drivers of inequality, even\nin simple, abstract settings, and exhibit consistency across networks with\ndifferent origins and descriptions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16966v1",
    "published": "2025-05-22T17:47:08+00:00",
    "categories": [
      "cs.GT",
      "cs.SI"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16965v1",
    "title": "BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation",
    "authors": [
      "Fengyi Li",
      "Kayhan Behdin",
      "Natesh Pillai",
      "Xiaofeng Wang",
      "Zhipeng Wang",
      "Ercan Yildiz"
    ],
    "abstract": "Text segmentation based on the semantic meaning of sentences is a fundamental\ntask with broad utility in many downstream applications. In this paper, we\npropose a graphical model-based unsupervised learning approach, named BP-Seg\nfor efficient text segmentation. Our method not only considers local coherence,\ncapturing the intuition that adjacent sentences are often more related, but\nalso effectively groups sentences that are distant in the text yet semantically\nsimilar. This is achieved through belief propagation on the carefully\nconstructed graphical models. Experimental results on both an illustrative\nexample and a dataset with long-form documents demonstrate that our method\nperforms favorably compared to competing approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.16965v1",
    "published": "2025-05-22T17:46:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16964v1",
    "title": "MedFrameQA: A Multi-Image Medical VQA Benchmark for Clinical Reasoning",
    "authors": [
      "Suhao Yu",
      "Haojin Wang",
      "Juncheng Wu",
      "Cihang Xie",
      "Yuyin Zhou"
    ],
    "abstract": "Existing medical VQA benchmarks mostly focus on single-image analysis, yet\nclinicians almost always compare a series of images before reaching a\ndiagnosis. To better approximate this workflow, we introduce MedFrameQA -- the\nfirst benchmark that explicitly evaluates multi-image reasoning in medical VQA.\nTo build MedFrameQA both at scale and in high-quality, we develop 1) an\nautomated pipeline that extracts temporally coherent frames from medical videos\nand constructs VQA items whose content evolves logically across images, and 2)\na multiple-stage filtering strategy, including model-based and manual review,\nto preserve data clarity, difficulty, and medical relevance. The resulting\ndataset comprises 2,851 VQA pairs (gathered from 9,237 high-quality frames in\n3,420 videos), covering nine human body systems and 43 organs; every question\nis accompanied by two to five images. We comprehensively benchmark ten advanced\nMultimodal LLMs -- both proprietary and open source, with and without explicit\nreasoning modules -- on MedFrameQA. The evaluation challengingly reveals that\nall models perform poorly, with most accuracies below 50%, and accuracy\nfluctuates as the number of images per question increases. Error analysis\nfurther shows that models frequently ignore salient findings, mis-aggregate\nevidence across images, and propagate early mistakes through their reasoning\nchains; results also vary substantially across body systems, organs, and\nmodalities. We hope this work can catalyze research on clinically grounded,\nmulti-image reasoning and accelerate progress toward more capable diagnostic AI\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16964v1",
    "published": "2025-05-22T17:46:11+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16963v1",
    "title": "A Formal Proof of Complexity Bounds on Diophantine Equations",
    "authors": [
      "Jonas Bayer",
      "Marco David"
    ],
    "abstract": "We present a universal construction of Diophantine equations with bounded\ncomplexity in Isabelle/HOL. This is a formalization of our own work in number\ntheory.\n  Hilbert's Tenth Problem was answered negatively by Yuri Matiyasevich, who\nshowed that there is no general algorithm to decide whether an arbitrary\nDiophantine equation has a solution. However, the problem remains open when\ngeneralized to the field of rational numbers, or contrarily, when restricted to\nDiophantine equations with bounded complexity, characterized by the number of\nvariables $\\nu$ and the degree $\\delta$. If every Diophantine set can be\nrepresented within the bounds $(\\nu, \\delta)$, we say that this pair is\nuniversal, and it follows that the corresponding class of equations is\nundecidable. In a separate mathematics article, we have determined the first\nnon-trivial universal pair for the case of integer unknowns.\n  In this paper, we contribute a formal verification of the main construction\nrequired to establish said universal pair. In doing so, we markedly extend the\nIsabelle AFP entry on multivariate polynomials, formalize parts of a number\ntheory textbook, and develop classical theory on Diophantine equations in\nIsabelle. Additionally, our work includes metaprogramming infrastructure\ndesigned to efficiently handle complex definitions of multivariate polynomials.\nOur mathematical draft has been formalized while the mathematical research was\nongoing, and benefitted largely from the help of the theorem prover. We reflect\nhow the close collaboration between mathematician and computer is an uncommon\nbut promising modus operandi.",
    "pdf_url": "http://arxiv.org/pdf/2505.16963v1",
    "published": "2025-05-22T17:45:33+00:00",
    "categories": [
      "cs.LO",
      "math.NT"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16962v1",
    "title": "Attached Decelerating Turbulent Boundary Layers over Riblets",
    "authors": [
      "Benjamin S. Savino",
      "Amirreza Rouhi",
      "Wen Wu"
    ],
    "abstract": "Turbulent boundary layers over riblets subjected to adverse pressure\ngradients (APGs) are investigated by direct numerical simulation. Multiple APG\nstrengths and riblet sizes are examined, permitting evaluation of drag\nmodification by riblets, and associated physical mechanisms, in various regimes\nestablished for zero-pressure-gradient (ZPG) riblet flows. The APG strengths\nare selected such that the flow remains attached. It is found that during APGs,\nriblets reduce drag beyond what has been achieved in ZPG flows. In extreme\ncases, an upstream force (i.e., negative drag) is attained. The significant\ndrag reduction is found to be a product of Kelvin-Helmholtz roller vortices\nforming near the riblet crest, which are augmented in size, strength, and\nfrequency during the APG. The preliminary results reported here indicate the\nneed to modify existing metrics to predict drag reduction and the onset of KH\nrollers by riblets when the pressure gradient is non-negligible. Further\nanalysis will be documented in the final paper.",
    "pdf_url": "http://arxiv.org/pdf/2505.16962v1",
    "published": "2025-05-22T17:45:15+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.16961v3",
    "title": "Predicting the outcome of collisional neutrino flavor conversion",
    "authors": [
      "Julien Froustey"
    ],
    "abstract": "Collisional flavor instabilities, driven by differing neutrino and\nantineutrino reaction rates, are expected to occur in dense astrophysical\nenvironments like supernovae and neutron star mergers, but have yet to be\nincorporated in large-scale simulations. We derive analytical expressions for\nthe asymptotic state resulting from a homogeneous and isotropic instability,\nand apply these predictions to two representative conditions from a neutron\nstar merger simulation. We emphasize the importance of using a collision term\nthat allows for both damping of flavor coherence and relaxation back to the\nclassical steady state. When this classical configuration is\ncollisional-unstable, the resulting asymptotic state reflects a compromise\nbetween classical relaxation and flavor conversion, defining a \"quantum\"\nequilibrium with nonzero coherence. This analysis highlights the possibility of\na tradeoff between classical and quantum effects, an important feature with\nregard to the inclusion of flavor oscillation physics into global simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16961v3",
    "published": "2025-05-22T17:44:06+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.HE"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16960v1",
    "title": "Rank one elliptic curves and rank stability",
    "authors": [
      "David Zywina"
    ],
    "abstract": "For any quadratic extension $L/K$ of number fields, we prove that there are\ninfinitely many elliptic curves $E$ over $K$ so that the abelian groups $E(K)$\nand $E(L)$ both have rank $1$. In particular, there are infinitely many\nelliptic curves of rank $1$ over any number field. This result generalizes\ntheorems of Koymans-Pagano and Alp\\\"oge-Bhargava-Ho-Shnidman which were used to\nindependently show that Hilbert's tenth problem over the ring of integers of\nany number field has a negative answer. Our approach differs since we are\nobtaining our elliptic curves by specializing a nonisotrivial rank $1$ family\nof elliptic curves and we compute all the ranks involved.",
    "pdf_url": "http://arxiv.org/pdf/2505.16960v1",
    "published": "2025-05-22T17:43:35+00:00",
    "categories": [
      "math.NT",
      "11G18 Primary) 14J27 (Secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.12030v1",
    "title": "Impact, Causation and Prediction of Socio-Academic and Economic Factors in Exam-centric Student Evaluation Measures using Machine Learning and Causal Analysis",
    "authors": [
      "Md. Biplob Hosen",
      "Sabbir Ahmed",
      "Bushra Akter",
      "Mehrin Anannya"
    ],
    "abstract": "Understanding socio-academic and economic factors influencing students'\nperformance is crucial for effective educational interventions. This study\nemploys several machine learning techniques and causal analysis to predict and\nelucidate the impacts of these factors on academic performance. We constructed\na hypothetical causal graph and collected data from 1,050 student profiles.\nFollowing meticulous data cleaning and visualization, we analyze linear\nrelationships through correlation and variable plots, and perform causal\nanalysis on the hypothetical graph. Regression and classification models are\napplied for prediction, and unsupervised causality analysis using PC, GES,\nICA-LiNGAM, and GRASP algorithms is conducted. Our regression analysis shows\nthat Ridge Regression achieve a Mean Absolute Error (MAE) of 0.12 and a Mean\nSquared Error (MSE) of 0.024, indicating robustness, while classification\nmodels like Random Forest achieve nearly perfect F1-scores. The causal analysis\nshows significant direct and indirect effects of factors such as class\nattendance, study hours, and group study on CGPA. These insights are validated\nthrough unsupervised causality analysis. By integrating the best regression\nmodel into a web application, we are developing a practical tool for students\nand educators to enhance academic outcomes based on empirical evidence.",
    "pdf_url": "http://arxiv.org/pdf/2506.12030v1",
    "published": "2025-05-22T17:41:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16959v2",
    "title": "Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models",
    "authors": [
      "Alessandro Favero",
      "Antonio Sclocchi",
      "Matthieu Wyart"
    ],
    "abstract": "Diffusion probabilistic models have become a cornerstone of modern generative\nAI, yet the mechanisms underlying their generalization remain poorly\nunderstood. In fact, if these models were perfectly minimizing their training\nloss, they would just generate data belonging to their training set, i.e.,\nmemorize, as empirically found in the overparameterized regime. We revisit this\nview by showing that, in highly overparameterized diffusion models,\ngeneralization in natural data domains is progressively achieved during\ntraining before the onset of memorization. Our results, ranging from image to\nlanguage diffusion models, systematically support the empirical law that\nmemorization time is proportional to the dataset size. Generalization vs.\nmemorization is then best understood as a competition between time scales. We\nshow that this phenomenology is recovered in diffusion models learning a simple\nprobabilistic context-free grammar with random rules, where generalization\ncorresponds to the hierarchical acquisition of deeper grammar rules as training\ntime grows, and the generalization cost of early stopping can be characterized.\nWe summarize these results in a phase diagram. Overall, our results support\nthat a principled early-stopping criterion - scaling with dataset size - can\neffectively optimize generalization while avoiding memorization, with direct\nimplications for hyperparameter transfer and privacy-sensitive applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16959v2",
    "published": "2025-05-22T17:40:08+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16958v3",
    "title": "Global hypoellipticity of systems of Fourier multipliers on compact Lie groups",
    "authors": [
      "André Pedroso Kowacs"
    ],
    "abstract": "We apply the characterization of global hypoellipticity for $G$-invariant\noperators on homogeneous vector bundles obtained by Cardona and Kowacs [J.\nPseudo-Differ. Oper. Appl. 16, 23 (2025)] to obtain a necessary and sufficient\ncondition for an arbitrary system of left-invariant operators on a compact Lie\ngroup to be globally hypoelliptic, providing a full proof independent of the\nbundle structure of that paper. We then prove alternative sufficient conditions\nfor globally hypoellipticity for a large class of particular cases of systems\nmaking use of lower bounds for the smallest singular value of complex matrices.",
    "pdf_url": "http://arxiv.org/pdf/2505.16958v3",
    "published": "2025-05-22T17:37:59+00:00",
    "categories": [
      "math.AP",
      "22E30, 43A77, 58J40"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16957v1",
    "title": "Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models",
    "authors": [
      "Junjie Xiong",
      "Changjia Zhu",
      "Shuhang Lin",
      "Chong Zhang",
      "Yongfeng Zhang",
      "Yao Liu",
      "Lingyao Li"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly equipped with capabilities of\nreal-time web search and integrated with protocols like Model Context Protocol\n(MCP). This extension could introduce new security vulnerabilities. We present\na systematic investigation of LLM vulnerabilities to hidden adversarial prompts\nthrough malicious font injection in external resources like webpages, where\nattackers manipulate code-to-glyph mapping to inject deceptive content which\nare invisible to users. We evaluate two critical attack scenarios: (1)\n\"malicious content relay\" and (2) \"sensitive data leakage\" through MCP-enabled\ntools. Our experiments reveal that indirect prompts with injected malicious\nfont can bypass LLM safety mechanisms through external resources, achieving\nvarying success rates based on data sensitivity and prompt design. Our research\nunderscores the urgent need for enhanced security measures in LLM deployments\nwhen processing external content.",
    "pdf_url": "http://arxiv.org/pdf/2505.16957v1",
    "published": "2025-05-22T17:36:33+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16956v1",
    "title": "On Multilingual Encoder Language Model Compression for Low-Resource Languages",
    "authors": [
      "Daniil Gurgurov",
      "Michal Gregor",
      "Josef van Genabith",
      "Simon Ostermann"
    ],
    "abstract": "In this paper, we combine two-step knowledge distillation, structured\npruning, truncation, and vocabulary trimming for extremely compressing\nmultilingual encoder-only language models for low-resource languages. Our novel\napproach systematically combines existing techniques and takes them to the\nextreme, reducing layer depth, feed-forward hidden size, and intermediate layer\nembedding size to create significantly smaller monolingual models while\nretaining essential language-specific knowledge. We achieve compression rates\nof up to 92% with only a marginal performance drop of 2-10% in four downstream\ntasks, including sentiment analysis, topic classification, named entity\nrecognition, and part-of-speech tagging, across three low-resource languages.\nNotably, the performance degradation correlates with the amount of\nlanguage-specific data in the teacher model, with larger datasets resulting in\nsmaller performance losses. Additionally, we conduct extensive ablation studies\nto identify best practices for multilingual model compression using these\ntechniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.16956v1",
    "published": "2025-05-22T17:35:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16955v1",
    "title": "Boundedness criteria for real quivers of rank 3",
    "authors": [
      "Roger Casals",
      "Kenton Ke"
    ],
    "abstract": "We study the boundedness of a mutation class for quivers with real weights.\nThe main result is a characterization of bounded mutation classes for real\nquivers of rank 3.",
    "pdf_url": "http://arxiv.org/pdf/2505.16955v1",
    "published": "2025-05-22T17:35:16+00:00",
    "categories": [
      "math.CO",
      "math.DS",
      "math.RT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16954v1",
    "title": "Cracking Aegis: An Adversarial LLM-based Game for Raising Awareness of Vulnerabilities in Privacy Protection",
    "authors": [
      "Jiaying Fu",
      "Yiyang Lu",
      "Zehua Yang",
      "Fiona Nah",
      "RAY LC"
    ],
    "abstract": "Traditional methods for raising awareness of privacy protection often fail to\nengage users or provide hands-on insights into how privacy vulnerabilities are\nexploited. To address this, we incorporate an adversarial mechanic in the\ndesign of the dialogue-based serious game Cracking Aegis. Leveraging LLMs to\nsimulate natural interactions, the game challenges players to impersonate\ncharacters and extract sensitive information from an AI agent, Aegis. A user\nstudy (n=22) revealed that players employed diverse deceptive linguistic\nstrategies, including storytelling and emotional rapport, to manipulate Aegis.\nAfter playing, players reported connecting in-game scenarios with real-world\nprivacy vulnerabilities, such as phishing and impersonation, and expressed\nintentions to strengthen privacy control, such as avoiding oversharing personal\ninformation with AI systems. This work highlights the potential of LLMs to\nsimulate complex relational interactions in serious games, while demonstrating\nhow an adversarial game strategy provides unique insights for designs for\nsocial good, particularly privacy protection.",
    "pdf_url": "http://arxiv.org/pdf/2505.16954v1",
    "published": "2025-05-22T17:34:45+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16952v1",
    "title": "A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization",
    "authors": [
      "Shengyu Feng",
      "Weiwei Sun",
      "Shanda Li",
      "Ameet Talwalkar",
      "Yiming Yang"
    ],
    "abstract": "Machine learning (ML) has demonstrated considerable potential in supporting\nmodel design and optimization for combinatorial optimization (CO) problems.\nHowever, much of the progress to date has been evaluated on small-scale,\nsynthetic datasets, raising concerns about the practical effectiveness of\nML-based solvers in real-world, large-scale CO scenarios. Additionally, many\nexisting CO benchmarks lack sufficient training data, limiting their utility\nfor evaluating data-driven approaches. To address these limitations, we\nintroduce FrontierCO, a comprehensive benchmark that covers eight canonical CO\nproblem types and evaluates 16 representative ML-based solvers--including graph\nneural networks and large language model (LLM) agents. FrontierCO features\nchallenging instances drawn from industrial applications and frontier CO\nresearch, offering both realistic problem difficulty and abundant training\ndata. Our empirical results provide critical insights into the strengths and\nlimitations of current ML methods, helping to guide more robust and practically\nrelevant advances at the intersection of machine learning and combinatorial\noptimization. Our data is available at\nhttps://huggingface.co/datasets/CO-Bench/FrontierCO.",
    "pdf_url": "http://arxiv.org/pdf/2505.16952v1",
    "published": "2025-05-22T17:34:38+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16953v1",
    "title": "ICYM2I: The illusion of multimodal informativeness under missingness",
    "authors": [
      "Young Sang Choi",
      "Vincent Jeanselme",
      "Pierre Elias",
      "Shalmali Joshi"
    ],
    "abstract": "Multimodal learning is of continued interest in artificial intelligence-based\napplications, motivated by the potential information gain from combining\ndifferent types of data. However, modalities collected and curated during\ndevelopment may differ from the modalities available at deployment due to\nmultiple factors including cost, hardware failure, or -- as we argue in this\nwork -- the perceived informativeness of a given modality. Na{\\\"i}ve estimation\nof the information gain associated with including an additional modality\nwithout accounting for missingness may result in improper estimates of that\nmodality's value in downstream tasks. Our work formalizes the problem of\nmissingness in multimodal learning and demonstrates the biases resulting from\nignoring this process. To address this issue, we introduce ICYM2I (In Case You\nMultimodal Missed It), a framework for the evaluation of predictive performance\nand information gain under missingness through inverse probability\nweighting-based correction. We demonstrate the importance of the proposed\nadjustment to estimate information gain under missingness on synthetic,\nsemi-synthetic, and real-world medical datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.16953v1",
    "published": "2025-05-22T17:34:38+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16951v1",
    "title": "From Reality to Virtual Worlds: The Role of Photogrammetry in Game Development",
    "authors": [
      "Santiago Berrezueta-Guzman",
      "Andrei Koshelev",
      "Stefan Wagner"
    ],
    "abstract": "Photogrammetry is transforming digital content creation by enabling the rapid\nconversion of real-world objects into highly detailed 3D models. This paper\nevaluates the role of RealityCapture, a GPU-accelerated photogrammetry tool, in\ngame development of Virtual Reality (VR). We assess its efficiency,\nreconstruction accuracy, and integration with Unreal Engine, comparing its\nadvantages and limitations against traditional modeling workflows.\nAdditionally, we examined user preferences between designed 3D assets and\nphotogrammetry-generated models. The results revealed that while photogrammetry\nenhances realism and interactivity, users slightly preferred manually designed\nmodels for small, manipulable elements because of the level of detail. However,\nfrom a developer perspective, RealityCapture significantly reduces development\ntime while maintaining geometric precision and photorealistic textures. Despite\nits reliance on high-performance hardware, its automation, scalability, and\nseamless integration with real-time rendering engines make it a valuable tool\nfor game developers and VR creators. Future improvements in AI-driven\noptimization and cloud-based processing could enhance accessibility, broadening\nits applications in gaming, cultural heritage preservation, and simulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16951v1",
    "published": "2025-05-22T17:33:54+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16950v2",
    "title": "Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning",
    "authors": [
      "Adnan Oomerjee",
      "Zafeirios Fountas",
      "Zhongwei Yu",
      "Haitham Bou-Ammar",
      "Jun Wang"
    ],
    "abstract": "Despite their impressive capabilities, Large Language Models struggle with\ngeneralisation beyond their training distribution, often exhibiting\nsophisticated pattern interpolation rather than true abstract reasoning\n(extrapolation). In this work, we approach this limitation through the lens of\nInformation Bottleneck (IB) theory, which posits that model generalisation\nemerges from an optimal balance between input compression and retention of\npredictive information in latent representations. We prove using IB theory that\ndecoder-only Transformers are inherently constrained in their ability to form\ntask-optimal sequence representations. We then use this result to demonstrate\nthat periodic global transformation of the internal sequence-level\nrepresentations (KV cache) is a necessary computational step for improving\nTransformer generalisation in reasoning tasks. Based on these theoretical\ninsights, we propose a modification to the Transformer architecture, in the\nform of an additional module that globally rewrites the KV cache at periodic\nintervals, shifting its capacity away from memorising input prefixes and toward\nencoding features most useful for predicting future tokens. Our model delivers\nsubstantial gains on mathematical reasoning benchmarks, outperforming both\nvanilla Transformers with up to 3.5x more parameters, as well as\nheuristic-driven pruning mechanisms for cache compression. Our approach can be\nseen as a principled generalisation of existing KV-cache compression methods;\nwhereas such methods focus solely on compressing input representations, they\noften do so at the expense of retaining predictive information, and thus their\ncapabilities are inherently bounded by those of an unconstrained model. This\nestablishes a principled framework to manipulate Transformer memory using\ninformation theory, addressing fundamental reasoning limitations that scaling\nalone cannot overcome.",
    "pdf_url": "http://arxiv.org/pdf/2505.16950v2",
    "published": "2025-05-22T17:33:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16949v2",
    "title": "On some connections between Kobayashi geometry and pluripotential theory",
    "authors": [
      "Gautam Bharali",
      "Rumpa Masanta"
    ],
    "abstract": "In this paper, we explore some connections between Kobayashi geometry and the\nDirichlet problem for the complex Monge--Amp\\`ere equation. Among the results\nwe obtain through these connections are: $(i)$~a theorem on the continuous\nextension up to $\\partial{D}$ of a proper holomorphic map $F: D\\longrightarrow\n\\Omega$ between domains with $\\dim_{\\mathbb{C}}(D) <\n\\dim_{\\mathbb{C}}(\\Omega)$, and $(ii)$~a result that establishes the existence\nof bounded domains with ``nice'' boundary geometry on which H\\\"older regularity\nof the solutions to the complex Monge--Amp\\`ere equation fails. The first, a\nresult in Kobayashi geometry, relies upon an auxiliary construction that\ninvolves solving the complex Monge--Amp\\`ere equation with H\\\"older estimates.\nThe second result relies crucially on a bound for the Kobayashi metric.",
    "pdf_url": "http://arxiv.org/pdf/2505.16949v2",
    "published": "2025-05-22T17:33:35+00:00",
    "categories": [
      "math.CV",
      "math.AP",
      "32F45, 32H35, 32U05 (Primary) 32T40 (Secondary)"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16948v1",
    "title": "Quantum Routing and Entanglement Dynamics Through Bottlenecks",
    "authors": [
      "Dhruv Devulapalli",
      "Chao Yin",
      "Andrew Y. Guo",
      "Eddie Schoute",
      "Andrew M. Childs",
      "Alexey V. Gorshkov",
      "Andrew Lucas"
    ],
    "abstract": "To implement arbitrary quantum circuits in architectures with restricted\ninteractions, one may effectively simulate all-to-all connectivity by routing\nquantum information. We consider the entanglement dynamics and routing between\ntwo regions only connected through an intermediate \"bottleneck\" region with few\nqubits. In such systems, where the entanglement rate is restricted by a vertex\nboundary rather than an edge boundary of the underlying interaction graph,\nexisting results such as the small incremental entangling theorem give only a\ntrivial constant lower bound on the routing time (the minimum time to perform\nan arbitrary permutation). We significantly improve the lower bound on the\nrouting time in systems with a vertex bottleneck. Specifically, for any system\nwith two regions $L, R$ with $N_L, N_R$ qubits, respectively, coupled only\nthrough an intermediate region $C$ with $N_C$ qubits, for any $\\delta > 0$ we\nshow a lower bound of $\\Omega(N_R^{1-\\delta}/\\sqrt{N_L}N_C)$ on the Hamiltonian\nquantum routing time when using piecewise time-independent Hamiltonians, or\ntime-dependent Hamiltonians subject to a smoothness condition. We also prove an\nupper bound on the average amount of bipartite entanglement between $L$ and\n$C,R$ that can be generated in time $t$ by such architecture-respecting\nHamiltonians in systems constrained by vertex bottlenecks, improving the\nscaling in the system size from $O(N_L t)$ to $O(\\sqrt{N_L} t)$. As a special\ncase, when applied to the star graph (i.e., one vertex connected to $N$\nleaves), we obtain an $\\Omega(\\sqrt{N^{1-\\delta}})$ lower bound on the routing\ntime and on the time to prepare $N/2$ Bell pairs between the vertices. We also\nshow that, in systems of free particles, we can route optimally on the star\ngraph in time $\\Theta(\\sqrt{N})$ using Hamiltonian quantum routing, obtaining a\nspeed-up over gate-based routing, which takes time $\\Theta(N)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16948v1",
    "published": "2025-05-22T17:33:11+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16947v1",
    "title": "MixAT: Combining Continuous and Discrete Adversarial Training for LLMs",
    "authors": [
      "Csaba Dékány",
      "Stefan Balauca",
      "Robin Staab",
      "Dimitar I. Dimitrov",
      "Martin Vechev"
    ],
    "abstract": "Despite recent efforts in Large Language Models (LLMs) safety and alignment,\ncurrent adversarial attacks on frontier LLMs are still able to force harmful\ngenerations consistently. Although adversarial training has been widely studied\nand shown to significantly improve the robustness of traditional machine\nlearning models, its strengths and weaknesses in the context of LLMs are less\nunderstood. Specifically, while existing discrete adversarial attacks are\neffective at producing harmful content, training LLMs with concrete adversarial\nprompts is often computationally expensive, leading to reliance on continuous\nrelaxations. As these relaxations do not correspond to discrete input tokens,\nsuch latent training methods often leave models vulnerable to a diverse set of\ndiscrete attacks. In this work, we aim to bridge this gap by introducing MixAT,\na novel method that combines stronger discrete and faster continuous attacks\nduring training. We rigorously evaluate MixAT across a wide spectrum of\nstate-of-the-art attacks, proposing the At Least One Attack Success Rate\n(ALO-ASR) metric to capture the worst-case vulnerability of models. We show\nMixAT achieves substantially better robustness (ALO-ASR < 20%) compared to\nprior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to\nmethods based on continuous relaxations. We further analyze MixAT in realistic\ndeployment settings, exploring how chat templates, quantization, low-rank\nadapters, and temperature affect both adversarial training and evaluation,\nrevealing additional blind spots in current methodologies. Our results\ndemonstrate that MixAT's discrete-continuous defense offers a principled and\nsuperior robustness-accuracy tradeoff with minimal computational overhead,\nhighlighting its promise for building safer LLMs. We provide our code and\nmodels at https://github.com/insait-institute/MixAT.",
    "pdf_url": "http://arxiv.org/pdf/2505.16947v1",
    "published": "2025-05-22T17:32:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.7; K.4.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16946v3",
    "title": "NY Real Estate Racial Equity Analysis via Applied Machine Learning",
    "authors": [
      "Sanjana Chalavadi",
      "Andrei Pastor",
      "Terry Leitch"
    ],
    "abstract": "This study analyzes tract-level real estate ownership patterns in New York\nState (NYS) and New York City (NYC) to uncover racial disparities. We use an\nadvanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering,\nvalidated at 89.2% accuracy) to compare the predicted racial composition of\nproperty owners to the resident population from census data. We examine both a\nFull Model (statewide) and a Name-Only LSTM Model (NYC) to assess how\nincorporating geospatial context affects our predictions and disparity\nestimates. The results reveal significant inequities: White individuals hold a\ndisproportionate share of properties and property value relative to their\npopulation, while Black, Hispanic, and Asian communities are underrepresented\nas property owners. These disparities are most pronounced in minority-majority\nneighborhoods, where ownership is predominantly White despite a predominantly\nnon-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates\nthese gaps by reducing owner-occupied opportunities in urban minority\ncommunities. We provide a breakdown of ownership vs. population by race for\nmajority-White, -Black, -Hispanic, and -Asian tracts, identify those with\nextreme ownership disparities, and compare patterns in urban, suburban, and\nrural contexts. The findings underscore persistent racial inequity in property\nownership, reflecting broader historical and socio-economic forces, and\nhighlight the importance of data-driven approaches to address these issues.",
    "pdf_url": "http://arxiv.org/pdf/2505.16946v3",
    "published": "2025-05-22T17:32:28+00:00",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16945v1",
    "title": "On a certain class of para-Hermite Einstein spaces",
    "authors": [
      "Adam Chudecki"
    ],
    "abstract": "A special class of (complex) para-Hermite Einstein spaces is analyzed. It is\nwell-known that the self-dual Weyl tensor in para-Hermite Einstein spaces is of\nthe Petrov-Penrose type [D]. In what follows we assume that the anti-self-dual\nWeyl tensor is algebraically degenerate. It is equivalent to the existence of\nan anti-self-dual congruence of null strings which is assumed not to be\nparallely propagated. Hence, spaces analyzed here are not Walker spaces. A\nclassification of such spaces is given and the explicit metrics are found.",
    "pdf_url": "http://arxiv.org/pdf/2505.16945v1",
    "published": "2025-05-22T17:32:17+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16944v1",
    "title": "AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios",
    "authors": [
      "Yunjia Qi",
      "Hao Peng",
      "Xiaozhi Wang",
      "Amy Xin",
      "Youfeng Liu",
      "Bin Xu",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated advanced capabilities in\nreal-world agentic applications. Growing research efforts aim to develop\nLLM-based agents to address practical demands, introducing a new challenge:\nagentic scenarios often involve lengthy instructions with complex constraints,\nsuch as extended system prompts and detailed tool specifications. While\nadherence to such instructions is crucial for agentic applications, whether\nLLMs can reliably follow them remains underexplored. In this paper, we\nintroduce AgentIF, the first benchmark for systematically evaluating LLM\ninstruction following ability in agentic scenarios. AgentIF features three key\ncharacteristics: (1) Realistic, constructed from 50 real-world agentic\napplications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.\n(3) Complex, averaging 11.9 constraints per instruction, covering diverse\nconstraint types, such as tool specifications and condition constraints. To\nconstruct AgentIF, we collect 707 human-annotated instructions across 50\nagentic tasks from industrial application agents and open-source agentic\nsystems. For each instruction, we annotate the associated constraints and\ncorresponding evaluation metrics, including code-based evaluation, LLM-based\nevaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically\nevaluate existing advanced LLMs. We observe that current models generally\nperform poorly, especially in handling complex constraint structures and tool\nspecifications. We further conduct error analysis and analytical experiments on\ninstruction length and meta constraints, providing some findings about the\nfailure modes of existing LLMs. We have released the code and data to\nfacilitate future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.16944v1",
    "published": "2025-05-22T17:31:10+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16943v2",
    "title": "Sliding Friction of Hard Sliders on Rubber: Theory and Experiment",
    "authors": [
      "R. Xu",
      "B. N. J. Persson"
    ],
    "abstract": "We present a study of sliding friction for rigid triangular steel sliders on\nsoft rubber substrates under both lubricated and dry conditions. For rubber\nsurfaces lubricated with a thin film of silicone oil, the measured sliding\nfriction at room temperature agrees well with theoretical predictions obtained\nfrom a viscoelastic model originally developed for rolling friction. On the\nlubricated surface, the sliding friction is primarily due to bulk viscoelastic\nenergy dissipation in the rubber. The model, which includes strain-dependent\nsoftening of the rubber modulus, accurately predicts the experimental friction\ncurves. At lower temperatures ($T = -20^\\circ {\\rm C}$ and $-40^\\circ {\\rm\nC}$), the measured friction exceeds the theoretical prediction. We attribute\nthis increase to penetration of the lubricant film by surface asperities,\nleading to a larger adhesive contribution. For dry surfaces, the adhesive\ncontribution becomes dominant. By subtracting the viscoelastic component\ninferred from the lubricated case, we estimate the interfacial frictional shear\nstress. This shear stress increases approximately linearly with the logarithm\nof the sliding speed, consistent with stress-augmented thermal activation\nmechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.16943v2",
    "published": "2025-05-22T17:30:58+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.16942v1",
    "title": "Efficient Correlation Volume Sampling for Ultra-High-Resolution Optical Flow Estimation",
    "authors": [
      "Karlis Martins Briedis",
      "Markus Gross",
      "Christopher Schroers"
    ],
    "abstract": "Recent optical flow estimation methods often employ local cost sampling from\na dense all-pairs correlation volume. This results in quadratic computational\nand memory complexity in the number of pixels. Although an alternative\nmemory-efficient implementation with on-demand cost computation exists, this is\nslower in practice and therefore prior methods typically process images at\nreduced resolutions, missing fine-grained details.\n  To address this, we propose a more efficient implementation of the all-pairs\ncorrelation volume sampling, still matching the exact mathematical operator as\ndefined by RAFT. Our approach outperforms on-demand sampling by up to 90% while\nmaintaining low memory usage, and performs on par with the default\nimplementation with up to 95% lower memory usage. As cost sampling makes up a\nsignificant portion of the overall runtime, this can translate to up to 50%\nsavings for the total end-to-end model inference in memory-constrained\nenvironments. Our evaluation of existing methods includes an 8K\nultra-high-resolution dataset and an additional inference-time modification of\nthe recent SEA-RAFT method. With this, we achieve state-of-the-art results at\nhigh resolutions both in accuracy and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.16942v1",
    "published": "2025-05-22T17:30:38+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16941v3",
    "title": "FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records",
    "authors": [
      "Chao Pang",
      "Vincent Jeanselme",
      "Young Sang Choi",
      "Xinzhuo Jiang",
      "Zilin Jing",
      "Aparajita Kashyap",
      "Yuta Kobayashi",
      "Yanwei Li",
      "Florent Pollet",
      "Karthik Natarajan",
      "Shalmali Joshi"
    ],
    "abstract": "Foundation models hold significant promise in healthcare, given their\ncapacity to extract meaningful representations independent of downstream tasks.\nThis property has enabled state-of-the-art performance across several clinical\napplications trained on structured electronic health record (EHR) data, even in\nsettings with limited labeled data, a prevalent challenge in healthcare.\nHowever, there is little consensus on these models' potential for clinical\nutility due to the lack of desiderata of comprehensive and meaningful tasks and\nsufficiently diverse evaluations to characterize the benefit over conventional\nsupervised learning. To address this gap, we propose a suite of clinically\nmeaningful tasks spanning patient outcomes, early prediction of acute and\nchronic conditions, including desiderata for robust evaluations. We evaluate\nstate-of-the-art foundation models on EHR data consisting of 5 million patients\nfrom Columbia University Irving Medical Center (CUMC), a large urban academic\nmedical center in New York City, across 14 clinically relevant tasks. We\nmeasure overall accuracy, calibration, and subpopulation performance to surface\ntradeoffs based on the choice of pre-training, tokenization, and data\nrepresentation strategies. Our study aims to advance the empirical evaluation\nof structured EHR foundation models and guide the development of future\nhealthcare foundation models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16941v3",
    "published": "2025-05-22T17:29:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16940v1",
    "title": "Center-symmetric Landau gauge, the deconfinement transition and the gluon propagator as seen in lattice QCD",
    "authors": [
      "Duifje Maria van Egmond",
      "Orlando Oliveira",
      "Urko Reinosa",
      "Julien Serreau",
      "Paulo J. Silva",
      "Matthieu Tissier"
    ],
    "abstract": "We address the lattice computation of the gluon propagator in the\ncenter-symmetric Landau gauge. After discussing a proper lattice implementation\nof the center-symmetric Landau gauge, we compare the lattice data with\nanalytical results, and we identify various signatures of center symmetry\nbreaking.",
    "pdf_url": "http://arxiv.org/pdf/2505.16940v1",
    "published": "2025-05-22T17:29:40+00:00",
    "categories": [
      "hep-lat",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.16939v1",
    "title": "Delayed dynamic-feedback controller design for multi-frequency vibration suppression",
    "authors": [
      "Adrian Saldanha",
      "Adam Peichl",
      "Wim Michiels",
      "Tomáš Vyhlídal"
    ],
    "abstract": "We present a methodology for designing a dynamic controller with delayed\noutput feedback for achieving non-collocated vibration suppression with a focus\non the multi-frequency case. To synthesize the delay-based controller, we first\nremodel the system of equations as a delay-differential algebraic equation\n(DDAE) in such a way that existing tools for design of a static output feedback\ncontroller can be easily adapted. The problem of achieving non-collocated\nvibration suppression with sufficient damping is formulated as a constrained\noptimization problem of minimizing the spectral abscissa in the presence of\nzero-location constraints, with the constraints exhibiting polynomial\ndependence on its parameters. We transform the problem into an unconstrained\none using elimination, following which we solve the resulting non-convex,\nnon-smooth optimization problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.16939v1",
    "published": "2025-05-22T17:28:51+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC",
      "93D20",
      "I.6.5; F.2.1"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16938v3",
    "title": "InternAgent: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification",
    "authors": [
      "InternAgent Team",
      "Bo Zhang",
      "Shiyang Feng",
      "Xiangchao Yan",
      "Jiakang Yuan",
      "Runmin Ma",
      "Yusong Hu",
      "Zhiyin Yu",
      "Xiaohan He",
      "Songtao Huang",
      "Shaowei Hou",
      "Zheng Nie",
      "Zhilong Wang",
      "Jinyao Liu",
      "Tianshuo Peng",
      "Peng Ye",
      "Dongzhan Zhou",
      "Shufei Zhang",
      "Xiaosong Wang",
      "Yilan Zhang",
      "Meng Li",
      "Zhongying Tu",
      "Xiangyu Yue",
      "Wangli Ouyang",
      "Bowen Zhou",
      "Lei Bai"
    ],
    "abstract": "Artificial Intelligence (AI) is accelerating the transformation of scientific\nresearch paradigms, not only enhancing research efficiency but also driving\ninnovation. We introduce InternAgent, a unified closed-loop multi-agent\nframework to conduct Autonomous Scientific Research (ASR) across various\nscientific research fields, enabling researchers to tackle complicated problems\nin these fields with unprecedented speed and precision. InternAgent highlights\nthree key advantages: 1) Scalability: InternAgent has demonstrated its\nversatility across 12 scientific research tasks, capable of generating\ninnovative ideas to enhance the performance of baseline code. 2) Interactivity:\nInternAgent provides an interface for human expert feedback and multi-agent\ninteraction in automated end-to-end processes, allowing for the seamless\nintegration of domain expert knowledge. 3) Efficiency: InternAgent has achieved\npromising performance gains in several scientific fields with significantly\nless time cost compared to human efforts. For instance, in reaction yield\nprediction, it increased from 27.6% to 35.4% in just 12 hours; in enhancer\nactivity prediction, accuracy rose from 0.65 to 0.79 with only 4 hours of\nprocessing; and in 2D semantic segmentation, precision advanced from 78.8% to\n81.0% in a mere 30 hours.",
    "pdf_url": "http://arxiv.org/pdf/2505.16938v3",
    "published": "2025-05-22T17:27:43+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16937v2",
    "title": "Quasi-optimal hierarchically semi-separable matrix approximation",
    "authors": [
      "Noah Amsel",
      "Tyler Chen",
      "Feyza Duman Keles",
      "Diana Halikias",
      "Cameron Musco",
      "Christopher Musco",
      "David Persson"
    ],
    "abstract": "We present a randomized algorithm for producing a quasi-optimal\nhierarchically semi-separable (HSS) approximation to an $N\\times N$ matrix $A$\nusing only matrix-vector products with $A$ and $A^T$. We prove that, using $O(k\n\\log(N/k))$ matrix-vector products and ${O}(N k^2 \\log(N/k))$ additional\nruntime, the algorithm returns an HSS matrix $B$ with rank-$k$ blocks whose\nexpected Frobenius norm error $\\mathbb{E}[\\|A - B\\|_F^2]$ is at most\n$O(\\log(N/k))$ times worse than the best possible approximation error by an HSS\nrank-$k$ matrix. In fact, the algorithm we analyze in a simple modification of\nan empirically effective method proposed by [Levitt & Martinsson, SISC 2024].\nAs a stepping stone towards our main result, we prove two results that are of\nindependent interest: a similar guarantee for a variant of the algorithm which\naccesses $A$'s entries directly, and explicit error bounds for near-optimal\nsubspace approximation using projection-cost-preserving sketches. To the best\nof our knowledge, our analysis constitutes the first polynomial-time\nquasi-optimality result for HSS matrix approximation, both in the explicit\naccess model and the matrix-vector product query model.",
    "pdf_url": "http://arxiv.org/pdf/2505.16937v2",
    "published": "2025-05-22T17:27:40+00:00",
    "categories": [
      "math.NA",
      "cs.DS",
      "cs.NA",
      "65F55, 68W20, 68W25"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16936v2",
    "title": "SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems",
    "authors": [
      "Yizhuo Chen",
      "Tianchen Wang",
      "You Lyu",
      "Yanlan Hu",
      "Jinyang Li",
      "Tomoyoshi Kimura",
      "Hongjue Zhao",
      "Yigong Hu",
      "Denizhan Kara",
      "Tarek Abdelzaher"
    ],
    "abstract": "This work develops the underpinnings of self-supervised placement-aware\nrepresentation learning given spatially-distributed (multi-view and multimodal)\nsensor observations, motivated by the need to represent external environmental\nstate in multi-sensor IoT systems in a manner that correctly distills spatial\nphenomena from the distributed multi-vantage observations. The objective of\nsensing in IoT systems is, in general, to collectively represent an externally\nobserved environment given multiple vantage points from which sensory\nobservations occur. Pretraining of models that help interpret sensor data must\ntherefore encode the relation between signals observed by sensors and the\nobservers' vantage points in order to attain a representation that encodes the\nobserved spatial phenomena in a manner informed by the specific placement of\nthe measuring instruments, while allowing arbitrary placement. The work\nsignificantly advances self-supervised model pretraining from IoT signals\nbeyond current solutions that often overlook the distinctive spatial nature of\nIoT data. Our framework explicitly learns the dependencies between measurements\nand geometric observer layouts and structural characteristics, guided by a core\ndesign principle: the duality between signals and observer positions. We\nfurther provide theoretical analyses from the perspectives of information\ntheory and occlusion-invariant representation learning to offer insight into\nthe rationale behind our design. Experiments on three real-world\ndatasets--covering vehicle monitoring, human activity recognition, and\nearthquake localization--demonstrate the superior generalizability and\nrobustness of our method across diverse modalities, sensor placements,\napplication-level inference tasks, and spatial scales.",
    "pdf_url": "http://arxiv.org/pdf/2505.16936v2",
    "published": "2025-05-22T17:26:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16935v1",
    "title": "Modeling and Constraint-Aware Control of Pressure Dynamics in Water Electrolysis Systems",
    "authors": [
      "Mostafaali Ayubirad",
      "Madiha Akbar",
      "Hamid R. Ossareh"
    ],
    "abstract": "This paper addresses the challenge of pressure constraint violations in water\nelectrolysis systems operating under dynamic power conditions, a problem common\nto both Proton Exchange Membrane and alkaline technologies. To investigate this\nissue, a control-oriented model of an alkaline electrolyzer is developed,\ncapturing key pressure and flow dynamics. To manage rapid power fluctuations\nthat may cause pressure to exceed manufacturer-defined operational boundaries,\na model-based constraint-aware power governor based on the Reference Governor\n(RG) framework is proposed. Simulation results show that the strategy\neffectively maintains pressure within the specified operating range,\noutperforming conventional filtering methods while enhancing hydrogen\nproduction and reducing auxiliary energy consumption.",
    "pdf_url": "http://arxiv.org/pdf/2505.16935v1",
    "published": "2025-05-22T17:25:06+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16934v1",
    "title": "In-Context Watermarks for Large Language Models",
    "authors": [
      "Yepeng Liu",
      "Xuandong Zhao",
      "Christopher Kruegel",
      "Dawn Song",
      "Yuheng Bu"
    ],
    "abstract": "The growing use of large language models (LLMs) for sensitive applications\nhas highlighted the need for effective watermarking techniques to ensure the\nprovenance and accountability of AI-generated text. However, most existing\nwatermarking methods require access to the decoding process, limiting their\napplicability in real-world settings. One illustrative example is the use of\nLLMs by dishonest reviewers in the context of academic peer review, where\nconference organizers have no access to the model used but still need to detect\nAI-generated reviews. Motivated by this gap, we introduce In-Context\nWatermarking (ICW), which embeds watermarks into generated text solely through\nprompt engineering, leveraging LLMs' in-context learning and\ninstruction-following abilities. We investigate four ICW strategies at\ndifferent levels of granularity, each paired with a tailored detection method.\nWe further examine the Indirect Prompt Injection (IPI) setting as a specific\ncase study, in which watermarking is covertly triggered by modifying input\ndocuments such as academic manuscripts. Our experiments validate the\nfeasibility of ICW as a model-agnostic, practical watermarking approach.\nMoreover, our findings suggest that as LLMs become more capable, ICW offers a\npromising direction for scalable and accessible content attribution.",
    "pdf_url": "http://arxiv.org/pdf/2505.16934v1",
    "published": "2025-05-22T17:24:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16933v2",
    "title": "LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning",
    "authors": [
      "Zebin You",
      "Shen Nie",
      "Xiaolu Zhang",
      "Jun Hu",
      "Jun Zhou",
      "Zhiwu Lu",
      "Ji-Rong Wen",
      "Chongxuan Li"
    ],
    "abstract": "In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large\nLanguage Model (MLLM) that integrates visual instruction tuning with masked\ndiffusion models, representing a departure from the autoregressive paradigms\ndominant in current multimodal approaches. Built upon LLaDA, a representative\nlarge language diffusion model, LLaDA-V incorporates a vision encoder and MLP\nconnector that projects visual features into the language embedding space,\nenabling effective multimodal alignment. Our empirical investigation reveals\nseveral intriguing results: First, LLaDA-V demonstrates promising multimodal\nperformance despite its language model being weaker on purely textual tasks\nthan counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same\ninstruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal\ntasks with better data scalability. It also narrows the performance gap to\nQwen2-VL, suggesting the effectiveness of its architecture for multimodal\ntasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal\nunderstanding compared to existing hybrid autoregressive-diffusion and purely\ndiffusion-based MLLMs. Our findings suggest that large language diffusion\nmodels show promise in multimodal contexts and warrant further investigation in\nfuture research. Project page and codes:\nhttps://ml-gsai.github.io/LLaDA-V-demo/.",
    "pdf_url": "http://arxiv.org/pdf/2505.16933v2",
    "published": "2025-05-22T17:23:26+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16932v2",
    "title": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm",
    "authors": [
      "Noah Amsel",
      "David Persson",
      "Christopher Musco",
      "Robert M. Gower"
    ],
    "abstract": "Computing the polar decomposition and the related matrix sign function, has\nbeen a well-studied problem in numerical analysis for decades. More recently,\nit has emerged as an important subroutine in deep learning, particularly within\nthe Muon optimization framework. However, the requirements in this setting\ndiffer significantly from those of traditional numerical analysis. In deep\nlearning, methods must be highly efficient and GPU-compatible, but high\naccuracy is often unnecessary. As a result, classical algorithms like\nNewton-Schulz (which suffers from slow initial convergence) and methods based\non rational functions (which rely on QR decompositions or matrix inverses) are\npoorly suited to this context. In this work, we introduce Polar Express, a\nGPU-friendly algorithm for computing the polar decomposition. Like classical\npolynomial methods such as Newton-Schulz, our approach uses only matrix-matrix\nmultiplications, making it GPU-compatible. Motivated by earlier work of Chen &\nChow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule\nat each iteration by solving a minimax optimization problem, and we prove that\nit enjoys a strong worst-case optimality guarantee. This property ensures both\nrapid early convergence and fast asymptotic convergence. We also address\nfinite-precision issues, making it stable in bfloat16 in practice. We apply\nPolar Express within the Muon optimization framework and show consistent\nimprovements in validation loss on large-scale models such as GPT-2,\noutperforming recent alternatives across a range of learning rates.",
    "pdf_url": "http://arxiv.org/pdf/2505.16932v2",
    "published": "2025-05-22T17:23:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NA",
      "math.NA",
      "math.OC",
      "65F30, 68T07, 68N19",
      "G.1.3; I.2.6; F.2.1; G.1.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16931v1",
    "title": "PIIvot: A Lightweight NLP Anonymization Framework for Question-Anchored Tutoring Dialogues",
    "authors": [
      "Matthew Zent",
      "Digory Smith",
      "Simon Woodhead"
    ],
    "abstract": "Personally identifiable information (PII) anonymization is a high-stakes task\nthat poses a barrier to many open-science data sharing initiatives. While PII\nidentification has made large strides in recent years, in practice, error\nthresholds and the recall/precision trade-off still limit the uptake of these\nanonymization pipelines. We present PIIvot, a lighter-weight framework for PII\nanonymization that leverages knowledge of the data context to simplify the PII\ndetection problem. To demonstrate its effectiveness, we also contribute\nQATD-2k, the largest open-source real-world tutoring dataset of its kind, to\nsupport the demand for quality educational dialogue data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16931v1",
    "published": "2025-05-22T17:22:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16930v1",
    "title": "Lorentz-violating QED inspired superconductivity",
    "authors": [
      "A. F. Morais",
      "M. C. Araújo",
      "T. T. Saraiva",
      "J. Furtado"
    ],
    "abstract": "We studied a Lorentz-violating inspired Ginzburg-Landau model for\nsuperconductivity where we considered a CPT-odd contribution given by\n$(k_{AF})^{\\mu}$, also known as the Carroll-Field-Jackiw term. In the static\nlimit of the equations, we could find a pair of modified Ginzburg-Landau\nequations. Furthermore, these equations were reduced to the London equation for\nthe magnetic field when assumed that the characteristic length of the order\nparameter is much smaller than the characteristic length of the magnetic field,\ni.e. the London penetration length. Our numerical solutions showed a simple\nMeissner state when this new term is small compared to $\\lambda_L$ and a phase\ntransition into phases with strong in-plane currents and anomalous vortices for\nlarge contributions. This model becomes useful in exemplifying the changes in\nthe phenomenology of superconductors when the setup of the system shows an\nimportant breakdown of Lorentz invariance. Based on these results, we discuss\nhow such models might be the hallmark of unusual superconducting states where\nthere is a direction where the system shows stratification, as in anapole\nsuperconductors UTe$_2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16930v1",
    "published": "2025-05-22T17:22:24+00:00",
    "categories": [
      "cond-mat.supr-con",
      "hep-th"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.16929v1",
    "title": "Neutron Star crust informed by nuclear structure data",
    "authors": [
      "Pietro Klausner",
      "Marco Antonelli",
      "Francesca Gulminelli"
    ],
    "abstract": "We perform a Bayesian analysis of the neutron star (NS) equation of state\n(EoS) based on a wide set of Skyrme functionals, derived from previous nuclear\nphysics inferences. The novelty of this approach lies in starting from the full\nmultidimensional posterior distribution of nuclear matter parameters,\nconsistent with a comprehensive set of static and dynamic nuclear structure\nobservables. We construct unified EoSs for $npe\\mu$ matter, where the inner\ncrust of the NS is treated using an extended Thomas-Fermi method, providing for\nthe first time a fully consistent Bayesian treatment of the correlation of bulk\nwith surface as well as with spin-orbit and effective mass parameters. We then\nemploy a standard Bayesian framework to identify those EoSs that satisfy\nastrophysical constraints from NS mass measurements, the tidal deformability\nfrom GW170817, and NICER mass-radius observations. We also examine NS\nobservables, such as the crustal moment of inertia, which is crucial in\nunderstanding pulsar glitches. Compared to previous works, we observe an\nincrease in both the NS surface thickness and the crustal moment of inertia.",
    "pdf_url": "http://arxiv.org/pdf/2505.16929v1",
    "published": "2025-05-22T17:22:16+00:00",
    "categories": [
      "nucl-th",
      "astro-ph.HE"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16928v1",
    "title": "Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning",
    "authors": [
      "Bosung Kim",
      "Prithviraj Ammanabrolu"
    ],
    "abstract": "We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks\nthat advances long-context understanding in embodied AI. $\\infty$-THOR\nprovides: (1) a generation framework for synthesizing scalable, reproducible,\nand unlimited long-horizon trajectories; (2) a novel embodied QA task,\nNeedle(s) in the Embodied Haystack, where multiple scattered clues across\nextended trajectories test agents' long-context reasoning ability; and (3) a\nlong-horizon dataset and benchmark suite featuring complex tasks that span\nhundreds of environment steps, each paired with ground-truth action sequences.\nTo enable this capability, we explore architectural adaptations, including\ninterleaved Goal-State-Action modeling, context extension techniques, and\nContext Parallelism, to equip LLM-based agents for extreme long-context\nreasoning and interaction. Experimental results and analyses highlight the\nchallenges posed by our benchmark and provide insights into training strategies\nand model behaviors under long-horizon conditions. Our work provides a\nfoundation for the next generation of embodied AI systems capable of robust,\nlong-term reasoning and planning.",
    "pdf_url": "http://arxiv.org/pdf/2505.16928v1",
    "published": "2025-05-22T17:20:38+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16927v1",
    "title": "Latent Principle Discovery for Language Model Self-Improvement",
    "authors": [
      "Keshav Ramji",
      "Tahira Naseem",
      "Ramón Fernandez Astudillo"
    ],
    "abstract": "When language model (LM) users aim to improve the quality of its generations,\nit is crucial to specify concrete behavioral attributes that the model should\nstrive to reflect. However, curating such principles across many domains, even\nnon-exhaustively, requires a labor-intensive annotation process. To automate\nthis process, we propose eliciting these latent attributes guiding model\nreasoning towards human-preferred responses by explicitly modeling them in a\nself-correction setting. Our approach mines new principles from the LM itself\nand compresses the discovered elements to an interpretable set via clustering.\nSpecifically, we employ an approximation of posterior-regularized Monte Carlo\nExpectation-Maximization to both identify a condensed set of the most effective\nlatent principles and teach the LM to strategically invoke them in order to\nintrinsically refine its responses. We demonstrate that bootstrapping our\nalgorithm over multiple iterations enables smaller language models (7-8B\nparameters) to self-improve, achieving +8-10% in AlpacaEval win-rate, an\naverage of +0.3 on MT-Bench, and +19-23% in principle-following win-rate on\nIFEval. We also show that clustering the principles yields interpretable and\ndiverse model-generated constitutions while retaining model performance. The\ngains our method achieves highlight the potential of automated,\nprinciple-driven post-training recipes toward continual self-improvement.",
    "pdf_url": "http://arxiv.org/pdf/2505.16927v1",
    "published": "2025-05-22T17:20:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16926v1",
    "title": "Photo-induced electronic excitations drive polymerization of carbon monoxide: A first-principles study",
    "authors": [
      "Rasool Ahmad",
      "Jonathan C. Crowhurst",
      "Stanimir A. Bonev"
    ],
    "abstract": "Under pressure, carbon monoxide (CO) transforms into a polymer that can be\nrecovered to ambient conditions. While this transformation can occur without\nadditional stimuli, experimental observations have shown that laser irradiation\ncan induce a similar transformation at reduced pressure. The resulting\npolymeric phase, which is metastable under ambient conditions, releases energy\nthrough decomposition into more stable configurations. Using time-dependent\ndensity functional theory and Born-Oppenheimer molecular dynamics simulations,\nwe investigate the mechanism by which electronic excitation facilitates CO\npolymerization. Our calculations reveal that electronic excitation enhances\ncarbon-carbon bonding, enabling polymerization at pressures significantly lower\nthan those required by conventional compression methods. These findings suggest\nthat a photo-assisted approach could be employed to synthesize novel,\npotentially energetic materials under less demanding pressure conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16926v1",
    "published": "2025-05-22T17:19:27+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.17169v1",
    "title": "Next Token Perception Score: Analytical Assessment of your LLM Perception Skills",
    "authors": [
      "Yu-Ang Cheng",
      "Leyang Hu",
      "Hai Huang",
      "Randall Balestriero"
    ],
    "abstract": "Autoregressive pretraining has become the de facto paradigm for learning\ngeneral-purpose representations in large language models (LLMs). However,\nlinear probe performance across downstream perception tasks shows substantial\nvariability, suggesting that features optimized for next-token prediction do\nnot consistently transfer well to downstream perception tasks. We demonstrate\nthat representations learned via autoregression capture features that may lie\noutside the subspaces most informative for perception. To quantify the\n(mis)alignment between autoregressive pretraining and downstream perception, we\nintroduce the Next Token Perception Score (NTPS)-a score derived under a linear\nsetting that measures the overlap between autoregressive and perception feature\nsubspaces. This metric can be easily computed in closed form from pretrained\nrepresentations and labeled data, and is proven to both upper- and lower-bound\nthe excess loss. Empirically, we show that NTPS correlates strongly with linear\nprobe accuracy across 12 diverse NLP datasets and eight pretrained models\nranging from 270M to 8B parameters, confirming its utility as a measure of\nalignment. Furthermore, we show that NTPS increases following low-rank\nadaptation (LoRA) fine-tuning, especially in large models, suggesting that LoRA\naligning representations to perception tasks enhances subspace overlap and thus\nimproves downstream performance. More importantly, we find that NTPS reliably\npredicts the additional accuracy gains attained by LoRA finetuning thereby\nproviding a lightweight prescreening tool for LoRA adaptation. Our results\noffer both theoretical insights and practical tools for analytically assessing\nLLM perception skills.",
    "pdf_url": "http://arxiv.org/pdf/2505.17169v1",
    "published": "2025-05-22T17:18:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16925v2",
    "title": "Risk-Averse Reinforcement Learning with Itakura-Saito Loss",
    "authors": [
      "Igor Udovichenko",
      "Olivier Croissant",
      "Anita Toleutaeva",
      "Evgeny Burnaev",
      "Alexander Korotin"
    ],
    "abstract": "Risk-averse reinforcement learning finds application in various high-stakes\nfields. Unlike classical reinforcement learning, which aims to maximize\nexpected returns, risk-averse agents choose policies that minimize risk,\noccasionally sacrificing expected value. These preferences can be framed\nthrough utility theory. We focus on the specific case of the exponential\nutility function, where one can derive the Bellman equations and employ various\nreinforcement learning algorithms with few modifications. To address this, we\nintroduce to the broad machine learning community a numerically stable and\nmathematically sound loss function based on the Itakura-Saito divergence for\nlearning state-value and action-value functions. We evaluate the Itakura-Saito\nloss function against established alternatives, both theoretically and\nempirically. In the experimental section, we explore multiple scenarios, some\nwith known analytical solutions, and show that the considered loss function\noutperforms the alternatives.",
    "pdf_url": "http://arxiv.org/pdf/2505.16925v2",
    "published": "2025-05-22T17:18:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16924v1",
    "title": "Some spectral properties and convergence of the $ (A,q)$-numerical radius and $ (A,q)$-Crawford number",
    "authors": [
      "Pembe Ipek Al",
      "Zameddin I. Ismailov",
      "Fuad Kittaneh",
      "Satyajit Sahoo"
    ],
    "abstract": "In this study, some estimates are given for the $ (A,q)$-numerical radius and\n$ (A,q)$-Crawford number via the $ A$-numerical radius and $ A$-Crawford number\nfor the $ A $-bounded linear operators in any complex semi-Hilbert space,\nrespectively. Then, some evolutions are studied for the tensor product of two\noperators. Lastly, some convergence properties of the $ (A,q)$-numerical radius\nand $ (A,q)$-Crawford number, via the $ A$-uniform convergence of operator\nsequences, are investigated. We also considered several examples to illustrate\nour results. Finally, a few applications of some operator functions classes are\nalso given.",
    "pdf_url": "http://arxiv.org/pdf/2505.16924v1",
    "published": "2025-05-22T17:17:22+00:00",
    "categories": [
      "math.FA",
      "47A05, 47A12, 47A30, 47A63"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16923v2",
    "title": "TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation",
    "authors": [
      "Yuhui Zhang",
      "Dongshen Wu",
      "Yuichiro Wada",
      "Takafumi Kanamori"
    ],
    "abstract": "A reliable uncertainty estimation method is the foundation of many modern\nout-of-distribution (OOD) detectors, which are critical for safe deployments of\ndeep learning models in the open world. In this work, we propose TULiP, a\ntheoretically-driven post-hoc uncertainty estimator for OOD detection. Our\napproach considers a hypothetical perturbation applied to the network before\nconvergence. Based on linearized training dynamics, we bound the effect of such\nperturbation, resulting in an uncertainty score computable by perturbing model\nparameters. Ultimately, our approach computes uncertainty from a set of sampled\npredictions. We visualize our bound on synthetic regression and classification\ndatasets. Furthermore, we demonstrate the effectiveness of TULiP using\nlarge-scale OOD detection benchmarks for image classification. Our method\nexhibits state-of-the-art performance, particularly for near-distribution\nsamples.",
    "pdf_url": "http://arxiv.org/pdf/2505.16923v2",
    "published": "2025-05-22T17:16:41+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16922v1",
    "title": "UNCLE: Uncertainty Expressions in Long-Form Generation",
    "authors": [
      "Ruihan Yang",
      "Caiqi Zhang",
      "Zhisong Zhang",
      "Xinting Huang",
      "Dong Yu",
      "Nigel Collier",
      "Deqing Yang"
    ],
    "abstract": "Large Language Models (LLMs) are prone to hallucination, particularly in\nlong-form generations. A promising direction to mitigate hallucination is to\nteach LLMs to express uncertainty explicitly when they lack sufficient\nknowledge. However, existing work lacks direct and fair evaluation of LLMs'\nability to express uncertainty effectively in long-form generation. To address\nthis gap, we first introduce UNCLE, a benchmark designed to evaluate\nuncertainty expression in both long- and short-form question answering (QA).\nUNCLE spans five domains and comprises 4k long-form QA instances and over 20k\nshort-form QA pairs. Our dataset is the first to directly bridge short- and\nlong-form QA with paired questions and gold-standard answers. Along with the\nbenchmark, we propose a suite of new metrics to assess the models' capabilities\nto selectively express uncertainty. Using UNCLE, we then demonstrate that\ncurrent models fail to convey uncertainty appropriately in long-form\ngeneration. We further explore both prompt-based and training-based methods to\nimprove models' performance, with the training-based methods yielding greater\ngains. Further analysis of alignment gaps between short- and long-form\nuncertainty expression highlights promising directions for future research\nusing UNCLE.",
    "pdf_url": "http://arxiv.org/pdf/2505.16922v1",
    "published": "2025-05-22T17:16:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16921v1",
    "title": "A NuSTAR study of quasi-periodic oscillations from the ultraluminous X-ray sources in M82",
    "authors": [
      "Hamza El Byad",
      "Matteo Bachetti",
      "Silvia Columbu",
      "Giuseppe Rodriguez",
      "Maura Pilia",
      "Matthew J. Middleton",
      "Dominic J Walton",
      "Murray Brightman",
      "Hannah Earnshaw",
      "Karl Forster",
      "Brian Grefenstette",
      "Felix Fürst",
      "Marianne Heida",
      "Matteo Imbrogno",
      "Eleonora Veronica Lai",
      "Thomas Maccarone"
    ],
    "abstract": "The study of quasi-periodic oscillations in X-ray binaries provides valuable\ninsights into the physics of accretion around compact objects. The M82 galaxy\nhosts two ultraluminous X-ray sources (ULXs), one of which is suspected to\nharbor an intermediate-mass black hole. Using 39 NuSTAR observations acquired\nbetween 2014--2024, we investigate the aperiodic X-ray variability in M82. In\nparticular, we study in detail the evolution of the QPO from M82 X-1 in the\nrange 20--300 mHz. We do not find additional timing features in the data,\nbesides a frequent broad noise component at lower frequencies. The QPO behaves\nsimilarly to other classes of low-frequency oscillations in accreting compact\nobjects, both black holes and neutron stars.",
    "pdf_url": "http://arxiv.org/pdf/2505.16921v1",
    "published": "2025-05-22T17:15:06+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM",
      "physics.data-an",
      "stat.AP"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16920v1",
    "title": "Scalar parity-odd trispectrum from gravitational Chern-Simons interaction vertices",
    "authors": [
      "Giorgio Orlando",
      "Shingo Akama",
      "Chunshan Lin"
    ],
    "abstract": "In this paper, we explore parity violation in a scalar trispectrum from a\ndynamical Chern-Simons gravity theory. So far, a graviton-mediated diagram with\ntwo vertexes being of general relativity has been studied in this theory by\ntaking into account the impact of a modified dispersion relation of gravitons\non graviton's bulk propagators. We instead study a parity-odd trispectrum from\nboth a graviton-mediated diagram, where one of the two vertexes originates from\nthe Chern-Simons term, and a contact diagram by using the bulk propagators in\ngeneral relativity. After computing the scalar-scalar-tensor cubic interactions\nand the scalar quartic ones originating from the Chern-Simons term, first we\nshow that the resultant parity-odd trispectrum vanishes in the case of\nBunch-Davies initial conditions, which is consistent with a no-go theorem for a\nnon-vanishing parity-odd trispectrum. Then, we discuss a way to acquire a\nnon-vanishing parity-odd trispectrum from the viewpoint of non-Bunch-Davies\ninitial conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16920v1",
    "published": "2025-05-22T17:14:54+00:00",
    "categories": [
      "hep-th",
      "astro-ph.CO"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16919v1",
    "title": "Hilbert space methods for approximating multi-output latent variable Gaussian processes",
    "authors": [
      "Soham Mukherjee",
      "Manfred Claassen",
      "Paul-Christian Bürkner"
    ],
    "abstract": "Gaussian processes are a powerful class of non-linear models, but have\nlimited applicability for larger datasets due to their high computational\ncomplexity. In such cases, approximate methods are required, for example, the\nrecently developed class of Hilbert space Gaussian processes. They have been\nshown to drastically reduce computation time while retaining most of the\nfavourable properties of exact Gaussian processes. However, Hilbert space\napproximations have so far only been developed for uni-dimensional outputs and\nmanifest (known) inputs. To this end, we generalise Hilbert space methods to\nmulti-output and latent input settings. Through extensive simulations, we show\nthat the developed approximate Gaussian processes are indeed not only faster,\nbut also provides similar or even better uncertainty calibration and accuracy\nof latent variable estimates compared to exact Gaussian processes. While not\nnecessarily faster than alternative Gaussian process approximations, our new\nmodels provide better calibration and estimation accuracy, thus striking an\nexcellent balance between trustworthiness and speed. We additionally validate\nour findings in a real world case study from single cell biology.",
    "pdf_url": "http://arxiv.org/pdf/2505.16919v1",
    "published": "2025-05-22T17:13:47+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.16918v1",
    "title": "Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype",
    "authors": [
      "Nikola Tankovic",
      "Robert Sajina"
    ],
    "abstract": "This paper presents a concise review of Contextual Multi-Armed Bandit (CMAB)\nmethods and introduces an experimental framework for scalable, interpretable\noffer selection, addressing the challenge of fast-changing offers. The approach\nmodels context at the product category level, allowing offers to span multiple\ncategories and enabling knowledge transfer across similar offers. This improves\nlearning efficiency and generalization in dynamic environments. The framework\nextends standard CMAB methodology to support multi-category contexts, and\nachieves scalability through efficient feature engineering and modular design.\nAdvanced features such as MPG (Member Purchase Gap) and MF (Matrix\nFactorization) capture nuanced user-offer interactions, with implementation in\nPython for practical deployment.\n  A key contribution is interpretability at scale: logistic regression models\nyield transparent weight vectors, accessible via a large language model (LLM)\ninterface for real-time, user-level tracking and explanation of evolving\npreferences. This enables the generation of detailed member profiles and\nidentification of behavioral patterns, supporting personalized offer\noptimization and enhancing trust in automated decisions. By situating our\nprototype alongside established paradigms like Generalized Linear Models and\nThompson Sampling, we demonstrate its value for both research and real-world\nCMAB applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16918v1",
    "published": "2025-05-22T17:13:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16917v1",
    "title": "Dynamical systems approach and cosmological attractors in newer general relativity",
    "authors": [
      "Manuel Hohmann",
      "Ulbossyn Ualikhanova"
    ],
    "abstract": "We study the cosmological dynamics of a class of symmetric teleparallel\ngravity theories known as ``newer general relativity'' using the methods of\ndynamical systems, restricted to the case of vacuum solutions with a spatially\nflat Friedmann-Lema\\^itre-Robertson-Walker metric. For the most general class\nof theories, we study generic properties of the solutions, in particular their\nfixed points, asymptotic behavior and effective dark energy. We then apply this\napproach to two phenomenologically motivated subclasses of theories, which we\nstudy in full detail. For these theories, we derive the complete space of\nsolutions and cosmological attractors, which we display in a number of phase\ndiagram. Depending on the particular theory at hand, we find different possible\nscenarios, including a turnaround followed by a big crunch, a big rip and an\neternally expanding universe whose Hubble parameter asymptotically approaches\nzero. It turns that this different behavior can be explained by the effective\ndark energy barotropic index, which shows either phantom or non-phantom\nbehavior, depending on the theory, but does not change dynamically between\nthese two possibilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.16917v1",
    "published": "2025-05-22T17:12:48+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16916v1",
    "title": "Backdoor Cleaning without External Guidance in MLLM Fine-tuning",
    "authors": [
      "Xuankun Rong",
      "Wenke Huang",
      "Jian Liang",
      "Jinhe Bi",
      "Xun Xiao",
      "Yiming Li",
      "Bo Du",
      "Mang Ye"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are increasingly deployed in\nfine-tuning-as-a-service (FTaaS) settings, where user-submitted datasets adapt\ngeneral-purpose models to downstream tasks. This flexibility, however,\nintroduces serious security risks, as malicious fine-tuning can implant\nbackdoors into MLLMs with minimal effort. In this paper, we observe that\nbackdoor triggers systematically disrupt cross-modal processing by causing\nabnormal attention concentration on non-semantic regions--a phenomenon we term\nattention collapse. Based on this insight, we propose Believe Your Eyes (BYE),\na data filtering framework that leverages attention entropy patterns as\nself-supervised signals to identify and filter backdoor samples. BYE operates\nvia a three-stage pipeline: (1) extracting attention maps using the fine-tuned\nmodel, (2) computing entropy scores and profiling sensitive layers via bimodal\nseparation, and (3) performing unsupervised clustering to remove suspicious\nsamples. Unlike prior defenses, BYE equires no clean supervision, auxiliary\nlabels, or model modifications. Extensive experiments across various datasets,\nmodels, and diverse trigger types validate BYE's effectiveness: it achieves\nnear-zero attack success rates while maintaining clean-task performance,\noffering a robust and generalizable solution against backdoor threats in MLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16916v1",
    "published": "2025-05-22T17:11:58+00:00",
    "categories": [
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16915v1",
    "title": "DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?",
    "authors": [
      "Qirui Jiao",
      "Daoyuan Chen",
      "Yilun Huang",
      "Xika Lin",
      "Ying Shen",
      "Yaliang Li"
    ],
    "abstract": "While recent text-to-image (T2I) models show impressive capabilities in\nsynthesizing images from brief descriptions, their performance significantly\ndegrades when confronted with long, detail-intensive prompts required in\nprofessional applications. We present DetailMaster, the first comprehensive\nbenchmark specifically designed to evaluate T2I models' systematical abilities\nto handle extended textual inputs that contain complex compositional\nrequirements. Our benchmark introduces four critical evaluation dimensions:\nCharacter Attributes, Structured Character Locations, Multi-Dimensional Scene\nAttributes, and Explicit Spatial/Interactive Relationships. The benchmark\ncomprises long and detail-rich prompts averaging 284.89 tokens, with high\nquality validated by expert annotators. Evaluation on 7 general-purpose and 5\nlong-prompt-optimized T2I models reveals critical performance limitations:\nstate-of-the-art models achieve merely ~50% accuracy in key dimensions like\nattribute binding and spatial reasoning, while all models showing progressive\nperformance degradation as prompt length increases. Our analysis highlights\nsystemic failures in structural comprehension and detail overload handling,\nmotivating future research into architectures with enhanced compositional\nreasoning. We open-source the dataset, data curation code, and evaluation tools\nto advance detail-rich T2I generation and enable broad applications that would\notherwise be infeasible due to the lack of a dedicated benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2505.16915v1",
    "published": "2025-05-22T17:11:27+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16914v1",
    "title": "Exposure measurement error correction in longitudinal studies with discrete outcomes",
    "authors": [
      "Ce Yang",
      "Ning Zhang",
      "Jiaxuan Li",
      "Unnati V. Mehta",
      "Jaime E. Hart",
      "Donna Spiegelman",
      "Molin Wang"
    ],
    "abstract": "Environmental epidemiologists are often interested in estimating the effect\nof time-varying functions of the exposure history on health outcomes. However,\nthe individual exposure measurements that constitute the history upon which an\nexposure history function is constructed are usually subject to measurement\nerrors. To obtain unbiased estimates of the effects of such mismeasured\nfunctions in longitudinal studies with discrete outcomes, a method applicable\nto the main study/validation study design is developed. Various estimation\nprocedures are explored. Simulation studies were conducted to assess its\nperformance compared to standard analysis, and we found that the proposed\nmethod had good performance in terms of finite sample bias reduction and\nnominal coverage probability improvement. As an illustrative example, we\napplied the new method to a study of long-term exposure to PM2.5, in relation\nto the occurrence of anxiety disorders in the Nurses Health Study II. Failing\nto correct the error-prone exposure can lead to an underestimation of the\nchronic exposure effect of PM2.5.",
    "pdf_url": "http://arxiv.org/pdf/2505.16914v1",
    "published": "2025-05-22T17:11:14+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.17168v1",
    "title": "Designing and Implementing Robust Test Automation Frameworks using Cucumber BDD and Java",
    "authors": [
      "Srikanth Srinivas",
      "Lagan Goel"
    ],
    "abstract": "Modern software development demands rapid, reliable testing methods to\nmaintain high quality in increasingly complex systems. This paper details a\ncomprehensive approach to designing and implementing robust test automation\nframeworks by leveraging Cucumber BDD with Java. By utilizing Cucumber BDD\nnatural language syntax, the framework enables clear communication between\ntechnical and non-technical team members, ensuring that requirements are\naccurately translated into executable tests. Java, renowned for its versatility\nand extensive libraries, serves as the backbone for creating scalable,\nmaintainable, and efficient test scripts. The framework described herein\nfocuses on modular architecture, facilitating re usability and streamlined\nmaintenance across diverse application domains. It systematically addresses\nchallenges such as test data management, dynamic environment handling, and\nintegration with continuous integration/continuous delivery pipelines.\nEmpirical evaluations demonstrate that this integrated approach not only\nreduces manual testing effort but also significantly enhances defect detection\nand overall software reliability. The methodology encourages the adoption of\nbest practices in test design, including clear documentation, iterative\ndevelopment, and automated reporting.",
    "pdf_url": "http://arxiv.org/pdf/2505.17168v1",
    "published": "2025-05-22T17:11:05+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16913v2",
    "title": "Quantum Systems with jump-discontinuous mass. I",
    "authors": [
      "Fabio Deelan Cunden",
      "Giovanni Gramegna",
      "Marilena Ligabò"
    ],
    "abstract": "We consider a free quantum particle in one dimension whose mass profile\nexhibits jump discontinuities. The corresponding Hamiltonian is realised as a\nself-adjoint extension of the kinetic energy operator formulated in divergence\nform, with the extension encoded in the boundary conditions at the mass\ndiscontinuity points. For a family of scale-free boundary conditions, we\nanalyse the associated spectral problem. We find that the eigenfunctions\nexhibit a highly sensitive and erratic dependence on the energy, leading to\nirregular spectral behaviour. Notably, the system supports infinitely many\ndistinct semiclassical limits, each labeled by a point on a spectral curve\nembedded in the two-torus. These results demonstrate a rich interplay between\ndiscontinuous coefficients, boundary data, and spectral asymptotics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16913v2",
    "published": "2025-05-22T17:10:53+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "math.SP",
      "nlin.CD",
      "quant-ph"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16912v2",
    "title": "UAV See, UGV Do: Aerial Imagery and Virtual Teach Enabling Zero-Shot Ground Vehicle Repeat",
    "authors": [
      "Desiree Fisker",
      "Alexander Krawciw",
      "Sven Lilge",
      "Melissa Greeff",
      "Timothy D. Barfoot"
    ],
    "abstract": "This paper presents Virtual Teach and Repeat (VirT&R): an extension of the\nTeach and Repeat (T&R) framework that enables GPS-denied, zero-shot autonomous\nground vehicle navigation in untraversed environments. VirT&R leverages aerial\nimagery captured for a target environment to train a Neural Radiance Field\n(NeRF) model so that dense point clouds and photo-textured meshes can be\nextracted. The NeRF mesh is used to create a high-fidelity simulation of the\nenvironment for piloting an unmanned ground vehicle (UGV) to virtually define a\ndesired path. The mission can then be executed in the actual target environment\nby using NeRF-generated point cloud submaps associated along the path and an\nexisting LiDAR Teach and Repeat (LT&R) framework. We benchmark the\nrepeatability of VirT&R on over 12 km of autonomous driving data using physical\nmarkings that allow a sim-to-real lateral path-tracking error to be obtained\nand compared with LT&R. VirT&R achieved measured root mean squared errors\n(RMSE) of 19.5 cm and 18.4 cm in two different environments, which are slightly\nless than one tire width (24 cm) on the robot used for testing, and respective\nmaximum errors were 39.4 cm and 47.6 cm. This was done using only the\nNeRF-derived teach map, demonstrating that VirT&R has similar closed-loop\npath-tracking performance to LT&R but does not require a human to manually\nteach the path to the UGV in the actual environment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16912v2",
    "published": "2025-05-22T17:10:28+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16911v2",
    "title": "Active Speech Enhancement: Active Speech Denoising Decliping and Deveraberation",
    "authors": [
      "Ofir Yaish",
      "Yehuda Mishaly",
      "Eliya Nachmani"
    ],
    "abstract": "We introduce a new paradigm for active sound modification: Active Speech\nEnhancement (ASE). While Active Noise Cancellation (ANC) algorithms focus on\nsuppressing external interference, ASE goes further by actively shaping the\nspeech signal -- both attenuating unwanted noise components and amplifying\nspeech-relevant frequencies -- to improve intelligibility and perceptual\nquality. To enable this, we propose a novel Transformer-Mamba-based\narchitecture, along with a task-specific loss function designed to jointly\noptimize interference suppression and signal enrichment. Our method outperforms\nexisting baselines across multiple speech processing tasks -- including\ndenoising, dereverberation, and declipping -- demonstrating the effectiveness\nof active, targeted modulation in challenging acoustic environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16911v2",
    "published": "2025-05-22T17:10:18+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16910v1",
    "title": "Elliptic curves of rank one over number fields",
    "authors": [
      "Peter Koymans",
      "Carlo Pagano"
    ],
    "abstract": "We prove that for every number field $K$, there exist infinitely many\nelliptic curves $E$ over $K$ with rank exactly equal to 1.",
    "pdf_url": "http://arxiv.org/pdf/2505.16910v1",
    "published": "2025-05-22T17:10:05+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16909v1",
    "title": "Braided categories of bimodules from stated skein TQFTs",
    "authors": [
      "Francesco Costantino",
      "Matthieu Faitg"
    ],
    "abstract": "For each braided category $\\mathcal{C}$ we show that, under mild hypotheses,\nthere is an associated category of \"half braided algebras\" and their bimodules\ninternal to $\\mathcal{C}$ which is not only monoidal but even braided and\nbalanced. We use this in the case where $\\mathcal{C}$ is the category of\nmodules over a ribbon Hopf algebra to interpret stated skeins as a TQFT, namely\na braided balanced functor from a category of cobordisms to this category of\nalgebras and their bimodules. Although our construction works in full\ngenerality, we relate in the special case of finite-dimensional ribbon\nfactorizable Hopf algebras the stated skein functor to the Kerler-Lyubashenko\nTQFT by interpreting the former as the \"endomorphisms\" of the latter.",
    "pdf_url": "http://arxiv.org/pdf/2505.16909v1",
    "published": "2025-05-22T17:09:48+00:00",
    "categories": [
      "math.QA",
      "math.GT"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16908v2",
    "title": "Is Circuit Depth Accurate for Comparing Quantum Circuit Runtimes?",
    "authors": [
      "Matthew Tremba",
      "Paul Hovland",
      "Ji Liu"
    ],
    "abstract": "Although quantum circuit depth is commonly used to approximate circuit\nruntimes, it overlooks a prevailing trait of current hardware implementation:\ndifferent gates have different execution times. Recognizing the potential for\ndiscrepancies, we investigate depth's accuracy for comparing runtimes between\ncompiled versions of the same circuit. In particular, we assess the accuracy of\ntraditional and multi-qubit depth for (1) predicting relative differences in\nruntime and (2) identifying compiled circuit version(s) with the shortest\nruntime. Finding that circuit depth is not accurate for either task, we\nintroduce a new metric, gate-aware depth, that weights gates' contributions to\nruntime using an architecture's average gate execution times. Using average\ngate times allows gate-aware depth to capture variations by gate type without\nrequiring exact knowledge of all gate times, increasing accuracy while\nmaintaining portability across devices of the same architecture. Compared to\ntraditional and multi-qubit depth, gate-aware depth reduces the average\nrelative error of predictions in task (1) by 68 and 18 times and increases the\naverage number of correct identifications in task (2) by 20 and 43 percentage\npoints, respectively. Finally, we provide gate-aware depth weight\nconfigurations for current IBM Eagle and Heron architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16908v2",
    "published": "2025-05-22T17:09:43+00:00",
    "categories": [
      "quant-ph",
      "cs.ET"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16907v1",
    "title": "Persistent homology of function spaces",
    "authors": [
      "Jonathan Block",
      "Fedor Manin",
      "Shmuel Weinberger"
    ],
    "abstract": "We can view the Lipschitz constant as a height function on the space of maps\nbetween two manifolds and ask (as Gromov did nearly 30 years ago) what its\n``Morse landscape'' looks like: are there high peaks, deep valleys and mountain\npasses? A simple and relatively well-studied version of this question: given\ntwo points in the same component (homotopic maps), does a path between them (a\nhomotopy) have to pass through maps of much higher Lipschitz constant? Now we\nalso consider similar questions for higher-dimensional cycles in the space. We\nmake this precise using the language of persistent homology and give some first\nresults.",
    "pdf_url": "http://arxiv.org/pdf/2505.16907v1",
    "published": "2025-05-22T17:07:20+00:00",
    "categories": [
      "math.AT",
      "math.DG",
      "math.MG",
      "53C23 (Primary), 55N31, 55P62, 55S37 (Secondary)"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16906v2",
    "title": "Higher order Jacobi method for solving system of linear equations",
    "authors": [
      "Nithin Kumar Goona",
      "Lama Tarsissi"
    ],
    "abstract": "This work proposes a higher-order iterative framework for solving matrix\nequations, inspired by the structure and functionality of neural networks. A\nmodification of the classical Jacobi iterative method is introduced to compute\nhigher-order coefficient matrices through matrix-matrix multiplications. The\nresulting method, termed the higher order Jacobi method (HOJM), structurally\nresembles a shallow linear network and allows direct computation of the inverse\nof the coefficient matrix. Building on this, an iterative scheme is developed\nthat allows efficient resolution of system variations without recomputing the\ncoefficients, once the network parameters are trained for a known system. This\niterative process naturally assumes the form of a deep recurrent neural\nnetwork. The proposed approach goes beyond conventional physics-informed neural\nnetworks (PINNs) by providing an explicit, training-free definition of network\nparameters rooted in physical and mathematical formulations. Computational\nanalysis on GPU reveals significant enhancement in the order of complexity,\nhighlighting a compelling and transformative direction for advancing\nalgorithmic efficiency in solving linear systems. This methodology opens\navenues for interpretable and scalable solutions to physically motivated\nproblems in computational science.",
    "pdf_url": "http://arxiv.org/pdf/2505.16906v2",
    "published": "2025-05-22T17:07:05+00:00",
    "categories": [
      "cond-mat.supr-con",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.16905v1",
    "title": "Accurate crystal field Hamiltonians of single-ion magnets at mean-field cost",
    "authors": [
      "Linqing Peng",
      "Shuanglong Liu",
      "Xing Zhang",
      "Xiao Chen",
      "Chenghan Li",
      "Hai-Ping Cheng",
      "Garnet Kin-Lic Chan"
    ],
    "abstract": "The effective crystal field Hamiltonian provides the key description of the\nelectronic properties of single-ion magnets, but obtaining its parameters from\nab initio computation is challenging. We introduce a simple approach to derive\nthe effective crystal field Hamiltonian through density functional calculations\nof randomly rotated mean-field states within the low-energy manifold. In\nbenchmarks on five lanthanide-based complexes, we find that we compute with\nmean-field cost an effective crystal field Hamiltonian that matches the\nstate-of-the-art from much more expensive multi-configurational quantum\nchemistry methods. In addition, we are able to reproduce the experimental\nlow-energy spectrum and magnetic properties with an accuracy exceeding prior\nattempts. Due to its low cost, our approach provides a crucial ingredient in\nthe computational design of single-ion magnets with tailored physical\nproperties and low-energy spectra.",
    "pdf_url": "http://arxiv.org/pdf/2505.16905v1",
    "published": "2025-05-22T17:06:25+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el",
      "physics.comp-ph",
      "quant-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16904v2",
    "title": "Well-Posedness for the Rosenzweig-MacArthur Model with Internal Stochasticity",
    "authors": [
      "Louis Shuo Wang",
      "Jiguang Yu"
    ],
    "abstract": "In this work, we propose a stochastic version of the Rosenzweig-MacArthur\nmodel solely driven by internal demographic noise, extending classical\nLotka-Volterra-type systems focused on external noise. We give a criterion for\nthe existence and uniqueness of autonomous stochastic differential equations\n(SDEs) on an open submanifold of $\\mathbb{R}^{n}$, and the framework allows for\na wider choice of Lyapunov functions. In the meantime, the invariance of open\nsubmanifolds, which is a biologically feasible result and has been implicitly\nincorporated into many biological and ecological models, facilitates the\napplication of analytic tools typically suited to $\\mathbb{R}^{d}$ and\nindicates the persistence of predator and prey populations, thus providing a\ncriterion for determining whether a population will become extinct. We apply\nthe well-posedness criterion to our stochastic Rosenzweig-MacArthur model and\nshow the existence and uniqueness of solutions. Furthermore, the asymptotic\nestimates of solutions are obtained, indicating the at most exponential growth\nof the population with internal stochasticity. Some numerical experiments are\nperformed, which illustrate the discrepancy between the deterministic and\nstochastic models. Overall, this work demonstrates the broad applicability of\nour results to ecological models with constrained dynamics, offering a\nfoundation for analyzing extinction, persistence, and well-posedness in systems\nwhere internal randomness dominates. This paper not only promotes the\ndevelopment of stochastic modeling and stochastic differential equations in\ntheoretical ecology but also proposes a rigorous mathematical methodology for\nstudying the predator-prey system with internal stochasticity.",
    "pdf_url": "http://arxiv.org/pdf/2505.16904v2",
    "published": "2025-05-22T17:05:43+00:00",
    "categories": [
      "math.PR",
      "math.DS",
      "34D20, 37H10, 37N25"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02004v1",
    "title": "Party Ideologies and Political Polarization-Driven Conflicts: A Study of the Global South",
    "authors": [
      "Shreyansh Padarha"
    ],
    "abstract": "Post-World War II armed conflicts have often been viewed with higher scrutiny\nin order to avoid a full-scale global war. This scrutiny has led to the\nestablishment of determinants of war such as poverty, inequalities, literacy,\nand many more. There is a gap that exists in probing countries in the Global\nSouth for political party fragmentation and examining ideology-driven\npolarization's effect on armed conflicts. This paper fills this gap by asking\nthe question: How does political identity-induced polarization affect conflicts\nin the Global South region? Polarization indices are created based on socially\nrelevant issues and party stances from the V-Party Dataset. Along with control\nvariables, they are tested against the response variables conflict frequency\nand conflict severity created from the UCDP (Uppsala Conflict Data Program).\nThrough Chow's test, Regional Structural Breaks are found between regions when\naccounting for polarization-conflict dynamics. A multilevel mixed effects\nmodelling approach is used to create region-specific models to find what types\nof polarization affect conflict in different geographies and their adherence to\nnormative current developments. The paper highlights that vulnerable regions of\nthe world are prone to higher polarization-induced violence. Modelling\nestimates indicate polarization of party credo on Minority Rights, Rejection of\nPolitical Violence, Religious Principles, and Political Pluralism are strong\nproponents of cultivated violence. The Global South's inhibitions and slow\nprogress towards development are caused by hindrances from armed conflicts;\nthis paper's results show self-inflicted political instability and\nfragmentation's influence on these events, making the case for urgency in\naddressing and building inter-group homogeneity and tolerance.",
    "pdf_url": "http://arxiv.org/pdf/2506.02004v1",
    "published": "2025-05-22T17:05:23+00:00",
    "categories": [
      "physics.soc-ph",
      "math.ST",
      "stat.AP",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16903v1",
    "title": "Unsupervised Prompting for Graph Neural Networks",
    "authors": [
      "Peyman Baghershahi",
      "Sourav Medya"
    ],
    "abstract": "Prompt tuning methods for Graph Neural Networks (GNNs) have become popular to\naddress the semantic gap between pre-training and fine-tuning steps. However,\nexisting GNN prompting methods rely on labeled data and involve lightweight\nfine-tuning for downstream tasks. Meanwhile, in-context learning methods for\nLarge Language Models (LLMs) have shown promising performance with no parameter\nupdating and no or minimal labeled data. Inspired by these approaches, in this\nwork, we first introduce a challenging problem setup to evaluate GNN prompting\nmethods. This setup encourages a prompting function to enhance a pre-trained\nGNN's generalization to a target dataset under covariate shift without updating\nthe GNN's parameters and with no labeled data. Next, we propose a fully\nunsupervised prompting method based on consistency regularization through\npseudo-labeling. We use two regularization techniques to align the prompted\ngraphs' distribution with the original data and reduce biased predictions.\nThrough extensive experiments under our problem setting, we demonstrate that\nour unsupervised approach outperforms the state-of-the-art prompting methods\nthat have access to labels.",
    "pdf_url": "http://arxiv.org/pdf/2505.16903v1",
    "published": "2025-05-22T17:03:20+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17167v1",
    "title": "CRG Score: A Distribution-Aware Clinical Metric for Radiology Report Generation",
    "authors": [
      "Ibrahim Ethem Hamamci",
      "Sezgin Er",
      "Suprosanna Shit",
      "Hadrien Reynaud",
      "Bernhard Kainz",
      "Bjoern Menze"
    ],
    "abstract": "Evaluating long-context radiology report generation is challenging. NLG\nmetrics fail to capture clinical correctness, while LLM-based metrics often\nlack generalizability. Clinical accuracy metrics are more relevant but are\nsensitive to class imbalance, frequently favoring trivial predictions. We\npropose the CRG Score, a distribution-aware and adaptable metric that evaluates\nonly clinically relevant abnormalities explicitly described in reference\nreports. CRG supports both binary and structured labels (e.g., type, location)\nand can be paired with any LLM for feature extraction. By balancing penalties\nbased on label distribution, it enables fairer, more robust evaluation and\nserves as a clinically aligned reward function.",
    "pdf_url": "http://arxiv.org/pdf/2505.17167v1",
    "published": "2025-05-22T17:02:28+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16902v1",
    "title": "RealEngine: Simulating Autonomous Driving in Realistic Context",
    "authors": [
      "Junzhe Jiang",
      "Nan Song",
      "Jingyu Li",
      "Xiatian Zhu",
      "Li Zhang"
    ],
    "abstract": "Driving simulation plays a crucial role in developing reliable driving agents\nby providing controlled, evaluative environments. To enable meaningful\nassessments, a high-quality driving simulator must satisfy several key\nrequirements: multi-modal sensing capabilities (e.g., camera and LiDAR) with\nrealistic scene rendering to minimize observational discrepancies; closed-loop\nevaluation to support free-form trajectory behaviors; highly diverse traffic\nscenarios for thorough evaluation; multi-agent cooperation to capture\ninteraction dynamics; and high computational efficiency to ensure affordability\nand scalability. However, existing simulators and benchmarks fail to\ncomprehensively meet these fundamental criteria. To bridge this gap, this paper\nintroduces RealEngine, a novel driving simulation framework that holistically\nintegrates 3D scene reconstruction and novel view synthesis techniques to\nachieve realistic and flexible closed-loop simulation in the driving context.\nBy leveraging real-world multi-modal sensor data, RealEngine reconstructs\nbackground scenes and foreground traffic participants separately, allowing for\nhighly diverse and realistic traffic scenarios through flexible scene\ncomposition. This synergistic fusion of scene reconstruction and view synthesis\nenables photorealistic rendering across multiple sensor modalities, ensuring\nboth perceptual fidelity and geometric accuracy. Building upon this\nenvironment, RealEngine supports three essential driving simulation categories:\nnon-reactive simulation, safety testing, and multi-agent interaction,\ncollectively forming a reliable and comprehensive benchmark for evaluating the\nreal-world performance of driving agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.16902v1",
    "published": "2025-05-22T17:01:00+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16901v4",
    "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks",
    "authors": [
      "Hongyuan Tao",
      "Ying Zhang",
      "Zhenhao Tang",
      "Hongen Peng",
      "Xukun Zhu",
      "Bingchang Liu",
      "Yingguang Yang",
      "Ziyin Zhang",
      "Zhaogui Xu",
      "Haipeng Zhang",
      "Linchao Zhu",
      "Rui Wang",
      "Hang Yu",
      "Jianguo Li",
      "Peng Di"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have shown promise in\nfunction-level code generation, yet repository-level software engineering tasks\nremain challenging. Current solutions predominantly rely on proprietary LLM\nagents, which introduce unpredictability and limit accessibility, raising\nconcerns about data privacy and model customization. This paper investigates\nwhether open-source LLMs can effectively address repository-level tasks without\nrequiring agent-based approaches. We demonstrate this is possible by enabling\nLLMs to comprehend functions and files within codebases through their semantic\ninformation and structural dependencies. To this end, we introduce Code Graph\nModels (CGMs), which integrate repository code graph structures into the LLM's\nattention mechanism and map node attributes to the LLM's input space using a\nspecialized adapter. When combined with an agentless graph RAG framework, our\napproach achieves a 43.00% resolution rate on the SWE-bench Lite benchmark\nusing the open-source Qwen2.5-72B model. This performance ranks first among\nopen weight models, second among methods with open-source systems, and eighth\noverall, surpassing the previous best open-source model-based method by 12.33%.",
    "pdf_url": "http://arxiv.org/pdf/2505.16901v4",
    "published": "2025-05-22T17:00:55+00:00",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16900v5",
    "title": "Power-Law Decay Loss for Large Language Model Finetuning: A Theory Perspective",
    "authors": [
      "Jintian Shao"
    ],
    "abstract": "During the finetuning stage of text generation tasks, standard cross-entropy\nloss treats all tokens equally. This can lead models to overemphasize\nhigh-frequency, low-information tokens, neglecting lower-frequency tokens\ncrucial for specificity and informativeness in generated content. This paper\nintroduces a novel loss function, Power-Law Decay Loss (PDL), specifically\ndesigned to optimize the finetuning process for text generation. The core\nmotivation for PDL stems from observations in information theory and\nlinguistics: the informativeness of a token is often inversely proportional to\nits frequency of occurrence. PDL re-weights the contribution of each token in\nthe standard cross-entropy loss based on its frequency in the training corpus,\nfollowing a power-law decay. Specifically, the weights for high-frequency\ntokens are reduced, while low-frequency, information-dense tokens are assigned\nhigher weights. This mechanism guides the model during finetuning to focus more\non learning and generating tokens that convey specific and unique information,\nthereby enhancing the quality, diversity, and informativeness of the generated\ntext. We theoretically elaborate on the motivation and construction of PDL and\ndiscuss its potential applications and advantages across various text\ngeneration finetuning tasks, such as abstractive summarization, dialogue\nsystems, and style transfer.",
    "pdf_url": "http://arxiv.org/pdf/2505.16900v5",
    "published": "2025-05-22T16:59:26+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16899v1",
    "title": "Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships",
    "authors": [
      "Kerem Oktar",
      "Katherine M. Collins",
      "Jose Hernandez-Orallo",
      "Diane Coyle",
      "Stephen Cave",
      "Adrian Weller",
      "Ilia Sucholutsky"
    ],
    "abstract": "Artificial Intelligence (AI) systems have historically been used as tools\nthat execute narrowly defined tasks. Yet recent advances in AI have unlocked\npossibilities for a new class of models that genuinely collaborate with humans\nin complex reasoning, from conceptualizing problems to brainstorming solutions.\nSuch AI thought partners enable novel forms of collaboration and extended\ncognition, yet they also pose major risks-including and beyond risks of typical\nAI tools and agents. In this commentary, we systematically identify risks of AI\nthought partners through a novel framework that identifies risks at multiple\nlevels of analysis, including Real-time, Individual, and Societal risks arising\nfrom collaborative cognition (RISc). We leverage this framework to propose\nconcrete metrics for risk evaluation, and finally suggest specific mitigation\nstrategies for developers and policymakers. As AI thought partners continue to\nproliferate, these strategies can help prevent major harms and ensure that\nhumans actively benefit from productive thought partnerships.",
    "pdf_url": "http://arxiv.org/pdf/2505.16899v1",
    "published": "2025-05-22T16:58:48+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16898v2",
    "title": "Active Quantum Reservoir Engineering: Using a Qubit to Manipulate its Environment",
    "authors": [
      "Marcelo Janovitch",
      "Matteo Brunelli",
      "Patrick P. Potts"
    ],
    "abstract": "Quantum reservoir engineering leverages dissipative processes to achieve\ndesired behavior, with applications ranging from entanglement generation to\nquantum error correction. Therein, a structured environment acts as an entropy\nsink for the system and no time-dependent control over the system is required.\nWe develop a theoretical framework for active reservoir engineering, where\ntime-dependent control over a quantum system is used to manipulate its\nenvironment. In this case, the system may act as an entropy sink for the\nenvironment. Our framwork captures the dynamical interplay between system and\nenvironment, and provides an intuitive picture of how finite-size effects and\nsystem-environment correlations allow for manipulating the environment by\nrepeated initialization of the quantum system. We illustrate our results with\ntwo examples: a superconducting qubit coupled to an environment of two-level\nsystems and a semiconducting quantum dot coupled to nuclear spins. In both\nscenarios, we find qualitative agreement with previous experimental results,\nillustrating how active control can unlock new functionalities in open quantum\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16898v2",
    "published": "2025-05-22T16:58:24+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16897v1",
    "title": "Derivative coupling in horizon brightened acceleration radiation: a quantum optics approach",
    "authors": [
      "Ashmita Das",
      "Anjana Krishnan",
      "Soham Sen",
      "Sunandan Gangopadhyay"
    ],
    "abstract": "Horizon Brightened Acceleration Radiation (HBAR) signifies a unique radiation\nprocess and provides a promising framework in exploring acceleration radiation\nin flat/ curved spacetime. Its construction primarily relies on the transition\nprobability of an atom falling through a high-Q cavity while interacting with a\nquantum field. The HBAR effect has typically been explored in the context of\nminimal coupling between the atom and the field amplitude. However, the\nminimally coupled models are affected by the infrared (IR) divergences that\narise in the massless limit of the quantum fields in (1+1) dimensions. Thus, in\nthe present manuscript, we examine the HBAR process using both the point-like\nand finite size detectors coupled with the momentum of the field, which plays a\ncrucial role in naturally resolving IR divergences. Our results suggest that\nthe transition probability for the point-like detector is independent of its\nfrequency. This can be interpreted as the influence of the local gravitational\nfield which modifies the sensitivity of the detector to its frequency and\nbroadens its effective frequency range. Through a comparative study based on\nthe length of the detector, we find that for a detector with a smaller length,\nthe steady state solution for the density matrix of the field vanishes. This\nmay indicate the existence of a non equilibrium thermodynamic state under the\ncondition of finite size detector-field interaction. These distinctive features\nare exclusive to the derivative coupling between the atom and the field,\nhighlighting them as a compelling subject for future investigation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16897v1",
    "published": "2025-05-22T16:58:22+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16896v1",
    "title": "Structure-Aligned Protein Language Model",
    "authors": [
      "Can Chen",
      "David Heurtel-Depeiges",
      "Robert M. Vernon",
      "Christopher James Langmead",
      "Yoshua Bengio",
      "Quentin Fournier"
    ],
    "abstract": "Protein language models (pLMs) pre-trained on vast protein sequence databases\nexcel at various downstream tasks but lack the structural knowledge essential\nfor many biological applications. To address this, we integrate structural\ninsights from pre-trained protein graph neural networks (pGNNs) into pLMs\nthrough a latent-level contrastive learning task. This task aligns residue\nrepresentations from pLMs with those from pGNNs across multiple proteins,\nenriching pLMs with inter-protein structural knowledge. Additionally, we\nincorporate a physical-level task that infuses intra-protein structural\nknowledge by optimizing pLMs to predict structural tokens. The proposed\ndual-task framework effectively incorporates both inter-protein and\nintra-protein structural knowledge into pLMs. Given the variability in the\nquality of protein structures in PDB, we further introduce a residue loss\nselection module, which uses a small model trained on high-quality structures\nto select reliable yet challenging residue losses for the pLM to learn.\nApplying our structure alignment method to the state-of-the-art ESM2 and\nAMPLIFY results in notable performance gains across a wide range of tasks,\nincluding a 12.7% increase in ESM2 contact prediction. The data, code, and\nresulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.",
    "pdf_url": "http://arxiv.org/pdf/2505.16896v1",
    "published": "2025-05-22T16:56:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18211v1",
    "title": "Degradation of methylparaben by anodic oxidation, electro-Fenton, and photoelectro-Fenton using carbon felt-BDD cell",
    "authors": [
      "Aline B. Trench",
      "Nihal Oturan",
      "Aydeniz Demir",
      "João P. C. Moura",
      "Clément Trellu",
      "Mauro C. Santos",
      "Mehmet A. Oturan"
    ],
    "abstract": "In this study, the comparative efficiency of different electrochemical\nadvanced oxidation processes, such as anodic oxidation with electrogenerated\nH2O2 (AO- H2O2), electro-Fenton (EF), and its combination with UV irradiation\n(photoelectron-Fenton (PEF)), was investigated for the removal of methylparaben\n(MP) using a carbon felt cathode and a boron-doped diamond anode. The EF\nprocess achieved a higher MP removal efficiency than the AO-H2O2 process for\nall applied current densities. The total organic carbon (TOC) removal after 6 h\nof treatment at a current density of 10 mA cm-2 reached 75.0% and 91.9% for the\nAO- H2O2 and EF processes, respectively. The combination of EF and UV light\nimproved the efficiency of the EF process. The PEF process achieved a TOC\nremoval of 84.6% in only 2 h at 5 mA cm-2 and 96.8% after 6 h of treatment.\nFurthermore, based on identifying oxidation reaction intermediates and\nshort-chain carboxylic acids generated during the treatment, a reaction pathway\nfor methylparaben mineralization by hydroxyl radicals was proposed.",
    "pdf_url": "http://arxiv.org/pdf/2505.18211v1",
    "published": "2025-05-22T16:54:40+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21729v1",
    "title": "Bridging the Narrative Divide: Cross-Platform Discourse Networks in Fragmented Ecosystems",
    "authors": [
      "Patrick Gerard",
      "Hans W. A. Hanley",
      "Luca Luceri",
      "Emilio Ferrara"
    ],
    "abstract": "Political discourse has grown increasingly fragmented across different social\nplatforms, making it challenging to trace how narratives spread and evolve\nwithin such a fragmented information ecosystem. Reconstructing social graphs\nand information diffusion networks is challenging, and available strategies\ntypically depend on platform-specific features and behavioral signals which are\noften incompatible across systems and increasingly restricted. To address these\nchallenges, we present a platform-agnostic framework that allows to accurately\nand efficiently reconstruct the underlying social graph of users'\ncross-platform interactions, based on discovering latent narratives and users'\nparticipation therein. Our method achieves state-of-the-art performance in key\nnetwork-based tasks: information operation detection, ideological stance\nprediction, and cross-platform engagement\nprediction$\\unicode{x2013}$$\\unicode{x2013}$while requiring significantly less\ndata than existing alternatives and capturing a broader set of users. When\napplied to cross-platform information dynamics between Truth Social and X\n(formerly Twitter), our framework reveals a small, mixed-platform group of\n$\\textit{bridge users}$, comprising just 0.33% of users and 2.14% of posts, who\nintroduce nearly 70% of $\\textit{migrating narratives}$ to the receiving\nplatform. These findings offer a structural lens for anticipating how\nnarratives traverse fragmented information ecosystems, with implications for\ncross-platform governance, content moderation, and policy interventions.",
    "pdf_url": "http://arxiv.org/pdf/2505.21729v1",
    "published": "2025-05-22T16:53:52+00:00",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16895v1",
    "title": "Quantum circuits for partial differential equations in Fourier space",
    "authors": [
      "Michael Lubasch",
      "Yuta Kikuchi",
      "Lewis Wright",
      "Conor Mc Keever"
    ],
    "abstract": "For the solution of partial differential equations (PDEs), we show that the\nquantum Fourier transform (QFT) can enable the design of quantum circuits that\nare particularly simple, both conceptually and with regard to hardware\nrequirements. This is shown by explicit circuit constructions for the\nincompressible advection, heat, isotropic acoustic wave, and Poisson's\nequations as canonical examples. We utilize quantum singular value\ntransformation to develop circuits that are expected to be of optimal\ncomputational complexity. Additionally, we consider approximations suited for\nsmooth initial conditions and describe circuits that make lower demands on\nhardware. The simple QFT-based circuits are efficient with respect to\ndimensionality and pave the way for current quantum computers to solve\nhigh-dimensional PDEs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16895v1",
    "published": "2025-05-22T16:53:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16894v1",
    "title": "Shadows in the Attention: Contextual Perturbation and Representation Drift in the Dynamics of Hallucination in LLMs",
    "authors": [
      "Zeyu Wei",
      "Shuo Wang",
      "Xiaohui Rong",
      "Xuemin Liu",
      "He Li"
    ],
    "abstract": "Hallucinations -- plausible yet erroneous outputs -- remain a critical\nbarrier to reliable deployment of large language models (LLMs). We present the\nfirst systematic study linking hallucination incidence to internal-state drift\ninduced by incremental context injection. Using TruthfulQA, we construct two\n16-round \"titration\" tracks per question: one appends relevant but partially\nflawed snippets, the other injects deliberately misleading content. Across six\nopen-source LLMs, we track overt hallucination rates with a tri-perspective\ndetector and covert dynamics via cosine, entropy, JS and Spearman drifts of\nhidden states and attention maps. Results reveal (1) monotonic growth of\nhallucination frequency and representation drift that plateaus after 5--7\nrounds; (2) relevant context drives deeper semantic assimilation, producing\nhigh-confidence \"self-consistent\" hallucinations, whereas irrelevant context\ninduces topic-drift errors anchored by attention re-routing; and (3)\nconvergence of JS-Drift ($\\sim0.69$) and Spearman-Drift ($\\sim0$) marks an\n\"attention-locking\" threshold beyond which hallucinations solidify and become\nresistant to correction. Correlation analyses expose a seesaw between\nassimilation capacity and attention diffusion, clarifying size-dependent error\nmodes. These findings supply empirical foundations for intrinsic hallucination\nprediction and context-aware mitigation mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.16894v1",
    "published": "2025-05-22T16:50:58+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16893v2",
    "title": "Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference",
    "authors": [
      "Shuichi Nishino",
      "Tomohiro Shiraishi",
      "Teruyuki Katsuoka",
      "Ichiro Takeuchi"
    ],
    "abstract": "Graph Neural Networks (GNNs) have gained prominence for their ability to\nprocess graph-structured data across various domains. However, interpreting GNN\ndecisions remains a significant challenge, leading to the adoption of saliency\nmaps for identifying salient subgraphs composed of influential nodes and edges.\nDespite their utility, the reliability of GNN saliency maps has been\nquestioned, particularly in terms of their robustness to input noise. In this\nstudy, we propose a statistical testing framework to rigorously evaluate the\nsignificance of saliency maps. Our main contribution lies in addressing the\ninflation of the Type I error rate caused by double-dipping of data, leveraging\nthe framework of Selective Inference. Our method provides statistically valid\n$p$-values while controlling the Type I error rate, ensuring that identified\nsalient subgraphs contain meaningful information rather than random artifacts.\nThe method is applicable to a variety of saliency methods with piecewise\nlinearity (e.g., Class Activation Mapping). We validate our method on synthetic\nand real-world datasets, demonstrating its capability in assessing the\nreliability of GNN interpretations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16893v2",
    "published": "2025-05-22T16:50:55+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16892v2",
    "title": "FlashBack: Consistency Model-Accelerated Shared Autonomy",
    "authors": [
      "Luzhe Sun",
      "Jingtian Ji",
      "Xiangshan Tan",
      "Matthew R. Walter"
    ],
    "abstract": "Shared autonomy is an enabling technology that provides users with control\nauthority over robots that would otherwise be difficult if not impossible to\ndirectly control. Yet, standard methods make assumptions that limit their\nadoption in practice-for example, prior knowledge of the user's goals or the\nobjective (i.e., reward) function that they wish to optimize, knowledge of the\nuser's policy, or query-level access to the user during training.\nDiffusion-based approaches to shared autonomy do not make such assumptions and\ninstead only require access to demonstrations of desired behaviors, while\nallowing the user to maintain control authority. However, these advantages have\ncome at the expense of high computational complexity, which has made real-time\nshared autonomy all but impossible. To overcome this limitation, we propose\nConsistency Shared Autonomy (CSA), a shared autonomy framework that employs a\nconsistency model-based formulation of diffusion. Key to CSA is that it employs\nthe distilled probability flow of ordinary differential equations (PF ODE) to\ngenerate high-fidelity samples in a single step. This results in inference\nspeeds significantly than what is possible with previous diffusion-based\napproaches to shared autonomy, enabling real-time assistance in complex domains\nwith only a single function evaluation. Further, by intervening on flawed\nactions at intermediate states of the PF ODE, CSA enables varying levels of\nassistance. We evaluate CSA on a variety of challenging simulated and\nreal-world robot control problems, demonstrating significant improvements over\nstate-of-the-art methods both in terms of task performance and computational\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.16892v2",
    "published": "2025-05-22T16:50:53+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16891v2",
    "title": "Quantum Compiler Design for Qubit Mapping and Routing: A Cross-Architectural Survey of Superconducting, Trapped-Ion, and Neutral Atom Systems",
    "authors": [
      "Chenghong Zhu",
      "Xian Wu",
      "Zhaohui Yang",
      "Jingbo Wang",
      "Anbang Wu",
      "Shenggen Zheng",
      "Xin Wang"
    ],
    "abstract": "Quantum hardware development is progressing rapidly with substantial\nadvancements achieved across leading platforms, including superconducting\ncircuits, trapped-ion systems, and neutral atom arrays. As the pursuit of\npractical quantum advantage continues, efficient quantum program compilation\nbecomes essential for transforming high-level representations of quantum\nalgorithms into physically executable circuits. A fundamental challenge in this\nprocess is qubit mapping and gate scheduling, which play a critical role in\nadapting compiled circuits to the architectural constraints and physical\nlimitations of specific quantum hardware. In this survey, we systematically\nreview and categorize research on the qubit mapping and routing problems across\nthe three mainstream quantum hardware platforms. We primarily explore the\ndevelopment of hardware-aware compilers for superconducting platforms,\nclassifying existing methods into solver-based, heuristic-based, and machine\nlearning-based approaches, and analyze their optimization targets, including\ngate count, circuit duration, fidelity, and scalability. Furthermore, we\nexamine the evolution of trapped-ion and neutral atom devices, analyzing the\ndistinct challenges posed by their hardware characteristics and highlighting\nspecialized compilers tailored to these unique physical constraints. Finally,\nwe summarize the key challenges and identify some promising opportunities for\nfuture research in quantum compiler design across these hardware platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.16891v2",
    "published": "2025-05-22T16:49:57+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16890v3",
    "title": "Inkspot: A stress-resilient, anthocyanin rich, dwarf tomato variant for off-world cultivation",
    "authors": [
      "Sarah Lang",
      "A'nya Buckner",
      "Solomon Jones",
      "Gabrielle Erwin",
      "Sally Lee",
      "Rafael Loureiro"
    ],
    "abstract": "As humanity prepares for sustained off-world habitation, the development of\nregolith-based agriculture (RBA) is essential for achieving self-sufficiency in\nspace crop production. However, lunar regolith's alkaline pH, poor water\nretention, and high metal content pose severe physiological and biochemical\nchallenges to plant growth. This study evaluates the performance of Solanum\nlycopersicum 'Inkspot', a stress-adaptive, anthocyanin-rich tomato variant, in\ncomparison to its progenitor 'Tiny Tim', under control and simulated lunar\nregolith (LHS-2) conditions. A randomized complete block design was used to\nassess germination dynamics, morphology, fruit quality, antioxidant activity,\nand root architecture across 80 replicates over 65 days in controlled chambers.\nInkspot maintained high germination rates (85% in regolith) with low variation\n(CV = 14%) and showed only moderate reductions in height and biomass, while\nTiny Tim suffered a 45% biomass reduction and 60% fruit yield loss. Inkspot\nfruits increased anthocyanin content 2.5-fold in regolith, functioning as a\nstress-response mechanism and potential bioindicator. Physiological assessments\nrevealed greater retention of chlorophyll, Fv/Fm efficiency, and stomatal\nconductance in Inkspot, correlated with higher SOD and CAT enzyme activity and\nlower lipid peroxidation. Root imaging showed Inkspot developed a significantly\nlarger, more complex root system, while Tiny Tim's roots contracted under\nstress. These findings highlight Inkspot's abiotic stress tolerance and\npotential as a candidate for closed-loop life support and in-situ resource\nutilization strategies in RBA systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16890v3",
    "published": "2025-05-22T16:47:59+00:00",
    "categories": [
      "q-bio.OT"
    ],
    "primary_category": "q-bio.OT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16889v1",
    "title": "Quantum-to-classical transition and the emergence of quantum Darwinism with measurements distributed in time -- a path integral approach",
    "authors": [
      "Harsh Arora",
      "Bishal Kumar Das",
      "Baladitya Suri",
      "Vaibhav Madhok"
    ],
    "abstract": "We present a new formulation for the emergence of classical dynamics in a\nquantum world by considering a path integral approach that also incorporates\ncontinuous measurements. Our program is conceptually different from the\ndecoherence program as well as the quantum-to-classical transition framework\nwith coarse-grained measurements. The path integral formulation provides the\njoint statistics of a sequence of measurements with each Feynman path picking\nup an additional random phase due to measurements. The magnitude of this phase\nis proportional to the measurement strength, and we give conditions under which\nthe dominant contribution to the probability amplitude comes from the\ntrajectories in the vicinity of the classical paths. The proliferation of this\ninformation accross the environment, an essential feature of quantum Darwinism,\ntakes place via scattering of plane-wave probes by the system. Extending to\nrepeated measurements, we show that in the continuous limit, each system\ntrajectory picks up an additional phase due to work done by the momentum kicks\nfrom the probes - origin of the back-action force. We provide conditions for\nwhich the measurement provides sufficient ''which-path\" information and keeps\nthe wave packet sufficiently localized. This allows for description of\nquantum-to-classical transition at the level of individual trajectories in\ncontrast to the statistical ensemble interpretation provided by density\nmatrices in the decoherence program.",
    "pdf_url": "http://arxiv.org/pdf/2505.16889v1",
    "published": "2025-05-22T16:47:51+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16888v2",
    "title": "CAIN: Hijacking LLM-Humans Conversations via Malicious System Prompts",
    "authors": [
      "Viet Pham",
      "Thai Le"
    ],
    "abstract": "Large language models (LLMs) have advanced many applications, but are also\nknown to be vulnerable to adversarial attacks. In this work, we introduce a\nnovel security threat: hijacking AI-human conversations by manipulating LLMs'\nsystem prompts to produce malicious answers only to specific targeted questions\n(e.g., \"Who should I vote for US President?\", \"Are Covid vaccines safe?\"),\nwhile behaving benignly on others. This attack is detrimental as it can enable\nmalicious actors to exercise large-scale information manipulation by spreading\nharmful but benign-looking system prompts online. To demonstrate such an\nattack, we develop CAIN, an algorithm that can automatically curate such\nharmful system prompts for a specific target question in a black-box setting or\nwithout the need to access the LLM's parameters. Evaluated on both open-source\nand commercial LLMs, CAIN demonstrates significant adversarial impact. In\nuntargeted attacks or forcing LLMs to output incorrect answers, CAIN achieves\nup to 40% F1 degradation on targeted questions while preserving high accuracy\non benign inputs. For targeted attacks or forcing LLMs to output specific\nharmful answers, CAIN achieves over 70% F1 scores on these targeted responses\nwith minimal impact on benign questions. Our results highlight the critical\nneed for enhanced robustness measures to safeguard the integrity and safety of\nLLMs in real-world applications. All source code will be publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.16888v2",
    "published": "2025-05-22T16:47:15+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16887v1",
    "title": "Hydrogen peroxide electrogeneration from O2 electroreduction: a review focusing on carbon electrocatalysts and environmental applications",
    "authors": [
      "Aline B. Trench",
      "Caio Machado Fernandes",
      "João Paulo C. Moura",
      "Lanna E. B. Lucchetti",
      "Thays S. Lima",
      "Vanessa S. Antonin",
      "James M. de Almeida",
      "Pedro Autreto",
      "Irma Robles",
      "Artur J. Motheo",
      "Marcos R. V. Lanza",
      "Mauro C. Santos"
    ],
    "abstract": "Hydrogen peroxide (H2O2) stands as one of the foremost utilized oxidizing\nagents in modern times. The established method for its production involves the\nintricate and costly anthraquinone process. However, a promising alternative\npathway is the electrochemical hydrogen peroxide production, accomplished\nthrough the oxygen reduction reaction via a 2-electron pathway. This method not\nonly simplifies the production process but also upholds environmental\nsustainability, especially when compared to the conventional anthraquinone\nmethod. In this review paper, recent works from the literature focusing on the\n2-electron oxygen reduction reaction promoted by carbon electrocatalysts are\nsummarized. The practical applications of these materials in the treatment of\neffluents contaminated with different pollutants (drugs, dyes, pesticides, and\nherbicides) are presented. Water treatment aiming to address these issues can\nbe achieved through advanced oxidation electrochemical processes such as\nelectro-Fenton, solar-electro-Fenton, and photo-electro-Fenton. These processes\nare discussed in detail in this work and the possible radicals that degrade the\npollutants in each case are highlighted. The review broadens its scope to\nencompass contemporary computational simulations focused on the 2-electron\noxygen reduction reaction, employing different models to describe carbon-based\nelectrocatalysts. Finally, perspectives and future challenges in the area of\ncarbon-based electrocatalysts for H2O2 electrogeneration are discussed. This\nreview paper presents a forward-oriented viewpoint of present innovations and\npragmatic implementations, delineating forthcoming challenges and prospects of\nthis ever-evolving field.",
    "pdf_url": "http://arxiv.org/pdf/2505.16887v1",
    "published": "2025-05-22T16:46:31+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16886v1",
    "title": "Don't \"Overthink\" Passage Reranking: Is Reasoning Truly Necessary?",
    "authors": [
      "Nour Jedidi",
      "Yung-Sung Chuang",
      "James Glass",
      "Jimmy Lin"
    ],
    "abstract": "With the growing success of reasoning models across complex natural language\ntasks, researchers in the Information Retrieval (IR) community have begun\nexploring how similar reasoning capabilities can be integrated into passage\nrerankers built on Large Language Models (LLMs). These methods typically employ\nan LLM to produce an explicit, step-by-step reasoning process before arriving\nat a final relevance prediction. But, does reasoning actually improve reranking\naccuracy? In this paper, we dive deeper into this question, studying the impact\nof the reasoning process by comparing reasoning-based pointwise rerankers\n(ReasonRR) to standard, non-reasoning pointwise rerankers (StandardRR) under\nidentical training conditions, and observe that StandardRR generally\noutperforms ReasonRR. Building on this observation, we then study the\nimportance of reasoning to ReasonRR by disabling its reasoning process\n(ReasonRR-NoReason), and find that ReasonRR-NoReason is surprisingly more\neffective than ReasonRR. Examining the cause of this result, our findings\nreveal that reasoning-based rerankers are limited by the LLM's reasoning\nprocess, which pushes it toward polarized relevance scores and thus fails to\nconsider the partial relevance of passages, a key factor for the accuracy of\npointwise rerankers.",
    "pdf_url": "http://arxiv.org/pdf/2505.16886v1",
    "published": "2025-05-22T16:41:37+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16885v1",
    "title": "Bose-Einstein condensation in exotic lattice geometries",
    "authors": [
      "Kamil Dutkiewicz",
      "Marcin Płodzień",
      "Abel Rojo-Francàs",
      "Bruno Juliá-Díaz",
      "Maciej Lewenstein",
      "Tobias Grass"
    ],
    "abstract": "Modern quantum engineering techniques allow for synthesizing quantum systems\nin exotic lattice geometries, from self-similar fractal networks to negatively\ncurved hyperbolic graphs. We demonstrate that these structures profoundly\nreshape Bose-Einstein condensation. Fractal lattices dramatically lower the\ncondensation temperature, while hyperbolic lattices cause it to increase as the\nsystem grows - a behavior not seen in ordinary two-dimensional arrays, where\nthe condensation temperature vanishes in the large-size limit. The underlying\ngeometry also controls condensate fluctuations, enhancing them on fractal\nnetworks but suppressing them on hyperbolic graphs compared with regular\none-dimensional or two-dimensional lattices. When strong repulsive interactions\nare included, the gas enters a Mott insulating state. A multi-site Gutzwiller\napproach finds a smooth interpolation between the characteristic insulating\nlobes of one-dimensional and two-dimensional systems. Re-entrant Mott\ntransitions are seen within a first-order resummed hopping expansion. Our\nfindings establish lattice geometry as a powerful tuning knob for quantum phase\nphenomena and pave the way for experimental exploration in photonic waveguide\narrays and Rydberg-atom tweezer arrays.",
    "pdf_url": "http://arxiv.org/pdf/2505.16885v1",
    "published": "2025-05-22T16:40:22+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.16884v1",
    "title": "Periodic Variability in Space Photometry of 181 New Supermassive Black Hole Binary Candidates",
    "authors": [
      "Pablo Huijse",
      "Jordy Davelaar",
      "Joris De Ridder",
      "Nicholas Jannsen",
      "Conny Aerts"
    ],
    "abstract": "Robust detections of supermassive black hole binaries (SMBHBs) are essential\nto unravel the role of galaxy mergers in galaxy evolution and for identifying\npotential sources of low-frequency gravitational waves. One of the most\ncommonly used observational signatures of SMBHBs is periodic variability in the\nlight curves of active galactic nuclei (AGN), which may arise from accretion\nrate modulation or relativistic Doppler boosting due to binary orbital motion.\nHowever, intrinsic stochastic AGN variability can mimic such periodic signals,\ncomplicating robust identification. We report the discovery of 181 new SMBHB\ncandidates from a sample of approximately 770,000 AGN observed by the Gaia\nspace observatory. Periodic signals were identified using a novel and\ncomputationally efficient Bayesian model selection framework, enabling unbiased\nsource selection and quantifying the likelihood of periodicity over stochastic\nvariability. These candidates nearly double the known SMBHB population and\nprovide a prioritized target list for next-generation time-domain surveys.",
    "pdf_url": "http://arxiv.org/pdf/2505.16884v1",
    "published": "2025-05-22T16:37:03+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16883v2",
    "title": "Test-Field vs Physical Quasi-Normal Modes in Scalar-Tensor Theories",
    "authors": [
      "Alexandre Arbey",
      "Etera R. Livine",
      "Clara Montagnon"
    ],
    "abstract": "In the context of the general effort to model black hole dynamics, and in\nparticular their return-to-equilibrium through quasi-normal modes, it is\ncrucial to understand how much test-field perturbations deviate from physical\nperturbations in modified gravity scenarios. On the one hand, physical\nperturbations follow the modified Einstein equations of the considered\nextension of general relativity. The complexity of those equations can quickly\nescalate with extra fields and non-linear couplings. On the other hand,\ntest-field perturbations, with negligible back-reaction on the space-time\ngeometry, describe the propagation of both matter fields and spin $s=2$\ngravitational waves on the black hole geometry. They are not subject to the\nintricacies of the modified Einstein equations, and only probe the background\nspacetime metric. If their physics were to not deviate significantly from\nphysical perturbations, they would be especially useful to investigate\npredictions from quantum gravity scenarios which lack explicit detailed\nEinstein equations.\n  Here we focus on a specific modified gravity solution -- BCL black holes in\nscalar-tensor theories -- for which physical perturbations and related QNM\nfrequencies have already been studied and computed numerically. We compute the\ntest-field QNM frequencies and compare the two QNM spectra. This provides a\nconcrete example of the significant differences arising between test-fields and\nphysical perturbations, and flags unphysical deviations related to the\ntest-field framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.16883v2",
    "published": "2025-05-22T16:36:53+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16882v2",
    "title": "Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga)",
    "authors": [
      "Isla Duporge",
      "Sofia Minano",
      "Nikoloz Sirmpilatze",
      "Igor Tatarnikov",
      "Scott Wolf",
      "Adam L. Tyson",
      "Daniel Rubenstein"
    ],
    "abstract": "Ethological research increasingly benefits from the growing affordability and\naccessibility of drones, which enable the capture of high-resolution footage of\nanimal movement at fine spatial and temporal scales. However, analyzing such\nfootage presents the technical challenge of separating animal movement from\ndrone motion. While non-trivial, computer vision techniques such as image\nregistration and Structure-from-Motion (SfM) offer practical solutions. For\nconservationists, open-source tools that are user-friendly, require minimal\nsetup, and deliver timely results are especially valuable for efficient data\ninterpretation. This study evaluates three approaches: a bioimaging-based\nregistration technique, an SfM pipeline, and a hybrid interpolation method. We\napply these to a recorded escape event involving 44 plains zebras, captured in\na single drone video. Using the best-performing method, we extract individual\ntrajectories and identify key behavioral patterns: increased alignment\n(polarization) during escape, a brief widening of spacing just before stopping,\nand tighter coordination near the group's center. These insights highlight the\nmethod's effectiveness and its potential to scale to larger datasets,\ncontributing to broader investigations of collective animal behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.16882v2",
    "published": "2025-05-22T16:36:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16881v1",
    "title": "CASTILLO: Characterizing Response Length Distributions of Large Language Models",
    "authors": [
      "Daniel F. Perez-Ramirez",
      "Dejan Kostic",
      "Magnus Boman"
    ],
    "abstract": "Efficiently managing compute resources for Large Language Model (LLM)\ninference remains challenging due to the inherently stochastic and variable\nlengths of autoregressive text generation. Accurately estimating response\nlengths in advance enables proactive resource allocation, yet existing\napproaches either bias text generation towards certain lengths or rely on\nassumptions that ignore model- and prompt-specific variability. We introduce\nCASTILLO, a dataset characterizing response length distributions across 13\nwidely-used open-source LLMs evaluated on seven distinct instruction-following\ncorpora. For each $\\langle$prompt, model$\\rangle$ sample pair, we generate 10\nindependent completions using fixed decoding hyper-parameters, record the token\nlength of each response, and publish summary statistics (mean, std-dev,\npercentiles), along with the shortest and longest completions, and the exact\ngeneration settings. Our analysis reveals significant inter- and intra-model\nvariability in response lengths (even under identical generation settings), as\nwell as model-specific behaviors and occurrences of partial text degeneration\nin only subsets of responses. CASTILLO enables the development of predictive\nmodels for proactive scheduling and provides a systematic framework for\nanalyzing model-specific generation behaviors. We publicly release the dataset\nand code to foster research at the intersection of generative language modeling\nand systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16881v1",
    "published": "2025-05-22T16:35:33+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16880v1",
    "title": "Resolving the $Δ(1232)$ partial width anomaly: Complex pole residue is not a fundamental resonance property",
    "authors": [
      "Saša Ceci",
      "Hedim Osmanović",
      "Branimir Zauner"
    ],
    "abstract": "The resonant properties of excited hadrons are commonly identified with the\ncomplex pole positions and residues of the scattering amplitude. The mass and\ntotal decay width are given by position, whereas the partial width is given by\nthe magnitude of the residue. If this identification was correct, the partial\nwidth of famous $\\Delta(1232)$ would be larger than its total width. By using a\nsimple model that predicts residue phases of prominent baryons $N^*$, $\\Delta$,\n$\\Lambda$, $\\Sigma$, and low mass mesons, we resolve this anomaly and show that\nthe residue cannot be a fundamental resonant property.",
    "pdf_url": "http://arxiv.org/pdf/2505.16880v1",
    "published": "2025-05-22T16:34:30+00:00",
    "categories": [
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16879v1",
    "title": "How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning",
    "authors": [
      "Hannah Sansford",
      "Nick Whiteley",
      "Patrick Rubin-Delanchy"
    ],
    "abstract": "We present a generalised Hanson-Wright inequality and use it to establish new\nstatistical insights into the geometry of data point-clouds. In the setting of\na general random function model of data, we clarify the roles played by three\nnotions of dimensionality: ambient intrinsic dimension $p_{\\mathrm{int}}$,\nwhich measures total variability across orthogonal feature directions;\ncorrelation rank, which measures functional complexity across samples; and\nlatent intrinsic dimension, which is the dimension of manifold structure hidden\nin data. Our analysis shows that in order for persistence diagrams to reveal\nlatent homology and for manifold structure to emerge it is sufficient that\n$p_{\\mathrm{int}}\\gg \\log n$, where $n$ is the sample size. Informed by these\ntheoretical perspectives, we revisit the ground-breaking neuroscience discovery\nof toroidal structure in grid-cell activity made by Gardner et al. (Nature,\n2022): our findings reveal, for the first time, evidence that this structure is\nin fact isometric to physical space, meaning that grid cell activity conveys a\ngeometrically faithful representation of the real world.",
    "pdf_url": "http://arxiv.org/pdf/2505.16879v1",
    "published": "2025-05-22T16:34:15+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16878v1",
    "title": "A monotonic MM-type algorithm for estimation of nonparametric finite mixture models with dependent marginals",
    "authors": [
      "Michael Levine"
    ],
    "abstract": "In this manuscript, we consider a finite nonparametric mixture model with\nnon-independent marginal density functions. Dependence between the marginal\ndensities is modeled using a copula device. Until recently, no deterministic\nalgorithms capable of estimating components of such a model have been\navailable. A deterministic algorithm that is capable of this has been proposed\nin \\citet*{levine2024smoothed}. That algorithm seeks to maximize a smoothed\nnonparametric penalized log-likelihood; it seems to perform well in practice\nbut does not possess the monotonicity property. In this manuscript, we\nintroduce a deterministic MM (Minorization-Maximization) algorithm for\nestimation of components of this model that is also maximizing a smoothed\npenalized nonparametric log-likelihood but that is monotonic with respect to\nthis objective functional. Besides the convergence of the objective functional,\nthe convergence of a subsequence of arguments of this functional, generated by\nthis algorithm, is also established. The behavior of this algorithm is\nillustrated using both simulated datasets as well as a real dataset. The\nresults illustrate performance that is at least comparable to the earlier\nalgorithm of \\citet*{levine2024smoothed}. A discussion of the results and\npossible future research directions make up the last part of the manuscript.",
    "pdf_url": "http://arxiv.org/pdf/2505.16878v1",
    "published": "2025-05-22T16:33:22+00:00",
    "categories": [
      "stat.ME",
      "stat.CO",
      "62G07, 62H30"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.16877v1",
    "title": "Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings",
    "authors": [
      "Yuqicheng Zhu",
      "Daniel Hernández",
      "Yuan He",
      "Zifeng Ding",
      "Bo Xiong",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "abstract": "Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is\ncrucial for ensuring the reliability of downstream applications. A recent work\napplies conformal prediction to KGE methods, providing uncertainty estimates by\ngenerating a set of answers that is guaranteed to include the true answer with\na predefined confidence level. However, existing methods provide probabilistic\nguarantees averaged over a reference set of queries and answers (marginal\ncoverage guarantee). In high-stakes applications such as medical diagnosis, a\nstronger guarantee is often required: the predicted sets must provide\nconsistent coverage per query (conditional coverage guarantee). We propose\nCondKGCP, a novel method that approximates predicate-conditional coverage\nguarantees while maintaining compact prediction sets. CondKGCP merges\npredicates with similar vector representations and augments calibration with\nrank information. We prove the theoretical guarantees and demonstrate empirical\neffectiveness of CondKGCP by comprehensive evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16877v1",
    "published": "2025-05-22T16:33:20+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16876v1",
    "title": "Inferring neutron star merger ejecta morphologies with kilonovae",
    "authors": [
      "Brendan L. King",
      "Soumi De",
      "Oleg Korobkin",
      "Michael W. Coughlin",
      "Peter T. H. Pang"
    ],
    "abstract": "In this study we incorporate a new grid of kilonova simulations produced by\nthe Monte Carlo radiative transfer code SuperNu in an inference pipeline for\nastrophysical transients, and evaluate their performance. These simulations\ncontain four different two-component ejecta morphology classes. We analyze\nfollow-up observational strategies by Vera Rubin Observatory in optical, and\nJames Webb Space Telescope (JWST) in mid-infrared (MIR). Our analysis suggests\nthat, within these strategies, it is possible to discriminate between different\nmorphologies only when late-time JWST observations in MIR are available. We\nconclude that follow-ups by the new Vera Rubin Observatory alone are not\nsufficient to determine ejecta morphology. Additionally, we make comparisons\nbetween surrogate models based on radiative transfer simulation grids by\nSuperNu and POSSIS, by analyzing the historic kilonova AT2017gfo that\naccompanied the gravitational wave event GW170817. We show that both SuperNu\nand POSSIS models provide similar fits to photometric observations. Our results\nshow a slight preference for SuperNu models, since the wind ejecta parameters\nrecovered with these models are in better agreement with expectations from\nnumerical simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16876v1",
    "published": "2025-05-22T16:32:13+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16875v1",
    "title": "T2I-ConBench: Text-to-Image Benchmark for Continual Post-training",
    "authors": [
      "Zhehao Huang",
      "Yuhang Liu",
      "Yixin Lou",
      "Zhengbao He",
      "Mingzhen He",
      "Wenxing Zhou",
      "Tao Li",
      "Kehan Li",
      "Zeyi Huang",
      "Xiaolin Huang"
    ],
    "abstract": "Continual post-training adapts a single text-to-image diffusion model to\nlearn new tasks without incurring the cost of separate models, but naive\npost-training causes forgetting of pretrained knowledge and undermines\nzero-shot compositionality. We observe that the absence of a standardized\nevaluation protocol hampers related research for continual post-training. To\naddress this, we introduce T2I-ConBench, a unified benchmark for continual\npost-training of text-to-image models. T2I-ConBench focuses on two practical\nscenarios, item customization and domain enhancement, and analyzes four\ndimensions: (1) retention of generality, (2) target-task performance, (3)\ncatastrophic forgetting, and (4) cross-task generalization. It combines\nautomated metrics, human-preference modeling, and vision-language QA for\ncomprehensive assessment. We benchmark ten representative methods across three\nrealistic task sequences and find that no approach excels on all fronts. Even\njoint \"oracle\" training does not succeed for every task, and cross-task\ngeneralization remains unsolved. We release all datasets, code, and evaluation\ntools to accelerate research in continual post-training for text-to-image\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.16875v1",
    "published": "2025-05-22T16:31:43+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16874v1",
    "title": "Magnetic vortex writing and local reversal seeding in artificial spin-vortex ice via all-optical and surface-probe control",
    "authors": [
      "Holly Holder",
      "Jack C. Gartside",
      "Alex Vanstone",
      "Troy Dion",
      "Xiaofei Xiao",
      "Kilian D. Stenning",
      "Tingjun Zheng",
      "Daniel Bromley",
      "Tobias Farchy",
      "Rupert F. Oulton",
      "Will R. Branford"
    ],
    "abstract": "Artificial spin-vortex ice ('ASVI') is a reconfigurable nanomagnetic\nmetamaterial consisting of magnetic nanoislands tailored to support both Ising\nmacrospin and vortex textures. ASVI has recently shown functional applications\nincluding reconfigurable magnonics and neuromorphic computing, where the\nintroduction of vortex textures broadens functionality beyond conventional\nartificial spin ice which generally supports macrospin states. However, local\ncontrol of writing vortex states in ASVI remains an open challenge. Here we\ndemonstrate techniques for field-free magnetic vortex writing in ASVI. We\nexpand ASVI to support metastable macrospin, single-vortex and double-vortex\nstates. All-optical writing via focused laser illumination can locally write\ndouble-vortex textures, and surface-probe writing using an MFM tip can locally\nwrite single vortex states. We leverage this writing to tailor and explore the\nreconfigurable energy landscape of ASVI, demonstrating programmable local\nseeding of avalanche-like reversal events. The global field-free texture\nselective writing techniques reported here expand the suite of nanomagnetic\ncontrol techniques, with a host of future applications including fundamental\nstudies of avalanche dynamics, physical memory, and direct writing of\nnanomagnetic 'weights' in physical neuromorphic neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16874v1",
    "published": "2025-05-22T16:29:17+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.16873v1",
    "title": "Modular correspondences and replicable functions (unabridged version)",
    "authors": [
      "J-M. Maillard"
    ],
    "abstract": "Landen transformation, and more generally modular correspondences, can be\nseen to be exact symmetries of some integrable lattice models, like the square\nIsing model, or the Baxter model. They are solutions of remarkable Schwarzian\nequations and have some compositional properties. Most of the known examples\ncorrespond, in an elliptic curves framework, to an automorphy property of\npullbacked $_2F_1$ hypergeometric functions, associated with modular forms. It\nis, however, important to underline that these Schwarzian equations go beyond\nan elliptic curves, and hypergeometric functions framework. The question of a\nmodular correspondence interpretation of the solutions of these ``Schwarzian''\nequations was clearly an open question. This paper tries to shed some light on\nthis open question. We first shed some light on the very nature of a\none-parameter series solution of the Schwarzian equation. This one-parameter\nseries is not generically a modular correspondence series, but it actually\nreduces to an\n  infinite set of modular correspondence series for an infinite set of (N-th\nroot of unity) values of the parameter. We also provide an example of\ntwo-parameter series, with a compositional property, solution of a Schwarzian\nequation. We finally provide simple pedagogical examples that are very similar\nto modular correspondence series, but are far beyond the elliptic curves\nframework. These last examples show that the modular correspondence-like\nseries, or the nome-like series, are not necessarily globally bounded. The\nresults of that paper can be seen as an incentive to study differentially\nalgebraic series with integer coefficients, in physics or enumeratice\ncombinatorics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16873v1",
    "published": "2025-05-22T16:29:11+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "34M55, 47Exx, 32Hxx, 32Nxx, 34Lxx, 34Mxx, 14Kxx, 14H52"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16872v1",
    "title": "A Multi-Step Comparative Framework for Anomaly Detection in IoT Data Streams",
    "authors": [
      "Mohammed Al-Qudah",
      "Fadi AlMahamid"
    ],
    "abstract": "The rapid expansion of Internet of Things (IoT) devices has introduced\ncritical security challenges, underscoring the need for accurate anomaly\ndetection. Although numerous studies have proposed machine learning (ML)\nmethods for this purpose, limited research systematically examines how\ndifferent preprocessing steps--normalization, transformation, and feature\nselection--interact with distinct model architectures. To address this gap,\nthis paper presents a multi-step evaluation framework assessing the combined\nimpact of preprocessing choices on three ML algorithms: RNN-LSTM, autoencoder\nneural networks (ANN), and Gradient Boosting (GBoosting). Experiments on the\nIoTID20 dataset shows that GBoosting consistently delivers superior accuracy\nacross preprocessing configurations, while RNN-LSTM shows notable gains with\nz-score normalization and autoencoders excel in recall, making them well-suited\nfor unsupervised scenarios. By offering a structured analysis of preprocessing\ndecisions and their interplay with various ML techniques, the proposed\nframework provides actionable guidance to enhance anomaly detection performance\nin IoT environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16872v1",
    "published": "2025-05-22T16:28:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16871v1",
    "title": "Improvement of H$_2$O$_2$ electrogeneration using a Vulcan XC72 carbon-based electrocatalyst modified with Ce-doped Nb$_2$O$_5$",
    "authors": [
      "Aline B. Trench",
      "João Paulo C. Moura",
      "Vanessa S. Antonin",
      "Caio Machado Fernandes",
      "Liying Liu",
      "Mauro C. Santos"
    ],
    "abstract": "The use of the oxygen reduction reaction (ORR) for in-situ production of\nH$_2$O$_2$ is an attractive alternative to replace the methods based on\nanthraquinone oxidation. This study investigates the modification of Vulcan\nXC72 carbon with Ce-doped Nb$_2$O$_5$ in different molar proportions and its\napplication as electrocatalysts in the ORR. One performed the characterization\nof the electrocatalysts using X-ray diffraction, Raman spectroscopy, scanning\nelectron microscopy, transmission electron microscopy, contact angle\nmeasurements, and X-ray photoelectron spectroscopy. Subsequently, the\nelectrocatalysts were analyzed for the ORR and the Nb$_2$O$_5$ doped with 0.5%\nCe showing the highest electrocatalytic response. This electrocatalyst was also\nemployed as a gas diffusion electrode and exhibited more significant H$_2$O$_2$\nproduction at all potentials than the Vulcan XC72 carbon modified solely with\nNb$_2$O$_5$. At the applied potentials of -1.3 V and -1.9 V, it produced 105%\nand 86% more H$_2$O$_2$, respectively, than the Vulcan XC72 carbon modified\nonly with Nb$_2$O$_5$. These results can be attributed to the doping of\nNb$_2$O$_5$ with 0.5% Ce, which induces local distortions in the crystal\nlattice of Nb$_2$O$_5$ due to the difference in ionic radius between Nb$^{5+}$\nand Ce$^{3+}$, which combined with increased hydrophilicity and wetting\nproperties, may have facilitated electron transfer and O$_2$ transport,\nfavoring the ORR.",
    "pdf_url": "http://arxiv.org/pdf/2505.16871v1",
    "published": "2025-05-22T16:28:07+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16870v1",
    "title": "First-principles study of metal-biphenylene interfaces: structural, electronic, and catalytic properties",
    "authors": [
      "Maicon P. Lebre",
      "Dominike Pacine",
      "Erika N. Lima",
      "Alexandre A. C. Cotta",
      "Igor S. S. de Oliveira"
    ],
    "abstract": "We employ first-principles density functional theory (DFT) calculations to\ninvestigate the structural, electronic, and catalytic properties of biphenylene\nsupported on various metal substrates. The substrates considered are the (111)\nsurfaces of Ag, Au, Ni, Pd, Pt, Cu, Al, and the Cu$_3$Au alloy. Our results\nreveal how the interaction between biphenylene and the substrate governs its\nstability, degree of corrugation, electronic hybridization, and interfacial\ncharge transfer. In particular, we observe a clear trend where weakly\ninteracting metals preserve the intrinsic features of biphenylene, while more\nreactive substrates lead to significant structural and electronic\nmodifications. We further evaluate the hydrogen evolution reaction (HER)\nactivity of these systems, showing that certain metal supports, especially Pd,\nPt, Ag, and Cu, can enhance the catalytic performance of biphenylene. Notably,\nAg and Cu combine good catalytic activity with lower cost and chemical\nstability, offering a promising balance for practical applications. These\nfindings provide insights into the design of biphenylene-metal interfaces,\nsupporting their use in next-generation electronic and catalytic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.16870v1",
    "published": "2025-05-22T16:27:18+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16869v1",
    "title": "MPO: Multilingual Safety Alignment via Reward Gap Optimization",
    "authors": [
      "Weixiang Zhao",
      "Yulin Hu",
      "Yang Deng",
      "Tongtong Wu",
      "Wenxuan Zhang",
      "Jiahe Guo",
      "An Zhang",
      "Yanyan Zhao",
      "Bing Qin",
      "Tat-Seng Chua",
      "Ting Liu"
    ],
    "abstract": "Large language models (LLMs) have become increasingly central to AI\napplications worldwide, necessitating robust multilingual safety alignment to\nensure secure deployment across diverse linguistic contexts. Existing\npreference learning methods for safety alignment, such as RLHF and DPO, are\nprimarily monolingual and struggle with noisy multilingual data. To address\nthese limitations, we introduce Multilingual reward gaP Optimization (MPO), a\nnovel approach that leverages the well-aligned safety capabilities of the\ndominant language (English) to improve safety alignment across multiple\nlanguages. MPO directly minimizes the reward gap difference between the\ndominant language and target languages, effectively transferring safety\ncapabilities while preserving the original strengths of the dominant language.\nExtensive experiments on three LLMs, LLaMA-3.1, Gemma-2 and Qwen2.5, validate\nMPO's efficacy in multilingual safety alignment without degrading general\nmultilingual utility.",
    "pdf_url": "http://arxiv.org/pdf/2505.16869v1",
    "published": "2025-05-22T16:24:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16868v1",
    "title": "Comparative analysis of subword tokenization approaches for Indian languages",
    "authors": [
      "Sudhansu Bala Das",
      "Samujjal Choudhury",
      "Tapas Kumar Mishra",
      "Bidyut Kr. Patra"
    ],
    "abstract": "Tokenization is the act of breaking down text into smaller parts, or tokens,\nthat are easier for machines to process. This is a key phase in machine\ntranslation (MT) models. Subword tokenization enhances this process by breaking\ndown words into smaller subword units, which is especially beneficial in\nlanguages with complicated morphology or a vast vocabulary. It is useful in\ncapturing the intricate structure of words in Indian languages (ILs), such as\nprefixes, suffixes, and other morphological variations. These languages\nfrequently use agglutinative structures, in which words are formed by the\ncombination of multiple morphemes such as suffixes, prefixes, and stems. As a\nresult, a suitable tokenization strategy must be chosen to address these\nscenarios. This paper examines how different subword tokenization techniques,\nsuch as SentencePiece, Byte Pair Encoding (BPE), and WordPiece Tokenization,\naffect ILs. The effectiveness of these subword tokenization techniques is\ninvestigated in statistical, neural, and multilingual neural machine\ntranslation models. All models are examined using standard evaluation metrics,\nsuch as the Bilingual Evaluation Understudy (BLEU) score, TER, METEOR, CHRF,\nRIBES, and COMET. Based on the results, it appears that for the majority of\nlanguage pairs for the Statistical and Neural MT models, the SentencePiece\ntokenizer continuously performed better than other tokenizers in terms of BLEU\nscore. However, BPE tokenization outperformed other tokenization techniques in\nthe context of Multilingual Neural Machine Translation model. The results show\nthat, despite using the same tokenizer and dataset for each model, translations\nfrom ILs to English surpassed translations from English to ILs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16868v1",
    "published": "2025-05-22T16:24:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.05359v1",
    "title": "Enhancing Meme Token Market Transparency: A Multi-Dimensional Entity-Linked Address Analysis for Liquidity Risk Evaluation",
    "authors": [
      "Qiangqiang Liu",
      "Qian Huang",
      "Frank Fan",
      "Haishan Wu",
      "Xueyan Tang"
    ],
    "abstract": "Meme tokens represent a distinctive asset class within the cryptocurrency\necosystem, characterized by high community engagement, significant market\nvolatility, and heightened vulnerability to market manipulation. This paper\nintroduces an innovative approach to assessing liquidity risk in meme token\nmarkets using entity-linked address identification techniques. We propose a\nmulti-dimensional method integrating fund flow analysis, behavioral similarity,\nand anomalous transaction detection to identify related addresses. We develop a\ncomprehensive set of liquidity risk indicators tailored for meme tokens,\ncovering token distribution, trading activity, and liquidity metrics. Empirical\nanalysis of tokens like BabyBonk, NMT, and BonkFork validates our approach,\nrevealing significant disparities between apparent and actual liquidity in meme\ntoken markets. The findings of this study provide significant empirical\nevidence for market participants and regulatory authorities, laying a\ntheoretical foundation for building a more transparent and robust meme token\necosystem.",
    "pdf_url": "http://arxiv.org/pdf/2506.05359v1",
    "published": "2025-05-22T16:24:09+00:00",
    "categories": [
      "q-fin.ST",
      "cs.CR"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.16867v1",
    "title": "The Double Tidal Disruption Event AT 2022dbl Implies That at Least Some \"Standard\" Optical TDEs are Partial Disruptions",
    "authors": [
      "Lydia Makrygianni",
      "Iair Arcavi",
      "Megan Newsome",
      "Ananya Bandopadhyay",
      "Eric R. Coughlin",
      "Itai Linial",
      "Brenna Mockler",
      "Eliot Quataert",
      "Chris Nixon",
      "Benjamin Godson",
      "Miika Pursiainen",
      "Giorgos Leloudas",
      "K. Decker French",
      "Adi Zitrin",
      "Sara Faris",
      "Marco C. Lam",
      "Assaf Horesh",
      "Itai Sfaradi",
      "Michael Fausnaugh",
      "Ehud Nakar",
      "Kendall Ackley",
      "Moira Andrews",
      "Panos Charalampopoulos",
      "Benjamin D. R. Davies",
      "Yael Dgany",
      "Martin J. Dyer",
      "Joseph Farah",
      "Rob Fender",
      "David A. Green",
      "D. Andrew Howell",
      "Thomas Killestein",
      "Niilo Koivisto",
      "Joseph Lyman",
      "Curtis McCully",
      "Morgan A. Mitchell",
      "Estefania Padilla Gonzalez",
      "Lauren Rhodes",
      "Anwesha Sahu",
      "Giacomo Terreran",
      "Ben Warwick"
    ],
    "abstract": "Flares produced following the tidal disruption of stars by supermassive black\nholes can reveal the properties of the otherwise dormant majority of black\nholes and the physics of accretion. In the past decade, a class of\noptical-ultraviolet tidal disruption flares has been discovered whose emission\nproperties do not match theoretical predictions. This has led to extensive\nefforts to model the dynamics and emission mechanisms of optical-ultraviolet\ntidal disruptions in order to establish them as probes of supermassive black\nholes. Here we present the optical-ultraviolet tidal disruption event AT\n2022dbl, which showed a nearly identical repetition 700 days after the first\nflare. Ruling out gravitational lensing and two chance unrelated disruptions,\nwe conclude that at least the first flare represents the partial disruption of\na star, possibly captured through the Hills mechanism. Since both flares are\ntypical of the optical-ultraviolet class of tidal disruptions in terms of their\nradiated energy, temperature, luminosity, and spectral features, it follows\nthat either the entire class are partial rather than full stellar disruptions,\ncontrary to the prevalent assumption, or that some members of the class are\npartial disruptions, having nearly the same observational characteristics as\nfull disruptions. Whichever option is true, these findings could require\nrevised models for the emission mechanisms of optical-ultraviolet tidal\ndisruption flares and a reassessment of their expected rates.",
    "pdf_url": "http://arxiv.org/pdf/2505.16867v1",
    "published": "2025-05-22T16:23:46+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16866v1",
    "title": "Including the magnitude variability of a signal into the ordinal pattern analysis",
    "authors": [
      "Melvyn Tyloo",
      "Joaquín González",
      "Nicolás Rubido"
    ],
    "abstract": "One of the most popular and innovative methods to analyse signals is by using\nOrdinal Patterns (OPs). The OP encoding is based on transforming a (univariate)\nsignal into a symbolic sequence of OPs, where each OP represents the number of\npermutations needed to order a small subset of the signal's magnitudes. This\nimplies that OPs are conceptually clear, methodologically simple to implement,\nrobust to noise, and can be applied to short signals. Moreover, they simplify\nthe statistical analyses that can be carried out on a signal, such as entropy\nand complexity quantifications. However, because of the relative ordering,\ninformation about the magnitude of the signal at each timestamp is lost -- this\nbeing one of the major drawbacks in the method. Here, we propose a way to use\nthe signal magnitudes discarded in the OP encoding as a complementary variable\nto its permutation entropy. To illustrate our approach, we analyse synthetic\ntrajectories from logistic and H{\\'e}non maps -- with and without added noise\n-- and intracranial electroencephalographic recordings from rats in different\nsleep-wake states. Our results show that, when complementing the permutation\nentropy with the variability in the signal magnitudes, the characterisation of\nthe dynamical behaviours of the maps and the sleep-wake states is improved.\nThis implies that our approach can be useful for feature engineering and\nimproving AI classifiers, where typical machine learning algorithms need\ncomplementary signal features as inputs to improve classification accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16866v1",
    "published": "2025-05-22T16:22:55+00:00",
    "categories": [
      "nlin.CD",
      "eess.SP"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16865v2",
    "title": "LARES: Latent Reasoning for Sequential Recommendation",
    "authors": [
      "Enze Liu",
      "Bowen Zheng",
      "Xiaolei Wang",
      "Wayne Xin Zhao",
      "Jinpeng Wang",
      "Sheng Chen",
      "Ji-Rong Wen"
    ],
    "abstract": "Sequential recommender systems have become increasingly important in\nreal-world applications that model user behavior sequences to predict their\npreferences. However, existing sequential recommendation methods predominantly\nrely on non-reasoning paradigms, which may limit the model's computational\ncapacity and result in suboptimal recommendation performance. To address these\nlimitations, we present LARES, a novel and scalable LAtent REasoning framework\nfor Sequential recommendation that enhances model's representation capabilities\nthrough increasing the computation density of parameters by depth-recurrent\nlatent reasoning. Our proposed approach employs a recurrent architecture that\nallows flexible expansion of reasoning depth without increasing parameter\ncomplexity, thereby effectively capturing dynamic and intricate user interest\npatterns. A key difference of LARES lies in refining all input tokens at each\nimplicit reasoning step to improve the computation utilization. To fully unlock\nthe model's reasoning potential, we design a two-phase training strategy: (1)\nSelf-supervised pre-training (SPT) with dual alignment objectives; (2)\nReinforcement post-training (RPT). During the first phase, we introduce\ntrajectory-level alignment and step-level alignment objectives, which enable\nthe model to learn recommendation-oriented latent reasoning patterns without\nrequiring supplementary annotated data. The subsequent phase utilizes\nreinforcement learning (RL) to harness the model's exploratory ability, further\nrefining its reasoning capabilities. Comprehensive experiments on real-world\nbenchmarks demonstrate our framework's superior performance. Notably, LARES\nexhibits seamless compatibility with existing advanced models, further\nimproving their recommendation performance. Our code is available at\nhttps://anonymous.4open.science/r/LARES-E458/.",
    "pdf_url": "http://arxiv.org/pdf/2505.16865v2",
    "published": "2025-05-22T16:22:54+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16864v1",
    "title": "Training-Free Efficient Video Generation via Dynamic Token Carving",
    "authors": [
      "Yuechen Zhang",
      "Jinbo Xing",
      "Bin Xia",
      "Shaoteng Liu",
      "Bohao Peng",
      "Xin Tao",
      "Pengfei Wan",
      "Eric Lo",
      "Jiaya Jia"
    ],
    "abstract": "Despite the remarkable generation quality of video Diffusion Transformer\n(DiT) models, their practical deployment is severely hindered by extensive\ncomputational requirements. This inefficiency stems from two key challenges:\nthe quadratic complexity of self-attention with respect to token length and the\nmulti-step nature of diffusion models. To address these limitations, we present\nJenga, a novel inference pipeline that combines dynamic attention carving with\nprogressive resolution generation. Our approach leverages two key insights: (1)\nearly denoising steps do not require high-resolution latents, and (2) later\nsteps do not require dense attention. Jenga introduces a block-wise attention\nmechanism that dynamically selects relevant token interactions using 3D\nspace-filling curves, alongside a progressive resolution strategy that\ngradually increases latent resolution during generation. Experimental results\ndemonstrate that Jenga achieves substantial speedups across multiple\nstate-of-the-art video diffusion models while maintaining comparable generation\nquality (8.83$\\times$ speedup with 0.01\\% performance drop on VBench). As a\nplug-and-play solution, Jenga enables practical, high-quality video generation\non modern hardware by reducing inference time from minutes to seconds --\nwithout requiring model retraining. Code:\nhttps://github.com/dvlab-research/Jenga",
    "pdf_url": "http://arxiv.org/pdf/2505.16864v1",
    "published": "2025-05-22T16:21:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16863v1",
    "title": "An exactly solvable model of quantum cosmology: the Hydrogen atom analogy with dust and Cosmological constant",
    "authors": [
      "Harkirat Singh Sahota",
      "Dipayan Mukherjee",
      "S. Shankaranarayanan"
    ],
    "abstract": "We study the Wheeler-DeWitt quantization of a spatially flat\nFriedmann-Lema\\^itre-Robertson-Walker (FLRW) universe with pressureless dust\n(modeled via the Brown-Kucha\\v{r} formalism) and a dynamical cosmological\nconstant $\\Lambda$ treated in the unimodular gravity framework, where\nunimodular time serves as a relational clock. Remarkably, the quantum dynamics\nof this system exhibit a mathematical correspondence to a non-relativistic\nhydrogen atom -- $\\Lambda$ maps to energy eigenvalues, the volume variable to\nthe radial coordinate, and the dust energy density parameter to the Coulomb\npotential strength. This analogy yields a continuous spectrum for positive\n$\\Lambda$, analogous to scattering states. For $\\Lambda > 0$, we prove the\nself-adjointness of the unimodular Hamiltonian, guaranteeing unitary evolution\nin unimodular time. By constructing wave packets from normalized stationary\nstates, we demonstrate a quantum bounce that resolves the classical Big Bang\nsingularity. The dynamics transition from semiclassical behavior far from the\nbounce to quantum-dominated regions featuring characteristic \"ringing\"\noscillations due to interference near the bounce. We quantify quantum effects\nthrough expectation values and fluctuations of cosmological observables,\nfinding evidence for persistent quantum effects in the late universe. Thus our\nresults suggest that quantum gravitational effects may leave imprints on\nlate-time cosmology, even beyond the bounce.",
    "pdf_url": "http://arxiv.org/pdf/2505.16863v1",
    "published": "2025-05-22T16:21:19+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16862v1",
    "title": "Conditional Panoramic Image Generation via Masked Autoregressive Modeling",
    "authors": [
      "Chaoyang Wang",
      "Xiangtai Li",
      "Lu Qi",
      "Xiaofan Lin",
      "Jinbin Bai",
      "Qianyu Zhou",
      "Yunhai Tong"
    ],
    "abstract": "Recent progress in panoramic image generation has underscored two critical\nlimitations in existing approaches. First, most methods are built upon\ndiffusion models, which are inherently ill-suited for equirectangular\nprojection (ERP) panoramas due to the violation of the identically and\nindependently distributed (i.i.d.) Gaussian noise assumption caused by their\nspherical mapping. Second, these methods often treat text-conditioned\ngeneration (text-to-panorama) and image-conditioned generation (panorama\noutpainting) as separate tasks, relying on distinct architectures and\ntask-specific data. In this work, we propose a unified framework, Panoramic\nAutoRegressive model (PAR), which leverages masked autoregressive modeling to\naddress these challenges. PAR avoids the i.i.d. assumption constraint and\nintegrates text and image conditioning into a cohesive architecture, enabling\nseamless generation across tasks. To address the inherent discontinuity in\nexisting generative models, we introduce circular padding to enhance spatial\ncoherence and propose a consistency alignment strategy to improve generation\nquality. Extensive experiments demonstrate competitive performance in\ntext-to-image generation and panorama outpainting tasks while showcasing\npromising scalability and generalization capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.16862v1",
    "published": "2025-05-22T16:20:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16861v1",
    "title": "Arbor-TVB: A Novel Multi-Scale Co-Simulation Framework with a Case Study on Neural-Level Seizure Generation and Whole-Brain Propagation",
    "authors": [
      "Thorsten Hater",
      "Juliette Courson",
      "Han Lu",
      "Sandra Diaz-Pier",
      "Thanos Manos"
    ],
    "abstract": "Computational neuroscience has traditionally focused on isolated scales,\nlimiting understanding of brain function across multiple levels. While\nmicroscopic models capture biophysical details of neurons, macroscopic models\ndescribe large-scale network dynamics. Integrating these scales, however,\nremains a significant challenge. In this study, we present a novel\nco-simulation framework that bridges these levels by integrating the neural\nsimulator Arbor with The Virtual Brain (TVB) platform. Arbor enables detailed\nsimulations from single-compartment neurons to populations of such cell, while\nTVB models whole-brain dynamics based on anatomical features and the mean\nneural activity of a brain region. By linking these simulators for the first\ntime, we provide an example of how to model and investigate the onset of\nseizures in specific areas and their propagation to the full brain. This\nframework employs an MPI intercommunicator for real-time bidirectional\ninteraction, translating between discrete spikes from Arbor and continuous TVB\nactivity. The novel Arbor-TVB co-simulator allows replacement of TVB nodes with\nbiologically realistic neuron populations, offering insights into seizure\npropagation and potential intervention strategies. The integration of Arbor and\nTVB marks a significant advancement in multi-scale modeling, providing a\ncomprehensive computational framework for studying neural disorders and\noptimizing treatments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16861v1",
    "published": "2025-05-22T16:19:25+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16860v1",
    "title": "GCAL: Adapting Graph Models to Evolving Domain Shifts",
    "authors": [
      "Ziyue Qiao",
      "Qianyi Cai",
      "Hao Dong",
      "Jiawei Gu",
      "Pengyang Wang",
      "Meng Xiao",
      "Xiao Luo",
      "Hui Xiong"
    ],
    "abstract": "This paper addresses the challenge of graph domain adaptation on evolving,\nmultiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation\nmethods are confined to single-step adaptation, making them ineffective in\nhandling continuous domain shifts and prone to catastrophic forgetting. This\npaper introduces the Graph Continual Adaptive Learning (GCAL) method, designed\nto enhance model sustainability and adaptability across various graph domains.\nGCAL employs a bilevel optimization strategy. The \"adapt\" phase uses an\ninformation maximization approach to fine-tune the model with new graph domains\nwhile re-adapting past memories to mitigate forgetting. Concurrently, the\n\"generate memory\" phase, guided by a theoretical lower bound derived from\ninformation bottleneck theory, involves a variational memory graph generation\nmodule to condense original graphs into memories. Extensive experimental\nevaluations demonstrate that GCAL substantially outperforms existing methods in\nterms of adaptability and knowledge retention.",
    "pdf_url": "http://arxiv.org/pdf/2505.16860v1",
    "published": "2025-05-22T16:19:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16859v1",
    "title": "Topological Phase Control via Dynamic Complex Pole-Zero Engineering",
    "authors": [
      "Alex Krasnok"
    ],
    "abstract": "Precise optical phase control is crucial for innovations in\ntelecommunications, optical computing, quantum information processing, and\nadvanced sensing. However, conventional phase modulators often introduce\nparasitic amplitude modulation and struggle to provide a full 2{\\pi} phase\nshift efficiently. This work introduces a novel paradigm for complete and\nrobust phase control at constant amplitude by dynamically engineering the\npole-zero constellation of resonant photonic systems within the complex\nfrequency plane. We theoretically elucidate and validate two distinct\napproaches: first, by modulating the complex frequency of an excitation signal\nto trace an iso-amplitude contour (apollonian circle) around a static\nreflection zero; and second, by dynamically tuning the physical parameters of\nthe resonator such that its reflection zero encircles a fixed-frequency\nmonochromatic excitation, again constraining operation to an iso-amplitude\ntrajectory. Both methods demonstrate the ability to impart a full 2{\\pi} phase\nshift while maintaining a pre-defined, constant reflection amplitude, thereby\neliminating amplitude-to-phase distortion. These results leverage the\ntopological nature of phase accumulation around critical points (poles and\nzeros), a concept gaining significant traction in non-Hermitian and topological\nphotonics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16859v1",
    "published": "2025-05-22T16:19:14+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.16858v1",
    "title": "Non-Parametric Attenuation Curves in Local Star-Forming Galaxies: Geometry Effect, Dust Evolution, and ISS",
    "authors": [
      "Jiafeng Lu",
      "Xi Kang",
      "Shiyin Shen",
      "Qi Zeng",
      "Shuai Feng"
    ],
    "abstract": "We introduce a non-parametric approach, the Stellar Population Synthesis with\nEquivalent Widths (SEW) method, to reconstruct spectral-resolution\nwavelength-dependent attenuation curves for 169,568 star-forming galaxies from\nthe SDSS DR7. Composite attenuation curves, stacked across stellar mass and\ninclination bins, reveal systematic trends: higher stellar mass correlates with\nsteeper attenuation slopes (lower $R_V$), while edge-on galaxies exhibit\nflatter curves due to geometric saturation effects. Radiative transfer\nmodelling under a uniform dust-star mixture confirms that the observed slope\nevolution with inclination comes from the galaxy geometry; the slope evolution\nwith stellar mass arises from intrinsic dust property variations, linked to\nmass-dependent grain processing mechanisms. Additionally, intermediate-scale\nstructures (ISS) at 4870, 6370, and 7690 \\r{A} are tentatively detected. These\nfindings underscore the interplay between dust geometry, grain evolution, and\ngalactic environment, offering new insights into dust lifecycle models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16858v1",
    "published": "2025-05-22T16:18:05+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16857v1",
    "title": "Redefining Clustered Federated Learning for System Identification: The Path of ClusterCraft",
    "authors": [
      "Ertuğrul Keçeci",
      "Müjde Güzelkaya",
      "Tufan Kumbasar"
    ],
    "abstract": "This paper addresses the System Identification (SYSID) problem within the\nframework of federated learning. We introduce a novel algorithm, Incremental\nClustering-based federated learning method for SYSID (IC-SYSID), designed to\ntackle SYSID challenges across multiple data sources without prior knowledge.\nIC-SYSID utilizes an incremental clustering method, ClusterCraft (CC), to\neliminate the dependency on the prior knowledge of the dataset. CC starts with\na single cluster model and assigns similar local workers to the same clusters\nby dynamically increasing the number of clusters. To reduce the number of\nclusters generated by CC, we introduce ClusterMerge, where similar cluster\nmodels are merged. We also introduce enhanced ClusterCraft to reduce the\ngeneration of similar cluster models during the training. Moreover, IC-SYSID\naddresses cluster model instability by integrating a regularization term into\nthe loss function and initializing cluster models with scaled Glorot\ninitialization. It also utilizes a mini-batch deep learning approach to manage\nlarge SYSID datasets during local training. Through the experiments conducted\non a real-world representing SYSID problem, where a fleet of vehicles\ncollaboratively learns vehicle dynamics, we show that IC-SYSID achieves a high\nSYSID performance while preventing the learning of unstable clusters.",
    "pdf_url": "http://arxiv.org/pdf/2505.16857v1",
    "published": "2025-05-22T16:15:12+00:00",
    "categories": [
      "cs.LG",
      "I.2.8; I.5.3; I.2.11"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16856v1",
    "title": "Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only",
    "authors": [
      "Wei Xiao",
      "Jiacheng Liu",
      "Zifeng Zhuang",
      "Runze Suo",
      "Shangke Lyu",
      "Donglin Wang"
    ],
    "abstract": "Improving the performance of pre-trained policies through online\nreinforcement learning (RL) is a critical yet challenging topic. Existing\nonline RL fine-tuning methods require continued training with offline\npretrained Q-functions for stability and performance. However, these offline\npretrained Q-functions commonly underestimate state-action pairs beyond the\noffline dataset due to the conservatism in most offline RL methods, which\nhinders further exploration when transitioning from the offline to the online\nsetting. Additionally, this requirement limits their applicability in scenarios\nwhere only pre-trained policies are available but pre-trained Q-functions are\nabsent, such as in imitation learning (IL) pre-training. To address these\nchallenges, we propose a method for efficient online RL fine-tuning using\nsolely the offline pre-trained policy, eliminating reliance on pre-trained\nQ-functions. We introduce PORL (Policy-Only Reinforcement Learning\nFine-Tuning), which rapidly initializes the Q-function from scratch during the\nonline phase to avoid detrimental pessimism. Our method not only achieves\ncompetitive performance with advanced offline-to-online RL algorithms and\nonline RL approaches that leverage data or policies prior, but also pioneers a\nnew path for directly fine-tuning behavior cloning (BC) policies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16856v1",
    "published": "2025-05-22T16:14:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16855v1",
    "title": "Nested Named Entity Recognition as Single-Pass Sequence Labeling",
    "authors": [
      "Alberto Muñoz-Ortiz",
      "David Vilares",
      "Caio COrro",
      "Carlos Gómez-Rodríguez"
    ],
    "abstract": "We cast nested named entity recognition (NNER) as a sequence labeling task by\nleveraging prior work that linearizes constituency structures, effectively\nreducing the complexity of this structured prediction problem to\nstraightforward token classification. By combining these constituency\nlinearizations with pretrained encoders, our method captures nested entities\nwhile performing exactly $n$ tagging actions. Our approach achieves competitive\nperformance compared to less efficient systems, and it can be trained using any\noff-the-shelf sequence labeling library.",
    "pdf_url": "http://arxiv.org/pdf/2505.16855v1",
    "published": "2025-05-22T16:13:39+00:00",
    "categories": [
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16854v2",
    "title": "Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models",
    "authors": [
      "Jiaqi Wang",
      "Kevin Qinghong Lin",
      "James Cheng",
      "Mike Zheng Shou"
    ],
    "abstract": "Reinforcement Learning (RL) has proven to be an effective post-training\nstrategy for enhancing reasoning in vision-language models (VLMs). Group\nRelative Policy Optimization (GRPO) is a recent prominent method that\nencourages models to generate complete reasoning traces before answering,\nleading to increased token usage and computational cost. Inspired by the\nhuman-like thinking process-where people skip reasoning for easy questions but\nthink carefully when needed-we explore how to enable VLMs to first decide when\nreasoning is necessary. To realize this, we propose TON, a two-stage training\nstrategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective\n'thought dropout' operation, where reasoning traces are randomly replaced with\nempty thoughts. This introduces a think-or-not format that serves as a cold\nstart for selective reasoning; (ii) a GRPO stage that enables the model to\nfreely explore when to think or not, while maximizing task-aware outcome\nrewards. Experimental results show that TON can reduce the completion length by\nup to 90% compared to vanilla GRPO, without sacrificing performance or even\nimproving it. Further evaluations across diverse vision-language tasks-covering\na range of reasoning difficulties under both 3B and 7B models-consistently\nreveal that the model progressively learns to bypass unnecessary reasoning\nsteps as training advances. These findings shed light on the path toward\nhuman-like reasoning patterns in reinforcement learning approaches. Our code is\navailable at https://github.com/kokolerk/TON.",
    "pdf_url": "http://arxiv.org/pdf/2505.16854v2",
    "published": "2025-05-22T16:13:29+00:00",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16853v1",
    "title": "Power law $α$-Starobinsky inflation",
    "authors": [
      "Saisandri Saini",
      "Akhilesh Nautiyal"
    ],
    "abstract": "In this work we consider a generalization of Starobinsky inflation obtained\nby combining power law ($R^\\beta$), and $\\alpha$-Starobinsky inflation\n($E$-model). The Einstein frame potential for this model is that of power law\nStarobinsky inflation modified by a parameter $\\alpha$ in the exponential.\nAfter computing power spectra for scalar and tensor perturbations numerically,\nwe perform MCMC analysis to put constraints on the potential parameter\n$\\alpha$, $\\beta$ and $M$, and the number of e-foldings $N_{pivot}$ during\ninflation, using Planck-2018, BICEP/Keck (BK18) and other LSS observations. We\nfind $\\log_{10}\\alpha= 0.37^{+0.82}_{-0.85}$, $\\beta =\n1.969^{+0.020}_{-0.023}$, $M=\\left(3.54^{+2.62}_{-1.73}\\right)\\times 10^{-5}$\nand $N_{pivot} = 47\\pm{10}$. We compute the Bayesian evidences for our proposed\nmodel, power law Starobinsky inflation, $\\alpha$-Starobinsky inflation and\nStarobinsky inflation. Considering the Starobinsky model as the base model, we\ncalculate the Bayes factor and find that our proposed model is preferred by the\nCMB and LSS observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16853v1",
    "published": "2025-05-22T16:13:22+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16852v1",
    "title": "Coherent states, background fields, and double copy",
    "authors": [
      "Anton Ilderton",
      "William Lindved"
    ],
    "abstract": "We show that scattering amplitudes on any gauge theory background admitting a\ncoherent state description double copy to amplitudes in a curved spacetime. The\nmetric of the spacetime is built from the gauge background using a notion of\nclassical double copy which emerges naturally at the amplitude level. In the\nself-dual sector this map relates backgrounds which are exact vacuum solutions\nin gauge theory and gravity.",
    "pdf_url": "http://arxiv.org/pdf/2505.16852v1",
    "published": "2025-05-22T16:13:13+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.17166v1",
    "title": "ViDoRe Benchmark V2: Raising the Bar for Visual Retrieval",
    "authors": [
      "Quentin Macé",
      "António Loison",
      "Manuel Faysse"
    ],
    "abstract": "The ViDoRe Benchmark V1 was approaching saturation with top models exceeding\n90% nDCG@5, limiting its ability to discern improvements. ViDoRe Benchmark V2\nintroduces realistic, challenging retrieval scenarios via blind contextual\nquerying, long and cross-document queries, and a hybrid synthetic and\nhuman-in-the-loop query generation process. It comprises four diverse,\nmultilingual datasets and provides clear evaluation instructions. Initial\nresults demonstrate substantial room for advancement and highlight insights on\nmodel generalization and multilingual capability. This benchmark is designed as\na living resource, inviting community contributions to maintain relevance\nthrough future evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2505.17166v1",
    "published": "2025-05-22T16:13:02+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17165v1",
    "title": "A Toolkit for Compliance, a Toolkit for Justice: Drawing on Cross-sectoral Expertise to Develop a Pro-justice EU AI Act Toolkit",
    "authors": [
      "Tomasz Hollanek",
      "Yulu Pi",
      "Cosimo Fiorini",
      "Virginia Vignali",
      "Dorian Peters",
      "Eleanor Drage"
    ],
    "abstract": "The introduction of the AI Act in the European Union presents the AI research\nand practice community with a set of new challenges related to compliance.\nWhile it is certain that AI practitioners will require additional guidance and\ntools to meet these requirements, previous research on toolkits that aim to\ntranslate the theory of AI ethics into development and deployment practice\nsuggests that such resources suffer from multiple limitations. These\nlimitations stem, in part, from the fact that the toolkits are either produced\nby industry-based teams or by academics whose work tends to be abstract and\ndivorced from the realities of industry. In this paper, we discuss the\nchallenge of developing an AI ethics toolkit for practitioners that helps them\ncomply with new AI-focused regulation, but that also moves beyond mere\ncompliance to consider broader socio-ethical questions throughout development\nand deployment. The toolkit was created through a cross-sectoral collaboration\nbetween an academic team based in the UK and an industry team in Italy. We\noutline the background and rationale for creating a pro-justice AI Act\ncompliance toolkit, detail the process undertaken to develop it, and describe\nthe collaboration and negotiation efforts that shaped its creation. We aim for\nthe described process to serve as a blueprint for other teams navigating the\nchallenges of academia-industry partnerships and aspiring to produce usable and\nmeaningful AI ethics resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.17165v1",
    "published": "2025-05-22T16:12:46+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.11055v1",
    "title": "PolyMicros: Bootstrapping a Foundation Model for Polycrystalline Material Structure",
    "authors": [
      "Michael Buzzy",
      "Andreas Robertson",
      "Peng Chen",
      "Surya Kalidindi"
    ],
    "abstract": "Recent advances in Foundation Models for Materials Science are poised to\nrevolutionize the discovery, manufacture, and design of novel materials with\ntailored properties and responses. Although great strides have been made,\nsuccesses have been restricted to materials classes where multi-million sample\ndata repositories can be readily curated (e.g., atomistic structures).\nUnfortunately, for many structural and functional materials (e.g., mesoscale\nstructured metal alloys), such datasets are too costly or prohibitive to\nconstruct; instead, datasets are limited to very few examples. To address this\nchallenge, we introduce a novel machine learning approach for learning from\nhyper-sparse, complex spatial data in scientific domains. Our core contribution\nis a physics-driven data augmentation scheme that leverages an ensemble of\nlocal generative models, trained on as few as five experimental observations,\nand coordinates them through a novel diversity curation strategy to generate a\nlarge-scale, physically diverse dataset. We utilize this framework to construct\nPolyMicros, the first Foundation Model for polycrystalline materials (a\nstructural material class important across a broad range of industrial and\nscientific applications). We demonstrate the utility of PolyMicros by zero-shot\nsolving several long standing challenges related to accelerating 3D\nexperimental microscopy. Finally, we make both our models and datasets openly\navailable to the community.",
    "pdf_url": "http://arxiv.org/pdf/2506.11055v1",
    "published": "2025-05-22T16:12:20+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16851v1",
    "title": "Fluctuation in energy extraction from quantum batteries: How open should the system be to control it?",
    "authors": [
      "Anindita Sarkar",
      "Paranjoy Chaki",
      "Priya Ghosh",
      "Ujjwal Sen"
    ],
    "abstract": "We ask whether there exists a relation between controllability of the\nfluctuations in extractable energy of a quantum battery and (a) how open an\narbitrary but fixed battery system is and (b) how large the battery is. We\nexamine three classes of quantum processes for the energy extraction: unitary\noperations, completely positive trace-preserving (CPTP) maps, and arbitrary\nquantum maps, including physically realizable non-CPTP maps. We show that all\nthree process classes yield the same average extractable energy from a fixed\nquantum battery. Moreover, open systems are better at controlling fluctuations\nin fixed quantum batteries: while random unitary operations result in nonzero\nfluctuation in the extractable energy, the remaining two classes lead to\nvanishing fluctuations in extractable energy. Furthermore, when the auxiliary\nsystem used to implement the non-unitary physically realizable maps is\nrestricted up to a dimension $n$, fluctuation in extractable energy scales as\n$1/n$ for CPTP maps, outperforming the $\\ln{n}/n$ scaling observed for general\nquantum maps. Even within open dynamics, therefore, energy extraction via\nrandom CPTP maps exhibits greater resilience to fluctuation compared to\nprocesses based on arbitrary quantum maps. We subsequently obtain that\nfluctuations in extractable energy scale as the inverse of the battery's\ndimension for all three process classes. Unitary maps, therefore, perform - in\nthe sense of as low fluctuation as possible - equally well as more\nresource-intensive open maps, provided we have access to large quantum\nbatteries. The results underscore a fundamental trade-off between performance\nof a battery and the resource cost of implementing the extraction processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.16851v1",
    "published": "2025-05-22T16:12:15+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16850v1",
    "title": "ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning",
    "authors": [
      "Tajamul Ashraf",
      "Mohammed Mohsen Peerzada",
      "Moloud Abdar",
      "Yutong Xie",
      "Yuyin Zhou",
      "Xiaofeng Liu",
      "Iqra Altaf Gillani",
      "Janibul Bashir"
    ],
    "abstract": "Federated Learning (FL) has emerged as a promising paradigm for collaborative\nmodel training while preserving data privacy across decentralized participants.\nAs FL adoption grows, numerous techniques have been proposed to tackle its\npractical challenges. However, the lack of standardized evaluation across key\ndimensions hampers systematic progress and fair comparison of FL methods. In\nthis work, we introduce ATR-Bench, a unified framework for analyzing federated\nlearning through three foundational dimensions: Adaptation, Trust, and\nReasoning. We provide an in-depth examination of the conceptual foundations,\ntask formulations, and open research challenges associated with each theme. We\nhave extensively benchmarked representative methods and datasets for adaptation\nto heterogeneous clients and trustworthiness in adversarial or unreliable\nenvironments. Due to the lack of reliable metrics and models for reasoning in\nFL, we only provide literature-driven insights for this dimension. ATR-Bench\nlays the groundwork for a systematic and holistic evaluation of federated\nlearning with real-world relevance. We will make our complete codebase publicly\naccessible and a curated repository that continuously tracks new developments\nand research in the FL literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.16850v1",
    "published": "2025-05-22T16:11:38+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16849v2",
    "title": "Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks",
    "authors": [
      "Martin Böckling",
      "Heiko Paulheim",
      "Andreea Iana"
    ],
    "abstract": "Large Language Models (LLMs) have showcased impressive reasoning abilities,\nbut often suffer from hallucinations or outdated knowledge. Knowledge Graph\n(KG)-based Retrieval-Augmented Generation (RAG) remedies these shortcomings by\ngrounding LLM responses in structured external information from a knowledge\nbase. However, many KG-based RAG approaches struggle with (i) aligning KG and\ntextual representations, (ii) balancing retrieval accuracy and efficiency, and\n(iii) adapting to dynamically updated KGs. In this work, we introduce\nWalk&Retrieve, a simple yet effective KG-based framework that leverages\nwalk-based graph traversal and knowledge verbalization for corpus generation\nfor zero-shot RAG. Built around efficient KG walks, our method does not require\nfine-tuning on domain-specific data, enabling seamless adaptation to KG\nupdates, reducing computational overhead, and allowing integration with any\noff-the-shelf backbone LLM. Despite its simplicity, Walk&Retrieve performs\ncompetitively, often outperforming existing RAG systems in response accuracy\nand hallucination reduction. Moreover, it demonstrates lower query latency and\nrobust scalability to large KGs, highlighting the potential of lightweight\nretrieval strategies as strong baselines for future RAG research.",
    "pdf_url": "http://arxiv.org/pdf/2505.16849v2",
    "published": "2025-05-22T16:11:35+00:00",
    "categories": [
      "cs.IR",
      "cs.CL",
      "H.3.3; I.2.7"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16848v1",
    "title": "Extraction of coherence times of biexciton and exciton photons emitted by a single resonantly excited quantum dot under controlled dephasing",
    "authors": [
      "Jaewon Lee",
      "Charlie Stalker",
      "Loris Colicchio",
      "Fernando Redivo Cardoso",
      "Jan Seelbinder",
      "Sven Höfling",
      "Christian Schneider",
      "Celso J. Villas-Boas",
      "Ana Predojević"
    ],
    "abstract": "The visibility of two-photon interference is limited by the\nindistinguishability of the photons. In the cascaded emission of a three-level\nsystem, such as a single quantum dot, the indistinguishability of each photon\nin the pair is primarily affected by two main factors: the temporal correlation\nbetween paired photons and dephasing. Investigating the individual effects of\nthese factors on photon indistinguishability is challenging, as both factors\naffect it simultaneously. In this study, we investigate the\ntemperature-dependent two-photon interference visibility of the biexciton and\nexciton photons emitted from a single quantum dot under two-photon resonant\nexcitation, while keeping temporal correlation between the paired photons\nintact. Finally, we simultaneously extract the coherence times of the biexciton\nand exciton photons as a function of temperature.",
    "pdf_url": "http://arxiv.org/pdf/2505.16848v1",
    "published": "2025-05-22T16:11:10+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16847v1",
    "title": "Understanding and Analyzing Inappropriately Targeting Language in Online Discourse: A Comparative Annotation Study",
    "authors": [
      "Baran Barbarestani",
      "Isa Maks",
      "Piek Vossen"
    ],
    "abstract": "This paper introduces a method for detecting inappropriately targeting\nlanguage in online conversations by integrating crowd and expert annotations\nwith ChatGPT. We focus on English conversation threads from Reddit, examining\ncomments that target individuals or groups. Our approach involves a\ncomprehensive annotation framework that labels a diverse data set for various\ntarget categories and specific target words within the conversational context.\nWe perform a comparative analysis of annotations from human experts, crowd\nannotators, and ChatGPT, revealing strengths and limitations of each method in\nrecognizing both explicit hate speech and subtler discriminatory language. Our\nfindings highlight the significant role of contextual factors in identifying\nhate speech and uncover new categories of targeting, such as social belief and\nbody image. We also address the challenges and subjective judgments involved in\nannotation and the limitations of ChatGPT in grasping nuanced language. This\nstudy provides insights for improving automated content moderation strategies\nto enhance online safety and inclusivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.16847v1",
    "published": "2025-05-22T16:10:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16846v1",
    "title": "Ray-tracing GR-MHD-generated Outflows from AGNs Hosting Thin Accretion Disks: An Analysis Approaching Horizon Scales",
    "authors": [
      "Bidisha Bandyopadhyay",
      "Christian Fendt",
      "Dominik R. G. Schleicher",
      "Neil M. Nagar",
      "Felipe Agurto-Sepulveda",
      "Javier Pedreros"
    ],
    "abstract": "AGNs exhibit a wide range of black hole masses and inflow/outflow properties.\nIt is now possible to probe regions close to the event horizons of nearby SMBHs\nusing VLBI with earth-sized baselines, as performed by the EHT. This study\nexplores the emission properties of accretion and outflows near the event\nhorizon of both low-mass and high-mass SMBHs. Using resistive GR-MHD\nsimulations, we model AGNs with thin Keplerian disks. This contrasts with\nwidely studied models featuring thick disks, such as magnetically arrested\ndisks (MADs) or the standard and normal evolution (SANE) scenario. Our models\nserve as simplified representations to study disk-jet-wind structures. These\nsimulations are postprocessed and ray-traced, using constraints of black hole\nmass and observed SEDs. Thermal synchrotron emission generated near the event\nhorizon is used to create emission maps, which are analysed by separating\naccretion and outflow components to determine their contributions to the total\nintensity. Whether the emission appears optically thick or thin at a given\nfrequency depends on its position relative to the synchrotron SED peak. At 230\nGHz, low-mass SMBHs appear optically thicker than high-mass ones, even at lower\naccretion rates. Doppler beaming affects the brightness of emission from\noutflows with changing viewing angles in low-mass systems. Eddington ratios\nfrom our models align with those inferred by the EHTC for M87 and SgrA* using\nthicker MAD/SANE models. Although thin disks are optically thicker, their\nspectral properties make high-mass systems appear optically thinner at 230 GHz;\nideal for probing GR effects like photon rings. In contrast, low-mass systems\nremain optically thicker at these frequencies because of synchrotron\nself-absorption, making outflow emissions near the horizon more pronounced.\nHowever, distinguishing these features remains challenging with current EHT\nresolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.16846v1",
    "published": "2025-05-22T16:10:03+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16845v1",
    "title": "Unlocking Temporal Flexibility: Neural Speech Codec with Variable Frame Rate",
    "authors": [
      "Hanglei Zhang",
      "Yiwei Guo",
      "Zhihan Li",
      "Xiang Hao",
      "Xie Chen",
      "Kai Yu"
    ],
    "abstract": "Most neural speech codecs achieve bitrate adjustment through intra-frame\nmechanisms, such as codebook dropout, at a Constant Frame Rate (CFR). However,\nspeech segments inherently have time-varying information density (e.g., silent\nintervals versus voiced regions). This property makes CFR not optimal in terms\nof bitrate and token sequence length, hindering efficiency in real-time\napplications. In this work, we propose a Temporally Flexible Coding (TFC)\ntechnique, introducing variable frame rate (VFR) into neural speech codecs for\nthe first time. TFC enables seamlessly tunable average frame rates and\ndynamically allocates frame rates based on temporal entropy. Experimental\nresults show that a codec with TFC achieves optimal reconstruction quality with\nhigh flexibility, and maintains competitive performance even at lower frame\nrates. Our approach is promising for the integration with other efforts to\ndevelop low-frame-rate neural speech codecs for more efficient downstream\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16845v1",
    "published": "2025-05-22T16:10:01+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16844v2",
    "title": "Parity-violating scalar trispectrum from helical primordial magnetic fields",
    "authors": [
      "Kaito Yura",
      "Shohei Saga",
      "Maresuke Shiraishi",
      "Shuichiro Yokoyama"
    ],
    "abstract": "Some recent observations of the cosmic microwave background (CMB)\nanisotropies and the large-scale structure of the Universe imply cosmic parity\nviolation. Among possible parity-violating sources, helical primordial magnetic\nfields (PMFs) are of particular interest, as they inherently violate parity\nsymmetry and can explain the observed magnetic fields, especially in void\nregions. PMFs, if generated in the early universe, can source curvature\nperturbations, which evolve into the present density fluctuations observed in\nCMB and galaxy surveys. Motivated by this, we study the imprint of helical PMFs\non the trispectrum of the sourced primordial curvature perturbations, which is\na leading-order scalar statistics sensitive to parity-violating signals. We\nderive full expressions for the trispectrum of the primordial curvature\nperturbations sourced by both the helical and non-helical PMFs and reduce them\nto computationally-feasible ones using a proper approximation. From numerical\nworks, we confirm that parity-odd signals are efficiently enhanced and surpass\nparity-even ones in specific momentum and parameter spaces. Parity-violating\nsignatures found in this paper are partially testable with observational\nimplications reported so far. Assuming nearly scale-invariant PMF power spectra\nand the PMF strength of $B_{r}=4.7 \\, {\\rm nG}$, we obtain a rough upper bound\non the helical-to-non-helical power ratio as $r_H\\lesssim 4\\times 10^{-4}$. Our\nfindings highlight the primordial trispectrum as a promising probe of helical\nPMFs and provide a theoretical basis for future precise observations of\nhigher-order statistics in the CMB anisotropies and the galaxy clustering.",
    "pdf_url": "http://arxiv.org/pdf/2505.16844v2",
    "published": "2025-05-22T16:09:50+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16843v1",
    "title": "$d$-dimensional spherical ferromagnets in random fields: Metastates, continuous symmetry breaking, and spin-glass features",
    "authors": [
      "Kalle Koskinen",
      "Christof Külske"
    ],
    "abstract": "We study the large-volume behavior of the spherical model for $d$-dimensional\nlocal spins, in the presence of $d$-dimensional random fields, for $d\\geq 2$.\nWe compare two models, one with volume-scaled random fields, and another one\nwith non-scaled random fields, on the level of Aizenman-Wehr metastates,\nNewman-Stein metastates, as well as overlap distributions. We show that in\n$d\\geq 2$ the metastates are fully supported on a continuity of random product\nstates, with weights which we describe, for both models. For the non-scaled\nrandom fields, the set of a.s. cluster points of Gibbs measures contains these\nproduct states, but behaves differently in the 'recurrent' spin dimension $d=2$\nwhere it also contains non-trivial mixtures of tilted measures. For the scaled\nmodel, moreover the overlap distribution displays spin-glass characteristics,\nas it is non-self averaging, and shows replica symmetry breaking, although it\nis ultrametric if and only if $d=1$. For $d\\geq 2$ it oscillates chaotically on\na set of continuous distributions for large volumes, while the limiting set\ncontains only discrete distributions in $d=1$. Our results are based on\nconcentration estimates, analysis of Gibbs measures in finite but large\nvolumes, and the asymptotics of $d$-dimensional random walks and their\nspherical projections.",
    "pdf_url": "http://arxiv.org/pdf/2505.16843v1",
    "published": "2025-05-22T16:09:10+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "math.PR",
      "82D30, 82B44, 60G57"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16842v1",
    "title": "First is the worst, second is the best? A Markov chain analysis of the basketball game knockout",
    "authors": [
      "Andrew Flatz",
      "Michael C. Loper",
      "Lezlie Weyer"
    ],
    "abstract": "The game of Knockout is a classic playground game played with two\nbasketballs. This paper uses a Markov process to analyze each player's\nprobability of winning the game given their starting position in line and\nshooting percentages, assuming all players are equally skilled. The two-player\ncase is solved in general for any probability of a long shot and short shot\nshooting percentage and the n-player case with n > 2 is solved numerically. In\ndoing so, this paper answers the question of whether or not the playground\nwisdom of ``first is the worst, second is best'' is true. We also examine the\naverage number of rounds it takes before the game ends, analyze trends in the\ndata to recommend tips to win at Knockout, and provide questions in the case of\nplayers not being equally skilled.",
    "pdf_url": "http://arxiv.org/pdf/2505.16842v1",
    "published": "2025-05-22T16:09:08+00:00",
    "categories": [
      "math.OC",
      "60J20"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16841v1",
    "title": "On the Deployment of RIS-mounted UAV Networks",
    "authors": [
      "Anupam Mondal",
      "Priyadarshi Mukherjee",
      "Sasthi C. Ghosh"
    ],
    "abstract": "Reconfigurable intelligent surfaces (RIS) enable smart wireless environments\nby dynamically controlling signal propagation to enhance communication and\nlocalization. Unmanned aerial vehicles (UAVs) can act as flying base stations\nand thus, improve system performance by avoiding signal blockages. In this\npaper, we propose a gradient ascent and coordinate search based method to\ndetermine the optimal location for a system that consists of a UAV and a RIS,\nwhere the UAV serves cellular users (CUs) and the RIS serves device-to-device\n(D2D) pairs. In particular, by optimizing the net throughput for both the D2D\npairs and the CUs, the suggested method establishes the ideal location for the\nRIS-mounted UAV. We consider both line of sight (LoS) and non-LoS paths for the\nRIS and UAV to calculate the throughput while accounting for blockages in the\nsystem. The numerical results show that the proposed method performs better\nthan the existing approaches in terms of both the net throughput and the user\nfairness.",
    "pdf_url": "http://arxiv.org/pdf/2505.16841v1",
    "published": "2025-05-22T16:08:26+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.03160v1",
    "title": "Applying MambaAttention, TabPFN, and TabTransformers to Classify SAE Automation Levels in Crashes",
    "authors": [
      "Shriyank Somvanshi",
      "Anannya Ghosh Tusti",
      "Mahmuda Sultana Mimi",
      "Md Monzurul Islam",
      "Sazzad Bin Bashar Polock",
      "Anandi Dutta",
      "Subasish Das"
    ],
    "abstract": "The increasing presence of automated vehicles (AVs) presents new challenges\nfor crash classification and safety analysis. Accurately identifying the SAE\nautomation level involved in each crash is essential to understanding crash\ndynamics and system accountability. However, existing approaches often overlook\nautomation-specific factors and lack model sophistication to capture\ndistinctions between different SAE levels. To address this gap, this study\nevaluates the performance of three advanced tabular deep learning models\nMambaAttention, TabPFN, and TabTransformer for classifying SAE automation\nlevels using structured crash data from Texas (2024), covering 4,649 cases\ncategorized as Assisted Driving (SAE Level 1), Partial Automation (SAE Level\n2), and Advanced Automation (SAE Levels 3-5 combined). Following class\nbalancing using SMOTEENN, the models were trained and evaluated on a unified\ndataset of 7,300 records. MambaAttention demonstrated the highest overall\nperformance (F1-scores: 88% for SAE 1, 97% for SAE 2, and 99% for SAE 3-5),\nwhile TabPFN excelled in zero-shot inference with high robustness for rare\ncrash categories. In contrast, TabTransformer underperformed, particularly in\ndetecting Partial Automation crashes (F1-score: 55%), suggesting challenges in\nmodeling shared human-system control dynamics. These results highlight the\ncapability of deep learning models tailored for tabular data to enhance the\naccuracy and efficiency of automation-level classification. Integrating such\nmodels into crash analysis frameworks can support policy development, AV safety\nevaluation, and regulatory decisions, especially in distinguishing high-risk\nconditions for mid- and high-level automation technologies.",
    "pdf_url": "http://arxiv.org/pdf/2506.03160v1",
    "published": "2025-05-22T16:08:21+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16840v1",
    "title": "Number theory combination: natural density and SMT",
    "authors": [
      "Guilherme V. Toledo",
      "Yoni Zohar"
    ],
    "abstract": "The study of theory combination in Satisfiability Modulo Theories (SMT)\ninvolves various model theoretic properties (e.g., stable infiniteness,\nsmoothness, etc.). We show that such properties can be partly captured by the\nnatural density of the spectrum of the studied theories, which is the set of\nsizes of their finite models. This enriches the toolbox of the theory\ncombination researcher, by providing new tools to determine the possibility of\ncombining theories. It also reveals interesting and surprising connections\nbetween theory combination and number theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.16840v1",
    "published": "2025-05-22T16:08:19+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16839v3",
    "title": "LaViDa: A Large Diffusion Language Model for Multimodal Understanding",
    "authors": [
      "Shufan Li",
      "Konstantinos Kallidromitis",
      "Hritik Bansal",
      "Akash Gokul",
      "Yusuke Kato",
      "Kazuki Kozuka",
      "Jason Kuen",
      "Zhe Lin",
      "Kai-Wei Chang",
      "Aditya Grover"
    ],
    "abstract": "Modern Vision-Language Models (VLMs) can solve a wide range of tasks\nrequiring visual reasoning. In real-world scenarios, desirable properties for\nVLMs include fast inference and controllable generation (e.g., constraining\noutputs to adhere to a desired format). However, existing autoregressive (AR)\nVLMs like LLaVA struggle in these aspects. Discrete diffusion models (DMs)\noffer a promising alternative, enabling parallel decoding for faster inference\nand bidirectional context for controllable generation through text-infilling.\nWhile effective in language-only settings, DMs' potential for multimodal tasks\nis underexplored. We introduce LaViDa, a family of VLMs built on DMs. We build\nLaViDa by equipping DMs with a vision encoder and jointly fine-tune the\ncombined parts for multimodal instruction following. To address challenges\nencountered, LaViDa incorporates novel techniques such as complementary masking\nfor effective training, prefix KV cache for efficient inference, and timestep\nshifting for high-quality sampling. Experiments show that LaViDa achieves\ncompetitive or superior performance to AR VLMs on multi-modal benchmarks such\nas MMMU, while offering unique advantages of DMs, including flexible\nspeed-quality tradeoff, controllability, and bidirectional reasoning. On COCO\ncaptioning, LaViDa surpasses Open-LLaVa-Next-8B by +4.1 CIDEr with 1.92x\nspeedup. On bidirectional tasks, it achieves +59% improvement on Constrained\nPoem Completion. These results demonstrate LaViDa as a strong alternative to AR\nVLMs. Code and models will be released in the camera-ready version.",
    "pdf_url": "http://arxiv.org/pdf/2505.16839v3",
    "published": "2025-05-22T16:07:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16838v1",
    "title": "R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search",
    "authors": [
      "Yibo Wang",
      "Li Shen",
      "Huanjin Yao",
      "Tiansheng Huang",
      "Rui Liu",
      "Naiqiang Tan",
      "Jiaxing Huang",
      "Kai Zhang",
      "Dacheng Tao"
    ],
    "abstract": "Chain-of-Thought (CoT) reasoning enhances large language models (LLMs) by\nenabling step-by-step problem-solving, yet its extension to Long-CoT introduces\nsubstantial computational overhead due to increased token length. Existing\ncompression approaches -- instance-level and token-level -- either sacrifice\nessential local reasoning signals like reflection or yield incoherent outputs.\nTo address these limitations, we propose R1-Compress, a two-stage chunk-level\ncompression framework that preserves both local information and coherence. Our\nmethod segments Long-CoT into manageable chunks, applies LLM-driven inner-chunk\ncompression, and employs an inter-chunk search mechanism to select the short\nand coherent sequence. Experiments on Qwen2.5-Instruct models across MATH500,\nAIME24, and GPQA-Diamond demonstrate that R1-Compress significantly reduces\ntoken usage while maintaining comparable reasoning accuracy. On MATH500,\nR1-Compress achieves an accuracy of 92.4%, with only a 0.6% drop compared to\nthe Long-CoT baseline, while reducing token usage by about 20%. Source code\nwill be available at https://github.com/w-yibo/R1-Compress",
    "pdf_url": "http://arxiv.org/pdf/2505.16838v1",
    "published": "2025-05-22T16:06:59+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16837v1",
    "title": "Dimension of unicycle posets",
    "authors": [
      "Antoine Abram",
      "Adrien Segovia"
    ],
    "abstract": "Motivated by the study of the dimension of random posets, it was conjectured\nby Bollob\\'as and Brightwell in 1997 that if $P$ is a finite poset whose cover\ngraph contains at most one cycle then its order dimension is at most $3$. In\nthis paper we prove this conjecture by giving a constructive proof with\nexplicit triplets of linear extensions realizing such posets.",
    "pdf_url": "http://arxiv.org/pdf/2505.16837v1",
    "published": "2025-05-22T16:05:45+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16835v1",
    "title": "A simulation and case study to evaluate the extrapolation performance of flexible Bayesian survival models when incorporating real-world data",
    "authors": [
      "Iain R. Timmins",
      "Fatemeh Torabi",
      "Christopher H. Jackson",
      "Paul C. Lambert",
      "Michael J. Sweeting"
    ],
    "abstract": "Background: Assessment of long-term survival for health technology assessment\noften necessitates extrapolation beyond the duration of a clinical trial.\nWithout robust methods and external data, extrapolations are unreliable.\nFlexible Bayesian survival models that incorporate longer-term data sources,\nincluding registry data and population mortality, have been proposed as an\nalternative to using standard parametric models with trial data alone.\n  Methods: The accuracy and uncertainty of extrapolations from the survextrap\nBayesian survival model and R package were evaluated. In case studies and\nsimulations, we assessed the accuracy of estimates with and without long-term\ndata, under different assumptions about the long-term hazard rate and how it\ndiffers between datasets, and about treatment effects.\n  Results: The survextrap model gives accurate extrapolations of long-term\nsurvival when long-term data on the patients of interest are included. Even\nusing moderately biased external data gives improvements over using the\nshort-term trial data alone. Furthermore, the model gives accurate\nextrapolations of differences in survival between treatment groups, provided\nthat a reasonably accurate assumption is made about how the treatment effect\nwill change over time. If no long-term data are available, then the model can\nquantify structural uncertainty about potential future changes in hazard rates.\n  Conclusions: This analysis shows that Bayesian modelling can give accurate\nand reliable survival extrapolations by making the most of all available trial\nand real-world data. This work improves confidence in the use of a powerful\ntool for evidence-based healthcare decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2505.16835v1",
    "published": "2025-05-22T16:05:06+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.16836v2",
    "title": "Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning",
    "authors": [
      "Fanrui Zhang",
      "Dian Li",
      "Qiang Zhang",
      "Chenjun",
      "sinbadliu",
      "Junxiong Lin",
      "Jiahong Yan",
      "Jiawei Liu",
      "Zheng-Jun Zha"
    ],
    "abstract": "The rapid spread of multimodal misinformation on social media has raised\ngrowing concerns, while research on video misinformation detection remains\nlimited due to the lack of large-scale, diverse datasets. Existing methods\noften overfit to rigid templates and lack deep reasoning over deceptive\ncontent. To address these challenges, we introduce FakeVV, a large-scale\nbenchmark comprising over 100,000 video-text pairs with fine-grained,\ninterpretable annotations. In addition, we further propose Fact-R1, a novel\nframework that integrates deep reasoning with collaborative rule-based\nreinforcement learning. Fact-R1 is trained through a three-stage process: (1)\nmisinformation long-Chain-of-Thought (CoT) instruction tuning, (2) preference\nalignment via Direct Preference Optimization (DPO), and (3) Group Relative\nPolicy Optimization (GRPO) using a novel verifiable reward function. This\nenables Fact-R1 to exhibit emergent reasoning behaviors comparable to those\nobserved in advanced text-based reinforcement learning systems, but in the more\ncomplex multimodal misinformation setting. Our work establishes a new paradigm\nfor misinformation detection, bridging large-scale video understanding,\nreasoning-guided alignment, and interpretable verification.",
    "pdf_url": "http://arxiv.org/pdf/2505.16836v2",
    "published": "2025-05-22T16:05:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16834v2",
    "title": "SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis",
    "authors": [
      "Shuang Sun",
      "Huatong Song",
      "Yuhao Wang",
      "Ruiyang Ren",
      "Jinhao Jiang",
      "Junjie Zhang",
      "Fei Bai",
      "Jia Deng",
      "Wayne Xin Zhao",
      "Zheng Liu",
      "Lei Fang",
      "Zhongyuan Wang",
      "Ji-Rong Wen"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems have advanced large language\nmodels (LLMs) in complex deep search scenarios requiring multi-step reasoning\nand iterative information retrieval. However, existing approaches face critical\nlimitations that lack high-quality training trajectories or suffer from the\ndistributional mismatches in simulated environments and prohibitive\ncomputational costs for real-world deployment. This paper introduces\nSimpleDeepSearcher, a lightweight yet effective framework that bridges this gap\nthrough strategic data engineering rather than complex training paradigms. Our\napproach synthesizes high-quality training data by simulating realistic user\ninteractions in live web search environments, coupled with a multi-criteria\ncuration strategy that optimizes the diversity and quality of input and output\nside. Experiments on five benchmarks across diverse domains demonstrate that\nSFT on only 871 curated samples yields significant improvements over RL-based\nbaselines. Our work establishes SFT as a viable pathway by systematically\naddressing the data-scarce bottleneck, offering practical insights for\nefficient deep search systems. Our code is available at\nhttps://github.com/RUCAIBox/SimpleDeepSearcher.",
    "pdf_url": "http://arxiv.org/pdf/2505.16834v2",
    "published": "2025-05-22T16:05:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16833v1",
    "title": "Strategically Linked Decisions in Long-Term Planning and Reinforcement Learning",
    "authors": [
      "Alihan Hüyük",
      "Finale Doshi-Velez"
    ],
    "abstract": "Long-term planning, as in reinforcement learning (RL), involves finding\nstrategies: actions that collectively work toward a goal rather than\nindividually optimizing their immediate outcomes. As part of a strategy, some\nactions are taken at the expense of short-term benefit to enable future actions\nwith even greater returns. These actions are only advantageous if followed up\nby the actions they facilitate, consequently, they would not have been taken if\nthose follow-ups were not available. In this paper, we quantify such\ndependencies between planned actions with strategic link scores: the drop in\nthe likelihood of one decision under the constraint that a follow-up decision\nis no longer available. We demonstrate the utility of strategic link scores\nthrough three practical applications: (i) explaining black-box RL agents by\nidentifying strategically linked pairs among decisions they make, (ii)\nimproving the worst-case performance of decision support systems by\ndistinguishing whether recommended actions can be adopted as standalone\nimprovements or whether they are strategically linked hence requiring a\ncommitment to a broader strategy to be effective, and (iii) characterizing the\nplanning processes of non-RL agents purely through interventions aimed at\nmeasuring strategic link scores - as an example, we consider a realistic\ntraffic simulator and analyze through road closures the effective planning\nhorizon of the emergent routing behavior of many drivers.",
    "pdf_url": "http://arxiv.org/pdf/2505.16833v1",
    "published": "2025-05-22T16:04:17+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16832v2",
    "title": "From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Reasoning-Driven Pedagogical Visualization",
    "authors": [
      "Haonian Ji",
      "Shi Qiu",
      "Siyang Xin",
      "Siwei Han",
      "Zhaorun Chen",
      "Dake Zhang",
      "Hongyi Wang",
      "Huaxiu Yao"
    ],
    "abstract": "While foundation models (FMs), such as diffusion models and large\nvision-language models (LVLMs), have been widely applied in educational\ncontexts, their ability to generate pedagogically effective visual explanations\nremains limited. Most existing approaches focus primarily on textual reasoning,\noverlooking the critical role of structured and interpretable visualizations in\nsupporting conceptual understanding. To better assess the visual reasoning\ncapabilities of FMs in educational settings, we introduce EduVisBench, a\nmulti-domain, multi-level benchmark. EduVisBench features diverse STEM problem\nsets requiring visually grounded solutions, along with a fine-grained\nevaluation rubric informed by pedagogical theory. Our empirical analysis\nreveals that existing models frequently struggle with the inherent challenge of\ndecomposing complex reasoning and translating it into visual representations\naligned with human cognitive processes. To address these limitations, we\npropose EduVisAgent, a multi-agent collaborative framework that coordinates\nspecialized agents for instructional planning, reasoning decomposition,\nmetacognitive prompting, and visualization design. Experimental results show\nthat EduVisAgent substantially outperforms all baselines, achieving a 40.2%\nimprovement and delivering more educationally aligned visualizations.\nEduVisBench and EduVisAgent are available at\nhttps://github.com/aiming-lab/EduVisBench and\nhttps://github.com/aiming-lab/EduVisAgent.",
    "pdf_url": "http://arxiv.org/pdf/2505.16832v2",
    "published": "2025-05-22T16:02:18+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16831v1",
    "title": "Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs",
    "authors": [
      "Xiaoyu Xu",
      "Xiang Yue",
      "Yang Liu",
      "Qingqing Ye",
      "Haibo Hu",
      "Minxin Du"
    ],
    "abstract": "Unlearning in large language models (LLMs) is intended to remove the\ninfluence of specific data, yet current evaluations rely heavily on token-level\nmetrics such as accuracy and perplexity. We show that these metrics can be\nmisleading: models often appear to forget, but their original behavior can be\nrapidly restored with minimal fine-tuning, revealing that unlearning may\nobscure information rather than erase it. To diagnose this phenomenon, we\nintroduce a representation-level evaluation framework using PCA-based\nsimilarity and shift, centered kernel alignment, and Fisher information.\nApplying this toolkit across six unlearning methods, three domains (text, code,\nmath), and two open-source LLMs, we uncover a critical distinction between\nreversible and irreversible forgetting. In reversible cases, models suffer\ntoken-level collapse yet retain latent features; in irreversible cases, deeper\nrepresentational damage occurs. We further provide a theoretical account\nlinking shallow weight perturbations near output layers to misleading\nunlearning signals, and show that reversibility is modulated by task type and\nhyperparameters. Our findings reveal a fundamental gap in current evaluation\npractices and establish a new diagnostic foundation for trustworthy unlearning\nin LLMs. We provide a unified toolkit for analyzing LLM representation changes\nunder unlearning and relearning:\nhttps://github.com/XiaoyuXU1/Representational_Analysis_Tools.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.16831v1",
    "published": "2025-05-22T16:02:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16830v1",
    "title": "Asymptotics of Fredholm determinant solutions of the noncommutative Painlevé II equation",
    "authors": [
      "Jia-Hao Du",
      "Shuai-Xia Xu",
      "Yu-Qiu Zhao"
    ],
    "abstract": "In this paper, we study the asymptotic behavior of a family of pole-free\nsolutions to the noncommutative Painlev\\'e II equation. These particular\nsolutions can be expressed in terms of the Fredholm determinant of the matrix\nversion of the classical Airy operator, which are analogous to the\nHastings-McLeod solution and the Ablowitz-Segur solution of the classical\nPainlev\\'e II equation. Using the Riemann-Hilbert approach, we derive the\nasymptotics of the Fredholm determinant and the associated particular solutions\n$\\beta(\\vec{s})$ to the noncommutative Painlev\\'e II equation in the regime\n$\\vec{s}=\\left(s+\\frac{\\tau}{\\sqrt{-s}},s-\\frac{\\tau}{\\sqrt{-s}}\\right)$ with\n$\\tau\\ge 0$ and $s\\to-\\infty$. The solutions depend on a two by two Hermitian\nmatrix with eigenvalues in the interval $(-1,1)$. The asymptotics are expressed\nin terms of one parameter family of special solutions of the classical\nPainlev\\'e V equation. Furthermore, we derive the asymptotics, including the\nconnection formulas, for this one parameter family of solutions of the\nPainlev\\'e V equation both as $ix\\to -\\infty$ and $x\\to 0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16830v1",
    "published": "2025-05-22T16:01:52+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16829v1",
    "title": "Contextual Learning for Stochastic Optimization",
    "authors": [
      "Anna Heuser",
      "Thomas Kesselheim"
    ],
    "abstract": "Motivated by stochastic optimization, we introduce the problem of learning\nfrom samples of contextual value distributions. A contextual value distribution\ncan be understood as a family of real-valued distributions, where each sample\nconsists of a context $x$ and a random variable drawn from the corresponding\nreal-valued distribution $D_x$. By minimizing a convex surrogate loss, we learn\nan empirical distribution $D'_x$ for each context, ensuring a small L\\'evy\ndistance to $D_x$. We apply this result to obtain the sample complexity bounds\nfor the learning of an $\\epsilon$-optimal policy for stochastic optimization\nproblems defined on an unknown contextual value distribution. The sample\ncomplexity is shown to be polynomial for the general case of strongly monotone\nand stable optimization problems, including Single-item Revenue Maximization,\nPandora's Box and Optimal Stopping.",
    "pdf_url": "http://arxiv.org/pdf/2505.16829v1",
    "published": "2025-05-22T16:01:49+00:00",
    "categories": [
      "cs.LG",
      "cs.DS",
      "cs.GT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16828v3",
    "title": "Rotatable Antenna Enabled Wireless Communication and Sensing: Opportunities and Challenges",
    "authors": [
      "Beixiong Zheng",
      "Tiantian Ma",
      "Changsheng You",
      "Jie Tang",
      "Robert Schober",
      "Rui Zhang"
    ],
    "abstract": "Non-fixed flexible antenna architectures, such as fluid antenna system (FAS),\nmovable antenna (MA), and pinching antenna, have garnered significant interest\nin recent years. Among them, rotatable antenna (RA) is an emerging technology\nthat offers significant potential to enhance wireless communication and sensing\nperformance by flexibly adjusting the boresight of directional antennas.\nSpecifically, RA can flexibly reconfigure its boresight direction via\nmechanical or electronic means, thereby improving communication channel\nconditions and/or enhancing sensing resolution and range. In this article, we\nfirst provide an overview of RA, covering its hardware architectures and\nradiation pattern characterization. We then illustrate how RA improves\ncommunication performance through interference mitigation, spatial\nmultiplexing, and flexible beamforming, as well as sensing capabilities in\nterms of coverage, resolution, and multi-target/dimensional sensing.\nFurthermore, we highlight representative applications of RA and discuss key\ndesign challenges in RA systems, including rotational scanning scheduling,\nchannel estimation/sensing, boresight optimization, and RA configuration.\nFinally, both experimental and simulation results are provided to validate the\nperformance gains achieved by RA for both communication and sensing. Leveraging\nits unique capabilities in flexible antenna/array rotation to adapt to various\ncommunication/sensing requirements and channel conditions, RA is poised to\nbecome a key enabler of future intelligent, resilient, and agile wireless\nnetworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16828v3",
    "published": "2025-05-22T16:01:07+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16827v1",
    "title": "GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent",
    "authors": [
      "Bin Xie",
      "Rui Shao",
      "Gongwei Chen",
      "Kaiwen Zhou",
      "Yinchuan Li",
      "Jie Liu",
      "Min Zhang",
      "Liqiang Nie"
    ],
    "abstract": "GUI automation faces critical challenges in dynamic environments. MLLMs\nsuffer from two key issues: misinterpreting UI components and outdated\nknowledge. Traditional fine-tuning methods are costly for app-specific\nknowledge updates. We propose GUI-explorer, a training-free GUI agent that\nincorporates two fundamental mechanisms: (1) Autonomous Exploration of\nFunction-aware Trajectory. To comprehensively cover all application\nfunctionalities, we design a Function-aware Task Goal Generator that\nautomatically constructs exploration goals by analyzing GUI structural\ninformation (e.g., screenshots and activity hierarchies). This enables\nsystematic exploration to collect diverse trajectories. (2) Unsupervised Mining\nof Transition-aware Knowledge. To establish precise screen-operation logic, we\ndevelop a Transition-aware Knowledge Extractor that extracts effective\nscreen-operation logic through unsupervised analysis the state transition of\nstructured interaction triples (observation, action, outcome). This eliminates\nthe need for human involvement in knowledge extraction. With a task success\nrate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows\nsignificant improvements over SOTA agents. It requires no parameter updates for\nnew apps. GUI-explorer is open-sourced and publicly available at\nhttps://github.com/JiuTian-VL/GUI-explorer.",
    "pdf_url": "http://arxiv.org/pdf/2505.16827v1",
    "published": "2025-05-22T16:01:06+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16826v1",
    "title": "KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning",
    "authors": [
      "Wei Sun",
      "Wen Yang",
      "Pu Jian",
      "Qianlong Du",
      "Fuwei Cui",
      "Shuo Ren",
      "Jiajun Zhang"
    ],
    "abstract": "Recent advances have demonstrated that integrating reinforcement learning\nwith rule-based rewards can significantly enhance the reasoning capabilities of\nlarge language models, even without supervised fine-tuning. However, prevalent\nreinforcement learning algorithms such as GRPO and its variants like DAPO,\nsuffer from a coarse granularity issue when computing the advantage.\nSpecifically, they compute rollout-level advantages that assign identical\nvalues to every token within a sequence, failing to capture token-specific\ncontributions and hindering effective learning. To address this limitation, we\npropose Key-token Advantage Estimation (KTAE) - a novel algorithm that\nestimates fine-grained, token-level advantages without introducing additional\nmodels. KTAE leverages the correctness of sampled rollouts and applies\nstatistical analysis to quantify the importance of individual tokens within a\nsequence to the final outcome. This quantified token-level importance is then\ncombined with the rollout-level advantage to obtain a more fine-grained\ntoken-level advantage estimation. Empirical results show that models trained\nwith GRPO+KTAE and DAPO+KTAE outperform baseline methods across five\nmathematical reasoning benchmarks. Notably, they achieve higher accuracy with\nshorter responses and even surpass R1-Distill-Qwen-1.5B using the same base\nmodel.",
    "pdf_url": "http://arxiv.org/pdf/2505.16826v1",
    "published": "2025-05-22T16:00:33+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16825v1",
    "title": "Impacts of Tidal Locking on Magnetospheric Energy Input to Exoplanet Atmospheres",
    "authors": [
      "Fatemeh Bagheri",
      "Alex Glocer",
      "Ramon E. Lopez"
    ],
    "abstract": "We investigate the effect of planetary corotation on energy dissipation\nwithin the magnetosphere-ionosphere system of exoplanets. Using MHD\nsimulations, we find that tidally locked exoplanets have a higher cross-polar\ncap potential (CPCP) compared to fast-rotating planets with the same magnetic\nfield strength, confirming previous studies. Our simulations show that for a\ngiven interplanetary magnetic field, an increase in corotation period leads to\na higher CPCP. Notably, this difference in CPCP between tidally locked and\nrotating planets persists across a range of solar wind conditions, including\nextreme environments such as those experienced by hot Jupiters. Furthermore, we\nobserve that variations in corotation have little impact on CPCP for\nEarth-sized planets. These results underscore the significance of both\ncorotation dynamics and planetary size in understanding how exoplanets interact\nwith their stellar environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16825v1",
    "published": "2025-05-22T16:00:05+00:00",
    "categories": [
      "astro-ph.EP",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16824v1",
    "title": "Interfacial Effects Determine Nonequilibrium Phase Behaviors in Chemically Driven Fluids",
    "authors": [
      "Yongick Cho",
      "William M. Jacobs"
    ],
    "abstract": "Coupling between chemical fuel consumption and phase separation can lead to\ncondensation at a nonequilibrium steady state, resulting in phase behaviors\nthat are not described by equilibrium thermodynamics. Theoretical models of\nsuch \"chemically driven fluids\" typically invoke near-equilibrium\napproximations at small length scales. However, because dissipation occurs due\nto both molecular-scale chemical reactions and mesoscale diffusive transport,\nit has remained unclear which properties of phase-separated reaction-diffusion\nsystems can be assumed to be at an effective equilibrium. Here we use\nmicroscopic simulations to show that mesoscopic fluxes are dependent on\nnonequilibrium fluctuations at phase-separated interfaces. We further develop a\nfirst-principles theory to predict nonequilibrium coexistence curves,\nlocalization of mesoscopic fluxes near phase-separated interfaces, and droplet\nsize-scaling relations in good agreement with simulations. Our findings\nhighlight the central role of interfacial properties in governing\nnonequilibrium condensation and have broad implications for droplet nucleation,\ncoarsening, and size control in chemically driven fluids.",
    "pdf_url": "http://arxiv.org/pdf/2505.16824v1",
    "published": "2025-05-22T15:58:32+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech",
      "physics.bio-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.16823v1",
    "title": "OWP-IMU: An RSS-based Optical Wireless and IMU Indoor Positioning Dataset",
    "authors": [
      "Fan Wu",
      "Jorik De Bruycker",
      "Daan Delabie",
      "Nobby Stevens",
      "Francois Rottenberg",
      "Lieven De Strycker"
    ],
    "abstract": "Received signal strength (RSS)-based optical wireless positioning (OWP)\nsystems are becoming popular for indoor localization because they are low-cost\nand accurate. However, few open-source datasets are available to test and\nanalyze RSS-based OWP systems. In this paper, we collected RSS values at a\nsampling frequency of 27 Hz, inertial measurement unit (IMU) at a sampling\nfrequency of 200 Hz and the ground truth at a sampling frequency of 160 Hz in\ntwo indoor environments. One environment has no obstacles, and the other has a\nmetal column as an obstacle to represent a non-line-of-sight (NLOS) scenario.\nWe recorded data with a vehicle at three different speeds (low, medium and\nhigh). The dataset includes over 110 k data points and covers more than 80 min.\nWe also provide benchmark tests to show localization performance using only\nRSS-based OWP and improve accuracy by combining IMU data via extended kalman\nfilter. The dataset OWP-IMU is open source1 to support further research on\nindoor localization methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.16823v1",
    "published": "2025-05-22T15:58:17+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16822v1",
    "title": "Quantitative bounds in a popular polynomial Szemerédi theorem",
    "authors": [
      "Xuancheng Shao",
      "Mengdi Wang"
    ],
    "abstract": "We obtain polylogarithmic bounds in the polynomial Szemer\\'{e}di theorem when\nthe polynomials have distinct degrees and zero constant terms. Specifically,\nlet $P_1, \\dots, P_m \\in \\mathbb Z[y]$ be polynomials with distinct degrees,\neach having zero constant term. Then there exists a constant $c =\nc(P_1,\\dots,P_m) > 0$ such that any subset $A \\subset \\{1,2,\\dots,N\\}$ of\ndensity at least $(\\log N)^{-c}$ contains a nontrivial polynomial progression\nof the form $x, x+P_1(y), \\dots, x+P_m(y)$. In addition, we prove an effective\n``popular'' version, showing that every dense subset $A$ has some non-zero $y$\nsuch that the number of polynomial progressions in $A$ with this difference $y$\nis almost optimal.",
    "pdf_url": "http://arxiv.org/pdf/2505.16822v1",
    "published": "2025-05-22T15:57:49+00:00",
    "categories": [
      "math.NT",
      "math.CO"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16821v2",
    "title": "LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols",
    "authors": [
      "Ziming Liu",
      "Bryan Liu",
      "Alvaro Valcarce",
      "Xiaoli Chu"
    ],
    "abstract": "Integrating large AI models (LAMs) into 6G mobile networks promises to\nredefine protocol design and control-plane intelligence by enabling autonomous,\ncognitive network operations. While industry concepts, such as ETSI's\nExperiential Networked Intelligence (ENI), envision LAM-driven agents for\nadaptive network slicing and intent-based management, practical implementations\nstill face challenges in protocol literacy and real-world deployment. This\npaper presents an end-to-end demonstration of a LAM that generates\nstandards-compliant, ASN.1-encoded Radio Resource Control (RRC) messages as\npart of control-plane procedures inside a gNB. We treat RRC messaging as a\ndomain-specific language and fine-tune a decoder-only transformer model (LLaMA\nclass) using parameter-efficient Low-Rank Adaptation (LoRA) on RRC messages\nlinearized to retain their ASN.1 syntactic structure before standard byte-pair\nencoding tokenization. This enables combinatorial generalization over RRC\nprotocol states while minimizing training overhead. On 30k field-test\nrequest-response pairs, our 8 B model achieves a median cosine similarity of\n0.97 with ground-truth messages on an edge GPU -- a 61 % relative gain over a\nzero-shot LLaMA-3 8B baseline -- indicating substantially improved structural\nand semantic RRC fidelity. Overall, our results show that LAMs, when augmented\nwith Radio Access Network (RAN)-specific reasoning, can directly orchestrate\ncontrol-plane procedures, representing a stepping stone toward the AI-native\nair-interface paradigm. Beyond RRC emulation, this work lays the groundwork for\nfuture AI-native wireless standards.",
    "pdf_url": "http://arxiv.org/pdf/2505.16821v2",
    "published": "2025-05-22T15:55:56+00:00",
    "categories": [
      "cs.NI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16820v2",
    "title": "Isotropy, anisotropies and non-Gaussianity in the scalar-induced gravitational-wave background: diagrammatic approach for primordial non-Gaussianity up to arbitrary order",
    "authors": [
      "Jun-Peng Li",
      "Sai Wang",
      "Zhi-Chao Zhao",
      "Kazunori Kohri"
    ],
    "abstract": "Produced nonlinearly by the enhanced linear cosmological curvature\nperturbations, the scalar-induced gravitational waves (SIGWs) can serve as a\npotentially powerful probe of primordial non-Gaussianity (PNG) in the early\nUniverse. In this work, we comprehensively investigate the imprints of\nlocal-type PNG on the SIGW background beyond the widely used quadratic and\ncubic approximations. We develop a diagrammatic approach capable of analyzing\nSIGWs for PNG up to arbitrary order. Following this approach, we derive\nsemi-analytic formulas for the energy-density fraction spectrum, the angular\npower spectrum, and the angular bispectrum and trispectrum to describe the\nisotropic component, anisotropies, and non-Gaussianity of the SIGW background,\nrespectively. Particularly, focusing on PNG up to quartic approximation\n(parameterized by $f_\\mathrm{NL}$, $g_\\mathrm{NL}$, and $h_\\mathrm{NL}$), we\nnumerically compute all contributions to these SIGW spectra. We find that PNG\ncan significantly alter the magnitude of the SIGW energy-density spectrum, and\ncan generate substantial anisotropies through the initial inhomogeneities in\nthe SIGW distribution. Furthermore, we observe that the SIGW angular bispectrum\nand trispectrum always vanish when the primordial curvature perturbations are\nGaussian; otherwise, they do not, indicating their potential utility as probes\nof PNG. Therefore, we anticipate that the SIGW background will provide\nessential information about the early Universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.16820v2",
    "published": "2025-05-22T15:55:50+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16819v2",
    "title": "Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts",
    "authors": [
      "Taewon Kang",
      "Ming C. Lin"
    ],
    "abstract": "Recent advances in scene-based video generation have enabled systems to\nsynthesize coherent visual narratives from structured prompts. However, a\ncrucial dimension of storytelling -- character-driven dialogue and speech --\nremains underexplored. In this paper, we present a modular pipeline that\ntransforms action-level prompts into visually and auditorily grounded narrative\ndialogue, enriching visual storytelling with natural voice and character\nexpression. Our method takes as input a pair of prompts per scene, where the\nfirst defines the setting and the second specifies a character's behavior.\nWhile a story generation model such as Text2Story produces the corresponding\nvisual scene, we focus on generating expressive, character-consistent\nutterances grounded in both the prompts and the scene image. A pretrained\nvision-language encoder extracts high-level semantic features from a\nrepresentative frame, capturing salient visual context. These features are then\nintegrated with structured prompts to guide a large language model in\nsynthesizing natural dialogue. To ensure contextual and emotional consistency\nacross scenes, we introduce a Recursive Narrative Bank -- a speaker-aware,\ntemporally structured memory that recursively accumulates each character's\ndialogue history. Inspired by Script Theory in cognitive psychology, this\ndesign enables characters to speak in ways that reflect their evolving goals,\nsocial context, and narrative roles throughout the story. Finally, we render\neach utterance as expressive, character-conditioned speech, resulting in\nfully-voiced, multimodal video narratives. Our training-free framework\ngeneralizes across diverse story settings -- from fantasy adventures to\nslice-of-life episodes -- offering a scalable solution for coherent,\ncharacter-grounded audiovisual storytelling.",
    "pdf_url": "http://arxiv.org/pdf/2505.16819v2",
    "published": "2025-05-22T15:54:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16818v1",
    "title": "Spanning trees of bounded degree in random geometric graphs",
    "authors": [
      "Michael Anastos",
      "Sahar Diskin",
      "Dawid Ignasiak",
      "Lyuben Lichev",
      "Yetong Sha"
    ],
    "abstract": "We determine the sharp threshold for the containment of all $n$-vertex trees\nof bounded degree in random geometric graphs with $n$ vertices. This provides a\ngeometric counterpart of Montgomery's threshold result for binomial random\ngraphs, and confirms a conjecture of Espuny D\\'iaz, Lichev, Mitsche, and\nWesolek. Our proof is algorithmic and adapts to other families of graphs, in\nparticular graphs with bounded genus or tree-width.",
    "pdf_url": "http://arxiv.org/pdf/2505.16818v1",
    "published": "2025-05-22T15:54:17+00:00",
    "categories": [
      "math.CO",
      "math.MG",
      "math.PR"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.18210v1",
    "title": "Multi-Objective Optimization Algorithms for Energy Management Systems in Microgrids: A Control Strategy Based on a PHIL System",
    "authors": [
      "Saiful Islam",
      "Sanaz Mostaghim",
      "Michael Hartmann"
    ],
    "abstract": "In this research a real time power hardware in loop configuration has been\nimplemented for an microgrid with the combination of distribution energy\nresources such as photovoltaic, grid tied inverter, battery, utility grid, and\na diesel generator. This paper introduces an unique adaptive multi-objective\noptimization approach that employs weighted optimization techniques for\nreal-time microgrid systems. The aim is to effectively balance various factors\nincluding fuel consumption, load mismatch, power quality, battery degradation,\nand the utilization of renewable energy sources. A real time experimental data\nfrom power hardware in loop system has been used for dynamically updating\nsystem states. The adaptive preference-based selection method are adjusted\nbased on state of battery charging thresholds. The technique has been\nintegrated with six technical objectives and complex constraints. This approach\nhelps to practical microgrid decision making and optimization of dynamic energy\nsystems. The energy management process were also able to maximize photovoltaic\nproduction where minimizing power mismatch, stabilizing battery state of charge\nunder different condition. The research results were also compared with the\nbaseline system without optimization techniques, and a reliable outcome was\nfound.",
    "pdf_url": "http://arxiv.org/pdf/2505.18210v1",
    "published": "2025-05-22T15:52:30+00:00",
    "categories": [
      "eess.SY",
      "cs.CE",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16817v1",
    "title": "Braid Group Representations and Defect Operators in AdS/CFT Correspondence",
    "authors": [
      "Tzu-Miao Chou"
    ],
    "abstract": "This paper investigates the connection between braid group representations,\ndefect operators, and holography within the AdS/CFT framework. It focuses on\nthe correspondence between bulk Wilson loops and boundary defect operators,\nemphasizing how braid group representations map to these operators. The study\nalso explores fusion and braiding operations in modular tensor categories,\nwhich are crucial for understanding anyons in topological quantum field\ntheories. By providing a unified framework, this work bridges the gap between\nbulk and boundary physics and offers insights into the holographic realization\nof topological defects. The results suggest new avenues for research in\nholographic anyons and their applications in quantum field theory and condensed\nmatter physics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16817v1",
    "published": "2025-05-22T15:52:11+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16816v2",
    "title": "Fusion for High-Dimensional Linear Optical Quantum Computing with Improved Success Probability",
    "authors": [
      "Gözde Üstün",
      "Eleanor G. Rieffel",
      "Simon J. Devitt",
      "Jason Saied"
    ],
    "abstract": "Type-II fusion is a probabilistic entangling measurement that is essential to\nmeasurement-based linear optical quantum computing and can be used for quantum\nteleportation more broadly. However, it remains under-explored for\nhigh-dimensional qudits. Our main result gives a Type-II fusion protocol with\nproven success probability approximately $2/d^2$ for qudits of arbitrary\ndimension $d$. This generalizes a previous method which only applied to\neven-dimensional qudits. We believe this protocol to be the most efficient\nknown protocol for Type-II fusion, with the $d=5$ case beating the previous\nrecord by a factor of approximately $723$. We discuss the construction of the\nrequired $(d-2)$-qudit ancillary state using a silicon spin qudit ancilla\ncoupled to a microwave cavity through time-bin multiplexing. We then introduce\na general framework of extra-dimensional corrections, a natural technique in\nlinear optics that can be used to non-deterministically correct\nnon-maximally-entangled projections into Bell measurements. We use this method\nto analyze and improve several different circuits for high-dimensional Type-II\nfusion and compare their benefits and drawbacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16816v2",
    "published": "2025-05-22T15:52:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16815v1",
    "title": "Perceptual Quality Assessment for Embodied AI",
    "authors": [
      "Chunyi Li",
      "Jiaohao Xiao",
      "Jianbo Zhang",
      "Farong Wen",
      "Zicheng Zhang",
      "Yuan Tian",
      "Xiangyang Zhu",
      "Xiaohong Liu",
      "Zhengxue Cheng",
      "Weisi Lin",
      "Guangtao Zhai"
    ],
    "abstract": "Embodied AI has developed rapidly in recent years, but it is still mainly\ndeployed in laboratories, with various distortions in the Real-world limiting\nits application. Traditionally, Image Quality Assessment (IQA) methods are\napplied to predict human preferences for distorted images; however, there is no\nIQA method to assess the usability of an image in embodied tasks, namely, the\nperceptual quality for robots. To provide accurate and reliable quality\nindicators for future embodied scenarios, we first propose the topic: IQA for\nEmbodied AI. Specifically, we (1) based on the Mertonian system and\nmeta-cognitive theory, constructed a perception-cognition-decision-execution\npipeline and defined a comprehensive subjective score collection process; (2)\nestablished the Embodied-IQA database, containing over 36k reference/distorted\nimage pairs, with more than 5m fine-grained annotations provided by Vision\nLanguage Models/Vision Language Action-models/Real-world robots; (3) trained\nand validated the performance of mainstream IQA methods on Embodied-IQA,\ndemonstrating the need to develop more accurate quality indicators for Embodied\nAI. We sincerely hope that through evaluation, we can promote the application\nof Embodied AI under complex distortions in the Real-world. Project page:\nhttps://github.com/lcysyzxdxc/EmbodiedIQA",
    "pdf_url": "http://arxiv.org/pdf/2505.16815v1",
    "published": "2025-05-22T15:51:07+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16814v2",
    "title": "Does Synthetic Data Help Named Entity Recognition for Low-Resource Languages?",
    "authors": [
      "Gaurav Kamath",
      "Sowmya Vajjala"
    ],
    "abstract": "Named Entity Recognition(NER) for low-resource languages aims to produce\nrobust systems for languages where there is limited labeled training data\navailable, and has been an area of increasing interest within NLP. Data\naugmentation for increasing the amount of low-resource labeled data is a common\npractice. In this paper, we explore the role of synthetic data in the context\nof multilingual, low-resource NER, considering 11 languages from diverse\nlanguage families. Our results suggest that synthetic data does in fact hold\npromise for low-resource language NER, though we see significant variation\nbetween languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.16814v2",
    "published": "2025-05-22T15:50:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16813v1",
    "title": "Dynamic Reservoir Computing with Physical Neuromorphic Networks",
    "authors": [
      "Yinhao Xu",
      "Georg A. Gottwald",
      "Zdenka Kuncic"
    ],
    "abstract": "Reservoir Computing (RC) with physical systems requires an understanding of\nthe underlying structure and internal dynamics of the specific physical\nreservoir. In this study, physical nano-electronic networks with neuromorphic\ndynamics are investigated for their use as physical reservoirs in an RC\nframework. These neuromorphic networks operate as dynamic reservoirs, with node\nactivities in general coupled to the edge dynamics through nonlinear\nnano-electronic circuit elements, and the reservoir outputs influenced by the\nunderlying network connectivity structure. This study finds that networks with\nvarying degrees of sparsity generate more useful nonlinear temporal outputs for\ndynamic RC compared to dense networks. Dynamic RC is also tested on an\nautonomous multivariate chaotic time series prediction task with networks of\nvarying densities, which revealed the importance of network sparsity in\nmaintaining network activity and overall dynamics, that in turn enabled the\nlearning of the chaotic Lorenz63 system's attractor behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.16813v1",
    "published": "2025-05-22T15:50:45+00:00",
    "categories": [
      "cs.ET",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.16812v1",
    "title": "Lp boundedness, r-nuclearity and approximation of pseudo-differential operators on $\\hbar\\mathbb{Z}^n$",
    "authors": [
      "Juan Pablo Lopez"
    ],
    "abstract": "In this work sufficient conditions on the order of the symbol are developed\nto ensure boundedness, compactness and r-nuclearity of pseudo-differential\noperators in $\\hbar\\mathbb{Z}^n$. In addition, these conditions allow us to\nobtain growth estimates for the eigenvalues of some elliptic operators, in\nparticular perturbed discrete Schr\\\"odinger operator.",
    "pdf_url": "http://arxiv.org/pdf/2505.16812v1",
    "published": "2025-05-22T15:50:30+00:00",
    "categories": [
      "math.AP",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16811v1",
    "title": "Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining",
    "authors": [
      "Shangquan Sun",
      "Wenqi Ren",
      "Juxiang Zhou",
      "Shu Wang",
      "Jianhou Gan",
      "Xiaochun Cao"
    ],
    "abstract": "Significant progress has been made in video restoration under rainy\nconditions over the past decade, largely propelled by advancements in deep\nlearning. Nevertheless, existing methods that depend on paired data struggle to\ngeneralize effectively to real-world scenarios, primarily due to the disparity\nbetween synthetic and authentic rain effects. To address these limitations, we\npropose a dual-branch spatio-temporal state-space model to enhance rain streak\nremoval in video sequences. Specifically, we design spatial and temporal\nstate-space model layers to extract spatial features and incorporate temporal\ndependencies across frames, respectively. To improve multi-frame feature\nfusion, we derive a dynamic stacking filter, which adaptively approximates\nstatistical filters for superior pixel-wise feature refinement. Moreover, we\ndevelop a median stacking loss to enable semi-supervised learning by generating\npseudo-clean patches based on the sparsity prior of rain. To further explore\nthe capacity of deraining models in supporting other vision-based tasks in\nrainy environments, we introduce a novel real-world benchmark focused on object\ndetection and tracking in rainy conditions. Our method is extensively evaluated\nacross multiple benchmarks containing numerous synthetic and real-world rainy\nvideos, consistently demonstrating its superiority in quantitative metrics,\nvisual quality, efficiency, and its utility for downstream tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16811v1",
    "published": "2025-05-22T15:50:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16810v2",
    "title": "DeepRec: Towards a Deep Dive Into the Item Space with Large Language Model Based Recommendation",
    "authors": [
      "Bowen Zheng",
      "Xiaolei Wang",
      "Enze Liu",
      "Xi Wang",
      "Lu Hongyu",
      "Yu Chen",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, large language models (LLMs) have been introduced into recommender\nsystems (RSs), either to enhance traditional recommendation models (TRMs) or\nserve as recommendation backbones. However, existing LLM-based RSs often do not\nfully exploit the complementary advantages of LLMs (e.g., world knowledge and\nreasoning) and TRMs (e.g., recommendation-specific knowledge and efficiency) to\nfully explore the item space. To address this, we propose DeepRec, a novel\nLLM-based RS that enables autonomous multi-turn interactions between LLMs and\nTRMs for deep exploration of the item space. In each interaction turn, LLMs\nreason over user preferences and interact with TRMs to retrieve candidate\nitems. After multi-turn interactions, LLMs rank the retrieved items to generate\nthe final recommendations. We adopt reinforcement learning(RL) based\noptimization and propose novel designs from three aspects: recommendation model\nbased data rollout, recommendation-oriented hierarchical rewards, and a\ntwo-stage RL training strategy. For data rollout, we introduce a\npreference-aware TRM, with which LLMs interact to construct trajectory data.\nFor rewards, we design a hierarchical reward function that involves both\nprocess-level and outcome-level rewards to optimize the interaction process and\nrecommendation performance, respectively. For RL training, we develop a\ntwo-stage training strategy, where the first stage aims to guide LLMs to\ninteract with TRMs and the second stage focuses on performance improvement.\nExperiments on public datasets demonstrate that DeepRec significantly\noutperforms both traditional and LLM-based baselines, offering a new paradigm\nfor deep exploration in recommendation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16810v2",
    "published": "2025-05-22T15:49:38+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16809v3",
    "title": "Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor Segmentation with Missing Modalities",
    "authors": [
      "Junze Wang",
      "Lei Fan",
      "Weipeng Jing",
      "Donglin Di",
      "Yang Song",
      "Sidong Liu",
      "Cong Cong"
    ],
    "abstract": "Existing methods for multimodal MRI segmentation with missing modalities\ntypically assume that all MRI modalities are available during training.\nHowever, in clinical practice, some modalities may be missing due to the\nsequential nature of MRI acquisition, leading to performance degradation.\nFurthermore, retraining models to accommodate newly available modalities can be\ninefficient and may cause overfitting, potentially compromising previously\nlearned knowledge. To address these challenges, we propose Replay-based\nHypergraph Domain Incremental Learning (ReHyDIL) for brain tumor segmentation\nwith missing modalities. ReHyDIL leverages Domain Incremental Learning (DIL) to\nenable the segmentation model to learn from newly acquired MRI modalities\nwithout forgetting previously learned information. To enhance segmentation\nperformance across diverse patient scenarios, we introduce the Cross-Patient\nHypergraph Segmentation Network (CHSNet), which utilizes hypergraphs to capture\nhigh-order associations between patients. Additionally, we incorporate\nTversky-Aware Contrastive (TAC) loss to effectively mitigate information\nimbalance both across and within different modalities. Extensive experiments on\nthe BraTS2019 dataset demonstrate that ReHyDIL outperforms state-of-the-art\nmethods, achieving an improvement of over 2% in the Dice Similarity Coefficient\nacross various tumor regions. Our code is available at\nhttps://github.com/reeive/ReHyDIL.",
    "pdf_url": "http://arxiv.org/pdf/2505.16809v3",
    "published": "2025-05-22T15:49:25+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16808v1",
    "title": "Fractional balanced chromatic number and arboricity of planar (signed) graphs",
    "authors": [
      "Reza Naserasr",
      "Lan Anh Pham",
      "Cyril Pujol",
      "Huan Zhou"
    ],
    "abstract": "A fractional coloring of a signed graph $(G, {\\sigma})$ is an assignment of\nnonnegative weights to the balanced sets (sets which do not induce a negative\ncycle) such that each vertex has an accumulated weight of at least 1. The\nminimum total wight among all such colorings is defined to be the fractional\nbalanced chromatic number, denoted by $\\chi-{fb}(G, {\\sigma})$. This value is\nclearly upper bounded by the fractional arboricity of $G$, denoted $a_f (G)$,\nwhere weights are assigned to sets inducing no cycle rather than sets inducing\nno negative cycle. In this work we present an example of a planar signed simple\ngraph of fractional balanced chromatic number larger than 2, thus in particular\nrefuting a conjecture of Bonamy, Kardos, Kelly, and Postle suggesting that the\nfractional arboricity of planar graphs is bounded above by 2. By iterating the\nconstruction, we show that the supremum of the fractional balanced chromatic\nnumber of planar signed simple graphs is at least as $83/41 = 2 + 1/41$. With\nsimilar operations, we built a sequence of planar graphs whose limit of\nfractional arboricity is $a_f (G) = 2 + 2/25$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16808v1",
    "published": "2025-05-22T15:48:11+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16807v1",
    "title": "Chirp Delay-Doppler Domain Modulation: A New Paradigm of Integrated Sensing and Communication for Autonomous Vehicles",
    "authors": [
      "Zhuoran Li",
      "Shufeng Tan",
      "Zhen Gao",
      "Yi Tao",
      "Zhonghuai Wu",
      "Zhongxiang Li",
      "Chun Hu",
      "Dezhi Zheng"
    ],
    "abstract": "Autonomous driving is reshaping the way humans travel, with millimeter wave\n(mmWave) radar playing a crucial role in this transformation to enabe\nvehicle-to-everything (V2X). Although chirp is widely used in mmWave radar\nsystems for its strong sensing capabilities, the lack of integrated\ncommunication functions in existing systems may limit further advancement of\nautonomous driving. In light of this, we first design ``dedicated chirps\"\ntailored for sensing chirp signals in the environment, facilitating the\nidentification of idle time-frequency resources. Based on these dedicated\nchirps, we propose a chirp-division multiple access (Chirp-DMA) scheme,\nenabling multiple pairs of mmWave radar transceivers to perform integrated\nsensing and communication (ISAC) without interference. Subsequently, we propose\ntwo chirp-based delay-Doppler domain modulation schemes that enable each pair\nof mmWave radar transceivers to simultaneously sense and communicate within\ntheir respective time-frequency resource blocks. The modulation schemes are\nbased on different multiple-input multiple-output (MIMO) radar schemes: the\ntime division multiplexing (TDM)-based scheme offers higher communication\nrates, while the Doppler division multiplexing (DDM)-based scheme is suitable\nfor working in a lower signal-to-noise ratio range. We then validate the\neffectiveness of the proposed DDM-based scheme through simulations. Finally, we\npresent some challenges and issues that need to be addressed to advance ISAC in\nV2X for better autonomous driving. Simulation codes are provided to reproduce\nthe results in this paper:\n\\href{https://github.com/LiZhuoRan0/2025-IEEE-Network-ChirpDelayDopplerModulationISAC}{https://github.com/LiZhuoRan0}.",
    "pdf_url": "http://arxiv.org/pdf/2505.16807v1",
    "published": "2025-05-22T15:47:06+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16806v1",
    "title": "Two-way Evidence self-Alignment based Dual-Gated Reasoning Enhancement",
    "authors": [
      "Kexin Zhang",
      "Junlan Chen",
      "Daifeng Li",
      "Yuxuan Zhang",
      "Yangyang Feng",
      "Bowen Deng",
      "Weixu Chen"
    ],
    "abstract": "Large language models (LLMs) encounter difficulties in knowledge-intensive\nmulti-step reasoning (KIMSR) tasks. One challenge is how to effectively extract\nand represent rationale evidence. The current methods often extract\nsemantically relevant but logically irrelevant evidence, resulting in flawed\nreasoning and inaccurate responses. We propose a two-way evidence\nself-alignment (TW-ESA) module, which utilizes the mutual alignment between\nstrict reasoning and LLM reasoning to enhance its understanding of the causal\nlogic of evidence, thereby addressing the first challenge. Another challenge is\nhow to utilize the rationale evidence and LLM's intrinsic knowledge for\naccurate reasoning when the evidence contains uncertainty. We propose a\ndual-gated reasoning enhancement (DGR) module to gradually fuse useful\nknowledge of LLM within strict reasoning, which can enable the model to perform\naccurate reasoning by focusing on causal elements in the evidence and exhibit\ngreater robustness. The two modules are collaboratively trained in a unified\nframework ESA-DGR. Extensive experiments on three diverse and challenging KIMSR\ndatasets reveal that ESA-DGR significantly surpasses state-of-the-art LLM-based\nfine-tuning methods, with remarkable average improvements of 4% in exact match\n(EM) and 5% in F1 score. The implementation code is available at\nhttps://anonymous.4open.science/r/ESA-DGR-2BF8.",
    "pdf_url": "http://arxiv.org/pdf/2505.16806v1",
    "published": "2025-05-22T15:45:29+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16805v1",
    "title": "SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving",
    "authors": [
      "Xuesong Chen",
      "Linjiang Huang",
      "Tao Ma",
      "Rongyao Fang",
      "Shaoshuai Shi",
      "Hongsheng Li"
    ],
    "abstract": "The integration of Vision-Language Models (VLMs) into autonomous driving\nsystems has shown promise in addressing key challenges such as learning\ncomplexity, interpretability, and common-sense reasoning. However, existing\napproaches often struggle with efficient integration and realtime\ndecision-making due to computational demands. In this paper, we introduce\nSOLVE, an innovative framework that synergizes VLMs with end-to-end (E2E)\nmodels to enhance autonomous vehicle planning. Our approach emphasizes\nknowledge sharing at the feature level through a shared visual encoder,\nenabling comprehensive interaction between VLM and E2E components. We propose a\nTrajectory Chain-of-Thought (T-CoT) paradigm, which progressively refines\ntrajectory predictions, reducing uncertainty and improving accuracy. By\nemploying a temporal decoupling strategy, SOLVE achieves efficient cooperation\nby aligning high-quality VLM outputs with E2E real-time performance. Evaluated\non the nuScenes dataset, our method demonstrates significant improvements in\ntrajectory prediction accuracy, paving the way for more robust and reliable\nautonomous driving systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16805v1",
    "published": "2025-05-22T15:44:30+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16804v2",
    "title": "Quantitative delocalization for solid-on-solid models at high temperature and arbitrary tilt",
    "authors": [
      "Sébastien Ott",
      "Florian Schweiger"
    ],
    "abstract": "We study a family of integer-valued random interface models on the\ntwo-dimensional square lattice that include the solid-on-solid model and more\ngenerally $p$-SOS models for $0<p\\le2$, and prove that at sufficiently high\ntemperature the interface is delocalized logarithmically uniformly in the\nboundary data. Fr\\\"ohlich and Spencer had studied the analogous problem with\nfree boundary data, and our proof is based on their multi-scale argument, with\nvarious technical improvements.",
    "pdf_url": "http://arxiv.org/pdf/2505.16804v2",
    "published": "2025-05-22T15:44:17+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16803v1",
    "title": "Many-faced Painlevé I: irregular conformal blocks, topological recursion, and holomorphic anomaly approaches",
    "authors": [
      "Nikolai Iorgov",
      "Kohei Iwaki",
      "Oleg Lisovyy",
      "Yurii Zhuravlov"
    ],
    "abstract": "In recent years, the Fourier series (Zak transform) structure of the\nPainlev\\'e I tau function has emerged in multiple contexts. Its main building\nblock admits several conjectural interpretations, such as the partition\nfunction of an Argyres-Douglas gauge theory, the topological recursion\npartition function for the Weierstrass elliptic curve, and a 1-point conformal\nblock on the Riemann sphere with an irregular insertion of rank $\\frac52$. We\nreview and further develop a mathematical framework for these constructions,\nand formulate conjectures on their equivalence. In particular, we give a simple\nexplanation of the Fourier series representation of the tau function based on\nthe Jimbo-Miwa-Ueno differential extended to the space of Stokes data. We\nprovide an algebraic construction of the rank $\\frac52$ Whittaker state for the\nVirasoro algebra embedded into a rank $2$ Whittaker module, prove its existence\nand uniqueness, and fix its descendant structure. We also prove the conifold\ngap property of the relevant topological recursion partition function, which,\non one hand, enables its efficient computation within the holomorphic anomaly\napproach and, on the other, establishes the existence of solution for the\nlatter.",
    "pdf_url": "http://arxiv.org/pdf/2505.16803v1",
    "published": "2025-05-22T15:43:58+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.CA",
      "math.MP",
      "math.RT",
      "nlin.SI"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16802v1",
    "title": "A Chase-based Approach to Consistent Answers of Analytic Queries in Star Schemas",
    "authors": [
      "Dominique Laurent",
      "Nicolas Spyratos"
    ],
    "abstract": "We present an approach to computing consistent answers to analytic queries in\ndata warehouses operating under a star schema and possibly containing missing\nvalues and inconsistent data. Our approach is based on earlier work concerning\nconsistent query answering for standard, non-analytic queries in multi-table\ndatabases. In that work we presented polynomial algorithms for computing either\nthe exact consistent answer to a standard, non analytic query or bounds of the\nexact answer, depending on whether the query involves a selection condition or\nnot.\n  We extend this approach to computing exact consistent answers of analytic\nqueries over star schemas, provided that the selection condition in the query\ninvolves no keys and satisfies the property of independency (i.e., the\ncondition can be expressed as a conjunction of conditions each involving a\nsingle attribute). The main contributions of this paper are: (a) a polynomial\nalgorithm for computing the exact consistent answer to a usual\nprojection-selection-join query over a star schema under the above restrictions\non the selection condition, and (b) showing that, under the same restrictions\nthe exact consistent answer to an analytic query over a star schema can be\ncomputed in time polynomial in the size of the data warehouse.",
    "pdf_url": "http://arxiv.org/pdf/2505.16802v1",
    "published": "2025-05-22T15:42:20+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.16801v2",
    "title": "A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents",
    "authors": [
      "Eleftherios Kalafatis",
      "Konstantinos Mitsis",
      "Konstantia Zarkogianni",
      "Maria Athanasiou",
      "Konstantina Nikita"
    ],
    "abstract": "Serious Games (SGs) are nowadays shifting focus to include procedural content\ngeneration (PCG) in the development process as a means of offering personalized\nand enhanced player experience. However, the development of a framework to\nassess the impact of PCG techniques when integrated into SGs remains\nparticularly challenging. This study proposes a methodology for automated\nevaluation of PCG integration in SGs, incorporating deep reinforcement learning\n(DRL) game testing agents. To validate the proposed framework, a previously\nintroduced SG featuring card game mechanics and incorporating three different\nversions of PCG for nonplayer character (NPC) creation has been deployed.\nVersion 1 features random NPC creation, while versions 2 and 3 utilize a\ngenetic algorithm approach. These versions are used to test the impact of\ndifferent dynamic SG environments on the proposed framework's agents. The\nobtained results highlight the superiority of the DRL game testing agents\ntrained on Versions 2 and 3 over those trained on Version 1 in terms of win\nrate (i.e. number of wins per played games) and training time. More\nspecifically, within the execution of a test emulating regular gameplay, both\nVersions 2 and 3 peaked at a 97% win rate and achieved statistically\nsignificant higher (p=0009) win rates compared to those achieved in Version 1\nthat peaked at 94%. Overall, results advocate towards the proposed framework's\ncapability to produce meaningful data for the evaluation of procedurally\ngenerated content in SGs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16801v2",
    "published": "2025-05-22T15:40:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16800v1",
    "title": "Learning Beyond Limits: Multitask Learning and Synthetic Data for Low-Resource Canonical Morpheme Segmentation",
    "authors": [
      "Changbing Yang",
      "Garrett Nicolai"
    ],
    "abstract": "We introduce a transformer-based morpheme segmentation system that augments a\nlow-resource training signal through multitask learning and LLM-generated\nsynthetic data. Our framework jointly predicts morphological segments and\nglosses from orthographic input, leveraging shared linguistic representations\nobtained through a common documentary process to enhance model generalization.\nTo further address data scarcity, we integrate synthetic training data\ngenerated by large language models (LLMs) using in-context learning.\nExperimental results on the SIGMORPHON 2023 dataset show that our approach\nsignificantly improves word-level segmentation accuracy and morpheme-level\nF1-score across multiple low-resource languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.16800v1",
    "published": "2025-05-22T15:40:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16799v1",
    "title": "Synthesis of Y$_3$Fe$_4$H$_{20}$ as a new prototype structure for ternary superhydrides recoverable at ambient pressure",
    "authors": [
      "M. Caussé",
      "L. Toraille",
      "G. Geneste",
      "P. Loubeyre"
    ],
    "abstract": "Reaching pressures in the 100 GPa range enables the synthesis of\nhydrogen-rich compounds, with nontraditional H stoichiometries and H\nsublattices, called superhydrides. Record-breaking superconductivity\ntemperature in some superhydrides have attracted great interest. A crucial next\nstep is to stabilize superhydrides outside of high-pressure environments,\nleading to a search beyond binary hydrides to ternary hydrides. Here, we report\nthe synthesis of Y$_3$Fe$_4$H$_{20}$ at pressures starting at 60 GPa by\ncompressing an hydrogenated Y-Fe compound, embedded in hydrogen in a\nlaser-heated diamond anvil cell. Single-crystal X-ray diffraction allowed us to\nresolve the Y$_3$Fe$_4$ lattice skeleton, and a constrained ab initio\nstructural search was used to position the hydrogen atoms. FeH$_8$ cubic\nmolecular units form building blocks which are connected edge-to-edge by\nsharing two hydrogen atoms, creating a framework that hosts Y cations.\nRemarkably, Y$_3$Fe$_4$H$_{20}$ maintains its structure through decompression,\nmaking it the first superhydride recovered metastable under ambient conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16799v1",
    "published": "2025-05-22T15:39:54+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.other",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16798v1",
    "title": "SEED: Speaker Embedding Enhancement Diffusion Model",
    "authors": [
      "KiHyun Nam",
      "Jungwoo Heo",
      "Jee-weon Jung",
      "Gangin Park",
      "Chaeyoung Jung",
      "Ha-Jin Yu",
      "Joon Son Chung"
    ],
    "abstract": "A primary challenge when deploying speaker recognition systems in real-world\napplications is performance degradation caused by environmental mismatch. We\npropose a diffusion-based method that takes speaker embeddings extracted from a\npre-trained speaker recognition model and generates refined embeddings. For\ntraining, our approach progressively adds Gaussian noise to both clean and\nnoisy speaker embeddings extracted from clean and noisy speech, respectively,\nvia forward process of a diffusion model, and then reconstructs them to clean\nembeddings in the reverse process. While inferencing, all embeddings are\nregenerated via diffusion process. Our method needs neither speaker label nor\nany modification to the existing speaker recognition pipeline. Experiments on\nevaluation sets simulating environment mismatch scenarios show that our method\ncan improve recognition accuracy by up to 19.6% over baseline models while\nretaining performance on conventional scenarios. We publish our code here\nhttps://github.com/kaistmm/seed-pytorch",
    "pdf_url": "http://arxiv.org/pdf/2505.16798v1",
    "published": "2025-05-22T15:38:37+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16797v1",
    "title": "V2V: Scaling Event-Based Vision through Efficient Video-to-Voxel Simulation",
    "authors": [
      "Hanyue Lou",
      "Jinxiu Liang",
      "Minggui Teng",
      "Yi Wang",
      "Boxin Shi"
    ],
    "abstract": "Event-based cameras offer unique advantages such as high temporal resolution,\nhigh dynamic range, and low power consumption. However, the massive storage\nrequirements and I/O burdens of existing synthetic data generation pipelines\nand the scarcity of real data prevent event-based training datasets from\nscaling up, limiting the development and generalization capabilities of event\nvision models. To address this challenge, we introduce Video-to-Voxel (V2V), an\napproach that directly converts conventional video frames into event-based\nvoxel grid representations, bypassing the storage-intensive event stream\ngeneration entirely. V2V enables a 150 times reduction in storage requirements\nwhile supporting on-the-fly parameter randomization for enhanced model\nrobustness. Leveraging this efficiency, we train several video reconstruction\nand optical flow estimation model architectures on 10,000 diverse videos\ntotaling 52 hours--an order of magnitude larger than existing event datasets,\nyielding substantial improvements.",
    "pdf_url": "http://arxiv.org/pdf/2505.16797v1",
    "published": "2025-05-22T15:38:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00025v3",
    "title": "Modeling Maritime Transportation Behavior Using AIS Trajectories and Markovian Processes in the Gulf of St. Lawrence",
    "authors": [
      "Gabriel Spadon",
      "Ruixin Song",
      "Vaishnav Vaidheeswaran",
      "Md Mahbub Alam",
      "Floris Goerlandt",
      "Ronald Pelot"
    ],
    "abstract": "Maritime transportation is central to the global economy, and analyzing its\nlarge-scale behavioral data is critical for operational planning, environmental\nstewardship, and governance. This work presents a spatio-temporal analytical\nframework based on discrete-time Markov chains to model vessel movement\npatterns in the Gulf of St. Lawrence, with particular emphasis on disruptions\ninduced by the COVID-19 pandemic. We discretize the maritime domain into\nhexagonal cells and construct mobility signatures for distinct vessel types\nusing cell transition frequencies and dwell times. These features are used to\nbuild origin-destination matrices and spatial transition probability models\nthat characterize maritime dynamics across multiple temporal resolutions.\nFocusing on commercial, fishing, and passenger vessels, we analyze the temporal\nevolution of mobility behaviors during the pandemic, highlighting significant\nyet transient disruptions to recurring transport patterns. The methodology we\ncontribute to this paper allows for an extensive behavioral analytics key for\ntransportation planning. Accordingly, our findings reveal vessel-specific\nmobility signatures that persist across spatially disjoint regions, suggesting\nbehaviors invariant to time. In contrast, we observe temporal deviations among\npassenger and fishing vessels during the pandemic, reflecting the influence of\nsocial isolation measures and operational constraints on non-essential maritime\ntransport in this region.",
    "pdf_url": "http://arxiv.org/pdf/2506.00025v3",
    "published": "2025-05-22T15:37:47+00:00",
    "categories": [
      "stat.AP",
      "cs.CE",
      "math.PR"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.11057v1",
    "title": "STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization",
    "authors": [
      "Xijun Li",
      "Jiexiang Yang",
      "Jinghao Wang",
      "Bo Peng",
      "Jianguo Yao",
      "Haibing Guan"
    ],
    "abstract": "Combinatorial optimization (CO) problems, central to operation research and\ntheoretical computer science, present significant computational challenges due\nto their NP-hard nature. While large language models (LLMs) have emerged as\npromising tools for CO--either by directly generating solutions or synthesizing\nsolver-specific codes--existing approaches often neglect critical structural\npriors inherent to CO problems, leading to suboptimality and iterative\ninefficiency. Inspired by human experts' success in leveraging CO structures\nfor algorithm design, we propose STRCMP, a novel structure-aware LLM-based\nalgorithm discovery framework that systematically integrates structure priors\nto enhance solution quality and solving efficiency. Our framework combines a\ngraph neural network (GNN) for extracting structural embeddings from CO\ninstances with an LLM conditioned on these embeddings to identify\nhigh-performing algorithms in the form of solver-specific codes. This composite\narchitecture ensures syntactic correctness, preserves problem topology, and\naligns with natural language objectives, while an evolutionary refinement\nprocess iteratively optimizes generated algorithm. Extensive evaluations across\nMixed Integer Linear Programming and Boolean Satisfiability problems, using\nnine benchmark datasets, demonstrate that our proposed STRCMP outperforms five\nstrong neural and LLM-based methods by a large margin, in terms of both\nsolution optimality and computational efficiency. The code and learned model\nwill be publicly available upon the acceptance of the paper.",
    "pdf_url": "http://arxiv.org/pdf/2506.11057v1",
    "published": "2025-05-22T15:37:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16796v1",
    "title": "Extending Quantum Computing through Subspace, Embedding and Classical Molecular Dynamics Techniques",
    "authors": [
      "Thomas M. Bickley",
      "Angus Mingare",
      "Tim Weaving",
      "Michael Williams de la Bastida",
      "Shunzhou Wan",
      "Martina Nibbi",
      "Philipp Seitz",
      "Alexis Ralli",
      "Peter J. Love",
      "Minh Chung",
      "Mario Hernández Vera",
      "Laura Schulz",
      "Peter V. Coveney"
    ],
    "abstract": "The advent of hybrid computing platforms consisting of quantum processing\nunits integrated with conventional high-performance computing brings new\nopportunities for algorithms design. By strategically offloading select\nportions of the workload to classical hardware where tractable, we may broaden\nthe applicability of quantum computation in the near term. In this perspective,\nwe review techniques that facilitate the study of subdomains of chemical\nsystems with quantum computers and present a proof-of-concept demonstration of\nquantum-selected configuration interaction deployed within a\nmultiscale/multiphysics simulation workflow leveraging classical molecular\ndynamics, projection-based embedding and qubit subspace tools. This allows the\ntechnology to be utilised for simulating systems of real scientific and\nindustrial interest, which not only brings true quantum utility closer to\nrealisation but is also relevant as we look forward to the fault-tolerant\nregime.",
    "pdf_url": "http://arxiv.org/pdf/2505.16796v1",
    "published": "2025-05-22T15:37:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16795v1",
    "title": "Sequential simulation-based inference for extreme mass ratio inspirals",
    "authors": [
      "Philippa S. Cole",
      "James Alvey",
      "Lorenzo Speri",
      "Christoph Weniger",
      "Uddipta Bhardwaj",
      "Davide Gerosa",
      "Gianfranco Bertone"
    ],
    "abstract": "Extreme mass-ratio inspirals pose a difficult challenge in terms of both\nsearch and parameter estimation for upcoming space-based gravitational-wave\ndetectors such as LISA. Their signals are long and of complex morphology,\nmeaning they carry a large amount of information about their source, but are\nalso difficult to search for and analyse. We explore how sequential\nsimulation-based inference methods, specifically truncated marginal neural\nratio estimation, could offer solutions to some of the challenges surrounding\nextreme-mass-ratio inspiral data analysis. We show that this method can\nefficiently narrow down the volume of the complex 11-dimensional search\nparameter space by a factor of $10^6-10^7$ and provide 1-dimensional marginal\nproposal distributions for non-spinning extreme-mass-ratio inspirals. We\ndiscuss the current limitations of this approach and place it in the broader\ncontext of a global strategy for future space-based gravitational-wave data\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.16795v1",
    "published": "2025-05-22T15:36:49+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16794v1",
    "title": "Boundedness and decay of waves on spatially flat decelerated FLRW spacetimes",
    "authors": [
      "Mahdi Haghshenas"
    ],
    "abstract": "We study the linear wave equation on a class of spatially homogeneous and\nisotropic Friedmann-Lema\\^itre-Robertson-Walker (FLRW) spacetimes in the\ndecelerated regime with spatial topology $\\mathbb{R}^3$. Employing twisted\n$t$-weighted multiplier vector fields, we establish uniform energy bounds and\nderive integrated local energy decay estimates across the entire range of the\ndecelerated expansion regime. Furthermore, we obtain a hierarchy of\n$r^p$-weighted energy estimates \\`a la the Dafermos-Rodnianski $r^p$-method,\nwhich leads to energy decay estimates. As a consequence, we demonstrate\npointwise decay estimates for solutions and their derivatives. In the wave\nzone, this pointwise decay is optimal in the \"radiation\" and \"sub-radiation\"\ncases, and almost optimal around the radiation case.",
    "pdf_url": "http://arxiv.org/pdf/2505.16794v1",
    "published": "2025-05-22T15:36:41+00:00",
    "categories": [
      "gr-qc",
      "math-ph",
      "math.AP",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16793v1",
    "title": "REOBench: Benchmarking Robustness of Earth Observation Foundation Models",
    "authors": [
      "Xiang Li",
      "Yong Tao",
      "Siyuan Zhang",
      "Siwei Liu",
      "Zhitong Xiong",
      "Chunbo Luo",
      "Lu Liu",
      "Mykola Pechenizkiy",
      "Xiao Xiang Zhu",
      "Tianjin Huang"
    ],
    "abstract": "Earth observation foundation models have shown strong generalization across\nmultiple Earth observation tasks, but their robustness under real-world\nperturbations remains underexplored. To bridge this gap, we introduce REOBench,\nthe first comprehensive benchmark for evaluating the robustness of Earth\nobservation foundation models across six tasks and twelve types of image\ncorruptions, including both appearance-based and geometric perturbations. To\nensure realistic and fine-grained evaluation, our benchmark focuses on\nhigh-resolution optical remote sensing images, which are widely used in\ncritical applications such as urban planning and disaster response. We conduct\na systematic evaluation of a broad range of models trained using masked image\nmodeling, contrastive learning, and vision-language pre-training paradigms. Our\nresults reveal that (1) existing Earth observation foundation models experience\nsignificant performance degradation when exposed to input corruptions. (2) The\nseverity of degradation varies across tasks, model architectures, backbone\nsizes, and types of corruption, with performance drop varying from less than 1%\nto over 20%. (3) Vision-language models show enhanced robustness, particularly\nin multimodal tasks. REOBench underscores the vulnerability of current Earth\nobservation foundation models to real-world corruptions and provides actionable\ninsights for developing more robust and reliable models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16793v1",
    "published": "2025-05-22T15:34:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16792v1",
    "title": "REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training",
    "authors": [
      "Ziqiao Wang",
      "Wangbo Zhao",
      "Yuhao Zhou",
      "Zekai Li",
      "Zhiyuan Liang",
      "Mingjia Shi",
      "Xuanlei Zhao",
      "Pengfei Zhou",
      "Kaipeng Zhang",
      "Zhangyang Wang",
      "Kai Wang",
      "Yang You"
    ],
    "abstract": "Diffusion Transformers (DiTs) deliver state-of-the-art image quality, yet\ntheir training remains notoriously slow. A recent remedy -- representation\nalignment (REPA) that matches DiT hidden features to those of a non-generative\nteacher (e.g. DINO) -- dramatically accelerates the early epochs but plateaus\nor even degrades performance later. We trace this failure to a capacity\nmismatch: once the generative student begins modelling the joint data\ndistribution, the teacher's lower-dimensional embeddings and attention patterns\nbecome a straitjacket rather than a guide. We then introduce HASTE (Holistic\nAlignment with Stage-wise Termination for Efficient training), a two-phase\nschedule that keeps the help and drops the hindrance. Phase I applies a\nholistic alignment loss that simultaneously distills attention maps (relational\npriors) and feature projections (semantic anchors) from the teacher into\nmid-level layers of the DiT, yielding rapid convergence. Phase II then performs\none-shot termination that deactivates the alignment loss, once a simple trigger\nsuch as a fixed iteration is hit, freeing the DiT to focus on denoising and\nexploit its generative capacity. HASTE speeds up training of diverse DiTs\nwithout architecture changes. On ImageNet 256X256, it reaches the vanilla\nSiT-XL/2 baseline FID in 50 epochs and matches REPA's best FID in 500 epochs,\namounting to a 28X reduction in optimization steps. HASTE also improves\ntext-to-image DiTs on MS-COCO, demonstrating to be a simple yet principled\nrecipe for efficient diffusion training across various tasks. Our code is\navailable at https://github.com/NUS-HPC-AI-Lab/HASTE .",
    "pdf_url": "http://arxiv.org/pdf/2505.16792v1",
    "published": "2025-05-22T15:34:33+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16791v1",
    "title": "Cohort-Based Active Modality Acquisition",
    "authors": [
      "Tillmann Rheude",
      "Roland Eils",
      "Benjamin Wild"
    ],
    "abstract": "Real-world machine learning applications often involve data from multiple\nmodalities that must be integrated effectively to make robust predictions.\nHowever, in many practical settings, not all modalities are available for every\nsample, and acquiring additional modalities can be costly. This raises the\nquestion: which samples should be prioritized for additional modality\nacquisition when resources are limited? While prior work has explored\nindividual-level acquisition strategies and training-time active learning\nparadigms, test-time and cohort-based acquisition remain underexplored despite\ntheir importance in many real-world settings. We introduce Cohort-based Active\nModality Acquisition (CAMA), a novel test-time setting to formalize the\nchallenge of selecting which samples should receive additional modalities. We\nderive acquisition strategies that leverage a combination of generative\nimputation and discriminative modeling to estimate the expected benefit of\nacquiring missing modalities based on common evaluation metrics. We also\nintroduce upper-bound heuristics that provide performance ceilings to benchmark\nacquisition strategies. Experiments on common multimodal datasets demonstrate\nthat our proposed imputation-based strategies can more effectively guide the\nacquisition of new samples in comparison to those relying solely on unimodal\ninformation, entropy guidance, and random selections. Our work provides an\neffective solution for optimizing modality acquisition at the cohort level,\nenabling better utilization of resources in constrained settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16791v1",
    "published": "2025-05-22T15:32:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16790v3",
    "title": "Learning Flexible Forward Trajectories for Masked Molecular Diffusion",
    "authors": [
      "Hyunjin Seo",
      "Taewon Kim",
      "Sihyun Yu",
      "SungSoo Ahn"
    ],
    "abstract": "Masked diffusion models (MDMs) have achieved notable progress in modeling\ndiscrete data, while their potential in molecular generation remains\nunderexplored. In this work, we explore their potential and introduce the\nsurprising result that naively applying standards MDMs severely degrades the\nperformance. We identify the critical cause of this issue as a state-clashing\nproblem-where the forward diffusion of distinct molecules collapse into a\ncommon state, resulting in a mixture of reconstruction targets that cannot be\nlearned using typical reverse diffusion process with unimodal predictions. To\nmitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that\norchestrates per-element corruption trajectories to avoid collision between\ndistinct molecular graphs. This is achieved through a parameterized noise\nscheduling network that assigns distinct corruption rates to individual graph\nelements, i.e., atoms and bonds. Extensive experiments on diverse molecular\nbenchmarks reveal that MELD markedly enhances overall generation quality\ncompared to element-agnostic noise scheduling, increasing the chemical validity\nof vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves\nstate-of-the-art property alignment in conditional generation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16790v3",
    "published": "2025-05-22T15:30:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16789v2",
    "title": "Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards",
    "authors": [
      "Punya Syon Pandey",
      "Samuel Simko",
      "Kellin Pelrine",
      "Zhijing Jin"
    ],
    "abstract": "As large language models (LLMs) gain popularity, their vulnerability to\nadversarial attacks emerges as a primary concern. While fine-tuning models on\ndomain-specific datasets is often employed to improve model performance, it can\ninadvertently introduce vulnerabilities within the underlying model. In this\nwork, we investigate Accidental Vulnerability, unexpected vulnerabilities\narising from characteristics of fine-tuning data. We begin by identifying\npotential correlation factors such as linguistic features, semantic similarity,\nand toxicity across multiple experimental datasets. We then evaluate the\nadversarial robustness of these fine-tuned models, analyzing persona shifts and\ninterpretability traits to understand how dataset factors contribute to attack\nsuccess rates. Lastly, we explore causal relationships that offer new insights\ninto adversarial defense strategies, highlighting the crucial role of dataset\ndesign in preserving model alignment. Our code is available at\nhttps://github.com/psyonp/accidental_vulnerability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16789v2",
    "published": "2025-05-22T15:30:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16788v1",
    "title": "Interpretable contour level selection for heat maps for gridded data",
    "authors": [
      "Tarn Duong"
    ],
    "abstract": "Gridded data formats, where the observed multivariate data are aggregated\ninto grid cells, ensure confidentiality and reduce storage requirements, with\nthe trade-off that access to the underlying point data is lost. Heat maps are a\nhighly pertinent visualisation for gridded data, and heat maps with a small\nnumber of well-selected contour levels offer improved interpretability over\ncontinuous contour levels. There are many possible contour level choices.\nAmongst them, density contour levels are highly suitable in many cases, and\ntheir probabilistic interpretation form a rigorous statistical basis for\nfurther quantitative data analyses. Current methods for computing density\ncontour levels requires access to the observed point data, so they are not\napplicable to gridded data. To remedy this, we introduce an approximation of\ndensity contour levels for gridded data. We then compare our proposed method to\nexisting contour level selection methods, and conclude that our proposal\nprovides improved interpretability for synthetic and experimental gridded data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16788v1",
    "published": "2025-05-22T15:29:41+00:00",
    "categories": [
      "stat.CO",
      "stat.AP",
      "62-04, 62G07"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16787v2",
    "title": "Enter the Void - Planning to Seek Entropy When Reward is Scarce",
    "authors": [
      "Ashish Sundar",
      "Chunbo Luo",
      "Xiaoyang Wang"
    ],
    "abstract": "Model-based reinforcement learning (MBRL) offers an intuitive way to increase\nthe sample efficiency of model-free RL methods by simultaneously training a\nworld model that learns to predict the future. MBRL methods have progressed by\nlargely prioritising the actor; optimising the world model learning has been\nneglected meanwhile. Improving the fidelity of the world model and reducing its\ntime to convergence can yield significant downstream benefits, one of which is\nimproving the ensuing performance of any actor it may train. We propose a novel\napproach that anticipates and actively seeks out high-entropy states using\nshort-horizon latent predictions generated by the world model, offering a\nprincipled alternative to traditional curiosity-driven methods that chase\nonce-novel states well after they were stumbled into. While many model\npredictive control (MPC) based methods offer similar alternatives, they\ntypically lack commitment, synthesising multi step plans after every step. To\nmitigate this, we present a hierarchical planner that dynamically decides when\nto replan, planning horizon length, and the weighting between reward and\nentropy. While our method can theoretically be applied to any model that trains\nits own actors with solely model generated data, we have applied it to just\nDreamer as a proof of concept. Our method finishes the Miniworld procedurally\ngenerated mazes 50% faster than base Dreamer at convergence and the policy\ntrained in imagination converges in only 60% of the environment steps that base\nDreamer needs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16787v2",
    "published": "2025-05-22T15:28:50+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16786v1",
    "title": "FlowMixer: A Constrained Neural Architecture for Interpretable Spatiotemporal Forecasting",
    "authors": [
      "Fares B. Mehouachi",
      "Saif Eddin Jabari"
    ],
    "abstract": "We introduce FlowMixer, a neural architecture that leverages constrained\nmatrix operations to model structured spatiotemporal patterns. At its core,\nFlowMixer incorporates non-negative matrix mixing layers within a reversible\nmapping framework-applying transforms before mixing and their inverses\nafterward. This shape-preserving design enables a Kronecker-Koopman eigenmode\nframework that bridges statistical learning with dynamical systems theory,\nproviding interpretable spatiotemporal patterns and facilitating direct\nalgebraic manipulation of prediction horizons without retraining. Extensive\nexperiments across diverse domains demonstrate FlowMixer's robust long-horizon\nforecasting capabilities while effectively modeling physical phenomena such as\nchaotic attractors and turbulent flows. These results suggest that\narchitectural constraints can simultaneously enhance predictive performance and\nmathematical interpretability in neural forecasting systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16786v1",
    "published": "2025-05-22T15:28:47+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16785v1",
    "title": "CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models",
    "authors": [
      "Zhenzhen Ren",
      "GuoBiao Li",
      "Sheng Li",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "abstract": "Despite providing superior performance, open-source large language models\n(LLMs) are vulnerable to abusive usage. To address this issue, recent works\npropose LLM fingerprinting methods to identify the specific source LLMs behind\nsuspect applications. However, these methods fail to provide stealthy and\nrobust fingerprint verification. In this paper, we propose a novel LLM\nfingerprinting scheme, namely CoTSRF, which utilizes the Chain of Thought (CoT)\nas the fingerprint of an LLM. CoTSRF first collects the responses from the\nsource LLM by querying it with crafted CoT queries. Then, it applies\ncontrastive learning to train a CoT extractor that extracts the CoT feature\n(i.e., fingerprint) from the responses. Finally, CoTSRF conducts fingerprint\nverification by comparing the Kullback-Leibler divergence between the CoT\nfeatures of the source and suspect LLMs against an empirical threshold. Various\nexperiments have been conducted to demonstrate the advantage of our proposed\nCoTSRF for fingerprinting LLMs, particularly in stealthy and robust fingerprint\nverification.",
    "pdf_url": "http://arxiv.org/pdf/2505.16785v1",
    "published": "2025-05-22T15:28:25+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16784v2",
    "title": "Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles",
    "authors": [
      "Jun Xie",
      "Xiongjun Guan",
      "Yingjian Zhu",
      "Zhaoran Zhao",
      "Xinming Wang",
      "Hongzhu Yi",
      "Feng Chen",
      "Zhepeng Wang"
    ],
    "abstract": "In this paper, we present the runner-up solution for the Ego4D EgoSchema\nChallenge at CVPR 2025 (Confirmed on May 20, 2025). Inspired by the success of\nlarge models, we evaluate and leverage leading accessible multimodal large\nmodels and adapt them to video understanding tasks via few-shot learning and\nmodel ensemble strategies. Specifically, diversified prompt styles and process\nparadigms are systematically explored and evaluated to effectively guide the\nattention of large models, fully unleashing their powerful generalization and\nadaptability abilities. Experimental results demonstrate that, with our\ncarefully designed approach, directly utilizing an individual multimodal model\nalready outperforms the previous state-of-the-art (SOTA) method which includes\nseveral additional processes. Besides, an additional stage is further\nintroduced that facilitates the cooperation and ensemble of periodic results,\nwhich achieves impressive performance improvements. We hope this work serves as\na valuable reference for the practical application of large models and inspires\nfuture research in the field. Our Code is available at\nhttps://github.com/XiongjunGuan/EgoSchema-CVPR25.",
    "pdf_url": "http://arxiv.org/pdf/2505.16784v2",
    "published": "2025-05-22T15:27:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16783v2",
    "title": "Circular equatorial orbits of extended bodies with spin-induced quadrupole around a Kerr black hole: Comparing spin-supplementary conditions",
    "authors": [
      "Misbah Shahzadi",
      "Georgios Lukes-Gerakopoulos",
      "Martin Kološ"
    ],
    "abstract": "The worldline of an extended body in curved spacetime can be described by the\nMathisson-Papapetrou-Dixon equations when its centroid, i.e., its center of\nmass, is fixed by a spin supplementary condition (SSC). Different SSC choices\nresult in distinct worldlines. To examine the properties of these choices, we\ninvestigate the frequency of circular equatorial orbits of extended bodies\nwithin the pole-dipole-(spin-induced) quadrupole approximation moving around a\nKerr black hole for the Tulzcyjew-Dixon (TD) and the Mathisson-Pirani (MP)\nSSCs. First, we examine similarities and discrepancies in the prograde and\nretrograde orbital frequencies by expanding these frequencies in power series\nof the spin without taking into account the fact that both the position of the\ncentroid and the spin measure change under the transition from one SSC to\nanother. Then, by taking into account the centroid transition laws we examine\nthe orbital frequencies convergence between the non-helical MP frame to the TD\nframe. In particular, we demonstrate that, in analogy to the pole-dipole\napproximation, the transition from one circular orbit to another within the\npole-dipole-(spin-induced)quadrupole approximation under a change in the SSC,\nresults in convergence between the SSCs only up to certain terms in the spin\nexpansion and does not extend to the entire power series. Finally, we discuss\nthe innermost stable circular orbits (ISCOs) in the\npole-dipole-(spin-induced)quadrupole approximation under TD and MP SSCs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16783v2",
    "published": "2025-05-22T15:27:02+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16782v1",
    "title": "Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning",
    "authors": [
      "Xinghao Chen",
      "Anhao Zhao",
      "Heming Xia",
      "Xuan Lu",
      "Hanlin Wang",
      "Yanjun Chen",
      "Wei Zhang",
      "Jian Wang",
      "Wenjie Li",
      "Xiaoyu Shen"
    ],
    "abstract": "Large Language Models (LLMs) have achieved impressive performance on complex\nreasoning tasks with Chain-of-Thought (CoT) prompting. However, conventional\nCoT relies on reasoning steps explicitly verbalized in natural language,\nintroducing inefficiencies and limiting its applicability to abstract\nreasoning. To address this, there has been growing research interest in latent\nCoT reasoning, where inference occurs within latent spaces. By decoupling\nreasoning from language, latent reasoning promises richer cognitive\nrepresentations and more flexible, faster inference. Researchers have explored\nvarious directions in this promising field, including training methodologies,\nstructural innovations, and internal reasoning mechanisms. This paper presents\na comprehensive overview and analysis of this reasoning paradigm. We begin by\nproposing a unified taxonomy from four perspectives: token-wise strategies,\ninternal mechanisms, analysis, and applications. We then provide in-depth\ndiscussions and comparative analyses of representative methods, highlighting\ntheir design patterns, strengths, and open challenges. We aim to provide a\nstructured foundation for advancing this emerging direction in LLM reasoning.\nThe relevant papers will be regularly updated at\nhttps://github.com/EIT-NLP/Awesome-Latent-CoT.",
    "pdf_url": "http://arxiv.org/pdf/2505.16782v1",
    "published": "2025-05-22T15:26:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16781v1",
    "title": "Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making",
    "authors": [
      "Qianlei Jia",
      "Xinliang Zhou",
      "Ondrej Krejcar",
      "Enrique Herrera-Viedma"
    ],
    "abstract": "In group decision-making (GDM) scenarios, uncertainty, dynamic social\nstructures, and vague information present major challenges for traditional\nopinion dynamics models. To address these issues, this study proposes a novel\nsocial network group decision-making (SNGDM) framework that integrates\nthree-way decision (3WD) theory, dynamic network reconstruction, and linguistic\nopinion representation. First, the 3WD mechanism is introduced to explicitly\nmodel hesitation and ambiguity in agent judgments, thereby preventing\nirrational decisions. Second, a connection adjustment rule based on opinion\nsimilarity is developed, enabling agents to adaptively update their\ncommunication links and better reflect the evolving nature of social\nrelationships. Third, linguistic terms are used to describe agent opinions,\nallowing the model to handle subjective, vague, or incomplete information more\neffectively. Finally, an integrated multi-agent decision-making framework is\nconstructed, which simultaneously considers individual uncertainty, opinion\nevolution, and network dynamics. The proposed model is applied to a multi-UAV\ncooperative decision-making scenario, where simulation results and consensus\nanalysis demonstrate its effectiveness. Experimental comparisons further verify\nthe advantages of the algorithm in enhancing system stability and representing\nrealistic decision-making behaviors.",
    "pdf_url": "http://arxiv.org/pdf/2505.16781v1",
    "published": "2025-05-22T15:26:48+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17164v2",
    "title": "A pedagogical approach to the black hole information problem",
    "authors": [
      "Thiago T. Bergamaschi"
    ],
    "abstract": "The semiclassical depiction of gravity has provided many important results,\nsuch as particle creation effects in expanding universes and in spacetimes\ncontaining black holes. However, many questions remain open, most notably\nconcerning the final product of the black hole evaporation process and the\nconservation of information. From a pedagogical perspective, we review the\nconcepts that lead to this state of affairs, also known as the black hole\ninformation problem, and discuss the assumptions and hypotheses necessary for\nits formulation. Stating the necessary conjectures and results that lead to the\ngeometrical properties of black holes, we present the notion of black hole\nevaporation and the result that entanglement between causally complementary\nregions is an intrinsic feature of quantum field theory under the Hadamard\ncondition. We then show that, under certain assumptions, formation and complete\nevaporation of a black hole can lead to information loss. Comparing such a\nresult to the main alternatives to this non-unitary dynamical evolution, we\nformulate the black hole information problem and show that information loss is\na genuine prediction if no deviations from the semiclassical picture occur at\nthe Planck scale.",
    "pdf_url": "http://arxiv.org/pdf/2505.17164v2",
    "published": "2025-05-22T15:26:03+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17163v1",
    "title": "OCR-Reasoning Benchmark: Unveiling the True Capabilities of MLLMs in Complex Text-Rich Image Reasoning",
    "authors": [
      "Mingxin Huang",
      "Yongxin Shi",
      "Dezhi Peng",
      "Songxuan Lai",
      "Zecheng Xie",
      "Lianwen Jin"
    ],
    "abstract": "Recent advancements in multimodal slow-thinking systems have demonstrated\nremarkable performance across diverse visual reasoning tasks. However, their\ncapabilities in text-rich image reasoning tasks remain understudied due to the\nlack of a systematic benchmark. To address this gap, we propose OCR-Reasoning,\na comprehensive benchmark designed to systematically assess Multimodal Large\nLanguage Models on text-rich image reasoning tasks. The benchmark comprises\n1,069 human-annotated examples spanning 6 core reasoning abilities and 18\npractical reasoning tasks in text-rich visual scenarios. Furthermore, unlike\nother text-rich image understanding benchmarks that only annotate the final\nanswers, OCR-Reasoning also annotates the reasoning process simultaneously.\nWith the annotated reasoning process and the final answers, OCR-Reasoning\nevaluates not only the final answers generated by models but also their\nreasoning processes, enabling a holistic analysis of their problem-solving\nabilities. Leveraging this benchmark, we conducted a comprehensive evaluation\nof state-of-the-art MLLMs. Our results demonstrate the limitations of existing\nmethodologies. Notably, even state-of-the-art MLLMs exhibit substantial\ndifficulties, with none achieving accuracy surpassing 50\\% across\nOCR-Reasoning, indicating that the challenges of text-rich image reasoning are\nan urgent issue to be addressed. The benchmark and evaluation scripts are\navailable at https://github.com/SCUT-DLVCLab/OCR-Reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.17163v1",
    "published": "2025-05-22T15:25:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16780v1",
    "title": "Large time and distance asymptotics of the one-dimensional impenetrable Bose gas and Painlevé IV transition",
    "authors": [
      "Zhi-Xuan Meng",
      "Shuai-Xia Xu",
      "Yu-Qiu Zhao"
    ],
    "abstract": "In the present paper, we study the time-dependent correlation function of the\none-dimensional impenetrable Bose gas, which can be expressed in terms of the\nFredholm determinant of a time-dependent sine kernel and the solutions of the\nseparated NLS equations. We derive the large time and distance asymptotic\nexpansions of this determinant and the solutions of the separated NLS equations\nin both the space-like region and time-like region of the $(x,t)$-plane.\nFurthermore, we observe a phase transition between the asymptotic expansions in\nthese two different regions. The phase transition is then shown to be described\nby a particular solution of the Painlev\\'e IV equation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16780v1",
    "published": "2025-05-22T15:21:47+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "math.ST",
      "stat.TH",
      "35Q55 (33E17 34M55 35C20 82C10)"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16779v2",
    "title": "Phase engineering of MoS$_2$ monolayers: A pathway to enhanced lithium-polysulfide battery performance",
    "authors": [
      "J. W. González",
      "E. Flórez",
      "R. A. Gallardo",
      "J. D. Correa"
    ],
    "abstract": "This study explores the potential of MoS$_2$ polymorphs, specifically the\nsemiconducting 2H phase and the metallic 1T$^\\prime$ phase, as anchoring\nmaterials to enhance the electrochemical performance of lithium-sulfur (Li--S)\nbatteries. Using density functional theory calculations, we show that\n1T$^\\prime$-MoS$_2$ exhibits stronger Li--S interactions, greater charge\ntransfer, and enhanced catalytic activity compared to its 2H counterpart,\neffectively suppressing polysulfide dissolution and facilitating redox\nreactions. The reversible 2H$\\leftrightarrow$1T$^\\prime$ transition offers a\ntunable design space for balancing conductivity and structural stability. These\nfindings position hybrid MoS$_2$ architectures as promising platforms for\nnext-generation Li--S batteries with improved energy density, cycling\nstability, and rate capability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16779v2",
    "published": "2025-05-22T15:20:48+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16778v1",
    "title": "Single Domain Generalization for Few-Shot Counting via Universal Representation Matching",
    "authors": [
      "Xianing Chen",
      "Si Huo",
      "Borui Jiang",
      "Hailin Hu",
      "Xinghao Chen"
    ],
    "abstract": "Few-shot counting estimates the number of target objects in an image using\nonly a few annotated exemplars. However, domain shift severely hinders existing\nmethods to generalize to unseen scenarios. This falls into the realm of single\ndomain generalization that remains unexplored in few-shot counting. To solve\nthis problem, we begin by analyzing the main limitations of current methods,\nwhich typically follow a standard pipeline that extract the object prototypes\nfrom exemplars and then match them with image feature to construct the\ncorrelation map. We argue that existing methods overlook the significance of\nlearning highly generalized prototypes. Building on this insight, we propose\nthe first single domain generalization few-shot counting model, Universal\nRepresentation Matching, termed URM. Our primary contribution is the discovery\nthat incorporating universal vision-language representations distilled from a\nlarge scale pretrained vision-language model into the correlation construction\nprocess substantially improves robustness to domain shifts without compromising\nin domain performance. As a result, URM achieves state-of-the-art performance\non both in domain and the newly introduced domain generalization setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.16778v1",
    "published": "2025-05-22T15:20:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16777v1",
    "title": "Fast Low Energy Reconstruction using Convolutional Neural Networks",
    "authors": [
      "IceCube Collaboration"
    ],
    "abstract": "IceCube is a Cherenkov detector instrumenting over a cubic kilometer of\nglacial ice deep under the surface of the South Pole. The DeepCore sub-detector\nlowers the detection energy threshold to a few GeV, enabling the precise\nmeasurements of neutrino oscillation parameters with atmospheric neutrinos. The\nreconstruction of neutrino interactions inside the detector is essential in\nstudying neutrino oscillations. It is particularly challenging to reconstruct\nsub-100 GeV events with the IceCube detectors due to the relatively sparse\ndetection units and detection medium. Convolutional neural networks (CNNs) are\nbroadly used in physics experiments for both classification and regression\npurposes. This paper discusses the CNNs developed and employed for the latest\nIceCube-DeepCore oscillation measurements. These CNNs estimate various\nproperties of the detected neutrinos, such as their energy, direction of\narrival, interaction vertex position, flavor-related signature, and are also\nused for background classification.",
    "pdf_url": "http://arxiv.org/pdf/2505.16777v1",
    "published": "2025-05-22T15:19:02+00:00",
    "categories": [
      "astro-ph.HE",
      "hep-ex"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16776v1",
    "title": "Dissipatively dressed quasiparticles in boundary driven integrable spin chains",
    "authors": [
      "Vladislav Popkov",
      "Xin Zhang",
      "Carlo Presilla",
      "Tomaž Prosen"
    ],
    "abstract": "The nonequilibrium steady state (NESS) of integrable spin chains experiencing\nstrong boundary dissipation is accounted by introducing quasiparticles with a\nrenormalized -- dissipatively dressed -- dispersion relation. This allows us to\nevaluate the spectrum of the NESS in terms of the Bethe ansatz equations for a\nrelated coherent system which has the same set of eigenstates, the so-called\ndissipation-projected Hamiltonian. We find explicit analytic expressions for\nthe dressed energies of the XXX and XXZ models with effective, i.e., induced by\nthe dissipation, diagonal boundary fields, which are U(1) invariant, as well as\nthe XXZ and XYZ models with effective non-diagonal boundary fields. In all\ncases, the dissipative dressing generates an extra singularity in the\ndispersion relation, substantially altering the NESS spectrum with respect to\nthe spectrum of the corresponding coherent model.",
    "pdf_url": "http://arxiv.org/pdf/2505.16776v1",
    "published": "2025-05-22T15:18:41+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "math-ph",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.16775v1",
    "title": "The lattice Schäffer constant",
    "authors": [
      "Michael Alexánder Rincón Villamizar",
      "Timur Oikhberg"
    ],
    "abstract": "For a Banach lattice $X$, its lattice Sch\\\"affer constant is defined by:\n\\begin{gather*}\n  \\lambda^+(X)=\\inf\\{\\max\\{\\|x+y\\|,\\|x-y\\|\\}\\,\\colon\\,\\|x\\|=\\|y\\|=1,x,y\\geq{\\bf0}\\}.\n\\end{gather*}\n  In this paper, we investigate this constant, as well as the companion\nparameter \\begin{gather*}\n  \\beta(X)=\\inf\\{\\|x\\vee y\\|\\,\\colon\\,\\mbox{$\\|x\\|=\\|y\\|=1$, $x,y\\geq{\\bf0}$\nand $x\\wedge y={\\bf0}$}\\}. \\end{gather*} Our main results fall into two groups.\n(1) We link the behavior of the parameters $\\lambda^+$ and $\\beta$ to the\nglobal properties of the lattice $X$. For instance, we prove that (i) if\n$\\lambda^+(X)>1$, then the Banach lattice $X$ is a KB-space, and moreover, it\nsatisfies a lower $q$-estimate for some $q\\in(1,\\infty)$; (ii) $\\lambda^+(X)=1$\nif and only if $X$ contains lattice-almost isometric copies of $\\ell_\\infty^2$;\nand (iii) that $\\lambda^+(X)=2$ if and only if $X$ is an abstract $L$-space.\n(2) We establish inequalities relating $\\lambda^+(X)$ to the characteristics of\nmonotonicity, $\\varepsilon_{0,m}(X)$ and $\\tilde\\varepsilon_{0,m}(X)$. Along\nthe way, we compute $\\lambda^+(X)$ and $\\beta(X)$ for various Banach lattices\n$X$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16775v1",
    "published": "2025-05-22T15:18:26+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16774v1",
    "title": "IFEval-Audio: Benchmarking Instruction-Following Capability in Audio-based Large Language Models",
    "authors": [
      "Yiming Gao",
      "Bin Wang",
      "Chengwei Wei",
      "Shuo Sun",
      "AiTi Aw"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong instruction-following\ncapabilities in text-based tasks. However, this ability often deteriorates in\nmultimodal models after alignment with non-text modalities such as images or\naudio. While several recent efforts have investigated instruction-following\nperformance in text and vision-language models, instruction-following in\naudio-based large language models remains largely unexplored. To bridge this\ngap, we introduce IFEval-Audio, a novel evaluation dataset designed to assess\nthe ability to follow instructions in an audio LLM. IFEval-Audio contains 280\naudio-instruction-answer triples across six diverse dimensions: Content,\nCapitalization, Symbol, List Structure, Length, and Format. Each example pairs\nan audio input with a text instruction, requiring the model to generate an\noutput that follows a specified structure. We benchmark state-of-the-art audio\nLLMs on their ability to follow audio-involved instructions. The dataset is\nreleased publicly to support future research in this emerging area.",
    "pdf_url": "http://arxiv.org/pdf/2505.16774v1",
    "published": "2025-05-22T15:15:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16773v1",
    "title": "Mitigating Overfitting in Medical Imaging: Self-Supervised Pretraining vs. ImageNet Transfer Learning for Dermatological Diagnosis",
    "authors": [
      "Iván Matas",
      "Carmen Serrano",
      "Miguel Nogales",
      "David Moreno",
      "Lara Ferrándiz",
      "Teresa Ojeda",
      "Begoña Acha"
    ],
    "abstract": "Deep learning has transformed computer vision but relies heavily on large\nlabeled datasets and computational resources. Transfer learning, particularly\nfine-tuning pretrained models, offers a practical alternative; however, models\npretrained on natural image datasets such as ImageNet may fail to capture\ndomain-specific characteristics in medical imaging. This study introduces an\nunsupervised learning framework that extracts high-value dermatological\nfeatures instead of relying solely on ImageNet-based pretraining. We employ a\nVariational Autoencoder (VAE) trained from scratch on a proprietary\ndermatological dataset, allowing the model to learn a structured and clinically\nrelevant latent space. This self-supervised feature extractor is then compared\nto an ImageNet-pretrained backbone under identical classification conditions,\nhighlighting the trade-offs between general-purpose and domain-specific\npretraining. Our results reveal distinct learning patterns. The self-supervised\nmodel achieves a final validation loss of 0.110 (-33.33%), while the\nImageNet-pretrained model stagnates at 0.100 (-16.67%), indicating overfitting.\nAccuracy trends confirm this: the self-supervised model improves from 45% to\n65% (+44.44%) with a near-zero overfitting gap, whereas the ImageNet-pretrained\nmodel reaches 87% (+50.00%) but plateaus at 75% (+19.05%), with its overfitting\ngap increasing to +0.060. These findings suggest that while ImageNet\npretraining accelerates convergence, it also amplifies overfitting on\nnon-clinically relevant features. In contrast, self-supervised learning\nachieves steady improvements, stronger generalization, and superior\nadaptability, underscoring the importance of domain-specific feature extraction\nin medical imaging.",
    "pdf_url": "http://arxiv.org/pdf/2505.16773v1",
    "published": "2025-05-22T15:15:17+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16772v1",
    "title": "On the steadiness of symmetric solutions to higher order perturbations of KdV",
    "authors": [
      "Long Pei",
      "Fengyang Xiao",
      "Pan Zhang"
    ],
    "abstract": "We consider the traveling structure of symmetric solutions to the\nRosenau-Kawahara-RLW equation and the perturbed R-KdV-RLW equation. Both\nequations are higher order perturbations of the classical KdV equation. For the\nRosenau-Kawahara-RLW equation, we prove that classical and weak solutions with\na priori symmetry must be traveling solutions. For the more complicated\nperturbed R-KdV-RLW equation, we classify all symmetric traveling solutions,\nand prove that there exists no nontrivial symmetric traveling solution of\nsolitary type once dissipation or shoaling perturbations exist. This gives a\nnew perspective for evaluating the suitableness of a model for water waves. In\naddition, this result illustrates the sharpness of the symmetry principle in\n[Int. Math. Res. Not. IMRN, 2009; Ehrnstrom, Holden \\& Raynaud] for solitary\nwaves.",
    "pdf_url": "http://arxiv.org/pdf/2505.16772v1",
    "published": "2025-05-22T15:14:15+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17162v1",
    "title": "DailyQA: A Benchmark to Evaluate Web Retrieval Augmented LLMs Based on Capturing Real-World Changes",
    "authors": [
      "Jiehan Cheng",
      "Zhicheng Dou"
    ],
    "abstract": "We propose DailyQA, an automatically updated dynamic dataset that updates\nquestions weekly and contains answers to questions on any given date. DailyQA\nutilizes daily updates from Wikipedia revision logs to implement a fully\nautomated pipeline of data filtering, query generation synthesis, quality\nchecking, answer extraction, and query classification. The benchmark requires\nlarge language models (LLMs) to process and answer questions involving\nfast-changing factual data and covering multiple domains. We evaluate several\nopen-source and closed-source LLMs using different RAG pipelines with web\nsearch augmentation. We compare the ability of different models to process\ntime-sensitive web information and find that rerank of web retrieval results is\ncritical. Our results indicate that LLMs still face significant challenges in\nhandling frequently updated information, suggesting that DailyQA benchmarking\nprovides valuable insights into the direction of progress for LLMs and RAG\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17162v1",
    "published": "2025-05-22T15:13:33+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17161v1",
    "title": "Massive scalar field perturbations of 4D de Sitter Einstein-Gauss-Bonnet black holes",
    "authors": [
      "Ramón Bécar",
      "P. A. González",
      "Eleftherios Papantonopoulos",
      "Yerko Vásquez"
    ],
    "abstract": "We investigate the propagation of massive scalar fields in the background of\nfour-dimensional Einstein-Gauss-Bonnet black holes with de Sitter (dS)\nasymptotics. Our study focuses on the various branches of quasinormal modes\npresent in this background, employing the pseudospectral Chebyshev method and\nthe third-order Wentzel-Kramers-Brillouin approximation. We identify that the\nintroduction of the Gauss-Bonnet coupling constant $\\alpha$ gives rise to three\nbranches of modes: the perturbative (in $\\alpha$) Schwarzschild branch, the\nperturbative (in $\\alpha$) dS branch, and a non-perturbative (in $\\alpha$) dS\nbranch. Our results show that the propagation of a massive scalar field is\nstable in this background. Furthermore, the Gauss-Bonnet coupling constant\ninduces significant deviations in the Schwarzschild branch and smaller\ndeviations in the perturbative dS branch compared to the corresponding branches\nin the Schwarzschild-dS limit. Additionally, the non-perturbative dS branch of\nmodes, absent when $\\alpha=0$, emerges as a novel feature of the\nEinstein-Gauss-Bonnet framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.17161v1",
    "published": "2025-05-22T15:13:00+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16771v1",
    "title": "Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review",
    "authors": [
      "Beyazit Bestami Yuksel",
      "Ayse Yilmazer Metin"
    ],
    "abstract": "This paper presents a comprehensive synthesis of major breakthroughs in\nartificial intelligence (AI) over the past fifteen years, integrating\nhistorical, theoretical, and technological perspectives. It identifies key\ninflection points in AI' s evolution by tracing the convergence of\ncomputational resources, data access, and algorithmic innovation. The analysis\nhighlights how researchers enabled GPU based model training, triggered a data\ncentric shift with ImageNet, simplified architectures through the Transformer,\nand expanded modeling capabilities with the GPT series. Rather than treating\nthese advances as isolated milestones, the paper frames them as indicators of\ndeeper paradigm shifts. By applying concepts from statistical learning theory\nsuch as sample complexity and data efficiency, the paper explains how\nresearchers translated breakthroughs into scalable solutions and why the field\nmust now embrace data centric approaches. In response to rising privacy\nconcerns and tightening regulations, the paper evaluates emerging solutions\nlike federated learning, privacy enhancing technologies (PETs), and the data\nsite paradigm, which reframe data access and security. In cases where real\nworld data remains inaccessible, the paper also assesses the utility and\nconstraints of mock and synthetic data generation. By aligning technical\ninsights with evolving data infrastructure, this study offers strategic\nguidance for future AI research and policy development.",
    "pdf_url": "http://arxiv.org/pdf/2505.16771v1",
    "published": "2025-05-22T15:12:48+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16770v2",
    "title": "RBench-V: A Primary Assessment for Visual Reasoning Models with Multi-modal Outputs",
    "authors": [
      "Meng-Hao Guo",
      "Xuanyu Chu",
      "Qianrui Yang",
      "Zhe-Han Mo",
      "Yiqing Shen",
      "Pei-lin Li",
      "Xinjie Lin",
      "Jinnian Zhang",
      "Xin-Sheng Chen",
      "Yi Zhang",
      "Kiyohiro Nakayama",
      "Zhengyang Geng",
      "Houwen Peng",
      "Han Hu",
      "Shi-Min Hu"
    ],
    "abstract": "The rapid advancement of native multi-modal models and omni-models,\nexemplified by GPT-4o, Gemini, and o3, with their capability to process and\ngenerate content across modalities such as text and images, marks a significant\nmilestone in the evolution of intelligence. Systematic evaluation of their\nmulti-modal output capabilities in visual thinking processes (also known as\nmulti-modal chain of thought, M-CoT) becomes critically important. However,\nexisting benchmarks for evaluating multi-modal models primarily focus on\nassessing multi-modal inputs and text-only reasoning while neglecting the\nimportance of reasoning through multi-modal outputs. In this paper, we present\na benchmark, dubbed RBench-V, designed to assess models' vision-indispensable\nreasoning abilities. To construct RBench-V, we carefully hand-pick 803\nquestions covering math, physics, counting, and games. Unlike previous\nbenchmarks that typically specify certain input modalities, RBench-V presents\nproblems centered on multi-modal outputs, which require image manipulation such\nas generating novel images and constructing auxiliary lines to support the\nreasoning process. We evaluate numerous open- and closed-source models on\nRBench-V, including o3, Gemini 2.5 Pro, Qwen2.5-VL, etc. Even the\nbest-performing model, o3, achieves only 25.8% accuracy on RBench-V, far below\nthe human score of 82.3%, highlighting that current models struggle to leverage\nmulti-modal reasoning. Data and code are available at\nhttps://evalmodels.github.io/rbenchv",
    "pdf_url": "http://arxiv.org/pdf/2505.16770v2",
    "published": "2025-05-22T15:11:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16769v1",
    "title": "Simulation-Guided Approximate Logic Synthesis Under the Maximum Error Constraint",
    "authors": [
      "Chang Meng",
      "Weikang Qian",
      "Giovanni De Micheli"
    ],
    "abstract": "Approximate computing is an effective computing paradigm for improving energy\nefficiency of error-tolerant applications. Approximate logic synthesis (ALS) is\nan automatic process to generate approximate circuits with reduced area, delay,\nand power, while satisfying user-specified error constraints. This paper\nfocuses on ALS under the maximum error constraint. As an essential error metric\nthat provides a worst-case error guarantee, the maximum error is crucial for\nmany applications such as image processing and machine learning. This work\nproposes an efficient simulation-guided ALS flow that handles this constraint.\nIt utilizes logic simulation to 1) prune local approximate changes (LACs) with\nlarge errors that violate the error constraint, and 2) accelerate the SAT-based\nLAC selection process. Furthermore, to enhance scalability, our ALS flow\niteratively selects a set of promising LACs satisfying the error constraint to\nimprove the efficiency. The experimental results show that compared with the\nstate-of-the-art method, our ALS flow accelerates by 30.6 times, and further\nreduces circuit area and delay by 18.2% and 4.9%, respectively. Notably, our\nflow scales to large EPFL benchmarks with up to 38540 nodes, which cannot be\nhandled by any existing ALS method for maximum error.",
    "pdf_url": "http://arxiv.org/pdf/2505.16769v1",
    "published": "2025-05-22T15:11:45+00:00",
    "categories": [
      "cs.ET"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2506.12029v1",
    "title": "Physics-Informed Neural Networks for Vessel Trajectory Prediction: Learning Time-Discretized Kinematic Dynamics via Finite Differences",
    "authors": [
      "Md Mahbub Alam",
      "Amilcar Soares",
      "José F. Rodrigues-Jr",
      "Gabriel Spadon"
    ],
    "abstract": "Accurate vessel trajectory prediction is crucial for navigational safety,\nroute optimization, traffic management, search and rescue operations, and\nautonomous navigation. Traditional data-driven models lack real-world physical\nconstraints, leading to forecasts that disobey vessel motion dynamics, such as\nin scenarios with limited or noisy data where sudden course changes or speed\nvariations occur due to external factors. To address this limitation, we\npropose a Physics-Informed Neural Network (PINN) approach for trajectory\nprediction that integrates a streamlined kinematic model for vessel motion into\nthe neural network training process via a first- and second-order, finite\ndifference physics-based loss function. This loss function, discretized using\nthe first-order forward Euler method, Heun's second-order approximation, and\nrefined with a midpoint approximation based on Taylor series expansion,\nenforces fidelity to fundamental physical principles by penalizing deviations\nfrom expected kinematic behavior. We evaluated PINN using real-world AIS\ndatasets that cover diverse maritime conditions and compared it with\nstate-of-the-art models. Our results demonstrate that the proposed method\nreduces average displacement errors by up to 32% across models and datasets\nwhile maintaining physical consistency. These results enhance model reliability\nand adherence to mission-critical maritime activities, where precision\ntranslates into better situational awareness in the oceans.",
    "pdf_url": "http://arxiv.org/pdf/2506.12029v1",
    "published": "2025-05-22T15:09:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16768v3",
    "title": "High-Efficiency Plasma-Based Compressor for Ultrafast Soft X-ray Free-Electron Lasers",
    "authors": [
      "Mingchang Wang",
      "Li Zeng",
      "Bingbing Zhang",
      "Qinghao Zhu",
      "Xiaozhe Shen",
      "Xiaofan Wang",
      "Qinming Li",
      "Weiqing Zhang"
    ],
    "abstract": "The generation of intense, femtosecond-scale X-ray pulses is crucial for\nprobing matter under extreme temporal and field conditions. Current\nchirped-pulse amplification (CPA) techniques in free-electron lasers (FELs),\nhowever, face efficiency limitations in the soft X-ray regime due to the\ninherent constraints of conventional optical compressors. To address this\nchallenge, we propose a high-efficiency plasma-based compressor utilizing\nhighly ionized noble gas plasma. Exploiting strong refractive index dispersion\nnear ionic resonances, this scheme achieves over 70% transmission efficiency\naround 5.2 nm, and is extendable to other highly charged ions for operation\nacross the soft X-ray to vacuum ultraviolet range. Simulations demonstrate that\na 25 fs FEL pulse can be compressed to 1.4 fs with peak power boosted to over\n100 GW, while maintaining high energy throughput. This approach overcomes the\nlong-standing efficiency bottleneck of soft X-ray CPA and opens a scalable path\ntoward compact, high-brightness attosecond FEL sources.",
    "pdf_url": "http://arxiv.org/pdf/2505.16768v3",
    "published": "2025-05-22T15:08:21+00:00",
    "categories": [
      "physics.acc-ph",
      "physics.optics",
      "physics.plasm-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16767v2",
    "title": "One-loop kernels in scale-dependent Horndeski theory",
    "authors": [
      "Ziyang Zheng",
      "Hanqiong Jia",
      "Bilal Tüdes",
      "Anton Chudaykin",
      "Martin Kunz",
      "Luca Amendola"
    ],
    "abstract": "We investigate the nonlinear evolution of cosmological perturbations in\ntheories with scale-dependent perturbation growth, first in general and then\nfocusing on Horndeski gravity. Within the framework of standard perturbation\ntheory, we derive the second- and third-order kernels and show that they are\nfully determined by two effective functions, $h_1$ and $h_c$, which parametrize\ndeviations from general relativity. Using the Wronskian method, we obtain\nsolutions for the nonlinear growth functions and present explicit expressions\nfor the resulting kernels, including bias and redshift space distortions. We\nshow that the kernels are entirely dependent on the linear growing mode: once\nthis is calculated, the kernels are analytic up to a time integral. Our\napproach provides a physically motivated framework for evaluating the one-loop\ngalaxy power spectrum in scale-dependent theories, suitable for the forecasts\nand actual data analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.16767v2",
    "published": "2025-05-22T15:08:04+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16766v2",
    "title": "Dynamical Geometric Theory of Principal Bundle Constrained Systems: Strong Transversality Conditions and Variational Framework for Gauge Field Coupling",
    "authors": [
      "Dongzhe Zheng"
    ],
    "abstract": "This paper introduces a geometric mechanics framework for constrained systems\non principal bundles through \\emph{compatible pairs} $(\\mathcal{D}, \\lambda)$,\naddressing fundamental challenges in gauge-constrained physical systems. We\ncharacterize the strong transversality condition by pairing constraint\ndistributions $\\mathcal{D}$ with Lie algebra dual functions $\\lambda: P \\to\n\\mathfrak{g}^*$ satisfying compatibility $\\mathcal{D}_p = \\{v :\n\\langle\\lambda(p), \\omega(v)\\rangle = 0\\}$ and differential consistency\n$d\\lambda + \\mathrm{ad}^*_\\omega \\lambda = 0$. This framework proves equivalent\nto $G$-equivariant Atiyah sequence splittings. We establish bidirectional\nconstruction enabling computation: forward (from $\\lambda$ to compatible\n$\\mathcal{D}$) and inverse (via variational minimization). Key mathematical\ncontributions include existence theorems for bundles with\n$\\mathrm{ad}^*_\\Omega\\lambda = 0$ and uniqueness results for semi-simple groups\nwith $\\mathfrak{z}(\\mathfrak{g}) = 0$, providing rigorous foundations for\nconstraint classification. Our central physical insight emerges from\nvariational principles, deriving dynamic connection equations $\\partial_t\\omega\n= d^{\\omega}\\eta - \\iota_{X_H}\\Omega$ revealing constraint-curvature coupling:\n$P_{\\text{constraint}} = \\langle\\lambda,\\Omega(\\dot{q},\\delta q)\\rangle$. This\nexplains non-trivial constraint-field interactions in magnetohydrodynamics and\nYang-Mills systems absent in kinematic theories. We construct Spencer\ncohomology for compatible pairs, establishing deep connections between\ntopological invariants and conservation laws. Systematic comparison\ndemonstrates that strong transversality captures essential constraint-curvature\nphysics invisible to standard approaches. Applications span fluid dynamics,\ngauge theories, and geometric control, providing new tools for complex physical\nsystems with intrinsic gauge-constraint coupling.",
    "pdf_url": "http://arxiv.org/pdf/2505.16766v2",
    "published": "2025-05-22T15:07:59+00:00",
    "categories": [
      "math.GM",
      "53C05, 37J60, 58A20"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16765v1",
    "title": "When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques",
    "authors": [
      "Jianing Geng",
      "Biao Yi",
      "Zekun Fei",
      "Tongxi Wu",
      "Lihai Nie",
      "Zheli Liu"
    ],
    "abstract": "Jailbreak attacks pose a serious threat to large language models (LLMs) by\nbypassing built-in safety mechanisms and leading to harmful outputs. Studying\nthese attacks is crucial for identifying vulnerabilities and improving model\nsecurity. This paper presents a systematic survey of jailbreak methods from the\nnovel perspective of stealth. We find that existing attacks struggle to\nsimultaneously achieve toxic stealth (concealing toxic content) and linguistic\nstealth (maintaining linguistic naturalness). Motivated by this, we propose\nStegoAttack, a fully stealthy jailbreak attack that uses steganography to hide\nthe harmful query within benign, semantically coherent text. The attack then\nprompts the LLM to extract the hidden query and respond in an encrypted manner.\nThis approach effectively hides malicious intent while preserving naturalness,\nallowing it to evade both built-in and external safety mechanisms. We evaluate\nStegoAttack on four safety-aligned LLMs from major providers, benchmarking\nagainst eight state-of-the-art methods. StegoAttack achieves an average attack\nsuccess rate (ASR) of 92.00%, outperforming the strongest baseline by 11.0%.\nIts ASR drops by less than 1% even under external detection (e.g., Llama\nGuard). Moreover, it attains the optimal comprehensive scores on stealth\ndetection metrics, demonstrating both high efficacy and exceptional stealth\ncapabilities. The code is available at\nhttps://anonymous.4open.science/r/StegoAttack-Jail66",
    "pdf_url": "http://arxiv.org/pdf/2505.16765v1",
    "published": "2025-05-22T15:07:34+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16764v2",
    "title": "Can a domain-specific language improve program structure comprehension of data pipelines? A mixed-methods study",
    "authors": [
      "Philip Heltweg",
      "Georg-Daniel Schwarz",
      "Dirk Riehle"
    ],
    "abstract": "In many application domains, domain-specific languages can allow domain\nexperts to contribute to collaborative projects more correctly and efficiently.\nTo do so, they must be able to understand program structure from reading\nexisting source code. With high-quality data becoming an increasingly important\nresource, the creation of data pipelines is an important application domain for\ndomain-specific languages. We execute a mixed-method study consisting of a\ncontrolled experiment and a follow-up descriptive survey among the participants\nto understand the effects of a domain-specific language on bottom-up program\nunderstanding and generate hypotheses for future research. During the\nexperiment, participants need the same time to solve program structure\ncomprehension tasks, but are significantly more correct when using the\ndomain-specific language. In the descriptive survey, participants describe\nreasons related to the programming language itself, such as a better pipeline\noverview, more enforced code structure, and a closer alignment to the mental\nmodel of a data pipeline. In addition, human factors such as less required\nprogramming experience and the ability to reuse experience from other data\nengineering tools are discussed. Based on these results, domain-specific\nlanguages are a promising tool for creating data pipelines that can increase\ncorrect understanding of program structure and lower barriers to entry for\ndomain experts. Open questions exist to make more informed implementation\ndecisions for domain-specific languages for data pipelines in the future.",
    "pdf_url": "http://arxiv.org/pdf/2505.16764v2",
    "published": "2025-05-22T15:06:10+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16763v2",
    "title": "Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation",
    "authors": [
      "Hongji Yang",
      "Yucheng Zhou",
      "Wencheng Han",
      "Jianbing Shen"
    ],
    "abstract": "Text-to-image models are powerful for producing high-quality images based on\ngiven text prompts, but crafting these prompts often requires specialized\nvocabulary. To address this, existing methods train rewriting models with\nsupervision from large amounts of manually annotated data and trained aesthetic\nassessment models. To alleviate the dependence on data scale for model training\nand the biases introduced by trained models, we propose a novel prompt\noptimization framework, designed to rephrase a simple user prompt into a\nsophisticated prompt to a text-to-image model. Specifically, we employ the\nlarge vision language models (LVLMs) as the solver to rewrite the user prompt,\nand concurrently, employ LVLMs as a reward model to score the aesthetics and\nalignment of the images generated by the optimized prompt. Instead of laborious\nhuman feedback, we exploit the prior knowledge of the LVLM to provide rewards,\ni.e., AI feedback. Simultaneously, the solver and the reward model are unified\ninto one model and iterated in reinforcement learning to achieve\nself-improvement by giving a solution and judging itself. Results on two\npopular datasets demonstrate that our method outperforms other strong\ncompetitors.",
    "pdf_url": "http://arxiv.org/pdf/2505.16763v2",
    "published": "2025-05-22T15:05:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16762v1",
    "title": "A Riemannian Optimization Approach for Finding the Nearest Reversible Markov Chain",
    "authors": [
      "Fabio Durastante",
      "Miryam Gnazzo",
      "Beatrice Meini"
    ],
    "abstract": "We address the algorithmic problem of determining the reversible Markov chain\n$\\tilde X$ that is closest to a given Markov chain $X$, with an identical\nstationary distribution. More specifically, $\\tilde X$ is the reversible Markov\nchain with the closest transition matrix, in the Frobenius norm, to the\ntransition matrix of $X$. To compute the transition matrix of $\\tilde X$, we\npropose a novel approach based on Riemannian optimization. Our method\nintroduces a modified multinomial manifold endowed with a prescribed stationary\nvector, while also satisfying the detailed balance conditions, all within the\nframework of the Fisher metric. We evaluate the performance of the proposed\napproach in comparison with an existing quadratic programming method and\ndemonstrate its effectiveness through a series of synthetic experiments, as\nwell as in the construction of a reversible Markov chain from transition count\ndata obtained via direct estimation from a stochastic differential equation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16762v1",
    "published": "2025-05-22T15:04:40+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16761v1",
    "title": "Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning",
    "authors": [
      "Jian Liu",
      "Jing Xu",
      "Song Guo",
      "Jing Li",
      "Jingfeng Guo",
      "Jiaao Yu",
      "Haohan Weng",
      "Biwen Lei",
      "Xianghui Yang",
      "Zhuo Chen",
      "Fangqi Zhu",
      "Tao Han",
      "Chunchao Guo"
    ],
    "abstract": "Existing pretrained models for 3D mesh generation often suffer from data\nbiases and produce low-quality results, while global reinforcement learning\n(RL) methods rely on object-level rewards that struggle to capture local\nstructure details. To address these challenges, we present \\textbf{Mesh-RFT}, a\nnovel fine-grained reinforcement fine-tuning framework that employs Masked\nDirect Preference Optimization (M-DPO) to enable localized refinement via\nquality-aware face masking. To facilitate efficient quality evaluation, we\nintroduce an objective topology-aware scoring system to evaluate geometric\nintegrity and topological regularity at both object and face levels through two\nmetrics: Boundary Edge Ratio (BER) and Topology Score (TS). By integrating\nthese metrics into a fine-grained RL strategy, Mesh-RFT becomes the first\nmethod to optimize mesh quality at the granularity of individual faces,\nresolving localized errors while preserving global coherence. Experiment\nresults show that our M-DPO approach reduces Hausdorff Distance (HD) by 24.6\\%\nand improves Topology Score (TS) by 3.8\\% over pre-trained models, while\noutperforming global DPO methods with a 17.4\\% HD reduction and 4.9\\% TS gain.\nThese results demonstrate Mesh-RFT's ability to improve geometric integrity and\ntopological regularity, achieving new state-of-the-art performance in\nproduction-ready mesh generation. Project Page:\n\\href{https://hitcslj.github.io/mesh-rft/}{this https URL}.",
    "pdf_url": "http://arxiv.org/pdf/2505.16761v1",
    "published": "2025-05-22T15:04:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16759v1",
    "title": "On the inclusion $\\cO_2 \\subset \\cQ_2$",
    "authors": [
      "Jacopo Bassi",
      "Roberto Conti"
    ],
    "abstract": "The diadic $C^*$-algebra $\\cQ_2$ contains canonically a copy of the Cuntz\nalgebra $\\cO_2$. It is shown that the inclusion $\\cO_2 \\subset \\cQ_2$ is\n$C^*$-irreducible and rigid. It follows that the injective envelopes of these\ntwo $C^*$-algebras are $*$-isomorphic.",
    "pdf_url": "http://arxiv.org/pdf/2505.16759v1",
    "published": "2025-05-22T15:04:07+00:00",
    "categories": [
      "math.OA",
      "(MSC 2010) Primary: 46L05, Secondary: 47L40"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16760v1",
    "title": "AdS/CFT Duality and Anyons in $SU(N)_k$ Chern-Simons Theory",
    "authors": [
      "Tzu-Miao Chou"
    ],
    "abstract": "This paper investigates the holographic realization of anyons in \\(SU(N)_k\\)\nChern-Simons theory within the AdS/CFT framework. The study extends traditional\nmodels, such as \\(SU(2)\\), to higher-rank groups like \\(SU(3)\\) and \\(SU(4)\\),\nfocusing on the fusion, braiding, and quantum dimensions of anyons. A\ncorrespondence between Wilson loops in the bulk and boundary defect operators\nis established, demonstrating how the modular data of Chern-Simons theory\nrelates to the boundary conformal field theory (CFT). The topological defects,\nfusion algebras, and operator spectra are analyzed from both the bulk and\nboundary perspectives, highlighting the relationship between bulk topological\ndefects and boundary operators. Additionally, a conjecture is made that the\nboundary operator algebra forms a modular tensor category, providing a\nframework for exploring holographic dualities in topologically non-trivial\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16760v1",
    "published": "2025-05-22T15:04:07+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.11056v2",
    "title": "xInv: Explainable Optimization of Inverse Problems",
    "authors": [
      "Sean Memery",
      "Kevin Denamganai",
      "Anna Kapron-King",
      "Kartic Subr"
    ],
    "abstract": "Inverse problems are central to a wide range of fields, including healthcare,\nclimate science, and agriculture. They involve the estimation of inputs,\ntypically via iterative optimization, to some known forward model so that it\nproduces a desired outcome. Despite considerable development in the\nexplainability and interpretability of forward models, the iterative\noptimization of inverse problems remains largely cryptic to domain experts. We\npropose a methodology to produce explanations, from traces produced by an\noptimizer, that are interpretable by humans at the abstraction of the domain.\nThe central idea in our approach is to instrument a differentiable simulator so\nthat it emits natural language events during its forward and backward passes.\nIn a post-process, we use a Language Model to create an explanation from the\nlist of events. We demonstrate the effectiveness of our approach with an\nillustrative optimization problem and an example involving the training of a\nneural network.",
    "pdf_url": "http://arxiv.org/pdf/2506.11056v2",
    "published": "2025-05-22T15:02:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16758v1",
    "title": "Monte Carlo approach to quantum work in strongly correlated electron systems",
    "authors": [
      "Qian-Xi Zhao",
      "Jian-Jun Dong",
      "Zi-Xiang Hu"
    ],
    "abstract": "We develop a Monte Carlo framework to analyze the statistics of quantum work\nin correlated electron systems. Using the Ising-Kondo model in heavy fermions\nas a paradigmatic platform, we thoroughly illustrate the process of determining\nthe moment generating function of quantum work under nonequilibrium conditions\nin detail. Based on this function, we systematically investigate essential\nstatistical quantities, including the mean irreversible work density, the mean\nwork density, variance, and the third central moment of quantum work across\ndifferent quench processes. Our findings highlight distinct singularities in\nthese quantities at the metal-insulator phase transition point at low\ntemperatures. However, these singularities disappear, and the transition\nbecomes a smooth crossover at high temperatures. This stark contrast\nunderscores quantum work as an effective thermodynamic tool for identifying\nmetal-insulator phase transitions. Our approach provides a promising new\nframework for investigating nonequilibrium quantum thermodynamics in strongly\ncorrelated electron systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16758v1",
    "published": "2025-05-22T15:01:05+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.16757v1",
    "title": "Regularity of two-phase free boundary minimizers in periodic media",
    "authors": [
      "Farhan Abedin",
      "William M Feldman"
    ],
    "abstract": "We study the regularity of minimizers of a two-phase energy functional in\nperiodic media. Our main result is a large scale Lipschitz estimate. We also\nestablish improvement-of-flatness for non-degenerate minimizers, which is a key\ningredient in the proof of the Lipschitz estimate. As a consequence, we obtain\na Liouville property for entire non-degenerate minimizers.",
    "pdf_url": "http://arxiv.org/pdf/2505.16757v1",
    "published": "2025-05-22T15:00:57+00:00",
    "categories": [
      "math.AP",
      "5R35, 35B27, 35B65, 49Q05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16756v1",
    "title": "Representation Discrepancy Bridging Method for Remote Sensing Image-Text Retrieval",
    "authors": [
      "Hailong Ning",
      "Siying Wang",
      "Tao Lei",
      "Xiaopeng Cao",
      "Huanmin Dou",
      "Bin Zhao",
      "Asoke K. Nandi",
      "Petia Radeva"
    ],
    "abstract": "Remote Sensing Image-Text Retrieval (RSITR) plays a critical role in\ngeographic information interpretation, disaster monitoring, and urban planning\nby establishing semantic associations between image and textual descriptions.\nExisting Parameter-Efficient Fine-Tuning (PEFT) methods for Vision-and-Language\nPre-training (VLP) models typically adopt symmetric adapter structures for\nexploring cross-modal correlations. However, the strong discriminative nature\nof text modality may dominate the optimization process and inhibits image\nrepresentation learning. The nonnegligible imbalanced cross-modal optimization\nremains a bottleneck to enhancing the model performance. To address this issue,\nthis study proposes a Representation Discrepancy Bridging (RDB) method for the\nRSITR task. On the one hand, a Cross-Modal Asymmetric Adapter (CMAA) is\ndesigned to enable modality-specific optimization and improve feature\nalignment. The CMAA comprises a Visual Enhancement Adapter (VEA) and a Text\nSemantic Adapter (TSA). VEA mines fine-grained image features by Differential\nAttention (DA) mechanism, while TSA identifies key textual semantics through\nHierarchical Attention (HA) mechanism. On the other hand, this study extends\nthe traditional single-task retrieval framework to a dual-task optimization\nframework and develops a Dual-Task Consistency Loss (DTCL). The DTCL improves\ncross-modal alignment robustness through an adaptive weighted combination of\ncross-modal, classification, and exponential moving average consistency\nconstraints. Experiments on RSICD and RSITMD datasets show that the proposed\nRDB method achieves a 6%-11% improvement in mR metrics compared to\nstate-of-the-art PEFT methods and a 1.15%-2% improvement over the full\nfine-tuned GeoRSCLIP model.",
    "pdf_url": "http://arxiv.org/pdf/2505.16756v1",
    "published": "2025-05-22T14:59:30+00:00",
    "categories": [
      "cs.CV",
      "cs.IR",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16755v1",
    "title": "Multi-Output Gaussian Processes for Graph-Structured Data",
    "authors": [
      "Ayano Nakai-Kasai",
      "Tadashi Wadayama"
    ],
    "abstract": "Graph-structured data is a type of data to be obtained associated with a\ngraph structure where vertices and edges describe some kind of data\ncorrelation. This paper proposes a regression method on graph-structured data,\nwhich is based on multi-output Gaussian processes (MOGP), to capture both the\ncorrelation between vertices and the correlation between associated data. The\nproposed formulation is built on the definition of MOGP. This allows it to be\napplied to a wide range of data configurations and scenarios. Moreover, it has\nhigh expressive capability due to its flexibility in kernel design. It includes\nexisting methods of Gaussian processes for graph-structured data as special\ncases and is possible to remove restrictions on data configurations, model\nselection, and inference scenarios in the existing methods. The performance of\nextensions achievable by the proposed formulation is evaluated through computer\nexperiments with synthetic and real data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16755v1",
    "published": "2025-05-22T14:59:21+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16754v2",
    "title": "PyTupli: A Scalable Infrastructure for Collaborative Offline Reinforcement Learning Projects",
    "authors": [
      "Hannah Markgraf",
      "Michael Eichelbeck",
      "Daria Cappey",
      "Selin Demirtürk",
      "Yara Schattschneider",
      "Matthias Althoff"
    ],
    "abstract": "Offline reinforcement learning (RL) has gained traction as a powerful\nparadigm for learning control policies from pre-collected data, eliminating the\nneed for costly or risky online interactions. While many open-source libraries\noffer robust implementations of offline RL algorithms, they all rely on\ndatasets composed of experience tuples consisting of state, action, next state,\nand reward. Managing, curating, and distributing such datasets requires\nsuitable infrastructure. Although static datasets exist for established\nbenchmark problems, no standardized or scalable solution supports developing\nand sharing datasets for novel or user-defined benchmarks. To address this gap,\nwe introduce PyTupli, a Python-based tool to streamline the creation, storage,\nand dissemination of benchmark environments and their corresponding tuple\ndatasets. PyTupli includes a lightweight client library with defined interfaces\nfor uploading and retrieving benchmarks and data. It supports fine-grained\nfiltering at both the episode and tuple level, allowing researchers to curate\nhigh-quality, task-specific datasets. A containerized server component enables\nproduction-ready deployment with authentication, access control, and automated\ncertificate provisioning for secure use. By addressing key barriers in dataset\ninfrastructure, PyTupli facilitates more collaborative, reproducible, and\nscalable offline RL research.",
    "pdf_url": "http://arxiv.org/pdf/2505.16754v2",
    "published": "2025-05-22T14:59:20+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16753v2",
    "title": "Energy-Energy Correlator at Hadron Colliders: Celestial Blocks and Singularities",
    "authors": [
      "Hao Chen",
      "Hongyi Ruan",
      "Hua Xing Zhu"
    ],
    "abstract": "Energy-energy correlator (EEC) is an event shape observable that\ncharacterizes the distribution of energy flux in collision events. We initiate\nthe study of full-range EEC at hadron colliders, generalizing the extensively\nstudied EEC in $e^+e^-$ collision as well as the transverse EEC in hadron\ncollisions. We derive celestial blocks from Lorentz symmetry to perform partial\nwave decomposition of the EEC at hadron colliders. These celestial blocks are\nessentially conformal blocks on the 2d celestial sphere, which have additional\ndependence on the collinear spin of ``light-ray transition matrix'' along the\ncollision axis. In this work, we perform the first leading-order (LO) analytic\ncalculation of this observable in pure Yang-Mills theory and use it as an\nexample to illustrate the block decomposition. Numerically, the block expansion\ndemonstrates superior accuracy in the collinear limit compared to conventional\npower series expansion. Analytically, we observe in this example that the block\ncoefficients exhibit analyticity in both collinear and transverse spin. In\naddition, we analyze several kinematic limits at LO -- collinear, back-to-back,\nopposite coplanar and Regge limit. While the first three limits naturally\ngeneralize their $e^+e^-$ collision counterparts or transverse EEC and are\ngoverned by soft-collinear dynamics, the Regge limit requires complete angular\ndependence and reveals BFKL physics. Phenomenologically, we propose a realistic\nexperimental setup and briefly discuss how the convolution of parton\ndistribution function modifies the perturbative EEC result. Our work suggests\nthat the full-range EEC at hadron colliders is an elegant observable which\nprobes a broader kinematic space and connects various regimes of different QCD\ndynamics through a single measurement.",
    "pdf_url": "http://arxiv.org/pdf/2505.16753v2",
    "published": "2025-05-22T14:59:11+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16752v3",
    "title": "Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation",
    "authors": [
      "Hao Guo",
      "Erpeng Xue",
      "Lei Huang",
      "Shichao Wang",
      "Xiaolei Wang",
      "Lei Wang",
      "Jinpeng Wang",
      "Sheng Chen"
    ],
    "abstract": "Deep Learning Recommendation Models (DLRMs) often rely on extensive manual\nfeature engineering to improve accuracy and user experience, which increases\nsystem complexity and limits scalability of model performance with respect to\ncomputational resources. Recently, Meta introduced a generative ranking\nparadigm based on HSTU block that enables end-to-end learning from raw user\nbehavior sequences and demonstrates scaling law on large datasets that can be\nregarded as the state-of-the-art (SOTA). However, splitting user behaviors into\ninterleaved item and action information significantly increases the input\nsequence length, which adversely affects both training and inference\nefficiency. To address this issue, we propose the Dual-Flow Generative Ranking\nNetwork (DFGR), that employs a dual-flow mechanism to optimize interaction\nmodeling, ensuring efficient training and inference through end-to-end token\nprocessing. DFGR duplicates the original user behavior sequence into a real\nflow and a fake flow based on the authenticity of the action information, and\nthen defines a novel interaction method between the real flow and the fake flow\nwithin the QKV module of the self-attention mechanism. This design reduces\ncomputational overhead and improves both training efficiency and inference\nperformance compared to Meta's HSTU-based model. Experiments on both\nopen-source and real industrial datasets show that DFGR outperforms DLRM, which\nserves as the industrial online baseline with extensive feature engineering, as\nwell as Meta's HSTU and other common recommendation models such as DIN, DCN,\nDIEN, and DeepFM. Furthermore, we investigate optimal parameter allocation\nstrategies under computational constraints, establishing DFGR as an efficient\nand effective next-generation generative ranking paradigm.",
    "pdf_url": "http://arxiv.org/pdf/2505.16752v3",
    "published": "2025-05-22T14:58:53+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16751v1",
    "title": "Satellite-assisted Entanglement Distribution with High-Dimensional Photonic Encoding",
    "authors": [
      "V. Domínguez Tubío",
      "M. C. Dijksman",
      "J. Borregaard"
    ],
    "abstract": "Satellite-assisted entanglement distribution is a promising approach for\nrealizing long-range quantum networking. However, the limited coherence time of\nexisting quantum memories makes it challenging to obtain multiple event-ready\nentangled pairs between ground stations since one pair decoheres before the\nsuccessful distribution of another. We demonstrate how this can be circumvented\nby pairing existing satellite-compatible spontaneous parametric down conversion\n(SPDC) sources with qudit-compatible quantum memories on ground. By operating\nthe SPDC source as a source of time-bin encoded photonic qudits, simultaneous\ndistribution of multiple entangled pairs between the ground stations can be\nachieved at a significantly higher rate than if the SPDC sources was operated\nas a source of photonic qubits. We find that for achievable coherence times of\nseveral seconds and demonstrated satellite performances from the Micius\nsatellite, the qudit operation leads to several orders of magnitude faster\ndistribution rates than the qubit-based operation when more than one\nevent-ready high-quality (Bell pair fidelity $\\geq0.95$) entangled pair is\ndesired. To ensure high-quality entanglement distribution, we consider\nmultiplexed quantum memory operation storage and, in the qubit case, we also\nconsider storage cutoff times.",
    "pdf_url": "http://arxiv.org/pdf/2505.16751v1",
    "published": "2025-05-22T14:58:37+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16750v3",
    "title": "Theory of cell size regulation during migration in adhered cells",
    "authors": [
      "Jonathan E. Ron",
      "Ram M. Adar"
    ],
    "abstract": "Cell migration is closely linked to cell shape, yet cell size is often\nassumed to remain constant. This assumption is challenged by recent experiments\nshowing that cells undergo volume loss during spreading and swelling upon\nactivation, with migration velocity correlated to cell size. In this Letter, we\npresent a minimal theoretical framework for cellular size regulation and its\ninfluence on migration velocity. We connect cell size to membrane potential and\nactive, actin-driven forces. Spatial inhomogeneities in these forces establish\ncell polarization and drive migration. Crucially, inhomogeneity is easier to\nestablish over larger sizes, giving rise to a critical contact area, above\nwhich migration is possible. Our theory captures the coupled dynamics of cell\nvolume, surface area, and motility and explains recent experiments on\nneutrophils.",
    "pdf_url": "http://arxiv.org/pdf/2505.16750v3",
    "published": "2025-05-22T14:58:10+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16749v2",
    "title": "Rotation angles of a rotating disc -- A toy model exhibiting the geometric phase --",
    "authors": [
      "Takuya Matsumoto",
      "Hiroki Takada",
      "Osami Yasukura"
    ],
    "abstract": "In this paper, we consider a simple kinematic model, which is a rotating disc\non the edge of another fixed disc without slipping, and study the rotation\nangle of the rotating disc. The rotation angle consists of two parts, the\ndynamical phase $\\Delta_d$ and the geometric phase $\\Delta_g$. The former is a\ndynamical rotation of the disc itself, and the geometric motion of the disc\ncharacterizes the latter. In fact, $\\Delta_g$ is regarded as the geometric\nphase appearing in several important contexts in physics. The clue to finding\nthe explicit form of $\\Delta_g$ is the Baumkuchen lemma, which we called. Due\nto the Gauss-Bonnet theorem, in the case that the rotating disc comes back to\nthe initial position, $\\Delta_g$ is interpreted as the signed area of a\ntwo-sphere enclosed by the trajectory of the Gauss vector, which is a unit\nnormal vector on the moving disc. We also comment on typical models sharing the\ncommon underlying structure, which include Foucault's pendulum, Dirac's\nmonopole potentials, and Berry phase. Hence, our model is a very simple but\ndistinguished one in the sense that it embodies the essential concepts in\ndifferential geometry and theoretical physics such as the Gauss-Bonnet theorem,\nthe geometric phase, and the fiber bundles.",
    "pdf_url": "http://arxiv.org/pdf/2505.16749v2",
    "published": "2025-05-22T14:58:05+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.DG",
      "math.MP",
      "physics.app-ph",
      "quant-ph"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16748v1",
    "title": "Revenue Optimization with Price-Sensitive and Interdependent Demand",
    "authors": [
      "Julien Laasri",
      "Marc Revol"
    ],
    "abstract": "As Kalyan T. Talluri and Garrett J. Van Ryzin describe in their work [3],\nRevenue Management aims to maximize an organization's revenue by considering\nthree types of decision categories: structural, pricing, and quantity. In this\ndocument, our primary focus will be on decisions related to pricing and\nquantity for the sale of airline tickets on a direct flight over a certain\nnumber of time periods. More specifically, we will only focus on the\noptimization aspect of this problem. We will assume the demand data to be\ngiven, since Air France estimates it beforehand using real data. Similarly, we\nassume all price options to be predetermined by Air France's algorithms and\nverified by their analysts. Our objective will be to maximize the revenue of a\ndirect flight by choosing the prices for each product from the predefined set\nof options.\n  --\n  Comme d\\'ecrit par Kalyan T. Talluri et Garrett J. Van Ryzin dans leur\nouvrage [3], le Revenue Management consiste en la maximisation du revenu d'un\norganisme \\`a partir de trois types de cat\\'egories de d\\'ecision :\nstructurelles, prix et quantit\\'e. Dans ce document, nous nous int\\'eresserons\nprincipalement aux d\\'ecisions de type prix et quantit\\'e pour la vente de\nbillets d'avion sur un vol direct au cours d'un certain nombre de pas de temps.\nPlus pr\\'ecis\\'ement, nous nous situerons dans la partie optimisation du\nprobl\\`eme. Nous prendrons ainsi les donn\\'ees de demande comme acquises, car\nelles sont estim\\'ees au pr\\'ealable par Air France \\`a partir des donn\\'ees\nr\\'eelles. De m\\^eme, pour chaque produit que l'on cherchera \\`a vendre, on\nnous impose en amont les prix possibles que l'on a droit d'utiliser et qui se\nbasent sur des algorithmes d'Air France dont les r\\'esultats sont v\\'erifi\\'es\npar des analystes. Notre but sera alors de maximiser le revenu d'un vol direct\nen choisissant les prix de chaque produit parmi ceux impos\\'es.",
    "pdf_url": "http://arxiv.org/pdf/2505.16748v1",
    "published": "2025-05-22T14:57:43+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "90C59",
      "G.1.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16747v1",
    "title": "Characterizations and properties of solutions to parabolic problems of linear growth",
    "authors": [
      "Theo Elenius"
    ],
    "abstract": "We consider notions of weak solutions to a general class of parabolic\nproblems of linear growth, formulated independently of time regularity.\nEquivalence with variational solutions is established using a stability result\nfor weak solutions. A key tool in our arguments is approximation of parabolic\nBV functions using time mollification and Sobolev approximations. We also prove\na comparison principle and a local boundedness result for solutions. When the\ntime derivative of the solution is in $L^2$ our definitions are equivalent with\nthe definition based on the Anzellotti pairing.",
    "pdf_url": "http://arxiv.org/pdf/2505.16747v1",
    "published": "2025-05-22T14:56:56+00:00",
    "categories": [
      "math.AP",
      "35K20, 35K67, 35K92"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16746v2",
    "title": "Emergent Orbital Dynamics in Strongly Spin-Orbit Coupled Systems",
    "authors": [
      "A. S. Miñarro",
      "G. Herranz"
    ],
    "abstract": "The interplay between spin and orbital degrees of freedom gives rise to a\nvariety of emergent phases in correlated 4d and 5d transition-metal systems.\nStrong spin-orbit coupling (SOC) significantly alters Jahn-Teller (JT) physics,\noften suppressing static distortions or promoting dynamic fluctuations, thereby\nreducing or even quenching orbital polarization. While intersite hybridization\nis a fundamental aspect of crystalline solids, its role in shaping the dynamics\nof spin-orbit-entangled states has received comparatively little attention.\nHere, we show that electronic hopping can locally restore orbital polarization\nwhen the ground state is perturbed, even in the absence of static orbital\norder. Using a Matsubara lattice formalism, we analyze how local orbital\nperturbations propagate through correlated, spin-orbit-entangled systems. When\nintersite hopping is included, such perturbations induce short-range orbital\npolarization with a characteristic orthogonal response at nearest-neighbor\nsites. Although the energy scale of these hybridization-driven orbital\nreconstructions likely makes their detection challenging, they may still\ninfluence low-energy spectral features and interact with other excitations.\nThese results underscore the importance of including orbital dynamics in the\ninterpretation of spectroscopic data and provide a framework for understanding\ndynamical responses in spin-orbit-entangled materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.16746v2",
    "published": "2025-05-22T14:56:49+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.16745v1",
    "title": "Flipping and Forking",
    "authors": [
      "Wojciech Przybyszewski",
      "Szymon Toruńczyk"
    ],
    "abstract": "Monadic stability and the more general monadic dependence (or NIP) are\ntameness conditions for classes of logical structures, studied in the 80's in\nShelah's classification program in model theory. They recently emerged in\nalgorithmic and structural graph theory and finite model theory as central\nnotions in relation with the model checking problem for first-order logic: the\nproblem was shown to be fixed-parameter tractable for inputs which come from a\nfixed class of graphs which is monadically stable, and is conjectured to be\ntractable in all monadically dependent classes. Several combinatorial\ncharacterizations of such graph classes turned out to be essential in their\nalgorithmic treatment; they are all based on the fundamental operation of\n\"flipping\" a graph.\n  We introduce the notions of $\\textit{flips}$ and $\\textit{flip independence}$\nin arbitrary relational structures. We lift prior combinatorial\ncharacterizations of monadically stable graph classes to monadically stable\nclasses of relational structures. We show the equivalence of flip independence\nwith $\\textit{forking independence}$ (over models) -- a logical notion of\nparamount importance in stability theory -- in monadically stable structures,\nshedding new light on the relevance of flips, also characterizing forking\nindependence (over models) combinatorially. We give more precise descriptions\nof forking independence in the case of monadically stable graphs, and\nrelational structures with a nowhere dense Gaifman graph.",
    "pdf_url": "http://arxiv.org/pdf/2505.16745v1",
    "published": "2025-05-22T14:54:15+00:00",
    "categories": [
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16744v1",
    "title": "PulserDiff: a pulse differentiable extension for Pulser",
    "authors": [
      "Vytautas Abramavicius",
      "Melvin Mathé",
      "Gergana V. Velikova",
      "João P. Moutinho",
      "Mario Dagrada",
      "Vincent E. Elfving",
      "Alexandre Dauphin",
      "Joseph Vovrosh",
      "Roland Guichard"
    ],
    "abstract": "Programming analog quantum processing units (QPUs), such as those produced by\nPasqal, can be achieved using specialized low-level pulse libraries like\nPulser. However, few currently offer the possibility to optimize pulse sequence\nparameters. In this paper, we introduce PulserDiff, a user-friendly and\nopen-source Pulser extension designed to optimize pulse sequences over a\nwell-defined set of control parameters that drive the quantum computation. We\ndemonstrate its usefulness through several case studies involving analog\nconfigurations that emulate digital gates and state preparation. PulserDiff\nproduces hardware-compatible pulses with remarkably high fidelities, showcasing\nits potential for advancing analog quantum computing applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16744v1",
    "published": "2025-05-22T14:54:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16743v1",
    "title": "TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning",
    "authors": [
      "Florentin Beck",
      "William Rudman",
      "Carsten Eickhoff"
    ],
    "abstract": "Large Language Models (LLMs) present significant computational and memory\nchallenges due to their extensive size, making pruning essential for their\nefficient deployment. Existing one-shot pruning methods often apply uniform\nsparsity constraints across layers or within each layer, resulting in\nsuboptimal performance, especially at high sparsity ratios. This work\nintroduces TRIM (Targeted Row-wise Iterative Metric-driven pruning), a novel\napproach that applies varying sparsity ratios to individual output dimensions\n(rows) within each layer. TRIM employs an iterative adjustment process guided\nby quality metrics to optimize dimension-wise sparsity allocation, focusing on\nreducing variance in quality retention across outputs to preserve critical\ninformation. TRIM can be seamlessly integrated with existing layer-wise pruning\nstrategies. Our evaluations on perplexity and zero-shot tasks across diverse\nLLM families (Qwen2.5, LLaMA-2, and OPT) and sparsity levels demonstrate that\nTRIM achieves new state-of-the-art results and enhances stability. For\ninstance, at 80% sparsity, TRIM reduces perplexity by 48% for Qwen2.5-14B and\nover 90% for OPT-13B compared to baseline methods. We conclude that\nfine-grained, dimension-wise sparsity adaptation is crucial for pushing the\nlimits of extreme LLM compression. Code available at:\nhttps://github.com/flobk/TRIM",
    "pdf_url": "http://arxiv.org/pdf/2505.16743v1",
    "published": "2025-05-22T14:53:53+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.6; F.2.2"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16742v1",
    "title": "Pressure dependence of the interfacial polarization and negative activation volume for dielectric relaxation in heterogeneous systems",
    "authors": [
      "Anthony N. Papathanassiou"
    ],
    "abstract": "Negative activation volumes for dielectric relaxation are rarely reported in\nsolid state physics and are limited to atomic scale processes. Broadband\nDielectric Spectroscopy on heterogeneous systems, such as polycrystalline\ncalcite and magnesite, hosting water in their porous spce, detectedintense\ndielectric relaxation mechanisms related to the interfacial polarization. The\ncharacteristic relaxation frequency increased uponhydrostatic compression,\nindicating that the activation volumes for relaxation are negative. However, a\ntheoretical interpretation for the negative sign of the activation volume is\nlacking up to date. Within the frame of effective medium approximation for\nmesoscopic heterogeneous two phase solid - fluid systems, we investigate how\nthe synergyof the pressure depedencies of polarization and electric charge\ntransport, respectively, dictate the pressure dependence of interfacial\npolarization . predicting the value of the effective activation volume. Our\ntheoretical approach succeeds in predicting the negative sign and magnitude of\nthe activation volume in water saturated polycrystalline materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.16742v1",
    "published": "2025-05-22T14:53:40+00:00",
    "categories": [
      "physics.geo-ph",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16741v1",
    "title": "Meta-reinforcement learning with minimum attention",
    "authors": [
      "Pilhwa Lee",
      "Shashank Gupta"
    ],
    "abstract": "Minimum attention applies the least action principle in the changes of\ncontrol concerning state and time, first proposed by Brockett. The involved\nregularization is highly relevant in emulating biological control, such as\nmotor learning. We apply minimum attention in reinforcement learning (RL) as\npart of the rewards and investigate its connection to meta-learning and\nstabilization. Specifically, model-based meta-learning with minimum attention\nis explored in high-dimensional nonlinear dynamics. Ensemble-based model\nlearning and gradient-based meta-policy learning are alternately performed.\nEmpirically, we show that the minimum attention does show outperforming\ncompetence in comparison to the state-of-the-art algorithms in model-free and\nmodel-based RL, i.e., fast adaptation in few shots and variance reduction from\nthe perturbations of the model and environment. Furthermore, the minimum\nattention demonstrates the improvement in energy efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.16741v1",
    "published": "2025-05-22T14:53:06+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16740v1",
    "title": "Robust Vision-Based Runway Detection through Conformal Prediction and Conformal mAP",
    "authors": [
      "Alya Zouzou",
      "Léo andéol",
      "Mélanie Ducoffe",
      "Ryma Boumazouza"
    ],
    "abstract": "We explore the use of conformal prediction to provide statistical uncertainty\nguarantees for runway detection in vision-based landing systems (VLS). Using\nfine-tuned YOLOv5 and YOLOv6 models on aerial imagery, we apply conformal\nprediction to quantify localization reliability under user-defined risk levels.\nWe also introduce Conformal mean Average Precision (C-mAP), a novel metric\naligning object detection performance with conformal guarantees. Our results\nshow that conformal prediction can improve the reliability of runway detection\nby quantifying uncertainty in a statistically sound way, increasing safety\non-board and paving the way for certification of ML system in the aerospace\ndomain.",
    "pdf_url": "http://arxiv.org/pdf/2505.16740v1",
    "published": "2025-05-22T14:52:59+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16739v1",
    "title": "Asymptotics of the partition function of the perturbed Gross-Witten-Wadia unitary matrix model",
    "authors": [
      "Yu Chen",
      "Shuai-Xia Xu",
      "Yu-Qiu Zhao"
    ],
    "abstract": "We consider the asymptotics of the partition function of the extended\nGross-Witten-Wadia unitary matrix model by introducing an extra logarithmic\nterm in the potential. The partition function can be written as a Toeplitz\ndeterminant with entries expressed in terms of the modified Bessel functions of\nthe first kind and furnishes a $\\tau$-function sequence of the Painlev\\'e III'\nequation. We derive the asymptotic expansions of the Toeplitz determinant up to\nand including the constant terms as the size of the determinant tends to\ninfinity. The constant terms therein are expressed in terms of the Riemann\nzeta-function and the Barnes $G$-function. A third-order phase transition in\nthe leading terms of the asymptotic expansions is also observed.",
    "pdf_url": "http://arxiv.org/pdf/2505.16739v1",
    "published": "2025-05-22T14:52:20+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "30E15 (33C10)"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16738v1",
    "title": "The S-PLUS Fornax Project (S+FP): Mapping H$α$+[NII] emission in 77 Fornax galaxy members reaching $\\sim$4 Rvir",
    "authors": [
      "A. R. Lopes",
      "A. V. Smith Castelli",
      "A. C. Krabbe",
      "J. A. Hernandez-Jimenez",
      "D. Pallero",
      "S. Torres-Flores",
      "E. Telles",
      "M. Sarzi",
      "A. Cortesi",
      "J. Thainá-Batista",
      "R. Cid Fernandes",
      "E. A. D. Lacerda",
      "M. Sampaio",
      "V. H. Sasse",
      "F. R. Herpich",
      "I. Andruchow",
      "R. Demarco",
      "L. A. Gutiérrez-Soto",
      "M. Grossi",
      "R. F. Haack",
      "P. K. Humire",
      "C. Lima-Dias",
      "G. Limberg",
      "C. Lobo",
      "L. Lomelí-Núñez",
      "P. A. A. Lopes",
      "D. E. Olave-Rojas",
      "S. V . Werner",
      "F. Almeida-Fernandes",
      "G. B. Oliveira Schwarz",
      "W. Schoenell",
      "T. Ribeiro",
      "A. Kanaan",
      "C. Mendes de Oliveira"
    ],
    "abstract": "The Fornax cluster, the second-largest galaxy cluster within 20 Mpc, presents\nan ideal environment for studying environmental effects on galaxy evolution.\nUtilizing data from the Southern Photometric Local Universe Survey (S-PLUS),\nthis study explores the H$\\alpha$+[NII] emission maps across an area of\napproximately 208 square degrees around NGC 1399. For such, a dedicated\nsemi-automated pipeline, Pixel-to-Pixel Emission Line Estimate (PELE), was\ndeveloped to generate emission line maps by processing S-PLUS images using the\nThree Filter Method. A morphological analysis was conducted using the\nASTROMORPHLIB package to determine whether H$\\alpha$+[NII] emitters exhibit\nperturbed features. The study successfully detected 77 H$\\alpha$+[NII] emitters\nwith $r<18$ mag, extending to four times the virial radius of the Fornax\ncluster. PELE demonstrated its ability to recover flux down to 2e-17 erg\ns$^{-1}$ cm$^{-2}$ when compared to H$\\alpha$ maps from MUSE/VLT. Among the\nemitters, 25% are early-type galaxies (ETG) and 75% late-type galaxies (LTG).\nSigns of morphological perturbation or merger activity are observed in 44% of\nthe LTG and in three ETG located beyond the cluster's virial radius. A\nsignificant fraction (91%) of the emitters are identified as recent infallers,\nprimarily located in the northwestern region of the cluster, while others are\nassociated with the infalling group Fornax A in the southwest. Disturbed,\nlow-mass galaxies at larger cluster-centric distances provide evidence of\ngalaxies begin transforming before entering the main cluster. This study\ndemonstrates S-PLUS's effectiveness in detecting emitters, whose distribution\nreflects the Fornax cluster's assembly history, with LTG linked to recent\ninfall from the field, possibly along a Fornax-Eridanus filament, and ETG may\nhave evolved prior to entry.",
    "pdf_url": "http://arxiv.org/pdf/2505.16738v1",
    "published": "2025-05-22T14:52:11+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16737v1",
    "title": "Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization",
    "authors": [
      "Chengcan Wu",
      "Zhixin Zhang",
      "Zeming Wei",
      "Yihao Zhang",
      "Meng Sun"
    ],
    "abstract": "The significant progress of large language models (LLMs) has led to\nremarkable achievements across numerous applications. However, their ability to\ngenerate harmful content has sparked substantial safety concerns. Despite the\nimplementation of safety alignment techniques during the pre-training phase,\nrecent research indicates that fine-tuning LLMs on adversarial or even benign\ndata can inadvertently compromise their safety. In this paper, we re-examine\nthe fundamental issue of why fine-tuning on non-harmful data still results in\nsafety degradation. We introduce a safety-aware probing (SAP) optimization\nframework designed to mitigate the safety risks of fine-tuning LLMs.\nSpecifically, SAP incorporates a safety-aware probe into the gradient\npropagation process, mitigating the model's risk of safety degradation by\nidentifying potential pitfalls in gradient directions, thereby enhancing\ntask-specific performance while successfully preserving model safety. Our\nextensive experimental results demonstrate that SAP effectively reduces\nharmfulness below the original fine-tuned model and achieves comparable test\nloss to standard fine-tuning methods. Our code is available at\nhttps://github.com/ChengcanWu/SAP.",
    "pdf_url": "http://arxiv.org/pdf/2505.16737v1",
    "published": "2025-05-22T14:52:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17160v1",
    "title": "Harry Potter is Still Here! Probing Knowledge Leakage in Targeted Unlearned Large Language Models via Automated Adversarial Prompting",
    "authors": [
      "Bang Trinh Tran To",
      "Thai Le"
    ],
    "abstract": "This work presents LURK (Latent UnleaRned Knowledge), a novel framework that\nprobes for hidden retained knowledge in unlearned LLMs through adversarial\nsuffix prompting. LURK automatically generates adversarial prompt suffixes\ndesigned to elicit residual knowledge about the Harry Potter domain, a commonly\nused benchmark for unlearning. Our experiments reveal that even models deemed\nsuccessfully unlearned can leak idiosyncratic information under targeted\nadversarial conditions, highlighting critical limitations of current unlearning\nevaluation standards. By uncovering latent knowledge through indirect probing,\nLURK offers a more rigorous and diagnostic tool for assessing the robustness of\nunlearning algorithms. All code will be publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.17160v1",
    "published": "2025-05-22T14:51:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16736v1",
    "title": "Backward Oversmoothing: why is it hard to train deep Graph Neural Networks?",
    "authors": [
      "Nicolas Keriven"
    ],
    "abstract": "Oversmoothing has long been identified as a major limitation of Graph Neural\nNetworks (GNNs): input node features are smoothed at each layer and converge to\na non-informative representation, if the weights of the GNN are sufficiently\nbounded. This assumption is crucial: if, on the contrary, the weights are\nsufficiently large, then oversmoothing may not happen. Theoretically, GNN could\nthus learn to not oversmooth. However it does not really happen in practice,\nwhich prompts us to examine oversmoothing from an optimization point of view.\nIn this paper, we analyze backward oversmoothing, that is, the notion that\nbackpropagated errors used to compute gradients are also subject to\noversmoothing from output to input. With non-linear activation functions, we\noutline the key role of the interaction between forward and backward smoothing.\nMoreover, we show that, due to backward oversmoothing, GNNs provably exhibit\nmany spurious stationary points: as soon as the last layer is trained, the\nwhole GNN is at a stationary point. As a result, we can exhibit regions where\ngradients are near-zero while the loss stays high. The proof relies on the fact\nthat, unlike forward oversmoothing, backward errors are subjected to a linear\noversmoothing even in the presence of non-linear activation function, such that\nthe average of the output error plays a key role. Additionally, we show that\nthis phenomenon is specific to deep GNNs, and exhibit counter-example\nMulti-Layer Perceptron. This paper is a step toward a more complete\ncomprehension of the optimization landscape specific to GNNs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16736v1",
    "published": "2025-05-22T14:51:38+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16735v2",
    "title": "Adversarial Deep Metric Learning for Cross-Modal Audio-Text Alignment in Open-Vocabulary Keyword Spotting",
    "authors": [
      "Youngmoon Jung",
      "Yong-Hyeok Lee",
      "Myunghun Jung",
      "Jaeyoung Roh",
      "Chang Woo Han",
      "Hoon-Young Cho"
    ],
    "abstract": "For text enrollment-based open-vocabulary keyword spotting (KWS), acoustic\nand text embeddings are typically compared at either the phoneme or utterance\nlevel. To facilitate this, we optimize acoustic and text encoders using deep\nmetric learning (DML), enabling direct comparison of multi-modal embeddings in\na shared embedding space. However, the inherent heterogeneity between audio and\ntext modalities presents a significant challenge. To address this, we propose\nModality Adversarial Learning (MAL), which reduces the domain gap in\nheterogeneous modality representations. Specifically, we train a modality\nclassifier adversarially to encourage both encoders to generate\nmodality-invariant embeddings. Additionally, we apply DML to achieve\nphoneme-level alignment between audio and text, and conduct extensive\ncomparisons across various DML objectives. Experiments on the Wall Street\nJournal (WSJ) and LibriPhrase datasets demonstrate the effectiveness of the\nproposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.16735v2",
    "published": "2025-05-22T14:49:46+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16734v1",
    "title": "Maximum Total Correlation Reinforcement Learning",
    "authors": [
      "Bang You",
      "Puze Liu",
      "Huaping Liu",
      "Jan Peters",
      "Oleg Arenz"
    ],
    "abstract": "Simplicity is a powerful inductive bias. In reinforcement learning,\nregularization is used for simpler policies, data augmentation for simpler\nrepresentations, and sparse reward functions for simpler objectives, all that,\nwith the underlying motivation to increase generalizability and robustness by\nfocusing on the essentials. Supplementary to these techniques, we investigate\nhow to promote simple behavior throughout the episode. To that end, we\nintroduce a modification of the reinforcement learning problem that\nadditionally maximizes the total correlation within the induced trajectories.\nWe propose a practical algorithm that optimizes all models, including policy\nand state representation, based on a lower-bound approximation. In simulated\nrobot environments, our method naturally generates policies that induce\nperiodic and compressible trajectories, and that exhibit superior robustness to\nnoise and changes in dynamics compared to baseline methods, while also\nimproving performance in the original tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16734v1",
    "published": "2025-05-22T14:48:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16733v1",
    "title": "Forward-only Diffusion Probabilistic Models",
    "authors": [
      "Ziwei Luo",
      "Fredrik K. Gustafsson",
      "Jens Sjölund",
      "Thomas B. Schön"
    ],
    "abstract": "This work presents a forward-only diffusion (FoD) approach for generative\nmodelling. In contrast to traditional diffusion models that rely on a coupled\nforward-backward diffusion scheme, FoD directly learns data generation through\na single forward diffusion process, yielding a simple yet efficient generative\nframework. The core of FoD is a state-dependent linear stochastic differential\nequation that involves a mean-reverting term in both the drift and diffusion\nfunctions. This mean-reversion property guarantees the convergence to clean\ndata, naturally simulating a stochastic interpolation between source and target\ndistributions. More importantly, FoD is analytically tractable and is trained\nusing a simple stochastic flow matching objective, enabling a few-step\nnon-Markov chain sampling during inference. The proposed FoD model, despite its\nsimplicity, achieves competitive performance on various image-conditioned\n(e.g., image restoration) and unconditional generation tasks, demonstrating its\neffectiveness in generative modelling. Our code is available at\nhttps://github.com/Algolzw/FoD.",
    "pdf_url": "http://arxiv.org/pdf/2505.16733v1",
    "published": "2025-05-22T14:47:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16732v1",
    "title": "Sequential Monte Carlo for Policy Optimization in Continuous POMDPs",
    "authors": [
      "Hany Abdulsamad",
      "Sahel Iqbal",
      "Simo Särkkä"
    ],
    "abstract": "Optimal decision-making under partial observability requires agents to\nbalance reducing uncertainty (exploration) against pursuing immediate\nobjectives (exploitation). In this paper, we introduce a novel policy\noptimization framework for continuous partially observable Markov decision\nprocesses (POMDPs) that explicitly addresses this challenge. Our method casts\npolicy learning as probabilistic inference in a non-Markovian Feynman--Kac\nmodel that inherently captures the value of information gathering by\nanticipating future observations, without requiring extrinsic exploration\nbonuses or handcrafted heuristics. To optimize policies under this model, we\ndevelop a nested sequential Monte Carlo~(SMC) algorithm that efficiently\nestimates a history-dependent policy gradient under samples from the optimal\ntrajectory distribution induced by the POMDP. We demonstrate the effectiveness\nof our algorithm across standard continuous POMDP benchmarks, where existing\nmethods struggle to act under uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2505.16732v1",
    "published": "2025-05-22T14:45:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17159v4",
    "title": "Simple and accurate complete elliptic integrals for the full range of modulus",
    "authors": [
      "Teepanis Chachiyo"
    ],
    "abstract": "The complete elliptic integral of the first and second kind, K(k) and E(k),\nappear in a multitude of physics and engineering applications. Because there is\nno known closed-form, the exact values have to be computed numerically. Here,\napproximations for the integrals are proposed based on their asymptotic\nbehaviors. An inverse of K is also presented. As a result, the proposed K(k)\nand E(k) reproduce the exact analytical forms both in the zero and asymptotic\nlimits, while in the mid-range of modulus maintain average error of 0.06% and\n0.01% respectively. The key finding is the ability to compute the integrals\nwith exceptional accuracy on both limits of elliptical conditions. An accuracy\nof 1 in 1,000 should be sufficient for practical or prototyping engineering and\narchitecture designs. The simplicity should facilitate discussions of advanced\nphysics topics in introductory physics classes, and enable broader\ncollaborations among researchers from other fields of expertise. For example,\nthe phase space of energy-conserving nonlinear pendulum using only elementary\nfunctions is discussed. The proposed inverse of K is shown to be Never Failing\nNewton Initialization and is an important step for the computation of the exact\ninverse. An algorithm based on Arithmetic-Geometric Mean for computing exact\nintegrals and their derivatives are also presented, which should be useful in a\nplatform that special functions are not accessible such as web-based and\nfirmware developments.",
    "pdf_url": "http://arxiv.org/pdf/2505.17159v4",
    "published": "2025-05-22T14:42:51+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16731v1",
    "title": "High angular resolution near-ultraviolet polarization imaging of the Herbig Ae/Be star LK-Hα-233",
    "authors": [
      "F. Marin"
    ],
    "abstract": "Herbig Ae/Be stars are young, pre-main-sequence stars that provide critical\ninsights into the processes of stellar formation, early stellar evolution and\nprotoplanetary disks.Two of the key features of such stars are their\ncircumstellar dusty disk and bipolar ionized outflows, which are key components\nfor understanding planet formation processes and energy/matter deposition in\nthe interstellar medium, respectively. In this context, imaging polarimetry is\nprobably the sharpest tool to characterize the various structures and dynamics\naround the central star, due to the sensitivity of polarization to the\nmorphology of the emitting, scattering and absorbing media. We take advantage\nof never published, near-ultraviolet polarimetric data of LK-H{\\alpha}-233\ntaken by the Faint Object Camera aboard the Hubble Space Telescope in 1991,\n1994 and 1995, which remained dormant in the archives despite their quality.\nUsing the most recent and robust reduction pipeline for this instrument, we\nobtained high spatial resolution (0.0287 x 0.0287 arcsecond2) maps of this\nobject at 4118 {\\AA}, together with polarimetric measurements. A dark lane,\nbisecting the approaching and receding polar outflows, suggests the presence of\na circumstellar disk or dust torus, obscuring the pre-main sequence star and\ncollimating the ejecta. Polarization reveals that the outflows have an X-shape\nstructure with a significant centro-symmetric pattern in polarization angle,\nindicating that the outflows are both hollow and scattering the emission from\nthe buried star. We constrain the half-opening angle of both the outflows and\ncircumstellar disk, determine the inclination of the system and estimate the\nobscured star's intrinsic flux. This study highlights the importance of\nhigh-resolution polarimetric observations in understanding the complex\nenvironment around Herbig Ae/Be stars and advocates for future similar\ninstruments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16731v1",
    "published": "2025-05-22T14:40:20+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA",
      "astro-ph.SR",
      "85-02,",
      "I.4.5"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16730v1",
    "title": "Detecting Fake News Belief via Skin and Blood Flow Signals",
    "authors": [
      "Gennie Nguyen",
      "Lei Wang",
      "Yangxueqing Jiang",
      "Tom Gedeon"
    ],
    "abstract": "Misinformation poses significant risks to public opinion, health, and\nsecurity. While most fake news detection methods rely on text analysis, little\nis known about how people physically respond to false information or repeated\nexposure to the same statements. This study investigates whether wearable\nsensors can detect belief in a statement or prior exposure to it. We conducted\na controlled experiment where participants evaluated statements while wearing\nan EmotiBit sensor that measured their skin conductance (electrodermal\nactivity, EDA) and peripheral blood flow (photoplethysmography, PPG). From 28\nparticipants, we collected a dataset of 672 trials, each labeled with whether\nthe participant believed the statement and whether they had seen it before.\nThis dataset introduces a new resource for studying physiological responses to\nmisinformation. Using machine learning models, including KNN, CNN, and\nLightGBM, we analyzed these physiological patterns. The best-performing model\nachieved 67.83\\% accuracy, with skin conductance outperforming PPG. These\nfindings demonstrate the potential of wearable sensors as a minimally intrusive\ntool for detecting belief and prior exposure, offering new directions for\nreal-time misinformation detection and adaptive, user-aware systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16730v1",
    "published": "2025-05-22T14:40:10+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16729v2",
    "title": "Equilibrium States, Zero Temperature Limits and Entropy Continuity for Almost-Additive Potentials",
    "authors": [
      "Jie Cao"
    ],
    "abstract": "This paper is devoted to study the equilibrium states for almost-additive\npotentials defined over topologically mixing countable Markov shifts (that is a\nnon-compact space) without the big images and preimages (BIP) property. Let\n$\\F$ be an almost-additive and summable potential with bounded variation\npotential. We prove that there exists an unique equilibrium state $\\mu_{t\\F}$\nfor each $t>1$ and there exists an accumulation point $\\mu_{\\infty}$ for the\nfamily $(\\mu_{t\\F})_{t>1}$ as $t\\to\\infty$. We also obtain that the Gurevich\npressure $P_{G}(t\\F)$ is $C^1$ on $(1,\\infty)$ and the Kolmogorov-Sinai entropy\n$h(\\mu_{t\\F})$ is continuous at $(1,\\infty)$. As two applications, we extend\ncompletely the results for the zero temperature limit [J. Stat. Phys. ,155\n(2014),pp. 23-46] and entropy continuity at infinity [J. Stat. Phys., 126\n(2007),pp. 315-324] beyond the finitely primitive case. We also extend the\nresult [Trans. Amer. Math. Soc., 370 (2018), pp. 8451-8465] for almost-additive\npotentials.",
    "pdf_url": "http://arxiv.org/pdf/2505.16729v2",
    "published": "2025-05-22T14:37:25+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16728v1",
    "title": "Probing Superfluidity with Quantum Vortex Necklaces",
    "authors": [
      "Andrea Richaud",
      "Pietro Massignan"
    ],
    "abstract": "We present a method for measuring the superfluid fraction of a Bose-Einstein\ncondensate (BEC) without relying on external perturbations or imposed optical\nlattices. Our approach leverages the intrinsic rotation of vortex necklaces in\none component of a binary superfluid mixture, where the vortex cores act as\neffective potential wells for the second component. The rotation of the vortex\nnecklace transfers angular momentum to the latter, enabling a direct\ndetermination of its effective moment of inertia. Comparing this value with its\nclassical counterpart allows us to extract the superfluid fraction, which we\nfind to be precisely bracketed by the Leggett bounds. By increasing\nintercomponent interactions, the second component undergoes a crossover from a\ndelocalized and fully superfluid state to an insulating state consisting of a\nregular array of localized density peaks. Furthermore, the dynamical\ninstability of vortex necklaces provides a natural framework for investigating\nsuperfluidity in dynamically evolving and disordered landscapes.",
    "pdf_url": "http://arxiv.org/pdf/2505.16728v1",
    "published": "2025-05-22T14:37:04+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.16727v1",
    "title": "Moduli spaces of sextic curves with simple singularities and their compactifications",
    "authors": [
      "Chenglong Yu",
      "Zhiwei Zheng",
      "Yiming Zhong"
    ],
    "abstract": "In this paper, we study moduli spaces of sextic curves with simple\nsingularities. Through period maps of K3 surfaces with ADE singularities, we\nprove such moduli spaces admit algebraic open embeddings into arithmetic\nquotients of type IV domains. For all cases, we prove the identifications of\nGIT compactifications and Looijenga compactifications. We also describe Picard\nlattices in an explicit way for many cases and apply this to study the relation\nof orbifold structures on two sides of the period map.",
    "pdf_url": "http://arxiv.org/pdf/2505.16727v1",
    "published": "2025-05-22T14:37:03+00:00",
    "categories": [
      "math.AG",
      "math.GT",
      "14D23, 14D07, 14J28"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16726v1",
    "title": "D-LIO: 6DoF Direct LiDAR-Inertial Odometry based on Simultaneous Truncated Distance Field Mapping",
    "authors": [
      "Lucia Coto-Elena",
      "J. E. Maese",
      "L. Merino",
      "F. Caballero"
    ],
    "abstract": "This paper presents a new approach for 6DoF Direct LiDAR-Inertial Odometry\n(D-LIO) based on the simultaneous mapping of truncated distance fields on CPU.\nSuch continuous representation (in the vicinity of the points) enables working\nwith raw 3D LiDAR data online, avoiding the need of LiDAR feature selection and\ntracking, simplifying the odometry pipeline and easily generalizing to many\nscenarios. The method is based on the proposed Fast Truncated Distance Field\n(Fast-TDF) method as a convenient tool to represent the environment. Such\nrepresentation enables i) solving the LiDAR point-cloud registration as a\nnonlinear optimization process without the need of selecting/tracking LiDAR\nfeatures in the input data, ii) simultaneously producing an accurate truncated\ndistance field map of the environment, and iii) updating such map at constant\ntime independently of its size. The approach is tested using open datasets,\naerial and ground. It is also benchmarked against other state-of-the-art\nodometry approaches, demonstrating the same or better level of accuracy with\nthe added value of an online-generated TDF representation of the environment,\nthat can be used for other robotics tasks as planning or collision avoidance.\nThe source code is publicly available at\nhttps://anonymous.4open.science/r/D-LIO",
    "pdf_url": "http://arxiv.org/pdf/2505.16726v1",
    "published": "2025-05-22T14:34:32+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16725v1",
    "title": "Masked Conditioning for Deep Generative Models",
    "authors": [
      "Phillip Mueller",
      "Jannik Wiese",
      "Sebastian Mueller",
      "Lars Mikelsons"
    ],
    "abstract": "Datasets in engineering domains are often small, sparsely labeled, and\ncontain numerical as well as categorical conditions. Additionally.\ncomputational resources are typically limited in practical applications which\nhinders the adoption of generative models for engineering tasks. We introduce a\nnovel masked-conditioning approach, that enables generative models to work with\nsparse, mixed-type data. We mask conditions during training to simulate sparse\nconditions at inference time. For this purpose, we explore the use of various\nsparsity schedules that show different strengths and weaknesses. In addition,\nwe introduce a flexible embedding that deals with categorical as well as\nnumerical conditions. We integrate our method into an efficient variational\nautoencoder as well as a latent diffusion model and demonstrate the\napplicability of our approach on two engineering-related datasets of 2D point\nclouds and images. Finally, we show that small models trained on limited data\ncan be coupled with large pretrained foundation models to improve generation\nquality while retaining the controllability induced by our conditioning scheme.",
    "pdf_url": "http://arxiv.org/pdf/2505.16725v1",
    "published": "2025-05-22T14:33:03+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16724v1",
    "title": "Advancing Brainwave Modeling with a Codebook-Based Foundation Model",
    "authors": [
      "Konstantinos Barmpas",
      "Na Lee",
      "Yannis Panagakis",
      "Dimitrios A. Adamos",
      "Nikolaos Laskaris",
      "Stefanos Zafeiriou"
    ],
    "abstract": "Recent advances in large-scale pre-trained Electroencephalogram (EEG) models\nhave shown great promise, driving progress in Brain-Computer Interfaces (BCIs)\nand healthcare applications. However, despite their success, many existing\npre-trained models have struggled to fully capture the rich information content\nof neural oscillations, a limitation that fundamentally constrains their\nperformance and generalizability across diverse BCI tasks. This limitation is\nfrequently rooted in suboptimal architectural design choices which constrain\ntheir representational capacity. In this work, we introduce LaBraM++, an\nenhanced Large Brainwave Foundation Model (LBM) that incorporates principled\nimprovements grounded in robust signal processing foundations. LaBraM++\ndemonstrates substantial gains across a variety of tasks, consistently\noutperforming its originally-based architecture and achieving competitive\nresults when compared to other open-source LBMs. Its superior performance and\ntraining efficiency highlight its potential as a strong foundation for future\nadvancements in LBMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16724v1",
    "published": "2025-05-22T14:32:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16723v1",
    "title": "Robust LLM Fingerprinting via Domain-Specific Watermarks",
    "authors": [
      "Thibaud Gloaguen",
      "Robin Staab",
      "Nikola Jovanović",
      "Martin Vechev"
    ],
    "abstract": "As open-source language models (OSMs) grow more capable and are widely shared\nand finetuned, ensuring model provenance, i.e., identifying the origin of a\ngiven model instance, has become an increasingly important issue. At the same\ntime, existing backdoor-based model fingerprinting techniques often fall short\nof achieving key requirements of real-world model ownership detection. In this\nwork, we build on the observation that while current open-source model\nwatermarks fail to achieve reliable content traceability, they can be\neffectively adapted to address the challenge of model provenance. To this end,\nwe introduce the concept of domain-specific watermarking for model\nfingerprinting. Rather than watermarking all generated content, we train the\nmodel to embed watermarks only within specified subdomains (e.g., particular\nlanguages or topics). This targeted approach ensures detection reliability,\nwhile improving watermark durability and quality under a range of real-world\ndeployment settings. Our evaluations show that domain-specific watermarking\nenables model fingerprinting with strong statistical guarantees, controllable\nfalse positive rates, high detection power, and preserved generation quality.\nMoreover, we find that our fingerprints are inherently stealthy and naturally\nrobust to real-world variability across deployment scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16723v1",
    "published": "2025-05-22T14:32:23+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16722v2",
    "title": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification",
    "authors": [
      "Himanshu Beniwal",
      "Youngwoo Kim",
      "Maarten Sap",
      "Soham Dan",
      "Thomas Hartvigsen"
    ],
    "abstract": "As large language models (LLMs) become increasingly prevalent in global\napplications, ensuring that they are toxicity-free across diverse linguistic\ncontexts remains a critical challenge. We explore \"Cross-lingual\nDetoxification\", a cross-lingual paradigm that mitigates toxicity, enabling\ndetoxification capabilities to transfer between high and low-resource languages\nacross different script families. We analyze cross-lingual detoxification's\neffectiveness through 392 extensive settings to evaluate toxicity reduction in\ncross-distribution settings with limited data and investigate how mitigation\nimpacts model performance on non-toxic tasks, revealing trade-offs between\nsafety and knowledge preservation. Our code and dataset are publicly available\nat https://github.com/himanshubeniwal/Breaking-mBad.",
    "pdf_url": "http://arxiv.org/pdf/2505.16722v2",
    "published": "2025-05-22T14:30:14+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16721v1",
    "title": "Optimal control of mean-field limit of multiagent systems with and without common noise",
    "authors": [
      "Giuseppe La Scala"
    ],
    "abstract": "We consider a generic, suitable class of optimal control problems under a\nconstraint given by a finite-dimensional SDE-ODE system, describing a system of\ntwo interacting species of particles: the herd, described by SDEs, and the\nherders, described by ODEs with the addition of a control function.\n  In particular, we firstly show that for a low number of herders and for the\nlimit of large number of herd individuals, the SDE-ODE system can be\napproximated by an infinite-dimensional system given by a McKean-Vlasov single\nSDE coupled with ODEs. Then, thanks to this we show the $\\Gamma-$convergence of\nthe optimal control problem for the finite-dimensional system to a certain\noptimal control problem for the mean-field system.\n  Differently from Ascione-Castorina-Solombrino [9] (SIAM J. Math. Anal., Vol.\n55, No. 6, pp. 6965-6990 (2023)), we do not consider an additive noise for the\nherd, but a more general class, given by idiosyncratic noises (due to a single\nherd individual) together with common noise (due to how the environment affects\nthe whole herd), and they are independent one from another. As well as this, we\nconsider a more general class of control functions in the ODEs for herders,\nwhere the control is applied not only on the herd dynamics, but also on the\nherd one.",
    "pdf_url": "http://arxiv.org/pdf/2505.16721v1",
    "published": "2025-05-22T14:30:05+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16719v1",
    "title": "$p$-Bifree biset functors",
    "authors": [
      "Olcay Coşkun",
      "Deniz Yılmaz"
    ],
    "abstract": "We introduce and study the category of $p$-bifree biset functors for a fixed\nprime $p$, defined via bisets whose left and right stabilizers are $p'$-groups.\nThis category naturally lies between the classical biset functors and the\ndiagonal $p$-permutation functors, serving as a bridge between them. Every\nbiset functor and every diagonal $p$-permutation functor restricts to a\n$p$-bifree biset functor.\n  We classify the simple $p$-bifree biset functors over a field $K$ of\ncharacteristic zero, showing that they are parametrized by pairs $(G,V)$, where\n$G$ is a finite group and $V$ is a simple $K\\mathrm{Out}(G)$-module. As key\nexamples, we compute the composition factors of several\nrepresentation-theoretic functors in the $p$-bifree setting, including the\nBurnside ring functor, the $p$-bifree Burnside functor, the Brauer character\nring functor, and the ordinary character ring functor. We further investigate\nclassical simple biset functors, $S_{C_p \\times C_p, \\mathbb{C}}$ and $S_{C_q\n\\times C_q, \\mathbb{C}}$ for a prime $q\\neq p$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16719v1",
    "published": "2025-05-22T14:27:09+00:00",
    "categories": [
      "math.RT",
      "18A25, 18B99, 19A22, 20J15"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16720v1",
    "title": "Streaming Diameter of High-Dimensional Points",
    "authors": [
      "Magnús M. Halldórsson",
      "Nicolaos Matsakis",
      "Pavel Veselý"
    ],
    "abstract": "We improve the space bound for streaming approximation of Diameter but also\nof Farthest Neighbor queries, Minimum Enclosing Ball and its Coreset, in\nhigh-dimensional Euclidean spaces. In particular, our deterministic streaming\nalgorithms store $\\mathcal{O}(\\varepsilon^{-2}\\log(\\frac{1}{\\varepsilon}))$\npoints. This improves by a factor of $\\varepsilon^{-1}$ the previous space\nbound of Agarwal and Sharathkumar (SODA 2010), while offering a simpler and\nmore complete argument. We also show that storing $\\Omega(\\varepsilon^{-1})$\npoints is necessary for a $(\\sqrt{2}+\\varepsilon)$-approximation of Farthest\nPair or Farthest Neighbor queries.",
    "pdf_url": "http://arxiv.org/pdf/2505.16720v1",
    "published": "2025-05-22T14:27:09+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16718v1",
    "title": "$d$-orthogonal polynomials, Fuss-Catalan matrices and lattice paths",
    "authors": [
      "Paul Barry"
    ],
    "abstract": "In this note, we show how to define certain Riordan arrays, that we call the\nFuss-Catalan-Riordan arrays, by means of a special family of $d$-orthogonal\npolynomials. We relate the Fuss-Catalan Riordan arrays to the Fuss Catalan\nnumbers, and to certain lattice paths. We emphasise the role of the production\nmatrices of the Riordan arrays that we encounter in our study.",
    "pdf_url": "http://arxiv.org/pdf/2505.16718v1",
    "published": "2025-05-22T14:25:39+00:00",
    "categories": [
      "math.CO",
      "Primary 05A15, Secondary 15B36, 11B37, 11B83, 11C20, 42C05, 11Y55\n  11C20, 42C05, 11Y55"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16717v1",
    "title": "On the angular anisotropy of the distribution function of radiating particles in relativistic jets",
    "authors": [
      "T. I. Khalilov",
      "V. S. Beskin",
      "V. I. Pariev"
    ],
    "abstract": "The observed power-law spectra of relativistic jets from active galactic\nnuclei clearly indicate a synchrotron mechanism of radiation by particles that\nsimilarly possess a power-law energy spectrum. However, the issue of their\nangular anisotropy has not been given sufficient attention until recently,\nalthough the example of the solar wind (where a strongly magnetized wind is\nrealized in a similar way) shows the importance of taking this circumstance\ninto account. In this paper, we study the evolution of an initially isotropic\npower-law spectrum of radiating particles as they propagate along expanding\nrelativistic jets. It is shown that for relativistic flows in which the\nelectric field plays a crucial role, the preservation of the first adiabatic\ninvariant does not lead to a decrease in the pitch angles of radiating\nparticles as they enter the region of weak magnetic fields. This is due to the\ndrift nature of the particle motion.",
    "pdf_url": "http://arxiv.org/pdf/2505.16717v1",
    "published": "2025-05-22T14:25:17+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16716v1",
    "title": "The Computational Complexity of Counting Linear Regions in ReLU Neural Networks",
    "authors": [
      "Moritz Stargalla",
      "Christoph Hertrich",
      "Daniel Reichman"
    ],
    "abstract": "An established measure of the expressive power of a given ReLU neural network\nis the number of linear regions into which it partitions the input space. There\nexist many different, non-equivalent definitions of what a linear region\nactually is. We systematically assess which papers use which definitions and\ndiscuss how they relate to each other. We then analyze the computational\ncomplexity of counting the number of such regions for the various definitions.\nGenerally, this turns out to be an intractable problem. We prove NP- and\n#P-hardness results already for networks with one hidden layer and strong\nhardness of approximation results for two or more hidden layers. Finally, on\nthe algorithmic side, we demonstrate that counting linear regions can at least\nbe achieved in polynomial space for some common definitions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16716v1",
    "published": "2025-05-22T14:25:12+00:00",
    "categories": [
      "cs.CC",
      "cs.DM",
      "cs.LG",
      "cs.NE",
      "math.CO"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16715v1",
    "title": "Simultaneous Estimation of Nonlinear Functionals of a Quantum State",
    "authors": [
      "Kean Chen",
      "Qisheng Wang",
      "Zhan Yu",
      "Zhicheng Zhang"
    ],
    "abstract": "We consider a fundamental task in quantum information theory, estimating the\nvalues of $\\operatorname{tr}(O\\rho)$, $\\operatorname{tr}(O\\rho^2)$, ...,\n$\\operatorname{tr}(O\\rho^k)$ for an observable $O$ and a quantum state $\\rho$.\nWe show that $\\widetilde\\Theta(k)$ samples of $\\rho$ are sufficient and\nnecessary to simultaneously estimate all the $k$ values. This means that\nestimating all the $k$ values is almost as easy as estimating only one of them,\n$\\operatorname{tr}(O\\rho^k)$. As an application, our approach advances the\nsample complexity of entanglement spectroscopy and the virtual cooling for\nquantum many-body systems. Moreover, we extend our approach to estimating\ngeneral functionals by polynomial approximation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16715v1",
    "published": "2025-05-22T14:23:48+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16714v1",
    "title": "Experimental robustness benchmark of quantum neural network on a superconducting quantum processor",
    "authors": [
      "Hai-Feng Zhang",
      "Zhao-Yun Chen",
      "Peng Wang",
      "Liang-Liang Guo",
      "Tian-Le Wang",
      "Xiao-Yan Yang",
      "Ren-Ze Zhao",
      "Ze-An Zhao",
      "Sheng Zhang",
      "Lei Du",
      "Hao-Ran Tao",
      "Zhi-Long Jia",
      "Wei-Cheng Kong",
      "Huan-Yu Liu",
      "Athanasios V. Vasilakos",
      "Yang Yang",
      "Yu-Chun Wu",
      "Ji Guan",
      "Peng Duan",
      "Guo-Ping Guo"
    ],
    "abstract": "Quantum machine learning (QML) models, like their classical counterparts, are\nvulnerable to adversarial attacks, hindering their secure deployment. Here, we\nreport the first systematic experimental robustness benchmark for 20-qubit\nquantum neural network (QNN) classifiers executed on a superconducting\nprocessor. Our benchmarking framework features an efficient adversarial attack\nalgorithm designed for QNNs, enabling quantitative characterization of\nadversarial robustness and robustness bounds. From our analysis, we verify that\nadversarial training reduces sensitivity to targeted perturbations by\nregularizing input gradients, significantly enhancing QNN's robustness.\nAdditionally, our analysis reveals that QNNs exhibit superior adversarial\nrobustness compared to classical neural networks, an advantage attributed to\ninherent quantum noise. Furthermore, the empirical upper bound extracted from\nour attack experiments shows a minimal deviation ($3 \\times 10^{-3}$) from the\ntheoretical lower bound, providing strong experimental confirmation of the\nattack's effectiveness and the tightness of fidelity-based robustness bounds.\nThis work establishes a critical experimental framework for assessing and\nimproving quantum adversarial robustness, paving the way for secure and\nreliable QML applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16714v1",
    "published": "2025-05-22T14:18:14+00:00",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16713v2",
    "title": "Sharp concentration of uniform generalization errors in binary linear classification",
    "authors": [
      "Shogo Nakakita"
    ],
    "abstract": "We examine the concentration of uniform generalization errors around their\nexpectation in binary linear classification problems via an isoperimetric\nargument. In particular, we establish Poincar\\'{e} and log-Sobolev inequalities\nfor the joint distribution of the output labels and the label-weighted input\nvectors, which we apply to derive concentration bounds. The derived\nconcentration bounds are sharp up to moderate multiplicative constants by those\nunder well-balanced labels. In asymptotic analysis, we also show that almost\nsure convergence of uniform generalization errors to their expectation occurs\nin very broad settings, such as proportionally high-dimensional regimes. Using\nthis convergence, we establish uniform laws of large numbers under\ndimension-free conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16713v2",
    "published": "2025-05-22T14:14:50+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16712v1",
    "title": "From precursor to afterglow: The complex evolution of GRB 210312B",
    "authors": [
      "M. Jelínek",
      "S. A. Grebenev",
      "P. Yu. Minaev",
      "C. C. Thöne",
      "A. de Ugarte Postigo",
      "A. Rossi",
      "D. Paris",
      "D. A. Kann",
      "J. F. Agüí Fernández",
      "J. Štrobl",
      "A. S. Pozanenko",
      "I. V. Chelovekov",
      "F. Novotný",
      "S. Karpov",
      "M. Topinka",
      "M. Blažek",
      "S. Vítek",
      "R. Hudec"
    ],
    "abstract": "Long gamma-ray bursts (GRBs) are characterized by a brief gamma-ray flash\nfollowed by a longer-lasting multiwavelength afterglow. The basic mechanism is\nlargely understood, and the early afterglow evolution often shows complex\nfeatures that provide crucial insights into the transition between prompt and\nafterglow phases. We present a detailed analysis of GRB 210312B, detected by\nINTEGRAL, which exhibits both a precursor and a complex optical afterglow\nevolution. Through careful modeling using Markov chain Monte Carlo methods, we\ndisentangled the contributions of an early optical flare and forward shock\nemission. Our analysis reveals a gamma-ray precursor 17 s before the main pulse\nwith a significantly softer spectrum (hardness ratio 0.37 +/- 0.12 versus 1.9\n+/- 0.4). The optical afterglow shows an early peak at 76.0^{+4.4}{-5.1} s\ncharacterized by a steep rise ({\\alpha}{flare,1} = -4.1^{+1.6}{-2.3}) and decay\n({\\alpha}{flare,2} = 4.0^{+2.1}{-1.5}), followed by forward shock emission with\na broad hydrodynamic peak at around 150 s. In the subsequent plateau phase, the\nafterglow initially has a complex structure before settling into a final power\nlaw decay consistent with an electron distribution index p =\n2.36^{+0.18}{-0.15}. The negligible host extinction (A_{V,host} =\n-0.073^{+0.100}_{-0.078}) suggests we are observing the intrinsic afterglow\nspectrum. The host system consists of two luminous (M_B ~ -21.7) components\nseparated by 11.5 kpc at z = 1.069, which are possibly an interacting galaxy\npair. GRB 210312B provides a rare opportunity to study the prompt-to-afterglow\ntransition in detail. The consistency of the forward shock component with\nstandard afterglow theory supports our physical interpretation despite the lack\nof X-ray coverage.",
    "pdf_url": "http://arxiv.org/pdf/2505.16712v1",
    "published": "2025-05-22T14:13:54+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16711v1",
    "title": "Partial wave analysis of reactions with four meson final states",
    "authors": [
      "M. A. Matveev",
      "A. T. Sitnikov",
      "A. V. Sarantsev"
    ],
    "abstract": "We construct a formalism which describes the resonances decaying into four\npseudoscalar meson final states. This method is fully covariant and can be\ndirectly applied for the partial-wave analysis of high statistical data. Two\ntopologies of the process are considered: two intermediate resonances each\ndecaying into two final mesons and cascade decay via three meson intermediate\nstates. In particular, we consider the production of such states in the central\ncollision reactions and in radiative $J/\\Psi$ decay.",
    "pdf_url": "http://arxiv.org/pdf/2505.16711v1",
    "published": "2025-05-22T14:12:06+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16710v1",
    "title": "Training Long-Context LLMs Efficiently via Chunk-wise Optimization",
    "authors": [
      "Wenhao Li",
      "Yuxin Zhang",
      "Gen Luo",
      "Daohai Yu",
      "Rongrong Ji"
    ],
    "abstract": "While long-context large language models (LLMs) exhibit remarkable document\nprocessing capabilities, their prohibitively high training costs often hinder\ncustomized applications. To mitigate this issue, we propose \\textit{Sequential\nChunk-wise Optimization} (SeCO), a memory-efficient training paradigm that\npartitions lengthy inputs into manageable chunks. Each chunk independently\nconstructs its computational graph and performs localized backpropagation,\nensuring that only one chunk's forward activations are stored in memory.\nBuilding on SeCO, we further introduce \\textit{Sparse Chunk-wise Optimization}\n(SpaCO), which reduces computational overhead by selectively propagating\ngradients to specific chunks and incorporates a carefully designed compensation\nfactor to ensure unbiased gradient estimation. SpaCO decouples the\ncomputational cost of backpropagation from the context length, enabling\ntraining time to gradually converge to inference time as sequences become\nlonger. Implemented as lightweight training wrappers, both SeCO and SpaCO offer\nsubstantial practical benefits. For example, when fine-tuning an 8B model with\nLoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to\n16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up\nto 3x faster than SeCO under the same experimental setup. These innovations\nprovide new insights into optimizing long-context models, making them more\naccessible for practical applications. We have open-sourced the code at\n\\href{https://github.com/wenhaoli-xmu/seco}{here}.",
    "pdf_url": "http://arxiv.org/pdf/2505.16710v1",
    "published": "2025-05-22T14:11:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16709v1",
    "title": "SEDD-PCC: A Single Encoder-Dual Decoder Framework For End-To-End Learned Point Cloud Compression",
    "authors": [
      "Kai Hsiang Hsieh",
      "Monyneath Yim",
      "Jui Chiu Chiang"
    ],
    "abstract": "To encode point clouds containing both geometry and attributes, most\nlearning-based compression schemes treat geometry and attribute coding\nseparately, employing distinct encoders and decoders. This not only increases\ncomputational complexity but also fails to fully exploit shared features\nbetween geometry and attributes. To address this limitation, we propose\nSEDD-PCC, an end-to-end learning-based framework for lossy point cloud\ncompression that jointly compresses geometry and attributes. SEDD-PCC employs a\nsingle encoder to extract shared geometric and attribute features into a\nunified latent space, followed by dual specialized decoders that sequentially\nreconstruct geometry and attributes. Additionally, we incorporate knowledge\ndistillation to enhance feature representation learning from a teacher model,\nfurther improving coding efficiency. With its simple yet effective design,\nSEDD-PCC provides an efficient and practical solution for point cloud\ncompression. Comparative evaluations against both rule-based and learning-based\nmethods demonstrate its competitive performance, highlighting SEDD-PCC as a\npromising AI-driven compression approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.16709v1",
    "published": "2025-05-22T14:11:24+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16708v1",
    "title": "A Novel Generative Model with Causality Constraint for Mitigating Biases in Recommender Systems",
    "authors": [
      "Jianfeng Deng",
      "Qingfeng Chen",
      "Debo Cheng",
      "Jiuyong Li",
      "Lin Liu",
      "Shichao Zhang"
    ],
    "abstract": "Accurately predicting counterfactual user feedback is essential for building\neffective recommender systems. However, latent confounding bias can obscure the\ntrue causal relationship between user feedback and item exposure, ultimately\ndegrading recommendation performance. Existing causal debiasing approaches\noften rely on strong assumptions-such as the availability of instrumental\nvariables (IVs) or strong correlations between latent confounders and proxy\nvariables-that are rarely satisfied in real-world scenarios. To address these\nlimitations, we propose a novel generative framework called Latent Causality\nConstraints for Debiasing representation learning in Recommender Systems\n(LCDR). Specifically, LCDR leverages an identifiable Variational Autoencoder\n(iVAE) as a causal constraint to align the latent representations learned by a\nstandard Variational Autoencoder (VAE) through a unified loss function. This\nalignment allows the model to leverage even weak or noisy proxy variables to\nrecover latent confounders effectively. The resulting representations are then\nused to improve recommendation performance. Extensive experiments on three\nreal-world datasets demonstrate that LCDR consistently outperforms existing\nmethods in both mitigating bias and improving recommendation accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16708v1",
    "published": "2025-05-22T14:09:39+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16707v1",
    "title": "KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models",
    "authors": [
      "Yongliang Wu",
      "Zonghui Li",
      "Xinting Hu",
      "Xinyu Ye",
      "Xianfang Zeng",
      "Gang Yu",
      "Wenbo Zhu",
      "Bernt Schiele",
      "Ming-Hsuan Yang",
      "Xu Yang"
    ],
    "abstract": "Recent advances in multi-modal generative models have enabled significant\nprogress in instruction-based image editing. However, while these models\nproduce visually plausible outputs, their capacity for knowledge-based\nreasoning editing tasks remains under-explored. In this paper, we introduce\nKRIS-Bench (Knowledge-based Reasoning in Image-editing Systems Benchmark), a\ndiagnostic benchmark designed to assess models through a cognitively informed\nlens. Drawing from educational theory, KRIS-Bench categorizes editing tasks\nacross three foundational knowledge types: Factual, Conceptual, and Procedural.\nBased on this taxonomy, we design 22 representative tasks spanning 7 reasoning\ndimensions and release 1,267 high-quality annotated editing instances. To\nsupport fine-grained evaluation, we propose a comprehensive protocol that\nincorporates a novel Knowledge Plausibility metric, enhanced by knowledge hints\nand calibrated through human studies. Empirical results on 10 state-of-the-art\nmodels reveal significant gaps in reasoning performance, highlighting the need\nfor knowledge-centric benchmarks to advance the development of intelligent\nimage editing systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16707v1",
    "published": "2025-05-22T14:08:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16706v2",
    "title": "The Graded Classification Conjecture holds for graphs with disjoint cycles",
    "authors": [
      "Lia Vas"
    ],
    "abstract": "The Graded Classification Conjecture (GCC) states that the pointed\n$K_0^{\\operatorname{gr}}$-group is a complete invariant of the Leavitt path\nalgebras of finite graphs when these algebras are considered with their natural\ngrading by $\\mathbb Z.$ The conjecture has previously been shown to hold in\nsome special cases. The main result of the paper shows that the GCC holds for a\nsignificantly more general class of graphs included in the class of graphs with\ndisjoint cycles. In particular, our result holds for finite graphs with\ndisjoint cycles. We show the main result also for graph $C^*$-algebras. As a\nconsequence, the graded version of the Isomorphism Conjecture holds for the\nclass of graphs we consider.\n  Besides showing the conjecture for the class of graphs we consider, we\nrealize the Grothendieck $\\mathbb Z$-group isomorphism by a specific graded\n$*$-isomorphism. In particular, we introduce a series of graph operations which\npreserve the graded $*$-isomorphism class of their algebras. After performing\nthese operations on a graph, we obtain well-behaved ``representative'' graphs,\nwhich we call canonical forms. We define an equivalence $\\approx$ on graphs\nsuch that $E\\approx F$ holds when there are isomorphic canonical forms of $E$\nand $F$ and we show that the condition $E\\approx F$ is equivalent to the\nexistence of an isomorphism $f$ of the Grothendieck $\\mathbb Z$-groups of the\nalgebras of $E$ and $F$ in the appropriate category. As $E\\approx F$ can be\nrealized by a finite series of specific graph operations, any such isomorphism\n$f$ can be realized by an explicit graded $*$-algebra isomorphism. Thus, we\ndescribe the graded ($*$-)isomorphism classes of the algebras of graphs we\nconsider. Besides the ties to symbolic dynamics and Williams' Problem, such a\ndescription is relevant for the active program of classification of graph\n$C^*$-algebras.",
    "pdf_url": "http://arxiv.org/pdf/2505.16706v2",
    "published": "2025-05-22T14:07:50+00:00",
    "categories": [
      "math.RA",
      "math.DS",
      "math.OA",
      "16S88, 46L35, 37A55, 19A49, 16E20"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16705v1",
    "title": "An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations",
    "authors": [
      "Seonghwan Park",
      "Jueun Mun",
      "Donghyun Oh",
      "Namhoon Lee"
    ],
    "abstract": "Concept bottleneck models (CBMs) ensure interpretability by decomposing\npredictions into human interpretable concepts. Yet the annotations used for\ntraining CBMs that enable this transparency are often noisy, and the impact of\nsuch corruption is not well understood. In this study, we present the first\nsystematic study of noise in CBMs and show that even moderate corruption\nsimultaneously impairs prediction performance, interpretability, and the\nintervention effectiveness. Our analysis identifies a susceptible subset of\nconcepts whose accuracy declines far more than the average gap between noisy\nand clean supervision and whose corruption accounts for most performance loss.\nTo mitigate this vulnerability we propose a two-stage framework. During\ntraining, sharpness-aware minimization stabilizes the learning of\nnoise-sensitive concepts. During inference, where clean labels are unavailable,\nwe rank concepts by predictive entropy and correct only the most uncertain\nones, using uncertainty as a proxy for susceptibility. Theoretical analysis and\nextensive ablations elucidate why sharpness-aware training confers robustness\nand why uncertainty reliably identifies susceptible concepts, providing a\nprincipled basis that preserves both interpretability and resilience in the\npresence of noise.",
    "pdf_url": "http://arxiv.org/pdf/2505.16705v1",
    "published": "2025-05-22T14:06:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16704v1",
    "title": "Finite temperature Casimir effect for a spinor field in cosmic dispiration spacetime",
    "authors": [
      "Joás Venâncio",
      "Herondy Mota",
      "Azadeh Mohammadi"
    ],
    "abstract": "This study explores the finite temperature Casimir effect for a massive\nspinor field in cosmic dispiration spacetime, formed by the combination of a\ncosmic string and a screw dislocation using the generalized zeta function\nregularization method. First, we examine the cosmic string spacetime with a\nquasi-antiperiodic boundary condition, where the Casimir energy and its\ncorrections depend on two nonzero heat kernel coefficients, one associated with\nthe Euclidean divergence and the other with the nontrivial topology, both\nvanishing when renormalized. Interestingly, for specific choice of parameters\nthe quasi-antiperiodicity effect can entirely cancel out the topological\ncontribution, leaving only the Euclidean divergence. We then extend this\nanalysis to cosmic dispiration spacetime. This configuration alters the\nspacetime topology, modifying the structure of the heat kernel coefficient\nrelated to the new nontrivial topology. In this case, the renormalized Casimir\nenergy density can take positive or negative values and decreases exponentially\nas the field mass increases. Additionally, we examine the asymptotic behavior\nof the renormalized temperature correction term in the massless regime, showing\nthat the spinor vacuum free energy vanishes at very high temperatures. At very\nlow temperatures, it is dominated by the zero-temperature Casimir energy\ndensity.",
    "pdf_url": "http://arxiv.org/pdf/2505.16704v1",
    "published": "2025-05-22T14:05:21+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16703v1",
    "title": "Locate-then-Merge: Neuron-Level Parameter Fusion for Mitigating Catastrophic Forgetting in Multimodal LLMs",
    "authors": [
      "Zeping Yu",
      "Sophia Ananiadou"
    ],
    "abstract": "Although multimodal large language models (MLLMs) have achieved impressive\nperformance, the multimodal instruction tuning stage often causes catastrophic\nforgetting of the base LLM's language ability, even in strong models like\nLlama3. To address this, we propose Locate-then-Merge, a training-free\nparameter fusion framework that first locates important parameters and then\nselectively merges them. We further introduce Neuron-Fusion, a neuron-level\nstrategy that preserves the influence of neurons with large parameter\nshifts--neurons likely responsible for newly acquired visual\ncapabilities--while attenuating the influence of neurons with smaller changes\nthat likely encode general-purpose language skills. This design enables better\nretention of visual adaptation while mitigating language degradation.\nExperiments on 13 benchmarks across both language and visual tasks show that\nNeuron-Fusion consistently outperforms existing model merging methods. Further\nanalysis reveals that our method effectively reduces context hallucination in\ngeneration.",
    "pdf_url": "http://arxiv.org/pdf/2505.16703v1",
    "published": "2025-05-22T14:04:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16702v1",
    "title": "Truth and Trust: Fake News Detection via Biosignals",
    "authors": [
      "Gennie Nguyen",
      "Lei Wang",
      "Yangxueqing Jiang",
      "Tom Gedeon"
    ],
    "abstract": "Understanding how individuals physiologically respond to false information is\ncrucial for advancing misinformation detection systems. This study explores the\npotential of using physiological signals, specifically electrodermal activity\n(EDA) and photoplethysmography (PPG), to classify both the veracity of\ninformation and its interaction with user belief. In a controlled laboratory\nexperiment, we collected EDA and PPG signals while participants evaluated the\ntruthfulness of climate-related claims. Each trial was labeled based on the\nobjective truth of the claim and the participant's belief, enabling two\nclassification tasks: binary veracity detection and a novel four-class joint\nbelief-veracity classification. We extracted handcrafted features from the raw\nsignals and trained several machine learning models to benchmark the dataset.\nOur results show that EDA outperforms PPG, indicating its greater sensitivity\nto physiological responses related to truth perception. However, performance\nsignificantly drops in the joint belief-veracity classification task,\nhighlighting the complexity of modeling the interaction between belief and\ntruth. These findings suggest that while physiological signals can reflect\nbasic truth perception, accurately modeling the intricate relationships between\nbelief and veracity remains a significant challenge. This study emphasizes the\nimportance of multimodal approaches that incorporate psychological,\nphysiological, and cognitive factors to improve fake news detection systems.\nOur work provides a foundation for future research aimed at enhancing\nmisinformation detection via addressing the complexities of human belief and\ntruth processing.",
    "pdf_url": "http://arxiv.org/pdf/2505.16702v1",
    "published": "2025-05-22T14:03:20+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16701v1",
    "title": "Open interacting particle systems and Ising measures",
    "authors": [
      "Ngo P. N. Ngoc",
      "Gunter M. Schütz"
    ],
    "abstract": "We first survey some open questions concerning stochastic interacting\nparticle systems with open boundaries. Then, an asymmetric exclusion process\nwith open boundaries that generalizes the lattice gas model of Katz, Lebowitz,\nand Spohn is introduced and invariance of the one-dimensional Ising measure is\nproved. The stationary current is computed in explicit form and is shown to\nexhibit current reversal at some density. Based on the extremal-current\nprinciple for one-dimensional driven diffusive systems with one conservation\nlaw, the phase diagram for boundary-induced phase transitions is conjectured\nfor this case. There are two extremal-current phases, unlike in the open ASEP\n(one extremal-current phase) or in the conventional KLS model (one or three\nextremal-current phases).",
    "pdf_url": "http://arxiv.org/pdf/2505.16701v1",
    "published": "2025-05-22T14:02:47+00:00",
    "categories": [
      "math.PR",
      "cond-mat.stat-mech"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16700v1",
    "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models",
    "authors": [
      "Xuanqi Gao",
      "Siyi Xie",
      "Juan Zhai",
      "Shqing Ma",
      "Chao Shen"
    ],
    "abstract": "As Large Language Models (LLMs) evolve from passive text generators to active\nreasoning agents capable of tool interaction, the Model Context Protocol (MCP)\nhas emerged as a standardized framework for dynamic tool discovery and\norchestration. Despite widespread industry adoption, existing evaluation\nmethodologies fail to adequately assess tool utilization capabilities within\nthis new paradigm. This paper introduces MCP-RADAR, the first comprehensive\nbenchmark specifically designed to evaluate LLM performance in the MCP\nframework through a novel five-dimensional approach measuring: answer accuracy,\ntool selection efficiency, computational resource efficiency, parameter\nconstruction accuracy, and execution speed. Unlike conventional benchmarks that\nrely on subjective human evaluations or binary success metrics, MCP-RADAR\nemploys objective, quantifiable measurements across multiple task domains\nincluding software engineering, mathematical reasoning, and general\nproblem-solving. Our evaluations of leading commercial and open-source LLMs\nreveal distinctive capability profiles with significant trade-offs between\naccuracy, efficiency, and speed, challenging traditional single-metric\nperformance rankings. Besides, we provide valuable guidance for developers to\noptimize their tools for maximum model compatibility and effectiveness. While\nfocused on MCP due to its standardized approach, our methodology remains\napplicable across all LLM agent tool integration frameworks, providing valuable\ninsights for both LLM developers and tool creators to optimize the entire\nLLM-tool interaction ecosystem. The implementation, configurations, and\ndatasets used in our evaluation are publicly available at\nhttps://anonymous.4open.science/r/MCPRadar-B143.",
    "pdf_url": "http://arxiv.org/pdf/2505.16700v1",
    "published": "2025-05-22T14:02:37+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16699v1",
    "title": "Neutrino Decoherence via Modified Dispersion",
    "authors": [
      "Bikash Kumar Acharya",
      "Indra Kumar Banerjee",
      "Ujjal Kumar Dey"
    ],
    "abstract": "We study in detail the effect of quantum decoherence in neutrino\noscillations. We adopt a phenomenological approach that allows us to\nparametrize the energy dependence of the decoherence effects resulting from the\nmodification of the neutrino dispersion relation. Using the open quantum system\nframework we derive decoherence parameters, which are usually connected to\nquantum gravitational effects. Furthermore, we study the sensitivity of\ndecoherence on high-energy astrophysical neutrinos among all possible initial\nsource compositions. We find that variation in the flux composition at neutrino\ntelescopes can be a good probe to test such effects. Additionally, we show that\na simple extension with heavy sterile neutrino decoherence produces verifiable\nsignatures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16699v1",
    "published": "2025-05-22T14:00:57+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16698v1",
    "title": "Tuning Topological States by Dissipation",
    "authors": [
      "Xue-Ping Ren",
      "Yue Hu",
      "Long-Ye Lu",
      "Xin-Ran Ma",
      "Ji-Yao Fan",
      "Cui-Xian Guo",
      "Su-Peng Kou"
    ],
    "abstract": "The bulk-boundary correspondence plays a crucial role in topological quantum\nsystems, however,this principle is broken in non-Hermitian systems. The\nbreakdown of the bulk-boundary correspondence indicates that the global phase\ndiagrams under open boundary conditions are significantly different from those\nunder periodic boundary conditions. In this paper, we investigate how the\nbulk-boundary correspondence breaks down by gradually tearing the system. We\nfind that by tuning the strength of gain and loss domain wall, in the\nthermodynamic limit, the global phase diagrams of the topological system become\nthe hybrids of those under periodic and open boundary conditions. Moreover,\nduring the breakdown of the bulk-boundary correspondence, several phase\ntransitions occur. This situation is quite different from earlier work, where\nthe breakdown of the bulk-boundary correspondence in the thermodynamic limit\noccurred suddenly due to infinitesimal boundary hopping amplitudes. To support\nour conclusions, we provide both analytical and numerical calculations. These\nresults help researchers better understand non-Hermitian topological systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16698v1",
    "published": "2025-05-22T14:00:47+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.other"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16697v1",
    "title": "Software Architecture Meets LLMs: A Systematic Literature Review",
    "authors": [
      "Larissa Schmid",
      "Tobias Hey",
      "Martin Armbruster",
      "Sophie Corallo",
      "Dominik Fuchß",
      "Jan Keim",
      "Haoyu Liu",
      "Anne Koziolek"
    ],
    "abstract": "Large Language Models (LLMs) are used for many different software engineering\ntasks. In software architecture, they have been applied to tasks such as\nclassification of design decisions, detection of design patterns, and\ngeneration of software architecture design from requirements. However, there is\nlittle overview on how well they work, what challenges exist, and what open\nproblems remain. In this paper, we present a systematic literature review on\nthe use of LLMs in software architecture. We analyze 18 research articles to\nanswer five research questions, such as which software architecture tasks LLMs\nare used for, how much automation they provide, which models and techniques are\nused, and how these approaches are evaluated. Our findings show that while LLMs\nare increasingly applied to a variety of software architecture tasks and often\noutperform baselines, some areas, such as generating source code from\narchitectural design, cloud-native computing and architecture, and checking\nconformance remain underexplored. Although current approaches mostly use simple\nprompting techniques, we identify a growing research interest in refining\nLLM-based approaches by integrating advanced techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.16697v1",
    "published": "2025-05-22T14:00:29+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16696v1",
    "title": "Sensitivity of ECG QRS Complexes to His-Purkinje Structure in Computational Heart Models",
    "authors": [
      "Preetam V. Tanikella",
      "Laryssa Abdala",
      "Karin Leiderman",
      "Annie Green Howard",
      "Boyce E. Griffith"
    ],
    "abstract": "Cardiac digital twins (CDT) are emerging as a potentially transformative tool\nin cardiology. A critical yet understudied determinant of CDT accuracy is the\nHis-Purkinje system (HPS), which influences ventricular depolarization and\nshapes the QRS complex of the electrocardiogram (ECG). Here, we quantify how\nstructural variations in the HPS alter QRS morphology and identify which\nparameters drive this variability. We generated HPS structures using a\nfractal-tree, rule-based algorithm, systematically varying nine model\nparameters and assessing their effects on ten QRS-related metrics. We conducted\na Sobol sensitivity analysis to quantify direct and interaction-driven\ncontributions of each parameter to observed variability. Our results suggest\nthat most minor changes in HPS structure exert minimal influence on individual\nQRS features; however, certain parameter combinations can produce abnormal QRS\nmorphologies. Wave durations and peak amplitudes of the QRS complex exhibit low\nsensitivity to individual HPS parameter variations; however, we found that\nspecific parameter combinations can result in interactions that significantly\nalter these aspects of QRS morphology. We found that certain HPS structures can\ncause premature QRS formation, obscuring P-wave formation. QRS timing\nvariability was primarily driven by interactions among branch and fascicle\nangles and branch repulsivity, though other parameters also showed notable\ninteraction effects. In addition to interactions, individual variations in the\nnumber of branches in the HPS also affected QRS timing. While future models\nshould account for these potential sources of variability, this study indicates\nthat minor anatomical differences between a healthy patient's HPS and that of a\ngeneric model are unlikely to significantly impact model fidelity or clinical\ninterpretation when both systems are physiologically normal.",
    "pdf_url": "http://arxiv.org/pdf/2505.16696v1",
    "published": "2025-05-22T14:00:05+00:00",
    "categories": [
      "q-bio.QM",
      "stat.OT"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16695v1",
    "title": "Novel active avalanche paradigm for power semiconductor device extending extending SOA to 6.5kV/15kA",
    "authors": [
      "Liu Jiapeng",
      "Liu Fucheng",
      "Wu Jinpeng",
      "Ren Chunpin",
      "Pan Jianhong",
      "Chen Zhengyu",
      "Zhao Biao",
      "Li Xiaozhao",
      "Zhuang Chijie",
      "Yu Zhanqing",
      "Wei Xiaoguang",
      "Zeng Rong"
    ],
    "abstract": "With the rapid growth of renewable energy being integrated, transmitted, and\nutilized in various forms, power systems are evolving from traditional\nmetal-based infrastructures to advanced semiconductor-based technologies.\nCentral to this transformation, power semiconductor devices now face the\ncrucial demands of ultrahigh switching ability, presenting a long-standing\nchallenge in the field. In this work, building on the P-N-P-N scheme, we\npropose a novel Avalanche Controlled Thyristor (ACT) device, which pivots an\nactive avalanche paradigm to realize robust and strong switch-off ability\nthrough semiconductor-level electrical potential manipulation. Unprecedentedly,\nwe achieve a controllable switch-off current record of 15kA, 375% that of the\nconventional devices without sacrificing the blocking and conduction\ncapability. The novel device signifies that switching ability is no longer a\nbottleneck for power semiconductor devices, which is believed to\nrevolutionarily reshape the technical and practical landscape of power\nconversion, and fundamentally boost the large-scale integration, cross-regional\ntransmission, and cost-effective utilization of renewable energy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16695v1",
    "published": "2025-05-22T13:59:57+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16694v2",
    "title": "Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence",
    "authors": [
      "Gouki Minegishi",
      "Hiroki Furuta",
      "Shohei Taniguchi",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "abstract": "Transformer-based language models exhibit In-Context Learning (ICL), where\npredictions are made adaptively based on context. While prior work links\ninduction heads to ICL through a sudden jump in accuracy, this can only account\nfor ICL when the answer is included within the context. However, an important\nproperty of practical ICL in large language models is the ability to meta-learn\nhow to solve tasks from context, rather than just copying answers from context;\nhow such an ability is obtained during training is largely unexplored. In this\npaper, we experimentally clarify how such meta-learning ability is acquired by\nanalyzing the dynamics of the model's circuit during training. Specifically, we\nextend the copy task from previous research into an In-Context Meta Learning\nsetting, where models must infer a task from examples to answer queries.\nInterestingly, in this setting, we find that there are multiple phases in the\nprocess of acquiring such abilities, and that a unique circuit emerges in each\nphase, contrasting with the single-phases change in induction heads. The\nemergence of such circuits can be related to several phenomena known in large\nlanguage models, and our analysis lead to a deeper understanding of the source\nof the transformer's ICL ability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16694v2",
    "published": "2025-05-22T13:59:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16693v1",
    "title": "Optimized Energy Harvesting in Cell-Free Massive MIMO Using Markov Process Evolution",
    "authors": [
      "Muhammad Zeeshan Mumtaz",
      "Mohammadali Mohammadi",
      "Hien Quoc Ngo",
      "Michail Matthaiou"
    ],
    "abstract": "This paper investigates a discrete energy state transition model for energy\nharvesting (EH) in cell-free massive multiple-input-multiple-output (CF-mMIMO)\nnetworks. A Markov chain-based stochastic process is conceived to characterize\nthe temporal evolution of the user equipment (UE) energy level by leveraging\nstate transition probabilities (STP) based on the energy differential ($\\Delta\nE$) between the EH and consumed energy within each coherence interval.\nTractable mathematical relationships are derived for the STP cases using a new\nstochastic model of non-linear EH, approximated using a Gamma distribution.\nThis derivation leverages closed-form expressions for the mean and variance of\nthe harvested energy. To improve the positive STP of the minimum energy UE\namong all network UEs, we aim to maximize the $\\Delta E$ for this UE using two\npower allocation (PA) schemes. The first scheme is a heuristic PA using the\nrelative channel characteristics to this UE from all access points (APs). The\nsecond scheme is the optimized PA based on the solution of a second-order conic\nproblem to maximize the $\\Delta E$ using a responsive primal-dual interior\npoint method (PD-IPM) algorithm with modified backtracking line-search,\niterating over multiple PA periods. Our simulation results illustrate that both\nthe proposed PA schemes enhance the dynamic minimum UE energy level by around\nfour-fold over full power control, along with the performance improvement\nattributed to spatial resource diversification of CF-mMIMO systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16693v1",
    "published": "2025-05-22T13:58:54+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16692v1",
    "title": "Increased hydrogen escape from Mars atmosphere during periods of high obliquity",
    "authors": [
      "Gabriella Gilli",
      "Francisco González-Galindo",
      "Jean-Yves Chaufray",
      "Ehouarn Millour",
      "François Forget",
      "Franck Montmessin",
      "Franck Lefèvre",
      "Joseph Naar",
      "Yangcheng Luo",
      "Margaux Vals",
      "Loïc Rossi",
      "Miguel Ángel López-Valverde",
      "Adrián Brines"
    ],
    "abstract": "It is still unknown how much water has escaped from Mars during its history.\nHydrogen escape from Mars's atmosphere probably played a major role in drying\nthe planet, but present-day Hloss rates (about 3x10^26 atoms per second on\naverage) cannot explain the geological evidence for the large volumes of liquid\nwater on ancient Mars. Here we used the three-dimensional Mars-Planetary\nClimate Model to show that H loss rates could have increased by more than one\norder of magnitude (6x10^27 atoms per second) during higher spin axis obliquity\nperiods, notably in the last few million years when Mars's obliquity was about\n35 deg on average. The resulting accumulated H escape over Mars's history\ntranslates into an approx. 80 m global equivalent layer, which is close to the\nlower limit of geological estimates, assessing the major role of atmospheric\nescape in drying Mars.",
    "pdf_url": "http://arxiv.org/pdf/2505.16692v1",
    "published": "2025-05-22T13:57:09+00:00",
    "categories": [
      "astro-ph.EP",
      "physics.ao-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16691v2",
    "title": "EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion",
    "authors": [
      "Advait Joglekar",
      "Divyanshu Singh",
      "Rooshil Rohit Bhatia",
      "S. Umesh"
    ],
    "abstract": "Voice Conversion research in recent times has increasingly focused on\nimproving the zero-shot capabilities of existing methods. Despite remarkable\nadvancements, current architectures still tend to struggle in zero-shot\ncross-lingual settings. They are also often unable to generalize for speakers\nof unseen languages and accents. In this paper, we adopt a simple yet effective\napproach that combines discrete speech representations from self-supervised\nmodels with a non-autoregressive Diffusion-Transformer based conditional flow\nmatching speech decoder. We show that this architecture allows us to train a\nvoice-conversion model in a purely textless, self-supervised fashion. Our\ntechnique works without requiring multiple encoders to disentangle speech\nfeatures. Our model also manages to excel in zero-shot cross-lingual settings\neven for unseen languages. For Demo: https://ez-vc.github.io/EZ-VC-Demo/",
    "pdf_url": "http://arxiv.org/pdf/2505.16691v2",
    "published": "2025-05-22T13:57:02+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16690v1",
    "title": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator",
    "authors": [
      "Beier Luo",
      "Shuoyuan Wang",
      "Yixuan Li",
      "Hongxin Wei"
    ],
    "abstract": "Post-training of large language models is essential for adapting pre-trained\nlanguage models (PLMs) to align with human preferences and downstream tasks.\nWhile PLMs typically exhibit well-calibrated confidence, post-trained language\nmodels (PoLMs) often suffer from over-confidence, assigning high confidence to\nboth correct and incorrect outputs, which can undermine reliability in critical\napplications. A major obstacle in calibrating PoLMs is the scarcity of labeled\ndata for individual downstream tasks. To address this, we propose\nDisagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to\noptimize the parameters (e.g., temperature $\\tau$) in post-hoc confidence\ncalibration. Our method is motivated by the under-confidence issue caused by\nprediction disagreement between the PLM and PoLM while aligning their\nconfidence via temperature scaling. Theoretically, the PLM's confidence\nunderestimates PoLM's prediction accuracy on disagreement examples, causing a\nlarger $\\tau$ and producing under-confident predictions. DACA mitigates this by\nselectively using only agreement examples for calibration, effectively\ndecoupling the influence of disagreement. In this manner, our method avoids an\noverly large $\\tau$ in temperature scaling caused by disagreement examples,\nimproving calibration performance. Extensive experiments demonstrate the\neffectiveness of our method, improving the average ECE of open-sourced and\nAPI-based LLMs (e.g. GPT-4o) by up to 15.08$\\%$ on common benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16690v1",
    "published": "2025-05-22T13:55:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16689v2",
    "title": "Deformations of quasi-Hamiltonian spaces",
    "authors": [
      "Jean-Philippe Burelle",
      "Mohamed Moussadek Maiza",
      "Maxence Mayrand"
    ],
    "abstract": "We introduce a notion of deformations of quasi-Hamiltonian $G$-spaces to\nHamiltonian $G$-spaces and provide several examples. In particular, we show\nthat the double $G \\times G$ of a Lie group, viewed as a quasi-Hamiltonian $G\n\\times G$-space, deforms smoothly to the cotangent bundle $T^*G$. Likewise, any\nconjugacy class of $G$ sufficiently close to the identity deforms to a\ncoadjoint orbit. We further show that the moduli space of flat $G$-connections\non a compact oriented surface of genus $g$ with $r+1$ boundary components\ndeforms to $T^*G^{r+g}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16689v2",
    "published": "2025-05-22T13:55:37+00:00",
    "categories": [
      "math.SG",
      "math.DG"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16688v1",
    "title": "Existence proofs for rotationally symmetric translating solutions to mean curvature flow",
    "authors": [
      "Hakar Raji",
      "Oliver C. Schnürer"
    ],
    "abstract": "There exist rotationally symmetric translating solutions to mean curvature\nflow that can be written as a graph over Euclidean space. This result is\nwell-known. Its proof uses the symmetry and techniques from partial\ndifferential equations. However, the result can also be formulated as an\nexistence result for a singular ordinary differential equation. Here, we\nprovide different methods to prove existence of these solutions based on the\nstudy of the singular ordinary differential equation without using methods from\npartial differential equations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16688v1",
    "published": "2025-05-22T13:54:52+00:00",
    "categories": [
      "math.DG",
      "53E10, 34A12"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16687v1",
    "title": "One-Step Diffusion-Based Image Compression with Semantic Distillation",
    "authors": [
      "Naifu Xue",
      "Zhaoyang Jia",
      "Jiahao Li",
      "Bin Li",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "abstract": "While recent diffusion-based generative image codecs have shown impressive\nperformance, their iterative sampling process introduces unpleasing latency. In\nthis work, we revisit the design of a diffusion-based codec and argue that\nmulti-step sampling is not necessary for generative compression. Based on this\ninsight, we propose OneDC, a One-step Diffusion-based generative image Codec --\nthat integrates a latent compression module with a one-step diffusion\ngenerator. Recognizing the critical role of semantic guidance in one-step\ndiffusion, we propose using the hyperprior as a semantic signal, overcoming the\nlimitations of text prompts in representing complex visual content. To further\nenhance the semantic capability of the hyperprior, we introduce a semantic\ndistillation mechanism that transfers knowledge from a pretrained generative\ntokenizer to the hyperprior codec. Additionally, we adopt a hybrid pixel- and\nlatent-domain optimization to jointly enhance both reconstruction fidelity and\nperceptual realism. Extensive experiments demonstrate that OneDC achieves SOTA\nperceptual quality even with one-step generation, offering over 40% bitrate\nreduction and 20x faster decoding compared to prior multi-step diffusion-based\ncodecs. Code will be released later.",
    "pdf_url": "http://arxiv.org/pdf/2505.16687v1",
    "published": "2025-05-22T13:54:09+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.05358v1",
    "title": "Can ChatGPT Perform Image Splicing Detection? A Preliminary Study",
    "authors": [
      "Souradip Nath"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) like GPT-4V are capable of reasoning\nacross text and image modalities, showing promise in a variety of complex\nvision-language tasks. In this preliminary study, we investigate the\nout-of-the-box capabilities of GPT-4V in the domain of image forensics,\nspecifically, in detecting image splicing manipulations. Without any\ntask-specific fine-tuning, we evaluate GPT-4V using three prompting strategies:\nZero-Shot (ZS), Few-Shot (FS), and Chain-of-Thought (CoT), applied over a\ncurated subset of the CASIA v2.0 splicing dataset.\n  Our results show that GPT-4V achieves competitive detection performance in\nzero-shot settings (more than 85% accuracy), with CoT prompting yielding the\nmost balanced trade-off across authentic and spliced images. Qualitative\nanalysis further reveals that the model not only detects low-level visual\nartifacts but also draws upon real-world contextual knowledge such as object\nscale, semantic consistency, and architectural facts, to identify implausible\ncomposites. While GPT-4V lags behind specialized state-of-the-art splicing\ndetection models, its generalizability, interpretability, and encyclopedic\nreasoning highlight its potential as a flexible tool in image forensics.",
    "pdf_url": "http://arxiv.org/pdf/2506.05358v1",
    "published": "2025-05-22T13:53:53+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16686v1",
    "title": "SPaRC: A Spatial Pathfinding Reasoning Challenge",
    "authors": [
      "Lars Benedikt Kaesberg",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Bela Gipp"
    ],
    "abstract": "Existing reasoning datasets saturate and fail to test abstract, multi-step\nproblems, especially pathfinding and complex rule constraint satisfaction. We\nintroduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000\n2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,\nrequiring step-by-step planning with arithmetic and geometric rules. Humans\nachieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best\nreasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).\nModels often generate invalid paths (>50% of puzzles for o4-mini), and\nreasoning tokens reveal they make errors in navigation and spatial logic.\nUnlike humans, who take longer on hard puzzles, models fail to scale test-time\ncompute with difficulty. Allowing models to make multiple solution attempts\nimproves accuracy, suggesting potential for better spatial reasoning with\nimproved training and efficient test-time scaling methods. SPaRC can be used as\na window into models' spatial reasoning limitations and drive research toward\nnew methods that excel in abstract, multi-step problem-solving.",
    "pdf_url": "http://arxiv.org/pdf/2505.16686v1",
    "published": "2025-05-22T13:53:50+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16685v1",
    "title": "On the use of Graphs for Satellite Image Time Series",
    "authors": [
      "Corentin Dufourg",
      "Charlotte Pelletier",
      "Stéphane May",
      "Sébastien Lefèvre"
    ],
    "abstract": "The Earth's surface is subject to complex and dynamic processes, ranging from\nlarge-scale phenomena such as tectonic plate movements to localized changes\nassociated with ecosystems, agriculture, or human activity. Satellite images\nenable global monitoring of these processes with extensive spatial and temporal\ncoverage, offering advantages over in-situ methods. In particular, resulting\nsatellite image time series (SITS) datasets contain valuable information. To\nhandle their large volume and complexity, some recent works focus on the use of\ngraph-based techniques that abandon the regular Euclidean structure of\nsatellite data to work at an object level. Besides, graphs enable modelling\nspatial and temporal interactions between identified objects, which are crucial\nfor pattern detection, classification and regression tasks. This paper is an\neffort to examine the integration of graph-based methods in spatio-temporal\nremote-sensing analysis. In particular, it aims to present a versatile\ngraph-based pipeline to tackle SITS analysis. It focuses on the construction of\nspatio-temporal graphs from SITS and their application to downstream tasks. The\npaper includes a comprehensive review and two case studies, which highlight the\npotential of graph-based approaches for land cover mapping and water resource\nforecasting. It also discusses numerous perspectives to resolve current\nlimitations and encourage future developments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16685v1",
    "published": "2025-05-22T13:53:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16684v1",
    "title": "Triple V-shaped type-II quantum wells for long wavelength interband cascade lasers",
    "authors": [
      "B. Petrović",
      "T. Sato",
      "S. Birner",
      "J. Zanon",
      "M. E. Flatté",
      "R. Weih",
      "F. Hartmann",
      "S. Höfling"
    ],
    "abstract": "We investigate triple V-shaped type-II quantum wells designed to emit at 6-9\n{\\mu}m wavelength range, consisting of three InAs(Sb) electron quantum wells\nand two Ga0.6In0.4Sb hole quantum wells. The wells' composition and thicknesses\nare optimized in terms of wavefunction overlap and valence intersubband\nabsorption (VISA) by using kp calculation. The triple V-shaped type-II quantum\nwell designed for emission at 6.2 {\\mu}m, 7.5 {\\mu}m and 9.0 {\\mu}m, show 18.8\n%, 18.9 % and 19.2 % higher wavefunction overlap respectively, compared to the\ncorresponding W-shaped designs of InAs/Ga0.6In0.4Sb/InAs wells commonly\nemployed in active regions of interband cascade lasers. In addition, the\ncalculated VISA in V-shaped quantum wells for the designed wavelength is\nsignificantly smaller than in W-shaped wells. These enhancements might extend\nthe wavelength limit of room temperature emission of GaSb-based interband\ncascade lasers.",
    "pdf_url": "http://arxiv.org/pdf/2505.16684v1",
    "published": "2025-05-22T13:52:29+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16683v1",
    "title": "Continuous Petri Nets Faithfully Fluidify Most Permissive Boolean Networks",
    "authors": [
      "Stefan Haar",
      "Juri Kolčák"
    ],
    "abstract": "The analysis of biological networks has benefited from the richness of\nBoolean networks (BNs) and the associated theory. These results have been\nfurther fortified in recent years by the emergence of Most Permissive (MP)\nsemantics, combining efficient analysis methods with a greater capacity of\nexplaining pathways to states hitherto thought unreachable, owing to\nlimitations of the classical update modes. While MPBNs are understood to\ncapture any behaviours that can be observed at a lower level of abstraction,\nall the way down to continuous refinements, the specifics and potential of the\nmodels and analysis, especially attractors, across the abstraction scale remain\nunexplored. Here, we fluidify MPBNs by means of Continuous Petri nets (CPNs), a\nmodel of (uncountably infinite) dynamic systems that has been successfully\nexplored for modelling and theoretical purposes. CPNs create a formal link\nbetween MPBNs and their continuous dynamical refinements such as ODE models.\nThe benefits of CPNs extend beyond the model refinement, and constitute well\nestablished theory and analysis methods, recently augmented by abstract and\nsymbolic reachability graphs. These structures are shown to compact the\npossible behaviours of the system with focus on events which drive the choice\nof long-term behaviour in which the system eventually stabilises. The current\npaper brings an important keystone to this novel methodology for biological\nnetworks, namely the proof that extant PN encoding of BNs instantiated as a CPN\nsimulates the MP semantics. In spite of the underlying dynamics being\ncontinuous, the analysis remains in the realm of discrete methods, constituting\nan extension of all previous work.",
    "pdf_url": "http://arxiv.org/pdf/2505.16683v1",
    "published": "2025-05-22T13:52:27+00:00",
    "categories": [
      "cs.DM",
      "cs.LO"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16682v1",
    "title": "MEbots: Integrating a RISC-V Virtual Platform with a Robotic Simulator for Energy-aware Design",
    "authors": [
      "Giovanni Pollo",
      "Mohamed Amine Hamdi",
      "Matteo Risso",
      "Lorenzo Ruotolo",
      "Pietro Furbatto",
      "Matteo Isoldi",
      "Yukai Chen",
      "Alessio Burrello",
      "Enrico Macii",
      "Massimo Poncino",
      "Daniele Jahier Pagliari",
      "Sara Vinco"
    ],
    "abstract": "Virtual Platforms (VPs) enable early software validation of autonomous\nsystems' electronics, reducing costs and time-to-market. While many VPs support\nboth functional and non-functional simulation (e.g., timing, power), they lack\nthe capability of simulating the environment in which the system operates. In\ncontrast, robotics simulators lack accurate timing and power features. This\ntwofold shortcoming limits the effectiveness of the design flow, as the\ndesigner can not fully evaluate the features of the solution under development.\nThis paper presents a novel, fully open-source framework bridging this gap by\nintegrating a robotics simulator (Webots) with a VP for RISC-V-based systems\n(MESSY). The framework enables a holistic, mission-level, energy-aware\nco-simulation of electronics in their surrounding environment, streamlining the\nexploration of design configurations and advanced power management policies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16682v1",
    "published": "2025-05-22T13:51:52+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16681v2",
    "title": "Quantum melting of generalized electron crystal in twisted bilayer MoSe2",
    "authors": [
      "Qi Jun Zong",
      "Haolin Wang",
      "Qi Zhang",
      "Xinle Cheng",
      "Yangchen He",
      "Qiaoling Xu",
      "Ammon Fischer",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Daniel A. Rhodes",
      "Lede Xian",
      "Dante M. Kennes",
      "Angel Rubio",
      "Geliang Yu",
      "Lei Wang"
    ],
    "abstract": "Electrons can form an ordered solid crystal phase ascribed to the interplay\nbetween Coulomb repulsion and kinetic energy. Tuning these energy scales can\ndrive a phase transition from electron solid to liquid, i.e. melting of Wigner\ncrystal. Generalized Wigner crystals (GWCs) pinned to moire superlattices have\nbeen reported by optical and scanning-probe-based methods. Using transport\nmeasurements to investigate GWCs is vital to a complete characterization,\nhowever, still poses a significant challenge due to difficulties in making\nreliable electrical contacts. Here, we report the electrical transport\ndetection of GWCs at fractional fillings nu = 2/5, 1/2, 3/5, 2/3, 8/9, 10/9,\nand 4/3 in twisted bilayer MoSe2. We further observe that these GWCs undergo\ncontinuous quantum melting transitions to liquid phases by tuning doping\ndensity, magnetic and displacement fields, manifested by quantum critical\nscaling behaviors. Our findings establish twisted bilayer MoSe2 as a novel\nsystem to study strongly correlated states of matter and their quantum phase\ntransitions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16681v2",
    "published": "2025-05-22T13:49:13+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.21520v1",
    "title": "Do DeepFake Attribution Models Generalize?",
    "authors": [
      "Spiros Baxavanakis",
      "Manos Schinas",
      "Symeon Papadopoulos"
    ],
    "abstract": "Recent advancements in DeepFake generation, along with the proliferation of\nopen-source tools, have significantly lowered the barrier for creating\nsynthetic media. This trend poses a serious threat to the integrity and\nauthenticity of online information, undermining public trust in institutions\nand media. State-of-the-art research on DeepFake detection has primarily\nfocused on binary detection models. A key limitation of these models is that\nthey treat all manipulation techniques as equivalent, despite the fact that\ndifferent methods introduce distinct artifacts and visual cues. Only a limited\nnumber of studies explore DeepFake attribution models, although such models are\ncrucial in practical settings. By providing the specific manipulation method\nemployed, these models could enhance both the perceived trustworthiness and\nexplainability for end users. In this work, we leverage five state-of-the-art\nbackbone models and conduct extensive experiments across six DeepFake datasets.\nFirst, we compare binary and multi-class models in terms of cross-dataset\ngeneralization. Second, we examine the accuracy of attribution models in\ndetecting seen manipulation methods in unknown datasets, hence uncovering data\ndistribution shifts on the same DeepFake manipulations. Last, we assess the\neffectiveness of contrastive methods in improving cross-dataset generalization\nperformance. Our findings indicate that while binary models demonstrate better\ngeneralization abilities, larger models, contrastive methods, and higher data\nquality can lead to performance improvements in attribution models. The code of\nthis work is available on GitHub.",
    "pdf_url": "http://arxiv.org/pdf/2505.21520v1",
    "published": "2025-05-22T13:49:05+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16680v1",
    "title": "Learning Genomic Structure from $k$-mers",
    "authors": [
      "Filip Thor",
      "Carl Nettelblad"
    ],
    "abstract": "Sequencing a genome to determine an individual's DNA produces an enormous\nnumber of short nucleotide subsequences known as reads, which must be\nreassembled to reconstruct the full genome. We present a method for analyzing\nthis type of data using contrastive learning, in which an encoder model is\ntrained to produce embeddings that cluster together sequences from the same\ngenomic region. The sequential nature of genomic regions is preserved in the\nform of trajectories through this embedding space. Trained solely to reflect\nthe structure of the genome, the resulting model provides a general\nrepresentation of $k$-mer sequences, suitable for a range of downstream tasks\ninvolving read data. We apply our framework to learn the structure of the $E.\\\ncoli$ genome, and demonstrate its use in simulated ancient DNA (aDNA) read\nmapping and identification of structural variations. Furthermore, we illustrate\nthe potential of using this type of model for metagenomic species\nidentification. We show how incorporating a domain-specific noise model can\nenhance embedding robustness, and how a supervised contrastive learning setting\ncan be adopted when a linear reference genome is available, by introducing a\ndistance thresholding parameter $\\Gamma$. The model can also be trained fully\nself-supervised on read data, enabling analysis without the need to construct a\nfull genome assembly using specialized algorithms. Small prediction heads based\non a pre-trained embedding are shown to perform on par with BWA-aln, the\ncurrent gold standard approach for aDNA mapping, in terms of accuracy and\nruntime for short genomes. Given the method's favorable scaling properties with\nrespect to total genome size, inference using our approach is highly promising\nfor metagenomic applications and for mapping to genomes comparable in size to\nthe human genome.",
    "pdf_url": "http://arxiv.org/pdf/2505.16680v1",
    "published": "2025-05-22T13:46:18+00:00",
    "categories": [
      "cs.LG",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16679v1",
    "title": "Semantic Compression of 3D Objects for Open and Collaborative Virtual Worlds",
    "authors": [
      "Jordan Dotzel",
      "Tony Montes",
      "Mohamed S. Abdelfattah",
      "Zhiru Zhang"
    ],
    "abstract": "Traditional methods for 3D object compression operate only on structural\ninformation within the object vertices, polygons, and textures. These methods\nare effective at compression rates up to 10x for standard object sizes but\nquickly deteriorate at higher compression rates with texture artifacts,\nlow-polygon counts, and mesh gaps. In contrast, semantic compression ignores\nstructural information and operates directly on the core concepts to push to\nextreme levels of compression. In addition, it uses natural language as its\nstorage format, which makes it natively human-readable and a natural fit for\nemerging applications built around large-scale, collaborative projects within\naugmented and virtual reality. It deprioritizes structural information like\nlocation, size, and orientation and predicts the missing information with\nstate-of-the-art deep generative models. In this work, we construct a pipeline\nfor 3D semantic compression from public generative models and explore the\nquality-compression frontier for 3D object compression. We apply this pipeline\nto achieve rates as high as 105x for 3D objects taken from the Objaverse\ndataset and show that semantic compression can outperform traditional methods\nin the important quality-preserving region around 100x compression.",
    "pdf_url": "http://arxiv.org/pdf/2505.16679v1",
    "published": "2025-05-22T13:45:35+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16678v1",
    "title": "Tracking shear mode dynamics across the glass transition in a 2D colloidal system",
    "authors": [
      "Jimin Bai",
      "Peter Keim",
      "Matteo Baggioli"
    ],
    "abstract": "Long-wavelength collective shear dynamics are profoundly different in solids\nand liquids. According to the theoretical framework developed by Maxwell and\nFrenkel, collective shear waves vanish upon melting by acquiring a\ncharacteristic wave-vector gap, known as the $k$-gap. While this prediction has\nbeen supported by numerous simulations, experimental validation remains\nlimited. In this work, we track the dispersion relation of collective shear\nmodes in a two-dimensional colloidal system and provide direct experimental\nevidence for the emergence of a $k$-gap. This gap appears at an effective\ntemperature consistent with the onset of the glass transition and the vanishing\nof the static shear modulus. Our results not only confirm the predictions of\nthe Maxwell-Frenkel framework but also highlight their relevance across\ncontinuous melting processes originating from low-temperature amorphous solid\nphases.",
    "pdf_url": "http://arxiv.org/pdf/2505.16678v1",
    "published": "2025-05-22T13:43:42+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.16677v1",
    "title": "Universal estimates for the density of states for aperiodic block subwavelength resonator systems",
    "authors": [
      "Habib Ammari",
      "Silvio Barandun",
      "Bryn Davies",
      "Erik Orvehed Hiltunen",
      "Alexander Uhlmann"
    ],
    "abstract": "We consider the spectral properties of aperiodic block subwavelength\nresonator systems in one dimension, with a primary focus on the density of\nstates. We prove that for random block configurations, as the number of blocks\n$M\\to \\infty$, the integrated density of states converges to a non-random,\ncontinuous function. We show both analytically and numerically that the density\nof states exhibits a tripartite decomposition: it vanishes identically within\nbandgaps; it forms smooth, band-like distributions in shared pass bands (a\nconsequence of constructive eigenmode interactions); and, most notably, it\nexhibits a distinct fractal-like character in hybridisation regions. We\ndemonstrate that this fractal-like behaviour stems from the limited interaction\nbetween eigenmodes within these hybridisation regions. Capitalising on this\ninsight, we introduce an efficient meta-atom approach that enables rapid and\naccurate prediction of the density of states in these hybridisation regions.\nThis approach is shown to extend to systems with quasiperiodic and hyperuniform\narrangements of blocks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16677v1",
    "published": "2025-05-22T13:42:15+00:00",
    "categories": [
      "math-ph",
      "cond-mat.dis-nn",
      "cond-mat.mtrl-sci",
      "math.MP",
      "35J05, 35C20, 35P20, 37A30, 47B36"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16676v1",
    "title": "Hybrid Parameterized Quantum States for Variational Quantum Learning",
    "authors": [
      "Chen-Yu Liu"
    ],
    "abstract": "Variational quantum learning faces practical challenges in the noisy\nintermediate-scale quantum (NISQ) era. Parameterized quantum circuit (PQC)\nmodels suffer from statistical uncertainty due to finite-shot measurements and\nare highly sensitive to quantum noise, while purely classical approximations\nlike neural quantum states (NQS) lack access to genuine quantum correlations\nand are limited in scalability. This work introduces Hybrid Parameterized\nQuantum States (HPQS), a general-purpose modeling framework that interpolates\nbetween quantum and classical parameterizations. HPQS combines PQC-based\nmeasurements with neural estimators via a blending mechanism and postprocessing\nfunctions, enabling enhanced, shot-efficient evaluation under hardware\nconstraints. We demonstrate HPQS across three representative quantum learning\ntasks: (1) Expectation-based QML, where HPQS yields higher classification\naccuracy than PQC-only and NQS-only baselines under limited quantum\nmeasurements. (2) Quantum-Train, where HPQS generates the entire parameter set\nof classical networks using polylogarithmic trainable variables; and (3)\nQuantum Parameter Adaptation (QPA), where HPQS produces LoRA adapter parameters\nfor fine-tuning large language models like GPT-2 and Gemma-2 with improved\nperplexity under low-shot conditions; Together, these results position HPQS as\na scalable, noise-resilient approach for variational quantum learning,\ncompatible with both current NISQ hardware and future fault-tolerant\narchitectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16676v1",
    "published": "2025-05-22T13:40:24+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16675v1",
    "title": "On the Out-of-Distribution Generalization of Self-Supervised Learning",
    "authors": [
      "Wenwen Qiang",
      "Jingyao Wang",
      "Zeen Song",
      "Jiangmeng Li",
      "Changwen Zheng"
    ],
    "abstract": "In this paper, we focus on the out-of-distribution (OOD) generalization of\nself-supervised learning (SSL). By analyzing the mini-batch construction during\nthe SSL training phase, we first give one plausible explanation for SSL having\nOOD generalization. Then, from the perspective of data generation and causal\ninference, we analyze and conclude that SSL learns spurious correlations during\nthe training process, which leads to a reduction in OOD generalization. To\naddress this issue, we propose a post-intervention distribution (PID) grounded\nin the Structural Causal Model. PID offers a scenario where the spurious\nvariable and label variable is mutually independent. Besides, we demonstrate\nthat if each mini-batch during SSL training satisfies PID, the resulting SSL\nmodel can achieve optimal worst-case OOD performance. This motivates us to\ndevelop a batch sampling strategy that enforces PID constraints through the\nlearning of a latent variable model. Through theoretical analysis, we\ndemonstrate the identifiability of the latent variable model and validate the\neffectiveness of the proposed sampling strategy. Experiments conducted on\nvarious downstream OOD tasks demonstrate the effectiveness of the proposed\nsampling strategy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16675v1",
    "published": "2025-05-22T13:40:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16674v1",
    "title": "Zero-Shot Anomaly Detection in Battery Thermal Images Using Visual Question Answering with Prior Knowledge",
    "authors": [
      "Marcella Astrid",
      "Abdelrahman Shabayek",
      "Djamila Aouada"
    ],
    "abstract": "Batteries are essential for various applications, including electric vehicles\nand renewable energy storage, making safety and efficiency critical concerns.\nAnomaly detection in battery thermal images helps identify failures early, but\ntraditional deep learning methods require extensive labeled data, which is\ndifficult to obtain, especially for anomalies due to safety risks and high data\ncollection costs. To overcome this, we explore zero-shot anomaly detection\nusing Visual Question Answering (VQA) models, which leverage pretrained\nknowledge and textbased prompts to generalize across vision tasks. By\nincorporating prior knowledge of normal battery thermal behavior, we design\nprompts to detect anomalies without battery-specific training data. We evaluate\nthree VQA models (ChatGPT-4o, LLaVa-13b, and BLIP-2) analyzing their robustness\nto prompt variations, repeated trials, and qualitative outputs. Despite the\nlack of finetuning on battery data, our approach demonstrates competitive\nperformance compared to state-of-the-art models that are trained with the\nbattery data. Our findings highlight the potential of VQA-based zero-shot\nlearning for battery anomaly detection and suggest future directions for\nimproving its effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.16674v1",
    "published": "2025-05-22T13:39:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16673v1",
    "title": "R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO",
    "authors": [
      "Huanjin Yao",
      "Qixiang Yin",
      "Jingyi Zhang",
      "Min Yang",
      "Yibo Wang",
      "Wenhao Wu",
      "Fei Su",
      "Li Shen",
      "Minghui Qiu",
      "Dacheng Tao",
      "Jiaxing Huang"
    ],
    "abstract": "In this work, we aim to incentivize the reasoning ability of Multimodal Large\nLanguage Models (MLLMs) via reinforcement learning (RL) and develop an\neffective approach that mitigates the sparse reward and advantage vanishing\nissues during RL. To this end, we propose Share-GRPO, a novel RL approach that\ntackle these issues by exploring and sharing diverse reasoning trajectories\nover expanded question space. Specifically, Share-GRPO first expands the\nquestion space for a given question via data transformation techniques, and\nthen encourages MLLM to effectively explore diverse reasoning trajectories over\nthe expanded question space and shares the discovered reasoning trajectories\nacross the expanded questions during RL. In addition, Share-GRPO also shares\nreward information during advantage computation, which estimates solution\nadvantages hierarchically across and within question variants, allowing more\naccurate estimation of relative advantages and improving the stability of\npolicy training. Extensive evaluations over six widely-used reasoning\nbenchmarks showcase the superior performance of our method. Code will be\navailable at https://github.com/HJYao00/R1-ShareVL.",
    "pdf_url": "http://arxiv.org/pdf/2505.16673v1",
    "published": "2025-05-22T13:39:32+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17158v2",
    "title": "Torsional Effects in the Coupling between Gravity and Spinors -- Yukawa Gravity",
    "authors": [
      "Elisa Varani"
    ],
    "abstract": "We study spinors in the framework of general relativity, starting from the\nDirac field Lagrangian in the approximation of weak gravity. We focus on how\nfermions couple to gravity through the spin connection, and we analyze these\ncouplings by analogy with the Ginzburg-Landau model and the Yukawa interaction\nknown from the Higgs mechanism. By solving the field equations, we explore how\nthese couplings affect the spacetime metric. In particular, torsion generated\nby fermionic spin currents naturally emerges and leads to the breaking of\nLorentz symmetry. As a consequence, gravity acquires a mass and fermions gain\nadditional mass contributions through their interaction with this gravitational\nfield. These effects are localized and diminish quickly with distance. Our\nmodel offers an alternative explanation to phenomena usually attributed to dark\nmatter and dark energy. We link these cosmological effects to chirality-flip\nprocesses of Majorana neutrinos interacting with a massive graviton.\nRight-handed Majorana neutrinos, which are sterile under Standard Model\ninteractions, generate repulsive gravitational curvature and act as a source of\ndark energy, while left-handed neutrinos contribute to attractive gravitational\neffects akin to dark matter. The spin-gravity coupling modifies the curvature\nof spacetime, influencing galaxy rotation, the accelerated expansion of the\nuniverse, and the bending of light. In short, the intrinsic spin of fermions,\nwhen coupled to gravity via torsion, changes gravity from a long-range,\nmassless force to a short-range, massive one. This new framework provides fresh\ninsights into fundamental physics and cosmology, potentially explaining dark\nmatter and dark energy phenomena through spin-related gravitational effects.",
    "pdf_url": "http://arxiv.org/pdf/2505.17158v2",
    "published": "2025-05-22T13:38:31+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16672v1",
    "title": "Quantum Feature Optimization for Enhanced Clustering of Blockchain Transaction Data",
    "authors": [
      "Yun-Cheng Tsai",
      "Samuel Yen-Chi Chen"
    ],
    "abstract": "Blockchain transaction data exhibits high dimensionality, noise, and\nintricate feature entanglement, presenting significant challenges for\ntraditional clustering algorithms. In this study, we conduct a comparative\nanalysis of three clustering approaches: (1) Classical K-Means Clustering,\napplied to pre-processed feature representations; (2) Hybrid Clustering,\nwherein classical features are enhanced with quantum random features extracted\nusing randomly initialized quantum neural networks (QNNs); and (3) Fully\nQuantum Clustering, where a QNN is trained in a self-supervised manner\nleveraging a SwAV-based loss function to optimize the feature space for\nclustering directly. The proposed experimental framework systematically\ninvestigates the impact of quantum circuit depth and the number of learned\nprototypes, demonstrating that even shallow quantum circuits can effectively\nextract meaningful non-linear representations, significantly improving\nclustering performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.16672v1",
    "published": "2025-05-22T13:37:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16671v1",
    "title": "Low-energy eigenstates in a vanishing magnetic field",
    "authors": [
      "Lino Benedetto"
    ],
    "abstract": "This paper is dedicated to the spectral analysis of the semiclassical purely\nmagnetic Laplacian on the plane in the situation where the magnetic field $B$\nvanishes nondegenerately on an open smooth curve $\\Gamma$. We prove the\nexistence of a discrete spectrum for energy windows of the scale $h^{4/3}$ and\ngive complete asymptotics in the semiclassical paramater $h$ for eigenvalues in\nsuch windows. Our strategy relies on the microlocalization of the corresponding\neigenfunctions close to the zero locus $\\Gamma$ and on the implementation of a\nBorn-Oppenheimer strategy through the use of operator-valued pseudodifferential\ncalculus and superadiatic projectors. This allows us to reduce our spectral\nanalysis to that of effective semiclassical pseudodifferential operators in\ndimension 1 and apply the well-known semiclassical techniques \\`a la\nHelffer-Sj\\\"ostrand.",
    "pdf_url": "http://arxiv.org/pdf/2505.16671v1",
    "published": "2025-05-22T13:36:42+00:00",
    "categories": [
      "math.SP",
      "math.AP"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16670v2",
    "title": "BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models",
    "authors": [
      "Xiaobei Yan",
      "Yiming Li",
      "Zhaoxin Fan",
      "Han Qiu",
      "Tianwei Zhang"
    ],
    "abstract": "Large language models (LLMs) have shown impressive capabilities across a wide\nrange of applications, but their ever-increasing size and resource demands make\nthem vulnerable to inference cost attacks, where attackers induce victim LLMs\nto generate the longest possible output content. In this paper, we revisit\nexisting inference cost attacks and reveal that these methods can hardly\nproduce large-scale malicious effects since they are self-targeting, where\nattackers are also the users and therefore have to execute attacks solely\nthrough the inputs, whose generated content will be charged by LLMs and can\nonly directly influence themselves. Motivated by these findings, this paper\nintroduces a new type of inference cost attacks (dubbed 'bit-flip inference\ncost attack') that target the victim model itself rather than its inputs.\nSpecifically, we design a simple yet effective method (dubbed 'BitHydra') to\neffectively flip critical bits of model parameters. This process is guided by a\nloss function designed to suppress <EOS> token's probability with an efficient\ncritical bit search algorithm, thus explicitly defining the attack objective\nand enabling effective optimization. We evaluate our method on 11 LLMs ranging\nfrom 1.5B to 14B parameters under both int8 and float16 settings. Experimental\nresults demonstrate that with just 4 search samples and as few as 3 bit flips,\nBitHydra can force 100% of test prompts to reach the maximum generation length\n(e.g., 2048 tokens) on representative LLMs such as LLaMA3, highlighting its\nefficiency, scalability, and strong transferability across unseen inputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16670v2",
    "published": "2025-05-22T13:36:00+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16669v1",
    "title": "An open harmonic chain: Exact vs global and local reduced dynamics",
    "authors": [
      "Melika Babakan",
      "Fabio Benatti",
      "Laleh Memarzadeh"
    ],
    "abstract": "In the following, we study the dissipative time-evolution of a quantum chain\nconsisting of three coupled harmonic oscillators, the first and third of which\nweakly interact quadratically with two independent thermal baths in equilibrium\nat different temperatures. Due to the quadratic form of the total Hamiltonian,\nthe unitary dynamics of the compound system is formally analytically solvable\nand defines a one-parameter group of Gaussian maps which enables us to solve\nthe exact dynamics of the chain numerically. Following the\nGorini-Kossakowski-Sudarshan-Lindblad (GKSL) approach to open quantum systems,\none can perform the rotating wave approximation with respect to the\ninteracting, or non-interacting chain Hamiltonian and respectively derive the\nso-called global and local master equations. The solutions of the ensuing\ndifferent master equations can then be compared with the exact one, possibly\nsorting out the two approaches in correspondence to different time-scales of\nthe system. We derive the steady states of the open chain quantum dynamics in\nthe two approaches and show that the behaviour of fidelity between them versus\ninter-oscillator coupling depends on the two bath temperatures, revealing the\nexistence of a temperature-dependent critical inter-oscillator coupling\nstrength that determines the domain of validity of each approach. When the\nnewly found coupling is less than this critical value, the local approach\noutperforms the global approach, whereas for larger inter-oscillator coupling,\nthe global approach is a better approximation of the exact evolution. This\ncritical value of inter-oscillator coupling depends on the two bath\ntemperatures, which then play a crucial role in deciding the best possible\napproximating open dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16669v1",
    "published": "2025-05-22T13:33:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16668v1",
    "title": "Impact pressure enhancement upon disk impact on a boiling liquid",
    "authors": [
      "Yee Li",
      "Fan",
      "Bernardo Palacios Muniz",
      "Nayoung Kim",
      "Devaraj van der Meer"
    ],
    "abstract": "We experimentally investigate the impact of a flat, horizontal disk onto a\nboiling liquid, i.e., a liquid in thermal equilibrium with its vapor phase. We\nobserve exceptionally high impact pressures deviating strongly from the\ninertial scaling found for impact in a non-condensable environment, coinciding\nwith the rapid collapse of the vapor pocket entrapped below the disk. We\nexplain our findings, which are relevant for the safe transportation of\ncryogenic fuels, as a result of vapor condensation, leading to accelerated\nvapor pocket contraction at high impact velocity and low vapor density.",
    "pdf_url": "http://arxiv.org/pdf/2505.16668v1",
    "published": "2025-05-22T13:32:42+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.16667v1",
    "title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming",
    "authors": [
      "Xinwei Yang",
      "Zhaofeng Liu",
      "Chen Huang",
      "Jiashuai Zhang",
      "Tong Zhang",
      "Yifan Zhang",
      "Wenqiang Lei"
    ],
    "abstract": "While recent research increasingly emphasizes the value of human-LLM\ncollaboration in competitive programming and proposes numerous empirical\nmethods, a comprehensive understanding remains elusive due to the fragmented\nnature of existing studies and their use of diverse, application-specific human\nfeedback. Thus, our work serves a three-fold purpose: First, we present the\nfirst taxonomy of human feedback consolidating the entire programming process,\nwhich promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a\nnovel programming dataset specifically designed for human-LLM collaboration,\nmeticulously annotated to enable large-scale simulated human feedback and\nfacilitate costeffective real human interaction studies. Third, we introduce\nELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM\ncompetitive programming. With ELABORATION, we pinpoint strengthes and\nweaknesses of existing methods, thereby setting the foundation for future\nimprovement. Our code and dataset are available at\nhttps://github.com/SCUNLP/ELABORATION",
    "pdf_url": "http://arxiv.org/pdf/2505.16667v1",
    "published": "2025-05-22T13:32:39+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16666v1",
    "title": "Morphological stability of Au-metal nanosatellites",
    "authors": [
      "Sofia Zinzani",
      "Robert M. Jones",
      "Mirko Vanzan",
      "Francesca Baletto"
    ],
    "abstract": "Hybrid metallic nanoalloys combining plasmonic and catalytic metals are\nessential for developing advanced photocatalysts. A promising design called\ncore-satellites comprises a spherical nanogold dotted with smaller\ntransition-metal clusters. While these nanoalloys' catalytic activity and\nhot-carriers generation have been extensively studied, their morphological\nstability remains poorly explored. Performing molecular dynamics simulations,\nwe highlight the critical role of the transition metal in governing the\nmorphological stability of plasmonic core-satellites. Rh satellites exhibit the\nhighest stability, while only 27\\% Pt and 16\\% Pd satellites survive after 200\nns at 600K. AuPt and AuPd quickly rearrange into single spherical\nnanostructures. AuPt forms icosahedra with an Au outer shell due to Au's\nsurface diffusion. AuPd favors FCC and decahedral shapes and shows the highest\nAu mobility and significant Pd interdiffusion. In contrast, AuRh maintains its\noriginal shape, exhibiting a slow surface diffusion of gold onto rhodium and\nnegligible mixing.",
    "pdf_url": "http://arxiv.org/pdf/2505.16666v1",
    "published": "2025-05-22T13:29:07+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.16665v1",
    "title": "MDVT: Enhancing Multimodal Recommendation with Model-Agnostic Multimodal-Driven Virtual Triplets",
    "authors": [
      "Jinfeng Xu",
      "Zheyu Chen",
      "Jinze Li",
      "Shuo Yang",
      "Hewei Wang",
      "Yijie Li",
      "Mengran Li",
      "Puzhen Wu",
      "Edith C. H. Ngai"
    ],
    "abstract": "The data sparsity problem significantly hinders the performance of\nrecommender systems, as traditional models rely on limited historical\ninteractions to learn user preferences and item properties. While incorporating\nmultimodal information can explicitly represent these preferences and\nproperties, existing works often use it only as side information, failing to\nfully leverage its potential. In this paper, we propose MDVT, a model-agnostic\napproach that constructs multimodal-driven virtual triplets to provide valuable\nsupervision signals, effectively mitigating the data sparsity problem in\nmultimodal recommendation systems. To ensure high-quality virtual triplets, we\nintroduce three tailored warm-up threshold strategies: static, dynamic, and\nhybrid. The static warm-up threshold strategy exhaustively searches for the\noptimal number of warm-up epochs but is time-consuming and computationally\nintensive. The dynamic warm-up threshold strategy adjusts the warm-up period\nbased on loss trends, improving efficiency but potentially missing optimal\nperformance. The hybrid strategy combines both, using the dynamic strategy to\nfind the approximate optimal number of warm-up epochs and then refining it with\nthe static strategy in a narrow hyper-parameter space. Once the warm-up\nthreshold is satisfied, the virtual triplets are used for joint model\noptimization by our enhanced pair-wise loss function without causing\nsignificant gradient skew. Extensive experiments on multiple real-world\ndatasets demonstrate that integrating MDVT into advanced multimodal\nrecommendation models effectively alleviates the data sparsity problem and\nimproves recommendation performance, particularly in sparse data scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16665v1",
    "published": "2025-05-22T13:28:55+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.12028v1",
    "title": "Rényi-Induced Information Geometry and Hartigan's Prior Family",
    "authors": [
      "Rebecca Maria Kuntz",
      "Heinrich von Campe",
      "Björn Malte Schäfer"
    ],
    "abstract": "We derive the information geometry induced by the statistical R\\'enyi\ndivergence, namely its metric tensor, its dual parametrized connections, as\nwell as its dual Laplacians. Based on these results, we demonstrate that the\nR\\'enyi-geometry, though closely related, differs in structure from Amari's\nwell-known $\\alpha$-geometry. Subsequently, we derive the canonical uniform\nprior distributions for a statistical manifold endowed with a R\\'enyi-geometry,\nnamely the dual R\\'enyi-covolumes. We find that the R\\'enyi-priors can be made\nto coincide with Takeuchi and Amari's $\\alpha$-priors by a reparameterization,\nwhich is itself of particular significance in statistics. Herewith, we\ndemonstrate that Hartigan's parametrized ($\\alpha_H$) family of priors is\nprecisely the parametrized ($\\rho$) family of R\\'enyi-priors ($\\alpha_H =\n\\rho$).",
    "pdf_url": "http://arxiv.org/pdf/2506.12028v1",
    "published": "2025-05-22T13:28:27+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.16664v2",
    "title": "End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries",
    "authors": [
      "Khoa Tran",
      "Tri Le",
      "Bao Huynh",
      "Hung-Cuong Trinh",
      "Vy-Rin Nguyen"
    ],
    "abstract": "Accurate prediction of the Remaining Useful Life (RUL) is essential for\nenabling timely maintenance of lithium-ion batteries, impacting the operational\nefficiency of electric applications that rely on them. This paper proposes a\nRUL prediction approach that leverages data from recent charge-discharge cycles\nto estimate the number of remaining usable cycles. The approach introduces both\na novel signal processing pipeline and a deep learning prediction model. In the\nsignal preprocessing pipeline, a derived capacity feature $\\dot{Q}(I, Q)$ is\ncomputed based on current and capacity signals. Alongside original capacity,\nvoltage and current, these features are denoised and enhanced using statistical\nmetrics and a delta-based method to capture differences between the current and\nprevious cycles. In the prediction model, the processed features are then fed\ninto a hybrid deep learning architecture composed of 1D Convolutional Neural\nNetworks (CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary\nDifferential Equation-based LSTM (ODE-LSTM) blocks. This architecture is\ndesigned to capture both local signal characteristics and long-range temporal\ndependencies while modeling the continuous-time dynamics of battery\ndegradation. The model is further evaluated using transfer learning across\ndifferent learning strategies and target data partitioning scenarios. Results\nindicate that the model maintains robust performance, even when fine-tuned on\nlimited target data. Experimental results on two publicly available large-scale\ndatasets demonstrate that the proposed method outperforms a baseline deep\nlearning approach and machine learning techniques, achieving an RMSE of 101.59,\nhighlighting its strong potential for real-world RUL prediction applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16664v2",
    "published": "2025-05-22T13:28:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16663v1",
    "title": "CoNav: Collaborative Cross-Modal Reasoning for Embodied Navigation",
    "authors": [
      "Haihong Hao",
      "Mingfei Han",
      "Changlin Li",
      "Zhihui Li",
      "Xiaojun Chang"
    ],
    "abstract": "Embodied navigation demands comprehensive scene understanding and precise\nspatial reasoning. While image-text models excel at interpreting pixel-level\ncolor and lighting cues, 3D-text models capture volumetric structure and\nspatial relationships. However, unified fusion approaches that jointly fuse 2D\nimages, 3D point clouds, and textual instructions face challenges in limited\navailability of triple-modality data and difficulty resolving conflicting\nbeliefs among modalities. In this work, we introduce CoNav, a collaborative\ncross-modal reasoning framework where a pretrained 3D-text model explicitly\nguides an image-text navigation agent by providing structured spatial-semantic\nknowledge to resolve ambiguities during navigation. Specifically, we introduce\nCross-Modal Belief Alignment, which operationalizes this cross-modal guidance\nby simply sharing textual hypotheses from the 3D-text model to the navigation\nagent. Through lightweight fine-tuning on a small 2D-3D-text corpus, the\nnavigation agent learns to integrate visual cues with spatial-semantic\nknowledge derived from the 3D-text model, enabling effective reasoning in\nembodied navigation. CoNav achieves significant improvements on four standard\nembodied navigation benchmarks (R2R, CVDN, REVERIE, SOON) and two spatial\nreasoning benchmarks (ScanQA, SQA3D). Moreover, under close navigation Success\nRate, CoNav often generates shorter paths compared to other methods (as\nmeasured by SPL), showcasing the potential and challenges of fusing data from\ndifferent modalities in embodied navigation. Project Page:\nhttps://oceanhao.github.io/CoNav/",
    "pdf_url": "http://arxiv.org/pdf/2505.16663v1",
    "published": "2025-05-22T13:27:54+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16662v2",
    "title": "Joint Magnetometer-IMU Calibration via Maximum A Posteriori Estimation",
    "authors": [
      "Chuan Huang",
      "Gustaf Hendeby",
      "Isaac Skog"
    ],
    "abstract": "This paper presents a new approach for jointly calibrating magnetometers and\ninertial measurement units, focusing on improving calibration accuracy and\ncomputational efficiency. The proposed method formulates the calibration\nproblem as a maximum a posteriori estimation problem, treating both the\ncalibration parameters and orientation trajectory of the sensors as unknowns.\nThis formulation enables efficient optimization with closed-form derivatives.\nThe method is compared against two state-of-the-art approaches in terms of\ncomputational complexity and estimation accuracy. Simulation results\ndemonstrate that the proposed method achieves lower root mean square error in\ncalibration parameters while maintaining competitive computational efficiency.\nFurther validation through real-world experiments confirms the practical\nbenefits of our approach: it effectively reduces position drift in a magnetic\nfield-aided inertial navigation system by more than a factor of two on most\ndatasets. Moreover, the proposed method calibrated 30 magnetometers in less\nthan 2 minutes. The contributions include a new calibration method, an analysis\nof existing methods, and a comprehensive empirical evaluation. Datasets and\nalgorithms are made publicly available to promote reproducible research.",
    "pdf_url": "http://arxiv.org/pdf/2505.16662v2",
    "published": "2025-05-22T13:27:42+00:00",
    "categories": [
      "cs.RO",
      "eess.SP"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16661v2",
    "title": "A Japanese Language Model and Three New Evaluation Benchmarks for Pharmaceutical NLP",
    "authors": [
      "Shinnosuke Ono",
      "Issey Sukeda",
      "Takuro Fujii",
      "Kosei Buma",
      "Shunsuke Sasaki"
    ],
    "abstract": "We present a Japanese domain-specific language model for the pharmaceutical\nfield, developed through continual pretraining on 2 billion Japanese\npharmaceutical tokens and 8 billion English biomedical tokens. To enable\nrigorous evaluation, we introduce three new benchmarks: YakugakuQA, based on\nnational pharmacist licensing exams; NayoseQA, which tests cross-lingual\nsynonym and terminology normalization; and SogoCheck, a novel task designed to\nassess consistency reasoning between paired statements. We evaluate our model\nagainst both open-source medical LLMs and commercial models, including GPT-4o.\nResults show that our domain-specific model outperforms existing open models\nand achieves competitive performance with commercial ones, particularly on\nterminology-heavy and knowledge-based tasks. Interestingly, even GPT-4o\nperforms poorly on SogoCheck, suggesting that cross-sentence consistency\nreasoning remains an open challenge. Our benchmark suite offers a broader\ndiagnostic lens for pharmaceutical NLP, covering factual recall, lexical\nvariation, and logical consistency. This work demonstrates the feasibility of\nbuilding practical, secure, and cost-effective language models for Japanese\ndomain-specific applications, and provides reusable evaluation resources for\nfuture research in pharmaceutical and healthcare NLP. Our model, codes, and\ndatasets are released at https://github.com/EQUES-Inc/pharma-LLM-eval.",
    "pdf_url": "http://arxiv.org/pdf/2505.16661v2",
    "published": "2025-05-22T13:27:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16660v3",
    "title": "Can reasoning models comprehend mathematical problems in Chinese ancient texts? An empirical study based on data from Suanjing Shishu",
    "authors": [
      "Chang Liu",
      "Dongbo Wang",
      "Liu liu",
      "Zhixiao Zhao"
    ],
    "abstract": "This study addresses the challenges in intelligent processing of Chinese\nancient mathematical classics by constructing Guji_MATH, a benchmark for\nevaluating classical texts based on Suanjing Shishu. It systematically assesses\nthe mathematical problem-solving capabilities of mainstream reasoning models\nunder the unique linguistic constraints of classical Chinese. Through\nmachine-assisted annotation and manual verification, 538 mathematical problems\nwere extracted from 8 canonical texts, forming a structured dataset centered on\nthe \"Question-Answer-Solution\" framework, supplemented by problem types and\ndifficulty levels. Dual evaluation modes--closed-book (autonomous\nproblem-solving) and open-book (reproducing classical solution methods)--were\ndesigned to evaluate the performance of six reasoning models on ancient Chinese\nmathematical problems. Results indicate that reasoning models can partially\ncomprehend and solve these problems, yet their overall performance remains\ninferior to benchmarks on modern mathematical tasks. Enhancing models'\nclassical Chinese comprehension and cultural knowledge should be prioritized\nfor optimization. This study provides methodological support for mining\nmathematical knowledge from ancient texts and disseminating traditional\nculture, while offering new perspectives for evaluating cross-linguistic and\ncross-cultural capabilities of reasoning models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16660v3",
    "published": "2025-05-22T13:24:52+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16659v1",
    "title": "SD-MAD: Sign-Driven Few-shot Multi-Anomaly Detection in Medical Images",
    "authors": [
      "Kaiyu Guo",
      "Tan Pan",
      "Chen Jiang",
      "Zijian Wang",
      "Brian C. Lovell",
      "Limei Han",
      "Yuan Cheng",
      "Mahsa Baktashmotlagh"
    ],
    "abstract": "Medical anomaly detection (AD) is crucial for early clinical intervention,\nyet it faces challenges due to limited access to high-quality medical imaging\ndata, caused by privacy concerns and data silos. Few-shot learning has emerged\nas a promising approach to alleviate these limitations by leveraging the\nlarge-scale prior knowledge embedded in vision-language models (VLMs). Recent\nadvancements in few-shot medical AD have treated normal and abnormal cases as a\none-class classification problem, often overlooking the distinction among\nmultiple anomaly categories. Thus, in this paper, we propose a framework\ntailored for few-shot medical anomaly detection in the scenario where the\nidentification of multiple anomaly categories is required. To capture the\ndetailed radiological signs of medical anomaly categories, our framework\nincorporates diverse textual descriptions for each category generated by a\nLarge-Language model, under the assumption that different anomalies in medical\nimages may share common radiological signs in each category. Specifically, we\nintroduce SD-MAD, a two-stage Sign-Driven few-shot Multi-Anomaly Detection\nframework: (i) Radiological signs are aligned with anomaly categories by\namplifying inter-anomaly discrepancy; (ii) Aligned signs are selected further\nto mitigate the effect of the under-fitting and uncertain-sample issue caused\nby limited medical data, employing an automatic sign selection strategy at\ninference. Moreover, we propose three protocols to comprehensively quantify the\nperformance of multi-anomaly detection. Extensive experiments illustrate the\neffectiveness of our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.16659v1",
    "published": "2025-05-22T13:24:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16658v2",
    "title": "Zero-Shot Hyperspectral Pansharpening Using Hysteresis-Based Tuning for Spectral Quality Control",
    "authors": [
      "Giuseppe Guarino",
      "Matteo Ciotola",
      "Gemine Vivone",
      "Giovanni Poggi",
      "Giuseppe Scarpa"
    ],
    "abstract": "Hyperspectral pansharpening has received much attention in recent years due\nto technological and methodological advances that open the door to new\napplication scenarios. However, research on this topic is only now gaining\nmomentum. The most popular methods are still borrowed from the more mature\nfield of multispectral pansharpening and often overlook the unique challenges\nposed by hyperspectral data fusion, such as i) the very large number of bands,\nii) the overwhelming noise in selected spectral ranges, iii) the significant\nspectral mismatch between panchromatic and hyperspectral components, iv) a\ntypically high resolution ratio. Imprecise data modeling especially affects\nspectral fidelity. Even state-of-the-art methods perform well in certain\nspectral ranges and much worse in others, failing to ensure consistent quality\nacross all bands, with the risk of generating unreliable results. Here, we\npropose a hyperspectral pansharpening method that explicitly addresses this\nproblem and ensures uniform spectral quality. To this end, a single lightweight\nneural network is used, with weights that adapt on the fly to each band. During\nfine-tuning, the spatial loss is turned on and off to ensure a fast convergence\nof the spectral loss to the desired level, according to a hysteresis-like\ndynamic. Furthermore, the spatial loss itself is appropriately redefined to\naccount for nonlinear dependencies between panchromatic and spectral bands.\nOverall, the proposed method is fully unsupervised, with no prior training on\nexternal data, flexible, and low-complexity. Experiments on a recently\npublished benchmarking toolbox show that it ensures excellent sharpening\nquality, competitive with the state-of-the-art, consistently across all bands.\nThe software code and the full set of results are shared online on\nhttps://github.com/giu-guarino/rho-PNN.",
    "pdf_url": "http://arxiv.org/pdf/2505.16658v2",
    "published": "2025-05-22T13:24:24+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17157v1",
    "title": "Sharp bounds for the growth and distortion of the analytic part of convex K-quasiconformal harmonic mappings",
    "authors": [
      "Peijin Li",
      "Saminathan Ponnusamy"
    ],
    "abstract": "The main aim of this paper is to obtain the sharp upper and lower bounds for\nthe growth and distortion of the analytic part $h$ of sense-preserving convex\n$K$-quasiconformal harmonic mappings.",
    "pdf_url": "http://arxiv.org/pdf/2505.17157v1",
    "published": "2025-05-22T13:24:11+00:00",
    "categories": [
      "math.CV"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16657v1",
    "title": "Effect of spark plasma sintering on the superconducting properties of Sm-based oxypnictide",
    "authors": [
      "Mohammad Azam",
      "Tatiana Zajarniuk",
      "Konrad Kwatek",
      "Paolo Mele",
      "Shiv J. Singh"
    ],
    "abstract": "We optimize the superconducting properties of Sm-based oxypnictide (Sm1111:\nSmFeAsO0.80F0.20) by using the Spark Plasma Sintering (SPS) technique under\nvarious synthesis conditions, including heating temperatures ranging from 600\nto 1000 {\\deg}C for durations of 5 to 30 minutes at the applied pressure of 45\nMPa. All prepared bulks are characterized by structural and microstructural\nanalysis as well as transport and magnetic measurements to conclude our\nfindings. SmFeAsO0.80F0.20 bulks are also prepared using the conventional\nsynthesis process at ambient pressure (CSP) and the high gas pressure and high\ntemperature (HP-HTS) methods at 500 MPa, which exhibit a superconducting\ntransition temperature (Tc) of ~54 K. Interestingly, the SPS process of\nSmFeAsO0.80F0.20 increases the sample densities up to 97-98% and confirms the\noptimized synthesis conditions of 900{\\deg}C for 5-10 min; however, the\nincreased sintering temperature or duration reduces Tc due to the possible\nevaporation of lighter elements, particularly fluorine. Furthermore, the SPS\ntechnique is unable to reduce the observed impurity phases for the Sm1111,\nwhich is similar to the CSP and HP-HTS processes. A slight increment in the Jc\nby the SPS process is observed due to the enhancement of sample density. A\ncomparative analysis of Sm1111 superconductors prepared by SPS is performed\nwith CSP and HP-HTS processes, suggesting that an increased sample density is\nineffective on the superconducting properties in the presence of the impurity\nphases. This finding can be beneficial for the fundamental and applied research\nof iron-based superconductor (FBS).",
    "pdf_url": "http://arxiv.org/pdf/2505.16657v1",
    "published": "2025-05-22T13:23:12+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.16656v1",
    "title": "Statistical analysis of level spacing ratios in pseudo-integrable systems: semi-Poisson insight and beyond",
    "authors": [
      "Afshin Akhshani",
      "Małgorzata Białous",
      "Leszek Sirko"
    ],
    "abstract": "We studied the statistical properties of a quantum system in the\npseudo-integrable regime through the gap ratios between consecutive energy\nlevels of the scattering spectra. A two-dimensional quantum billiard containing\na point-like (zero-range) perturbation was experimentally simulated by a flat\nrectangular resonator with wire antennas. We show that the system exhibits\nsemi-Poisson behavior in the frequency range $8 <\\nu < 16 $ GHz. The\nprobability distribution $P(r)$ of the studied system is characterized by the\nparameter $\\xi=0.97 \\pm 0.03 $, with the expected value $\\xi=1$ for the\nshort-range plasma model. Furthermore, we provide a theoretical expression for\nthe higher-order non-overlapping probability distribution\n$P_{\\mathrm{sP}}^k(r)$, $k \\geq 1$, in the semi-Poisson regime, incorporating\nlong-range spectral correlations between levels. The experimental and numerical\nresults confirm the pseudo-integrability of the studied system. The\nsemi-Poisson ensemble, for $k=2$, approaches the GUE distribution. In addition,\nthe uncorrelated Poisson statistics mimic the RMT ensembles at certain $k$\nvalues, $k=4$ for GUE and $k=7$ for GSE. This unexpected scale-dependent\nconvergence shows how spectral statistics can exhibit chaos-like features even\nin non-chaotic systems, suggesting that scale-dependent analysis bridges\nintegrable and chaotic regimes.",
    "pdf_url": "http://arxiv.org/pdf/2505.16656v1",
    "published": "2025-05-22T13:22:37+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16655v1",
    "title": "Sampling and equidistribution theorems for elliptic second order operators, lifting of eigenvalues, and applications",
    "authors": [
      "Martin Tautenhahn",
      "Ivan Veselic"
    ],
    "abstract": "We consider elliptic second order partial differential operators with\nLipschitz continuous leading order coefficients on finite cubes and the whole\nEuclidean space. We prove quantitative sampling and equidistribution theorems\nfor eigenfunctions. The estimates are scale-free, in the sense that for a\nsequence of growing cubes we obtain uniform estimates. These results are\napplied to prove lifting of eigenvalues as well as the infimum of the essential\nspectrum, and an uncertainty relation (aka spectral inequality) for short\nenergy interval spectral projectors. Several application including random\noperators are discussed. In the proof we have to overcome several challenges\nposed by the variable coefficients of the leading term.",
    "pdf_url": "http://arxiv.org/pdf/2505.16655v1",
    "published": "2025-05-22T13:21:28+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "math.OC"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16654v1",
    "title": "Optimising the decision threshold in a weighted voting system: The case of the IMF's Board of Governors",
    "authors": [
      "Dóra Gréta Petróczy"
    ],
    "abstract": "In a weighted majority voting game, the players' weights are determined based\non the decision-maker's intentions. The weights are challenging to change in\nnumerous cases, as they represent some desired disparity. However, the voting\nweights and the actual voting power do not necessarily coincide. Changing a\ndecision threshold would offer some remedy. The International Monetary Fund\n(IMF) is one of the most important international organisations that uses a\nweighted voting system to make decisions. The voting weights in its Board of\nGovernors depend on the quotas of the 191 member countries, which reflect their\neconomic strengths to some extent. We analyse the connection between the\ndecision threshold and the a priori voting power of the countries by\ncalculating the Banzhaf indices for each threshold between 50% and 87\\%. The\ndifference between the quotas and voting powers is minimised if the decision\nthreshold is 58% or 60%.",
    "pdf_url": "http://arxiv.org/pdf/2505.16654v1",
    "published": "2025-05-22T13:21:23+00:00",
    "categories": [
      "econ.GN",
      "cs.CY",
      "math.OC",
      "q-fin.EC",
      "91A80, 91B12"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.16653v2",
    "title": "Very persistent random walkers reveal transitions in landscape topology",
    "authors": [
      "Jaron Kent-Dobias"
    ],
    "abstract": "We study the typical behavior of random walkers on the microcanonical\nconfiguration space of mean-field disordered systems. Passive walks have an\nergodicity-breaking transition at precisely the energy density associated with\nthe dynamical glass transition, but persistent walks remain ergodic at lower\nenergies. In models where the energy landscape is thoroughly understood, we\nshow that, in the limit of infinite persistence time, the ergodicity-breaking\ntransition coincides with a transition in the topology of microcanonical\nconfiguration space. We conjecture that this correspondence generalizes to\nother models, and use it to determine the topological transition energy in\nsituations where the landscape properties are ambiguous.",
    "pdf_url": "http://arxiv.org/pdf/2505.16653v2",
    "published": "2025-05-22T13:20:47+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.16652v2",
    "title": "Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding",
    "authors": [
      "Feilong Tang",
      "Chengzhi Liu",
      "Zhongxing Xu",
      "Ming Hu",
      "Zelin Peng",
      "Zhiwei Yang",
      "Jionglong Su",
      "Minquan Lin",
      "Yifan Peng",
      "Xuelian Cheng",
      "Imran Razzak",
      "Zongyuan Ge"
    ],
    "abstract": "Recent advancements in multimodal large language models (MLLMs) have\nsignificantly improved performance in visual question answering. However, they\noften suffer from hallucinations. In this work, hallucinations are categorized\ninto two main types: initial hallucinations and snowball hallucinations. We\nargue that adequate contextual information can be extracted directly from the\ntoken interaction process. Inspired by causal inference in the decoding\nstrategy, we propose to leverage causal masks to establish information\npropagation between multimodal tokens. The hypothesis is that insufficient\ninteraction between those tokens may lead the model to rely on outlier tokens,\noverlooking dense and rich contextual cues. Therefore, we propose to intervene\nin the propagation process by tackling outlier tokens to enhance in-context\ninference. With this goal, we present FarSight, a versatile plug-and-play\ndecoding strategy to reduce attention interference from outlier tokens merely\nby optimizing the causal mask. The heart of our method is effective token\npropagation. We design an attention register structure within the upper\ntriangular matrix of the causal mask, dynamically allocating attention to\ncapture attention diverted to outlier tokens. Moreover, a positional awareness\nencoding method with a diminishing masking rate is proposed, allowing the model\nto attend to further preceding tokens, especially for video sequence tasks.\nWith extensive experiments, FarSight demonstrates significant\nhallucination-mitigating performance across different MLLMs on both image and\nvideo benchmarks, proving its effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.16652v2",
    "published": "2025-05-22T13:19:57+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16651v1",
    "title": "Risk-averse formulations of Stochastic Optimal Control and Markov Decision Processes",
    "authors": [
      "Alexander Shapiro",
      "Yan Li"
    ],
    "abstract": "The aim of this paper is to investigate risk-averse and distributionally\nrobust modeling of Stochastic Optimal Control (SOC) and Markov Decision Process\n(MDP). We discuss construction of conditional nested risk functionals, a\nparticular attention is given to the Value-at-Risk measure. Necessary and\nsufficient conditions for existence of non-randomized optimal policies in the\nframework of robust SOC and MDP are derived. We also investigate sample\ncomplexity of optimization problems involving the Value-at-Risk measure.",
    "pdf_url": "http://arxiv.org/pdf/2505.16651v1",
    "published": "2025-05-22T13:19:35+00:00",
    "categories": [
      "math.OC",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16650v1",
    "title": "Unsupervised Network Anomaly Detection with Autoencoders and Traffic Images",
    "authors": [
      "Michael Neri",
      "Sara Baldoni"
    ],
    "abstract": "Due to the recent increase in the number of connected devices, the need to\npromptly detect security issues is emerging. Moreover, the high number of\ncommunication flows creates the necessity of processing huge amounts of data.\nFurthermore, the connected devices are heterogeneous in nature, having\ndifferent computational capacities. For this reason, in this work we propose an\nimage-based representation of network traffic which allows to realize a compact\nsummary of the current network conditions with 1-second time windows. The\nproposed representation highlights the presence of anomalies thus reducing the\nneed for complex processing architectures. Finally, we present an unsupervised\nlearning approach which effectively detects the presence of anomalies. The code\nand the dataset are available at\nhttps://github.com/michaelneri/image-based-network-traffic-anomaly-detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.16650v1",
    "published": "2025-05-22T13:19:30+00:00",
    "categories": [
      "cs.CV",
      "cs.CR",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16649v1",
    "title": "Stochastic Forward-Forward Learning through Representational Dimensionality Compression",
    "authors": [
      "Zhichao Zhu",
      "Yang Qi",
      "Hengyuan Ma",
      "Wenlian Lu",
      "Jianfeng Feng"
    ],
    "abstract": "The Forward-Forward (FF) algorithm provides a bottom-up alternative to\nbackpropagation (BP) for training neural networks, relying on a layer-wise\n\"goodness\" function to guide learning. Existing goodness functions, inspired by\nenergy-based learning (EBL), are typically defined as the sum of squared\npost-synaptic activations, neglecting the correlations between neurons. In this\nwork, we propose a novel goodness function termed dimensionality compression\nthat uses the effective dimensionality (ED) of fluctuating neural responses to\nincorporate second-order statistical structure. Our objective minimizes ED for\nclamped inputs when noise is considered while maximizing it across the sample\ndistribution, promoting structured representations without the need to prepare\nnegative samples. We demonstrate that this formulation achieves competitive\nperformance compared to other non-BP methods. Moreover, we show that noise\nplays a constructive role that can enhance generalization and improve inference\nwhen predictions are derived from the mean of squared outputs, which is\nequivalent to making predictions based on the energy term. Our findings\ncontribute to the development of more biologically plausible learning\nalgorithms and suggest a natural fit for neuromorphic computing, where\nstochasticity is a computational resource rather than a nuisance. The code is\navailable at https://github.com/ZhichaoZhu/StochasticForwardForward",
    "pdf_url": "http://arxiv.org/pdf/2505.16649v1",
    "published": "2025-05-22T13:19:29+00:00",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16648v1",
    "title": "Collaboration among Multiple Large Language Models for Medical Question Answering",
    "authors": [
      "Kexin Shang",
      "Chia-Hsuan Chang",
      "Christopher C. Yang"
    ],
    "abstract": "Empowered by vast internal knowledge reservoir, the new generation of large\nlanguage models (LLMs) demonstrate untapped potential to tackle medical tasks.\nHowever, there is insufficient effort made towards summoning up a synergic\neffect from multiple LLMs' expertise and background. In this study, we propose\na multi-LLM collaboration framework tailored on a medical multiple-choice\nquestions dataset. Through post-hoc analysis on 3 pre-trained LLM participants,\nour framework is proved to boost all LLMs reasoning ability as well as\nalleviate their divergence among questions. We also measure an LLM's confidence\nwhen it confronts with adversary opinions from other LLMs and observe a\nconcurrence between LLM's confidence and prediction accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16648v1",
    "published": "2025-05-22T13:18:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16647v1",
    "title": "Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models",
    "authors": [
      "Sushant Gautam",
      "Michael A. Riegler",
      "Pål Halvorsen"
    ],
    "abstract": "We investigate fine-tuning Vision-Language Models (VLMs) for multi-task\nmedical image understanding, focusing on detection, localization, and counting\nof findings in medical images. Our objective is to evaluate whether\ninstruction-tuned VLMs can simultaneously improve these tasks, with the goal of\nenhancing diagnostic accuracy and efficiency. Using MedMultiPoints, a\nmultimodal dataset with annotations from endoscopy (polyps and instruments) and\nmicroscopy (sperm cells), we reformulate each task into instruction-based\nprompts suitable for vision-language reasoning. We fine-tune\nQwen2.5-VL-7B-Instruct using Low-Rank Adaptation (LoRA) across multiple task\ncombinations. Results show that multi-task training improves robustness and\naccuracy. For example, it reduces the Count Mean Absolute Error (MAE) and\nincreases Matching Accuracy in the Counting + Pointing task. However,\ntrade-offs emerge, such as more zero-case point predictions, indicating reduced\nreliability in edge cases despite overall performance gains. Our study\nhighlights the potential of adapting general-purpose VLMs to specialized\nmedical tasks via prompt-driven fine-tuning. This approach mirrors clinical\nworkflows, where radiologists simultaneously localize, count, and describe\nfindings - demonstrating how VLMs can learn composite diagnostic reasoning\npatterns. The model produces interpretable, structured outputs, offering a\npromising step toward explainable and versatile medical AI. Code, model\nweights, and scripts will be released for reproducibility at\nhttps://github.com/simula/PointDetectCount.",
    "pdf_url": "http://arxiv.org/pdf/2505.16647v1",
    "published": "2025-05-22T13:18:44+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45, 68T07",
      "I.2.10; I.4.8"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16646v3",
    "title": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving",
    "authors": [
      "Yujie Hou",
      "Ting Zhang",
      "Mei Wang",
      "Xuetao Ma",
      "Hua Huang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable results on a variety of\nmathematical benchmarks. However, concerns remain as to whether these successes\nreflect genuine reasoning or superficial pattern recognition. Common evaluation\nmethods, which focus on the either the final answer or the reasoning process,\nfail to assess the entire problem-solving procedure. To address these\nlimitations, we introduce SMART: a Self-Generating and Self-Validating\nMulti-Dimensional Assessment Framework, together with its corresponding\nbenchmark, SMART-Bench. SMART decomposes the entire problem solving process\ninto four distinct cognitive dimensions: Understanding, Reasoning, Arithmetic,\nand Reflection \\& Refinement. Each dimension is evaluated independently through\ntailored tasks, enabling interpretable and fine-grained analysis of LLM\nbehavior. We apply SMART to 21 state-of-the-art open- and closed-source LLMs,\nuncovering significant discrepancies in their abilities across different\ndimensions. Our findings reveal genuine weaknesses in current LLMs and motivate\na new metric, the All-Pass Score, to better capture true problem-solving\ncapabilities. Code and benchmarks will be released upon acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2505.16646v3",
    "published": "2025-05-22T13:18:24+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16645v3",
    "title": "Relativistic corrections of order $mα^6$: singular operators and regularization",
    "authors": [
      "Vladimir I Korobov"
    ],
    "abstract": "The finite operators are derived for the nonrecoil (leading order in the\n$(m/M)$ expansion) relativistic corrections in hydrogen-like atoms and ions at\norders $m\\alpha^6$ in the two- and three-body formalism beyond the adiabatic\napproximation. Singular operators that appear in the derivation are analysed,\nand various regularization methods are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.16645v3",
    "published": "2025-05-22T13:17:32+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16644v1",
    "title": "Learning non-equilibrium diffusions with Schrödinger bridges: from exactly solvable to simulation-free",
    "authors": [
      "Stephen Y. Zhang",
      "Michael P H Stumpf"
    ],
    "abstract": "We consider the Schr\\\"odinger bridge problem which, given ensemble\nmeasurements of the initial and final configurations of a stochastic dynamical\nsystem and some prior knowledge on the dynamics, aims to reconstruct the \"most\nlikely\" evolution of the system compatible with the data. Most existing\nliterature assume Brownian reference dynamics and are implicitly limited to\npotential-driven dynamics. We depart from this regime and consider reference\nprocesses described by a multivariate Ornstein-Uhlenbeck process with generic\ndrift matrix $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$. When $\\mathbf{A}$ is\nasymmetric, this corresponds to a non-equilibrium system with non-conservative\nforces at play: this is important for applications to biological systems, which\nare naturally exist out-of-equilibrium. In the case of Gaussian marginals, we\nderive explicit expressions that characterise the solution of both the static\nand dynamic Schr\\\"odinger bridge. For general marginals, we propose mvOU-OTFM,\na simulation-free algorithm based on flow and score matching for learning the\nSchr\\\"odinger bridge. In application to a range of problems based on synthetic\nand real single cell data, we demonstrate that mvOU-OTFM achieves higher\naccuracy compared to competing methods, whilst being significantly faster to\ntrain.",
    "pdf_url": "http://arxiv.org/pdf/2505.16644v1",
    "published": "2025-05-22T13:17:30+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "62M45, 49N10"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16643v1",
    "title": "From Evaluation to Defense: Advancing Safety in Video Large Language Models",
    "authors": [
      "Yiwei Sun",
      "Peiqi Jiang",
      "Chuanbin Liu",
      "Luohao Lin",
      "Zhiying Lu",
      "Hongtao Xie"
    ],
    "abstract": "While the safety risks of image-based large language models have been\nextensively studied, their video-based counterparts (Video LLMs) remain\ncritically under-examined. To systematically study this problem, we introduce\n\\textbf{VideoSafetyBench (VSB-77k) - the first large-scale, culturally diverse\nbenchmark for Video LLM safety}, which compromises 77,646 video-query pairs and\nspans 19 principal risk categories across 10 language communities. \\textit{We\nreveal that integrating video modality degrades safety performance by an\naverage of 42.3\\%, exposing systemic risks in multimodal attack exploitation.}\nTo address this vulnerability, we propose \\textbf{VideoSafety-R1}, a dual-stage\nframework achieving unprecedented safety gains through two innovations: (1)\nAlarm Token-Guided Safety Fine-Tuning (AT-SFT) injects learnable alarm tokens\ninto visual and textual sequences, enabling explicit harm perception across\nmodalities via multitask objectives. (2) Then, Safety-Guided GRPO enhances\ndefensive reasoning through dynamic policy optimization with rule-based rewards\nderived from dual-modality verification. These components synergize to shift\nsafety alignment from passive harm recognition to active reasoning. The\nresulting framework achieves a 65.1\\% improvement on VSB-Eval-HH, and improves\nby 59.1\\%, 44.3\\%, and 15.0\\% on the image safety datasets MMBench, VLGuard,\nand FigStep, respectively. \\textit{Our codes are available in the supplementary\nmaterials.} \\textcolor{red}{Warning: This paper contains examples of harmful\nlanguage and videos, and reader discretion is recommended.}",
    "pdf_url": "http://arxiv.org/pdf/2505.16643v1",
    "published": "2025-05-22T13:16:53+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16642v1",
    "title": "On geometric spectral functionals",
    "authors": [
      "Arkadiusz Bochniak",
      "Ludwik Dąbrowski",
      "Andrzej Sitarz",
      "Paweł Zalecki"
    ],
    "abstract": "We investigate spectral functionals associated with Dirac and Laplace-type\ndifferential operators on manifolds, defined via the Wodzicki residue,\nextending classical results for Dirac operators derived from the Levi-Civita\nconnection to geometries with torsion. The local densities of these functionals\nrecover fundamental geometric tensors, including the volume form, Riemannian\nmetric, scalar curvature, Einstein tensor, and torsion tensor. Additionally, we\nintroduce chiral spectral functionals using a grading operator, which yields\nnovel spectral invariants. These constructions offer a richer\nspectral-geometric characterization of manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2505.16642v1",
    "published": "2025-05-22T13:13:04+00:00",
    "categories": [
      "math-ph",
      "gr-qc",
      "math.DG",
      "math.MP",
      "math.SP",
      "58B34, 58J50, 46L87, 83C65"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16641v1",
    "title": "Constraining anti-baryonic dark matter through correlated nucleon decay signatures",
    "authors": [
      "Mathew Thomas Arun",
      "Anuja Bandu Khadse"
    ],
    "abstract": "Baryon number violation in the visible sector induced by anti-baryonic dark\nmatter provides a viable mechanism for low-scale baryogenesis. Two of the most\nsensitive probes of this scenario are neutron decay processes such as $n \\to\n\\text{invisible}$ and $n \\to \\pi^0 + \\text{invisible}$. In this work, we\ndiscuss the generation of di-nucleon decay processes such as $nn \\to\n\\bar{\\nu}\\bar{\\nu}$ and $nn \\to \\pi^0\\pi^0$ at one-loop, arising from the\noperators responsible for induced nucleon decays. While nucleon decay rates in\nthis model depend on the local dark matter density, di-nucleon decay processes\ndo not, providing a complementary probe of the new physics. We thus use bounds\non both nucleon and di-nucleon decays to constrain the mass and terrestrial\ndensity of anti-baryonic dark matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.16641v1",
    "published": "2025-05-22T13:12:51+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16640v1",
    "title": "BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization",
    "authors": [
      "Xueyang Zhou",
      "Guiyao Tie",
      "Guowen Zhang",
      "Hechang Wang",
      "Pan Zhou",
      "Lichao Sun"
    ],
    "abstract": "Vision-Language-Action (VLA) models have advanced robotic control by enabling\nend-to-end decision-making directly from multimodal inputs. However, their\ntightly coupled architectures expose novel security vulnerabilities. Unlike\ntraditional adversarial perturbations, backdoor attacks represent a stealthier,\npersistent, and practically significant threat-particularly under the emerging\nTraining-as-a-Service paradigm-but remain largely unexplored in the context of\nVLA models. To address this gap, we propose BadVLA, a backdoor attack method\nbased on Objective-Decoupled Optimization, which for the first time exposes the\nbackdoor vulnerabilities of VLA models. Specifically, it consists of a\ntwo-stage process: (1) explicit feature-space separation to isolate trigger\nrepresentations from benign inputs, and (2) conditional control deviations that\nactivate only in the presence of the trigger, while preserving clean-task\nperformance. Empirical results on multiple VLA benchmarks demonstrate that\nBadVLA consistently achieves near-100% attack success rates with minimal impact\non clean task accuracy. Further analyses confirm its robustness against common\ninput perturbations, task transfers, and model fine-tuning, underscoring\ncritical security vulnerabilities in current VLA deployments. Our work offers\nthe first systematic investigation of backdoor vulnerabilities in VLA models,\nhighlighting an urgent need for secure and trustworthy embodied model design\npractices. We have released the project page at\nhttps://badvla-project.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.16640v1",
    "published": "2025-05-22T13:12:46+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "68T07",
      "I.2.6; I.2.9"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16639v1",
    "title": "Soft Factor Structure of MHV Amplitudes for Massless Charged Particles",
    "authors": [
      "Christoph Bartsch",
      "Karol Kampf",
      "David Podivín"
    ],
    "abstract": "We present a simple derivation of MHV amplitudes in massless spinor and\nscalar electrodynamics. Working with permutationally invariant amplitudes, we\nshow that they are fully determined by their soft photon behavior and admit a\nsimple factorized form in terms of soft factors and lower-point amplitudes. We\nprove these formulae using recursion relations. Finally, we consider possible\nextensions of these results by looking at supersymmetric theories, amplitudes\nbeyond the MHV sector, gravity, and theories with charged particles of higher\nspins.",
    "pdf_url": "http://arxiv.org/pdf/2505.16639v1",
    "published": "2025-05-22T13:11:39+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16638v2",
    "title": "Reconsidering Fairness Through Unawareness From the Perspective of Model Multiplicity",
    "authors": [
      "Benedikt Höltgen",
      "Nuria Oliver"
    ],
    "abstract": "Fairness through Unawareness (FtU) describes the idea that discrimination\nagainst demographic groups can be avoided by not considering group membership\nin the decisions or predictions. This idea has long been criticized in the\nmachine learning literature as not being sufficient to ensure fairness. In\naddition, the use of additional features is typically thought to increase the\naccuracy of the predictions for all groups, so that FtU is sometimes thought to\nbe detrimental to all groups. In this paper, we show both theoretically and\nempirically that FtU can reduce algorithmic discrimination without necessarily\nreducing accuracy. We connect this insight with the literature on Model\nMultiplicity, to which we contribute with novel theoretical and empirical\nresults. Furthermore, we illustrate how, in a real-life application, FtU can\ncontribute to the deployment of more equitable policies without losing\nefficacy. Our findings suggest that FtU is worth considering in practical\napplications, particularly in high-risk scenarios, and that the use of\nprotected attributes such as gender in predictive models should be accompanied\nby a clear and well-founded justification.",
    "pdf_url": "http://arxiv.org/pdf/2505.16638v2",
    "published": "2025-05-22T13:11:33+00:00",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16637v3",
    "title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation",
    "authors": [
      "Wenjie Yang",
      "Mao Zheng",
      "Mingyang Song",
      "Zheng Li",
      "Sitong Wang"
    ],
    "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities in machine translation (MT). However, most advanced MT-specific\nLLMs heavily rely on external supervision signals during training, such as\nhuman-annotated reference data or trained reward models (RMs), which are often\nexpensive to obtain and challenging to scale. To overcome this limitation, we\npropose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for\nMT that is reference-free, fully online, and relies solely on self-judging\nrewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as\nthe backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs,\ne.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like\nQwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks\nfrom WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR\nwith external supervision from COMET, our strongest model, SSR-X-Zero-7B,\nachieves state-of-the-art performance in English $\\leftrightarrow$ Chinese\ntranslation, surpassing all existing open-source models under 72B parameters\nand even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro.\nOur analysis highlights the effectiveness of the self-rewarding mechanism\ncompared to the external LLM-as-a-judge approach in MT and demonstrates its\ncomplementary benefits when combined with trained RMs. Our findings provide\nvaluable insight into the potential of self-improving RL methods. We have\npublicly released our code, data and models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16637v3",
    "published": "2025-05-22T13:08:25+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16636v1",
    "title": "Multivariate Latent Recalibration for Conditional Normalizing Flows",
    "authors": [
      "Victor Dheur",
      "Souhaib Ben Taieb"
    ],
    "abstract": "Reliably characterizing the full conditional distribution of a multivariate\nresponse variable given a set of covariates is crucial for trustworthy\ndecision-making. However, misspecified or miscalibrated multivariate models may\nyield a poor approximation of the joint distribution of the response variables,\nleading to unreliable predictions and suboptimal decisions. Furthermore,\nstandard recalibration methods are primarily limited to univariate settings,\nwhile conformal prediction techniques, despite generating multivariate\nprediction regions with coverage guarantees, do not provide a full probability\ndensity function. We address this gap by first introducing a novel notion of\nlatent calibration, which assesses probabilistic calibration in the latent\nspace of a conditional normalizing flow. Second, we propose latent\nrecalibration (LR), a novel post-hoc model recalibration method that learns a\ntransformation of the latent space with finite-sample bounds on latent\ncalibration. Unlike existing methods, LR produces a recalibrated distribution\nwith an explicit multivariate density function while remaining computationally\nefficient. Extensive experiments on both tabular and image datasets show that\nLR consistently improves latent calibration error and the negative\nlog-likelihood of the recalibrated models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16636v1",
    "published": "2025-05-22T13:08:20+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16635v1",
    "title": "WikiDBGraph: Large-Scale Database Graph of Wikidata for Collaborative Learning",
    "authors": [
      "Zhaomin Wu",
      "Ziyang Wang",
      "Bingsheng He"
    ],
    "abstract": "Tabular data, ubiquitous and rich in informational value, is an increasing\nfocus for deep representation learning, yet progress is hindered by studies\ncentered on single tables or isolated databases, which limits model\ncapabilities due to data scale. While collaborative learning approaches such as\nfederated learning, transfer learning, split learning, and tabular foundation\nmodels aim to learn from multiple correlated databases, they are challenged by\na scarcity of real-world interconnected tabular resources. Current data lakes\nand corpora largely consist of isolated databases lacking defined\ninter-database correlations. To overcome this, we introduce WikiDBGraph, a\nlarge-scale graph of 100,000 real-world tabular databases from WikiData,\ninterconnected by 17 million edges and characterized by 13 node and 12 edge\nproperties derived from its database schema and data distribution.\nWikiDBGraph's weighted edges identify both instance- and feature-overlapped\ndatabases. Experiments on these newly identified databases confirm that\ncollaborative learning yields superior performance, thereby offering\nconsiderable promise for structured foundation model training while also\nexposing key challenges and future directions for learning from interconnected\ntabular data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16635v1",
    "published": "2025-05-22T13:07:06+00:00",
    "categories": [
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.16634v2",
    "title": "Constructive approach to solution of the conservation condition for conformal higher spin tree-point correlation function with equal spins",
    "authors": [
      "Melik Karapetyan",
      "Ruben Manvelyan"
    ],
    "abstract": "We propose a new constructive approach to the solutions of the conservation\ncondition for the three-point conformal correlation function in the\nOsborn-Petkou formulation generalized by the authors for higher spins. We\npropose for correlation functions of the same spin conformal currents the\ngeneral hypothesis that the Osborn-Petkou structural tensor of higher spins\nsatisfying the right symmetry conditions can be obtained from the combination\nof the principal terms of spin one and two structural tensors raised to the\ndegree corresponding to the value of spin s. We verified this hypothesis for\nthe case of spin three and four and showed that the construction of the\nconserved three-point function can be reduced to the algebraic task of\ncanceling the right hand sides of the divergences of constructed terms.\nMoreover it follows from this consideration that for spin three and four cases\nour solutions can be interpreted as the $CFT$-dual to the cubic interaction in\nthe AdS space with one dimension more.",
    "pdf_url": "http://arxiv.org/pdf/2505.16634v2",
    "published": "2025-05-22T13:05:25+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.17156v1",
    "title": "PersonaBOT: Bringing Customer Personas to Life with LLMs and RAG",
    "authors": [
      "Muhammed Rizwan",
      "Lars Carlsson",
      "Mohammad Loni"
    ],
    "abstract": "The introduction of Large Language Models (LLMs) has significantly\ntransformed Natural Language Processing (NLP) applications by enabling more\nadvanced analysis of customer personas. At Volvo Construction Equipment (VCE),\ncustomer personas have traditionally been developed through qualitative\nmethods, which are time-consuming and lack scalability. The main objective of\nthis paper is to generate synthetic customer personas and integrate them into a\nRetrieval-Augmented Generation (RAG) chatbot to support decision-making in\nbusiness processes. To this end, we first focus on developing a persona-based\nRAG chatbot integrated with verified personas. Next, synthetic personas are\ngenerated using Few-Shot and Chain-of-Thought (CoT) prompting techniques and\nevaluated based on completeness, relevance, and consistency using McNemar's\ntest. In the final step, the chatbot's knowledge base is augmented with\nsynthetic personas and additional segment information to assess improvements in\nresponse accuracy and practical utility. Key findings indicate that Few-Shot\nprompting outperformed CoT in generating more complete personas, while CoT\ndemonstrated greater efficiency in terms of response time and token usage.\nAfter augmenting the knowledge base, the average accuracy rating of the chatbot\nincreased from 5.88 to 6.42 on a 10-point scale, and 81.82% of participants\nfound the updated system useful in business contexts.",
    "pdf_url": "http://arxiv.org/pdf/2505.17156v1",
    "published": "2025-05-22T13:04:34+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16633v1",
    "title": "Towards Texture- And Shape-Independent 3D Keypoint Estimation in Birds",
    "authors": [
      "Valentin Schmuker",
      "Alex Hoi Hang Chan",
      "Bastian Goldluecke",
      "Urs Waldmann"
    ],
    "abstract": "In this paper, we present a texture-independent approach to estimate and\ntrack 3D joint positions of multiple pigeons. For this purpose, we build upon\nthe existing 3D-MuPPET framework, which estimates and tracks the 3D poses of up\nto 10 pigeons using a multi-view camera setup. We extend this framework by\nusing a segmentation method that generates silhouettes of the individuals,\nwhich are then used to estimate 2D keypoints. Following 3D-MuPPET, these 2D\nkeypoints are triangulated to infer 3D poses, and identities are matched in the\nfirst frame and tracked in 2D across subsequent frames. Our proposed\ntexture-independent approach achieves comparable accuracy to the original\ntexture-dependent 3D-MuPPET framework. Additionally, we explore our approach's\napplicability to other bird species. To do that, we infer the 2D joint\npositions of four bird species without additional fine-tuning the model trained\non pigeons and obtain preliminary promising results. Thus, we think that our\napproach serves as a solid foundation and inspires the development of more\nrobust and accurate texture-independent pose estimation frameworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16633v1",
    "published": "2025-05-22T13:04:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16632v1",
    "title": "Homogeneous Convex Foliations of degree 6",
    "authors": [
      "Carla Pracias",
      "Maycol Falla Luza"
    ],
    "abstract": "In this paper, we classify homogeneous convex foliations with $3$ radial\nsingularities. We also obtain the classification of convex homogeneous\nfoliations of degree $6$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16632v1",
    "published": "2025-05-22T13:03:35+00:00",
    "categories": [
      "math.AG",
      "math.CV",
      "math.DS"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16631v1",
    "title": "MiLQ: Benchmarking IR Models for Bilingual Web Search with Mixed Language Queries",
    "authors": [
      "Jonghwi Kim",
      "Deokhyung Kang",
      "Seonjeong Hwang",
      "Yunsu Kim",
      "Jungseul Ok",
      "Gary Lee"
    ],
    "abstract": "Despite bilingual speakers frequently using mixed-language queries in web\nsearches, Information Retrieval (IR) research on them remains scarce. To\naddress this, we introduce MiLQ,Mixed-Language Query test set, the first public\nbenchmark of mixed-language queries, confirmed as realistic and highly\npreferred. Experiments show that multilingual IR models perform moderately on\nMiLQ and inconsistently across native, English, and mixed-language queries,\nalso suggesting code-switched training data's potential for robust IR models\nhandling such queries. Meanwhile, intentional English mixing in queries proves\nan effective strategy for bilinguals searching English documents, which our\nanalysis attributes to enhanced token matching compared to native queries.",
    "pdf_url": "http://arxiv.org/pdf/2505.16631v1",
    "published": "2025-05-22T13:03:15+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16630v1",
    "title": "SoccerChat: Integrating Multimodal Data for Enhanced Soccer Game Understanding",
    "authors": [
      "Sushant Gautam",
      "Cise Midoglu",
      "Vajira Thambawita",
      "Michael A. Riegler",
      "Pål Halvorsen",
      "Mubarak Shah"
    ],
    "abstract": "The integration of artificial intelligence in sports analytics has\ntransformed soccer video understanding, enabling real-time, automated insights\ninto complex game dynamics. Traditional approaches rely on isolated data\nstreams, limiting their effectiveness in capturing the full context of a match.\nTo address this, we introduce SoccerChat, a multimodal conversational AI\nframework that integrates visual and textual data for enhanced soccer video\ncomprehension. Leveraging the extensive SoccerNet dataset, enriched with jersey\ncolor annotations and automatic speech recognition (ASR) transcripts,\nSoccerChat is fine-tuned on a structured video instruction dataset to\nfacilitate accurate game understanding, event classification, and referee\ndecision making. We benchmark SoccerChat on action classification and referee\ndecision-making tasks, demonstrating its performance in general soccer event\ncomprehension while maintaining competitive accuracy in referee decision\nmaking. Our findings highlight the importance of multimodal integration in\nadvancing soccer analytics, paving the way for more interactive and explainable\nAI-driven sports analysis. https://github.com/simula/SoccerChat",
    "pdf_url": "http://arxiv.org/pdf/2505.16630v1",
    "published": "2025-05-22T13:01:51+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45, 68T50",
      "I.2.10; I.2.7; H.5.2"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16629v1",
    "title": "Non-side-to-side tilings of the sphere by congruent triangles with any irrational angle",
    "authors": [
      "Wen Chen",
      "Jinjin Liang",
      "Erxiao Wang"
    ],
    "abstract": "We develop the basic and new tools for classifying non-side-to-side tilings\nof the sphere by congruent triangles. Then we prove that, if the triangle has\nany irrational angle in degree, such tilings are: a sequence of 1-parameter\nfamilies of triangles each admitting many 2-layer earth map tilings with\n$2n$($n\\geq3$) tiles, together with rotational modifications for even $n$; a\n1-parameter family of triangles each admitting a unique tiling with $8$ tiles;\nand a sporadic triangle admitting a unique tiling with $16$ tiles. Then a\nscheme is outlined to classify the case with all angles being rational in\ndegree, justified by some known and new examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.16629v1",
    "published": "2025-05-22T13:00:42+00:00",
    "categories": [
      "math.CO",
      "52C20, 05B45"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16628v1",
    "title": "A model with fragments of projective determinacy and failures of $\\mathsf{DC}$",
    "authors": [
      "Sandra Müller",
      "Bartosz Wcisło"
    ],
    "abstract": "We describe a construction of a model of second order arithmetic in which\n(boldface) $\\bm{\\Pi^1_n}$-determinacy holds, but (lightface)\n$\\Pi^1_{n+2}$-$\\mathsf{DC}$ fails, thus showing that no projective level of\ndeterminacy implies full $\\mathsf{DC}_{\\mathbb{R}}$. The construction builds\nupon the work of Gitman, Friedman, and Kanovei.",
    "pdf_url": "http://arxiv.org/pdf/2505.16628v1",
    "published": "2025-05-22T13:00:29+00:00",
    "categories": [
      "math.LO",
      "03E45, 03E60, 03E30, 03E25, 03E35, 03F35"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16627v1",
    "title": "Tailored Vapor Deposition Unlocks Large-Grain, Wafer-Scale Epitaxial Growth of 2D Magnetic CrCl3",
    "authors": [
      "Vivek Kumar",
      "Abhishek Jangid",
      "Manas Sharma",
      "Manvi Verma",
      "Jampala Pasyanthi",
      "Keerthana S Kumar",
      "Piyush Sharma",
      "Emil O. Chiglintsev",
      "Mikhail I. Panin",
      "Sudeep N. Punnathanam",
      "Alexander I. Chernov",
      "Ananth Govind Rajan",
      "Akshay Singh"
    ],
    "abstract": "Two-dimensional magnetic materials (2D-MM) are an exciting playground for\nfundamental research, and for spintronics and quantum sensing. However, their\nlarge-grain large-area synthesis using scalable vapour deposition methods is\nstill an unsolved challenge. Here, we develop a tailored approach for\ncentimetre-scale growth of semiconducting 2D-MM CrCl3 films on mica substrate,\nvia physical vapour transport deposition. A controlled synthesis protocol,\nenabled via innovations concerning light management, very-high carrier-gas\nflow, precursor flux, and oxygen/moisture removal, is critical for wafer-scale\ngrowth. Optical, stoichiometric, structural, and magnetic characterization\nidentify crystalline, phase-pure 2D-MM CrCl3. Substrate temperature tunes\nthickness of films from few-layers to tens of nanometres. Further,\nselective-area growth and large-area transfer are demonstrated.\nSubstrate-dependent growth features are explained by density functional theory\nand state-of-the-art machine learning interatomic potential-based atomic-scale\nsimulations. This scalable vapour deposition approach can be applied for growth\nof several 2D-MM, and low growth temperature (~500 C) will enable creation of\nhybrid heterostructures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16627v1",
    "published": "2025-05-22T13:00:23+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16626v1",
    "title": "To reset or not to reset in a finite domain: that is the question",
    "authors": [
      "Gregorio García-Valladares",
      "Antonio Prados",
      "Alessandro Manacorda",
      "Carlos A. Plata"
    ],
    "abstract": "We investigate the search of a target with a given spatial distribution in a\nfinite one-dimensional domain. The searcher follows Brownian dynamics and is\nalways reset to its initial position when reaching the boundaries of the domain\n(boundary resetting). In addition, the searcher may be reset to its initial\nposition from any internal point of the domain (bulk resetting). Specifically,\nwe look for the optimal strategy for bulk resetting, i.e., the spatially\ndependent bulk resetting rate that minimizes the average search time. The best\nsearch strategy exhibits a second-order transition from vanishing to\nnon-vanishing bulk resetting when varying the target distribution. The obtained\nmathematical criteria are further analyzed for a monoparametric family of\ndistributions, to shed light on the properties that control the optimal\nstrategy for bulk resetting. Our work paves new research lines in the study of\nsearch processes, emphasizing the relevance of the target distribution for the\noptimal search strategy, and identifies a successful framework to address these\nquestions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16626v1",
    "published": "2025-05-22T13:00:07+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.16625v1",
    "title": "Background Matters: A Cross-view Bidirectional Modeling Framework for Semi-supervised Medical Image Segmentation",
    "authors": [
      "Luyang Cao",
      "Jianwei Li",
      "Yinghuan Shi"
    ],
    "abstract": "Semi-supervised medical image segmentation (SSMIS) leverages unlabeled data\nto reduce reliance on manually annotated images. However, current SOTA\napproaches predominantly focus on foreground-oriented modeling (i.e.,\nsegmenting only the foreground region) and have largely overlooked the\npotential benefits of explicitly modeling the background region. Our study\ntheoretically and empirically demonstrates that highly certain predictions in\nbackground modeling enhance the confidence of corresponding foreground\nmodeling. Building on this insight, we propose the Cross-view Bidirectional\nModeling (CVBM) framework, which introduces a novel perspective by\nincorporating background modeling to improve foreground modeling performance.\nWithin CVBM, background modeling serves as an auxiliary perspective, providing\ncomplementary supervisory signals to enhance the confidence of the foreground\nmodel. Additionally, CVBM introduces an innovative bidirectional consistency\nmechanism, which ensures mutual alignment between foreground predictions and\nbackground-guided predictions. Extensive experiments demonstrate that our\napproach achieves SOTA performance on the LA, Pancreas, ACDC, and HRF datasets.\nNotably, on the Pancreas dataset, CVBM outperforms fully supervised methods\n(i.e., DSC: 84.57% vs. 83.89%) while utilizing only 20% of the labeled data.\nOur code is publicly available at https://github.com/caoluyang0830/CVBM.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.16625v1",
    "published": "2025-05-22T12:59:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16624v1",
    "title": "Grounding Chest X-Ray Visual Question Answering with Generated Radiology Reports",
    "authors": [
      "Francesco Dalla Serra",
      "Patrick Schrempf",
      "Chaoyang Wang",
      "Zaiqiao Meng",
      "Fani Deligianni",
      "Alison Q. O'Neil"
    ],
    "abstract": "We present a novel approach to Chest X-ray (CXR) Visual Question Answering\n(VQA), addressing both single-image image-difference questions. Single-image\nquestions focus on abnormalities within a specific CXR (\"What abnormalities are\nseen in image X?\"), while image-difference questions compare two longitudinal\nCXRs acquired at different time points (\"What are the differences between image\nX and Y?\"). We further explore how the integration of radiology reports can\nenhance the performance of VQA models. While previous approaches have\ndemonstrated the utility of radiology reports during the pre-training phase, we\nextend this idea by showing that the reports can also be leveraged as\nadditional input to improve the VQA model's predicted answers. First, we\npropose a unified method that handles both types of questions and\nauto-regressively generates the answers. For single-image questions, the model\nis provided with a single CXR. For image-difference questions, the model is\nprovided with two CXRs from the same patient, captured at different time\npoints, enabling the model to detect and describe temporal changes. Taking\ninspiration from 'Chain-of-Thought reasoning', we demonstrate that performance\non the CXR VQA task can be improved by grounding the answer generator module\nwith a radiology report predicted for the same CXR. In our approach, the VQA\nmodel is divided into two steps: i) Report Generation (RG) and ii) Answer\nGeneration (AG). Our results demonstrate that incorporating predicted radiology\nreports as evidence to the AG model enhances performance on both single-image\nand image-difference questions, achieving state-of-the-art results on the\nMedical-Diff-VQA dataset.",
    "pdf_url": "http://arxiv.org/pdf/2505.16624v1",
    "published": "2025-05-22T12:57:35+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16623v1",
    "title": "Manipulating decoherence: Towards a universal framework",
    "authors": [
      "Kallol Sen",
      "Animesh Sinha Roy",
      "Saumya Ranjan Behera",
      "Snigdhadev Ray",
      "A. R. P. Rau",
      "Urbasi Sinha"
    ],
    "abstract": "Coherence is a fundamental characteristic of quantum systems and central to\nunderstanding quantum behaviour. It is also important for a variety of\napplications in quantum information. However, physical systems suffer from\ndecoherence due to their interaction with the environment. Although different\napproaches have been developed to deal with decoherence, there is no unified\nframework to manipulate the degradation of quantum entanglement. In this work,\nusing a time-dependent formalism (TDF), we take a step towards a broad\nframework for manipulating decoherence in photonic systems that lead to {\\it\nEntanglement Sudden Death} (ESD). We show explicitly that a time-delay\nparameter can be used to tune ESD in damping channels. We further propose a\nnovel setup along with the TDF to explore between two limits, one of an\namplitude-damping channel (ADC) and another of a correlated amplitude-damping\nchannel (CADC). The generalized definition of the Kraus operators in the TDF\nallows treatment of the three domains where ESD is hastened, delayed, or\ncompletely avoided. We show how a cascade of such damping channels is affected\nby to the time-delay parameter.",
    "pdf_url": "http://arxiv.org/pdf/2505.16623v1",
    "published": "2025-05-22T12:55:13+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16622v1",
    "title": "Decoherence manipulation through entanglement dynamics: A photonic experiment",
    "authors": [
      "Saumya Ranjan Behera",
      "Animesh Sinha Roy",
      "Kallol Sen",
      "Ashutosh Singh",
      "A. R. P. Rau",
      "Urbasi Sinha"
    ],
    "abstract": "Decoherence serves as a major obstacle to achieving higher efficiency in all\nquantum technologies. Thus, controlling and mitigating decoherence is currently\nan active research direction. In this work, we experimentally manipulate\nentanglement sudden death (ESD), a major manifestation of decoherence, in an\nall-photonic setup. We demonstrate a protocol that uses local unitary NOT\noperations along with a variant of amplitude-damping decoherence to influence\nthe evolution of bipartite entangled states through an amplitude-damping\nchannel. Our results obtained using the photonic test-bed demonstrate the\nability to hasten, delay, or completely prevent ESD, thereby offering a\npotential avenue for improving and scaling various quantum architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16622v1",
    "published": "2025-05-22T12:55:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16621v1",
    "title": "Families of isospectral and isoscattering quantum graphs",
    "authors": [
      "Pavel Kurasov",
      "Omer Farooq",
      "Michał Ławniczak",
      "Szymon Bauch",
      "Mats-Erik Pistol",
      "Matthew de Courcy-Ireland",
      "Leszek Sirko"
    ],
    "abstract": "A concept of germ graphs and the M-function formalism are employed to\nconstruct large families of isospectral and isoscattering graphs. This approach\nrepresents a complete departure from the original approach pioneered by Sunada,\nwhere isospectral graphs are obtained as quotients of a certain large symmetric\ngraph. Using the M-function formalism and the symmetries of the graph itself we\nconstruct isospectral and isoscattering pairs. In our novel approach\nisospectral pairs do not need to be embedded into a larger symmetric graph as\nin Sunada's approach. We demonstrate that the introduced formalism can also be\nextended to graphs with dissipation. The theoretical predictions are validated\nexperimentally using microwave networks emulating open quantum graphs with\ndissipation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16621v1",
    "published": "2025-05-22T12:54:52+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16620v1",
    "title": "CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models",
    "authors": [
      "Benjamin Herdeanu",
      "Juan Nathaniel",
      "Carla Roesch",
      "Jatan Buch",
      "Gregor Ramien",
      "Johannes Haux",
      "Pierre Gentine"
    ],
    "abstract": "Causal discovery for dynamical systems poses a major challenge in fields\nwhere active interventions are infeasible. Most methods used to investigate\nthese systems and their associated benchmarks are tailored to deterministic,\nlow-dimensional and weakly nonlinear time-series data. To address these\nlimitations, we present CausalDynamics, a large-scale benchmark and extensible\ndata generation framework to advance the structural discovery of dynamical\ncausal models. Our benchmark consists of true causal graphs derived from\nthousands of coupled ordinary and stochastic differential equations as well as\ntwo idealized climate models. We perform a comprehensive evaluation of\nstate-of-the-art causal discovery algorithms for graph reconstruction on\nsystems with noisy, confounded, and lagged dynamics. CausalDynamics consists of\na plug-and-play, build-your-own coupling workflow that enables the construction\nof a hierarchy of physical systems. We anticipate that our framework will\nfacilitate the development of robust causal discovery algorithms that are\nbroadly applicable across domains while addressing their unique challenges. We\nprovide a user-friendly implementation and documentation on\nhttps://kausable.github.io/CausalDynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16620v1",
    "published": "2025-05-22T12:54:30+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16619v1",
    "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences",
    "authors": [
      "Gavin Farrell",
      "Eleni Adamidi",
      "Rafael Andrade Buono",
      "Mihail Anton",
      "Omar Abdelghani Attafi",
      "Salvador Capella Gutierrez",
      "Emidio Capriotti",
      "Leyla Jael Castro",
      "Davide Cirillo",
      "Lisa Crossman",
      "Christophe Dessimoz",
      "Alexandros Dimopoulos",
      "Raul Fernandez-Diaz",
      "Styliani-Christina Fragkouli",
      "Carole Goble",
      "Wei Gu",
      "John M. Hancock",
      "Alireza Khanteymoori",
      "Tom Lenaerts",
      "Fabio G. Liberante",
      "Peter Maccallum",
      "Alexander Miguel Monzon",
      "Magnus Palmblad",
      "Lucy Poveda",
      "Ovidiu Radulescu",
      "Denis C. Shields",
      "Shoaib Sufi",
      "Thanasis Vergoulis",
      "Fotis Psomopoulos",
      "Silvio C. E. Tosatto"
    ],
    "abstract": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16619v1",
    "published": "2025-05-22T12:52:34+00:00",
    "categories": [
      "cs.AI",
      "q-bio.OT",
      "92",
      "J.3"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16618v1",
    "title": "Bosonic quantum Fourier codes",
    "authors": [
      "Anthony Leverrier"
    ],
    "abstract": "While 2-level systems, aka qubits, are a natural choice to perform a logical\nquantum computation, the situation is less clear at the physical level.\nEncoding information in higher-dimensional physical systems can indeed provide\na first level of redundancy and error correction that simplifies the overall\nfault-tolerant architecture. A challenge then is to ensure universal control\nover the encoded qubits. Here, we explore an approach where information is\nencoded in an irreducible representation of a finite subgroup of $U(2)$ through\nan inverse quantum Fourier transform. We illustrate this idea by applying it to\nthe real Pauli group $\\langle X, Z\\rangle$ in the bosonic setting. The\nresulting two-mode Fourier cat code displays good error correction properties\nand admits an experimentally-friendly universal gate set that we discuss in\ndetail.",
    "pdf_url": "http://arxiv.org/pdf/2505.16618v1",
    "published": "2025-05-22T12:51:22+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16617v1",
    "title": "Tropical limit of hyperbolic amoebas of complex analytic surfaces",
    "authors": [
      "Peter Petrov",
      "Mikhail Shkolnikov"
    ],
    "abstract": "In this letter, we establish a general fact about the convergence of images\nof families of closed analytic surfaces in the special linear group\n$\\operatorname{SL}_2(\\mathbb{C})$ under the quotient by its maximal compact\nsubgroup $\\operatorname{SU}(2)$ subject to a contracting scaling sequence.",
    "pdf_url": "http://arxiv.org/pdf/2505.16617v1",
    "published": "2025-05-22T12:51:21+00:00",
    "categories": [
      "math.AG",
      "math.CV",
      "math.GR",
      "math.MG",
      "14T10, 14T20, 14L35, 14T90, 14H10"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16616v1",
    "title": "Performance of Objective Speech Quality Metrics on Languages Beyond Validation Data: A Study of Turkish and Korean",
    "authors": [
      "Javier Perez",
      "Dimme de Groot",
      "Jorge Martinez"
    ],
    "abstract": "Objective speech quality measures are widely used to assess the performance\nof video conferencing platforms and telecommunication systems. They predict\nhuman-rated speech quality and are crucial for assessing the systems quality of\nexperience. Despite the widespread use, the quality measures are developed on a\nlimited set of languages. This can be problematic since the performance on\nunseen languages is consequently not guaranteed or even studied. Here we raise\nawareness to this issue by investigating the performance of two objective\nspeech quality measures (PESQ and ViSQOL) on Turkish and Korean. Using English\nas baseline, we show that Turkish samples have significantly higher ViSQOL\nscores and that for Turkish male speakers the correlation between PESQ and\nViSQOL is highest. These results highlight the need to explore biases across\nmetrics and to develop a labeled speech quality dataset with a variety of\nlanguages.",
    "pdf_url": "http://arxiv.org/pdf/2505.16616v1",
    "published": "2025-05-22T12:50:32+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16615v1",
    "title": "Quantum thermodynamics of continuous feedback control",
    "authors": [
      "Kacper Prech",
      "Joël Aschwanden",
      "Patrick P. Potts"
    ],
    "abstract": "The laws of thermodynamics are a cornerstone for describing nanoscale and\nopen quantum systems. However, formulating these laws for systems under\ncontinuous feedback control and under experimentally relevant conditions is\nchallenging. In this work, we lay out a formalism for the laws of\nthermodynamics in an open quantum system under continuous measurement and\nfeedback described by a Quantum Fokker Planck Master Equation. We derive\nexpressions for work, heat, and measurement-induced energy changes, and we\ninvestigate entropy production and fluctuation theorems. We illustrate our\nresults with a continuous version of a measurement-driven Szilard engine, as\nwell as a work extraction scheme in a two-level system under bang-bang control.\nOur results provide insights into the energetics as well as the irreversibility\nof classical and quantum systems under continuous feedback control.",
    "pdf_url": "http://arxiv.org/pdf/2505.16615v1",
    "published": "2025-05-22T12:50:18+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16614v1",
    "title": "Energy Consumption Framework and Analysis of Post-Quantum Key-Generation on Embedded Devices",
    "authors": [
      "J Cameron Patterson",
      "William J Buchanan",
      "Callum Turino"
    ],
    "abstract": "The emergence of quantum computing and Shor's algorithm necessitates an\nimminent shift from current public key cryptography techniques to post-quantum\nrobust techniques. NIST has responded by standardising Post-Quantum\nCryptography (PQC) algorithms, with ML-KEM (FIPS-203) slated to replace ECDH\n(Elliptic Curve Diffie-Hellman) for key exchange. A key practical concern for\nPQC adoption is energy consumption. This paper introduces a new framework for\nmeasuring the PQC energy consumption on a Raspberry Pi when performing key\ngeneration. The framework uses both available traditional methods and the newly\nstandardised ML-KEM algorithm via the commonly utilised OpenSSL library.",
    "pdf_url": "http://arxiv.org/pdf/2505.16614v1",
    "published": "2025-05-22T12:49:18+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16613v1",
    "title": "Long-term impact of PM2.5 on mortality is exacerbated when wildfire events occur",
    "authors": [
      "Federica Spoto",
      "Francesca Dominici",
      "Danielle Braun",
      "Joan A. Casey"
    ],
    "abstract": "There is extensive evidence that long-term exposure to all-source PM2.5\nincreases mortality. However, to date, no study has evaluated whether this\neffect is exacerbated in the presence of wildfire events. Here, we study 60+\nmillion older US adults and find that wildfire events increase the harmful\neffects of long-term all-source PM2.5 exposure on mortality, providing a new\nand realistic conceptualization of wildfire health risks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16613v1",
    "published": "2025-05-22T12:48:30+00:00",
    "categories": [
      "q-bio.PE",
      "physics.soc-ph"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16612v1",
    "title": "Steering Large Language Models for Machine Translation Personalization",
    "authors": [
      "Daniel Scalena",
      "Gabriele Sarti",
      "Arianna Bisazza",
      "Elisabetta Fersini",
      "Malvina Nissim"
    ],
    "abstract": "High-quality machine translation systems based on large language models\n(LLMs) have simplified the production of personalized translations reflecting\nspecific stylistic constraints. However, these systems still struggle in\nsettings where stylistic requirements are less explicit and might be harder to\nconvey via prompting. We explore various strategies for personalizing\nLLM-generated translations in low-resource settings, focusing on the\nchallenging literary translation domain. We explore prompting strategies and\ninference-time interventions for steering model generations towards a\npersonalized style, and propose a contrastive framework exploiting latent\nconcepts extracted from sparse autoencoders to identify salient personalization\nproperties. Our results show that steering achieves strong personalization\nwhile preserving translation quality. We further examine the impact of steering\non LLM representations, finding model layers with a relevant impact for\npersonalization are impacted similarly by multi-shot prompting and our steering\nmethod, suggesting similar mechanism at play.",
    "pdf_url": "http://arxiv.org/pdf/2505.16612v1",
    "published": "2025-05-22T12:47:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16611v1",
    "title": "Exploring magneto-electric coupling through lattice distortions: insights from a pantograph model",
    "authors": [
      "Daniel C. Cabra",
      "Gerardo L. Rossini"
    ],
    "abstract": "Multiferroic materials exhibit the coexistence of magnetic and electric\norder.\n  They are at the forefront of modern condensed matter physics due to their\npotential applications in next-generation technologies such as data storage,\nsensors, and actuators.\n  Despite significant progress, understanding and optimizing the coupling\nmechanisms between electric polarization and magnetism remain active areas of\nresearch.\n  We review here a series of papers presenting a comprehensive numerical and\ntheoretical exploration of a pantograph mechanism modeling magneto-electric\ncoupling through lattice distortions in low dimensional multiferroic systems.\n  These works introduce and elaborate a microscopic model where elastic lattice\ndistortions mediate interactions between spin 1/2 magnetic moments and electric\ndipoles, uncovering novel physics and functionalities.\n  The model successfully describes ubiquitous phenomena in type II improper\nmultiferroics, particularly when dominant Ising spin components are\n  introduced through XXZ-type rotational symmetry breaking spin interactions.\n  We also study more realistic extensions relevant for materials with higher\nspin magnetic ions and to materials where magnetic couplings draw higher\ndimensional lattices.",
    "pdf_url": "http://arxiv.org/pdf/2505.16611v1",
    "published": "2025-05-22T12:45:20+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.16610v1",
    "title": "From Generic Empathy to Personalized Emotional Support: A Self-Evolution Framework for User Preference Alignment",
    "authors": [
      "Jing Ye",
      "Lu Xiang",
      "Yaping Zhang",
      "Chengqing Zong"
    ],
    "abstract": "Effective emotional support hinges on understanding users' emotions and needs\nto provide meaningful comfort during multi-turn interactions. Large Language\nModels (LLMs) show great potential for expressing empathy; however, they often\ndeliver generic and one-size-fits-all responses that fail to address users'\nspecific needs. To tackle this issue, we propose a self-evolution framework\ndesigned to help LLMs improve their responses to better align with users'\nimplicit preferences concerning user profiles (personalities), emotional\nstates, and specific situations. Our framework consists of two distinct phases:\n\\textit{(1)} \\textit{Emotional Support Experience Acquisition}, where LLMs are\nfine-tuned on limited emotional support conversation data to provide basic\nsupport, and \\textit{(2)} \\textit{Self-Improvement for Personalized Emotional\nSupport}, where LLMs leverage self-reflection and self-refinement to generate\npersonalized responses. Through iterative direct preference optimization\nbetween the pre- and post-refined responses, our model generates responses that\nreflect a better understanding of the user's implicit preferences. Extensive\nexperiments and evaluations demonstrate that our method significantly enhances\nthe model's performance in emotional support, reducing unhelpful responses and\nminimizing discrepancies between user preferences and model outputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16610v1",
    "published": "2025-05-22T12:45:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16609v1",
    "title": "Monitoring Electrostatic Adhesion Forces via Acoustic Pressure",
    "authors": [
      "Huacen Wang",
      "Jiarui Zou",
      "Zeju Zheng",
      "Hongqiang Wang"
    ],
    "abstract": "Electrostatic adhesion is widely used in mobile robotics, haptics, and\nrobotic end effectors for its adaptability to diverse substrates and low energy\nconsumption. Force sensing is important for feedback control, interaction, and\nmonitoring in the EA system. However, EA force monitoring often relies on bulky\nand expensive sensors, increasing the complexity and weight of the entire\nsystem. This paper presents an acoustic-pressure-based method to monitor EA\nforces without contacting the adhesion pad. When the EA pad is driven by a\nbipolar square-wave voltage to adhere a conductive object, periodic acoustic\npulses arise from the EA system. We employed a microphone to capture these\nacoustic pressure signals and investigate the influence of peak pressure\nvalues. Results show that the peak value of acoustic pressure increased with\nthe mass and contact area of the adhered object, as well as with the amplitude\nand frequency of the driving voltage. We applied this technique to mass\nestimation of various objects and simultaneous monitoring of two EA systems.\nThen, we integrated this technique into an EA end effector that enables\nmonitoring the change of adhered object mass during transport. The proposed\ntechnique offers a low-cost, non-contact, and multi-object monitoring solution\nfor EA end effectors in handling tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16609v1",
    "published": "2025-05-22T12:45:08+00:00",
    "categories": [
      "cs.RO",
      "eess.SP"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16608v2",
    "title": "Statistical Analysis of Large-scale Item Response Data under Measurement Non-invariance: A Statistically Consistent Method and Its Application to PISA 2022",
    "authors": [
      "Jing Ouyang",
      "Yunxiao Chen",
      "Chengcheng Li",
      "Gongjun Xu"
    ],
    "abstract": "With the process of globalization, International Large-scale Assessments in\neducation (ILSAs), such as the Programme for International Student Assessment\n(PISA), have become increasingly important in educational research and\npolicy-making. They collect valuable data on education quality and performance\ndevelopment across many education systems worldwide, allowing countries to\nshare techniques and policies that have proven efficient and successful. A key\nto analyzing ILSA data is an Item Response Theory (IRT) model, which is used to\nestimate the performance distributions of different groups (e.g., countries)\nand then produce a ranking. A major challenge in calibrating the IRT model is\nthat some items suffer from Differential Item Functioning (DIF), i.e.,\ndifferent groups have different probabilities of correctly answering the items\nafter controlling for individual proficiency levels. DIF is particularly common\nin ILSA due to the differences in test languages, cultural contexts, and\ncurriculum designs across different groups. Ignoring or improperly accounting\nfor DIF when calibrating the IRT model can lead to severe biases in the\nestimated performance distributions, which may further distort the ranking of\nthe groups. Unfortunately, existing methods cannot guarantee the statistically\nconsistent recovery of the group ranking without unrealistic assumptions for\nILSA, such as the existence and knowledge of reference groups and anchor items.\nTo fill this gap, this paper proposes a new approach to DIF analysis across\nmultiple groups. This approach is computationally efficient and statistically\nconsistent, without making strong assumptions about reference groups and anchor\nitems. The proposed method is applied to PISA 2022 data from the mathematics,\nscience, and reading domains, providing insights into their DIF structures and\nperformance rankings of countries.",
    "pdf_url": "http://arxiv.org/pdf/2505.16608v2",
    "published": "2025-05-22T12:43:30+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.16607v1",
    "title": "Attractor-Based Speech Separation of Multiple Utterances by Unknown Number of Speakers",
    "authors": [
      "Yuzhu Wang",
      "Archontis Politis",
      "Konstantinos Drossos",
      "Tuomas Virtanen"
    ],
    "abstract": "This paper addresses the problem of single-channel speech separation, where\nthe number of speakers is unknown, and each speaker may speak multiple\nutterances. We propose a speech separation model that simultaneously performs\nseparation, dynamically estimates the number of speakers, and detects\nindividual speaker activities by integrating an attractor module. The proposed\nsystem outperforms existing methods by introducing an attractor-based\narchitecture that effectively combines local and global temporal modeling for\nmulti-utterance scenarios. To evaluate the method in reverberant and noisy\nconditions, a multi-speaker multi-utterance dataset was synthesized by\ncombining Librispeech speech signals with WHAM! noise signals. The results\ndemonstrate that the proposed system accurately estimates the number of\nsources. The system effectively detects source activities and separates the\ncorresponding utterances into correct outputs in both known and unknown source\ncount scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16607v1",
    "published": "2025-05-22T12:41:42+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16606v1",
    "title": "Fast and high-fidelity transfer of edge states via dynamical control of topological phases and effects of dissipation",
    "authors": [
      "Yuuki Kanda",
      "Yusuke Fujisawa",
      "Kousuke Yakubo",
      "Norio Kawakami",
      "Hideaki Obuse"
    ],
    "abstract": "Topological edge states are robust against symmetry-preserving perturbations\nand noise, making them promising for quantum information and computation,\nparticularly in topological quantum computation through braiding operations of\nMajorana quasiparticles. Realizing these applications requires fast and\nhigh-fidelity dynamic control of edge states. In this work, we theoretically\npropose a high-fidelity method for transferring one-dimensional topological\nedge states by dynamically moving a domain wall between regions of different\ntopological numbers. This method fundamentally relies on Lorentz invariance and\nrelativistic effects, as moving the domain wall at a constant speed results in\nthe problem into the uniform linear motion of a particle obeying a Dirac\nequation. We demonstrate effectiveness of our method in transferring edge\nstates with high fidelity using a one-dimensional quantum walk with two\ninternal states, which is feasible with current experimental technology. We\nalso investigate how bit and phase-flip dissipation from environment affects\ntransfer efficiency. Remarkably, these dissipation have minimal effects on\nefficiency at slow and fast transfer limits, respectively, which can be\nexplained by relativistic effects to the edge states.",
    "pdf_url": "http://arxiv.org/pdf/2505.16606v1",
    "published": "2025-05-22T12:40:48+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.stat-mech",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.16605v1",
    "title": "Manin triples for double Lie bialgebroids",
    "authors": [
      "Ana Carolina Mançur"
    ],
    "abstract": "We verify that LA-Courant algebroids provide the Manin triple framework for\ndouble Lie bialgebroids. Specifically, we establish a correspondence between\ndouble Lie bialgebroids and LA-Manin triples, i.e., LA-Courant algebroids\nequipped with a pair of complementary LA-Dirac structures. This work sheds\nlight on the infinitesimal-global correspondence between LA-Courant algebroids\nand multiplicative Courant algebroids.",
    "pdf_url": "http://arxiv.org/pdf/2505.16605v1",
    "published": "2025-05-22T12:40:13+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16603v1",
    "title": "Lattice study of correlators of chromoelectric fields for heavy quarkonium dynamics in the quark-gluon plasma",
    "authors": [
      "Nora Brambilla",
      "Saumen Datta",
      "Marc Janer",
      "Viljami Leino",
      "Julian Mayer-Steudte",
      "Peter Petreczky",
      "Antonio Vairo"
    ],
    "abstract": "We perform a lattice calculation of the correlators of two chromoelectric\nfields in the adjoint representation connected by adjoint Wilson lines at\nnon-zero temperature. These correlators arise in the study of quarkonium\ndynamics and of adjoint heavy quark diffusion in deconfined matter. We work in\nSU(3) gauge theory using either gradient flow or multi-level algorithms for\nnoise reduction, and discuss the renormalization of the correlators on the\nlattice. We find that a Casimir factor rescaling relates the adjoint\ncorrelators corresponding to the diffusion of an adjoint heavy quark and the\noctet-octet quarkonium transitions to the chromoelectric correlator in the\nfundamental representation describing the diffusion of a heavy quark.",
    "pdf_url": "http://arxiv.org/pdf/2505.16603v1",
    "published": "2025-05-22T12:39:34+00:00",
    "categories": [
      "hep-lat",
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.16604v2",
    "title": "The chromoelectric adjoint correlators in Euclidean space at next-to-leading order",
    "authors": [
      "Nora Brambilla",
      "Panayiotis Panayiotou",
      "Saga Säppi",
      "Antonio Vairo"
    ],
    "abstract": "The physics of quarkonium created in heavy-ion collisions is intrinsically\nconnected to the correlation functions of adjoint chromoelectric fields in\nquantum chromodynamics. We study such correlation functions in a weak-coupling\nexpansion in a thermal medium. We identify three distinct gauge-invariant\ncorrelators, and evaluate them to next-to-leading order. Two of the resulting\ncorrelators turn out to be asymmetric. We pinpoint the source of this asymmetry\nto Matsubara zero modes associated with Wilson lines. The results are shown to\nagree well with recent lattice calculations at high temperatures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16604v2",
    "published": "2025-05-22T12:39:34+00:00",
    "categories": [
      "hep-ph",
      "hep-lat",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16602v1",
    "title": "MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation",
    "authors": [
      "Bohan Zhou",
      "Yi Zhan",
      "Zhongbin Zhang",
      "Zongqing Lu"
    ],
    "abstract": "Egocentric hand-object motion generation is crucial for immersive AR/VR and\nrobotic imitation but remains challenging due to unstable viewpoints,\nself-occlusions, perspective distortion, and noisy ego-motion. Existing methods\nrely on predefined 3D object priors, limiting generalization to novel objects,\nwhich restricts their generalizability to novel objects. Meanwhile, recent\nmultimodal approaches suffer from ambiguous generation from abstract textual\ncues, intricate pipelines for modeling 3D hand-object correlation, and\ncompounding errors in open-loop prediction. We propose MEgoHand, a multimodal\nframework that synthesizes physically plausible hand-object interactions from\negocentric RGB, text, and initial hand pose. MEgoHand introduces a bi-level\narchitecture: a high-level \"cerebrum\" leverages a vision language model (VLM)\nto infer motion priors from visual-textual context and a monocular depth\nestimator for object-agnostic spatial reasoning, while a low-level DiT-based\nflow-matching policy generates fine-grained trajectories with temporal\northogonal filtering to enhance stability. To address dataset inconsistency, we\ndesign a dataset curation paradigm with an Inverse MANO Retargeting Network and\nVirtual RGB-D Renderer, curating a unified dataset of 3.35M RGB-D frames, 24K\ninteractions, and 1.2K objects. Extensive experiments across five in-domain and\ntwo cross-domain datasets demonstrate the effectiveness of MEgoHand, achieving\nsubstantial reductions in wrist translation error (86.9%) and joint rotation\nerror (34.1%), highlighting its capacity to accurately model fine-grained hand\njoint structures and generalize robustly across diverse scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16602v1",
    "published": "2025-05-22T12:37:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16600v1",
    "title": "Major issues in theory of Bose-Einstein condensation",
    "authors": [
      "V. I. Yukalov"
    ],
    "abstract": "Major issues arising in the theory of Bose-Einstein condensation are\nreviewed. These issues, although being principally important, are very often\nmisunderstood, which results in wrong conclusions. The basic point is global\ngauge symmetry breaking that is a necessary and sufficient condition for\nBose-Einstein condensation. Paying no attention to this basic point is a common\nfallacy leading to a number of confusions. For instance, the attempt of\ndescribing Bose condensation without gauge symmetry breaking produces the\nso-called ``grand canonical catastrophe\" that actually does not exist in the\ncorrect description of Bose condensation accompanied by gauge symmetry\nbreaking. The other common flaw is forgetting to consider the stability of the\nstudied systems. One sometimes accomplishes lengthy calculations and discusses\nthe properties of a system that in reality cannot exist being unstable. In some\ncases, the seeming instability is caused by the negligence of the simple\nmathematical reason teaching us that one should not go beyond the approximation\napplicability. An example of such an artificial instability is related to the\nappearance of the so-called ``thermodynamically anomalous fluctuations\" whose\narising is due to the use of a second-order approximation for calculating\nfourth-order terms, in this way distorting the $O(2)$-class model of a\nBose-condensed system to the Gaussian-class model. These and other principal\npoints, important for the correct treatment of Bose-condensed systems, are\nreviewed, including the resolution of the Hohenberg-Martin dilemma of gapless\nversus conserving theories for Bose-condensed systems and the problem of\nstatistical ensemble equivalence.",
    "pdf_url": "http://arxiv.org/pdf/2505.16600v1",
    "published": "2025-05-22T12:36:05+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.16599v2",
    "title": "Decoupled Geometric Parameterization and its Application in Deep Homography Estimation",
    "authors": [
      "Yao Huang",
      "Si-Yuan Cao",
      "Yaqing Ding",
      "Hao Yin",
      "Shibin Xie",
      "Shuting Wang",
      "Zhijun Fang",
      "Jiachun Wang",
      "Shen Cai",
      "Junchi Yan",
      "Shuhan Shen"
    ],
    "abstract": "Planar homography, with eight degrees of freedom (DOFs), is fundamental in\nnumerous computer vision tasks. While the positional offsets of four corners\nare widely adopted (especially in neural network predictions), this\nparameterization lacks geometric interpretability and typically requires\nsolving a linear system to compute the homography matrix. This paper presents a\nnovel geometric parameterization of homographies, leveraging the\nsimilarity-kernel-similarity (SKS) decomposition for projective\ntransformations. Two independent sets of four geometric parameters are\ndecoupled: one for a similarity transformation and the other for the kernel\ntransformation. Additionally, the geometric interpretation linearly relating\nthe four kernel transformation parameters to angular offsets is derived. Our\nproposed parameterization allows for direct homography estimation through\nmatrix multiplication, eliminating the need for solving a linear system, and\nachieves performance comparable to the four-corner positional offsets in deep\nhomography estimation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16599v2",
    "published": "2025-05-22T12:33:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16597v1",
    "title": "Silver Electrodeposition from Ag/AgCl Electrodes: Implications for Nanoscience",
    "authors": [
      "Chuhongxu Chen",
      "Ziwei Wang",
      "Guilin Chen",
      "Zhijia Zhang",
      "Zakhar Bedran",
      "Stephen Tipper",
      "Pablo Dıaz-Nunez",
      "Ivan Timokhin",
      "Artem Mishchenko",
      "Qian Yang"
    ],
    "abstract": "With the advancement of nanoscience, silver/silver chloride (Ag/AgCl)\nelectrodes have become widely utilised in microscale and nanoscale fluidic\nexperiments, because of their stability. However, our findings reveal that the\ndissolution of AgCl from the electrode in \\ch{Cl-}-rich solutions can lead to\nsignificant silver contamination, through the formation of silver complexes,\n\\ch{[AgCl_{n+1}]^{n-}}. We demonstrate the electrodeposition of silver\nparticles on graphene in KCl aqueous solution, with AgCl dissolution from the\nelectrode as the sole source of silver. This unexpected electrodeposition\nprocess offers a more plausible interpretation of the recently reported ``ionic\nflow-induced current in graphene''. That is, the measured electronic current in\ngraphene is due to the electrodeposition of silver, challenging the previously\nclaimed ``ionic Coulomb drag''. More caution is called for when using Ag/AgCl\nelectrodes in microfluidic, and especially nanofluidic systems, because AgCl\ndissolution should not be neglected.",
    "pdf_url": "http://arxiv.org/pdf/2505.16597v1",
    "published": "2025-05-22T12:32:20+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.16596v1",
    "title": "Safe Uncertainty-Aware Learning of Robotic Suturing",
    "authors": [
      "Wilbert Peter Empleo",
      "Yitaek Kim",
      "Hansoul Kim",
      "Thiusius Rajeeth Savarimuthu",
      "Iñigo Iturrate"
    ],
    "abstract": "Robot-Assisted Minimally Invasive Surgery is currently fully manually\ncontrolled by a trained surgeon. Automating this has great potential for\nalleviating issues, e.g., physical strain, highly repetitive tasks, and\nshortages of trained surgeons. For these reasons, recent works have utilized\nArtificial Intelligence methods, which show promising adaptability. Despite\nthese advances, there is skepticism of these methods because they lack\nexplainability and robust safety guarantees. This paper presents a framework\nfor a safe, uncertainty-aware learning method. We train an Ensemble Model of\nDiffusion Policies using expert demonstrations of needle insertion. Using an\nEnsemble model, we can quantify the policy's epistemic uncertainty, which is\nused to determine Out-Of-Distribution scenarios. This allows the system to\nrelease control back to the surgeon in the event of an unsafe scenario.\nAdditionally, we implement a model-free Control Barrier Function to place\nformal safety guarantees on the predicted action. We experimentally evaluate\nour proposed framework using a state-of-the-art robotic suturing simulator. We\nevaluate multiple scenarios, such as dropping the needle, moving the camera,\nand moving the phantom. The learned policy is robust to these perturbations,\nshowing corrective behaviors and generalization, and it is possible to detect\nOut-Of-Distribution scenarios. We further demonstrate that the Control Barrier\nFunction successfully limits the action to remain within our specified safety\nset in the case of unsafe predictions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16596v1",
    "published": "2025-05-22T12:31:18+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16595v1",
    "title": "Stable anisotropic minimal hypersurfaces in $\\mathbb{R}^{5}$ and $\\mathbb{R}^{6}$",
    "authors": [
      "Jia Li",
      "Chao Xia"
    ],
    "abstract": "In this paper, we prove that a complete, two-sided, stable anisotropic\nminimal immersed hypersurface in $\\mathbb{R}^{5}$ or $\\mathbb{R}^{6}$ is flat,\nprovided the anisotropic area functional is $C^4$-close to the area functional.",
    "pdf_url": "http://arxiv.org/pdf/2505.16595v1",
    "published": "2025-05-22T12:29:44+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16594v1",
    "title": "Temporal Object Captioning for Street Scene Videos from LiDAR Tracks",
    "authors": [
      "Vignesh Gopinathan",
      "Urs Zimmermann",
      "Michael Arnold",
      "Matthias Rottmann"
    ],
    "abstract": "Video captioning models have seen notable advancements in recent years,\nespecially with regard to their ability to capture temporal information. While\nmany research efforts have focused on architectural advancements, such as\ntemporal attention mechanisms, there remains a notable gap in understanding how\nmodels capture and utilize temporal semantics for effective temporal feature\nextraction, especially in the context of Advanced Driver Assistance Systems. We\npropose an automated LiDAR-based captioning procedure that focuses on the\ntemporal dynamics of traffic participants. Our approach uses a rule-based\nsystem to extract essential details such as lane position and relative motion\nfrom object tracks, followed by a template-based caption generation. Our\nfindings show that training SwinBERT, a video captioning model, using only\nfront camera images and supervised with our template-based captions,\nspecifically designed to encapsulate fine-grained temporal behavior, leads to\nimproved temporal understanding consistently across three datasets. In\nconclusion, our results clearly demonstrate that integrating LiDAR-based\ncaption supervision significantly enhances temporal understanding, effectively\naddressing and reducing the inherent visual/static biases prevalent in current\nstate-of-the-art model architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16594v1",
    "published": "2025-05-22T12:28:50+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16593v1",
    "title": "Bochner-Riesz commutators for Grushin Operators",
    "authors": [
      "Md Nurul Molla",
      "Joydwip Singh"
    ],
    "abstract": "In this paper, we study the boundedness of Bochner-Riesz commutator $$[b,\nS^{\\alpha}(\\mathcal{L})](f) = b S^{\\alpha}(\\mathcal{L})(f) -\nS^{\\alpha}(\\mathcal{L})(bf)$$ of a $BMO^{\\varrho}(\\mathbb{R}^d)$ function $b$\nand the Bochner-Riesz operator $S^{\\alpha}(\\mathcal{L})$ associated to the\nGrushin operator $\\mathcal{L}$ on $\\mathbb{R}^d$ with $d:= d_1 +d_2$. We prove\nthat for $1\\leq p \\leq \\min \\{2d_1/(d_1 +2), 2(d_2 +1)/(d_2+3)\\}$ and $\\alpha >\nd(1/p - 1/2) - 1/2$, if $b \\in BMO^{\\varrho}(\\mathbb{R}^d)$, then $[b,\nS^{\\alpha}(\\mathcal{L})]$ is bounded on $L^q(\\mathbb{R}^d)$ whenever $p < q <\np'$. Moreover, if $b \\in CMO^{\\varrho}(\\mathbb{R}^d)$, then we show that $[b,\nS^{\\alpha}(\\mathcal{L})]$ is a compact operator on $L^q(\\mathbb{R}^d)$ in the\nsame range.",
    "pdf_url": "http://arxiv.org/pdf/2505.16593v1",
    "published": "2025-05-22T12:28:24+00:00",
    "categories": [
      "math.AP",
      "42B15, 43A85"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.18209v1",
    "title": "Optimal Control of Covid-19 Interventions in Public Health Management",
    "authors": [
      "Isabella Kemajou-Brown",
      "Romario Gildas Foko Tiomela",
      "Olawale Nasiru Lawal",
      "Samson Adekola Alagbe",
      "Serges Love Teutu Talla"
    ],
    "abstract": "This study explores the application of Pontryagin's Maximum Principle to\nderive optimal strategies for controlling the spread of COVID-19, leveraging a\nnovel compartmental model to capture the disease dynamics. We prioritize three\nkey criteria: cost, effectiveness, and feasibility, each examined independently\nto evaluate their unique contributions to pandemic management. By addressing\nthese criteria, this study aims to design intervention strategies that are\nscientifically robust, practical, and economically sustainable. Furthermore,\nthe focus on cost, effectiveness and feasibility seeks to provide policymakers\nwith actionable insights for implementing interventions that maximize public\nhealth benefits while remaining feasible under real-world conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.18209v1",
    "published": "2025-05-22T12:27:54+00:00",
    "categories": [
      "math.OC",
      "49J20, 49K15, 92D30"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16592v2",
    "title": "What Media Frames Reveal About Stance: A Dataset and Study about Memes in Climate Change Discourse",
    "authors": [
      "Shijia Zhou",
      "Siyao Peng",
      "Simon Luebke",
      "Jörg Haßler",
      "Mario Haim",
      "Saif M. Mohammad",
      "Barbara Plank"
    ],
    "abstract": "Media framing refers to the emphasis on specific aspects of perceived reality\nto shape how an issue is defined and understood. Its primary purpose is to\nshape public perceptions often in alignment with the authors' opinions and\nstances. However, the interaction between stance and media frame remains\nlargely unexplored. In this work, we apply an interdisciplinary approach to\nconceptualize and computationally explore this interaction with internet memes\non climate change. We curate CLIMATEMEMES, the first dataset of climate-change\nmemes annotated with both stance and media frames, inspired by research in\ncommunication science. CLIMATEMEMES includes 1,184 memes sourced from 47\nsubreddits, enabling analysis of frame prominence over time and communities,\nand sheds light on the framing preferences of different stance holders. We\npropose two meme understanding tasks: stance detection and media frame\ndetection. We evaluate LLaVA-NeXT and Molmo in various setups, and report the\ncorresponding results on their LLM backbone. Human captions consistently\nenhance performance. Synthetic captions and human-corrected OCR also help\noccasionally. Our findings highlight that VLMs perform well on stance, but\nstruggle on frames, where LLMs outperform VLMs. Finally, we analyze VLMs'\nlimitations in handling nuanced frames and stance expressions on climate change\ninternet memes.",
    "pdf_url": "http://arxiv.org/pdf/2505.16592v2",
    "published": "2025-05-22T12:27:12+00:00",
    "categories": [
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16591v1",
    "title": "Evaluating Large Language Model with Knowledge Oriented Language Specific Simple Question Answering",
    "authors": [
      "Bowen Jiang",
      "Runchuan Zhu",
      "Jiang Wu",
      "Zinco Jiang",
      "Yifan He",
      "Junyuan Gao",
      "Jia Yu",
      "Rui Min",
      "Yinfan Wang",
      "Haote Yang",
      "Songyang Zhang",
      "Dahua Lin",
      "Lijun Wu",
      "Conghui He"
    ],
    "abstract": "We introduce KoLasSimpleQA, the first benchmark evaluating the multilingual\nfactual ability of Large Language Models (LLMs). Inspired by existing research,\nwe created the question set with features such as single knowledge point\ncoverage, absolute objectivity, unique answers, and temporal stability. These\nquestions enable efficient evaluation using the LLM-as-judge paradigm, testing\nboth the LLMs' factual memory and self-awareness (\"know what they don't know\").\nKoLasSimpleQA expands existing research in two key dimensions: (1) Breadth\n(Multilingual Coverage): It includes 9 languages, supporting global\napplicability evaluation. (2) Depth (Dual Domain Design): It covers both the\ngeneral domain (global facts) and the language-specific domain (such as\nhistory, culture, and regional traditions) for a comprehensive assessment of\nmultilingual capabilities. We evaluated mainstream LLMs, including traditional\nLLM and emerging Large Reasoning Models. Results show significant performance\ndifferences between the two domains, particularly in performance metrics,\nranking, calibration, and robustness. This highlights the need for targeted\nevaluation and optimization in multilingual contexts. We hope KoLasSimpleQA\nwill help the research community better identify LLM capability boundaries in\nmultilingual contexts and provide guidance for model optimization. We will\nrelease KoLasSimpleQA at https://github.com/opendatalab/KoLasSimpleQA .",
    "pdf_url": "http://arxiv.org/pdf/2505.16591v1",
    "published": "2025-05-22T12:27:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16590v3",
    "title": "Larger Is Not Always Better: Exploring Small Open-source Language Models in Logging Statement Generation",
    "authors": [
      "Renyi Zhong",
      "Yichen Li",
      "Guangba Yu",
      "Wenwei Gu",
      "Jinxi Kuang",
      "Yintong Huo",
      "Michael R. Lyu"
    ],
    "abstract": "Developers use logging statements to create logs that document system\nbehavior and aid in software maintenance. As such, high-quality logging is\nessential for effective maintenance; however, manual logging often leads to\nerrors and inconsistency. Recent methods emphasize using large language models\n(LLMs) for automated logging statement generation, but these present privacy\nand resource issues, hindering their suitability for enterprise use. This paper\npresents the first large-scale empirical study evaluating small open-source\nlanguage models (SOLMs) for automated logging statement generation. We evaluate\nfour prominent SOLMs using various prompt strategies and parameter-efficient\nfine-tuning techniques, such as Low-Rank Adaptation (LoRA) and\nRetrieval-Augmented Generation (RAG). Our results show that fine-tuned SOLMs\nwith LoRA and RAG prompts, particularly Qwen2.5-coder-14B, outperform existing\ntools and LLM baselines in predicting logging locations and generating\nhigh-quality statements, with robust generalization across diverse\nrepositories. These findings highlight SOLMs as a privacy-preserving, efficient\nalternative for automated logging.",
    "pdf_url": "http://arxiv.org/pdf/2505.16590v3",
    "published": "2025-05-22T12:26:53+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16589v1",
    "title": "Profinite groups with many elements with large nilpotentizer and generalizations",
    "authors": [
      "Martino Garonzi",
      "Andrea Lucchini",
      "Nowras Otmen"
    ],
    "abstract": "Given a profinite group $G$ and a family $\\mathcal{F}$ of finite groups\nclosed under taking subgroups, direct products and quotients, denote by\n$\\mathcal{F}(G)$ the set of elements $g \\in G$ such that $\\{x \\in G\\ |\\ \\langle\ng,x \\rangle \\ \\mbox{is a pro-}\\mathcal{F} \\mbox{ group}\\}$ has positive Haar\nmeasure. We investigate the properties of $\\mathcal{F}(G)$ for various choices\nof $\\mathcal{F}$ and its influence on the structure of $G$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16589v1",
    "published": "2025-05-22T12:26:49+00:00",
    "categories": [
      "math.GR"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16588v1",
    "title": "Computing magnitudes, colours, distances, and absolute magnitudes at any signal-to-noise level",
    "authors": [
      "Michael Weiler"
    ],
    "abstract": "The computation of magnitudes and distances from low signal-to-noise\nobservations is known to be problematic, in the sense that the magnitudes and\ndistances tend to assume extreme values, or are even undefined or unphysical in\nthe case of negative observed fluxes or parallaxes. In this work we show that\nmagnitudes can be computed consistently at all signal-to-noise levels, and even\nfor negative fluxes, if the prior information that the true flux or distance is\nnon-negative is properly included. Furthermore, we derive an all-purpose\nestimator for distances from a prior implementing only the non-negativity of\nthe true parallax. We apply our results to the case of combining magnitudes to\ncolours, and magnitudes and distances to obtain absolute magnitudes. The\nresulting expressions are easy to compute and we show that the resulting\ndistribution functions for magnitudes, colours, distances, and absolute\nmagnitudes are not only consistent for all signal-to-noise levels and\napplicable to both, positive and negative observed fluxes and parallaxes, but\nalso show no strong tails. While biases at very low signal-to-noise levels are\nunavoidable, the estimator for distances derived in this work is less biased\nthan previously used estimators. We find that the magnitude, colour, distance,\nand absolute magnitude distributions for vanishing signals converge to limiting\ndistributions, whose median values are important for assessing biases when\nworking with data at low signal-to-noise levels.",
    "pdf_url": "http://arxiv.org/pdf/2505.16588v1",
    "published": "2025-05-22T12:26:48+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16587v1",
    "title": "A Survey on the Application of Large Language Models in Scenario-Based Testing of Automated Driving Systems",
    "authors": [
      "Yongqi Zhao",
      "Ji Zhou",
      "Dong Bi",
      "Tomislav Mihalj",
      "Jia Hu",
      "Arno Eichberger"
    ],
    "abstract": "The safety and reliability of Automated Driving Systems (ADSs) must be\nvalidated prior to large-scale deployment. Among existing validation\napproaches, scenario-based testing has been regarded as a promising method to\nimprove testing efficiency and reduce associated costs. Recently, the emergence\nof Large Language Models (LLMs) has introduced new opportunities to reinforce\nthis approach. While an increasing number of studies have explored the use of\nLLMs in the field of automated driving, a dedicated review focusing on their\napplication within scenario-based testing remains absent. This survey addresses\nthis gap by systematically categorizing the roles played by LLMs across various\nphased of scenario-based testing, drawing from both academic research and\nindustrial practice. In addition, key characteristics of LLMs and corresponding\nusage strategies are comprehensively summarized. The paper concludes by\noutlining five open challenges and potential research directions. To support\nongoing research efforts, a continuously updated repository of recent\nadvancements and relevant open-source tools is made available at:\nhttps://github.com/ftgTUGraz/LLM4ADSTest.",
    "pdf_url": "http://arxiv.org/pdf/2505.16587v1",
    "published": "2025-05-22T12:25:44+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.05357v1",
    "title": "Inventory record inaccuracy in grocery retailing: Impact of promotions and product perishability, and targeted effect of audits",
    "authors": [
      "Yacine Rekik",
      "Rogelio Oliva",
      "Christoph Glock",
      "Aris Syntetos"
    ],
    "abstract": "We report the results of a study to identify and quantify drivers of\ninventory record inaccuracy (IRI) in a grocery retailing environment, a context\nwhere products are often subject to promotion activity and a substantial share\nof items are perishable. The analysis covers ~24,000 stock keeping units (SKUs)\nsold in 11 stores. We find that IRI is positively associated with average\ninventory level, restocking frequency, and whether the item is perishable, and\nnegatively associated with promotional activity. We also conduct a field\nquasi-experiment to assess the marginal effect of stockcounts on sales. While\nperforming an inventory audit is found to lead to an 11% store-wide sales lift,\nthe audit has heterogeneous effects with all the sales lift concentrated on\nitems exhibiting negative IRI (i.e., where system inventory is greater than\nactual inventory). The benefits of inventory audits are also found to be more\npronounced on perishable items, that are associated with higher IRI levels. Our\nfindings inform retailers on the appropriate allocation of effort to improve\nIRI and reframes stock counting as a sales-increasing strategy rather than a\ncost-intensive necessity.",
    "pdf_url": "http://arxiv.org/pdf/2506.05357v1",
    "published": "2025-05-22T12:25:01+00:00",
    "categories": [
      "q-fin.GN"
    ],
    "primary_category": "q-fin.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.16586v1",
    "title": "A correlation between accretion and outflow rates for Class II Young Stellar Objects with full and transition disks",
    "authors": [
      "A. A. Rota",
      "N. van der Marel",
      "A. Garufi",
      "C. Carrasco-González",
      "E. Macias",
      "I. Pascucci",
      "A. Sellek",
      "L. Testi",
      "A. Isella",
      "S. Facchini"
    ],
    "abstract": "Magnetothermal (MHD) winds and jets originate in a wide range of regions of\nprotoplanetary disks (1-30 au) and are thought to be the primary mechanisms\ndriving accretion onto the central star. One indirect signature of these\nprocesses is the free-free emission from ionized gas close to the star. We\nanalyze a sample of 31 Class II disks: 18 full disks (FD) and 13 transition\ndisks (TD). All sources show evidence of excess free-free emission over the\ncontribution of the thermal dust. We investigate the origin of this emission\nand whether it is associated with other observables. We first analyzed a sample\nof objects in Taurus, exploring correlations with the properties of the central\nstar, the disk, and other disk-wind tracers. We compared our findings with a\nsample of TD for which free-free emission was shown to be likely associated\nwith an MHD-wind/jet. We found no correlation between the detected free-free\nemission and either the X-ray or the [OI]6300A line properties. We found a\nstrong correlation between the ionized mass loss rate, as inferred from the\nfree-free emission, and the accretion rate, suggesting that free-free emission\nin FD is associated with an MHD-wind/jet. The detected free-free emission in\nboth TD and FD is likely similarly associated with an ionized gas close to the\nstar from an MHD-wind/jet. The free-free emission detected in TD shows hints of\nshallower correlations with accretion properties than in FD. Whereas the\nefficiency in transforming accretion into outflow might differ in TD and FD,\nconsidering the correlations between free-free emission and accretion\nproperties, this difference could simply result from a bias toward strong\naccretors in the TD sample. Therefore, observations of a more complete and\nuniform sample are necessary to determine whether this change in correlations\nholds only for strong accretors or for TD in general.",
    "pdf_url": "http://arxiv.org/pdf/2505.16586v1",
    "published": "2025-05-22T12:24:48+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17155v2",
    "title": "TrimR: Verifier-based Training-Free Thinking Compression for Efficient Test-Time Scaling",
    "authors": [
      "Weizhe Lin",
      "Xing Li",
      "Zhiyuan Yang",
      "Xiaojin Fu",
      "Hui-Ling Zhen",
      "Yaoyuan Wang",
      "Xianzhi Yu",
      "Wulong Liu",
      "Xiaosong Li",
      "Mingxuan Yuan"
    ],
    "abstract": "Large Reasoning Models (LRMs) demonstrate exceptional capability in tackling\ncomplex mathematical, logical, and coding tasks by leveraging extended\nChain-of-Thought (CoT) reasoning. Test-time scaling methods, such as prolonging\nCoT with explicit token-level exploration, can push LRMs' accuracy boundaries,\nbut they incur significant decoding overhead. A key inefficiency source is LRMs\noften generate redundant thinking CoTs, which demonstrate clear structured\noverthinking and underthinking patterns. Inspired by human cognitive reasoning\nprocesses and numerical optimization theories, we propose TrimR, a\nverifier-based, training-free, efficient framework for dynamic CoT compression\nto trim reasoning and enhance test-time scaling, explicitly tailored for\nproduction-level deployment. Our method employs a lightweight, pretrained,\ninstruction-tuned verifier to detect and truncate redundant intermediate\nthoughts of LRMs without any LRM or verifier fine-tuning. We present both the\ncore algorithm and asynchronous online system engineered for high-throughput\nindustrial applications. Empirical evaluations on Ascend NPUs and vLLM show\nthat our framework delivers substantial gains in inference efficiency under\nlarge-batch workloads. In particular, on the four MATH500, AIME24, AIME25, and\nGPQA benchmarks, the reasoning runtime of Pangu Pro MoE, Pangu-R-38B, QwQ-32B,\nand DeepSeek-R1-Distill-Qwen-32B is improved by up to 70% with negligible\nimpact on accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.17155v2",
    "published": "2025-05-22T12:23:30+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16585v2",
    "title": "Expanded regimes of area law for lattice Yang-Mills theories",
    "authors": [
      "Sky Cao",
      "Ron Nissim",
      "Scott Sheffield"
    ],
    "abstract": "We extend the parameter regimes for which area law is proven for pure\n$\\mathrm{U}(N)$ lattice Yang-Mills theories, in particular when $N$ is large.\nThis improves on a classical result of Osterwalder-Seiler from 1978. To do so,\nwe view the master loop equation as a linear inhomogeneous equation for Wilson\nstring expectations, and then prove an a priori bound for solutions to the\nequation. The main novelty is in how we deal with the merger term in the master\nloop equation. This is done by introducing a truncated model for which the\nmerger term is unproblematic, and then showing that the truncated model well\napproximates the original model.",
    "pdf_url": "http://arxiv.org/pdf/2505.16585v2",
    "published": "2025-05-22T12:20:42+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP",
      "81T13, 82B20"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16583v5",
    "title": "Training on Plausible Counterfactuals Removes Spurious Correlations",
    "authors": [
      "Shpresim Sadiku",
      "Kartikeya Chitranshi",
      "Hiroshi Kera",
      "Sebastian Pokutta"
    ],
    "abstract": "Plausible counterfactual explanations (p-CFEs) are perturbations that\nminimally modify inputs to change classifier decisions while remaining\nplausible under the data distribution. In this study, we demonstrate that\nclassifiers can be trained on p-CFEs labeled with induced \\emph{incorrect}\ntarget classes to classify unperturbed inputs with the original labels. While\nprevious studies have shown that such learning is possible with adversarial\nperturbations, we extend this paradigm to p-CFEs. Interestingly, our\nexperiments reveal that learning from p-CFEs is even more effective: the\nresulting classifiers achieve not only high in-distribution accuracy but also\nexhibit significantly reduced bias with respect to spurious correlations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16583v5",
    "published": "2025-05-22T12:17:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16582v2",
    "title": "O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering",
    "authors": [
      "Jianbiao Mei",
      "Tao Hu",
      "Daocheng Fu",
      "Licheng Wen",
      "Xuemeng Yang",
      "Rong Wu",
      "Pinlong Cai",
      "Xinyu Cai",
      "Xing Gao",
      "Yu Yang",
      "Chengjun Xie",
      "Botian Shi",
      "Yong Liu",
      "Yu Qiao"
    ],
    "abstract": "Large Language Models (LLMs), despite their advancements, are fundamentally\nlimited by their static parametric knowledge, hindering performance on tasks\nrequiring open-domain up-to-date information. While enabling LLMs to interact\nwith external knowledge environments is a promising solution, current efforts\nprimarily address closed-end problems. Open-ended questions, which\ncharacterized by lacking a standard answer or providing non-unique and diverse\nanswers, remain underexplored. To bridge this gap, we present O$^2$-Searcher, a\nnovel search agent leveraging reinforcement learning to effectively tackle both\nopen-ended and closed-ended questions in the open domain. O$^2$-Searcher\nleverages an efficient, locally simulated search environment for dynamic\nknowledge acquisition, effectively decoupling the external world knowledge from\nmodel's sophisticated reasoning processes. It employs a unified training\nmechanism with meticulously designed reward functions, enabling the agent to\nidentify problem types and adapt different answer generation strategies.\nFurthermore, to evaluate performance on complex open-ended tasks, we construct\nO$^2$-QA, a high-quality benchmark featuring 300 manually curated, multi-domain\nopen-ended questions with associated web page caches. Extensive experiments\nshow that O$^2$-Searcher, using only a 3B model, significantly surpasses\nleading LLM agents on O$^2$-QA. It also achieves SOTA results on various\nclosed-ended QA benchmarks against similarly-sized models, while performing on\npar with much larger ones.",
    "pdf_url": "http://arxiv.org/pdf/2505.16582v2",
    "published": "2025-05-22T12:17:13+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16581v1",
    "title": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning",
    "authors": [
      "Max Weltevrede",
      "Moritz A. Zanger",
      "Matthijs T. J. Spaan",
      "Wendelin Böhmer"
    ],
    "abstract": "In the zero-shot policy transfer setting in reinforcement learning, the goal\nis to train an agent on a fixed set of training environments so that it can\ngeneralise to similar, but unseen, testing environments. Previous work has\nshown that policy distillation after training can sometimes produce a policy\nthat outperforms the original in the testing environments. However, it is not\nyet entirely clear why that is, or what data should be used to distil the\npolicy. In this paper, we prove, under certain assumptions, a generalisation\nbound for policy distillation after training. The theory provides two practical\ninsights: for improved generalisation, you should 1) train an ensemble of\ndistilled policies, and 2) distil it on as much data from the training\nenvironments as possible. We empirically verify that these insights hold in\nmore general settings, when the assumptions required for the theory no longer\nhold. Finally, we demonstrate that an ensemble of policies distilled on a\ndiverse dataset can generalise significantly better than the original agent.",
    "pdf_url": "http://arxiv.org/pdf/2505.16581v1",
    "published": "2025-05-22T12:15:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16580v1",
    "title": "Orbital-resolved anisotropic electron pockets in electron-doped SrTiO3 observed by ARPES",
    "authors": [
      "Yuki K. Wakabayashi",
      "Akihira Munakata",
      "Yoshitaka Taniyasu",
      "Masaki Kobayashi"
    ],
    "abstract": "SrTiO3 has attracted considerable interest as a wide-band gap semiconductor\nfor advanced high-k capacitors and photocatalytic applications. Although\nprevious angle-resolved photoemission spectroscopy (ARPES) studies have\ncharacterized the valence band structure originating from O 2p orbitals, the\nconduction band arising from Ti 3d orbitals upon electron doping, which is\ncalled electron pockets, remain poorly understood. In this study,\npolarization-dependent ARPES measurements were performed on Nb 1%-doped SrTiO3\n(001), enabling direct, orbital-selective visualization of the electron\npockets. From the measured band dispersion, we quantitatively determined their\neffective masses, anisotropy, and electron density. Our results revealed\nformation of an electron pocket at the Gamma point induced by Nb doping,\nyielding a direct bandgap of 3.79 eV at Gamma, consistent with previous optical\nmeasurements. Furthermore, the effective masses of m1 = 0.63m0 (short-axis\ndirection) and m2 = 8.0m0 (long-axis direction) were identified, where m0 is\nthe free electron mass, and the Fermi surface has been shown to be ellipsoidal.\nThe electron density derived from these dispersions was found to be 3.58e20\ncm-3. These findings provide a comprehensive picture of the conduction-band\nelectronic structure that will be crucial in the design of STO-based functional\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2505.16580v1",
    "published": "2025-05-22T12:14:42+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16579v1",
    "title": "Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning",
    "authors": [
      "Siqu Ou",
      "Hongcheng Liu",
      "Pingjie Wang",
      "Yusheng Liao",
      "Chuan Xuan",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "abstract": "While chains-of-thought (CoT) have advanced complex reasoning in multimodal\nlarge language models (MLLMs), existing methods remain confined to text or\nstatic visual domains, often faltering in dynamic spatial reasoning tasks. To\nbridge this gap, we present GRASSLAND, a novel maze navigation benchmark\ndesigned to evaluate dynamic spatial reasoning. Our experiments show that\naugmenting textual reasoning chains with dynamic visual drafts, overlaid on\ninput images, significantly outperforms conventional approaches, offering new\ninsights into spatial reasoning in evolving environments. To generalize this\ncapability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free\nframework that seamlessly integrates textual CoT with corresponding visual\ndrafts into MLLMs. Extensive evaluations demonstrate that D2R consistently\nenhances performance across diverse tasks, establishing a robust baseline for\ndynamic spatial reasoning without requiring model fine-tuning. Project is open\nat https://github.com/Cratileo/D2R.",
    "pdf_url": "http://arxiv.org/pdf/2505.16579v1",
    "published": "2025-05-22T12:14:23+00:00",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16578v3",
    "title": "Standard Running, \"Physical Running\", Cosmological Constant and Newton Coupling",
    "authors": [
      "Hikaru Kawai",
      "Nobuyoshi Ohta"
    ],
    "abstract": "Recently it is asserted that the standard beta function does not describe the\ncorrect running of the coupling constant in some theories. We show that the\nproblem arises from the assumption $\\mu=p$ ($\\mu$ is a renormalization point)\nand that a suitable choice of $\\mu$ gives the correct running. It is also\nclaimed that neither the cosmological constant nor Newton coupling run. We\nargue that running can be discussed when we consider the curved spacetime.",
    "pdf_url": "http://arxiv.org/pdf/2505.16578v3",
    "published": "2025-05-22T12:13:48+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16577v1",
    "title": "Large Language Model-Empowered Interactive Load Forecasting",
    "authors": [
      "Yu Zuo",
      "Dalin Qin",
      "Yi Wang"
    ],
    "abstract": "The growing complexity of power systems has made accurate load forecasting\nmore important than ever. An increasing number of advanced load forecasting\nmethods have been developed. However, the static design of current methods\noffers no mechanism for human-model interaction. As the primary users of\nforecasting models, system operators often find it difficult to understand and\napply these advanced models, which typically requires expertise in artificial\nintelligence (AI). This also prevents them from incorporating their experience\nand real-world contextual understanding into the forecasting process. Recent\nbreakthroughs in large language models (LLMs) offer a new opportunity to\naddress this issue. By leveraging their natural language understanding and\nreasoning capabilities, we propose an LLM-based multi-agent collaboration\nframework to bridge the gap between human operators and forecasting models. A\nset of specialized agents is designed to perform different tasks in the\nforecasting workflow and collaborate via a dedicated communication mechanism.\nThis framework embeds interactive mechanisms throughout the load forecasting\npipeline, reducing the technical threshold for non-expert users and enabling\nthe integration of human experience. Our experiments demonstrate that the\ninteractive load forecasting accuracy can be significantly improved when users\nprovide proper insight in key stages. Our cost analysis shows that the\nframework remains affordable, making it practical for real-world deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16577v1",
    "published": "2025-05-22T12:11:10+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21519v2",
    "title": "Stationary and Non-Stationary Transition Probabilities in Decision Making: Modeling COVID-19 Dynamics",
    "authors": [
      "Romario Gildas Foko Tiomela",
      "Samson Adekola Alagbe",
      "Olawale Nasiru Lawal",
      "Serges Love Teutu Talla",
      "Isabella Kemajou-Brown"
    ],
    "abstract": "This study introduces a comparative modeling framework using stationary and\nnon-stationary transition probabilities within a Markov Decision Process (MDP)\nto assess COVID-19 disease dynamics. Stationary transition probabilities assume\nconstant transition rates, while non-stationary transitions reflect\ntime-dependent behaviors including policy interventions or behavioral changes.\nWe develop a comprehensive compartmental model with transitions based on\nbinomial and multinomial processes. Mathematical models for both stationary and\nnon-stationary transition frameworks are developed and simulated over a 365-day\nperiod to emphasize dynamic variations in epidemic outcomes. Our findings\nhighlight the significance of non-stationary modeling in accurately\nrepresenting the dynamic characteristics of pandemic situations and provide\nrecommendations for optimizing public health interventions under uncertainty.\nThis comparative analysis offers useful information for epidemiological\nmodeling and decision-making in dynamic risk environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.21519v2",
    "published": "2025-05-22T12:08:55+00:00",
    "categories": [
      "physics.soc-ph",
      "q-bio.PE",
      "37A50, 37M25, 90C40, 92D30"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16576v2",
    "title": "EMULATE: A Multi-Agent Framework for Determining the Veracity of Atomic Claims by Emulating Human Actions",
    "authors": [
      "Spencer Hong",
      "Meng Luo",
      "Xinyi Wan"
    ],
    "abstract": "Determining the veracity of atomic claims is an imperative component of many\nrecently proposed fact-checking systems. Many approaches tackle this problem by\nfirst retrieving evidence by querying a search engine and then performing\nclassification by providing the evidence set and atomic claim to a large\nlanguage model, but this process deviates from what a human would do in order\nto perform the task. Recent work attempted to address this issue by proposing\niterative evidence retrieval, allowing for evidence to be collected several\ntimes and only when necessary. Continuing along this line of research, we\npropose a novel claim verification system, called EMULATE, which is designed to\nbetter emulate human actions through the use of a multi-agent framework where\neach agent performs a small part of the larger task, such as ranking search\nresults according to predefined criteria or evaluating webpage content.\nExtensive experiments on several benchmarks show clear improvements over prior\nwork, demonstrating the efficacy of our new multi-agent framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.16576v2",
    "published": "2025-05-22T12:08:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16575v1",
    "title": "Data Center Model for Transient Stability Analysis of Power Systems",
    "authors": [
      "Alberto Jimenez-Ruiz",
      "Federico Milano"
    ],
    "abstract": "The rising demand of computing power leads to the installation of a large\nnumber of Data Centers (DCs). Their Fault-Ride-Through (FRT) behavior and their\nunique power characteristics, especially for DCs catered to Artificial\nIntelligence (AI) workloads, pose a threat to the stability of power systems.\nTo ensure its stability, it is required accurate models of the loads involved.\nHere we propose a dynamic load model that properly captures the behaviour of\nDCs. Its three most defining features are the use of an Uninterrupted Power\nSupply (UPS) which sits between the server load and the grid, the cooling load\nrepresented by an induction motor, and a pulsing load that represents the\ntransients caused by contemporary DCs with significant AI workloads. The\nfeatures of the proposed model and its impact on the dynamic performance of\ntransmission systems are illustrated through a model of the all-island Irish\ntransmission system and real-world data of the DCs currently connected to this\nsystem.",
    "pdf_url": "http://arxiv.org/pdf/2505.16575v1",
    "published": "2025-05-22T12:07:19+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16574v2",
    "title": "The effect of preferential node deletion on the structure of networks that evolve via preferential attachment",
    "authors": [
      "Barak Budnick",
      "Ofer Biham",
      "Eytan Katzav"
    ],
    "abstract": "We present analytical results for the effect of preferential node deletion on\nthe structure of networks that evolve via node addition and preferential\nattachment. To this end, we consider a\npreferential-attachment-preferential-deletion (PAPD) model, in which at each\ntime step, with probability $P_{\\rm add}$ there is a growth step where an\nisolated node is added to the network, followed by the addition of $m$ edges,\nwhere each edge connects a node selected uniformly at random to a node selected\npreferentially in proportion to its degree. Alternatively, with probability\n$P_{\\rm del}=1-P_{\\rm add}$ there is a contraction step, in which a\npreferentially selected node is deleted and its links are erased. The balance\nbetween the growth and contraction processes is captured by the\ngrowth/contraction rate $\\eta=P_{\\rm add}-P_{\\rm del}$. For $0 < \\eta \\le 1$\nthe overall process is of network growth, while for $-1\\le\\eta<0$ the overall\nprocess is of network contraction. Using the master equation and the generating\nfunction formalism, we study the time-dependent degree distribution $P_t(k)$.\nIt is found that for each value of $m>0$ there is a critical value\n$\\eta_c(m)=-(m-2)/(m+2)$ such that for $\\eta_c(m)<\\eta\\le1$ the degree\ndistribution $P_t(k)$ converges towards a stationary distribution $P_{\\rm\nst}(k)$. In the special case of pure growth, where $\\eta=1$, the model is\nreduced to a preferential attachment growth model and $P_{\\rm st}(k)$ exhibits\na power-law tail, which is a characteristic of scale-free networks. In\ncontrast, for $\\eta_c(m)<\\eta<1$ the distribution $P_{\\rm st}(k)$ exhibits an\nexponential tail, which has a well-defined scale.This implies a phase\ntransition at $\\eta=1$, in contrast with the\npreferential-attachment-random-deletion (PARD) model [B. Budnick, O. Biham and\nE. Katzav, J. Stat. Mech. 013401 (2025)], in which the power-law tail remains\nintact as long as $\\eta>0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16574v2",
    "published": "2025-05-22T12:05:24+00:00",
    "categories": [
      "physics.soc-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16573v1",
    "title": "From Local Patterns to Global Understanding: Cross-Stock Trend Integration for Enhanced Predictive Modeling",
    "authors": [
      "Yi Hu",
      "Hanchi Ren",
      "Jingjing Deng",
      "Xianghua Xie"
    ],
    "abstract": "Stock price prediction is a critical area of financial forecasting,\ntraditionally approached by training models using the historical price data of\nindividual stocks. While these models effectively capture single-stock\npatterns, they fail to leverage potential correlations among stock trends,\nwhich could improve predictive performance. Current single-stock learning\nmethods are thus limited in their ability to provide a broader understanding of\nprice dynamics across multiple stocks. To address this, we propose a novel\nmethod that merges local patterns into a global understanding through\ncross-stock pattern integration. Our strategy is inspired by Federated Learning\n(FL), a paradigm designed for decentralized model training. FL enables\ncollaborative learning across distributed datasets without sharing raw data,\nfacilitating the aggregation of global insights while preserving data privacy.\nIn our adaptation, we train models on individual stock data and iteratively\nmerge them to create a unified global model. This global model is subsequently\nfine-tuned on specific stock data to retain local relevance. The proposed\nstrategy enables parallel training of individual stock models, facilitating\nefficient utilization of computational resources and reducing overall training\ntime. We conducted extensive experiments to evaluate the proposed method,\ndemonstrating that it outperforms benchmark models and enhances the predictive\ncapabilities of state-of-the-art approaches. Our results highlight the efficacy\nof Cross-Stock Trend Integration (CSTI) in advancing stock price prediction,\noffering a robust alternative to traditional single-stock learning\nmethodologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16573v1",
    "published": "2025-05-22T12:04:10+00:00",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16572v2",
    "title": "On the equality of De Branges-Rovnyak and Dirichlet spaces",
    "authors": [
      "Eugenio Dellepiane",
      "Marco M. Peloso",
      "Anita Tabacco"
    ],
    "abstract": "This work is devoted to the comparison of de Branges--Rovnyak $H(b)$ spaces\nharmonically weighted Dirichlet spaces $\\mathcal{D}_\\mu$. We completely\ncharacterize which $H(b)$ spaces are also harmonically weighted Dirichlet\nspaces $\\mathcal{D}_\\mu$, when $\\mu$ is a finite sum of atoms. This is a\ngeneralization of a previous result by Costara--Ransford \\cite{costara2013}: we\nmake no assumptions on the Pythagorean pair $(b,a)$, and we produce new\nexamples.",
    "pdf_url": "http://arxiv.org/pdf/2505.16572v2",
    "published": "2025-05-22T12:03:55+00:00",
    "categories": [
      "math.FA",
      "math.CV",
      "30H45, 30H10, 46E22, 30J99"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16571v1",
    "title": "Does freezing impede the growth of random recursive trees?",
    "authors": [
      "Anna Brandenberger",
      "Simon Briend",
      "Hannah Cairns",
      "Robin Khanfir",
      "Igor Kortchemski"
    ],
    "abstract": "Uniform attachment with freezing is an extension of the classical model of\nrandom recursive trees, in which trees are recursively built by attaching new\nvertices to old ones. In the model of uniform attachment with freezing,\nvertices are allowed to freeze, in the sense that new vertices cannot be\nattached to already frozen ones. We study the impact of removing attachment\nand/or freezing steps on the height of the trees. We show in particular that\nremoving an attachment step can increase the expected height, and that freezing\ncannot substantially decrease the height of random recursive trees. Our methods\nare based on coupling arguments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16571v1",
    "published": "2025-05-22T12:02:02+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16570v1",
    "title": "URLs Help, Topics Guide: Understanding Metadata Utility in LLM Training",
    "authors": [
      "Dongyang Fan",
      "Vinko Sabolčec",
      "Martin Jaggi"
    ],
    "abstract": "Large Language Models (LLMs) are commonly pretrained on vast corpora of text\nwithout utilizing contextual metadata such as source, quality, or topic,\nleading to a context-free learning paradigm. While recent studies suggest that\nadding metadata like URL information as context (i.e., auxiliary inputs not\nused in the loss calculation) can improve training efficiency and downstream\nperformance, they offer limited understanding of which types of metadata are\ntruly effective and under what conditions. In this work, we conduct a\nsystematic evaluation and find that not all metadata types contribute equally.\nOnly URL context speeds up training, whereas quality scores and topic/format\ndomain information offer no clear benefit. Furthermore, the improved downstream\nperformances of URL conditioning emerge only when longer prompts are used at\ninference time. In addition, we demonstrate that context-aware pretraining\nenables more controllable generation than context-free pretraining, in a\nclassifier-free guidance fashion. Although topic and format metadata do not\naccelerate training, they are effective for steering outputs, offering\nhuman-interpretable control over generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16570v1",
    "published": "2025-05-22T12:01:20+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16569v2",
    "title": "Macdonald deformation of Vogel's universality and link hyperpolynomials",
    "authors": [
      "Liudmila Bishler",
      "Andrei Mironov",
      "Alexei Morozov"
    ],
    "abstract": "Vogel's universality implies a unified description of the adjoint sector of\nrepresentation theory for simple Lie algebras in terms of three parameters\n$\\alpha,\\beta,\\gamma$, which are homogeneous coordinates of Vogel's plane.\nActually this is true (if at all) only for a piece of representation theory\ncaptured by knot/Chern-Simons theory, where some irreducible representations\nare often undistinguishable and combined into new ``universally-irreducible\"\nentities (uirreps). We consider from this point of view the recently discovered\nMacdonald deformation of quantum dimensions, for which a kind of universality\nholds for the ADE series. The claim is that universal are not Macdonald\ndimensions themselves, but their products with Littlewood-Richardson\ncoefficients, which themselves are functions of $q$ and $t$ in Macdonald\ntheory. These products are precisely what arises in knot/refined Chern-Simons\ntheory. Actually, we consider the simplest decomposition of adjoint square into\nsix uirreps and obtain the universal formulas for hyperpolynomials of the Hopf\nlink and, more generally, of the torus links $T[2,2n]$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16569v2",
    "published": "2025-05-22T12:00:31+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP",
      "math.QA"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16568v1",
    "title": "Arf rings, simple singularities and reflexive modules",
    "authors": [
      "Özgür Esentepe"
    ],
    "abstract": "In a pandemic era preprint, Dao showed showed two remarkable properties of\nArf rings: under some mild conditions, they admit finitely many indecomposable\nreflexive modules up to isomorphism and every reflexive module is actually\nisomorphic to its own dual. In fact, the latter property characterises Arf\nrings. Arf rings are one dimensional rings and it is natural to wonder what\nhappens in higher Krull dimension. In this paper, we investigate the self-dual\nproperty for commutative Noetherian local rings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16568v1",
    "published": "2025-05-22T12:00:07+00:00",
    "categories": [
      "math.AC",
      "13D07, 13C05, 13C14, 13C60"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16567v2",
    "title": "Finetuning-Activated Backdoors in LLMs",
    "authors": [
      "Thibaud Gloaguen",
      "Mark Vero",
      "Robin Staab",
      "Martin Vechev"
    ],
    "abstract": "Finetuning openly accessible Large Language Models (LLMs) has become standard\npractice for achieving task-specific performance improvements. Until now,\nfinetuning has been regarded as a controlled and secure process in which\ntraining on benign datasets led to predictable behaviors. In this paper, we\ndemonstrate for the first time that an adversary can create poisoned LLMs that\ninitially appear benign but exhibit malicious behaviors once finetuned by\ndownstream users. To this end, our proposed attack, FAB (Finetuning-Activated\nBackdoor), poisons an LLM via meta-learning techniques to simulate downstream\nfinetuning, explicitly optimizing for the emergence of malicious behaviors in\nthe finetuned models. At the same time, the poisoned LLM is regularized to\nretain general capabilities and to exhibit no malicious behaviors prior to\nfinetuning. As a result, when users finetune the seemingly benign model on\ntheir own datasets, they unknowingly trigger its hidden backdoor behavior. We\ndemonstrate the effectiveness of FAB across multiple LLMs and three target\nbehaviors: unsolicited advertising, refusal, and jailbreakability.\nAdditionally, we show that FAB-backdoors are robust to various finetuning\nchoices made by the user (e.g., dataset, number of steps, scheduler). Our\nfindings challenge prevailing assumptions about the security of finetuning,\nrevealing yet another critical attack vector exploiting the complexities of\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16567v2",
    "published": "2025-05-22T11:59:44+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16566v1",
    "title": "ScholarBench: A Bilingual Benchmark for Abstraction, Comprehension, and Reasoning Evaluation in Academic Contexts",
    "authors": [
      "Dongwon Noh",
      "Donghyeok Koh",
      "Junghun Yuk",
      "Gyuwan Kim",
      "Jaeyong Lee",
      "Kyungtae Lim",
      "Cheoneum Park"
    ],
    "abstract": "Prior benchmarks for evaluating the domain-specific knowledge of large\nlanguage models (LLMs) lack the scalability to handle complex academic tasks.\nTo address this, we introduce \\texttt{ScholarBench}, a benchmark centered on\ndeep expert knowledge and complex academic problem-solving, which evaluates the\nacademic reasoning ability of LLMs and is constructed through a three-step\nprocess. \\texttt{ScholarBench} targets more specialized and logically complex\ncontexts derived from academic literature, encompassing five distinct problem\ntypes. Unlike prior benchmarks, \\texttt{ScholarBench} evaluates the\nabstraction, comprehension, and reasoning capabilities of LLMs across eight\ndistinct research domains. To ensure high-quality evaluation data, we define\ncategory-specific example attributes and design questions that are aligned with\nthe characteristic research methodologies and discourse structures of each\ndomain. Additionally, this benchmark operates as an English-Korean bilingual\ndataset, facilitating simultaneous evaluation for linguistic capabilities of\nLLMs in both languages. The benchmark comprises 5,031 examples in Korean and\n5,309 in English, with even state-of-the-art models like o3-mini achieving an\naverage evaluation score of only 0.543, demonstrating the challenging nature of\nthis benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2505.16566v1",
    "published": "2025-05-22T11:59:06+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16565v1",
    "title": "M2SVid: End-to-End Inpainting and Refinement for Monocular-to-Stereo Video Conversion",
    "authors": [
      "Nina Shvetsova",
      "Goutam Bhat",
      "Prune Truong",
      "Hilde Kuehne",
      "Federico Tombari"
    ],
    "abstract": "We tackle the problem of monocular-to-stereo video conversion and propose a\nnovel architecture for inpainting and refinement of the warped right view\nobtained by depth-based reprojection of the input left view. We extend the\nStable Video Diffusion (SVD) model to utilize the input left video, the warped\nright video, and the disocclusion masks as conditioning input to generate a\nhigh-quality right camera view. In order to effectively exploit information\nfrom neighboring frames for inpainting, we modify the attention layers in SVD\nto compute full attention for discoccluded pixels. Our model is trained to\ngenerate the right view video in an end-to-end manner by minimizing image space\nlosses to ensure high-quality generation. Our approach outperforms previous\nstate-of-the-art methods, obtaining an average rank of 1.43 among the 4\ncompared methods in a user study, while being 6x faster than the second placed\nmethod.",
    "pdf_url": "http://arxiv.org/pdf/2505.16565v1",
    "published": "2025-05-22T11:58:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16564v1",
    "title": "Graph splitting methods: Fixed points and strong convergence for linear subspaces",
    "authors": [
      "Francisco J. Aragón-Artacho",
      "Heinz H. Bauschke",
      "Rubén Campoy",
      "César López-Pastor"
    ],
    "abstract": "In this paper, we develop a general analysis for the fixed points of the\noperators defining the graph splitting methods from [SIAM J. Optim., 34 (2024),\npp. 1569-1594] by Bredies, Chenchene and Naldi. We particularize it to the case\nwhere the maximally monotone operators are normal cones of closed linear\nsubspaces and provide an explicit formula for the limit points of the graph\nsplitting schemes. We exemplify these results on some particular algorithms,\nunifying in this way some results previously derived as well as obtaining new\nones.",
    "pdf_url": "http://arxiv.org/pdf/2505.16564v1",
    "published": "2025-05-22T11:57:07+00:00",
    "categories": [
      "math.OC",
      "47H05, 47H09, 47N10, 65K05, 90C25"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.20313v1",
    "title": "Reasoning in Neurosymbolic AI",
    "authors": [
      "Son Tran",
      "Edjard Mota",
      "Artur d'Avila Garcez"
    ],
    "abstract": "Knowledge representation and reasoning in neural networks have been a\nlong-standing endeavor which has attracted much attention recently. The\nprincipled integration of reasoning and learning in neural networks is a main\nobjective of the area of neurosymbolic Artificial Intelligence (AI). In this\nchapter, a simple energy-based neurosymbolic AI system is described that can\nrepresent and reason formally about any propositional logic formula. This\ncreates a powerful combination of learning from data and knowledge and logical\nreasoning. We start by positioning neurosymbolic AI in the context of the\ncurrent AI landscape that is unsurprisingly dominated by Large Language Models\n(LLMs). We identify important challenges of data efficiency, fairness and\nsafety of LLMs that might be addressed by neurosymbolic reasoning systems with\nformal reasoning capabilities. We then discuss the representation of logic by\nthe specific energy-based system, including illustrative examples and empirical\nevaluation of the correspondence between logical reasoning and energy\nminimization using Restricted Boltzmann Machines (RBM). Learning from data and\nknowledge is also evaluated empirically and compared with a symbolic, neural\nand a neurosymbolic system. Results reported in this chapter in an accessible\nway are expected to reignite the research on the use of neural networks as\nmassively-parallel models for logical reasoning and promote the principled\nintegration of reasoning and learning in deep networks. We conclude the chapter\nwith a discussion of the importance of positioning neurosymbolic AI within a\nbroader framework of formal reasoning and accountability in AI, discussing the\nchallenges for neurosynbolic AI to tackle the various known problems of\nreliability of deep learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.20313v1",
    "published": "2025-05-22T11:57:04+00:00",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16563v2",
    "title": "A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices",
    "authors": [
      "Chen Gong",
      "Rui Xing",
      "Zhenzhe Zheng",
      "Fan Wu"
    ],
    "abstract": "The demand for machine learning (ML) model training on edge devices is\nescalating due to data privacy and personalized service needs. However, we\nobserve that current on-device model training is hampered by the\nunder-utilization of on-device data, due to low training throughput, limited\nstorage and diverse data importance. To improve data resource utilization, we\npropose a two-stage data selection framework {\\sf Titan} to select the most\nimportant data batch from streaming data for model training with guaranteed\nefficiency and effectiveness. Specifically, in the first stage, {\\sf Titan}\nfilters out a candidate dataset with potentially high importance in a\ncoarse-grained manner.In the second stage of fine-grained selection, we propose\na theoretically optimal data selection strategy to identify the data batch with\nthe highest model performance improvement to current training round. To further\nenhance time-and-resource efficiency, {\\sf Titan} leverages a pipeline to\nco-execute data selection and model training, and avoids resource conflicts by\nexploiting idle computing resources. We evaluate {\\sf Titan} on real-world edge\ndevices and three representative edge computing tasks with diverse models and\ndata modalities. Empirical results demonstrate that {\\sf Titan} achieves up to\n$43\\%$ reduction in training time and $6.2\\%$ increase in final accuracy with\nminor system overhead, such as data processing delay, memory footprint and\nenergy consumption.",
    "pdf_url": "http://arxiv.org/pdf/2505.16563v2",
    "published": "2025-05-22T11:53:48+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16562v4",
    "title": "Hunting Hidden Axion Signals in Pulsar Dispersion Measurements with Machine Learning",
    "authors": [
      "Haihao Shi",
      "Zhenyang Huang",
      "Qiyu Yan",
      "Jun Li",
      "Guoliang Lü",
      "Xuefei Chen"
    ],
    "abstract": "In axion models, interactions between axions and electromagnetic waves induce\nfrequency-dependent time delays determined by the axion mass and decay\nconstant. These small delays are difficult to detect, limiting the\neffectiveness of traditional methods. We compute such delays under realistic\nradio telescope conditions and identify a prominent dispersive feature near\nhalf the axion mass, which appears non-divergent within the limits of\nobservational resolution. Based on this, we develop a machine learning pipeline\nthat achieves 95\\% classification accuracy and demonstrates robust detection\nperformance in low signal-to-noise regimes. The method's robustness is\nconfirmed against false positives using both simulated noisy data and\nreal-world, known-null observations. Future improvements in optical clock\nprecision and telescope bandwidth, particularly with instruments such as the\nQitai Radio Telescope, may enhance constraints on the axion decay constant by\nup to four orders of magnitude in the $10^{-6} \\sim 10^{-4}$ eV mass range.",
    "pdf_url": "http://arxiv.org/pdf/2505.16562v4",
    "published": "2025-05-22T11:52:56+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16561v3",
    "title": "Auto-nnU-Net: Towards Automated Medical Image Segmentation",
    "authors": [
      "Jannis Becktepe",
      "Leona Hennig",
      "Steffen Oeltze-Jafra",
      "Marius Lindauer"
    ],
    "abstract": "Medical Image Segmentation (MIS) includes diverse tasks, from bone to organ\nsegmentation, each with its own challenges in finding the best segmentation\nmodel. The state-of-the-art AutoML-related MIS-framework nnU-Net automates many\naspects of model configuration but remains constrained by fixed hyperparameters\nand heuristic design choices. As a full-AutoML framework for MIS, we propose\nAuto-nnU-Net, a novel nnU-Net variant enabling hyperparameter optimization\n(HPO), neural architecture search (NAS), and hierarchical NAS (HNAS).\nAdditionally, we propose Regularized PriorBand to balance model accuracy with\nthe computational resources required for training, addressing the resource\nconstraints often faced in real-world medical settings that limit the\nfeasibility of extensive training procedures. We evaluate our approach across\ndiverse MIS datasets from the well-established Medical Segmentation Decathlon,\nanalyzing the impact of AutoML techniques on segmentation performance,\ncomputational efficiency, and model design choices. The results demonstrate\nthat our AutoML approach substantially improves the segmentation performance of\nnnU-Net on 6 out of 10 datasets and is on par on the other datasets while\nmaintaining practical resource requirements. Our code is available at\nhttps://github.com/automl/AutoNNUnet.",
    "pdf_url": "http://arxiv.org/pdf/2505.16561v3",
    "published": "2025-05-22T11:52:16+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16560v2",
    "title": "On the Auslander--Reiten Theory for Extended Hearts of Proper Connective DG Algebras",
    "authors": [
      "Nao Mochizuki",
      "Marvin Plogmann"
    ],
    "abstract": "We prove that, for a proper connective dg algebra $A$ with cohomology\nconcentrated in degrees between $1-d$ and $0$, the extended heart\n$\\mathcal{D}^{fd}(A)^{(-d,0]}\\subseteq \\mathcal{D}^{fd}(A)$ is an\nextriangulated category with almost-split conflations. We also prove a version\nof the 1st Brauer--Thrall Conjecture in this context.",
    "pdf_url": "http://arxiv.org/pdf/2505.16560v2",
    "published": "2025-05-22T11:52:04+00:00",
    "categories": [
      "math.RT",
      "Primary: 18G80. Secondary: 16E45, 16G70"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16559v1",
    "title": "CTRAP: Embedding Collapse Trap to Safeguard Large Language Models from Harmful Fine-Tuning",
    "authors": [
      "Biao Yi",
      "Tiansheng Huang",
      "Baolei Zhang",
      "Tong Li",
      "Lihai Nie",
      "Zheli Liu",
      "Li Shen"
    ],
    "abstract": "Fine-tuning-as-a-service, while commercially successful for Large Language\nModel (LLM) providers, exposes models to harmful fine-tuning attacks. As a\nwidely explored defense paradigm against such attacks, unlearning attempts to\nremove malicious knowledge from LLMs, thereby essentially preventing them from\nbeing used to perform malicious tasks. However, we highlight a critical flaw:\nthe powerful general adaptability of LLMs allows them to easily bypass\nselective unlearning by rapidly relearning or repurposing their capabilities\nfor harmful tasks. To address this fundamental limitation, we propose a\nparadigm shift: instead of selective removal, we advocate for inducing model\ncollapse--effectively forcing the model to \"unlearn everything\"--specifically\nin response to updates characteristic of malicious adaptation. This collapse\ndirectly neutralizes the very general capabilities that attackers exploit,\ntackling the core issue unaddressed by selective unlearning. We introduce the\nCollapse Trap (CTRAP) as a practical mechanism to implement this concept\nconditionally. Embedded during alignment, CTRAP pre-configures the model's\nreaction to subsequent fine-tuning dynamics. If updates during fine-tuning\nconstitute a persistent attempt to reverse safety alignment, the pre-configured\ntrap triggers a progressive degradation of the model's core language modeling\nabilities, ultimately rendering it inert and useless for the attacker.\nCrucially, this collapse mechanism remains dormant during benign fine-tuning,\nensuring the model's utility and general capabilities are preserved for\nlegitimate users. Extensive empirical results demonstrate that CTRAP\neffectively counters harmful fine-tuning risks across various LLMs and attack\nsettings, while maintaining high performance in benign scenarios. Our code is\navailable at https://anonymous.4open.science/r/CTRAP.",
    "pdf_url": "http://arxiv.org/pdf/2505.16559v1",
    "published": "2025-05-22T11:47:08+00:00",
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16558v2",
    "title": "SU(3) flavor symmetry analysis of hyperon non-leptonic two body decays",
    "authors": [
      "Xin Wu",
      "Qi Chen",
      "Ye Xing",
      "Zhi-Peng Xing",
      "Ruilin Zhu"
    ],
    "abstract": "This paper present a systematic study of hyperon non-leptonic two-body decays\ninduced by light quark transitions, particularly the $s \\rightarrow u\\bar{u}d$\nprocess, within the framework of SU(3) flavor symmetry. The effective weak\nHamiltonian is decomposed into irreducible SU(3) representations, including the\n27-plet and octet components, and applied to analyze decays of octet and\ndecuplet baryons and charmed baryons. Both the irreducible representation\namplitude (IRA) approach and the topological diagrammatic analysis (TDA) are\nemployed to construct decay amplitudes and constrain the parameter space. SU(3)\nsymmetry-breaking effects arising from the strange quark mass are incorporated\nsystematically. A global fit to current experimental data allows us to extract\nform factors and predict branching ratios and asymmetry parameters for several\ndecay channels, including $\\Lambda^0 \\rightarrow p\\pi^-$, $\\Sigma^+ \\rightarrow\np\\pi^0$, and $\\Omega^- \\rightarrow \\Xi^0\\pi^-$. Our results demonstrate the\npredictive power of SU(3) flavor symmetry while highlighting significant\nsymmetry-breaking effects, especially in amplitudes related to the 27-plet.\nNotably, the $\\Sigma^+ \\rightarrow p\\pi^0$ decay channel exhibits a deviation\nexceeding $1\\sigma$ from experimental measurements, suggesting the possible\npresence of new decay mechanisms or contributions beyond the Standard Model.\nThis work provides a systematic framework for future tests of the Standard\nModel and the search for new physics in hyperon decays.",
    "pdf_url": "http://arxiv.org/pdf/2505.16558v2",
    "published": "2025-05-22T11:46:50+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16557v2",
    "title": "Is Your LLM-Based Multi-Agent a Reliable Real-World Planner? Exploring Fraud Detection in Travel Planning",
    "authors": [
      "Junchi Yao",
      "Jianhua Xu",
      "Tianyu Xin",
      "Ziyi Wang",
      "Shenzhe Zhu",
      "Shu Yang",
      "Di Wang"
    ],
    "abstract": "The rise of Large Language Model-based Multi-Agent Planning has leveraged\nadvanced frameworks to enable autonomous and collaborative task execution. Some\nsystems rely on platforms like review sites and social media, which are prone\nto fraudulent information, such as fake reviews or misleading descriptions.\nThis reliance poses risks, potentially causing financial losses and harming\nuser experiences. To evaluate the risk of planning systems in real-world\napplications, we introduce \\textbf{WandaPlan}, an evaluation environment\nmirroring real-world data and injected with deceptive content. We assess system\nperformance across three fraud cases: Misinformation Fraud, Team-Coordinated\nMulti-Person Fraud, and Level-Escalating Multi-Round Fraud. We reveal\nsignificant weaknesses in existing frameworks that prioritize task efficiency\nover data authenticity. At the same time, we validate WandaPlan's\ngeneralizability, capable of assessing the risks of real-world open-source\nplanning frameworks. To mitigate the risk of fraud, we propose integrating an\nanti-fraud agent, providing a solution for reliable planning.",
    "pdf_url": "http://arxiv.org/pdf/2505.16557v2",
    "published": "2025-05-22T11:46:46+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02003v1",
    "title": "Navigating the Edge-Cloud Continuum: A State-of-Practice Survey",
    "authors": [
      "Loris Belcastro",
      "Fabrizio Marozzo",
      "Alessio Orsino",
      "Domenico Talia",
      "Paolo Trunfio"
    ],
    "abstract": "The edge-cloud continuum has emerged as a transformative paradigm that meets\nthe growing demand for low-latency, scalable, end-to-end service delivery by\nintegrating decentralized edge resources with centralized cloud\ninfrastructures. Driven by the exponential growth of IoT-generated data and the\nneed for real-time responsiveness, this continuum features multi-layered\narchitectures. However, its adoption is hindered by infrastructural challenges,\nfragmented standards, and limited guidance for developers and researchers.\nExisting surveys rarely tackle practical implementation or recent industrial\nadvances. This survey closes those gaps from a developer-oriented perspective,\nintroducing a conceptual framework for navigating the edge-cloud continuum. We\nsystematically examine architectural models, performance metrics, and paradigms\nfor computation, communication, and deployment, together with enabling\ntechnologies and widely used edge-to-cloud platforms. We also discuss\nreal-world applications in smart cities, healthcare, and Industry 4.0, as well\nas tools for testing and experimentation. Drawing on academic research and\npractices of leading cloud providers, this survey serves as a practical guide\nfor developers and a structured reference for researchers, while identifying\nopen challenges and emerging trends that will shape the future of the\ncontinuum.",
    "pdf_url": "http://arxiv.org/pdf/2506.02003v1",
    "published": "2025-05-22T11:45:35+00:00",
    "categories": [
      "cs.DC",
      "cs.ET",
      "cs.NI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16556v2",
    "title": "Rigidity for Patterson--Sullivan systems with applications to random walks and entropy rigidity",
    "authors": [
      "Dongryul M. Kim",
      "Andrew Zimmer"
    ],
    "abstract": "In this paper we introduce Patterson--Sullivan systems, which consist of a\ngroup action on a compact metrizable space and a quasi-invariant measure which\nbehaves like a classical Patterson--Sullivan measure. For such systems we prove\na generalization of Tukia's measurable boundary rigidity theorem. We then apply\nthis generalization to (1) study the singularity conjecture for\nPatterson--Sullivan measures (or, conformal densities) and stationary measures\nof random walks on isometry groups of Gromov hyperbolic spaces, mapping class\ngroups, and discrete subgroups of semisimple Lie groups; (2) prove versions of\nTukia's theorem for word hyperbolic groups, Teichm\\\"uller spaces, and higher\nrank symmetric spaces; and (3) prove an entropy rigidity result for\npseudo-Riemannian hyperbolic spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.16556v2",
    "published": "2025-05-22T11:45:23+00:00",
    "categories": [
      "math.GT",
      "math.DS",
      "math.GR",
      "math.PR"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16555v2",
    "title": "The Darboux Classification of Curl Forces",
    "authors": [
      "Arash Yavari",
      "Alain Goriely"
    ],
    "abstract": "We study particle dynamics under curl forces. These forces are a class of\nnon-conservative, non-dissipative, position-dependent forces that cannot be\nexpressed as gradient of a potential function. We show that the fundamental\nquantity of particle dynamics under curl forces is a work $1$-form. By using\nthe Darboux classification of differential $1$-forms on $\\mathbb{R}^2$ and\n$\\mathbb{R}^3$, we establish that any curl force in two dimensions has at most\ntwo generalized potentials, while in three dimensions, it has at most three.\nThese potentials generalize the single potential of conservative systems. For\nany curl force field, we introduce a corresponding conservative force field --\nthe conservative auxiliary force. The Hamiltonian of this conservative force is\na conserved quantity of motion for the dynamics of a particle under the curl\nforce, although it is not the physical energy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16555v2",
    "published": "2025-05-22T11:43:11+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16554v1",
    "title": "Comment on \"Shell-Shaped Quantum Droplet in a Three-Component Ultracold Bose Gas\"",
    "authors": [
      "Francesco Ancilotto"
    ],
    "abstract": "In a recent paper (Y. Ma and X. Cui, Phys. Rev. Lett. 134, 043402 (2025)), a\nnew type of shell-shaped Bose-Einstein condensate with a self-bound character\nhas been proposed, made of three-component $Na^{23}K^{39}K^{41}$ Bose mixture\n(species (1,2,3) in the following), where the mixtures (1, 2) and (2, 3) both\nform quantum droplets. The proposed structures are made of an outer shell of\nliquid (1,2) enveloping a spherical core of (2,3) liquid, which is claimed to\nbe stable without the need of any trapping potential. I comment in the\nfollowing that these structures are not actually the ground-states solutions to\nthe system but rather local energy minima, and most likely impossible to\nrealize in practice.",
    "pdf_url": "http://arxiv.org/pdf/2505.16554v1",
    "published": "2025-05-22T11:42:54+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.16553v1",
    "title": "Denoising Milky Way stellar survey data with normalizing flow models",
    "authors": [
      "Ziyang Yan",
      "Jason L. Sanders"
    ],
    "abstract": "The Gaia dataset has revealed many intricate Milky Way substructures in\nexquisite detail, including moving groups and the phase spiral. Precise\ncharacterisation of these features and detailed comparisons to theoretical\nmodels require engaging with Gaia's heteroscedastic noise model, particularly\nin more distant parts of the Galactic disc and halo. We propose a general,\nnovel machine-learning approach using normalizing flows for denoising density\nestimation, with particular focus on density estimation from stellar survey\ndata such as that from Gaia. Normalizing flows transform a simple base\ndistribution into a complex target distribution through bijective\ntransformations resulting in a highly expressive and flexible model. The\ndenoising is performed using importance sampling. We demonstrate that this\ngeneral procedure works excellently on Gaia data by reconstructing detailed\nlocal velocity distributions artificially corrupted with noise. For example, we\nshow the multiple branches of the Hercules stream and the phase-space spiral\ncan both be well captured by our model. We discuss hyperparameter choice to\noptimally recover substructure and compare our approach to extreme\ndeconvolution. The model therefore promises to be a robust tool for studying\nthe Milky Way's kinematics in Galactic locations where the noise from Gaia is\nsignificant.",
    "pdf_url": "http://arxiv.org/pdf/2505.16553v1",
    "published": "2025-05-22T11:40:34+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16552v4",
    "title": "Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains",
    "authors": [
      "Wenhui Tan",
      "Jiaze Li",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Jian Luan",
      "Ruihua Song"
    ],
    "abstract": "Large Language Models (LLMs) achieve superior performance through\nChain-of-Thought (CoT) reasoning, but these token-level reasoning chains are\ncomputationally expensive and inefficient. In this paper, we introduce\nCompressed Latent Reasoning (CoLaR), a novel framework that dynamically\ncompresses reasoning processes in latent space through a two-stage training\napproach. First, during supervised fine-tuning, CoLaR extends beyond next-token\nprediction by incorporating an auxiliary next compressed embedding prediction\nobjective. This process merges embeddings of consecutive tokens using a\ncompression factor randomly sampled from a predefined range, and trains a\nspecialized latent head to predict distributions of subsequent compressed\nembeddings. Second, we enhance CoLaR through reinforcement learning (RL) that\nleverages the latent head's non-deterministic nature to explore diverse\nreasoning paths and exploit more compact ones. This approach enables CoLaR to:\ni) perform reasoning at a dense latent level (i.e., silently), substantially\nreducing reasoning chain length, and ii) dynamically adjust reasoning speed at\ninference time by simply prompting the desired compression factor. Extensive\nexperiments across four mathematical reasoning datasets demonstrate that CoLaR\nachieves 14.1% higher accuracy than latent-based baseline methods at comparable\ncompression ratios, and reduces reasoning chain length by 53.3% with only 4.8%\nperformance degradation compared to explicit CoT method. Moreover, when applied\nto more challenging mathematical reasoning tasks, our RL-enhanced CoLaR\ndemonstrates performance gains of up to 5.4% while dramatically reducing latent\nreasoning chain length by 82.8%. The code and models will be released upon\nacceptance.",
    "pdf_url": "http://arxiv.org/pdf/2505.16552v4",
    "published": "2025-05-22T11:40:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16551v1",
    "title": "Restricted Chase Termination: You Want More than Fairness",
    "authors": [
      "David Carral",
      "Lukas Gerlach",
      "Lucas Larroque",
      "Michaël Thomazo"
    ],
    "abstract": "The chase is a fundamental algorithm with ubiquitous uses in database theory.\nGiven a database and a set of existential rules (aka tuple-generating\ndependencies), it iteratively extends the database to ensure that the rules are\nsatisfied in a most general way. This process may not terminate, and a major\nproblem is to decide whether it does. This problem has been studied for a large\nnumber of chase variants, which differ by the conditions under which a rule is\napplied to extend the database. Surprisingly, the complexity of the universal\ntermination of the restricted (aka standard) chase is not fully understood. We\nclose this gap by placing universal restricted chase termination in the\nanalytical hierarchy. This higher hardness is due to the fairness condition,\nand we propose an alternative condition to reduce the hardness of universal\ntermination.",
    "pdf_url": "http://arxiv.org/pdf/2505.16551v1",
    "published": "2025-05-22T11:40:22+00:00",
    "categories": [
      "cs.LO",
      "cs.DB"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16550v1",
    "title": "Towards Machine-actionable FAIR Digital Objects with a Typing Model that Enables Operations",
    "authors": [
      "Maximilian Inckmann",
      "Nicolas Blumenröhr",
      "Rossella Aversa"
    ],
    "abstract": "FAIR Digital Objects support research data management aligned with the FAIR\nprinciples. To be machine-actionable, they must support operations that\ninteract with their contents. This can be achieved by associating operations\nwith FAIR-DO data types. However, current typing models and Data Type\nRegistries lack support for type-associated operations. In this work, we\nintroduce a typing model that describes type-associated and technology-agnostic\nFAIR Digital Object Operations in a machine-actionable way, building and\nimproving on the existing concepts. In addition, we introduce the Integrated\nData Type and Operations Registry with Inheritance System, a prototypical\nimplementation of this model that integrates inheritance mechanisms for data\ntypes, a rule-based validation system, and the computation of type-operation\nassociations. Our approach significantly improves the machine-actionability of\nFAIR Digital Objects, paving the way towards dynamic, interoperable, and\nreproducible research workflows.",
    "pdf_url": "http://arxiv.org/pdf/2505.16550v1",
    "published": "2025-05-22T11:38:19+00:00",
    "categories": [
      "cs.DL",
      "cs.DB"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16549v1",
    "title": "Towards Coordinate- and Dimension-Agnostic Machine Learning for Partial Differential Equations",
    "authors": [
      "Trung V. Phan",
      "George A. Kevrekidis",
      "Soledad Villar",
      "Yannis G. Kevrekidis",
      "Juan M. Bello-Rivas"
    ],
    "abstract": "The machine learning methods for data-driven identification of partial\ndifferential equations (PDEs) are typically defined for a given number of\nspatial dimensions and a choice of coordinates the data have been collected in.\nThis dependence prevents the learned evolution equation from generalizing to\nother spaces. In this work, we reformulate the problem in terms of coordinate-\nand dimension-independent representations, paving the way toward what we call\n``spatially liberated\" PDE learning. To this end, we employ a machine learning\napproach to predict the evolution of scalar field systems expressed in the\nformalism of exterior calculus, which is coordinate-free and immediately\ngeneralizes to arbitrary dimensions by construction. We demonstrate the\nperformance of this approach in the FitzHugh-Nagumo and Barkley\nreaction-diffusion models, as well as the Patlak-Keller-Segel model informed by\nin-situ chemotactic bacteria observations. We provide extensive numerical\nexperiments that demonstrate that our approach allows for seamless transitions\nacross various spatial contexts. We show that the field dynamics learned in one\nspace can be used to make accurate predictions in other spaces with different\ndimensions, coordinate systems, boundary conditions, and curvatures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16549v1",
    "published": "2025-05-22T11:37:55+00:00",
    "categories": [
      "cs.LG",
      "35Q92, 68T07",
      "I.2.6; G.1.8"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16548v1",
    "title": "Incremental Sequence Classification with Temporal Consistency",
    "authors": [
      "Lucas Maystre",
      "Gabriel Barello",
      "Tudor Berariu",
      "Aleix Cambray",
      "Rares Dolga",
      "Alvaro Ortega Gonzalez",
      "Andrei Nica",
      "David Barber"
    ],
    "abstract": "We address the problem of incremental sequence classification, where\npredictions are updated as new elements in the sequence are revealed. Drawing\non temporal-difference learning from reinforcement learning, we identify a\ntemporal-consistency condition that successive predictions should satisfy. We\nleverage this condition to develop a novel loss function for training\nincremental sequence classifiers. Through a concrete example, we demonstrate\nthat optimizing this loss can offer substantial gains in data efficiency. We\napply our method to text classification tasks and show that it improves\npredictive accuracy over competing approaches on several benchmark datasets. We\nfurther evaluate our approach on the task of verifying large language model\ngenerations for correctness in grade-school math problems. Our results show\nthat models trained with our method are better able to distinguish promising\ngenerations from unpromising ones after observing only a few tokens.",
    "pdf_url": "http://arxiv.org/pdf/2505.16548v1",
    "published": "2025-05-22T11:37:53+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16547v1",
    "title": "Find the Fruit: Designing a Zero-Shot Sim2Real Deep RL Planner for Occlusion Aware Plant Manipulation",
    "authors": [
      "Nitesh Subedi",
      "Hsin-Jung Yang",
      "Devesh K. Jha",
      "Soumik Sarkar"
    ],
    "abstract": "This paper presents an end-to-end deep reinforcement learning (RL) framework\nfor occlusion-aware robotic manipulation in cluttered plant environments. Our\napproach enables a robot to interact with a deformable plant to reveal hidden\nobjects of interest, such as fruits, using multimodal observations. We decouple\nthe kinematic planning problem from robot control to simplify zero-shot\nsim2real transfer for the trained policy. Our results demonstrate that the\ntrained policy, deployed using our framework, achieves up to 86.7% success in\nreal-world trials across diverse initial conditions. Our findings pave the way\ntoward autonomous, perception-driven agricultural robots that intelligently\ninteract with complex foliage plants to \"find the fruit\" in challenging\noccluded scenarios, without the need for explicitly designed geometric and\ndynamic models of every plant scenario.",
    "pdf_url": "http://arxiv.org/pdf/2505.16547v1",
    "published": "2025-05-22T11:37:39+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16546v2",
    "title": "Twisted Partition Functions as Order Parameters",
    "authors": [
      "Jun Maeda",
      "Yuya Tanizaki"
    ],
    "abstract": "For quantum field theories with global symmetry, we can study the behavior of\nthe partition function with the background gauge field to diagnose different\nquantum phases. For the case of discrete symmetries, we find that the\nsymmetry-twisted partition function works as an order parameter that\ndiscriminates spontaneous symmetry breaking (SSB), symmetry-protected\ntopological (SPT) states, and symmetry-enriched topological (SET) states. We\nthen consider its application to the case of 4d Yang-Mills theory with adjoint\nmatters to understand the relation between the twisted partition function and\nthe Wilson-'t Hooft classification. We also study its behavior for the\nspontaneously broken U(1) symmetry and interpret the result from the viewpoint\nof the mixed anomaly with the emergent solitonic symmetry.",
    "pdf_url": "http://arxiv.org/pdf/2505.16546v2",
    "published": "2025-05-22T11:37:23+00:00",
    "categories": [
      "hep-th",
      "cond-mat.str-el"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16545v2",
    "title": "$\\mathcal{PT-}$Symmetric Open Quantum Systems: Information Theoretic Facets",
    "authors": [
      "Baibhab Bose",
      "Devvrat Tiwari",
      "Subhashish Banerjee"
    ],
    "abstract": "The theory of an $\\eta$-pseudo Hermitian Hamiltonian with $\\mathcal{PT}$\nsymmetry is reviewed and extended to include open system dynamics. Inspired by\na simple light matter interaction open system model, information theoretic\nquantities like a non-Markovian witness and fidelity are calculated for the\n$\\mathcal{PT-}$symmetric Hamiltonian, and the results are compared with their\ncorresponding Hermitian counterparts. The nature of entanglement between two\n$\\mathcal{PT-}$symmetric and Hermitian open quantum systems is calculated, and\nthe contrast observed.",
    "pdf_url": "http://arxiv.org/pdf/2505.16545v2",
    "published": "2025-05-22T11:36:48+00:00",
    "categories": [
      "quant-ph",
      "hep-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16544v1",
    "title": "Phonon-limited carrier transport in the Weyl semimetal TaAs",
    "authors": [
      "Zhe Liu",
      "Shashi B. Mishra",
      "Jae-Mo Lihm",
      "Samuel Poncé",
      "Elena R. Margine"
    ],
    "abstract": "Topological Weyl semimetals represent a novel class of quantum materials that\nexhibit remarkable properties arising from their unique electronic structure.\nIn this work, we employ state-of-the-art ab initio methods to investigate the\nrole of the electron-phonon interactions on the charge transport properties of\nTaAs. Our calculations of the temperature-dependent electrical conductivity\nwith the iterative Boltzmann transport equation show excellent agreement with\nexperimental measurements above 100 K. Extending the analysis to doped systems,\nwe demonstrate that even small shifts in the Fermi level can lead to\nsubstantial changes in conductivity, driven by the complex topology of the\nFermi surface. In particular, modifications in Fermi surface nesting emerge as\na key factor influencing scattering processes and carrier lifetimes. These\nfindings offer critical insights into the microscopic mechanisms that govern\ntransport in TaAs and highlight the sensitivity of Weyl semimetals to doping\nand carrier dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16544v1",
    "published": "2025-05-22T11:36:28+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16543v1",
    "title": "Abiotic Ozone in the Observable Atmospheres of Venus and Venus-like Exoplanets",
    "authors": [
      "Robb Calder",
      "Oliver Shorttle",
      "Sean Jordan",
      "Paul Rimmer",
      "Tereza Constantinou"
    ],
    "abstract": "Ozone is a potential biosignature and disambuguator between Earth-like and\nVenus-like exoplanets due to its association on Earth with photosynthetically\nproduced oxygen (O$_2$). However, the existence of ozone in Venus's observable\natmosphere, a planet with no known life, raises the possibility of ozone\nbiosignature false-positives on Venus-like exoplanets. We use a photochemical\nmodel of Venus's atmosphere to investigate the origin of its mesospheric ozone\nlayer, and to predict how similar ozone layers would manifest for Venus-like\nexoplanets. For Venus, our model shows that the previously proposed fluxes of O\natoms produced on the dayside and transported to the nightside cannot generate\nenough ozone to match the observed nightside ozone concentrations without also\nproducing O$_2$ in excess of the observed upper limit. Nor can sufficient ozone\nbe produced by varying the lower-atmosphere chemistry, atmospheric thermal\nstructure, or received stellar flux in our model of Venus's atmosphere. These\nresults imply that a presently unknown chemical pathway is responsible for the\nozone production in Venus's nightside mesosphere. Ozone production rates from\nthis pathway of 10$^5$--10$^7$ cm$^{-3}$s$^{-1}$ above the cloud layer on the\nnightside can re-produce the observed O$_3$ concentrations. Generalised to\nVenus-like exoplanets, known chemistry similarly fails to produce ozone in the\nabundance seen in the Venusian mesosphere. However, until the origin of Venus's\nozone is understood, we cannot rule out that ozone production at concentrations\nobservable with JWST will be common on abiotic Venus-like worlds, a possibility\nthat limits the usefulness of ozone as a habsignature and as a biosignature.",
    "pdf_url": "http://arxiv.org/pdf/2505.16543v1",
    "published": "2025-05-22T11:35:50+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16542v2",
    "title": "Cancellation properties for exotic $4$-dimensional positive scalar curvature metrics",
    "authors": [
      "Johannes Ebert"
    ],
    "abstract": "Ruberman constructed families $\\{g_n\\vert n \\in \\mathbb{N}\\} \\subset\n\\mathcal{R}^+ (M)$ of metrics of positive scalar curvature on certain\n$4$-manifolds which are concordant but lie in different path components of\n$\\mathcal{R}^+ (M)$. We prove a cancellation result along the following lines.\nFor each closed manifold $N$, there is a map $\\nu_N: \\mathcal{R}^+ (M) \\to\n\\mathcal{R}^+ (M \\times N)$, well-defined up to homotopy, that takes the\nproduct with $N$. We prove that when $N$ has positive dimension $\\nu_N$ takes\nall metrics of Ruberman's family to the same path component. This is trivial\nwhen $N$ has a psc metric and follows from pseudoisotopy theory when $\\dim (N)\n\\geq 3$. Our proof is cobordism theoretic in nature and also applies to\n$\\dim(N) =1,2$. The proof relies on rigidity properties for the action of the\ndiffeomorphism group on $\\mathcal{R}^+(L)$ for high-dimensional $N$ and a\ncalculation of $\\pi_1(\\mathrm{MTSO(4)})$ that we also carry out.\n  Recently, Auckly and Ruberman exhibited examples of elements in higher\nhomotopy groups of $\\mathcal{R}^+(M^4)$ for certain $M$. Using the same method,\nwe also prove that these elements lie in the kernel of the induced map\n$(\\nu_N)_*$ on rational homotopy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16542v2",
    "published": "2025-05-22T11:33:54+00:00",
    "categories": [
      "math.AT",
      "math.DG"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16541v1",
    "title": "Generalized Polarization Matrix Approach to Near-Field Optical Chirality",
    "authors": [
      "Kayn A. Forbes",
      "David L. Andrews"
    ],
    "abstract": "For paraxial light beams and electromagnetic fields, the Stokes vector and\npolarization matrix provide equivalent scalar measures of optical chirality,\nwidely used in linear optics. However, growing interest in non-paraxial fields,\nwith fully three-dimensional polarization components, necessitates an extended\nframework. Here, we develop a general theory for characterizing optical\nchirality in arbitrary electromagnetic fields, formulated through extensions of\nthe polarization matrix approach. This framework applies to both near- and\nfar-field optical helicity and chirality. As examples, we demonstrate its\nrelevance to near-zone fields from chiral dipole emission and the focal plane\nof tightly focused beams.",
    "pdf_url": "http://arxiv.org/pdf/2505.16541v1",
    "published": "2025-05-22T11:33:13+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.16540v1",
    "title": "TextureSAM: Towards a Texture Aware Foundation Model for Segmentation",
    "authors": [
      "Inbal Cohen",
      "Boaz Meivar",
      "Peihan Tu",
      "Shai Avidan",
      "Gal Oren"
    ],
    "abstract": "Segment Anything Models (SAM) have achieved remarkable success in object\nsegmentation tasks across diverse datasets. However, these models are\npredominantly trained on large-scale semantic segmentation datasets, which\nintroduce a bias toward object shape rather than texture cues in the image.\nThis limitation is critical in domains such as medical imaging, material\nclassification, and remote sensing, where texture changes define object\nboundaries. In this study, we investigate SAM's bias toward semantics over\ntextures and introduce a new texture-aware foundation model, TextureSAM, which\nperforms superior segmentation in texture-dominant scenarios. To achieve this,\nwe employ a novel fine-tuning approach that incorporates texture augmentation\ntechniques, incrementally modifying training images to emphasize texture\nfeatures. By leveraging a novel texture-alternation of the ADE20K dataset, we\nguide TextureSAM to prioritize texture-defined regions, thereby mitigating the\ninherent shape bias present in the original SAM model. Our extensive\nexperiments demonstrate that TextureSAM significantly outperforms SAM-2 on both\nnatural (+0.2 mIoU) and synthetic (+0.18 mIoU) texture-based segmentation\ndatasets. The code and texture-augmented dataset will be publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.16540v1",
    "published": "2025-05-22T11:31:56+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.11054v2",
    "title": "Adaptive Composition of Machine Learning as a Service (MLaaS) for IoT Environments",
    "authors": [
      "Deepak Kanneganti",
      "Sajib Mistry",
      "Sheik Mohammad Mostakim Fattah",
      "Aneesh Krishna",
      "Monowar Bhuyan"
    ],
    "abstract": "The dynamic nature of Internet of Things (IoT) environments challenges the\nlong-term effectiveness of Machine Learning as a Service (MLaaS) compositions.\nThe uncertainty and variability of IoT environments lead to fluctuations in\ndata distribution, e.g., concept drift and data heterogeneity, and evolving\nsystem requirements, e.g., scalability demands and resource limitations. This\npaper proposes an adaptive MLaaS composition framework to ensure a seamless,\nefficient, and scalable MLaaS composition. The framework integrates a service\nassessment model to identify underperforming MLaaS services and a candidate\nselection model to filter optimal replacements. An adaptive composition\nmechanism is developed that incrementally updates MLaaS compositions using a\ncontextual multi-armed bandit optimization strategy. By continuously adapting\nto evolving IoT constraints, the approach maintains Quality of Service (QoS)\nwhile reducing the computational cost associated with recomposition from\nscratch. Experimental results on a real-world dataset demonstrate the\nefficiency of our proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2506.11054v2",
    "published": "2025-05-22T11:31:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16539v1",
    "title": "A neural network approach to determining photometric metallicities of M-type dwarf stars",
    "authors": [
      "C. Duque-Arribas",
      "H. M. Tabernero",
      "D. Montes",
      "J. A. Caballero",
      "E. Galceran"
    ],
    "abstract": "M dwarfs are the most abundant stars in the Galaxy and serve as key targets\nfor stellar and exoplanetary studies. It is particularly challenging to\ndetermine their metallicities because their spectra are complex. For this\nreason, several authors have focused on photometric estimates of the M-dwarf\nmetallicity. Although artificial neural networks have been used in the\nframework of modern astrophysics, their application to a photometric\nmetallicity estimate for M dwarfs remains unexplored. We develop an accurate\nmethod for estimating the photometric metallicities of M dwarfs using\nartificial neural networks to address the limitations of traditional empirical\napproaches. We trained a neural network on a dataset of M dwarfs with\nspectroscopically derived metallicities. We used eight absolute magnitudes in\nthe visible and infrared from Gaia, 2MASS, and WISE as input features. Batch\nnormalization and dropout regularization stabilized the training and prevented\noverfitting. We applied the Monte Carlo dropout technique to obtain more robust\npredictions. The neural network demonstrated a strong performance in estimating\nphotometric metallicities for M dwarfs in the range of -0.45<[Fe/H]<0.45dex and\nfor spectral types as late as M5.0V. On the test sample, the predictions showed\nuncertainties down to 0.08dex. This surpasses the accuracy of previous methods.\nWe further validated our results using an additional sample of 46 M dwarfs in\nwide binary systems with FGK-type primary stars with well-defined metallicities\nand achieved an excellent predictive performance that surpassed the 0.1dex\nerror threshold. This study introduces a ML-based framework for estimating the\nphotometric metallicities of M dwarfs and provides a scalable data-driven\nsolution for analyzing large photometric surveys. The results outline the\npotential of artificial neural networks to enhance the determination of stellar\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.16539v1",
    "published": "2025-05-22T11:30:01+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16538v1",
    "title": "Mechanistic Understanding and Mitigation of Language Confusion in English-Centric Large Language Models",
    "authors": [
      "Ercong Nie",
      "Helmut Schmid",
      "Hinrich Schütze"
    ],
    "abstract": "Language confusion -- where large language models (LLMs) generate unintended\nlanguages against the user's need -- remains a critical challenge, especially\nfor English-centric models. We present the first mechanistic interpretability\n(MI) study of language confusion, combining behavioral benchmarking with\nneuron-level analysis. Using the Language Confusion Benchmark (LCB), we show\nthat confusion points (CPs) -- specific positions where language switches occur\n-- are central to this phenomenon. Through layer-wise analysis with TunedLens\nand targeted neuron attribution, we reveal that transition failures in the\nfinal layers drive confusion. We further demonstrate that editing a small set\nof critical neurons, identified via comparative analysis with\nmultilingual-tuned models, substantially mitigates confusion without harming\ngeneral competence or fluency. Our approach matches multilingual alignment in\nconfusion reduction for most languages and yields cleaner, higher-quality\noutputs. These findings provide new insights into the internal dynamics of LLMs\nand highlight neuron-level interventions as a promising direction for robust,\ninterpretable multilingual language modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.16538v1",
    "published": "2025-05-22T11:29:17+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17154v1",
    "title": "Can Large Language Models Design Biological Weapons? Evaluating Moremi Bio",
    "authors": [
      "Gertrude Hattoh",
      "Jeremiah Ayensu",
      "Nyarko Prince Ofori",
      "Solomon Eshun",
      "Darlington Akogo"
    ],
    "abstract": "Advances in AI, particularly LLMs, have dramatically shortened drug discovery\ncycles by up to 40% and improved molecular target identification. However,\nthese innovations also raise dual-use concerns by enabling the design of toxic\ncompounds. Prompting Moremi Bio Agent without the safety guardrails to\nspecifically design novel toxic substances, our study generated 1020 novel\ntoxic proteins and 5,000 toxic small molecules. In-depth computational toxicity\nassessments revealed that all the proteins scored high in toxicity, with\nseveral closely matching known toxins such as ricin, diphtheria toxin, and\ndisintegrin-based snake venom proteins. Some of these novel agents showed\nsimilarities with other several known toxic agents including disintegrin\neristostatin, metalloproteinase, disintegrin triflavin, snake venom\nmetalloproteinase, corynebacterium ulcerans toxin. Through quantitative risk\nassessments and scenario analyses, we identify dual-use capabilities in current\nLLM-enabled biodesign pipelines and propose multi-layered mitigation\nstrategies. The findings from this toxicity assessment challenge claims that\nlarge language models (LLMs) are incapable of designing bioweapons. This\nreinforces concerns about the potential misuse of LLMs in biodesign, posing a\nsignificant threat to research and development (R&D). The accessibility of such\ntechnology to individuals with limited technical expertise raises serious\nbiosecurity risks. Our findings underscore the critical need for robust\ngovernance and technical safeguards to balance rapid biotechnological\ninnovation with biosecurity imperatives.",
    "pdf_url": "http://arxiv.org/pdf/2505.17154v1",
    "published": "2025-05-22T11:27:50+00:00",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16537v1",
    "title": "Kinetically controlling surface atom arrangements in thermally robust, amorphous high-entropy alloy nanoparticles by solvent selection",
    "authors": [
      "Varatharaja Nallathambi",
      "Se-Ho Kim",
      "Baptiste Gault",
      "Sven Reichenberger",
      "Dierk Raabe",
      "Stephan Barcikowski"
    ],
    "abstract": "The ability to tailor nanoscale surface atom arrangements through\nmulti-elemental compositional control provides high-entropy nanoalloys with\npromising functional properties. Developing a fundamental understanding of\nnanoalloy formation mechanisms during synthesis is therefore essential for\neffectively engineering the surface composition and resulting functional\nproperties. Using the Cantor alloy (CrMnFeCoNi) as a model system, we\ninvestigate how solvent selection during reactive, nanosecond-pulsed laser\nsynthesis influences carbon doping and the resulting changes in nanoparticle\nmorphology, structure, and composition. Supersaturated carbon incorporation,\npartitioned from the organic solvent molecules, produces amorphous\nnanoparticles with distinctive carbon shells, thermally stable up to 350\n{\\deg}C. We propose kinetically controlled particle formation mechanisms and\nrationalize the criticality of the time scales between the competing reactions\nof carbon doping, carbon shell formation, and coalescence of metallic\nfragments, ruling compositional and morphological characteristics. This work\ndemonstrates effective solvent-driven surface-compositional control in\namorphous high-entropy nanoalloys. It introduces a novel synthesis approach for\ntailoring surface atom arrangements through carbon incorporation via reactive,\npulsed laser synthesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.16537v1",
    "published": "2025-05-22T11:27:23+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.17153v1",
    "title": "Amplify Adjacent Token Differences: Enhancing Long Chain-of-Thought Reasoning with Shift-FFN",
    "authors": [
      "Yao Xu",
      "Mingyu Xu",
      "Fangyu Lei",
      "Wangtao Sun",
      "Xiangrong Zeng",
      "Bingning Wang",
      "Guang Liu",
      "Shizhu He",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Recently, models such as OpenAI-o1 and DeepSeek-R1 have demonstrated\nremarkable performance on complex reasoning tasks through Long Chain-of-Thought\n(Long-CoT) reasoning. Although distilling this capability into student models\nsignificantly enhances their performance, this paper finds that fine-tuning\nLLMs with full parameters or LoRA with a low rank on long CoT data often leads\nto Cyclical Reasoning, where models repeatedly reiterate previous inference\nsteps until the maximum length limit. Further analysis reveals that smaller\ndifferences in representations between adjacent tokens correlates with a higher\ntendency toward Cyclical Reasoning. To mitigate this issue, this paper proposes\nShift Feedforward Networks (Shift-FFN), a novel approach that edits the current\ntoken's representation with the previous one before inputting it to FFN. This\narchitecture dynamically amplifies the representation differences between\nadjacent tokens. Extensive experiments on multiple mathematical reasoning tasks\ndemonstrate that LoRA combined with Shift-FFN achieves higher accuracy and a\nlower rate of Cyclical Reasoning across various data sizes compared to full\nfine-tuning and standard LoRA. Our data and code are available at\nhttps://anonymous.4open.science/r/Shift-FFN",
    "pdf_url": "http://arxiv.org/pdf/2505.17153v1",
    "published": "2025-05-22T11:27:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16536v1",
    "title": "Role of Translational Noise in Motility-Induced Phase Separation of Hard Active Particles",
    "authors": [
      "Felipe Hawthorne",
      "Pablo de Castro",
      "José A. Freire"
    ],
    "abstract": "Self-propelled particles, like motile cells and artificial colloids, can\nspontaneously form macroscopic clusters. This phenomenon is called\nmotility-induced phase separation (MIPS) and occurs even without attractive\nforces, provided that the self-propulsion direction fluctuates slowly. In\naddition to rotational noise, these particles may experience translational\nnoise, not coupled to rotational noise, due to environmental fluctuations. We\nstudy the role of translational noise in the clustering of active Brownian hard\ndisks. To tease apart the contribution of translational noise, we model\nexcluded-volume interactions through a Monte-Carlo-like overlap rejection\napproach. Upon increasing the translational diffusivity, we find that clusters\nbecome more rounded (less fractal), eventually transitioning to genuine MIPS.\nFor sufficiently higher translational diffusivity, clusters melt down. We\ndevelop a theory for the cluster mass distribution, and employ a hydrodynamic\napproach with parameters taken from the simulation, that explains the\nclustering phase diagram.",
    "pdf_url": "http://arxiv.org/pdf/2505.16536v1",
    "published": "2025-05-22T11:26:35+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.16535v1",
    "title": "SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane Deformation and Latent Diffusion",
    "authors": [
      "Asrar Alruwayqi"
    ],
    "abstract": "We present a novel framework for dynamic 3D scene reconstruction that\nintegrates three key components: an explicit tri-plane deformation field, a\nview-conditioned canonical radiance field with spherical harmonics (SH)\nattention, and a temporally-aware latent diffusion prior. Our method encodes 4D\nscenes using three orthogonal 2D feature planes that evolve over time, enabling\nefficient and compact spatiotemporal representation. These features are\nexplicitly warped into a canonical space via a deformation offset field,\neliminating the need for MLP-based motion modeling.\n  In canonical space, we replace traditional MLP decoders with a structured\nSH-based rendering head that synthesizes view-dependent color via attention\nover learned frequency bands improving both interpretability and rendering\nefficiency. To further enhance fidelity and temporal consistency, we introduce\na transformer-guided latent diffusion module that refines the tri-plane and\ndeformation features in a compressed latent space. This generative module\ndenoises scene representations under ambiguous or out-of-distribution (OOD)\nmotion, improving generalization.\n  Our model is trained in two stages: the diffusion module is first pre-trained\nindependently, and then fine-tuned jointly with the full pipeline using a\ncombination of image reconstruction, diffusion denoising, and temporal\nconsistency losses. We demonstrate state-of-the-art results on synthetic\nbenchmarks, surpassing recent methods such as HexPlane and 4D Gaussian\nSplatting in visual quality, temporal coherence, and robustness to sparse-view\ndynamic inputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16535v1",
    "published": "2025-05-22T11:25:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.11053v1",
    "title": "Bootstrapping your behavior: a new pretraining strategy for user behavior sequence data",
    "authors": [
      "Weichang Wu",
      "Xiaolu Zhang",
      "Jun Zhou",
      "Yuchen Li",
      "Wenwen Xia"
    ],
    "abstract": "User Behavior Sequence (UBS) modeling is crucial in industrial applications.\nAs data scale and task diversity grow, UBS pretraining methods have become\nincreasingly pivotal. State-of-the-art UBS pretraining methods rely on\npredicting behavior distributions. The key step in these methods is\nconstructing a selected behavior vocabulary. However, this manual step is\nlabor-intensive and prone to bias. The limitation of vocabulary capacity also\ndirectly affects models' generalization ability. In this paper, we introduce\nBootstrapping Your Behavior (\\model{}), a novel UBS pretraining strategy that\npredicts an automatically constructed supervision embedding summarizing all\nbehaviors' information within a future time window, eliminating the manual\nbehavior vocabulary selection. In implementation, we incorporate a\nstudent-teacher encoder scheme to construct the pretraining supervision\neffectively. Experiments on two real-world industrial datasets and eight\ndownstream tasks demonstrate that \\model{} achieves an average improvement of\n3.9\\% in AUC and 98.9\\% in training throughput. Notably, the model exhibits\nmeaningful attention patterns and cluster representations during pretraining\nwithout any label supervision. In our online deployment over two months, the\npretrained model improves the KS by about 2.7\\% and 7.1\\% over the baseline\nmodel for two financial overdue risk prediction tasks in the Alipay mobile\napplication, which reduces bad debt risk by millions of dollars for Ant group.",
    "pdf_url": "http://arxiv.org/pdf/2506.11053v1",
    "published": "2025-05-22T11:23:38+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16533v1",
    "title": "Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video Reconstruction",
    "authors": [
      "Jiacong Chen",
      "Qingyu Mao",
      "Youneng Bao",
      "Xiandong Meng",
      "Fanyang Meng",
      "Ronggang Wang",
      "Yongsheng Liang"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) has emerged as a high-fidelity and efficient\nparadigm for online free-viewpoint video (FVV) reconstruction, offering viewers\nrapid responsiveness and immersive experiences. However, existing online\nmethods face challenge in prohibitive storage requirements primarily due to\npoint-wise modeling that fails to exploit the motion properties. To address\nthis limitation, we propose a novel Compact Gaussian Streaming (ComGS)\nframework, leveraging the locality and consistency of motion in dynamic scene,\nthat models object-consistent Gaussian point motion through keypoint-driven\nmotion representation. By transmitting only the keypoint attributes, this\nframework provides a more storage-efficient solution. Specifically, we first\nidentify a sparse set of motion-sensitive keypoints localized within motion\nregions using a viewspace gradient difference strategy. Equipped with these\nkeypoints, we propose an adaptive motion-driven mechanism that predicts a\nspatial influence field for propagating keypoint motion to neighboring Gaussian\npoints with similar motion. Moreover, ComGS adopts an error-aware correction\nstrategy for key frame reconstruction that selectively refines erroneous\nregions and mitigates error accumulation without unnecessary overhead. Overall,\nComGS achieves a remarkable storage reduction of over 159 X compared to\n3DGStream and 14 X compared to the SOTA method QUEEN, while maintaining\ncompetitive visual fidelity and rendering speed. Our code will be released.",
    "pdf_url": "http://arxiv.org/pdf/2505.16533v1",
    "published": "2025-05-22T11:22:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16532v1",
    "title": "Causal-Invariant Cross-Domain Out-of-Distribution Recommendation",
    "authors": [
      "Jiajie Zhu",
      "Yan Wang",
      "Feng Zhu",
      "Pengfei Ding",
      "Hongyang Liu",
      "Zhu Sun"
    ],
    "abstract": "Cross-Domain Recommendation (CDR) aims to leverage knowledge from a\nrelatively data-richer source domain to address the data sparsity problem in a\nrelatively data-sparser target domain. While CDR methods need to address the\ndistribution shifts between different domains, i.e., cross-domain distribution\nshifts (CDDS), they typically assume independent and identical distribution\n(IID) between training and testing data within the target domain. However, this\nIID assumption rarely holds in real-world scenarios due to single-domain\ndistribution shift (SDDS). The above two co-existing distribution shifts lead\nto out-of-distribution (OOD) environments that hinder effective knowledge\ntransfer and generalization, ultimately degrading recommendation performance in\nCDR. To address these co-existing distribution shifts, we propose a novel\nCausal-Invariant Cross-Domain Out-of-distribution Recommendation framework,\ncalled CICDOR. In CICDOR, we first learn dual-level causal structures to infer\ndomain-specific and domain-shared causal-invariant user preferences for\ntackling both CDDS and SDDS under OOD environments in CDR. Then, we propose an\nLLM-guided confounder discovery module that seamlessly integrates LLMs with a\nconventional causal discovery method to extract observed confounders for\neffective deconfounding, thereby enabling accurate causal-invariant preference\ninference. Extensive experiments on two real-world datasets demonstrate the\nsuperior recommendation accuracy of CICDOR over state-of-the-art methods across\nvarious OOD scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16532v1",
    "published": "2025-05-22T11:21:51+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16531v2",
    "title": "HOFT: Householder Orthogonal Fine-tuning",
    "authors": [
      "Alejandro Moreno Arcas",
      "Albert Sanchis",
      "Jorge Civera",
      "Alfons Juan"
    ],
    "abstract": "Adaptation of foundation models using low-rank methods is a widespread\napproach. Another way to adapt these models is to employ orthogonal fine-tuning\nmethods, which are less time and memory efficient despite their good\ngeneralization properties. In this work, we propose Householder Orthogonal\nFine-tuning (HOFT), a novel orthogonal fine-tuning method that aims to\nalleviate time and space complexity. Moreover, some theoretical properties of\nthe orthogonal fine-tuning paradigm are explored. From this exploration, Scaled\nHouseholder Orthogonal Fine-tuning (SHOFT) is proposed. Both HOFT and SHOFT are\nevaluated in downstream tasks, namely commonsense reasoning, machine\ntranslation, subject-driven generation and mathematical reasoning. Compared\nwith state-of-the-art adaptation methods, HOFT and SHOFT show comparable or\nbetter results.",
    "pdf_url": "http://arxiv.org/pdf/2505.16531v2",
    "published": "2025-05-22T11:20:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16530v1",
    "title": "DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection",
    "authors": [
      "Yuliang Yan",
      "Haochun Tang",
      "Shuo Yan",
      "Enyan Dai"
    ],
    "abstract": "Large language models (LLMs) are considered valuable Intellectual Properties\n(IP) for legitimate owners due to the enormous computational cost of training.\nIt is crucial to protect the IP of LLMs from malicious stealing or unauthorized\ndeployment. Despite existing efforts in watermarking and fingerprinting LLMs,\nthese methods either impact the text generation process or are limited in\nwhite-box access to the suspect model, making them impractical. Hence, we\npropose DuFFin, a novel $\\textbf{Du}$al-Level $\\textbf{Fin}$gerprinting\n$\\textbf{F}$ramework for black-box setting ownership verification. DuFFin\nextracts the trigger pattern and the knowledge-level fingerprints to identify\nthe source of a suspect model. We conduct experiments on a variety of models\ncollected from the open-source website, including four popular base models as\nprotected LLMs and their fine-tuning, quantization, and safety alignment\nversions, which are released by large companies, start-ups, and individual\nusers. Results show that our method can accurately verify the copyright of the\nbase protected LLM on their model variants, achieving the IP-ROC metric greater\nthan 0.95. Our code is available at\nhttps://github.com/yuliangyan0807/llm-fingerprint.",
    "pdf_url": "http://arxiv.org/pdf/2505.16530v1",
    "published": "2025-05-22T11:16:46+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16529v2",
    "title": "Modular forms of CM type mod $\\ell$",
    "authors": [
      "Luís Dieulefait",
      "Josep González",
      "Joan-C. Lario"
    ],
    "abstract": "We say that a normalized modular form without complex multiplication is of CM\ntype modulo $\\ell$ by an imaginary quadratic field $K$ if its Fourier\ncoefficients $a_p$ are $0$ modulo a prime ideal dividing $\\ell$ for every prime\n$p$ inert in $K$.\n  In this paper, we address the following problem: Given a weight 2 cuspidal\nHecke eigenform $f$ without CM which is of CM type modulo $\\ell$ by an\nimaginary quadratic field $K$, does there exist a congruence modulo $\\ell$\nbetween $f$ and a genuine CM modular form of weight 2? We conjecture that the\nanswer is yes, and prove this conjecture in most cases.\n  We study three situations: the case of modular forms attached to abelian\nsurfaces with quaternionic multiplication, the case of $\\mathbb{Q}$-curves\ncompletely defined over an imaginary quadratic field, and the case of elliptic\ncurves over $\\mathbb{Q}$ with modular-maximal cyclic group of order $16$ as\n$5$-torsion Galois module. In all these situations, at some specific primes\n$\\ell$, it can be shown that the residual representation is monomial by a\nquadratic imaginary field $K$ (or even more than one), and we can conclude that\nin most of these cases there is a congruence with a CM modular form. Finally,\nwe present some of the numerical evidence that initially led us to formulate\nthe conjecture.",
    "pdf_url": "http://arxiv.org/pdf/2505.16529v2",
    "published": "2025-05-22T11:16:41+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16528v1",
    "title": "Influence of Bar Formation on Star Formation Segregation and Stellar Migration: Implications for Variations in the Age Distribution of Milky Way Disk Stars",
    "authors": [
      "Junichi Baba"
    ],
    "abstract": "We present a chemo-dynamical $N$-body/hydrodynamic simulation of an isolated\nMilky Way-like galaxy to investigate how bar formation influences star\nformation rates, stellar migration, and the resulting age and metallicity\ndistributions of disk stars. Focusing on the transient epoch of bar formation,\na phase that triggers gas inflows, enhances local star formation, and drives\nsignificant orbital migration, we find that the star formation rate in the\ninner disk exhibits a pronounced peak during this period. This behavior arises\nfrom the combined effect of vigorous star formation driven by strong spiral\narms prior to bar formation and the subsequent suppression of star formation\nonce the bar is established. In contrast, star formation in the outer disk\npersists after bar formation at modest levels, and enhanced outward migration\nof stars originally formed in the inner regions gives rise to a pronounced peak\nin the outer disk's stellar age distribution corresponding to the bar formation\nepoch. Moreover, stars formed during this epoch tend to exhibit higher\ngas-phase metallicities, reflecting their origin in more metal-rich inner\nregions. Although our model does not capture every detail of the Milky Way's\ncomplex evolution, our results highlight the dominant role of bar driven\nmigration in segregating star formation activity and in shaping the long-term\nchemical and age structure of the Galactic disk. Recent observational studies\nsuggest that the Milky Way's bar is approximately 8 Gyr old; therefore, our\nfindings imply that the age distribution of stars in the solar circle and outer\ndisk should show a corresponding peak around that age.",
    "pdf_url": "http://arxiv.org/pdf/2505.16528v1",
    "published": "2025-05-22T11:16:15+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16527v1",
    "title": "Joint Relational Database Generation via Graph-Conditional Diffusion Models",
    "authors": [
      "Mohamed Amine Ketata",
      "David Lüdke",
      "Leo Schwinn",
      "Stephan Günnemann"
    ],
    "abstract": "Building generative models for relational databases (RDBs) is important for\napplications like privacy-preserving data release and augmenting real datasets.\nHowever, most prior work either focuses on single-table generation or relies on\nautoregressive factorizations that impose a fixed table order and generate\ntables sequentially. This approach limits parallelism, restricts flexibility in\ndownstream applications like missing value imputation, and compounds errors due\nto commonly made conditional independence assumptions. We propose a\nfundamentally different approach: jointly modeling all tables in an RDB without\nimposing any order. By using a natural graph representation of RDBs, we propose\nthe Graph-Conditional Relational Diffusion Model (GRDM). GRDM leverages a graph\nneural network to jointly denoise row attributes and capture complex\ninter-table dependencies. Extensive experiments on six real-world RDBs\ndemonstrate that our approach substantially outperforms autoregressive\nbaselines in modeling multi-hop inter-table correlations and achieves\nstate-of-the-art performance on single-table fidelity metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16527v1",
    "published": "2025-05-22T11:12:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16526v1",
    "title": "EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance",
    "authors": [
      "Heejae Suh",
      "Yejin Jeon",
      "Deokhyung Kang",
      "Taehee Park",
      "Yejin Min",
      "Gary Geunbae Lee"
    ],
    "abstract": "Small large language models (sLLMs) offer the advantage of being lightweight\nand efficient, which makes them suitable for resource-constrained environments.\nHowever, sLLMs often struggle to maintain topic consistency in task-oriented\ndialogue systems, which is critical for scenarios such as service chatbots.\nSpecifically, it is important to ensure that the model denies off-topic or\nmalicious inputs and adheres to its intended functionality so as to prevent\npotential misuse and uphold reliability. Towards this, existing activation\nengineering approaches have been proposed to manipulate internal activations\nduring inference. While these methods are effective in certain scenarios, our\npreliminary experiments reveal their limitations in ensuring topic adherence.\nTherefore, to address this, we propose a novel approach termed Entropy-scaled\nSteering vectors for Topic Maintenance (EnSToM). EnSToM dynamically adjusts the\nsteering intensity based on input uncertainty, which allows the model to handle\noff-topic distractors effectively while preserving on-topic accuracy. Our\nexperiments demonstrate that EnSToM achieves significant performance gain with\na relatively small data size compared to fine-tuning approaches. By improving\ntopic adherence without compromising efficiency, our approach provides a robust\nsolution for enhancing sLLM-based dialogue systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16526v1",
    "published": "2025-05-22T11:12:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17152v1",
    "title": "LSM-VEC: A Large-Scale Disk-Based System for Dynamic Vector Search",
    "authors": [
      "Shurui Zhong",
      "Dingheng Mo",
      "Siqiang Luo"
    ],
    "abstract": "Vector search underpins modern AI applications by supporting approximate\nnearest neighbor (ANN) queries over high-dimensional embeddings in tasks like\nretrieval-augmented generation (RAG), recommendation systems, and multimodal\nsearch. Traditional ANN search indices (e.g., HNSW) are limited by memory\nconstraints at large data scale. Disk-based indices such as DiskANN reduce\nmemory overhead but rely on offline graph construction, resulting in costly and\ninefficient vector updates. The state-of-the-art clustering-based approach\nSPFresh offers better scalability but suffers from reduced recall due to coarse\npartitioning. Moreover, SPFresh employs in-place updates to maintain its index\nstructure, limiting its efficiency in handling high-throughput insertions and\ndeletions under dynamic workloads.\n  This paper presents LSM-VEC, a disk-based dynamic vector index that\nintegrates hierarchical graph indexing with LSM-tree storage. By distributing\nthe proximity graph across multiple LSM-tree levels, LSM-VEC supports\nout-of-place vector updates. It enhances search efficiency via a sampling-based\nprobabilistic search strategy with adaptive neighbor selection, and\nconnectivity-aware graph reordering further reduces I/O without requiring\nglobal reconstruction. Experiments on billion-scale datasets demonstrate that\nLSM-VEC consistently outperforms existing disk-based ANN systems. It achieves\nhigher recall, lower query and update latency, and reduces memory footprint by\nover 66.2%, making it well-suited for real-world large-scale vector search with\ndynamic updates.",
    "pdf_url": "http://arxiv.org/pdf/2505.17152v1",
    "published": "2025-05-22T11:11:02+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.16525v1",
    "title": "Extreme value statistics and eigenstate thermalization in kicked quantum chaotic spin-$1/2$ chains",
    "authors": [
      "Tanay Pathak",
      "Masaki Tezuka"
    ],
    "abstract": "It is often expected (and assumed) for a quantum chaotic system that the\npresence of correlated eigenvalues implies that all the other properties as\ndictated by random matrix theory are satisfied. We demonstrate using the\nspin-$1/2$ kicked field Ising model that this is not necessarily true. We study\nthe properties of eigenvalues of the reduced density matrix for this model,\nwhich constitutes the entanglement spectrum. It is shown that the largest\neigenvalue does not follow the expected Tracy--Widom distribution even for the\nlarge system sizes considered. The distribution instead follows the extreme\nvalue distribution of Weibull type. Furthermore, we also show that such\ndeviations do not lead to drastic change in the thermalization property of this\nsystem by showing that the models satisfy the diagonal and off-diagonal\neigenstate thermalization hypothesis. Finally, we study the spin-spin\nautocorrelation function and numerically show that it has the characteristic\nbehavior for chaotic systems: it decreases exponentially and saturates to a\nvalue at late time that decreases with system size.",
    "pdf_url": "http://arxiv.org/pdf/2505.16525v1",
    "published": "2025-05-22T11:09:21+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16524v1",
    "title": "CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving",
    "authors": [
      "Huitong Yang",
      "Zhuoxiao Chen",
      "Fengyi Zhang",
      "Zi Huang",
      "Yadan Luo"
    ],
    "abstract": "Maintaining robust 3D perception under dynamic and unpredictable test-time\nconditions remains a critical challenge for autonomous driving systems.\nExisting test-time adaptation (TTA) methods often fail in high-variance tasks\nlike 3D object detection due to unstable optimization and sharp minima. While\nrecent model merging strategies based on linear mode connectivity (LMC) offer\nimproved stability by interpolating between fine-tuned checkpoints, they are\ncomputationally expensive, requiring repeated checkpoint access and multiple\nforward passes. In this paper, we introduce CodeMerge, a lightweight and\nscalable model merging framework that bypasses these limitations by operating\nin a compact latent space. Instead of loading full models, CodeMerge represents\neach checkpoint with a low-dimensional fingerprint derived from the source\nmodel's penultimate features and constructs a key-value codebook. We compute\nmerging coefficients using ridge leverage scores on these fingerprints,\nenabling efficient model composition without compromising adaptation quality.\nOur method achieves strong performance across challenging benchmarks, improving\nend-to-end 3D detection 14.9% NDS on nuScenes-C and LiDAR-based detection by\nover 7.6% mAP on nuScenes-to-KITTI, while benefiting downstream tasks such as\nonline mapping, motion prediction and planning even without training. Code and\npretrained models are released in the supplementary material.",
    "pdf_url": "http://arxiv.org/pdf/2505.16524v1",
    "published": "2025-05-22T11:09:15+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16523v2",
    "title": "Strict advantage of complex quantum theory in a communication task",
    "authors": [
      "Thomas J. Elliott"
    ],
    "abstract": "Standard formulations of quantum theory are based on complex numbers: Quantum\nstates can be in superpositions, with weights given by complex probability\namplitudes. Motivated by quantum theory promising a range of practical\nadvantages over classical for a multitude of tasks, we investigate how the\npresence of complex amplitudes in quantum theory can yield operational\nadvantages over counterpart real formulations. We identify a straightforward\ncommunication task for which complex quantum theory exhibits a provably lower\ncommunication cost than not just any classical approach, but also any approach\nbased on real quantum theory. We certify the necessity of complex quantum\ntheory for optimal approaches to the task through geometric properties of\nquantum state ensembles that witness the presence of basis-independent\ncomplexity. This substantiates a strict operational advantage of complex\nquantum theory. We discuss the relevance of this finding for quantum advantages\nin stochastic simulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16523v2",
    "published": "2025-05-22T11:06:09+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16522v2",
    "title": "Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing",
    "authors": [
      "Zhouhao Sun",
      "Zhiyuan Kan",
      "Xiao Ding",
      "Li Du",
      "Yang Zhao",
      "Bing Qin",
      "Ting Liu"
    ],
    "abstract": "Despite significant progress, recent studies have indicated that current\nlarge language models (LLMs) may still utilize bias during inference, leading\nto the poor generalizability of LLMs. Some benchmarks are proposed to\ninvestigate the generalizability of LLMs, with each piece of data typically\ncontaining one type of controlled bias. However, a single piece of data may\ncontain multiple types of biases in practical applications. To bridge this gap,\nwe propose a multi-bias benchmark where each piece of data contains five types\nof biases. The evaluations conducted on this benchmark reveal that the\nperformance of existing LLMs and debiasing methods is unsatisfying,\nhighlighting the challenge of eliminating multiple types of biases\nsimultaneously. To overcome this challenge, we propose a causal effect\nestimation-guided multi-bias elimination method (CMBE). This method first\nestimates the causal effect of multiple types of biases simultaneously.\nSubsequently, we eliminate the causal effect of biases from the total causal\neffect exerted by both the semantic information and biases during inference.\nExperimental results show that CMBE can effectively eliminate multiple types of\nbias simultaneously to enhance the generalizability of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16522v2",
    "published": "2025-05-22T11:04:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16521v2",
    "title": "Unveiling the inert Triplet desert region with a pNGB Dark Matter and its Gravitational Wave signatures",
    "authors": [
      "Pankaj Borah",
      "Pradipta Ghosh"
    ],
    "abstract": "In this work, we extend the scalar sector of the conventional hyperchargeless\ninert triplet model (ITM) to include a second dark matter (DM) candidate, which\nappears to be a pseudo-Nambu-Goldstone boson (pNGB). The usual ITM with an\nextended scalar sector offers a DM candidate along with novel signatures at\ndifferent experiments, e.g., colliders, gravitational wave detectors, etc.\nNevertheless, hitherto unseen experimental detections have placed stringent\nconstraints on the ITM parameter space. Moreover, triplet masses lighter than\n$1.9$ TeV, consistent with the existing or upcoming collider sensitivity reach,\nare already excluded from the DM observable, as they yield an underabundant\nrelic density due to a strong $SU(2)_L$ gauge annihilation. Inclusion of a pNGB\nDM, via a complex $SU(2)_L$ scalar singlet and through the soft-breaking of a\n$U(1)$ symmetry, helps to revive the sub-TeV regime of the triplet DM. This\nresurgence relies on a proficient conversion between the two DM species. Using\nthis inter-conversion, with the triplet DM as the lighter one between the two,\nwe show that it is possible to push the triplet DM contribution to $50\\% -\n60\\%$ of the total relic density. This offers a significant improvement over\nthe traditional ITM with a single DM candidate, where the same can at most\nreach $10\\% - 20\\%$. Besides, the concerned bipartite DM framework also offers\nthe possibility of a first-order phase transition along various constituent\nfield directions. Among these, the one along the real $SU(2)_L$ singlet\ndirection can be a strong one which subsequently yields detectable\ngravitational wave signals at the upcoming space-based gravitational wave\ndetectors such as LISA, BBO, DECIGO, etc., alongside distinctive and\ncomplementary signatures at the various DM and collider quests.",
    "pdf_url": "http://arxiv.org/pdf/2505.16521v2",
    "published": "2025-05-22T11:02:57+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "hep-ex",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16520v3",
    "title": "Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs",
    "authors": [
      "Giovanni Servedio",
      "Alessandro De Bellis",
      "Dario Di Palma",
      "Vito Walter Anelli",
      "Tommaso Di Noia"
    ],
    "abstract": "Factual hallucinations are a major challenge for Large Language Models\n(LLMs). They undermine reliability and user trust by generating inaccurate or\nfabricated content. Recent studies suggest that when generating false\nstatements, the internal states of LLMs encode information about truthfulness.\nHowever, these studies often rely on synthetic datasets that lack realism,\nwhich limits generalization when evaluating the factual accuracy of text\ngenerated by the model itself. In this paper, we challenge the findings of\nprevious work by investigating truthfulness encoding capabilities, leading to\nthe generation of a more realistic and challenging dataset. Specifically, we\nextend previous work by introducing: (1) a strategy for sampling plausible\ntrue-false factoid sentences from tabular data and (2) a procedure for\ngenerating realistic, LLM-dependent true-false datasets from Question Answering\ncollections. Our analysis of two open-source LLMs reveals that while the\nfindings from previous studies are partially validated, generalization to\nLLM-generated datasets remains challenging. This study lays the groundwork for\nfuture research on factuality in LLMs and offers practical guidelines for more\neffective evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16520v3",
    "published": "2025-05-22T11:00:53+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16519v1",
    "title": "SONIC: Cost-Effective Web Access for Developing Countries",
    "authors": [
      "Ayush Pandey",
      "Rohail Asim",
      "Jean Louis K. E. Fendji",
      "Talal Rahwan",
      "Matteo Varvello",
      "Yasir Zaki"
    ],
    "abstract": "Over 2.6 billion people remain without access to the Internet in 2025. This\nphenomenon is especially pronounced in developing regions, where cost and\ninfrastructure limitations are major barriers to connectivity. In response, we\ndesign SONIC, a low-cost, scalable data delivery system that builds on existing\ninfrastructures: FM radio for downlink broadcasting, and SMS for personalized\nuplink. SONIC is motivated by the widespread availability of FM radio and SMS\ninfrastructure in developing regions, along with embedded FM radio tuners in\naffordable mobile phones. SONIC offers several innovations to effectively\ntransmit Web content over sound over FM radio, in a reliable and compressed\nform. For example, we transmit pre-rendered webpages and leverage pixel\ninterpolation to recover errors at the receiver. We further modify Android to\noffer a simpler deployment pipeline, supporting a wide range of devices. We\ndeployed SONIC at an FM radio station in Cameroon for six weeks with 30\nparticipants. Our results demonstrate a sustained downlink throughput of 10\nkbps, less than 20% loss for a majority of transmissions with signal strength\nabove -90 dbM, and a strong user engagement across both Web browsing and\nChatGPT interactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16519v1",
    "published": "2025-05-22T10:58:47+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16518v2",
    "title": "CUB: Benchmarking Context Utilisation Techniques for Language Models",
    "authors": [
      "Lovisa Hagström",
      "Youna Kim",
      "Haeun Yu",
      "Sang-goo Lee",
      "Richard Johansson",
      "Hyunsoo Cho",
      "Isabelle Augenstein"
    ],
    "abstract": "Incorporating external knowledge is crucial for knowledge-intensive tasks,\nsuch as question answering and fact checking. However, language models (LMs)\nmay ignore relevant information that contradicts outdated parametric memory or\nbe distracted by irrelevant contexts. While many context utilisation\nmanipulation techniques (CMTs) have recently been proposed to alleviate these\nissues, few have seen systematic comparison. In this paper, we develop CUB\n(Context Utilisation Benchmark) - the first comprehensive benchmark designed to\nhelp practitioners within retrieval-augmented generation (RAG) diagnose CMTs\nunder different context conditions. With this benchmark, we conduct the most\nextensive evaluation to date of seven state-of-the-art methods, representative\nof the main categories of CMTs, across three diverse datasets and tasks,\napplied to nine LMs. Our results reveal that most existing CMTs struggle to\nhandle the full spectrum of context types encountered in real-world\nretrieval-augmented scenarios. We also find that many CMTs display inflated\nperformance on simple synthesised datasets, compared to more realistic datasets\nwith naturally occurring samples. Our findings expose critical gaps in current\nCMT evaluation practices and demonstrate the need for holistic testing and the\ndevelopment of CMTs that can robustly handle multiple context types.",
    "pdf_url": "http://arxiv.org/pdf/2505.16518v2",
    "published": "2025-05-22T10:57:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16517v2",
    "title": "ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models",
    "authors": [
      "Zirui Song",
      "Guangxian Ouyang",
      "Mingzhe Li",
      "Yuheng Ji",
      "Chenxi Wang",
      "Zixiang Xu",
      "Zeyu Zhang",
      "Xiaoqing Zhang",
      "Qian Jiang",
      "Zhenhao Chen",
      "Zhongzhi Li",
      "Rui Yan",
      "Xiuying Chen"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have recently advanced robotic\nmanipulation by leveraging vision for scene perception and language for\ninstruction following. However, existing methods rely heavily on costly\nhuman-annotated training datasets, which limits their generalization and causes\nthem to struggle in out-of-domain (OOD) scenarios, reducing real-world\nadaptability. To address these challenges, we propose ManipLVM-R1, a novel\nreinforcement learning framework that replaces traditional supervision with\nReinforcement Learning using Verifiable Rewards (RLVR). By directly optimizing\nfor task-aligned outcomes, our method enhances generalization and physical\nreasoning while removing the dependence on costly annotations. Specifically, we\ndesign two rule-based reward functions targeting key robotic manipulation\nsubtasks: an Affordance Perception Reward to enhance localization of\ninteraction regions, and a Trajectory Match Reward to ensure the physical\nplausibility of action paths. These rewards provide immediate feedback and\nimpose spatial-logical constraints, encouraging the model to go beyond shallow\npattern matching and instead learn deeper, more systematic reasoning about\nphysical interactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16517v2",
    "published": "2025-05-22T10:57:07+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.18208v1",
    "title": "Off-diagonal deformations of regular Schwarzschild black holes and general relativistic G. Perelman thermodynamics",
    "authors": [
      "Sergiu I. Vacaru",
      "Elşen Veli Veliev"
    ],
    "abstract": "We construct new classes of solutions describing generic off-diagonal\ndeformations of regular Schwarzschild black holes (BHs) in general relativity\n(GR). Examples of such (primary) diagonal metrics reducing the Einstein\nequations to integrable systems of nonlinear ordinary differential equations\nwere studied in a recent work by R. Casadio, A. Kamenshchik and J. Ovalle in\nPhys. Rev. D 111 (2025) 064036. We develop and apply our anholonomic frame and\nconnection deformations method, which allows us to generate new classes of\ntarget off-diagonal solutions. Ansatz that reduces the gravitational field\nequations to systems of (exactly or parametric) integrable systems of nonlinear\npartial differential equations are used. We find and analyze certain families\nof deformed regular BHs containing an off-diagonal de Sitter condensate\nencoding solitonic vacuum configurations, with possible deformations of\nhorizons and/or gravitational polarizations of constants. We emphasize that\ngeneral off-diagonal solutions do not involve certain hypersurface or\nholographic configurations. This means that the Bekenstein-Hawking\nthermodynamic paradigm is not applicable for characterizing the physical\nproperties of such target regular solutions. We argue that the concept of G.\nPerelman's entropy and relativistic geometric flow thermodynamics is more\nappropriate. Using nonlinear symmetries involving effective cosmological\nconstants, we show how to compute thermodynamic variables for various classes\nof physically essential solutions in GR.",
    "pdf_url": "http://arxiv.org/pdf/2505.18208v1",
    "published": "2025-05-22T10:53:29+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16516v1",
    "title": "Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods",
    "authors": [
      "Majid Mohammadi",
      "Siu Lun Chau",
      "Krikamol Muandet"
    ],
    "abstract": "Kernel methods are widely used in machine learning due to their flexibility\nand expressive power. However, their black-box nature poses significant\nchallenges to interpretability, limiting their adoption in high-stakes\napplications. Shapley value-based feature attribution techniques, such as SHAP\nand kernel-specific variants like RKHS-SHAP, offer a promising path toward\nexplainability. Yet, computing exact Shapley values remains computationally\nintractable in general, motivating the development of various approximation\nschemes. In this work, we introduce PKeX-Shapley, a novel algorithm that\nutilizes the multiplicative structure of product kernels to enable the exact\ncomputation of Shapley values in polynomial time. We show that product-kernel\nmodels admit a functional decomposition that allows for a recursive formulation\nof Shapley values. This decomposition not only yields computational efficiency\nbut also enhances interpretability in kernel-based learning. We also\ndemonstrate how our framework can be generalized to explain kernel-based\nstatistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the\nHilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for\ninterpretable statistical inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.16516v1",
    "published": "2025-05-22T10:53:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16515v1",
    "title": "Seniority-two valence-shell building blocks of the octupole phonon",
    "authors": [
      "M. Scheck",
      "R. Chapman",
      "K. Mashtakov",
      "R. Meeten",
      "P. L. Sassarini",
      "P. Spagnoletti"
    ],
    "abstract": "The relative ordering of $J^-$ levels of multiplets resulting from two-body\nexcitations, which include a $J^{\\pi}=3^-$ state that can contribute to the\noctupole phonon, are investigated in a simplistic shell-model approach. To\ncalculate the relative level ordering, harmonic oscillator wavefunctions and a\nresidual $\\delta$ interaction are used. The simplistic approach confirms for\nthe particle-particle channel, the often stated preference of the $\\Delta j=3,\n\\Delta l =3$ subshell combination over the $\\Delta j=3, \\Delta l =1$ subshell\ncombination through an enhanced energy gain. Furthermore, it is shown that, in\nthe particle-hole channel, the gain is less pronounced for the $\\Delta j=3,\n\\Delta l =3$ subshell configuration. In combination with the overall structure\nof an oscillator shell, these results explain the comparatively low excitation\nenergy for 3$^-_1$ excitations observed for the octupole-soft proton and\nneutron numbers predicted by various models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16515v1",
    "published": "2025-05-22T10:50:51+00:00",
    "categories": [
      "nucl-th",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16514v2",
    "title": "AppealCase: A Dataset and Benchmark for Civil Case Appeal Scenarios",
    "authors": [
      "Yuting Huang",
      "Meitong Guo",
      "Yiquan Wu",
      "Ang Li",
      "Xiaozhong Liu",
      "Keting Yin",
      "Changlong Sun",
      "Fei Wu",
      "Kun Kuang"
    ],
    "abstract": "Recent advances in LegalAI have primarily focused on individual case judgment\nanalysis, often overlooking the critical appellate process within the judicial\nsystem. Appeals serve as a core mechanism for error correction and ensuring\nfair trials, making them highly significant both in practice and in research.\nTo address this gap, we present the AppealCase dataset, consisting of 10,000\npairs of real-world, matched first-instance and second-instance documents\nacross 91 categories of civil cases. The dataset also includes detailed\nannotations along five dimensions central to appellate review: judgment\nreversals, reversal reasons, cited legal provisions, claim-level decisions, and\nwhether there is new information in the second instance. Based on these\nannotations, we propose five novel LegalAI tasks and conduct a comprehensive\nevaluation across 20 mainstream models. Experimental results reveal that all\ncurrent models achieve less than 50% F1 scores on the judgment reversal\nprediction task, highlighting the complexity and challenge of the appeal\nscenario. We hope that the AppealCase dataset will spur further research in\nLegalAI for appellate case analysis and contribute to improving consistency in\njudicial decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2505.16514v2",
    "published": "2025-05-22T10:50:33+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16513v1",
    "title": "Detailed Evaluation of Modern Machine Learning Approaches for Optic Plastics Sorting",
    "authors": [
      "Vaishali Maheshkar",
      "Aadarsh Anantha Ramakrishnan",
      "Charuvahan Adhivarahan",
      "Karthik Dantu"
    ],
    "abstract": "According to the EPA, only 25% of waste is recycled, and just 60% of U.S.\nmunicipalities offer curbside recycling. Plastics fare worse, with a recycling\nrate of only 8%; an additional 16% is incinerated, while the remaining 76% ends\nup in landfills. The low plastic recycling rate stems from contamination, poor\neconomic incentives, and technical difficulties, making efficient recycling a\nchallenge. To improve recovery, automated sorting plays a critical role.\nCompanies like AMP Robotics and Greyparrot utilize optical systems for sorting,\nwhile Materials Recovery Facilities (MRFs) employ Near-Infrared (NIR) sensors\nto detect plastic types.\n  Modern optical sorting uses advances in computer vision such as object\nrecognition and instance segmentation, powered by machine learning. Two-stage\ndetectors like Mask R-CNN use region proposals and classification with deep\nbackbones like ResNet. Single-stage detectors like YOLO handle detection in one\npass, trading some accuracy for speed. While such methods excel under ideal\nconditions with a large volume of labeled training data, challenges arise in\nrealistic scenarios, emphasizing the need to further examine the efficacy of\noptic detection for automated sorting.\n  In this study, we compiled novel datasets totaling 20,000+ images from varied\nsources. Using both public and custom machine learning pipelines, we assessed\nthe capabilities and limitations of optical recognition for sorting. Grad-CAM,\nsaliency maps, and confusion matrices were employed to interpret model\nbehavior. We perform this analysis on our custom trained models from the\ncompiled datasets. To conclude, our findings are that optic recognition methods\nhave limited success in accurate sorting of real-world plastics at MRFs,\nprimarily because they rely on physical properties such as color and shape.",
    "pdf_url": "http://arxiv.org/pdf/2505.16513v1",
    "published": "2025-05-22T10:48:30+00:00",
    "categories": [
      "cs.CV",
      "68T45",
      "I.4.9; I.4.6"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16512v4",
    "title": "Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection",
    "authors": [
      "Jiaxin Liu",
      "Jia Wang",
      "Saihui Hou",
      "Min Ren",
      "Huijia Wu",
      "Long Ma",
      "Renwang Pei",
      "Zhaofeng He"
    ],
    "abstract": "In recent years, the explosive advancement of deepfake technology has posed a\ncritical and escalating threat to public security: diffusion-based digital\nhuman generation. Unlike traditional face manipulation methods, such models can\ngenerate highly realistic videos with consistency via multimodal control\nsignals. Their flexibility and covertness pose severe challenges to existing\ndetection strategies. To bridge this gap, we introduce DigiFakeAV, the new\nlarge-scale multimodal digital human forgery dataset based on diffusion models.\nLeveraging five of the latest digital human generation methods and a voice\ncloning method, we systematically construct a dataset comprising 60,000 videos\n(8.4 million frames), covering multiple nationalities, skin tones, genders, and\nreal-world scenarios, significantly enhancing data diversity and realism. User\nstudies demonstrate that the misrecognition rate by participants for DigiFakeAV\nreaches as high as 68%. Moreover, the substantial performance degradation of\nexisting detection models on our dataset further highlights its challenges. To\naddress this problem, we propose DigiShield, an effective detection baseline\nbased on spatiotemporal and cross-modal fusion. By jointly modeling the 3D\nspatiotemporal features of videos and the semantic-acoustic features of audio,\nDigiShield achieves state-of-the-art (SOTA) performance on the DigiFakeAV and\nshows strong generalization on other datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.16512v4",
    "published": "2025-05-22T10:46:37+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16511v1",
    "title": "Neural network based control of unknown nonlinear systems via contraction analysis",
    "authors": [
      "Hao Yin",
      "Claudio De Persis",
      "Bayu Jayawardhana",
      "Santiago Sanchez Escalonilla Plaza"
    ],
    "abstract": "This paper studies the design of neural network (NN)-based controllers for\nunknown nonlinear systems, using contraction analysis. A Neural Ordinary\nDifferential Equation (NODE) system is constructed by approximating the unknown\ndraft dynamics with a feedforward NN. Incremental sector bounds and contraction\ntheory are applied to the activation functions and the weights of the NN,\nrespectively. It is demonstrated that if the incremental sector bounds and the\nweights satisfy some non-convex conditions, the NODE system is contractive. To\nimprove computational efficiency, these non-convex conditions are reformulated\nas convex LMI conditions. Additionally, it is proven that when the NODE system\nis contractive, the trajectories of the original autonomous system converge to\na neighborhood of the unknown equilibrium, with the size of this neighborhood\ndetermined by the approximation error. For a single-layer NN, the NODE system\nis simplified to a continuous-time Hopfield NN. If the NODE system does not\nsatisfy the contraction conditions, an NN-based controller is designed to\nenforce contractivity. This controller integrates a linear component, which\nensures contraction through suitable control gains, and an NN component, which\ncompensates for the NODE system's nonlinearities. This integrated controller\nguarantees that the trajectories of the original affine system converge to a\nneighborhood of the unknown equilibrium. The effectiveness of the proposed\napproach is demonstrated through two illustrative examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.16511v1",
    "published": "2025-05-22T10:46:00+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16510v1",
    "title": "Approximation of the Solutions to Quasilinear Parabolic Problems with Perturbed $VMO_x$ Coefficients",
    "authors": [
      "Rosamaria Rescigno",
      "Lubomira Softova"
    ],
    "abstract": "We consider the Cauchy-Dirichlet problem for second-order quasilinear\nnon-divergence form operators of parabolic type. The data are\nCara\\-th\\'e\\-o\\-dory functions, and the principal part is of $VMO_x$-type with\nrespect to the variables $ (x,t).$ Assuming the existence of a strong solution\n$u_0,$ we apply the Implicit Function Theorem in a small domain of this\nsolution to show that small bounded perturbations of the data, locally in time,\nlead to small perturbations of the solution $u_0$. Additionally, we apply the\nNewton Iteration Procedure to construct an approximating sequence converging to\nthe solution $u_0$ in the corresponding Sobolev space.",
    "pdf_url": "http://arxiv.org/pdf/2505.16510v1",
    "published": "2025-05-22T10:44:55+00:00",
    "categories": [
      "math.AP",
      "math.FA",
      "35K55, 35K61, 47J07"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16509v1",
    "title": "Selection of Dwarf Galaxies Hosting AGNs: A Measure of Bias and Contamination using Unsupervised Machine Learning Techniques",
    "authors": [
      "Sogol Sanjaripour",
      "Archana Aravindan",
      "Gabriela Canalizo",
      "Shoubaneh Hemmati",
      "Bahram Mobasher",
      "Alison L. Coil",
      "Barry C. Barish"
    ],
    "abstract": "Identifying AGNs in dwarf galaxies is critical for understanding black hole\nformation but remains challenging due to their low luminosities, low\nmetallicities, and star formation-driven emission that can obscure AGN\nsignatures. Machine learning (ML) techniques, particularly unsupervised\nmethods, offer new ways to address these challenges by uncovering patterns in\ncomplex data. In this study, we apply Self-Organizing Maps (SOMs) to explore\nthe SED manifold of dwarf galaxies and evaluate AGN selection biases across\ndiagnostics. We train a 51 by 51 SOM on 30,344 dwarf galaxies (redshift less\nthan 0.055 and stellar mass below 10 to the 9.5 solar masses) from the NSA\ncatalog using nine-band photometry from near-UV to mid-infrared. A set of 438\npreviously identified dwarf AGNs, selected via various methods, was mapped onto\nthe SOM. AGNs identified by different methods occupy distinct and partially\noverlapping regions in SED space, reflecting selection biases tied to host\nproperties. BPT selected AGNs cluster in higher-mass regions, while X-ray and\nvariability-selected AGNs show broader distributions. WISE-selected AGNs are\nconcentrated in lower-mass regions and form two clumps: one associated with\nbluer, starburst-like systems and the other with redder, more AGN-like SEDs.\nThis separation may help distinguish true AGN hosts from starburst contaminants\nin WISE-selected samples. AGNs selected via traditional emission-line,\nbroad-line, and WISE methods tend to avoid SOM regions linked to strong star\nformation. In contrast, a subset of AGNs in low-mass galaxies occupy regions\nindicative of high AGN luminosity relative to stellar content, highlighting\nluminous AGNs in faint hosts. These results demonstrate the utility of manifold\nlearning for improving AGN selection in the low-mass regime.",
    "pdf_url": "http://arxiv.org/pdf/2505.16509v1",
    "published": "2025-05-22T10:43:41+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16508v2",
    "title": "Edge-First Language Model Inference: Models, Metrics, and Tradeoffs",
    "authors": [
      "SiYoung Jang",
      "Roberto Morabito"
    ],
    "abstract": "The widespread adoption of Language Models (LMs) across industries is driving\ninterest in deploying these services across the computing continuum, from the\ncloud to the network edge. This shift aims to reduce costs, lower latency, and\nimprove reliability and privacy. Small Language Models (SLMs), enabled by\nadvances in model compression, are central to this shift, offering a path to\non-device inference on resource-constrained edge platforms. This work examines\nthe interplay between edge and cloud deployments, starting from detailed\nbenchmarking of SLM capabilities on single edge devices, and extending to\ndistributed edge clusters. We identify scenarios where edge inference offers\ncomparable performance with lower costs, and others where cloud fallback\nbecomes essential due to limits in scalability or model capacity. Rather than\nproposing a one-size-fits-all solution, we present platform-level comparisons\nand design insights for building efficient, adaptive LM inference systems\nacross heterogeneous environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16508v2",
    "published": "2025-05-22T10:43:00+00:00",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI",
      "cs.PF"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16507v1",
    "title": "Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)",
    "authors": [
      "Anshu Xiong",
      "Songmao Zhang"
    ],
    "abstract": "The notion of relevance was proposed for stability of justification status of\na single argument in incomplete argumentation frameworks (IAFs) in 2024 by\nOdekerken et al. To extend the notion, we study the relevance for stability of\nverification status of a set of arguments in this paper, i.e., the\nuncertainties in an IAF that have to be resolved in some situations so that\nanswering whether a given set of arguments is an extension obtains the same\nresult in every completion of the IAF. Further we propose the notion of strong\nrelevance for describing the necessity of resolution in all situations reaching\nstability. An analysis of complexity reveals that detecting the (strong)\nrelevance for stability of sets of arguments can be accomplished in P time\nunder the most semantics discussed in the paper. We also discuss the difficulty\nin finding tractable methods for relevance detection under grounded semantics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16507v1",
    "published": "2025-05-22T10:42:16+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16506v1",
    "title": "Utilizing citation index and synthetic quality measure to compare Wikipedia languages across various topics",
    "authors": [
      "Włodzimierz Lewoniewski",
      "Krzysztof Węcel",
      "Witold Abramowicz"
    ],
    "abstract": "This study presents a comparative analysis of 55 Wikipedia language editions\nemploying a citation index alongside a synthetic quality measure. Specifically,\nwe identified the most significant Wikipedia articles within distinct topical\nareas, selecting the top 10, top 25, and top 100 most cited articles in each\ntopic and language version. This index was built on the basis of wikilinks\nbetween Wikipedia articles in each language version and in order to do that we\nprocessed 6.6 billion page-to-page link records. Next, we used a quality score\nfor each Wikipedia article - a synthetic measure scaled from 0 to 100. This\napproach enabled quality comparison of Wikipedia articles even between language\nversions with different quality grading schemes. Our results highlight\ndisparities among Wikipedia language editions, revealing strengths and gaps in\ncontent coverage and quality across topics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16506v1",
    "published": "2025-05-22T10:41:55+00:00",
    "categories": [
      "cs.IR",
      "cs.CY",
      "cs.DL",
      "stat.AP"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16505v1",
    "title": "Sparse Activation Editing for Reliable Instruction Following in Narratives",
    "authors": [
      "Runcong Zhao",
      "Chengyu Cao",
      "Qinglin Zhu",
      "Xiucheng Lv",
      "Shun Shao",
      "Lin Gui",
      "Ruifeng Xu",
      "Yulan He"
    ],
    "abstract": "Complex narrative contexts often challenge language models' ability to follow\ninstructions, and existing benchmarks fail to capture these difficulties. To\naddress this, we propose Concise-SAE, a training-free framework that improves\ninstruction following by identifying and editing instruction-relevant neurons\nusing only natural language instructions, without requiring labelled data. To\nthoroughly evaluate our method, we introduce FreeInstruct, a diverse and\nrealistic benchmark of 1,212 examples that highlights the challenges of\ninstruction following in narrative-rich settings. While initially motivated by\ncomplex narratives, Concise-SAE demonstrates state-of-the-art instruction\nadherence across varied tasks without compromising generation quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.16505v1",
    "published": "2025-05-22T10:41:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16504v1",
    "title": "A Tutorial on Beyond-Diagonal Reconfigurable Intelligent Surfaces: Modeling, Architectures, System Design and Optimization, and Applications",
    "authors": [
      "Hongyu Li",
      "Matteo Nerini",
      "Shanpu Shen",
      "Bruno Clerckx"
    ],
    "abstract": "Written by its inventors, this first tutorial on Beyond-Diagonal\nReconfigurable Intelligent Surfaces (BD-RISs) provides the readers with the\nbasics and fundamental tools necessary to appreciate, understand, and\ncontribute to this emerging and disruptive technology. Conventional (Diagonal)\nRISs (D-RISs) are characterized by a diagonal scattering matrix\n$\\mathbf{\\Theta}$ such that the wave manipulation flexibility of D-RIS is\nextremely limited. In contrast, BD-RIS refers to a novel and general framework\nfor RIS where its scattering matrix is not limited to be diagonal (hence, the\n``beyond-diagonal'' terminology) and consequently, all entries of\n$\\mathbf{\\Theta}$ can potentially help shaping waves for much higher\nmanipulation flexibility. This physically means that BD-RIS can artificially\nengineer and reconfigure coupling across elements of the surface thanks to\ninter-element reconfigurable components which allow waves absorbed by one\nelement to flow through other elements. Consequently, BD-RIS opens the door to\nmore general and versatile intelligent surfaces that subsumes existing RIS\narchitectures as special cases. In this tutorial, we share all the secret sauce\nto model, design, and optimize BD-RIS and make BD-RIS transformative in many\ndifferent applications. Topics discussed include physics-consistent and\nmulti-port network-aided modeling; transmitting, reflecting, hybrid, and\nmulti-sector mode analysis; reciprocal and non-reciprocal architecture designs\nand optimal performance-complexity Pareto frontier of BD-RIS; signal\nprocessing, optimization, and channel estimation for BD-RIS; hardware\nimpairments (discrete-value impedance and admittance, lossy interconnections\nand components, wideband effects, mutual coupling) of BD-RIS; benefits and\napplications of BD-RIS in communications, sensing, power transfer.",
    "pdf_url": "http://arxiv.org/pdf/2505.16504v1",
    "published": "2025-05-22T10:37:31+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16503v1",
    "title": "Language-based Security and Time-inserting Supervisor",
    "authors": [
      "Damas P. Gruska"
    ],
    "abstract": "Algebraic methods are employed in order to define language-based security\nproperties of processes. A supervisor is introduced that can disable unwanted\nbehavior of an insecure process by controlling some of its actions or by\ninserting timed actions to make an insecure process secure. We assume a\nsituation where neither the supervisor nor the attacker has complete\ninformation about the ongoing systems behavior. We study the conditions under\nwhich such a supervisor exists, as well as its properties and limitations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16503v1",
    "published": "2025-05-22T10:36:50+00:00",
    "categories": [
      "cs.CR",
      "cs.LO"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16502v2",
    "title": "Recursive Offloading for LLM Serving in Multi-tier Networks",
    "authors": [
      "Zhiyuan Wu",
      "Sheng Sun",
      "Yuwei Wang",
      "Min Liu",
      "Bo Gao",
      "Jinda Lu",
      "Zheming Yang",
      "Tian Wen"
    ],
    "abstract": "Heterogeneous device-edge-cloud computing infrastructures have become widely\nadopted in telecommunication operators and Wide Area Networks (WANs), offering\nmulti-tier computational support for emerging intelligent services. With the\nrapid proliferation of Large Language Model (LLM) services, efficiently\ncoordinating inference tasks and reducing communication overhead within these\nmulti-tier network architectures becomes a critical deployment challenge.\nExisting LLM serving paradigms exhibit significant limitations: on-device\ndeployment supports only lightweight LLMs due to hardware constraints, while\ncloud-centric deployment suffers from resource congestion and considerable\nprompt communication overhead caused by frequent service requests during peak\nperiods. Although the model-cascading-based inference strategy adapts better to\nmulti-tier networks, its reliance on fine-grained, manually adjusted thresholds\nmakes it less responsive to dynamic network conditions and varying task\ncomplexities. To address these challenges, we propose RecServe, a recursive\noffloading framework tailored for LLM serving in multi-tier networks. RecServe\nintegrates a task-specific hierarchical confidence evaluation mechanism that\nguides offloading decisions based on inferred task complexity in progressively\nscaled LLMs across device, edge, and cloud tiers. To further enable intelligent\ntask routing across tiers, RecServe employs a sliding-window-based dynamic\noffloading strategy with quantile interpolation, enabling real-time tracking of\nhistorical confidence distributions and adaptive offloading threshold\nadjustments. Experiments on eight datasets demonstrate that RecServe\noutperforms CasServe in both service quality and communication efficiency, and\nreduces the communication burden by over 50\\% compared to centralized\ncloud-based serving.",
    "pdf_url": "http://arxiv.org/pdf/2505.16502v2",
    "published": "2025-05-22T10:36:05+00:00",
    "categories": [
      "cs.DC",
      "cs.NI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16501v1",
    "title": "Performance of Confidential Computing GPUs",
    "authors": [
      "Antonio Martínez Ibarra",
      "Julian James Stephen",
      "Aurora González Vidal",
      "K. R. Jayaram",
      "Antonio Fernando Skarmeta Gómez"
    ],
    "abstract": "This work examines latency, throughput, and other metrics when performing\ninference on confidential GPUs. We explore different traffic patterns and\nscheduling strategies using a single Virtual Machine with one NVIDIA H100 GPU,\nto perform relaxed batch inferences on multiple Large Language Models (LLMs),\noperating under the constraint of swapping models in and out of memory, which\nnecessitates efficient control. The experiments simulate diverse real-world\nscenarios by varying parameters such as traffic load, traffic distribution\npatterns, scheduling strategies, and Service Level Agreement (SLA)\nrequirements. The findings provide insights into the differences between\nconfidential and non-confidential settings when performing inference in\nscenarios requiring active model swapping. Results indicate that in No-CC mode,\nrelaxed batch inference with model swapping latency is 20-30% lower than in\nconfidential mode. Additionally, SLA attainment is 15-20% higher in No-CC\nsettings. Throughput in No-CC scenarios surpasses that of confidential mode by\n45-70%, and GPU utilization is approximately 50% higher in No-CC environments.\nOverall, performance in the confidential setting is inferior to that in the\nNo-CC scenario, primarily due to the additional encryption and decryption\noverhead required for loading models onto the GPU in confidential environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16501v1",
    "published": "2025-05-22T10:35:44+00:00",
    "categories": [
      "cs.PF"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2505.16500v2",
    "title": "Towards Realistic Detection Pipelines of Taiji: New Challenges in Data Analysis and High-Fidelity Simulations of Space-Borne Gravitational Wave Antenna",
    "authors": [
      "Minghui Du",
      "Pengcheng Wang",
      "Ziren Luo",
      "Wen-Biao Han",
      "Xin Zhang",
      "Xian Chen",
      "Zhoujian Cao",
      "Xilong Fan",
      "He Wang",
      "Xiaodong Peng",
      "Li-E Qiang",
      "Ke An",
      "Yidi Fan",
      "Jiafeng Zhang",
      "Liang-Gui Zhu",
      "Ping Shen",
      "Qianyun Yun",
      "Xiao-Bo Zou",
      "Ye Jiang",
      "Tianyu Zhao",
      "Yong Yuan",
      "Xiaotong Wei",
      "Yuxiang Xu",
      "Bo Liang",
      "Peng Xu",
      "Yueliang Wu"
    ],
    "abstract": "Taiji, a Chinese space-based gravitational wave detection project, aims to\nexplore the millihertz gravitational wave universe with unprecedented\nsensitivity, targeting astrophysical and cosmological sources including\nGalactic binaries, massive black hole binaries, extreme mass-ratio inspirals,\nand stochastic gravitational wave backgrounds, etc. These observations are\nexpected to provide transformative insights into astrophysics, cosmology, and\nfundamental physics. However, Taiji's data analysis faces unique challenges\ndistinct from ground-based detectors like LIGO-Virgo-KAGRA, such as the overlap\nof numerous signals, extended data durations, more rigorous accuracy\nrequirements for the waveform templates, non-negligible subdominant waveform\ncomplexities, incompletely characterized noise spectra, non-stationary noises,\nand various data anomalies. This paper presents the second round of Taiji Data\nChallenge, a collection of simulation datasets designed as a shared platform\nfor resolving these critical data analysis problems. The current platform\ndistinguishes from previous works by the systematic integration of orbital\ndynamics based on the full drag-free and attitude control simulation, extended\nnoise sources, more sophisticated and overlapping gravitational wave signals,\nsecond-generation time-delay interferometry and the coupling effect of\ntime-varying armlengths, etc. Concurrently released is the open-source toolkit\nTriangle (available at https://github.com/TriangleDataCenter), which offers the\ncapabilities for customized simulation of signals, noises and other\ninstrumental effects. By taking a step further towards realistic detection,\nTaiji Data Challenge II and Triangle altogether serve as a new testbed,\nsupporting the development of Taiji's global analysis and end-to-end pipelines,\nand ultimately bridging the gaps between observation and scientific objectives.",
    "pdf_url": "http://arxiv.org/pdf/2505.16500v2",
    "published": "2025-05-22T10:35:23+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.IM"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16499v2",
    "title": "Smaller, Smarter, Closer: The Edge of Collaborative Generative AI",
    "authors": [
      "Roberto Morabito",
      "SiYoung Jang"
    ],
    "abstract": "The rapid adoption of generative AI (GenAI), particularly Large Language\nModels (LLMs), has exposed critical limitations of cloud-centric deployments,\nincluding latency, cost, and privacy concerns. Meanwhile, Small Language Models\n(SLMs) are emerging as viable alternatives for resource-constrained edge\nenvironments, though they often lack the capabilities of their larger\ncounterparts. This article explores the potential of collaborative inference\nsystems that leverage both edge and cloud resources to address these\nchallenges. By presenting distinct cooperation strategies alongside practical\ndesign principles and experimental insights, we offer actionable guidance for\ndeploying GenAI across the computing continuum.",
    "pdf_url": "http://arxiv.org/pdf/2505.16499v2",
    "published": "2025-05-22T10:34:48+00:00",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.20312v1",
    "title": "Let's Get You Hired: A Job Seeker's Perspective on Multi-Agent Recruitment Systems for Explaining Hiring Decisions",
    "authors": [
      "Aditya Bhattacharya",
      "Katrien Verbert"
    ],
    "abstract": "During job recruitment, traditional applicant selection methods often lack\ntransparency. Candidates are rarely given sufficient justifications for\nrecruiting decisions, whether they are made manually by human recruiters or\nthrough the use of black-box Applicant Tracking Systems (ATS). To address this\nproblem, our work introduces a multi-agent AI system that uses Large Language\nModels (LLMs) to guide job seekers during the recruitment process. Using an\niterative user-centric design approach, we first conducted a two-phased\nexploratory study with four active job seekers to inform the design and\ndevelopment of the system. Subsequently, we conducted an in-depth, qualitative\nuser study with 20 active job seekers through individual one-to-one interviews\nto evaluate the developed prototype. The results of our evaluation demonstrate\nthat participants perceived our multi-agent recruitment system as significantly\nmore actionable, trustworthy, and fair compared to traditional methods. Our\nstudy further helped us uncover in-depth insights into factors contributing to\nthese perceived user experiences. Drawing from these insights, we offer broader\ndesign implications for building user-aligned, multi-agent explainable AI\nsystems across diverse domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.20312v1",
    "published": "2025-05-22T10:33:42+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16498v1",
    "title": "Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models",
    "authors": [
      "Augusto Luis Ballardini",
      "Miguel Ángel Sotelo"
    ],
    "abstract": "Achieving full automation in self-driving vehicles remains a challenge,\nespecially in dynamic urban environments where navigation requires real-time\nadaptability. Existing systems struggle to handle navigation plans when faced\nwith unpredictable changes in road layouts, spontaneous detours, or missing map\ndata, due to their heavy reliance on predefined cartographic information. In\nthis work, we explore the use of Large Language Models to generate Answer Set\nProgramming rules by translating informal navigation instructions into\nstructured, logic-based reasoning. ASP provides non-monotonic reasoning,\nallowing autonomous vehicles to adapt to evolving scenarios without relying on\npredefined maps. We present an experimental evaluation in which LLMs generate\nASP constraints that encode real-world urban driving logic into a formal\nknowledge representation. By automating the translation of informal navigation\ninstructions into logical rules, our method improves adaptability and\nexplainability in autonomous navigation. Results show that LLM-driven ASP rule\ngeneration supports semantic-based decision-making, offering an explainable\nframework for dynamic navigation planning that aligns closely with how humans\ncommunicate navigational intent.",
    "pdf_url": "http://arxiv.org/pdf/2505.16498v1",
    "published": "2025-05-22T10:32:43+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16497v2",
    "title": "K3 surfaces of degree six arising from desmic tetrahedra",
    "authors": [
      "Alex Degtyarev",
      "Igor Dolgachev",
      "Shigeyuki Kondo"
    ],
    "abstract": "We study K3 surfaces of degree 6 containing two sets of 12 skew lines such\nthat each line from a set intersects exactly six lines from the other set.\nThese surfaces arise as hyperplane sections of the cubic line complex\nassociated with the pencil of desmic quartic surfaces introduced by George\nHumbert and recently studied by the second and third authors. We discuss\nalternative birational models of the surfaces, compute the Picard lattice and a\ngroup of projective automorphisms, and describe rational curves of low degree\non the general surface.",
    "pdf_url": "http://arxiv.org/pdf/2505.16497v2",
    "published": "2025-05-22T10:30:23+00:00",
    "categories": [
      "math.AG",
      "14J28"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16496v1",
    "title": "Minimizing Energy in Reliability and Deadline-Ensured Workflow Scheduling in Cloud",
    "authors": [
      "Suvarthi Sarkar",
      "Dhanesh V",
      "Ketan Singh",
      "Aryabartta Sahu"
    ],
    "abstract": "With the increasing prevalence of computationally intensive workflows in\ncloud environments, it has become crucial for cloud platforms to optimize\nenergy consumption while ensuring the feasibility of user workflow schedules\nwith respect to strict deadlines and reliability constraints. The key\nchallenges faced when cloud systems provide virtual machines of varying levels\nof reliability, energy consumption, processing frequencies, and computing\ncapabilities to execute tasks of these workflows. To address these issues, we\npropose an adaptive strategy based on maximum fan-out ratio considering the\nslack of tasks and deadline distribution for scheduling workflows in a single\ncloud platform, intending to minimise energy consumption while ensuring strict\nreliability and deadline constraints. We also propose an approach for dynamic\nscheduling of workflow using the rolling horizon concept to consider the\ndynamic execution time of tasks of the workflow where the actual task execution\ntime at run time is shorter than worst-case execution time in most of the\ncases. Our proposed static approach outperforms the state-of-the-art (SOTA) by\nup to 70% on average in scenarios without deadline constraints, and achieves an\nimprovement of approximately 2% in deadline-constrained cases. The dynamic\nvariant of our approach demonstrates even stronger performance, surpassing SOTA\nby 82% in non-deadline scenarios and by up to 27% on average when deadline\nconstraints are enforced. Furthermore, in comparison with the static optimal\nsolution, our static approach yields results within a factor of 1.1, while the\ndynamic approach surpasses the optimal baseline by an average of 25%.",
    "pdf_url": "http://arxiv.org/pdf/2505.16496v1",
    "published": "2025-05-22T10:30:14+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16495v1",
    "title": "ALTo: Adaptive-Length Tokenizer for Autoregressive Mask Generation",
    "authors": [
      "Lingfeng Wang",
      "Hualing Lin",
      "Senda Chen",
      "Tao Wang",
      "Changxu Cheng",
      "Yangyang Zhong",
      "Dong Zheng",
      "Wuyue Zhao"
    ],
    "abstract": "While humans effortlessly draw visual objects and shapes by adaptively\nallocating attention based on their complexity, existing multimodal large\nlanguage models (MLLMs) remain constrained by rigid token representations.\nBridging this gap, we propose ALTo, an adaptive length tokenizer for\nautoregressive mask generation. To achieve this, a novel token length predictor\nis designed, along with a length regularization term and a differentiable token\nchunking strategy. We further build ALToLLM that seamlessly integrates ALTo\ninto MLLM. Preferences on the trade-offs between mask quality and efficiency is\nimplemented by group relative policy optimization (GRPO). Experiments\ndemonstrate that ALToLLM achieves state-of-the-art performance with adaptive\ntoken cost on popular segmentation benchmarks. Code and models are released at\nhttps://github.com/yayafengzi/ALToLLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.16495v1",
    "published": "2025-05-22T10:26:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16494v1",
    "title": "Accuracy vs. Accuracy: Computational Tradeoffs Between Classification Rates and Utility",
    "authors": [
      "Noga Amit",
      "Omer Reingold",
      "Guy N. Rothblum"
    ],
    "abstract": "We revisit the foundations of fairness and its interplay with utility and\nefficiency in settings where the training data contain richer labels, such as\nindividual types, rankings, or risk estimates, rather than just binary\noutcomes. In this context, we propose algorithms that achieve stronger notions\nof evidence-based fairness than are possible in standard supervised learning.\nOur methods support classification and ranking techniques that preserve\naccurate subpopulation classification rates, as suggested by the underlying\ndata distributions, across a broad class of classification rules and downstream\napplications. Furthermore, our predictors enable loss minimization, whether\naimed at maximizing utility or in the service of fair treatment.\n  Complementing our algorithmic contributions, we present impossibility results\ndemonstrating that simultaneously achieving accurate classification rates and\noptimal loss minimization is, in some cases, computationally infeasible. Unlike\nprior impossibility results, our notions are not inherently in conflict and are\nsimultaneously satisfied by the Bayes-optimal predictor. Furthermore, we show\nthat each notion can be satisfied individually via efficient learning. Our\nseparation thus stems from the computational hardness of learning a\nsufficiently good approximation of the Bayes-optimal predictor. These\ncomputational impossibilities present a choice between two natural and\nattainable notions of accuracy that could both be motivated by fairness.",
    "pdf_url": "http://arxiv.org/pdf/2505.16494v1",
    "published": "2025-05-22T10:26:30+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16493v1",
    "title": "Constrained Non-negative Matrix Factorization for Guided Topic Modeling of Minority Topics",
    "authors": [
      "Seyedeh Fatemeh Ebrahimi",
      "Jaakko Peltonen"
    ],
    "abstract": "Topic models often fail to capture low-prevalence, domain-critical themes,\nso-called minority topics, such as mental health themes in online comments.\nWhile some existing methods can incorporate domain knowledge, such as expected\ntopical content, methods allowing guidance may require overly detailed expected\ntopics, hindering the discovery of topic divisions and variation. We propose a\ntopic modeling solution via a specially constrained NMF. We incorporate a seed\nword list characterizing minority content of interest, but we do not require\nexperts to pre-specify their division across minority topics. Through\nprevalence constraints on minority topics and seed word content across topics,\nwe learn distinct data-driven minority topics as well as majority topics. The\nconstrained NMF is fitted via Karush-Kuhn-Tucker (KKT) conditions with\nmultiplicative updates. We outperform several baselines on synthetic data in\nterms of topic purity, normalized mutual information, and also evaluate topic\nquality using Jensen-Shannon divergence (JSD). We conduct a case study on\nYouTube vlog comments, analyzing viewer discussion of mental health content;\nour model successfully identifies and reveals this domain-relevant minority\ncontent.",
    "pdf_url": "http://arxiv.org/pdf/2505.16493v1",
    "published": "2025-05-22T10:25:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16492v1",
    "title": "Learning collective multi-cellular dynamics from temporal scRNA-seq via a transformer-enhanced Neural SDE",
    "authors": [
      "Qi Jiang",
      "Lei Zhang",
      "Longquan Li",
      "Lin Wan"
    ],
    "abstract": "Time-series single-cell RNA-sequencing (scRNA-seq) datasets offer\nunprecedented insights into the dynamics and heterogeneity of cellular systems.\nThese systems exhibit multiscale collective behaviors driven by intricate\nintracellular gene regulatory networks and intercellular interactions of\nmolecules. However, inferring interacting cell population dynamics from\ntime-series scRNA-seq data remains a significant challenge, as cells are\nisolated and destroyed during sequencing. To address this, we introduce scIMF,\na single-cell deep generative Interacting Mean Field model, designed to learn\ncollective multi-cellular dynamics. Our approach leverages a\ntransformer-enhanced stochastic differential equation network to simultaneously\ncapture cell-intrinsic dynamics and intercellular interactions. Through\nextensive benchmarking on multiple scRNA-seq datasets, scIMF outperforms\nexisting methods in reconstructing gene expression at held-out time points,\ndemonstrating that modeling cell-cell communication enhances the accuracy of\nmulticellular dynamics characterization.Additionally, our model provides\nbiologically interpretable insights into cell-cell interactions during dynamic\nprocesses, offering a powerful tool for understanding complex cellular systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16492v1",
    "published": "2025-05-22T10:23:07+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16491v2",
    "title": "LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing",
    "authors": [
      "Dario Di Palma",
      "Alessandro De Bellis",
      "Giovanni Servedio",
      "Vito Walter Anelli",
      "Fedelucio Narducci",
      "Tommaso Di Noia"
    ],
    "abstract": "Large Language Models (LLMs) have rapidly become central to NLP,\ndemonstrating their ability to adapt to various tasks through prompting\ntechniques, including sentiment analysis. However, we still have a limited\nunderstanding of how these models capture sentiment-related information. This\nstudy probes the hidden layers of Llama models to pinpoint where sentiment\nfeatures are most represented and to assess how this affects sentiment\nanalysis.\n  Using probe classifiers, we analyze sentiment encoding across layers and\nscales, identifying the layers and pooling methods that best capture sentiment\nsignals. Our results show that sentiment information is most concentrated in\nmid-layers for binary polarity tasks, with detection accuracy increasing up to\n14% over prompting techniques. Additionally, we find that in decoder-only\nmodels, the last token is not consistently the most informative for sentiment\nencoding. Finally, this approach enables sentiment tasks to be performed with\nmemory requirements reduced by an average of 57%.\n  These insights contribute to a broader understanding of sentiment in LLMs,\nsuggesting layer-specific probing as an effective approach for sentiment tasks\nbeyond prompting, with potential to enhance model utility and reduce memory\nrequirements.",
    "pdf_url": "http://arxiv.org/pdf/2505.16491v2",
    "published": "2025-05-22T10:22:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16490v2",
    "title": "HPP-Voice: A Large-Scale Evaluation of Speech Embeddings for Multi-Phenotypic Classification",
    "authors": [
      "David Krongauz",
      "Hido Pinto",
      "Sarah Kohn",
      "Yanir Marmor",
      "Eran Segal"
    ],
    "abstract": "Human speech contains paralinguistic cues that reflect a speaker's\nphysiological and neurological state, potentially enabling non-invasive\ndetection of various medical phenotypes. We introduce the Human Phenotype\nProject Voice corpus (HPP-Voice): a dataset of 7,188 recordings in which\nHebrew-speaking adults count for 30 seconds, with each speaker linked to up to\n15 potentially voice-related phenotypes spanning respiratory, sleep, mental\nhealth, metabolic, immune, and neurological conditions. We present a systematic\ncomparison of 14 modern speech embedding models, where modern speech embeddings\nfrom these 30-second counting tasks outperform MFCCs and demographics for\ndownstream health condition classifications. We found that embedding learned\nfrom a speaker identification model can predict objectively measured moderate\nto severe sleep apnea in males with an AUC of 0.64 $\\pm$ 0.03, while MFCC and\ndemographic features led to AUCs of 0.56 $\\pm$ 0.02 and 0.57 $\\pm$ 0.02,\nrespectively. Additionally, our results reveal gender-specific patterns in\nmodel effectiveness across different medical domains. For males, speaker\nidentification and diarization models consistently outperformed speech\nfoundation models for respiratory conditions (e.g., asthma: 0.61 $\\pm$ 0.03 vs.\n0.56 $\\pm$ 0.02) and sleep-related conditions (insomnia: 0.65 $\\pm$ 0.04 vs.\n0.59 $\\pm$ 0.05). For females, speaker diarization models performed best for\nsmoking status (0.61 $\\pm$ 0.02 vs 0.55 $\\pm$ 0.02), while Hebrew-specific\nmodels performed best (0.59 $\\pm$ 0.02 vs. 0.58 $\\pm$ 0.02) in classifying\nanxiety compared to speech foundation models. Our findings provide evidence\nthat a simple counting task can support large-scale, multi-phenotypic voice\nscreening and highlight which embedding families generalize best to specific\nconditions, insights that can guide future vocal biomarker research and\nclinical deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16490v2",
    "published": "2025-05-22T10:22:15+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16489v1",
    "title": "Spin-polarized alkali-metal trimers revisited",
    "authors": [
      "Jiří Klimeš",
      "Pavel Soldán"
    ],
    "abstract": "Homonuclear spin-polarized alkali-metal trimers in their lowest-lying\nelectronic state are investigated theoretically. Their equilibrium geometries\nand binding energies are determined with the state-of-the-art quantum chemical\nmethods at three levels of approximation. The equilibrium geometries obtained\n$R_{\\rm eq}({\\rm Li}_3) = 3.100$ \\r{A}, $R_{\\rm eq}({\\rm Na}_3) = 4.353$ \\r{A},\n$R_{\\rm eq}({\\rm K}_3) = 4.996$ \\r{A}, $R_{\\rm eq}({\\rm Rb}_3) = 5.391$ \\r{A},\nand $R_{\\rm eq}({\\rm Cs}_3) = 5.730$ \\r{A} are compared to the other\ntheoretical results and also with the very recent experimental results obtained\nthrough the laser-induced Coulomb explosion. Further theoretical studies are\nproposed, which could help with better interpretation of the experimental\nresults for the sodium and cesium trimers.",
    "pdf_url": "http://arxiv.org/pdf/2505.16489v1",
    "published": "2025-05-22T10:20:34+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17151v1",
    "title": "Bayesian Optimization for Enhanced Language Models: Optimizing Acquisition Functions",
    "authors": [
      "Zishuo Bao",
      "Yibo Liu",
      "Changyutao Qiu"
    ],
    "abstract": "With the rise of different language model architecture, fine-tuning is\nbecoming even more important for down stream tasks Model gets messy, finding\nproper hyperparameters for fine-tuning. Although BO has been tried for\nhyperparameter tuning, most of the existing methods are oblivious to the fact\nthat BO relies on careful choices of acquisition functions, which are essential\ncomponents of BO that guide how much to explore versus exploit during the\noptimization process; Different acquisition functions have different levels of\nsensitivity towards training loss and validation performance; existing methods\noften just apply an acquisition function no matter if the training and\nvalidation performance are sensitive to the acquisition function or not. This\nwork introduces{Bilevel - BO - SWA}, a model fusion approach coupled with a\nbilevel BO strategy to improve the fine - tunning of large language models. Our\nwork on mixture of acquisition functions like EI and UCB into nested opt loops,\nwhere inner loop perform minimization of training loss while outer loops\noptimized w.r.t. val metric. Experiments on GLUE tasks using RoBERTA - base\nshow that when using EI and UCB, there is an improvement in generalization, and\nfine - tuning can be improved by up to 2.7%.",
    "pdf_url": "http://arxiv.org/pdf/2505.17151v1",
    "published": "2025-05-22T10:16:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16488v2",
    "title": "Kinetic approximation for equations of discrete turbulence in the subcritical case",
    "authors": [
      "Andrey Dymov"
    ],
    "abstract": "We consider a damped/driven cubic NLS equation on a torus under the limit\nwhen first the amplitude of solutions goes to zero and then the period of the\ntorus goes to infinity. We suggest another proof of the kinetic approximation\nfor the energy spectrum under a subcritical scaling, extending to the exact\nsolutions result obtained in [Dymov, Kuksin, Maiocchi, Vladuts '2023] for\nquasisolutions which were defined as the second order truncations of\ndecompositions for the solutions in amplitude. The proof does not involve\nFeynman diagrams, instead relying on a robust inductive analysis of cumulants.",
    "pdf_url": "http://arxiv.org/pdf/2505.16488v2",
    "published": "2025-05-22T10:13:52+00:00",
    "categories": [
      "math-ph",
      "math.AP",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16487v1",
    "title": "Implicit Neural Shape Optimization for 3D High-Contrast Electrical Impedance Tomography",
    "authors": [
      "Junqing Chen",
      "Haibo Liu"
    ],
    "abstract": "We present a novel implicit neural shape optimization framework for 3D\nhigh-contrast Electrical Impedance Tomography (EIT), addressing scenarios where\nconductivity exhibits sharp discontinuities across material interfaces. These\nhigh-contrast cases, prevalent in metallic implant monitoring and industrial\ndefect detection, challenge traditional reconstruction methods due to severe\nill-posedness. Our approach synergizes shape optimization with implicit neural\nrepresentations, introducing key innovations including a shape derivative-based\noptimization scheme that explicitly incorporates high-contrast interface\nconditions and an efficient latent space representation that reduces variable\ndimensionality. Through rigorous theoretical analysis of algorithm convergence\nand extensive numerical experiments, we demonstrate substantial performance\nimprovements, establishing our framework as promising for practical\napplications in medical imaging with metallic implants and industrial\nnon-destructive testing.",
    "pdf_url": "http://arxiv.org/pdf/2505.16487v1",
    "published": "2025-05-22T10:13:19+00:00",
    "categories": [
      "math.NA",
      "cs.CV",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16486v1",
    "title": "Asset liability management under sequential stochastic dominance constraints",
    "authors": [
      "Giorgio Consigli",
      "Darinka Dentcheva",
      "Francesca Maggioni",
      "Giovanni Micheli"
    ],
    "abstract": "We consider a financial intermediary managing assets and liabilities exposed\nto several risk sources and seeking an optimal portfolio strategy to minimise\nthe initial capital invested and the total risk associated with investment\nlosses and financial debt. We formulate the problem as a multistage stochastic\nprogramming model, with a time-consistent dynamic risk measure in the objective\nfunction to control the investment risk. To ensure that the intermediary's\nfinancial equilibrium is preserved, we introduce a funding constraint in the\nmodel by enforcing in a time-consistent manner a sequential second-order\nstochastic dominance (SSD) of the portfolio return distribution over the\nliability distribution. We demonstrate that imposing the SSD constraint at the\nlast-but-one stage is sufficient to enforce the SSD ordering at each stage. To\ndeal with the computational burden of associated MSP, we develop a novel\ndecomposition scheme integrating, for the first time in the literature,\ntime-consistent dynamic risk measures and sequential stochastic dominance\nconstraints. The proposed methodology is computationally validated on a case\nstudy developed on a property and casualty ALM problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.16486v1",
    "published": "2025-05-22T10:13:10+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16485v1",
    "title": "InspectionV3: Enhancing Tobacco Quality Assessment with Deep Convolutional Neural Networks for Automated Workshop Management",
    "authors": [
      "Yao Wei",
      "Muhammad Usman",
      "Hazrat Bilal"
    ],
    "abstract": "The problems that tobacco workshops encounter include poor curing,\ninconsistencies in supplies, irregular scheduling, and a lack of oversight, all\nof which drive up expenses and worse quality. Large quantities make manual\nexamination costly, sluggish, and unreliable. Deep convolutional neural\nnetworks have recently made strides in capabilities that transcend those of\nconventional methods. To effectively enhance them, nevertheless, extensive\ncustomization is needed to account for subtle variations in tobacco grade. This\nstudy introduces InspectionV3, an integrated solution for automated flue-cured\ntobacco grading that makes use of a customized deep convolutional neural\nnetwork architecture. A scope that covers color, maturity, and curing\nsubtleties is established via a labelled dataset consisting of 21,113 images\nspanning 20 quality classes. Expert annotators performed preprocessing on the\ntobacco leaf images, including cleaning, labelling, and augmentation.\nMulti-layer CNN factors use batch normalization to describe domain properties\nlike as permeability and moisture spots, and so account for the subtleties of\nthe workshop. Its expertise lies in converting visual patterns into useful\ninformation for enhancing workflow. Fast notifications are made possible by\nreal-time, on-the-spot grading that matches human expertise. Images-powered\nanalytics dashboards facilitate the tracking of yield projections, inventories,\nbottlenecks, and the optimization of data-driven choices. More labelled images\nare assimilated after further retraining, improving representational capacities\nand enabling adaptations for seasonal variability. Metrics demonstrate 97%\naccuracy, 95% precision and recall, 96% F1-score and AUC, 95% specificity;\nvalidating real-world viability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16485v1",
    "published": "2025-05-22T10:11:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16484v1",
    "title": "Quantum Multi-view Kernel Learning with Local Information",
    "authors": [
      "Jing Li",
      "Yanqi Song",
      "Sujuan Qin",
      "Fei Gao"
    ],
    "abstract": "Kernel methods serve as powerful tools to capture nonlinear patterns behind\ndata in machine learning. The quantum kernel, integrating kernel theory with\nquantum computing, has attracted widespread attention. However, existing\nstudies encounter performance bottlenecks when processing complex data with\nlocalized structural patterns, stemming from the limitation in single-view\nfeature representation and the exclusive reliance on global data structure. In\nthis paper, we propose quantum multi-view kernel learning with local\ninformation, called L-QMVKL. Specifically, based on the multi-kernel learning,\na representative method for multi-view data processing, we construct the\nquantum multi-kernel that combines view-specific quantum kernels to effectively\nfuse cross-view information. Further leveraging local information to capture\nintrinsic structural information, we design a sequential training strategy for\nthe quantum circuit parameters and weight coefficients with the use of the\nhybrid global-local kernel alignment. We evaluate the effectiveness of L-QMVKL\nthrough comprehensive numerical simulations on the Mfeat dataset, demonstrating\nsignificant accuracy improvements achieved through leveraging multi-view\nmethodology and local information. Meanwhile, the results show that L-QMVKL\nexhibits a higher accuracy than its classical counterpart. Our work holds\npromise for advancing the theoretical and practical understanding of quantum\nkernel methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.16484v1",
    "published": "2025-05-22T10:11:49+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16483v2",
    "title": "Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning",
    "authors": [
      "Shuzheng Si",
      "Haozhe Zhao",
      "Cheng Gao",
      "Yuzhuo Bai",
      "Zhitong Wang",
      "Bofei Gao",
      "Kangyang Luo",
      "Wenhao Li",
      "Yufei Huang",
      "Gang Chen",
      "Fanchao Qi",
      "Minjia Zhang",
      "Baobao Chang",
      "Maosong Sun"
    ],
    "abstract": "Teaching large language models (LLMs) to be faithful in the provided context\nis crucial for building reliable information-seeking systems. Therefore, we\npropose a systematic framework, CANOE, to reduce faithfulness hallucinations of\nLLMs across different downstream tasks without human annotations. Specifically,\nwe first synthesize short-form question-answering (QA) data with four diverse\ntasks to construct high-quality and easily verifiable training data without\nhuman annotation. Also, we propose Dual-GRPO, a rule-based reinforcement\nlearning method that includes three tailored rule-based rewards derived from\nsynthesized short-form QA data, while simultaneously optimizing both short-form\nand long-form response generation. Notably, Dual-GRPO eliminates the need to\nmanually label preference data to train reward models and avoids\nover-optimizing short-form generation when relying only on the synthesized\nshort-form QA data. Experimental results show that CANOE greatly improves the\nfaithfulness of LLMs across 11 different tasks, even outperforming the most\nadvanced LLMs, e.g., GPT-4o and OpenAI o1.",
    "pdf_url": "http://arxiv.org/pdf/2505.16483v2",
    "published": "2025-05-22T10:10:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16482v1",
    "title": "Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes",
    "authors": [
      "Huynh Thi Thanh Binh",
      "Le Van Cuong",
      "Dang Hai Dang",
      "Le Trong Vinh"
    ],
    "abstract": "Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the\nadvantage of wireless energy transfer technology have opened a promising\nopportunity in solving the limited energy issue. However, an ineffective\ncharging strategy may reduce the charging performance. Although many practical\ncharging algorithms have been introduced, these studies mainly focus on\noptimizing the charging path with a fully charging approach. This approach may\nlead to the death of a series of sensors due to their extended charging\nlatency. This paper introduces a novel partial charging approach that follows a\nbi-level optimized scheme to minimize energy depletion in WRSNs. We aim at\noptimizing simultaneously two factors: the charging path and time. To\naccomplish this, we first formulate a mathematical model of the investigated\nproblem. We then propose two approximate algorithms in which the optimization\nof the charging path and the charging time are considered as the upper and\nlower level, respectively. The first algorithm combines a Multi-start Local\nSearch method and a Genetic Algorithm to find a solution. The second algorithm\nadopts a nested approach that utilizes the advantages of the Multitasking and\nCovariance Matrix Adaptation Evolutionary Strategies. Experimental validations\non various network scenarios demonstrate that our proposed algorithms\noutperform the existing works.",
    "pdf_url": "http://arxiv.org/pdf/2505.16482v1",
    "published": "2025-05-22T10:09:21+00:00",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16481v3",
    "title": "Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling",
    "authors": [
      "Xinxing Shi",
      "Xiaoyu Jiang",
      "Mauricio A. Álvarez"
    ],
    "abstract": "Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by\nreplacing the fully factorised Gaussian prior with a GP prior, thereby\ncapturing richer correlations among latent variables. However, performing exact\nGP inference in large-scale GPVAEs is computationally prohibitive, often\nforcing existing approaches to rely on restrictive kernel assumptions or large\nsets of inducing points. In this work, we propose a neighbour-driven\napproximation strategy that exploits local adjacencies in the latent space to\nachieve scalable GPVAE inference. By confining computations to the nearest\nneighbours of each data point, our method preserves essential latent\ndependencies, allowing more flexible kernel choices and mitigating the need for\nnumerous inducing points. Through extensive experiments on tasks including\nrepresentation learning, data imputation, and conditional generation, we\ndemonstrate that our approach outperforms other GPVAE variants in both\npredictive performance and computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.16481v3",
    "published": "2025-05-22T10:07:33+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16480v2",
    "title": "Gravitational collapse of matter fields in de Sitter spacetimes",
    "authors": [
      "Akriti Garg",
      "Ayan Chatterjee"
    ],
    "abstract": "In this paper, we discuss the spherically symmetric gravitational collapse of\nmatter fields in the de Sitter universe. The energy-momentum tensor of the\nmatter field is assumed to admit a wide variety including dust, perfect fluids\nwith equations of state, fluids with tangential and radial pressure, and with\nbulk and shear viscosity. Under different initial conditions imposed on the\nvelocity and the density profiles, and by combining the results from exact\nanalytical methods with those obtained from numerical techniques, we track the\nformation and evolution of spherical marginally trapped spheres as the matter\nsuffers continual gravitational collapse. We show that the quasilocal formalism\nof trapped surfaces provides an ideal framework to study the evolution of\nhorizons. More precisely, black hole and cosmological horizons may be viewed as\nthe time development of marginally trapped surfaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.16480v2",
    "published": "2025-05-22T10:06:45+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16479v1",
    "title": "Clear Nights Ahead: Towards Multi-Weather Nighttime Image Restoration",
    "authors": [
      "Yuetong Liu",
      "Yunqiu Xu",
      "Yang Wei",
      "Xiuli Bi",
      "Bin Xiao"
    ],
    "abstract": "Restoring nighttime images affected by multiple adverse weather conditions is\na practical yet under-explored research problem, as multiple weather conditions\noften coexist in the real world alongside various lighting effects at night.\nThis paper first explores the challenging multi-weather nighttime image\nrestoration task, where various types of weather degradations are intertwined\nwith flare effects. To support the research, we contribute the AllWeatherNight\ndataset, featuring large-scale high-quality nighttime images with diverse\ncompositional degradations, synthesized using our introduced illumination-aware\ndegradation generation. Moreover, we present ClearNight, a unified nighttime\nimage restoration framework, which effectively removes complex degradations in\none go. Specifically, ClearNight extracts Retinex-based dual priors and\nexplicitly guides the network to focus on uneven illumination regions and\nintrinsic texture contents respectively, thereby enhancing restoration\neffectiveness in nighttime scenarios. In order to better represent the common\nand unique characters of multiple weather degradations, we introduce a\nweather-aware dynamic specific-commonality collaboration method, which\nidentifies weather degradations and adaptively selects optimal candidate units\nassociated with specific weather types. Our ClearNight achieves\nstate-of-the-art performance on both synthetic and real-world images.\nComprehensive ablation experiments validate the necessity of AllWeatherNight\ndataset as well as the effectiveness of ClearNight. Project page:\nhttps://henlyta.github.io/ClearNight/mainpage.html",
    "pdf_url": "http://arxiv.org/pdf/2505.16479v1",
    "published": "2025-05-22T10:06:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16478v2",
    "title": "Unified Multi-Rate Model Predictive Control for a Jet-Powered Humanoid Robot",
    "authors": [
      "Davide Gorbani",
      "Giuseppe L'Erario",
      "Hosameldin Awadalla Omer Mohamed",
      "Daniele Pucci"
    ],
    "abstract": "We propose a novel Model Predictive Control (MPC) framework for a jet-powered\nflying humanoid robot. The controller is based on a linearised centroidal\nmomentum model to represent the flight dynamics, augmented with a second-order\nnonlinear model to explicitly account for the slow and nonlinear dynamics of\njet propulsion. A key contribution is the introduction of a multi-rate MPC\nformulation that handles the different actuation rates of the robot's joints\nand jet engines while embedding the jet dynamics directly into the predictive\nmodel. We validated the framework using the jet-powered humanoid robot iRonCub,\nperforming simulations in Mujoco; the simulation results demonstrate the\nrobot's ability to recover from external disturbances and perform stable,\nnon-abrupt flight manoeuvres, validating the effectiveness of the proposed\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2505.16478v2",
    "published": "2025-05-22T10:06:25+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16477v1",
    "title": "Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery",
    "authors": [
      "Yanbo Zhang",
      "Sumeer A. Khan",
      "Adnan Mahmud",
      "Huck Yang",
      "Alexander Lavin",
      "Michael Levin",
      "Jeremy Frey",
      "Jared Dunnmon",
      "James Evans",
      "Alan Bundy",
      "Saso Dzeroski",
      "Jesper Tegner",
      "Hector Zenil"
    ],
    "abstract": "With recent Nobel Prizes recognising AI contributions to science, Large\nLanguage Models (LLMs) are transforming scientific research by enhancing\nproductivity and reshaping the scientific method. LLMs are now involved in\nexperimental design, data analysis, and workflows, particularly in chemistry\nand biology. However, challenges such as hallucinations and reliability\npersist. In this contribution, we review how Large Language Models (LLMs) are\nredefining the scientific method and explore their potential applications\nacross different stages of the scientific cycle, from hypothesis testing to\ndiscovery. We conclude that, for LLMs to serve as relevant and effective\ncreative engines and productivity enhancers, their deep integration into all\nsteps of the scientific process should be pursued in collaboration and\nalignment with human scientific goals, with clear evaluation metrics. The\ntransition to AI-driven science raises ethical questions about creativity,\noversight, and responsibility. With careful guidance, LLMs could evolve into\ncreative engines, driving transformative breakthroughs across scientific\ndisciplines responsibly and effectively. However, the scientific community must\nalso decide how much it leaves to LLMs to drive science, even when associations\nwith 'reasoning', mostly currently undeserved, are made in exchange for the\npotential to explore hypothesis and solution regions that might otherwise\nremain unexplored by human exploration alone.",
    "pdf_url": "http://arxiv.org/pdf/2505.16477v1",
    "published": "2025-05-22T10:05:48+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16476v1",
    "title": "NeuralTSNE: A Python Package for the Dimensionality Reduction of Molecular Dynamics Data Using Neural Networks",
    "authors": [
      "Patryk Tajs",
      "Mateusz Skarupski",
      "Jakub Rydzewski"
    ],
    "abstract": "Unsupervised machine learning has recently gained much attention in the field\nof molecular dynamics (MD). Particularly, dimensionality reduction techniques\nhave been regularly employed to analyze large volumes of high-dimensional MD\ndata to gain insight into hidden information encoded in MD trajectories. Among\nmany such techniques, t-distributed stochastic neighbor embedding (t-SNE) is\nparticularly popular. A parametric version of t-SNE that employs neural\nnetworks is less commonly known, yet it has demonstrated superior performance\nin dimensionality reduction compared to the standard implementation. Here, we\npresent a Python package called NeuralTSNE with our implementation of\nparametric t-SNE. The implementation is done using the PyTorch library and the\nPyTorch Lightning framework and can be imported as a module or used from the\ncommand line. We show that NeuralTSNE offers an easy-to-use tool for the\nanalysis of MD data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16476v1",
    "published": "2025-05-22T10:05:04+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16475v1",
    "title": "ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection",
    "authors": [
      "Jiaqi Li",
      "Xinyi Dong",
      "Yang Liu",
      "Zhizhuo Yang",
      "Quansen Wang",
      "Xiaobo Wang",
      "SongChun Zhu",
      "Zixia Jia",
      "Zilong Zheng"
    ],
    "abstract": "We present a novel pipeline, ReflectEvo, to demonstrate that small language\nmodels (SLMs) can enhance meta introspection through reflection learning. This\nprocess iteratively generates self-reflection for self-training, fostering a\ncontinuous and self-evolving process. Leveraging this pipeline, we construct\nReflectEvo-460k, a large-scale, comprehensive, self-generated reflection\ndataset with broadened instructions and diverse multi-domain tasks. Building\nupon this dataset, we demonstrate the effectiveness of reflection learning to\nimprove SLMs' reasoning abilities using SFT and DPO with remarkable\nperformance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral\nfrom 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the\nreasoning capability of the three prominent open-sourced models on BIG-bench\nwithout distillation from superior models or fine-grained human annotation. We\nfurther conduct a deeper analysis of the high quality of self-generated\nreflections and their impact on error localization and correction. Our work\nhighlights the potential of continuously enhancing the reasoning performance of\nSLMs through iterative reflection learning in the long run.",
    "pdf_url": "http://arxiv.org/pdf/2505.16475v1",
    "published": "2025-05-22T10:03:05+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16474v1",
    "title": "Consistent World Models via Foresight Diffusion",
    "authors": [
      "Yu Zhang",
      "Xingzhuo Guo",
      "Haoran Xu",
      "Mingsheng Long"
    ],
    "abstract": "Diffusion and flow-based models have enabled significant progress in\ngeneration tasks across various modalities and have recently found applications\nin world modeling. However, unlike typical generation tasks that encourage\nsample diversity, world models entail different sources of uncertainty and\nrequire consistent samples aligned with the ground-truth trajectory, which is a\nlimitation we empirically observe in diffusion models. We argue that a key\nbottleneck in learning consistent diffusion-based world models lies in the\nsuboptimal predictive ability, which we attribute to the entanglement of\ncondition understanding and target denoising within shared architectures and\nco-training schemes. To address this, we propose Foresight Diffusion\n(ForeDiff), a diffusion-based world modeling framework that enhances\nconsistency by decoupling condition understanding from target denoising.\nForeDiff incorporates a separate deterministic predictive stream to process\nconditioning inputs independently of the denoising stream, and further\nleverages a pretrained predictor to extract informative representations that\nguide generation. Extensive experiments on robot video prediction and\nscientific spatiotemporal forecasting show that ForeDiff improves both\npredictive accuracy and sample consistency over strong baselines, offering a\npromising direction for diffusion-based world models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16474v1",
    "published": "2025-05-22T10:01:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16473v1",
    "title": "Hausdorff measure of sets of inhomogeneous Dirichlet non-improvable affine forms with weights",
    "authors": [
      "Yubin He"
    ],
    "abstract": "Under a reasonable decay assumption on the approximating function, we\nestablish a zero-full law for the Hausdorff measure of sets of inhomogeneous\nDirichlet non-improvable affine forms with weights, thereby answering a\nquestion posed by Kim and Kim (\\S 5.3, Adv. Math., 2022).",
    "pdf_url": "http://arxiv.org/pdf/2505.16473v1",
    "published": "2025-05-22T09:59:59+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16472v1",
    "title": "On the Lebesgue Component of Semiclassical Measures for Abelian Quantum Actions",
    "authors": [
      "Gabriel Rivière",
      "Lasse L. Wolf"
    ],
    "abstract": "For a large class of symplectic integer matrices, the action on the torus\nextends to a symplectic $\\mathbb{Z}^r$-action with $r\\geq 2$. We apply this to\nthe study of semiclassical measures for joint eigenfunctions of the\nquantization of the symplectic matrices of the $\\mathbb{Z}^r$-action. In the\nirreducible setting, we prove that the resulting probability measures are\nconvex combinations of the Lebesgue measure with weight $\\geq 1/2$ and a zero\nentropy measure. We also provide a general theorem in the reducible case\nshowing that the Lebesgue components along isotropic and symplectic invariant\nsubtori must have total weight $\\geq 1/2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16472v1",
    "published": "2025-05-22T09:59:20+00:00",
    "categories": [
      "math-ph",
      "math.AP",
      "math.MP",
      "math.SP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.04234v1",
    "title": "Velocity determination for time lapse surveys using residual prestack depth migration",
    "authors": [
      "Joerg F. Schneider"
    ],
    "abstract": "The presented approach aims at estimating the lateral variation of seismic\nvelocities for a seismic timelapse survey. The monitor survey is depth migrated\nwith the known velocity model of the base survey. An analysis is performed to\ndetermine whether the moveout to be expected for the monitor survey after\nresidual prestack depth migration (RPSM) can be used for the velocity\ndetermination of the formation of interest. In that case the migrated response\nfor the base horizon of the monitor survey is analyzed in order to determine\nthe velocity distribution by employing residual migration concepts. With the\nuse of Fresnel apertures a rather local application is possible at\ncomparatively low signal to noise ratios. The approach is successfully\ndemonstrated for two isotropic depth models both for a lens-like and for a\nfaulted reservoir structures. In both cases the velocities of the monitor\nsurvey is recovered accurately. In addition it is demonstrated that an\niterative application is possible and that for these two models even severe\ncompaction of the model has little influence on the velocity estimation.",
    "pdf_url": "http://arxiv.org/pdf/2506.04234v1",
    "published": "2025-05-22T09:56:49+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16471v2",
    "title": "Graph-Supported Dynamic Algorithm Configuration for Multi-Objective Combinatorial Optimization",
    "authors": [
      "Robbert Reijnen",
      "Yaoxin Wu",
      "Zaharah Bukhsh",
      "Yingqian Zhang"
    ],
    "abstract": "Deep reinforcement learning (DRL) has been widely used for dynamic algorithm\nconfiguration, particularly in evolutionary computation, which benefits from\nthe adaptive update of parameters during the algorithmic execution. However,\napplying DRL to algorithm configuration for multi-objective combinatorial\noptimization (MOCO) problems remains relatively unexplored. This paper presents\na novel graph neural network (GNN) based DRL to configure multi-objective\nevolutionary algorithms. We model the dynamic algorithm configuration as a\nMarkov decision process, representing the convergence of solutions in the\nobjective space by a graph, with their embeddings learned by a GNN to enhance\nthe state representation. Experiments on diverse MOCO challenges indicate that\nour method outperforms traditional and DRL-based algorithm configuration\nmethods in terms of efficacy and adaptability. It also exhibits advantageous\ngeneralizability across objective types and problem sizes, and applicability to\ndifferent evolutionary computation methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.16471v2",
    "published": "2025-05-22T09:53:54+00:00",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16470v1",
    "title": "Benchmarking Retrieval-Augmented Multimomal Generation for Document Question Answering",
    "authors": [
      "Kuicai Dong",
      "Yujing Chang",
      "Shijie Huang",
      "Yasheng Wang",
      "Ruiming Tang",
      "Yong Liu"
    ],
    "abstract": "Document Visual Question Answering (DocVQA) faces dual challenges in\nprocessing lengthy multimodal documents (text, images, tables) and performing\ncross-modal reasoning. Current document retrieval-augmented generation (DocRAG)\nmethods remain limited by their text-centric approaches, frequently missing\ncritical visual information. The field also lacks robust benchmarks for\nassessing multimodal evidence selection and integration. We introduce MMDocRAG,\na comprehensive benchmark featuring 4,055 expert-annotated QA pairs with\nmulti-page, cross-modal evidence chains. Our framework introduces innovative\nmetrics for evaluating multimodal quote selection and enables answers that\ninterleave text with relevant visual elements. Through large-scale experiments\nwith 60 VLM/LLM models and 14 retrieval systems, we identify persistent\nchallenges in multimodal evidence retrieval, selection, and integration.Key\nfindings reveal advanced proprietary LVMs show superior performance than\nopen-sourced alternatives. Also, they show moderate advantages using multimodal\ninputs over text-only inputs, while open-source alternatives show significant\nperformance degradation. Notably, fine-tuned LLMs achieve substantial\nimprovements when using detailed image descriptions. MMDocRAG establishes a\nrigorous testing ground and provides actionable insights for developing more\nrobust multimodal DocVQA systems. Our benchmark and code are available at\nhttps://mmdocrag.github.io/MMDocRAG/.",
    "pdf_url": "http://arxiv.org/pdf/2505.16470v1",
    "published": "2025-05-22T09:52:57+00:00",
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.06305v1",
    "title": "Template-Guided 3D Molecular Pose Generation via Flow Matching and Differentiable Optimization",
    "authors": [
      "Noémie Bergues",
      "Arthur Carré",
      "Paul Join-Lambert",
      "Brice Hoffmann",
      "Arnaud Blondel",
      "Hamza Tajmouati"
    ],
    "abstract": "Predicting the 3D conformation of small molecules within protein binding\nsites is a key challenge in drug design. When a crystallized reference ligand\n(template) is available, it provides geometric priors that can guide 3D pose\nprediction. We present a two-stage method for ligand conformation generation\nguided by such templates. In the first stage, we introduce a molecular\nalignment approach based on flow-matching to generate 3D coordinates for the\nligand, using the template structure as a reference. In the second stage, a\ndifferentiable pose optimization procedure refines this conformation based on\nshape and pharmacophore similarities, internal energy, and, optionally, the\nprotein binding pocket. We evaluate our approach on a new benchmark of ligand\npairs co-crystallized with the same target and show that it outperforms\nstandard docking tools and open-access alignment methods, especially in cases\ninvolving low similarity to the template or high ligand flexibility.",
    "pdf_url": "http://arxiv.org/pdf/2506.06305v1",
    "published": "2025-05-22T09:50:51+00:00",
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16469v1",
    "title": "Clogging-unclogging transition in 2D vertical pipe",
    "authors": [
      "Y. Zhou",
      "M. Li",
      "Y. Wang",
      "Y. Guan",
      "Y. Liu",
      "Z. Zou"
    ],
    "abstract": "We experimentally and numerically investigate the clogging behavior of\ngranular materials in a two-dimensional vertical pipe. The nonmonotonicity of\nclogging probability found in cylindrical vertical pipe is also observed in the\ntwo-dimensional case. We numerically demonstrate that the clogging probability\nstrongly correlates with the friction coefficient $\\mu$, in addition to the\npipe-to-particle diameter ratio $D/d$. We thus construct a clogging-unclogging\n$D/d$-$\\mu$ phase diagram within the $2<D/d<3$ range. Finally, by analyzing the\ngeometrical arrangements of particles and using a simple analysis of forces and\ntorques, we are able to predict the clogging-unclogging transition in the\n$D/d$-$\\mu$ phase diagram and explain the mechanism of the observed\ncounterintuitive nonmonotonicity in more detail. From this work, we identify\ntwo primary conditions for clogging formation: first, all particles must\nachieve force and torque equilibrium; second, they must geometrically form an\narch. Our theoretical analysis reveals that the clogging-unclogging transition\nin vertical pipe is a natural example of the shear jamming transition.",
    "pdf_url": "http://arxiv.org/pdf/2505.16469v1",
    "published": "2025-05-22T09:49:49+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.16468v1",
    "title": "Local projection stabilization methods for $\\boldsymbol{H}({\\rm curl})$ and $\\boldsymbol{H}({\\rm div})$ advection problems",
    "authors": [
      "Yangfan Luo",
      "Jindong Wang",
      "Shuonan Wu"
    ],
    "abstract": "We devise local projection stabilization (LPS) methods for advection problems\nin the $\\boldsymbol{H}$(curl) and $\\boldsymbol{H}$(div) spaces, employing\nconforming finite element spaces of arbitrary order within a unified framework.\nThe key ingredient is a local inf-sup condition, enabled by enriching the\napproximation space with appropriate $\\boldsymbol{H}$(d) bubble functions (with\nd = curl or div). This enrichment allows for the construction of modified\ninterpolation operators, which are crucial for establishing optimal a priori\nerror estimates in the energy norm. Numerical examples are presented to verify\nboth the theoretical results and the stabilization properties of the proposed\nmethod.",
    "pdf_url": "http://arxiv.org/pdf/2505.16468v1",
    "published": "2025-05-22T09:49:35+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65N60, 65N12"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16467v1",
    "title": "Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization",
    "authors": [
      "Vera Neplenbroek",
      "Arianna Bisazza",
      "Raquel Fernández"
    ],
    "abstract": "Generative Large Language Models (LLMs) infer user's demographic information\nfrom subtle cues in the conversation -- a phenomenon called implicit\npersonalization. Prior work has shown that such inferences can lead to lower\nquality responses for users assumed to be from minority groups, even when no\ndemographic information is explicitly provided. In this work, we systematically\nexplore how LLMs respond to stereotypical cues using controlled synthetic\nconversations, by analyzing the models' latent user representations through\nboth model internals and generated answers to targeted user questions. Our\nfindings reveal that LLMs do infer demographic attributes based on these\nstereotypical signals, which for a number of groups even persists when the user\nexplicitly identifies with a different demographic group. Finally, we show that\nthis form of stereotype-driven implicit personalization can be effectively\nmitigated by intervening on the model's internal representations using a\ntrained linear probe to steer them toward the explicitly stated identity. Our\nresults highlight the need for greater transparency and control in how LLMs\nrepresent user identity.",
    "pdf_url": "http://arxiv.org/pdf/2505.16467v1",
    "published": "2025-05-22T09:48:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16466v1",
    "title": "Conf-GNNRec: Quantifying and Calibrating the Prediction Confidence for GNN-based Recommendation Methods",
    "authors": [
      "Meng Yan",
      "Cai Xu",
      "Xujing Wang",
      "Ziyu Guan",
      "Wei Zhao",
      "Yuhang Zhou"
    ],
    "abstract": "Recommender systems based on graph neural networks perform well in tasks such\nas rating and ranking. However, in real-world recommendation scenarios, noise\nsuch as user misuse and malicious advertisement gradually accumulates through\nthe message propagation mechanism. Even if existing studies mitigate their\neffects by reducing the noise propagation weights, the severe sparsity of the\nrecommender system still leads to the low-weighted noisy neighbors being\nmistaken as meaningful information, and the prediction result obtained based on\nthe polluted nodes is not entirely trustworthy. Therefore, it is crucial to\nmeasure the confidence of the prediction results in this highly noisy\nframework. Furthermore, our evaluation of the existing representative GNN-based\nrecommendation shows that it suffers from overconfidence. Based on the above\nconsiderations, we propose a new method to quantify and calibrate the\nprediction confidence of GNN-based recommendations (Conf-GNNRec). Specifically,\nwe propose a rating calibration method that dynamically adjusts excessive\nratings to mitigate overconfidence based on user personalization. We also\ndesign a confidence loss function to reduce the overconfidence of negative\nsamples and effectively improve recommendation performance. Experiments on\npublic datasets demonstrate the validity of Conf-GNNRec in prediction\nconfidence and recommendation performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.16466v1",
    "published": "2025-05-22T09:48:17+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16465v1",
    "title": "Explicit and Mixed Estimates for Thue inequalities with few coefficients",
    "authors": [
      "N. Saradha",
      "Divyum Sharma"
    ],
    "abstract": "Let $F(x,y)$ be an irreducible form of degree $r\\geq 3$ and having $s+1$\nnon-zero coefficients. Let $h\\geq 1$ be an integer and consider the Thue\ninequality $$|F(x,y)|\\leq h.$$ Following the seminal work of Thue in 1909,\nseveral papers were written giving an upper bound for the number of solutions\nof the above inequality as $\\ll c(r,s,h)$ where $c(r,s,h)$ is an explicit\nfunction of $r,s$ and $h.$ Invariably, the absolute constant involved in $\\ll$\nhas been left undetermined. In this paper, following Bombieri, Schmidt and\nMueller, we give three different upper bounds which are explicit in every\naspect.",
    "pdf_url": "http://arxiv.org/pdf/2505.16465v1",
    "published": "2025-05-22T09:47:14+00:00",
    "categories": [
      "math.NT",
      "11D61"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16464v1",
    "title": "Twisted regular representations and bimodules in vertex operator algebra theory",
    "authors": [
      "Yiyi Zhu"
    ],
    "abstract": "In this paper, we use the twisted regular representation theory of vertex\noperator algebras to construct bimodules over twisted Zhu algebras, extending\nHaisheng Li's work in untwisted scenarios. Moreover, a conjecture of Dong and\nJiang on bimodule theory is confirmed.",
    "pdf_url": "http://arxiv.org/pdf/2505.16464v1",
    "published": "2025-05-22T09:45:49+00:00",
    "categories": [
      "math.QA",
      "17B69"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16463v3",
    "title": "AnchorFormer: Differentiable Anchor Attention for Efficient Vision Transformer",
    "authors": [
      "Jiquan Shan",
      "Junxiao Wang",
      "Lifeng Zhao",
      "Liang Cai",
      "Hongyuan Zhang",
      "Ioannis Liritzis"
    ],
    "abstract": "Recently, vision transformers (ViTs) have achieved excellent performance on\nvision tasks by measuring the global self-attention among the image patches.\nGiven $n$ patches, they will have quadratic complexity such as\n$\\mathcal{O}(n^2)$ and the time cost is high when splitting the input image\nwith a small granularity. Meanwhile, the pivotal information is often randomly\ngathered in a few regions of an input image, some tokens may not be helpful for\nthe downstream tasks. To handle this problem, we introduce an anchor-based\nefficient vision transformer (AnchorFormer), which employs the anchor tokens to\nlearn the pivotal information and accelerate the inference. Firstly, by\nestimating the bipartite attention between the anchors and tokens, the\ncomplexity will be reduced from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$, where\n$m$ is an anchor number and $m < n$. Notably, by representing the anchors with\nthe neurons in a neural layer, we can differentiably learn these anchors and\napproximate global self-attention through the Markov process. It avoids the\nburden caused by non-differentiable operations and further speeds up the\napproximate attention. Moreover, we extend the proposed model to three\ndownstream tasks including classification, detection, and segmentation.\nExtensive experiments show the effectiveness of our AnchorFormer, e.g.,\nachieving up to a 9.0% higher accuracy or 46.7% FLOPs reduction on ImageNet\nclassification, 81.3% higher mAP on COCO detection under comparable FLOPs, as\ncompared to the current baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.16463v3",
    "published": "2025-05-22T09:44:44+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16462v1",
    "title": "Synthesis of Ventilator Dyssynchrony Waveforms using a Hybrid Generative Model and a Lung Model",
    "authors": [
      "Sagar Deep Deb",
      "Suvakash Dey",
      "Deepak K. Agrawal"
    ],
    "abstract": "Ventilator dyssynchrony (VD) is often described as a mismatch between a\npatient breathing effort and the ventilator support during mechanical\nventilation. This mismatch is often associated with an increased risk of lung\ninjury and longer hospital stays. The manual VD detection method is unreliable\nand requires considerable effort from medical professionals. Automating this\nprocess requires a computational pipeline that can identify VD breaths from\ncontinuous waveform signals. For that, while various machine learning (ML)\nmodels have been proposed, their accuracy is often limited due to the\nunavailability of a large, well-annotated VD waveform dataset. This paper\npresents a new approach combining mathematical and deep generative models to\ngenerate synthetic, clinically relevant VD waveforms. The mathematical model,\nwhich we call the VD lung ventilator model (VDLV), can accurately replicate\nclinically observable deformation in the pressure and volume waveforms. These\ntemporal deformations are hypothesized to be related to specific VD breaths. We\nleverage the VDLV model to produce training waveform datasets covering normal\nand various VD breaths. These datasets are further diversified using deep\nlearning models such as Generative Adversarial Network (GAN) and Conditional\nGAN (cGAN). The performance of both GAN and cGAN models is assessed through\nquantitative metrics, demonstrating that this hybrid approach effectively\ncreates realistic and diverse VD waveforms. Notably, the pressure and volume\ncGAN models enable the generation of more precise and targeted VD signals.\nThese improved synthetic waveform datasets have the potential to significantly\nenhance the accuracy and robustness of VD detection algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.16462v1",
    "published": "2025-05-22T09:44:29+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16461v2",
    "title": "On equivalence of weak and viscosity solutions to nonlocal double phase problems with nonhomogeneous data",
    "authors": [
      "Sekhar Ghosh",
      "R. Lakshmi",
      "Chao Zhang"
    ],
    "abstract": "This work focuses on the nonhomogeneous nonlocal double phase problem\n\\begin{align*}\n  L_au(x)=f(x,u,D_s^p u, D_{a,t}^q u) \\text{ in } \\Omega, \\end{align*} where\n$\\Omega\\subset\\mathbb{R}^N$ is a bounded domain with Lipschitz boundary,\n$0<s,t<1<p\\leq q<\\infty$ with $tq\\leq sp$ and the operator $L_a$ is defined as\n\\begin{align*}\n  L_a\nu(x)&=2\\operatorname{P.V.}\\int_{\\mathbb{R}^N}|u(x)-u(y)|^{p-2}(u(x)-u(y))K_{s,p}(x,y)\n  &\\ \\ \\\n+2\\operatorname{P.V.}\\int_{\\mathbb{R}^N}a(x,y)|u(x)-u(y)|^{q-2}(u(x)-u(y))K_{t,q}(x,y)dy.\n\\end{align*} We establish the equivalence between weak and viscosity solutions\nunder boundedness and continuity assumptions. In addition, the local\nboundedness of weak solutions in some special cases on $f$ is also obtained\nusing the notion of De Giorgi classes.",
    "pdf_url": "http://arxiv.org/pdf/2505.16461v2",
    "published": "2025-05-22T09:43:24+00:00",
    "categories": [
      "math.AP",
      "35D30, 35D40, 35R05, 35R11, 35B65"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16460v1",
    "title": "University of Indonesia at SemEval-2025 Task 11: Evaluating State-of-the-Art Encoders for Multi-Label Emotion Detection",
    "authors": [
      "Ikhlasul Akmal Hanif",
      "Eryawan Presma Yulianrifat",
      "Jaycent Gunawan Ongris",
      "Eduardus Tjitrahardja",
      "Muhammad Falensi Azmi",
      "Rahmat Bryan Naufal",
      "Alfan Farizki Wicaksono"
    ],
    "abstract": "This paper presents our approach for SemEval 2025 Task 11 Track A, focusing\non multilabel emotion classification across 28 languages. We explore two main\nstrategies: fully fine-tuning transformer models and classifier-only training,\nevaluating different settings such as fine-tuning strategies, model\narchitectures, loss functions, encoders, and classifiers. Our findings suggest\nthat training a classifier on top of prompt-based encoders such as mE5 and BGE\nyields significantly better results than fully fine-tuning XLMR and mBERT. Our\nbest-performing model on the final leaderboard is an ensemble combining\nmultiple BGE models, where CatBoost serves as the classifier, with different\nconfigurations. This ensemble achieves an average F1-macro score of 56.58\nacross all languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.16460v1",
    "published": "2025-05-22T09:42:11+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16459v4",
    "title": "MMLU-Reason: Benchmarking Multi-Task Multi-modal Language Understanding and Reasoning",
    "authors": [
      "Guiyao Tie",
      "Xueyang Zhou",
      "Tianhe Gu",
      "Ruihang Zhang",
      "Chaoran Hu",
      "Sizhe Zhang",
      "Mengqu Sun",
      "Yan Zhang",
      "Pan Zhou",
      "Lichao Sun"
    ],
    "abstract": "Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled\nunified processing of language, vision, and structured inputs, opening the door\nto complex tasks such as logical deduction, spatial reasoning, and scientific\nanalysis. Despite their promise, the reasoning capabilities of MLLMs,\nparticularly those augmented with intermediate thinking traces (MLLMs-T),\nremain poorly understood and lack standardized evaluation benchmarks. Existing\nwork focuses primarily on perception or final answer correctness, offering\nlimited insight into how models reason or fail across modalities. To address\nthis gap, we introduce the MMLU-Reason, a new benchmark designed to rigorously\nevaluate multi-modal reasoning with explicit thinking. The MMLU-Reason\ncomprises 1) a high-difficulty dataset of 1,083 questions spanning six diverse\nreasoning types with symbolic depth and multi-hop demands and 2) a modular\nReasoning Trace Evaluation Pipeline (RTEP) for assessing reasoning quality\nbeyond accuracy through metrics like relevance, consistency, and structured\nerror annotations. Empirical results show that MLLMs-T overall outperform\nnon-thinking counterparts, but even top models like Claude-3.7-Sonnet and\nGemini-2.5 Pro suffer from reasoning pathologies such as inconsistency and\noverthinking. This benchmark reveals persistent gaps between accuracy and\nreasoning quality and provides an actionable evaluation pipeline for future\nmodel development. Overall, the MMLU-Reason offers a scalable foundation for\nevaluating, comparing, and improving the next generation of multi-modal\nreasoning systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16459v4",
    "published": "2025-05-22T09:41:55+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16458v1",
    "title": "Improving 1D stellar atmosphere models with insights from multi-dimensional simulations II. 1D versus 3D hydrodynamically consistent model comparison for WR stars",
    "authors": [
      "G. González-Torà",
      "A. A. C. Sander",
      "N. Moens",
      "J. O. Sundqvist",
      "D. Debnath",
      "L. Delbroek",
      "J. Josiek",
      "R. R. Lefever",
      "C. Van der Sijpt",
      "O. Verhamme",
      "M. Bernini-Peron"
    ],
    "abstract": "Classical Wolf-Rayet (cWR) stars are evolved massive stars that have lost\nmost of their H envelope and exhibit dense, extended atmospheres with strong,\nline-driven winds. Accurately modeling wind launching from optically thick\nlayers remains a challenge. Two main approaches have advanced our\nunderstanding: 1D stationary atmosphere models with consistent hydrodynamics\nand time-dependent, multi-dimensional radiation-hydrodynamic simulations. Due\nto high computational demands, multi-dimensional models are limited in scope.\nTherefore, 1D hydrodynamically consistent models remain essential but must\nincorporate insights from 3D simulations. We compare averaged stratifications\nfrom recent multi-dimensional cWR models with 1D models computed using the\nhydrodynamically consistent PoWR$^{HD}$ code. We focus on winds driven by the\nhot iron opacity bump and explore how variations in 1D input parameters affect\nmodel outcomes. The 1D models reproduce the average 3D density structure well.\nWhile mass-loss rates are typically $\\lesssim$0.2 dex higher in 1D models,\nsmall adjustments accounting for multi-dimensional dispersion reconcile the\ndifferences. 1D models tend to be more radially extended, with higher terminal\nvelocities and lower effective temperatures. They reproduce the general\nvelocity trends of 3D models but launch winds slightly further out and reach\nhigher velocities during the hot iron bump. These differences also manifest in\nsynthetic spectra computed from different 1D model approaches. Despite\nmethodological variations, both 1D and averaged 3D models yield consistent\nstellar parameters when accounting for the variability seen in time-dependent\nsimulations. For stars near the Eddington limit, reducing Doppler velocities in\n1D models improves agreement in mass-loss rates, temperatures, and wind\nvelocities. Matching temperature structures in optically thin layers remains an\nopen challenge.",
    "pdf_url": "http://arxiv.org/pdf/2505.16458v1",
    "published": "2025-05-22T09:41:07+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16457v2",
    "title": "Maximum Separation of Quantum Communication Complexity With and Without Shared Entanglement",
    "authors": [
      "Atsuya Hasegawa",
      "François Le Gall",
      "Augusto Modanese"
    ],
    "abstract": "We present relation problems whose input size is $n$ such that they can be\nsolved with no communication for entanglement-assisted quantum communication\nmodels, but require $\\Omega(n)$ qubit communication for $2$-way quantum\ncommunication models without prior shared entanglement. This is the maximum\nseparation of quantum communication complexity with and without shared\nentanglement. To our knowledge, our result even shows the first lower bound on\nquantum communication complexity without shared entanglement when the upper\nbound of entanglement-assisted quantum communication models is zero. The\nproblem we consider is parallel repetition of any non-local game which has a\nperfect quantum strategy and no perfect classical strategy, and for which a\nparallel repetition theorem holds with exponential decay.",
    "pdf_url": "http://arxiv.org/pdf/2505.16457v2",
    "published": "2025-05-22T09:41:04+00:00",
    "categories": [
      "quant-ph",
      "cs.CC"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16456v1",
    "title": "MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM",
    "authors": [
      "Siwei Meng",
      "Yawei Luo",
      "Ping Liu"
    ],
    "abstract": "Recent advances in static 3D generation have intensified the demand for\nphysically consistent dynamic 3D content. However, existing video generation\nmodels, including diffusion-based methods, often prioritize visual realism\nwhile neglecting physical plausibility, resulting in implausible object\ndynamics. Prior approaches for physics-aware dynamic generation typically rely\non large-scale annotated datasets or extensive model fine-tuning, which imposes\nsignificant computational and data collection burdens and limits scalability\nacross scenarios. To address these challenges, we present MAGIC, a\ntraining-free framework for single-image physical property inference and\ndynamic generation, integrating pretrained image-to-video diffusion models with\niterative LLM-based reasoning. Our framework generates motion-rich videos from\na static image and closes the visual-to-physical gap through a\nconfidence-driven LLM feedback loop that adaptively steers the diffusion model\ntoward physics-relevant motion. To translate visual dynamics into controllable\nphysical behavior, we further introduce a differentiable MPM simulator\noperating directly on 3D Gaussians reconstructed from the single image,\nenabling physically grounded, simulation-ready outputs without any supervision\nor model tuning. Experiments show that MAGIC outperforms existing physics-aware\ngenerative methods in inference accuracy and achieves greater temporal\ncoherence than state-of-the-art video diffusion models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16456v1",
    "published": "2025-05-22T09:40:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16455v1",
    "title": "Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events",
    "authors": [
      "Mengzhu Liu",
      "Zhengqiu Zhu",
      "Chuan Ai",
      "Chen Gao",
      "Xinghong Li",
      "Lingnan He",
      "Kaisheng Lai",
      "Yingfeng Chen",
      "Xin Lu",
      "Yong Li",
      "Quanjun Yin"
    ],
    "abstract": "During sudden disaster events, accurately predicting public panic sentiment\non social media is crucial for proactive governance and crisis management.\nCurrent efforts on this problem face three main challenges: lack of finely\nannotated data hinders emotion prediction studies, unmodeled risk perception\ncauses prediction inaccuracies, and insufficient interpretability of panic\nformation mechanisms. We address these issues by proposing a Psychology-driven\ngenerative Agent framework (PsychoAgent) for explainable panic prediction based\non emotion arousal theory. Specifically, we first construct a fine-grained open\npanic emotion dataset (namely COPE) via human-large language models (LLMs)\ncollaboration to mitigate semantic bias. Then, we develop a framework\nintegrating cross-domain heterogeneous data grounded in psychological\nmechanisms to model risk perception and cognitive differences in emotion\ngeneration. To enhance interpretability, we design an LLM-based role-playing\nagent that simulates individual psychological chains through dedicatedly\ndesigned prompts. Experimental results on our annotated dataset show that\nPsychoAgent improves panic emotion prediction performance by 12.6% to 21.7%\ncompared to baseline models. Furthermore, the explainability and generalization\nof our approach is validated. Crucially, this represents a paradigm shift from\nopaque \"data-driven fitting\" to transparent \"role-based simulation with\nmechanistic interpretation\" for panic emotion prediction during emergencies.\nOur implementation is publicly available at:\nhttps://anonymous.4open.science/r/PsychoAgent-19DD.",
    "pdf_url": "http://arxiv.org/pdf/2505.16455v1",
    "published": "2025-05-22T09:39:39+00:00",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16454v1",
    "title": "Parallel Phase-shifting Digital Ghost Holography",
    "authors": [
      "Shuhei Yoshida"
    ],
    "abstract": "The ghost imaging (GI) technique, which has attracted attention as a highly\nsensitive and noise-resistant technique, employs a spatially modulated\nilluminating light and a single-pixel detector. Generally, the information\nacquired by GI is the transmittance or reflectance distribution of an object. A\nmethod has also been proposed to measure the complex amplitude by applying\ndigital holography (DH) techniques. These methods irradiate phase-modulated\nilluminating lights onto an object, and the intensities of the interference\nlights between the lights interacting with the object and the reference light\nare measured. Then, the complex amplitude of the object light is reconstructed\nbased on the correlation between the light intensities and the phase patterns.\nIn DH-based GI, it is necessary to remove unwanted components from the\ninterferogram by phase shifting, which requires more measurements than the\nconventional GI method. Thus, we propose a technique to reconstruct the complex\namplitude in DH-based GI without increasing the number of measurements using\nparallel phase-shifting optics. In the proposed method, interferograms\nphase-shifted in steps of $\\pi/2$ with waveplates are divided into four using\npolarization beam splitters (PBS), and their intensities are measured\nsimultaneously. The object light component can be extracted from the\nintensities of these four interferograms. We demonstrate the effectiveness of\nthe proposed method through experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16454v1",
    "published": "2025-05-22T09:38:36+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.16453v1",
    "title": "SpineWave: Harnessing Fish Rigid-Flexible Spinal Kinematics for Enhancing Biomimetic Robotic Locomotion",
    "authors": [
      "Qu He",
      "Weikun Li",
      "Guangmin Dai",
      "Hao Chen",
      "Qimeng Liu",
      "Xiaoqing Tian",
      "Jie You",
      "Weicheng Cui",
      "Michael S. Triantafyllou",
      "Dixia Fan"
    ],
    "abstract": "Fish have endured millions of years of evolution, and their distinct\nrigid-flexible body structures offer inspiration for overcoming challenges in\nunderwater robotics, such as limited mobility, high energy consumption, and\nadaptability. This paper introduces SpineWave, a biomimetic robotic fish\nfeaturing a fish-spine-like rigid-flexible transition structure. The structure\nintegrates expandable fishbone-like ribs and adjustable magnets, mimicking the\nstretch and recoil of fish muscles to balance rigidity and flexibility. In\naddition, we employed an evolutionary algorithm to optimize the hydrodynamics\nof the robot, achieving significant improvements in swimming performance.\nReal-world tests demonstrated robustness and potential for environmental\nmonitoring, underwater exploration, and industrial inspection. These tests\nestablished SpineWave as a transformative platform for aquatic robotics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16453v1",
    "published": "2025-05-22T09:36:44+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16452v2",
    "title": "CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI",
    "authors": [
      "Mohamed S. Elmahdy",
      "Marius Staring",
      "Patrick J. H. de Koning",
      "Samer Alabed",
      "Mahan Salehi",
      "Faisal Alandejani",
      "Michael Sharkey",
      "Ziad Aldabbagh",
      "Andrew J. Swift",
      "Rob J. van der Geest"
    ],
    "abstract": "Accurate and efficient quantification of cardiac function is essential for\nthe estimation of prognosis of cardiovascular diseases (CVDs). One of the most\ncommonly used metrics for evaluating cardiac pumping performance is left\nventricular ejection fraction (LVEF). However, LVEF can be affected by factors\nsuch as inter-observer variability and varying pre-load and after-load\nconditions, which can reduce its reproducibility. Additionally, cardiac\ndysfunction may not always manifest as alterations in LVEF, such as in heart\nfailure and cardiotoxicity diseases. An alternative measure that can provide a\nrelatively load-independent quantitative assessment of myocardial contractility\nis myocardial strain and strain rate. By using LVEF in combination with\nmyocardial strain, it is possible to obtain a thorough description of cardiac\nfunction. Automated estimation of LVEF and other volumetric measures from\ncine-MRI sequences can be achieved through segmentation models, while strain\ncalculation requires the estimation of tissue displacement between sequential\nframes, which can be accomplished using registration models. These tasks are\noften performed separately, potentially limiting the assessment of cardiac\nfunction. To address this issue, in this study we propose an end-to-end deep\nlearning (DL) model that jointly estimates groupwise (GW) registration and\nsegmentation for cardiac cine-MRI images. The proposed anatomically-guided Deep\nGW network was trained and validated on a large dataset of 4-chamber view\ncine-MRI image series of 374 subjects. A quantitative comparison with\nconventional GW registration using elastix and two DL-based methods showed that\nthe proposed model improved performance and substantially reduced computation\ntime.",
    "pdf_url": "http://arxiv.org/pdf/2505.16452v2",
    "published": "2025-05-22T09:36:42+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16451v1",
    "title": "The Solution of the Critical Dynamics of the Mean-Field Kob-Andersen Model",
    "authors": [
      "Gianmarco Perrupato",
      "Tommaso Rizzo"
    ],
    "abstract": "We analytically solve the critical dynamics of the Kob-Andersen kinetically\nconstrained model of supercooled liquids on the Bethe lattice, employing a\ncombinatorial argument based on the cavity method. For arbitrary values of\ngraph connectivity z and facilitation parameter m, we demonstrate that the\ncritical behavior of the order parameter is governed by equations of motion\nequivalent to those found in Mode-Coupling Theory. The resulting predictions\nfor the dynamical exponents are validated through direct comparisons with\nnumerical simulations that include both continuous and discontinuous transition\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16451v1",
    "published": "2025-05-22T09:36:37+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.16450v1",
    "title": "Volume growth of horospheres in diagonalizable Heintze groups",
    "authors": [
      "Gilles Courtois",
      "Pablo Lessa",
      "Emiliano Sequeira"
    ],
    "abstract": "We study the volume growth of horospheres in a Heintze group of the form R\n___ A R d with A a diagonal derivation. We conclude that the isometry and\nquasi-isometry classes of horospheres (with their intrinsic geometry) coincide.\nFurthermore, if A is not a scalar multiple of the identity, then there are\nexactly two such classes, characterized by their volume growth, which we\ncalculate explicitly.",
    "pdf_url": "http://arxiv.org/pdf/2505.16450v1",
    "published": "2025-05-22T09:36:29+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16449v1",
    "title": "Dynamic boundary conditions with noise for energy balance models coupled to geophysical flows",
    "authors": [
      "Gianmarco Del Sarto",
      "Matthias Hieber",
      "Tarek Zöchling"
    ],
    "abstract": "This article investigates an energy balance model coupled to the primitive\nequations by a dynamic boundary condition with and without noise on the\nboundary. It is shown that this system is globally strongly well-posed both in\nthe deterministic setting for arbitrary large data in $W^{2(1-\\frac{1}{p}),p}$\nfor $p \\in [2,\\infty)$ and in the stochastic setting for arbitrary large data\nin $H^1$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16449v1",
    "published": "2025-05-22T09:36:21+00:00",
    "categories": [
      "math.AP",
      "35Q86, 35Q35, 60H15, 76D03, 35K55"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.18770v1",
    "title": "Importance of User Control in Data-Centric Steering for Healthcare Experts",
    "authors": [
      "Aditya Bhattacharya",
      "Simone Stumpf",
      "Katrien Verbert"
    ],
    "abstract": "As Artificial Intelligence (AI) becomes increasingly integrated into\nhigh-stakes domains like healthcare, effective collaboration between healthcare\nexperts and AI systems is critical. Data-centric steering, which involves\nfine-tuning prediction models by improving training data quality, plays a key\nrole in this process. However, little research has explored how varying levels\nof user control affect healthcare experts during data-centric steering. We\naddress this gap by examining manual and automated steering approaches through\na between-subjects, mixed-methods user study with 74 healthcare experts. Our\nfindings show that manual steering, which grants direct control over training\ndata, significantly improves model performance while maintaining trust and\nsystem understandability. Based on these findings, we propose design\nimplications for a hybrid steering system that combines manual and automated\napproaches to increase user involvement during human-AI collaboration.",
    "pdf_url": "http://arxiv.org/pdf/2506.18770v1",
    "published": "2025-05-22T09:36:17+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16448v2",
    "title": "Internal Bias in Reasoning Models leads to Overthinking",
    "authors": [
      "Renfei Dang",
      "Shujian Huang",
      "Jiajun Chen"
    ],
    "abstract": "While current reasoning models possess strong exploratory capabilities, they\nare often criticized for overthinking due to redundant and unnecessary\nreflections. In this work, we reveal for the first time that overthinking in\nreasoning models may stem from their internal bias towards input texts. Upon\nencountering a reasoning problem, the model immediately forms a preliminary\nguess about the answer, which we term as an internal bias since it is not\nderived through actual reasoning. When this guess conflicts with its reasoning\nresult, the model tends to engage in reflection, leading to the waste of\ncomputational resources. Through further interpretability experiments, we find\nthat this behavior is largely driven by the model's excessive attention to the\ninput section, which amplifies the influence of internal bias on its\ndecision-making process. Additionally, by masking out the original input\nsection, the affect of internal bias can be effectively alleviated and the\nreasoning length could be reduced by 31%-53% across different complex reasoning\ntasks. Notably, in most cases, this approach also leads to improvements in\naccuracy. These findings demonstrate a causal relationship between internal\nbias and overthinking.",
    "pdf_url": "http://arxiv.org/pdf/2505.16448v2",
    "published": "2025-05-22T09:35:52+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16447v1",
    "title": "TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition",
    "authors": [
      "Oliver Grainge",
      "Michael Milford",
      "Indu Bodala",
      "Sarvapali D. Ramchurn",
      "Shoaib Ehsan"
    ],
    "abstract": "TAT-VPR is a ternary-quantized transformer that brings dynamic\naccuracy-efficiency trade-offs to visual SLAM loop-closure. By fusing ternary\nweights with a learned activation-sparsity gate, the model can control\ncomputation by up to 40% at run-time without degrading performance (Recall@1).\nThe proposed two-stage distillation pipeline preserves descriptor quality,\nletting it run on micro-UAV and embedded SLAM stacks while matching\nstate-of-the-art localization accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16447v1",
    "published": "2025-05-22T09:35:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16446v1",
    "title": "Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models",
    "authors": [
      "Zhaoxin Wang",
      "Handing Wang",
      "Cong Tian",
      "Yaochu Jin"
    ],
    "abstract": "Multimodal large language models (MLLMs) enable powerful cross-modal\nreasoning capabilities. However, the expanded input space introduces new attack\nsurfaces. Previous jailbreak attacks often inject malicious instructions from\ntext into less aligned modalities, such as vision. As MLLMs increasingly\nincorporate cross-modal consistency and alignment mechanisms, such explicit\nattacks become easier to detect and block. In this work, we propose a novel\nimplicit jailbreak framework termed IJA that stealthily embeds malicious\ninstructions into images via least significant bit steganography and couples\nthem with seemingly benign, image-related textual prompts. To further enhance\nattack effectiveness across diverse MLLMs, we incorporate adversarial suffixes\ngenerated by a surrogate model and introduce a template optimization module\nthat iteratively refines both the prompt and embedding based on model feedback.\nOn commercial models like GPT-4o and Gemini-1.5 Pro, our method achieves attack\nsuccess rates of over 90% using an average of only 3 queries.",
    "pdf_url": "http://arxiv.org/pdf/2505.16446v1",
    "published": "2025-05-22T09:34:47+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.11052v1",
    "title": "ACCORD: Autoregressive Constraint-satisfying Generation for COmbinatorial Optimization with Routing and Dynamic attention",
    "authors": [
      "Henrik Abgaryan",
      "Tristan Cazenave",
      "Ararat Harutyunyan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning\ncapabilities, yet their direct application to NP-hard combinatorial problems\n(CPs) remains underexplored. In this work, we systematically investigate the\nreasoning abilities of LLMs on a variety of NP-hard combinatorial optimization\ntasks and introduce ACCORD: Autoregressive Constraint-satisfying generation for\nCOmbinatorial optimization with Routing and Dynamic attention. ACCORD features\na novel dataset representation and model architecture that leverage the\nautoregressive nature of LLMs to dynamically enforce feasibility constraints,\ncoupled with attention-based routing to activate problem-specific LoRA modules.\nWe also present the ACCORD-90k supervised dataset, covering six NP-hard\ncombinatorial problems: TSP, VRP, Knapsack, FlowShop, JSSP, and BinPacking.\nExtensive experiments demonstrate that our ACCORD model, built on an\n8B-parameter Llama backbone, consistently outperforms standard prompting and\ninput-output methods, even when compared to much larger LLMs, such as gpt-4.\nAblation studies further show that our output structure enhances solution\nfeasibility. To the best of our knowledge, this is the first large-scale,\nend-to-end framework for exploring the applications of LLMs to a broad spectrum\nof combinatorial optimization problems. The codes are publicly available at\nhttps://github.com/starjob42/ACCORD",
    "pdf_url": "http://arxiv.org/pdf/2506.11052v1",
    "published": "2025-05-22T09:33:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16445v1",
    "title": "DAS-MP: Enabling High-Quality Macro Placement with Enhanced Dataflow Awareness",
    "authors": [
      "Xiaotian Zhao",
      "Zixuan Li",
      "Yichen Cai",
      "Tianju Wang",
      "Yushan Pan",
      "Xinfei Guo"
    ],
    "abstract": "Dataflow is a critical yet underexplored factor in automatic macro placement,\nwhich is becoming increasingly important for developing intelligent design\nautomation techniques that minimize reliance on manual adjustments and reduce\ndesign iterations. Existing macro or mixed-size placers with dataflow awareness\nprimarily focus on intrinsic relationships among macros, overlooking the\ncrucial influence of standard cell clusters on macro placement. To address\nthis, we propose DAS-MP, which extracts hidden connections between macros and\nstandard cells and incorporates a series of algorithms to enhance dataflow\nawareness, integrating them into placement constraints for improved macro\nplacement. To further optimize placement results, we introduce two fine-tuning\nsteps: (1) congestion optimization by taking macro area into consideration, and\n(2) flipping decisions to determine the optimal macro orientation based on the\nextracted dataflow information. By integrating enhanced dataflow awareness into\nplacement constraints and applying these fine-tuning steps, the proposed\napproach achieves an average 7.9% improvement in half-perimeter wirelength\n(HPWL) across multiple widely used benchmark designs compared to a\nstate-of-the-art dataflow-aware macro placer. Additionally, it significantly\nimproves congestion, reducing overflow by an average of 82.5%, and achieves\nimprovements of 36.97% in Worst Negative Slack (WNS) and 59.44% in Total\nNegative Slack (TNS). The approach also maintains efficient runtime throughout\nthe entire placement process, incurring less than a 1.5% runtime overhead.\nThese results show that the proposed dataflow-driven methodology, combined with\nthe fine-tuning steps, provides an effective foundation for macro placement and\ncan be seamlessly integrated into existing design flows to enhance placement\nquality.",
    "pdf_url": "http://arxiv.org/pdf/2505.16445v1",
    "published": "2025-05-22T09:33:32+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16444v1",
    "title": "Scaling Quantum Simulation-Based Optimization: Demonstrating Efficient Power Grid Management with Deep QAOA Circuits",
    "authors": [
      "Maximilian Adler",
      "Jonas Stein",
      "Michael Lachner"
    ],
    "abstract": "Quantum Simulation-based Optimization (QuSO) is a recently proposed class of\noptimization problems that entails industrially relevant problems characterized\nby cost functions or constraints that depend on summary statistic information\nabout the simulation of a physical system or process. This work extends initial\ntheoretical results that proved an up-to-exponential speedup for the simulation\ncomponent of the QAOA-based QuSO solver proposed by Stein et al. for the unit\ncommitment problem by an empirical evaluation of the optimization component\nusing a standard benchmark dataset, the IEEE 57-bus system. Exploiting clever\nclassical pre-computation, we develop a very efficient classical quantum\ncircuit simulation that bypasses costly ancillary qubit requirements by the\noriginal algorithm, allowing for large-scale experiments. Utilizing more than\n1000 QAOA layers and up to 20 qubits, our experiments complete a proof of\nconcept implementation for the proposed QuSO solver, showing that it can\nachieve both highly competitive performance and efficiency in its optimization\ncomponent compared to a standard classical baseline, i.e., simulated annealing.",
    "pdf_url": "http://arxiv.org/pdf/2505.16444v1",
    "published": "2025-05-22T09:33:29+00:00",
    "categories": [
      "quant-ph",
      "cs.DM"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16443v2",
    "title": "Stochastic collocation schemes for Neural Field Equations with random data",
    "authors": [
      "Daniele Avitabile",
      "Francesca Cavallini",
      "Svetlana Dubinkina",
      "Gabriel J. Lord"
    ],
    "abstract": "We develop and analyse numerical schemes for uncertainty quantification in\nneural field equations subject to random parametric data in the synaptic\nkernel, firing rate, external stimulus, and initial conditions. The schemes\ncombine a generic projection method for spatial discretisation to a stochastic\ncollocation scheme for the random variables. We study the problem in operator\nform, and derive estimates for the total error of the schemes, in terms of the\nspatial projector. We give conditions on the projected random data which\nguarantee analyticity of the semi-discrete solution as a Banach-valued\nfunction. We illustrate how to verify hypotheses starting from analytic random\ndata and a choice of spatial projection. We provide evidence that the predicted\nconvergence rates are found in various numerical experiments for linear and\nnonlinear neural field problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16443v2",
    "published": "2025-05-22T09:33:06+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.DS",
      "nlin.PS"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16442v1",
    "title": "MAFE R-CNN: Selecting More Samples to Learn Category-aware Features for Small Object Detection",
    "authors": [
      "Yichen Li",
      "Qiankun Liu",
      "Zhenchao Jin",
      "Jiuzhe Wei",
      "Jing Nie",
      "Ying Fu"
    ],
    "abstract": "Small object detection in intricate environments has consistently represented\na major challenge in the field of object detection. In this paper, we identify\nthat this difficulty stems from the detectors' inability to effectively learn\ndiscriminative features for objects of small size, compounded by the complexity\nof selecting high-quality small object samples during training, which motivates\nthe proposal of the Multi-Clue Assignment and Feature Enhancement\nR-CNN.Specifically, MAFE R-CNN integrates two pivotal components.The first is\nthe Multi-Clue Sample Selection (MCSS) strategy, in which the Intersection over\nUnion (IoU) distance, predicted category confidence, and ground truth region\nsizes are leveraged as informative clues in the sample selection process. This\nmethodology facilitates the selection of diverse positive samples and ensures a\nbalanced distribution of object sizes during training, thereby promoting\neffective model learning.The second is the Category-aware Feature Enhancement\nMechanism (CFEM), where we propose a simple yet effective category-aware memory\nmodule to explore the relationships among object features. Subsequently, we\nenhance the object feature representation by facilitating the interaction\nbetween category-aware features and candidate box features.Comprehensive\nexperiments conducted on the large-scale small object dataset SODA validate the\neffectiveness of the proposed method. The code will be made publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.16442v1",
    "published": "2025-05-22T09:30:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16441v1",
    "title": "Ranked Entropy Minimization for Continual Test-Time Adaptation",
    "authors": [
      "Jisu Han",
      "Jaemin Na",
      "Wonjun Hwang"
    ],
    "abstract": "Test-time adaptation aims to adapt to realistic environments in an online\nmanner by learning during test time. Entropy minimization has emerged as a\nprincipal strategy for test-time adaptation due to its efficiency and\nadaptability. Nevertheless, it remains underexplored in continual test-time\nadaptation, where stability is more important. We observe that the entropy\nminimization method often suffers from model collapse, where the model\nconverges to predicting a single class for all images due to a trivial\nsolution. We propose ranked entropy minimization to mitigate the stability\nproblem of the entropy minimization method and extend its applicability to\ncontinuous scenarios. Our approach explicitly structures the prediction\ndifficulty through a progressive masking strategy. Specifically, it gradually\naligns the model's probability distributions across different levels of\nprediction difficulty while preserving the rank order of entropy. The proposed\nmethod is extensively evaluated across various benchmarks, demonstrating its\neffectiveness through empirical results. Our code is available at\nhttps://github.com/pilsHan/rem",
    "pdf_url": "http://arxiv.org/pdf/2505.16441v1",
    "published": "2025-05-22T09:29:38+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16440v1",
    "title": "An automated algorithmic method to mitigate long-term variations in the efficiency of the GRAPES-3 muon telescope",
    "authors": [
      "S. Paul",
      "K. P. Arunbabu",
      "M. Chakraborty",
      "S. K. Gupta",
      "B. Hariharan",
      "Y. Hayashi",
      "P. Jagadeesan",
      "A. Jain",
      "P. Jain",
      "M. Karthik",
      "S. Kawakami",
      "H. Kojima",
      "K. Manjunath",
      "P. K. Mohanty",
      "S. D. Morris",
      "Y. Muraki",
      "P. K. Nayak",
      "T. Nonaka",
      "A. Oshima",
      "D. Pattanaik",
      "B. Rajesh",
      "M. Rameez",
      "K. Ramesh",
      "B. S. Rao",
      "L. V. Reddy",
      "S. Shibata",
      "K. Tanaka",
      "F. Varsi",
      "M. Zuberi"
    ],
    "abstract": "The GRAPES-3 large area muon telescope with its sixteen independent modules\nrecords the high energy (>1 GeV) muons continuously over 2.3 sr of the sky.\nHowever, the recorded muon rates are contaminated by instrumental effects and\ninstabilities spanning both short- and long-timescales, such as variations in\nthe efficiency of the detector. We present an automated, algorithmic method,\nwhich employs Bayesian blocks to discretize the data stream into periods and\nexploits the correlations among the sixteen independent modules of the muon\ntelescope to separate the impact of these instrumental problems from those\noriginating in physical effects of interest, allowing the Savitzky-Golay filter\nto be employed to mitigate the former. Compared to legacy methods, this method\nis less dependent on subjective input from experimental operators and provides\na data stream free of all known instrumental effects over calendar years. The\nmuon rate obtained with the new method shows a fairly better correlation with\nneutron monitor data, than that obtained with the legacy method.",
    "pdf_url": "http://arxiv.org/pdf/2505.16440v1",
    "published": "2025-05-22T09:29:20+00:00",
    "categories": [
      "astro-ph.IM",
      "hep-ex"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16439v1",
    "title": "Password Strength Detection via Machine Learning: Analysis, Modeling, and Evaluation",
    "authors": [
      "Jiazhi Mo",
      "Hailu Kuang",
      "Xiaoqi Li"
    ],
    "abstract": "As network security issues continue gaining prominence, password security has\nbecome crucial in safeguarding personal information and network systems. This\nstudy first introduces various methods for system password cracking, outlines\npassword defense strategies, and discusses the application of machine learning\nin the realm of password security. Subsequently, we conduct a detailed public\npassword database analysis, uncovering standard features and patterns among\npasswords. We extract multiple characteristics of passwords, including length,\nthe number of digits, the number of uppercase and lowercase letters, and the\nnumber of special characters. We then experiment with six different machine\nlearning algorithms: support vector machines, logistic regression, neural\nnetworks, decision trees, random forests, and stacked models, evaluating each\nmodel's performance based on various metrics, including accuracy, recall, and\nF1 score through model validation and hyperparameter tuning. The evaluation\nresults on the test set indicate that decision trees and stacked models excel\nin accuracy, recall, and F1 score, making them a practical option for the\nstrong and weak password classification task.",
    "pdf_url": "http://arxiv.org/pdf/2505.16439v1",
    "published": "2025-05-22T09:27:40+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16438v1",
    "title": "Exploring parametrized dark energy models in interacting scenario",
    "authors": [
      "Sangita Goswami",
      "Sudipta Das"
    ],
    "abstract": "In the present work, we have studied the dynamics of accelerating universe\nconsidering a simple parametrization of the equation of state parameter in an\ninteracting scenario. In this toy model, the dark energy component is allowed\nto interact with the dark matter component through a source term. The\nexpressions for various relevant cosmological parameters for the proposed\nparametrized model have been obtained and it has been found that the proposed\nmodel consistently drives the late time cosmic acceleration of the universe. We\nhave also carried out the Bayesian analysis using recent observational datasets\nin order to obtain the best fit values of the model parameters. It has been\nfound that the dark energy model with $Q \\propto H\\rho_{de}$ can provide a\npossible resolution of the Hubble tension in an interacting scenario where the\ndark energy component decays into the dark matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.16438v1",
    "published": "2025-05-22T09:27:31+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16437v1",
    "title": "D-grading and quasifree evolution",
    "authors": [
      "Heide Narnhofer"
    ],
    "abstract": "Generalizing the relation between spin-systems and Fermi-systems on the\nlattice we construct for a spin-system with dimension d an algebra for which\nquasifree time-evolutions exist. With appropriate assumptions the gauge\ninvariant subalgebra common for both algebras is invariant under this\ntime-evolution and on this subalgebra is norm-asymptotically abelian.",
    "pdf_url": "http://arxiv.org/pdf/2505.16437v1",
    "published": "2025-05-22T09:26:50+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16436v1",
    "title": "On QFT in Klein space",
    "authors": [
      "Bin Chen",
      "Zezhou Hu",
      "Xin-cheng Mao"
    ],
    "abstract": "In this paper, we investigate the quantum field theory in Klein space that\nhas two time directions. To study the canonical quantization, we select the\n``length of time\" $q$ as the evolution direction of the system. In our novel\nconstruction, some additional modes beyond the plane wave modes are crucial in\nthe canonical quantization and the later derivation of the LSZ reduction\nformula. We also derive the free two-point function by using Wick contraction\nin the canonical quantization formalism. Moreover, we introduce the\npath-integral formalism in which we can redefine the vacuum states and rederive\nthe correlation functions. We show that all the results in the Klein space\nderived in our novel approach match those obtained via analytical continuation\nfrom the Minkowski spacetime.",
    "pdf_url": "http://arxiv.org/pdf/2505.16436v1",
    "published": "2025-05-22T09:26:12+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.17150v1",
    "title": "Efficient Training of Neural SDEs Using Stochastic Optimal Control",
    "authors": [
      "Rembert Daems",
      "Manfred Opper",
      "Guillaume Crevecoeur",
      "Tolga Birdal"
    ],
    "abstract": "We present a hierarchical, control theory inspired method for variational\ninference (VI) for neural stochastic differential equations (SDEs). While VI\nfor neural SDEs is a promising avenue for uncertainty-aware reasoning in\ntime-series, it is computationally challenging due to the iterative nature of\nmaximizing the ELBO. In this work, we propose to decompose the control term\ninto linear and residual non-linear components and derive an optimal control\nterm for linear SDEs, using stochastic optimal control. Modeling the non-linear\ncomponent by a neural network, we show how to efficiently train neural SDEs\nwithout sacrificing their expressive power. Since the linear part of the\ncontrol term is optimal and does not need to be learned, the training is\ninitialized at a lower cost and we observe faster convergence.",
    "pdf_url": "http://arxiv.org/pdf/2505.17150v1",
    "published": "2025-05-22T09:26:01+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.PR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16435v1",
    "title": "Estimation of multiple parameters encoded in the modal structure of light",
    "authors": [
      "Alexander Boeschoten",
      "Giacomo Sorelli",
      "Manuel Gessner",
      "Claude Fabre",
      "Nicolas Treps"
    ],
    "abstract": "We investigate the problem of estimating simultaneously multiple parameters\nencoded in the shape of the modes on which the light is expanded. For this, we\ngeneralize the mode-encoded parameter estimation theory as introduced in\nRef.[1] to a multi-parameter scenario. We derive the general expression for the\nQuantum Fisher information matrix and establish the conditions under which the\nmulti-parameter Quantum Cram\\'er-Rao bound is attainable. In specific\nscenarios, we find that each parameter can be associated with a mode -- the\ndetection mode -- that is proportional to the derivative of either a single\nnon-vacuum mode or the mean-field mode. For a single non-vacuum mode, the\ncorrelation between parameters is determined by the real part of the overlap of\nthese detection modes, while in the case of a strong mean-field by the\ncovariance of the quadrature operators of the derivative modes. In both cases,\nthe attainability of the Quantum Cram\\'er-Rao bound is determined by the\nimaginary part of the overlap of the detection modes. Our findings provide\nclear criteria for optimal joint estimation of parameters encoded in the modal\nstructure of light, and can be used to benchmark experimental multi-parameter\nestimations and find optimal measurement strategies by carefully shaping the\nmodes and populating them with non-classical light.",
    "pdf_url": "http://arxiv.org/pdf/2505.16435v1",
    "published": "2025-05-22T09:20:02+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16434v1",
    "title": "Joint Flow And Feature Refinement Using Attention For Video Restoration",
    "authors": [
      "Ranjith Merugu",
      "Mohammad Sameer Suhail",
      "Akshay P Sarashetti",
      "Venkata Bharath Reddy Reddem",
      "Pankaj Kumar Bajpai",
      "Amit Satish Unde"
    ],
    "abstract": "Recent advancements in video restoration have focused on recovering\nhigh-quality video frames from low-quality inputs. Compared with static images,\nthe performance of video restoration significantly depends on efficient\nexploitation of temporal correlations among successive video frames. The\nnumerous techniques make use of temporal information via flow-based strategies\nor recurrent architectures. However, these methods often encounter difficulties\nin preserving temporal consistency as they utilize degraded input video frames.\nTo resolve this issue, we propose a novel video restoration framework named\nJoint Flow and Feature Refinement using Attention (JFFRA). The proposed JFFRA\nis based on key philosophy of iteratively enhancing data through the\nsynergistic collaboration of flow (alignment) and restoration. By leveraging\npreviously enhanced features to refine flow and vice versa, JFFRA enables\nefficient feature enhancement using temporal information. This interplay\nbetween flow and restoration is executed at multiple scales, reducing the\ndependence on precise flow estimation. Moreover, we incorporate an\nocclusion-aware temporal loss function to enhance the network's capability in\neliminating flickering artifacts. Comprehensive experiments validate the\nversatility of JFFRA across various restoration tasks such as denoising,\ndeblurring, and super-resolution. Our method demonstrates a remarkable\nperformance improvement of up to 1.62 dB compared to state-of-the-art\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.16434v1",
    "published": "2025-05-22T09:18:51+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16433v1",
    "title": "Non-perturbative effects in JT gravity from KdV equations",
    "authors": [
      "Yasuyuki Hatsuda",
      "Takaki Matsumoto",
      "Kazumi Okuyama"
    ],
    "abstract": "It is well-known that the partition function of the Jackiw-Teitelboim (JT)\ngravity is obtained by an integral transformation of volumes of moduli spaces\nfor Riemann surfaces, also known as the Weil-Petersson volumes. This fact\nenables us to compute the perturbative genus expansion of the partition\nfunction by solving a KdV-type non-linear partial differential equation. In\nthis work, we find that this KdV equation also admits transseries solutions. We\ngive a systematic algorithm to explicitly construct a one-parameter transseries\nsolution to the KdV equation. Our approach is based on general two-dimensional\ntopological gravity, and the results for the JT gravity are easily obtained as\na special case. The results in the leading non-perturbative sector perfectly\nagree with another independent calculation from topological recursions in\nrandom matrices.",
    "pdf_url": "http://arxiv.org/pdf/2505.16433v1",
    "published": "2025-05-22T09:17:37+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16432v1",
    "title": "High-pressure high-temperature solution growth, structural, and superconducting properties of Fe-substituted MgB2 single crystals",
    "authors": [
      "N. D. Zhigadlo",
      "R. Puzniak"
    ],
    "abstract": "Clarifying the impact of Fe doping on the structural and superconducting\nproperties of MgB2 is crucial, considering that iron is commonly used as a\nsheath material for the fabrication of metal-clad MgB2 wires and tapes. To date\nthe effects of Fe doping have only been investigated in polycrystalline\nsamples, but the obtained results are controversial. Here, we report the\nsuccessful growth of Mg1-xFexB2 single crystals in a quaternary Mg-Fe-B-N\nsystem using the cubic anvil high-pressure and high-temperature technique. The\nreaction took place in a closed boron nitride crucible at a pressure of 3 GPa\nand a temperature of 1960 {\\deg}C. The grown crystals exhibit plate-like shapes\nwith sizes up to 0.9 x 0.7 x 0.1 mm3. The variation of the critical temperature\nTc of Mg1-xFexB2 crystals with Fe content was found to be different from that\nobserved in polycrystalline samples. For a small Fe doping, up to x < 0.03, the\nbehaviour of Tc(x) is similar to that for the crystals with Al and C\nsubstitutions, which suggests that Fe is in non-magnetic state. In this doping\nrange, measurements of the temperature-dependent magnetization performed in\nhigh magnetic fields exclude spin states other than S = 0 for the Fe ions.\nHowever, for x > 0.03, certain crystals start to show a dramatic decrease in\nTc, suggesting that Fe might be in a magnetic state. The M-H dependence for\nthese crystals shows significant increase of magnetization with increasing\nfield in low magnetic field, pointing to a weak ferromagnetism. Overall, the\navailability of Fe substituted MgB2 single crystals exhibiting such peculiar\nbehaviour offers a unique opportunity to investigate the effect of disorder\nalone on one hand and the influence of magnetic substituent on the\nsuperconducting characteristics on the other.",
    "pdf_url": "http://arxiv.org/pdf/2505.16432v1",
    "published": "2025-05-22T09:16:34+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.16431v2",
    "title": "On the Two Paths Theorem and the Two Disjoint Paths Problem",
    "authors": [
      "Samuel Humeau",
      "Damien Pous"
    ],
    "abstract": "A tuple (s1,t1,s2,t2) of vertices in a simple undirected graph is 2-linked\nwhen there are two vertex-disjoint paths respectively from s1 to t1 and s2 to\nt2. A graph is 2-linked when all such tuples are 2-linked. We give a new and\nsimple proof of the ``two paths theorem'', a characterisation of edge-maximal\ngraphs which are not 2-linked as webs: particular near triangulations filled\nwith cliques. Our proof works by generalising the theorem, replacing the four\nvertices above by an arbitrary tuple; it does not require major theorems such\nas Kuratowski's or Menger's theorems. Instead it follows an inductive\ncharacterisation of generalised webs via parallel composition, a graph\noperation consisting in taking a disjoint union before identifying some pairs\nof vertices. We use the insights provided by this proof to design a simple\nO(nm) recursive algorithm for the ``two vertex-disjoint paths'' problem. This\nalgorithm is constructive in that it returns either two disjoint paths, or an\nembedding of the input graph into a web.",
    "pdf_url": "http://arxiv.org/pdf/2505.16431v2",
    "published": "2025-05-22T09:14:45+00:00",
    "categories": [
      "cs.DS",
      "math.CO"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16430v1",
    "title": "AutoMCQ -- Automatically Generate Code Comprehension Questions using GenAI",
    "authors": [
      "Martin Goodfellow",
      "Robbie Booth",
      "Andrew Fagan",
      "Alasdair Lambert"
    ],
    "abstract": "Students often do not fully understand the code they have written. This\nsometimes does not become evident until later in their education, which can\nmean it is harder to fix their incorrect knowledge or misunderstandings. In\naddition, being able to fully understand code is increasingly important in a\nworld where students have access to generative artificial intelligence (GenAI)\ntools, such as GitHub Copilot. One effective solution is to utilise code\ncomprehension questions, where a marker asks questions about a submission to\ngauge understanding, this can also have the side effect of helping to detect\nplagiarism. However, this approach is time consuming and can be difficult\nand/or expensive to scale. This paper introduces AutoMCQ, which uses GenAI for\nthe automatic generation of multiple-choice code comprehension questions. This\nis integrated with the CodeRunner automated assessment platform.",
    "pdf_url": "http://arxiv.org/pdf/2505.16430v1",
    "published": "2025-05-22T09:14:41+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16429v1",
    "title": "Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems",
    "authors": [
      "Song Jin",
      "Juntian Zhang",
      "Yuhan Liu",
      "Xun Zhang",
      "Yufei Zhang",
      "Guojun Yin",
      "Fei Jiang",
      "Wei Lin",
      "Rui Yan"
    ],
    "abstract": "Evaluating and iterating upon recommender systems is crucial, yet traditional\nA/B testing is resource-intensive, and offline methods struggle with dynamic\nuser-platform interactions. While agent-based simulation is promising, existing\nplatforms often lack a mechanism for user actions to dynamically reshape the\nenvironment. To bridge this gap, we introduce RecInter, a novel agent-based\nsimulation platform for recommender systems featuring a robust interaction\nmechanism. In RecInter platform, simulated user actions (e.g., likes, reviews,\npurchases) dynamically update item attributes in real-time, and introduced\nMerchant Agents can reply, fostering a more realistic and evolving ecosystem.\nHigh-fidelity simulation is ensured through Multidimensional User Profiling\nmodule, Advanced Agent Architecture, and LLM fine-tuned on Chain-of-Thought\n(CoT) enriched interaction data. Our platform achieves significantly improved\nsimulation credibility and successfully replicates emergent phenomena like\nBrand Loyalty and the Matthew Effect. Experiments demonstrate that this\ninteraction mechanism is pivotal for simulating realistic system evolution,\nestablishing our platform as a credible testbed for recommender systems\nresearch.",
    "pdf_url": "http://arxiv.org/pdf/2505.16429v1",
    "published": "2025-05-22T09:14:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16428v2",
    "title": "Sharp Asymptotic Minimaxity for One-Group Priors in Sparse Normal Means Problem",
    "authors": [
      "Sayantan Paul",
      "Prasenjit Ghosh",
      "Arijit Chakrabarti"
    ],
    "abstract": "In this paper, we consider the asymptotic properties of the Bayesian multiple\ntesting rules when the mean parameter of the sparse normal means problem is\nmodeled by a broad class of global-local priors, expressed as a scale mixture\nof normals. We are interested in studying the least possible risk, i.e., the\nminimax risk for two frequentist losses, one being the usual misclassification\n(or Hamming) loss, and the other one, measured as the sum of FDR and FNR. Under\nthe betamin separation condition, at first, assuming the level of sparsity to\nbe known, we propose a condition on the global parameter of our chosen class of\npriors, such that the resultant decision rule attains the minimax risk for both\nof the losses mentioned above. When the level of sparsity is unknown, we either\nuse an estimate of the global parameter obtained from the data, or propose an\nabsolutely continuous prior on it. For both of the procedures, under some\nassumption on the unknown level of sparsity, we show that the decision rules\nalso attain the minimax risk, again for both of the losses. Our results also\nprovide a guideline regarding the selection of priors, in the sense that beyond\na subclass(horseshoe type priors) of our chosen class of priors, the minimax\nrisk is not achievable with respect to any one of the two loss functions\nconsidered in this article. However, the subclass, horseshoe-type priors, is\nsuch a large subclass that it contains Horseshoe, Strawderman Berger, standard\ndouble Pareto, inverse gamma priors, just to name a few. In this way, along\nwith the most popular BH procedure and approach using spike and slab prior, a\nmultiple testing rule based on one group priors also achieves the optimal\nboundary. To the best of our knowledge, these are the first results in the\nliterature of global local priors which ensure the optimal minimax risk can be\nachieved exactly.",
    "pdf_url": "http://arxiv.org/pdf/2505.16428v2",
    "published": "2025-05-22T09:13:53+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.16427v1",
    "title": "Lineshapes in Pump-Probe Spectroscopy of Polaritons",
    "authors": [
      "Luca Nils Philipp",
      "Eva Münzel",
      "Julian Lüttig",
      "Roland Mitrić"
    ],
    "abstract": "Forming new hybrid quasiparticles by strong light-matter coupling is a\npromising tool for tailoring photophysics and photochemistry of molecules.\nThus, the ultrafast dynamics of polaritons formed upon strong light-matter\ncoupling has been extensively studied by pump-probe spectroscopy. Although it\nwas predicted that the partial photonic character of polaritons should shorten\ntheir lifetime compared to purely molecular excited states, many studies do not\nobserve this effect. So far, the unexpected longevity of the spectral\nsignatures was either explained by relaxation into a manifold of so-called dark\nstates or by other uncontrolled effects that change the properties of cavity\nmaterials. In order to resolve these issues, we investigate here the dependence\nof the lineshape of pump-probe spectra of polaritons on the ratio of photonic\nand molecular character. Furthermore, by phenomenologically including\nrelaxation to dark states, we find that it is possible to spectrally resolve\nthis relaxation process by observing a characteristic phase flip in the\npump-probe signal. Our results show that the signatures of various effects and\ntheir contributions to the polariton dynamics can be disentangled from the\nspectral lineshapes.",
    "pdf_url": "http://arxiv.org/pdf/2505.16427v1",
    "published": "2025-05-22T09:13:20+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16426v1",
    "title": "LCSR predictions for $B \\to K$ Hadronic Matrix Elements",
    "authors": [
      "Dayanand Mishra"
    ],
    "abstract": "In this talk, I will present the calculation of LCSR predictions for the $B\n\\to K$ Hadronic Matrix Elements (HME) at low $q^2$ using light meson\ndistribution amplitudes. I will discuss the results obtained.",
    "pdf_url": "http://arxiv.org/pdf/2505.16426v1",
    "published": "2025-05-22T09:12:03+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00024v2",
    "title": "Subgyrogroups within the product spaces of paratopological gyrogroups",
    "authors": [
      "Ying-Ying Jin",
      "Ye-Qing Sheng",
      "Yi-Ting Wang",
      "Li-Hong Xie"
    ],
    "abstract": "We present a characterization of paratopological gyrogroups that can be\ntopologically embedded as subgyrogroups into a product of first-countable\n$T_{i}$ paratopological gyrogroups for $i = 0, 1, 2$. Specifically, we\ndemonstrate that a strongly paratopological gyrogroup $G$ is topologically\nisomorphic to a subgyrogroup of a topological product of first-countable $T_1$\nstrongly paratopological gyrogroups if and only if $G$ is $T_1$,\n$\\omega$-balanced and the weakly Hausdorff number of $G$ is countable. This\nmeans that for every neighborhood $U$ of the identity 0 in $G$, there exists a\ncountable family $\\gamma$ of neighborhoods of 0 such that for all $V\n\\in\\gamma$, $\\bigcap_{V\\in\\gamma} (\\ominus V)\\subseteq U$. Similarly, we prove\nthat a strongly paratopological gyrogroup $G$ is topologically isomorphic to a\nsubgyrogroup of a topological product of first-countable Hausdorff strongly\nparatopological gyrogroups if and only if $G$ is Hausdorff, $\\omega$-balanced\nand the Hausdorff number of $G$ is countable. This means that for every\nneighborhood $U$ of the identity 0 in $G$, there exists a countable family\n$\\gamma$ of neighborhoods of 0 such that for all $V \\in\\gamma$,\n$\\bigcap_{V\\in\\gamma} (V\\boxminus V)\\subseteq U$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00024v2",
    "published": "2025-05-22T09:11:40+00:00",
    "categories": [
      "math.GN"
    ],
    "primary_category": "math.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.16425v1",
    "title": "$I^2G$: Generating Instructional Illustrations via Text-Conditioned Diffusion",
    "authors": [
      "Jing Bi",
      "Pinxin Liu",
      "Ali Vosoughi",
      "Jiarui Wu",
      "Jinxi He",
      "Chenliang Xu"
    ],
    "abstract": "The effective communication of procedural knowledge remains a significant\nchallenge in natural language processing (NLP), as purely textual instructions\noften fail to convey complex physical actions and spatial relationships. We\naddress this limitation by proposing a language-driven framework that\ntranslates procedural text into coherent visual instructions. Our approach\nmodels the linguistic structure of instructional content by decomposing it into\ngoal statements and sequential steps, then conditioning visual generation on\nthese linguistic elements. We introduce three key innovations: (1) a\nconstituency parser-based text encoding mechanism that preserves semantic\ncompleteness even with lengthy instructions, (2) a pairwise discourse coherence\nmodel that maintains consistency across instruction sequences, and (3) a novel\nevaluation protocol specifically designed for procedural language-to-image\nalignment. Our experiments across three instructional datasets (HTStep,\nCaptainCook4D, and WikiAll) demonstrate that our method significantly\noutperforms existing baselines in generating visuals that accurately reflect\nthe linguistic content and sequential nature of instructions. This work\ncontributes to the growing body of research on grounding procedural language in\nvisual content, with applications spanning education, task guidance, and\nmultimodal language understanding.",
    "pdf_url": "http://arxiv.org/pdf/2505.16425v1",
    "published": "2025-05-22T09:10:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16424v1",
    "title": "Web Element Relocalization in Evolving Web Applications: A Comparative Analysis and Extension Study",
    "authors": [
      "Anton Kluge",
      "Andrea Stocco"
    ],
    "abstract": "Fragile web tests, primarily caused by locator breakages, are a persistent\nchallenge in web development. Hence, researchers have proposed techniques for\nweb-element re-identification in which algorithms utilize a range of element\nproperties to relocate elements on updated versions of websites based on\nsimilarity scoring. In this paper, we replicate the original studies of the\nmost recent propositions in the literature, namely the Similo algorithm and its\nsuccessor, VON Similo. We also acknowledge and reconsider assumptions related\nto threats to validity in the original studies, which prompted additional\nanalysis and the development of mitigation techniques. Our analysis revealed\nthat VON Similo, despite its novel approach, tends to produce more false\npositives than Similo. We mitigated these issues through algorithmic\nrefinements and optimization algorithms that enhance parameters and comparison\nmethods across all Similo variants, improving the accuracy of Similo on its\noriginal benchmark by 5.62%. Moreover, we extend the replicated studies by\nproposing a larger evaluation benchmark (23x bigger than the original study) as\nwell as a novel approach that combines the strengths of both Similo and VON\nSimilo, called HybridSimilo. The combined approach achieved a gain comparable\nto the improved Similo alone. Results on the extended benchmark show that\nHybridSimilo locates 98.8% of elements with broken locators in realistic\ntesting scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16424v1",
    "published": "2025-05-22T09:09:31+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16423v1",
    "title": "Matrix-valued Hilbert modular forms",
    "authors": [
      "Enrico Da Ronche"
    ],
    "abstract": "In this paper we generalize the notion of logarithmic vector-valued modular\nform in order to give a general definition of matrix-valued Hilbert modular\nforms. We prove that they admit unique polynomial Fourier expansions and we\nbuild examples in some particular cases.",
    "pdf_url": "http://arxiv.org/pdf/2505.16423v1",
    "published": "2025-05-22T09:09:16+00:00",
    "categories": [
      "math.NT",
      "11F03"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16422v3",
    "title": "Unlocking Smarter Device Control: Foresighted Planning with a World Model-Driven Code Execution Approach",
    "authors": [
      "Xiaoran Yin",
      "Xu Luo",
      "Hao Wu",
      "Lianli Gao",
      "Jingkuan Song"
    ],
    "abstract": "The automatic control of mobile devices is essential for efficiently\nperforming complex tasks that involve multiple sequential steps. However, these\ntasks pose significant challenges due to the limited environmental information\navailable at each step, primarily through visual observations. As a result,\ncurrent approaches, which typically rely on reactive policies, focus solely on\nimmediate observations and often lead to suboptimal decision-making. To address\nthis problem, we propose \\textbf{Foresighted Planning with World Model-Driven\nCode Execution (FPWC)},a framework that prioritizes natural language\nunderstanding and structured reasoning to enhance the agent's global\nunderstanding of the environment by developing a task-oriented, refinable\n\\emph{world model} at the outset of the task. Foresighted actions are\nsubsequently generated through iterative planning within this world model,\nexecuted in the form of executable code. Extensive experiments conducted in\nsimulated environments and on real mobile devices demonstrate that our method\noutperforms previous approaches, particularly achieving a 44.4\\% relative\nimprovement in task success rate compared to the state-of-the-art in the\nsimulated environment. Code and demo are provided in the supplementary\nmaterial.",
    "pdf_url": "http://arxiv.org/pdf/2505.16422v3",
    "published": "2025-05-22T09:08:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16421v1",
    "title": "WebAgent-R1: Training Web Agents via End-to-End Multi-Turn Reinforcement Learning",
    "authors": [
      "Zhepei Wei",
      "Wenlin Yao",
      "Yao Liu",
      "Weizhi Zhang",
      "Qin Lu",
      "Liang Qiu",
      "Changlong Yu",
      "Puyang Xu",
      "Chao Zhang",
      "Bing Yin",
      "Hyokun Yun",
      "Lihong Li"
    ],
    "abstract": "While reinforcement learning (RL) has demonstrated remarkable success in\nenhancing large language models (LLMs), it has primarily focused on single-turn\ntasks such as solving math problems. Training effective web agents for\nmulti-turn interactions remains challenging due to the complexity of\nlong-horizon decision-making across dynamic web interfaces. In this work, we\npresent WebAgent-R1, a simple yet effective end-to-end multi-turn RL framework\nfor training web agents. It learns directly from online interactions with web\nenvironments by asynchronously generating diverse trajectories, entirely guided\nby binary rewards depending on task success. Experiments on the WebArena-Lite\nbenchmark demonstrate the effectiveness of WebAgent-R1, boosting the task\nsuccess rate of Qwen-2.5-3B from 6.1% to 33.9% and Llama-3.1-8B from 8.5% to\n44.8%, significantly outperforming existing state-of-the-art methods and strong\nproprietary models such as OpenAI o3. In-depth analyses reveal the\neffectiveness of the thinking-based prompting strategy and test-time scaling\nthrough increased interactions for web tasks. We further investigate different\nRL initialization policies by introducing two variants, namely WebAgent-R1-Zero\nand WebAgent-R1-CoT, which highlight the importance of the warm-up training\nstage (i.e., behavior cloning) and provide insights on incorporating long\nchain-of-thought (CoT) reasoning in web agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.16421v1",
    "published": "2025-05-22T09:07:43+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16420v1",
    "title": "Meta-Calibration of the Cosmic Magnification Coefficient: Toward Unbiased Weak Lensing Reconstruction by Counting Galaxies",
    "authors": [
      "Jian Qin",
      "Pengjie Zhang",
      "Zhu Chen",
      "Liping Fu",
      "Yu Yu",
      "Haojie Xu",
      "Ji Yao",
      "Yuan Shi",
      "Huanyuan Shan"
    ],
    "abstract": "Weak lensing alters galaxy sizes and fluxes, influencing the clustering\npatterns of galaxies through cosmic magnification. This effect enables the\nreconstruction of weak lensing convergence $\\hat{\\kappa}$ maps for DES and\nDECaLS by linearly combining galaxy overdensities across magnitude bins in the\n$g$, $r$, and $z$ photometry bands \\citep{Qin+,Qin2+}. In this study, we\nenhance the lensing reconstruction method by addressing biases in the\nmagnification coefficient estimation, which arise from incomplete consideration\nof selection effects, especially those induced by photometric redshift\n(photo-$z$) selection. Using a Random Forest-based photo-$z$ estimation for\nDECaLS and DES galaxies, we quantify the impact of photo-$z$ induced selection\non magnification coefficient estimation. Our results show that neglecting\nphoto-$z$ selection introduces significant biases in the magnification\ncoefficient, leading to deviations in the reconstructed convergence map\namplitude $A$, with values ranging from 0.4 to 3.5 depending on the survey,\nredshift, and magnitude cuts. By incorporating an improved magnification\ncoefficient estimation that accounts for photo-$z$ selection, these biases are\nsignificantly reduced, with $A$ converging to $\\sim 1$ as the magnitude cuts\napproach optimal values. This improvement is consistently observed across DES\nand DECaLS datasets and redshift bins, despite differences in survey strategies\nand depths. Our findings highlight the importance of addressing photo-$z$\ninduced selection to achieve unbiased weak lensing reconstructions and accurate\ncosmic magnification measurements.",
    "pdf_url": "http://arxiv.org/pdf/2505.16420v1",
    "published": "2025-05-22T09:06:25+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16419v1",
    "title": "Investigating Fine- and Coarse-grained Structural Correspondences Between Deep Neural Networks and Human Object Image Similarity Judgments Using Unsupervised Alignment",
    "authors": [
      "Soh Takahashi",
      "Masaru Sasaki",
      "Ken Takeda",
      "Masafumi Oizumi"
    ],
    "abstract": "The learning mechanisms by which humans acquire internal representations of\nobjects are not fully understood. Deep neural networks (DNNs) have emerged as a\nuseful tool for investigating this question, as they have internal\nrepresentations similar to those of humans as a byproduct of optimizing their\nobjective functions. While previous studies have shown that models trained with\nvarious learning paradigms - such as supervised, self-supervised, and CLIP -\nacquire human-like representations, it remains unclear whether their similarity\nto human representations is primarily at a coarse category level or extends to\nfiner details. Here, we employ an unsupervised alignment method based on\nGromov-Wasserstein Optimal Transport to compare human and model object\nrepresentations at both fine-grained and coarse-grained levels. The unique\nfeature of this method compared to conventional representational similarity\nanalysis is that it estimates optimal fine-grained mappings between the\nrepresentation of each object in human and model representations. We used this\nunsupervised alignment method to assess the extent to which the representation\nof each object in humans is correctly mapped to the corresponding\nrepresentation of the same object in models. Using human similarity judgments\nof 1,854 objects from the THINGS dataset, we find that models trained with CLIP\nconsistently achieve strong fine- and coarse-grained matching with human object\nrepresentations. In contrast, self-supervised models showed limited matching at\nboth fine- and coarse-grained levels, but still formed object clusters that\nreflected human coarse category structure. Our results offer new insights into\nthe role of linguistic information in acquiring precise object representations\nand the potential of self-supervised learning to capture coarse categorical\nstructures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16419v1",
    "published": "2025-05-22T09:06:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16418v1",
    "title": "Exploring the Relationship Between Diversity and Quality in Ad Text Generation",
    "authors": [
      "Yoichi Aoki",
      "Soichiro Murakami",
      "Ukyo Honda",
      "Akihiko Kato"
    ],
    "abstract": "In natural language generation for advertising, creating diverse and engaging\nad texts is crucial for capturing a broad audience and avoiding advertising\nfatigue. Regardless of the importance of diversity, the impact of the\ndiversity-enhancing methods in ad text generation -- mainly tested on tasks\nsuch as summarization and machine translation -- has not been thoroughly\nexplored. Ad text generation significantly differs from these tasks owing to\nthe text style and requirements. This research explores the relationship\nbetween diversity and ad quality in ad text generation by considering multiple\nfactors, such as diversity-enhancing methods, their hyperparameters,\ninput-output formats, and the models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16418v1",
    "published": "2025-05-22T09:05:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16417v1",
    "title": "On the Hausdorff spectra of free pro-$p$ groups and certain $p$-adic analytic groups",
    "authors": [
      "Iker de las Heras",
      "Benjamin Klopsch",
      "Anitha Thillaisundaram"
    ],
    "abstract": "We establish that finitely generated non-abelian direct products $G$ of free\npro-$p$ groups have full Hausdorff spectrum with respect to the lower\n$p$-series $\\mathcal{L}$. This complements similar results with respect to\nother standard filtration series and a recent theorem showing that the\nHausdorff spectrum $\\text{hspec}^\\mathcal{L}(G)$ of a $p$-adic analytic pro-$p$\ngroup $G$ is discrete and consists of at most $2^{\\dim(G)}$ rational numbers.\n  The latter also left some room for improvement regarding the upper bound.\nIndeed, for finitely generated nilpotent pro-$p$ groups $G$ we obtain the\nstronger assertion that the cardinality of the Hausdorff spectrum is at most\nthe analytic dimension of $G$. Moreover, we produce a corresponding result when\nthe $p$-adic analytic pro-$p$ group $G$ is just infinite, which holds not just\nfor the lower $p$-series but for arbitrary filtration series.\n  Finally, we show that, if $G$ is a countably based pro-$p$ group with an open\nsubgroup mapping onto the free abelian pro-$p$ group $\\mathbb{Z}_p \\oplus\n\\mathbb{Z}_p$, then for every prescribed finite set $\\{0,1\\} \\subseteq X\n\\subseteq [0,1]$ there is a filtration series $\\mathcal{S}$ such that\n$\\text{hspec}^\\mathcal{S}(G) = X$; in particular,\n$|\\text{hspec}^{\\mathcal{S}}(G)|$ is unbounded, as $\\mathcal{S}$ runs through\nall filtration series of $G$ with $|\\text{hspec}^{\\mathcal{S}}(G)| < \\infty$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16417v1",
    "published": "2025-05-22T09:05:13+00:00",
    "categories": [
      "math.GR"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16416v1",
    "title": "Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models",
    "authors": [
      "Chengcheng Wang",
      "Jianyuan Guo",
      "Hongguang Li",
      "Yuchuan Tian",
      "Ying Nie",
      "Chang Xu",
      "Kai Han"
    ],
    "abstract": "Rotary Position Embedding (RoPE) is a widely adopted technique for encoding\nrelative positional information in large language models (LLMs). However, when\nextended to large vision-language models (LVLMs), its variants introduce\nunintended cross-modal positional biases. Specifically, they enforce relative\npositional dependencies between text token indices and image tokens, causing\nspurious alignments. This issue arises because image tokens representing the\nsame content but located at different spatial positions are assigned distinct\npositional biases, leading to inconsistent cross-modal associations. To address\nthis, we propose Per-Token Distance (PTD) - a simple yet effective metric for\nquantifying the independence of positional encodings across modalities.\nInformed by this analysis, we introduce Circle-RoPE, a novel encoding scheme\nthat maps image token indices onto a circular trajectory orthogonal to the\nlinear path of text token indices, forming a cone-like structure. This\nconfiguration ensures that each text token maintains an equal distance to all\nimage tokens, reducing artificial cross-modal biases while preserving\nintra-image spatial information. To further enhance performance, we propose a\nstaggered layer strategy that applies different RoPE variants across layers.\nThis design leverages the complementary strengths of each RoPE variant, thereby\nenhancing the model's overall performance. Our experimental results demonstrate\nthat our method effectively preserves spatial information from images while\nreducing relative positional bias, offering a more robust and flexible\npositional encoding framework for LVLMs. The code is available at\n[https://github.com/lose4578/CircleRoPE](https://github.com/lose4578/CircleRoPE).",
    "pdf_url": "http://arxiv.org/pdf/2505.16416v1",
    "published": "2025-05-22T09:05:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16415v2",
    "title": "Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation",
    "authors": [
      "Ruizhe Li",
      "Chen Chen",
      "Yuchen Hu",
      "Yanjun Gao",
      "Xi Wang",
      "Emine Yilmaz"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) leverages large language models (LLMs)\ncombined with external contexts to enhance the accuracy and reliability of\ngenerated responses. However, reliably attributing generated content to\nspecific context segments, context attribution, remains challenging due to the\ncomputationally intensive nature of current methods, which often require\nextensive fine-tuning or human annotation. In this work, we introduce a novel\nJensen-Shannon Divergence driven method to Attribute Response to Context\n(ARC-JSD), enabling efficient and accurate identification of essential context\nsentences without additional fine-tuning or surrogate modelling. Evaluations on\na wide range of RAG benchmarks, such as TyDi QA, Hotpot QA, and Musique, using\ninstruction-tuned LLMs in different scales demonstrate superior accuracy and\nsignificant computational efficiency improvements compared to the previous\nsurrogate-based method. Furthermore, our mechanistic analysis reveals specific\nattention heads and multilayer perceptron (MLP) layers responsible for context\nattribution, providing valuable insights into the internal workings of RAG\nmodels. Our code is available at https://github.com/ruizheliUOA/ARC_JSD",
    "pdf_url": "http://arxiv.org/pdf/2505.16415v2",
    "published": "2025-05-22T09:04:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17149v1",
    "title": "Large Language Models for Predictive Analysis: How Far Are They?",
    "authors": [
      "Qin Chen",
      "Yuanyi Ren",
      "Xiaojun Ma",
      "Yuyang Shi"
    ],
    "abstract": "Predictive analysis is a cornerstone of modern decision-making, with\napplications in various domains. Large Language Models (LLMs) have emerged as\npowerful tools in enabling nuanced, knowledge-intensive conversations, thus\naiding in complex decision-making tasks. With the burgeoning expectation to\nharness LLMs for predictive analysis, there is an urgent need to systematically\nassess their capability in this domain. However, there is a lack of relevant\nevaluations in existing studies. To bridge this gap, we introduce the\n\\textbf{PredictiQ} benchmark, which integrates 1130 sophisticated predictive\nanalysis queries originating from 44 real-world datasets of 8 diverse fields.\nWe design an evaluation protocol considering text analysis, code generation,\nand their alignment. Twelve renowned LLMs are evaluated, offering insights into\ntheir practical use in predictive analysis. Generally, we believe that existing\nLLMs still face considerable challenges in conducting predictive analysis. See\n\\href{https://github.com/Cqkkkkkk/PredictiQ}{Github}.",
    "pdf_url": "http://arxiv.org/pdf/2505.17149v1",
    "published": "2025-05-22T09:02:15+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16414v1",
    "title": "Critical mean field equations for equilibrium turbulence with sign-changing prescribed functions",
    "authors": [
      "Linlin Sun",
      "Xiaobao Zhu"
    ],
    "abstract": "Let $(M,g)$ be a compact Riemann surface with unit area. We investigate the\nmean field equation for equilibrium turbulence: \\begin{align} \\begin{cases}\n-\\Delta u = \\rho_1\\left(\\frac{h_1e^{u}}{\\int_Mh_1e^udv_g}-1\\right) -\n\\rho_2\\left(\\frac{h_2e^{-u}}{\\int_Mh_2e^{-u}dv_g}-1\\right), \\\\ \\int_Mudv_g=0,\n\\end{cases} \\end{align} where $\\rho_1=8\\pi$ and $\\rho_2\\in(0,8\\pi]$ are\nparameters, and $h_1, h_2$ are smooth functions on $M$ that are positive\nsomewhere. By employing a refined Brezis-Merle type analysis, we establish\nsufficient conditions of Ding-Jost-Li-Wang type for the existence of solutions\nto this equation in critical cases, particularly when $h_1$ and $h_2$ may\nchange signs. Our results extend Zhou's existence theorems (Nonlinear Anal. 69\n(2008), no.~8, 2541--2552) for the case $h_1=h_2\\equiv 1$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16414v1",
    "published": "2025-05-22T09:01:51+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16413v1",
    "title": "TAPAS: A Pattern-Based Approach to Assessing Government Transparency",
    "authors": [
      "Jos Zuijderwijk",
      "Iris Beerepoot",
      "Thomas Martens",
      "Eva Knies",
      "Tanja van der Lippe",
      "Hajo A. Reijers"
    ],
    "abstract": "Government transparency, widely recognized as a cornerstone of open\ngovernment, depends on robust information management practices. Yet effective\nassessment of information management remains challenging, as existing methods\nfail to consider the actual working behavior of civil servants and are\nresource-intensive. Using a design science research approach, we present the\nTransparency Anti-Pattern Assessment System (TAPAS) -- a novel, data-driven\nmethodology designed to evaluate government transparency through the\nidentification of behavioral patterns that impede transparency. We demonstrate\nTAPAS's real-world applicability at a Dutch ministry, analyzing their\nelectronic document management system data from the past two decades. We\nidentify eight transparency anti-patterns grouped into four categories:\nIncomplete Documentation, Limited Accessibility, Unclear Information, and\nDelayed Documentation. We show that TAPAS enables continuous monitoring and\nprovides actionable insights without requiring significant resource\ninvestments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16413v1",
    "published": "2025-05-22T09:01:42+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16412v1",
    "title": "Pose-invariant face recognition via feature-space pose frontalization",
    "authors": [
      "Nikolay Stanishev",
      "Yuhang Lu",
      "Touradj Ebrahimi"
    ],
    "abstract": "Pose-invariant face recognition has become a challenging problem for modern\nAI-based face recognition systems. It aims at matching a profile face captured\nin the wild with a frontal face registered in a database. Existing methods\nperform face frontalization via either generative models or learning a pose\nrobust feature representation. In this paper, a new method is presented to\nperform face frontalization and recognition within the feature space. First, a\nnovel feature space pose frontalization module (FSPFM) is proposed to transform\nprofile images with arbitrary angles into frontal counterparts. Second, a new\ntraining paradigm is proposed to maximize the potential of FSPFM and boost its\nperformance. The latter consists of a pre-training and an attention-guided\nfine-tuning stage. Moreover, extensive experiments have been conducted on five\npopular face recognition benchmarks. Results show that not only our method\noutperforms the state-of-the-art in the pose-invariant face recognition task\nbut also maintains superior performance in other standard scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16412v1",
    "published": "2025-05-22T09:01:01+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16411v1",
    "title": "Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression",
    "authors": [
      "Sreetama Sarkar",
      "Yue Che",
      "Alex Gavin",
      "Peter A. Beerel",
      "Souvik Kundu"
    ],
    "abstract": "Despite their remarkable progress in multimodal understanding tasks, large\nvision language models (LVLMs) often suffer from \"hallucinations\", generating\ntexts misaligned with the visual context. Existing methods aimed at reducing\nhallucinations through inference time intervention incur a significant increase\nin latency. To mitigate this, we present SPIN, a task-agnostic attention-guided\nhead suppression strategy that can be seamlessly integrated during inference,\nwithout incurring any significant compute or latency overhead. We investigate\nwhether hallucination in LVLMs can be linked to specific model components. Our\nanalysis suggests that hallucinations can be attributed to a dynamic subset of\nattention heads in each layer. Leveraging this insight, for each text query\ntoken, we selectively suppress attention heads that exhibit low attention to\nimage tokens, keeping the top-K attention heads intact. Extensive evaluations\non visual question answering and image description tasks demonstrate the\nefficacy of SPIN in reducing hallucination scores up to 2.7x while maintaining\nF1, and improving throughput by 1.8x compared to existing alternatives. Code is\navailable at https://github.com/YUECHE77/SPIN.",
    "pdf_url": "http://arxiv.org/pdf/2505.16411v1",
    "published": "2025-05-22T09:00:57+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16410v1",
    "title": "Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning",
    "authors": [
      "Guanting Dong",
      "Yifei Chen",
      "Xiaoxi Li",
      "Jiajie Jin",
      "Hongjin Qian",
      "Yutao Zhu",
      "Hangyu Mao",
      "Guorui Zhou",
      "Zhicheng Dou",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, large language models (LLMs) have shown remarkable reasoning\ncapabilities via large-scale reinforcement learning (RL). However, leveraging\nthe RL algorithm to empower effective multi-tool collaborative reasoning in\nLLMs remains an open challenge. In this paper, we introduce Tool-Star, an\nRL-based framework designed to empower LLMs to autonomously invoke multiple\nexternal tools during stepwise reasoning. Tool-Star integrates six types of\ntools and incorporates systematic designs in both data synthesis and training.\nTo address the scarcity of tool-use data, we propose a general tool-integrated\nreasoning data synthesis pipeline, which combines tool-integrated prompting\nwith hint-based sampling to automatically and scalably generate tool-use\ntrajectories. A subsequent quality normalization and difficulty-aware\nclassification process filters out low-quality samples and organizes the\ndataset from easy to hard. Furthermore, we propose a two-stage training\nframework to enhance multi-tool collaborative reasoning by: (1) cold-start\nfine-tuning, which guides LLMs to explore reasoning patterns via\ntool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with\nhierarchical reward design, which reinforces reward understanding and promotes\neffective tool collaboration. Experimental analyses on over 10 challenging\nreasoning benchmarks highlight the effectiveness and efficiency of Tool-Star.\nThe code is available at https://github.com/dongguanting/Tool-Star.",
    "pdf_url": "http://arxiv.org/pdf/2505.16410v1",
    "published": "2025-05-22T09:00:19+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16409v1",
    "title": "FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS",
    "authors": [
      "Chaeeun Kim",
      "Seungone Kim"
    ],
    "abstract": "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in\nmulti-step reasoning and calling search engines at appropriate steps. However,\nexisting retrieval-augmented reasoning approaches rely on separate retrieval\nmodels, limiting the LRM's role in retrieval to deciding when to retrieve and\nhow to query. This separation not only increases hardware and operational costs\nbut also leads to errors in the retrieval process due to the representation\nbottleneck, a phenomenon where the retriever's embedding space is not\nexpressive enough to meet the generator's requirements. To address this, we\nshift our perspective from sequence-to-sequence matching to locating the\nanswer-containing paths within the corpus, and propose a novel framework called\nFREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables\nLRMs to retrieve relevant knowledge on their own by acting as both a generator\nand retriever. To achieve this, we introduce a variant of the MCTS algorithm\nspecialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing\nMonte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus\ntoward answer-containing regions. Our results on five open-domain QA\nbenchmarks, including single-hop and multi-hop questions, show that FREESON\nachieves an average improvement of 14.4% in EM and F1 over four multi-step\nreasoning models with a separate retriever, and it also performs comparably to\nthe strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.",
    "pdf_url": "http://arxiv.org/pdf/2505.16409v1",
    "published": "2025-05-22T09:00:08+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16408v1",
    "title": "From Surveys to Narratives: Rethinking Cultural Value Adaptation in LLMs",
    "authors": [
      "Muhammad Farid Adilazuarda",
      "Chen Cecilia Liu",
      "Iryna Gurevych",
      "Alham Fikri Aji"
    ],
    "abstract": "Adapting cultural values in Large Language Models (LLMs) presents significant\nchallenges, particularly due to biases and limited training data. Prior work\nprimarily aligns LLMs with different cultural values using World Values Survey\n(WVS) data. However, it remains unclear whether this approach effectively\ncaptures cultural nuances or produces distinct cultural representations for\nvarious downstream tasks. In this paper, we systematically investigate\nWVS-based training for cultural value adaptation and find that relying solely\non survey data can homogenize cultural norms and interfere with factual\nknowledge. To investigate these issues, we augment WVS with encyclopedic and\nscenario-based cultural narratives from Wikipedia and NormAd. While these\nnarratives may have variable effects on downstream tasks, they consistently\nimprove cultural distinctiveness than survey data alone. Our work highlights\nthe inherent complexity of aligning cultural values with the goal of guiding\ntask-specific behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.16408v1",
    "published": "2025-05-22T09:00:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16407v2",
    "title": "Robust Longitudinal-lateral Look-ahead Pursuit Path-Following Control: Fast Finite-Time Stability Guarantee",
    "authors": [
      "Zimao Sheng",
      "Hong'an Yang",
      "Shuxiang Yang",
      "Zirui Yu"
    ],
    "abstract": "This paper addresses the challenging problem of robust path-following for\nfixed-wing unmanned aerial vehicles (UAVs) in complex environments with bounded\nexternal disturbances and non-smooth predefined paths. Due to the unique\naerodynamic characteristics and flight constraints of fixed-wing UAVs,\nachieving accurate and fast stable path following remains difficult, especially\nin low-altitude mountainous terrains, urban landscapes, and under wind\ndisturbances. Most existing path-following guidance laws often struggle to\nensure fast stabilization under unknown bounded disturbances while maintaining\nsufficient robustness, and there is a lack of research on optimizing robustness\nfor non-smooth paths under flight constraints. This paper addresses these\nissues by proposing a constraints-based robust path-following controller.\nFirstly, from the perspective of global random attractor, we innovatively\nintroduce robustness metrics that quantify both the exponential convergence\nrate and the range of the ultimate attractor set. Secondly, building on these\nmetrics, we develop a robust longitudinal-lateral look-ahead pursuit (RLLP)\nguidance law for fixed-wing UAVs, specifically considering the flight path\nangle and track angle under external disturbances. Thirdly, we also derive an\noptimized version (Optimal-RLLP) to enhance the robustness metrics, and\nelaborate on the sufficient conditions for fast finite-time stability, ensuring\nthe guidance law achieves finite-time stability and robustness with reduced\nsensitivity to constrained uncertainties. The simulation results validate the\nproposed guidance law's feasibility, optimality and robustness under\natmospheric disturbances using a high-fidelity simulation platform and provide\nkey principle for practical deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16407v2",
    "published": "2025-05-22T08:59:39+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16406v1",
    "title": "On the reliability of feature attribution methods for speech classification",
    "authors": [
      "Gaofei Shen",
      "Hosein Mohebbi",
      "Arianna Bisazza",
      "Afra Alishahi",
      "Grzegorz Chrupała"
    ],
    "abstract": "As the capabilities of large-scale pre-trained models evolve, understanding\nthe determinants of their outputs becomes more important. Feature attribution\naims to reveal which parts of the input elements contribute the most to model\noutputs. In speech processing, the unique characteristics of the input signal\nmake the application of feature attribution methods challenging. We study how\nfactors such as input type and aggregation and perturbation timespan impact the\nreliability of standard feature attribution methods, and how these factors\ninteract with characteristics of each classification task. We find that\nstandard approaches to feature attribution are generally unreliable when\napplied to the speech domain, with the exception of word-aligned perturbation\nmethods when applied to word-based classification tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16406v1",
    "published": "2025-05-22T08:59:25+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16405v2",
    "title": "Microcanonical cascades and random homeomorphisms",
    "authors": [
      "Xinxin Chen",
      "Yong Han",
      "Yanqi Qiu",
      "Zipeng Wang"
    ],
    "abstract": "We give a complete solution to the Mandelbrot-Kahane problem for the\nmicrocanonical cascade measures by determing their exact Fourier dimensions. We\nalso discuss the Frostman regularity as well as the bi-H\\\"older continuity of\nthe Dubins-Freedman random homeomorphisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.16405v2",
    "published": "2025-05-22T08:57:48+00:00",
    "categories": [
      "math.PR",
      "math.FA"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16404v1",
    "title": "UBGAN: Enhancing Coded Speech with Blind and Guided Bandwidth Extension",
    "authors": [
      "Kishan Gupta",
      "Srikanth Korse",
      "Andreas Brendel",
      "Nicola Pia",
      "Guillaume Fuchs"
    ],
    "abstract": "In practical application of speech codecs, a multitude of factors such as the\nquality of the radio connection, limiting hardware or required user experience\nnecessitate trade-offs between achievable perceptual quality, engendered\nbitrate and computational complexity. Most conventional and neural speech\ncodecs operate on wideband (WB) speech signals to achieve this compromise. To\nfurther enhance the perceptual quality of coded speech, bandwidth extension\n(BWE) of the transmitted speech is an attractive and popular technique in\nconventional speech coding. In contrast, neural speech codecs are typically\ntrained end-to-end to a specific set of requirements and are often not easily\nadaptable. In particular, they are typically trained to operate at a single\nfixed sampling rate. With the Universal Bandwidth Extension Generative\nAdversarial Network (UBGAN), we propose a modular and lightweight GAN-based\nsolution that increases the operational flexibility of a wide range of\nconventional and neural codecs. Our model operates in the subband domain and\nextends the bandwidth of WB signals from 8 kHz to 16 kHz, resulting in\nsuper-wideband (SWB) signals. We further introduce two variants, guided-UBGAN\nand blind-UBGAN, where the guided version transmits quantized learned\nrepresentation as a side information at a very low bitrate additional to the\nbitrate of the codec, while blind-BWE operates without such side-information.\nOur subjective assessments demonstrate the advantage of UBGAN applied to WB\ncodecs and highlight the generalization capacity of our proposed method across\nmultiple codecs and bitrates.",
    "pdf_url": "http://arxiv.org/pdf/2505.16404v1",
    "published": "2025-05-22T08:56:35+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16403v2",
    "title": "Performance Guaranteed Poisoning Attacks in Federated Learning: A Sliding Mode Approach",
    "authors": [
      "Huazi Pan",
      "Yanjun Zhang",
      "Leo Yu Zhang",
      "Scott Adams",
      "Abbas Kouzani",
      "Suiyang Khoo"
    ],
    "abstract": "Manipulation of local training data and local updates, i.e., the poisoning\nattack, is the main threat arising from the collaborative nature of the\nfederated learning (FL) paradigm. Most existing poisoning attacks aim to\nmanipulate local data/models in a way that causes denial-of-service (DoS)\nissues. In this paper, we introduce a novel attack method, named Federated\nLearning Sliding Attack (FedSA) scheme, aiming at precisely introducing the\nextent of poisoning in a subtle controlled manner. It operates with a\npredefined objective, such as reducing global model's prediction accuracy by\n10%. FedSA integrates robust nonlinear control-Sliding Mode Control (SMC)\ntheory with model poisoning attacks. It can manipulate the updates from\nmalicious clients to drive the global model towards a compromised state,\nachieving this at a controlled and inconspicuous rate. Additionally, leveraging\nthe robust control properties of FedSA allows precise control over the\nconvergence bounds, enabling the attacker to set the global accuracy of the\npoisoned model to any desired level. Experimental results demonstrate that\nFedSA can accurately achieve a predefined global accuracy with fewer malicious\nclients while maintaining a high level of stealth and adjustable learning\nrates.",
    "pdf_url": "http://arxiv.org/pdf/2505.16403v2",
    "published": "2025-05-22T08:54:17+00:00",
    "categories": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16402v2",
    "title": "AdvReal: Physical Adversarial Patch Generation Framework for Security Evaluation of Object Detection Systems",
    "authors": [
      "Yuanhao Huang",
      "Yilong Ren",
      "Jinlei Wang",
      "Lujia Huo",
      "Xuesong Bai",
      "Jinchuan Zhang",
      "Haiyan Yu"
    ],
    "abstract": "Autonomous vehicles are typical complex intelligent systems with artificial\nintelligence at their core. However, perception methods based on deep learning\nare extremely vulnerable to adversarial samples, resulting in security\naccidents. How to generate effective adversarial examples in the physical world\nand evaluate object detection systems is a huge challenge. In this study, we\npropose a unified joint adversarial training framework for both 2D and 3D\ndomains, which simultaneously optimizes texture maps in 2D image and 3D mesh\nspaces to better address intra-class diversity and real-world environmental\nvariations. The framework includes a novel realistic enhanced adversarial\nmodule, with time-space and relighting mapping pipeline that adjusts\nillumination consistency between adversarial patches and target garments under\nvaried viewpoints. Building upon this, we develop a realism enhancement\nmechanism that incorporates non-rigid deformation modeling and texture\nremapping to ensure alignment with the human body's non-rigid surfaces in 3D\nscenes. Extensive experiment results in digital and physical environments\ndemonstrate that the adversarial textures generated by our method can\neffectively mislead the target detection model. Specifically, our method\nachieves an average attack success rate (ASR) of 70.13% on YOLOv12 in physical\nscenarios, significantly outperforming existing methods such as T-SEA (21.65%)\nand AdvTexture (19.70%). Moreover, the proposed method maintains stable ASR\nacross multiple viewpoints and distances, with an average attack success rate\nexceeding 90% under both frontal and oblique views at a distance of 4 meters.\nThis confirms the method's strong robustness and transferability under\nmulti-angle attacks, varying lighting conditions, and real-world distances. The\ndemo video and code can be obtained at\nhttps://github.com/Huangyh98/AdvReal.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.16402v2",
    "published": "2025-05-22T08:54:03+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16401v4",
    "title": "Divide-Fuse-Conquer: Eliciting \"Aha Moments\" in Multi-Scenario Games",
    "authors": [
      "Xiaoqing Zhang",
      "Huabin Zheng",
      "Ang Lv",
      "Yuhan Liu",
      "Zirui Song",
      "Xiuying Chen",
      "Rui Yan",
      "Flood Sung"
    ],
    "abstract": "Large language models (LLMs) have been observed to suddenly exhibit advanced\nreasoning abilities during reinforcement learning (RL), resembling an ``aha\nmoment'' triggered by simple outcome-based rewards. While RL has proven\neffective in eliciting such breakthroughs in tasks involving mathematics,\ncoding, and vision, it faces significant challenges in multi-scenario games.\nThe diversity of game rules, interaction modes, and environmental complexities\noften leads to policies that perform well in one scenario but fail to\ngeneralize to others. Simply combining multiple scenarios during training\nintroduces additional challenges, such as training instability and poor\nperformance. To overcome these challenges, we propose Divide-Fuse-Conquer, a\nframework designed to enhance generalization in multi-scenario RL. This\napproach starts by heuristically grouping games based on characteristics such\nas rules and difficulties. Specialized models are then trained for each group\nto excel at games in the group is what we refer to as the divide step. Next, we\nfuse model parameters from different groups as a new model, and continue\ntraining it for multiple groups, until the scenarios in all groups are\nconquered. Experiments across 18 TextArena games show that Qwen2.5-32B-Align\ntrained with the Divide-Fuse-Conquer strategy reaches a performance level\ncomparable to Claude3.5, achieving 7 wins and 4 draws. We hope our approach can\ninspire future research on using reinforcement learning to improve the\ngeneralization of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16401v4",
    "published": "2025-05-22T08:52:21+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16400v3",
    "title": "AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning",
    "authors": [
      "Yang Chen",
      "Zhuolin Yang",
      "Zihan Liu",
      "Chankyu Lee",
      "Peng Xu",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Wei Ping"
    ],
    "abstract": "Despite recent progress in large-scale reinforcement learning (RL) for\nreasoning, the training recipe for building high-performing reasoning models\nremains elusive. Key implementation details of frontier models, such as\nDeepSeek-R1, including data curation strategies and RL training recipe, are\noften omitted. Moreover, recent research indicates distillation remains more\neffective than RL for smaller models. In this work, we demonstrate that\nlarge-scale RL can significantly enhance the reasoning capabilities of strong,\nsmall- and mid-sized models, achieving results that surpass those of\nstate-of-the-art distillation-based models. We systematically study the RL\ntraining process through extensive ablations and propose a simple yet effective\napproach: first training on math-only prompts, then on code-only prompts.\nNotably, we find that math-only RL not only significantly enhances the\nperformance of strong distilled models on math benchmarks (e.g., +14.6% /\n+17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks\n(e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition,\nextended code-only RL iterations further improve performance on code benchmarks\nwith minimal or no degradation in math results. We develop a robust data\ncuration pipeline to collect challenging prompts with high-quality, verifiable\nanswers and test cases to enable verification-based RL across both domains.\nFinally, we identify key experimental insights, including curriculum learning\nwith progressively increasing response lengths and the stabilizing effect of\non-policy parameter updates. We find that RL not only elicits the foundational\nreasoning capabilities acquired during pretraining and supervised fine-tuning\n(e.g., distillation), but also pushes the limits of the model's reasoning\nability, enabling it to solve problems that were previously unsolvable.",
    "pdf_url": "http://arxiv.org/pdf/2505.16400v3",
    "published": "2025-05-22T08:50:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16399v1",
    "title": "Sketchy Bounding-box Supervision for 3D Instance Segmentation",
    "authors": [
      "Qian Deng",
      "Le Hui",
      "Jin Xie",
      "Jian Yang"
    ],
    "abstract": "Bounding box supervision has gained considerable attention in weakly\nsupervised 3D instance segmentation. While this approach alleviates the need\nfor extensive point-level annotations, obtaining accurate bounding boxes in\npractical applications remains challenging. To this end, we explore the\ninaccurate bounding box, named sketchy bounding box, which is imitated through\nperturbing ground truth bounding box by adding scaling, translation, and\nrotation. In this paper, we propose Sketchy-3DIS, a novel weakly 3D instance\nsegmentation framework, which jointly learns pseudo labeler and segmentator to\nimprove the performance under the sketchy bounding-box supervisions.\nSpecifically, we first propose an adaptive box-to-point pseudo labeler that\nadaptively learns to assign points located in the overlapped parts between two\nsketchy bounding boxes to the correct instance, resulting in compact and pure\npseudo instance labels. Then, we present a coarse-to-fine instance segmentator\nthat first predicts coarse instances from the entire point cloud and then\nlearns fine instances based on the region of coarse instances. Finally, by\nusing the pseudo instance labels to supervise the instance segmentator, we can\ngradually generate high-quality instances through joint training. Extensive\nexperiments show that our method achieves state-of-the-art performance on both\nthe ScanNetV2 and S3DIS benchmarks, and even outperforms several fully\nsupervised methods using sketchy bounding boxes. Code is available at\nhttps://github.com/dengq7/Sketchy-3DIS.",
    "pdf_url": "http://arxiv.org/pdf/2505.16399v1",
    "published": "2025-05-22T08:49:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16398v1",
    "title": "Consistent and Compatible Modelling of Cyber Intrusions and Incident Response Demonstrated in the Context of Malware Attacks on Critical Infrastructure",
    "authors": [
      "Peter Maynard",
      "Yulia Cherdantseva",
      "Avi Shaked",
      "Pete Burnap",
      "Arif Mehmood"
    ],
    "abstract": "Cyber Security Incident Response (IR) Playbooks are used to capture the steps\nrequired to recover from a cyber intrusion. Individual IR playbooks should\nfocus on a specific type of incident and be aligned with the architecture of a\nsystem under attack. Intrusion modelling focuses on a specific potential cyber\nintrusion and is used to identify where and what countermeasures are needed,\nand the resulting intrusion models are expected to be used in effective IR,\nideally by feeding IR Playbooks designs. IR playbooks and intrusion models,\nhowever, are created in isolation and at varying stages of the system's\nlifecycle. We take nine critical national infrastructure intrusion models -\nexpressed using Sequential AND Attack Trees - and transform them into models of\nthe same format as IR playbooks. We use Security Modelling Framework for\nmodelling attacks and playbooks, and for demonstrating the feasibility of the\nbetter integration between risk assessment and IR at the modelling level. This\nresults in improved intrusion models and tighter coupling between IR playbooks\nand threat modelling which - as we demonstrate - yields novel insights into the\nanalysis of attacks and response actions. The main contributions of this paper\nare (a) a novel way of representing attack trees using the Security Modelling\nFramework,(b) a new tool for converting Sequential AND attack trees into models\ncompatible with playbooks, and (c) the examples of nine intrusion models\nrepresented using the Security Modelling Framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.16398v1",
    "published": "2025-05-22T08:49:35+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16397v1",
    "title": "Dynamic Caustics by Ultrasonically Modulated Liquid Surface",
    "authors": [
      "Koki Nagakura",
      "Tatsuki Fushimi",
      "Ayaka Tsutsui",
      "Yoichi Ochiai"
    ],
    "abstract": "This paper presents a method for generating dynamic caustic patterns by\nutilising dual-optimised holographic fields with Phased Array Transducer (PAT).\nBuilding on previous research in static caustic optimisation and ultrasonic\nmanipulation, this approach employs computational techniques to dynamically\nshape fluid surfaces, thereby creating controllable and real-time caustic\nimages. The system employs a Digital Twin framework, which enables iterative\nfeedback and refinement, thereby improving the accuracy and quality of the\ncaustic patterns produced. This paper extends the foundational work in caustic\ngeneration by integrating liquid surfaces as refractive media. This concept has\npreviously been explored in simulations but not fully realised in practical\napplications. The utilisation of ultrasound to directly manipulate these\nsurfaces enables the generation of dynamic caustics with a high degree of\nflexibility. The Digital Twin approach further enhances this process by\nallowing for precise adjustments and optimisation based on real-time feedback.\nExperimental results demonstrate the technique's capacity to generate\ncontinuous animations and complex caustic patterns at high frequencies.\nAlthough there are limitations in contrast and resolution compared to\nsolid-surface methods, this approach offers advantages in terms of real-time\nadaptability and scalability. This technique has the potential to be applied in\na number of areas, including interactive displays, artistic installations and\neducational tools. This research builds upon the work of previous researchers\nin the fields of caustics optimisation, ultrasonic manipulation, and\ncomputational displays. Future research will concentrate on enhancing the\nresolution and intricacy of the generated patterns.",
    "pdf_url": "http://arxiv.org/pdf/2505.16397v1",
    "published": "2025-05-22T08:49:14+00:00",
    "categories": [
      "cs.GR",
      "cs.HC"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16396v1",
    "title": "Trajectory-Independent Flexibility Envelopes of Energy-Constrained Systems with State-Dependent Losses",
    "authors": [
      "Julie Rousseau",
      "Carlo Tajoli",
      "Hanmin Cai",
      "Philipp Heer",
      "Kristina Orehounig",
      "Gabriela Hug"
    ],
    "abstract": "As non-dispatchable renewable power units become prominent in electric power\ngrids, demand-side flexibility appears as a key element of future power\nsystems' operation. Power and energy bounds are intuitive metrics to describe\nthe flexibility of energy-constrained loads. However, to be used in operation,\nany power consumption trajectory fulfilling the power and energy bounds must\nnecessarily fulfill the load's constraints. In this paper, we demonstrate that\nenergy bounds defined as the minimum and maximum energy consumption potential\nof a load with state-dependent losses are Trajectory-Dependent (TD), i.e., for\nany energy value in the bounds a feasible power trajectory exists, but not all\npower trajectories enclosed in the energy envelopes satisfy the load's\nconstraints. To guarantee the satisfaction of load constraints for all\ntrajectories, we define Trajectory-Independent (TI) energy bounds. We present\nTI envelope formulations for individual loads, as well as physically coupled\nloads and assess the proposed formulations in a building heating system, a\nsystem with state-dependent losses. We find that using a TD envelope as energy\nbounds in operation may yield room temperature up to 3.8{\\deg}C higher and\n3.4{\\deg}C lower than admissible. Overall, poorly insulated buildings observe a\nTI energy envelope that differs significantly from their TD envelope.",
    "pdf_url": "http://arxiv.org/pdf/2505.16396v1",
    "published": "2025-05-22T08:49:06+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16395v1",
    "title": "Magnonic entanglement in a chiral cavity-magnon coupling system",
    "authors": [
      "Yuxin Kang",
      "Xin Zeng",
      "Wuji Zhang",
      "Chunfang Sun",
      "Chunfeng Wu",
      "Gangcheng Wang"
    ],
    "abstract": "The generation of magnon entanglement and squeezing plays a crucial role in\nquantum information processing. In this study, we propose a scheme based on a\nchiral cavity-magnon system, which consists of a torus-shaped cavity and two\nyttrium iron garnet spheres. The magnon mode of each yttrium iron garnet sphere\nis selectively coupled to one of the two degenerate rotating microwave modes of\nthe toroidal cavity. The system aims to achieve entangled and squeezed magnon\nstates through the mediation of the cavity. We further show that bipartite\nentanglement can be achieved by tuning external driving parameters.\nAdditionally, our scheme does not rely on the magnon Kerr nonlinearity, which\nis usually extremely weak in yttrium iron garnet spheres. This work provides\ninsights and methods for the research of quantum states in cavity-magnon\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16395v1",
    "published": "2025-05-22T08:47:56+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16394v1",
    "title": "Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)",
    "authors": [
      "Zhenjie Yang",
      "Xiaosong Jia",
      "Qifeng Li",
      "Xue Yang",
      "Maoqing Yao",
      "Junchi Yan"
    ],
    "abstract": "Reinforcement Learning (RL) can mitigate the causal confusion and\ndistribution shift inherent to imitation learning (IL). However, applying RL to\nend-to-end autonomous driving (E2E-AD) remains an open problem for its training\ndifficulty, and IL is still the mainstream paradigm in both academia and\nindustry. Recently Model-based Reinforcement Learning (MBRL) have demonstrated\npromising results in neural planning; however, these methods typically require\nprivileged information as input rather than raw sensor data. We fill this gap\nby designing Raw2Drive, a dual-stream MBRL approach. Initially, we efficiently\ntrain an auxiliary privileged world model paired with a neural planner that\nuses privileged information as input. Subsequently, we introduce a raw sensor\nworld model trained via our proposed Guidance Mechanism, which ensures\nconsistency between the raw sensor world model and the privileged world model\nduring rollouts. Finally, the raw sensor world model combines the prior\nknowledge embedded in the heads of the privileged world model to effectively\nguide the training of the raw sensor policy. Raw2Drive is so far the only RL\nbased end-to-end method on CARLA Leaderboard 2.0, and Bench2Drive and it\nachieves state-of-the-art performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.16394v1",
    "published": "2025-05-22T08:46:53+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17148v1",
    "title": "LLM-Powered Agents for Navigating Venice's Historical Cadastre",
    "authors": [
      "Tristan Karch",
      "Jakhongir Saydaliev",
      "Isabella Di Lenardo",
      "Frédéric Kaplan"
    ],
    "abstract": "Cadastral data reveal key information about the historical organization of\ncities but are often non-standardized due to diverse formats and human\nannotations, complicating large-scale analysis. We explore as a case study\nVenice's urban history during the critical period from 1740 to 1808, capturing\nthe transition following the fall of the ancient Republic and the Ancien\nR\\'egime. This era's complex cadastral data, marked by its volume and lack of\nuniform structure, presents unique challenges that our approach adeptly\nnavigates, enabling us to generate spatial queries that bridge past and present\nurban landscapes. We present a text-to-programs framework that leverages Large\nLanguage Models (LLMs) to translate natural language queries into executable\ncode for processing historical cadastral records. Our methodology implements\ntwo complementary techniques: a text-to-SQL approach for handling structured\nqueries about specific cadastral information, and a text-to-Python approach for\ncomplex analytical operations requiring custom data manipulation. We propose a\ntaxonomy that classifies historical research questions based on their\ncomplexity and analytical requirements, mapping them to the most appropriate\ntechnical approach. This framework is supported by an investigation into the\nexecution consistency of the system, alongside a qualitative analysis of the\nanswers it produces. By ensuring interpretability and minimizing hallucination\nthrough verifiable program outputs, we demonstrate the system's effectiveness\nin reconstructing past population information, property features, and\nspatiotemporal comparisons in Venice.",
    "pdf_url": "http://arxiv.org/pdf/2505.17148v1",
    "published": "2025-05-22T08:45:15+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16392v1",
    "title": "Resource for Error Analysis in Text Simplification: New Taxonomy and Test Collection",
    "authors": [
      "Benjamin Vendeville",
      "Liana Ermakova",
      "Pierre De Loor"
    ],
    "abstract": "The general public often encounters complex texts but does not have the time\nor expertise to fully understand them, leading to the spread of misinformation.\nAutomatic Text Simplification (ATS) helps make information more accessible, but\nits evaluation methods have not kept up with advances in text generation,\nespecially with Large Language Models (LLMs). In particular, recent studies\nhave shown that current ATS metrics do not correlate with the presence of\nerrors. Manual inspections have further revealed a variety of errors,\nunderscoring the need for a more nuanced evaluation framework, which is\ncurrently lacking. This resource paper addresses this gap by introducing a test\ncollection for detecting and classifying errors in simplified texts. First, we\npropose a taxonomy of errors, with a formal focus on information distortion.\nNext, we introduce a parallel dataset of automatically simplified scientific\ntexts. This dataset has been human-annotated with labels based on our proposed\ntaxonomy. Finally, we analyze the quality of the dataset, and we study the\nperformance of existing models to detect and classify errors from that\ntaxonomy. These contributions give researchers the tools to better evaluate\nerrors in ATS, develop more reliable models, and ultimately improve the quality\nof automatically simplified texts.",
    "pdf_url": "http://arxiv.org/pdf/2505.16392v1",
    "published": "2025-05-22T08:45:14+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.6; I.5.2"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16393v1",
    "title": "Bottom-up Analysis of Ro-Vibrational Helical Dichroism",
    "authors": [
      "Mateja Hrast",
      "Georgios M. Koutentakis",
      "Mikhail Maslov",
      "Mikhail Lemeshko"
    ],
    "abstract": "Helical dichroism (HD) is a proposed method for the resolution of molecular\nchirality, employing the orbital angular momentum (OAM) of light. Going beyond\nthe conventional assumptions about HD, this work proposes a rigid theoretical\nframework for the analysis of the HD, based on molecular symmetries and\nrotational eigenstates. We derive the rotational selection rules, which clearly\nestablish that HD only emerges from the spin-orbit coupling of light, even for\nbeams without far-field OAM. Our findings refine the conditions for observing\nHD, shedding light on the outcome of prior experiments and guiding future\ndesigns for chiral sensing using structured light.",
    "pdf_url": "http://arxiv.org/pdf/2505.16393v1",
    "published": "2025-05-22T08:45:14+00:00",
    "categories": [
      "physics.atom-ph",
      "physics.atm-clus",
      "physics.chem-ph",
      "physics.optics"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16391v1",
    "title": "Quantum-Driven Multihead Inland Waterbody Detection With Transformer-Encoded CYGNSS Delay-Doppler Map Data",
    "authors": [
      "Chia-Hsiang Lin",
      "Jhao-Ting Lin",
      "Po-Ying Chiu",
      "Shih-Ping Chen",
      "Charles C. H. Lin"
    ],
    "abstract": "Inland waterbody detection (IWD) is critical for water resources management\nand agricultural planning. However, the development of high-fidelity IWD\nmapping technology remains unresolved. We aim to propose a practical solution\nbased on the easily accessible data, i.e., the delay-Doppler map (DDM) provided\nby NASA's Cyclone Global Navigation Satellite System (CYGNSS), which\nfacilitates effective estimation of physical parameters on the Earth's surface\nwith high temporal resolution and wide spatial coverage. Specifically, as\nquantum deep network (QUEEN) has revealed its strong proficiency in addressing\nclassification-like tasks, we encode the DDM using a customized transformer,\nfollowed by feeding the transformer-encoded DDM (tDDM) into a highly entangled\nQUEEN to distinguish whether the tDDM corresponds to a hydrological region. In\nrecent literature, QUEEN has achieved outstanding performances in numerous\nchallenging remote sensing tasks (e.g., hyperspectral restoration, change\ndetection, and mixed noise removal, etc.), and its high effectiveness stems\nfrom the fundamentally different way it adopts to extract features (the\nso-called quantum unitary-computing features). The meticulously designed\nIWD-QUEEN retrieves high-precision river textures, such as those in Amazon\nRiver Basin in South America, demonstrating its superiority over traditional\nclassification methods and existing global hydrography maps. IWD-QUEEN,\ntogether with its parallel quantum multihead scheme, works in a near-real-time\nmanner (i.e., millisecond-level computing per DDM). To broaden accessibility\nfor users of traditional computers, we also provide the non-quantum counterpart\nof our method, called IWD-Transformer, thereby increasing the impact of this\nwork.",
    "pdf_url": "http://arxiv.org/pdf/2505.16391v1",
    "published": "2025-05-22T08:44:48+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16390v1",
    "title": "Observational Properties of Thermal Emission from Relativistic Jets Embedded in AGN Disks",
    "authors": [
      "Ken Chen",
      "Zi-Gao Dai"
    ],
    "abstract": "Relativistic jets can be produced within the accretion disk of an active\ngalactic nucleus (AGN), leading to distinct thermal emission as they propagate\nthrough a dense disk environment. In this paper, we present a comprehensive\nstudy of dynamical evolution of jets embedded in an AGN disk and their\nassociated observational properties, focusing on scenarios in which jets either\nsuccessfully break out of the disk or become choked. By modeling the jet-cocoon\nsystem propagation, we calculate the thermal emission contributions from the\njet-head shock breakout, disk cocoon, and jet cocoon components. Our results\nreveal that soft X-ray flares are the most prominent observable signatures,\nwith duration ranging from O(10^2) s to O(10^5) s, occasionally exhibiting\ndouble-peaked light curves, whereas UV/optical flares are detectable only for\npowerful jets, persisting for several days to tens of days. This thermal\nemission serves as a critical electromagnetic counterpart to jet-producing\nevents and provide insights into jet dynamics and AGN disk properties. Our\nfindings highlight the importance of multi-wavelength follow-up observations to\nestablish a diagnostic paradigm for candidate electromagnetic counterpart\nidentification to AGN-embedded events and to distinguish thermal flares from\nAGN background variability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16390v1",
    "published": "2025-05-22T08:43:56+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16389v1",
    "title": "Coverage Path Planning For Multi-view SAR-UAV Observation System Under Energy Constraint",
    "authors": [
      "Deyu Song",
      "Xiangyin Zhang",
      "Zipei Yu",
      "Kaiyu Qin"
    ],
    "abstract": "Multi-view Synthetic Aperture Radar (SAR) imaging can effectively enhance the\nperformance of tasks such as automatic target recognition and image information\nfusion. Unmanned aerial vehicles (UAVs) have the advantages of flexible\ndeployment and cost reduction. A swarm of UAVs equipped with synthetic aperture\nradar imaging equipment is well suited to meet the functional requirements of\nmulti-view synthetic aperture radar imaging missions. However, to provide\noptimal paths for SAR-UAVs from the base station to cover target viewpoints in\nthe mission area is of NP-hard computational complexity. In this work, the\ncoverage path planning problem for multi-view SAR-UAV observation systems is\nstudied. First, the coordinate of observation viewpoints is calculated based on\nthe location of targets and base station under a brief geometric model. Then,\nthe exact problem formulation is modeled in order to fully describe the\nsolution space and search for optimal paths that provide maximum coverage rate\nfor SAR-UAVs. Finally, an Adaptive Density Peak Clustering (ADPC) method is\nproposed to overcome the additional energy consumption due to the viewpoints\nbeing far away from the base station. The Particle Swarm Optimization (PSO)\nalgorithm is introduced for optimal path generation. Experimental results\ndemonstrate the effectiveness and computational efficiency of the proposed\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2505.16389v1",
    "published": "2025-05-22T08:42:33+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16388v1",
    "title": "Serious Games: Human-AI Interaction, Evolution, and Coevolution",
    "authors": [
      "Nandini Doreswamy",
      "Louise Horstmanshof"
    ],
    "abstract": "The serious games between humans and AI have only just begun. Evolutionary\nGame Theory (EGT) models the competitive and cooperative strategies of\nbiological entities. EGT could help predict the potential evolutionary\nequilibrium of humans and AI. The objective of this work was to examine some of\nthe EGT models relevant to human-AI interaction, evolution, and coevolution. Of\nthirteen EGT models considered, three were examined: the Hawk-Dove Game,\nIterated Prisoner's Dilemma, and the War of Attrition. This selection was based\non the widespread acceptance and clear relevance of these models to potential\nhuman-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove\nGame predicts balanced mixed-strategy equilibria based on the costs of\nconflict. It also shows the potential for balanced coevolution rather than\ndominance. Iterated Prisoner's Dilemma suggests that repeated interaction may\nlead to cognitive coevolution. It demonstrates how memory and reciprocity can\nlead to cooperation. The War of Attrition suggests that competition for\nresources may result in strategic coevolution, asymmetric equilibria, and\nconventions on sharing resources. Therefore, EGT may provide a suitable\nframework to understand and predict the human-AI evolutionary dynamic. However,\nfuture research could extend beyond EGT and explore additional frameworks,\nempirical validation methods, and interdisciplinary perspectives. AI is being\nshaped by human input and is evolving in response to it. So too,\nneuroplasticity allows the human brain to grow and evolve in response to\nstimuli. If humans and AI converge in future, what might be the result of human\nneuroplasticity combined with an ever-evolving AI? Future research should be\nmindful of the ethical and cognitive implications of human-AI interaction,\nevolution, and coevolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.16388v1",
    "published": "2025-05-22T08:41:37+00:00",
    "categories": [
      "cs.AI",
      "cs.GT",
      "91A22 (Primary), 68T99 (Secondary)",
      "J.4; I.2.0; K.4.1; J.3; K.4.0"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16387v1",
    "title": "Multi-Channel Sequence-to-Sequence Neural Diarization: Experimental Results for The MISP 2025 Challenge",
    "authors": [
      "Ming Cheng",
      "Fei Su",
      "Cancan Li",
      "Juan Liu",
      "Ming Li"
    ],
    "abstract": "This paper describes the speaker diarization system developed for the\nMultimodal Information-Based Speech Processing (MISP) 2025 Challenge. First, we\nutilize the Sequence-to-Sequence Neural Diarization (S2SND) framework to\ngenerate initial predictions using single-channel audio. Then, we extend the\noriginal S2SND framework to create a new version, Multi-Channel\nSequence-to-Sequence Neural Diarization (MC-S2SND), which refines the initial\nresults using multi-channel audio. The final system achieves a diarization\nerror rate (DER) of 8.09% on the evaluation set of the competition database,\nranking first place in the speaker diarization task of the MISP 2025 Challenge.",
    "pdf_url": "http://arxiv.org/pdf/2505.16387v1",
    "published": "2025-05-22T08:39:48+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16386v1",
    "title": "Omni TM-AE: A Scalable and Interpretable Embedding Model Using the Full Tsetlin Machine State Space",
    "authors": [
      "Ahmed K. Kadhim",
      "Lei Jiao",
      "Rishad Shafik",
      "Ole-Christoffer Granmo"
    ],
    "abstract": "The increasing complexity of large-scale language models has amplified\nconcerns regarding their interpretability and reusability. While traditional\nembedding models like Word2Vec and GloVe offer scalability, they lack\ntransparency and often behave as black boxes. Conversely, interpretable models\nsuch as the Tsetlin Machine (TM) have shown promise in constructing explainable\nlearning systems, though they previously faced limitations in scalability and\nreusability. In this paper, we introduce Omni Tsetlin Machine AutoEncoder (Omni\nTM-AE), a novel embedding model that fully exploits the information contained\nin the TM's state matrix, including literals previously excluded from clause\nformation. This method enables the construction of reusable, interpretable\nembeddings through a single training phase. Extensive experiments across\nsemantic similarity, sentiment classification, and document clustering tasks\nshow that Omni TM-AE performs competitively with and often surpasses mainstream\nembedding models. These results demonstrate that it is possible to balance\nperformance, scalability, and interpretability in modern Natural Language\nProcessing (NLP) systems without resorting to opaque architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16386v1",
    "published": "2025-05-22T08:38:05+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16385v1",
    "title": "Semantic Pivots Enable Cross-Lingual Transfer in Large Language Models",
    "authors": [
      "Kaiyu He",
      "Tong Zhou",
      "Yubo Chen",
      "Delai Qiu",
      "Shengping Liu",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "Large language models (LLMs) demonstrate remarkable ability in cross-lingual\ntasks. Understanding how LLMs acquire this ability is crucial for their\ninterpretability. To quantify the cross-lingual ability of LLMs accurately, we\npropose a Word-Level Cross-Lingual Translation Task. To find how LLMs learn\ncross-lingual ability, we trace the outputs of LLMs' intermediate layers in the\nword translation task. We identify and distinguish two distinct behaviors in\nthe forward pass of LLMs: co-occurrence behavior and semantic pivot behavior.\nWe attribute LLMs' two distinct behaviors to the co-occurrence frequency of\nwords and find the semantic pivot from the pre-training dataset. Finally, to\napply our findings to improve the cross-lingual ability of LLMs, we reconstruct\na semantic pivot-aware pre-training dataset using documents with a high\nproportion of semantic pivots. Our experiments validate the effectiveness of\nour approach in enhancing cross-lingual ability. Our research contributes\ninsights into the interpretability of LLMs and offers a method for improving\nLLMs' cross-lingual ability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16385v1",
    "published": "2025-05-22T08:37:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16384v1",
    "title": "MAGE: A Multi-task Architecture for Gaze Estimation with an Efficient Calibration Module",
    "authors": [
      "Haoming Huang",
      "Musen Zhang",
      "Jianxin Yang",
      "Zhen Li",
      "Jinkai Li",
      "Yao Guo"
    ],
    "abstract": "Eye gaze can provide rich information on human psychological activities, and\nhas garnered significant attention in the field of Human-Robot Interaction\n(HRI). However, existing gaze estimation methods merely predict either the gaze\ndirection or the Point-of-Gaze (PoG) on the screen, failing to provide\nsufficient information for a comprehensive six Degree-of-Freedom (DoF) gaze\nanalysis in 3D space. Moreover, the variations of eye shape and structure among\nindividuals also impede the generalization capability of these methods. In this\nstudy, we propose MAGE, a Multi-task Architecture for Gaze Estimation with an\nefficient calibration module, to predict the 6-DoF gaze information that is\napplicable for the real-word HRI. Our basic model encodes both the directional\nand positional features from facial images, and predicts gaze results with\ndedicated information flow and multiple decoders. To reduce the impact of\nindividual variations, we propose a novel calibration module, namely\nEasy-Calibration, to fine-tune the basic model with subject-specific data,\nwhich is efficient to implement without the need of a screen. Experimental\nresults demonstrate that our method achieves state-of-the-art performance on\nthe public MPIIFaceGaze, EYEDIAP, and our built IMRGaze datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.16384v1",
    "published": "2025-05-22T08:36:58+00:00",
    "categories": [
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16383v2",
    "title": "Filling in the Blanks? A Systematic Review and Theoretical Conceptualisation for Measuring WikiData Content Gaps",
    "authors": [
      "Marisa Ripoll",
      "Neal Reeves",
      "Anelia Kurteva",
      "Elena Simperl",
      "Albert Meroño Peñuela",
      "Klaus Diepold"
    ],
    "abstract": "Wikidata is a collaborative knowledge graph which provides machine-readable\nstructured data for Wikimedia projects including Wikipedia. Managed by a\ncommunity of volunteers, it has grown to become the most edited Wikimedia\nproject. However, it features a long-tail of items with limited data and a\nnumber of systematic gaps within the available content. In this paper, we\npresent the results of a systematic literature review aimed to understand the\nstate of these content gaps within Wikidata. We propose a typology of gaps\nbased on prior research and contribute a theoretical framework intended to\nconceptualise gaps and support their measurement. We also describe the methods\nand metrics present used within the literature and classify them according to\nour framework to identify overlooked gaps that might occur in Wikidata. We then\ndiscuss the implications for collaboration and editor activity within Wikidata\nas well as future research directions. Our results contribute to the\nunderstanding of quality, completeness and the impact of systematic biases\nwithin Wikidata and knowledge gaps more generally.",
    "pdf_url": "http://arxiv.org/pdf/2505.16383v2",
    "published": "2025-05-22T08:36:30+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16382v1",
    "title": "Electronic and Vibrational Properties of Layered Boron Nitride Polymorphs",
    "authors": [
      "Priyanka Mishra",
      "Nevill Gonzalez Szwacki"
    ],
    "abstract": "We present a comprehensive first-principles investigation of the structural,\nelectronic, and vibrational properties of four layered boron nitride (BN)\npolymorphs--AA-stacked ($e$-BN), AA$^\\prime$-stacked ($h$-BN), ABC-stacked\n($r$-BN), and AB-stacked ($b$-BN). Using density functional theory and density\nfunctional perturbation theory with and without van der Waals (vdW)\ncorrections, we quantify the impact of interlayer dispersion on lattice\nparameters, electronic band gaps, phonon frequencies, and infrared and Raman\nintensities. Our results demonstrate that vdW interactions are essential for\nreproducing experimental lattice constants and stabilizing interlayer phonon\nmodes. The vibrational spectra exhibit distinct stacking-dependent features,\nenabling clear differentiation among polytypes. Notably, $b$-BN displays a\ndirect band gap, while $r$-BN shows enhanced IR and Raman activity due to LO-TO\nsplitting and symmetry breaking. These findings underscore the critical role of\ninterlayer interactions in determining the physical properties of $sp^2$-bonded\nBN and offer insight into the experimental identification and functionalization\nof BN polytypes for electronic and photonic applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16382v1",
    "published": "2025-05-22T08:36:27+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16381v1",
    "title": "PaTH Attention: Position Encoding via Accumulating Householder Transformations",
    "authors": [
      "Songlin Yang",
      "Yikang Shen",
      "Kaiyue Wen",
      "Shawn Tan",
      "Mayank Mishra",
      "Liliang Ren",
      "Rameswar Panda",
      "Yoon Kim"
    ],
    "abstract": "The attention mechanism is a core primitive in modern large language models\n(LLMs) and AI more broadly. Since attention by itself is permutation-invariant,\nposition encoding is essential for modeling structured domains such as\nlanguage. Rotary position encoding (RoPE) has emerged as the de facto standard\napproach for position encoding and is part of many modern LLMs. However, in\nRoPE the key/query transformation between two elements in a sequence is only a\nfunction of their relative position and otherwise independent of the actual\ninput. This limits the expressivity of RoPE-based transformers.\n  This paper describes PaTH, a flexible data-dependent position encoding scheme\nbased on accumulated products of Householder(like) transformations, where each\ntransformation is data-dependent, i.e., a function of the input. We derive an\nefficient parallel algorithm for training through exploiting a compact\nrepresentation of products of Householder matrices, and implement a\nFlashAttention-style blockwise algorithm that minimizes I/O cost. Across both\ntargeted synthetic benchmarks and moderate-scale real-world language modeling\nexperiments, we find that PaTH demonstrates superior performance compared to\nRoPE and other recent baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.16381v1",
    "published": "2025-05-22T08:36:09+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16380v2",
    "title": "On the Identification of Exotic Compact Binaries with Gravitational Waves: a Phenomenological approach",
    "authors": [
      "Shrobana Ghosh",
      "Mark Hannam"
    ],
    "abstract": "Gravitational wave (GW) astronomy has been hailed as a gateway to discovering\nunexpected phenomena in the universe. Over the last decade there have been\nclose to one hundred GW observations of compact-binary mergers. While these\nsignals are largely consistent with mergers of binary black holes, binary\nneutron stars, or black hole-neutron star systems, some events suggest the\nintriguing possibility of binaries involving exotic compact objects (ECOs).\nIdentifying and characterising an ECO merger would require accurate ECO\nwaveform models. Using large numbers of numerical relativity simulations to\ndevelop customised models for ECO mergers akin to those used for binary black\nholes, would be not only computationally expensive but also challenging due to\nthe limited understanding of the underlying physics. Alternatively, key\nphysical imprints of the ECO on the inspiral or merger could in principle be\nincorporated phenomenologically into waveform models, sufficient to quantify\ngeneric properties. In this work we present a first application of this idea to\nassess the detectability and distinguishability of ECO mergers, and we propose\na phenomenological approach that can iteratively incorporate features of ECO\nmergers, laying the groundwork for an effective exotic compact object\nidentifier in compact binary coalescences. We demonstrate that within this\nframework the compactness of the objects in GW150914 are consistent with that\nof black holes. The efficacy of the identifier can be refined by adding\ninformation from numerical relativity simulations involving fundamental fields.\nConversely, such an identifier framework can help focus future numerical\nrelativity and modeling efforts for exotic objects.",
    "pdf_url": "http://arxiv.org/pdf/2505.16380v2",
    "published": "2025-05-22T08:35:12+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16379v1",
    "title": "Materials Generation in the Era of Artificial Intelligence: A Comprehensive Survey",
    "authors": [
      "Zhixun Li",
      "Bin Cao",
      "Rui Jiao",
      "Liang Wang",
      "Ding Wang",
      "Yang Liu",
      "Dingshuo Chen",
      "Jia Li",
      "Qiang Liu",
      "Yu Rong",
      "Liang Wang",
      "Tong-yi Zhang",
      "Jeffrey Xu Yu"
    ],
    "abstract": "Materials are the foundation of modern society, underpinning advancements in\nenergy, electronics, healthcare, transportation, and infrastructure. The\nability to discover and design new materials with tailored properties is\ncritical to solving some of the most pressing global challenges. In recent\nyears, the growing availability of high-quality materials data combined with\nrapid advances in Artificial Intelligence (AI) has opened new opportunities for\naccelerating materials discovery. Data-driven generative models provide a\npowerful tool for materials design by directly create novel materials that\nsatisfy predefined property requirements. Despite the proliferation of related\nwork, there remains a notable lack of up-to-date and systematic surveys in this\narea. To fill this gap, this paper provides a comprehensive overview of recent\nprogress in AI-driven materials generation. We first organize various types of\nmaterials and illustrate multiple representations of crystalline materials. We\nthen provide a detailed summary and taxonomy of current AI-driven materials\ngeneration approaches. Furthermore, we discuss the common evaluation metrics\nand summarize open-source codes and benchmark datasets. Finally, we conclude\nwith potential future directions and challenges in this fast-growing field. The\nrelated sources can be found at\nhttps://github.com/ZhixunLEE/Awesome-AI-for-Materials-Generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16379v1",
    "published": "2025-05-22T08:33:21+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16378v3",
    "title": "Observing the dynamics of octupolar structural transitions in trapped-ion clusters",
    "authors": [
      "Akhil Ayyadevara",
      "Anand Prakash",
      "Shovan Dutta",
      "Arun Paramekanti",
      "S. A. Rangwala"
    ],
    "abstract": "Interacting many-particle systems can self-organize into a rich variety of\ncrystalline structures. While symmetry provides a powerful framework for\npredicting whether transitions between crystal states are continuous or\ndiscontinuous, collective lattice dynamics offer complementary insights into\nthe microscopic mechanisms that drive these transitions. Trapped laser-cooled\nions present a pristine and highly controllable few-body system for studying\nthis interplay of symmetry and dynamics. Here, we use real-time fluorescence\nimaging while deforming the trap potential to observe a variety of structural\ntransitions in three-dimensional (3D), unit-cell-like ion clusters. We identify\na set of transitions signaled by parity-odd octupole order parameters, and\nprobe their distinct dynamical signatures. Our observations reveal the\nsoftening of a collective Higgs-like mode indicating spontaneous\nsymmetry-breaking, hysteresis resulting from a catastrophe where a metastable\nstate vanishes abruptly, and stochastic switching between metastable states of\ndiffering symmetries. We also uncover a remarkable coincidence of\nsymmetry-breaking and discontinuous transitions, analogous to a thermodynamic\ntriple point. Our results establish 3D trapped-ion clusters as a versatile\nplatform to engineer complex potential energy landscapes, opening new avenues\nfor studies of reaction kinetics, geometric frustration, and related phenomena\nin mesoscopic platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.16378v3",
    "published": "2025-05-22T08:30:46+00:00",
    "categories": [
      "physics.atom-ph",
      "cond-mat.mes-hall",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16377v1",
    "title": "VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving",
    "authors": [
      "Yansong Qu",
      "Zilin Huang",
      "Zihao Sheng",
      "Jiancong Chen",
      "Sikai Chen",
      "Samuel Labi"
    ],
    "abstract": "Reinforcement learning (RL)-based autonomous driving policy learning faces\ncritical limitations such as low sample efficiency and poor generalization; its\nreliance on online interactions and trial-and-error learning is especially\nunacceptable in safety-critical scenarios. Existing methods including safe RL\noften fail to capture the true semantic meaning of \"safety\" in complex driving\ncontexts, leading to either overly conservative driving behavior or constraint\nviolations. To address these challenges, we propose VL-SAFE, a world\nmodel-based safe RL framework with Vision-Language model\n(VLM)-as-safety-guidance paradigm, designed for offline safe policy learning.\nSpecifically, we construct offline datasets containing data collected by expert\nagents and labeled with safety scores derived from VLMs. A world model is\ntrained to generate imagined rollouts together with safety estimations,\nallowing the agent to perform safe planning without interacting with the real\nenvironment. Based on these imagined trajectories and safety evaluations,\nactor-critic learning is conducted under VLM-based safety guidance to optimize\nthe driving policy more safely and efficiently. Extensive evaluations\ndemonstrate that VL-SAFE achieves superior sample efficiency, generalization,\nsafety, and overall performance compared to existing baselines. To the best of\nour knowledge, this is the first work that introduces a VLM-guided world\nmodel-based approach for safe autonomous driving. The demo video and code can\nbe accessed at: https://ys-qu.github.io/vlsafe-website/",
    "pdf_url": "http://arxiv.org/pdf/2505.16377v1",
    "published": "2025-05-22T08:29:59+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16376v1",
    "title": "DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos",
    "authors": [
      "Zijia Lu",
      "A S M Iftekhar",
      "Gaurav Mittal",
      "Tianjian Meng",
      "Xiawei Wang",
      "Cheng Zhao",
      "Rohith Kukkala",
      "Ehsan Elhamifar",
      "Mei Chen"
    ],
    "abstract": "Long Video Temporal Grounding (LVTG) aims at identifying specific moments\nwithin lengthy videos based on user-provided text queries for effective content\nretrieval. The approach taken by existing methods of dividing video into clips\nand processing each clip via a full-scale expert encoder is challenging to\nscale due to prohibitive computational costs of processing a large number of\nclips in long videos. To address this issue, we introduce DeCafNet, an approach\nemploying ``delegate-and-conquer'' strategy to achieve computation efficiency\nwithout sacrificing grounding performance. DeCafNet introduces a sidekick\nencoder that performs dense feature extraction over all video clips in a\nresource-efficient manner, while generating a saliency map to identify the most\nrelevant clips for full processing by the expert encoder. To effectively\nleverage features from sidekick and expert encoders that exist at different\ntemporal resolutions, we introduce DeCaf-Grounder, which unifies and refines\nthem via query-aware temporal aggregation and multi-scale temporal refinement\nfor accurate grounding. Experiments on two LTVG benchmark datasets demonstrate\nthat DeCafNet reduces computation by up to 47\\% while still outperforming\nexisting methods, establishing a new state-of-the-art for LTVG in terms of both\nefficiency and performance. Our code is available at\nhttps://github.com/ZijiaLewisLu/CVPR2025-DeCafNet.",
    "pdf_url": "http://arxiv.org/pdf/2505.16376v1",
    "published": "2025-05-22T08:29:57+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16375v2",
    "title": "Realizability of fusion systems by discrete groups: II",
    "authors": [
      "Carles Broto",
      "Ran Levi",
      "Bob Oliver"
    ],
    "abstract": "We compare four different types of realizability for saturated fusion systems\nover discrete $p$-toral groups. For example, when $G$ is a locally finite group\nall of whose $p$-subgroups are artinian (hence discrete $p$-toral), we show\nthat it has ``weakly Sylow'' $p$-subgroups and give explicit constructions of\nsaturated fusion systems and associated linking systems associated to $G$. We\nalso show that a fusion system over a discrete $p$-toral group $S$ is saturated\nif its set of morphisms is closed under a certain topology and the finite\nsubgroups of $S$ satisfy the saturation axioms, and prove a version of the\nCartan-Eilenberg stable elements theorem for locally finite groups.",
    "pdf_url": "http://arxiv.org/pdf/2505.16375v2",
    "published": "2025-05-22T08:29:41+00:00",
    "categories": [
      "math.GR",
      "math.AT",
      "20D20, 20F50"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16374v1",
    "title": "Scalable and Efficient Aggregation of Energy-Constrained Flexible Loads",
    "authors": [
      "Julie Rousseau",
      "Philipp Heer",
      "Kristina Orehounig",
      "Gabriela Hug"
    ],
    "abstract": "Loads represent a promising flexibility source to support the integration of\nrenewable energy sources, as they may shift their energy consumption over time.\nBy computing the aggregated flexibility of power and energy-constrained loads,\naggregators can communicate the group's flexibility without sharing individual\nprivate information. However, this computation is, in practice, challenging.\nSome studies suggest different inner approximations of aggregated flexibility\npolytopes, but all suffer from large computational costs for realistic load\nnumbers and horizon lengths. In this paper, we develop a novel approximation of\nthe aggregated flexibility of loads based on the concept of worst-case energy\ndispatch, i.e., if aggregated energy consumptions are assumed to be dispatched\nin the worst manner possible. This leads to conservative piecewise linear\nbounds that restrict the aggregated energy consumption only based on the\nprevious aggregated energy consumed. A comparative case study reveals that our\nmethod can compute an approximation of the aggregation of thousands of loads\nefficiently, while displaying an accuracy comparable to other approximation\ntechniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.16374v1",
    "published": "2025-05-22T08:28:15+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16373v1",
    "title": "PCMamba: Physics-Informed Cross-Modal State Space Model for Dual-Camera Compressive Hyperspectral Imaging",
    "authors": [
      "Ge Meng",
      "Zhongnan Cai",
      "Jingyan Tu",
      "Yingying Wang",
      "Chenxin Li",
      "Yue Huang",
      "Xinghao Ding"
    ],
    "abstract": "Panchromatic (PAN) -assisted Dual-Camera Compressive Hyperspectral Imaging\n(DCCHI) is a key technology in snapshot hyperspectral imaging. Existing\nresearch primarily focuses on exploring spectral information from 2D\ncompressive measurements and spatial information from PAN images in an explicit\nmanner, leading to a bottleneck in HSI reconstruction. Various physical\nfactors, such as temperature, emissivity, and multiple reflections between\nobjects, play a critical role in the process of a sensor acquiring\nhyperspectral thermal signals. Inspired by this, we attempt to investigate the\ninterrelationships between physical properties to provide deeper theoretical\ninsights for HSI reconstruction. In this paper, we propose a Physics-Informed\nCross-Modal State Space Model Network (PCMamba) for DCCHI, which incorporates\nthe forward physical imaging process of HSI into the linear complexity of Mamba\nto facilitate lightweight and high-quality HSI reconstruction. Specifically, we\nanalyze the imaging process of hyperspectral thermal signals to enable the\nnetwork to disentangle the three key physical properties-temperature,\nemissivity, and texture. By fully exploiting the potential information embedded\nin 2D measurements and PAN images, the HSIs are reconstructed through a\nphysics-driven synthesis process. Furthermore, we design a Cross-Modal Scanning\nMamba Block (CSMB) that introduces inter-modal pixel-wise interaction with\npositional inductive bias by cross-scanning the backbone features and PAN\nfeatures. Extensive experiments conducted on both real and simulated datasets\ndemonstrate that our method significantly outperforms SOTA methods in both\nquantitative and qualitative metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16373v1",
    "published": "2025-05-22T08:27:46+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16372v1",
    "title": "Temporal and Spatial Feature Fusion Framework for Dynamic Micro Expression Recognition",
    "authors": [
      "Feng Liu",
      "Bingyu Nan",
      "Xuezhong Qian",
      "Xiaolan Fu"
    ],
    "abstract": "When emotions are repressed, an individual's true feelings may be revealed\nthrough micro-expressions. Consequently, micro-expressions are regarded as a\ngenuine source of insight into an individual's authentic emotions. However, the\ntransient and highly localised nature of micro-expressions poses a significant\nchallenge to their accurate recognition, with the accuracy rate of\nmicro-expression recognition being as low as 50%, even for professionals. In\norder to address these challenges, it is necessary to explore the field of\ndynamic micro expression recognition (DMER) using multimodal fusion techniques,\nwith special attention to the diverse fusion of temporal and spatial modal\nfeatures. In this paper, we propose a novel Temporal and Spatial feature Fusion\nframework for DMER (TSFmicro). This framework integrates a Retention Network\n(RetNet) and a transformer-based DMER network, with the objective of efficient\nmicro-expression recognition through the capture and fusion of temporal and\nspatial relations. Meanwhile, we propose a novel parallel time-space fusion\nmethod from the perspective of modal fusion, which fuses spatio-temporal\ninformation in high-dimensional feature space, resulting in complementary\n\"where-how\" relationships at the semantic level and providing richer semantic\ninformation for the model. The experimental results demonstrate the superior\nperformance of the TSFmicro method in comparison to other contemporary\nstate-of-the-art methods. This is evidenced by its effectiveness on three\nwell-recognised micro-expression datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.16372v1",
    "published": "2025-05-22T08:26:19+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16371v1",
    "title": "Privacy-Aware Cyberterrorism Network Analysis using Graph Neural Networks and Federated Learning",
    "authors": [
      "Anas Ali",
      "Mubashar Husain",
      "Peter Hans"
    ],
    "abstract": "Cyberterrorism poses a formidable threat to digital infrastructures, with\nincreasing reliance on encrypted, decentralized platforms that obscure threat\nactor activity. To address the challenge of analyzing such adversarial networks\nwhile preserving the privacy of distributed intelligence data, we propose a\nPrivacy-Aware Federated Graph Neural Network (PA-FGNN) framework. PA-FGNN\nintegrates graph attention networks, differential privacy, and homomorphic\nencryption into a robust federated learning pipeline tailored for\ncyberterrorism network analysis. Each client trains locally on sensitive graph\ndata and exchanges encrypted, noise-perturbed model updates with a central\naggregator, which performs secure aggregation and broadcasts global updates. We\nimplement anomaly detection for flagging high-risk nodes and incorporate\ndefenses against gradient poisoning. Experimental evaluations on simulated dark\nweb and cyber-intelligence graphs demonstrate that PA-FGNN achieves over 91\\%\nclassification accuracy, maintains resilience under 20\\% adversarial client\nbehavior, and incurs less than 18\\% communication overhead. Our results\nhighlight that privacy-preserving GNNs can support large-scale cyber threat\ndetection without compromising on utility, privacy, or robustness.",
    "pdf_url": "http://arxiv.org/pdf/2505.16371v1",
    "published": "2025-05-22T08:26:09+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16370v1",
    "title": "Diffraction Stress Factors Calculated Using a Maximum Entropy Method",
    "authors": [
      "Maximilian Krause",
      "Nicola Simon",
      "Claudius Klein",
      "Jens Gibmeier",
      "Thomas Böhlke"
    ],
    "abstract": "Diffraction-based stress analysis of textured materials depends on\nunderstanding their elastic heterogeneity and its influence on microscopic\nstrain distributions, which is generally done by using simplifying assumptions\nfor crystallite interactions to calculate tensorial stress factors or in the\ncase of very strong textures, by considering the material phase as a single\ncrystal (crystallite group method). In this paper, we apply the micromechanical\nMaximum Entropy Method (MEM) to this purpose, which marks its first use for\nmaterials with texture. The special feature of this approach is a native\nparametrization by the effective stiffness of the material, which allows the\napproach to be tailored to a macroscopically measurable sample property. We\nperform example stress analyses of cold-rolled copper, finding through\nvalidation with full-field simulations that the MEM yields accurate local\nstrains even for materials with extremely sharp textures. In an example stress\nanalysis of mildly textured cold-rolled ferritic steel, the accuracy of the\napproach compares favorably to the established Voigt, Reuss and self-consistent\nEshelby-Kr\\\"oner approaches. Compared to the latter, the method is also\nnumerically efficient to calculate.",
    "pdf_url": "http://arxiv.org/pdf/2505.16370v1",
    "published": "2025-05-22T08:25:39+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16369v2",
    "title": "X-ARES: A Comprehensive Framework for Assessing Audio Encoder Performance",
    "authors": [
      "Junbo Zhang",
      "Heinrich Dinkel",
      "Yadong Niu",
      "Chenyu Liu",
      "Si Cheng",
      "Anbei Zhao",
      "Jian Luan"
    ],
    "abstract": "We introduces X-ARES (eXtensive Audio Representation and Evaluation Suite), a\nnovel open-source benchmark designed to systematically assess audio encoder\nperformance across diverse domains. By encompassing tasks spanning speech,\nenvironmental sounds, and music, X-ARES provides two evaluation approaches for\nevaluating audio representations: linear fine-tuning and unparameterized\nevaluation. The framework includes 22 distinct tasks that cover essential\naspects of audio processing, from speech recognition and emotion detection to\nsound event classification and music genre identification. Our extensive\nevaluation of state-of-the-art audio encoders reveals significant performance\nvariations across different tasks and domains, highlighting the complexity of\ngeneral audio representation learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.16369v2",
    "published": "2025-05-22T08:23:54+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16368v1",
    "title": "SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning",
    "authors": [
      "Huanyu Liu",
      "Jia Li",
      "Hao Zhu",
      "Kechi Zhang",
      "Yihong Dong",
      "Ge Li"
    ],
    "abstract": "How to design reinforcement learning (RL) tasks that effectively unleash the\nreasoning capability of large language models (LLMs) remains an open question.\nExisting RL tasks (e.g., math, programming, and constructing reasoning tasks)\nsuffer from three key limitations: (1) Scalability. They rely heavily on human\nannotation or expensive LLM synthesis to generate sufficient training data. (2)\nVerifiability. LLMs' outputs are hard to verify automatically and reliably. (3)\nControllable Difficulty. Most tasks lack fine-grained difficulty control,\nmaking it hard to train LLMs to develop reasoning ability from easy to hard.\n  To address these limitations, we propose Saturn, a SAT-based RL framework\nthat uses Boolean Satisfiability (SAT) problems to train and evaluate LLM\nreasoning. Saturn enables scalable task construction, rule-based verification,\nand precise difficulty control. Saturn designs a curriculum learning pipeline\nthat continuously improves LLMs' reasoning capability by constructing SAT tasks\nof increasing difficulty and training LLMs from easy to hard. To ensure stable\ntraining, we design a principled mechanism to control difficulty transitions.\n  We introduce Saturn-2.6k, a dataset of 2,660 SAT problems with varying\ndifficulty. It supports the evaluation of how LLM reasoning changes with\nproblem difficulty. We apply Saturn to DeepSeek-R1-Distill-Qwen and obtain\nSaturn-1.5B and Saturn-7B. We achieve several notable results: (1) On SAT\nproblems, Saturn-1.5B and Saturn-7B achieve average pass@3 improvements of\n+14.0 and +28.1, respectively. (2) On math and programming tasks, Saturn-1.5B\nand Saturn-7B improve average scores by +4.9 and +1.8 on benchmarks (e.g.,\nAIME, LiveCodeBench). (3) Compared to the state-of-the-art (SOTA) approach in\nconstructing RL tasks, Saturn achieves further improvements of +8.8%. We\nrelease the source code, data, and models to support future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.16368v1",
    "published": "2025-05-22T08:23:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17147v1",
    "title": "MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming",
    "authors": [
      "Weiyang Guo",
      "Jing Li",
      "Wenya Wang",
      "YU LI",
      "Daojing He",
      "Jun Yu",
      "Min Zhang"
    ],
    "abstract": "The proliferation of jailbreak attacks against large language models (LLMs)\nhighlights the need for robust security measures. However, in multi-round\ndialogues, malicious intentions may be hidden in interactions, leading LLMs to\nbe more prone to produce harmful responses. In this paper, we propose the\n\\textbf{M}ulti-\\textbf{T}urn \\textbf{S}afety \\textbf{A}lignment (\\ourapproach)\nframework, to address the challenge of securing LLMs in multi-round\ninteractions. It consists of two stages: In the thought-guided attack learning\nstage, the red-team model learns about thought-guided multi-round jailbreak\nattacks to generate adversarial prompts. In the adversarial iterative\noptimization stage, the red-team model and the target model continuously\nimprove their respective capabilities in interaction. Furthermore, we introduce\na multi-turn reinforcement learning algorithm based on future rewards to\nenhance the robustness of safety alignment. Experimental results show that the\nred-team model exhibits state-of-the-art attack capabilities, while the target\nmodel significantly improves its performance on safety benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.17147v1",
    "published": "2025-05-22T08:22:57+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16367v1",
    "title": "Chain-of-Thought Poisoning Attacks against R1-based Retrieval-Augmented Generation Systems",
    "authors": [
      "Hongru Song",
      "Yu-an Liu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Yixing Fan"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems can effectively mitigate the\nhallucination problem of large language models (LLMs),but they also possess\ninherent vulnerabilities. Identifying these weaknesses before the large-scale\nreal-world deployment of RAG systems is of great importance, as it lays the\nfoundation for building more secure and robust RAG systems in the future.\nExisting adversarial attack methods typically exploit knowledge base poisoning\nto probe the vulnerabilities of RAG systems, which can effectively deceive\nstandard RAG models. However, with the rapid advancement of deep reasoning\ncapabilities in modern LLMs, previous approaches that merely inject incorrect\nknowledge are inadequate when attacking RAG systems equipped with deep\nreasoning abilities. Inspired by the deep thinking capabilities of LLMs, this\npaper extracts reasoning process templates from R1-based RAG systems, uses\nthese templates to wrap erroneous knowledge into adversarial documents, and\ninjects them into the knowledge base to attack RAG systems. The key idea of our\napproach is that adversarial documents, by simulating the chain-of-thought\npatterns aligned with the model's training signals, may be misinterpreted by\nthe model as authentic historical reasoning processes, thus increasing their\nlikelihood of being referenced. Experiments conducted on the MS MARCO passage\nranking dataset demonstrate the effectiveness of our proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.16367v1",
    "published": "2025-05-22T08:22:46+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16366v1",
    "title": "ReCopilot: Reverse Engineering Copilot in Binary Analysis",
    "authors": [
      "Guoqiang Chen",
      "Huiqi Sun",
      "Daguang Liu",
      "Zhiqi Wang",
      "Qiang Wang",
      "Bin Yin",
      "Lu Liu",
      "Lingyun Ying"
    ],
    "abstract": "Binary analysis plays a pivotal role in security domains such as malware\ndetection and vulnerability discovery, yet it remains labor-intensive and\nheavily reliant on expert knowledge. General-purpose large language models\n(LLMs) perform well in programming analysis on source code, while\nbinaryspecific LLMs are underexplored. In this work, we present ReCopilot, an\nexpert LLM designed for binary analysis tasks. ReCopilot integrates binary code\nknowledge through a meticulously constructed dataset, encompassing continue\npretraining (CPT), supervised fine-tuning (SFT), and direct preference\noptimization (DPO) stages. It leverages variable data flow and call graph to\nenhance context awareness and employs test-time scaling to improve reasoning\ncapabilities. Evaluations on a comprehensive binary analysis benchmark\ndemonstrate that ReCopilot achieves state-of-the-art performance in tasks such\nas function name recovery and variable type inference on the decompiled pseudo\ncode, outperforming both existing tools and LLMs by 13%. Our findings highlight\nthe effectiveness of domain-specific training and context enhancement, while\nalso revealing challenges in building super long chain-of-thought. ReCopilot\nrepresents a significant step toward automating binary analysis with\ninterpretable and scalable AI assistance in this domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.16366v1",
    "published": "2025-05-22T08:21:39+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16365v1",
    "title": "A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules",
    "authors": [
      "Manuel Ruiz-Botella",
      "Marta Sales-Pardo",
      "Roger Guimerà"
    ],
    "abstract": "Developing new molecular compounds is crucial to address pressing challenges,\nfrom health to environmental sustainability. However, exploring the molecular\nspace to discover new molecules is difficult due to the vastness of the space.\nHere we introduce CoCoGraph, a collaborative and constrained graph diffusion\nmodel capable of generating molecules that are guaranteed to be chemically\nvalid. Thanks to the constraints built into the model and to the collaborative\nmechanism, CoCoGraph outperforms state-of-the-art approaches on standard\nbenchmarks while requiring up to an order of magnitude fewer parameters.\nAnalysis of 36 chemical properties also demonstrates that CoCoGraph generates\nmolecules with distributions more closely matching real molecules than current\nmodels. Leveraging the model's efficiency, we created a database of 8.2M\nmillion synthetically generated molecules and conducted a Turing-like test with\norganic chemistry experts to further assess the plausibility of the generated\nmolecules, and potential biases and limitations of CoCoGraph.",
    "pdf_url": "http://arxiv.org/pdf/2505.16365v1",
    "published": "2025-05-22T08:21:27+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16364v1",
    "title": "Single-shot 3D characterization the spatiotemporal optical vortex via a spatiotemporal wavefront sensor (STWFS)",
    "authors": [
      "Xiuyu Yao",
      "Ping Zhu",
      "Youjian Yi",
      "Zezhao Gong",
      "Dongjun Zhang",
      "Ailin Guo",
      "Fucai Ding",
      "Xiao Liang",
      "Xuejie Zhang",
      "Meizhi Sun",
      "Qiang Zhang",
      "Miaoyan Tong",
      "Lijie Cui",
      "Hailun Zen",
      "Xinglong Xie",
      "Jianqiang Zhu"
    ],
    "abstract": "The advent of spatiotemporal wave packets (STWPs), represented by\nspatiotemporal optical vortices (STOVs), has paved the way for the exploration\nin optics and photonics. To date, despite considerable efforts, a comprehensive\nand efficient practical means to characterizing wave packets with such complex\nstructures is still lacking. In this study, we introduced a new method designed\nto achieve high-precision and high-throughput spatiotemporal wave packet\nmeasurements using a user-friendly set up. This method is based on a quadriwave\nlateral shearing interferometric wavefront sensor that utilizes wavelength\ndivision multiplexing, termed the \"spatiotemporal wavefront sensor (STWFS).\"\nUsing this method, we have fabricated a compact prototype with 295 * 295\nspatial pixels * 36 wavelength channels of 0.5 nm spectral resolution in a\nsingle frame. This STWFS enabled, for the first time, single-shot\nself-referenced spatiotemporal three-dimensional (3D) optical field\ncharacterizations of STOV pulses with transverse orbital angular momenta L of 1\nand 2, and obtained the dynamic visualization of the focused propagation of\nSTOV pulses. Furthermore, the STWFS provides a 1.87 nm (0.95%) root mean square\n(RMS) absolute accuracy for spatiotemporal phase reconstruction. This\nachievement represents the highest performance compared with other\nthree-dimensional spatiotemporal metrology methods. As a spatiotemporal optical\nfield characterization method, the STWFS offers ultrafast 3D diagnostics,\ncontributing to spatiotemporal photonics and broader applications across\ndifferent fields, such as light-matter interactions and optical communications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16364v1",
    "published": "2025-05-22T08:18:11+00:00",
    "categories": [
      "physics.optics",
      "physics.ins-det"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.16363v1",
    "title": "AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training",
    "authors": [
      "Huishuai Zhang",
      "Bohan Wang",
      "Luoxin Chen"
    ],
    "abstract": "We introduce AdamS, a simple yet effective alternative to Adam for large\nlanguage model (LLM) pretraining and post-training. By leveraging a novel\ndenominator, i.e., the root of weighted sum of squares of the momentum and the\ncurrent gradient, AdamS eliminates the need for second-moment estimates. Hence,\nAdamS is efficient, matching the memory and compute footprint of SGD with\nmomentum while delivering superior optimization performance. Moreover, AdamS is\neasy to adopt: it can directly inherit hyperparameters of AdamW, and is\nentirely model-agnostic, integrating seamlessly into existing pipelines without\nmodifications to optimizer APIs or architectures. The motivation behind AdamS\nstems from the observed $(L_0, L_1)$ smoothness properties in transformer\nobjectives, where local smoothness is governed by gradient magnitudes that can\nbe further approximated by momentum magnitudes. We establish rigorous\ntheoretical convergence guarantees and provide practical guidelines for\nhyperparameter selection. Empirically, AdamS demonstrates strong performance in\nvarious tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B\nparameters) and reinforcement learning in post-training regimes. With its\nefficiency, simplicity, and theoretical grounding, AdamS stands as a compelling\nalternative to existing optimizers.",
    "pdf_url": "http://arxiv.org/pdf/2505.16363v1",
    "published": "2025-05-22T08:16:48+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16362v1",
    "title": "Neuromorphic-based metaheuristics: A new generation of low power, low latency and small footprint optimization algorithms",
    "authors": [
      "El-ghazali Talbi"
    ],
    "abstract": "Neuromorphic computing (NC) introduces a novel algorithmic paradigm\nrepresenting a major shift from traditional digital computing of Von Neumann\narchitectures. NC emulates or simulates the neural dynamics of brains in the\nform of Spiking Neural Networks (SNNs). Much of the research in NC has\nconcentrated on machine learning applications and neuroscience simulations.\nThis paper investigates the modelling and implementation of optimization\nalgorithms and particularly metaheuristics using the NC paradigm as an\nalternative to Von Neumann architectures, leading to breakthroughs in solving\noptimization problems.\n  Neuromorphic-based metaheuristics (Nheuristics) are supposed to be\ncharacterized by low power, low latency and small footprint. Since NC systems\nare fundamentally different from conventional Von Neumann computers, several\nchallenges are posed to the design and implementation of Nheuristics. A\nguideline based on a classification and critical analysis is conducted on the\ndifferent families of metaheuristics and optimization problems they address. We\nalso discuss future directions that need to be addressed to expand both the\ndevelopment and application of Nheuristics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16362v1",
    "published": "2025-05-22T08:14:07+00:00",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16361v1",
    "title": "Multi-Sheet Wormholes in the Gravitational Soliton Formalism",
    "authors": [
      "Yusuke Makita",
      "Keisuke Izumi",
      "Daisuke Yoshida",
      "Keiya Uemichi"
    ],
    "abstract": "We analytically construct static regular solutions describing wormholes that\nconnect multiple asymptotic regions, supported by a phantom scalar field. The\nsolutions are static and axially symmetric, and are constructed using the\ngravitational soliton formalism, in which the equations of motion reduce to the\nLaplace equations on a two-dimensional sheet. However, the presence of multiple\nasymptotic regions necessitates the introduction of multiple such sheets. These\nsheets are appropriately cut and glued together to form a globally regular\ngeometry. This gluing procedure represents the principal distinction from\nconventional Weyl-type solitonic solutions and is a characteristic feature of\nthe wormhole geometries studied in this paper.",
    "pdf_url": "http://arxiv.org/pdf/2505.16361v1",
    "published": "2025-05-22T08:12:05+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16360v1",
    "title": "Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation",
    "authors": [
      "Estelle Chigot",
      "Dennis G. Wilson",
      "Meriem Ghrib",
      "Thomas Oberlin"
    ],
    "abstract": "Semantic segmentation models trained on synthetic data often perform poorly\non real-world images due to domain gaps, particularly in adverse conditions\nwhere labeled data is scarce. Yet, recent foundation models enable to generate\nrealistic images without any training. This paper proposes to leverage such\ndiffusion models to improve the performance of vision models when learned on\nsynthetic data. We introduce two novel techniques for semantically consistent\nstyle transfer using diffusion models: Class-wise Adaptive Instance\nNormalization and Cross-Attention (CACTI) and its extension with selective\nattention Filtering (CACTIF). CACTI applies statistical normalization\nselectively based on semantic classes, while CACTIF further filters\ncross-attention maps based on feature similarity, preventing artifacts in\nregions with weak cross-attention correspondences. Our methods transfer style\ncharacteristics while preserving semantic boundaries and structural coherence,\nunlike approaches that apply global transformations or generate content without\nconstraints. Experiments using GTA5 as source and Cityscapes/ACDC as target\ndomains show that our approach produces higher quality images with lower FID\nscores and better content preservation. Our work demonstrates that class-aware\ndiffusion-based style transfer effectively bridges the synthetic-to-real domain\ngap even with minimal target domain data, advancing robust perception systems\nfor challenging real-world applications. The source code is available at:\nhttps://github.com/echigot/cactif.",
    "pdf_url": "http://arxiv.org/pdf/2505.16360v1",
    "published": "2025-05-22T08:11:10+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "68T45 (Primary) 68T10, 68T07 (Secondary)",
      "F.1.2; F.1.4"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16359v1",
    "title": "Determining non-symmetric dark matter halo around magnetars with two fluid approach",
    "authors": [
      "Asit karan",
      "Ritam Mallick",
      "Anil Kumar",
      "Monika Sinha"
    ],
    "abstract": "We investigate the impact of dark matter on the structure and deformation of\nmagnetars. We assume a perturbative approach for the magnetic field deformation\nand that the dark matter only interacts gravitationally with hardonic matter.\nAssuming that the DM is significantly softer than HM, we find that the magnetic\nfield can affect dark matter through the deformation of space-time. The number\nof stars having a dark matter halo outside the hadronic matter surface\nincreases with an increase in dark matter fraction and the stiffness of the\ndark matter equation of state. As the magnetic field deforms the stars from\nsphericity, we can have a situation where we have a non-symmetric dark matter\nhalo outside the star. This can have interesting observational gravitational\nsignatures unique to magnetars with having DM halo.",
    "pdf_url": "http://arxiv.org/pdf/2505.16359v1",
    "published": "2025-05-22T08:08:55+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16358v1",
    "title": "Strategic Content Creation in the Age of GenAI: To Share or Not to Share?",
    "authors": [
      "Gur Keinan",
      "Omer Ben-Porat"
    ],
    "abstract": "We introduce a game-theoretic framework examining strategic interactions\nbetween a platform and its content creators in the presence of AI-generated\ncontent. Our model's main novelty is in capturing creators' dual strategic\ndecisions: The investment in content quality and their (possible) consent to\nshare their content with the platform's GenAI, both of which significantly\nimpact their utility. To incentivize creators, the platform strategically\nallocates a portion of its GenAI-driven revenue to creators who share their\ncontent. We focus on the class of full-sharing equilibrium profiles, in which\nall creators willingly share their content with the platform's GenAI system.\nSuch equilibria are highly desirable both theoretically and practically. Our\nmain technical contribution is formulating and efficiently solving a novel\noptimization problem that approximates the platform's optimal revenue subject\nto inducing a full-sharing equilibrium. A key aspect of our approach is\nidentifying conditions under which full-sharing equilibria exist and a\nsurprising connection to the Prisoner's Dilemma. Finally, our simulations\ndemonstrate how revenue-allocation mechanisms affect creator utility and the\nplatform's revenue.",
    "pdf_url": "http://arxiv.org/pdf/2505.16358v1",
    "published": "2025-05-22T08:07:50+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16357v2",
    "title": "Efficient Probabilistic Model Checking for Relational Reachability (Extended Version)",
    "authors": [
      "Lina Gerlach",
      "Tobias Winkler",
      "Erika Ábrahám",
      "Borzoo Bonakdarpour",
      "Sebastian Junges"
    ],
    "abstract": "Markov decision processes model systems subject to nondeterministic and\nprobabilistic uncertainty. A plethora of verification techniques addresses\nvariations of reachability properties, such as: Is there a scheduler resolving\nthe nondeterminism such that the probability to reach an error state is above a\nthreshold? We consider an understudied extension that relates different\nreachability probabilities, such as: Is there a scheduler such that two sets of\nstates are reached with different probabilities? These questions appear\nnaturally in the design of randomized algorithms and in various security\napplications. We provide a tractable algorithm for many variations of this\nproblem, while proving computational hardness of some others. An implementation\nof our algorithm beats solvers for more general probabilistic hyperlogics by\norders of magnitude, on the subset of their benchmarks that are within our\nfragment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16357v2",
    "published": "2025-05-22T08:07:25+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16356v1",
    "title": "Statistical properties of non-linear observables of fractal Gaussian fields with a focus on spatial-averaging observables and on composite operators",
    "authors": [
      "Cecile Monthus"
    ],
    "abstract": "The statistical properties of non-linear observables of the fractal Gaussian\nfield $\\phi(\\vec x)$ of negative Hurst exponent $H<0$ in dimension $d$ are\nrevisited with a focus on spatial-averaging observables and on the properties\nof the finite parts $\\phi_n(\\vec x)$ of the ill-defined composite operators\n$\\phi^n(\\vec x) $. For the special case $n=2$ of quadratic observables,\nexplicit results include the cumulants of arbitrary order, the\nL\\'evy-Khintchine formula for the characteristic function and the anomalous\nlarge deviations properties. The case of observables of arbitrary order $n>2$\nis analyzed via the Wiener-Ito chaos-expansion for functionals of the white\nnoise: the multiple stochastic Ito integrals are useful to identify the finite\nparts $\\phi_n(\\vec x)$ of the ill-defined composite operators $\\phi^n(\\vec x) $\nand to compute their correlations involving the Hurst exponents $H_n=nH$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16356v1",
    "published": "2025-05-22T08:07:06+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "math.PR"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.16355v1",
    "title": "Arbitrarily polarized $γ$-photon source from nonlinear Compton scattering",
    "authors": [
      "Yu Xin",
      "Zu-dong Zhao",
      "Suo Tang"
    ],
    "abstract": "We investigate the nonlinear Compton photon source for upcoming\nlaser-particle experiments in the collision scenario of high-energy electron\nbeams and relativistic laser pulses. The stronger laser field could not only\nimprove the scattering probability but also induce broader photon beam\ndivergence. To maximize the photon flux in a realistic narrow angular\nacceptance, we show that a balance must be met for the laser intensity to boost\nthe scattering probability and simultaneously confine its beam divergence. For\nthe currently experiment-concerned $10~\\textrm{GeV}$ energy regime, the\nbalanced laser intensity locates in the intermediate intensity regime of $\\xi\n\\sim O(1)$. In these regimes of laser intensity and electron energy, the\naccepted photons within a relatively narrow acceptance are highly polarized in\nthe state closely relating to the polarization of the laser pulse, which\nactually implies a potential route to finely control the photon polarization\nvia the laser polarization.",
    "pdf_url": "http://arxiv.org/pdf/2505.16355v1",
    "published": "2025-05-22T08:06:41+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16354v1",
    "title": "Classical solutions to a mixed-type PDE with a Keldysh-type degeneracy and accelerating transonic solutions to the Euler-Poisson system",
    "authors": [
      "Myoungjean Bae",
      "Ben Duan",
      "Chunjing Xie"
    ],
    "abstract": "In this paper, we first prove the existence of classical solutions to a class\nof Keldysh-type equations. Next, we apply this existence result to prove the\nstructural stability of one-dimensional smooth transonic solutions to the\nsteady Euler-Poisson system.\n  Most importantly, the solutions constructed in this paper are classical\nsolutions to the Euler-Poisson system, thus their sonic interfaces are not weak\ndiscontinuities in the sense that all the flow variables, such as density,\nvelocity and pressure, are at least $C^1$ across the interfaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.16354v1",
    "published": "2025-05-22T08:06:08+00:00",
    "categories": [
      "math.AP",
      "35M10, 35M30, 35M32, 76H05, 76N10"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16353v2",
    "title": "Arrival Control in Quasi-Reversible Queueing Systems: Optimization and Reinforcement Learning",
    "authors": [
      "Céline Comte",
      "Pascal Moyal"
    ],
    "abstract": "In this paper, we introduce a versatile scheme for optimizing the arrival\nrates of quasi-reversible queueing systems. We first propose an alternative\ndefinition of quasi-reversibility that encompasses reversibility and highlights\nthe importance of the definition of customer classes. In a second time, we\nintroduce balanced arrival control policies, which generalize the notion of\nbalanced arrival rates introduced in the context of Whittle networks, to the\nmuch broader class of quasi-reversible queueing systems. We prove that\nsupplementing a quasi-reversible queueing system with a balanced\narrival-control policy preserves the quasi-reversibility, and we specify the\nform of the stationary measures. We revisit two canonical examples of\nquasi-reversible queueing systems, Whittle networks and order-independent\nqueues. Lastly, we focus on the problem of admission control and leverage our\nresults in the frameworks of optimization and reinforcement learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.16353v2",
    "published": "2025-05-22T08:05:36+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "math.PR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16352v1",
    "title": "Estimating Perceptual Attributes of Haptic Textures Using Visuo-Tactile Data",
    "authors": [
      "Mudassir Ibrahim Awan",
      "Seokhee Jeon"
    ],
    "abstract": "Accurate prediction of perceptual attributes of haptic textures is essential\nfor advancing VR and AR applications and enhancing robotic interaction with\nphysical surfaces. This paper presents a deep learning-based multi-modal\nframework, incorporating visual and tactile data, to predict perceptual texture\nratings by leveraging multi-feature inputs. To achieve this, a four-dimensional\nhaptic attribute space encompassing rough-smooth, flat-bumpy, sticky-slippery,\nand hard-soft dimensions is first constructed through psychophysical\nexperiments, where participants evaluate 50 diverse real-world texture samples.\nA physical signal space is subsequently created by collecting visual and\ntactile data from these textures. Finally, a deep learning architecture\nintegrating a CNN-based autoencoder for visual feature learning and a ConvLSTM\nnetwork for tactile data processing is trained to predict user-assigned\nattribute ratings. This multi-modal, multi-feature approach maps physical\nsignals to perceptual ratings, enabling accurate predictions for unseen\ntextures. To evaluate predictive accuracy, we employed leave-one-out\ncross-validation to rigorously assess the model's reliability and\ngeneralizability against several machine learning and deep learning baselines.\nExperimental results demonstrate that the framework consistently outperforms\nsingle-modality approaches, achieving lower MAE and RMSE, highlighting the\nefficacy of combining visual and tactile modalities.",
    "pdf_url": "http://arxiv.org/pdf/2505.16352v1",
    "published": "2025-05-22T08:03:11+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16351v2",
    "title": "Dysfluent WFST: A Framework for Zero-Shot Speech Dysfluency Transcription and Detection",
    "authors": [
      "Chenxu Guo",
      "Jiachen Lian",
      "Xuanru Zhou",
      "Jinming Zhang",
      "Shuhe Li",
      "Zongli Ye",
      "Hwi Joo Park",
      "Anaisha Das",
      "Zoe Ezzes",
      "Jet Vonk",
      "Brittany Morin",
      "Rian Bogley",
      "Lisa Wauters",
      "Zachary Miller",
      "Maria Gorno-Tempini",
      "Gopala Anumanchipalli"
    ],
    "abstract": "Automatic detection of speech dysfluency aids speech-language pathologists in\nefficient transcription of disordered speech, enhancing diagnostics and\ntreatment planning. Traditional methods, often limited to classification,\nprovide insufficient clinical insight, and text-independent models misclassify\ndysfluency, especially in context-dependent cases. This work introduces\nDysfluent-WFST, a zero-shot decoder that simultaneously transcribes phonemes\nand detects dysfluency. Unlike previous models, Dysfluent-WFST operates with\nupstream encoders like WavLM and requires no additional training. It achieves\nstate-of-the-art performance in both phonetic error rate and dysfluency\ndetection on simulated and real speech data. Our approach is lightweight,\ninterpretable, and effective, demonstrating that explicit modeling of\npronunciation behavior in decoding, rather than complex architectures, is key\nto improving dysfluency processing systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16351v2",
    "published": "2025-05-22T08:02:50+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16350v2",
    "title": "Sensing-Enhanced Handover Criterion for Low-Altitude Wireless Network (LAWNs)",
    "authors": [
      "Jingli Li",
      "Yiyan Ma",
      "Bo Ai",
      "Weijie Yuan",
      "Qingqing Cheng",
      "Guoyu Ma",
      "Mi Yang",
      "Yunlong Lu",
      "Wenwei Yue",
      "Zhangdui Zhong"
    ],
    "abstract": "With the rapid growth of the low-altitude economy, the demand for\ncellular-enabled low-altitude wireless networks (LAWN) is rising significantly.\nThe three-dimensional mobility of drones will lead to frequent handovers (HOs)\nin cellular networks, while traditional reference signal received power\n(RSRP)-based criteria may fail to capture the dynamic environment, causing\nredundant HOs or HO failures. To address this issue and motivated by the\nunderutilization of sensing information in conventional HO mechanisms, we\npropose a novel HO activation criterion for drone systems that integrates both\nsensing parameters provided by integrated sensing and communication (ISAC)\nsignals and RSRP. First, we construct an ISAC signal model tailored for\nlow-altitude scenarios and derive the Cram\\'er--Rao lower bound for sensing\ndistance estimation. Subsequently, we propose a novel joint HO criterion that\nextends the conventional RSRP-based method by integrating sensing information\nfrom ISAC signals, enabling more reliable HOs in dynamic drone environments.\nSimulation results show that the joint HO criterion outperforms the baseline\nRSRP-based criterion under different signal-to-noise ratio (SNR) and sensing\npilot ratio conditions. Particularly, when the SNR exceeds 0dB and the sensing\npilot ratio is 20%, the proposed joint HO criterion reduces the average HO\nregion length by 75.20% and improves the activation probability by 76.31%.",
    "pdf_url": "http://arxiv.org/pdf/2505.16350v2",
    "published": "2025-05-22T08:01:52+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16349v1",
    "title": "Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature Summarization",
    "authors": [
      "Pierre Achkar",
      "Tim Gollub",
      "Martin Potthast"
    ],
    "abstract": "The exponential growth of scientific publications has made it increasingly\ndifficult for researchers to stay updated and synthesize knowledge effectively.\nThis paper presents XSum, a modular pipeline for multi-document summarization\n(MDS) in the scientific domain using Retrieval-Augmented Generation (RAG). The\npipeline includes two core components: a question-generation module and an\neditor module. The question-generation module dynamically generates questions\nadapted to the input papers, ensuring the retrieval of relevant and accurate\ninformation. The editor module synthesizes the retrieved content into coherent\nand well-structured summaries that adhere to academic standards for proper\ncitation. Evaluated on the SurveySum dataset, XSum demonstrates strong\nperformance, achieving considerable improvements in metrics such as CheckEval,\nG-Eval and Ref-F1 compared to existing approaches. This work provides a\ntransparent, adaptable framework for scientific summarization with potential\napplications in a wide range of domains. Code available at\nhttps://github.com/webis-de/scolia25-xsum",
    "pdf_url": "http://arxiv.org/pdf/2505.16349v1",
    "published": "2025-05-22T08:00:59+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16348v1",
    "title": "Embodied Agents Meet Personalization: Exploring Memory Utilization for Personalized Assistance",
    "authors": [
      "Taeyoon Kwon",
      "Dongwook Choi",
      "Sunghwan Kim",
      "Hyojun Kim",
      "Seungjun Moon",
      "Beong-woo Kwak",
      "Kuan-Hao Huang",
      "Jinyoung Yeo"
    ],
    "abstract": "Embodied agents empowered by large language models (LLMs) have shown strong\nperformance in household object rearrangement tasks. However, these tasks\nprimarily focus on single-turn interactions with simplified instructions, which\ndo not truly reflect the challenges of providing meaningful assistance to\nusers. To provide personalized assistance, embodied agents must understand the\nunique semantics that users assign to the physical world (e.g., favorite cup,\nbreakfast routine) by leveraging prior interaction history to interpret\ndynamic, real-world instructions. Yet, the effectiveness of embodied agents in\nutilizing memory for personalized assistance remains largely underexplored. To\naddress this gap, we present MEMENTO, a personalized embodied agent evaluation\nframework designed to comprehensively assess memory utilization capabilities to\nprovide personalized assistance. Our framework consists of a two-stage memory\nevaluation process design that enables quantifying the impact of memory\nutilization on task performance. This process enables the evaluation of agents'\nunderstanding of personalized knowledge in object rearrangement tasks by\nfocusing on its role in goal interpretation: (1) the ability to identify target\nobjects based on personal meaning (object semantics), and (2) the ability to\ninfer object-location configurations from consistent user patterns, such as\nroutines (user patterns). Our experiments across various LLMs reveal\nsignificant limitations in memory utilization, with even frontier models like\nGPT-4o experiencing a 30.5% performance drop when required to reference\nmultiple memories, particularly in tasks involving user patterns. These\nfindings, along with our detailed analyses and case studies, provide valuable\ninsights for future research in developing more effective personalized embodied\nagents. Project website: https://connoriginal.github.io/MEMENTO",
    "pdf_url": "http://arxiv.org/pdf/2505.16348v1",
    "published": "2025-05-22T08:00:10+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16347v1",
    "title": "Graph Attention Network for Optimal User Association in Wireless Networks",
    "authors": [
      "Javad Mirzaei",
      "Jeebak Mitra",
      "Gwenael Poitau"
    ],
    "abstract": "With increased 5G deployments, network densification is higher than ever to\nsupport the exponentially high throughput requirements. However, this has meant\na significant increase in energy consumption, leading to higher operational\nexpenditure (OpEx) for network operators creating an acute need for\nimprovements in network energy savings (NES). A key determinant of operational\nefficacy in cellular networks is the user association (UA) policy, as it\naffects critical aspects like spectral efficiency, load balancing etc. and\ntherefore impacts the overall energy consumption of the network directly.\nFurthermore, with cellular network topologies lending themselves well to\ngraphical abstractions, use of graphs in network optimization has gained\nsignificant prominence. In this work, we propose and analyze a graphical\nabstraction based optimization for UA in cellular networks to improve NES by\ndetermining when energy saving features like cell switch off can be activated.\nA comparison with legacy approaches establishes the superiority of the proposed\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2505.16347v1",
    "published": "2025-05-22T08:00:01+00:00",
    "categories": [
      "cs.IT",
      "cs.LG",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16346v2",
    "title": "How to keep pushing ML accelerator performance? Know your rooflines!",
    "authors": [
      "Marian Verhelst",
      "Luca Benini",
      "Naveen Verma"
    ],
    "abstract": "The rapidly growing importance of Machine Learning (ML) applications, coupled\nwith their ever-increasing model size and inference energy footprint, has\ncreated a strong need for specialized ML hardware architectures. Numerous ML\naccelerators have been explored and implemented, primarily to increase\ntask-level throughput per unit area and reduce task-level energy consumption.\nThis paper surveys key trends toward these objectives for more efficient ML\naccelerators and provides a unifying framework to understand how compute and\nmemory technologies/architectures interact to enhance system-level efficiency\nand performance. To achieve this, the paper introduces an enhanced version of\nthe roofline model and applies it to ML accelerators as an effective tool for\nunderstanding where various execution regimes fall within roofline bounds and\nhow to maximize performance and efficiency under the rooline. Key concepts are\nillustrated with examples from state-of-the-art designs, with a view towards\nopen research opportunities to further advance accelerator performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.16346v2",
    "published": "2025-05-22T07:59:26+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16345v1",
    "title": "Convergence analysis of GMRES applied to Helmholtz problems near resonances",
    "authors": [
      "Victorita Dolean",
      "Pierre Marchand",
      "Axel Modave",
      "Timothée Raynaud"
    ],
    "abstract": "In this work we study how the convergence rate of GMRES is influenced by the\nproperties of linear systems arising from Helmholtz problems near resonances or\nquasi-resonances. We extend an existing convergence bound to demonstrate that\nthe approximation of small eigenvalues by harmonic Ritz values plays a key role\nin convergence behavior. Next, we analyze the impact of deflation using\ncarefully selected vectors and combine this with a Complex Shifted Laplacian\npreconditioner. Finally, we apply these tools to two numerical examples near\n(quasi-)resonant frequencies, using them to explain how the convergence rate\nevolves.",
    "pdf_url": "http://arxiv.org/pdf/2505.16345v1",
    "published": "2025-05-22T07:59:18+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65F10 (Primary), 65N22, 65N30 (Secondary)"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16344v1",
    "title": "Half-Marker Codes for Deletion Channels with Applications in DNA Storage",
    "authors": [
      "Javad Haghighat",
      "Tolga M. Duman"
    ],
    "abstract": "DNA storage systems face significant challenges, including insertion,\ndeletion, and substitution (IDS) errors. Therefore, designing effective\nsynchronization codes, i.e., codes capable of correcting IDS errors, is\nessential for DNA storage systems. Marker codes are a favorable choice for this\npurpose. In this paper, we extend the notion of marker codes by making the\nfollowing key observation. Since each DNA base is equivalent to a 2-bit storage\nunit, one bit can be reserved for synchronization, while the other is dedicated\nto data transmission. Using this observation, we propose a new class of marker\ncodes, which we refer to as half-marker codes. We demonstrate that this\nextension has the potential to significantly increase the mutual information\nbetween the input symbols and the soft outputs of an IDS channel modeling a DNA\nstorage system. Specifically, through examples, we show that when concatenated\nwith an outer error-correcting code, half-marker codes outperform standard\nmarker codes and significantly reduce the end-to-end bit error rate of the\nsystem.",
    "pdf_url": "http://arxiv.org/pdf/2505.16344v1",
    "published": "2025-05-22T07:58:18+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16343v2",
    "title": "Neural Field Equations with random data",
    "authors": [
      "Daniele Avitabile",
      "Francesca Cavallini",
      "Svetlana Dubinkina",
      "Gabriel J. Lord"
    ],
    "abstract": "We study neural field equations, which are prototypical models of large-scale\ncortical activity, subject to random data. We view this spatially-extended,\nnonlocal evolution equation as a Cauchy problem on abstract Banach spaces, with\nrandomness in the synaptic kernel, firing rate function, external stimuli, and\ninitial conditions. We determine conditions on the random data that guarantee\nexistence, uniqueness, and measurability of the solution in an appropriate\nBanach space, and examine the regularity of the solution in relation to the\nregularity of the inputs. We present results for linear and nonlinear neural\nfields, and for the two most common functional setups in the numerical analysis\nof this problem. In addition to the continuous problem, we analyse in abstract\nform neural fields that have been spatially discretised, setting the\nfoundations for analysing uncertainty quantification (UQ) schemes.",
    "pdf_url": "http://arxiv.org/pdf/2505.16343v2",
    "published": "2025-05-22T07:58:06+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.DS",
      "math.PR",
      "nlin.PS"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16342v1",
    "title": "Cosmological Unstraightening",
    "authors": [
      "Nima Rasekh"
    ],
    "abstract": "The unstraightening construction due to Lurie establishes an equivalence\nbetween presheaves and fibrations, using one prominent model of\n$(\\infty,1)$-categories, namely quasi-categories. In this work we generalize\nthis result by proving that for all $\\infty$-cosmoi of $(\\infty,1)$-categories\nin the sense of Riehl and Verity, which includes quasi-categories but also\ncomplete Segal spaces or $1$-complicial sets, their corresponding notions of\nfibrations and presheaves are biequivalent $\\infty$-cosmoi via a natural\nzig-zag of cosmological biequivalences. The major idea that makes this possible\nis a lift of the quasi-categorical unstraightening construction to a\ncosmological biequivalence.",
    "pdf_url": "http://arxiv.org/pdf/2505.16342v1",
    "published": "2025-05-22T07:57:36+00:00",
    "categories": [
      "math.CT",
      "18N60, 18N40, 18N50, 18N45"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16341v3",
    "title": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning",
    "authors": [
      "Yaxin Hou",
      "Yuheng Jia"
    ],
    "abstract": "This paper studies the long-tailed semi-supervised learning (LTSSL) with\ndistribution mismatch, where the class distribution of the labeled training\ndata follows a long-tailed distribution and mismatches with that of the\nunlabeled training data. Most existing methods introduce auxiliary classifiers\n(experts) to model various unlabeled data distributions and produce\npseudo-labels, but the expertises of various experts are not fully utilized. We\nobserve that different experts are good at predicting different intervals of\nsamples, e.g., long-tailed expert is skilled in samples located in the head\ninterval and uniform expert excels in samples located in the medium interval.\nTherefore, we propose a dynamic expert assignment module that can estimate the\nclass membership (i.e., head, medium, or tail class) of samples, and\ndynamically assigns suitable expert to each sample based on the estimated\nmembership to produce high-quality pseudo-label in the training phase and\nproduce prediction in the testing phase. We also theoretically reveal that\nintegrating different experts' strengths will lead to a smaller generalization\nerror bound. Moreover, we find that the deeper features are more biased toward\nthe head class but with more discriminative ability, while the shallower\nfeatures are less biased but also with less discriminative ability. We,\ntherefore, propose a multi-depth feature fusion module to utilize different\ndepth features to mitigate the model bias. Our method demonstrates its\neffectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT,\nand SVHN-LT datasets across various settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16341v3",
    "published": "2025-05-22T07:56:44+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16340v1",
    "title": "Improving Chemical Understanding of LLMs via SMILES Parsing",
    "authors": [
      "Yunhui Jang",
      "Jaehyung Kim",
      "Sungsoo Ahn"
    ],
    "abstract": "Large language models (LLMs) are increasingly recognized as powerful tools\nfor scientific discovery, particularly in molecular science. A fundamental\nrequirement for these models is the ability to accurately understand molecular\nstructures, commonly encoded in the SMILES representation. However, current\nLLMs struggle to interpret SMILES, even failing to carry out basic tasks such\nas counting molecular rings. To address this limitation, we introduce CLEANMOL,\na novel framework that formulates SMILES parsing into a suite of clean and\ndeterministic tasks explicitly designed to promote graph-level molecular\ncomprehension. These tasks span from subgraph matching to global graph\nmatching, providing structured supervision aligned with molecular structural\nproperties. We construct a molecular pretraining dataset with adaptive\ndifficulty scoring and pre-train open-source LLMs on these tasks. Our results\nshow that CLEANMOL not only enhances structural comprehension but also achieves\nthe best or competes with the baseline on the Mol-Instructions benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2505.16340v1",
    "published": "2025-05-22T07:54:39+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16339v1",
    "title": "Rethinking Code Review Workflows with LLM Assistance: An Empirical Study",
    "authors": [
      "Fannar Steinn Aðalsteinsson",
      "Björn Borgar Magnússon",
      "Mislav Milicevic",
      "Adam Nirving Davidsson",
      "Chih-Hong Cheng"
    ],
    "abstract": "Code reviews are a critical yet time-consuming aspect of modern software\ndevelopment, increasingly challenged by growing system complexity and the\ndemand for faster delivery. This paper presents a study conducted at\nWirelessCar Sweden AB, combining an exploratory field study of current code\nreview practices with a field experiment involving two variations of an\nLLM-assisted code review tool. The field study identifies key challenges in\ntraditional code reviews, including frequent context switching, insufficient\ncontextual information, and highlights both opportunities (e.g., automatic\nsummarization of complex pull requests) and concerns (e.g., false positives and\ntrust issues) in using LLMs. In the field experiment, we developed two\nprototype variations: one offering LLM-generated reviews upfront and the other\nenabling on-demand interaction. Both utilize a semantic search pipeline based\non retrieval-augmented generation to assemble relevant contextual information\nfor the review, thereby tackling the uncovered challenges. Developers evaluated\nboth variations in real-world settings: AI-led reviews are overall more\npreferred, while still being conditional on the reviewers' familiarity with the\ncode base, as well as on the severity of the pull request.",
    "pdf_url": "http://arxiv.org/pdf/2505.16339v1",
    "published": "2025-05-22T07:54:07+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16338v1",
    "title": "Fusion of Foundation and Vision Transformer Model Features for Dermatoscopic Image Classification",
    "authors": [
      "Amirreza Mahbod",
      "Rupert Ecker",
      "Ramona Woitek"
    ],
    "abstract": "Accurate classification of skin lesions from dermatoscopic images is\nessential for diagnosis and treatment of skin cancer. In this study, we\ninvestigate the utility of a dermatology-specific foundation model, PanDerm, in\ncomparison with two Vision Transformer (ViT) architectures (ViT base and Swin\nTransformer V2 base) for the task of skin lesion classification. Using frozen\nfeatures extracted from PanDerm, we apply non-linear probing with three\ndifferent classifiers, namely, multi-layer perceptron (MLP), XGBoost, and\nTabNet. For the ViT-based models, we perform full fine-tuning to optimize\nclassification performance. Our experiments on the HAM10000 and MSKCC datasets\ndemonstrate that the PanDerm-based MLP model performs comparably to the\nfine-tuned Swin transformer model, while fusion of PanDerm and Swin Transformer\npredictions leads to further performance improvements. Future work will explore\nadditional foundation models, fine-tuning strategies, and advanced fusion\ntechniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.16338v1",
    "published": "2025-05-22T07:53:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16337v1",
    "title": "Urban transport systems shape experiences of social segregation",
    "authors": [
      "Yitao Yang",
      "Erjian Liu",
      "Bin Jia",
      "Ed Manley"
    ],
    "abstract": "Mobility is a fundamental feature of human life, and through it our\ninteractions with the world and people around us generate complex and\nconsequential social phenomena. Social segregation, one such process, is\nincreasingly acknowledged as a product of one's entire lived experience rather\nthan mere residential location. Increasingly granular sources of data on human\nmobility have evidenced how segregation persists outside the home, in\nworkplaces, cafes, and on the street. Yet there remains only a weak evidential\nlink between the production of social segregation and urban policy. This study\naddresses this gap through an assessment of the role of the urban\ntransportation systems in shaping social segregation. Using city-scale GPS\nmobility data and a novel probabilistic mobility framework, we establish social\ninteractions at the scale of transportation infrastructure, by rail and bus\nservice segment, individual roads, and city blocks. The outcomes show how\nsocial segregation is more than a single process in space, but varying by time\nof day, urban design and structure, and service design. These findings\nreconceptualize segregation as a product of likely encounters during one's\ndaily mobility practice. We then extend these findings through exploratory\nsimulations, highlighting how transportation policy to promote sustainable\ntransport may have potentially unforeseen impacts on segregation. The study\nunderscores that to understand social segregation and achieve positive social\nchange urban policymakers must consider the broadest impacts of their\ninterventions and seek to understand their impact on the daily lived experience\nof their citizens.",
    "pdf_url": "http://arxiv.org/pdf/2505.16337v1",
    "published": "2025-05-22T07:53:05+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16336v1",
    "title": "The Role of Intangible Investment in Predicting Stock Returns: Six Decades of Evidence",
    "authors": [
      "Lin Li"
    ],
    "abstract": "Using an intangible intensity factor that is orthogonal to the Fama--French\nfactors, we compare the role of intangible investment in predicting stock\nreturns over the periods 1963--1992 and 1993--2022. For 1963--1992, intangible\ninvestment is weak in predicting stock returns, but for 1993--2022, the\npredictive power of intangible investment becomes very strong. Intangible\ninvestment has a significant impact not only on the MTB ratio (Fama--French\nhigh minus low [HML] factor) but also on operating profitability (OP)\n(Fama--French robust minus weak [RMW] factor) when forecasting stock returns\nfrom 1993 to 2022. For intangible asset-intensive firms, intangible investment\nis the main predictor of stock returns, rather than MTB ratio and\nprofitability. Our evidence suggests that intangible investment has become an\nimportant factor in explaining stock returns over time, independent of other\nfactors such as profitability and MTB ratio.",
    "pdf_url": "http://arxiv.org/pdf/2505.16336v1",
    "published": "2025-05-22T07:52:09+00:00",
    "categories": [
      "q-fin.PR"
    ],
    "primary_category": "q-fin.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17146v1",
    "title": "Proof-of-Principle Experiment on a Displacement-Noise-Free Neutron Interferometer for Gravitational Wave Detection",
    "authors": [
      "Shoki Iwaguchi",
      "Takuhiro Fujiie",
      "Taro Nambu",
      "Masaaki Kitaguchi",
      "Yutaka Yamagata",
      "Kenji Mishima",
      "Atsushi Nishizawa",
      "Tomohiro Ishikawa",
      "Kenji Tsuji",
      "Kurumi Umemura",
      "Kazuhiro Kobayashi",
      "Takafumi Onishi",
      "Keiko Kokeyama",
      "Hirohiko Shimizu",
      "Yuta Michimura",
      "Seiji Kawamura"
    ],
    "abstract": "The displacement-noise-free interferometer (DFI) is designed to eliminate all\ndisplacement-induced noise while retaining sensitivity to gravitational wave\n(GW) signals. Ground-based DFIs suffer from physical arm-length limitations,\nresulting in poor sensitivity at frequencies below 1 kHz. To address this,\nprevious research introduced a neutron-based DFI, which replaces laser light\nwith neutrons and achieves exceptional sensitivity down to a few hertz. In this\nstudy, we conducted a proof-of-principle experiment using a pulsed neutron\nsource at the Japan Proton Accelerator Research Complex (J- PARC). Despite\npractical constraints that led to deviations from the ideal experimental\ndesign, we optimized the setup and developed a novel analysis method that\nsuccessfully cancels displacement noise while preserving simulated GW signals.\nThis work presents the first successful demonstration of a neutron DFI and a\nneutron interferometer for GW detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.17146v1",
    "published": "2025-05-22T07:50:34+00:00",
    "categories": [
      "physics.ins-det",
      "astro-ph.IM",
      "gr-qc"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.16335v1",
    "title": "FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design",
    "authors": [
      "Renjie Wei",
      "Songqiang Xu",
      "Qingyu Guo",
      "Meng Li"
    ],
    "abstract": "Visual autoregressive (VAR) modeling has marked a paradigm shift in image\ngeneration from next-token prediction to next-scale prediction. VAR predicts a\nset of tokens at each step from coarse to fine scale, leading to better image\nquality and faster inference speed compared to existing diffusion models.\nHowever, the large parameter size and computation cost hinder its deployment on\nedge devices. To reduce the memory and computation cost, we propose FPQVAR, an\nefficient post-training floating-point (FP) quantization framework for VAR\nfeaturing algorithm and hardware co-design. At the algorithm level, we first\nidentify the challenges of quantizing VAR. To address them, we propose Dual\nFormat Quantization for the highly imbalanced input activation. We further\npropose Group-wise Hadamard Transformation and GHT-Aware Learnable\nTransformation to address the time-varying outlier channels. At the hardware\nlevel, we design the first low-bit FP quantizer and multiplier with lookup\ntables on FPGA and propose the first FPGA-based VAR accelerator featuring\nlow-bit FP computation and an elaborate two-level pipeline. Extensive\nexperiments show that compared to the state-of-the-art quantization method, our\nproposed FPQVAR significantly improves Fr\\'echet Inception Distance (FID) from\n10.83 to 3.58, Inception Score (IS) from 175.9 to 241.5 under 4-bit\nquantization. FPQVAR also significantly improves the performance of 6-bit\nquantized VAR, bringing it on par with the FP16 model. Our accelerator on\nAMD-Xilinx VCK190 FPGA achieves a throughput of 1.1 image/s, which is 3.1x\nhigher than the integer-based accelerator. It also demonstrates 3.6x and 2.8x\nhigher energy efficiency compared to the integer-based accelerator and GPU\nbaseline, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.16335v1",
    "published": "2025-05-22T07:47:51+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16334v2",
    "title": "Panoptic Captioning: Seeking An Equivalency Bridge for Image and Text",
    "authors": [
      "Kun-Yu Lin",
      "Hongjun Wang",
      "Weining Ren",
      "Kai Han"
    ],
    "abstract": "This work introduces panoptic captioning, a novel task striving to seek the\nminimum text equivalence of images. We take the first step towards panoptic\ncaptioning by formulating it as a task of generating a comprehensive textual\ndescription for an image, which encapsulates all entities, their respective\nlocations and attributes, relationships among entities, as well as global image\nstate. Through an extensive evaluation, our work reveals that state-of-the-art\nMulti-modal Large Language Models (MLLMs) have limited performance in solving\npanoptic captioning. To address this, we propose an effective data engine named\nPancapEngine to produce high-quality data and a novel method named PancapChain\nto improve panoptic captioning. Specifically, our PancapEngine first detects\ndiverse categories of entities in images by an elaborate detection suite, and\nthen generates required panoptic captions using entity-aware prompts.\nAdditionally, our PancapChain explicitly decouples the challenging panoptic\ncaptioning task into multiple stages and generates panoptic captions step by\nstep. More importantly, we contribute a comprehensive metric named PancapScore\nand a human-curated test set for reliable model evaluation. Experiments show\nthat our PancapChain-13B model can beat state-of-the-art open-source MLLMs like\nInternVL-2.5-78B and even surpass proprietary models like GPT-4o and\nGemini-2.0-Pro, demonstrating the effectiveness of our data engine and method.\nProject page: https://visual-ai.github.io/pancap/",
    "pdf_url": "http://arxiv.org/pdf/2505.16334v2",
    "published": "2025-05-22T07:44:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16333v2",
    "title": "Understanding Differential Transformer Unchains Pretrained Self-Attentions",
    "authors": [
      "Chaerin Kong",
      "Jiho Jang",
      "Nojun Kwak"
    ],
    "abstract": "Differential Transformer has recently gained significant attention for its\nimpressive empirical performance, often attributed to its ability to perform\nnoise canceled attention. However, precisely how differential attention\nachieves its empirical benefits remains poorly understood. Moreover,\nDifferential Transformer architecture demands large-scale training from\nscratch, hindering utilization of open pretrained weights. In this work, we\nconduct an in-depth investigation of Differential Transformer, uncovering three\nkey factors behind its success: (1) enhanced expressivity via negative\nattention, (2) reduced redundancy among attention heads, and (3) improved\nlearning dynamics. Based on these findings, we propose DEX, a novel method to\nefficiently integrate the advantages of differential attention into pretrained\nlanguage models. By reusing the softmax attention scores and adding a\nlightweight differential operation on the output value matrix, DEX effectively\nincorporates the key advantages of differential attention while remaining\nlightweight in both training and inference. Evaluations confirm that DEX\nsubstantially improves the pretrained LLMs across diverse benchmarks, achieving\nsignificant performance gains with minimal adaptation data (< 0.01%).",
    "pdf_url": "http://arxiv.org/pdf/2505.16333v2",
    "published": "2025-05-22T07:42:16+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16332v2",
    "title": "Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing",
    "authors": [
      "Zhehui Wang",
      "Benjamin Chen Ming Choong",
      "Tian Huang",
      "Daniel Gerlinghoff",
      "Rick Siow Mong Goh",
      "Cheng Liu",
      "Tao Luo"
    ],
    "abstract": "Quantum optimization is the most mature quantum computing technology to date,\nproviding a promising approach towards efficiently solving complex\ncombinatorial problems. Methods such as adiabatic quantum computing (AQC) have\nbeen employed in recent years on important optimization problems across various\ndomains. In deep learning, deep neural networks (DNN) have reached immense\nsizes to support new predictive capabilities. Optimization of large-scale\nmodels is critical for sustainable deployment, but becomes increasingly\nchallenging with ever-growing model sizes and complexity. While quantum\noptimization is suitable for solving complex problems, its application to DNN\noptimization is not straightforward, requiring thorough reformulation for\ncompatibility with commercially available quantum devices. In this work, we\nexplore the potential of adopting AQC for fine-grained pruning-quantization of\nconvolutional neural networks. We rework established heuristics to formulate\nmodel compression as a quadratic unconstrained binary optimization (QUBO)\nproblem, and assess the solution space offered by commercial quantum annealing\ndevices. Through our exploratory efforts of reformulation, we demonstrate that\nAQC can achieve effective compression of practical DNN models. Experiments\ndemonstrate that adiabatic quantum computing (AQC) not only outperforms\nclassical algorithms like genetic algorithms and reinforcement learning in\nterms of time efficiency but also excels at identifying global optima.",
    "pdf_url": "http://arxiv.org/pdf/2505.16332v2",
    "published": "2025-05-22T07:40:23+00:00",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16331v1",
    "title": "Generalized bulk-interface correspondence for non-quantized spin transport",
    "authors": [
      "Jiayu Qiu",
      "Hai Zhang"
    ],
    "abstract": "This paper establishes a rigorous mathematical framework for a generalized\nbulk-interface correspondence (BIC) in electronic systems with possibly\nnonconserved spin charge, where the Hamiltonian and spin operator do not\ncommute. We first introduce the bulk spin conductance as a character of the\nbulk medium, which is defined as a potential-current correlation function and\nis not quantized if the spin charge is nonconserved. Then we establish the\nprinciple of BIC, which states that the difference of bulk spin conductances\nacross an interface equals the sum of two quantities associated with the spin\ntransport along the interface: the spin-drift conductance, which captures spin\ntransport carried by interface modes, and the spin-torque conductance, which\naccounts for spin generation near the interface due to the non-conservation of\nspin. Furthermore, when the spin charge is conserved, our result recovers the\nexisting BIC based on the spin Chern number or Fu-Kane-Mele $\\mathbb{Z}_2$\nindex. Our findings demonstrate that the principle of BIC is not restricted to\nsystems with quantized characters and provides new insights into spin transport\nphenomena.",
    "pdf_url": "http://arxiv.org/pdf/2505.16331v1",
    "published": "2025-05-22T07:39:37+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.20311v1",
    "title": "The EU AI Act, Stakeholder Needs, and Explainable AI: Aligning Regulatory Compliance in a Clinical Decision Support System",
    "authors": [
      "Anton Hummel",
      "Håkan Burden",
      "Susanne Stenberg",
      "Jan-Philipp Steghöfer",
      "Niklas Kühl"
    ],
    "abstract": "Explainable AI (XAI) is a promising solution to ensure compliance with the EU\nAI Act, the first multi-national regulation for AI. XAI aims to enhance\ntransparency and human oversight of AI systems, particularly ``black-box\nmodels'', which are criticized as incomprehensible. However, the discourse\naround the main stakeholders in the AI Act and XAI appears disconnected. While\nXAI prioritizes the end user's needs as the primary goal, the AI Act focuses on\nthe obligations of the provider and deployer of the AI system. We aim to bridge\nthis divide and provide guidance on how these two worlds are related. By\nfostering an interdisciplinary discussion in a cross-functional team with XAI,\nAI Act, legal, and requirements engineering experts, we walk through the steps\nnecessary to analyze an AI-based clinical decision support system to clarify\nthe end-user needs and assess AI Act applicability. By analyzing our justified\nunderstanding using an AI system under development as a case, we show that XAI\ntechniques can fill a gap between stakeholder needs and the requirements of the\nAI Act. We look at the similarities and contrasts between the legal\nrequirements and the needs of stakeholders. In doing so, we encourage\nresearchers and practitioners from the XAI community to reflect on their role\ntowards the AI Act by achieving a mutual understanding of the implications of\nXAI and the AI Act within different disciplines.",
    "pdf_url": "http://arxiv.org/pdf/2505.20311v1",
    "published": "2025-05-22T07:39:04+00:00",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16330v1",
    "title": "SC4ANM: Identifying Optimal Section Combinations for Automated Novelty Prediction in Academic Papers",
    "authors": [
      "Wenqing Wu",
      "Chengzhi Zhang",
      "Tong Bao",
      "Yi Zhao"
    ],
    "abstract": "Novelty is a core component of academic papers, and there are multiple\nperspectives on the assessment of novelty. Existing methods often focus on word\nor entity combinations, which provide limited insights. The content related to\na paper's novelty is typically distributed across different core sections,\ne.g., Introduction, Methodology and Results. Therefore, exploring the optimal\ncombination of sections for evaluating the novelty of a paper is important for\nadvancing automated novelty assessment. In this paper, we utilize different\ncombinations of sections from academic papers as inputs to drive language\nmodels to predict novelty scores. We then analyze the results to determine the\noptimal section combinations for novelty score prediction. We first employ\nnatural language processing techniques to identify the sectional structure of\nacademic papers, categorizing them into introduction, methods, results, and\ndiscussion (IMRaD). Subsequently, we used different combinations of these\nsections (e.g., introduction and methods) as inputs for pretrained language\nmodels (PLMs) and large language models (LLMs), employing novelty scores\nprovided by human expert reviewers as ground truth labels to obtain prediction\nresults. The results indicate that using introduction, results and discussion\nis most appropriate for assessing the novelty of a paper, while the use of the\nentire text does not yield significant results. Furthermore, based on the\nresults of the PLMs and LLMs, the introduction and results appear to be the\nmost important section for the task of novelty score prediction. The code and\ndataset for this paper can be accessed at\nhttps://github.com/njust-winchy/SC4ANM.",
    "pdf_url": "http://arxiv.org/pdf/2505.16330v1",
    "published": "2025-05-22T07:34:59+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16329v1",
    "title": "Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping",
    "authors": [
      "Simone Bombari",
      "Inbar Seroussi",
      "Marco Mondelli"
    ],
    "abstract": "Differentially private (DP) linear regression has received significant\nattention in the recent theoretical literature, with several works aimed at\nobtaining improved error rates. A common approach is to set the clipping\nconstant much larger than the expected norm of the per-sample gradients. While\nsimplifying the analysis, this is however in sharp contrast with what empirical\nevidence suggests to optimize performance. Our work bridges this gap between\ntheory and practice: we provide sharper rates for DP stochastic gradient\ndescent (DP-SGD) by crucially operating in a regime where clipping happens\nfrequently. Specifically, we consider the setting where the data is\nmultivariate Gaussian, the number of training samples $n$ is proportional to\nthe input dimension $d$, and the algorithm guarantees constant-order zero\nconcentrated DP. Our method relies on establishing a deterministic equivalent\nfor the trajectory of DP-SGD in terms of a family of ordinary differential\nequations (ODEs). As a consequence, the risk of DP-SGD is bounded between two\nODEs, with upper and lower bounds matching for isotropic data. By studying\nthese ODEs when $n / d$ is large enough, we demonstrate the optimality of\naggressive clipping, and we uncover the benefits of decaying learning rate and\nprivate noise scheduling.",
    "pdf_url": "http://arxiv.org/pdf/2505.16329v1",
    "published": "2025-05-22T07:34:27+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16328v2",
    "title": "Jet Substructure Probe on Scalar Leptoquark Models via Top Polarization",
    "authors": [
      "Anupam Ghosh",
      "Partha Konar",
      "Tousik Samui",
      "Ritesh K. Singh"
    ],
    "abstract": "The study of leptoquarks and their couplings to fermions with different\nchiralities provides a powerful tool for distinguishing among different\nleptoquark models. As a case study, we focus on two specific third-generation\nscalar leptoquark models, $S_3$ and $R_2$, which differ in their electroweak\nquantum numbers and chiral structures of couplings to the top quark, leading to\ndistinct top-quark polarization states. To enhance the efficacy of the\nanalysis, we employ jet substructure techniques like Soft Drop,\n$N$-subjettiness, and our custom $b$-tagging method, along with other event\nvariables. The analysis has been performed using both fixed radius and dynamic\nradius jet clustering algorithms. A multivariate analysis using a boosted\ndecision tree (BDT) is performed to isolate signal from the Standard Model\nbackground. For a leptoquark mass of 1250 GeV, the analysis achieves a signal\nsignificance of up to $5.3\\,\\sigma$ at the 14 TeV HL-LHC. Furthermore, a\n$CL_s$-based profile likelihood estimator is applied to polarization-sensitive\nvariables to discriminate between the two models. To enhance separation between\nthe two models, an additional BDT classifier score is obtained by training a\nBDT network to distinguish between the $S_3$ and $R_2$ models. In the chosen\nsignal region, the BDT classifier score provides a separation score of up to\n$3.2\\,\\sigma$, outperforming traditional variables such as $E_b/E_t$ and\n$\\cos\\theta_b$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16328v2",
    "published": "2025-05-22T07:33:44+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16327v1",
    "title": "Cooperative NOMA Meets Emerging Technologies: A Survey for Next-Generation Wireless Networks",
    "authors": [
      "Mahmoud M. Salim",
      "Suhail I. Al-Dharrab",
      "Daniel Benevides Da Costa",
      "Ali H. Muqaibel"
    ],
    "abstract": "The emerging demands of sixth-generation wireless networks, such as\nultra-connectivity, native intelligence, and cross-domain convergence, are\nbringing renewed focus to cooperative non-orthogonal multiple access (C-NOMA)\nas a fundamental enabler of scalable, efficient, and intelligent communication\nsystems. C-NOMA builds on the core benefits of NOMA by leveraging user\ncooperation and relay strategies to enhance spectral efficiency, coverage, and\nenergy performance. This article presents a unified and forward-looking survey\non the integration of C-NOMA with key enabling technologies, including radio\nfrequency energy harvesting, cognitive radio networks, reconfigurable\nintelligent surfaces, space-air-ground integrated networks, and integrated\nsensing and communication-assisted semantic communication. Foundational\nprinciples and relaying protocols are first introduced to establish the\ntechnical relevance of C-NOMA. Then, a focused investigation is conducted into\nprotocol-level synergies, architectural models, and deployment strategies\nacross these technologies. Beyond integration, this article emphasizes the\norchestration of C-NOMA across future application domains such as digital\ntwins, extended reality, and e-health. In addition, it provides an extensive\nand in-depth review of recent literature, categorized by relaying schemes,\nsystem models, performance metrics, and optimization paradigms, including\nmodel-based, heuristic, and AI-driven approaches. Finally, open challenges and\nfuture research directions are outlined, spanning standardization, security,\nand cross-layer design, positioning C-NOMA as a key pillar of intelligent\nnext-generation network architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16327v1",
    "published": "2025-05-22T07:32:48+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16326v2",
    "title": "ChemMLLM: Chemical Multimodal Large Language Model",
    "authors": [
      "Qian Tan",
      "Dongzhan Zhou",
      "Peng Xia",
      "Wanhao Liu",
      "Wanli Ouyang",
      "Lei Bai",
      "Yuqiang Li",
      "Tianfan Fu"
    ],
    "abstract": "Multimodal large language models (MLLMs) have made impressive progress in\nmany applications in recent years. However, chemical MLLMs that can handle\ncross-modal understanding and generation remain underexplored. To fill this\ngap, we propose ChemMLLM, a unified chemical multimodal large language model\nfor molecule understanding and generation. Also, we design five multimodal\ntasks across text, molecular SMILES strings, and image, and curate the\ndatasets. We benchmark ChemMLLM against a range of general leading MLLMs and\nChemical LLMs on these tasks. Experimental results show that ChemMLLM achieves\nsuperior performance across all evaluated tasks. For example, in molecule image\noptimization task, ChemMLLM outperforms the best baseline (GPT-4o) by 116.75\\%\n(4.27 vs 1.97 property improvement). The code is publicly available at\nhttps://github.com/bbsbz/ChemMLLM.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.16326v2",
    "published": "2025-05-22T07:32:17+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16325v1",
    "title": "CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation",
    "authors": [
      "Yuyang Jiang",
      "Chacha Chen",
      "Shengyuan Wang",
      "Feng Li",
      "Zecong Tang",
      "Benjamin M. Mervak",
      "Lydia Chelala",
      "Christopher M Straus",
      "Reve Chahine",
      "Samuel G. Armato III",
      "Chenhao Tan"
    ],
    "abstract": "Existing metrics often lack the granularity and interpretability to capture\nnuanced clinical differences between candidate and ground-truth radiology\nreports, resulting in suboptimal evaluation. We introduce a Clinically-grounded\ntabular framework with Expert-curated labels and Attribute-level comparison for\nRadiology report evaluation (CLEAR). CLEAR not only examines whether a report\ncan accurately identify the presence or absence of medical conditions, but also\nassesses whether it can precisely describe each positively identified condition\nacross five key attributes: first occurrence, change, severity, descriptive\nlocation, and recommendation. Compared to prior works, CLEAR's\nmulti-dimensional, attribute-level outputs enable a more comprehensive and\nclinically interpretable evaluation of report quality. Additionally, to measure\nthe clinical alignment of CLEAR, we collaborate with five board-certified\nradiologists to develop CLEAR-Bench, a dataset of 100 chest X-ray reports from\nMIMIC-CXR, annotated across 6 curated attributes and 13 CheXpert conditions.\nOur experiments show that CLEAR achieves high accuracy in extracting clinical\nattributes and provides automated metrics that are strongly aligned with\nclinical judgment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16325v1",
    "published": "2025-05-22T07:32:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17145v1",
    "title": "LLM Access Shield: Domain-Specific LLM Framework for Privacy Policy Compliance",
    "authors": [
      "Yu Wang",
      "Cailing Cai",
      "Zhihua Xiao",
      "Peifung E. Lam"
    ],
    "abstract": "Large language models (LLMs) are increasingly applied in fields such as\nfinance, education, and governance due to their ability to generate human-like\ntext and adapt to specialized tasks. However, their widespread adoption raises\ncritical concerns about data privacy and security, including the risk of\nsensitive data exposure.\n  In this paper, we propose a security framework to enforce policy compliance\nand mitigate risks in LLM interactions. Our approach introduces three key\ninnovations: (i) LLM-based policy enforcement: a customizable mechanism that\nenhances domain-specific detection of sensitive data. (ii) Dynamic policy\ncustomization: real-time policy adaptation and enforcement during user-LLM\ninteractions to ensure compliance with evolving security requirements. (iii)\nSensitive data anonymization: a format-preserving encryption technique that\nprotects sensitive information while maintaining contextual integrity.\nExperimental results demonstrate that our framework effectively mitigates\nsecurity risks while preserving the functional accuracy of LLM-driven tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.17145v1",
    "published": "2025-05-22T07:30:37+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17144v1",
    "title": "MDIT-Bench: Evaluating the Dual-Implicit Toxicity in Large Multimodal Models",
    "authors": [
      "Bohan Jin",
      "Shuhan Qi",
      "Kehai Chen",
      "Xinyi Guo",
      "Xuan Wang"
    ],
    "abstract": "The widespread use of Large Multimodal Models (LMMs) has raised concerns\nabout model toxicity. However, current research mainly focuses on explicit\ntoxicity, with less attention to some more implicit toxicity regarding\nprejudice and discrimination. To address this limitation, we introduce a\nsubtler type of toxicity named dual-implicit toxicity and a novel toxicity\nbenchmark termed MDIT-Bench: Multimodal Dual-Implicit Toxicity Benchmark.\nSpecifically, we first create the MDIT-Dataset with dual-implicit toxicity\nusing the proposed Multi-stage Human-in-loop In-context Generation method.\nBased on this dataset, we construct the MDIT-Bench, a benchmark for evaluating\nthe sensitivity of models to dual-implicit toxicity, with 317,638 questions\ncovering 12 categories, 23 subcategories, and 780 topics. MDIT-Bench includes\nthree difficulty levels, and we propose a metric to measure the toxicity gap\nexhibited by the model across them. In the experiment, we conducted MDIT-Bench\non 13 prominent LMMs, and the results show that these LMMs cannot handle\ndual-implicit toxicity effectively. The model's performance drops significantly\nin hard level, revealing that these LMMs still contain a significant amount of\nhidden but activatable toxicity. Data are available at\nhttps://github.com/nuo1nuo/MDIT-Bench.",
    "pdf_url": "http://arxiv.org/pdf/2505.17144v1",
    "published": "2025-05-22T07:30:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16324v1",
    "title": "TensorAR: Refinement is All You Need in Autoregressive Image Generation",
    "authors": [
      "Cheng Cheng",
      "Lin Song",
      "Yicheng Xiao",
      "Yuxin Chen",
      "Xuchong Zhang",
      "Hongbin Sun",
      "Ying Shan"
    ],
    "abstract": "Autoregressive (AR) image generators offer a language-model-friendly approach\nto image generation by predicting discrete image tokens in a causal sequence.\nHowever, unlike diffusion models, AR models lack a mechanism to refine previous\npredictions, limiting their generation quality. In this paper, we introduce\nTensorAR, a new AR paradigm that reformulates image generation from next-token\nprediction to next-tensor prediction. By generating overlapping windows of\nimage patches (tensors) in a sliding fashion, TensorAR enables iterative\nrefinement of previously generated content. To prevent information leakage\nduring training, we propose a discrete tensor noising scheme, which perturbs\ninput tokens via codebook-indexed noise. TensorAR is implemented as a\nplug-and-play module compatible with existing AR models. Extensive experiments\non LlamaGEN, Open-MAGVIT2, and RAR demonstrate that TensorAR significantly\nimproves the generation performance of autoregressive models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16324v1",
    "published": "2025-05-22T07:27:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16323v1",
    "title": "Characterization of polynomials by their invariance properties",
    "authors": [
      "J. M. Amira",
      "Ya-Qing Hu"
    ],
    "abstract": "We prove that certain classical groups $G\\subseteq {\\rm GL}(d,\\mathbb{R}^d)$\nserve to characterize ordinary polynomials in $d$ real variables as elements of\nfinite-dimensional subspaces of $C(\\mathbb{R}^d)$ that are invariant by changes\nof variables induced by translations and elements of $G$. We also show that, if\nthe field $\\mathbb{K}$ has characteristic $0$, the elements of\n$\\mathbb{K}[x_1,\\cdots,x_d]$ admit a similar characterization for $G= {\\rm\nGL}(d,\\mathbb{K})$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16323v1",
    "published": "2025-05-22T07:26:40+00:00",
    "categories": [
      "math.CA",
      "math.GR",
      "39B05, 39B22, 39B52, 39A70"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.20310v1",
    "title": "Manalyzer: End-to-end Automated Meta-analysis with Multi-agent System",
    "authors": [
      "Wanghan Xu",
      "Wenlong Zhang",
      "Fenghua Ling",
      "Ben Fei",
      "Yusong Hu",
      "Fangxuan Ren",
      "Jintai Lin",
      "Wanli Ouyang",
      "Lei Bai"
    ],
    "abstract": "Meta-analysis is a systematic research methodology that synthesizes data from\nmultiple existing studies to derive comprehensive conclusions. This approach\nnot only mitigates limitations inherent in individual studies but also\nfacilitates novel discoveries through integrated data analysis. Traditional\nmeta-analysis involves a complex multi-stage pipeline including literature\nretrieval, paper screening, and data extraction, which demands substantial\nhuman effort and time. However, while LLM-based methods can accelerate certain\nstages, they still face significant challenges, such as hallucinations in paper\nscreening and data extraction. In this paper, we propose a multi-agent system,\nManalyzer, which achieves end-to-end automated meta-analysis through tool\ncalls. The hybrid review, hierarchical extraction, self-proving, and feedback\nchecking strategies implemented in Manalyzer significantly alleviate these two\nhallucinations. To comprehensively evaluate the performance of meta-analysis,\nwe construct a new benchmark comprising 729 papers across 3 domains,\nencompassing text, image, and table modalities, with over 10,000 data points.\nExtensive experiments demonstrate that Manalyzer achieves significant\nperformance improvements over the LLM baseline in multi meta-analysis tasks.\nProject page: https://black-yt.github.io/meta-analysis-page/ .",
    "pdf_url": "http://arxiv.org/pdf/2505.20310v1",
    "published": "2025-05-22T07:25:31+00:00",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16322v1",
    "title": "AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners",
    "authors": [
      "Woosung Koh",
      "Wonbeen Oh",
      "Jaein Jang",
      "MinHyung Lee",
      "Hyeongjin Kim",
      "Ah Yeon Kim",
      "Joonkee Kim",
      "Junghyun Lee",
      "Taehyeon Kim",
      "Se-Young Yun"
    ],
    "abstract": "Self-Taught Reasoners (STaR), synonymously known as Rejection sampling\nFine-Tuning (RFT), is an integral part of the training pipeline of\nself-improving reasoning Language Models (LMs). The self-improving mechanism\noften employs random observation (data) sampling. However, this results in\ntrained observation imbalance; inefficiently over-training on solved examples\nwhile under-training on challenging ones. In response, we introduce Adaptive\nSTaR (AdaSTaR), a novel algorithm that rectifies this by integrating two\nadaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting\nbalanced training across observations, and (2) Adaptive Sampling for\nCurriculum: dynamically adjusting data difficulty to match the model's evolving\nstrength. Across six benchmarks, AdaSTaR achieves best test accuracy in all\ninstances (6/6) and reduces training FLOPs by an average of 58.6% against an\nextensive list of baselines. These improvements in performance and efficiency\ngeneralize to different pre-trained LMs and larger models, paving the way for\nmore efficient and effective self-improving LMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16322v1",
    "published": "2025-05-22T07:24:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17143v1",
    "title": "Evaluating the Performance of Nigerian Lecturers using Multilayer Perceptron",
    "authors": [
      "I. E. Ezeibe",
      "S. O. Okide",
      "D. C. Asogwa"
    ],
    "abstract": "Evaluating the performance of a lecturer has been essential for enhancing\nteaching quality, improving student learning outcomes, and strengthening the\ninstitution's reputation. The absence of such a system brings about lecturer\nperformance evaluation which was neither comprehensive nor holistic. This\nsystem was designed using a web-based platform, created a secure database, and\nby using a custom dataset, captured some performance metrics which included\nstudent evaluation scores, Research Publications, Years of Experience, and\nAdministrative Duties. Multilayer Perceptron (MLP) algorithm was utilized due\nto its ability to process complex data patterns and generates accurate\npredictions in a lecturer's performance based on historical data. This research\nfocused on designing multiple performance metrics beyond the standard ones,\nincorporating student participation, and integrating analytical tools to\ndeliver a comprehensive and holistic evaluation of lecturers' performance and\nwas developed using Object-Oriented Analysis and Design (OOAD) methodology.\nLecturers' performance is evaluated by the model, and the evaluation accuracy\nis about 91% compared with actual performance. Finally, by evaluating the\nperformance of the MLP model, it is concluded that MLP enhanced lecturer\nperformance evaluation by providing accurate predictions, reducing bias, and\nsupporting data-driven decisions, ultimately improving the fairness and\nefficiency of the evaluation process. The MLP model's performance was evaluated\nusing Mean Squared Error (MSE) and Mean Absolute Error (MAE), achieved a test\nloss (MSE) of 256.99 and a MAE of 13.76, and reflected a high level of\nprediction accuracy. The model also demonstrated an estimated accuracy rate of\napproximately 96%, validated its effectiveness in predicting lecturer\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2505.17143v1",
    "published": "2025-05-22T07:23:14+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16321v1",
    "title": "Efficient Motion Prompt Learning for Robust Visual Tracking",
    "authors": [
      "Jie Zhao",
      "Xin Chen",
      "Yongsheng Yuan",
      "Michael Felsberg",
      "Dong Wang",
      "Huchuan Lu"
    ],
    "abstract": "Due to the challenges of processing temporal information, most trackers\ndepend solely on visual discriminability and overlook the unique temporal\ncoherence of video data. In this paper, we propose a lightweight and\nplug-and-play motion prompt tracking method. It can be easily integrated into\nexisting vision-based trackers to build a joint tracking framework leveraging\nboth motion and vision cues, thereby achieving robust tracking through\nefficient prompt learning. A motion encoder with three different positional\nencodings is proposed to encode the long-term motion trajectory into the visual\nembedding space, while a fusion decoder and an adaptive weight mechanism are\ndesigned to dynamically fuse visual and motion features. We integrate our\nmotion module into three different trackers with five models in total.\nExperiments on seven challenging tracking benchmarks demonstrate that the\nproposed motion module significantly improves the robustness of vision-based\ntrackers, with minimal training costs and negligible speed sacrifice. Code is\navailable at https://github.com/zj5559/Motion-Prompt-Tracking.",
    "pdf_url": "http://arxiv.org/pdf/2505.16321v1",
    "published": "2025-05-22T07:22:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16320v2",
    "title": "Learning novel representations of variable sources from multi-modal $\\textit{Gaia}$ data via autoencoders",
    "authors": [
      "P. Huijse",
      "J. De Ridder",
      "L. Eyer",
      "L. Rimoldini",
      "B. Holl",
      "N. Chornay",
      "J. Roquette",
      "K. Nienartowicz",
      "G. Jevardat de Fombelle",
      "D. J. Fritzewski",
      "A. Kemp",
      "V. Vanlaer",
      "M. Vanrespaille",
      "H. Wang",
      "M. I. Carnerero",
      "C. M. Raiteri",
      "G. Marton",
      "M. Madarász",
      "G. Clementini",
      "P. Gavras",
      "C. Aerts"
    ],
    "abstract": "Gaia Data Release 3 (DR3) published for the first time epoch photometry,\nBP/RP (XP) low-resolution mean spectra, and supervised classification results\nfor millions of variable sources. This extensive dataset offers a unique\nopportunity to study their variability by combining multiple Gaia data\nproducts. In preparation for DR4, we propose and evaluate a machine learning\nmethodology capable of ingesting multiple Gaia data products to achieve an\nunsupervised classification of stellar and quasar variability. A dataset of 4\nmillion Gaia DR3 sources is used to train three variational autoencoders (VAE),\nwhich are artificial neural networks (ANNs) designed for data compression and\ngeneration. One VAE is trained on Gaia XP low-resolution spectra, another on a\nnovel approach based on the distribution of magnitude differences in the Gaia G\nband, and the third on folded Gaia G band light curves. Each Gaia source is\ncompressed into 15 numbers, representing the coordinates in a 15-dimensional\nlatent space generated by combining the outputs of these three models. The\nlearned latent representation produced by the ANN effectively distinguishes\nbetween the main variability classes present in Gaia DR3, as demonstrated\nthrough both supervised and unsupervised classification analysis of the latent\nspace. The results highlight a strong synergy between light curves and\nlow-resolution spectral data, emphasising the benefits of combining the\ndifferent Gaia data products. A two-dimensional projection of the latent\nvariables reveals numerous overdensities, most of which strongly correlate with\nastrophysical properties, showing the potential of this latent space for\nastrophysical discovery. We show that the properties of our novel latent\nrepresentation make it highly valuable for variability analysis tasks,\nincluding classification, clustering and outlier detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.16320v2",
    "published": "2025-05-22T07:21:54+00:00",
    "categories": [
      "astro-ph.IM",
      "cs.LG"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16319v2",
    "title": "FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail",
    "authors": [
      "Yangyang Wang",
      "Jiawei Gu",
      "Li Long",
      "Xin Li",
      "Li Shen",
      "Zhouyu Fu",
      "Xiangjun Zhou",
      "Xu Jiang"
    ],
    "abstract": "Accurate demand estimation is critical for the retail business in guiding the\ninventory and pricing policies of perishable products. However, it faces\nfundamental challenges from censored sales data during stockouts, where\nunobserved demand creates systemic policy biases. Existing datasets lack the\ntemporal resolution and annotations needed to address this censoring effect. To\nfill this gap, we present FreshRetailNet-50K, the first large-scale benchmark\nfor censored demand estimation. It comprises 50,000 store-product time series\nof detailed hourly sales data from 898 stores in 18 major cities, encompassing\n863 perishable SKUs meticulously annotated for stockout events. The hourly\nstock status records unique to this dataset, combined with rich contextual\ncovariates, including promotional discounts, precipitation, and temporal\nfeatures, enable innovative research beyond existing solutions. We demonstrate\none such use case of two-stage demand modeling: first, we reconstruct the\nlatent demand during stockouts using precise hourly annotations. We then\nleverage the recovered demand to train robust demand forecasting models in the\nsecond stage. Experimental results show that this approach achieves a 2.73%\nimprovement in prediction accuracy while reducing the systematic demand\nunderestimation from 7.37% to near-zero bias. With unprecedented temporal\ngranularity and comprehensive real-world information, FreshRetailNet-50K opens\nnew research directions in demand imputation, perishable inventory\noptimization, and causal retail analytics. The unique annotation quality and\nscale of the dataset address long-standing limitations in retail AI, providing\nimmediate solutions and a platform for future methodological innovation. The\ndata (https://huggingface.co/datasets/Dingdong-Inc/FreshRetailNet-50K) and code\n(https://github.com/Dingdong-Inc/frn-50k-baseline}) are openly released.",
    "pdf_url": "http://arxiv.org/pdf/2505.16319v2",
    "published": "2025-05-22T07:21:40+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16318v1",
    "title": "SuperPure: Efficient Purification of Localized and Distributed Adversarial Patches via Super-Resolution GAN Models",
    "authors": [
      "Hossein Khalili",
      "Seongbin Park",
      "Venkat Bollapragada",
      "Nader Sehatbakhsh"
    ],
    "abstract": "As vision-based machine learning models are increasingly integrated into\nautonomous and cyber-physical systems, concerns about (physical) adversarial\npatch attacks are growing. While state-of-the-art defenses can achieve\ncertified robustness with minimal impact on utility against highly-concentrated\nlocalized patch attacks, they fall short in two important areas: (i)\nState-of-the-art methods are vulnerable to low-noise distributed patches where\nperturbations are subtly dispersed to evade detection or masking, as shown\nrecently by the DorPatch attack; (ii) Achieving high robustness with\nstate-of-the-art methods is extremely time and resource-consuming, rendering\nthem impractical for latency-sensitive applications in many cyber-physical\nsystems.\n  To address both robustness and latency issues, this paper proposes a new\ndefense strategy for adversarial patch attacks called SuperPure. The key\nnovelty is developing a pixel-wise masking scheme that is robust against both\ndistributed and localized patches. The masking involves leveraging a GAN-based\nsuper-resolution scheme to gradually purify the image from adversarial patches.\nOur extensive evaluations using ImageNet and two standard classifiers, ResNet\nand EfficientNet, show that SuperPure advances the state-of-the-art in three\nmajor directions: (i) it improves the robustness against conventional localized\npatches by more than 20%, on average, while also improving top-1 clean accuracy\nby almost 10%; (ii) It achieves 58% robustness against distributed patch\nattacks (as opposed to 0% in state-of-the-art method, PatchCleanser); (iii) It\ndecreases the defense end-to-end latency by over 98% compared to PatchCleanser.\nOur further analysis shows that SuperPure is robust against white-box attacks\nand different patch sizes. Our code is open-source.",
    "pdf_url": "http://arxiv.org/pdf/2505.16318v1",
    "published": "2025-05-22T07:21:04+00:00",
    "categories": [
      "cs.CV",
      "cs.CR",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16317v1",
    "title": "Early Stellar Flybys are Unlikely: Improved Constraints from Sednoids and Large-$q$ TNOs",
    "authors": [
      "Qingru Hu",
      "Yukun Huang",
      "Brett Gladman",
      "Wei Zhu"
    ],
    "abstract": "Sedna-like objects (a.k.a. sednoids) are transneptunian objects (TNOs)\ncharacterized by large semimajor axes and exceptionally high perihelia. Their\nhigh-$q$ orbits are detached from the influence of the four giant planets and\nneed extra perturbation to form. One hypothesis posits that close stellar\nflybys could have perturbed objects from the primordial scattering disk,\ngenerating the sednoid population. In this study, we run N-body simulations\nwith different stellar encounter configurations to explore whether such a close\nstellar flyby can satisfy new constraints identified from sednoid (and detached\nextreme TNO) observation, including the low-inclination ($i<30^\\circ$) profile\nand primordial orbital alignment. Our results suggest that flybys with field\nstars are unable to generate a sufficient population, whereas flybys within the\nbirth cluster fail to produce the primordial orbital alignment. To meet the\ninclination constraint of detached extreme TNOs, flybys have to be either\ncoplanar ($i_\\star \\sim 0^\\circ$) or symmetric about the ecliptic plane\n($\\omega_\\star \\sim 0^\\circ, i_\\star \\sim 90^\\circ$). After taking into account\ntheir occurrence rate at the early stage of the Solar System, we conclude that\nclose-in stellar flybys ($q_\\star \\le 1000$~au) that satisfy all constraints\nare unlikely to happen ($\\lesssim$5\\%). Future discoveries of additional\nsednoids with precise orbital determinations are crucial to confirm the\nexistence of the low-inclination tendency and the primordial alignment, and to\nfurther constrain the early dynamical evolution of the Solar System.",
    "pdf_url": "http://arxiv.org/pdf/2505.16317v1",
    "published": "2025-05-22T07:20:27+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.07316v1",
    "title": "Vulnerability and Defence: A Case for Stackelberg Game Dynamics",
    "authors": [
      "Azhar Iqbal",
      "Ishan Honhaga",
      "Eyoel Teffera",
      "Anthony Perry",
      "Robin Baker",
      "Glenn Pearce",
      "Claudia Szabo"
    ],
    "abstract": "This paper examines the tactical interaction between drones and tanks in\nmodern warfare through game theory, particularly focusing on Stackelberg\nequilibrium and backward induction. It describes a high-stakes conflict between\ntwo teams: one using advanced drones for attack, and the other defending using\ntanks. The paper conceptualizes this as a sequential game, illustrating the\ncomplex strategic dynamics similar to Stackelberg competition, where moves and\ncountermoves are carefully analyzed and predicted.",
    "pdf_url": "http://arxiv.org/pdf/2506.07316v1",
    "published": "2025-05-22T07:16:25+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16316v1",
    "title": "Differential Characters and $D$-Group Schemes",
    "authors": [
      "Rajat Kumar Mishra",
      "Arnab Saha"
    ],
    "abstract": "Let $K$ be a field of characteristic zero with a fixed derivation $\\partial$\non it. In the case when $A$ is an abelian scheme, Buium considered the group\nscheme $K(A)$ which is the kernel of differential characters (also known as\nManin characters) on the jet space of $A$. Then $K(A)$ naturally inherits a\n$D$-group scheme structure. Using the theory of universal vectorial extensions\nof $A$, he further showed that $K(A)$ is a finite dimensional vectorial\nextension of $A$.\n  Let $G$ be a smooth connected commutative finite dimensional group scheme\nover $\\mathrm{Spec}~ K$. In this paper, using the theory of differential\ncharacters, we show that the associated kernel group scheme $K(G)$ is a finite\ndimensional $D$-group scheme that is a vectorial extension of such a general\n$G$.\n  Our proof relies entirely on understanding the structure of jet spaces. Our\nmethod also allows us togive a classification of the module of differential\ncharacters $\\mathbf{X}_\\infty(G)$ in terms of primitive characters as a\n$K\\{\\partial\\}$-module.",
    "pdf_url": "http://arxiv.org/pdf/2505.16316v1",
    "published": "2025-05-22T07:15:31+00:00",
    "categories": [
      "math.AG",
      "14L15, 14L40, 14K99"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16315v2",
    "title": "Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning",
    "authors": [
      "Xiaoxue Cheng",
      "Junyi Li",
      "Zhenduo Zhang",
      "Xinyu Tang",
      "Wayne Xin Zhao",
      "Xinyu Kong",
      "Zhiqiang Zhang"
    ],
    "abstract": "Large reasoning models (LRMs) have demonstrated strong performance on complex\nreasoning tasks, but often suffer from overthinking, generating redundant\ncontent regardless of task difficulty. Inspired by the dual process theory in\ncognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a\nreinforcement learning framework that enables LRMs to achieve efficient\nreasoning through adaptive cognitive allocation and dynamic system switch. ACPO\nincorporates two key components: (1) introducing system-aware reasoning tokens\nto explicitly represent the thinking modes thereby making the model's cognitive\nprocess transparent, and (2) integrating online difficulty estimation and token\nlength budget to guide adaptive system switch and reasoning during\nreinforcement learning. To this end, we propose a two-stage training strategy.\nThe first stage begins with supervised fine-tuning to cold start the model,\nenabling it to generate reasoning paths with explicit thinking modes. In the\nsecond stage, we apply ACPO to further enhance adaptive system switch for\ndifficulty-aware reasoning. Experimental results demonstrate that ACPO\neffectively reduces redundant reasoning while adaptively adjusting cognitive\nallocation based on task complexity, achieving efficient hybrid reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.16315v2",
    "published": "2025-05-22T07:15:08+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16314v1",
    "title": "NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment",
    "authors": [
      "Shuhao Han",
      "Haotian Fan",
      "Fangyuan Kong",
      "Wenjie Liao",
      "Chunle Guo",
      "Chongyi Li",
      "Radu Timofte",
      "Liang Li",
      "Tao Li",
      "Junhui Cui",
      "Yunqiu Wang",
      "Yang Tai",
      "Jingwei Sun",
      "Jianhui Sun",
      "Xinli Yue",
      "Tianyi Wang",
      "Huan Hou",
      "Junda Lu",
      "Xinyang Huang",
      "Zitang Zhou",
      "Zijian Zhang",
      "Xuhui Zheng",
      "Xuecheng Wu",
      "Chong Peng",
      "Xuezhi Cao",
      "Trong-Hieu Nguyen-Mau",
      "Minh-Hoang Le",
      "Minh-Khoa Le-Phan",
      "Duy-Nam Ly",
      "Hai-Dang Nguyen",
      "Minh-Triet Tran",
      "Yukang Lin",
      "Yan Hong",
      "Chuanbiao Song",
      "Siyuan Li",
      "Jun Lan",
      "Zhichao Zhang",
      "Xinyue Li",
      "Wei Sun",
      "Zicheng Zhang",
      "Yunhao Li",
      "Xiaohong Liu",
      "Guangtao Zhai",
      "Zitong Xu",
      "Huiyu Duan",
      "Jiarui Wang",
      "Guangji Ma",
      "Liu Yang",
      "Lu Liu",
      "Qiang Hu",
      "Xiongkuo Min",
      "Zichuan Wang",
      "Zhenchen Tang",
      "Bo Peng",
      "Jing Dong",
      "Fengbin Guan",
      "Zihao Yu",
      "Yiting Lu",
      "Wei Luo",
      "Xin Li",
      "Minhao Lin",
      "Haofeng Chen",
      "Xuanxuan He",
      "Kele Xu",
      "Qisheng Xu",
      "Zijian Gao",
      "Tianjiao Wan",
      "Bo-Cheng Qiu",
      "Chih-Chung Hsu",
      "Chia-ming Lee",
      "Yu-Fan Lin",
      "Bo Yu",
      "Zehao Wang",
      "Da Mu",
      "Mingxiu Chen",
      "Junkang Fang",
      "Huamei Sun",
      "Wending Zhao",
      "Zhiyu Wang",
      "Wang Liu",
      "Weikang Yu",
      "Puhong Duan",
      "Bin Sun",
      "Xudong Kang",
      "Shutao Li",
      "Shuai He",
      "Lingzhi Fu",
      "Heng Cong",
      "Rongyu Zhang",
      "Jiarong He",
      "Zhishan Qiao",
      "Yongqing Huang",
      "Zewen Chen",
      "Zhe Pang",
      "Juan Wang",
      "Jian Guo",
      "Zhizhuo Shao",
      "Ziyu Feng",
      "Bing Li",
      "Weiming Hu",
      "Hesong Li",
      "Dehua Liu",
      "Zeming Liu",
      "Qingsong Xie",
      "Ruichen Wang",
      "Zhihao Li",
      "Yuqi Liang",
      "Jianqi Bi",
      "Jun Luo",
      "Junfeng Yang",
      "Can Li",
      "Jing Fu",
      "Hongwei Xu",
      "Mingrui Long",
      "Lulin Tang"
    ],
    "abstract": "This paper reports on the NTIRE 2025 challenge on Text to Image (T2I)\ngeneration model quality assessment, which will be held in conjunction with the\nNew Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2025.\nThe aim of this challenge is to address the fine-grained quality assessment of\ntext-to-image generation models. This challenge evaluates text-to-image models\nfrom two aspects: image-text alignment and image structural distortion\ndetection, and is divided into the alignment track and the structural track.\nThe alignment track uses the EvalMuse-40K, which contains around 40K\nAI-Generated Images (AIGIs) generated by 20 popular generative models. The\nalignment track has a total of 371 registered participants. A total of 1,883\nsubmissions are received in the development phase, and 507 submissions are\nreceived in the test phase. Finally, 12 participating teams submitted their\nmodels and fact sheets. The structure track uses the EvalMuse-Structure, which\ncontains 10,000 AI-Generated Images (AIGIs) with corresponding structural\ndistortion mask. A total of 211 participants have registered in the structure\ntrack. A total of 1155 submissions are received in the development phase, and\n487 submissions are received in the test phase. Finally, 8 participating teams\nsubmitted their models and fact sheets. Almost all methods have achieved better\nresults than baseline methods, and the winning methods in both tracks have\ndemonstrated superior prediction performance on T2I model quality assessment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16314v1",
    "published": "2025-05-22T07:12:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16313v1",
    "title": "Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box Settings",
    "authors": [
      "Arjhun Swaminathan",
      "Mete Akgün"
    ],
    "abstract": "Deep neural networks for image classification remain vulnerable to\nadversarial examples -- small, imperceptible perturbations that induce\nmisclassifications. In black-box settings, where only the final prediction is\naccessible, crafting targeted attacks that aim to misclassify into a specific\ntarget class is particularly challenging due to narrow decision regions.\nCurrent state-of-the-art methods often exploit the geometric properties of the\ndecision boundary separating a source image and a target image rather than\nincorporating information from the images themselves. In contrast, we propose\nTargeted Edge-informed Attack (TEA), a novel attack that utilizes edge\ninformation from the target image to carefully perturb it, thereby producing an\nadversarial image that is closer to the source image while still achieving the\ndesired target classification. Our approach consistently outperforms current\nstate-of-the-art methods across different models in low query settings (nearly\n70\\% fewer queries are used), a scenario especially relevant in real-world\napplications with limited queries and black-box access. Furthermore, by\nefficiently generating a suitable adversarial example, TEA provides an improved\ntarget initialization for established geometry-based attacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16313v1",
    "published": "2025-05-22T07:10:12+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17142v2",
    "title": "MetaSTH-Sleep: Towards Effective Few-Shot Sleep Stage Classification for Health Management with Spatial-Temporal Hypergraph Enhanced Meta-Learning",
    "authors": [
      "Jingyu Li",
      "Tiehua Zhang",
      "Jinze Wang",
      "Yi Zhang",
      "Yuhuan Li",
      "Yifan Zhao",
      "Zhishu Shen",
      "Libing Wu",
      "Jiannan Liu"
    ],
    "abstract": "Accurate classification of sleep stages based on bio-signals is fundamental\nnot only for automatic sleep stage annotation, but also for clinical health\nmanagement and continuous sleep monitoring. Traditionally, this task relies on\nexperienced clinicians to manually annotate data, a process that is both\ntime-consuming and labor-intensive. In recent years, deep learning methods have\nshown promise in automating this task. However, three major challenges remain:\n(1) deep learning models typically require large-scale labeled datasets, making\nthem less effective in real-world settings where annotated data is limited; (2)\nsignificant inter-individual variability in bio-signals often results in\ninconsistent model performance when applied to new subjects, limiting\ngeneralization; and (3) existing approaches often overlook the high-order\nrelationships among bio-signals, failing to simultaneously capture signal\nheterogeneity and spatial-temporal dependencies. To address these issues, we\npropose MetaSTH-Sleep, a few-shot sleep stage classification framework based on\nspatial-temporal hypergraph enhanced meta-learning. Our approach enables rapid\nadaptation to new subjects using only a few labeled samples, while the\nhypergraph structure effectively models complex spatial interconnections and\ntemporal dynamics simultaneously in EEG signals. Experimental results\ndemonstrate that MetaSTH-Sleep achieves substantial performance improvements\nacross diverse subjects, offering valuable insights to support clinicians in\nsleep stage annotation.",
    "pdf_url": "http://arxiv.org/pdf/2505.17142v2",
    "published": "2025-05-22T07:09:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16312v1",
    "title": "EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning",
    "authors": [
      "Jiawei Liu",
      "Qisi Chen",
      "Jianshu Zhang",
      "Quan Liu",
      "Defu Lian"
    ],
    "abstract": "Large Language Models (LLMs) excel at complex reasoning through search\nalgorithms, yet current strategies often suffer from massive token consumption\ndue to redundant exploration of semantically equivalent steps. Existing\nsemantic similarity methods struggle to accurately identify such equivalence in\ndomain-specific contexts like mathematical reasoning. To address this, we\npropose EquivPruner, a simple yet effective approach that identifies and prunes\nsemantically equivalent actions during LLM reasoning search. We also introduce\nMathEquiv, the first dataset we created for mathematical statement equivalence,\nwhich enables the training of a lightweight equivalence detector. Extensive\nexperiments across various models and tasks demonstrate that EquivPruner\nsignificantly reduces token consumption, improving searching efficiency and\noften bolstering reasoning accuracy. For instance, when applied to\nQwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by\n48.1\\% while also improving accuracy. Our code is available at\nhttps://github.com/Lolo1222/EquivPruner.",
    "pdf_url": "http://arxiv.org/pdf/2505.16312v1",
    "published": "2025-05-22T07:07:43+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16311v1",
    "title": "Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions",
    "authors": [
      "Marc Brooks",
      "Gabriel Durham",
      "Kihyuk Hong",
      "Ambuj Tewari"
    ],
    "abstract": "Recent advances in generative artificial intelligence (GenAI) models have\nenabled the generation of personalized content that adapts to up-to-date user\ncontext. While personalized decision systems are often modeled using bandit\nformulations, the integration of GenAI introduces new structure into otherwise\nclassical sequential learning problems. In GenAI-powered interventions, the\nagent selects a query, but the environment experiences a stochastic response\ndrawn from the generative model. Standard bandit methods do not explicitly\naccount for this structure, where actions influence rewards only through\nstochastic, observed treatments. We introduce generator-mediated\nbandit-Thompson sampling (GAMBITTS), a bandit approach designed for this\naction/treatment split, using mobile health interventions with large language\nmodel-generated text as a motivating case study. GAMBITTS explicitly models\nboth the treatment and reward generation processes, using information in the\ndelivered treatment to accelerate policy learning relative to standard methods.\nWe establish regret bounds for GAMBITTS by decomposing sources of uncertainty\nin treatment and reward, identifying conditions where it achieves stronger\nguarantees than standard bandit approaches. In simulation studies, GAMBITTS\nconsistently outperforms conventional algorithms by leveraging observed\ntreatments to more accurately estimate expected rewards.",
    "pdf_url": "http://arxiv.org/pdf/2505.16311v1",
    "published": "2025-05-22T07:06:51+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16310v1",
    "title": "Paired and Unpaired Image to Image Translation using Generative Adversarial Networks",
    "authors": [
      "Gaurav Kumar",
      "Soham Satyadharma",
      "Harpreet Singh"
    ],
    "abstract": "Image to image translation is an active area of research in the field of\ncomputer vision, enabling the generation of new images with different styles,\ntextures, or resolutions while preserving their characteristic properties.\nRecent architectures leverage Generative Adversarial Networks (GANs) to\ntransform input images from one domain to another. In this work, we focus on\nthe study of both paired and unpaired image translation across multiple image\ndomains. For the paired task, we used a conditional GAN model, and for the\nunpaired task, we trained it using cycle consistency loss. We experimented with\ndifferent types of loss functions, multiple Patch-GAN sizes, and model\narchitectures. New quantitative metrics - precision, recall, and FID score -\nwere used for analysis. In addition, a qualitative study of the results of\ndifferent experiments was conducted.",
    "pdf_url": "http://arxiv.org/pdf/2505.16310v1",
    "published": "2025-05-22T07:06:39+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17141v1",
    "title": "Fashion Industry in the Age of Generative Artificial Intelligence and Metaverse: A systematic Review",
    "authors": [
      "Rania Ahmed",
      "Eman Ahmed",
      "Ahmed Elbarbary",
      "Ashraf Darwish",
      "Aboul Ella Hassanien"
    ],
    "abstract": "The fashion industry is an extremely profitable market that generates\ntrillions of dollars in revenue by producing and distributing apparel,\nfootwear, and accessories. This systematic literature review (SLR) seeks to\nsystematically review and analyze the research landscape about the Generative\nArtificial Intelligence (GAI) and metaverse in the fashion industry. Thus,\ninvestigating the impact of integrating both technologies to enhance the\nfashion industry. This systematic review uses the Reporting Items for\nSystematic reviews and Meta-Analyses (PRISMA) methodology, including three\nessential phases: identification, evaluation, and reporting. In the\nidentification phase, the target search problems are determined by selecting\nappropriate keywords and alternative synonyms. After that 578 documents from\n2014 to the end of 2023 are retrieved. The evaluation phase applies three\nscreening steps to assess papers and choose 118 eligible papers for full-text\nreading. Finally, the reporting phase thoroughly examines and synthesizes the\n118 eligible papers to identify key themes associated with GAI and Metaverse in\nthe fashion industry. Based on Strengths, Weaknesses, Opportunities, and\nThreats (SWOT) analyses performed for both GAI and metaverse for the fashion\nindustry, it is concluded that the integration of GAI and the metaverse holds\nthe capacity to profoundly revolutionize the fashion sector, presenting chances\nfor improved manufacturing, design, sales, and client experiences. Accordingly,\nthe research proposes a new framework to integrate GAI and metaverse to enhance\nthe fashion industry. The framework presents different use cases to promote the\nfashion industry using the integration. Future research points for achieving a\nsuccessful integration are demonstrated.",
    "pdf_url": "http://arxiv.org/pdf/2505.17141v1",
    "published": "2025-05-22T07:06:27+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.07315v1",
    "title": "Towards Competent AI for Fundamental Analysis in Finance: A Benchmark Dataset and Evaluation",
    "authors": [
      "Zonghan Wu",
      "Junlin Wang",
      "Congyuan Zou",
      "Chenhan Wang",
      "Yilei Shao"
    ],
    "abstract": "Generative AI, particularly large language models (LLMs), is beginning to\ntransform the financial industry by automating tasks and helping to make sense\nof complex financial information. One especially promising use case is the\nautomatic creation of fundamental analysis reports, which are essential for\nmaking informed investment decisions, evaluating credit risks, guiding\ncorporate mergers, etc. While LLMs attempt to generate these reports from a\nsingle prompt, the risks of inaccuracy are significant. Poor analysis can lead\nto misguided investments, regulatory issues, and loss of trust. Existing\nfinancial benchmarks mainly evaluate how well LLMs answer financial questions\nbut do not reflect performance in real-world tasks like generating financial\nanalysis reports. In this paper, we propose FinAR-Bench, a solid benchmark\ndataset focusing on financial statement analysis, a core competence of\nfundamental analysis. To make the evaluation more precise and reliable, we\nbreak this task into three measurable steps: extracting key information,\ncalculating financial indicators, and applying logical reasoning. This\nstructured approach allows us to objectively assess how well LLMs perform each\nstep of the process. Our findings offer a clear understanding of LLMs current\nstrengths and limitations in fundamental analysis and provide a more practical\nway to benchmark their performance in real-world financial settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.07315v1",
    "published": "2025-05-22T07:06:20+00:00",
    "categories": [
      "q-fin.ST",
      "cs.AI"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.16309v1",
    "title": "From Nonextremal to Extremal: Entropy of Reissner-Nordström and Kerr black holes Revisited",
    "authors": [
      "C. Fairoos",
      "Chiranjeeb Singha"
    ],
    "abstract": "In this paper, we derive the entropy of Reissner-Nordstr\\\"om (RN) and Kerr\nblack holes using the Hawking-Gibbons path integral method. We determine the\nperiodicity of the Euclidean time coordinate using two approaches: first, by\nanalyzing the near-horizon geometry, and second, by applying the\nChern-Gauss-Bonnet (CGB) theorem. For non-extremal cases, both these methods\nyield a consistent and unique periodicity, which in turn leads to a\nwell-defined expression for the entropy. In contrast, the extremal case\nexhibits a crucial difference. The absence of a conical structure in the\nnear-horizon geometry implies that the periodicity of the Euclidean time is no\nlonger uniquely fixed within the Hawking-Gibbons framework. The CGB theorem\nalso fails to constrain the periodicity, as the corresponding Euler\ncharacteristic vanishes. As a result, the entropy cannot be uniquely determined\nusing either method.",
    "pdf_url": "http://arxiv.org/pdf/2505.16309v1",
    "published": "2025-05-22T07:05:26+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16308v1",
    "title": "CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting",
    "authors": [
      "Xingyu Zhang",
      "Wenwen Qiang",
      "Siyu Zhao",
      "Huijie Guo",
      "Jiangmeng Li",
      "Chuxiong Sun",
      "Changwen Zheng"
    ],
    "abstract": "Most existing multivariate time series forecasting methods adopt an\nall-to-all paradigm that feeds all variable histories into a unified model to\npredict their future values without distinguishing their individual roles.\nHowever, this undifferentiated paradigm makes it difficult to identify\nvariable-specific causal influences and often entangles causally relevant\ninformation with spurious correlations. To address this limitation, we propose\nan all-to-one forecasting paradigm that predicts each target variable\nseparately. Specifically, we first construct a Structural Causal Model from\nobservational data and then, for each target variable, we partition the\nhistorical sequence into four sub-segments according to the inferred causal\nstructure: endogenous, direct causal, collider causal, and spurious\ncorrelation. The prediction relies solely on the first three causally relevant\nsub-segments, while the spurious correlation sub-segment is excluded.\nFurthermore, we propose Causal Informed Transformer (CAIFormer), a novel\nforecasting model comprising three components: Endogenous Sub-segment\nPrediction Block, Direct Causal Sub-segment Prediction Block, and Collider\nCausal Sub-segment Prediction Block, which process the endogenous, direct\ncausal, and collider causal sub-segments, respectively. Their outputs are then\ncombined to produce the final prediction. Extensive experiments on multiple\nbenchmark datasets demonstrate the effectiveness of the CAIFormer.",
    "pdf_url": "http://arxiv.org/pdf/2505.16308v1",
    "published": "2025-05-22T07:04:21+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16307v1",
    "title": "PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models",
    "authors": [
      "Chenzhuo Zhao",
      "Ziqian Liu",
      "Xingda Wang",
      "Junting Lu",
      "Chaoyi Ruan"
    ],
    "abstract": "Prompt optimization offers a practical and broadly applicable alternative to\nfine-tuning for improving large language model (LLM) performance. However,\nexisting methods often rely on costly output generation, self-critiquing\nabilities, or human-annotated preferences, which limit their scalability,\nespecially for smaller or non-instruction-tuned models. We introduce PMPO\n(Probabilistic Metric Prompt Optimization), a unified framework that refines\nprompts using token-level cross-entropy loss as a direct, lightweight\nevaluation signal. PMPO identifies low-quality prompt segments by masking and\nmeasuring their impact on loss, then rewrites and selects improved variants by\nminimizing loss over positive and negative examples. Unlike prior methods, it\nrequires no output sampling or human evaluation during optimization, relying\nonly on forward passes and log-likelihoods. PMPO supports both supervised and\npreference-based tasks through a closely aligned loss-based evaluation\nstrategy. Experiments show that PMPO consistently outperforms prior methods\nacross model sizes and tasks: it achieves the highest average accuracy on BBH,\nperforms strongly on GSM8K and AQUA-RAT, and improves AlpacaEval 2.0 win rates\nby over 19 points. These results highlight PMPO's effectiveness, efficiency,\nand broad applicability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16307v1",
    "published": "2025-05-22T06:59:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16306v1",
    "title": "Layer-wise Investigation of Large-Scale Self-Supervised Music Representation Models",
    "authors": [
      "Yizhi Zhou",
      "Haina Zhu",
      "Hangting Chen"
    ],
    "abstract": "Recently, pre-trained models for music information retrieval based on\nself-supervised learning (SSL) are becoming popular, showing success in various\ndownstream tasks. However, there is limited research on the specific meanings\nof the encoded information and their applicability. Exploring these aspects can\nhelp us better understand their capabilities and limitations, leading to more\neffective use in downstream tasks.\n  In this study, we analyze the advanced music representation model MusicFM and\nthe newly emerged SSL model MuQ. We focus on three main aspects: (i) validating\nthe advantages of SSL models across multiple downstream tasks, (ii) exploring\nthe specialization of layer-wise information for different tasks, and (iii)\ncomparing performance differences when selecting specific layers. Through this\nanalysis, we reveal insights into the structure and potential applications of\nSSL models in music information retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2505.16306v1",
    "published": "2025-05-22T06:58:24+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16305v1",
    "title": "Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution",
    "authors": [
      "Bingyang Cheng",
      "Zhongtao Chen",
      "Yichen Jin",
      "Hao Zhang",
      "Chen Zhang",
      "Edmud Y. Lam",
      "Yik-Chung Wu"
    ],
    "abstract": "Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for\ntensor reconstruction. Although the Bayesian framework allows for principled\nuncertainty quantification and automatic hyperparameter learning, existing\nmethods do not scale well for large tensors because of high-dimensional matrix\ninversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD\nalgorithm. This algorithm leverages generalized approximate message passing\n(GAMP) to avoid matrix inversions and incorporates an expectation-maximization\nroutine to jointly infer the tensor rank and noise power. Through multiple\nexperiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements\nobserved, the proposed algorithm reduces runtime by 82.7% compared to the\nstate-of-the-art variational Bayesian CPD method, while maintaining comparable\nreconstruction accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16305v1",
    "published": "2025-05-22T06:57:49+00:00",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16304v2",
    "title": "SAMba-UNet: SAM2-Mamba UNet for Cardiac MRI in Medical Robotic Perception",
    "authors": [
      "Guohao Huo",
      "Ruiting Dai",
      "Ling Shao",
      "Hao Tang"
    ],
    "abstract": "To address complex pathological feature extraction in automated cardiac MRI\nsegmentation, we propose SAMba-UNet, a novel dual-encoder architecture that\nsynergistically combines the vision foundation model SAM2, the\nlinear-complexity state-space model Mamba, and the classical UNet to achieve\ncross-modal collaborative feature learning; to overcome domain shifts between\nnatural images and medical scans, we introduce a Dynamic Feature Fusion Refiner\nthat employs multi-scale pooling and channel-spatial dual-path calibration to\nstrengthen small-lesion and fine-structure representation, and we design a\nHeterogeneous Omni-Attention Convergence Module (HOACM) that fuses SAM2's local\npositional semantics with Mamba's long-range dependency modeling via global\ncontextual attention and branch-selective emphasis, yielding substantial gains\nin both global consistency and boundary precision-on the ACDC cardiac MRI\nbenchmark, SAMba-UNet attains a Dice of 0.9103 and HD95 of 1.0859 mm, notably\nimproving boundary localization for challenging structures like the right\nventricle, and its robust, high-fidelity segmentation maps are directly\napplicable as a perception module within intelligent medical and surgical\nrobotic systems to support preoperative planning, intraoperative navigation,\nand postoperative complication screening; the code will be open-sourced to\nfacilitate clinical translation and further validation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16304v2",
    "published": "2025-05-22T06:57:03+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16303v1",
    "title": "INFERENCEDYNAMICS: Efficient Routing Across LLMs through Structured Capability and Knowledge Profiling",
    "authors": [
      "Haochen Shi",
      "Tianshi Zheng",
      "Weiqi Wang",
      "Baixuan Xu",
      "Chunyang Li",
      "Chunkit Chan",
      "Tao Fan",
      "Yangqiu Song",
      "Qiang Yang"
    ],
    "abstract": "Large Language Model (LLM) routing is a pivotal technique for navigating a\ndiverse landscape of LLMs, aiming to select the best-performing LLMs tailored\nto the domains of user queries, while managing computational resources.\nHowever, current routing approaches often face limitations in scalability when\ndealing with a large pool of specialized LLMs, or in their adaptability to\nextending model scope and evolving capability domains. To overcome those\nchallenges, we propose InferenceDynamics, a flexible and scalable\nmulti-dimensional routing framework by modeling the capability and knowledge of\nmodels. We operate it on our comprehensive dataset RouteMix, and demonstrate\nits effectiveness and generalizability in group-level routing using modern\nbenchmarks including MMLU-Pro, GPQA, BigGenBench, and LiveBench, showcasing its\nability to identify and leverage top-performing models for given tasks, leading\nto superior outcomes with efficient resource utilization. The broader adoption\nof Inference Dynamics can empower users to harness the full specialized\npotential of the LLM ecosystem, and our code will be made publicly available to\nencourage further research.",
    "pdf_url": "http://arxiv.org/pdf/2505.16303v1",
    "published": "2025-05-22T06:56:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16302v2",
    "title": "Covariance matrix estimation in the singular case using regularized Cholesky factor",
    "authors": [
      "Olivier Besson"
    ],
    "abstract": "We consider estimating the population covariance matrix when the number of\navailable samples is less than the size of the observations. The sample\ncovariance matrix (SCM) being singular, regularization is mandatory in this\ncase. For this purpose we consider minimizing Stein's loss function and we\ninvestigate a method based on augmenting the partial Cholesky decomposition of\nthe SCM. We first derive the finite sample optimum estimator which minimizes\nthe loss for each data realization, then the Oracle estimator which minimizes\nthe risk, i.e., the average value of the loss. Finally a practical scheme is\npresented where the missing part of the Cholesky decomposition is filled. We\nconduct a numerical performance study of the proposed method and compare it\nwith available related methods. In particular we investigate the influence of\nthe condition number of the covariance matrix as well as of the shape of its\nspectrum.",
    "pdf_url": "http://arxiv.org/pdf/2505.16302v2",
    "published": "2025-05-22T06:56:41+00:00",
    "categories": [
      "math.ST",
      "eess.SP",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.16301v1",
    "title": "Artificial Intelligence for Direct Prediction of Molecular Dynamics Across Chemical Space",
    "authors": [
      "Fuchun Ge",
      "Pavlo O. Dral"
    ],
    "abstract": "Molecular dynamics (MD) is a powerful tool for exploring the behavior of\natomistic systems, but its reliance on sequential numerical integration limits\nsimulation efficiency. We present MDtrajNet-1, a foundational AI model that\ndirectly generates MD trajectories across chemical space, bypassing force\ncalculations and integration. This approach accelerates simulations by up to\ntwo orders of magnitude compared to traditional MD, even those enhanced by\nmachine-learning interatomic potentials. MDtrajNet-1 combines equivariant\nneural networks with a Transformer-based architecture to achieve strong\naccuracy and transferability in predicting long-time trajectories for both\nknown and unseen systems. Remarkably, the errors of the trajectories generated\nby MDtrajNet-1 for various molecular systems are close to those of the\nconventional ab initio MD. The model's flexible design supports diverse\napplication scenarios, including different statistical ensembles, boundary\nconditions, and interaction types. By overcoming the intrinsic speed barrier of\nconventional MD, MDtrajNet-1 opens new frontiers in efficient and scalable\natomistic simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16301v1",
    "published": "2025-05-22T06:56:19+00:00",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16300v1",
    "title": "Poster: Towards an Automated Security Testing Framework for Industrial UEs",
    "authors": [
      "Sotiris Michaelides",
      "Daniel Eguiguren Chavez",
      "Martin Henze"
    ],
    "abstract": "With the ongoing adoption of 5G for communication in industrial systems and\ncritical infrastructure, the security of industrial UEs such as 5G-enabled\nindustrial robots becomes an increasingly important topic. Most notably, to\nmeet the stringent security requirements of industrial deployments, industrial\nUEs not only have to fully comply with the 5G specifications but also implement\nand use correctly secure communication protocols such as TLS. To ensure the\nsecurity of industrial UEs, operators of industrial 5G networks rely on\nsecurity testing before deploying new devices to their production networks.\nHowever, currently only isolated tests for individual security aspects of\nindustrial UEs exist, severely hindering comprehensive testing. In this paper,\nwe report on our ongoing efforts to alleviate this situation by creating an\nautomated security testing framework for industrial UEs to comprehensively\nevaluate their security posture before deployment. With this framework, we aim\nto provide stakeholders with a fully automated-method to verify that\nhigher-layer security protocols are correctly implemented, while simultaneously\nensuring that the UE's protocol stack adheres to 3GPP specifications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16300v1",
    "published": "2025-05-22T06:54:38+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16299v1",
    "title": "Eclipsing millisecond pulsars with He star companions",
    "authors": [
      "Yunlang Guo",
      "Bo Wang",
      "Xiangdong Li",
      "Dongdong Liu",
      "Wenshi Tang"
    ],
    "abstract": "Eclipsing millisecond pulsars (MSPs) are a type of pulsar binaries with close\norbits ($\\lesssim1.0\\,$d). They are important objects for studying the\naccretion history of neutron stars (NSs), pulsar winds, and the origin of\nisolated MSPs, etc. Recently, a new eclipsing MSP, PSR J$1928+1815$, was\ndiscovered by the Five-hundred-meter Aperture Spherical radio Telescope. It is\nthe first known pulsar with a He star companion, as suggested in Yang et al.\nThe system features a short orbital period of $\\sim0.15\\,$d and a relatively\nmassive companion $\\gtrsim1.0\\,M_\\odot$. However, the origin of PSR\nJ$1928+1815$ remains highly uncertain. In this paper, we investigated the\nformation of the new subclass of eclipsing MSPs containing (evolved) He star\ncompanions through NS + He star channel. We found that if a NS binary undergoes\nsubsequent mass-transfer phases following Case BA or Case BB, it may appear as\nan eclipsing MSP during the detached phase. Additionally, we obtained the\ninitial parameter space for producing eclipsing MSPs with He star companions.\nUsing binary population synthesis approach, we estimated their birth rate to be\n$\\sim2.1-4.7\\times10^{-4}\\rm\\,yr^{-1}$, corresponding to a total number of\n$\\sim55-150$ systems in the Galaxy. Moreover, we concluded that PSR\nJ$1928+1815$ may originate from the evolution of an NS+He star system with an\ninitial orbital period of $\\sim0.1\\,$d, which can undergo the Case BB mass\ntransfer.",
    "pdf_url": "http://arxiv.org/pdf/2505.16299v1",
    "published": "2025-05-22T06:54:20+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16298v1",
    "title": "Flow Matching based Sequential Recommender Model",
    "authors": [
      "Feng Liu",
      "Lixin Zou",
      "Xiangyu Zhao",
      "Min Tang",
      "Liming Dong",
      "Dan Luo",
      "Xiangyang Luo",
      "Chenliang Li"
    ],
    "abstract": "Generative models, particularly diffusion model, have emerged as powerful\ntools for sequential recommendation. However, accurately modeling user\npreferences remains challenging due to the noise perturbations inherent in the\nforward and reverse processes of diffusion-based methods. Towards this end,\nthis study introduces FMRec, a Flow Matching based model that employs a\nstraight flow trajectory and a modified loss tailored for the recommendation\ntask. Additionally, from the diffusion-model perspective, we integrate a\nreconstruction loss to improve robustness against noise perturbations, thereby\nretaining user preferences during the forward process. In the reverse process,\nwe employ a deterministic reverse sampler, specifically an ODE-based updating\nfunction, to eliminate unnecessary randomness, thereby ensuring that the\ngenerated recommendations closely align with user needs. Extensive evaluations\non four benchmark datasets reveal that FMRec achieves an average improvement of\n6.53% over state-of-the-art methods. The replication code is available at\nhttps://github.com/FengLiu-1/FMRec.",
    "pdf_url": "http://arxiv.org/pdf/2505.16298v1",
    "published": "2025-05-22T06:53:03+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16297v1",
    "title": "ToDi: Token-wise Distillation via Fine-Grained Divergence Control",
    "authors": [
      "Seongryong Jung",
      "Suwan Yoon",
      "DongGeon Kim",
      "Hwanhee Lee"
    ],
    "abstract": "Large language models (LLMs) offer impressive performance but are impractical\nfor resource-constrained deployment due to high latency and energy consumption.\nKnowledge distillation (KD) addresses this by transferring knowledge from a\nlarge teacher to a smaller student model. However, conventional KD, notably\napproaches like Forward KL (FKL) and Reverse KL (RKL), apply uniform divergence\nloss across the entire vocabulary, neglecting token-level prediction\ndiscrepancies. By investigating these representative divergences via gradient\nanalysis, we reveal that FKL boosts underestimated tokens, while RKL suppresses\noverestimated ones, showing their complementary roles. Based on this\nobservation, we propose Token-wise Distillation (ToDi), a novel method that\nadaptively combines FKL and RKL per token using a sigmoid-based weighting\nfunction derived from the teacher-student probability log-ratio. ToDi\ndynamically emphasizes the appropriate divergence for each token, enabling\nprecise distribution alignment. We demonstrate that ToDi consistently\noutperforms recent distillation baselines using uniform or less granular\nstrategies across instruction-following benchmarks. Extensive ablation studies\nand efficiency analysis further validate ToDi's effectiveness and practicality.",
    "pdf_url": "http://arxiv.org/pdf/2505.16297v1",
    "published": "2025-05-22T06:51:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16295v1",
    "title": "On the Odd Unitary Analogue of Gram-Schmidt Process",
    "authors": [
      "Ambily A. A.",
      "Aparna Pradeep V. K"
    ],
    "abstract": "In 1976, L.N. Vaserstein used a construction analogous to the Gram-Schmidt\northogonalisation, for obtaining a set of symplectic matrices from a set of\nelementary matrices. We have a similar construction for Petrov's odd unitary\ngroup. Here, we prove that the elementary matrices in the odd unitary analogue\nof the Gram-Schmidt process form a set of generators for the elementary linear\ngroup.",
    "pdf_url": "http://arxiv.org/pdf/2505.16295v1",
    "published": "2025-05-22T06:48:40+00:00",
    "categories": [
      "math.GR",
      "math.KT",
      "20G99 (primary), 13A99, 14L35, 15A24 (secondary)"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16296v1",
    "title": "A finite element solver for a thermodynamically consistent electrolyte model",
    "authors": [
      "Jan Habscheid",
      "Satyvir Singh",
      "Lambert Theisen",
      "Stefanie Braun",
      "Manuel Torrilhon"
    ],
    "abstract": "In this study, we present a finite element solver for a thermodynamically\nconsistent electrolyte model that accurately captures multicomponent ionic\ntransport by incorporating key physical phenomena such as steric effects,\nsolvation, and pressure coupling. The model is rooted in the principles of\nnon-equilibrium thermodynamics and strictly enforces mass conservation, charge\nneutrality, and entropy production. It extends beyond classical frameworks like\nthe Nernst-Planck system by employing modified partial mass balances, the\nelectrostatic Poisson equation, and a momentum balance expressed in terms of\nelectrostatic potential, atomic fractions, and pressure, thereby enhancing\nnumerical stability and physical consistency. Implemented using the FEniCSx\nplatform, the solver efficiently handles one- and two-dimensional problems with\nvaried boundary conditions and demonstrates excellent convergence behavior and\nrobustness. Validation against benchmark problems confirms its improved\nphysical fidelity, particularly in regimes characterized by high ionic\nconcentrations and strong electrochemical gradients. Simulation results reveal\ncritical electrolyte phenomena, including electric double layer formation,\nrectification behavior, and the effects of solvation number, Debye length, and\ncompressibility. The solver's modular variational formulation facilitates its\nextension to complex electrochemical systems involving multiple ionic species\nwith asymmetric valences.",
    "pdf_url": "http://arxiv.org/pdf/2505.16296v1",
    "published": "2025-05-22T06:48:40+00:00",
    "categories": [
      "cs.CE",
      "physics.chem-ph",
      "physics.comp-ph"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.17140v1",
    "title": "Data Doping or True Intelligence? Evaluating the Transferability of Injected Knowledge in LLMs",
    "authors": [
      "Essa Jan",
      "Moiz Ali",
      "Muhammad Saram Hassan",
      "Fareed Zaffar",
      "Yasir Zaki"
    ],
    "abstract": "As the knowledge of large language models (LLMs) becomes outdated over time,\nthere is a growing need for efficient methods to update them, especially when\ninjecting proprietary information. Our study reveals that\ncomprehension-intensive fine-tuning tasks (e.g., question answering and blanks)\nachieve substantially higher knowledge retention rates (48%) compared to\nmapping-oriented tasks like translation (17%) or text-to-JSON conversion (20%),\ndespite exposure to identical factual content. We demonstrate that this pattern\npersists across model architectures and follows scaling laws, with larger\nmodels showing improved retention across all task types. However, all models\nexhibit significant performance drops when applying injected knowledge in\nbroader contexts, suggesting limited semantic integration. These findings show\nthe importance of task selection in updating LLM knowledge, showing that\neffective knowledge injection relies not just on data exposure but on the depth\nof cognitive engagement during fine-tuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.17140v1",
    "published": "2025-05-22T06:48:33+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17139v3",
    "title": "EarthSE: A Benchmark for Evaluating Earth Scientific Exploration Capability of LLMs",
    "authors": [
      "Wanghan Xu",
      "Xiangyu Zhao",
      "Yuhao Zhou",
      "Xiaoyu Yue",
      "Ben Fei",
      "Fenghua Ling",
      "Wenlong Zhang",
      "Lei Bai"
    ],
    "abstract": "Advancements in Large Language Models (LLMs) drive interest in scientific\napplications, necessitating specialized benchmarks such as Earth science.\nExisting benchmarks either present a general science focus devoid of Earth\nscience specificity or cover isolated subdomains, lacking holistic evaluation.\nFurthermore, current benchmarks typically neglect the assessment of LLMs'\ncapabilities in open-ended scientific exploration. In this paper, we present a\ncomprehensive and professional benchmark for the Earth sciences, designed to\nevaluate the capabilities of LLMs in scientific exploration within this domain,\nspanning from fundamental to advanced levels. Leveraging a corpus of 100,000\nresearch papers, we first construct two Question Answering (QA) datasets:\nEarth-Iron, which offers extensive question coverage for broad assessment, and\nEarth-Silver, which features a higher level of difficulty to evaluate\nprofessional depth. These datasets encompass five Earth spheres, 114\ndisciplines, and 11 task categories, assessing foundational knowledge crucial\nfor scientific exploration. Most notably, we introduce Earth-Gold with new\nmetrics, a dataset comprising open-ended multi-turn dialogues specifically\ndesigned to evaluate the advanced capabilities of LLMs in scientific\nexploration, including methodology induction, limitation analysis, and concept\nproposal. Extensive experiments reveal limitations in 11 leading LLMs across\ndifferent domains and tasks, highlighting considerable room for improvement in\ntheir scientific exploration capabilities. The benchmark is available on\nhttps://huggingface.co/ai-earth .",
    "pdf_url": "http://arxiv.org/pdf/2505.17139v3",
    "published": "2025-05-22T06:46:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16294v1",
    "title": "Self-Classification Enhancement and Correction for Weakly Supervised Object Detection",
    "authors": [
      "Yufei Yin",
      "Lechao Cheng",
      "Wengang Zhou",
      "Jiajun Deng",
      "Zhou Yu",
      "Houqiang Li"
    ],
    "abstract": "In recent years, weakly supervised object detection (WSOD) has attracted much\nattention due to its low labeling cost. The success of recent WSOD models is\noften ascribed to the two-stage multi-class classification (MCC) task, i.e.,\nmultiple instance learning and online classification refinement. Despite\nachieving non-trivial progresses, these methods overlook potential\nclassification ambiguities between these two MCC tasks and fail to leverage\ntheir unique strengths. In this work, we introduce a novel WSOD framework to\nameliorate these two issues. For one thing, we propose a self-classification\nenhancement module that integrates intra-class binary classification (ICBC) to\nbridge the gap between the two distinct MCC tasks. The ICBC task enhances the\nnetwork's discrimination between positive and mis-located samples in a\nclass-wise manner and forges a mutually reinforcing relationship with the MCC\ntask. For another, we propose a self-classification correction algorithm during\ninference, which combines the results of both MCC tasks to effectively reduce\nthe mis-classified predictions. Extensive experiments on the prevalent VOC 2007\n& 2012 datasets demonstrate the superior performance of our framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.16294v1",
    "published": "2025-05-22T06:45:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16293v1",
    "title": "Augmenting LLM Reasoning with Dynamic Notes Writing for Complex QA",
    "authors": [
      "Rishabh Maheshwary",
      "Masoud Hashemi",
      "Khyati Mahajan",
      "Shiva Krishna Reddy Malay",
      "Sai Rajeswar",
      "Sathwik Tejaswi Madhusudhan",
      "Spandana Gella",
      "Vikas Yadav"
    ],
    "abstract": "Iterative RAG for multi-hop question answering faces challenges with lengthy\ncontexts and the buildup of irrelevant information. This hinders a model's\ncapacity to process and reason over retrieved content and limits performance.\nWhile recent methods focus on compressing retrieved information, they are\neither restricted to single-round RAG, require finetuning or lack scalability\nin iterative RAG. To address these challenges, we propose Notes Writing, a\nmethod that generates concise and relevant notes from retrieved documents at\neach step, thereby reducing noise and retaining only essential information.\nThis indirectly increases the effective context length of Large Language Models\n(LLMs), enabling them to reason and plan more effectively while processing\nlarger volumes of input text. Notes Writing is framework agnostic and can be\nintegrated with different iterative RAG methods. We demonstrate its\neffectiveness with three iterative RAG methods, across two models and four\nevaluation datasets. Notes writing yields an average improvement of 15.6\npercentage points overall, with minimal increase in output tokens.",
    "pdf_url": "http://arxiv.org/pdf/2505.16293v1",
    "published": "2025-05-22T06:45:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16292v1",
    "title": "Characterization of the time-dependent free Schrödinger operator by the Galilei invariance",
    "authors": [
      "Hiromichi Nakazato",
      "Tohru Ozawa"
    ],
    "abstract": "The time-dependent free Schr\\\"odinger operator is shown to be characterized\nas the only linear partial differential operator of the second order that is\ninvariant under the Galilei group in the Euclidean space-time $\\mathbb\nR\\times\\mathbb R^n$. The method of proof depends on the analysis of the\ninvariance of polynomials given by the application of the linear partial\ndifferential operators to monochromatic plane waves under space rotations and\npure Galilei transformations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16292v1",
    "published": "2025-05-22T06:44:17+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16291v1",
    "title": "Fairness under Competition",
    "authors": [
      "Ronen Gradwohl",
      "Eilam Shapira",
      "Moshe Tennenholtz"
    ],
    "abstract": "Algorithmic fairness has emerged as a central issue in ML, and it has become\nstandard practice to adjust ML algorithms so that they will satisfy fairness\nrequirements such as Equal Opportunity. In this paper we consider the effects\nof adopting such fair classifiers on the overall level of ecosystem fairness.\nSpecifically, we introduce the study of fairness with competing firms, and\ndemonstrate the failure of fair classifiers in yielding fair ecosystems. Our\nresults quantify the loss of fairness in systems, under a variety of\nconditions, based on classifiers' correlation and the level of their data\noverlap. We show that even if competing classifiers are individually fair, the\necosystem's outcome may be unfair; and that adjusting biased algorithms to\nimprove their individual fairness may lead to an overall decline in ecosystem\nfairness. In addition to these theoretical results, we also provide supporting\nexperimental evidence. Together, our model and results provide a novel and\nessential call for action.",
    "pdf_url": "http://arxiv.org/pdf/2505.16291v1",
    "published": "2025-05-22T06:43:15+00:00",
    "categories": [
      "cs.LG",
      "cs.GT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16290v1",
    "title": "Multimodal Generative AI for Story Point Estimation in Software Development",
    "authors": [
      "Mohammad Rubyet Islam",
      "Peter Sandborn"
    ],
    "abstract": "This research explores the application of Multimodal Generative AI to enhance\nstory point estimation in Agile software development. By integrating text,\nimage, and categorical data using advanced models like BERT, CNN, and XGBoost,\nour approach surpasses the limitations of traditional single-modal estimation\nmethods. The results demonstrate strong accuracy for simpler story points,\nwhile also highlighting challenges in more complex categories due to data\nimbalance. This study further explores the impact of categorical data,\nparticularly severity, on the estimation process, emphasizing its influence on\nmodel performance. Our findings emphasize the transformative potential of\nmultimodal data integration in refining AI-driven project management, paving\nthe way for more precise, adaptable, and domain-specific AI capabilities.\nAdditionally, this work outlines future directions for addressing data\nvariability and enhancing the robustness of AI in Agile methodologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16290v1",
    "published": "2025-05-22T06:40:41+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "68T07, 68T45",
      "I.2.6; I.2.10; D.2.9; H.2.8"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16289v2",
    "title": "TacCompress: A Benchmark for Multi-Point Tactile Data Compression in Dexterous Hand",
    "authors": [
      "Yan Zhao",
      "Yang Li",
      "Zhengxue Cheng",
      "Hengdi Zhang",
      "Li Song"
    ],
    "abstract": "Though robotic dexterous manipulation has progressed substantially recently,\nchallenges like in-hand occlusion still necessitate fine-grained tactile\nperception, leading to the integration of more tactile sensors into robotic\nhands. Consequently, the increased data volume imposes substantial bandwidth\npressure on signal transmission from the hand's controller. However, the\nacquisition and compression of multi-point tactile signals based on the\ndexterous hands' physical structures have not been thoroughly explored. In this\npaper, our contributions are twofold. First, we introduce a Multi-Point Tactile\nDataset for Dexterous Hand Grasping (Dex-MPTD). This dataset captures tactile\nsignals from multiple contact sensors across various objects and grasping\nposes, offering a comprehensive benchmark for advancing dexterous robotic\nmanipulation research. Second, we investigate both lossless and lossy\ncompression on Dex-MPTD by converting tactile data into images and applying six\nlossless and five lossy image codecs for efficient compression. Experimental\nresults demonstrate that tactile data can be losslessly compressed to as low as\n0.0364 bits per sub-sample (bpss), achieving approximately 200$\\times$\ncompression ratio compared to the raw tactile data. Efficient lossy compressors\nlike HM and VTM can achieve about 1000$\\times$ data reductions while preserving\nacceptable data fidelity. The exploration of lossy compression also reveals\nthat screen-content-targeted coding tools outperform general-purpose codecs in\ncompressing tactile data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16289v2",
    "published": "2025-05-22T06:36:37+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16288v1",
    "title": "No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery",
    "authors": [
      "Xiaoxue Han",
      "Pengfei Hu",
      "Jun-En Ding",
      "Chang Lu",
      "Feng Liu",
      "Yue Ning"
    ],
    "abstract": "Deep learning models trained on extensive Electronic Health Records (EHR)\ndata have achieved high accuracy in diagnosis prediction, offering the\npotential to assist clinicians in decision-making and treatment planning.\nHowever, these models lack two crucial features that clinicians highly value:\ninterpretability and interactivity. The ``black-box'' nature of these models\nmakes it difficult for clinicians to understand the reasoning behind\npredictions, limiting their ability to make informed decisions. Additionally,\nthe absence of interactive mechanisms prevents clinicians from incorporating\ntheir own knowledge and experience into the decision-making process. To address\nthese limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal\ndiscovery framework that integrates personalized knowledge databases and\nagentic LLMs. II-KEA enhances interpretability through explicit reasoning and\ncausal analysis, while also improving interactivity by allowing clinicians to\ninject their knowledge and experience through customized knowledge bases and\nprompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating\nsuperior performance along with enhanced interpretability and interactivity, as\nevidenced by its strong results from extensive case studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16288v1",
    "published": "2025-05-22T06:36:30+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.11051v1",
    "title": "Software Security Mapping Framework: Operationalization of Security Requirements",
    "authors": [
      "Sung Une Lee",
      "Liming Dong",
      "Zhenchang Xing",
      "Muhammad Ejaz Ahmed",
      "Stefan Avgoustakis"
    ],
    "abstract": "The escalating complexity of modern software development environments has\nheightened concerns around supply chain security. However, existing frameworks\noften fall short in translating abstract security principles into concrete,\nactionable practices. This paper introduces the Software Security Mapping\nFramework, a structured solution designed to operationalize security\nrequirements across hierarchical levels -- from high-level regulatory standards\n(e.g., ISM, Australia cybersecurity standard published by the Australian\nSignals Directorate), through mid-level frameworks (e.g., NIST SSDF, the U.S.\nSecure Software Development Framework), to fine-grained technical activities\n(e.g., SLSA, a software supply chain security framework). Developed through\ncollaborative research with academic experts and industry practitioners, the\nframework systematically maps 131 refined security requirements to over 400\nactionable operational steps spanning the software development lifecycle. It is\ngrounded in four core security goals: Secure Software Environment, Secure\nSoftware Development, Software Traceability, and Vulnerability Management. Our\napproach leverages the KAOS goal modeling methodology to establish traceable\nlinkages between strategic goals and tactical operations, enhancing clarity,\naccountability, and practical implementation. To facilitate adoption, we\nprovide a web-based navigation tool for interactive exploration of the\nframework. A real-world case study based on the Log4j vulnerability illustrates\nthe framework's utility by generating a tailored checklist aligned with\nindustry best practices. Additionally, we offer a structured, machine-readable\nOSCAL Catalog Model of the Software Security Mapping Framework, enabling\norganizations to automate implementation, streamline compliance processes, and\nrespond effectively to evolving security risks.",
    "pdf_url": "http://arxiv.org/pdf/2506.11051v1",
    "published": "2025-05-22T06:34:48+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22681v1",
    "title": "General contractions in new type perturbed metric spaces",
    "authors": [
      "Bekir Danış"
    ],
    "abstract": "We focus on the new type perturbed metric spaces and introduce a contraction\nmapping namely new type perturbed Kannan mappings. For these mappings, we show\nthat Banach's fixed point theorem holds. Moreover, this new generalization of\nBanach's contraction principle does not depend on the continuity of the\noperator.",
    "pdf_url": "http://arxiv.org/pdf/2505.22681v1",
    "published": "2025-05-22T06:34:41+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16287v1",
    "title": "Machine learning approach to stock price crash risk",
    "authors": [
      "Abdullah Karasan",
      "Ozge Sezgin Alp",
      "Gerhard-Wilhelm Weber"
    ],
    "abstract": "In this study, we propose a novel machine-learning-based measure for stock\nprice crash risk, utilizing the minimum covariance determinant methodology.\nEmploying this newly introduced dependent variable, we predict stock price\ncrash risk through cross-sectional regression analysis. The findings confirm\nthat the proposed method effectively captures stock price crash risk, with the\nmodel demonstrating strong performance in terms of both statistical\nsignificance and economic relevance. Furthermore, leveraging a newly developed\nfirm-specific investor sentiment index, the analysis identifies a positive\ncorrelation between stock price crash risk and firm-specific investor\nsentiment. Specifically, higher levels of sentiment are associated with an\nincreased likelihood of stock price crash risk. This relationship remains\nrobust across different firm sizes and when using the detoned version of the\nfirm-specific investor sentiment index, further validating the reliability of\nthe proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.16287v1",
    "published": "2025-05-22T06:33:35+00:00",
    "categories": [
      "q-fin.CP"
    ],
    "primary_category": "q-fin.CP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16286v2",
    "title": "Microwave Engineering of Tunable Spin Interactions with Superconducting Qubits",
    "authors": [
      "Kui Zhao",
      "Ziting Wang",
      "Yu Liu",
      "Gui - Han Liang",
      "Cai - Ping Fang",
      "Yun - Hao Shi",
      "Lv Zhang",
      "Jia - Chi Zhang",
      "Tian - Ming Li",
      "Hao Li",
      "Yueshan Xu",
      "Wei - Guo Ma",
      "Hao - Tian Liu",
      "Jia - Cheng Song",
      "Zhen - Ting Bao",
      "Yong - Xi Xiao",
      "Bing - Jie Chen",
      "Cheng - Lin Deng",
      "Zheng - He Liu",
      "Yang He",
      "Si - Yun Zhou",
      "Xiaohui Song",
      "Zhongcheng Xiang",
      "Dongning Zheng",
      "Kaixuan Huang",
      "Kai Xu",
      "Heng Fan"
    ],
    "abstract": "Quantum simulation has emerged as a powerful framework for investigating\ncomplex many - body phenomena. A key requirement for emulating these dynamics\nis the realization of fully controllable quantum systems enabling various spin\ninteractions. Yet, quantum simulators remain constrained in the types of\nattainable interactions. Here we demonstrate experimental realization of\nmultiple microwave - engineered spin interactions in superconducting quantum\ncircuits. By precisely controlling the native XY interaction and microwave\ndrives, we achieve tunable spin Hamiltonians including: (i) XYZ spin models\nwith continuously adjustable parameters, (ii) transverse - field Ising systems,\nand (iii) Dzyaloshinskii - Moriya interacting systems. Our work expands the\ntoolbox for analogue - digital quantum simulation, enabling exploration of a\nwide range of exotic quantum spin models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16286v2",
    "published": "2025-05-22T06:32:36+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16285v1",
    "title": "Maps between circle bundles: Fiber-preserving, Finiteness and Realization of mapping degree sets",
    "authors": [
      "Christoforos Neofytidis",
      "Hongbin Sun",
      "Ye Tian",
      "Shicheng Wang",
      "Zhongzi Wang"
    ],
    "abstract": "Let $E_i$ be an oriented circle bundle over a closed oriented aspherical\n$n$-manifold $M_i$ with Euler class $e_i\\in H^2(M_i;\\mathbb{Z})$, $i=1,2$. We\nprove the following:\n  (i) If every finite-index subgroup of $\\pi_1(M_2)$ has trivial center, then\nany non-zero degree map from $E_1$ to $E_2$ is homotopic to a fiber-preserving\nmap.\n  (ii) The mapping degree set of fiber-preserving maps from $E_1$ to $E_2$ is\ngiven by $$\\{0\\} \\cup\\{k\\cdot \\mathrm{deg}(f) \\ | \\, k\\ne 0, \\ f\\colon M_1\\to\nM_2 \\, \\text{with} \\, \\mathrm{deg}(f)\\ne 0 \\ \\text{such that}\\,\nf^\\#(e_2)=ke_1\\},$$ where $f^\\# \\colon H^2(M_2;\\mathbb{Z})\\to\nH^2(M_1;\\mathbb{Z})$ is the induced homomorphism.\n  As applications of (i) and (ii), we obtain the following results with respect\nto the finiteness and the realization problems for mapping degree sets:\n  ($\\mathcal F$) The mapping degree set $D(E_1, E_2)$ is finite if $M_2$ is\nhyperbolic and $e_2$ is not torsion.\n  ($\\mathcal R$) For any finite set $A$ of integers containing $0$ and each\n$n>2$, $A$ is the mapping degree set $D(M,N)$ for some closed oriented\n$n$-manifolds $M$ and $N$.\n  Items (i) and ($\\mathcal F$) extend in all dimensions $\\geq 3$ the previously\nknown $3$-dimensional case (i.e., for maps between circle bundles over\nhyperbolic surfaces). Item ($\\mathcal R$) gives a complete answer to the\nrealization problem for finite sets (containing $0$) in any dimension,\nestablishing in particular the previously unknown cases in dimensions $n= 4,\n5$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16285v1",
    "published": "2025-05-22T06:32:03+00:00",
    "categories": [
      "math.GT",
      "math.AT",
      "math.GR",
      "math.NT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16284v1",
    "title": "Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse",
    "authors": [
      "Josh Alman",
      "Zhao Song"
    ],
    "abstract": "Attention mechanisms lie at the heart of modern large language models (LLMs).\nStraightforward algorithms for forward and backward (gradient) computation take\nquadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023]\nand [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary\nunless the model weights are small, in which case almost linear time algorithms\nare possible. In this paper, we show that large weights are necessary to avoid\na strong preclusion to representational strength we call layer collapse, which\nmeans that the entire network can be approximated well by a network with only a\nsingle layer. Thus, the quadratic running time of attention is unavoidable for\nexpressive transformers.\n  The notion of layer collapse that we introduce is a variant on the notion of\nrank collapse from the work of [Dong, Cordonnier, and Loukas ICML 2021]. They\nshowed that in Self Attention Networks with small weights and with skip\nconnections, rank collapse must occur. This is typically interpreted as\njustifying the necessity of skip connections in expressive networks. However,\nour result shows that even with skip connections, if the weights are small,\nthen layer collapse still occurs. Thus, only large weights, and not skip\nconnections, can prevent these representational weaknesses.",
    "pdf_url": "http://arxiv.org/pdf/2505.16284v1",
    "published": "2025-05-22T06:26:28+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16283v1",
    "title": "Efficient Prototype Consistency Learning in Medical Image Segmentation via Joint Uncertainty and Data Augmentation",
    "authors": [
      "Lijian Li",
      "Yuanpeng He",
      "Chi-Man Pun"
    ],
    "abstract": "Recently, prototype learning has emerged in semi-supervised medical image\nsegmentation and achieved remarkable performance. However, the scarcity of\nlabeled data limits the expressiveness of prototypes in previous methods,\npotentially hindering the complete representation of prototypes for class\nembedding. To overcome this issue, we propose an efficient prototype\nconsistency learning via joint uncertainty quantification and data augmentation\n(EPCL-JUDA) to enhance the semantic expression of prototypes based on the\nframework of Mean-Teacher. The concatenation of original and augmented labeled\ndata is fed into student network to generate expressive prototypes. Then, a\njoint uncertainty quantification method is devised to optimize pseudo-labels\nand generate reliable prototypes for original and augmented unlabeled data\nseparately. High-quality global prototypes for each class are formed by fusing\nlabeled and unlabeled prototypes, which are utilized to generate\nprototype-to-features to conduct consistency learning. Notably, a prototype\nnetwork is proposed to reduce high memory requirements brought by the\nintroduction of augmented data. Extensive experiments on Left Atrium,\nPancreas-NIH, Type B Aortic Dissection datasets demonstrate EPCL-JUDA's\nsuperiority over previous state-of-the-art approaches, confirming the\neffectiveness of our framework. The code will be released soon.",
    "pdf_url": "http://arxiv.org/pdf/2505.16283v1",
    "published": "2025-05-22T06:25:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16282v1",
    "title": "ARPO:End-to-End Policy Optimization for GUI Agents with Experience Replay",
    "authors": [
      "Fanbin Lu",
      "Zhisheng Zhong",
      "Shu Liu",
      "Chi-Wing Fu",
      "Jiaya Jia"
    ],
    "abstract": "Training large language models (LLMs) as interactive agents for controlling\ngraphical user interfaces (GUIs) presents a unique challenge to optimize\nlong-horizon action sequences with multimodal feedback from complex\nenvironments. While recent works have advanced multi-turn reinforcement\nlearning (RL) for reasoning and tool-using capabilities in LLMs, their\napplication to GUI-based agents remains relatively underexplored due to the\ndifficulty of sparse rewards, delayed feedback, and high rollout costs. In this\npaper, we investigate end-to-end policy optimization for vision-language-based\nGUI agents with the aim of improving performance on complex, long-horizon\ncomputer tasks. We propose Agentic Replay Policy Optimization (ARPO), an\nend-to-end RL approach that augments Group Relative Policy Optimization (GRPO)\nwith a replay buffer to reuse the successful experience across training\niterations. To further stabilize the training process, we propose a task\nselection strategy that filters tasks based on baseline agent performance,\nallowing the agent to focus on learning from informative interactions.\nAdditionally, we compare ARPO with offline preference optimization approaches,\nhighlighting the advantages of policy-based methods in GUI environments.\nExperiments on the OSWorld benchmark demonstrate that ARPO achieves competitive\nresults, establishing a new performance baseline for LLM-based GUI agents\ntrained via reinforcement learning. Our findings underscore the effectiveness\nof reinforcement learning for training multi-turn, vision-language GUI agents\ncapable of managing complex real-world UI interactions. Codes and\nmodels:https://github.com/dvlab-research/ARPO.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.16282v1",
    "published": "2025-05-22T06:24:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16281v1",
    "title": "HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation Evaluation",
    "authors": [
      "Shijie Zhang",
      "Renhao Li",
      "Songsheng Wang",
      "Philipp Koehn",
      "Min Yang",
      "Derek F. Wong"
    ],
    "abstract": "The advancement of Large Language Models (LLMs) enables flexible and\ninterpretable automatic evaluations. In the field of machine translation\nevaluation, utilizing LLMs with translation error annotations based on\nMultidimensional Quality Metrics (MQM) yields more human-aligned judgments.\nHowever, current LLM-based evaluation methods still face challenges in\naccurately identifying error spans and assessing their severity. In this paper,\nwe propose HiMATE, a Hierarchical Multi-Agent Framework for Machine Translation\nEvaluation. We argue that existing approaches inadequately exploit the\nfine-grained structural and semantic information within the MQM hierarchy. To\naddress this, we develop a hierarchical multi-agent system grounded in the MQM\nerror typology, enabling granular evaluation of subtype errors. Two key\nstrategies are incorporated to further mitigate systemic hallucinations within\nthe framework: the utilization of the model's self-reflection capability and\nthe facilitation of agent discussion involving asymmetric information.\nEmpirically, HiMATE outperforms competitive baselines across different datasets\nin conducting human-aligned evaluations. Further analyses underscore its\nsignificant advantage in error span detection and severity assessment,\nachieving an average F1-score improvement of 89% over the best-performing\nbaseline. We make our code and data publicly available at\nhttps://anonymous.4open.science/r/HiMATE-Anony.",
    "pdf_url": "http://arxiv.org/pdf/2505.16281v1",
    "published": "2025-05-22T06:24:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16280v1",
    "title": "Brand: Managing Training Data with Batched Random Access",
    "authors": [
      "Yuhao Li",
      "Xuanhua Shi",
      "Yunfei Zhao",
      "Yongluan Zhou",
      "Yusheng Hua",
      "Xuehai Qian"
    ],
    "abstract": "This paper propose Brand, a comprehensive memory management system for deep\nlearning training (DLT) where the memory capacity is much smaller than the size\nof the training datasets. Brand starts with a bold design choice that data\nfiles are always read from disk in batch, named chunk. Based on this\nassumption, we propose efficient data access protocol in both single-node\nsetting and distributed environment with multiple nodes. The protocol minimizes\nthe wasted data read due to larger granularity, enables efficient inter-node\nprefetching, while still ensuring randomness required by DLT. The experimental\nresults indicate that Brand can significantly accelerate data fetching in DLT,\nachieving up to a 4.57x improvement in end-to-end training compared to PyTorch.",
    "pdf_url": "http://arxiv.org/pdf/2505.16280v1",
    "published": "2025-05-22T06:23:37+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16279v1",
    "title": "MM-MovieDubber: Towards Multi-Modal Learning for Multi-Modal Movie Dubbing",
    "authors": [
      "Junjie Zheng",
      "Zihao Chen",
      "Chaofan Ding",
      "Yunming Liang",
      "Yihan Fan",
      "Huan Yang",
      "Lei Xie",
      "Xinhan Di"
    ],
    "abstract": "Current movie dubbing technology can produce the desired speech using a\nreference voice and input video, maintaining perfect synchronization with the\nvisuals while effectively conveying the intended emotions. However, crucial\naspects of movie dubbing, including adaptation to various dubbing styles,\neffective handling of dialogue, narration, and monologues, as well as\nconsideration of subtle details such as speaker age and gender, remain\ninsufficiently explored. To tackle these challenges, we introduce a multi-modal\ngenerative framework. First, it utilizes a multi-modal large vision-language\nmodel (VLM) to analyze visual inputs, enabling the recognition of dubbing types\nand fine-grained attributes. Second, it produces high-quality dubbing using\nlarge speech generation models, guided by multi-modal inputs. Additionally, a\nmovie dubbing dataset with annotations for dubbing types and subtle details is\nconstructed to enhance movie understanding and improve dubbing quality for the\nproposed multi-modal framework. Experimental results across multiple benchmark\ndatasets show superior performance compared to state-of-the-art (SOTA) methods.\nIn details, the LSE-D, SPK-SIM, EMO-SIM, and MCD exhibit improvements of up to\n1.09%, 8.80%, 19.08%, and 18.74%, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.16279v1",
    "published": "2025-05-22T06:23:05+00:00",
    "categories": [
      "cs.MM",
      "cs.CV"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16278v1",
    "title": "DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving",
    "authors": [
      "Zhenjie Yang",
      "Yilin Chai",
      "Xiaosong Jia",
      "Qifeng Li",
      "Yuqian Shao",
      "Xuekai Zhu",
      "Haisheng Su",
      "Junchi Yan"
    ],
    "abstract": "End-to-end autonomous driving (E2E-AD) demands effective processing of\nmulti-view sensory data and robust handling of diverse and complex driving\nscenarios, particularly rare maneuvers such as aggressive turns. Recent success\nof Mixture-of-Experts (MoE) architecture in Large Language Models (LLMs)\ndemonstrates that specialization of parameters enables strong scalability. In\nthis work, we propose DriveMoE, a novel MoE-based E2E-AD framework, with a\nScene-Specialized Vision MoE and a Skill-Specialized Action MoE. DriveMoE is\nbuilt upon our $\\pi_0$ Vision-Language-Action (VLA) baseline (originally from\nthe embodied AI field), called Drive-$\\pi_0$. Specifically, we add Vision MoE\nto Drive-$\\pi_0$ by training a router to select relevant cameras according to\nthe driving context dynamically. This design mirrors human driving cognition,\nwhere drivers selectively attend to crucial visual cues rather than\nexhaustively processing all visual information. In addition, we add Action MoE\nby training another router to activate specialized expert modules for different\ndriving behaviors. Through explicit behavioral specialization, DriveMoE is able\nto handle diverse scenarios without suffering from modes averaging like\nexisting models. In Bench2Drive closed-loop evaluation experiments, DriveMoE\nachieves state-of-the-art (SOTA) performance, demonstrating the effectiveness\nof combining vision and action MoE in autonomous driving tasks. We will release\nour code and models of DriveMoE and Drive-$\\pi_0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16278v1",
    "published": "2025-05-22T06:23:04+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16277v1",
    "title": "Spontaneous Speech Variables for Evaluating LLMs Cognitive Plausibility",
    "authors": [
      "Sheng-Fu Wang",
      "Laurent Prevot",
      "Jou-an Chi",
      "Ri-Sheng Huang",
      "Shu-Kai Hsieh"
    ],
    "abstract": "The achievements of Large Language Models in Natural Language Processing,\nespecially for high-resource languages, call for a better understanding of\ntheir characteristics from a cognitive perspective. Researchers have attempted\nto evaluate artificial models by testing their ability to predict behavioral\n(e.g., eye-tracking fixations) and physiological (e.g., brain responses)\nvariables during language processing (e.g., reading/listening). In this paper,\nwe propose using spontaneous speech corpora to derive production variables\n(speech reductions, prosodic prominences) and applying them in a similar\nfashion. More precisely, we extract. We then test models trained with a\nstandard procedure on different pretraining datasets (written, spoken, and\nmixed genres) for their ability to predict these two variables. Our results\nshow that, after some fine-tuning, the models can predict these production\nvariables well above baselines. We also observe that spoken genre training data\nprovides more accurate predictions than written genres. These results\ncontribute to the broader effort of using high-quality speech corpora as\nbenchmarks for LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16277v1",
    "published": "2025-05-22T06:23:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16276v1",
    "title": "How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance",
    "authors": [
      "Desiree Heim",
      "Lars-Peter Meyer",
      "Markus Schröder",
      "Johannes Frey",
      "Andreas Dengel"
    ],
    "abstract": "When using Large Language Models (LLMs) to support Knowledge Graph\nEngineering (KGE), one of the first indications when searching for an\nappropriate model is its size. According to the scaling laws, larger models\ntypically show higher capabilities. However, in practice, resource costs are\nalso an important factor and thus it makes sense to consider the ratio between\nmodel performance and costs. The LLM-KG-Bench framework enables the comparison\nof LLMs in the context of KGE tasks and assesses their capabilities of\nunderstanding and producing KGs and KG queries. Based on a dataset created in\nan LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the\nmodel size scaling laws specific to KGE tasks. In our analyses, we assess how\nbenchmark scores evolve between different model size categories. Additionally,\nwe inspect how the general score development of single models and families of\nmodels correlates to their size. Our analyses revealed that, with a few\nexceptions, the model size scaling laws generally also apply to the selected\nKGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e.,\nthe task performance did not change much between a model and the next larger\nmodel. In these cases, smaller models could be considered to achieve high\ncost-effectiveness. Regarding models of the same family, sometimes larger\nmodels performed worse than smaller models of the same family. These effects\noccurred only locally. Hence it is advisable to additionally test the next\nsmallest and largest model of the same family.",
    "pdf_url": "http://arxiv.org/pdf/2505.16276v1",
    "published": "2025-05-22T06:21:40+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16275v1",
    "title": "Semiparametric Bernstein-von Mises theorems for reversible diffusions",
    "authors": [
      "Matteo Giordano",
      "Kolyan Ray"
    ],
    "abstract": "We establish a general semiparametric Bernstein-von Mises theorem for\nBayesian nonparametric priors based on continuous observations in a periodic\nreversible multidimensional diffusion model. We consider a wide range of\nfunctionals satisfying an approximate linearization condition, including\nseveral nonlinear functionals of the invariant measure. Our result is applied\nto Gaussian and Besov-Laplace priors, showing these can perform efficient\nsemiparametric inference and thus justifying the corresponding Bayesian\napproach to uncertainty quantification. Our theoretical results are illustrated\nvia numerical simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16275v1",
    "published": "2025-05-22T06:21:29+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.16274v1",
    "title": "Multimodal AI-based visualization of strategic leaders' emotional dynamics: a deep behavioral analysis of Trump's trade war discourse",
    "authors": [
      "Wei Meng"
    ],
    "abstract": "This study investigates the emotional rhythms and behavioral mechanisms of\ndominant political leaders in strategic decision-making. Using the Trump\nadministration's 125 percent tariff hike on China as a case, it adopts a\nMultimodal Cognitive Behavioral Modeling framework. This includes\nmicro-expression tracking, acoustic intonation analysis, semantic flow\nmodeling, cognitive load simulation, and strategic behavior mapping to\nconstruct a full-cycle simulation of emotion, motivation, and output. Results\nreveal that Trump's decisions are not driven by rational deduction, but emerge\nfrom dominance-coherence rhythms. A six-axis National Strategic Tempo\nIntervention Framework is proposed to support anticipatory policy modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.16274v1",
    "published": "2025-05-22T06:19:57+00:00",
    "categories": [
      "cs.CY",
      "68T07, 68T45, 91E45, 91F20, 68U05, 62H30",
      "I.2.10; I.2.7; H.1.2; I.5.4; H.5.2; J.4"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16273v1",
    "title": "Symmetries and selection rules in photoelectron chiral dichroism from tailored light",
    "authors": [
      "Ofer Neufeld"
    ],
    "abstract": "Photoelectron circular dichroism (PECD) is a method whereby randomly oriented\nchiral molecules are irradiated by circularly-polarized light, photoionizing\nelectrons, which are measured in a momentum-resolved manner. This scheme\npermits chiral light-matter interactions within the electric-dipole\napproximation (avoiding weak magnetic-dipole interactions), yielding huge\nchiral signals in the form of a forwards-backwards asymmetry in photoemission.\nRecently, more intricate realizations of PECD have been explored where the\ncircularly-polarized light is replaced with elaborate polarization-tailored\nlight (e.g. bi-chromatic, non-collinear, etc.), some of which do not even\nrequire circularly-polarized components, but still lead to massive chiral\nsignals. However, the connection between generalized symmetries and asymmetries\nof the laser drive and selection rules in PECD have not yet been derived. Here\nwe formulate this connection analytically from group theory, also predicting\ntwo previously unknown selection rules for PECD from fields with dynamical\ninversion and improper-rotational symmetries. We further propose bi-chromatic\nbi-elliptical fields for breaking symmetries in typical spectra, yielding\npotentially more information for ultrafast-resolved measurements. We\nnumerically demonstrate all of our results with state-of-the-art ab-initio\nsimulations in the archetypal chiral molecule, Bromochlorofluoromethane,\nproviding predictions for experiments. Our work presents a roadmap for\nanalyzing PECD from tailored light and resolved a long-standing issue in the\nfield. It should motivate theoretical and experimental investigations in novel\nPECD set-ups.",
    "pdf_url": "http://arxiv.org/pdf/2505.16273v1",
    "published": "2025-05-22T06:18:23+00:00",
    "categories": [
      "physics.chem-ph",
      "physics.optics"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17138v2",
    "title": "RAP: Runtime-Adaptive Pruning for LLM Inference",
    "authors": [
      "Huanrong Liu",
      "Chunlin Tian",
      "Xuyang Wei",
      "Jiaheng Dai",
      "Qin Liu",
      "Tianqi Wei",
      "Qingbiao Li",
      "Li Li"
    ],
    "abstract": "Large language models (LLMs) excel at language understanding and generation,\nbut their enormous computational and memory requirements hinder deployment.\nCompression offers a potential solution to mitigate these constraints. However,\nmost existing methods rely on fixed heuristics and thus fail to adapt to\nruntime memory variations or heterogeneous KV-cache demands arising from\ndiverse user requests. To address these limitations, we propose RAP, an elastic\npruning framework driven by reinforcement learning (RL) that dynamically\nadjusts compression strategies in a runtime-aware manner. Specifically, RAP\ndynamically tracks the evolving ratio between model parameters and KV-cache\nacross practical execution. Recognizing that FFNs house most parameters,\nwhereas parameter -light attention layers dominate KV-cache formation, the RL\nagent retains only those components that maximize utility within the current\nmemory budget, conditioned on instantaneous workload and device state.\nExtensive experiments results demonstrate that RAP outperforms state-of-the-art\nbaselines, marking the first time to jointly consider model weights and\nKV-cache on the fly.",
    "pdf_url": "http://arxiv.org/pdf/2505.17138v2",
    "published": "2025-05-22T06:12:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16272v1",
    "title": "Die Separation for Mitigation of Phonon Bursts in Superconducting Circuits",
    "authors": [
      "Guy Moshel",
      "Omer Rabinowitz",
      "Eliya Blumenthal",
      "Shay Hacohen-Gourgy"
    ],
    "abstract": "Cosmic rays and background radioactive decay can deposit significant energy\ninto superconducting quantum circuits on planar chips. This energy converts\ninto pair-breaking phonons that travel across the substrate and generate\nquasiparticles, leading to correlated energy and phase errors in nearby qubits.\nTo mitigate this, we fabricated two separate dies and placed them adjacently\nwithout a galvanic connection between them. This blocks phonon propagation from\none die to the other. Using microwave kinetic inductance detectors on both\ndies, we successfully detected high-energy bursts and conclusively demonstrated\nthe blocking effect. However, we also observed simultaneous events in both\ndies, likely from a single cosmic particle traversing both dies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16272v1",
    "published": "2025-05-22T06:08:34+00:00",
    "categories": [
      "quant-ph",
      "physics.ins-det"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16271v1",
    "title": "Variations of the Near-Surface Electric field measured at Aragats during Geomagnetic Storms",
    "authors": [
      "A. Chilingarian"
    ],
    "abstract": "At least two mechanisms effectively transfer interplanetary magnetic field\n(IMF) disturbances into the atmosphere. First, the inflow of solar wind into\nthe ionosphere at low latitudes significantly enhances the total vertical\nelectron content, increasing atmospheric conductivity. Second, Forbush\ndecreases (FD) reduce the cosmic ray flux by a few percent, lowering ionization\nlevels at middle latitudes and decreasing conductivity. Changes in atmospheric\nconductivity affect the global electric circuit and atmospheric electric field\n(AEF). However, to study the response of AEF to geomagnetic storms (GMS), it is\nnecessary to carefully monitor atmospheric conditions before and during storms,\nas meteorological influences can be much stronger than those of GMS. Charged\nclouds above detectors, lightning flashes, and abrupt weather changes\nsignificantly impact near-surface electric field (NSEF) variations, which serve\nas a proxy for AEF measured at the Earth's surface. The facilities at Aragats\nstation monitor all environmental parameters on a one-minute timescale. We\nanalyze four GMS events described in previous studies, detailing the\ncorresponding weather conditions to isolate the genuine influence of GMS on\nNSEF. The GMS of June 22, 2015, and September 8, 2017, occurred under\nfair-weather conditions, providing clear evidence of GMS influence on NSEF.\nThese events were long-lasting, positive, and modest, ranging from 0.2 to 0.3\nkV/m, and coincided with the depletion phase of FD. The sky was clear, no rain\nwas detected, and lightning flashes from previous thunderstorms were more than\n20 km from the station. The other two events did not meet favorable weather\ncriteria, and their occurrence during GMS seemed incidental. We identify a\nfeature that may indicate the solar (FD) origin of NSEF enhancement: a dip in\nthe enhanced NSEF during the daytime.",
    "pdf_url": "http://arxiv.org/pdf/2505.16271v1",
    "published": "2025-05-22T06:04:20+00:00",
    "categories": [
      "physics.ao-ph",
      "physics.plasm-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.18207v1",
    "title": "BAGELS: Benchmarking the Automated Generation and Extraction of Limitations from Scholarly Text",
    "authors": [
      "Ibrahim Al Azher",
      "Miftahul Jannat Mokarrama",
      "Zhishuai Guo",
      "Sagnik Ray Choudhury",
      "Hamed Alhoori"
    ],
    "abstract": "In scientific research, limitations refer to the shortcomings, constraints,\nor weaknesses within a study. Transparent reporting of such limitations can\nenhance the quality and reproducibility of research and improve public trust in\nscience. However, authors often a) underreport them in the paper text and b)\nuse hedging strategies to satisfy editorial requirements at the cost of\nreaders' clarity and confidence. This underreporting behavior, along with an\nexplosion in the number of publications, has created a pressing need to\nautomatically extract or generate such limitations from scholarly papers. In\nthis direction, we present a complete architecture for the computational\nanalysis of research limitations. Specifically, we create a dataset of\nlimitations in ACL, NeurIPS, and PeerJ papers by extracting them from papers'\ntext and integrating them with external reviews; we propose methods to\nautomatically generate them using a novel Retrieval Augmented Generation (RAG)\ntechnique; we create a fine-grained evaluation framework for generated\nlimitations; and we provide a meta-evaluation for the proposed evaluation\ntechniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.18207v1",
    "published": "2025-05-22T06:04:02+00:00",
    "categories": [
      "cs.DL",
      "cs.LG",
      "68T50 Natural language processing"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16270v1",
    "title": "Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning",
    "authors": [
      "Jiaru Zou",
      "Yikun Ban",
      "Zihao Li",
      "Yunzhe Qi",
      "Ruizhong Qiu",
      "Ling Yang",
      "Jingrui He"
    ],
    "abstract": "Large language models are typically adapted to downstream tasks through\nsupervised fine-tuning on domain-specific data. While standard fine-tuning\nfocuses on minimizing generation loss to optimize model parameters, we take a\ndeeper step by retaining and leveraging the model's own learning signals,\nanalogous to how human learners reflect on past mistakes to improve future\nperformance. We first introduce the concept of Mistake Log to systematically\ntrack the model's learning behavior and recurring errors throughout\nfine-tuning. Treating the original transformer-based model as the Pilot, we\ncorrespondingly design a Copilot model to refine the Pilot's inference\nperformance via logits rectification. We name the overall Pilot-Copilot\nframework the Transformer Copilot, which introduces (i) a novel Copilot model\ndesign, (ii) a joint training paradigm where the Copilot continuously learns\nfrom the evolving Mistake Log alongside the Pilot, and (iii) a fused inference\nparadigm where the Copilot rectifies the Pilot's logits for enhanced\ngeneration. We provide both theoretical and empirical analyses on our new\nlearning framework. Experiments on 12 benchmarks spanning commonsense,\narithmetic, and recommendation tasks demonstrate that Transformer Copilot\nconsistently improves performance by up to 34.5%, while introducing marginal\ncomputational overhead to Pilot models and exhibiting strong scalability and\ntransferability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16270v1",
    "published": "2025-05-22T06:00:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16269v1",
    "title": "Energy Spectra of Secondary Particles Induced by Solar Energetic Proton Events and Magnetospheric Effects",
    "authors": [
      "A. Chilingarian"
    ],
    "abstract": "We investigate the energy spectra of secondary cosmic ray particles\nassociated with two distinct solar events: the magnetospheric effect (ME) of 5\nNovember 2023 and ground-level enhancement (GLE 74) of 11 May 2024. Using data\nfrom the SEVAN and Neutron Monitor networks and energy release histograms from\nparticle spectrometers, we reconstruct spectra and identify key differences\nbetween ME and GLE. CORSIKA-based simulations reveal that MEs are caused by\ngalactic protons below geomagnetic cutoff rigidities (Rc = 7.1 GV at Aragats)\npenetrating the magnetosphere during geomagnetic storms, leading to localized\nflux enhancements at mountain altitudes but not at sea level. In contrast, SEP\nevents initiated by GLEs can involve high-energy solar protons (>10 GeV),\nproducing secondaries that reach sea level at middle latitudes. We present\nintegral energy spectra and spatial correlation of detector responses,\ndemonstrating that SEVAN's energy-resolved data offer new diagnostic tools for\nidentifying hard-spectrum SERs. Our results refine the definition of ME and\nsuggest a strategy for early warning of hazardous solar particle events based\non real-time ground-based observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16269v1",
    "published": "2025-05-22T06:00:36+00:00",
    "categories": [
      "physics.ao-ph",
      "astro-ph.SR"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16268v2",
    "title": "Variational Quantum Algorithm for Solving the Liouvillian Gap",
    "authors": [
      "Xu-Dan Xie",
      "Zheng-Yuan Xue",
      "Dan-Bo Zhang"
    ],
    "abstract": "In open quantum systems, the Liouvillian gap characterizes the relaxation\ntime toward the steady state. However, accurately computing this quantity is\nnotoriously difficult due to the exponential growth of the Hilbert space and\nthe non-Hermitian nature of the Liouvillian superoperator. In this work, we\npropose a variational quantum algorithm for efficiently estimating the\nLiouvillian gap. By utilizing the Choi-Jamiokowski isomorphism, we reformulate\nthe problem as finding the first excitation energy of an effective\nnon-Hermitian Hamiltonian. Our method employs variance minimization with an\northogonality constraint to locate the first excited state and adopts a\ntwo-stage optimization scheme to enhance convergence. Moreover, to address\nscenarios with degenerate steady states, we introduce an iterative\nenergy-offset scanning technique. Numerical simulations on the dissipative XXZ\nmodel confirm the accuracy and robustness of our algorithm across a range of\nsystem sizes and dissipation strengths. These results demonstrate the promise\nof variational quantum algorithms for simulating open quantum many-body systems\non near-term quantum hardware.",
    "pdf_url": "http://arxiv.org/pdf/2505.16268v2",
    "published": "2025-05-22T05:59:55+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21518v1",
    "title": "Resilient LLM-Empowered Semantic MAC Protocols via Zero-Shot Adaptation and Knowledge Distillation",
    "authors": [
      "Yongjun Kim",
      "Jihong Park",
      "Mehdi Bennis",
      "Junil Choi"
    ],
    "abstract": "Neural network-based medium access control (MAC) protocol models (NPMs)\nimprove goodput through site-specific operations but are vulnerable to shifts\nfrom their training network environments, such as changes in the number of user\nequipments (UEs) severely degrade goodput. To enhance resilience against such\nenvironmental shifts, we propose three novel semantic MAC protocol frameworks\nempowered by large language models (LLMs). First, we introduce a token-based\nprotocol model (TPM), where an LLM generates MAC signaling messages. By editing\nLLM instruction prompts, TPM enables instant adaptation, which can be further\nenhanced by TextGrad, an LLM-based automated prompt optimizer. TPM inference is\nfast but coarse due to the lack of real interactions with the changed\nenvironment, and computationally intensive due to the large size of the LLM. To\nimprove goodput and computation efficiency, we develop T2NPM, which transfers\nand augments TPM knowledge into an NPM via knowledge distillation (KD).\nIntegrating TPM and T2NPM, we propose T3NPM, which employs TPM in the early\nphase and switches to T2NPM later. To optimize this phase switching, we design\na novel metric of meta-resilience, which quantifies resilience to unknown\ntarget goodput after environmental shifts. Simulations corroborate that T3NPM\nachieves 20.56% higher meta-resilience than NPM with 19.8x lower computation\ncost than TPM in FLOPS.",
    "pdf_url": "http://arxiv.org/pdf/2505.21518v1",
    "published": "2025-05-22T05:59:36+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16267v1",
    "title": "Rapid adiabatic couplers with arbitrary split ratios for broadband DWDM interleaver application",
    "authors": [
      "Daehan Choi",
      "Woo-Joo Kim",
      "Young-Ik Sohn"
    ],
    "abstract": "We experimentally demonstrate a compact and broadband rapid adiabatic\ncouplers (RACs) with arbitrary power split ratios, achieved through the\ncombination of translational offset and waveguide width control. Fabricated\nRACs of four different target split ratios show power splitting within $\\pm$3%\nof the design target over a 160 nm wavelength range. Using these RACs, we\nimplement an 8-channel dense wavelength division multiplexing (DWDM)\ninterleaver exhibiting < -20 dB crosstalk for the center 8 channels with\nflat-top passbands. Over a broader wavelength range, the design maintains\ncrosstalk below -10 dB across more than 40 channels with 100 GHz spacing,\ndemonstrating the broadband capability and scalability of RAC-based photonic\nintegrated circuits.",
    "pdf_url": "http://arxiv.org/pdf/2505.16267v1",
    "published": "2025-05-22T05:56:23+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.16266v1",
    "title": "Anisotropic quantum universe in Hořava-Lifshitz gravity",
    "authors": [
      "Vikramaditya Mondal",
      "Shinji Mukohyama"
    ],
    "abstract": "We quantize a Bianchi IX universe in Ho\\v{r}ava-Lifshitz theory. For\nanalytical tractability, we consider the small anisotropy limit of the Bianchi\nIX, that is, a perturbative anisotropic deformation of a closed, homogeneous\nand isotropic universe. In the case of the projectable theory we further set\nthe ``dark matter as integration constant'' to zero by assuming that the space\nconsists of only one connected piece. In that limit and under the assumption,\nwe first study the semi-classical WKB solutions to the Wheeler-DeWitt equation.\nWe find the wave function of the universe, up to an overall normalization, and\nestimate the semi-classical tunneling probability for the emergence of an\nexpanding universe. We establish a dictionary of correspondence between the WKB\nwave functions in General Relativity and Ho\\v{r}ava-Lifshitz theory in the\nlarge-scale factor (or IR) limit. For a small universe (UV limit), on the other\nhand, due to contributions from higher-dimensional operators, the anisotropies\ndecouple from the scale factor, a behavior significantly different from General\nRelativity, and analytic solutions to the Wheeler-DeWitt equation beyond the\nWKB approximation can be found. The wave function of the scale factor satisfies\nthe DeWitt criterion, whereas the wave functions of anisotropies resemble those\nof quantum harmonic oscillators. The quantum prediction for the initial\ncondition of anisotropies is obtained in terms of the coupling parameters of\nHo\\v{r}ava-Lifshitz theory. We find a bound on the coupling parameters from the\nnormalizability of the wave functions of anisotropies. Further, we calculate\nthe expectation values for squared anisotropic shear and squared anisotropies\nin both the large universe and small universe limits.",
    "pdf_url": "http://arxiv.org/pdf/2505.16266v1",
    "published": "2025-05-22T05:56:14+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.16265v1",
    "title": "Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models",
    "authors": [
      "Ilgee Hong",
      "Changlong Yu",
      "Liang Qiu",
      "Weixiang Yan",
      "Zhenghao Xu",
      "Haoming Jiang",
      "Qingru Zhang",
      "Qin Lu",
      "Xin Liu",
      "Chao Zhang",
      "Tuo Zhao"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has become a powerful\npost-training paradigm for aligning large language models with human\npreferences. A core challenge in RLHF is constructing accurate reward signals,\nwhere the conventional Bradley-Terry reward models (BT RMs) often suffer from\nsensitivity to data size and coverage, as well as vulnerability to reward\nhacking. Generative reward models (GenRMs) offer a more robust alternative by\ngenerating chain-of-thought (CoT) rationales followed by a final reward.\nHowever, existing GenRMs rely on shallow, vertically scaled reasoning, limiting\ntheir capacity to handle nuanced or complex (e.g., reasoning-intensive) tasks.\nMoreover, their pairwise preference outputs are incompatible with standard RLHF\nalgorithms that require pointwise reward signals. In this work, we introduce\nThink-RM, a training framework that enables long-horizon reasoning in GenRMs by\nmodeling an internal thinking process. Rather than producing structured,\nexternally provided rationales, Think-RM generates flexible, self-guided\nreasoning traces that support advanced capabilities such as self-reflection,\nhypothetical reasoning, and divergent reasoning. To elicit these reasoning\nabilities, we first warm-up the models by supervised fine-tuning (SFT) over\nlong CoT data. We then further improve the model's long-horizon abilities by\nrule-based reinforcement learning (RL). In addition, we propose a novel\npairwise RLHF pipeline that directly optimizes policies using pairwise\npreference rewards, eliminating the need for pointwise reward conversion and\nenabling more effective use of Think-RM outputs. Experiments show that Think-RM\nachieves state-of-the-art results on RM-Bench, outperforming both BT RM and\nvertically scaled GenRM by 8%. When combined with our pairwise RLHF pipeline,\nit demonstrates superior end-policy performance compared to traditional\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.16265v1",
    "published": "2025-05-22T05:56:11+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16264v1",
    "title": "LINEA: Fast and Accurate Line Detection Using Scalable Transformers",
    "authors": [
      "Sebastian Janampa",
      "Marios Pattichis"
    ],
    "abstract": "Line detection is a basic digital image processing operation used by\nhigher-level processing methods. Recently, transformer-based methods for line\ndetection have proven to be more accurate than methods based on CNNs, at the\nexpense of significantly lower inference speeds. As a result, video analysis\nmethods that require low latencies cannot benefit from current\ntransformer-based methods for line detection. In addition, current\ntransformer-based models require pretraining attention mechanisms on large\ndatasets (e.g., COCO or Object360). This paper develops a new transformer-based\nmethod that is significantly faster without requiring pretraining the attention\nmechanism on large datasets. We eliminate the need to pre-train the attention\nmechanism using a new mechanism, Deformable Line Attention (DLA). We use the\nterm LINEA to refer to our new transformer-based method based on DLA. Extensive\nexperiments show that LINEA is significantly faster and outperforms previous\nmodels on sAP in out-of-distribution dataset testing.",
    "pdf_url": "http://arxiv.org/pdf/2505.16264v1",
    "published": "2025-05-22T05:56:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16263v1",
    "title": "All You Need is \"Leet\": Evading Hate-speech Detection AI",
    "authors": [
      "Sampanna Yashwant Kahu",
      "Naman Ahuja"
    ],
    "abstract": "Social media and online forums are increasingly becoming popular.\nUnfortunately, these platforms are being used for spreading hate speech. In\nthis paper, we design black-box techniques to protect users from hate-speech on\nonline platforms by generating perturbations that can fool state of the art\ndeep learning based hate speech detection models thereby decreasing their\nefficiency. We also ensure a minimal change in the original meaning of\nhate-speech. Our best perturbation attack is successfully able to evade\nhate-speech detection for 86.8 % of hateful text.",
    "pdf_url": "http://arxiv.org/pdf/2505.16263v1",
    "published": "2025-05-22T05:55:26+00:00",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.LG",
      "K.6.5"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16262v2",
    "title": "Exact quantum dynamics of methanol: full-dimensional ab initio potential energy surface of spectroscopic quality and variational vibrational states",
    "authors": [
      "Ayaki Sunaga",
      "Tibor Győri",
      "Gábor Czakó",
      "Edit Matyus"
    ],
    "abstract": "The methanol molecule is a sensitive probe of astrochemistry, astrophysics,\nand fundamental physics. The first-principles elucidation and prediction of its\nrotation-torsional-vibrational motions are enabled in this work by the\ncomputation of a full-dimensional, \\emph{ab initio} potential energy surface\n(PES) and numerically exact quantum dynamics. An active-learning approach is\nused to sample explicitly correlated coupled-cluster electronic energies, and\nthe datapoints are fitted with permutationally invariant polynomials to obtain\na spectroscopic-quality PES representation. Variational vibrational energies\nand corresponding tunnelling splittings are computed up to the first overtone\nof the C-O stretching mode by direct numerical solution of the vibrational\nSchr\\\"odinger equation with optimal internal coordinates and efficient basis\nand grid truncation techniques. As a result, the computed vibrational band\norigins finally agree with experiment within 5 cm$^{-1}$, allowing for the\nexploration of the large-amplitude quantum mechanical motion and tunnelling\nsplittings coupled with the small-amplitude vibrational dynamics. These\ndevelopments open the route towards simulating rovibrational spectra used to\nprobe methanol in outer space and in precision science laboratories, as well as\nfor probing interactions with external magnetic fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.16262v2",
    "published": "2025-05-22T05:54:53+00:00",
    "categories": [
      "physics.chem-ph",
      "quant-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16261v1",
    "title": "Interpretable Anomaly Detection in Encrypted Traffic Using SHAP with Machine Learning Models",
    "authors": [
      "Kalindi Singh",
      "Aayush Kashyap",
      "Aswani Kumar Cherukuri"
    ],
    "abstract": "The widespread adoption of encrypted communication protocols such as HTTPS\nand TLS has enhanced data privacy but also rendered traditional anomaly\ndetection techniques less effective, as they often rely on inspecting\nunencrypted payloads. This study aims to develop an interpretable machine\nlearning-based framework for anomaly detection in encrypted network traffic.\nThis study proposes a model-agnostic framework that integrates multiple machine\nlearning classifiers, with SHapley Additive exPlanations SHAP to ensure\npost-hoc model interpretability. The models are trained and evaluated on three\nbenchmark encrypted traffic datasets. Performance is assessed using standard\nclassification metrics, and SHAP is used to explain model predictions by\nattributing importance to individual input features. SHAP visualizations\nsuccessfully revealed the most influential traffic features contributing to\nanomaly predictions, enhancing the transparency and trustworthiness of the\nmodels. Unlike conventional approaches that treat machine learning as a black\nbox, this work combines robust classification techniques with explainability\nthrough SHAP, offering a novel interpretable anomaly detection system tailored\nfor encrypted traffic environments. While the framework is generalizable,\nreal-time deployment and performance under adversarial conditions require\nfurther investigation. Future work may explore adaptive models and real-time\ninterpretability in operational network environments. This interpretable\nanomaly detection framework can be integrated into modern security operations\nfor encrypted environments, allowing analysts not only to detect anomalies with\nhigh precision but also to understand why a model made a particular decision a\ncrucial capability in compliance-driven and mission-critical settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16261v1",
    "published": "2025-05-22T05:50:39+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16260v1",
    "title": "Small-to-Large Generalization: Data Influences Models Consistently Across Scale",
    "authors": [
      "Alaa Khaddaj",
      "Logan Engstrom",
      "Aleksander Madry"
    ],
    "abstract": "Choice of training data distribution greatly influences model behavior. Yet,\nin large-scale settings, precisely characterizing how changes in training data\naffects predictions is often difficult due to model training costs. Current\npractice is to instead extrapolate from scaled down, inexpensive-to-train proxy\nmodels. However, changes in data do not influence smaller and larger models\nidentically. Therefore, understanding how choice of data affects large-scale\nmodels raises the question: how does training data distribution influence model\nbehavior across compute scale? We find that small- and large-scale language\nmodel predictions (generally) do highly correlate across choice of training\ndata. Equipped with these findings, we characterize how proxy scale affects\neffectiveness in two downstream proxy model applications: data attribution and\ndataset selection.",
    "pdf_url": "http://arxiv.org/pdf/2505.16260v1",
    "published": "2025-05-22T05:50:19+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16259v1",
    "title": "Dialogue in Resonance: An Interactive Music Piece for Piano and Real-Time Automatic Transcription System",
    "authors": [
      "Hayeon Bang",
      "Taegyun Kwon",
      "Juhan Nam"
    ],
    "abstract": "This paper presents <Dialogue in Resonance>, an interactive music piece for a\nhuman pianist and a computer-controlled piano that integrates real-time\nautomatic music transcription into a score-driven framework. Unlike previous\napproaches that primarily focus on improvisation-based interactions, our work\nestablishes a balanced framework that combines composed structure with dynamic\ninteraction. Through real-time automatic transcription as its core mechanism,\nthe computer interprets and responds to the human performer's input in real\ntime, creating a musical dialogue that balances compositional intent with live\ninteraction while incorporating elements of unpredictability. In this paper, we\npresent the development process from composition to premiere performance,\nincluding technical implementation, rehearsal process, and performance\nconsiderations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16259v1",
    "published": "2025-05-22T05:50:13+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16258v2",
    "title": "IRONIC: Coherence-Aware Reasoning Chains for Multi-Modal Sarcasm Detection",
    "authors": [
      "Aashish Anantha Ramakrishnan",
      "Aadarsh Anantha Ramakrishnan",
      "Dongwon Lee"
    ],
    "abstract": "Interpreting figurative language such as sarcasm across multi-modal inputs\npresents unique challenges, often requiring task-specific fine-tuning and\nextensive reasoning steps. However, current Chain-of-Thought approaches do not\nefficiently leverage the same cognitive processes that enable humans to\nidentify sarcasm. We present IRONIC, an in-context learning framework that\nleverages Multi-modal Coherence Relations to analyze referential, analogical\nand pragmatic image-text linkages. Our experiments show that IRONIC achieves\nstate-of-the-art performance on zero-shot Multi-modal Sarcasm Detection across\ndifferent baselines. This demonstrates the need for incorporating linguistic\nand cognitive insights into the design of multi-modal reasoning strategies. Our\ncode is available at: https://github.com/aashish2000/IRONIC",
    "pdf_url": "http://arxiv.org/pdf/2505.16258v2",
    "published": "2025-05-22T05:49:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "68T50",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16257v1",
    "title": "Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics",
    "authors": [
      "Masanari Kimura"
    ],
    "abstract": "This study develops a higher-order asymptotic framework for test-time\nadaptation (TTA) of Batch Normalization (BN) statistics under distribution\nshift by integrating classical Edgeworth expansion and saddlepoint\napproximation techniques with a novel one-step M-estimation perspective. By\nanalyzing the statistical discrepancy between training and test distributions,\nwe derive an Edgeworth expansion for the normalized difference in BN means and\nobtain an optimal weighting parameter that minimizes the mean-squared error of\nthe adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows\nus to derive higher-order local asymptotic normality results, which incorporate\nskewness and other higher moments into the estimator's behavior. Moreover, we\nquantify the trade-offs among bias, variance, and skewness in the adaptation\nprocess and establish a corresponding generalization bound on the model risk.\nThe refined saddlepoint approximations further deliver uniformly accurate\ndensity and tail probability estimates for the BN TTA statistic. These\ntheoretical insights provide a comprehensive understanding of how higher-order\ncorrections and robust one-step updating can enhance the reliability and\nperformance of BN layers in adapting to changing data distributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16257v1",
    "published": "2025-05-22T05:47:19+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16256v1",
    "title": "DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor",
    "authors": [
      "Yan Zhao",
      "Zhengxue Cheng",
      "Junxuan Zhang",
      "Qunshan Gu",
      "Qi Wang",
      "Li Song"
    ],
    "abstract": "Most learning-based lossless compressors are designed for a single modality,\nrequiring separate models for multi-modal data and lacking flexibility.\nHowever, different modalities vary significantly in format and statistical\nproperties, making it ineffective to use compressors that lack\nmodality-specific adaptations. While multi-modal large language models (MLLMs)\noffer a potential solution for modality-unified compression, their excessive\ncomplexity hinders practical deployment. To address these challenges, we focus\non the two most common modalities, image and text, and propose DualComp, the\nfirst unified and lightweight learning-based dual-modality lossless compressor.\nBuilt on a lightweight backbone, DualComp incorporates three key structural\nenhancements to handle modality heterogeneity: modality-unified tokenization,\nmodality-switching contextual learning, and modality-routing\nmixture-of-experts. A reparameterization training strategy is also used to\nboost compression performance. DualComp integrates both modality-specific and\nshared parameters for efficient parameter utilization, enabling near real-time\ninference (200KB/s) on desktop CPUs. With much fewer parameters, DualComp\nachieves compression performance on par with the SOTA LLM-based methods for\nboth text and image datasets. Its simplified single-modality variant surpasses\nthe previous best image compressor on the Kodak dataset by about 9% using just\n1.2% of the model size.",
    "pdf_url": "http://arxiv.org/pdf/2505.16256v1",
    "published": "2025-05-22T05:46:14+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16255v1",
    "title": "Investigating the chemical link between H$_2$CO and CH$_3$OH within the CMZ of NGC 253",
    "authors": [
      "K. -Y. Huang",
      "E. Behrens",
      "M. Bouvier",
      "S. Viti",
      "J. G. Mangum",
      "C. Eibensteiner"
    ],
    "abstract": "Formaldehyde (H$_2$CO) and methanol (CH$_3$OH) have served as traditional\ntracers of the star formation process for decades. Studies of the environments\nwhich produce these species, though, have pointed to significant differences in\nthe physical environments within which each molecule resides. In this paper we\ninvestigate the physical and chemical conditions which give rise to\nformaldehyde and methanol emission in the nearby starburst galaxy NGC 253. We\nemploy high spatial (1.$''$6 or $\\sim28$ pc) and spectral ($\\sim10$ km/s)\nimaging of the NGC 253 central molecular zone (CMZ) from the ALCHEMI Large\nProgram to constrain radiative transfer models of the dense gas volume density,\nand temperature, molecular species column density, and source filling factor\nwithin eight giant molecular clouds (GMCs). We also measure the relative\nabundances of the two nuclear spin isomers of CH$_3$OH to investigate its\nformation history. The physical and chemical conditions derived clearly\nindicate that H$_2$CO and CH$_3$OH originate from distinct physical\nenvironments. H$_2$CO traces low volume density and high kinetic temperatures,\nwhile CH$_3$OH traces high volume density and low kinetic temperatures. The\nH$_2$CO abundances are constant, though poorly constrained, within the eight\nNGC 253 GMCs analyzed, while the CH$_3$OH abundance shows a radial gradient\nfrom low to high values within the NGC 253 CMZ. Our findings highlight the\ncomplex chemical and physical differentiation of CH$_3$OH and H$_2$CO in the\nstarburst environment of NGC 253. Methanol formation appears to be influenced\nby warm, dynamic processes rather than cold cloud chemistry, while formaldehyde\nprimarily forms via gas-phase reactions. These results challenge the assumption\nof a direct chemical link between CH$_3$OH and H$_2$CO and underscores the\nimpact of starburst-driven shocks, turbulence, and cosmic rays on molecular gas\nchemistry.",
    "pdf_url": "http://arxiv.org/pdf/2505.16255v1",
    "published": "2025-05-22T05:45:39+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16254v2",
    "title": "Reassessing Collaborative Writing Theories and Frameworks in the Age of LLMs: What Still Applies and What We Must Leave Behind",
    "authors": [
      "Daisuke Yukita",
      "Tim Miller",
      "Joel Mackenzie"
    ],
    "abstract": "In this paper, we conduct a critical review of existing theories and\nframeworks on human-human collaborative writing to assess their relevance to\nthe current human-AI paradigm in professional contexts, and draw seven insights\nalong with design implications for human-AI collaborative writing tools. We\nfound that, as LLMs nudge the writing process more towards an empirical \"trial\nand error\" process analogous to prototyping, the non-linear cognitive process\nof writing will stay the same, but more rigor will be required for revision\nmethodologies. This shift would shed further light on the importance of\ncoherence support, but the large language model (LLM)'s unprecedented semantic\ncapabilities can bring novel approaches to this ongoing challenge. We argue\nthat teamwork-related factors such as group awareness, consensus building and\nauthorship - which have been central in human-human collaborative writing\nstudies - should not apply to the human-AI paradigm due to excessive\nanthropomorphism. With the LLM's text generation capabilities becoming\nessentially indistinguishable from human-written ones, we are entering an era\nwhere, for the first time in the history of computing, we are engaging in\ncollaborative writing with AI at workplaces on a daily basis. We aim to bring\ntheoretical grounding and practical design guidance to the interaction designs\nof human-AI collaborative writing, with the goal of enhancing future human-AI\nwriting software.",
    "pdf_url": "http://arxiv.org/pdf/2505.16254v2",
    "published": "2025-05-22T05:44:09+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16253v1",
    "title": "Swin Transformer for Robust CGI Images Detection: Intra- and Inter-Dataset Analysis across Multiple Color Spaces",
    "authors": [
      "Preeti Mehta",
      "Aman Sagar",
      "Suchi Kumari"
    ],
    "abstract": "This study aims to address the growing challenge of distinguishing\ncomputer-generated imagery (CGI) from authentic digital images across three\ndifferent color spaces; RGB, YCbCr, and HSV. Given the limitations of existing\nclassification methods in handling the complexity and variability of CGI, this\nresearch proposes a Swin Transformer based model for accurate differentiation\nbetween natural and synthetic images. The proposed model leverages the Swin\nTransformer's hierarchical architecture to capture local and global features\nfor distinguishing CGI from natural images. Its performance was assessed\nthrough intra- and inter-dataset testing across three datasets: CiFAKE, JSSSTU,\nand Columbia. The model was evaluated individually on each dataset (D1, D2, D3)\nand on the combined datasets (D1+D2+D3) to test its robustness and domain\ngeneralization. To address dataset imbalance, data augmentation techniques were\napplied. Additionally, t-SNE visualization was used to demonstrate the feature\nseparability achieved by the Swin Transformer across the selected color spaces.\nThe model's performance was tested across all color schemes, with the RGB color\nscheme yielding the highest accuracy for each dataset. As a result, RGB was\nselected for domain generalization analysis and compared with other CNN-based\nmodels, VGG-19 and ResNet-50. The comparative results demonstrate the proposed\nmodel's effectiveness in detecting CGI, highlighting its robustness and\nreliability in both intra-dataset and inter-dataset evaluations. The findings\nof this study highlight the Swin Transformer model's potential as an advanced\ntool for digital image forensics, particularly in distinguishing CGI from\nnatural images. The model's strong performance indicates its capability for\ndomain generalization, making it a valuable asset in scenarios requiring\nprecise and reliable image classification.",
    "pdf_url": "http://arxiv.org/pdf/2505.16253v1",
    "published": "2025-05-22T05:43:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16252v1",
    "title": "Does Localization Inform Unlearning? A Rigorous Examination of Local Parameter Attribution for Knowledge Unlearning in Language Models",
    "authors": [
      "Hwiyeong Lee",
      "Uiji Hwang",
      "Hyelim Lim",
      "Taeuk Kim"
    ],
    "abstract": "Large language models often retain unintended content, prompting growing\ninterest in knowledge unlearning. Recent approaches emphasize localized\nunlearning, which restricts parameter updates to specific regions in an effort\nto remove target knowledge while preserving unrelated general knowledge.\nHowever, their effectiveness remains uncertain due to the lack of robust and\nthorough evaluation of the trade-off between the competing goals of unlearning.\nIn this paper, we begin by revisiting existing localized unlearning approaches.\nWe then conduct controlled experiments to rigorously evaluate whether local\nparameter updates causally contribute to unlearning. Our findings reveal that\nthe set of parameters that must be modified for effective unlearning is not\nstrictly determined, challenging the core assumption of localized unlearning\nthat parameter locality is inherently indicative of effective knowledge\nremoval.",
    "pdf_url": "http://arxiv.org/pdf/2505.16252v1",
    "published": "2025-05-22T05:41:53+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16251v1",
    "title": "Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry",
    "authors": [
      "Masanari Kimura"
    ],
    "abstract": "Label shift adaptation aims to recover target class priors when the labelled\nsource distribution $P$ and the unlabelled target distribution $Q$ share $P(X\n\\mid Y) = Q(X \\mid Y)$ but $P(Y) \\neq Q(Y)$. Classical black-box shift\nestimators invert an empirical confusion matrix of a frozen classifier,\nproducing a brittle point estimate that ignores sampling noise and similarity\namong classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully\nprobabilistic alternative that places Laplacian-Gaussian priors on both target\nlog-priors and confusion-matrix columns, tying them together on a\nlabel-similarity graph. The resulting posterior is tractable with HMC or a fast\nblock Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction,\nvariance bounds that shrink with the graph's algebraic connectivity, and\nrobustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE\nthrough information geometry, showing that it generalizes existing shift\nestimators.",
    "pdf_url": "http://arxiv.org/pdf/2505.16251v1",
    "published": "2025-05-22T05:40:34+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.17137v4",
    "title": "Cog-TiPRO: Iterative Prompt Refinement with LLMs to Detect Cognitive Decline via Longitudinal Voice Assistant Commands",
    "authors": [
      "Kristin Qi",
      "Youxiang Zhu",
      "Caroline Summerour",
      "John A. Batsis",
      "Xiaohui Liang"
    ],
    "abstract": "Early detection of cognitive decline is crucial for enabling interventions\nthat can slow neurodegenerative disease progression. Traditional diagnostic\napproaches rely on labor-intensive clinical assessments, which are impractical\nfor frequent monitoring. Our pilot study investigates voice assistant systems\n(VAS) as non-invasive tools for detecting cognitive decline through\nlongitudinal analysis of speech patterns in voice commands. Over an 18-month\nperiod, we collected voice commands from 35 older adults, with 15 participants\nproviding daily at-home VAS interactions. To address the challenges of\nanalyzing these short, unstructured and noisy commands, we propose Cog-TiPRO, a\nframework that combines (1) LLM-driven iterative prompt refinement for\nlinguistic feature extraction, (2) HuBERT-based acoustic feature extraction,\nand (3) transformer-based temporal modeling. Using iTransformer, our approach\nachieves 73.80% accuracy and 72.67% F1-score in detecting MCI, outperforming\nits baseline by 27.13%. Through our LLM approach, we identify linguistic\nfeatures that uniquely characterize everyday command usage patterns in\nindividuals experiencing cognitive decline.",
    "pdf_url": "http://arxiv.org/pdf/2505.17137v4",
    "published": "2025-05-22T05:40:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16250v1",
    "title": "An inverse boundary value problem for the Maxwell's equations with partial data",
    "authors": [
      "Jian Zhai"
    ],
    "abstract": "We consider an inverse boundary problem for the dynamical Maxwell's\nequations. We show that the electric permittivity, conductivity, and magnetic\npermeability can be uniquely determined locally if there is a strictly convex\nfoliation with respect to the wave speed.",
    "pdf_url": "http://arxiv.org/pdf/2505.16250v1",
    "published": "2025-05-22T05:36:31+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16249v2",
    "title": "Manipulating Elasto-Plastic Objects With 3D Occupancy and Learning-Based Predictive Control",
    "authors": [
      "Zhen Zhang",
      "Xiangyu Chu",
      "Yunxi Tang",
      "Lulu Zhao",
      "Jing Huang",
      "Zhongliang Jiang",
      "K. W. Samuel Au"
    ],
    "abstract": "Manipulating elasto-plastic objects remains a significant challenge due to\nsevere self-occlusion, difficulties of representation, and complicated\ndynamics. This work proposes a novel framework for elasto-plastic object\nmanipulation with a quasi-static assumption for motions, leveraging 3D\noccupancy to represent such objects, a learned dynamics model trained with 3D\noccupancy, and a learning-based predictive control algorithm to address these\nchallenges effectively. We build a novel data collection platform to collect\nfull spatial information and propose a pipeline for generating a 3D occupancy\ndataset. To infer the 3D occupancy during manipulation, an occupancy prediction\nnetwork is trained with multiple RGB images supervised by the generated\ndataset. We design a deep neural network empowered by a 3D convolution neural\nnetwork (CNN) and a graph neural network (GNN) to predict the complex\ndeformation with the inferred 3D occupancy results. A learning-based predictive\ncontrol algorithm is introduced to plan the robot actions, incorporating a\nnovel shape-based action initialization module specifically designed to improve\nthe planner efficiency. The proposed framework in this paper can successfully\nshape the elasto-plastic objects into a given goal shape and has been verified\nin various experiments both in simulation and the real world.",
    "pdf_url": "http://arxiv.org/pdf/2505.16249v2",
    "published": "2025-05-22T05:36:00+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16248v1",
    "title": "Graph Neural Network-Based Collaborative Perception for Adaptive Scheduling in Distributed Systems",
    "authors": [
      "Wenxuan Zhu",
      "Qiyuan Wu",
      "Tengda Tang",
      "Renzi Meng",
      "Sheng Chai",
      "Xuehui Quan"
    ],
    "abstract": "This paper addresses the limitations of multi-node perception and delayed\nscheduling response in distributed systems by proposing a GNN-based multi-node\ncollaborative perception mechanism. The system is modeled as a graph structure.\nMessage-passing and state-update modules are introduced. A multi-layer graph\nneural network is constructed to enable efficient information aggregation and\ndynamic state inference among nodes. In addition, a perception representation\nmethod is designed by fusing local states with global features. This improves\neach node's ability to perceive the overall system status. The proposed method\nis evaluated within a customized experimental framework. A dataset featuring\nheterogeneous task loads and dynamic communication topologies is used.\nPerformance is measured in terms of task completion rate, average latency, load\nbalancing, and transmission efficiency. Experimental results show that the\nproposed method outperforms mainstream algorithms under various conditions,\nincluding limited bandwidth and dynamic structural changes. It demonstrates\nsuperior perception capabilities and cooperative scheduling performance. The\nmodel achieves rapid convergence and efficient responses to complex system\nstates.",
    "pdf_url": "http://arxiv.org/pdf/2505.16248v1",
    "published": "2025-05-22T05:34:02+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16247v1",
    "title": "Rogers's proof of Vaaler's theorem",
    "authors": [
      "Roman Karasev"
    ],
    "abstract": "We note that an argument by Rogers (1958) gives a proof of Vaaler's theorem\n(1979) about sections of the cube and allows its certain generalizations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16247v1",
    "published": "2025-05-22T05:32:04+00:00",
    "categories": [
      "math.MG",
      "52A38, 52B10, 52B11"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16246v2",
    "title": "Verifiable Exponential Mechanism for Median Estimation",
    "authors": [
      "Hyukjun Kwon",
      "Chenglin Fan"
    ],
    "abstract": "Differential Privacy (DP) is a rigorous privacy standard widely adopted in\ndata analysis and machine learning. However, its guarantees rely on correctly\nintroducing randomized noise--an assumption that may not hold if the\nimplementation is faulty or manipulated by an untrusted analyst. To address\nthis concern, we propose the first verifiable implementation of the exponential\nmechanism using zk-SNARKs. As a concrete application, we present the first\nverifiable differentially private (DP) median estimation scheme, which\nleverages this construction to ensure both privacy and verifiability. Our\nmethod encodes the exponential mechanism and a utility function for the median\ninto an arithmetic circuit, employing a scaled inverse CDF technique for\nsampling. This design enables cryptographic verification that the reported\noutput adheres to the intended DP mechanism, ensuring both privacy and\nintegrity without revealing sensitive data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16246v2",
    "published": "2025-05-22T05:31:22+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16245v2",
    "title": "Diverse, not Short: A Length-Controlled Self-Learning Framework for Improving Response Diversity of Language Models",
    "authors": [
      "Vijeta Deshpande",
      "Debasmita Ghose",
      "John D. Patterson",
      "Roger Beaty",
      "Anna Rumshisky"
    ],
    "abstract": "Diverse language model responses are crucial for creative generation,\nopen-ended tasks, and self-improvement training. We show that common diversity\nmetrics, and even reward models used for preference optimization,\nsystematically bias models toward shorter outputs, limiting expressiveness. To\naddress this, we introduce Diverse, not Short (Diverse-NS), a length-controlled\nself-learning framework that improves response diversity while maintaining\nlength parity. By generating and filtering preference data that balances\ndiversity, quality, and length, Diverse-NS enables effective training using\nonly 3,000 preference pairs. Applied to LLaMA-3.1-8B and the Olmo-2 family,\nDiverse-NS substantially enhances lexical and semantic diversity. We show\nconsistent improvement in diversity with minor reduction or gains in response\nquality on four creative generation tasks: Divergent Associations, Persona\nGeneration, Alternate Uses, and Creative Writing. Surprisingly, experiments\nwith the Olmo-2 model family (7B, and 13B) show that smaller models like\nOlmo-2-7B can serve as effective \"diversity teachers\" for larger models. By\nexplicitly addressing length bias, our method efficiently pushes models toward\nmore diverse and expressive outputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16245v2",
    "published": "2025-05-22T05:29:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16244v1",
    "title": "Generalized Power Priors for Improved Bayesian Inference with Historical Data",
    "authors": [
      "Masanari Kimura",
      "Howard Bondell"
    ],
    "abstract": "The power prior is a class of informative priors designed to incorporate\nhistorical data alongside current data in a Bayesian framework. It includes a\npower parameter that controls the influence of historical data, providing\nflexibility and adaptability. A key property of the power prior is that the\nresulting posterior minimizes a linear combination of KL divergences between\ntwo pseudo-posterior distributions: one ignoring historical data and the other\nfully incorporating it. We extend this framework by identifying the posterior\ndistribution as the minimizer of a linear combination of Amari's\n$\\alpha$-divergence, a generalization of KL divergence. We show that this\ngeneralization can lead to improved performance by allowing for the data to\nadapt to appropriate choices of the $\\alpha$ parameter. Theoretical properties\nof this generalized power posterior are established, including behavior as a\ngeneralized geodesic on the Riemannian manifold of probability distributions,\noffering novel insights into its geometric interpretation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16244v1",
    "published": "2025-05-22T05:26:40+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16243v1",
    "title": "A novel splitting method for Vlasov-Ampere",
    "authors": [
      "James A. Rossmanith",
      "Christine Vaughan"
    ],
    "abstract": "Vlasov equations model the dynamics of plasma in the collisionless regime. A\nstandard approach for numerically solving the Vlasov equation is to operator\nsplit the spatial and velocity derivative terms, allowing simpler time-stepping\nschemes to be applied to each piece separately (known as the Cheng-Knorr\nmethod). One disadvantage of such an operator split method is that the order of\naccuracy of fluid moments (e.g., mass, momentum, and energy) is restricted by\nthe order of the operator splitting (second-order accuracy in the Cheng-Knorr\ncase). In this work, we develop a novel approach that first represents the\nparticle density function on a velocity mesh with a local fluid approximation\nin each discrete velocity band and then introduces an operator splitting that\nsplits the inter-velocity band coupling terms from the dynamics within the\ndiscrete velocity band. The advantage is that the inter-velocity band coupling\nterms are only needed to achieve consistency of the full distribution\nfunctions, but the local fluid models within each band are sufficient to\nachieve high-order accuracy on global moments such as mass, momentum, and\nenergy. The resulting scheme is verified on several standard Vlasov-Poisson\ntest cases.",
    "pdf_url": "http://arxiv.org/pdf/2505.16243v1",
    "published": "2025-05-22T05:22:49+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.plasm-ph",
      "65M60, 82D10"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16242v1",
    "title": "Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies",
    "authors": [
      "Runze Yan",
      "Xun Shen",
      "Akifumi Wachi",
      "Sebastien Gros",
      "Anni Zhao",
      "Xiao Hu"
    ],
    "abstract": "When applying offline reinforcement learning (RL) in healthcare scenarios,\nthe out-of-distribution (OOD) issues pose significant risks, as inappropriate\ngeneralization beyond clinical expertise can result in potentially harmful\nrecommendations. While existing methods like conservative Q-learning (CQL)\nattempt to address the OOD issue, their effectiveness is limited by only\nconstraining action selection by suppressing uncertain actions. This\naction-only regularization imitates clinician actions that prioritize\nshort-term rewards, but it fails to regulate downstream state trajectories,\nthereby limiting the discovery of improved long-term treatment strategies. To\nsafely improve policy beyond clinician recommendations while ensuring that\nstate-action trajectories remain in-distribution, we propose \\textit{Offline\nGuarded Safe Reinforcement Learning} ($\\mathsf{OGSRL}$), a theoretically\ngrounded model-based offline RL framework. $\\mathsf{OGSRL}$ introduces a novel\ndual constraint mechanism for improving policy with reliability and safety.\nFirst, the OOD guardian is established to specify clinically validated regions\nfor safe policy exploration. By constraining optimization within these regions,\nit enables the reliable exploration of treatment strategies that outperform\nclinician behavior by leveraging the full patient state history, without\ndrifting into unsupported state-action trajectories. Second, we introduce a\nsafety cost constraint that encodes medical knowledge about physiological\nsafety boundaries, providing domain-specific safeguards even in areas where\ntraining data might contain potentially unsafe interventions. Notably, we\nprovide theoretical guarantees on safety and near-optimality: policies that\nsatisfy these constraints remain in safe and reliable regions and achieve\nperformance close to the best possible policy supported by the data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16242v1",
    "published": "2025-05-22T05:22:03+00:00",
    "categories": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17136v1",
    "title": "Foundation Models for Geospatial Reasoning: Assessing Capabilities of Large Language Models in Understanding Geometries and Topological Spatial Relations",
    "authors": [
      "Yuhan Ji",
      "Song Gao",
      "Ying Nie",
      "Ivan Majić",
      "Krzysztof Janowicz"
    ],
    "abstract": "Applying AI foundation models directly to geospatial datasets remains\nchallenging due to their limited ability to represent and reason with\ngeographical entities, specifically vector-based geometries and natural\nlanguage descriptions of complex spatial relations. To address these issues, we\ninvestigate the extent to which a well-known-text (WKT) representation of\ngeometries and their spatial relations (e.g., topological predicates) are\npreserved during spatial reasoning when the geospatial vector data are passed\nto large language models (LLMs) including GPT-3.5-turbo, GPT-4, and\nDeepSeek-R1-14B. Our workflow employs three distinct approaches to complete the\nspatial reasoning tasks for comparison, i.e., geometry embedding-based, prompt\nengineering-based, and everyday language-based evaluation. Our experiment\nresults demonstrate that both the embedding-based and prompt engineering-based\napproaches to geospatial question-answering tasks with GPT models can achieve\nan accuracy of over 0.6 on average for the identification of topological\nspatial relations between two geometries. Among the evaluated models, GPT-4\nwith few-shot prompting achieved the highest performance with over 0.66\naccuracy on topological spatial relation inference. Additionally, GPT-based\nreasoner is capable of properly comprehending inverse topological spatial\nrelations and including an LLM-generated geometry can enhance the effectiveness\nfor geographic entity retrieval. GPT-4 also exhibits the ability to translate\ncertain vernacular descriptions about places into formal topological relations,\nand adding the geometry-type or place-type context in prompts may improve\ninference accuracy, but it varies by instance. The performance of these spatial\nreasoning tasks offers valuable insights for the refinement of LLMs with\ngeographical knowledge towards the development of geo-foundation models capable\nof geospatial reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.17136v1",
    "published": "2025-05-22T05:21:31+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16241v3",
    "title": "Three Minds, One Legend: Jailbreak Large Reasoning Model with Adaptive Stacked Ciphers",
    "authors": [
      "Viet-Anh Nguyen",
      "Shiqian Zhao",
      "Gia Dao",
      "Runyi Hu",
      "Yi Xie",
      "Luu Anh Tuan"
    ],
    "abstract": "Recently, Large Reasoning Models (LRMs) have demonstrated superior logical\ncapabilities compared to traditional Large Language Models (LLMs), gaining\nsignificant attention. Despite their impressive performance, the potential for\nstronger reasoning abilities to introduce more severe security vulnerabilities\nremains largely underexplored. Existing jailbreak methods often struggle to\nbalance effectiveness with robustness against adaptive safety mechanisms. In\nthis work, we propose SEAL, a novel jailbreak attack that targets LRMs through\nan adaptive encryption pipeline designed to override their reasoning processes\nand evade potential adaptive alignment. Specifically, SEAL introduces a stacked\nencryption approach that combines multiple ciphers to overwhelm the models\nreasoning capabilities, effectively bypassing built-in safety mechanisms. To\nfurther prevent LRMs from developing countermeasures, we incorporate two\ndynamic strategies - random and adaptive - that adjust the cipher length,\norder, and combination. Extensive experiments on real-world reasoning models,\nincluding DeepSeek-R1, Claude Sonnet, and OpenAI GPT-o4, validate the\neffectiveness of our approach. Notably, SEAL achieves an attack success rate of\n80.8% on GPT o4-mini, outperforming state-of-the-art baselines by a significant\nmargin of 27.2%. Warning: This paper contains examples of inappropriate,\noffensive, and harmful content.",
    "pdf_url": "http://arxiv.org/pdf/2505.16241v3",
    "published": "2025-05-22T05:19:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16240v1",
    "title": "Spatio-temporal agent-based modelling of malaria",
    "authors": [
      "Camelia R. Walker",
      "Md Nurul Anwar",
      "Leandra Brauninger",
      "Jack Richards",
      "Ricardo Ataide",
      "Ngo Duc Thang",
      "Nguyen Xuan Thang",
      "Sara Canavati",
      "Jennifer A. Flegg"
    ],
    "abstract": "Plasmodium falciparum is responsible for the majority of malaria morbidity\nand mortality each year. Malaria transmission rates vary by location and time\nof year due to climate and environmental conditions. We show the impact of\nthese factors by developing a stochastic spatiotemporal agent-based malaria\nmodel that captures the impact of spatially distributed interventions on\nmalaria transmission. Our model uses spatiotemporal estimates of mosquito\nclimatic suitability and household location data to model the interaction\nbetween human and mosquito agents. We apply our model to investigate how\nstrategies for distributing interventions to households in Vietnam impact the\ndisease burden. Our study shows that providing some level of protection to a\nwide range of households reduces malaria prevalence more compared to providing\na strong level of protection to a limited number of households.",
    "pdf_url": "http://arxiv.org/pdf/2505.16240v1",
    "published": "2025-05-22T05:18:42+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16239v1",
    "title": "DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution",
    "authors": [
      "Zheng Chen",
      "Zichen Zou",
      "Kewei Zhang",
      "Xiongfei Su",
      "Xin Yuan",
      "Yong Guo",
      "Yulun Zhang"
    ],
    "abstract": "Diffusion models have demonstrated promising performance in real-world video\nsuper-resolution (VSR). However, the dozens of sampling steps they require,\nmake inference extremely slow. Sampling acceleration techniques, particularly\nsingle-step, provide a potential solution. Nonetheless, achieving one step in\nVSR remains challenging, due to the high training overhead on video data and\nstringent fidelity demands. To tackle the above issues, we propose DOVE, an\nefficient one-step diffusion model for real-world VSR. DOVE is obtained by\nfine-tuning a pretrained video diffusion model (*i.e.*, CogVideoX). To\neffectively train DOVE, we introduce the latent-pixel training strategy. The\nstrategy employs a two-stage scheme to gradually adapt the model to the video\nsuper-resolution task. Meanwhile, we design a video processing pipeline to\nconstruct a high-quality dataset tailored for VSR, termed HQ-VSR. Fine-tuning\non this dataset further enhances the restoration capability of DOVE. Extensive\nexperiments show that DOVE exhibits comparable or superior performance to\nmulti-step diffusion-based VSR methods. It also offers outstanding inference\nefficiency, achieving up to a **28$\\times$** speed-up over existing methods\nsuch as MGLD-VSR. Code is available at: https://github.com/zhengchen1999/DOVE.",
    "pdf_url": "http://arxiv.org/pdf/2505.16239v1",
    "published": "2025-05-22T05:16:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16238v1",
    "title": "Magnetic Charge State Controlled Spin-Wave Dynamics in Nanoscale Three-Dimensional Artificial Spin Ice",
    "authors": [
      "Chandan Kumar",
      "Amrit Kumar Mondal",
      "Sreya Pal",
      "Sayan Mathur",
      "Jay R. Scott",
      "Arjen van Den Berg",
      "Adekunle O. Adeyeye",
      "Sam Ladak",
      "Anjan Barman"
    ],
    "abstract": "Three-dimensional (3D) magnetic nanostructures offer a versatile platform for\nexploring complex spin textures and spin-wave (SW) dynamics, with implications\nin next-generation spintronic and magnonic technologies. Advances in 3D\nnanofabrication have allowed a wide-range of structures and phenomena to be\nrealized. Whilst the study of simple cylindrical magnetic nanowires allows the\nrealization of ultrafast domain walls and a spin Cherenkov effect, placing such\nwires of complex cross-section into 3D arrangements allows one to produce\nmagnetic metamaterials, known as artificial spin-ice (ASI), where the overall\nground state and spin dynamics are governed by magnetostatic interactions\nbetween elements. Here, using Brillouin Light Scattering (BLS) we demonstrate\nthe direct detection of magnetic charged states in a 3D-ASI system. The\nmeasured spin-wave modes in 3D-ASI are found to be directly controlled by the\nlocal magnetic charge configuration and the direction of the applied magnetic\nfield. Micromagnetic simulations provide insight into the spatially selective\nexcitation of spin waves and the evolution of magnetic microstates, uncovering\na direct link to the field-dependent characteristics of the spin-wave spectrum.\nThese findings make 3D-ASI architectures a promising system to realize\nreconfigurable, low-power magnonic devices with engineered collective dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.16238v1",
    "published": "2025-05-22T05:15:52+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.16237v1",
    "title": "Align-GRAG: Reasoning-Guided Dual Alignment for Graph Retrieval-Augmented Generation",
    "authors": [
      "Derong Xu",
      "Pengyue Jia",
      "Xiaopeng Li",
      "Yingyi Zhang",
      "Maolin Wang",
      "Qidong Liu",
      "Xiangyu Zhao",
      "Yichao Wang",
      "Huifeng Guo",
      "Ruiming Tang",
      "Enhong Chen",
      "Tong Xu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, but\nstill struggle with issues like hallucinations and outdated information.\nRetrieval-augmented generation (RAG) addresses these issues by grounding LLM\noutputs in external knowledge with an Information Retrieval (IR) system.\nBuilding on this foundation, graph-based RAG systems go a step further by\nretrieving subgraphs, which preserve the relationships between knowledge\nentities and provide more comprehensive context. However, graph RAG faces two\nchallenges: (1) Retrieving relevant information introduces irrelevant nodes\n(especially in dense graph databases, where retrieval usually extends to\nadjacent nodes), and leads to overly lengthy inputs that hinder efficiency; (2)\nThe representation gap between graph and language during generation with LLMs\nlimits the ability to fully leverage graph structures for enhanced\nunderstanding. To address these limitations, we propose Align-GRAG, a novel\nreasoning-guided dual alignment framework in post-retrieval phrase. It first\nformulates a subgraph by retrieving nodes and edges. Then an Aligner is\nproposed to jointly optimizes a graph encoder with LLM-summarized reasoning. It\nachieves dual alignment of graph node and representation by leveraging KL\ndivergence loss and contrastive loss, facilitating efficient pruning of\nirrelevant knowledge and establishing a unified semantic space. The Generator\nintegrates the aligned graph data with LLM to produce coherent and accurate\nanswers. Experiments on GraphQA benchmark across three tasks (including common\nsense reasoning, scene graph understanding, and knowledge graph reasoning)\nvalidate the effectiveness of our method. The code will be available upon\naccepted.",
    "pdf_url": "http://arxiv.org/pdf/2505.16237v1",
    "published": "2025-05-22T05:15:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16236v2",
    "title": "Base Station Placement Optimization for Networked Sensing Exploiting Target Location Distribution",
    "authors": [
      "Kaiyue Hou",
      "Shuowen Zhang"
    ],
    "abstract": "This paper studies a networked sensing system with multiple base stations\n(BSs), which collaboratively sense the unknown and random three-dimensional\n(3D) location of a target based on the target-reflected echo signals received\nat the BSs. Considering a practical scenario where the target location\ndistribution is known a priori for exploitation, we aim to design the placement\nof the multiple BSs to optimize the networked sensing performance. Firstly, we\ncharacterize the posterior Cram\\'er-Rao bound (PCRB) of the mean-squared error\n(MSE) in sensing the target's 3D location. Despite its complex form under\nnetworked sensing, we derive its closed-form expression in terms of the BS\nlocations. Next, we formulate the BS placement optimization problem to minimize\nthe sensing PCRB, which is non-convex and difficult to solve. By leveraging a\nseries of equivalent transformations and the iterative inner approximation\nmethod, we devise an algorithm with polynomial-time complexity which is\nguaranteed to converge to a solution satisfying the Karush-Kuhn Tucker (KKT)\nconditions of the problem. Numerical results show that the proposed placement\ndesign significantly outperforms various benchmark designs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16236v2",
    "published": "2025-05-22T05:10:57+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.17135v4",
    "title": "When can isotropy help adapt LLMs' next word prediction to numerical domains?",
    "authors": [
      "Rashed Shelim",
      "Shengzhe Xu",
      "Walid Saad",
      "Naren Ramakrishnan"
    ],
    "abstract": "Vector representations of contextual embeddings learned by pre-trained large\nlanguage models (LLMs) are effective in various downstream tasks in numerical\ndomains such as time series forecasting. Despite their significant benefits,\nthe tendency of LLMs to hallucinate in such domains can have severe\nconsequences in applications such as energy, nature, finance, healthcare,\nretail and transportation, among others. To guarantee prediction reliability\nand accuracy in numerical domains, it is necessary to open the black box behind\nthe LLM and provide performance guarantees through explanation. However, there\nis little theoretical understanding of when pre-trained language models help\nsolve numerical downstream tasks. This paper seeks to bridge this gap by\nunderstanding when the next-word prediction capability of LLMs can be adapted\nto numerical domains through a novel analysis based on the concept of isotropy\nin the contextual embedding space. Specifically, a log-linear model for LLMs is\nconsidered in which numerical data can be predicted from its context through a\nnetwork with softmax in the output layer of LLMs (i.e., language model head in\nself-attention). For this model, it is demonstrated that, in order to achieve\nstate-of-the-art performance in numerical domains, the hidden representations\nof the LLM embeddings must possess a structure that accounts for the\nshift-invariance of the softmax function. By formulating a gradient structure\nof self-attention in pre-trained models, it is shown how the isotropic property\nof LLM embeddings in contextual embedding space preserves the underlying\nstructure of representations, thereby resolving the shift-invariance problem\nand providing a performance guarantee. Experiments show that different\ncharacteristics of numerical data and model architectures have different\nimpacts on isotropy, and this variability directly affects the performances.",
    "pdf_url": "http://arxiv.org/pdf/2505.17135v4",
    "published": "2025-05-22T05:10:34+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16235v2",
    "title": "$α+{}^2n+{}^2n$ 3-body cluster structures and dineutron breaking in ${}^8 \\mathrm{He}$",
    "authors": [
      "Kosei Nakagawa",
      "Yoshiko Kanada-En'yo"
    ],
    "abstract": "The $0_2^+$ state of ${}^8\\mathrm{He}$ has been discovered by a recent\nexperiment, which suggested a developed cluster structure of spatially\ncorrelated neutron pairs, called \"dineutrons\" (${}^2n$). We aim to investigate\nthe structure of ${}^8\\mathrm{He}(0^+_1)$ and ${}^8\\mathrm{He}(0^+_2)$ to\nclarify the monopole excitation mode in ${}^8\\mathrm{He}$ system while focusing\non the $\\alpha+{}^2n+{}^2n$ cluster structures and the breaking of ${}^2n$\nclusters. We apply a microscopic cluster model with the generator coordinate\nmethod for the $\\alpha+{}^2n+{}^2n$ cluster and ${}^6\\mathrm{He}+{}^2n$ cluster\ndynamics. The $p_{3/2}$-closure component, which is induced by the spin-orbit\nforce, is also incorporated. The present calculation reasonably reproduces the\nexperimental data of the properties of ${}^8\\mathrm{He}$, such as $2n$ and $4n$\nseparation energies, energy spectra, and radii. The spatially developed cluster\nstructure of the $0_2^+$ state is obtained. The $0_1^+$ and $0_2^+$ states have\ndominant components of $\\alpha+{}^2n+{}^2n$ 3-body cluster, but contain\nsignificant ${}^2n$ breaking components which contribute to the energy gain and\nsize shrinking of the ${}^8\\mathrm{He}$ system. The monopole excitation in\n${}^8\\mathrm{He}$ is regarded as a radial excitation, which is similar to that\nin ${}^{12}\\mathrm{C}$. The $\\alpha+{}^2n+{}^2n$ cluster structures play a\ndominant role in ${}^8\\mathrm{He}(0_{1,2}^+)$, and the mixing of the dineutron\nbreaking contributes to significant structural effects.",
    "pdf_url": "http://arxiv.org/pdf/2505.16235v2",
    "published": "2025-05-22T05:10:00+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16234v2",
    "title": "LIFEBench: Evaluating Length Instruction Following in Large Language Models",
    "authors": [
      "Wei Zhang",
      "Zhenhong Zhou",
      "Kun Wang",
      "Junfeng Fang",
      "Yuanhe Zhang",
      "Rui Wang",
      "Ge Zhang",
      "Xavier Li",
      "Li Sun",
      "Lingjuan Lyu",
      "Yang Liu",
      "Sen Su"
    ],
    "abstract": "While large language models (LLMs) can solve PhD-level reasoning problems\nover long context inputs, they still struggle with a seemingly simpler task:\nfollowing explicit length instructions-e.g., write a 10,000-word novel.\nAdditionally, models often generate far too short outputs, terminate\nprematurely, or even refuse the request. Existing benchmarks focus primarily on\nevaluating generations quality, but often overlook whether the generations meet\nlength constraints. To this end, we introduce Length Instruction Following\nEvaluation Benchmark (LIFEBench) to comprehensively evaluate LLMs' ability to\nfollow length instructions across diverse tasks and a wide range of specified\nlengths. LIFEBench consists of 10,800 instances across 4 task categories in\nboth English and Chinese, covering length constraints ranging from 16 to 8192\nwords. We evaluate 26 widely-used LLMs and find that most models reasonably\nfollow short-length instructions but deteriorate sharply beyond a certain\nthreshold. Surprisingly, almost all models fail to reach the vendor-claimed\nmaximum output lengths in practice, as further confirmed by our evaluations\nextending up to 32K words. Even long-context LLMs, despite their extended\ninput-output windows, counterintuitively fail to improve length-instructions\nfollowing. Notably, Reasoning LLMs outperform even specialized long-text\ngeneration models, achieving state-of-the-art length following. Overall,\nLIFEBench uncovers fundamental limitations in current LLMs' length instructions\nfollowing ability, offering critical insights for future progress.",
    "pdf_url": "http://arxiv.org/pdf/2505.16234v2",
    "published": "2025-05-22T05:08:27+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16233v1",
    "title": "Novel Rewiring Mechanism for Restoration of the Fragmented Social Networks after Attacks",
    "authors": [
      "Rajesh Kumar",
      "Suchi Kumari",
      "Anubhav Mishra"
    ],
    "abstract": "Real-world complex systems exhibit intricate interconnections and\ndependencies, especially social networks, technological infrastructures, and\ncommunication networks. These networks are prone to disconnection due to random\nfailures or external attacks on their components. Therefore, managing the\nsecurity and resilience of such networks is a prime concern, particularly at\nthe time of disaster. Therefore, in this research work, network is\nreconstructed by rewiring/addition of the edges and robustness of the networks\nis measured. To this aim, two approaches namely (i) Strategic rewiring (ii)\nbudget constrained optimal rewiring are adopted. While current research often\nassesses robustness by examining the size of the largest connected component,\nthis approach fails to capture the complete spectrum of vulnerability. The\nfailure of a small number of connections leads to a sparser network yet\nconnected network. Thus, the present research work delves deeper into\nevaluating the robustness of the restored network by evaluating Laplacian\nEnergy to better comprehend the system's behavior during the restoration of the\nnetwork still considering the size of the largest connected component attacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16233v1",
    "published": "2025-05-22T05:05:47+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16232v1",
    "title": "MuseRAG: Idea Originality Scoring At Scale",
    "authors": [
      "Ali Sarosh Bangash",
      "Krish Veera",
      "Ishfat Abrar Islam",
      "Raiyan Abdul Baten"
    ],
    "abstract": "An objective, face-valid way to assess the originality of creative ideas is\nto measure how rare each idea is within a population -- an approach long used\nin creativity research but difficult to automate at scale. Tabulating response\nfrequencies via manual bucketing of idea rephrasings is labor-intensive,\nerror-prone, and brittle under large corpora. We introduce a fully automated,\npsychometrically validated pipeline for frequency-based originality scoring.\nOur method, MuseRAG, combines large language models (LLMs) with an externally\norchestrated retrieval-augmented generation (RAG) framework. Given a new idea,\nthe system retrieves semantically similar prior idea buckets and zero-shot\nprompts the LLM to judge whether the new idea belongs to an existing bucket or\nforms a new one. The resulting buckets enable computation of frequency-based\noriginality metrics. Across five datasets (N=1143, n_ideas=16294), MuseRAG\nmatches human annotators in idea clustering structure and resolution (AMI =\n0.59) and in participant-level scoring (r = 0.89) -- while exhibiting strong\nconvergent and external validity. Our work enables intent-sensitive,\nhuman-aligned originality scoring at scale to aid creativity research.",
    "pdf_url": "http://arxiv.org/pdf/2505.16232v1",
    "published": "2025-05-22T05:05:25+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16231v1",
    "title": "Modern Earth-like Chemical Disequilibrium Biosignatures Are Challenging To Constrain Through Spectroscopic Retrievals",
    "authors": [
      "Amber Young",
      "Tyler Robinson",
      "Joshua Krissansen-Totton",
      "Edward Schwieterman",
      "Giada Arney",
      "Gerrick Lindberg",
      "Cristina Thomas"
    ],
    "abstract": "Robust exoplanet characterization studies are underway, and the community is\nlooking ahead toward developing observational strategies to search for life\nbeyond our solar system. With the development of life detection approaches like\nsearching for atmospheric chemical species indicative of life, chemical\ndisequilibrium has also been proposed as a potentially key signature for life.\nChemical disequilibrium can arise from the production of waste gases due to\nbiological processes and can be quantified using a metric known as the\navailable Gibbs free energy. The main goal of this study was to explore the\ndetectability of chemical disequilibrium for a modern Earth-like analog.\nAtmospheric retrievals coupled to a thermodynamics model were used to determine\nposterior distributions for the available Gibbs free energy given simulated\nobservations at various noise levels. In reflected light, chemical\ndisequilibrium signals were difficult to detect and limited by the constraints\non the CH4 abundance, which was challenging to constrain for a modern Earth\ncase with simulated observations spanning ultraviolet through near-infrared\nwavelengths with V-band SNRs of 10, 20, and 40. For a modern Earth analog\norbiting a late-type M dwarf, we simulated transit observations with the James\nWebb Space Telescope Mid-Infrared Instrument (MIRI) and found that tight\nconstraints on the available Gibbs free energy can be achieved, but only at\nextremely low noise on the order of several ppm. This study serves as further\nproof of concept for remotely inferring chemical disequilibrium biosignatures\nand should be included in continuing to build life detection strategies for\nfuture exoplanet characterization missions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16231v1",
    "published": "2025-05-22T05:02:48+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16230v2",
    "title": "Beyond Diagonal Intelligent Reflecting Surface Aided Integrated Sensing and Communication",
    "authors": [
      "Shuo Zheng",
      "Shuowen Zhang"
    ],
    "abstract": "Beyond diagonal intelligent reflecting surface (BD-IRS) is a new promising\nIRS architecture for which the reflection matrix is not limited to the diagonal\nstructure as for conventional IRS. In this paper, we study a BD-IRS aided\nuplink integrated sensing and communication (ISAC) system where sensing is\nperformed in a device-based manner. Specifically, we aim to estimate the\nunknown and random location of an active target based on its uplink probing\nsignals sent to a multi-antenna base station (BS) as well as the known prior\ndistribution information of the target's location. Multiple communication users\nalso simultaneously send uplink signals, resulting in a challenging mutual\ninterference issue between sensing and communication. We first characterize the\nsensing performance metric by deriving the posterior Cram\\'{e}r-Rao bound\n(PCRB) of the mean-squared error (MSE) when prior information is available.\nThen, we formulate a BD-IRS reflection matrix optimization problem to maximize\nthe minimum expected achievable rate among the multiple users subject to a\nconstraint on the PCRB as well as the lossless and reciprocal constraints on\nthe BD-IRS reflection matrix. The formulated problem is non-convex and\nchallenging to solve. To tackle this problem, we propose a penalty dual\ndecomposition (PDD) based algorithm which can find a high-quality suboptimal\nsolution with polynomial-time complexity. In addition, we propose and optimize\na time-division multiple access (TDMA) based scheme which removes the\nsensing-communication mutual interference. Numerical results verify the\neffectiveness of the proposed designs and provide useful design insights such\nas the optimal choice of multiple access scheme.",
    "pdf_url": "http://arxiv.org/pdf/2505.16230v2",
    "published": "2025-05-22T05:00:07+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16229v1",
    "title": "CT-Agent: A Multimodal-LLM Agent for 3D CT Radiology Question Answering",
    "authors": [
      "Yuren Mao",
      "Wenyi Xu",
      "Yuyang Qin",
      "Yunjun Gao"
    ],
    "abstract": "Computed Tomography (CT) scan, which produces 3D volumetric medical data that\ncan be viewed as hundreds of cross-sectional images (a.k.a. slices), provides\ndetailed anatomical information for diagnosis. For radiologists, creating CT\nradiology reports is time-consuming and error-prone. A visual question\nanswering (VQA) system that can answer radiologists' questions about some\nanatomical regions on the CT scan and even automatically generate a radiology\nreport is urgently needed. However, existing VQA systems cannot adequately\nhandle the CT radiology question answering (CTQA) task for: (1) anatomic\ncomplexity makes CT images difficult to understand; (2) spatial relationship\nacross hundreds slices is difficult to capture. To address these issues, this\npaper proposes CT-Agent, a multimodal agentic framework for CTQA. CT-Agent\nadopts anatomically independent tools to break down the anatomic complexity;\nfurthermore, it efficiently captures the across-slice spatial relationship with\na global-local token compression strategy. Experimental results on two 3D chest\nCT datasets, CT-RATE and RadGenome-ChestCT, verify the superior performance of\nCT-Agent.",
    "pdf_url": "http://arxiv.org/pdf/2505.16229v1",
    "published": "2025-05-22T04:59:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16228v1",
    "title": "A Shape-Aware Total Body Photography System for In-focus Surface Coverage Optimization",
    "authors": [
      "Wei-Lun Huang",
      "Joshua Liu",
      "Davood Tashayyod",
      "Jun Kang",
      "Amir Gandjbakhche",
      "Misha Kazhdan",
      "Mehran Armand"
    ],
    "abstract": "Total Body Photography (TBP) is becoming a useful screening tool for patients\nat high risk for skin cancer. While much progress has been made, existing TBP\nsystems can be further improved for automatic detection and analysis of\nsuspicious skin lesions, which is in part related to the resolution and\nsharpness of acquired images. This paper proposes a novel shape-aware TBP\nsystem automatically capturing full-body images while optimizing image quality\nin terms of resolution and sharpness over the body surface. The system uses\ndepth and RGB cameras mounted on a 360-degree rotary beam, along with 3D body\nshape estimation and an in-focus surface optimization method to select the\noptimal focus distance for each camera pose. This allows for optimizing the\nfocused coverage over the complex 3D geometry of the human body given the\ncalibrated camera poses. We evaluate the effectiveness of the system in\ncapturing high-fidelity body images. The proposed system achieves an average\nresolution of 0.068 mm/pixel and 0.0566 mm/pixel with approximately 85% and 95%\nof surface area in-focus, evaluated on simulation data of diverse body shapes\nand poses as well as a real scan of a mannequin respectively. Furthermore, the\nproposed shape-aware focus method outperforms existing focus protocols (e.g.\nauto-focus). We believe the high-fidelity imaging enabled by the proposed\nsystem will improve automated skin lesion analysis for skin cancer screening.",
    "pdf_url": "http://arxiv.org/pdf/2505.16228v1",
    "published": "2025-05-22T04:57:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16227v2",
    "title": "Explain Less, Understand More: Jargon Detection via Personalized Parameter-Efficient Fine-tuning",
    "authors": [
      "Bohao Wu",
      "Qingyun Wang",
      "Yue Guo"
    ],
    "abstract": "Personalizing jargon detection and explanation is essential for making\ntechnical documents accessible to readers with diverse disciplinary\nbackgrounds. However, tailoring models to individual users typically requires\nsubstantial annotation efforts and computational resources due to user-specific\nfinetuning. To address this, we present a systematic study of personalized\njargon detection, focusing on methods that are both efficient and scalable for\nreal-world deployment. We explore two personalization strategies: (1)\nlightweight fine-tuning using Low-Rank Adaptation (LoRA) on open-source models,\nand (2) personalized prompting, which tailors model behavior at inference time\nwithout retaining. To reflect realistic constraints, we also investigate hybrid\napproaches that combine limited annotated data with unsupervised user\nbackground signals. Our personalized LoRA model outperforms GPT-4 by 21.4% in\nF1 score and exceeds the best performing oracle baseline by 8.3%. Remarkably,\nour method achieves comparable performance using only 10% of the annotated\ntraining data, demonstrating its practicality for resource-constrained\nsettings. Our study offers the first work to systematically explore efficient,\nlow-resource personalization of jargon detection using open-source language\nmodels, offering a practical path toward scalable, user-adaptive NLP system.",
    "pdf_url": "http://arxiv.org/pdf/2505.16227v2",
    "published": "2025-05-22T04:55:41+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16226v1",
    "title": "Realistic Evaluation of TabPFN v2 in Open Environments",
    "authors": [
      "Zi-Jian Cheng",
      "Zi-Yi Jia",
      "Zhi Zhou",
      "Yu-Feng Li",
      "Lan-Zhe Guo"
    ],
    "abstract": "Tabular data, owing to its ubiquitous presence in real-world domains, has\ngarnered significant attention in machine learning research. While tree-based\nmodels have long dominated tabular machine learning tasks, the recently\nproposed deep learning model TabPFN v2 has emerged, demonstrating unparalleled\nperformance and scalability potential. Although extensive research has been\nconducted on TabPFN v2 to further improve performance, the majority of this\nresearch remains confined to closed environments, neglecting the challenges\nthat frequently arise in open environments. This raises the question: Can\nTabPFN v2 maintain good performance in open environments? To this end, we\nconduct the first comprehensive evaluation of TabPFN v2's adaptability in open\nenvironments. We construct a unified evaluation framework covering various\nreal-world challenges and assess the robustness of TabPFN v2 under open\nenvironments scenarios using this framework. Empirical results demonstrate that\nTabPFN v2 shows significant limitations in open environments but is suitable\nfor small-scale, covariate-shifted, and class-balanced tasks. Tree-based models\nremain the optimal choice for general tabular tasks in open environments. To\nfacilitate future research on open environments challenges, we advocate for\nopen environments tabular benchmarks, multi-metric evaluation, and universal\nmodules to strengthen model robustness. We publicly release our evaluation\nframework at https://anonymous.4open.science/r/tabpfn-ood-4E65.",
    "pdf_url": "http://arxiv.org/pdf/2505.16226v1",
    "published": "2025-05-22T04:55:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16225v2",
    "title": "MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning",
    "authors": [
      "Zihan Chen",
      "Song Wang",
      "Zhen Tan",
      "Jundong Li",
      "Cong Shen"
    ],
    "abstract": "In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle\ndiverse tasks by incorporating multiple input-output examples, known as\ndemonstrations, into the input of LLMs. More recently, advancements in the\nexpanded context windows of LLMs have led to many-shot ICL, which uses hundreds\nof demonstrations and outperforms few-shot ICL, which relies on fewer examples.\nHowever, this approach is often hindered by the high cost of obtaining large\namounts of labeled data. To address this challenge, we propose Many-Shot\nAdaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL\nframework that utilizes pseudo-labeled samples to compensate for the lack of\nlabel information. We first identify a subset of impactful unlabeled samples\nand perform pseudo-labeling on them by querying LLMs. These pseudo-labeled\nsamples are then adaptively selected and tailored to each test query as input\nto improve the performance of many-shot ICL, without significant labeling\ncosts. Extensive experiments on real-world datasets demonstrate the\neffectiveness of our framework, showcasing its ability to enhance LLM\nadaptability and performance with limited labeled data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16225v2",
    "published": "2025-05-22T04:54:27+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16224v1",
    "title": "Dark Z-mediated dark matter with verifiable exotic scalars",
    "authors": [
      "Chuan-Ren Chen",
      "Cheng-Wei Chiang",
      "Leon M. G. de la Vega"
    ],
    "abstract": "In this work, we study a dark matter scenario where a dark Z boson possessing\nmass mixing with the SM Z boson couples to the DM candidate and serves as the\nportal to the SM. The UV origin of the mass mixing in the form of an extra dark\nHiggs doublet and a scalar dark singlet provides new exotic scalars which can\nconstitute the final state of DM annihilation during freeze-out. We find that\nexisting constraints on the observed Higgs coupling strength, exotic Higgs\nsearches and dark matter observables complement each other, while future\nsearches for exotic Higgs decays and resonant heavy scalars at HL-LHC will be\nsensitive to part of the allowed parameter space.",
    "pdf_url": "http://arxiv.org/pdf/2505.16224v1",
    "published": "2025-05-22T04:54:23+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16223v5",
    "title": "MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network",
    "authors": [
      "Sangyong Lee",
      "Subo Hwang",
      "Dohoon Kim"
    ],
    "abstract": "In this paper, we propose MADCluster, a novel model-agnostic anomaly\ndetection framework utilizing self-supervised clustering. MADCluster is\napplicable to various deep learning architectures and addresses the\n'hypersphere collapse' problem inherent in existing deep learning-based anomaly\ndetection methods. The core idea is to cluster normal pattern data into a\n'single cluster' while simultaneously learning the cluster center and mapping\ndata close to this center. Also, to improve expressiveness and enable effective\nsingle clustering, we propose a new 'One-directed Adaptive loss'. The\noptimization of this loss is mathematically proven. MADCluster consists of\nthree main components: Base Embedder capturing high-dimensional temporal\ndynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous\ncenter updates. Its model-agnostic characteristics are achieved by applying\nvarious architectures to the Base Embedder. Experiments on four time series\nbenchmark datasets demonstrate that applying MADCluster improves the overall\nperformance of comparative models. In conclusion, the compatibility of\nMADCluster shows potential for enhancing model performance across various\narchitectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.16223v5",
    "published": "2025-05-22T04:50:44+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16222v1",
    "title": "Don't Judge Code by Its Cover: Exploring Biases in LLM Judges for Code Evaluation",
    "authors": [
      "Jiwon Moon",
      "Yerin Hwang",
      "Dongryeol Lee",
      "Taegwan Kang",
      "Yongil Kim",
      "Kyomin Jung"
    ],
    "abstract": "With the growing use of large language models(LLMs) as evaluators, their\napplication has expanded to code evaluation tasks, where they assess the\ncorrectness of generated code without relying on reference implementations.\nWhile this offers scalability and flexibility, it also raises a critical,\nunresolved question: Can LLM judges fairly and robustly evaluate semantically\nequivalent code with superficial variations? Functionally correct code often\nexhibits variations-such as differences in variable names, comments, or\nformatting-that should not influence its correctness. Yet, whether LLM judges\ncan reliably handle these variations remains unclear. We present the first\ncomprehensive study of this issue, defining six types of potential bias in code\nevaluation and revealing their systematic impact on LLM judges. Across five\nprogramming languages and multiple LLMs, we empirically demonstrate that all\ntested LLM judges are susceptible to both positive and negative biases,\nresulting in inflated or unfairly low scores. Moreover, we observe that LLM\njudges remain vulnerable to these biases even when prompted to generate test\ncases before scoring, highlighting the need for more robust code evaluation\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.16222v1",
    "published": "2025-05-22T04:49:33+00:00",
    "categories": [
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16221v1",
    "title": "LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead",
    "authors": [
      "Yifan Zhang",
      "Xinkui Zhao",
      "Zuxin Wang",
      "Guanjie Cheng",
      "Yueshen Xu",
      "Shuiguang Deng",
      "Jianwei Yin"
    ],
    "abstract": "The rapid advancement of large language models has unlocked remarkable\ncapabilities across a diverse array of natural language processing tasks.\nHowever, the considerable differences among available LLMs-in terms of cost,\nperformance, and computational demands-pose significant challenges for users\naiming to identify the most suitable model for specific tasks. In this work, we\npresent LightRouter, a novel framework designed to systematically select and\nintegrate a small subset of LLMs from a larger pool, with the objective of\njointly optimizing both task performance and cost efficiency. LightRouter\nleverages an adaptive selection mechanism to identify models that require only\na minimal number of boot tokens, thereby reducing costs, and further employs an\neffective integration strategy to combine their outputs. Extensive experiments\nacross multiple benchmarks demonstrate that LightRouter matches or outperforms\nwidely-used ensemble baselines, achieving up to a 25% improvement in accuracy.\nCompared with leading high-performing models, LightRouter achieves comparable\nperformance while reducing inference costs by up to 27%. Importantly, our\nframework operates without any prior knowledge of individual models and relies\nexclusively on inexpensive, lightweight models. This work introduces a\npractical approach for efficient LLM selection and provides valuable insights\ninto optimal strategies for model combination.",
    "pdf_url": "http://arxiv.org/pdf/2505.16221v1",
    "published": "2025-05-22T04:46:04+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16220v1",
    "title": "Meta-PerSER: Few-Shot Listener Personalized Speech Emotion Recognition via Meta-learning",
    "authors": [
      "Liang-Yeh Shen",
      "Shi-Xin Fang",
      "Yi-Cheng Lin",
      "Huang-Cheng Chou",
      "Hung-yi Lee"
    ],
    "abstract": "This paper introduces Meta-PerSER, a novel meta-learning framework that\npersonalizes Speech Emotion Recognition (SER) by adapting to each listener's\nunique way of interpreting emotion. Conventional SER systems rely on aggregated\nannotations, which often overlook individual subtleties and lead to\ninconsistent predictions. In contrast, Meta-PerSER leverages a Model-Agnostic\nMeta-Learning (MAML) approach enhanced with Combined-Set Meta-Training,\nDerivative Annealing, and per-layer per-step learning rates, enabling rapid\nadaptation with only a few labeled examples. By integrating robust\nrepresentations from pre-trained self-supervised models, our framework first\ncaptures general emotional cues and then fine-tunes itself to personal\nannotation styles. Experiments on the IEMOCAP corpus demonstrate that\nMeta-PerSER significantly outperforms baseline methods in both seen and unseen\ndata scenarios, highlighting its promise for personalized emotion recognition.",
    "pdf_url": "http://arxiv.org/pdf/2505.16220v1",
    "published": "2025-05-22T04:44:20+00:00",
    "categories": [
      "eess.AS",
      "cs.CL"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16219v1",
    "title": "Hidden-Charm Tetraquarks in a Mixture Model: Coupled-Channel Analysis with $c\\bar{c}$ and Hadronic Molecular Components",
    "authors": [
      "Kotaro Miyake",
      "Yasuhiro Yamaguchi"
    ],
    "abstract": "The nature of the $X(3872)$ and other exotic hadrons has been a subject of\nextensive investigation since the first observation of the $X(3872)$ in 2003.\nWhile various theoretical models have been proposed, including hadronic\nmolecular and compact tetraquark interpretations, some experimental evidence\nsuggests that the $X(3872)$ may be a mixture state of a hadronic molecule and a\n$c\\bar{c}$ core. In this work, we perform a systematic study of the\nhidden-charm tetraquark candidates $X(3860)$, $X(3872)$, and $Z(3930)$ using a\ncoupled-channel model that incorporates both $c\\bar{c}$ states and\n$D^{(*)}\\bar{D}^{(*)}$ hadronic molecular components. The $c\\bar{c}$ sector is\ndescribed based on the constituent quark model predictions for the\n$\\chi_{cJ}(2P)$ ($J = 0, 1, 2$) states, while the meson-meson interactions are\nmodeled using pseudoscalar and vector meson exchange potentials. The model\nparameters are fixed to reproduce the masses of the $X(3872)$ and $Z(3930)$,\nand the resulting framework is used to predict the mass and structure of the\n$J^{PC} = 0^{++}$ state associated with the $X(3860)$. Our results support the\nmixture interpretation of these exotic hadrons, exhibiting strong attractions\nfrom the transition potential between $c\\bar{c}$ and $D^{(*)}\\bar{D}^{(*)}$\ncomponents. The molecular component is found to dominate in the $X(3872)$,\nwhile the $c\\bar{c}$ component plays a more prominent role in the $X(3860)$ and\n$Z(3930)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16219v1",
    "published": "2025-05-22T04:43:39+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16218v1",
    "title": "Understanding the Lyα Emission Observed by the Solar Disk Imager Aboard the Advanced Space-based Solar Observatory",
    "authors": [
      "Yiliang Li",
      "Ping Zhang",
      "Zhengyuan Tian",
      "Li Feng",
      "Guanglu Shi",
      "Jianchao Xue",
      "Ying Li",
      "Jun Tian",
      "Kaifan Ji",
      "Beili Ying",
      "Lei Lu",
      "Shuting Li",
      "Jiahui Shan",
      "Hui Li",
      "Weiqun Gan"
    ],
    "abstract": "The H I Lyman-alpha (Ly$\\alpha$) emission, with a wavelength of 1216 \\r{A},\nis the brightest solar ultraviolet (UV) line. However, comprehensive\nobservations of the Ly$\\alpha$ emission line across the full solar disk remain\nlimited. As part of the ASO-S mission, the Solar Disk Imager (SDI) has\nsuccessfully captured full-disk images in the Ly$\\alpha$ band. Gaussian fitting\nof SDI's spectral response function (SRF) yields a full width at half maximum\n(FWHM) of approximately 85 \\r{A}, which is significantly broader than the\ndistance of Si III line at 1206 \\r{A} and the Ly$\\alpha$ line. Thus, the\nemission contribution of Si III to the SDI Ly$\\alpha$ passband needs to be\nconsidered. For flares, in practice, we calculated the integrated intensity\nratio $I$(Si III)/$I$(Ly$\\alpha$) by analyzing spectral observations from the\nSOLSTICE instrument. It yields values between 1.7% and 14.6%. Empirically, the\nratio is proportional to the SXR flux. Further analysis of spectral data from\nthe SUMER instrument reveals that the ratio $I$(Si III)/$I$(Ly$\\alpha$) is\napproximately 0.5% for prominences, 0.7%--0.9% for the inner disk, and\n1.4%--1.9% close to the limb. These findings suggest that $I$(Si\nIII)/$I$(Ly$\\alpha$) is minimal for prominences and the inner disk, and the\nvarying ratios across regions align with the center-to-limb variation of the Si\nIII and Ly$\\alpha$ lines. Additionally, we compared Ly$\\alpha$ image intensity\nwith 304 \\r{A}, 1600 \\r{A}, and 1700 \\r{A} observations from AIA, as well as\nH$\\alpha$ from CHASE, in multiple regions (a prominence region, two active\nregions, and a quiet region). A relatively higher correlation of about 85% is\nfound between Ly$\\alpha$ and 304 \\r{A} in active regions, whereas in the quiet\nregion and prominence, their correlation coefficients are about 55%.",
    "pdf_url": "http://arxiv.org/pdf/2505.16218v1",
    "published": "2025-05-22T04:34:21+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16217v1",
    "title": "Reward-Aware Proto-Representations in Reinforcement Learning",
    "authors": [
      "Hon Tik Tse",
      "Siddarth Chandrasekar",
      "Marlos C. Machado"
    ],
    "abstract": "In recent years, the successor representation (SR) has attracted increasing\nattention in reinforcement learning (RL), and it has been used to address some\nof its key challenges, such as exploration, credit assignment, and\ngeneralization. The SR can be seen as representing the underlying credit\nassignment structure of the environment by implicitly encoding its induced\ntransition dynamics. However, the SR is reward-agnostic. In this paper, we\ndiscuss a similar representation that also takes into account the reward\ndynamics of the problem. We study the default representation (DR), a recently\nproposed representation with limited theoretical (and empirical) analysis.\nHere, we lay some of the theoretical foundation underlying the DR in the\ntabular case by (1) deriving dynamic programming and (2) temporal-difference\nmethods to learn the DR, (3) characterizing the basis for the vector space of\nthe DR, and (4) formally extending the DR to the function approximation case\nthrough default features. Empirically, we analyze the benefits of the DR in\nmany of the settings in which the SR has been applied, including (1) reward\nshaping, (2) option discovery, (3) exploration, and (4) transfer learning. Our\nresults show that, compared to the SR, the DR gives rise to qualitatively\ndifferent, reward-aware behaviour and quantitatively better performance in\nseveral settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16217v1",
    "published": "2025-05-22T04:33:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16216v1",
    "title": "Memorization or Reasoning? Exploring the Idiom Understanding of LLMs",
    "authors": [
      "Jisu Kim",
      "Youngwoo Shin",
      "Uiji Hwang",
      "Jihun Choi",
      "Richeng Xuan",
      "Taeuk Kim"
    ],
    "abstract": "Idioms have long posed a challenge due to their unique linguistic properties,\nwhich set them apart from other common expressions. While recent studies have\nleveraged large language models (LLMs) to handle idioms across various tasks,\ne.g., idiom-containing sentence generation and idiomatic machine translation,\nlittle is known about the underlying mechanisms of idiom processing in LLMs,\nparticularly in multilingual settings. To this end, we introduce MIDAS, a new\nlarge-scale dataset of idioms in six languages, each paired with its\ncorresponding meaning. Leveraging this resource, we conduct a comprehensive\nevaluation of LLMs' idiom processing ability, identifying key factors that\ninfluence their performance. Our findings suggest that LLMs rely not only on\nmemorization, but also adopt a hybrid approach that integrates contextual cues\nand reasoning, especially when processing compositional idioms. This implies\nthat idiom understanding in LLMs emerges from an interplay between internal\nknowledge retrieval and reasoning-based inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.16216v1",
    "published": "2025-05-22T04:31:25+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16215v1",
    "title": "A Scalable Hierarchical Intrusion Detection System for Internet of Vehicles",
    "authors": [
      "Md Ashraf Uddin",
      "Nam H. Chu",
      "Reza Rafeh",
      "Mutaz Barika"
    ],
    "abstract": "Due to its nature of dynamic, mobility, and wireless data transfer, the\nInternet of Vehicles (IoV) is prone to various cyber threats, ranging from\nspoofing and Distributed Denial of Services (DDoS) attacks to malware. To\nsafeguard the IoV ecosystem from intrusions, malicious activities, policy\nviolations, intrusion detection systems (IDS) play a critical role by\ncontinuously monitoring and analyzing network traffic to identify and mitigate\npotential threats in real-time. However, most existing research has focused on\ndeveloping centralized, machine learning-based IDS systems for IoV without\naccounting for its inherently distributed nature. Due to intensive computing\nrequirements, these centralized systems often rely on the cloud to detect cyber\nthreats, increasing delay of system response. On the other hand, edge nodes\ntypically lack the necessary resources to train and deploy complex machine\nlearning algorithms. To address this issue, this paper proposes an effective\nhierarchical classification framework tailored for IoV networks. Hierarchical\nclassification allows classifiers to be trained and tested at different levels,\nenabling edge nodes to detect specific types of attacks independently. With\nthis approach, edge nodes can conduct targeted attack detection while\nleveraging cloud nodes for comprehensive threat analysis and support. Given the\nresource constraints of edge nodes, we have employed the Boruta feature\nselection method to reduce data dimensionality, optimizing processing\nefficiency. To evaluate our proposed framework, we utilize the latest IoV\nsecurity dataset CIC-IoV2024, achieving promising results that demonstrate the\nfeasibility and effectiveness of our models in securing IoV networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16215v1",
    "published": "2025-05-22T04:30:26+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16214v2",
    "title": "Behavioral Safety Assessment towards Large-scale Deployment of Autonomous Vehicles",
    "authors": [
      "Henry X. Liu",
      "Xintao Yan",
      "Haowei Sun",
      "Tinghan Wang",
      "Zhijie Qiao",
      "Haojie Zhu",
      "Shengyin Shen",
      "Shuo Feng",
      "Greg Stevens",
      "Greg McGuire"
    ],
    "abstract": "Autonomous vehicles (AVs) have significantly advanced in real-world\ndeployment in recent years, yet safety continues to be a critical barrier to\nwidespread adoption. Traditional functional safety approaches, which primarily\nverify the reliability, robustness, and adequacy of AV hardware and software\nsystems from a vehicle-centric perspective, do not sufficiently address the\nAV's broader interactions and behavioral impact on the surrounding traffic\nenvironment. To overcome this limitation, we propose a paradigm shift toward\nbehavioral safety, a comprehensive approach focused on evaluating AV responses\nand interactions within traffic environment. To systematically assess\nbehavioral safety, we introduce a third-party AV safety assessment framework\ncomprising two complementary evaluation components: Driver Licensing Test and\nDriving Intelligence Test. The Driver Licensing Test evaluates AV's reactive\nbehaviors under controlled scenarios, ensuring basic behavioral competency. In\ncontrast, the Driving Intelligence Test assesses AV's interactive behaviors\nwithin naturalistic traffic conditions, quantifying the frequency of\nsafety-critical events to deliver statistically meaningful safety metrics\nbefore large-scale deployment. We validated our proposed framework using\n\\texttt{Autoware.Universe}, an open-source Level 4 AV, tested both in simulated\nenvironments and on the physical test track at the University of Michigan's\nMcity Testing Facility. The results indicate that \\texttt{Autoware.Universe}\npassed 6 out of 14 scenarios and exhibited a crash rate of 3.01e-3 crashes per\nmile, approximately 1,000 times higher than average human driver crash rate.\nDuring the tests, we also uncovered several unknown unsafe scenarios for\n\\texttt{Autoware.Universe}. These findings underscore the necessity of\nbehavioral safety evaluations for improving AV safety performance prior to\nwidespread public deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16214v2",
    "published": "2025-05-22T04:28:59+00:00",
    "categories": [
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16213v3",
    "title": "Continuum limit of the Kuramoto model with random natural frequencies on uniform graphs",
    "authors": [
      "Kazuyuki Yagasaki"
    ],
    "abstract": "We study the Kuramoto model (KM) having random natural frequencies and\ndefined on uniform graphs that may be complete, random dense or random sparse.\nThe natural frequencies are assumed to be independent and identically\ndistributed on a bounded interval. In the previous work, the corresponding\ncontinuum limit (CL) was proven to approximate stable motions in the KM well\nwhen the natural frequencies are deterministic, even if the graph is not\nuniform, although it may not do so for unstable motions and bifurcations. We\nshow that the method of CLs is still valid even when the natural frequencies\nare random, especially uniformly distributed. In particular, an asymptotically\nstable family of solutions to the CL is proven to behave in the $L^2$ sense as\nif it is an asymptotically stable one in the KM, under an appropriate uniform\nrandom permutation. We demonstrate the theoretical results by numerical\nsimulations for the KM with uniformly distributed random natural frequencies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16213v3",
    "published": "2025-05-22T04:28:22+00:00",
    "categories": [
      "math.DS",
      "34C15, 45J05, 34D06, 34D20, 45M10, 05C90"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16212v2",
    "title": "Large Language Models based ASR Error Correction for Child Conversations",
    "authors": [
      "Anfeng Xu",
      "Tiantian Feng",
      "So Hyun Kim",
      "Somer Bishop",
      "Catherine Lord",
      "Shrikanth Narayanan"
    ],
    "abstract": "Automatic Speech Recognition (ASR) has recently shown remarkable progress,\nbut accurately transcribing children's speech remains a significant challenge.\nRecent developments in Large Language Models (LLMs) have shown promise in\nimproving ASR transcriptions. However, their applications in child speech\nincluding conversational scenarios are underexplored. In this study, we explore\nthe use of LLMs in correcting ASR errors for conversational child speech. We\ndemonstrate the promises and challenges of LLMs through experiments on two\nchildren's conversational speech datasets with both zero-shot and fine-tuned\nASR outputs. We find that while LLMs are helpful in correcting zero-shot ASR\noutputs and fine-tuned CTC-based ASR outputs, it remains challenging for LLMs\nto improve ASR performance when incorporating contextual information or when\nusing fine-tuned autoregressive ASR (e.g., Whisper) outputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16212v2",
    "published": "2025-05-22T04:28:02+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16211v2",
    "title": "AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models",
    "authors": [
      "Kai Li",
      "Can Shen",
      "Yile Liu",
      "Jirui Han",
      "Kelong Zheng",
      "Xuechao Zou",
      "Zhe Wang",
      "Xingjian Du",
      "Shun Zhang",
      "Hanjun Luo",
      "Yingbin Jin",
      "Xinxin Xing",
      "Ziyang Ma",
      "Yue Liu",
      "Xiaojun Jia",
      "Yifan Zhang",
      "Junfeng Fang",
      "Kun Wang",
      "Yibo Yan",
      "Haoyang Li",
      "Yiming Li",
      "Xiaobin Zhuang",
      "Yang Liu",
      "Haibo Hu",
      "Zhizheng Wu",
      "Xiaolin Hu",
      "Eng-Siong Chng",
      "XiaoFeng Wang",
      "Wenyuan Xu",
      "Wei Dong",
      "Xinfeng Li"
    ],
    "abstract": "The rapid advancement and expanding applications of Audio Large Language\nModels (ALLMs) demand a rigorous understanding of their trustworthiness.\nHowever, systematic research on evaluating these models, particularly\nconcerning risks unique to the audio modality, remains largely unexplored.\nExisting evaluation frameworks primarily focus on the text modality or address\nonly a restricted set of safety dimensions, failing to adequately account for\nthe unique characteristics and application scenarios inherent to the audio\nmodality. We introduce AudioTrust-the first multifaceted trustworthiness\nevaluation framework and benchmark specifically designed for ALLMs. AudioTrust\nfacilitates assessments across six key dimensions: fairness, hallucination,\nsafety, privacy, robustness, and authentication. To comprehensively evaluate\nthese dimensions, AudioTrust is structured around 18 distinct experimental\nsetups. Its core is a meticulously constructed dataset of over 4,420 audio/text\nsamples, drawn from real-world scenarios (e.g., daily conversations, emergency\ncalls, voice assistant interactions), specifically designed to probe the\nmultifaceted trustworthiness of ALLMs. For assessment, the benchmark carefully\ndesigns 9 audio-specific evaluation metrics, and we employ a large-scale\nautomated pipeline for objective and scalable scoring of model outputs.\nExperimental results reveal the trustworthiness boundaries and limitations of\ncurrent state-of-the-art open-source and closed-source ALLMs when confronted\nwith various high-risk audio scenarios, offering valuable insights for the\nsecure and trustworthy deployment of future audio models. Our platform and\nbenchmark are available at https://github.com/JusperLee/AudioTrust.",
    "pdf_url": "http://arxiv.org/pdf/2505.16211v2",
    "published": "2025-05-22T04:27:46+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16210v1",
    "title": "NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics",
    "authors": [
      "Zhihang Cai",
      "Xingjun Zhang",
      "Zhendong Tan",
      "Zheng Wei"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency across\na wide range of tasks. However, LLMs often require larger batch sizes to\nenhance throughput or longer context lengths to meet task demands, which\nsignificantly increases the memory resource consumption of the Key-Value (KV)\ncache during inference, becoming a major bottleneck in LLM deployment. To\naddress this issue, quantization is a common and straightforward approach.\nCurrently, quantization methods for activations are limited to 8-bit, and\nquantization to even lower bits can lead to substantial accuracy drops. To\nfurther save space by quantizing the KV cache to even lower bits, we analyzed\nthe element distribution of the KV cache and designed the NQKV algorithm. Since\nthe elements within each block of the KV cache follow a normal distribution,\nNQKV employs per-block quantile quantization to achieve\ninformation-theoretically optimal quantization error. Without significantly\ncompromising model output quality, NQKV enables the OPT model to perform\ninference with an 2x larger batch size or a 4x longer context length, and it\nimproves throughput by 9.3x compared to when the KV cache is not used.",
    "pdf_url": "http://arxiv.org/pdf/2505.16210v1",
    "published": "2025-05-22T04:23:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16208v1",
    "title": "Using Echo-State Networks to Reproduce Rare Events in Chaotic Systems",
    "authors": [
      "Anton Erofeev",
      "Balasubramanya T. Nadiga",
      "Ilya Timofeyev"
    ],
    "abstract": "We apply the Echo-State Networks to predict the time series and statistical\nproperties of the competitive Lotka-Volterra model in the chaotic regime. In\nparticular, we demonstrate that Echo-State Networks successfully learn the\nchaotic attractor of the competitive Lotka-Volterra model and reproduce\nhistograms of dependent variables, including tails and rare events. We use the\nGeneralized Extreme Value distribution to quantify the tail behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.16208v1",
    "published": "2025-05-22T04:21:05+00:00",
    "categories": [
      "nlin.CD",
      "cs.AI",
      "cs.LG",
      "math.DS",
      "37N99, 68T30"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16209v2",
    "title": "MedCFVQA: A Causal Approach to Mitigate Modality Preference Bias in Medical Visual Question Answering",
    "authors": [
      "Shuchang Ye",
      "Usman Naseem",
      "Mingyuan Meng",
      "Dagan Feng",
      "Jinman Kim"
    ],
    "abstract": "Medical Visual Question Answering (MedVQA) is crucial for enhancing the\nefficiency of clinical diagnosis by providing accurate and timely responses to\nclinicians' inquiries regarding medical images. Existing MedVQA models suffered\nfrom modality preference bias, where predictions are heavily dominated by one\nmodality while overlooking the other (in MedVQA, usually questions dominate the\nanswer but images are overlooked), thereby failing to learn multimodal\nknowledge. To overcome the modality preference bias, we proposed a Medical\nCounterFactual VQA (MedCFVQA) model, which trains with bias and leverages\ncausal graphs to eliminate the modality preference bias during inference.\nExisting MedVQA datasets exhibit substantial prior dependencies between\nquestions and answers, which results in acceptable performance even if the\nmodel significantly suffers from the modality preference bias. To address this\nissue, we reconstructed new datasets by leveraging existing MedVQA datasets and\nChanged their P3rior dependencies (CP) between questions and their answers in\nthe training and test set. Extensive experiments demonstrate that MedCFVQA\nsignificantly outperforms its non-causal counterpart on both SLAKE, RadVQA and\nSLAKE-CP, RadVQA-CP datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.16209v2",
    "published": "2025-05-22T04:21:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16207v1",
    "title": "Differentiable K-means for Fully-optimized Discrete Token-based ASR",
    "authors": [
      "Kentaro Onda",
      "Yosuke Kashiwagi",
      "Emiru Tsunoo",
      "Hayato Futami",
      "Shinji Watanabe"
    ],
    "abstract": "Recent studies have highlighted the potential of discrete tokens derived from\nself-supervised learning (SSL) models for various speech-related tasks. These\ntokens serve not only as substitutes for text in language modeling but also as\nintermediate representations for tasks such as automatic speech recognition\n(ASR). However, discrete tokens are typically obtained via k-means clustering\nof SSL features independently of downstream tasks, making them suboptimal for\nspecific applications. This paper proposes the use of differentiable k-means,\nenabling the joint optimization of tokenization and downstream tasks. This\napproach enables the fine-tuning of the SSL parameters and learning weights for\noutputs from multiple SSL layers. Experiments were conducted with ASR as a\ndownstream task. ASR accuracy successfully improved owing to the optimized\ntokens. The acquired tokens also exhibited greater purity of phonetic\ninformation, which were found to be useful even in speech resynthesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.16207v1",
    "published": "2025-05-22T04:20:51+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16206v1",
    "title": "Finite temperatures and flat bands: the Hubbard model on three-dimensional Lieb lattices",
    "authors": [
      "Lucas O. Lima",
      "Julián Faúndez",
      "Natanael C. Costa",
      "Raimundo R. dos Santos"
    ],
    "abstract": "We investigate some thermodynamic and magnetic properties of the Hubbard\nmodel on two three-dimensional extensions of the Lieb lattice: the perovskite\nLieb lattice (PLL) and the layered Lieb lattice (LLL). Using determinant\nquantum Monte Carlo (DQMC) simulations alongside Hartree-Fock and cluster\nmean-field theory (CMFT) approaches, we analyze how flat-band degeneracy,\nconnectivity, and lattice anisotropy influence the emergence of magnetic order.\nOur results show that both geometries support finite-temperature magnetic\ntransitions, namely ferromagnetic (FM) on the PLL, and antiferromagnetic (AFM)\non the LLL. Further, we have established that the critical temperature, $T_c$,\nas a function of the uniform on-site coupling, $U$, displays a maximum, which\nis smaller in the AFM case than in the FM one, despite the absence of flat\nbands in the LLL. We also provide numerical evidence to show that flat bands in\nthe PLL rapidly generate magnetic moments, but a small interorbital\ncoordination suppresses the increase of $T_c$ at large interaction strength\n$U/t$. By contrast, the LLL benefits from higher connectivity, favoring\nmagnetic order even in the absence of flat bands. The possibilities of\nanisotropic interlayer hoppings and inhomogeneous on-site interactions were\nseparateley explored. We have found that magnetism in the PLL is hardly\naffected by hopping anisotropy, since the main driving mechanism is the\npreserved flat band; for the LLL, by contrast, spectral weight is removed from\n$d$-sites, which increases $T_c$ more significantly. At mean-field level, we\nhave obtained that setting $U=0$ on $p$ sites and $U=U_d\\neq0$ on $d$ sites\nleads to a quantum critical point at some $U_d$; this behavior was not\nconfirmed by our DQMC simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16206v1",
    "published": "2025-05-22T04:18:36+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.16205v1",
    "title": "VIVID: A Novel Approach to Remediation Prioritization in Static Application Security Testing (SAST)",
    "authors": [
      "Naeem Budhwani",
      "Mohammad Faghani",
      "Hayden Richard"
    ],
    "abstract": "Static Application Security Testing (SAST) enables organizations to detect\nvulnerabilities in code early; however, major SAST platforms do not include\nvisual aids and present little insight on correlations between tainted data\nchains. We propose VIVID - Vulnerability Information Via Data flow - a novel\nmethod to extract and consume SAST insights, which is to graph the\napplication's vulnerability data flows (VDFs) and carry out graph theory\nanalysis on the resulting VDF directed graph. Nine metrics were assessed to\nevaluate their effectiveness in analyzing the VDF graphs of deliberately\ninsecure web applications. These metrics include 3 centrality metrics, 2\nstructural metrics, PageRank, in-degree, out-degree, and cross-clique\nconnectivity. We present simulations that find that out-degree, betweenness\ncentrality, in-eigenvector centrality, and cross-clique connectivity were found\nto be associated with files exhibiting high vulnerability traffic, making them\nrefactoring candidates where input sanitization may have been missed.\nMeanwhile, out-eigenvector centrality, PageRank, and in-degree were found to be\nassociated with nodes enabling vulnerability flow and sinks, but not\nnecessarily where input validation should be placed. This is a novel method to\nautomatically provide development teams an evidence-based prioritized list of\nfiles to embed security controls into, informed by vulnerability propagation\npatterns in the application architecture.",
    "pdf_url": "http://arxiv.org/pdf/2505.16205v1",
    "published": "2025-05-22T04:16:56+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16204v1",
    "title": "Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks",
    "authors": [
      "Ichiro Hashimoto"
    ],
    "abstract": "In this paper, we prove directional convergence of network parameters of\nfixed width leaky ReLU two-layer neural networks optimized by gradient descent\nwith exponential loss, which was previously only known for gradient flow. By a\ncareful analysis of the convergent direction, we establish sufficient\nconditions of benign overfitting and discover a new phase transition in the\ntest error bound. All of these results hold beyond the nearly orthogonal data\nsetting which was studied in prior works. As an application, we demonstrate\nthat benign overfitting occurs with high probability in sub-Gaussian mixture\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.16204v1",
    "published": "2025-05-22T04:11:58+00:00",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH",
      "68T07 (primary)"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16203v1",
    "title": "Explicit Families of Spinor Representations",
    "authors": [
      "Jesus Sanchez Jr"
    ],
    "abstract": "We provide a recipe for building explicit representations of the real\nClifford algebras once an explicit family is given in dimensions $1$ through\n$4$. We further give an explicit construction of spin coordinate systems for a\ngiven real spinor module and use it to explicitly compute the parallel\ntransport of spinor fields. We further highlight some novelties such as the\nrelationship with the spectrum of the spinor Dirac operator and the Hodge de\nRham operator when a parallel spinor field exists and a brief discussion of\nspinors along a hypersurface in $\\bR^4$. Lastly, we extend our construction to\narbitrary signature quadratic forms thus providing a complete and explicit\nfamily of spinor representations for all mixed signature Clifford algberas. We\nshow that in all cases the spinor representations can be expressed as tensor\nproducts of multi-vectors over the fields $\\bR$, $\\bC$, and $\\bH$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16203v1",
    "published": "2025-05-22T04:11:13+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21517v1",
    "title": "Cold Start Problem: An Experimental Study of Knowledge Tracing Models with New Students",
    "authors": [
      "Indronil Bhattacharjee",
      "Christabel Wayllace"
    ],
    "abstract": "KnowledgeTracing (KT) involves predicting students' knowledge states based on\ntheir interactions with Intelligent Tutoring Systems (ITS). A key challenge is\nthe cold start problem, accurately predicting knowledge for new students with\nminimal interaction data. Unlike prior work, which typically trains KT models\non initial interactions of all students and tests on their subsequent\ninteractions, our approach trains models solely using historical data from past\nstudents, evaluating their performance exclusively on entirely new students. We\ninvestigate cold start effects across three KT models: Deep Knowledge Tracing\n(DKT), Dynamic Key-Value Memory Networks (DKVMN), and Self-Attentive Knowledge\nTracing (SAKT), using ASSISTments 2009, 2015, and 2017 datasets. Results\nindicate all models initially struggle under cold start conditions but\nprogressively improve with more interactions; SAKT shows higher initial\naccuracy yet still faces limitations. These findings highlight the need for KT\nmodels that effectively generalize to new learners, emphasizing the importance\nof developing models robust in few-shot and zero-shot learning scenarios",
    "pdf_url": "http://arxiv.org/pdf/2505.21517v1",
    "published": "2025-05-22T04:09:07+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16202v1",
    "title": "Light Black Holes from Light",
    "authors": [
      "Don N. Page"
    ],
    "abstract": "Alvarez-Dominguez, Garay, Martin-Martinez, and Polo-Gomez have suggested that\n``it is not possible to concentrate enough light to precipitate the formation\nof an event horizon. We argue that the dissipative quantum effects coming from\nthe self-interaction of light (such as vacuum polarization) are enough to\nprevent any meaningful buildup of energy that could create a black hole in any\nrealistic scenario,'' and ``the dissipation of energy via Schwinger effect\nalone is enough to prevent the formation of kugelblitze with radii ranging from\n$10^{-29}$ to $10^8$ m.'' While I agree that it is indeed highly implausible\nthat black holes will form mainly from light in our actual universe, either\nnaturally or by any foreseeable human activity, there are many idealized\ntheoretical processes for forming black holes of any size down to near the\nPlanck length (about $10^{-35}$ m) purely from photons, such as from colliding\napproximately plane-wave pulses, with only a small fraction of the energy\nescaping the black hole as scattered light or electron-positron pairs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16202v1",
    "published": "2025-05-22T04:08:55+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16201v1",
    "title": "On Quotients of a More General Theorem of Wilson",
    "authors": [
      "Ivan V. Morozov"
    ],
    "abstract": "The basis of this work is a simple, extended corollary of Wilson's theorem.\nThis corollary generates many more quotients than those already generated by\nWilson's theorem, and it was of interest to derive how they relate to each\nother and build on the established properties of the original quotients. The\nmost important results that were found were expressions for sums of these\nquotients, modular congruences that extended the results of Lehmer, and\ngenerating functions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16201v1",
    "published": "2025-05-22T04:06:03+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16200v1",
    "title": "Advanced Integration Strategies for ESD Protection and Termination in High-Speed LVDS Systems",
    "authors": [
      "Kavya Gaddipati"
    ],
    "abstract": "This technical article explores comprehensive strategies for integrating\nElectrostatic Discharge (ESD) protection diodes and termination resistors in\nLowVoltage Differential Signaling (LVDS) designs. The article examines critical\naspects of protection mechanisms, design considerations, impedance matching,\nand placement optimization techniques. Through detailed analysis of layout\nconsiderations and advanced design strategies, the article presents solutions\nfor common integration challenges. It emphasizes the importance of signal\nintegrity maintenance and protection effectiveness while providing practical\nguidelines for implementing robust LVDS systems. Various methodologies for\nperformance optimization and validation are discussed, offering designers a\nthorough framework for creating reliable high-speed digital systems that\nbalance protection requirements with signal integrity demands.",
    "pdf_url": "http://arxiv.org/pdf/2505.16200v1",
    "published": "2025-05-22T04:05:05+00:00",
    "categories": [
      "cs.AR",
      "cs.CE",
      "cs.ET"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17134v2",
    "title": "LongMagpie: A Self-synthesis Method for Generating Large-scale Long-context Instructions",
    "authors": [
      "Chaochen Gao",
      "Xing Wu",
      "Zijia Lin",
      "Debing Zhang",
      "Songlin Hu"
    ],
    "abstract": "High-quality long-context instruction data is essential for aligning\nlong-context large language models (LLMs). Despite the public release of models\nlike Qwen and Llama, their long-context instruction data remains proprietary.\nHuman annotation is costly and challenging, while template-based synthesis\nmethods limit scale, diversity, and quality. We introduce LongMagpie, a\nself-synthesis framework that automatically generates large-scale long-context\ninstruction data. Our key insight is that aligned long-context LLMs, when\npresented with a document followed by special tokens preceding a user turn,\nauto-regressively generate contextually relevant queries. By harvesting these\ndocument-query pairs and the model's responses, LongMagpie produces\nhigh-quality instructions without human effort. Experiments on HELMET, RULER,\nand Longbench v2 demonstrate that LongMagpie achieves leading performance on\nlong-context tasks while maintaining competitive performance on short-context\ntasks, establishing it as a simple and effective approach for open, diverse,\nand scalable long-context instruction data synthesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.17134v2",
    "published": "2025-05-22T04:05:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16199v1",
    "title": "Velocity Completion Task and Method for Event-based Player Positional Data in Soccer",
    "authors": [
      "Rikuhei Umemoto",
      "Keisuke Fujii"
    ],
    "abstract": "In many real-world complex systems, the behavior can be observed as a\ncollection of discrete events generated by multiple interacting agents.\nAnalyzing the dynamics of these multi-agent systems, especially team sports,\noften relies on understanding the movement and interactions of individual\nagents. However, while providing valuable snapshots, event-based positional\ndata typically lacks the continuous temporal information needed to directly\ncalculate crucial properties such as velocity. This absence severely limits the\ndepth of dynamic analysis, preventing a comprehensive understanding of\nindividual agent behaviors and emergent team strategies. To address this\nchallenge, we propose a new method to simultaneously complete the velocity of\nall agents using only the event-based positional data from team sports. Based\non this completed velocity information, we investigate the applicability of\nexisting team sports analysis and evaluation methods. Experiments using soccer\nevent data demonstrate that neural network-based approaches outperformed\nrule-based methods regarding velocity completion error, considering the\nunderlying temporal dependencies and graph structure of player-to-player or\nplayer-to-ball interaction. Moreover, the space evaluation results obtained\nusing the completed velocity are closer to those derived from complete tracking\ndata, highlighting our method's potential for enhanced team sports system\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.16199v1",
    "published": "2025-05-22T04:01:49+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16198v1",
    "title": "Effect of thermal conductivity on the simultaneous formation of a stable region at the top of Earth's core and magnetic field generation over four billion years",
    "authors": [
      "Takashi Nakagawa",
      "Shin-ichi Takahero",
      "Youhei Sasaki"
    ],
    "abstract": "The possibility of the emergence of a stratified region in the uppermost part\nof the Earth's outer core with long-term magnetic field generation is assessed,\ntaking into account uncertainties in the thermal conductivity of the Earth's\ncore and the present-day heat flow across the core-mantle boundary (CMB). The\nradial structures of the Earth's outer core are calculated for various values\nof thermal conductivity and CMB heat flow using a one-dimensional\nthermo-chemical model. The results show that there exist solutions that allow\nboth emergence of stable stratification and long-term magnetic field generation\nalthough their thickness of stratified region is thinner than 100 km. In order\nto satisfy both emergence of stratified region and long-term magnetic field\ngeneration, possible value of the present-day CMB heat flow (13-15 TW) suggests\na thermal conductivity of 77-121 W/m/K at CMB, which is in good agreement with\nthe values estimated from the electrical conductivity measurements under the\nEarth' s core condition. The thickness of the stratified region in this case is\nabout 50 km, which is also consistent with the thickness of the stratified\nregion estimated from the geomagnetic secular variation. However, the proposed\nvalues of thermal conductivity obtained by this analysis could be smaller when\nthe present-day CMB heat flow becomes smaller than the constraint used in this\nstudy.",
    "pdf_url": "http://arxiv.org/pdf/2505.16198v1",
    "published": "2025-05-22T04:01:43+00:00",
    "categories": [
      "astro-ph.EP",
      "physics.geo-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16197v1",
    "title": "Hypoellipticity of the Asymptotic Bismut Superconnection on Contact Manifolds",
    "authors": [
      "Jesus Sanchez Jr",
      "Andres Franco Valiente"
    ],
    "abstract": "Given a contact sub-Riemannian manifold, one obtains a non-integrable\nsplitting of the tangent bundle into the directions along the contact\ndistribution and the Reeb field. We generalize the construction of the Bismut\nsuperconnection to this non-integrable setting and show that although\nsingularities appear within the superconnection, if one extracts the finite\npart then the resulting operator is hypoelliptic. We then discuss the explicit\nform of the operator on principal $\\bS^1$-bundles and discuss possible\ndirections for generalizations and open questions; in particular, a possible\nrelationship between our hypoelliptic operator and a constrained supersymmetric\nsigma model.",
    "pdf_url": "http://arxiv.org/pdf/2505.16197v1",
    "published": "2025-05-22T04:01:06+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16196v2",
    "title": "SEM: Enhancing Spatial Understanding for Robust Robot Manipulation",
    "authors": [
      "Xuewu Lin",
      "Tianwei Lin",
      "Lichao Huang",
      "Hongyu Xie",
      "Yiwei Jin",
      "Keyu Li",
      "Zhizhong Su"
    ],
    "abstract": "A key challenge in robot manipulation lies in developing policy models with\nstrong spatial understanding, the ability to reason about 3D geometry, object\nrelations, and robot embodiment. Existing methods often fall short: 3D point\ncloud models lack semantic abstraction, while 2D image encoders struggle with\nspatial reasoning. To address this, we propose SEM (Spatial Enhanced\nManipulation model), a novel diffusion-based policy framework that explicitly\nenhances spatial understanding from two complementary perspectives. A spatial\nenhancer augments visual representations with 3D geometric context, while a\nrobot state encoder captures embodiment-aware structure through graphbased\nmodeling of joint dependencies. By integrating these modules, SEM significantly\nimproves spatial understanding, leading to robust and generalizable\nmanipulation across diverse tasks that outperform existing baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.16196v2",
    "published": "2025-05-22T04:00:12+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16195v2",
    "title": "SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet",
    "authors": [
      "Zhi Zhong",
      "Akira Takahashi",
      "Shuyang Cui",
      "Keisuke Toyama",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ],
    "abstract": "Foley synthesis aims to synthesize high-quality audio that is both\nsemantically and temporally aligned with video frames. Given its broad\napplication in creative industries, the task has gained increasing attention in\nthe research community. To avoid the non-trivial task of training audio\ngenerative models from scratch, adapting pretrained audio generative models for\nvideo-synchronized foley synthesis presents an attractive direction.\nControlNet, a method for adding fine-grained controls to pretrained generative\nmodels, has been applied to foley synthesis, but its use has been limited to\nhandcrafted human-readable temporal conditions. In contrast, from-scratch\nmodels achieved success by leveraging high-dimensional deep features extracted\nusing pretrained video encoders. We have observed a performance gap between\nControlNet-based and from-scratch foley models. To narrow this gap, we propose\nSpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward\nvideo-synchronized foley synthesis via ControlNet. To unlock the potential of a\nsingle ControlNet branch, we resolve the discrepancy between the temporal video\nfeatures and the time-frequency nature of the pretrained SpecMaskGIT via a\nfrequency-aware temporal feature aligner, eliminating the need for complicated\nconditioning mechanisms widely used in prior arts. Evaluations on a common\nfoley synthesis benchmark demonstrate that SpecMaskFoley could even outperform\nstrong from-scratch baselines, substantially advancing the development of\nControlNet-based foley synthesis models. Demo page:\nhttps://zzaudio.github.io/SpecMaskFoley_Demo/",
    "pdf_url": "http://arxiv.org/pdf/2505.16195v2",
    "published": "2025-05-22T03:58:16+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.IV"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16194v1",
    "title": "Pressure evolution of coplanar antiferromagnetism in heavy-fermion Ce$_{2}$CoAl$_{7}$Ge$_{4}$",
    "authors": [
      "M. O. Ajeesh",
      "A. O. Scheie",
      "Yu Liu",
      "L. Keller",
      "S. M. Thomas",
      "P. F. S. Rosa",
      "E. D. Bauer"
    ],
    "abstract": "Ce$_{2}$$M$Al$_{7}$Ge$_{4}$ ($M=$ Co, Ir, Ni or Pd) are heavy-fermion\nmaterials and host a variety of ground states ranging from magnetism to\nnon-Fermi liquid behavior. The Co, Ir, and Ni members of the series undergo\nmagnetic ordering with decreasing transition temperatures. In contrast, the Pd\ncompound does not magnetically order down to 0.4 K and shows non-Fermi liquid\nbehavior, suggesting proximity to a magnetic quantum critical point. Among the\nseries, Ce$_{2}$CoAl$_{7}$Ge$_{4}$ orders antiferromagnetically below $T_N=1.9$\nK along with heavy-fermion behavior below 15 K. We report the magnetic\nstructure of the antiferromagnetic phase in Ce$_{2}$CoAl$_{7}$Ge$_{4}$ and the\nevolution of the magnetic transition under external pressure. Rietveld\nrefinement of the neutron diffraction data suggests a coplanar\nantiferromagnetic structure with a wave vector $k = (1,1,1)$ and an ordered\nmoment of $0.383 \\pm 0.018 \\> \\mu_B$ in the antiferromagnetic phase. Electrical\nresistivity and AC calorimetry measurements under hydrostatic pressure reveal a\nsuppression of the antiferromagnetic transition toward zero temperature around\n$p=1.1$ GPa. However, there is no evidence of non-Fermi liquid behavior\nassociated with the suppression of magnetism by pressure, unlike the effect of\ntransition-metal substitution.",
    "pdf_url": "http://arxiv.org/pdf/2505.16194v1",
    "published": "2025-05-22T03:57:22+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.16193v1",
    "title": "An Empirical Study on Configuring In-Context Learning Demonstrations for Unleashing MLLMs' Sentimental Perception Capability",
    "authors": [
      "Daiqing Wu",
      "Dongbao Yang",
      "Sicheng Zhao",
      "Can Ma",
      "Yu Zhou"
    ],
    "abstract": "The advancements in Multimodal Large Language Models (MLLMs) have enabled\nvarious multimodal tasks to be addressed under a zero-shot paradigm. This\nparadigm sidesteps the cost of model fine-tuning, emerging as a dominant trend\nin practical application. Nevertheless, Multimodal Sentiment Analysis (MSA), a\npivotal challenge in the quest for general artificial intelligence, fails to\naccommodate this convenience. The zero-shot paradigm exhibits undesirable\nperformance on MSA, casting doubt on whether MLLMs can perceive sentiments as\ncompetent as supervised models. By extending the zero-shot paradigm to\nIn-Context Learning (ICL) and conducting an in-depth study on configuring\ndemonstrations, we validate that MLLMs indeed possess such capability.\nSpecifically, three key factors that cover demonstrations' retrieval,\npresentation, and distribution are comprehensively investigated and optimized.\nA sentimental predictive bias inherent in MLLMs is also discovered and later\neffectively counteracted. By complementing each other, the devised strategies\nfor three factors result in average accuracy improvements of 15.9% on six MSA\ndatasets against the zero-shot paradigm and 11.2% against the random ICL\nbaseline.",
    "pdf_url": "http://arxiv.org/pdf/2505.16193v1",
    "published": "2025-05-22T03:51:41+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16192v2",
    "title": "VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought",
    "authors": [
      "Chaoya Jiang",
      "Yongrui Heng",
      "Wei Ye",
      "Han Yang",
      "Haiyang Xu",
      "Ming Yan",
      "Ji Zhang",
      "Fei Huang",
      "Shikun Zhang"
    ],
    "abstract": "Recently, reasoning-based MLLMs have achieved a degree of success in\ngenerating long-form textual reasoning chains. However, they still struggle\nwith complex tasks that necessitate dynamic and iterative focusing on and\nrevisiting of visual regions to achieve precise grounding of textual reasoning\nin visual evidence. We introduce \\textbf{VLM-R$^3$} (\\textbf{V}isual\n\\textbf{L}anguage \\textbf{M}odel with \\textbf{R}egion \\textbf{R}ecognition and\n\\textbf{R}easoning), a framework that equips an MLLM with the ability to (i)\ndecide \\emph{when} additional visual evidence is needed, (ii) determine\n\\emph{where} to ground within the image, and (iii) seamlessly weave the\nrelevant sub-image content back into an interleaved chain-of-thought. The core\nof our method is \\textbf{Region-Conditioned Reinforcement Policy Optimization\n(R-GRPO)}, a training paradigm that rewards the model for selecting informative\nregions, formulating appropriate transformations (e.g.\\ crop, zoom), and\nintegrating the resulting visual context into subsequent reasoning steps. To\nbootstrap this policy, we compile a modest but carefully curated Visuo-Lingual\nInterleaved Rationale (VLIR) corpus that provides step-level supervision on\nregion selection and textual justification. Extensive experiments on MathVista,\nScienceQA, and other benchmarks show that VLM-R$^3$ sets a new state of the art\nin zero-shot and few-shot settings, with the largest gains appearing on\nquestions demanding subtle spatial reasoning or fine-grained visual cue\nextraction.",
    "pdf_url": "http://arxiv.org/pdf/2505.16192v2",
    "published": "2025-05-22T03:50:13+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16191v1",
    "title": "Prosodically Enhanced Foreign Accent Simulation by Discrete Token-based Resynthesis Only with Native Speech Corpora",
    "authors": [
      "Kentaro Onda",
      "Keisuke Imoto",
      "Satoru Fukayama",
      "Daisuke Saito",
      "Nobuaki Minematsu"
    ],
    "abstract": "Recently, a method for synthesizing foreign-accented speech only with native\nspeech data using discrete tokens obtained from self-supervised learning (SSL)\nmodels was proposed. Considering limited availability of accented speech data,\nthis method is expected to make it much easier to simulate foreign accents. By\nusing the synthesized accented speech as listening materials for humans or\ntraining data for automatic speech recognition (ASR), both of them will acquire\nhigher robustness against foreign accents. However, the previous method has a\nfatal flaw that it cannot reproduce duration-related accents. Durational\naccents are commonly seen when L2 speakers, whose native language has\nsyllable-timed or mora-timed rhythm, speak stress-timed languages, such as\nEnglish. In this paper, we integrate duration modification to the previous\nmethod to simulate foreign accents more accurately. Experiments show that the\nproposed method successfully replicates durational accents seen in real L2\nspeech.",
    "pdf_url": "http://arxiv.org/pdf/2505.16191v1",
    "published": "2025-05-22T03:50:05+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16190v1",
    "title": "Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare",
    "authors": [
      "Navid Seidi",
      "Satyaki Roy",
      "Sajal Das"
    ],
    "abstract": "Federated Learning (FL) holds great promise for digital health by enabling\ncollaborative model training without compromising patient data privacy.\nHowever, heterogeneity across institutions, lack of sustained reputation, and\nunreliable contributions remain major challenges. In this paper, we propose a\nrobust, peer-driven reputation mechanism for federated healthcare that employs\na hybrid communication model to integrate decentralized peer feedback with\nclustering-based noise handling to enhance model aggregation. Crucially, our\napproach decouples the federated aggregation and reputation mechanisms by\napplying differential privacy to client-side model updates before sharing them\nfor peer evaluation. This ensures sensitive information remains protected\nduring reputation computation, while unaltered updates are sent to the server\nfor global model training. Using the Cox Proportional Hazards model for\nsurvival analysis across multiple federated nodes, our framework addresses both\ndata heterogeneity and reputation deficit by dynamically adjusting trust scores\nbased on local performance improvements measured via the concordance index.\nExperimental evaluations on both synthetic datasets and the SEER dataset\ndemonstrate that our method consistently achieves high and stable C-index\nvalues, effectively down-weighing noisy client updates and outperforming FL\nmethods that lack a reputation system.",
    "pdf_url": "http://arxiv.org/pdf/2505.16190v1",
    "published": "2025-05-22T03:49:51+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16189v1",
    "title": "The Language of Interoception: Examining Embodiment and Emotion Through a Corpus of Body Part Mentions",
    "authors": [
      "Sophie Wu",
      "Jan Philip Wahle",
      "Saif M. Mohammad"
    ],
    "abstract": "This paper is the first investigation of the connection between emotion,\nembodiment, and everyday language in a large sample of natural language data.\nWe created corpora of body part mentions (BPMs) in online English text (blog\nposts and tweets). This includes a subset featuring human annotations for the\nemotions of the person whose body part is mentioned in the text. We show that\nBPMs are common in personal narratives and tweets (~5% to 10% of posts include\nBPMs) and that their usage patterns vary markedly by time and %geographic\nlocation. Using word-emotion association lexicons and our annotated data, we\nshow that text containing BPMs tends to be more emotionally charged, even when\nthe BPM is not explicitly used to describe a physical reaction to the emotion\nin the text. Finally, we discover a strong and statistically significant\ncorrelation between body-related language and a variety of poorer health\noutcomes. In sum, we argue that investigating the role of body-part related\nwords in language can open up valuable avenues of future research at the\nintersection of NLP, the affective sciences, and the study of human wellbeing.",
    "pdf_url": "http://arxiv.org/pdf/2505.16189v1",
    "published": "2025-05-22T03:47:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16188v1",
    "title": "SAE-SSV: Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models",
    "authors": [
      "Zirui He",
      "Mingyu Jin",
      "Bo Shen",
      "Ali Payani",
      "Yongfeng Zhang",
      "Mengnan Du"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language understanding and generation, but controlling their behavior\nreliably remains challenging, especially in open-ended generation settings.\nThis paper introduces a novel supervised steering approach that operates in\nsparse, interpretable representation spaces. We employ sparse autoencoders\n(SAEs)to obtain sparse latent representations that aim to disentangle semantic\nattributes from model activations. Then we train linear classifiers to identify\na small subspace of task-relevant dimensions in latent representations.\nFinally, we learn supervised steering vectors constrained to this subspace,\noptimized to align with target behaviors. Experiments across sentiment,\ntruthfulness, and politics polarity steering tasks with multiple LLMs\ndemonstrate that our supervised steering vectors achieve higher success rates\nwith minimal degradation in generation quality compared to existing methods.\nFurther analysis reveals that a notably small subspace is sufficient for\neffective steering, enabling more targeted and interpretable interventions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16188v1",
    "published": "2025-05-22T03:46:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16187v1",
    "title": "EasyInsert: A Data-Efficient and Generalizable Insertion Policy",
    "authors": [
      "Guanghe Li",
      "Junming Zhao",
      "Shengjie Wang",
      "Yang Gao"
    ],
    "abstract": "Insertion task is highly challenging that requires robots to operate with\nexceptional precision in cluttered environments. Existing methods often have\npoor generalization capabilities. They typically function in restricted and\nstructured environments, and frequently fail when the plug and socket are far\napart, when the scene is densely cluttered, or when handling novel objects.\nThey also rely on strong assumptions such as access to CAD models or a digital\ntwin in simulation. To address this, we propose EasyInsert, a framework which\nleverages the human intuition that relative pose (delta pose) between plug and\nsocket is sufficient for successful insertion, and employs efficient and\nautomated real-world data collection with minimal human labor to train a\ngeneralizable model for relative pose prediction. During execution, EasyInsert\nfollows a coarse-to-fine execution procedure based on predicted delta pose, and\nsuccessfully performs various insertion tasks. EasyInsert demonstrates strong\nzero-shot generalization capability for unseen objects in cluttered\nenvironments, handling cases with significant initial pose deviations while\nmaintaining high sample efficiency and requiring little human effort. In\nreal-world experiments, with just 5 hours of training data, EasyInsert achieves\nover 90% success in zero-shot insertion for 13 out of 15 unseen novel objects,\nincluding challenging objects like Type-C cables, HDMI cables, and Ethernet\ncables. Furthermore, with only one human demonstration and 4 minutes of\nautomatically collected data for fine-tuning, it reaches over 90% success rate\nfor all 15 objects.",
    "pdf_url": "http://arxiv.org/pdf/2505.16187v1",
    "published": "2025-05-22T03:46:05+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16186v1",
    "title": "SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning",
    "authors": [
      "Kaiwen Zhou",
      "Xuandong Zhao",
      "Gaowen Liu",
      "Jayanth Srinivasa",
      "Aosong Feng",
      "Dawn Song",
      "Xin Eric Wang"
    ],
    "abstract": "Large Reasoning Models (LRMs) introduce a new generation paradigm of\nexplicitly reasoning before answering, leading to remarkable improvements in\ncomplex tasks. However, they pose great safety risks against harmful queries\nand adversarial attacks. While recent mainstream safety efforts on LRMs,\nsupervised fine-tuning (SFT), improve safety performance, we find that\nSFT-aligned models struggle to generalize to unseen jailbreak prompts. After\nthorough investigation of LRMs' generation, we identify a safety aha moment\nthat can activate safety reasoning and lead to a safe response. This aha moment\ntypically appears in the `key sentence', which follows models' query\nunderstanding process and can indicate whether the model will proceed safely.\nBased on these insights, we propose SafeKey, including two complementary\nobjectives to better activate the safety aha moment in the key sentence: (1) a\nDual-Path Safety Head to enhance the safety signal in the model's internal\nrepresentations before the key sentence, and (2) a Query-Mask Modeling\nobjective to improve the models' attention on its query understanding, which\nhas important safety hints. Experiments across multiple safety benchmarks\ndemonstrate that our methods significantly improve safety generalization to a\nwide range of jailbreak attacks and out-of-distribution harmful prompts,\nlowering the average harmfulness rate by 9.6\\%, while maintaining general\nabilities. Our analysis reveals how SafeKey enhances safety by reshaping\ninternal attention and improving the quality of hidden representations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16186v1",
    "published": "2025-05-22T03:46:03+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16185v1",
    "title": "A Game for Counting Logic Formula Size and an Application to Linear Orders",
    "authors": [
      "Gregoire Fournier",
      "György Turán"
    ],
    "abstract": "Ehrenfeucht-Fra\\\"iss\\'e (EF) games are a basic tool in finite model theory\nfor proving definability lower bounds, with many applications in complexity\ntheory and related areas. They have been applied to study various logics,\ngiving insights on quantifier rank and other logical complexity measures. In\nthis paper, we present an EF game to capture formula size in counting logic\nwith a bounded number of variables. The game combines games introduced\npreviously for counting logic quantifier rank due to Immerman and Lander, and\nfor first-order formula size due to Adler and Immerman, and Hella and\nV\\\"a\\\"an\\\"anen. The game is used to prove the main result of the paper, an\nextension of a formula size lower bound of Grohe and Schweikardt for\ndistinguishing linear orders, from 3-variable first-order logic to 3-variable\ncounting logic. As far as we know, this is the first formula size lower bound\nfor counting logic.",
    "pdf_url": "http://arxiv.org/pdf/2505.16185v1",
    "published": "2025-05-22T03:42:48+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16184v1",
    "title": "Pure nematic transition inside the superconducting dome of iron chalcogenide superconductor FeSe$_{1-x}$Te$_x$",
    "authors": [
      "K. Y. Liang",
      "R . Z. Zhang",
      "Z. F. Lin",
      "Z. J. Li",
      "B. R. Chen",
      "P. H. Zhang",
      "K. Z. Yao",
      "Q. S. He",
      "Q. Z. Zhou",
      "H. X. Yao",
      "K. Jin",
      "Y. H. Wang"
    ],
    "abstract": "Nematicity and magnetism are prevalent orders in high transition temperature\n(Tc) superconductors, coexisting in the parent compound of most material\nfamilies. Quantum fluctuations of nematicity or spin orders are both plausible\ncandidates for mediating unconventional Cooper pairing. Identifying the sole\neffect of a nematic quantum critical point (QCP) on the emergence of\nsuperconducting dome without interference of spin fluctuations is therefore\nhighly desirable. The iron chalcogenide superconductor FeSe exhibits pure\nnematicity without any magnetic ordering. A nematic quantum phase transition\ncan be induced by Te substitution but experimental study of such transition is\nso far limited to its normal state. By performing local susceptometry on\ncomposition-spread FeSe$_{1-x}$Te$_x$ films ($0 < x < 1$) using scanning\nSuperconducting Quantum Interference Device (sSQUID) microscopy, we investigate\nthe superfluid density ($\\rho_s$) across the pure nematic transition in\nextremely fine steps of ${\\Delta}x$ = 0.0008. The temperature dependence of\n$\\rho_s$ changes from the form of anisotropic pairing on the nematic side to an\nisotropic one across the critical doping $x_c$. The power-law dependence of gap\nanisotropy on $|x - x_c|$ provides evidence for nematic quantum criticality\nunder the superconducting dome. The low-temperature $\\rho_s$ scales linearly\nwith Tc in the nematic phase $x < x_c$, whereas the gap amplitude, maximized at\n$x_c$, determines the Tc for $x>x_c$. Our results establish a pure nematic QCP\nin FeSe$_{1-x}$Te$_x$, separating two superconducting orders with distinct\npairing boosted by nematic quantum fluctuations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16184v1",
    "published": "2025-05-22T03:42:24+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.16183v1",
    "title": "Ultrafast charge-transfer dynamics in Ca$_2$CuO$_2$Cl$_2$ from time-resolved optical reflectivity",
    "authors": [
      "Haiyun Huang",
      "Xiu Zhang",
      "Junzhi Zhu",
      "Jianfa Zhao",
      "Lin Zhao",
      "Yu-Xia Duan",
      "Jian-Qiao Meng",
      "X. J. Zhou",
      "Changqing Jin",
      "Haiyun Liu"
    ],
    "abstract": "We employ time-resolved optical reflectivity to investigate the ultrafast\ndynamics of the charge-transfer gap (CTG) in a parent cuprate compound\nCa$_2$CuO$_2$Cl$_2$ (CCOC). We observe a persistent photoinduced red shift of\nthe CTG that lasts up to 1000 ps. The red shift during the slow decay after 10\nps can be well modeled by the localized picture, whereas its maximum value at\n~0.9 ps involves additional contribution from the renormalization of the\nHubbard U due to screening effect from delocalized electrons. Furthermore,\ncoupling between the mid-gap absorption and a slow acoustic phonon launches\ncoherent oscillations below the CTG, observed as a ~20 GHz modulation with a\ndispersion independent of the pump fluence. These results demonstrate the\ntunning of the CTG by light, unveil complex interplay between multiple degrees\nof freedom, and contribute to a deeper understanding of superconductivity and\ncorrelated materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.16183v1",
    "published": "2025-05-22T03:38:52+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.16182v1",
    "title": "Discrete Tokens Exhibit Interlanguage Speech Intelligibility Benefit: an Analytical Study Towards Accent-robust ASR Only with Native Speech Data",
    "authors": [
      "Kentaro Onda",
      "Keisuke Imoto",
      "Satoru Fukayama",
      "Daisuke Saito",
      "Nobuaki Minematsu"
    ],
    "abstract": "In this study, we gained insight that contributes to achieving accent-robust\nASR using only native speech data. In human perception of non-native speech,\nthe phenomenon known as \"interlanguage speech intelligibility benefit\" (ISIB)\nis observed, where non-native listeners who share the native language with the\nspeaker understand the speech better compared even to native listeners. Based\non the idea that discrete tokens extracted from self-supervised learning (SSL)\nmodels represent the human perception of speech, we conducted an analytical\nstudy on the robustness of discrete token-based ASR to non-native speech,\nvarying the language used for training the tokenization, which is viewed as a\ntechnical implementation of ISIB. The results showed that ISIB actually\noccurred in the discrete token-based ASR. Since our approach relies only on\nnative speech data to simulate the behavior of human perception, it is expected\nto be applicable to a wide range of accents for which speech data is scarce.",
    "pdf_url": "http://arxiv.org/pdf/2505.16182v1",
    "published": "2025-05-22T03:36:28+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16181v2",
    "title": "Understanding Generative AI Capabilities in Everyday Image Editing Tasks",
    "authors": [
      "Mohammad Reza Taesiri",
      "Brandon Collins",
      "Logan Bolton",
      "Viet Dac Lai",
      "Franck Dernoncourt",
      "Trung Bui",
      "Anh Totti Nguyen"
    ],
    "abstract": "Generative AI (GenAI) holds significant promise for automating everyday image\nediting tasks, especially following the recent release of GPT-4o on March 25,\n2025. However, what subjects do people most often want edited? What kinds of\nediting actions do they want to perform (e.g., removing or stylizing the\nsubject)? Do people prefer precise edits with predictable outcomes or highly\ncreative ones? By understanding the characteristics of real-world requests and\nthe corresponding edits made by freelance photo-editing wizards, can we draw\nlessons for improving AI-based editors and determine which types of requests\ncan currently be handled successfully by AI editors? In this paper, we present\na unique study addressing these questions by analyzing 83k requests from the\npast 12 years (2013-2025) on the Reddit community, which collected 305k\nPSR-wizard edits. According to human ratings, approximately only 33% of\nrequests can be fulfilled by the best AI editors (including GPT-4o,\nGemini-2.0-Flash, SeedEdit). Interestingly, AI editors perform worse on\nlow-creativity requests that require precise editing than on more open-ended\ntasks. They often struggle to preserve the identity of people and animals, and\nfrequently make non-requested touch-ups. On the other side of the table, VLM\njudges (e.g., o1) perform differently from human judges and may prefer AI edits\nmore than human edits. Code and qualitative examples are available at:\nhttps://psrdataset.github.io",
    "pdf_url": "http://arxiv.org/pdf/2505.16181v2",
    "published": "2025-05-22T03:35:15+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16180v1",
    "title": "Redemption Score: An Evaluation Framework to Rank Image Captions While Redeeming Image Semantics and Language Pragmatics",
    "authors": [
      "Ashim Dahal",
      "Ankit Ghimire",
      "Saydul Akbar Murad",
      "Nick Rahimi"
    ],
    "abstract": "Evaluating image captions requires cohesive assessment of both visual\nsemantics and language pragmatics, which is often not entirely captured by most\nmetrics. We introduce Redemption Score, a novel hybrid framework that ranks\nimage captions by triangulating three complementary signals: (1) Mutual\nInformation Divergence (MID) for global image-text distributional alignment,\n(2) DINO-based perceptual similarity of cycle-generated images for visual\ngrounding, and (3) BERTScore for contextual text similarity against human\nreferences. A calibrated fusion of these signals allows Redemption Score to\noffer a more holistic assessment. On the Flickr8k benchmark, Redemption Score\nachieves a Kendall-$\\tau$ of 56.43, outperforming twelve prior methods and\ndemonstrating superior correlation with human judgments without requiring\ntask-specific training. Our framework provides a more robust and nuanced\nevaluation by effectively redeeming image semantics and linguistic\ninterpretability indicated by strong transfer of knowledge in the Conceptual\nCaptions and MS COCO datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.16180v1",
    "published": "2025-05-22T03:35:12+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16179v2",
    "title": "On forest and bipartite cuts in sparse graphs",
    "authors": [
      "Ilya I. Bogdanov",
      "Elizaveta Neustroeva",
      "Georgy Sokolov",
      "Alexei Volostnov",
      "Nikolay Russkin",
      "Vsevolod Voronov"
    ],
    "abstract": "The paper is devoted to sufficient conditions for the existence of vertex\ncuts in simple graphs, where the induced subgraph on the cut vertices belongs\nto a specified graph class. In particular, we show that any connected graph\nwith $n$ vertices and fewer than $(19n - 28)/8$ edges admits a forest cut. This\nresult improves upon recent bounds, although it does not resolve the conjecture\nthat the sharp threshold is $3n - 6$ (Chernyshev, Rauch, Rautenbach, 2024).\nFurthermore, we prove that if the number of edges is less than $(80n-134)/31$,\nthen the graph admits a bipartite cut.",
    "pdf_url": "http://arxiv.org/pdf/2505.16179v2",
    "published": "2025-05-22T03:34:48+00:00",
    "categories": [
      "math.CO",
      "05C35, 05C40"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16178v1",
    "title": "Understanding Fact Recall in Language Models: Why Two-Stage Training Encourages Memorization but Mixed Training Teaches Knowledge",
    "authors": [
      "Ying Zhang",
      "Benjamin Heinzerling",
      "Dongyuan Li",
      "Ryoma Ishigaki",
      "Yuta Hitomi",
      "Kentaro Inui"
    ],
    "abstract": "Fact recall, the ability of language models (LMs) to retrieve specific\nfactual knowledge, remains a challenging task despite their impressive general\ncapabilities. Common training strategies often struggle to promote robust\nrecall behavior with two-stage training, which first trains a model with\nfact-storing examples (e.g., factual statements) and then with fact-recalling\nexamples (question-answer pairs), tending to encourage rote memorization rather\nthan generalizable fact retrieval. In contrast, mixed training, which jointly\nuses both types of examples, has been empirically shown to improve the ability\nto recall facts, but the underlying mechanisms are still poorly understood. In\nthis work, we investigate how these training strategies affect how model\nparameters are shaped during training and how these differences relate to their\nability to recall facts. We introduce cross-task gradient trace to identify\nshared parameters, those strongly influenced by both fact-storing and\nfact-recalling examples. Our analysis on synthetic fact recall datasets with\nthe Llama-3.2B and Pythia-2.8B models reveals that mixed training encouraging a\nlarger and more centralized set of shared parameters. These findings suggest\nthat the emergence of parameters may play a key role in enabling LMs to\ngeneralize factual knowledge across task formulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16178v1",
    "published": "2025-05-22T03:34:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17133v1",
    "title": "Learning Probabilities of Causation from Finite Population Data",
    "authors": [
      "Shuai Wang",
      "Song Jiang",
      "Yizhou Sun",
      "Judea Pearl",
      "Ang Li"
    ],
    "abstract": "Probabilities of causation play a crucial role in modern decision-making.\nThis paper addresses the challenge of predicting probabilities of causation for\nsubpopulations with \\textbf{insufficient} data using machine learning models.\nTian and Pearl first defined and derived tight bounds for three fundamental\nprobabilities of causation: the probability of necessity and sufficiency (PNS),\nthe probability of sufficiency (PS), and the probability of necessity (PN).\nHowever, estimating these probabilities requires both experimental and\nobservational distributions specific to each subpopulation, which are often\nunavailable or impractical to obtain with limited population-level data.\nTherefore, for most subgroups, the amount of data they have is not enough to\nguarantee the accuracy of their probabilities. Hence, to estimate these\nprobabilities for subpopulations with \\textbf{insufficient} data, we propose\nusing machine learning models that draw insights from subpopulations with\nsufficient data. Our evaluation of multiple machine learning models indicates\nthat, given the population-level data and an appropriate choice of machine\nlearning model and activation function, PNS can be effectively predicted.\nThrough simulation studies on multiple Structured Causal Models (SCMs), we show\nthat our multilayer perceptron (MLP) model with the Mish activation function\nachieves a mean absolute error (MAE) of approximately $0.02$ in predicting PNS\nfor $32,768$ subpopulations across most SCMs using data from only $2,000$\nsubpopulations with known PNS values.",
    "pdf_url": "http://arxiv.org/pdf/2505.17133v1",
    "published": "2025-05-22T03:31:44+00:00",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16177v1",
    "title": "Generative Latent Coding for Ultra-Low Bitrate Image and Video Compression",
    "authors": [
      "Linfeng Qi",
      "Zhaoyang Jia",
      "Jiahao Li",
      "Bin Li",
      "Houqiang Li",
      "Yan Lu"
    ],
    "abstract": "Most existing approaches for image and video compression perform transform\ncoding in the pixel space to reduce redundancy. However, due to the\nmisalignment between the pixel-space distortion and human perception, such\nschemes often face the difficulties in achieving both high-realism and\nhigh-fidelity at ultra-low bitrate. To solve this problem, we propose\n\\textbf{G}enerative \\textbf{L}atent \\textbf{C}oding (\\textbf{GLC}) models for\nimage and video compression, termed GLC-image and GLC-Video. The transform\ncoding of GLC is conducted in the latent space of a generative vector-quantized\nvariational auto-encoder (VQ-VAE). Compared to the pixel-space, such a latent\nspace offers greater sparsity, richer semantics and better alignment with human\nperception, and show its advantages in achieving high-realism and high-fidelity\ncompression. To further enhance performance, we improve the hyper prior by\nintroducing a spatial categorical hyper module in GLC-image and a\nspatio-temporal categorical hyper module in GLC-video. Additionally, the\ncode-prediction-based loss function is proposed to enhance the semantic\nconsistency. Experiments demonstrate that our scheme shows high visual quality\nat ultra-low bitrate for both image and video compression. For image\ncompression, GLC-image achieves an impressive bitrate of less than $0.04$ bpp,\nachieving the same FID as previous SOTA model MS-ILLM while using $45\\%$ fewer\nbitrate on the CLIC 2020 test set. For video compression, GLC-video achieves\n65.3\\% bitrate saving over PLVC in terms of DISTS.",
    "pdf_url": "http://arxiv.org/pdf/2505.16177v1",
    "published": "2025-05-22T03:31:33+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16176v1",
    "title": "Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning",
    "authors": [
      "Jun Rao",
      "Xuebo Liu",
      "Hexuan Deng",
      "Zepeng Lin",
      "Zixiong Yu",
      "Jiansheng Wei",
      "Xiaojun Meng",
      "Min Zhang"
    ],
    "abstract": "In the realm of data selection for reasoning tasks, existing approaches\npredominantly rely on externally predefined static metrics such as difficulty\nand diversity, which are often designed for supervised fine-tuning (SFT) and\nlack adaptability to continuous training processes. A critical limitation of\nthese methods is their inability to dynamically align with the evolving\ncapabilities of models during online training, a gap that becomes increasingly\npronounced with the rise of dynamic training paradigms and online reinforcement\nlearning (RL) frameworks (e.g., R1 models). To address this, we introduce\nSAI-DPO, an algorithm that dynamically selects training data by continuously\nassessing a model's stage-specific reasoning abilities across different\ntraining phases. By integrating real-time model performance feedback, SAI-DPO\nadaptively adapts data selection to the evolving strengths and weaknesses of\nthe model, thus enhancing both data utilization efficiency and final task\nperformance. Extensive experiments on three state-of-the-art models and eight\nmathematical reasoning benchmarks, including challenging competition-level\ndatasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average\nperformance boost of up to 21.3 percentage points, with particularly notable\nimprovements of 10 and 15 points on AIME24 and AMC23, respectively. These\nresults highlight the superiority of dynamic, model-adaptive data selection\nover static, externally defined strategies in advancing reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.16176v1",
    "published": "2025-05-22T03:27:05+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16175v2",
    "title": "QuickVideo: Real-Time Long Video Understanding with System Algorithm Co-Design",
    "authors": [
      "Benjamin Schneider",
      "Dongfu Jiang",
      "Chao Du",
      "Tianyu Pang",
      "Wenhu Chen"
    ],
    "abstract": "Long-video understanding has emerged as a crucial capability in real-world\napplications such as video surveillance, meeting summarization, educational\nlecture analysis, and sports broadcasting. However, it remains computationally\nprohibitive for VideoLLMs, primarily due to two bottlenecks: 1) sequential\nvideo decoding, the process of converting the raw bit stream to RGB frames can\ntake up to a minute for hour-long video inputs, and 2) costly prefilling of up\nto several million tokens for LLM inference, resulting in high latency and\nmemory use. To address these challenges, we propose QuickVideo, a\nsystem-algorithm co-design that substantially accelerates long-video\nunderstanding to support real-time downstream applications. It comprises three\nkey innovations: QuickDecoder, a parallelized CPU-based video decoder that\nachieves 2-3 times speedup by splitting videos into keyframe-aligned intervals\nprocessed concurrently; QuickPrefill, a memory-efficient prefilling method\nusing KV-cache pruning to support more frames with less GPU memory; and an\noverlapping scheme that overlaps CPU video decoding with GPU inference.\nTogether, these components infernece time reduce by a minute on long video\ninputs, enabling scalable, high-quality video understanding even on limited\nhardware. Experiments show that QuickVideo generalizes across durations and\nsampling rates, making long video processing feasible in practice.",
    "pdf_url": "http://arxiv.org/pdf/2505.16175v2",
    "published": "2025-05-22T03:26:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16174v1",
    "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility",
    "authors": [
      "Ping Liu",
      "Chi Zhang"
    ],
    "abstract": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16174v1",
    "published": "2025-05-22T03:26:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16173v2",
    "title": "Exact Expansion Formalism for Transport Properties of Heterogeneous Materials Characterized by Arbitrary Continuous Random Fields",
    "authors": [
      "Liyu Zhong",
      "Sheng Mao"
    ],
    "abstract": "We derive an exact contrast-expansion formalism for the effective\nconductivity of heterogeneous materials (media) with local properties described\nby arbitrary continuous random fields, significantly generalizing the widely\nused binary-field models. The theory produces a rapidly convergent\nNeumann-series that, upon Gaussian closure via a Hermite expansion, yields\nclosed-form first-, second- and third-order approximations, which achieve\npercent-level accuracy at first order for isotropic media. For anisotropic\nmedia, second-order approximations achieve sub-2% accuracy across a wide range\nof local property contrasts and correlations. Our formalism provides\nmathematically rigorous structure-property closures, with significant\nimplications for the discovery and design of novel graded and architected\nmaterials with tailored transport properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.16173v2",
    "published": "2025-05-22T03:25:45+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16172v1",
    "title": "Automated Feedback Loops to Protect Text Simplification with Generative AI from Information Loss",
    "authors": [
      "Abhay Kumara Sri Krishna Nandiraju",
      "Gondy Leroy",
      "David Kauchak",
      "Arif Ahmed"
    ],
    "abstract": "Understanding health information is essential in achieving and maintaining a\nhealthy life. We focus on simplifying health information for better\nunderstanding. With the availability of generative AI, the simplification\nprocess has become efficient and of reasonable quality, however, the algorithms\nremove information that may be crucial for comprehension. In this study, we\ncompare generative AI to detect missing information in simplified text,\nevaluate its importance, and fix the text with the missing information. We\ncollected 50 health information texts and simplified them using gpt-4-0613. We\ncompare five approaches to identify missing elements and regenerate the text by\ninserting the missing elements. These five approaches involve adding missing\nentities and missing words in various ways: 1) adding all the missing entities,\n2) adding all missing words, 3) adding the top-3 entities ranked by gpt-4-0613,\nand 4, 5) serving as controls for comparison, adding randomly chosen entities.\nWe use cosine similarity and ROUGE scores to evaluate the semantic similarity\nand content overlap between the original, simplified, and reconstructed\nsimplified text. We do this for both summaries and full text. Overall, we find\nthat adding missing entities improves the text. Adding all the missing entities\nresulted in better text regeneration, which was better than adding the\ntop-ranked entities or words, or random words. Current tools can identify these\nentities, but are not valuable in ranking them.",
    "pdf_url": "http://arxiv.org/pdf/2505.16172v1",
    "published": "2025-05-22T03:19:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16171v1",
    "title": "Fairness and Efficiency in Human-Agent Teams: An Iterative Algorithm Design Approach",
    "authors": [
      "Mai Lee Chang",
      "Kim Baraka",
      "Greg Trafton",
      "Zach Lalu Vazhekatt",
      "Andrea Lockerd Thomaz"
    ],
    "abstract": "When agents interact with people as part of a team, fairness becomes an\nimportant factor. Prior work has proposed fairness metrics based on teammates'\ncapabilities for task allocation within human-agent teams. However, most\nmetrics only consider teammate capabilities from a third-person point of view\n(POV). In this work, we extend these metrics to include task preferences and\nconsider a first-person POV. We leverage an iterative design method consisting\nof simulation data and human data to design a task allocation algorithm that\nbalances task efficiency and fairness based on both capabilities and\npreferences. We first show that these metrics may not align with people's\nperceived fairness from a first-person POV. In light of this result, we propose\na new fairness metric, fair-equity, and the Fair-Efficient Algorithm (FEA). Our\nfindings suggest that an agent teammate who balances efficiency and fairness\nbased on equity will be perceived to be fairer and preferred by human teammates\nin various human-agent team types. We suggest that the perception of fairness\nmay also depend on a person's POV.",
    "pdf_url": "http://arxiv.org/pdf/2505.16171v1",
    "published": "2025-05-22T03:18:47+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16170v2",
    "title": "When Do LLMs Admit Their Mistakes? Understanding the Role of Model Belief in Retraction",
    "authors": [
      "Yuqing Yang",
      "Robin Jia"
    ],
    "abstract": "Can large language models (LLMs) admit their mistakes when they should know\nbetter? In this work, we define the behavior of acknowledging errors in\npreviously generated answers as \"retraction\" and aim to understand when and why\nLLMs choose to retract. We first construct model-specific datasets to evaluate\nwhether a model will retract an incorrect answer that contradicts its own\nparametric knowledge. While LLMs are capable of retraction, they do so only\ninfrequently. We demonstrate that retraction is closely tied to previously\nidentified indicators of models' internal belief: models fail to retract wrong\nanswers that they \"believe\" to be factually correct. Steering experiments\nfurther demonstrate that internal belief causally influences model retraction.\nIn particular, when the model does not believe its answer, this not only\nencourages the model to attempt to verify the answer, but also alters attention\nbehavior during self-verification. Finally, we demonstrate that simple\nsupervised fine-tuning significantly improves retraction performance by helping\nthe model learn more accurate internal beliefs. Code and datasets are available\non https://github.com/ayyyq/llm-retraction.",
    "pdf_url": "http://arxiv.org/pdf/2505.16170v2",
    "published": "2025-05-22T03:16:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16169v1",
    "title": "Partitioning and Observability in Linear Systems via Submodular Optimization",
    "authors": [
      "Mohamad H. Kazma",
      "Ahmad F. Taha"
    ],
    "abstract": "Network partitioning has gained recent attention as a pathway to enable\ndecentralized operation and control in large-scale systems. This paper\naddresses the interplay between partitioning, observability, and sensor\nplacement (SP) in dynamic networks. The problem, being computationally\nintractable at scale, is largely unexplored in the literature. To that end, the\npaper's objective is designing scalable partitioning of linear systems while\nmaximizing observability metrics of the subsystems. We show that the\npartitioning problem can be posed as a submodular maximization problem -- and\nthe SP problem can subsequently be solved over the partitioned network.\nConsequently, theoretical bounds are derived to compare observability metrics\nof the original network with those of the resulting partitions, highlighting\nthe impact of partitioning on system observability. Case studies on networks of\nvarying sizes corroborate the derived theoretical bounds.",
    "pdf_url": "http://arxiv.org/pdf/2505.16169v1",
    "published": "2025-05-22T03:14:53+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16168v1",
    "title": "Selective Invocation for Multilingual ASR: A Cost-effective Approach Adapting to Speech Recognition Difficulty",
    "authors": [
      "Hongfei Xue",
      "Yufeng Tang",
      "Jun Zhang",
      "Xuelong Geng",
      "Lei Xie"
    ],
    "abstract": "Although multilingual automatic speech recognition (ASR) systems have\nsignificantly advanced, enabling a single model to handle multiple languages,\ninherent linguistic differences and data imbalances challenge SOTA performance\nacross all languages. While language identification (LID) models can route\nspeech to the appropriate ASR model, they incur high costs from invoking SOTA\ncommercial models and suffer from inaccuracies due to misclassification. To\novercome these, we propose SIMA, a selective invocation for multilingual ASR\nthat adapts to the difficulty level of the input speech. Built on a spoken\nlarge language model (SLLM), SIMA evaluates whether the input is simple enough\nfor direct transcription or requires the invocation of a SOTA ASR model. Our\napproach reduces word error rates by 18.7% compared to the SLLM and halves\ninvocation costs compared to LID-based methods. Tests on three datasets show\nthat SIMA is a scalable, cost-effective solution for multilingual ASR\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.16168v1",
    "published": "2025-05-22T03:13:40+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16167v1",
    "title": "Tactile-based Reinforcement Learning for Adaptive Grasping under Observation Uncertainties",
    "authors": [
      "Xiao Hu",
      "Yang Ye"
    ],
    "abstract": "Robotic manipulation in industrial scenarios such as construction commonly\nfaces uncertain observations in which the state of the manipulating object may\nnot be accurately captured due to occlusions and partial observables. For\nexample, object status estimation during pipe assembly, rebar installation, and\nelectrical installation can be impacted by observation errors. Traditional\nvision-based grasping methods often struggle to ensure robust stability and\nadaptability. To address this challenge, this paper proposes a tactile\nsimulator that enables a tactile-based adaptive grasping method to enhance\ngrasping robustness. This approach leverages tactile feedback combined with the\nProximal Policy Optimization (PPO) reinforcement learning algorithm to\ndynamically adjust the grasping posture, allowing adaptation to varying\ngrasping conditions under inaccurate object state estimations. Simulation\nresults demonstrate that the proposed method effectively adapts grasping\npostures, thereby improving the success rate and stability of grasping tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16167v1",
    "published": "2025-05-22T03:12:34+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16166v1",
    "title": "TRAIL: Transferable Robust Adversarial Images via Latent diffusion",
    "authors": [
      "Yuhao Xue",
      "Zhifei Zhang",
      "Xinyang Jiang",
      "Yifei Shen",
      "Junyao Gao",
      "Wentao Gu",
      "Jiale Zhao",
      "Miaojing Shi",
      "Cairong Zhao"
    ],
    "abstract": "Adversarial attacks exploiting unrestricted natural perturbations present\nsevere security risks to deep learning systems, yet their transferability\nacross models remains limited due to distribution mismatches between generated\nadversarial features and real-world data. While recent works utilize\npre-trained diffusion models as adversarial priors, they still encounter\nchallenges due to the distribution shift between the distribution of ideal\nadversarial samples and the natural image distribution learned by the diffusion\nmodel. To address the challenge, we propose Transferable Robust Adversarial\nImages via Latent Diffusion (TRAIL), a test-time adaptation framework that\nenables the model to generate images from a distribution of images with\nadversarial features and closely resembles the target images. To mitigate the\ndistribution shift, during attacks, TRAIL updates the diffusion U-Net's weights\nby combining adversarial objectives (to mislead victim models) and perceptual\nconstraints (to preserve image realism). The adapted model then generates\nadversarial samples through iterative noise injection and denoising guided by\nthese objectives. Experiments demonstrate that TRAIL significantly outperforms\nstate-of-the-art methods in cross-model attack transferability, validating that\ndistribution-aligned adversarial feature synthesis is critical for practical\nblack-box attacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16166v1",
    "published": "2025-05-22T03:11:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16165v1",
    "title": "RE-TRIP : Reflectivity Instance Augmented Triangle Descriptor for 3D Place Recognition",
    "authors": [
      "Yechan Park",
      "Gyuhyeon Pak",
      "Euntai Kim"
    ],
    "abstract": "While most people associate LiDAR primarily with its ability to measure\ndistances and provide geometric information about the environment (via point\nclouds), LiDAR also captures additional data, including reflectivity or\nintensity values. Unfortunately, when LiDAR is applied to Place Recognition\n(PR) in mobile robotics, most previous works on LiDAR-based PR rely only on\ngeometric measurements, neglecting the additional reflectivity information that\nLiDAR provides. In this paper, we propose a novel descriptor for 3D PR, named\nRE-TRIP (REflectivity-instance augmented TRIangle descriPtor). This new\ndescriptor leverages both geometric measurements and reflectivity to enhance\nrobustness in challenging scenarios such as geometric degeneracy, high\ngeometric similarity, and the presence of dynamic objects. To implement RE-TRIP\nin real-world applications, we further propose (1) a keypoint extraction\nmethod, (2) a key instance segmentation method, (3) a RE-TRIP matching method,\nand (4) a reflectivity-combined loop verification method. Finally, we conduct a\nseries of experiments to demonstrate the effectiveness of RE-TRIP. Applied to\npublic datasets (i.e., HELIPR, FusionPortable) containing diverse scenarios\nsuch as long corridors, bridges, large-scale urban areas, and highly dynamic\nenvironments -- our experimental results show that the proposed method\noutperforms existing state-of-the-art methods in terms of Scan Context,\nIntensity Scan Context, and STD.",
    "pdf_url": "http://arxiv.org/pdf/2505.16165v1",
    "published": "2025-05-22T03:11:30+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16164v1",
    "title": "Can LLMs Simulate Human Behavioral Variability? A Case Study in the Phonemic Fluency Task",
    "authors": [
      "Mengyang Qiu",
      "Zoe Brisebois",
      "Siena Sun"
    ],
    "abstract": "Large language models (LLMs) are increasingly explored as substitutes for\nhuman participants in cognitive tasks, but their ability to simulate human\nbehavioral variability remains unclear. This study examines whether LLMs can\napproximate individual differences in the phonemic fluency task, where\nparticipants generate words beginning with a target letter. We evaluated 34\nmodel configurations, varying prompt specificity, sampling temperature, and\nmodel type, and compared outputs to responses from 106 human participants.\nWhile some configurations, especially Claude 3.7 Sonnet, matched human averages\nand lexical preferences, none reproduced the scope of human variability. LLM\noutputs were consistently less diverse and structurally rigid, and LLM\nensembles failed to increase diversity. Network analyses further revealed\nfundamental differences in retrieval structure between humans and models. These\nresults highlight key limitations in using LLMs to simulate human cognition and\nbehavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.16164v1",
    "published": "2025-05-22T03:08:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16163v1",
    "title": "Improving adiabatic quantum factorization via chopped random-basis optimization",
    "authors": [
      "Tianlai Yang",
      "Mo Xiong",
      "Ming Xue",
      "Xinwei Li",
      "Jinbin Li"
    ],
    "abstract": "Integer factorization remains a significant challenge for classical computers\nand is fundamental to the security of RSA encryption. Adiabatic quantum\nalgorithms present a promising solution, yet their practical implementation is\nlimited by the short coherence times of current NISQ devices and quantum\nsimulators. In this work, we apply the chopped random-basis (CRAB) optimization\ntechnique to enhance adiabatic quantum factorization algorithms. We demonstrate\nthe effectiveness of CRAB by applying it to factor the integers ranging from 21\nto 2479, achieving significantly improved fidelity of the target state when the\nevolution time exceeds the quantum speed limit. Notably, this performance\nimprovement shows resilience in the presence of dephasing noise, highlighting\nCRAB's practical utility in noisy quantum systems. Our findings suggest that\nCRAB optimization can serve as a powerful tool for advancing adiabatic quantum\nalgorithms, with broader implications for quantum information processing tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16163v1",
    "published": "2025-05-22T03:06:02+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16162v1",
    "title": "KNN-SSD: Enabling Dynamic Self-Speculative Decoding via Nearest Neighbor Layer Set Optimization",
    "authors": [
      "Mingbo Song",
      "Heming Xia",
      "Jun Zhang",
      "Chak Tou Leong",
      "Qiancheng Xu",
      "Wenjie Li",
      "Sujian Li"
    ],
    "abstract": "Speculative Decoding (SD) has emerged as a widely used paradigm to accelerate\nthe inference of large language models (LLMs) without compromising generation\nquality. It works by efficiently drafting multiple tokens using a compact model\nand then verifying them in parallel using the target LLM. Notably,\nSelf-Speculative Decoding proposes skipping certain layers to construct the\ndraft model, which eliminates the need for additional parameters or training.\nDespite its strengths, we observe in this work that drafting with layer\nskipping exhibits significant sensitivity to domain shifts, leading to a\nsubstantial drop in acceleration performance. To enhance the domain\ngeneralizability of this paradigm, we introduce KNN-SSD, an algorithm that\nleverages K-Nearest Neighbor (KNN) search to match different skipped layers\nwith various domain inputs. We evaluated our algorithm in various models and\nmultiple tasks, observing that its application leads to 1.3x-1.6x speedup in\nLLM inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.16162v1",
    "published": "2025-05-22T03:04:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16161v1",
    "title": "Deep Learning-Driven Ultra-High-Definition Image Restoration: A Survey",
    "authors": [
      "Liyan Wang",
      "Weixiang Zhou",
      "Cong Wang",
      "Kin-Man Lam",
      "Zhixun Su",
      "Jinshan Pan"
    ],
    "abstract": "Ultra-high-definition (UHD) image restoration aims to specifically solve the\nproblem of quality degradation in ultra-high-resolution images. Recent\nadvancements in this field are predominantly driven by deep learning-based\ninnovations, including enhancements in dataset construction, network\narchitecture, sampling strategies, prior knowledge integration, and loss\nfunctions. In this paper, we systematically review recent progress in UHD image\nrestoration, covering various aspects ranging from dataset construction to\nalgorithm design. This serves as a valuable resource for understanding\nstate-of-the-art developments in the field. We begin by summarizing degradation\nmodels for various image restoration subproblems, such as super-resolution,\nlow-light enhancement, deblurring, dehazing, deraining, and desnowing, and\nemphasizing the unique challenges of their application to UHD image\nrestoration. We then highlight existing UHD benchmark datasets and organize the\nliterature according to degradation types and dataset construction methods.\nFollowing this, we showcase major milestones in deep learning-driven UHD image\nrestoration, reviewing the progression of restoration tasks, technological\ndevelopments, and evaluations of existing methods. We further propose a\nclassification framework based on network architectures and sampling\nstrategies, helping to clearly organize existing methods. Finally, we share\ninsights into the current research landscape and propose directions for further\nadvancements. A related repository is available at\nhttps://github.com/wlydlut/UHD-Image-Restoration-Survey.",
    "pdf_url": "http://arxiv.org/pdf/2505.16161v1",
    "published": "2025-05-22T03:03:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16160v3",
    "title": "EduBench: A Comprehensive Benchmarking Dataset for Evaluating Large Language Models in Diverse Educational Scenarios",
    "authors": [
      "Bin Xu",
      "Yu Bai",
      "Huashan Sun",
      "Yiguan Lin",
      "Siming Liu",
      "Xinyue Liang",
      "Yaolin Li",
      "Yang Gao",
      "Heyan Huang"
    ],
    "abstract": "As large language models continue to advance, their application in\neducational contexts remains underexplored and under-optimized. In this paper,\nwe address this gap by introducing the first diverse benchmark tailored for\neducational scenarios, incorporating synthetic data containing 9 major\nscenarios and over 4,000 distinct educational contexts. To enable comprehensive\nassessment, we propose a set of multi-dimensional evaluation metrics that cover\n12 critical aspects relevant to both teachers and students. We further apply\nhuman annotation to ensure the effectiveness of the model-generated evaluation\nresponses. Additionally, we succeed to train a relatively small-scale model on\nour constructed dataset and demonstrate that it can achieve performance\ncomparable to state-of-the-art large models (e.g., Deepseek V3, Qwen Max) on\nthe test set. Overall, this work provides a practical foundation for the\ndevelopment and evaluation of education-oriented language models. Code and data\nare released at https://github.com/ybai-nlp/EduBench.",
    "pdf_url": "http://arxiv.org/pdf/2505.16160v3",
    "published": "2025-05-22T03:01:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17132v2",
    "title": "Robustifying Vision-Language Models via Dynamic Token Reweighting",
    "authors": [
      "Tanqiu Jiang",
      "Jiacheng Liang",
      "Rongyi Zhu",
      "Jiawei Zhou",
      "Fenglong Ma",
      "Ting Wang"
    ],
    "abstract": "Large vision-language models (VLMs) are highly vulnerable to jailbreak\nattacks that exploit visual-textual interactions to bypass safety guardrails.\nIn this paper, we present DTR, a novel inference-time defense that mitigates\nmultimodal jailbreak attacks through optimizing the model's key-value (KV)\ncaches. Rather than relying on curated safety-specific data or costly\nimage-to-text conversion, we introduce a new formulation of the safety-relevant\ndistributional shift induced by the visual modality. This formulation enables\nDTR to dynamically adjust visual token weights, minimizing the impact of\nadversarial visual inputs while preserving the model's general capabilities and\ninference efficiency. Extensive evaluation across diverse VLMs and attack\nbenchmarks demonstrates that \\sys outperforms existing defenses in both attack\nrobustness and benign task performance, marking the first successful\napplication of KV cache optimization for safety enhancement in multimodal\nfoundation models. (warning: this paper contains potentially harmful content\ngenerated by VLMs.)",
    "pdf_url": "http://arxiv.org/pdf/2505.17132v2",
    "published": "2025-05-22T03:00:39+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16159v1",
    "title": "Why Can Accurate Models Be Learned from Inaccurate Annotations?",
    "authors": [
      "Chongjie Si",
      "Yidan Cui",
      "Fuchao Yang",
      "Xiaokang Yang",
      "Wei Shen"
    ],
    "abstract": "Learning from inaccurate annotations has gained significant attention due to\nthe high cost of precise labeling. However, despite the presence of erroneous\nlabels, models trained on noisy data often retain the ability to make accurate\npredictions. This intriguing phenomenon raises a fundamental yet largely\nunexplored question: why models can still extract correct label information\nfrom inaccurate annotations remains unexplored. In this paper, we conduct a\ncomprehensive investigation into this issue. By analyzing weight matrices from\nboth empirical and theoretical perspectives, we find that label inaccuracy\nprimarily accumulates noise in lower singular components and subtly perturbs\nthe principal subspace. Within a certain range, the principal subspaces of\nweights trained on inaccurate labels remain largely aligned with those learned\nfrom clean labels, preserving essential task-relevant information. We formally\nprove that the angles of principal subspaces exhibit minimal deviation under\nmoderate label inaccuracy, explaining why models can still generalize\neffectively. Building on these insights, we propose LIP, a lightweight plug-in\ndesigned to help classifiers retain principal subspace information while\nmitigating noise induced by label inaccuracy. Extensive experiments on tasks\nwith various inaccuracy conditions demonstrate that LIP consistently enhances\nthe performance of existing algorithms. We hope our findings can offer valuable\ntheoretical and practical insights to understand of model robustness under\ninaccurate supervision.",
    "pdf_url": "http://arxiv.org/pdf/2505.16159v1",
    "published": "2025-05-22T03:00:15+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16158v2",
    "title": "Confirming HSC strong lens candidates with DESI Spectroscopy. I. Project overview and first results",
    "authors": [
      "Yiping Shu",
      "Shen Li"
    ],
    "abstract": "Accurate redshift determinations of both lenses and sources are critical for\nconfirming strong-lens systems and fully realizing their scientific value.\nHowever, the thousands of strong-lens candidates now routinely discovered in\nwide-field imaging surveys make one-by-one follow-up observations impractical.\nIn this work, we investigate the capability and efficiency of large-scale\nspectroscopic surveys in confirming strong-lens systems. As a case study, we\ncross-match strong lens candidates identified from the Hyper Suprime-Cam Subaru\nStrategic Program with Data Release 1 (DR1) of the Dark Energy Spectroscopic\nInstrument (DESI). We find that DESI DR1 serendipitously observed putative\nlenses and/or lensed images in approximately 50\\% of these candidates.\nAnalyzing the DESI spectra for $\\approx 500$ matched candidates that meet our\nselection criteria, we determine both lens and source redshifts for 27 systems.\nAdditionally, 76 candidate systems feature lensing galaxies at $z > 0.8$, and\none candidate system contains a quasar within its lensing galaxy. Applying this\napproach to other strong-lens candidates will yield many more confirmations,\nwith a further several-fold increase anticipated from the final DESI data\nrelease. Our results highlight the growing importance of large-scale\nspectroscopic surveys in advancing strong lensing discoveries and science.",
    "pdf_url": "http://arxiv.org/pdf/2505.16158v2",
    "published": "2025-05-22T02:57:53+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16157v1",
    "title": "Breaking Complexity Barriers: High-Resolution Image Restoration with Rank Enhanced Linear Attention",
    "authors": [
      "Yuang Ai",
      "Huaibo Huang",
      "Tao Wu",
      "Qihang Fan",
      "Ran He"
    ],
    "abstract": "Transformer-based models have made remarkable progress in image restoration\n(IR) tasks. However, the quadratic complexity of self-attention in Transformer\nhinders its applicability to high-resolution images. Existing methods mitigate\nthis issue with sparse or window-based attention, yet inherently limit global\ncontext modeling. Linear attention, a variant of softmax attention,\ndemonstrates promise in global context modeling while maintaining linear\ncomplexity, offering a potential solution to the above challenge. Despite its\nefficiency benefits, vanilla linear attention suffers from a significant\nperformance drop in IR, largely due to the low-rank nature of its attention\nmap. To counter this, we propose Rank Enhanced Linear Attention (RELA), a\nsimple yet effective method that enriches feature representations by\nintegrating a lightweight depthwise convolution. Building upon RELA, we propose\nan efficient and effective image restoration Transformer, named LAformer.\nLAformer achieves effective global perception by integrating linear attention\nand channel attention, while also enhancing local fitting capabilities through\na convolutional gated feed-forward network. Notably, LAformer eliminates\nhardware-inefficient operations such as softmax and window shifting, enabling\nefficient processing of high-resolution images. Extensive experiments across 7\nIR tasks and 21 benchmarks demonstrate that LAformer outperforms SOTA methods\nand offers significant computational advantages.",
    "pdf_url": "http://arxiv.org/pdf/2505.16157v1",
    "published": "2025-05-22T02:57:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16156v2",
    "title": "Integral Imprecise Probability Metrics",
    "authors": [
      "Siu Lun Chau",
      "Michele Caprio",
      "Krikamol Muandet"
    ],
    "abstract": "Quantifying differences between probability distributions is fundamental to\nstatistics and machine learning, primarily for comparing statistical\nuncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete\nknowledge -- requires richer representations than those offered by classical\nprobability. Imprecise probability (IP) theory offers such models, capturing\nambiguity and partial belief. This has driven growing interest in imprecise\nprobabilistic machine learning (IPML), where inference and decision-making rely\non broader uncertainty models -- highlighting the need for metrics beyond\nclassical probability. This work introduces the Integral Imprecise Probability\nMetric (IIPM) framework, a Choquet integral-based generalisation of classical\nIntegral Probability Metric (IPM) to the setting of capacities -- a broad class\nof IP models encompassing many existing ones, including lower probabilities,\nprobability intervals, belief functions, and more. Theoretically, we establish\nconditions under which IIPM serves as a valid metric and metrises a form of\nweak convergence of capacities. Practically, IIPM not only enables comparison\nacross different IP models but also supports the quantification of epistemic\nuncertainty within a single IP model. In particular, by comparing an IP model\nwith its conjugate, IIPM gives rise to a new class of EU measures -- Maximum\nMean Imprecision -- which satisfy key axiomatic properties proposed in the\nUncertainty Quantification literature. We validate MMI through selective\nclassification experiments, demonstrating strong empirical performance against\nestablished EU measures, and outperforming them when classical methods struggle\nto scale to a large number of classes. Our work advances both theory and\npractice in IPML, offering a principled framework for comparing and quantifying\nepistemic uncertainty under imprecision.",
    "pdf_url": "http://arxiv.org/pdf/2505.16156v2",
    "published": "2025-05-22T02:56:57+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16155v2",
    "title": "Ore extensions of multiplier Hopf coquasigroups",
    "authors": [
      "Rui Zhang",
      "Na Zhang",
      "Yapeng Zeng",
      "Tao Yang"
    ],
    "abstract": "In this paper, Ore extensions of multiplier Hopf coquasigroups are studied.\nNecessary and sufficient conditions for the Ore extension of a regular\nmultiplier Hopf coquasigroup to be a multiplier Hopf coquasigroup are given.\nFurthermore, the isomorphism between two such Ore extensions is discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.16155v2",
    "published": "2025-05-22T02:53:56+00:00",
    "categories": [
      "math.RA",
      "16T05, 16T99"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16154v1",
    "title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World",
    "authors": [
      "Ji Guo",
      "Long Zhou",
      "Zhijin Wang",
      "Jiaming He",
      "Qiyang Song",
      "Aiguo Chen",
      "Wenbo Jiang"
    ],
    "abstract": "In recent years, deep learning-based Monocular Depth Estimation (MDE) models\nhave been widely applied in fields such as autonomous driving and robotics.\nHowever, their vulnerability to backdoor attacks remains unexplored. To fill\nthe gap in this area, we conduct a comprehensive investigation of backdoor\nattacks against MDE models. Typically, existing backdoor attack methods can not\nbe applied to MDE models. This is because the label used in MDE is in the form\nof a depth map. To address this, we propose BadDepth, the first backdoor attack\ntargeting MDE models. BadDepth overcomes this limitation by selectively\nmanipulating the target object's depth using an image segmentation model and\nrestoring the surrounding areas via depth completion, thereby generating\npoisoned datasets for object-level backdoor attacks. To improve robustness in\nphysical world scenarios, we further introduce digital-to-physical augmentation\nto adapt to the domain gap between the physical world and the digital domain.\nExtensive experiments on multiple models validate the effectiveness of BadDepth\nin both the digital domain and the physical world, without being affected by\nenvironmental factors.",
    "pdf_url": "http://arxiv.org/pdf/2505.16154v1",
    "published": "2025-05-22T02:53:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16153v2",
    "title": "Model-Independent Measurement of the Matter-Radiation Equality Scale in DESI 2024",
    "authors": [
      "B. Bahr-Kalus",
      "D. Parkinson",
      "K. Lodha",
      "E. Mueller",
      "E. Chaussidon",
      "A. de Mattia",
      "D. Forero-Sánchez",
      "J. Aguilar",
      "S. Ahlen",
      "D. Bianchi",
      "D. Brooks",
      "T. Claybaugh",
      "A. Cuceu",
      "A. de la Macorra",
      "P. Doel",
      "A. Font-Ribera",
      "E. Gaztañaga",
      "S. Gontcho",
      "A Gontcho",
      "G. Gutierrez",
      "K. Honscheid",
      "D. Huterer",
      "M. Ishak",
      "R. Kehoe",
      "S. Kent",
      "D. Kirkby",
      "T. Kisner",
      "A. Kremin",
      "O. Lahav",
      "M. Landriau",
      "L. Le Guillou",
      "C. Magneville",
      "M. Manera",
      "P. Martini",
      "A. Meisner",
      "R. Miquel",
      "J. Moustakas",
      "S. Nadathur",
      "N. Palanque-Delabrouille",
      "W. J. Percival",
      "F. Prada",
      "I. Pérez-Ràfols",
      "A. J. Ross",
      "G. Rossi",
      "L. Samushia",
      "E. Sanchez",
      "D. Schlegel",
      "M. Schubnell",
      "H. Seo",
      "J. Silber",
      "D. Sprayberry",
      "G. Tarlé",
      "B. A. Weaver",
      "R. Zhou",
      "H. Zou"
    ],
    "abstract": "The peak of the matter power spectrum, known as the turnover (TO) scale, is\ndetermined by the horizon size at the time of matter-radiation equality. This\nscale can serve as a standard ruler, independent of other features in the\nmatter power spectrum, such as baryon acoustic oscillations (BAO). Here, we\npresent the first detection of the turnover in the galaxy auto-power spectrum,\nutilising the distribution of quasars (QSO) and luminous red galaxies (LRG)\nmeasured by the Dark Energy Spectroscopic Instrument (DESI) during its first\nyear of survey operations in a model-independent manner. To avoid confirmation\nbias, we first analyse the data using data blinding methods designed for the\nDESI baryon acoustic oscillation, redshift space distortion and scale-dependent\nbias signals. We measure the angle-averaged dilation distance $D_V(z = 1.651) =\n(38.1\\pm 2.5)r_H$ from the quasars and $D_{V}(z = 0.733) = (21.8\\pm 1.0)r_H$\nfrom the LRG sample in units of the horizon $r_H$ at the\nmatter-radiation-equality epoch. Combining these two constraints and assuming a\nflat $\\Lambda$CDM model with three standard neutrino species, we can translate\nthis into a constraint of $\\Omega_{m}h^2 = 0.139^{+0.036}_{-0.046}$. We can\nbreak the $\\Omega_m$-$H_0$ degeneracy with low-redshift distance measurements\nfrom type-Ia supernova (SN) data from Pantheon+, we obtain a sound-horizon free\nestimate of the Hubble-Lema\\^itre parameter of $H_0=65.2^{+4.9}_{-6.2}$\nkm/s/Mpc, consistent with sound-horizon dependent DESI measurements. On the\nother hand, combining the DESI BAO and TO, we find a truly DESI-only\nmeasurement of $H_0=74.0^{+7.2}_{-3.5}$ km/s/Mpc, in line with DESI-only\nfull-shape results where the sound-horizon scale is marginalised out. This\ndiscrepancy in $H_0$ can be reconciled in a $w_0w_a$CDM cosmology, where the\ncombination of DESI BAO and TO data yields $H_0 = 66.5\\pm\n7.2\\;\\mathrm{km/s/Mpc}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16153v2",
    "published": "2025-05-22T02:52:20+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16152v1",
    "title": "Compressing Human Body Video with Interactive Semantics: A Generative Approach",
    "authors": [
      "Bolin Chen",
      "Shanzhi Yin",
      "Hanwei Zhu",
      "Lingyu Zhu",
      "Zihan Zhang",
      "Jie Chen",
      "Ru-Ling Liao",
      "Shiqi Wang",
      "Yan Ye"
    ],
    "abstract": "In this paper, we propose to compress human body video with interactive\nsemantics, which can facilitate video coding to be interactive and controllable\nby manipulating semantic-level representations embedded in the coded bitstream.\nIn particular, the proposed encoder employs a 3D human model to disentangle\nnonlinear dynamics and complex motion of human body signal into a series of\nconfigurable embeddings, which are controllably edited, compactly compressed,\nand efficiently transmitted. Moreover, the proposed decoder can evolve the\nmesh-based motion fields from these decoded semantics to realize the\nhigh-quality human body video reconstruction. Experimental results illustrate\nthat the proposed framework can achieve promising compression performance for\nhuman body videos at ultra-low bitrate ranges compared with the\nstate-of-the-art video coding standard Versatile Video Coding (VVC) and the\nlatest generative compression schemes. Furthermore, the proposed framework\nenables interactive human body video coding without any additional\npre-/post-manipulation processes, which is expected to shed light on\nmetaverse-related digital human communication in the future.",
    "pdf_url": "http://arxiv.org/pdf/2505.16152v1",
    "published": "2025-05-22T02:51:58+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16151v1",
    "title": "Training-Free Reasoning and Reflection in MLLMs",
    "authors": [
      "Hongchen Wei",
      "Zhenzhong Chen"
    ],
    "abstract": "Recent advances in Reasoning LLMs (e.g., DeepSeek-R1 and OpenAI-o1) have\nshowcased impressive reasoning capabilities via reinforcement learning.\nHowever, extending these capabilities to Multimodal LLMs (MLLMs) is hampered by\nthe prohibitive costs of retraining and the scarcity of high-quality,\nverifiable multimodal reasoning datasets. This paper introduces FRANK Model, a\ntraining-FRee ANd r1-liKe MLLM that imbues off-the-shelf MLLMs with reasoning\nand reflection abilities, without any gradient updates or extra supervision.\nOur key insight is to decouple perception and reasoning across MLLM decoder\nlayers. Specifically, we observe that compared to the deeper decoder layers,\nthe shallow decoder layers allocate more attention to visual tokens, while the\ndeeper decoder layers concentrate on textual semantics. This observation\nmotivates a hierarchical weight merging approach that combines a\nvisual-pretrained MLLM with a reasoning-specialized LLM. To this end, we\npropose a layer-wise, Taylor-derived closed-form fusion mechanism that\nintegrates reasoning capacity into deep decoder layers while preserving visual\ngrounding in shallow decoder layers. Extensive experiments on challenging\nmultimodal reasoning benchmarks demonstrate the effectiveness of our approach.\nOn the MMMU benchmark, our model FRANK-38B achieves an accuracy of 69.2,\noutperforming the strongest baseline InternVL2.5-38B by +5.3, and even\nsurpasses the proprietary GPT-4o model. Our project homepage is at:\nhttp://iip.whu.edu.cn/frank/index.html",
    "pdf_url": "http://arxiv.org/pdf/2505.16151v1",
    "published": "2025-05-22T02:51:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16150v1",
    "title": "Quantum $K$-theoretic divisor axiom for flag manifolds",
    "authors": [
      "Cristian Lenart",
      "Satoshi Naito",
      "Daisuke Sagaki",
      "Leonardo C. Mihalcea",
      "Weihong Xu"
    ],
    "abstract": "We prove an identity for (torus-equivariant) 3-point, genus 0, $K$-theoretic\nGromov-Witten invariants of full or partial flag manifolds, which can be\nthought of as a replacement for the ``divisor axiom'' for the\n(torus-equivariant) quantum $K$-theory of flag manifolds. This identity enables\nus to compute the (torus-equivariant) 3-point, genus 0, $K$-theoretic\nGromov-Witten invariants defined by two Schubert classes and a divisor Schubert\nclass in the (torus-equivariant) ordinary $K$-theory ring of flag manifolds. We\nprove this identity by making use of the Chevalley formula for the\n(torus-equivariant) quantum $K$-theory ring of flag manifolds, which is\ndescribed in terms of the quantum Bruhat graph.",
    "pdf_url": "http://arxiv.org/pdf/2505.16150v1",
    "published": "2025-05-22T02:49:41+00:00",
    "categories": [
      "math.QA",
      "math.AG",
      "math.CO",
      "math.KT",
      "math.RT",
      "Primary 14N35, Secondary 14M15, 14N15, 14N10, 05E14"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16149v1",
    "title": "When VLMs Meet Image Classification: Test Sets Renovation via Missing Label Identification",
    "authors": [
      "Zirui Pang",
      "Haosheng Tan",
      "Yuhan Pu",
      "Zhijie Deng",
      "Zhouan Shen",
      "Keyu Hu",
      "Jiaheng Wei"
    ],
    "abstract": "Image classification benchmark datasets such as CIFAR, MNIST, and ImageNet\nserve as critical tools for model evaluation. However, despite the cleaning\nefforts, these datasets still suffer from pervasive noisy labels and often\ncontain missing labels due to the co-existing image pattern where multiple\nclasses appear in an image sample. This results in misleading model comparisons\nand unfair evaluations. Existing label cleaning methods focus primarily on\nnoisy labels, but the issue of missing labels remains largely overlooked.\nMotivated by these challenges, we present a comprehensive framework named\nREVEAL, integrating state-of-the-art pre-trained vision-language models (e.g.,\nLLaVA, BLIP, Janus, Qwen) with advanced machine/human label curation methods\n(e.g., Docta, Cleanlab, MTurk), to systematically address both noisy labels and\nmissing label detection in widely-used image classification test sets. REVEAL\ndetects potential noisy labels and omissions, aggregates predictions from\nvarious methods, and refines label accuracy through confidence-informed\npredictions and consensus-based filtering. Additionally, we provide a thorough\nanalysis of state-of-the-art vision-language models and pre-trained image\nclassifiers, highlighting their strengths and limitations within the context of\ndataset renovation by revealing 10 observations. Our method effectively reveals\nmissing labels from public datasets and provides soft-labeled results with\nlikelihoods. Through human verifications, REVEAL significantly improves the\nquality of 6 benchmark test sets, highly aligning to human judgments and\nenabling more accurate and meaningful comparisons in image classification.",
    "pdf_url": "http://arxiv.org/pdf/2505.16149v1",
    "published": "2025-05-22T02:47:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16148v1",
    "title": "NAN: A Training-Free Solution to Coefficient Estimation in Model Merging",
    "authors": [
      "Chongjie Si",
      "Kangtao Lv",
      "Jingjing Jiang",
      "Yadao Wang",
      "Yongwei Wang",
      "Xiaokang Yang",
      "Wenbo Su",
      "Bo Zheng",
      "Wei Shen"
    ],
    "abstract": "Model merging offers a training-free alternative to multi-task learning by\ncombining independently fine-tuned models into a unified one without access to\nraw data. However, existing approaches often rely on heuristics to determine\nthe merging coefficients, limiting their scalability and generality. In this\nwork, we revisit model merging through the lens of least-squares optimization\nand show that the optimal merging weights should scale with the amount of\ntask-specific information encoded in each model. Based on this insight, we\npropose NAN, a simple yet effective method that estimates model merging\ncoefficients via the inverse of parameter norm. NAN is training-free,\nplug-and-play, and applicable to a wide range of merging strategies. Extensive\nexperiments on show that NAN consistently improves performance of baseline\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.16148v1",
    "published": "2025-05-22T02:46:08+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16147v1",
    "title": "Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value",
    "authors": [
      "Le Ma",
      "Shirao Yang",
      "Zihao Wang",
      "Yinggui Wang",
      "Lei Wang",
      "Tao Wei",
      "Kejun Zhang"
    ],
    "abstract": "The proliferation of large models has intensified the need for efficient data\nvaluation methods to quantify the contribution of individual data providers.\nTraditional approaches, such as game-theory-based Shapley value and\ninfluence-function-based techniques, face prohibitive computational costs or\nrequire access to full data and model training details, making them hardly\nachieve partial data valuation. To address this, we propose Unlearning Shapley,\na novel framework that leverages machine unlearning to estimate data values\nefficiently. By unlearning target data from a pretrained model and measuring\nperformance shifts on a reachable test set, our method computes Shapley values\nvia Monte Carlo sampling, avoiding retraining and eliminating dependence on\nfull data. Crucially, Unlearning Shapley supports both full and partial data\nvaluation, making it scalable for large models (e.g., LLMs) and practical for\ndata markets. Experiments on benchmark datasets and large-scale text corpora\ndemonstrate that our approach matches the accuracy of state-of-the-art methods\nwhile reducing computational overhead by orders of magnitude. Further analysis\nconfirms a strong correlation between estimated values and the true impact of\ndata subsets, validating its reliability in real-world scenarios. This work\nbridges the gap between data valuation theory and practical deployment,\noffering a scalable, privacy-compliant solution for modern AI ecosystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16147v1",
    "published": "2025-05-22T02:46:03+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16146v1",
    "title": "Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation",
    "authors": [
      "Zhenglin Hua",
      "Jinghan He",
      "Zijun Yao",
      "Tianxu Han",
      "Haiyun Guo",
      "Yuheng Jia",
      "Junfeng Fang"
    ],
    "abstract": "Large vision-language models (LVLMs) have achieved remarkable performance on\nmultimodal tasks such as visual question answering (VQA) and image captioning.\nHowever, they still suffer from hallucinations, generating text inconsistent\nwith visual input, posing significant risks in real-world applications.\nExisting approaches to address this issue focus on incorporating external\nknowledge bases, alignment training, or decoding strategies, all of which\nrequire substantial computational cost and time. Recent works try to explore\nmore efficient alternatives by adjusting LVLMs' internal representations.\nAlthough promising, these methods may cause hallucinations to be insufficiently\nsuppressed or lead to excessive interventions that negatively affect normal\nsemantics. In this work, we leverage sparse autoencoders (SAEs) to identify\nsemantic directions closely associated with either hallucinations or actuality,\nrealizing more precise and direct hallucination-related representations. Our\nanalysis demonstrates that interventions along the faithful direction we\nidentified can mitigate hallucinations, while those along the hallucinatory\ndirection can exacerbate them. Building on these insights, we propose Steering\nLVLMs via SAE Latent Directions (SSL), a training-free method based on\nSAE-derived latent directions to mitigate hallucinations in LVLMs. Extensive\nexperiments demonstrate that SSL significantly outperforms existing decoding\napproaches in mitigating hallucinations, while maintaining transferability\nacross different model architectures with negligible additional time overhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.16146v1",
    "published": "2025-05-22T02:45:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.12027v1",
    "title": "Constant Bit-size Transformers Are Turing Complete",
    "authors": [
      "Qian Li",
      "Yuyi Wang"
    ],
    "abstract": "We prove that any Turing machine running on inputs of arbitrary length can be\nsimulated by a constant bit-size transformer, as long as the context window is\nsufficiently long. This improves previous works, which require scaling up\neither the model's precision or the number of parameters on longer inputs.\nFurthermore, we prove that the complexity class SPACE$[s(n)]$ exactly\ncharacterizes the expressive power of a constant bit-size transformer with a\ncontext window of length $s(n)$. Our approach relies on simulating Post\nmachines, a Turing-complete computational model. Post machines can be modeled\nas automata equipped with a queue, exhibiting computational behaviors naturally\naligned with those of transformers. The behavioral similarity between\ntransformers and Post machines may offer new insights into the mechanisms\nunderlying the reasoning abilities of transformers.",
    "pdf_url": "http://arxiv.org/pdf/2506.12027v1",
    "published": "2025-05-22T02:45:38+00:00",
    "categories": [
      "cs.CC",
      "cs.LG"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16145v1",
    "title": "Exponential Convergence of CAVI for Bayesian PCA",
    "authors": [
      "Arghya Datta",
      "Philippe Gagnon",
      "Florian Maire"
    ],
    "abstract": "Probabilistic principal component analysis (PCA) and its Bayesian variant\n(BPCA) are widely used for dimension reduction in machine learning and\nstatistics. The main advantage of probabilistic PCA over the traditional\nformulation is allowing uncertainty quantification. The parameters of BPCA are\ntypically learned using mean-field variational inference, and in particular,\nthe coordinate ascent variational inference (CAVI) algorithm. So far, the\nconvergence speed of CAVI for BPCA has not been characterized. In our paper, we\nfill this gap in the literature. Firstly, we prove a precise exponential\nconvergence result in the case where the model uses a single principal\ncomponent (PC). Interestingly, this result is established through a connection\nwith the classical $\\textit{power iteration algorithm}$ and it indicates that\ntraditional PCA is retrieved as points estimates of the BPCA parameters.\nSecondly, we leverage recent tools to prove exponential convergence of CAVI for\nthe model with any number of PCs, thus leading to a more general result, but\none that is of a slightly different flavor. To prove the latter result, we\nadditionally needed to introduce a novel lower bound for the symmetric\nKullback--Leibler divergence between two multivariate normal distributions,\nwhich, we believe, is of independent interest in information theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.16145v1",
    "published": "2025-05-22T02:44:00+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16144v1",
    "title": "GMatch: Geometry-Constrained Feature Matching for RGB-D Object Pose Estimation",
    "authors": [
      "Ming Yang",
      "Haoran Li"
    ],
    "abstract": "We present GMatch, a learning-free feature matcher designed for robust 6DoF\nobject pose estimation, addressing common local ambiguities in sparse feature\nmatching. Unlike traditional methods that rely solely on descriptor similarity,\nGMatch performs a guided, incremental search, enforcing SE(3)-invariant\ngeometric consistency throughout the matching process. It leverages a provably\ncomplete set of geometric features that uniquely determine 3D keypoint\nconfigurations, ensuring globally consistent correspondences without the need\nfor training or GPU support. When combined with classical descriptors such as\nSIFT, GMatch-SIFT forms a general-purpose pose estimation pipeline that offers\nstrong interpretability and generalization across diverse objects and scenes.\nExperiments on the HOPE dataset show that GMatch outperforms both traditional\nand learning-based matchers, with GMatch-SIFT achieving or surpassing the\nperformance of instance-level pose networks. On the YCB-Video dataset,\nGMatch-SIFT demonstrates high accuracy and low variance on texture-rich\nobjects. These results not only validate the effectiveness of GMatch-SIFT for\nobject pose estimation but also highlight the broader applicability of GMatch\nas a general-purpose feature matcher. Code will be released upon acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2505.16144v1",
    "published": "2025-05-22T02:39:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16143v1",
    "title": "Graded Injective Domains",
    "authors": [
      "Mike Hensler",
      "Hannah Klawa"
    ],
    "abstract": "An integral domain $R$ is an $i$-domain if for every overring $S$ of $R$,\n$\\text{Spec}(S) \\rightarrow \\text{Spec}(R)$ is injective and is a mated\nintegral if for every overring $S$ of $R$ and prime ideal $P$ of $R$ such that\n$PS \\neq S$, there exists exactly one prime ideal $Q$ of $S$ such that $Q \\cap\nR = P$. In this paper, we explore graded notions of $i$-domains and mated\ndomains and their connection with gr-Pr\\\"{u}fer domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.16143v1",
    "published": "2025-05-22T02:37:49+00:00",
    "categories": [
      "math.AC",
      "13G05 (Primary) 13A02, 13A15, 13B30, 13F05 (Secondary)"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16142v3",
    "title": "Distilling the Implicit Multi-Branch Structure in LLMs' Reasoning via Reinforcement Learning",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Yunchang Zhu",
      "Jia Gu",
      "Zihao Wei",
      "Jingcheng Deng",
      "Feiyang Pan",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "Distilling reasoning paths from teacher to student models via supervised\nfine-tuning (SFT) provides a shortcut for improving the reasoning ability of\nsmaller Large Language Models (LLMs). However, the reasoning paths generated by\nteacher models often reflect only surface-level traces of their underlying\nauthentic reasoning. Insights from cognitive neuroscience suggest that\nauthentic reasoning involves a complex interweaving between meta-reasoning\n(which selects appropriate sub-problems from multiple candidates) and solving\n(which addresses the sub-problem). This implies authentic reasoning has an\nimplicit multi-branch structure. Supervised fine-tuning collapses this rich\nstructure into a flat sequence of token prediction in the teacher's reasoning\npath, preventing effective distillation of this structure to students. To\naddress this limitation, we propose RLKD, a reinforcement learning (RL)-based\ndistillation framework guided by a novel Generative Structure Reward Model\n(GSRM). Our GSRM converts reasoning paths into multiple meta-reasoning-solving\nsteps and computes rewards to measure structural alignment between student and\nteacher reasoning. RLKD combines this reward with RL, enabling student LLMs to\ninternalize the teacher's implicit multi-branch reasoning structure rather than\nmerely mimicking fixed output paths. Experiments show RLKD surpasses standard\nSFT-RL pipelines even when trained on 0.1% of data under an RL-only regime,\nunlocking greater student reasoning potential than SFT-based distillation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16142v3",
    "published": "2025-05-22T02:36:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16141v1",
    "title": "Persuasive Prediction via Decision Calibration",
    "authors": [
      "Jingwu Tang",
      "Jiahao Zhang",
      "Fei Fang",
      "Zhiwei Steven Wu"
    ],
    "abstract": "Bayesian persuasion, a central model in information design, studies how a\nsender, who privately observes a state drawn from a prior distribution,\nstrategically sends a signal to influence a receiver's action. A key assumption\nis that both sender and receiver share the precise knowledge of the prior.\nAlthough this prior can be estimated from past data, such assumptions break\ndown in high-dimensional or infinite state spaces, where learning an accurate\nprior may require a prohibitive amount of data. In this paper, we study a\nlearning-based variant of persuasion, which we term persuasive prediction. This\nsetting mirrors Bayesian persuasion with large state spaces, but crucially does\nnot assume a common prior: the sender observes covariates $X$, learns to\npredict a payoff-relevant outcome $Y$ from past data, and releases a prediction\nto influence a population of receivers.\n  To model rational receiver behavior without a common prior, we adopt a\nlearnable proxy: decision calibration, which requires the prediction to be\nunbiased conditioned on the receiver's best response to the prediction. This\ncondition guarantees that myopically responding to the prediction yields no\nswap regret. Assuming the receivers best respond to decision-calibrated\npredictors, we design a computationally and statistically efficient algorithm\nthat learns a decision-calibrated predictor within a randomized predictor class\nthat optimizes the sender's utility. In the commonly studied single-receiver\ncase, our method matches the utility of a Bayesian sender who has full\nknowledge of the underlying prior distribution. Finally, we extend our\nalgorithmic result to a setting where receivers respond stochastically to\npredictions and the sender may randomize over an infinite predictor class.",
    "pdf_url": "http://arxiv.org/pdf/2505.16141v1",
    "published": "2025-05-22T02:35:38+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16140v1",
    "title": "Geometric Frustration in Twist-Bend Nematic Droplets",
    "authors": [
      "Joseph Pollard",
      "Richard G. Morris"
    ],
    "abstract": "Liquid crystals formed of bent-core molecules are exotic materials that\nexhibit the twist-bend nematic phase. This arises when an energetic preference\nfor nonzero local bend distortion is accommodated via twist in the texture,\nresulting in properties synonymous with both smectics and cholesterics. Here we\ndescribe how the frustration inherent to the twist-bend phase can be\nexacerbated by confinement and boundary anchoring. Using a combination of\nnumerical simulations, topological and geometric analysis, we catalogue the\nequilibrium textures that arise in spherical twist-bend droplets with a radial\nanchoring as the two key parameters -- the molecular cone angle and the ratio\nbetween the pitch length and droplet radius -- are varied. This form of\nconfinement is known to produce a wide variety of topologically and\ngeometrically complex metastable states in cholesterics. We find that\ntwist-bend nematic droplets are no different, exhibiting a variety of complex\nlayered states, defect constellations, and Hopfions. However, whilst many of\nthe structures and defect configurations that we observe are equivalent to\ntheir cholesteric counterparts, they are geometrically very distinct, in part\ndue to the absence of chirality.",
    "pdf_url": "http://arxiv.org/pdf/2505.16140v1",
    "published": "2025-05-22T02:35:12+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.16139v1",
    "title": "On the Runtime of Local Mutual Exclusion for Anonymous Dynamic Networks",
    "authors": [
      "Anya Chaturvedi",
      "Joshua J. Daymude",
      "Andréa W. Richa"
    ],
    "abstract": "Algorithms for mutual exclusion aim to isolate potentially concurrent\naccesses to the same shared resources. Motivated by distributed computing\nresearch on programmable matter and population protocols where interactions\namong entities are often assumed to be isolated, Daymude, Richa, and Scheideler\n(SAND`22) introduced a variant of the local mutual exclusion problem that\napplies to arbitrary dynamic networks: each node, on issuing a lock request,\nmust acquire exclusive locks on itself and all its persistent neighbors, i.e.,\nthe neighbors that remain connected to it over the duration of the lock\nrequest. Assuming adversarial edge dynamics, semi-synchronous or asynchronous\nconcurrency, and anonymous nodes communicating via message passing, their\nrandomized algorithm achieves mutual exclusion (non-intersecting lock sets) and\nlockout freedom (eventual success with probability 1). However, they did not\nanalyze their algorithm's runtime. In this paper, we prove that any node will\nsuccessfully lock itself and its persistent neighbors within O$(n\\Delta^3)$\nopen rounds of its lock request in expectation, where $n$ is the number of\nnodes in the dynamic network, $\\Delta$ is the maximum degree of the dynamic\nnetwork, rounds are normalized to the execution time of the ``slowest'' node,\nand ``closed'' rounds when some persistent neighbors are already locked by\nanother node are ignored (i.e., only ``open\" rounds are considered).",
    "pdf_url": "http://arxiv.org/pdf/2505.16139v1",
    "published": "2025-05-22T02:32:32+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16138v1",
    "title": "Multimodal Online Federated Learning with Modality Missing in Internet of Things",
    "authors": [
      "Heqiang Wang",
      "Xiang Liu",
      "Xiaoxiong Zhong",
      "Lixing Chen",
      "Fangming Liu",
      "Weizhe Zhang"
    ],
    "abstract": "The Internet of Things (IoT) ecosystem generates vast amounts of multimodal\ndata from heterogeneous sources such as sensors, cameras, and microphones. As\nedge intelligence continues to evolve, IoT devices have progressed from simple\ndata collection units to nodes capable of executing complex computational\ntasks. This evolution necessitates the adoption of distributed learning\nstrategies to effectively handle multimodal data in an IoT environment.\nFurthermore, the real-time nature of data collection and limited local storage\non edge devices in IoT call for an online learning paradigm. To address these\nchallenges, we introduce the concept of Multimodal Online Federated Learning\n(MMO-FL), a novel framework designed for dynamic and decentralized multimodal\nlearning in IoT environments. Building on this framework, we further account\nfor the inherent instability of edge devices, which frequently results in\nmissing modalities during the learning process. We conduct a comprehensive\ntheoretical analysis under both complete and missing modality scenarios,\nproviding insights into the performance degradation caused by missing\nmodalities. To mitigate the impact of modality missing, we propose the\nPrototypical Modality Mitigation (PMM) algorithm, which leverages prototype\nlearning to effectively compensate for missing modalities. Experimental results\non two multimodal datasets further demonstrate the superior performance of PMM\ncompared to benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16138v1",
    "published": "2025-05-22T02:31:37+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16137v1",
    "title": "Outsourcing SAT-based Verification Computations in Network Security",
    "authors": [
      "Qi Duan",
      "Ehab Al-Shaer"
    ],
    "abstract": "The emergence of cloud computing gives huge impact on large computations.\nCloud computing platforms offer servers with large computation power to be\navailable for customers. These servers can be used efficiently to solve\nproblems that are complex by nature, for example, satisfiability (SAT)\nproblems. Many practical problems can be converted to SAT, for example, circuit\nverification and network configuration analysis. However, outsourcing SAT\ninstances to the servers may cause data leakage that can jeopardize system's\nsecurity. Before\n  outsourcing the SAT instance, one needs to hide the input information. One\nway to preserve privacy and hide information is to randomize the SAT\n  instance before outsourcing. In this paper, we present multiple novel methods\nto randomize SAT instances. We present a novel method to randomize the SAT\ninstance, a variable randomization method to randomize the solution set, and\nmethods to randomize Mincost SAT and MAX3SAT instances. Our analysis and\nevaluation show the correctness and feasibility of these randomization methods.\nThe scalability and generality of our methods make it applicable for real world\nproblems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16137v1",
    "published": "2025-05-22T02:26:50+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16136v1",
    "title": "Interpretable Machine Learning for Macro Alpha: A News Sentiment Case Study",
    "authors": [
      "Yuke Zhang"
    ],
    "abstract": "This study introduces an interpretable machine learning (ML) framework to\nextract macroeconomic alpha from global news sentiment. We process the Global\nDatabase of Events, Language, and Tone (GDELT) Project's worldwide news feed\nusing FinBERT -- a Bidirectional Encoder Representations from Transformers\n(BERT) based model pretrained on finance-specific language -- to construct\ndaily sentiment indices incorporating mean tone, dispersion, and event impact.\nThese indices drive an XGBoost classifier, benchmarked against logistic\nregression, to predict next-day returns for EUR/USD, USD/JPY, and 10-year U.S.\nTreasury futures (ZN). Rigorous out-of-sample (OOS) backtesting (5-fold\nexpanding-window cross-validation, OOS period: c. 2017-April 2025) demonstrates\nexceptional, cost-adjusted performance for the XGBoost strategy: Sharpe ratios\nachieve 5.87 (EUR/USD), 4.65 (USD/JPY), and 4.65 (Treasuries), with respective\ncompound annual growth rates (CAGRs) exceeding 50% in Foreign Exchange (FX) and\n22% in bonds. Shapley Additive Explanations (SHAP) affirm that sentiment\ndispersion and article impact are key predictive features. Our findings\nestablish that integrating domain-specific Natural Language Processing (NLP)\nwith interpretable ML offers a potent and explainable source of macro alpha.",
    "pdf_url": "http://arxiv.org/pdf/2505.16136v1",
    "published": "2025-05-22T02:24:45+00:00",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG",
      "q-fin.TR"
    ],
    "primary_category": "q-fin.CP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16135v1",
    "title": "Sudoku-Bench: Evaluating creative reasoning with Sudoku variants",
    "authors": [
      "Jeffrey Seely",
      "Yuki Imajuku",
      "Tianyu Zhao",
      "Edoardo Cetin",
      "Llion Jones"
    ],
    "abstract": "Existing reasoning benchmarks for large language models (LLMs) frequently\nfail to capture authentic creativity, often rewarding memorization of\npreviously observed patterns. We address this shortcoming with Sudoku-Bench, a\ncurated benchmark of challenging and unconventional Sudoku variants\nspecifically selected to evaluate creative, multi-step logical reasoning.\nSudoku variants form an unusually effective domain for reasoning research: each\npuzzle introduces unique or subtly interacting constraints, making memorization\ninfeasible and requiring solvers to identify novel logical breakthroughs\n(``break-ins''). Despite their diversity, Sudoku variants maintain a common and\ncompact structure, enabling clear and consistent evaluation. Sudoku-Bench\nincludes a carefully chosen puzzle set, a standardized text-based puzzle\nrepresentation, and flexible tools compatible with thousands of publicly\navailable puzzles -- making it easy to extend into a general research\nenvironment. Baseline experiments show that state-of-the-art LLMs solve fewer\nthan 15\\% of puzzles unaided, highlighting significant opportunities to advance\nlong-horizon, strategic reasoning capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.16135v1",
    "published": "2025-05-22T02:24:35+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16134v1",
    "title": "Position of Uncertainty: A Cross-Linguistic Study of Positional Bias in Large Language Models",
    "authors": [
      "Menschikov Mikhail",
      "Alexander Kharitonov",
      "Maiia Kotyga",
      "Vadim Porvatov",
      "Anna Zhukovskaya",
      "David Kagramanyan",
      "Egor Shvetsov",
      "Evgeny Burnaev"
    ],
    "abstract": "Large language models exhibit positional bias -- systematic neglect of\ninformation at specific context positions -- yet its interplay with linguistic\ndiversity remains poorly understood. We present a cross-linguistic study across\nfive typologically distinct languages (English, Russian, German, Hindi,\nVietnamese), examining how positional bias interacts with model uncertainty,\nsyntax, and prompting. Key findings: (1) Positional bias is model-driven, with\nlanguage-specific variations -- Qwen2.5-7B favors late positions, challenging\nassumptions of early-token bias; (2) Explicit positional guidance (e.g.,\ncorrect context is at position X) reduces accuracy across languages,\nundermining prompt-engineering practices; (3) Aligning context with positional\nbias increases entropy, yet minimal entropy does not predict accuracy. (4) We\nfurther uncover that LLMs differently impose dominant word order in\nfree-word-order languages like Hindi.",
    "pdf_url": "http://arxiv.org/pdf/2505.16134v1",
    "published": "2025-05-22T02:23:00+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16133v4",
    "title": "HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation",
    "authors": [
      "Jinyu Guo",
      "Xunlei Chen",
      "Qiyang Xia",
      "Zhaokun Wang",
      "Jie Ou",
      "Libo Qin",
      "Shunyu Yao",
      "Wenhong Tian"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) encounters efficiency challenges when\nscaling to massive knowledge bases while preserving contextual relevance. We\npropose Hash-RAG, a framework that integrates deep hashing techniques with\nsystematic optimizations to address these limitations. Our queries directly\nlearn binary hash codes from knowledgebase code, eliminating intermediate\nfeature extraction steps, and significantly reducing storage and computational\noverhead. Building upon this hash-based efficient retrieval framework, we\nestablish the foundation for fine-grained chunking. Consequently, we design a\nPrompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved\nhash-indexed propositions and their original document segments through prompt\nengineering to enhance the LLM's contextual awareness. Experimental evaluations\non NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a\n90% reduction in retrieval time compared to conventional methods while\nmaintaining considerate recall performance. Additionally, The proposed system\noutperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.",
    "pdf_url": "http://arxiv.org/pdf/2505.16133v4",
    "published": "2025-05-22T02:22:11+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16132v1",
    "title": "Beamforming-Codebook-Aware Channel Knowledge Map Construction for Multi-Antenna Systems",
    "authors": [
      "Haohan Wang",
      "Xu Shi",
      "Hengyu Zhang",
      "Yashuai Cao",
      "Jintao Wang"
    ],
    "abstract": "Channel knowledge map (CKM) has emerged as a crucial technology for\nnext-generation communication, enabling the construction of high-fidelity\nmappings between spatial environments and channel parameters via\nelectromagnetic information analysis. Traditional CKM construction methods like\nray tracing are computationally intensive. Recent studies utilizing neural\nnetworks (NNs) have achieved efficient CKM generation with reduced\ncomputational complexity and real-time processing capabilities. Nevertheless,\nexisting research predominantly focuses on single-antenna systems, failing to\naddress the beamforming requirements inherent to MIMO configurations. Given\nthat appropriate precoding vector selection in MIMO systems can substantially\nenhance user communication rates, this paper presents a TransUNet-based\nframework for constructing CKM, which effectively incorporates discrete Fourier\ntransform (DFT) precoding vectors. The proposed architecture combines a UNet\nbackbone for multiscale feature extraction with a Transformer module to capture\nglobal dependencies among encoded linear vectors. Experimental results\ndemonstrate that the proposed method outperforms state-of-the-art (SOTA) deep\nlearning (DL) approaches, yielding a 17\\% improvement in RMSE compared to\nRadioWNet. The code is publicly accessible at\nhttps://github.com/github-whh/TransUNet.",
    "pdf_url": "http://arxiv.org/pdf/2505.16132v1",
    "published": "2025-05-22T02:18:24+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16131v2",
    "title": "Machine Learning the 6d Supergravity Landscape",
    "authors": [
      "Nathan Brady",
      "David Tennyson",
      "Thomas Vandermeulen"
    ],
    "abstract": "In this paper, we apply both supervised and unsupervised machine learning\nalgorithms to the study of the string landscape and swampland in 6-dimensions.\nOur data are the (almost) anomaly-free 6-dimensional $\\mathcal{N} = (1,0)$\nsupergravity models, characterised by the Gram matrix of anomaly coefficients.\nOur work demonstrates the ability of machine learning algorithms to efficiently\nlearn highly complex features of the landscape and swampland. Employing an\nautoencoder for unsupervised learning, we provide an auto-classification of\nthese models by compressing the Gram matrix data to 2-dimensions. Through\ncompression, similar models cluster together, and we identify prominent\nfeatures of these clusters. The autoencoder also identifies outlier models\nwhich are difficult to reconstruct. One of these outliers proves to be\nincredibly difficult to combine with other models such that the\n$\\text{tr}R^{4}$ anomaly vanishes, making its presence in the landscape\nextremely rare. Further, we utilise supervised learning to build two\nclassifiers predicting (1) model consistency under probe string insertion\n(precision: 0.78, predicting consistency for 214,837 models with reasonable\ncertainty) and (2) inconsistency under anomaly inflow (precision: 0.91,\npredicting inconsistency for 1,909,359 models). Notably, projecting these\npredictions onto the autoencoder's 2-dimensional latent layer shows consistent\nmodels clustering together, further indicating that the autoencoder has learnt\ninteresting and complex features of the set of models and potentially offers a\nnovel approach to mapping the landscape and swampland of 6-dimensional\nsupergravity theories.",
    "pdf_url": "http://arxiv.org/pdf/2505.16131v2",
    "published": "2025-05-22T02:16:55+00:00",
    "categories": [
      "hep-th",
      "cs.LG"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16130v1",
    "title": "Scalable Graph Generative Modeling via Substructure Sequences",
    "authors": [
      "Zehong Wang",
      "Zheyuan Zhang",
      "Tianyi Ma",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "Graph neural networks (GNNs) has been predominantly driven by\nmessage-passing, where node representations are iteratively updated via local\nneighborhood aggregation. Despite their success, message-passing suffers from\nfundamental limitations -- including constrained expressiveness,\nover-smoothing, over-squashing, and limited capacity to model long-range\ndependencies. These issues hinder scalability: increasing data size or model\nsize often fails to yield improved performance, limiting the viability of GNNs\nas backbones for graph foundation models. In this work, we explore pathways\nbeyond message-passing and introduce Generative Graph Pattern Machine\n(G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM\nrepresents graph instances (nodes, edges, or entire graphs) as sequences of\nsubstructures, and employs generative pre-training over the sequences to learn\ngeneralizable, transferable representations. Empirically, G$^2$PM demonstrates\nstrong scalability: on the ogbn-arxiv benchmark, it continues to improve with\nmodel sizes up to 60M parameters, outperforming prior generative approaches\nthat plateau at significantly smaller scales (e.g., 3M). In addition, we\nsystematically analyze the model design space, highlighting key architectural\nchoices that contribute to its scalability and generalization. Across diverse\ntasks -- including node classification, graph classification, and transfer\nlearning -- G$^2$PM consistently outperforms strong baselines, establishing a\ncompelling foundation for scalable graph learning. The code and dataset are\navailable at https://github.com/Zehong-Wang/G2PM.",
    "pdf_url": "http://arxiv.org/pdf/2505.16130v1",
    "published": "2025-05-22T02:16:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16129v1",
    "title": "LLMs Are Not Scorers: Rethinking MT Evaluation with Generation-Based Methods",
    "authors": [
      "Hyang Cui"
    ],
    "abstract": "Recent studies have applied large language models (LLMs) to machine\ntranslation quality estimation (MTQE) by prompting models to assign numeric\nscores. Nonetheless, these direct scoring methods tend to show low\nsegment-level correlation with human judgments. In this paper, we propose a\ngeneration-based evaluation paradigm that leverages decoder-only LLMs to\nproduce high-quality references, followed by semantic similarity scoring using\nsentence embeddings. We conduct the most extensive evaluation to date in MTQE,\ncovering 8 LLMs and 8 language pairs. Empirical results show that our method\noutperforms both intra-LLM direct scoring baselines and external non-LLM\nreference-free metrics from MTME. These findings demonstrate the strength of\ngeneration-based evaluation and support a shift toward hybrid approaches that\ncombine fluent generation with accurate semantic assessment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16129v1",
    "published": "2025-05-22T02:14:38+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16128v2",
    "title": "Veracity Bias and Beyond: Uncovering LLMs' Hidden Beliefs in Problem-Solving Reasoning",
    "authors": [
      "Yue Zhou",
      "Barbara Di Eugenio"
    ],
    "abstract": "Despite LLMs' explicit alignment against demographic stereotypes, they have\nbeen shown to exhibit biases under various social contexts. In this work, we\nfind that LLMs exhibit concerning biases in how they associate solution\nveracity with demographics. Through experiments across five human value-aligned\nLLMs on mathematics, coding, commonsense, and writing problems, we reveal two\nforms of such veracity biases: Attribution Bias, where models\ndisproportionately attribute correct solutions to certain demographic groups,\nand Evaluation Bias, where models' assessment of identical solutions varies\nbased on perceived demographic authorship. Our results show pervasive biases:\nLLMs consistently attribute fewer correct solutions and more incorrect ones to\nAfrican-American groups in math and coding, while Asian authorships are least\npreferred in writing evaluation. In additional studies, we show LLMs\nautomatically assign racially stereotypical colors to demographic groups in\nvisualization code, suggesting these biases are deeply embedded in models'\nreasoning processes. Our findings indicate that demographic bias extends beyond\nsurface-level stereotypes and social context provocations, raising concerns\nabout LLMs' deployment in educational and evaluation settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16128v2",
    "published": "2025-05-22T02:13:48+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.11050v1",
    "title": "NSW-EPNews: A News-Augmented Benchmark for Electricity Price Forecasting with LLMs",
    "authors": [
      "Zhaoge Bi",
      "Linghan Huang",
      "Haolin Jin",
      "Qingwen Zeng",
      "Huaming Chen"
    ],
    "abstract": "Electricity price forecasting is a critical component of modern\nenergy-management systems, yet existing approaches heavily rely on numerical\nhistories and ignore contemporaneous textual signals. We introduce NSW-EPNews,\nthe first benchmark that jointly evaluates time-series models and large\nlanguage models (LLMs) on real-world electricity-price prediction. The dataset\nincludes over 175,000 half-hourly spot prices from New South Wales, Australia\n(2015-2024), daily temperature readings, and curated market-news summaries from\nWattClarity. We frame the task as 48-step-ahead forecasting, using multimodal\ninput, including lagged prices, vectorized news and weather features for\nclassical models, and prompt-engineered structured contexts for LLMs. Our\ndatasets yields 3.6k multimodal prompt-output pairs for LLM evaluation using\nspecific templates. Through compresive benchmark design, we identify that for\ntraditional statistical and machine learning models, the benefits gain is\nmarginal from news feature. For state-of-the-art LLMs, such as GPT-4o and\nGemini 1.5 Pro, we observe modest performance increase while it also produce\nfrequent hallucinations such as fabricated and malformed price sequences.\nNSW-EPNews provides a rigorous testbed for evaluating grounded numerical\nreasoning in multimodal settings, and highlights a critical gap between current\nLLM capabilities and the demands of high-stakes energy forecasting.",
    "pdf_url": "http://arxiv.org/pdf/2506.11050v1",
    "published": "2025-05-22T02:13:30+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16127v1",
    "title": "CMA-ES with Radial Basis Function Surrogate for Black-Box Optimization",
    "authors": [
      "Farshid Farhadi Khouzani",
      "Abdolreza Mirzaei",
      "Paul La Plante",
      "Laxmi Gewali"
    ],
    "abstract": "Evolutionary optimization algorithms often face defects and limitations that\ncomplicate the evolution processes or even prevent them from reaching the\nglobal optimum. A notable constraint pertains to the considerable quantity of\nfunction evaluations required to achieve the intended solution. This concern\nassumes heightened significance when addressing costly optimization problems.\nHowever, recent research has shown that integrating machine learning methods,\nspecifically surrogate models, with evolutionary optimization can enhance\nvarious aspects of these algorithms. Among the evolutionary algorithms, the\nCovariance Matrix Adaptation Evolutionary Strategy (CMA-ES) is particularly\nfavored. This preference is due to its use of Gaussian distribution for\ncalculating evolution and its ability to adapt optimization parameters, which\nreduces the need for user intervention in adjusting initial parameters. In this\nresearch endeavor, we propose the adoption of surrogate models within the\nCMA-ES framework called CMA-SAO to develop an initial surrogate model that\nfacilitates the adaptation of optimization parameters through the acquisition\nof pertinent information derived from the associated surrogate model. Empirical\nvalidation reveals that CMA-SAO algorithm markedly diminishes the number of\nfunction evaluations in comparison to prevailing algorithms, thereby providing\na significant enhancement in operational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.16127v1",
    "published": "2025-05-22T02:10:04+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00023v1",
    "title": "Sampling of Graph Signals Based on Joint Time-Vertex Fractional Fourier Transform",
    "authors": [
      "Yu Zhang",
      "Bing-Zhao Li"
    ],
    "abstract": "With the growing demand for non-Euclidean data analysis, graph signal\nprocessing (GSP) has gained significant attention for its capability to handle\ncomplex time-varying data. This paper introduces a novel sampling method based\non the joint time-vertex fractional Fourier transform (JFRFT), enhancing signal\nrepresentation in time-frequency analysis and GSP. The JFRFT sampling theory is\nestablished by deriving conditions for the perfect recovery of jointly\nbandlimited signals, along with an optimal sampling set selection strategy. To\nfurther enhance the efficiency of large-scale time-vertex signal processing,\nthe design of localized sampling operators is investigated. Numerical\nsimulations and real data experiments validate the superior performance of the\nproposed methods in terms of recovery accuracy and computational efficiency,\noffering new insights into efficient time-varying signal processing.",
    "pdf_url": "http://arxiv.org/pdf/2506.00023v1",
    "published": "2025-05-22T02:08:13+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2507.21062v1",
    "title": "Automated but Atrophied? Student Over-Reliance vs Expert Augmentation of AI in Learning and Cybersecurity",
    "authors": [
      "Koffka Khan"
    ],
    "abstract": "University students and working professionals are increasingly encountering\ngenerative artificial intelligence (AI) in education and practice, yet their\napproaches and outcomes differ markedly. This paper proposes an academic study\ncontrasting novice over-reliance on AI with expert augmentation of AI, grounded\nin two real-world narratives. In one, a university student attempted to\noutsource learning entirely to AI, eschewing course engagement. In the other,\nseasoned cybersecurity professionals in the Tradewinds 2025 red/blue team\nexercise collaboratively employed AI tools to enhance (not replace) their\ndomain expertise. This proposal outlines a comparative research design to\ninvestigate how students' perception of AI as a learning replacement versus\nprofessionals' use of AI as an expert tool impacts outcomes. Drawing on current\nliterature in educational technology and workplace AI, we examine implications\nfor curriculum design, AI literacy, and assessment reform in higher education.\nWe hypothesize that blind reliance on AI can erode fundamental skills and\nacademic integrity, whereas guided use of AI by knowledgeable users can amplify\nproductivity without sacrificing quality. The paper details methodologies for\nclassroom and workplace data collection, including student and professional\nsurveys, interviews, and performance analyses. Anticipated findings aim to\ninform responsible AI integration in curricula, balancing innovation with the\nnecessity of domain knowledge. We conclude with recommendations for pedagogical\nstrategies, institutional policies to foster AI literacy, and a call for\nlongitudinal studies tracking how AI usage during university affects\nprofessional competencies over time.",
    "pdf_url": "http://arxiv.org/pdf/2507.21062v1",
    "published": "2025-05-22T02:07:33+00:00",
    "categories": [
      "cs.CY",
      "68T07 (Primary), 68T05, 68U99 (Secondary)",
      "I.2.6; I.2.7; K.3.2; K.4.1; F.2.2"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16126v2",
    "title": "Robust Invariant Representation Learning by Distribution Extrapolation",
    "authors": [
      "Kotaro Yoshida",
      "Konstantinos Slavakis"
    ],
    "abstract": "Invariant risk minimization (IRM) aims to enable out-of-distribution (OOD)\ngeneralization in deep learning by learning invariant representations. As IRM\nposes an inherently challenging bi-level optimization problem, most existing\napproaches -- including IRMv1 -- adopt penalty-based single-level\napproximations. However, empirical studies consistently show that these methods\noften fail to outperform well-tuned empirical risk minimization (ERM),\nhighlighting the need for more robust IRM implementations. This work\ntheoretically identifies a key limitation common to many IRM variants: their\npenalty terms are highly sensitive to limited environment diversity and\nover-parameterization, resulting in performance degradation. To address this\nissue, a novel extrapolation-based framework is proposed that enhances\nenvironmental diversity by augmenting the IRM penalty through synthetic\ndistributional shifts. Extensive experiments -- ranging from synthetic setups\nto realistic, over-parameterized scenarios -- demonstrate that the proposed\nmethod consistently outperforms state-of-the-art IRM variants, validating its\neffectiveness and robustness.",
    "pdf_url": "http://arxiv.org/pdf/2505.16126v2",
    "published": "2025-05-22T02:03:34+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16125v1",
    "title": "KoBALT: Korean Benchmark For Advanced Linguistic Tasks",
    "authors": [
      "Hyopil Shin",
      "Sangah Lee",
      "Dongjun Jang",
      "Wooseok Song",
      "Jaeyoon Kim",
      "Chaeyoung Oh",
      "Hyemi Jo",
      "Youngchae Ahn",
      "Sihyun Oh",
      "Hyohyeong Chang",
      "Sunkyoung Kim",
      "Jinsik Lee"
    ],
    "abstract": "We introduce KoBALT (Korean Benchmark for Advanced Linguistic Tasks), a\ncomprehensive linguistically-motivated benchmark comprising 700 multiple-choice\nquestions spanning 24 phenomena across five linguistic domains: syntax,\nsemantics, pragmatics, phonetics/phonology, and morphology. KoBALT is designed\nto advance the evaluation of large language models (LLMs) in Korean, a\nmorphologically rich language, by addressing the limitations of conventional\nbenchmarks that often lack linguistic depth and typological grounding. It\nintroduces a suite of expert-curated, linguistically motivated questions with\nminimal n-gram overlap with standard Korean corpora, substantially mitigating\nthe risk of data contamination and allowing a more robust assessment of true\nlanguage understanding. Our evaluation of 20 contemporary LLMs reveals\nsignificant performance disparities, with the highest-performing model\nachieving 61\\% general accuracy but showing substantial variation across\nlinguistic domains - from stronger performance in semantics (66\\%) to\nconsiderable weaknesses in phonology (31\\%) and morphology (36\\%). Through\nhuman preference evaluation with 95 annotators, we demonstrate a strong\ncorrelation between KoBALT scores and human judgments, validating our\nbenchmark's effectiveness as a discriminative measure of Korean language\nunderstanding. KoBALT addresses critical gaps in linguistic evaluation for\ntypologically diverse languages and provides a robust framework for assessing\ngenuine linguistic competence in Korean language models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16125v1",
    "published": "2025-05-22T02:03:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17131v1",
    "title": "Relative Bias: A Comparative Framework for Quantifying Bias in LLMs",
    "authors": [
      "Alireza Arbabi",
      "Florian Kerschbaum"
    ],
    "abstract": "The growing deployment of large language models (LLMs) has amplified concerns\nregarding their inherent biases, raising critical questions about their\nfairness, safety, and societal impact. However, quantifying LLM bias remains a\nfundamental challenge, complicated by the ambiguity of what \"bias\" entails.\nThis challenge grows as new models emerge rapidly and gain widespread use,\nwhile introducing potential biases that have not been systematically assessed.\nIn this paper, we propose the Relative Bias framework, a method designed to\nassess how an LLM's behavior deviates from other LLMs within a specified target\ndomain. We introduce two complementary methodologies: (1) Embedding\nTransformation analysis, which captures relative bias patterns through sentence\nrepresentations over the embedding space, and (2) LLM-as-a-Judge, which employs\na language model to evaluate outputs comparatively. Applying our framework to\nseveral case studies on bias and alignment scenarios following by statistical\ntests for validation, we find strong alignment between the two scoring methods,\noffering a systematic, scalable, and statistically grounded approach for\ncomparative bias analysis in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.17131v1",
    "published": "2025-05-22T01:59:54+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16124v1",
    "title": "Controlling the false discovery rate in high-dimensional linear models using model-X knockoffs and $p$-values",
    "authors": [
      "Jinyuan Chang",
      "Chenlong Li",
      "Cheng Yong Tang",
      "Zhengtian Zhu"
    ],
    "abstract": "In this paper, we propose novel multiple testing methods for controlling the\nfalse discovery rate (FDR) in the context of high-dimensional linear models.\nOur development innovatively integrates model-X knockoff techniques with\ndebiased penalized regression estimators. The proposed approach addresses two\nfundamental challenges in high-dimensional statistical inference: (i)\nconstructing valid test statistics and corresponding $p$-values in solving\nproblems with a diverging number of model parameters, and (ii) ensuring FDR\ncontrol under complex and unknown dependence structures among test statistics.\nA central contribution of our methodology lies in the rigorous construction and\ntheoretical analysis of two paired sets of test statistics. Based on these test\nstatistics, our methodology adopts two $p$-value-based multiple testing\nalgorithms. The first applies the conventional Benjamini-Hochberg procedure,\njustified by the asymptotic mutual independence and normality of one set of the\ntest statistics. The second leverages the paired structure of both sets of test\nstatistics to improve detection power while maintaining rigorous FDR control.\nWe provide comprehensive theoretical analysis, establishing the validity of the\ndebiasing framework and ensuring that the proposed methods achieve proper FDR\ncontrol. Extensive simulation studies demonstrate that our procedures\noutperform existing approaches - particularly those relying on empirical\nevaluations of false discovery proportions - in terms of both power and\nempirical control of the FDR. Notably, our methodology yields substantial\nimprovements in settings characterized by weaker signals, smaller sample sizes,\nand lower pre-specified FDR levels.",
    "pdf_url": "http://arxiv.org/pdf/2505.16124v1",
    "published": "2025-05-22T01:59:15+00:00",
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.16123v1",
    "title": "Improved linear and Kerr nonlinear phase estimation via photon addition operations",
    "authors": [
      "Zekun Zhao",
      "Qingqian Kang",
      "Shoukang Chang",
      "Teng Zhao",
      "Cunjin Liu",
      "Xin Su",
      "Liyun Hu"
    ],
    "abstract": "The accuracy of quantum measurements can be effectively improved by using\nboth photon-added non-Gaussian operations and Kerr nonlinear phase shifters.\nHere, we employ coherent state mixed photon-added squeezed vacuum state as\ninput into a Mach-Zehnder interferometer with parity detection, thereby\nachieving a significant enhancement in phase measurement accuracy. Our research\nfocuses on phase sensitivity of linear phase shift under both ideal conditions\nand photon loss, as well as quantum Fisher information. The results demonstrate\nthat employing the photon addition operations can markedly enhance phase\nsensitivity and quantum Fisher information, and the measurement accuracy can\neven approach the Heisenberg limit. In addition, we delve deeper into the\nscenario of replacing the linear phase shifter with a Kerr nonlinear one and\nsystematically analyze the quantum Fisher information under both ideal and\nphoton loss conditions. By comparison, it is evident that employing both the\nphoton addition operations and the Kerr nonlinear phase shifter can further\nsignificantly enhance phase measurement accuracy while effectively improving\nthe system's robustness against photon loss. These findings are instrumental in\nfacilitating the development and practical application of quantum metrology.",
    "pdf_url": "http://arxiv.org/pdf/2505.16123v1",
    "published": "2025-05-22T01:57:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16122v2",
    "title": "Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning",
    "authors": [
      "Junhong Lin",
      "Xinyue Zeng",
      "Jie Zhu",
      "Song Wang",
      "Julian Shun",
      "Jun Wu",
      "Dawei Zhou"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in complex\nreasoning tasks, but their inference remains computationally inefficient. We\nobserve a common failure mode in many prevalent LLMs, overthinking, where\nmodels generate verbose and tangential reasoning traces even for simple\nqueries. Recent works have tried to mitigate this by enforcing fixed token\nbudgets, however, this can lead to underthinking, especially on harder\nproblems. Through empirical analysis, we identify that this inefficiency often\nstems from unclear problem-solving strategies. To formalize this, we develop a\ntheoretical model, BBAM (Bayesian Budget Allocation Model), which models\nreasoning as a sequence of sub-questions with varying uncertainty, and\nintroduce the $E^3$ metric to capture the trade-off between correctness and\ncomputation efficiency. Building on theoretical results from BBAM, we propose\nPlan-and-Budget, a model-agnostic, test-time framework that decomposes complex\nqueries into sub-questions and allocates token budgets based on estimated\ncomplexity using adaptive scheduling. Plan-and-Budget improves reasoning\nefficiency across a range of tasks and models, achieving up to +70% accuracy\ngains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it\nelevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger\nmodel (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close\nperformance gaps without retraining. Our code is available at\nhttps://github.com/junhongmit/P-and-B.",
    "pdf_url": "http://arxiv.org/pdf/2505.16122v2",
    "published": "2025-05-22T01:56:29+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16121v2",
    "title": "Emotion-based Recommender System",
    "authors": [
      "Hao Wang"
    ],
    "abstract": "Recommender system is one of the most critical technologies for large\ninternet companies such as Amazon and TikTok. Although millions of users use\nrecommender systems globally everyday, and indeed, much data analysis work has\nbeen done to improve the technical accuracy of the system, to our limited\nknowledge, there has been little attention paid to analysis of users' emotion\nin recommender systems. In this paper, we create a new theory and metrics that\ncould capture users' emotion when they are interacting with recommender\nsystems. We also provide effective and efficient visualization techniques for\nvisualization of users' emotion and its change in the customers' lifetime\ncycle. In the end, we design a framework for emotion-based recommendation\nalgorithms, illustrated in a straightforward example with experimental results\nto demonstrate the effectiveness of our new theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.16121v2",
    "published": "2025-05-22T01:54:58+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16120v1",
    "title": "LLM-Powered AI Agent Systems and Their Applications in Industry",
    "authors": [
      "Guannan Liang",
      "Qianqian Tong"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has reshaped agent systems.\nUnlike traditional rule-based agents with limited task scope, LLM-powered\nagents offer greater flexibility, cross-domain reasoning, and natural language\ninteraction. Moreover, with the integration of multi-modal LLMs, current agent\nsystems are highly capable of processing diverse data modalities, including\ntext, images, audio, and structured tabular data, enabling richer and more\nadaptive real-world behavior. This paper comprehensively examines the evolution\nof agent systems from the pre-LLM era to current LLM-powered architectures. We\ncategorize agent systems into software-based, physical, and adaptive hybrid\nsystems, highlighting applications across customer service, software\ndevelopment, manufacturing automation, personalized education, financial\ntrading, and healthcare. We further discuss the primary challenges posed by\nLLM-powered agents, including high inference latency, output uncertainty, lack\nof evaluation metrics, and security vulnerabilities, and propose potential\nsolutions to mitigate these concerns.",
    "pdf_url": "http://arxiv.org/pdf/2505.16120v1",
    "published": "2025-05-22T01:52:15+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16119v2",
    "title": "Source Separation by Flow Matching",
    "authors": [
      "Robin Scheibler",
      "John R. Hershey",
      "Arnaud Doucet",
      "Henry Li"
    ],
    "abstract": "We consider the problem of single-channel audio source separation with the\ngoal of reconstructing $K$ sources from their mixture. We address this\nill-posed problem with FLOSS (FLOw matching for Source Separation), a\nconstrained generation method based on flow matching, ensuring strict mixture\nconsistency. Flow matching is a general methodology that, when given samples\nfrom two probability distributions defined on the same space, learns an\nordinary differential equation to output a sample from one of the distributions\nwhen provided with a sample from the other. In our context, we have access to\nsamples from the joint distribution of $K$ sources and so the corresponding\nsamples from the lower-dimensional distribution of their mixture. To apply flow\nmatching, we augment these mixture samples with artificial noise components to\nmatch the dimensionality of the $K$ source distribution. Additionally, as any\npermutation of the sources yields the same mixture, we adopt an equivariant\nformulation of flow matching which relies on a neural network architecture that\nis equivariant by design. We demonstrate the performance of the method for the\nseparation of overlapping speech.",
    "pdf_url": "http://arxiv.org/pdf/2505.16119v2",
    "published": "2025-05-22T01:52:06+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16118v1",
    "title": "Semiotic Reconstruction of Destination Expectation Constructs An LLM-Driven Computational Paradigm for Social Media Tourism Analytics",
    "authors": [
      "Haotian Lan",
      "Yao Gao",
      "Yujun Cheng",
      "Wei Yuan",
      "Kun Wang"
    ],
    "abstract": "Social media's rise establishes user-generated content (UGC) as pivotal for\ntravel decisions, yet analytical methods lack scalability. This study\nintroduces a dual-method LLM framework: unsupervised expectation extraction\nfrom UGC paired with survey-informed supervised fine-tuning. Findings reveal\nleisure/social expectations drive engagement more than foundational\nnatural/emotional factors. By establishing LLMs as precision tools for\nexpectation quantification, we advance tourism analytics methodology and\npropose targeted strategies for experience personalization and social travel\npromotion. The framework's adaptability extends to consumer behavior research,\ndemonstrating computational social science's transformative potential in\nmarketing optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.16118v1",
    "published": "2025-05-22T01:52:01+00:00",
    "categories": [
      "cs.CL",
      "stat.AP"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16117v2",
    "title": "Inchworm tensor train hybridization expansion quantum impurity solver",
    "authors": [
      "Yang Yu",
      "André Erpenbeck",
      "Dominika Zgid",
      "Guy Cohen",
      "Olivier Parcollet",
      "Emanuel Gull"
    ],
    "abstract": "The investigation of quantum impurity models plays a crucial role in\ncondensed matter physics because of their wide-ranging applications, such as\nembedding theories and transport problems. Traditional methods often fall short\nof producing accurate results for multi-orbital systems with complex\ninteractions and off-diagonal hybridizations. Recently, tensor-train-based\nintegration and summation techniques have shown promise as effective\nalternatives. In this study, we use tensor train methods to tackle quantum\nimpurity problems formulated within the imaginary-time inchworm hybridization\nexpansion framework. We identify key challenges in the inchworm expansion\nitself and its interplay with tensor-train-based methods. We demonstrate the\naccuracy and versatility of our approach by solving general quantum impurity\nproblems. Our results suggest that tensor-train decomposition schemes offer a\nviable path toward accurate and efficient multi-orbital impurity solvers.",
    "pdf_url": "http://arxiv.org/pdf/2505.16117v2",
    "published": "2025-05-22T01:51:03+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.20309v1",
    "title": "Guiding Giants: Lightweight Controllers for Weighted Activation Steering in LLMs",
    "authors": [
      "Amr Hegazy",
      "Mostafa Elhoushi",
      "Amr Alanwar"
    ],
    "abstract": "Controlling undesirable Large Language Model (LLM) behaviors, such as the\ngeneration of unsafe content or failing to adhere to safety guidelines, often\nrelies on costly fine-tuning. Activation steering provides an alternative for\ninference-time control, but existing methods typically lack fine-grained,\nadaptive mechanisms. We introduce a novel approach using a lightweight,\ntrainable controller network integrated during inference. This controller\nnetwork observes specific intermediate LLM activations and predicts both a\nglobal scaling factor and layer-specific weights. The predicted global scaling\nfactor and layer-specific weights then dynamically modulate the intensity of a\nsteering patch, derived from a pre-computed \"refusal direction\" vector, applied\nacross the LLM's layers during generation. Trained on activations from both\nharmful and benign prompts, our controller learns to discriminatively apply\nnuanced, layer-aware interventions, activating steering primarily for harmful\ninputs. Experiments using safety benchmarks like ToxicChat & In-The-Wild\nJailbreak Prompts demonstrate that our weighted steering controller\nsignificantly increases refusal rates compared to the base LLM, achieving\ntargeted behavioral modification without altering the original model\nparameters. Our experiments with Llama-3.1-8B, Llama-3.2-1B & Mistral-7B show\nour approach outperforms existing methods, presenting an efficient and adaptive\nmethod for fine-grained control over LLM behavior at inference time.",
    "pdf_url": "http://arxiv.org/pdf/2505.20309v1",
    "published": "2025-05-22T01:48:38+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16116v1",
    "title": "Difference and Wavelet Characterizations of Distances from Functions in Lipschitz Spaces to Their Subspaces",
    "authors": [
      "Feng Dai",
      "Eero Saksman",
      "Dachun Yang",
      "Wen Yuan",
      "Yangyang Zhang"
    ],
    "abstract": "Let $\\Lambda_s$ denote the Lipschitz space of order $s\\in(0,\\infty)$ on\n$\\mathbb{R}^n$, which consists of all $f\\in\\mathfrak{C}\\cap L^\\infty$ such\nthat, for some constant $L\\in(0,\\infty)$ and some integer $r\\in(s,\\infty)$,\n\\begin{equation*} \\label{0-1}\\Delta_r f(x,y): =\\sup_{|h|\\leq y} |\\Delta_h^r\nf(x)|\\leq L y^s, \\ x\\in\\mathbb{R}^n, \\ y \\in(0, 1]. \\end{equation*} Here (and\nthroughout the article) $\\mathfrak{C}$ refers to continuous functions, and\n$\\Delta_h^r$ is the usual $r$-th order difference operator with step\n$h\\in\\mathbb{R}^n$. For each $f\\in \\Lambda_s$ and $\\varepsilon\\in(0,L)$, let $\nS(f,\\varepsilon):= \\{ (x,y)\\in\\mathbb{R}^n\\times [0,1]: \\frac {\\Delta_r\nf(x,y)}{y^s}>\\varepsilon\\}$, and let $\\mu: \\mathcal{B}(\\mathbb{R}_+^{n+1})\\to\n[0,\\infty]$ be a suitably defined nonnegative extended real-valued function on\nthe Borel $\\sigma$-algebra of subsets of $\\mathbb{R}_+^{n+1}$. Let\n$\\varepsilon(f)$ be the infimum of all $\\varepsilon\\in(0,\\infty)$ such that\n$\\mu(S(f,\\varepsilon))<\\infty$. The main target of this article is to\ncharacterize the distance from $f$ to a subspace $V\\cap \\Lambda_s$ of\n$\\Lambda_s$ for various function spaces $V$ (including Sobolev,\nBesov--Triebel--Lizorkin, and Besov--Triebel--Lizorkin-type spaces) in terms of\n$\\varepsilon(f)$, showing that \\begin{equation*} \\varepsilon(f)\\sim\n\\mathrm{dist} (f, V\\cap \\Lambda_s)_{\\Lambda_s}: = \\inf_{g\\in \\Lambda_s\\cap V}\n\\|f-g\\|_{\\Lambda_s}.\\end{equation*} Moreover, we present our results in a\ngeneral framework based on quasi-normed lattices of function sequences $X$ and\nDaubechies $s$-Lipschitz $X$-based spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.16116v1",
    "published": "2025-05-22T01:44:15+00:00",
    "categories": [
      "math.FA",
      "math.AP",
      "math.CA",
      "Primary 42B35, Secondary 26A16, 42B25, 42C40, 46E35"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16115v1",
    "title": "A Generic Framework for Conformal Fairness",
    "authors": [
      "Aditya T. Vadlamani",
      "Anutam Srinivasan",
      "Pranav Maneriker",
      "Ali Payani",
      "Srinivasan Parthasarathy"
    ],
    "abstract": "Conformal Prediction (CP) is a popular method for uncertainty quantification\nwith machine learning models. While conformal prediction provides probabilistic\nguarantees regarding the coverage of the true label, these guarantees are\nagnostic to the presence of sensitive attributes within the dataset. In this\nwork, we formalize \\textit{Conformal Fairness}, a notion of fairness using\nconformal predictors, and provide a theoretically well-founded algorithm and\nassociated framework to control for the gaps in coverage between different\nsensitive groups. Our framework leverages the exchangeability assumption\n(implicit to CP) rather than the typical IID assumption, allowing us to apply\nthe notion of Conformal Fairness to data types and tasks that are not IID, such\nas graph data. Experiments were conducted on graph and tabular datasets to\ndemonstrate that the algorithm can control fairness-related gaps in addition to\ncoverage aligned with theoretical expectations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16115v1",
    "published": "2025-05-22T01:41:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16114v1",
    "title": "Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language",
    "authors": [
      "Naiqi Li",
      "Peiyuan Liu",
      "Zheng Liu",
      "Tao Dai",
      "Yong Jiang",
      "Shu-Tao Xia"
    ],
    "abstract": "Solving puzzles in natural language poses a long-standing challenge in AI.\nWhile large language models (LLMs) have recently shown impressive capabilities\nin a variety of tasks, they continue to struggle with complex puzzles that\ndemand precise reasoning and exhaustive search. In this paper, we propose\nLogic-of-Thought (Logot), a novel framework that bridges LLMs with logic\nprogramming to address this problem. Our method leverages LLMs to translate\npuzzle rules and states into answer set programs (ASPs), the solution of which\nare then accurately and efficiently inferred by an ASP interpreter. This hybrid\napproach combines the natural language understanding of LLMs with the precise\nreasoning capabilities of logic programs. We evaluate our method on various\ngrid puzzles and dynamic puzzles involving actions, demonstrating near-perfect\naccuracy across all tasks. Our code and data are available at:\nhttps://github.com/naiqili/Logic-of-Thought.",
    "pdf_url": "http://arxiv.org/pdf/2505.16114v1",
    "published": "2025-05-22T01:37:40+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16113v1",
    "title": "Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools",
    "authors": [
      "Panagiotis Lymperopoulos",
      "Vasanth Sarathy"
    ],
    "abstract": "Modern Large Language Models (LLMs) often require external tools, such as\nmachine learning classifiers or knowledge retrieval systems, to provide\naccurate answers in domains where their pre-trained knowledge is insufficient.\nThis integration of LLMs with external tools expands their utility but also\nintroduces a critical challenge: determining the trustworthiness of responses\ngenerated by the combined system. In high-stakes applications, such as medical\ndecision-making, it is essential to assess the uncertainty of both the LLM's\ngenerated text and the tool's output to ensure the reliability of the final\nresponse. However, existing uncertainty quantification methods do not account\nfor the tool-calling scenario, where both the LLM and external tool contribute\nto the overall system's uncertainty. In this work, we present a novel framework\nfor modeling tool-calling LLMs that quantifies uncertainty by jointly\nconsidering the predictive uncertainty of the LLM and the external tool. We\nextend previous methods for uncertainty quantification over token sequences to\nthis setting and propose efficient approximations that make uncertainty\ncomputation practical for real-world applications. We evaluate our framework on\ntwo new synthetic QA datasets, derived from well-known machine learning\ndatasets, which require tool-calling for accurate answers. Additionally, we\napply our method to retrieval-augmented generation (RAG) systems and conduct a\nproof-of-concept experiment demonstrating the effectiveness of our uncertainty\nmetrics in scenarios where external information retrieval is needed. Our\nresults show that the framework is effective in enhancing trust in LLM-based\nsystems, especially in cases where the LLM's internal knowledge is insufficient\nand external tools are required.",
    "pdf_url": "http://arxiv.org/pdf/2505.16113v1",
    "published": "2025-05-22T01:34:23+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16112v1",
    "title": "Extensible Post Quantum Cryptography Based Authentication",
    "authors": [
      "Homer A. Riva-Cambrin",
      "Rahul Singh",
      "Sanju Lama",
      "Garnette R. Sutherland"
    ],
    "abstract": "Cryptography underpins the security of modern digital infrastructure, from\ncloud services to health data. However, many widely deployed systems will\nbecome vulnerable after the advent of scalable quantum computing. Although\nquantum-safe cryptographic primitives have been developed, such as\nlattice-based digital signature algorithms (DSAs) and key encapsulation\nmechanisms (KEMs), their unique structural and performance characteristics make\nthem unsuitable for existing protocols. In this work, we introduce a\nquantum-safe single-shot protocol for machine-to-machine authentication and\nauthorization that is specifically designed to leverage the strengths of\nlattice-based DSAs and KEMs. Operating entirely over insecure channels, this\nprotocol enables the forward-secure establishment of tokens in constrained\nenvironments. By demonstrating how new quantum-safe cryptographic primitives\ncan be incorporated into secure systems, this study lays the groundwork for\nscalable, resilient, and future-proof identity infrastructures in a\nquantum-enabled world.",
    "pdf_url": "http://arxiv.org/pdf/2505.16112v1",
    "published": "2025-05-22T01:34:17+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16111v1",
    "title": "Two tuples of noncommutative Orlicz sequence spaces and some geometry properties",
    "authors": [
      "Ma Zhenhua",
      "Jiang Lining"
    ],
    "abstract": "The primary contribution of this study lies in proposing a new concept termed\n$2$-tuples of noncommutative Orlicz sequence spaces\n$\\bigoplus\\limits_{j=1}^{2}S_{\\varphi_{j},p}$, where $S_{\\varphi_{j}}$ denotes\na noncommutative Orlicz sequence space. By leveraging the three-line theorem,\nwe establish the Riesz-Thorin interpolation theorem for\n$\\bigoplus\\limits_{j=1}^{2}S_{\\varphi_{j},p}$. As applications, we derive bound\nfor the nonsquare and von Neumann-Jordan constant of noncommutative Orlicz\nspace $S_{\\varphi_{s}} (0<s\\leq1)$, where $\\varphi_{s}$ is an intermediate\nfunction.",
    "pdf_url": "http://arxiv.org/pdf/2505.16111v1",
    "published": "2025-05-22T01:33:42+00:00",
    "categories": [
      "math.FA",
      "math.OA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2508.11632v1",
    "title": "Prediction of Spotify Chart Success Using Audio and Streaming Features",
    "authors": [
      "Ian Jacob Cabansag",
      "Paul Ntegeka"
    ],
    "abstract": "Spotify's streaming charts offer a real-time lens into music popularity,\ndriving discovery, playlists, and even revenue potential. Understanding what\ninfluences a song's rise in ranks on these charts-especially early on-can guide\nmarketing efforts, investment decisions, and even artistic direction. In this\nproject, we developed a classification pipeline to predict a song's chart\nsuccess based on its musical characteristics and early engagement data. Using\nall 2024 U.S. Top 200 Spotify Daily Charts and the Spotify Web API, we built a\ndataset containing both metadata and audio features for 14,639 unique songs.\n  The project was structured in two phases. First, we benchmarked four models:\nLogistic Regression, K Nearest Neighbors, Random Forest, and XGBoost-using a\nstandard train-test split. In the second phase, we incorporated\ncross-validation, hyperparameter tuning, and detailed class-level evaluation to\nensure robustness. Tree-based models consistently outperformed the rest, with\nRandom Forest and XGBoost achieving macro F1-scores near 0.95 and accuracy\naround 97%.\n  Even when stream count and rank history were excluded, models trained solely\non audio attributes retained predictive power. These findings validate the\npotential of audio-based modeling in A&R scouting, playlist optimization, and\nhit forecasting-long before a track reaches critical mass.",
    "pdf_url": "http://arxiv.org/pdf/2508.11632v1",
    "published": "2025-05-22T01:33:09+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16110v1",
    "title": "Sharp Brezis--Seeger--Van Schaftingen--Yung Formulae for Higher-Order Gradients in Ball Banach Function Spaces",
    "authors": [
      "Pingxu Hu",
      "Yinqin Li",
      "Dachun Yang",
      "Wen Yuan",
      "Yangyang Zhang"
    ],
    "abstract": "Let $X$ be a ball Banach function space on $\\mathbb{R}^n$, $k\\in\\mathbb{N}$,\n$h\\in\\mathbb{R}^n$, and $\\Delta^k_h$ denote the $k${\\rm th} order difference.\nIn this article, under some mild extra assumptions about $X$, the authors prove\nthat, for both parameters $q$ and $\\gamma$ in \\emph{sharp} ranges which are\nrelated to $X$ and for any locally integrable function $f$ on ${\\mathbb{R}^n}$\nsatisfying $|\\nabla^k f|\\in X$, $$ \\sup_{\\lambda\\in(0,\\infty)}\\lambda\n\\left\\|\\left[\\int_{\\{h\\in\\mathbb{R}^n:\\ |\\Delta_h^k\nf(\\cdot)|>\\lambda|h|^{k+\\frac{\\gamma}{q}}\\}}\n\\left|h\\right|^{\\gamma-n}\\,dh\\right]^\\frac{1}{q}\\right\\|_X \\sim\n\\left\\|\\,\\left|\\nabla^k f\\right|\\,\\right\\|_{X} $$ with the positive equivalence\nconstants independent of $f$. As applications, the authors establish the\nBrezis--Seeger--Van Schaftingen--Yung (for short, BSVY) characterization of\nhigher-order homogeneous ball Banach Sobolev spaces and higher-order fractional\nGagliardo--Nirenberg and Sobolev type inequalities in critical cases. All these\nresults are of quite wide generality and can be applied to various specific\nfunction spaces; moreover, even when $X:= L^{q}$, these results when $k=1$\ncoincide with the best known results and when $k\\ge 2$ are completely new. The\nfirst novelty is\n  to establish a sparse characterization of dyadic cubes in level sets related\nto the higher-order local approximation, which, together with the well-known\nWhitney inequality in approximation theory, further induces a higher-order\nweighted variant of the remarkable inequality obtained by A. Cohen, W. Dahmen,\nI. Daubechies, and R. DeVore; the second novelty is to combine this weighted\ninequality neatly with a variant higher-order Poincar\\'e inequality to\nestablish the desired upper estimate of BSVY formulae in weighted Lebesgue\nspaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.16110v1",
    "published": "2025-05-22T01:30:42+00:00",
    "categories": [
      "math.FA",
      "math.AP",
      "math.CA",
      "Primary 46E35, Secondary 26D10, 35A23, 42B25, 42B35"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16109v1",
    "title": "Absolutely summing Carleson embeddings on weighted Fock spaces with $A_{\\infty}$-type weights",
    "authors": [
      "Jiale Chen",
      "Bo He",
      "Maofa Wang"
    ],
    "abstract": "In this paper, we investigate the $r$-summing Carleson embeddings on weighted\nFock spaces $F^p_{\\alpha,w}$. By using duality arguments, translating\ntechniques and block diagonal operator skills, we completely characterize the\n$r$-summability of the natural embeddings $I_d:F^p_{\\alpha,w}\\to\nL^p_{\\alpha}(\\mu)$ for any $r\\geq1$ and $p>1$, where $w$ is a weight on the\ncomplex plane $\\mathbb{C}$ that satisfies an $A_p$-type condition. As\napplications, we establish some results on the $r$-summability of\ndifferentiation and integration operators, Volterra-type operators and\ncomposition operators. Especially, we completely characterize the boundedness\nof Volterra-type operators and composition operators on vector-valued Fock\nspaces for all $1<p<\\infty$, which were left open before for the case $1<p<2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16109v1",
    "published": "2025-05-22T01:30:39+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16108v1",
    "title": "Shape-invariant Potentials and Singular Spaces",
    "authors": [
      "Peng Yu",
      "Yuan Zhong",
      "Ziqi Wang",
      "Hui Wang",
      "Mengyang Zhang"
    ],
    "abstract": "We report two exact classical solutions in two-dimensional singular spaces.\nThese solutions are lower-dimensional versions of some five-dimensional brane\nworld solutions. Unlike the higher-dimensional model, our solutions have\nexactly solvable linear perturbation equations, namely, Schr\\\"odinger-like\nequations with P\\\"oschl-Teller I potential and Eckart potential. Both\npotentials are shape-invariant and can be solved exactly using supersymmetric\nquantum mechanics methods. In our work, the P\\\"oschl-Teller I potential has\ninfinitely many bound states, while the Eckart potential captures a finite\nnumber of bound states. Both potentials are positive-definite which indicates\nthat the background solutions are stable against linear perturbations.",
    "pdf_url": "http://arxiv.org/pdf/2505.16108v1",
    "published": "2025-05-22T01:28:42+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16107v1",
    "title": "MPL: Multiple Programming Languages with Large Language Models for Information Extraction",
    "authors": [
      "Bo Li",
      "Gexiang Fang",
      "Wei Ye",
      "Zhenghua Xu",
      "Jinglei Zhang",
      "Hao Cheng",
      "Shikun Zhang"
    ],
    "abstract": "Recent research in information extraction (IE) focuses on utilizing\ncode-style inputs to enhance structured output generation. The intuition behind\nthis is that the programming languages (PLs) inherently exhibit greater\nstructural organization than natural languages (NLs). This structural advantage\nmakes PLs particularly suited for IE tasks. Nevertheless, existing research\nprimarily focuses on Python for code-style simulation, overlooking the\npotential of other widely-used PLs (e.g., C++ and Java) during the supervised\nfine-tuning (SFT) phase. In this research, we propose \\textbf{M}ultiple\n\\textbf{P}rogramming \\textbf{L}anguages with large language models for\ninformation extraction (abbreviated as \\textbf{MPL}), a novel framework that\nexplores the potential of incorporating different PLs in the SFT phase.\nAdditionally, we introduce \\texttt{function-prompt} with virtual running to\nsimulate code-style inputs more effectively and efficiently. Experimental\nresults on a wide range of datasets demonstrate the effectiveness of MPL.\nFurthermore, we conduct extensive experiments to provide a comprehensive\nanalysis. We have released our code for future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.16107v1",
    "published": "2025-05-22T01:28:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16106v1",
    "title": "Pricing Model for Data Assets in Investment-Consumption Framework with Ambiguity",
    "authors": [
      "Xiaoshan Chen",
      "Chen Yang",
      "Zhou Yang"
    ],
    "abstract": "Data assets are data commodities that have been processed, produced, priced,\nand traded based on actual demand. Reasonable pricing mechanism for data assets\nis essential for developing the data market and realizing their value. Most\nexisting literature approaches data asset pricing from the seller's\nperspective, focusing on data properties and collection costs, however,\nresearch from the buyer's perspective remains scarce. This gap stems from the\nnature of data assets: their value lies not in direct revenue generation but in\nproviding informational advantages that enable enhanced decision-making and\nexcess returns. This paper addresses this gap by developing a pricing model\nbased on the informational value of data assets from the buyer's perspective.\nWe determine data asset prices through an implicit function derived from the\nvalue functions in two robust investment-consumption problems under ambiguity\nmarkets via the indifference pricing principle. By the existing research\nresults, we simplify the value function, using mathematical analysis and\ndifferential equation theory, we derive general expressions for data assets\nprice and explore their properties under various conditions. Furthermore, we\nderive the explicit pricing formulas for specific scenarios and provide\nnumerical illustration to describe how to use our pricing model.",
    "pdf_url": "http://arxiv.org/pdf/2505.16106v1",
    "published": "2025-05-22T01:22:16+00:00",
    "categories": [
      "q-fin.MF",
      "93E20, 49L99, 49N90, 35Q99, 65N06"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2505.16105v1",
    "title": "Sums and differences of sets (improvement over AlphaEvolve)",
    "authors": [
      "Robert Gerbicz"
    ],
    "abstract": "On May 14, 2025, DeepMind announced that AlphaEvolve, a large language model\napplied to a set of mathematical problems, had matched or exceeded the best\nknown bounds on several problems. In the case of the sum and difference of sets\nproblem, AlphaEvolve, using a set of $54265$ integers, improved the known lower\nbound of $\\theta=1.14465$ to $\\theta=1.1584$. In this paper, we present an\nimproved bound $\\theta=1.173050$ using an explicit construction of a U set that\ncontains more than $10^{43546}$ elements. For fast integer and floating-point\narithmetic, we used the (free) GMP library.",
    "pdf_url": "http://arxiv.org/pdf/2505.16105v1",
    "published": "2025-05-22T01:19:35+00:00",
    "categories": [
      "math.NT",
      "11B75"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16104v2",
    "title": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models",
    "authors": [
      "Yue Li",
      "Xin Yi",
      "Dongsheng Shi",
      "Gerard de Melo",
      "Xiaoling Wang",
      "Linlin Wang"
    ],
    "abstract": "With the increasing size of Large Vision-Language Models (LVLMs), network\npruning techniques aimed at compressing models for deployment in\nresource-constrained environments have garnered significant attention. However,\nwe observe that pruning often leads to a degradation in safety performance. To\naddress this issue, we present a novel and lightweight approach, termed\nHierarchical Safety Realignment (HSR). HSR operates by first quantifying the\ncontribution of each attention head to safety, identifying the most critical\nones, and then selectively restoring neurons directly within these attention\nheads that play a pivotal role in maintaining safety. This process\nhierarchically realigns the safety of pruned LVLMs, progressing from the\nattention head level to the neuron level. We validate HSR across various models\nand pruning strategies, consistently achieving notable improvements in safety\nperformance. To our knowledge, this is the first work explicitly focused on\nrestoring safety in LVLMs post-pruning.",
    "pdf_url": "http://arxiv.org/pdf/2505.16104v2",
    "published": "2025-05-22T01:06:28+00:00",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16103v1",
    "title": "Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI",
    "authors": [
      "Monirul Islam Mahmud"
    ],
    "abstract": "Keylogger detection involves monitoring for unusual system behaviors such as\ndelays between typing and character display, analyzing network traffic patterns\nfor data exfiltration. In this study, we provide a comprehensive analysis for\nkeylogger detection with traditional machine learning models - SVC, Random\nForest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes\nand advanced ensemble methods including Stacking, Blending and Voting.\nMoreover, feature selection approaches such as Information gain, Lasso L1 and\nFisher Score are thoroughly assessed to improve predictive performance and\nlower computational complexity. The Keylogger Detection dataset from publicly\navailable Kaggle website is used in this project. In addition to accuracy-based\nclassification, this study implements the approach for model interpretation\nusing Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to\ndeliver finer explanations for how much each feature contributes in assisting\nor hindering the detection process. To evaluate the models result, we have used\nAUC score, sensitivity, Specificity, Accuracy and F1 score. The best\nperformance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99,\n100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is\nnear-perfect classification with Fisher Score.",
    "pdf_url": "http://arxiv.org/pdf/2505.16103v1",
    "published": "2025-05-22T01:04:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16102v2",
    "title": "Continually Self-Improving Language Models for Bariatric Surgery Question--Answering",
    "authors": [
      "Yash Kumar Atri",
      "Thomas H Shin",
      "Thomas Hartvigsen"
    ],
    "abstract": "While bariatric and metabolic surgery (MBS) is considered the gold standard\ntreatment for severe and morbid obesity, its therapeutic efficacy hinges upon\nactive and longitudinal engagement with multidisciplinary providers, including\nsurgeons, dietitians/nutritionists, psychologists, and endocrinologists. This\nengagement spans the entire patient journey, from preoperative preparation to\nlong-term postoperative management. However, this process is often hindered by\nnumerous healthcare disparities, such as logistical and access barriers, which\nimpair easy patient access to timely, evidence-based, clinician-endorsed\ninformation. To address these gaps, we introduce bRAGgen, a novel adaptive\nretrieval-augmented generation (RAG)-based model that autonomously integrates\nreal-time medical evidence when response confidence dips below dynamic\nthresholds. This self-updating architecture ensures that responses remain\ncurrent and accurate, reducing the risk of misinformation. Additionally, we\npresent bRAGq, a curated dataset of 1,302 bariatric surgery--related questions,\nvalidated by an expert bariatric surgeon. bRAGq constitutes the first\nlarge-scale, domain-specific benchmark for comprehensive MBS care. In a\ntwo-phase evaluation, bRAGgen is benchmarked against state-of-the-art models\nusing both large language model (LLM)--based metrics and expert surgeon review.\nAcross all evaluation dimensions, bRAGgen demonstrates substantially superior\nperformance in generating clinically accurate and relevant responses.",
    "pdf_url": "http://arxiv.org/pdf/2505.16102v2",
    "published": "2025-05-22T01:02:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16101v1",
    "title": "Uniqueness of star central configurations in the $5$-body problem",
    "authors": [
      "Leasly A. Campa-Raymundo",
      "Luis Franco-Pérez"
    ],
    "abstract": "In this study, we present a rigorous analytical proof of the uniqueness of\ncentral configurations for the five-body problem, assuming that all five masses\nare equal and positioned at the vertices of a planar polygon. We consider\nconfigurations in which the bodies are equally spaced in angular position\nrelative to the center of mass, and aim to determine whether a central\nconfiguration arises under these constraints. We prove that the only central\nconfiguration that satisfies these conditions occurs when the five bodies form\na regular pentagon. Our approach is entirely analytical, relying on algebraic\ntechniques rather than numerical approximations. By transforming the governing\nequations into a reduced system involving only two variables, we analyze the\nsolution space over a significant and carefully bounded domain. This domain is\ndivided into sixteen disjoint regions, within which we rule out additional\nsolutions through explicit algebraic arguments. Our results confirm that the\nregular pentagonal configuration is the only central configuration in this\nsymmetric five-body scenario.",
    "pdf_url": "http://arxiv.org/pdf/2505.16101v1",
    "published": "2025-05-22T01:02:44+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "70F10, 70F15"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16100v1",
    "title": "BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research",
    "authors": [
      "Zifeng Wang",
      "Benjamin Danek",
      "Jimeng Sun"
    ],
    "abstract": "Validating scientific hypotheses is a central challenge in biomedical\nresearch, and remains difficult for artificial intelligence (AI) agents due to\nthe complexity of real-world data analysis and evidence interpretation. In this\nwork, we present BioDSA-1K, a benchmark designed to evaluate AI agents on\nrealistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K\nconsists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans,\ncurated from over 300 published biomedical studies to reflect the structure and\nreasoning found in authentic research workflows. Each task includes a\nstructured hypothesis derived from the original study's conclusions, expressed\nin the affirmative to reflect the language of scientific reporting, and one or\nmore pieces of supporting evidence grounded in empirical data tables. While\nthese hypotheses mirror published claims, they remain testable using standard\nstatistical or machine learning methods. The benchmark enables evaluation along\nfour axes: (1) hypothesis decision accuracy, (2) alignment between evidence and\nconclusion, (3) correctness of the reasoning process, and (4) executability of\nthe AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable\nhypotheses: cases where the available data are insufficient to support or\nrefute a claim, reflecting a common yet underexplored scenario in real-world\nscience. We propose BioDSA-1K as a foundation for building and evaluating\ngeneralizable, trustworthy AI agents for biomedical discovery.",
    "pdf_url": "http://arxiv.org/pdf/2505.16100v1",
    "published": "2025-05-22T01:02:21+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16099v2",
    "title": "Reinforcement Learning for Stock Transactions",
    "authors": [
      "Ziyi Zhou",
      "Nicholas Stern",
      "Julien Laasri"
    ],
    "abstract": "Much research has been done to analyze the stock market. After all, if one\ncan determine a pattern in the chaotic frenzy of transactions, then they could\nmake a hefty profit from capitalizing on these insights. As such, the goal of\nour project was to apply reinforcement learning (RL) to determine the best time\nto buy a stock within a given time frame. With only a few adjustments, our\nmodel can be extended to identify the best time to sell a stock as well. In\norder to use the format of free, real-world data to train the model, we define\nour own Markov Decision Process (MDP) problem. These two papers [5] [6] helped\nus in formulating the state space and the reward system of our MDP problem. We\ntrain a series of agents using Q-Learning, Q-Learning with linear function\napproximation, and deep Q-Learning. In addition, we try to predict the stock\nprices using machine learning regression and classification models. We then\ncompare our agents to see if they converge on a policy, and if so, which one\nlearned the best policy to maximize profit on the stock market.",
    "pdf_url": "http://arxiv.org/pdf/2505.16099v2",
    "published": "2025-05-22T01:00:57+00:00",
    "categories": [
      "cs.LG",
      "68T05",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17130v1",
    "title": "Acceleration of enzymatic reaction-diffusion kinetics by intermediate state",
    "authors": [
      "Akihiro Fukuda",
      "Yohei Nakayama",
      "Shoichi Toyabe"
    ],
    "abstract": "Biological molecular motors are high-performance nanomachines that convert\nchemical energy into mechanical motion via chemomechanical coupling. Their\nreaction cycles typically comprise a series of intermediate chemical states\nbetween the initial and final primary states. However, the influence of these\nintermediate states on motor performance has not yet been fully explored. In\nthis study, we investigate the impact of intermediate states on the motor\nkinetics using a reaction-diffusion model. In most cases, the intermediate\nstates accelerate the motor by lowering the effective barrier height. This\nacceleration is particularly pronounced when an external load is applied to the\nmotor, implying the practical importance of the intermediate states. The\nintermediate states can also slow down the reaction in some cases, such as the\nslow reaction limit with asymmetric kinetics. Our findings provide practical\ninsights into the design principles behind the high performance of biological\nmolecular motors, as well as the development of efficient artificial molecular\nmotors.",
    "pdf_url": "http://arxiv.org/pdf/2505.17130v1",
    "published": "2025-05-22T01:00:46+00:00",
    "categories": [
      "physics.bio-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16098v1",
    "title": "Dimension-adapted Momentum Outscales SGD",
    "authors": [
      "Damien Ferbach",
      "Katie Everett",
      "Gauthier Gidel",
      "Elliot Paquette",
      "Courtney Paquette"
    ],
    "abstract": "We investigate scaling laws for stochastic momentum algorithms with small\nbatch on the power law random features model, parameterized by data complexity,\ntarget complexity, and model size. When trained with a stochastic momentum\nalgorithm, our analysis reveals four distinct loss curve shapes determined by\nvarying data-target complexities. While traditional stochastic gradient descent\nwith momentum (SGD-M) yields identical scaling law exponents to SGD,\ndimension-adapted Nesterov acceleration (DANA) improves these exponents by\nscaling momentum hyperparameters based on model size and data complexity. This\noutscaling phenomenon, which also improves compute-optimal scaling behavior, is\nachieved by DANA across a broad range of data and target complexities, while\ntraditional methods fall short. Extensive experiments on high-dimensional\nsynthetic quadratics validate our theoretical predictions and large-scale text\nexperiments with LSTMs show DANA's improved loss exponents over SGD hold in a\npractical setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.16098v1",
    "published": "2025-05-22T00:58:50+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16097v1",
    "title": "TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials",
    "authors": [
      "Zifeng Wang",
      "Qiao Jin",
      "Jiacheng Lin",
      "Junyi Gao",
      "Jathurshan Pradeepkumar",
      "Pengcheng Jiang",
      "Benjamin Danek",
      "Zhiyong Lu",
      "Jimeng Sun"
    ],
    "abstract": "Developing artificial intelligence (AI) for vertical domains requires a solid\ndata foundation for both training and evaluation. In this work, we introduce\nTrialPanorama, a large-scale, structured database comprising 1,657,476 clinical\ntrial records aggregated from 15 global sources. The database captures key\naspects of trial design and execution, including trial setups, interventions,\nconditions, biomarkers, and outcomes, and links them to standard biomedical\nontologies such as DrugBank and MedDRA. This structured and ontology-grounded\ndesign enables TrialPanorama to serve as a unified, extensible resource for a\nwide range of clinical trial tasks, including trial planning, design, and\nsummarization. To demonstrate its utility, we derive a suite of benchmark tasks\ndirectly from the TrialPanorama database. The benchmark spans eight tasks\nacross two categories: three for systematic review (study search, study\nscreening, and evidence summarization) and five for trial design (arm design,\neligibility criteria, endpoint selection, sample size estimation, and trial\ncompletion assessment). The experiments using five state-of-the-art large\nlanguage models (LLMs) show that while general-purpose LLMs exhibit some\nzero-shot capability, their performance is still inadequate for high-stakes\nclinical trial workflows. We release TrialPanorama database and the benchmark\nto facilitate further research on AI for clinical trials.",
    "pdf_url": "http://arxiv.org/pdf/2505.16097v1",
    "published": "2025-05-22T00:58:43+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16096v1",
    "title": "Cosmos: A CXL-Based Full In-Memory System for Approximate Nearest Neighbor Search",
    "authors": [
      "Seoyoung Ko",
      "Hyunjeong Shim",
      "Wanju Doh",
      "Sungmin Yun",
      "Jinin So",
      "Yongsuk Kwon",
      "Sang-Soo Park",
      "Si-Dong Roh",
      "Minyong Yoon",
      "Taeksang Song",
      "Jung Ho Ahn"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is crucial for improving the quality of\nlarge language models by injecting proper contexts extracted from external\nsources. RAG requires high-throughput, low-latency Approximate Nearest Neighbor\nSearch (ANNS) over billion-scale vector databases. Conventional DRAM/SSD\nsolutions face capacity/latency limits, whereas specialized hardware or RDMA\nclusters lack flexibility or incur network overhead. We present Cosmos,\nintegrating general-purpose cores within CXL memory devices for full ANNS\noffload and introducing rank-level parallel distance computation to maximize\nmemory bandwidth. We also propose an adjacency-aware data placement that\nbalances search loads across CXL devices based on inter-cluster proximity.\nEvaluations on SIFT1B and DEEP1B traces show that Cosmos achieves up to 6.72x\nhigher throughput than the baseline CXL system and 2.35x over a\nstate-of-the-art CXL-based solution, demonstrating scalability for RAG\npipelines.",
    "pdf_url": "http://arxiv.org/pdf/2505.16096v1",
    "published": "2025-05-22T00:45:32+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16095v1",
    "title": "Towards Stream-Based Monitoring for EVM Networks",
    "authors": [
      "Emanuel Onica",
      "Claudiu-Nicu Bărbieru",
      "Andrei Arusoaie",
      "Oana-Otilia Captarencu",
      "Ciprian Amariei"
    ],
    "abstract": "We believe that leveraging real-time blockchain operational data is of\nparticular interest in the context of the current rapid expansion of rollup\nnetworks in the Ethereum ecosystem. Given the compatible but also competing\nground that rollups offer for applications, stream-based monitoring can be of\nuse both to developers and to EVM networks governance. In this paper, we\ndiscuss this perspective and propose a basic monitoring pipeline.",
    "pdf_url": "http://arxiv.org/pdf/2505.16095v1",
    "published": "2025-05-22T00:34:41+00:00",
    "categories": [
      "cs.PF",
      "cs.DC"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2505.16094v1",
    "title": "A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization",
    "authors": [
      "Ziqing Wang",
      "Kexin Zhang",
      "Zihan Zhao",
      "Yibo Wen",
      "Abhishek Pandey",
      "Han Liu",
      "Kaize Ding"
    ],
    "abstract": "Large language models (LLMs) are introducing a paradigm shift in molecular\ndiscovery by enabling text-guided interaction with chemical spaces through\nnatural language, symbolic notations, with emerging extensions to incorporate\nmulti-modal inputs. To advance the new field of LLM for molecular discovery,\nthis survey provides an up-to-date and forward-looking review of the emerging\nuse of LLMs for two central tasks: molecule generation and molecule\noptimization. Based on our proposed taxonomy for both problems, we analyze\nrepresentative techniques in each category, highlighting how LLM capabilities\nare leveraged across different learning settings. In addition, we include the\ncommonly used datasets and evaluation protocols. We conclude by discussing key\nchallenges and future directions, positioning this survey as a resource for\nresearchers working at the intersection of LLMs and molecular science. A\ncontinuously updated reading list is available at\nhttps://github.com/REAL-Lab-NU/Awesome-LLM-Centric-Molecular-Discovery.",
    "pdf_url": "http://arxiv.org/pdf/2505.16094v1",
    "published": "2025-05-22T00:26:27+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16093v3",
    "title": "Multiple chordal SLE($κ$) and quantum Calogero-Moser system",
    "authors": [
      "Jiaxin Zhang"
    ],
    "abstract": "We study multiple chordal SLE$(\\kappa)$ systems in a simply connected domain\n$\\Omega$, where $z_1, \\ldots, z_n \\in \\partial \\Omega$ are boundary starting\npoints and $q \\in \\partial \\Omega$ is an additional marked boundary point.\n  As a consequence of the domain Markov property and conformal invariance, we\nshow that the presence of the marked boundary point $q$ gives rise to a natural\nequivalence relation on partition functions. While these functions are not\nnecessarily conformally covariant, each equivalence class contains a\nconformally covariant representative.\n  Building on the framework introduced in \\cite{Dub07}, we demonstrate that in\nthe $\\mathbb{H}$-uniformization with $q = \\infty$, the partition functions\nsatisfy both the null vector equations and a dilatation equation with scaling\nexponent $d$.\n  Using techniques from the Coulomb gas formalism in conformal field theory, we\nconstruct two distinct families of solutions, each indexed by a topological\nlink pattern of type $(n, m)$ with $2m \\leq n$.\n  In the special case $\\Omega = \\mathbb{H}$ and $q = \\infty$, we further show\nthat these partition functions correspond to eigenstates of the quantum\nCalogero-Moser system, thereby extending the known correspondence beyond the\nstandard $(2n, n)$ setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.16093v3",
    "published": "2025-05-22T00:24:32+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.CV",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16092v2",
    "title": "Spontaneous generation of athermal phonon bursts within bulk silicon causing excess noise, low energy background events and quasiparticle poisoning in superconducting sensors",
    "authors": [
      "C. L. Chang",
      "Y. -Y. Chang",
      "M. Garcia-Sciveres",
      "W. Guo",
      "S. A. Hertel",
      "X. Li",
      "J. Lin",
      "M. Lisovenko",
      "R. Mahapatra",
      "W. Matava",
      "D. N. McKinsey",
      "P. K. Patel",
      "B. Penning",
      "M. Platt",
      "M. Pyle",
      "Y. Qi",
      "M. Reed",
      "I. Rydstrom",
      "R. K. Romani",
      "B. Sadoulet",
      "B. Serfass",
      "P. Sorensen",
      "B. Suerfu",
      "V. Velan",
      "G. Wang",
      "Y. Wang",
      "M. R. Williams",
      "V. G. Yefremenko"
    ],
    "abstract": "Solid state phonon detectors used in the search for dark matter or coherent\nneutrino nucleus interactions (CE$\\nu$NS) require excellent energy resolution\n(eV-scale or below) and low backgrounds to meet their science objectives.\nUnfortunately, an unknown source of phonon bursts (the low energy excess, or\n``LEE'') both dominates all other above threshold background sources and\nproduces shot noise from sub-threshold bursts which greatly exceeds all\nfundamental noise sources. In this paper, we measure these phonon bursts for 12\ndays after cool down in two nearly identical multi-phonon sensor channel\n1cm$^2$ silicon detectors which differ only in the thickness of their substrate\n(1 mm vs 4 mm thick). We find that both the correlated shot noise and near\nthreshold shared LEE relax with time since cooldown. Additionally, we show that\nboth shot noise and LEE rates scale linearly with substrate thickness. When\ncombined with previous measurements of other silicon phonon detectors with\ndifferent substrate geometries and mechanical support strategies, these\nmeasurements strongly suggest that the dominant source of both above and below\nthreshold LEE is the bulk substrate. By monitoring the relation between bias\npower and excess phonon shot noise we estimate that $\\varepsilon =\n\\frac{<E^2>}{<E>}$ for sub-threshold noise events is $0.68 \\pm 0.38$ meV. In\nour final dataset, we report a world-leading energy resolution of 258.5$\\pm$0.4\nmeV in the 1mm thick detector. Simple calculations suggest that these Si\nsubstrate phonon bursts are likely the dominant source of quasi-particle\npoisoning in superconducting qubits and sensors that are operated in well\nshielded and vibration free environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16092v2",
    "published": "2025-05-22T00:20:30+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.17129v2",
    "title": "Multiple chordal SLE(0) and classical Calogero-Moser system",
    "authors": [
      "Jiaxin Zhang"
    ],
    "abstract": "We develop a general theory of multiple chordal $\\mathrm{SLE}(0)$ systems of\ntype $(n, m)$ for positive integers $n$ and $m$ with $m \\leq \\lfloor n/2\n\\rfloor$, extending the construction of~\\cite{ABKM20} beyond the previously\nstudied case $n = 2m$.\n  By applying integrals of motion associated with the Loewner evolution, we\nshow that, in the $\\mathbb{H}$-uniformization with the marked point $q =\n\\infty$, the traces of type $(n, m)$ multiple chordal $\\mathrm{SLE}(0)$ systems\ncorrespond to the real locus of real rational functions with $n$ real simple\ncritical points, $m$ simple poles, and a pole of order $n - 2m + 1$ at\ninfinity.\n  Furthermore, we demonstrate that, under a common capacity parametrization,\nthe Loewner dynamics evolve according to the classical Calogero-Moser\nHamiltonian.",
    "pdf_url": "http://arxiv.org/pdf/2505.17129v2",
    "published": "2025-05-22T00:18:11+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.CV",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16091v4",
    "title": "OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates",
    "authors": [
      "Jinpei Guo",
      "Yifei Ji",
      "Zheng Chen",
      "Kai Liu",
      "Min Liu",
      "Wang Rao",
      "Wenbo Li",
      "Yong Guo",
      "Yulun Zhang"
    ],
    "abstract": "Pretrained latent diffusion models have shown strong potential for lossy\nimage compression, owing to their powerful generative priors. Most existing\ndiffusion-based methods reconstruct images by iteratively denoising from random\nnoise, guided by compressed latent representations. While these approaches have\nachieved high reconstruction quality, their multi-step sampling process incurs\nsubstantial computational overhead. Moreover, they typically require training\nseparate models for different compression bit-rates, leading to significant\ntraining and storage costs. To address these challenges, we propose a one-step\ndiffusion codec across multiple bit-rates. termed OSCAR. Specifically, our\nmethod views compressed latents as noisy variants of the original latents,\nwhere the level of distortion depends on the bit-rate. This perspective allows\nthem to be modeled as intermediate states along a diffusion trajectory. By\nestablishing a mapping from the compression bit-rate to a pseudo diffusion\ntimestep, we condition a single generative model to support reconstructions at\nmultiple bit-rates. Meanwhile, we argue that the compressed latents retain rich\nstructural information, thereby making one-step denoising feasible. Thus, OSCAR\nreplaces iterative sampling with a single denoising pass, significantly\nimproving inference efficiency. Extensive experiments demonstrate that OSCAR\nachieves superior performance in both quantitative and visual quality metrics.\nThe code and models will be released at https://github.com/jp-guo/OSCAR.",
    "pdf_url": "http://arxiv.org/pdf/2505.16091v4",
    "published": "2025-05-22T00:14:12+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16090v1",
    "title": "Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance",
    "authors": [
      "Dominick Kubica",
      "Dylan T. Gordon",
      "Nanami Emura",
      "Derleen Saini",
      "Charlie Goldenberg"
    ],
    "abstract": "As of 2025, Generative Artificial Intelligence (GenAI) has become a central\ntool for productivity across industries. Beyond text generation, GenAI now\nplays a critical role in coding, data analysis, and research workflows. As\nlarge language models (LLMs) continue to evolve, it is essential to assess the\nreliability and accuracy of their outputs, especially in specialized,\nhigh-stakes domains like finance. Most modern LLMs transform text into\nnumerical vectors, which are used in operations such as cosine similarity\nsearches to generate responses. However, this abstraction process can lead to\nmisinterpretation of emotional tone, particularly in nuanced financial\ncontexts. While LLMs generally excel at identifying sentiment in everyday\nlanguage, these models often struggle with the nuanced, strategically ambiguous\nlanguage found in earnings call transcripts. Financial disclosures frequently\nembed sentiment in hedged statements, forward-looking language, and\nindustry-specific jargon, making it difficult even for human analysts to\ninterpret consistently, let alone AI models. This paper presents findings from\nthe Santa Clara Microsoft Practicum Project, led by Professor Charlie\nGoldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's\nChatGPT, Google's Gemini, and traditional machine learning models for sentiment\nanalysis of financial text. Using Microsoft earnings call transcripts, the\nanalysis assesses how well LLM-derived sentiment correlates with market\nsentiment and stock movements and evaluates the accuracy of model outputs.\nPrompt engineering techniques are also examined to improve sentiment analysis\nresults. Visualizations of sentiment consistency are developed to evaluate\nalignment between tone and stock performance, with sentiment trends analyzed\nacross Microsoft's lines of business to determine which segments exert the\ngreatest influence.",
    "pdf_url": "http://arxiv.org/pdf/2505.16090v1",
    "published": "2025-05-22T00:09:11+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16089v1",
    "title": "\"If anybody finds out you are in BIG TROUBLE\": Understanding Children's Hopes, Fears, and Evaluations of Generative AI",
    "authors": [
      "Aayushi Dangol",
      "Robert Wolfe",
      "Daeun Yoo",
      "Arya Thiruvillakkat",
      "Ben Chickadel",
      "Julie A. Kientz"
    ],
    "abstract": "As generative artificial intelligence (genAI) increasingly mediates how\nchildren learn, communicate, and engage with digital content, understanding\nchildren's hopes and fears about this emerging technology is crucial. In a\npilot study with 37 fifth-graders, we explored how children (ages 9-10)\nenvision genAI and the roles they believe it should play in their daily life.\nOur findings reveal three key ways children envision genAI: as a companion\nproviding guidance, a collaborator working alongside them, and a task automator\nthat offloads responsibilities. However, alongside these hopeful views,\nchildren expressed fears about overreliance, particularly in academic settings,\nlinking it to fears of diminished learning, disciplinary consequences, and\nlong-term failure. This study highlights the need for child-centric AI design\nthat balances these tensions, empowering children with the skills to critically\nengage with and navigate their evolving relationships with digital\ntechnologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16089v1",
    "published": "2025-05-22T00:07:44+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16088v2",
    "title": "Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning",
    "authors": [
      "Gagan Bhatia",
      "Maxime Peyrard",
      "Wei Zhao"
    ],
    "abstract": "Modern BPE tokenizers often split calendar dates into meaningless fragments,\ne.g., 20250312 $\\rightarrow$ 202, 503, 12, inflating token counts and obscuring\nthe inherent structure needed for robust temporal reasoning. In this work, we\n(1) introduce a simple yet interpretable metric, termed date fragmentation\nratio, that measures how faithfully a tokenizer preserves multi-digit date\ncomponents; (2) release DateAugBench, a suite of 6500 examples spanning three\ntemporal reasoning tasks: context-based date resolution, format-invariance\npuzzles, and date arithmetic across historical, contemporary, and future time\nperiods; and (3) through layer-wise probing and causal attention-hop analyses,\nuncover an emergent date-abstraction mechanism whereby large language models\nstitch together the fragments of month, day, and year components for temporal\nreasoning. Our experiments show that excessive fragmentation correlates with\naccuracy drops of up to 10 points on uncommon dates like historical and\nfuturistic dates. Further, we find that the larger the model, the faster the\nemergent date abstraction that heals date fragments is accomplished. Lastly, we\nobserve a reasoning path that LLMs follow to assemble date fragments, typically\ndiffering from human interpretation (year $\\rightarrow$ month $\\rightarrow$\nday). Our datasets and code are made publicly available\n\\href{https://github.com/gagan3012/date-fragments}{here}.",
    "pdf_url": "http://arxiv.org/pdf/2505.16088v2",
    "published": "2025-05-22T00:06:29+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16087v1",
    "title": "Event-based Reconfiguration Control for Time-varying Formation of Robot Swarms in Narrow Spaces",
    "authors": [
      "Duy-Nam Bui",
      "Manh Duong Phung",
      "Hung Pham Duy"
    ],
    "abstract": "This study proposes an event-based reconfiguration control to navigate a\nrobot swarm through challenging environments with narrow passages such as\nvalleys, tunnels, and corridors. The robot swarm is modeled as an undirected\ngraph, where each node represents a robot capable of collecting real-time data\non the environment and the states of other robots in the formation. This data\nserves as the input for the controller to provide dynamic adjustments between\nthe desired and straight-line configurations. The controller incorporates a set\nof behaviors, designed using artificial potential fields, to meet the\nrequirements of goal-oriented motion, formation maintenance, tailgating, and\ncollision avoidance. The stability of the formation control is guaranteed via\nthe Lyapunov theorem. Simulation and comparison results show that the proposed\ncontroller not only successfully navigates the robot swarm through narrow\nspaces but also outperforms other established methods in key metrics including\nthe success rate, heading order, speed, travel time, and energy efficiency.\nSoftware-in-the-loop tests have also been conducted to validate the\ncontroller's applicability in practical scenarios. The source code of the\ncontroller is available at https://github.com/duynamrcv/erc.",
    "pdf_url": "http://arxiv.org/pdf/2505.16087v1",
    "published": "2025-05-22T00:04:46+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16086v2",
    "title": "Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development",
    "authors": [
      "Ming Shen",
      "Raphael Shu",
      "Anurag Pratik",
      "James Gung",
      "Yubin Ge",
      "Monica Sunkara",
      "Yi Zhang"
    ],
    "abstract": "We have seen remarkable progress in large language models (LLMs) empowered\nmulti-agent systems solving complex tasks necessitating cooperation among\nexperts with diverse skills. However, optimizing LLM-based multi-agent systems\nremains challenging. In this work, we perform an empirical case study on group\noptimization of role-based multi-agent systems utilizing natural language\nfeedback for challenging software development tasks under various evaluation\ndimensions. We propose a two-step agent prompts optimization pipeline:\nidentifying underperforming agents with their failure explanations utilizing\ntextual feedback and then optimizing system prompts of identified agents\nutilizing failure explanations. We then study the impact of various\noptimization settings on system performance with two comparison groups: online\nagainst offline optimization and individual against group optimization. For\ngroup optimization, we study two prompting strategies: one-pass and multi-pass\nprompting optimizations. Overall, we demonstrate the effectiveness of our\noptimization method for role-based multi-agent systems tackling software\ndevelopment tasks evaluated on diverse evaluation dimensions, and we\ninvestigate the impact of diverse optimization settings on group behaviors of\nthe multi-agent systems to provide practical insights for future development.",
    "pdf_url": "http://arxiv.org/pdf/2505.16086v2",
    "published": "2025-05-22T00:00:27+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  }
]