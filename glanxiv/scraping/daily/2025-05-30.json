[
  {
    "id": "http://arxiv.org/abs/2506.00314v1",
    "title": "FACE: A Fine-grained Reference Free Evaluator for Conversational Recommender Systems",
    "authors": [
      "Hideaki Joko",
      "Faegheh Hasibi"
    ],
    "abstract": "A systematic, reliable, and low-cost evaluation of Conversational Recommender\nSystems (CRSs) remains an open challenge. Existing automatic CRS evaluation\nmethods are proven insufficient for evaluating the dynamic nature of\nrecommendation conversations. This work proposes FACE: a Fine-grained,\nAspect-based Conversation Evaluation method that provides evaluation scores for\ndiverse turn and dialogue level qualities of recommendation conversations. FACE\nis reference-free and shows strong correlation with human judgments, achieving\nsystem correlation of 0.9 and turn/dialogue-level of 0.5, outperforming\nstate-of-the-art CRS evaluation methods by a large margin. Additionally, unlike\nexisting LLM-based methods that provide single uninterpretable scores, FACE\nprovides insights into the system performance and enables identifying and\nlocating problems within conversations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00314v1",
    "published": "2025-05-30T23:54:13+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00313v1",
    "title": "Data Flows in You: Benchmarking and Improving Static Data-flow Analysis on Binary Executables",
    "authors": [
      "Nicolaas Weideman",
      "Sima Arasteh",
      "Mukund Raghothaman",
      "Jelena Mirkovic",
      "Christophe Hauser"
    ],
    "abstract": "Data-flow analysis is a critical component of security research.\nTheoretically, accurate data-flow analysis in binary executables is an\nundecidable problem, due to complexities of binary code. Practically, many\nbinary analysis engines offer some data-flow analysis capability, but we lack\nunderstanding of the accuracy of these analyses, and their limitations. We\naddress this problem by introducing a labeled benchmark data set, including\n215,072 microbenchmark test cases, mapping to 277,072 binary executables,\ncreated specifically to evaluate data-flow analysis implementations.\nAdditionally, we augment our benchmark set with dynamically-discovered data\nflows from 6 real-world executables. Using our benchmark data set, we evaluate\nthree state of the art data-flow analysis implementations, in angr, Ghidra and\nMiasm and discuss their very low accuracy and reasons behind it. We further\npropose three model extensions to static data-flow analysis that significantly\nimprove accuracy, achieving almost perfect recall (0.99) and increasing\nprecision from 0.13 to 0.32. Finally, we show that leveraging these model\nextensions in a vulnerability-discovery context leads to a tangible improvement\nin vulnerable instruction identification.",
    "pdf_url": "http://arxiv.org/pdf/2506.00313v1",
    "published": "2025-05-30T23:49:57+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00312v1",
    "title": "An evaluation of LLMs for generating movie reviews: GPT-4o, Gemini-2.0 and DeepSeek-V3",
    "authors": [
      "Brendan Sands",
      "Yining Wang",
      "Chenhao Xu",
      "Yuxuan Zhou",
      "Lai Wei",
      "Rohitash Chandra"
    ],
    "abstract": "Large language models (LLMs) have been prominent in various tasks, including\ntext generation and summarisation. The applicability of LLMs to the generation\nof product reviews is gaining momentum, paving the way for the generation of\nmovie reviews. In this study, we propose a framework that generates movie\nreviews using three LLMs (GPT-4o, DeepSeek-V3, and Gemini-2.0), and evaluate\ntheir performance by comparing the generated outputs with IMDb user reviews. We\nuse movie subtitles and screenplays as input to the LLMs and investigate how\nthey affect the quality of reviews generated. We review the LLM-based movie\nreviews in terms of vocabulary, sentiment polarity, similarity, and thematic\nconsistency in comparison to IMDB user reviews. The results demonstrate that\nLLMs are capable of generating syntactically fluent and structurally complete\nmovie reviews. Nevertheless, there is still a noticeable gap in emotional\nrichness and stylistic coherence between LLM-generated and IMDb reviews,\nsuggesting that further refinement is needed to improve the overall quality of\nmovie review generation. We provided a survey-based analysis where participants\nwere told to distinguish between LLM and IMDb user reviews. The results show\nthat LLM-generated reviews are difficult to distinguish from IMDB user reviews.\nWe found that DeepSeek-V3 produced the most balanced reviews, closely matching\nIMDb reviews. GPT-4o overemphasised positive emotions, while Gemini-2.0\ncaptured negative emotions better but showed excessive emotional intensity.",
    "pdf_url": "http://arxiv.org/pdf/2506.00312v1",
    "published": "2025-05-30T23:45:53+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00311v1",
    "title": "Asteroseismology and Universal Relations in Neutron Stars with Gravitationally Bound Dark Matter",
    "authors": [
      "Ankit Kumar",
      "Hajime Sotani"
    ],
    "abstract": "We investigate the structural, dynamical, and oscillatory properties of\nneutron stars admixed with dark matter, modeled via a single-fluid formalism\nwhere dark matter interacts with nuclear matter through an effective\nHiggs-portal coupling. Employing three relativistic mean-field nuclear matter\nequations of state-IOPB-I, BigApple, and NL3- we incorporate a physically\nmotivated dark matter number density profile that scales with baryon density\nand is controlled by two parameters: a scaling factor $\\alpha M_\\chi$\n($M_{\\chi}$ being the mass of dark matter particle) and a steepness index\n$\\beta$. We construct equilibrium configurations and analyze their stability\nvia radial oscillations, finding that dark matter-induced gravitational\ncompression lowers the maximum mass and alters the radial mode spectrum in a\nnontrivial, $\\beta$-dependent fashion. We also compute the frequencies of\nnon-radial fluid oscillations under the relativistic Cowling approximation and\nanalyze the persistence of universal relations in the presence of dark matter.\nWhile deviations appear under extreme configurations, the overall structure of\nthese relations remains robust. Our findings offer a consistent framework to\nprobe dark matter effects on neutron star dynamics across a range of realistic\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2506.00311v1",
    "published": "2025-05-30T23:45:09+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.05377v1",
    "title": "An Independent Discriminant Network Towards Identification of Counterfeit Images and Videos",
    "authors": [
      "Shayantani Kar",
      "B. Shresth Bhimrajka",
      "Aditya Kumar",
      "Sahil Gupta",
      "Sourav Ghosh",
      "Subhamita Mukherjee",
      "Shauvik Paul"
    ],
    "abstract": "Rapid spread of false images and videos on online platforms is an emerging\nproblem. Anyone may add, delete, clone or modify people and entities from an\nimage using various editing software which are readily available. This\ngenerates false and misleading proof to hide the crime. Now-a-days, these false\nand counterfeit images and videos are flooding on the internet. These spread\nfalse information. Many methods are available in literature for detecting those\ncounterfeit contents but new methods of counterfeiting are also evolving.\nGenerative Adversarial Networks (GAN) are observed to be one effective method\nas it modifies the context and definition of images producing plausible results\nvia image-to-image translation. This work uses an independent discriminant\nnetwork that can identify GAN generated image or video. A discriminant network\nhas been created using a convolutional neural network based on\nInceptionResNetV2. The article also proposes a platform where users can detect\nforged images and videos. This proposed work has the potential to help the\nforensics domain to detect counterfeit videos and hidden criminal evidence\ntowards the identification of criminal activities.",
    "pdf_url": "http://arxiv.org/pdf/2506.05377v1",
    "published": "2025-05-30T23:44:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00310v1",
    "title": "Chemotaxis-Driven Instabilities Govern Size, Shape and Migration Efficiency of Multicellular Clusters",
    "authors": [
      "Monika Sanoria",
      "Gema Malet-Engra",
      "Giorgio Scita",
      "Nir Gov",
      "Ajay Gopinathan"
    ],
    "abstract": "The collective chemotaxis of multicellular clusters is an important\nphenomenon in various physiological contexts, ranging from embryonic\ndevelopment to cancer metastasis. Such clusters often display interesting shape\ndynamics and instabilities, but their physical origin, functional benefits, and\nrole in overall chemotactic migration remain unclear. Here, we combine\ncomputational modeling and experimental observations of malignant lymphocyte\ncluster migration in vitro to understand how these dynamics arise from an\ninterplay of chemotactic response and inter-cellular interactions. Our\ncell-based computational model incorporates active propulsion of cells, contact\ninhibition of locomotion, chemoattractant response, as well as alignment,\nadhesive, and exclusion interactions between cells. We find that clusters\nremain fluid and maintain cohesive forward migration in low chemoattractant\ngradients. However, above a threshold gradient, clusters display an instability\ndriven by local cluster-shape dependent velocity differentials that causes them\nto elongate perpendicular to the gradient and eventually break apart.\nComparison with our in vitro data shows the predicted transition to the cluster\ninstability regime with increased gradient, as well as quantitative agreement\nwith key features such as cluster aspect ratio, orientation, and breaking\nfrequency. This instability naturally limits the size of multicellular\naggregates, and, in addition, clusters in the instability regime display\noptimal forward migration speeds, suggesting functional implications in vivo.\nOur work provides valuable insights into generic instabilities of chemotactic\nclusters, elucidates physical factors that could contribute to metastatic\nspreading, and can be extended to other living or synthetic systems of active\nclusters.",
    "pdf_url": "http://arxiv.org/pdf/2506.00310v1",
    "published": "2025-05-30T23:43:27+00:00",
    "categories": [
      "q-bio.TO",
      "cond-mat.soft"
    ],
    "primary_category": "q-bio.TO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00309v3",
    "title": "Evaluation of LLMs for mathematical problem solving",
    "authors": [
      "Ruonan Wang",
      "Runxi Wang",
      "Yunwen Shen",
      "Chengfeng Wu",
      "Qinglin Zhou",
      "Rohitash Chandra"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive performance on a range of\neducational tasks, but are still understudied for their potential to solve\nmathematical problems. In this study, we compare three prominent LLMs,\nincluding GPT-4o, DeepSeek-V3, and Gemini-2.0, on three mathematics datasets of\nvarying complexities (GSM8K, MATH500, and MIT Open Courseware datasets). We\ntake a five-dimensional approach based on the Structured Chain-of-Thought\n(SCoT) framework to assess final answer correctness, step completeness, step\nvalidity, intermediate calculation accuracy, and problem comprehension. The\nresults show that GPT-4o is the most stable and consistent in performance\nacross all the datasets, but particularly it performs outstandingly in\nhigh-level questions of the MIT Open Courseware dataset. DeepSeek-V3 is\ncompetitively strong in well-structured domains such as optimisation, but\nsuffers from fluctuations in accuracy in statistical inference tasks.\nGemini-2.0 shows strong linguistic understanding and clarity in well-structured\nproblems but performs poorly in multi-step reasoning and symbolic logic. Our\nerror analysis reveals particular deficits in each model: GPT-4o is at times\nlacking in sufficient explanation or precision; DeepSeek-V3 leaves out\nintermediate steps; and Gemini-2.0 is less flexible in mathematical reasoning\nin higher dimensions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00309v3",
    "published": "2025-05-30T23:37:37+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00308v1",
    "title": "MythTriage: Scalable Detection of Opioid Use Disorder Myths on a Video-Sharing Platform",
    "authors": [
      "Hayoung Jung",
      "Shravika Mittal",
      "Ananya Aatreya",
      "Navreet Kaur",
      "Munmun De Choudhury",
      "Tanushree Mitra"
    ],
    "abstract": "Understanding the prevalence of misinformation in health topics online can\ninform public health policies and interventions. However, measuring such\nmisinformation at scale remains a challenge, particularly for high-stakes but\nunderstudied topics like opioid-use disorder (OUD)--a leading cause of death in\nthe U.S. We present the first large-scale study of OUD-related myths on\nYouTube, a widely-used platform for health information. With clinical experts,\nwe validate 8 pervasive myths and release an expert-labeled video dataset. To\nscale labeling, we introduce MythTriage, an efficient triage pipeline that uses\na lightweight model for routine cases and defers harder ones to a\nhigh-performing, but costlier, large language model (LLM). MythTriage achieves\nup to 0.86 macro F1-score while estimated to reduce annotation time and\nfinancial cost by over 76% compared to experts and full LLM labeling. We\nanalyze 2.9K search results and 343K recommendations, uncovering how myths\npersist on YouTube and offering actionable insights for public health and\nplatform moderation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00308v1",
    "published": "2025-05-30T23:37:10+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00307v2",
    "title": "Lossless Token Sequence Compression via Meta-Tokens",
    "authors": [
      "John Harvill",
      "Ziwei Fan",
      "Hao Wang",
      "Luke Huan",
      "Anoop Deoras",
      "Yizhou Sun",
      "Hao Ding"
    ],
    "abstract": "Existing work on prompt compression for Large Language Models (LLM) focuses\non lossy methods that try to maximize the retention of semantic information\nthat is relevant to downstream tasks while significantly reducing the sequence\nlength. In this paper, we introduce a task-agnostic lossless compression\ntechnique similar to LZ77 that makes it possible to reduce the input token\nsequence length on average by 27\\% and 18\\% for the two evaluation tasks\nexplored here. Given that we use transformer-based LLMs, this equates to 47\\%\nand 33\\% less encoding computation, respectively, due to the quadratic nature\nof attention. The token sequence transformation is trivial to reverse and\nhighlights that no semantic information is lost in the process. We evaluate our\nproposed approach on two tasks that require strict preservation of\nsemantics/syntax and demonstrate that existing lossy compression methods\nperform poorly in this setting. We find that our lossless compression technique\nproduces only a small gap in performance compared to using the uncompressed\ninput and posit that larger models and an expanded computing budget would\nlikely erase the gap entirely.",
    "pdf_url": "http://arxiv.org/pdf/2506.00307v2",
    "published": "2025-05-30T23:32:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00306v1",
    "title": "Phase-based analysis and control of low Reynolds number aeroelastic flows",
    "authors": [
      "Chathura R. Sumanasiri",
      "Tulsi Ram Sahu",
      "Aditya G. Nair"
    ],
    "abstract": "Flutter in lightweight airfoils under unsteady flows presents a critical\nchallenge in aeroelastic stability and control. This study uncovers\nphase-localized mechanisms that drive the onset and suppression of flutter in a\nfreely pitching airfoil at low Reynolds number. By introducing targeted\nimpulsive stiffness perturbations, we identify critical phases that trigger\ninstability. Using phase-sensitivity functions, energy-transfer metrics, and\ndynamic mode decomposition, we show that flutter arises from phase lock-on\nbetween structural and fluid modes. Leveraging this insight, we design an\nenergy-optimal, phase-based control strategy that applies transient heaving\nmotions to disrupt synchronization and arrest unstable growth. This minimal,\ntime-localized control suppresses subharmonic amplification and restores stable\nperiodic motion.",
    "pdf_url": "http://arxiv.org/pdf/2506.00306v1",
    "published": "2025-05-30T23:28:49+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.00305v2",
    "title": "Learning Aerodynamics for the Control of Flying Humanoid Robots",
    "authors": [
      "Antonello Paolino",
      "Gabriele Nava",
      "Fabio Di Natale",
      "Fabio Bergonti",
      "Punith Reddy Vanteddu",
      "Donato Grassi",
      "Luca Riccobene",
      "Alex Zanotti",
      "Renato Tognaccini",
      "Gianluca Iaccarino",
      "Daniele Pucci"
    ],
    "abstract": "Robots with multi-modal locomotion are an active research field due to their\nversatility in diverse environments. In this context, additional actuation can\nprovide humanoid robots with aerial capabilities. Flying humanoid robots face\nchallenges in modeling and control, particularly with aerodynamic forces. This\npaper addresses these challenges from a technological and scientific\nstandpoint. The technological contribution includes the mechanical design of\niRonCub-Mk1, a jet-powered humanoid robot, optimized for jet engine\nintegration, and hardware modifications for wind tunnel experiments on humanoid\nrobots for precise aerodynamic forces and surface pressure measurements. The\nscientific contribution offers a comprehensive approach to model and control\naerodynamic forces using classical and learning techniques. Computational Fluid\nDynamics (CFD) simulations calculate aerodynamic forces, validated through wind\ntunnel experiments on iRonCub-Mk1. An automated CFD framework expands the\naerodynamic dataset, enabling the training of a Deep Neural Network and a\nlinear regression model. These models are integrated into a simulator for\ndesigning aerodynamic-aware controllers, validated through flight simulations\nand balancing experiments on the iRonCub-Mk1 physical prototype.",
    "pdf_url": "http://arxiv.org/pdf/2506.00305v2",
    "published": "2025-05-30T23:27:44+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00304v1",
    "title": "Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs",
    "authors": [
      "Payal Mohapatra",
      "Akash Pandey",
      "Xiaoyuan Zhang",
      "Qi Zhu"
    ],
    "abstract": "Unvoiced electromyography (EMG) is an effective communication tool for\nindividuals unable to produce vocal speech. However, most prior methods rely on\npaired voiced and unvoiced EMG signals, along with speech data, for EMG-to-text\nconversion, which is not practical for such individuals. Given the rise of\nlarge language models (LLMs) in speech recognition, we explore their potential\nto understand unvoiced speech. To this end, we address the challenge of\nlearning from unvoiced EMG alone and propose a novel EMG adaptor module that\nmaps EMG features into an LLM's input space, achieving an average word error\nrate (WER) of 0.49 on a closed-vocabulary unvoiced EMG-to-text task. Even with\na conservative data availability of just six minutes, our approach improves\nperformance over specialized models by nearly 20%. While LLMs have been shown\nto be extendable to new language modalities -- such as audio -- understanding\narticulatory biosignals like unvoiced EMG remains more challenging. This work\ntakes a crucial first step toward enabling LLMs to comprehend unvoiced speech\nusing surface EMG.",
    "pdf_url": "http://arxiv.org/pdf/2506.00304v1",
    "published": "2025-05-30T23:22:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00303v1",
    "title": "Dynamical gravitational Casimir-Polder interaction",
    "authors": [
      "Yongshun Hu",
      "Dan Wen"
    ],
    "abstract": "We explore the time-dependent Casimir-Polder-like quantum gravitational\ninteraction between a nonpointlike object and a gravitational Dirichlet\nboundary, i.e., the dynamical gravitational Casimir-Polder interaction, based\non the theory of linearized quantum gravity. We demonstrate that the dynamical\ninteraction potential is nonzero prior to the radiation, which is generated by\nthe gravitational vacuum-fluctuation-induced mass quadrupole of the object,\nbeing reflected by the gravitational boundary and back-reacted to the object\n(i.e., the mirror image of the object lies outside its causal region). This\nindicates the nonlocality of the fluctuating gravitational field in vacuum and\ncalls for a reevaluation of the inherent causality within the interaction.\nMoreover, the dynamical gravitational Casimir-Polder interaction can be either\nattractive or repulsive depending on the distance of the object with respect to\nthe boundary and the time of interaction. When the interaction time is\nsufficiently long for the system to approach asymptotic equilibrium, the\ndynamical gravitational Casimir-Polder interaction potential reduces to the\nstatic one, which is time-independent and consistently repulsive in both the\nnear and far regimes.",
    "pdf_url": "http://arxiv.org/pdf/2506.00303v1",
    "published": "2025-05-30T23:19:50+00:00",
    "categories": [
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.00302v2",
    "title": "Beyond Atomic Geometry Representations in Materials Science: A Human-in-the-Loop Multimodal Framework",
    "authors": [
      "Can Polat",
      "Erchin Serpedin",
      "Mustafa Kurban",
      "Hasan Kurban"
    ],
    "abstract": "Most materials science datasets are limited to atomic geometries (e.g., XYZ\nfiles), restricting their utility for multimodal learning and comprehensive\ndata-centric analysis. These constraints have historically impeded the adoption\nof advanced machine learning techniques in the field. This work introduces\nMultiCrystalSpectrumSet (MCS-Set), a curated framework that expands materials\ndatasets by integrating atomic structures with 2D projections and structured\ntextual annotations, including lattice parameters and coordination metrics.\nMCS-Set enables two key tasks: (1) multimodal property and summary prediction,\nand (2) constrained crystal generation with partial cluster supervision.\nLeveraging a human-in-the-loop pipeline, MCS-Set combines domain expertise with\nstandardized descriptors for high-quality annotation. Evaluations using\nstate-of-the-art language and vision-language models reveal substantial\nmodality-specific performance gaps and highlight the importance of annotation\nquality for generalization. MCS-Set offers a foundation for benchmarking\nmultimodal models, advancing annotation practices, and promoting accessible,\nversatile materials science datasets. The dataset and implementations are\navailable at https://github.com/KurbanIntelligenceLab/MultiCrystalSpectrumSet.",
    "pdf_url": "http://arxiv.org/pdf/2506.00302v2",
    "published": "2025-05-30T23:18:42+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00301v1",
    "title": "Unique Reconstruction From Mean-Field Measurements",
    "authors": [
      "Narcicegi Kiran",
      "Tiago Pereira"
    ],
    "abstract": "We address the inverse problem of reconstructing both the structure and\ndynamics of a network from mean-field measurements, which are linear\ncombinations of node states. This setting arises in applications where only a\nfew aggregated observations are available, making network inference\nchallenging. We focus on the case when the number of mean-field measurements is\nsmaller than the number of nodes. To tackle this ill-posed recovery problem, we\npropose a framework that combines localized initial perturbations with sparse\noptimization techniques. We derive sufficient conditions that guarantee the\nunique reconstruction of the network's adjacency matrix from mean-field data\nand enable recovery of node states and local governing dynamics. Numerical\nexperiments demonstrate the robustness of our approach across a range of\nsparsity and connectivity regimes. These results provide theoretical and\ncomputational foundations for inferring high-dimensional networked systems from\nlow-dimensional observations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00301v1",
    "published": "2025-05-30T23:18:38+00:00",
    "categories": [
      "math.DS",
      "physics.data-an",
      "37M99, 37N99, 15A29, 94A12, 65P99, 05C50, 90C25"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00300v1",
    "title": "Bosonic quantum error correction using squeezed Fock states",
    "authors": [
      "E. N. Bashmakova",
      "S. B. Korolev",
      "T. Yu. Golubeva"
    ],
    "abstract": "In the paper, we develop a bosonic quantum error correction code based on\nsqueezed Fock states. We compare our proposed code with one based on squeezed\nSchrodinger's cat states using the Knill-Laflamme cost function and the Petz\nmap fidelity. We demonstrate that squeezed Fock states are competitive in\nprotecting information in a channel with particle loss and dephasing.",
    "pdf_url": "http://arxiv.org/pdf/2506.00300v1",
    "published": "2025-05-30T23:18:18+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00299v1",
    "title": "Inference-Time Alignment of Diffusion Models with Evolutionary Algorithms",
    "authors": [
      "Purvish Jajal",
      "Nick John Eliopoulos",
      "Benjamin Shiue-Hal Chou",
      "George K. Thiruvathukal",
      "James C. Davis",
      "Yung-Hsiang Lu"
    ],
    "abstract": "Diffusion models are state-of-the-art generative models in various domains,\nyet their samples often fail to satisfy downstream objectives such as safety\nconstraints or domain-specific validity. Existing techniques for alignment\nrequire gradients, internal model access, or large computational budgets. We\nintroduce an inference-time alignment framework based on evolutionary\nalgorithms. We treat diffusion models as black-boxes and search their latent\nspace to maximize alignment objectives. Our method enables efficient\ninference-time alignment for both differentiable and non-differentiable\nalignment objectives across a range of diffusion models. On the DrawBench and\nOpen Image Preferences benchmark, our EA methods outperform state-of-the-art\ngradient-based and gradient-free inference-time methods. In terms of memory\nconsumption, we require 55% to 76% lower GPU memory than gradient-based\nmethods. In terms of running-time, we are 72% to 80% faster than gradient-based\nmethods. We achieve higher alignment scores over 50 optimization steps on Open\nImage Preferences than gradient-based and gradient-free methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00299v1",
    "published": "2025-05-30T23:14:31+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00298v1",
    "title": "Millimeter-wave observations of Euclid Deep Field South using the South Pole Telescope: A data release of temperature maps and catalogs",
    "authors": [
      "M. Archipley",
      "A. Hryciuk",
      "L. E. Bleem",
      "K. Kornoelje",
      "M. Klein",
      "A. J. Anderson",
      "B. Ansarinejad",
      "M. Aravena",
      "L. Balkenhol",
      "P. S. Barry",
      "K. Benabed",
      "A. N. Bender",
      "B. A. Benson",
      "F. Bianchini",
      "S. Bocquet",
      "F. R. Bouchet",
      "E. Camphuis",
      "M. G. Campitiello",
      "J. E. Carlstrom",
      "J. Cathey",
      "C. L. Chang",
      "S. C. Chapman",
      "P. Chaubal",
      "P. M. Chichura",
      "A. Chokshi",
      "T. -L. Chou",
      "A. Coerver",
      "T. M. Crawford",
      "C. Daley",
      "T. de Haan",
      "R. P. Deane",
      "K. R. Dibert",
      "M. A. Dobbs",
      "M. Doohan",
      "A. Doussot",
      "D. Dutcher",
      "W. Everett",
      "C. Feng",
      "K. R. Ferguson",
      "K. Fichman",
      "B. Floyd",
      "A. Foster",
      "S. Galli",
      "A. E. Gambrel",
      "R. W. Gardner",
      "F. Ge",
      "N. Goeckner-Wald",
      "A. Gonzalez",
      "S. Grandis",
      "T. R. Greve",
      "R. Gualtieri",
      "F. Guidi",
      "S. Guns",
      "N. W. Halverson",
      "R. Hill",
      "E. Hivon",
      "G. P. Holder",
      "W. L. Holzapfel",
      "J. C. Hood",
      "N. Huang",
      "F. Kéruzoré",
      "A. R. Khalife",
      "L. Knox",
      "M. Korman",
      "C. -L. Kuo",
      "K. Levy",
      "A. E. Lowitz",
      "C. Lu",
      "G. P. Lynch",
      "A. Maniyar",
      "E. S. Martsen",
      "F. Menanteau",
      "M. Millea",
      "J. Montgomery",
      "Y. Nakato",
      "T. Natoli",
      "G. I. Noble",
      "Y. Omori",
      "A. Ouellette",
      "Z. Pan",
      "K. A. Phadke",
      "A. W. Pollak",
      "K. Prabhu",
      "W. Quan",
      "S. Raghunathan",
      "M. Rahimi",
      "A. Rahlin",
      "C. L. Reichardt",
      "C. Reuter",
      "M. Rouble",
      "J. E. Ruhl",
      "E. Schiappucci",
      "A. Simpson",
      "J. A. Sobrin",
      "B. Stalder",
      "A. A. Stark",
      "N. Sulzenauer",
      "C. Tandoi",
      "B. Thorne",
      "C. Trendafilova",
      "C. Umilta",
      "J. D. Vieira",
      "A. Vitrier",
      "D. Vizgan",
      "Y. Wan",
      "A. Weiß",
      "N. Whitehorn",
      "W. L. K. Wu",
      "M. R. Young",
      "J. A. Zebrowski",
      "D. Zhou"
    ],
    "abstract": "Context. The South Pole Telescope third-generation camera (SPT-3G) has\nobserved over 10,000 square degrees of sky at 95, 150, and 220 GHz (3.3, 2.0,\n1.4 mm, respectively) overlapping the ongoing 14,000 square-degree Euclid Wide\nSurvey. The Euclid collaboration recently released Euclid Deep Field\nobservations in the first quick data release (Q1). Aims. With the goal of\nreleasing complementary millimeter-wave data and encouraging legacy science, we\nperformed dedicated observations of a 57-square-degree field overlapping the\nEuclid Deep Field South (EDF-S). Methods. The observing time totaled 20 days\nand we reached noise depths of 4.3, 3.8, and 13.2 $\\mu$K-arcmin at 95, 150, and\n220 GHz, respectively. Results. In this work we present the temperature maps\nand two catalogs constructed from these data. The emissive source catalog\ncontains 601 objects (334 inside EDF-S) with 54% synchrotron-dominated sources\nand 46% thermal dust emission-dominated sources. The 5$\\sigma$ detection\nthresholds are 1.7, 2.0, and 6.5 mJy in the three bands. The cluster catalog\ncontains 217 cluster candidates (121 inside EDF-S) with median mass\n$M_{500c}=2.12 \\times 10^{14} M_{\\odot}/h_{70}$ and median redshift $z$ = 0.70,\ncorresponding to an order-of-magnitude improvement in cluster density over\nprevious tSZ-selected catalogs in this region (3.81 clusters per square\ndegree). Conclusions. The overlap between SPT and Euclid data will enable a\nrange of multiwavelength studies of the aforementioned source populations. This\nwork serves as the first step towards joint projects between SPT and Euclid and\nprovides a rich dataset containing information on galaxies, clusters, and their\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00298v1",
    "published": "2025-05-30T23:04:53+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00297v1",
    "title": "Improving Protein Sequence Design through Designability Preference Optimization",
    "authors": [
      "Fanglei Xue",
      "Andrew Kubaney",
      "Zhichun Guo",
      "Joseph K. Min",
      "Ge Liu",
      "Yi Yang",
      "David Baker"
    ],
    "abstract": "Protein sequence design methods have demonstrated strong performance in\nsequence generation for de novo protein design. However, as the training\nobjective was sequence recovery, it does not guarantee designability--the\nlikelihood that a designed sequence folds into the desired structure. To bridge\nthis gap, we redefine the training objective by steering sequence generation\ntoward high designability. To do this, we integrate Direct Preference\nOptimization (DPO), using AlphaFold pLDDT scores as the preference signal,\nwhich significantly improves the in silico design success rate. To further\nrefine sequence generation at a finer, residue-level granularity, we introduce\nResidue-level Designability Preference Optimization (ResiDPO), which applies\nresidue-level structural rewards and decouples optimization across residues.\nThis enables direct improvement in designability while preserving regions that\nalready perform well. Using a curated dataset with residue-level annotations,\nwe fine-tune LigandMPNN with ResiDPO to obtain EnhancedMPNN, which achieves a\nnearly 3-fold increase in in silico design success rate (from 6.56% to 17.57%)\non a challenging enzyme design benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2506.00297v1",
    "published": "2025-05-30T23:02:51+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.05376v2",
    "title": "A Red Teaming Roadmap Towards System-Level Safety",
    "authors": [
      "Zifan Wang",
      "Christina Q. Knight",
      "Jeremy Kritz",
      "Willow E. Primack",
      "Julian Michael"
    ],
    "abstract": "Large Language Model (LLM) safeguards, which implement request refusals, have\nbecome a widely adopted mitigation strategy against misuse. At the intersection\nof adversarial machine learning and AI safety, safeguard red teaming has\neffectively identified critical vulnerabilities in state-of-the-art\nrefusal-trained LLMs. However, in our view the many conference submissions on\nLLM red teaming do not, in aggregate, prioritize the right research problems.\nFirst, testing against clear product safety specifications should take a higher\npriority than abstract social biases or ethical principles. Second, red teaming\nshould prioritize realistic threat models that represent the expanding risk\nlandscape and what real attackers might do. Finally, we contend that\nsystem-level safety is a necessary step to move red teaming research forward,\nas AI models present new threats as well as affordances for threat mitigation\n(e.g., detection and banning of malicious users) once placed in a deployment\ncontext. Adopting these priorities will be necessary in order for red teaming\nresearch to adequately address the slate of new threats that rapid AI advances\npresent today and will present in the very near future.",
    "pdf_url": "http://arxiv.org/pdf/2506.05376v2",
    "published": "2025-05-30T22:58:54+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00296v1",
    "title": "CRScore++: Reinforcement Learning with Verifiable Tool and AI Feedback for Code Review",
    "authors": [
      "Manav Nitin Kapadnis",
      "Atharva Naik",
      "Carolyn Rose"
    ],
    "abstract": "Reinforcement learning (RL) to improve code review comment generation\nrequires handling unstructured outputs, making reinforcement learning (RL)\nfeedback challenging. The two main RL approaches, namely RL with Verifiable\nFeedback (RLVR) and RL with AI Feedback (RLAIF), offer trade-offs: RLVR\nprovides reliable feedback for structured tasks like code generation, while\nRLAIF works for unstructured outputs but is subjective. We bridge this gap with\nCRScore++, an RL framework that leverages both LLM-based subjective feedback\nand verifiable signals for training. Extending CRScore, a code review\nevaluation metric integrating LLMs with verifiers like linters and code smell\ndetectors, CRScore++ transforms these signals into training rewards. We show\nthat CRScore++ improves a weaker student model through a combination of\nsupervised fine-tuning and RL critique from a stronger teacher model, thus\nenabling generalization to novel programming languages.",
    "pdf_url": "http://arxiv.org/pdf/2506.00296v1",
    "published": "2025-05-30T22:58:35+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00295v1",
    "title": "Extended uncertainty principle inspired black hole in a Gödel Universe",
    "authors": [
      "Reggie C. Pantig"
    ],
    "abstract": "We explore analytically the implications of a curvature-modified extended\nuncertainty principle (EUP) derived in a rotating G\\\"odel spacetime and apply\nit to the construction of a semiclassical black hole model. Adapting techniques\nfrom corpuscular black hole frameworks, we reinterpret the G\\\"odel-type\nuncertainty relation as an effective energy bound, leading to a modified lapse\nfunction with explicit dependence on the global rotation parameter $a$ and the\nradial coordinate $ r_0 $. Analytic expressions are derived for key\ngravitational features, including the event horizon, photon spherehere, shadow\nradius, and deflection angle, with curvature corrections scaling as $ a^{-2} $\nand $ r_0^2 / a^4 $. Series expansion in the limit $ a \\to \\infty $ shows that\nglobal rotation consistently increases all observables relative to the\nSchwarzschild case. Applying these results to astrophysical data, we use Event\nHorizon Telescope (EHT) measurements of Sgr A* and M87* to infer lower bounds\nof $ a/M \\sim 10^5 $, while solar system light-bending observations in the\nparametrized post-Newtonian (PPN) framework yield $ a / M_\\odot \\sim 5 \\times\n10^4 $. These large but finite values validate the asymptotic expansion and\nconfirm that G\\\"odel-type rotation remains observationally suppressed, yet\ntheoretically coherent. Our results demonstrate that global rotation, when\ntreated semiclassically via curvature-modified uncertainty, introduces\ndetectable signatures in principle, though well below current observational\nsensitivity. The framework offers a consistent path toward exploring the\nquantum-gravitational interplay between global geometry and local black hole\nstructure.",
    "pdf_url": "http://arxiv.org/pdf/2506.00295v1",
    "published": "2025-05-30T22:55:33+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.00294v1",
    "title": "Applying Vision Transformers on Spectral Analysis of Astronomical Objects",
    "authors": [
      "Luis Felipe Strano Moraes",
      "Ignacio Becker",
      "Pavlos Protopapas",
      "Guillermo Cabrera-Vives"
    ],
    "abstract": "We apply pre-trained Vision Transformers (ViTs), originally developed for\nimage recognition, to the analysis of astronomical spectral data. By converting\ntraditional one-dimensional spectra into two-dimensional image representations,\nwe enable ViTs to capture both local and global spectral features through\nspatial self-attention. We fine-tune a ViT pretrained on ImageNet using\nmillions of spectra from the SDSS and LAMOST surveys, represented as spectral\nplots. Our model is evaluated on key tasks including stellar object\nclassification and redshift ($z$) estimation, where it demonstrates strong\nperformance and scalability. We achieve classification accuracy higher than\nSupport Vector Machines and Random Forests, and attain $R^2$ values comparable\nto AstroCLIP's spectrum encoder, even when generalizing across diverse object\ntypes. These results demonstrate the effectiveness of using pretrained vision\nmodels for spectroscopic data analysis. To our knowledge, this is the first\napplication of ViTs to large-scale, which also leverages real spectroscopic\ndata and does not rely on synthetic inputs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00294v1",
    "published": "2025-05-30T22:53:45+00:00",
    "categories": [
      "astro-ph.IM",
      "cs.CV"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00293v1",
    "title": "Influence of X-ray Irradiation on the Magnetic and Structural Properties of Gadolinium Silicide Nanoparticles for Self-Regulating Hyperthermia",
    "authors": [
      "Samantha E. Smith",
      "Santiago Bermudez",
      "Pavan Chaitanya",
      "Zoe Boekelheide",
      "Jessika Rojas Marin",
      "Ravi L. Hadimani"
    ],
    "abstract": "Magnetic hyperthermia treatment (MHT) utilizes heat generated from magnetic\nnanoparticles (MNPs) under an alternating magnetic field (AMF) for therapeutic\napplications. Gadolinium silicide (Gd5Si4) has emerged as a promising MHT\ncandidate due to its self-regulating heating properties and potential\nbiocompatibility. However, the impact of high-dose X-ray irradiation on its\nmagnetic behavior remains uncertain. This study examines Gd5Si4 nanoparticles\nexposed to 36 and 72 kGy X-ray irradiation at a high-dose rate (120 Gy/min).\nWhile X-ray diffraction, scanning electron microscopy, and energy dispersive\nspectroscopy confirm no structural or compositional changes, transmission\nelectron microscopy reveals localized lattice distortions, along with\nobservable changes in magnetic properties, as evidenced in magnetization vs.\ntemperature and hysteresis measurements. Despite this, magnetocaloric\nproperties and specific loss power (SLP) remain unaffected. Our findings\nconfirm the stability of Gd5Si4 under high-dose X-ray irradiation, supporting\nits potential for radiotherapy (RT) and magnetocaloric cooling in deep-space\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00293v1",
    "published": "2025-05-30T22:53:43+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.med-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00292v1",
    "title": "Minimizing the number of edges in LC-equivalent graph states",
    "authors": [
      "Hemant Sharma",
      "Kenneth Goodenough",
      "Johannes Borregaard",
      "Filip Rozpędek",
      "Jonas Helsen"
    ],
    "abstract": "Graph states are a powerful class of entangled states with numerous\napplications in quantum communication and quantum computation. Local Clifford\n(LC) operations that map one graph state to another can alter the structure of\nthe corresponding graphs, including changing the number of edges. Here, we\ntackle the associated edge-minimization problem: finding graphs with the\nminimum number of edges in the LC-equivalence class of a given graph. Such\ngraphs are called minimum edge representatives (MER), and are crucial for\nminimizing the resources required to create a graph state. We leverage\nBouchet's algebraic formulation of LC-equivalence to encode the\nedge-minimization problem as an integer linear program (ILP). We further\npropose a simulated annealing (SA) approach guided by the local clustering\ncoefficient for edge minimization. We identify new MERs for graph states with\nup to 16 qubits by combining SA and ILP. We extend the ILP to weighted-edge\nminimization, where each edge has an associated weight, and prove that this\nproblem is NP-complete. Finally, we employ our tools to minimize resources\nrequired to create all-photonic generalized repeater graph states using fusion\noperations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00292v1",
    "published": "2025-05-30T22:49:45+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00291v2",
    "title": "Improving Code Switching with Supervised Fine Tuning and GELU Adapters",
    "authors": [
      "Linh Pham"
    ],
    "abstract": "There are few code switching datasets, labeled or unlabled, that exist today.\nAs a result, ASR requires new methods to utilize the vast monolingual data and\nmodels that exist. This paper uses OpenAI's open source ASR model, Whisper,\nwhich has been pre-trained on 680K hours of audio to perform monolingual ASR\ntasks. In Part 1, this paper examines how exploiting Whisper's monolingual\nability to individually tokenize training text, called \"Switching Tokenizers\nMethod\", improves transcription accuracy. In Part 2, we combine the Switching\nTokenizers Method from part 1 and train a GELU based adapter on the encoder.\nThese two methods reduced Total Mixed Error Rate (MER) to 9.4% for the ASCEND\ndataset, 6% for SEAME devman and 9.7% for SEAME devsge, outperforming current\nSoTA methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00291v2",
    "published": "2025-05-30T22:43:18+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.00290v1",
    "title": "DLM-One: Diffusion Language Models for One-Step Sequence Generation",
    "authors": [
      "Tianqi Chen",
      "Shujian Zhang",
      "Mingyuan Zhou"
    ],
    "abstract": "This paper introduces DLM-One, a score-distillation-based framework for\none-step sequence generation with continuous diffusion language models (DLMs).\nDLM-One eliminates the need for iterative refinement by aligning the scores of\na student model's outputs in the continuous token embedding space with the\nscore function of a pretrained teacher DLM. We investigate whether DLM-One can\nachieve substantial gains in sampling efficiency for language modeling. Through\ncomprehensive experiments on DiffuSeq -- a representative continuous DLM -- we\nshow that DLM-One achieves up to ~500x speedup in inference time while\nmaintaining competitive performance on benchmark text generation tasks used to\nevaluate the teacher models. We further analyze the method's empirical behavior\nacross multiple datasets, providing initial insights into its generality and\npractical applicability. Our findings position one-step diffusion as a\npromising direction for efficient, high-quality language generation and broader\nadoption of continuous diffusion models operating in embedding space for\nnatural language processing.",
    "pdf_url": "http://arxiv.org/pdf/2506.00290v1",
    "published": "2025-05-30T22:42:23+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00289v1",
    "title": "Modules and generalizations of Joyce vertex algebras",
    "authors": [
      "Chenjing Bu"
    ],
    "abstract": "Joyce vertex algebras are vertex algebra structures defined on the homology\nof certain $\\mathbb{C}$-linear moduli stacks, and are used to express\nwall-crossing formulae for Joyce's homological enumerative invariants. This\npaper studies the generalization of this construction to settings that come\nfrom non-linear enumerative problems. In the special case of orthosymplectic\nenumerative geometry, we obtain twisted modules for Joyce vertex algebras.\n  We expect that our construction will be useful for formulating wall-crossing\nformulae for enumerative invariants for non-linear moduli stacks. We include\nseveral variants of our construction that apply to different flavours of\nenumerative invariants, including Joyce's homological invariants, DT4\ninvariants, and a version of $K$-theoretic enumerative invariants.",
    "pdf_url": "http://arxiv.org/pdf/2506.00289v1",
    "published": "2025-05-30T22:41:02+00:00",
    "categories": [
      "math.AG",
      "math.QA"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00288v2",
    "title": "Emergent Abilities of Large Language Models under Continued Pretraining for Language Adaptation",
    "authors": [
      "Ahmed Elhady",
      "Eneko Agirre",
      "Mikel Artetxe"
    ],
    "abstract": "Continued pretraining (CPT) is a popular approach to adapt existing large\nlanguage models (LLMs) to new languages. When doing so, it is common practice\nto include a portion of English data in the mixture, but its role has not been\ncarefully studied to date. In this work, we show that including English does\nnot impact validation perplexity, yet it is critical for the emergence of\ndownstream capabilities in the target language. We introduce a\nlanguage-agnostic benchmark for in-context learning (ICL), which reveals\ncatastrophic forgetting early on CPT when English is not included. This in turn\ndamages the ability of the model to generalize to downstream prompts in the\ntarget language as measured by perplexity, even if it does not manifest in\nterms of accuracy until later in training, and can be tied to a big shift in\nthe model parameters. Based on these insights, we introduce curriculum learning\nand exponential moving average (EMA) of weights as effective alternatives to\nmitigate the need for English. All in all, our work sheds light into the\ndynamics by which emergent abilities arise when doing CPT for language\nadaptation, and can serve as a foundation to design more effective methods in\nthe future.",
    "pdf_url": "http://arxiv.org/pdf/2506.00288v2",
    "published": "2025-05-30T22:31:59+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00287v1",
    "title": "Low Spontaneous Brillouin Scattering in Anti-Resonant Hollow-Core Fibers in GHz Frequency Range",
    "authors": [
      "Ryan E. Dunagin",
      "Robbie Mears",
      "Dario Bueno-Baques",
      "Vasyl S. Tyberkevych",
      "Yi Li",
      "William J. Wadsworth",
      "Zbigniew Celinski",
      "Valentine Novosad",
      "Dmytro A. Bozhko"
    ],
    "abstract": "Brillouin light scattering (BLS) is a powerful experimental tool that can be\nused to get insights into the fundamental and applied properties of matter,\nlike dispersions of quasiparticles in a solid, as well as their spatio-temporal\ndynamics. Many applications of light scattering favor the use of optical fibers\nin place of free-space optics. In this work, we compare the performance of\nanti-resonant hollow core fibers to that of conventional solid core fused\nsilica fibers for BLS experiments in the GHz frequency range. Conventional\nfibers are barely suitable for low-noise measurements because of the\nspontaneous scattering of the photons on various phononic modes present in the\ncore and cladding. In the case of the hollow-core fiber, we identify a range of\ndiscrete phononic modes and associate them with the various acoustic modes of\nthe structure surrounding the hollow core using finite-element numerical\nsimulations. The measured relative intensity of the spontaneous BLS signal from\nthese modes is orders of magnitude smaller than that of a solid-core fiber,\nmaking anti-resonant hollow-core fibers one of the best solutions for the\nsingle-mode light guidance for BLS and potentially other low-noise photonic\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00287v1",
    "published": "2025-05-30T22:29:16+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00286v1",
    "title": "Entropic Risk Optimization in Discounted MDPs: Sample Complexity Bounds with a Generative Model",
    "authors": [
      "Oliver Mortensen",
      "Mohammad Sadegh Talebi"
    ],
    "abstract": "In this paper we analyze the sample complexities of learning the optimal\nstate-action value function $Q^*$ and an optimal policy $\\pi^*$ in a discounted\nMarkov decision process (MDP) where the agent has recursive entropic\nrisk-preferences with risk-parameter $\\beta\\neq 0$ and where a generative model\nof the MDP is available. We provide and analyze a simple model based approach\nwhich we call model-based risk-sensitive $Q$-value-iteration (MB-RS-QVI) which\nleads to $(\\epsilon,\\delta)$-PAC-bounds on $\\|Q^*-Q^k\\|$, and\n$\\|V^*-V^{\\pi_k}\\|$ where $Q_k$ is the output of MB-RS-QVI after k iterations\nand $\\pi_k$ is the greedy policy with respect to $Q_k$. Both PAC-bounds have\nexponential dependence on the effective horizon $\\frac{1}{1-\\gamma}$ and the\nstrength of this dependence grows with the learners risk-sensitivity $|\\beta|$.\nWe also provide two lower bounds which shows that exponential dependence on\n$|\\beta|\\frac{1}{1-\\gamma}$ is unavoidable in both cases. The lower bounds\nreveal that the PAC-bounds are both tight in $\\varepsilon$ and $\\delta$ and\nthat the PAC-bound on $Q$-learning is tight in the number of actions $A$, and\nthat the PAC-bound on policy-learning is nearly tight in $A$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00286v1",
    "published": "2025-05-30T22:27:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00285v1",
    "title": "Lazy Heuristic Search for Solving POMDPs with Expensive-to-Compute Belief Transitions",
    "authors": [
      "Muhammad Suhail Saleem",
      "Rishi Veerapaneni",
      "Maxim Likhachev"
    ],
    "abstract": "Heuristic search solvers like RTDP-Bel and LAO* have proven effective for\ncomputing optimal and bounded sub-optimal solutions for Partially Observable\nMarkov Decision Processes (POMDPs), which are typically formulated as belief\nMDPs. A belief represents a probability distribution over possible system\nstates. Given a parent belief and an action, computing belief state transitions\ninvolves Bayesian updates that combine the transition and observation models of\nthe POMDP to determine successor beliefs and their transition probabilities.\nHowever, there is a class of problems, specifically in robotics, where\ncomputing these transitions can be prohibitively expensive due to costly\nphysics simulations, raycasting, or expensive collision checks required by the\nunderlying transition and observation models, leading to long planning times.\nTo address this challenge, we propose Lazy RTDP-Bel and Lazy LAO*, which defer\ncomputing expensive belief state transitions by leveraging Q-value estimation,\nsignificantly reducing planning time. We demonstrate the superior performance\nof the proposed lazy planners in domains such as contact-rich manipulation for\npose estimation, outdoor navigation in rough terrain, and indoor navigation\nwith a 1-D LiDAR sensor. Additionally, we discuss practical Q-value estimation\ntechniques for commonly encountered problem classes that our lazy planners can\nleverage. Our results show that lazy heuristic search methods dramatically\nimprove planning speed by postponing expensive belief transition evaluations\nwhile maintaining solution quality.",
    "pdf_url": "http://arxiv.org/pdf/2506.00285v1",
    "published": "2025-05-30T22:26:26+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00284v2",
    "title": "A Constructive Proof of Existence and Mass Gap for Pure SU(3) Yang-Mills in Four-Dimensional Space-Time",
    "authors": [
      "D. C. Jacobsen"
    ],
    "abstract": "In this work we present a constructive proof that pure SU(3) Yang-Mills\ntheory on R^4 exists as a nontrivial Wightman quantum field theory and exhibits\na strictly positive mass gap. Our approach embeds the four-dimensional gauge\ntheory as the zero-mode sector of a five-dimensional orbifold regulator that\npreserves gauge invariance and reflection positivity. A convergent joint\npolymer expansion on the Wilson lattice provides uniform control of the\ncontinuum (a->0) and infinite-volume (L->inf) limits; an Osterwalder-Schrader\nreconstruction yields a unique-vacuum Wightman theory; a nonperturbative\nBRST/Nielsen argument ensures gauge-parameter independence; a rigorously\ncontrolled operator-product expansion matches one-loop beta-function data; and\na Sturm-Liouville analysis of five-dimensional fluctuations, combined with\ntransfer-matrix spectral projections, isolates a strictly positive glueball\nmass m0. All steps rest on explicit epsilon-delta estimates and combinatorial\nbounds for SU(3), leaving no remaining gap between heuristic physics and\nmathematical proof.",
    "pdf_url": "http://arxiv.org/pdf/2506.00284v2",
    "published": "2025-05-30T22:25:19+00:00",
    "categories": [
      "physics.gen-ph",
      "81T08 (Primary) 81T13 (Secondary)"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00283v5",
    "title": "Direct-to-Cell: A First Look into Starlink's Direct Satellite-to-Device Radio Access Network through Crowdsourced Measurements",
    "authors": [
      "Jorge Garcia-Cabeza",
      "Javier Albert-Smet",
      "Zoraida Frias",
      "Luis Mendo",
      "Santiago Andrés Azcoitia",
      "Eduardo Yraola"
    ],
    "abstract": "Low Earth Orbit (LEO) satellite mega-constellations have recently emerged as\na viable access solution for broadband services in underserved areas. In 2024,\nDirect Satellite-to-Device (DS2D) communications, which enable unmodified\nsmartphones to connect directly to spaceborne base stations, entered\nlarge-scale beta testing, with Starlink globally leading deployments. This\npaper presents the first measurement study of commercial DS2D services. Using\ncrowdsourced mobile network data collected in the U.S. between October 2024 and\nApril 2025, our research derives evidence-based insights into the capabilities,\nlimitations, and prospective evolution of DS2D technologies providing\nSupplemental Coverage from Space (SCS) services to expand existing mobile\nnetwork connectivity. We observe a strong correlation between the number of\nsatellites deployed and the expanding extension of observed measurements,\nconcentrated in accessible but poorly covered areas by terrestrial networks,\nsuch as national parks and large low-density counties. The data reveal stable\nphysical-layer value measurement throughout the observation period, with a\nlower median RSRP (24-dB difference) and a higher RSRQ (3 dB difference)\ncompared to terrestrial networks, reflecting the SMS-only usage of the DS2D\nnetwork during this period. Based on SINR measurements, we estimate the\nexpected performance of the announced DS2D mobile data service to be around 4\nMbps per beam in outdoor conditions. We also discuss strategies to expand this\ncapacity up to 12 Mbps in the future, depending on key regulatory decisions\nregarding satellite licenses, spectrum availability, and allowable radiated\npower levels.",
    "pdf_url": "http://arxiv.org/pdf/2506.00283v5",
    "published": "2025-05-30T22:24:07+00:00",
    "categories": [
      "cs.NI",
      "C.2.1"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00282v1",
    "title": "Shill Bidding Prevention in Decentralized Auctions Using Smart Contracts",
    "authors": [
      "M. A. Bouaicha",
      "G. Destefanis",
      "T. Montanaro",
      "N. Lasla",
      "L. Patrono"
    ],
    "abstract": "In online auctions, fraudulent behaviors such as shill bidding pose\nsignificant risks. This paper presents a conceptual framework that applies\ndynamic, behavior-based penalties to deter auction fraud using blockchain smart\ncontracts. Unlike traditional post-auction detection methods, this approach\nprevents manipulation in real-time by introducing an economic disincentive\nsystem where penalty severity scales with suspicious bidding patterns. The\nframework employs the proposed Bid Shill Score (BSS) to evaluate nine distinct\nbidding behaviors, dynamically adjusting the penalty fees to make fraudulent\nactivity financially unaffordable while providing fair competition.\n  The system is implemented within a decentralized English auction on the\nEthereum blockchain, demonstrating how smart contracts enforce transparent\nauction rules without trusted intermediaries. Simulations confirm the\neffectiveness of the proposed model: the dynamic penalty mechanism reduces the\nprofitability of shill bidding while keeping penalties low for honest bidders.\nPerformance evaluation shows that the system introduces only moderate gas and\nlatency overhead, keeping transaction costs and response times within practical\nbounds for real-world use. The approach provides a practical method for\nbehaviour-based fraud prevention in decentralised systems where trust cannot be\nassumed.",
    "pdf_url": "http://arxiv.org/pdf/2506.00282v1",
    "published": "2025-05-30T22:23:29+00:00",
    "categories": [
      "cs.GT",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00281v1",
    "title": "Adversarial Threat Vectors and Risk Mitigation for Retrieval-Augmented Generation Systems",
    "authors": [
      "Chris M. Ward",
      "Josh Harguess"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems, which integrate Large Language\nModels (LLMs) with external knowledge sources, are vulnerable to a range of\nadversarial attack vectors. This paper examines the importance of RAG systems\nthrough recent industry adoption trends and identifies the prominent attack\nvectors for RAG: prompt injection, data poisoning, and adversarial query\nmanipulation. We analyze these threats under risk management lens, and propose\nrobust prioritized control list that includes risk-mitigating actions like\ninput validation, adversarial training, and real-time monitoring.",
    "pdf_url": "http://arxiv.org/pdf/2506.00281v1",
    "published": "2025-05-30T22:22:05+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00280v1",
    "title": "3D Gaussian Splat Vulnerabilities",
    "authors": [
      "Matthew Hull",
      "Haoyang Yang",
      "Pratham Mehta",
      "Mansi Phute",
      "Aeree Cho",
      "Haoran Wang",
      "Matthew Lau",
      "Wenke Lee",
      "Willian T. Lunardi",
      "Martin Andreoni",
      "Polo Chau"
    ],
    "abstract": "With 3D Gaussian Splatting (3DGS) being increasingly used in safety-critical\napplications, how can an adversary manipulate the scene to cause harm? We\nintroduce CLOAK, the first attack that leverages view-dependent Gaussian\nappearances - colors and textures that change with viewing angle - to embed\nadversarial content visible only from specific viewpoints. We further\ndemonstrate DAGGER, a targeted adversarial attack directly perturbing 3D\nGaussians without access to underlying training data, deceiving multi-stage\nobject detectors e.g., Faster R-CNN, through established methods such as\nprojected gradient descent. These attacks highlight underexplored\nvulnerabilities in 3DGS, introducing a new potential threat to robotic learning\nfor autonomous navigation and other safety-critical 3DGS applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00280v1",
    "published": "2025-05-30T22:21:22+00:00",
    "categories": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00279v1",
    "title": "Sleep Brain and Cardiac Activity Predict Cognitive Flexibility and Conceptual Reasoning Using Deep Learning",
    "authors": [
      "Boshra Khajehpiri",
      "Eric Granger",
      "Massimiliano de Zambotti",
      "Fiona C. Baker",
      "Mohamad Forouzanfar"
    ],
    "abstract": "Despite extensive research on the relationship between sleep and cognition,\nthe connection between sleep microstructure and human performance across\nspecific cognitive domains remains underexplored. This study investigates\nwhether deep learning models can predict executive functions, particularly\ncognitive adaptability and conceptual reasoning from physiological processes\nduring a night's sleep. To address this, we introduce CogPSGFormer, a\nmulti-scale convolutional-transformer model designed to process multi-modal\npolysomnographic data. This model integrates one-channel ECG and EEG signals\nalong with extracted features, including EEG power bands and heart rate\nvariability parameters, to capture complementary information across modalities.\nA thorough evaluation of the CogPSGFormer architecture was conducted to\noptimize the processing of extended sleep signals and identify the most\neffective configuration. The proposed framework was evaluated on 817\nindividuals from the STAGES dataset using cross-validation. The model achieved\n80.3\\% accuracy in classifying individuals into low vs. high cognitive\nperformance groups on unseen data based on Penn Conditional Exclusion Test\n(PCET) scores. These findings highlight the effectiveness of our multi-scale\nfeature extraction and multi-modal learning approach in leveraging\nsleep-derived signals for cognitive performance prediction. To facilitate\nreproducibility, our code is publicly accessible\n(https://github.com/boshrakh95/CogPSGFormer.git).",
    "pdf_url": "http://arxiv.org/pdf/2506.00279v1",
    "published": "2025-05-30T22:21:07+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00278v1",
    "title": "Search for the chiral magnetic effect through beam energy dependence of charge separation using event shape selection",
    "authors": [
      "The STAR Collaboration"
    ],
    "abstract": "High-energy, heavy-ion collisions can create local domains of\nchirality-imbalanced quarks, reflecting the topological features of quantum\nchromodynamics. The chiral magnetic effect (CME) predicts an electric charge\nseparation of quarks in such topological domains along the magnetic field\n($\\vec{B}$) generated by the passing of two high-$Z$ nuclei. We use a\ncorrelation observable $\\Delta\\gamma^{112}$ between charged meson pairs to\ndetect the CME-induced charge separation and a novel event shape selection\n(ESS) method to mitigate the background effects related to elliptic flow\n($v_2$). The ESS method classifies events based on the emission pattern of\nfinal-state particles and determines $\\Delta\\gamma^{112}_{\\rm ESS}$ from the\nzero-flow limit. We reconstruct the $\\vec{B}$ field direction from the\nspectator nucleons, which minimizes backgrounds unrelated to the collective\nmotion of the system. In this work, we report the measurements of\n$\\Delta\\gamma^{112}$ and a background indicator $\\Delta\\gamma^{132}$ in Au+Au\ncollisions from the RHIC Beam Energy Scan phase II and at the top RHIC energy.\nAfter background suppression, $\\Delta\\gamma^{132}_{\\rm ESS}$ aligns with zero,\nand $\\Delta\\gamma^{112}_{\\rm ESS}$ is reduced to no more than 20\\% of\n$\\Delta\\gamma^{112}$. We observe a finite residual charge separation with\n$2.6\\sigma$, $3.1\\sigma$, and $3.3\\sigma$ significance in the 20\\%--50\\%\ncentrality range of Au+Au collisions at 11.5, 14.6, and 19.6 GeV. The results\nat 17.3 and 27 GeV also show positive values but with a lower significance of\n$1.3\\sigma$ and $1.1\\sigma$, respectively. The corresponding\n$\\Delta\\gamma^{112}_{\\rm ESS}$ values at 7.7, 9.2, and 200 GeV are consistent\nwith zero within uncertainties.",
    "pdf_url": "http://arxiv.org/pdf/2506.00278v1",
    "published": "2025-05-30T22:17:55+00:00",
    "categories": [
      "nucl-ex",
      "hep-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2506.00277v1",
    "title": "Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings",
    "authors": [
      "Hans W. A. Hanley",
      "Zakir Durumeric"
    ],
    "abstract": "Contextual large language model embeddings are increasingly utilized for\ntopic modeling and clustering. However, current methods often scale poorly,\nrely on opaque similarity metrics, and struggle in multilingual settings. In\nthis work, we present a novel, scalable, interpretable, hierarchical, and\nmultilingual approach to clustering news articles and social media data. To do\nthis, we first train multilingual Matryoshka embeddings that can determine\nstory similarity at varying levels of granularity based on which subset of the\ndimensions of the embeddings is examined. This embedding model achieves\nstate-of-the-art performance on the SemEval 2022 Task 8 test dataset (Pearson\n$\\rho$ = 0.816). Once trained, we develop an efficient hierarchical clustering\nalgorithm that leverages the hierarchical nature of Matryoshka embeddings to\nidentify unique news stories, narratives, and themes. We conclude by\nillustrating how our approach can identify and cluster stories, narratives, and\noverarching themes within real-world news datasets.",
    "pdf_url": "http://arxiv.org/pdf/2506.00277v1",
    "published": "2025-05-30T22:17:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00276v1",
    "title": "RoboMoRe: LLM-based Robot Co-design via Joint Optimization of Morphology and Reward",
    "authors": [
      "Jiawei Fang",
      "Yuxuan Sun",
      "Chengtian Ma",
      "Qiuyu Lu",
      "Lining Yao"
    ],
    "abstract": "Robot co-design, jointly optimizing morphology and control policy, remains a\nlongstanding challenge in the robotics community, where many promising robots\nhave been developed. However, a key limitation lies in its tendency to converge\nto sub-optimal designs due to the use of fixed reward functions, which fail to\nexplore the diverse motion modes suitable for different morphologies. Here we\npropose RoboMoRe, a large language model (LLM)-driven framework that integrates\nmorphology and reward shaping for co-optimization within the robot co-design\nloop. RoboMoRe performs a dual-stage optimization: in the coarse optimization\nstage, an LLM-based diversity reflection mechanism generates both diverse and\nhigh-quality morphology-reward pairs and efficiently explores their\ndistribution. In the fine optimization stage, top candidates are iteratively\nrefined through alternating LLM-guided reward and morphology gradient updates.\nRoboMoRe can optimize both efficient robot morphologies and their suited motion\nbehaviors through reward shaping. Results demonstrate that without any\ntask-specific prompting or predefined reward/morphology templates, RoboMoRe\nsignificantly outperforms human-engineered designs and competing methods across\neight different tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00276v1",
    "published": "2025-05-30T22:16:07+00:00",
    "categories": [
      "cs.RO",
      "cs.CL",
      "68T40, 68T05, 90C90",
      "I.2.9; I.2.6; I.2.8; I.2.10"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00275v1",
    "title": "Charge Separation Measurements in Au+Au collisions at $\\sqrt{s_{NN}}=$ 7.7--200 GeV in Search of the Chiral Magnetic Effect",
    "authors": [
      "The STAR Collaboration"
    ],
    "abstract": "The chiral magnetic effect in heavy-ion collisions predicts a charge\nseparation signal along a magnetic field, which indicates local $P$ and $CP$\nviolations in the quark-gluon plasma. We report measurements of electric charge\nseparation signals perpendicular to the spectator event plane in Au+Au\ncollisions using high-statistics data from RHIC Beam Energy Scan II and\ntop-energy runs. A novel event shape selection method is employed to suppress\nthe flow-induced background. The residual charge separation signals near the\nzero-flow limit are positive in Au+Au collisions within the 20\\%--50\\%\ncentrality range, with significance levels of $2.6\\sigma$, $3.1\\sigma$, and\n$3.3\\sigma$ at $\\sqrt{s_{NN}} =$ 11.5, 14.6, and 19.6 GeV, respectively. At\nother beam energies, the signals are either statistically limited or consistent\nwith zero.",
    "pdf_url": "http://arxiv.org/pdf/2506.00275v1",
    "published": "2025-05-30T22:15:59+00:00",
    "categories": [
      "nucl-ex",
      "hep-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2506.00274v1",
    "title": "Chances and Challenges of the Model Context Protocol in Digital Forensics and Incident Response",
    "authors": [
      "Jan-Niclas Hilgert",
      "Carlo Jakobs",
      "Michael Külper",
      "Martin Lambertz",
      "Axel Mahr",
      "Elmar Padilla"
    ],
    "abstract": "Large language models hold considerable promise for supporting forensic\ninvestigations, but their widespread adoption is hindered by a lack of\ntransparency, explainability, and reproducibility. This paper explores how the\nemerging Model Context Protocol can address these challenges and support the\nmeaningful use of LLMs in digital forensics. Through a theoretical analysis, we\nexamine how MCP can be integrated across various forensic scenarios - ranging\nfrom artifact analysis to the generation of interpretable reports. We also\noutline both technical and conceptual considerations for deploying an MCP\nserver in forensic environments. Our analysis reveals a wide range of use cases\nin which MCP not only strengthens existing forensic workflows but also\nfacilitates the application of LLMs to areas of forensics where their use was\npreviously limited. Furthermore, we introduce the concept of the inference\nconstraint level - a way of characterizing how specific MCP design choices can\ndeliberately constrain model behavior, thereby enhancing both auditability and\ntraceability. Our insights demonstrate that MCP has significant potential as a\nfoundational component for developing LLM-assisted forensic workflows that are\nnot only more transparent, reproducible, and legally defensible, but also\nrepresent a step toward increased automation in digital forensic analysis.\nHowever, we also highlight potential challenges that the adoption of MCP may\npose for digital forensics in the future.",
    "pdf_url": "http://arxiv.org/pdf/2506.00274v1",
    "published": "2025-05-30T22:15:48+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00273v1",
    "title": "SoundSculpt: Direction and Semantics Driven Ambisonic Target Sound Extraction",
    "authors": [
      "Tuochao Chen",
      "D Shin",
      "Hakan Erdogan",
      "Sinan Hersek"
    ],
    "abstract": "This paper introduces SoundSculpt, a neural network designed to extract\ntarget sound fields from ambisonic recordings. SoundSculpt employs an\nambisonic-in-ambisonic-out architecture and is conditioned on both spatial\ninformation (e.g., target direction obtained by pointing at an immersive video)\nand semantic embeddings (e.g., derived from image segmentation and captioning).\nTrained and evaluated on synthetic and real ambisonic mixtures, SoundSculpt\ndemonstrates superior performance compared to various signal processing\nbaselines. Our results further reveal that while spatial conditioning alone can\nbe effective, the combination of spatial and semantic information is beneficial\nin scenarios where there are secondary sound sources spatially close to the\ntarget. Additionally, we compare two different semantic embeddings derived from\na text description of the target sound using text encoders.",
    "pdf_url": "http://arxiv.org/pdf/2506.00273v1",
    "published": "2025-05-30T22:15:10+00:00",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00272v1",
    "title": "Minimum Membership Geometric Set Cover in the Continuous Setting",
    "authors": [
      "Sathish Govindarajan",
      "Mayuresh Patle",
      "Siddhartha Sarkar"
    ],
    "abstract": "We study the minimum membership geometric set cover, i.e., MMGSC problem\n[SoCG, 2023] in the continuous setting. In this problem, the input consists of\na set $P$ of $n$ points in $\\mathbb{R}^{2}$, and a geometric object $t$, the\ngoal is to find a set $\\mathcal{S}$ of translated copies of the geometric\nobject $t$ that covers all the points in $P$ while minimizing $\\mathsf{memb}(P,\n\\mathcal{S})$, where $\\mathsf{memb}(P, \\mathcal{S})=\\max_{p\\in P}|\\{s\\in\n\\mathcal{S}: p\\in s\\}|$.\n  For unit squares, we present a simple $O(n\\log n)$ time algorithm that\noutputs a $1$-membership cover. We show that the size of our solution is at\nmost twice that of an optimal solution. We establish the NP-hardness on the\nproblem of computing the minimum number of non-overlapping unit squares\nrequired to cover a given set of points. This algorithm also generalizes to\nfixed-sized hyperboxes in $d$-dimensional space, where an $1$-membership cover\nwith size at most $2^{d-1}$ times the size of a minimum-sized $1$-membership\ncover is computed in $O(dn\\log n)$ time. Additionally, we characterize a class\nof objects for which a $1$-membership cover always exists. For unit disks, we\nprove that a $2$-membership cover exists for any point set, and the size of the\ncover is at most $7$ times that of the optimal cover. For arbitrary convex\npolygons with $m$ vertices, we present an algorithm that outputs a\n$4$-membership cover in $O(n\\log n + nm)$ time.",
    "pdf_url": "http://arxiv.org/pdf/2506.00272v1",
    "published": "2025-05-30T22:13:26+00:00",
    "categories": [
      "cs.CG"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00271v1",
    "title": "Adaptive Voxelization for Transform coding of 3D Gaussian splatting data",
    "authors": [
      "Chenjunjie Wang",
      "Shashank N. Sridhara",
      "Eduardo Pavez",
      "Antonio Ortega",
      "Cheng Chang"
    ],
    "abstract": "We present a novel compression framework for 3D Gaussian splatting (3DGS)\ndata that leverages transform coding tools originally developed for point\nclouds. Contrary to existing 3DGS compression methods, our approach can produce\ncompressed 3DGS models at multiple bitrates in a computationally efficient way.\nPoint cloud voxelization is a discretization technique that point cloud codecs\nuse to improve coding efficiency while enabling the use of fast transform\ncoding algorithms. We propose an adaptive voxelization algorithm tailored to\n3DGS data, to avoid the inefficiencies introduced by uniform voxelization used\nin point cloud codecs. We ensure the positions of larger volume Gaussians are\nrepresented at high resolution, as these significantly impact rendering\nquality. Meanwhile, a low-resolution representation is used for dense regions\nwith smaller Gaussians, which have a relatively lower impact on rendering\nquality. This adaptive voxelization approach significantly reduces the number\nof Gaussians and the bitrate required to encode the 3DGS data. After\nvoxelization, many Gaussians are moved or eliminated. Thus, we propose to\nfine-tune/recolor the remaining 3DGS attributes with an initialization that can\nreduce the amount of retraining required. Experimental results on pre-trained\ndatasets show that our proposed compression framework outperforms existing\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00271v1",
    "published": "2025-05-30T22:12:33+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00270v1",
    "title": "Bayesian Data Sketching for Varying Coefficient Regression Models",
    "authors": [
      "Rajarshi Guhaniyogi",
      "Laura Baracaldo",
      "Sudipto Banerjee"
    ],
    "abstract": "Varying coefficient models are popular for estimating nonlinear regression\nfunctions in functional data models. Their Bayesian variants have received\nlimited attention in large data applications, primarily due to prohibitively\nslow posterior computations using Markov chain Monte Carlo (MCMC) algorithms.\nWe introduce Bayesian data sketching for varying coefficient models to obviate\ncomputational challenges presented by large sample sizes. To address the\nchallenges of analyzing large data, we compress the functional response vector\nand predictor matrix by a random linear transformation to achieve dimension\nreduction and conduct inference on the compressed data. Our approach\ndistinguishes itself from several existing methods for analyzing large\nfunctional data in that it requires neither the development of new models or\nalgorithms, nor any specialized computational hardware while delivering fully\nmodel-based Bayesian inference. Well-established methods and algorithms for\nvarying coefficient regression models can be applied to the compressed data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00270v1",
    "published": "2025-05-30T22:09:06+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00269v1",
    "title": "Extended-variable probabilistic computing with p-dits",
    "authors": [
      "Christian Duffee",
      "Jordan Athas",
      "Andrea Grimaldi",
      "Deborah Volpe",
      "Giovanni Finocchio",
      "Ermin Wei",
      "Pedram Khalili Amiri"
    ],
    "abstract": "Ising machines can solve combinatorial optimization problems by representing\nthem as energy minimization problems. A common implementation is the\nprobabilistic Ising machine (PIM), which uses probabilistic (p-) bits to\nrepresent coupled binary spins. However, many real-world problems have complex\ndata representations that do not map naturally into a binary encoding, leading\nto a significant increase in hardware resources and time-to-solution. Here, we\ndescribe a generalized spin model that supports an arbitrary number of spin\ndimensions, each with an arbitrary real component. We define the probabilistic\nd-dimensional bit (p-dit) as the base unit of a p-computing implementation of\nthis model. We further describe two restricted forms of p-dits for specific\nclasses of common problems and implement them experimentally on an\napplication-specific integrated circuit (ASIC): (A) isotropic p-dits, which\nsimplify the implementation of categorical variables resulting in ~34x\nperformance improvement compared to a p-bit implementation on an example\n3-partition problem. (B) Probabilistic integers (p-ints), which simplify the\nrepresentation of numeric values and provide ~5x improvement compared to a\np-bit implementation of an example integer linear programming (ILP) problem.\nAdditionally, we report a field-programmable gate array (FPGA) p-int-based\ninteger quadratic programming (IQP) solver which shows ~64x faster\ntime-to-solution compared to the best of a series of state-of-the-art software\nsolvers. The generalized formulation of probabilistic variables presented here\nprovides a path to solving large-scale optimization problems on various\nhardware platforms including digital CMOS.",
    "pdf_url": "http://arxiv.org/pdf/2506.00269v1",
    "published": "2025-05-30T22:07:00+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00268v2",
    "title": "Shape derivative approach to fractional overdetermined problems",
    "authors": [
      "Sidy M. Djitte",
      "Ignace A. Minlend"
    ],
    "abstract": "We use shape derivative approach to prove that balls are the only convex and\n$C^{1,1}$ regular domains in which the fractional overdetermined problem\n\\begin{equation*} \\left\\{\\begin{aligned} \\Ds u&= \\lambda_{s, p}\nu^{p-1}\\quad\\text{in}\\quad\\Om \\\\ u &= 0\\quad \\text{in}\\quad\\R^N\\setminus \\Om\\\\\nu/d^s&=C_0\\quad\\text{on\\;\\; $\\partial\\O$} \\end{aligned} \\right. \\end{equation*}\nadmits a nontrivial solution for $p\\in [1, 2]$ and where $\\lambda_{s, p}=\n\\lambda_{s, p}(\\O)$ is the best constant in the family of Subcritical Sobolev\ninequalities. In the cases $p=1$ and $p=2$, we recover the classical symmetry\nresults of Serrin, corresponding to the torsion problem and the first Dirichlet\neigenvalue problem, respectively (see \\cite{FS-15}). We note that for $p\\in\n(1,2)$, the above problem lies outside the framework of \\cite{FS-15}, and the\nmethods developed therein do not apply. Our approach extends to the fractional\nsetting a method initially developed by A. Henrot and T. Chatelain in\n\\cite{CH-99}, and relies on the use of domain derivatives combined with the\ncontinuous Steiner symmetrization introduced by Brock in \\cite{Brock-00}.",
    "pdf_url": "http://arxiv.org/pdf/2506.00268v2",
    "published": "2025-05-30T22:06:21+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00267v3",
    "title": "CASPER: A Large Scale Spontaneous Speech Dataset",
    "authors": [
      "Cihan Xiao",
      "Ruixing Liang",
      "Xiangyu Zhang",
      "Mehmet Emre Tiryaki",
      "Veronica Bae",
      "Lavanya Shankar",
      "Rong Yang",
      "Ethan Poon",
      "Emmanuel Dupoux",
      "Sanjeev Khudanpur",
      "Leibny Paola Garcia Perera"
    ],
    "abstract": "The success of large language models has driven interest in developing\nsimilar speech processing capabilities. However, a key challenge is the\nscarcity of high-quality spontaneous speech data, as most existing datasets\ncontain scripted dialogues. To address this, we present a novel pipeline for\neliciting and recording natural dialogues and release our dataset with 100+\nhours of spontaneous speech. Our approach fosters fluid, natural conversations\nwhile encouraging a diverse range of topics and interactive exchanges. Unlike\ntraditional methods, it facilitates genuine interactions, providing a\nreproducible framework for future data collection. This paper introduces our\ndataset and methodology, laying the groundwork for addressing the shortage of\nspontaneous speech data. We plan to expand this dataset in future stages,\noffering a growing resource for the research community.",
    "pdf_url": "http://arxiv.org/pdf/2506.00267v3",
    "published": "2025-05-30T22:03:59+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00266v1",
    "title": "Determining unit groups and $\\mathrm{K}_1$ of finite rings",
    "authors": [
      "Tommy Hofmann"
    ],
    "abstract": "We consider the computational problem of determining the unit group of a\nfinite ring, by which we mean the computation of a finite presentation together\nwith an algorithm to express units as words in the generators. We show that the\nproblem is equivalent to the number theoretic problems of factoring integers\nand solving discrete logarithms in finite fields. A similar equivalence is\nshown for the problem of determining the abelianization of the unit group or\nthe first $K$-group of finite rings.",
    "pdf_url": "http://arxiv.org/pdf/2506.00266v1",
    "published": "2025-05-30T22:00:47+00:00",
    "categories": [
      "math.NT",
      "cs.SC",
      "math.KT",
      "math.RA",
      "Primary 68W30, 19D50, 20C05, 19-08, 11Y16, Secondary 16Z05"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.04246v1",
    "title": "Improving the average dilation of a metric graph by adding edges",
    "authors": [
      "Sariel Har-Peled",
      "Eliot W. Robson"
    ],
    "abstract": "For a graph $G$ spanning a metric space, the dilation of a pair of points is\nthe ratio of their distance in the shortest path graph metric to their distance\nin the metric space. Given a graph $G$ and a budget $k$, a classic problem is\nto augment $G$ with $k$ additional edges to reduce the maximum dilation.\n  In this note, we consider a variant of this problem where the goal is to\nreduce the average dilation for pairs of points in $G$. We provide an $O(k)$\napproximation algorithm for this problem, matching the approximation ratio\ngiven by prior work for the maximum dilation variant.",
    "pdf_url": "http://arxiv.org/pdf/2506.04246v1",
    "published": "2025-05-30T21:58:20+00:00",
    "categories": [
      "cs.CG"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00265v1",
    "title": "The Einstein Equation from an Informational-Geometrical Equivalence",
    "authors": [
      "Eduardo O. Dias"
    ],
    "abstract": "While any observer perceives its immediate neighborhood as locally flat, the\nmetric field deviates from Minkowski space to relate infinitesimal distances\nassigned by local observers at distinct spacetime points. In a quantum\ndescription, these events should emerge from interactions (and thus\ncorrelations) between quantum systems, with one of them acting as a reference\nframe that defines relational localization. In this context, the metric field\nconnects distances between interactions (events) \\textit{from the perspective\nof} distinct physical local reference frames (LRFs). Building on this idea --\ntogether with the connection between entanglement entropy and area (which, in\nturn, may be linked to the metric itself), and the fact that the Einstein\nequation does not require the explicit presence of these material frames -- we\npropose an \\emph{informational-geometrical equivalence} (IGE): for a\nsufficiently small spacelike region $ B $, let $\\rho_B $ and $ \\sigma_B$ denote\nthe reduced states of the quantum fields and the LRF within $ B $,\nrespectively. In this picture, the relational content of the entropy of the\nquantum fields as seen by the LRF -- quantified by the conditional entropy $\n\\delta_\\rho S(\\rho_B | \\sigma_B) $ -- is encoded in the variation $\n\\delta_{g,\\rho} S(\\rho_B) $ induced by a smooth geometric perturbation. When\nthe reference frame has complete information about the infrared sector, this\nIGE recovers the semiclassical Einstein equation. Furthermore, considering the\npresence of quantum correlations between the system and the LRF reveals a\npositive cosmological constant related to the density of quantum correlation\nwithin $B$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00265v1",
    "published": "2025-05-30T21:56:45+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.00264v2",
    "title": "MultiHoax: A Dataset of Multi-hop False-Premise Questions",
    "authors": [
      "Mohammadamin Shafiei",
      "Hamidreza Saffari",
      "Nafise Sadat Moosavi"
    ],
    "abstract": "As Large Language Models are increasingly deployed in high-stakes domains,\ntheir ability to detect false assumptions and reason critically is crucial for\nensuring reliable outputs. False-premise questions (FPQs) serve as an important\nevaluation method by exposing cases where flawed assumptions lead to incorrect\nresponses. While existing benchmarks focus on single-hop FPQs, real-world\nreasoning often requires multi-hop inference, where models must verify\nconsistency across multiple reasoning steps rather than relying on\nsurface-level cues. To address this gap, we introduce MultiHoax, a benchmark\nfor evaluating LLMs' ability to handle false premises in complex, multi-step\nreasoning tasks. Our dataset spans seven countries and ten diverse knowledge\ncategories, using Wikipedia as the primary knowledge source to enable factual\nreasoning across regions. Experiments reveal that state-of-the-art LLMs\nstruggle to detect false premises across different countries, knowledge\ncategories, and multi-hop reasoning types, highlighting the need for improved\nfalse premise detection and more robust multi-hop reasoning capabilities in\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00264v2",
    "published": "2025-05-30T21:55:18+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00263v1",
    "title": "Comparing the Performance of MC/DC's on-GPU Event-based Processing Methods in Multigroup and Continuous-energy Problems",
    "authors": [
      "Braxton Cuneo",
      "Joanna Piper Morgan",
      "Ilham Variansyah",
      "Kyle E. Niemeyer"
    ],
    "abstract": "Monte Carlo / Dynamic Code (MC/DC) is a portable Monte Carlo neutron\ntransport package for rapid numerical methods exploration in heterogeneous and\nHPC contexts, developed under the auspices of the Center for Exascale Monte\nCarlo Neutron Transport (CEMeNT). To support execution on GPUs, MC/DC delegates\nresource and execution management to Harmonize (another CEMeNT software\nproject). In this paper, we describe and compare the performance of the two\nmethods that Harmonize currently provides: a stack-based method and a\ndistributed, asynchronous method. As part of this investigation, we analyze the\nperformance of both methods under the 3D C5G7 k-eigenvalue benchmark problem\nand a continuous-energy infinite pin cell problem, as run across 4 NVIDIA Tesla\nV100s. We find that the asynchronous method exhibits stronger early scaling\ncompared to the stack-based method in the 3D C5G7 benchmark. We also found that\nthe asynchronous method exhibits mixed performance relative to the stack-based\nmethod in the continuous-energy problem, depending upon tally resolution,\nparticle count, and transport loop decomposition.",
    "pdf_url": "http://arxiv.org/pdf/2506.00263v1",
    "published": "2025-05-30T21:55:06+00:00",
    "categories": [
      "physics.comp-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00262v1",
    "title": "Compact and Selective Disclosure for Verifiable Credentials",
    "authors": [
      "Alessandro Buldini",
      "Carlo Mazzocca",
      "Rebecca Montanari",
      "Selcuk Uluagac"
    ],
    "abstract": "Self-Sovereign Identity (SSI) is a novel identity model that empowers\nindividuals with full control over their data, enabling them to choose what\ninformation to disclose, with whom, and when. This paradigm is rapidly gaining\ntraction worldwide, supported by numerous initiatives such as the European\nDigital Identity (EUDI) Regulation or Singapore's National Digital Identity\n(NDI). For instance, by 2026, the EUDI Regulation will enable all European\ncitizens to seamlessly access services across Europe using Verifiable\nCredentials (VCs). A key feature of SSI is the ability to selectively disclose\nonly specific claims within a credential, enhancing privacy protection of the\nidentity owner. This paper proposes a novel mechanism designed to achieve\nCompact and Selective Disclosure for VCs (CSD-JWT). Our method leverages a\ncryptographic accumulator to encode claims within a credential to a unique,\ncompact representation. We implemented CSD-JWT as an open-source solution and\nextensively evaluated its performance under various conditions. CSD-JWT\nprovides significant memory savings, reducing usage by up to 46% compared to\nthe state-of-the-art. It also minimizes network overhead by producing\nremarkably smaller Verifiable Presentations (VPs), reduced in size by 27% to\n93%. Such features make CSD-JWT especially well-suited for resource-constrained\ndevices, including hardware wallets designed for managing credentials.",
    "pdf_url": "http://arxiv.org/pdf/2506.00262v1",
    "published": "2025-05-30T21:53:07+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00261v2",
    "title": "GPR: Empowering Generation with Graph-Pretrained Retriever",
    "authors": [
      "Xiaochen Wang",
      "Zongyu Wu",
      "Yuan Zhong",
      "Xiang Zhang",
      "Suhang Wang",
      "Fenglong Ma"
    ],
    "abstract": "Graph retrieval-augmented generation (GRAG) places high demands on\ngraph-specific retrievers. However, existing retrievers often rely on language\nmodels pretrained on plain text, limiting their effectiveness due to domain\nmisalignment and structure ignorance. To address these challenges, we propose\nGPR, a graph-based retriever pretrained directly on knowledge graphs. GPR\naligns natural language questions with relevant subgraphs through LLM-guided\ngraph augmentation and employs a structure-aware objective to learn\nfine-grained retrieval strategies. Experiments on two datasets, three LLM\nbackbones, and five baselines show that GPR consistently improves both\nretrieval quality and downstream generation, demonstrating its effectiveness as\na robust retrieval solution for GRAG.",
    "pdf_url": "http://arxiv.org/pdf/2506.00261v2",
    "published": "2025-05-30T21:50:29+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00260v1",
    "title": "GrapheonRL: A Graph Neural Network and Reinforcement Learning Framework for Constraint and Data-Aware Workflow Mapping and Scheduling in Heterogeneous HPC Systems",
    "authors": [
      "Aasish Kumar Sharma",
      "Julian Kunkel"
    ],
    "abstract": "Effective resource utilization and decreased makespan in heterogeneous High\nPerformance Computing (HPC) environments are key benefits of workload mapping\nand scheduling. Tools such as Snakemake, a workflow management solution, employ\nInteger Linear Programming (ILP) and heuristic techniques to deploy workflows\nin various HPC environments like SLURM (Simple Linux Utility for Resource\nManagement) or Kubernetes. Its scheduler factors in workflow task dependencies,\nresource requirements, and individual task data sizes before system deployment.\nILP offers optimal solutions respecting constraints, but only for smaller\nworkflows. Meanwhile, meta-heuristics and heuristics offer faster, though\nsuboptimal, makespan. As problem sizes, system constraints, and complexities\nevolve, maintaining these schedulers becomes challenging. In this study, we\npropose a novel solution that integrates Graph Neural Network (GNN) and\nReinforcement Learning (RL) to flexibly handle workflows, dynamic constraints,\nand heterogeneous resources while providing quick responses. GNN manages\ndependencies and resource requirements, and RL optimizes scheduling\ndecision-making via a learned policy, overcoming the need for a comprehensive\nglobal search. Experimental results with different datasets demonstrate that\nthis method effectively adapts to different workflows, adheres to HPC\nconstraints, and offers optimal solutions akin to ILP but with drastically\nreduced execution times (76 percent faster), comparable to heuristic methods\n(only 3.85 times slower than OLB). Our contribution is to provide a robust yet\nscalable mapping and scheduling solution that can handle changing constraints,\nas well as workload sizes and complexities in a heterogeneous HPC Compute\nContinuum system landscape.",
    "pdf_url": "http://arxiv.org/pdf/2506.00260v1",
    "published": "2025-05-30T21:50:28+00:00",
    "categories": [
      "cs.DC",
      "cs.ET"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00259v2",
    "title": "PerFormer: A Permutation Based Vision Transformer for Remaining Useful Life Prediction",
    "authors": [
      "Zhengyang Fan",
      "Wanru Li",
      "Kuo-chu Chang",
      "Ting Yuan"
    ],
    "abstract": "Accurately estimating the remaining useful life (RUL) for degradation systems\nis crucial in modern prognostic and health management (PHM). Convolutional\nNeural Networks (CNNs), initially developed for tasks like image and video\nrecognition, have proven highly effectively in RUL prediction, demonstrating\nremarkable performance. However, with the emergence of the Vision Transformer\n(ViT), a Transformer model tailored for computer vision tasks such as image\nclassification, and its demonstrated superiority over CNNs, there is a natural\ninclination to explore its potential in enhancing RUL prediction accuracy.\nNonetheless, applying ViT directly to multivariate sensor data for RUL\nprediction poses challenges, primarily due to the ambiguous nature of spatial\ninformation in time series data. To address this issue, we introduce the\nPerFormer, a permutation-based vision transformer approach designed to permute\nmultivariate time series data, mimicking spatial characteristics akin to image\ndata, thereby making it suitable for ViT. To generate the desired permutation\nmatrix, we introduce a novel permutation loss function aimed at guiding the\nconvergence of any matrix towards a permutation matrix. Our experiments on\nNASA's C-MAPSS dataset demonstrate the PerFormer's superior performance in RUL\nprediction compared to state-of-the-art methods employing CNNs, Recurrent\nNeural Networks (RNNs), and various Transformer models. This underscores its\neffectiveness and potential in PHM applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00259v2",
    "published": "2025-05-30T21:49:10+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00258v2",
    "title": "Hidden in Plain Sight: Reasoning in Underspecified and Misspecified Scenarios for Multimodal LLMs",
    "authors": [
      "Qianqi Yan",
      "Hongquan Li",
      "Shan Jiang",
      "Yang Zhao",
      "Xinze Guan",
      "Ching-Chen Kuo",
      "Xin Eric Wang"
    ],
    "abstract": "Multimodal large language models (MLLMs) are increasingly deployed in\nopen-ended, real-world environments where inputs are messy, underspecified, and\nnot always trustworthy. Unlike curated benchmarks, these settings frequently\ninvolve instructions that refer to missing objects or contradictory facts, rely\non ambiguous references, or request infeasible actions. In such cases, success\nhinges not on task execution alone, but on a model's ability to detect when\nsomething is silently wrong. This paper presents a systematic analysis of how\ncurrent MLLMs handle such implicit reasoning scenarios: cases where the flaw is\nnot explicitly stated but must be inferred from context. Using a curated\ndiagnostic suite spanning four categories of real-world failure modes, we\nevaluate six MLLMs, including o3 and GPT-4o, and find that models frequently\nfail to surface hidden issues, even when they possess the necessary perceptual\nand reasoning skills. Explicit prompting reveals that the underlying\ncapabilities exist but are often suppressed in favor of user compliance. We\nfurther show that simple inference-time interventions, such as cautious persona\nprompting and, in particular, requiring a clarifying question, can dramatically\nrecover performance. Our findings highlight a persistent gap between reasoning\ncompetence and behavioral compliance in current MLLMs and suggest practical\nstrategies for making these models more trustworthy in underconstrained\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00258v2",
    "published": "2025-05-30T21:47:28+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00257v1",
    "title": "Estimation of Optimal Causal Bounds via Covariate-Assisted Optimal Transport",
    "authors": [
      "Sirui Lin",
      "Zijun Gao",
      "Jose Blanchet",
      "Peter Glynn"
    ],
    "abstract": "We study the estimation of causal estimand involving the joint distribution\nof treatment and control outcomes for a single unit. In typical causal\ninference settings, it is impossible to observe both outcomes simultaneously,\nwhich places our estimation within the domain of partial identification (PI).\nPre-treatment covariates can substantially reduce estimation uncertainty by\nshrinking the partially identified set. Recently, it was shown that\ncovariate-assisted PI sets can be characterized through conditional optimal\ntransport (COT) problems. However, finite-sample estimation of COT poses\nsignificant challenges, primarily because, as we explain, the COT functional is\ndiscontinuous under the weak topology, rendering the direct plug-in estimator\ninconsistent. To address this issue, existing literature relies on relaxations\nor indirect methods involving the estimation of non-parametric nuisance\nstatistics. In this work, we demonstrate the continuity of the COT functional\nunder a stronger topology induced by the adapted Wasserstein distance.\nLeveraging this result, we propose a direct, consistent, non-parametric\nestimator for COT value that avoids nuisance parameter estimation. We derive\nthe convergence rate for our estimator and validate its effectiveness through\ncomprehensive simulations, demonstrating its improved performance compared to\nexisting approaches.",
    "pdf_url": "http://arxiv.org/pdf/2506.00257v1",
    "published": "2025-05-30T21:47:05+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.00256v1",
    "title": "The Impact of Disability Disclosure on Fairness and Bias in LLM-Driven Candidate Selection",
    "authors": [
      "Mahammed Kamruzzaman",
      "Gene Louis Kim"
    ],
    "abstract": "As large language models (LLMs) become increasingly integrated into hiring\nprocesses, concerns about fairness have gained prominence. When applying for\njobs, companies often request/require demographic information, including\ngender, race, and disability or veteran status. This data is collected to\nsupport diversity and inclusion initiatives, but when provided to LLMs,\nespecially disability-related information, it raises concerns about potential\nbiases in candidate selection outcomes. Many studies have highlighted how\ndisability can impact CV screening, yet little research has explored the\nspecific effect of voluntarily disclosed information on LLM-driven candidate\nselection. This study seeks to bridge that gap. When candidates shared\nidentical gender, race, qualifications, experience, and backgrounds, and sought\njobs with minimal employment rate gaps between individuals with and without\ndisabilities (e.g., Cashier, Software Developer), LLMs consistently favored\ncandidates who disclosed that they had no disability. Even in cases where\ncandidates chose not to disclose their disability status, the LLMs were less\nlikely to select them compared to those who explicitly stated they did not have\na disability.",
    "pdf_url": "http://arxiv.org/pdf/2506.00256v1",
    "published": "2025-05-30T21:44:17+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00255v1",
    "title": "Bicomplex polar weighted homogeneous polynomials",
    "authors": [
      "Yesenia Bravo",
      "Inácio Rabelo",
      "Agustín Romano-Velázquez"
    ],
    "abstract": "We study the topology of real polynomial maps $\\mathbb{R}^{4n}\n\\longrightarrow \\mathbb{R}^{4}$ expressed in terms of bicomplex variables and\ntheir conjugates, which we refer to as bicomplex mixed polynomials. We\nintroduce the notion of polar weighted homogeneity, a property that generalizes\nthe concept of weighted homogeneity in the complex setting. This leads to the\nexistence of global and spherical Milnor fibrations. Moreover, we include a\ndiscussion on bicomplex vector calculus, a bicomplex holomorphic analogue of\nthe Milnor fibration theorem, and a theorem of Join type that describes the\nhomotopy type of the fibers of certain polynomials on separable variables. This\nextends previous works on mixed polynomials in complex variables and their\nconjugates.",
    "pdf_url": "http://arxiv.org/pdf/2506.00255v1",
    "published": "2025-05-30T21:44:05+00:00",
    "categories": [
      "math.AG",
      "Primary: 32S55, 30G35, Secondary: 32C18, 14B05"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00254v1",
    "title": "Pluto Geologic Map: Use of Crater Data to Understand Age Relationships",
    "authors": [
      "Kelsi N. Singer",
      "Oliver L. White",
      "Sarah Greenstreet",
      "Jeffrey M. Moore",
      "David A. Williams",
      "Rosaly M. C. Lopes"
    ],
    "abstract": "Pluto's surface displays a wide variety of geologic units from smooth plains\nto extremely rugged mountainous expanses. These terrains range in age from\nyoung, actively resurfaced regions (no observable craters even in the\nhighest-resolution New Horizons images) to old, heavily cratered, eroded\nregions. Here we expand upon the crater data analysis and the independent\ncrater data set used in the production of a 1:7M scale geologic map of Pluto\nthat is to be published by the United States Geologic Survey (USGS). We present\nboth relative ages based on crater spatial density (number of craters in a\ngiven size bin per km^2) and also quantitative ages (e.g., 2 Ga) using the\nestimated impactor flux onto Pluto. The techniques presented here were\ndeveloped specifically for the information available from a USGS geologic map,\nwhere smaller craters are mapped as points only (no specific diameter\ninformation per crater). We developed a new type of visualization, called a\ndistributed R-plot, to understand the relative ages of the geologic units. The\nuncertainties in the current knowledge of the Kuiper belt populations and\nimpactor flux at Pluto propagate to large uncertainties in the estimated\nquantitative ages (~a factor of two). However, both relative and quantitative\nages from crater analysis were still valuable tools in developing the sequence\nof geologic events. Pluto has large areas of crater-free young terrains (13\nunits making up ~27% of mapped higher-resolution surface area), with widely\nvarying morphologies, indicating a variety of resurfacing mechanisms, both\nexogenic and endogenic, likely active into Pluto's recent past or present.",
    "pdf_url": "http://arxiv.org/pdf/2506.00254v1",
    "published": "2025-05-30T21:41:56+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00253v3",
    "title": "Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race",
    "authors": [
      "Lihao Sun",
      "Chengzhi Mao",
      "Valentin Hofmann",
      "Xuechunzi Bai"
    ],
    "abstract": "Although value-aligned language models (LMs) appear unbiased in explicit bias\nevaluations, they often exhibit stereotypes in implicit word association tasks,\nraising concerns about their fair usage. We investigate the mechanisms behind\nthis discrepancy and find that alignment surprisingly amplifies implicit bias\nin model outputs. Specifically, we show that aligned LMs, unlike their\nunaligned counterparts, overlook racial concepts in early internal\nrepresentations when the context is ambiguous. Not representing race likely\nfails to activate safety guardrails, leading to unintended biases. Inspired by\nthis insight, we propose a new bias mitigation strategy that works by\nincentivizing the representation of racial concepts in the early model layers.\nIn contrast to conventional mitigation methods of machine unlearning, our\ninterventions find that steering the model to be more aware of racial concepts\neffectively mitigates implicit bias. Similar to race blindness in humans,\nignoring racial nuances can inadvertently perpetuate subtle biases in LMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00253v3",
    "published": "2025-05-30T21:41:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00252v1",
    "title": "How hard is learning to cut? Trade-offs and sample complexity",
    "authors": [
      "Sammy Khalife",
      "Andrea Lodi"
    ],
    "abstract": "In the recent years, branch-and-cut algorithms have been the target of\ndata-driven approaches designed to enhance the decision making in different\nphases of the algorithm such as branching, or the choice of cutting planes\n(cuts). In particular, for cutting plane selection two score functions have\nbeen proposed in the literature to evaluate the quality of a cut:\nbranch-and-cut tree size and gap closed. In this paper, we present new sample\ncomplexity lower bounds, valid for both scores. We show that for a wide family\nof classes $\\mathcal{F}$ that maps an instance to a cut, learning over an\nunknown distribution of the instances to minimize those scores requires at\nleast (up to multiplicative constants) as many samples as learning from the\nsame class function $\\mathcal{F}$ any generic target function (using square\nloss). Our results also extend to the case of learning from a restricted set of\ncuts, namely those from the Simplex tableau. To the best of our knowledge,\nthese constitute the first lower bounds for the learning-to-cut framework. We\ncompare our bounds to known upper bounds in the case of neural networks and\nshow they are nearly tight. We illustrate our results with a graph neural\nnetwork selection evaluated on set covering and facility location integer\nprogramming models and we empirically show that the gap closed score is an\neffective proxy to minimize the branch-and-cut tree size. Although the gap\nclosed score has been extensively used in the integer programming literature,\nthis is the first principled analysis discussing both scores at the same time\nboth theoretically and computationally.",
    "pdf_url": "http://arxiv.org/pdf/2506.00252v1",
    "published": "2025-05-30T21:41:01+00:00",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00251v1",
    "title": "Frequency Automata: A novel formal model of hybrid systems in combined time and frequency domains",
    "authors": [
      "Moon Kim",
      "Avinash Malik",
      "Partha Roop"
    ],
    "abstract": "Hybrid systems are mostly modelled, simulated, and verified in the time\ndomain by computer scientists. Engineers, however, use both frequency and time\ndomain modelling due to their distinct advantages. For example, frequency\ndomain modelling is better suited for control systems, using features such as\nspectra of the signal. Considering this, we introduce, for the first time, a\nformal model called frequency automata for hybrid systems modelling and\nsimulation, which are represented in combined time and frequency domains. We\npropose a sound translation from Hybrid Automata (HA) to Frequency Automata\n(FA). We also develop a numerical simulator for FA and compare it with the\nperformance of HA. Our approach provides precise level crossing detection and\nefficient simulation of hybrid systems. We provide empirical results comparing\nsimulation of HA via its translation to FA and its simulation via Matlab\nSimulink/Stateflow. The results show clear superiority of the proposed\ntechnique with the execution times of the proposed technique 118x to 1129x\nfaster compared to Simulink/Stateflow. Moreover, we also observe that the\nproposed technique is able to detect level crossing with complex guards\n(including equality), which Simulink/Stateflow fail.",
    "pdf_url": "http://arxiv.org/pdf/2506.00251v1",
    "published": "2025-05-30T21:40:44+00:00",
    "categories": [
      "cs.FL"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00250v3",
    "title": "PersianMedQA: Evaluating Large Language Models on a Persian-English Bilingual Medical Question Answering Benchmark",
    "authors": [
      "Mohammad Javad Ranjbar Kalahroodi",
      "Amirhossein Sheikholselami",
      "Sepehr Karimi",
      "Sepideh Ranjbar Kalahroodi",
      "Heshaam Faili",
      "Azadeh Shakery"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable performance on a wide\nrange of Natural Language Processing (NLP) benchmarks, often surpassing\nhuman-level accuracy. However, their reliability in high-stakes domains such as\nmedicine, particularly in low-resource languages, remains underexplored. In\nthis work, we introduce PersianMedQA, a large-scale dataset of 20,785\nexpert-validated multiple-choice Persian medical questions from 14 years of\nIranian national medical exams, spanning 23 medical specialties and designed to\nevaluate LLMs in both Persian and English. We benchmark 40 state-of-the-art\nmodels, including general-purpose, Persian fine-tuned, and medical LLMs, in\nzero-shot and chain-of-thought (CoT) settings. Our results show that\nclosed-source general models (e.g., GPT-4.1) consistently outperform all other\ncategories, achieving 83.09% accuracy in Persian and 80.7% in English, while\nPersian fine-tuned models such as Dorna underperform significantly (e.g., 34.9%\nin Persian), often struggling with both instruction-following and domain\nreasoning. We also analyze the impact of translation, showing that while\nEnglish performance is generally higher, 3-10% of questions can only be\nanswered correctly in Persian due to cultural and clinical contextual cues that\nare lost in translation. Finally, we demonstrate that model size alone is\ninsufficient for robust performance without strong domain or language\nadaptation. PersianMedQA provides a foundation for evaluating bilingual and\nculturally grounded medical reasoning in LLMs. The PersianMedQA dataset is\navailable: https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA .",
    "pdf_url": "http://arxiv.org/pdf/2506.00250v3",
    "published": "2025-05-30T21:34:30+00:00",
    "categories": [
      "cs.CL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00249v1",
    "title": "MIR: Methodology Inspiration Retrieval for Scientific Research Problems",
    "authors": [
      "Aniketh Garikaparthi",
      "Manasi Patwardhan",
      "Aditya Sanjiv Kanade",
      "Aman Hassan",
      "Lovekesh Vig",
      "Arman Cohan"
    ],
    "abstract": "There has been a surge of interest in harnessing the reasoning capabilities\nof Large Language Models (LLMs) to accelerate scientific discovery. While\nexisting approaches rely on grounding the discovery process within the relevant\nliterature, effectiveness varies significantly with the quality and nature of\nthe retrieved literature. We address the challenge of retrieving prior work\nwhose concepts can inspire solutions for a given research problem, a task we\ndefine as Methodology Inspiration Retrieval (MIR). We construct a novel dataset\ntailored for training and evaluating retrievers on MIR, and establish\nbaselines. To address MIR, we build the Methodology Adjacency Graph (MAG);\ncapturing methodological lineage through citation relationships. We leverage\nMAG to embed an \"intuitive prior\" into dense retrievers for identifying\npatterns of methodological inspiration beyond superficial semantic similarity.\nThis achieves significant gains of +5.4 in Recall@3 and +7.8 in Mean Average\nPrecision (mAP) over strong baselines. Further, we adapt LLM-based re-ranking\nstrategies to MIR, yielding additional improvements of +4.5 in Recall@3 and\n+4.8 in mAP. Through extensive ablation studies and qualitative analyses, we\nexhibit the promise of MIR in enhancing automated scientific discovery and\noutline avenues for advancing inspiration-driven retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2506.00249v1",
    "published": "2025-05-30T21:33:03+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00248v1",
    "title": "A higher dimensional generalization of the Kitaev spin liquid",
    "authors": [
      "Po-Jui Chen",
      "Piers Coleman"
    ],
    "abstract": "We construct an exactly solvable model of a four-dimensional Kitaev spin\nliquid. The lattice structure is orthorhombic and each unit-cell contains six\nsublattice degrees of freedom. We demonstrate that the Fermi surface of the\nmodel is made up of two-dimensional surfaces. Additionally, we evaluate the\nenergy cost of creating visons using scattering theory. The positive bond-flip\nenergy suggests that the system's ground state is flux-free, similar to the\ntwo-dimensional Kitaev honeycomb model. Our model sheds light on the\nrealization of high-dimensional fractionalization. high-dimensional\nfractionalization.",
    "pdf_url": "http://arxiv.org/pdf/2506.00248v1",
    "published": "2025-05-30T21:28:21+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.00247v1",
    "title": "Performance Analysis of Convolutional Neural Network By Applying Unconstrained Binary Quadratic Programming",
    "authors": [
      "Aasish Kumar Sharma",
      "Sanjeeb Prashad Pandey",
      "Julian M. Kunkel"
    ],
    "abstract": "Convolutional Neural Networks (CNNs) are pivotal in computer vision and Big\nData analytics but demand significant computational resources when trained on\nlarge-scale datasets. Conventional training via back-propagation (BP) with\nlosses like Mean Squared Error or Cross-Entropy often requires extensive\niterations and may converge sub-optimally. Quantum computing offers a promising\nalternative by leveraging superposition, tunneling, and entanglement to search\ncomplex optimization landscapes more efficiently. In this work, we propose a\nhybrid optimization method that combines an Unconstrained Binary Quadratic\nProgramming (UBQP) formulation with Stochastic Gradient Descent (SGD) to\naccelerate CNN training. Evaluated on the MNIST dataset, our approach achieves\na 10--15\\% accuracy improvement over a standard BP-CNN baseline while\nmaintaining similar execution times. These results illustrate the potential of\nhybrid quantum-classical techniques in High-Performance Computing (HPC)\nenvironments for Big Data and Deep Learning. Fully realizing these benefits,\nhowever, requires a careful alignment of algorithmic structures with underlying\nquantum mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2506.00247v1",
    "published": "2025-05-30T21:25:31+00:00",
    "categories": [
      "cs.LG",
      "cs.ET"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00246v1",
    "title": "Automatic detection of overshooting tops and their properties from visible satellite channels",
    "authors": [
      "Anežka Doležalová",
      "Jakub Seidl",
      "Jindřich Šťástka",
      "Ján Kaňák"
    ],
    "abstract": "Overshooting tops (OTs) are critical indicators of convective storm intensity\nand are widely utilized in meteorological analyses. This study presents an\nautomated algorithm for OT detection and OT height estimation using\nconvolutional neural networks applied to visible satellite imagery. The models\nare trained and validated on an extensive OT dataset comprising approximately\n10,000 manually detected cases over Europe. The OTs were identified from\nhigh-resolution visible (HRV) channel of the SEVIRI instrument on board the MSG\ngeostationary satellite, with the heights determined from the length of their\nshadows in the imagery. While conventional OT detection methods primarily rely\non the identification of cold features in thermal infrared channels, our\napproach extracts information from visible channels, leveraging the ground\ntruth data on OT shadow length provided by the training dataset. In the morning\nand afternoon hours, when the shadows are visible, the proposed models detect\nOTs with a probability of detection reaching 95% and estimate their height with\nan average error of 0.25 km. The performance is expected to further improve\nonce the model is applied to polar and new generation geostationary satellite\nwith increased spatial resolution.",
    "pdf_url": "http://arxiv.org/pdf/2506.00246v1",
    "published": "2025-05-30T21:24:10+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00245v1",
    "title": "Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity",
    "authors": [
      "Dang Nguyen",
      "Ali Payani",
      "Baharan Mirzasoleiman"
    ],
    "abstract": "Hallucination in large language models (LLMs) can be detected by assessing\nthe uncertainty of model outputs, typically measured using entropy. Semantic\nentropy (SE) enhances traditional entropy estimation by quantifying uncertainty\nat the semantic cluster level. However, as modern LLMs generate longer\none-sentence responses, SE becomes less effective because it overlooks two\ncrucial factors: intra-cluster similarity (the spread within a cluster) and\ninter-cluster similarity (the distance between clusters). To address these\nlimitations, we propose a simple black-box uncertainty quantification method\ninspired by nearest neighbor estimates of entropy. Our approach can also be\neasily extended to white-box settings by incorporating token probabilities.\nAdditionally, we provide theoretical results showing that our method\ngeneralizes semantic entropy. Extensive empirical results demonstrate its\neffectiveness compared to semantic entropy across two recent LLMs (Phi3 and\nLlama3) and three common text generation tasks: question answering, text\nsummarization, and machine translation. Our code is available at\nhttps://github.com/BigML-CS-UCLA/SNNE.",
    "pdf_url": "http://arxiv.org/pdf/2506.00245v1",
    "published": "2025-05-30T21:21:05+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00244v1",
    "title": "DeGLIF for Label Noise Robust Node Classification using GNNs",
    "authors": [
      "Pintu Kumar",
      "Nandyala Hemachandra"
    ],
    "abstract": "Noisy labelled datasets are generally inexpensive compared to clean labelled\ndatasets, and the same is true for graph data. In this paper, we propose a\ndenoising technique DeGLIF: Denoising Graph Data using Leave-One-Out Influence\nFunction. DeGLIF uses a small set of clean data and the leave-one-out influence\nfunction to make label noise robust node-level prediction on graph data.\nLeave-one-out influence function approximates the change in the model\nparameters if a training point is removed from the training dataset. Recent\nadvances propose a way to calculate the leave-one-out influence function for\nGraph Neural Networks (GNNs). We extend that recent work to estimate the change\nin validation loss, if a training node is removed from the training dataset. We\nuse this estimate and a new theoretically motivated relabelling function to\ndenoise the training dataset. We propose two DeGLIF variants to identify noisy\nnodes. Both these variants do not require any information about the noise model\nor the noise level in the dataset; DeGLIF also does not estimate these\nquantities. For one of these variants, we prove that the noisy points detected\ncan indeed increase risk. We carry out detailed computational experiments on\ndifferent datasets to show the effectiveness of DeGLIF. It achieves better\naccuracy than other baseline algorithms",
    "pdf_url": "http://arxiv.org/pdf/2506.00244v1",
    "published": "2025-05-30T21:20:40+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00243v2",
    "title": "Influence of a Perfectly Conducting Plate on the Uehling Potential of QED",
    "authors": [
      "Thales Azevedo",
      "Fabricio A. Barone",
      "Carlos Farina",
      "Reinaldo de Melo e Souza",
      "Gabriel Zarpelon"
    ],
    "abstract": "In this work, we investigate the influence of a perfectly conducting plate on\nthe Uehling potential of Quantum Electrodynamics (QED), corresponding to the\nfirst loop correction to the classical Coulomb potential in that situation. We\nuse the method of images adapted to the photon propagator, extending the method\nbeyond the standard (classical) tree level calculation. We show that the effect\nof the plate on the quantum correction is much stronger than the expectation\nfrom a naive application of the method of images.",
    "pdf_url": "http://arxiv.org/pdf/2506.00243v2",
    "published": "2025-05-30T21:19:48+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.00242v1",
    "title": "Whispers of Many Shores: Cultural Alignment through Collaborative Cultural Expertise",
    "authors": [
      "Shuai Feng",
      "Wei-Chuang Chan",
      "Srishti Chouhan",
      "Junior Francisco Garcia Ayala",
      "Srujananjali Medicherla",
      "Kyle Clark",
      "Mingwei Shi"
    ],
    "abstract": "The integration of large language models (LLMs) into global applications\nnecessitates effective cultural alignment for meaningful and\nculturally-sensitive interactions. Current LLMs often lack the nuanced\nunderstanding required for diverse cultural contexts, and adapting them\ntypically involves costly full fine-tuning. To address this, we introduce a\nnovel soft prompt fine-tuning framework that enables efficient and modular\ncultural alignment. Our method utilizes vectorized prompt tuning to dynamically\nroute queries to a committee of culturally specialized 'expert' LLM\nconfigurations, created by optimizing soft prompt embeddings without altering\nthe base model's parameters. Extensive experiments demonstrate that our\nframework significantly enhances cultural sensitivity and adaptability,\nimproving alignment scores from 0.208 to 0.820, offering a robust solution for\nculturally-aware LLM deployment. This research paves the way for subsequent\ninvestigations into enhanced cultural coverage and dynamic expert adaptation,\ncrucial for realizing autonomous AI with deeply nuanced understanding in a\nglobally interconnected world.",
    "pdf_url": "http://arxiv.org/pdf/2506.00242v1",
    "published": "2025-05-30T21:16:25+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00241v1",
    "title": "Designing AI Tools for Clinical Care Teams to Support Serious Illness Conversations with Older Adults in the Emergency Department",
    "authors": [
      "Menglin Zhao",
      "Zhuorui Yong",
      "Ruijia Guan",
      "Kai-Wei Chang",
      "Adrian Haimovich",
      "Kei Ouchi",
      "Timothy Bickmore",
      "Bingsheng Yao",
      "Dakuo Wang",
      "Smit Desai"
    ],
    "abstract": "Serious illness conversations (SICs), discussions between clinical care teams\nand patients with serious, life-limiting illnesses about their values, goals,\nand care preferences, are critical for patient-centered care. Without these\nconversations, patients often receive aggressive interventions that may not\nalign with their goals. Clinical care teams face significant barriers when\nconducting serious illness conversations with older adult patients in Emergency\nDepartment (ED) settings, where most older adult patients lack documented\ntreatment goals. To understand current practices and identify AI support\nopportunities, we conducted interviews with two domain experts and nine ED\nclinical care team members. Through thematic analysis, we characterized a\nfour-phase serious illness conversation workflow (identification, preparation,\nconduction, documentation) and identified key needs and challenges at each\nstage. Clinical care teams struggle with fragmented EHR data access, time\nconstraints, emotional preparation demands, and documentation burdens. While\nparticipants expressed interest in AI tools for information synthesis,\nconversational support, and automated documentation, they emphasized preserving\nhuman connection and clinical autonomy. We present design guidelines for AI\ntools supporting SIC workflows that fit within existing clinical practices.\nThis work contributes empirical understanding of ED-based serious illness\nconversations and provides design considerations for AI in high-stakes clinical\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00241v1",
    "published": "2025-05-30T21:15:57+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00240v1",
    "title": "Stellar populations in STARFORGE II: Comparison with observations",
    "authors": [
      "Juan P. Farias",
      "Stella S. R. Offner",
      "Ronan Kerr",
      "Michael Y. Grudić"
    ],
    "abstract": "Recent studies suggest that most star-forming regions in our Galaxy form\nstellar associations rather than bound clusters. We analyse models from the\nSTARFORGE simulation suite, a set of magneto-hydrodynamical simulations that\ninclude all key stellar feedback and radiative processes following star\nformation through cloud dispersal. We create synthetic observations by\nintroducing observational biases such as random spurious measurements,\nunresolved binaries, and photometric sensitivity. These biases affect the\nmeasurement of the group mass, size, and velocity dispersion, introducing\nuncertainties of up to 100%, with accuracy improving as the number of system\nmembers increases. Furthermore, models favouring the formation of groups around\nmassive stars were the most affected by observational biases, as massive stars\ncontribute a larger fraction of the group mass and are often missing from\nastrometric surveys like Gaia. We compare the simulations to the Cepheus Far\nNorth (CFN) region, and show that CFN groups may have formed in a low-density\nenvironment similar to those modelled in STARFORGE but with massive stars not\nlocated preferentially in groups. We also question the effectiveness of the\nkinematic traceback method, showing that it is accurate within 20% only for\ncertain associations with actual virial parameters above 2. However,\nobservational biases can artificially raise the virial parameter by up to a\nfactor ten, making it difficult to evaluate the reliability of the traceback\nage. Additionally, since stars continue to form during the dispersal of the\nparent cloud, we find no relation between the stellar-dynamical age difference\nand the length of the embedded phase.",
    "pdf_url": "http://arxiv.org/pdf/2506.00240v1",
    "published": "2025-05-30T21:15:55+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00239v1",
    "title": "SMELLNET: A Large-scale Dataset for Real-world Smell Recognition",
    "authors": [
      "Dewei Feng",
      "Carol Li",
      "Wei Dai",
      "Paul Pu Liang"
    ],
    "abstract": "The ability of AI to sense and identify various substances based on their\nsmell alone can have profound impacts on allergen detection (e.g., smelling\ngluten or peanuts in a cake), monitoring the manufacturing process, and sensing\nhormones that indicate emotional states, stress levels, and diseases. Despite\nthese broad impacts, there are virtually no large scale benchmarks, and\ntherefore little progress, for training and evaluating AI systems' ability to\nsmell in the real world. In this paper, we use portable gas and chemical\nsensors to create SmellNet, the first large-scale database that digitizes a\ndiverse range of smells in the natural world. SmellNet contains about 180,000\ntime steps of 50 substances (spanning nuts, spices, herbs, fruits, and\nvegetables) with 50 hours of data. Using SmellNet, we train AI models for\nreal-time classification of substances based on their smell alone. Our best\nmethods leverage sequence models, contrastive learning to integrate\nhigh-resolution Gas Chromatography-Mass Spectrometry molecular data, and a new\ntemporal difference method that identifies sharp changes in sensor readings.\nOur best models achieve up to 65.35% accuracy on pre-recorded data, and\ngeneralize to real-world conditions with 10.71% accuracy on nuts and 25.38% on\nspices in the challenging 50-way online classification task. Despite these\npromising results, SmellNet highlights many technical challenges in building AI\nfor smell, including richer feature learning, on-edge smell models, and\nrobustness to environmental changes.",
    "pdf_url": "http://arxiv.org/pdf/2506.00239v1",
    "published": "2025-05-30T21:15:25+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00238v1",
    "title": "ZeShot-VQA: Zero-Shot Visual Question Answering Framework with Answer Mapping for Natural Disaster Damage Assessment",
    "authors": [
      "Ehsan Karimi",
      "Maryam Rahnemoonfar"
    ],
    "abstract": "Natural disasters usually affect vast areas and devastate infrastructures.\nPerforming a timely and efficient response is crucial to minimize the impact on\naffected communities, and data-driven approaches are the best choice. Visual\nquestion answering (VQA) models help management teams to achieve in-depth\nunderstanding of damages. However, recently published models do not possess the\nability to answer open-ended questions and only select the best answer among a\npredefined list of answers. If we want to ask questions with new additional\npossible answers that do not exist in the predefined list, the model needs to\nbe fin-tuned/retrained on a new collected and annotated dataset, which is a\ntime-consuming procedure. In recent years, large-scale Vision-Language Models\n(VLMs) have earned significant attention. These models are trained on extensive\ndatasets and demonstrate strong performance on both unimodal and multimodal\nvision/language downstream tasks, often without the need for fine-tuning. In\nthis paper, we propose a VLM-based zero-shot VQA (ZeShot-VQA) method, and\ninvestigate the performance of on post-disaster FloodNet dataset. Since the\nproposed method takes advantage of zero-shot learning, it can be applied on new\ndatasets without fine-tuning. In addition, ZeShot-VQA is able to process and\ngenerate answers that has been not seen during the training procedure, which\ndemonstrates its flexibility.",
    "pdf_url": "http://arxiv.org/pdf/2506.00238v1",
    "published": "2025-05-30T21:15:11+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "I.2.7; I.2.10; I.5.1"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00237v3",
    "title": "A New State of Matter between the Hadronic Phase and the Quark-Gluon Plasma?",
    "authors": [
      "Yuki Fujimoto",
      "Kenji Fukushima",
      "Yoshimasa Hidaka",
      "Larry McLerran"
    ],
    "abstract": "Lattice-QCD simulations and theoretical arguments hint at the existence of an\nintermediate phase of strongly interacting matter between a confined hadron gas\nand a deconfined Quark-Gluon Plasma (QGP). We qualitatively and\nsemi-quantitatively explore and differentiate the phase structures in the\ntemperature window from the QCD pseudo-critical temperature $T_c\\simeq\n160\\;\\text{MeV}$ to the pure-gluonic deconfinement temperature $T_d\\simeq\n285\\;\\text{MeV}$. We propose a three-regime picture using a hadron resonance\ngas (HRG) description augmented with the glueball spectrum based on the\nanalysis of a large number, $N_c$, of colors. We estimate the entropy density\nfrom our model to confirm that the lattice-QCD data are bracketed with three\nregimes, i.e., a hadron gas, a QGP, and a new phase for $T_c \\lesssim T\n\\lesssim T_d$. In this new phase that we name a Spaghetti of Quarks with\nGlueballs (SQGB), thermal degrees of freedom of quarks are deconfined, yet\ngluons remain confined in glueballs. Since the Hagedorn temperature, $T_H\\sim\n285\\;\\text{MeV}$, is universal in the meson and the glueball sectors, in the\ninfinite $N_c$ limit, the phase diagram in the plane of the baryon chemical\npotential and the temperature is reduced to the one with the confined and\ndeconfined phases and Quarkyonic Matter at high density. At large but finite\n$N_c$, an SQGB window may open between these phases. We point out that the SQGB\nhas interesting similarities with Quarkyonic Matter and that this matter in the\nlarge $N_c$ limit is confined as measured by the interaction between heavy\nquarks, but behaves in other respects like a quasi-free gas of quarks. As a\nresult of the extrapolation to $N_c=3$, we present a revised phase diagram with\nthe SQGB phase bounded by thermal crossovers. Finally, we give a quantitative\nanalysis of chiral symmetry restoration in the SQGB phase.",
    "pdf_url": "http://arxiv.org/pdf/2506.00237v3",
    "published": "2025-05-30T21:15:07+00:00",
    "categories": [
      "hep-ph",
      "hep-lat",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00236v1",
    "title": "Localized LoRA: A Structured Low-Rank Approximation for Efficient Fine-Tuning",
    "authors": [
      "Babak Barazandeh"
    ],
    "abstract": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, offer compact\nand effective alternatives to full model fine-tuning by introducing low-rank\nupdates to pretrained weights. However, most existing approaches rely on global\nlow-rank structures, which can overlook spatial patterns spread across the\nparameter space. In this work, we propose Localized LoRA, a generalized\nframework that models weight updates as a composition of low-rank matrices\napplied to structured blocks of the weight matrix. This formulation enables\ndense, localized updates throughout the parameter space-without increasing the\ntotal number of trainable parameters. We provide a formal comparison between\nglobal, diagonal-local, and fully localized low-rank approximations, and show\nthat our method consistently achieves lower approximation error under matched\nparameter budgets. Experiments on both synthetic and practical settings\ndemonstrate that Localized LoRA offers a more expressive and adaptable\nalternative to existing methods, enabling efficient fine-tuning with improved\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2506.00236v1",
    "published": "2025-05-30T21:13:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00235v1",
    "title": "MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible Extensibility",
    "authors": [
      "Yexiao He",
      "Ang Li",
      "Boyi Liu",
      "Zhewei Yao",
      "Yuxiong He"
    ],
    "abstract": "Healthcare decision-making represents one of the most challenging domains for\nArtificial Intelligence (AI), requiring the integration of diverse knowledge\nsources, complex reasoning, and various external analytical tools. Current AI\nsystems often rely on either task-specific models, which offer limited\nadaptability, or general language models without grounding with specialized\nexternal knowledge and tools. We introduce MedOrch, a novel framework that\norchestrates multiple specialized tools and reasoning agents to provide\ncomprehensive medical decision support. MedOrch employs a modular, agent-based\narchitecture that facilitates the flexible integration of domain-specific tools\nwithout altering the core system. Furthermore, it ensures transparent and\ntraceable reasoning processes, enabling clinicians to meticulously verify each\nintermediate step underlying the system's recommendations. We evaluate MedOrch\nacross three distinct medical applications: Alzheimer's disease diagnosis,\nchest X-ray interpretation, and medical visual question answering, using\nauthentic clinical datasets. The results demonstrate MedOrch's competitive\nperformance across these diverse medical tasks. Notably, in Alzheimer's disease\ndiagnosis, MedOrch achieves an accuracy of 93.26%, surpassing the\nstate-of-the-art baseline by over four percentage points. For predicting\nAlzheimer's disease progression, it attains a 50.35% accuracy, marking a\nsignificant improvement. In chest X-ray analysis, MedOrch exhibits superior\nperformance with a Macro AUC of 61.2% and a Macro F1-score of 25.5%. Moreover,\nin complex multimodal visual question answering (Image+Table), MedOrch achieves\nan accuracy of 54.47%. These findings underscore MedOrch's potential to advance\nhealthcare AI by enabling reasoning-driven tool utilization for multimodal\nmedical data processing and supporting intricate cognitive tasks in clinical\ndecision-making.",
    "pdf_url": "http://arxiv.org/pdf/2506.00235v1",
    "published": "2025-05-30T21:13:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00234v2",
    "title": "Multisymplectic observable reduction using constraint triples",
    "authors": [
      "Antonio Michele Miti",
      "Leonid Ryvkin"
    ],
    "abstract": "The purpose of this paper is to present a fully algebraic formalism for the\nconstruction and reduction of $L_\\infty$-algebras of observables inspired by\nmultisymplectic geometry, using Gerstenhaber algebras, BV-modules, and the\nconstraint triple formalism. In the \"geometric case\", we reconstruct and\nconceptually explain the recent results of arXiv:2206.03137(3).",
    "pdf_url": "http://arxiv.org/pdf/2506.00234v2",
    "published": "2025-05-30T21:12:02+00:00",
    "categories": [
      "math.SG",
      "math.DG",
      "math.RA",
      "53D20 (primary) 53D05, 16W50 (secondary)"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00233v1",
    "title": "Ethical AI: Towards Defining a Collective Evaluation Framework",
    "authors": [
      "Aasish Kumar Sharma",
      "Dimitar Kyosev",
      "Julian Kunkel"
    ],
    "abstract": "Artificial Intelligence (AI) is transforming sectors such as healthcare,\nfinance, and autonomous systems, offering powerful tools for innovation. Yet\nits rapid integration raises urgent ethical concerns related to data ownership,\nprivacy, and systemic bias. Issues like opaque decision-making, misleading\noutputs, and unfair treatment in high-stakes domains underscore the need for\ntransparent and accountable AI systems. This article addresses these challenges\nby proposing a modular ethical assessment framework built on ontological blocks\nof meaning-discrete, interpretable units that encode ethical principles such as\nfairness, accountability, and ownership. By integrating these blocks with FAIR\n(Findable, Accessible, Interoperable, Reusable) principles, the framework\nsupports scalable, transparent, and legally aligned ethical evaluations,\nincluding compliance with the EU AI Act. Using a real-world use case in\nAI-powered investor profiling, the paper demonstrates how the framework enables\ndynamic, behavior-informed risk classification. The findings suggest that\nontological blocks offer a promising path toward explainable and auditable AI\nethics, though challenges remain in automation and probabilistic reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2506.00233v1",
    "published": "2025-05-30T21:10:47+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00232v1",
    "title": "ComposeRAG: A Modular and Composable RAG for Corpus-Grounded Multi-Hop Question Answering",
    "authors": [
      "Ruofan Wu",
      "Youngwon Lee",
      "Fan Shu",
      "Danmei Xu",
      "Seung-won Hwang",
      "Zhewei Yao",
      "Yuxiong He",
      "Feng Yan"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems are increasingly diverse, yet\nmany suffer from monolithic designs that tightly couple core functions like\nquery reformulation, retrieval, reasoning, and verification. This limits their\ninterpretability, systematic evaluation, and targeted improvement, especially\nfor complex multi-hop question answering. We introduce ComposeRAG, a novel\nmodular abstraction that decomposes RAG pipelines into atomic, composable\nmodules. Each module, such as Question Decomposition, Query Rewriting,\nRetrieval Decision, and Answer Verification, acts as a parameterized\ntransformation on structured inputs/outputs, allowing independent\nimplementation, upgrade, and analysis. To enhance robustness against errors in\nmulti-step reasoning, ComposeRAG incorporates a self-reflection mechanism that\niteratively revisits and refines earlier steps upon verification failure.\nEvaluated on four challenging multi-hop QA benchmarks, ComposeRAG consistently\noutperforms strong baselines in both accuracy and grounding fidelity.\nSpecifically, it achieves up to a 15% accuracy improvement over\nfine-tuning-based methods and up to a 5% gain over reasoning-specialized\npipelines under identical retrieval conditions. Crucially, ComposeRAG\nsignificantly enhances grounding: its verification-first design reduces\nungrounded answers by over 10% in low-quality retrieval settings, and by\napproximately 3% even with strong corpora. Comprehensive ablation studies\nvalidate the modular architecture, demonstrating distinct and additive\ncontributions from each component. These findings underscore ComposeRAG's\ncapacity to deliver flexible, transparent, scalable, and high-performing\nmulti-hop reasoning with improved grounding and interpretability.",
    "pdf_url": "http://arxiv.org/pdf/2506.00232v1",
    "published": "2025-05-30T21:10:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00231v1",
    "title": "Extensions of Schrödinger operators that generate $C_0$ contraction semigroups",
    "authors": [
      "Lawrence Frolov"
    ],
    "abstract": "Consider a non-relativistic quantum particle with wave function $\\psi$ in a\nbounded $C^2$ region $\\Omega \\subset \\mathbb{R}^n$, and suppose detectors are\nplaced along the boundary $\\partial \\Omega$. Assume the detection process is\nirreversible, its mechanism is time independent and also hard, i.e., detections\noccur only along the boundary $\\partial \\Omega$. Under these conditions Tumulka\nargued that the dynamics of $\\psi$ must be governed by a $C_0$ contraction\nsemigroup that weakly solves the Schr\\\"odinger equation and proposed modeling\nthe detector by a time-independent local absorbing boundary condition at\n$\\partial \\Omega$. In this paper, we apply the newly discovered theory of\nboundary quadruples to parameterize all $C_0$ contraction semigroups whose\ngenerators extend the Schr\\\"odinger Hamiltonian, and prove a variant of\nTumulka's claim: all such evolutions are generated by the placement of\n(potentially nonlocal) absorbing boundary conditions on $\\psi$ along $\\partial\n\\Omega$. We combine this result with the work of Werner to show that each $C_0$\ncontraction semigroup naturally admits a probability distribution for the time\nof detection along $\\partial \\Omega$, and we prove for a wide class of\nabsorbing boundary conditions that the probability of the particle being ever\ndetected is equal to $1$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00231v1",
    "published": "2025-05-30T21:08:15+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.08027v2",
    "title": "Recipes for Pre-training LLMs with MXFP8",
    "authors": [
      "Asit Mishra",
      "Dusan Stosic",
      "Simon Layton",
      "Paulius Micikevicius"
    ],
    "abstract": "Using fewer bits to represent model parameters and related tensors during\npre-training has become a required technique for improving GPU efficiency\nwithout sacrificing accuracy. Microscaling (MX) formats introduced in NVIDIA\nBlackwell generation of GPUs represent a major advancement of this technique,\nmaking it practical to combine narrow floating-point data types with finer\ngranularity per-block scaling factors. In turn, this enables both quantization\nof more tensors than previous approaches and more efficient execution of\noperations on those tensors.\n  Effective use of MX-formats requires careful choices of various parameters.\nIn this paper we review these choices and show how MXFP8-E4M3 datatype and a\nspecific number conversion algorithm result in training sessions that match\nthose carried out in BF16. We present results using models with up to 8B\nparameters, trained on high-quality datasets of up to 15T tokens.",
    "pdf_url": "http://arxiv.org/pdf/2506.08027v2",
    "published": "2025-05-30T21:08:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00230v1",
    "title": "Enhancing Spatio-Temporal Resolution of Process-Based Life Cycle Analysis with Model-Based Systems Engineering \\& Hetero-functional Graph Theory",
    "authors": [
      "Niraj Gohil",
      "Nawshad Haque",
      "Amgad Elgowainy",
      "Amro M. Farid"
    ],
    "abstract": "Life cycle analysis (LCA) has emerged as a vital tool for assessing the\nenvironmental impacts of products, processes, and systems throughout their\nentire lifecycle. It provides a systematic approach to quantifying resource\nconsumption, emissions, and waste, enabling industries, researchers, and\npolicymakers to identify hotspots for sustainability improvements. By providing\na comprehensive assessment of systems, from raw material extraction to\nend-of-life disposal, LCA facilitates the development of environmentally sound\nstrategies, thereby contributing significantly to sustainable engineering and\ninformed decision-making. Despite its strengths and ubiquitous use, life cycle\nanalysis has not been reconciled with the broader literature in model-based\nsystems engineering and analysis, thus hindering its integration into the\ndesign of complex systems more generally. This lack of reconciliation poses a\nsignificant problem, as it hinders the seamless integration of environmental\nsustainability into the design and optimization of complex systems. Without\nalignment between life cycle analysis (LCA) and model-based systems engineering\n(MBSE), sustainability remains an isolated consideration rather than an\ninherent part of the system's architecture and design. The original\ncontribution of this paper is twofold. First, the paper reconciles\nprocess-based life cycle analysis with the broader literature and vocabulary of\nmodel-based systems engineering and hetero-functional graph theory. It\nultimately proves that model-based systems engineering and hetero-functional\ngraph theory are a formal generalization of process-based life cycle analysis.\nSecondly, the paper demonstrates how model-based systems engineering and\nhetero-functional graph theory may be used to enhance the spatio-temporal\nresolution of process-based life cycle analysis in a manner that aligns with\nsystem design objectives.",
    "pdf_url": "http://arxiv.org/pdf/2506.00230v1",
    "published": "2025-05-30T21:06:35+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00229v1",
    "title": "Where's the Line? A Classroom Activity on Ethical and Constructive Use of Generative AI in Physics",
    "authors": [
      "Zosia Krusberg"
    ],
    "abstract": "Generative AI tools like ChatGPT are rapidly reshaping how students and\ninstructors engage with course material-and how they think about academic\nintegrity. This paper presents a classroom activity designed to help physics\nstudents critically examine the ethical and educational implications of using\nAI in coursework. Through a structured sequence of case analysis, discussion,\nand optional policy drafting, students develop the metacognitive, ethical, and\ncollaborative skills needed to navigate emerging technologies with\nthoughtfulness and integrity. Grounded in research on constructivist learning,\nmetacognition, and student agency, the activity positions students as\nco-creators of an ethical and engaged learning environment.",
    "pdf_url": "http://arxiv.org/pdf/2506.00229v1",
    "published": "2025-05-30T21:05:55+00:00",
    "categories": [
      "physics.ed-ph"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00228v1",
    "title": "Sorrel: A simple and flexible framework for multi-agent reinforcement learning",
    "authors": [
      "Rebekah A. Gelpí",
      "Yibing Ju",
      "Ethan C. Jackson",
      "Yikai Tang",
      "Shon Verch",
      "Claas Voelcker",
      "William A. Cunningham"
    ],
    "abstract": "We introduce Sorrel (https://github.com/social-ai-uoft/sorrel), a simple\nPython interface for generating and testing new multi-agent reinforcement\nlearning environments. This interface places a high degree of emphasis on\nsimplicity and accessibility, and uses a more psychologically intuitive\nstructure for the basic agent-environment loop, making it a useful tool for\nsocial scientists to investigate how learning and social interaction leads to\nthe development and change of group dynamics. In this short paper, we outline\nthe basic design philosophy and features of Sorrel.",
    "pdf_url": "http://arxiv.org/pdf/2506.00228v1",
    "published": "2025-05-30T21:04:47+00:00",
    "categories": [
      "cs.MA",
      "cs.LG"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00227v1",
    "title": "Ctrl-Crash: Controllable Diffusion for Realistic Car Crashes",
    "authors": [
      "Anthony Gosselin",
      "Ge Ya Luo",
      "Luis Lara",
      "Florian Golemo",
      "Derek Nowrouzezahrai",
      "Liam Paull",
      "Alexia Jolicoeur-Martineau",
      "Christopher Pal"
    ],
    "abstract": "Video diffusion techniques have advanced significantly in recent years;\nhowever, they struggle to generate realistic imagery of car crashes due to the\nscarcity of accident events in most driving datasets. Improving traffic safety\nrequires realistic and controllable accident simulations. To tackle the\nproblem, we propose Ctrl-Crash, a controllable car crash video generation model\nthat conditions on signals such as bounding boxes, crash types, and an initial\nimage frame. Our approach enables counterfactual scenario generation where\nminor variations in input can lead to dramatically different crash outcomes. To\nsupport fine-grained control at inference time, we leverage classifier-free\nguidance with independently tunable scales for each conditioning signal.\nCtrl-Crash achieves state-of-the-art performance across quantitative video\nquality metrics (e.g., FVD and JEDi) and qualitative measurements based on a\nhuman-evaluation of physical realism and video quality compared to prior\ndiffusion-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00227v1",
    "published": "2025-05-30T21:04:38+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00226v1",
    "title": "Riemannian Principal Component Analysis",
    "authors": [
      "Oldemar Rodríguez"
    ],
    "abstract": "This paper proposes an innovative extension of Principal Component Analysis\n(PCA) that transcends the traditional assumption of data lying in Euclidean\nspace, enabling its application to data on Riemannian manifolds. The primary\nchallenge addressed is the lack of vector space operations on such manifolds.\nFletcher et al., in their work {\\em Principal Geodesic Analysis for the Study\nof Nonlinear Statistics of Shape}, proposed Principal Geodesic Analysis (PGA)\nas a geometric approach to analyze data on Riemannian manifolds, particularly\neffective for structured datasets like medical images, where the manifold's\nintrinsic structure is apparent. However, PGA's applicability is limited when\ndealing with general datasets that lack an implicit local distance notion. In\nthis work, we introduce a generalized framework, termed {\\em Riemannian\nPrincipal Component Analysis (R-PCA)}, to extend PGA for any data endowed with\na local distance structure. Specifically, we adapt the PCA methodology to\nRiemannian manifolds by equipping data tables with local metrics, enabling the\nincorporation of manifold geometry. This framework provides a unified approach\nfor dimensionality reduction and statistical analysis directly on manifolds,\nopening new possibilities for datasets with region-specific or part-specific\ndistance notions, ensuring respect for their intrinsic geometric properties.",
    "pdf_url": "http://arxiv.org/pdf/2506.00226v1",
    "published": "2025-05-30T21:04:01+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.CO",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00225v1",
    "title": "Understanding while Exploring: Semantics-driven Active Mapping",
    "authors": [
      "Liyan Chen",
      "Huangying Zhan",
      "Hairong Yin",
      "Yi Xu",
      "Philippos Mordohai"
    ],
    "abstract": "Effective robotic autonomy in unknown environments demands proactive\nexploration and precise understanding of both geometry and semantics. In this\npaper, we propose ActiveSGM, an active semantic mapping framework designed to\npredict the informativeness of potential observations before execution. Built\nupon a 3D Gaussian Splatting (3DGS) mapping backbone, our approach employs\nsemantic and geometric uncertainty quantification, coupled with a sparse\nsemantic representation, to guide exploration. By enabling robots to\nstrategically select the most beneficial viewpoints, ActiveSGM efficiently\nenhances mapping completeness, accuracy, and robustness to noisy semantic data,\nultimately supporting more adaptive scene exploration. Our experiments on the\nReplica and Matterport3D datasets highlight the effectiveness of ActiveSGM in\nactive semantic mapping tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00225v1",
    "published": "2025-05-30T21:03:17+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00224v1",
    "title": "Automated Symmetric Constructions in Discrete Geometry",
    "authors": [
      "Bernardo Subercaseaux",
      "Ethan Mackey",
      "Long Qian",
      "Marijn J. H. Heule"
    ],
    "abstract": "We present a computational methodology for obtaining rotationally symmetric\nsets of points satisfying discrete geometric constraints, and demonstrate its\napplicability by discovering new solutions to some well-known problems in\ncombinatorial geometry. Our approach takes the usage of SAT solvers in discrete\ngeometry further by directly embedding rotational symmetry into the\ncombinatorial encoding of geometric configurations. Then, to realize concrete\npoint sets corresponding to abstract designs provided by a SAT solver, we\nintroduce a novel local-search realizability solver, which shows excellent\npractical performance despite the intrinsic $\\exists \\mathbb{R}$-completeness\nof the problem. Leveraging this combined approach, we provide symmetric\nextremal solutions to the Erd\\H{o}s-Szekeres problem, as well as a minimal\nodd-sized solution with 21 points for the everywhere-unbalanced-points problem,\nimproving on the previously known 23-point configuration. The imposed\nsymmetries yield more aesthetically appealing solutions, enhancing human\ninterpretability, and simultaneously offer computational benefits by\nsignificantly reducing the number of variables required to encode discrete\ngeometric problems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00224v1",
    "published": "2025-05-30T21:00:43+00:00",
    "categories": [
      "cs.DM",
      "cs.CG"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00223v1",
    "title": "Enhancing Drug Discovery: Autoencoder-Based Latent Space Augmentation for Improved Molecular Solubility Prediction using LatMixSol",
    "authors": [
      "Mohammad Saleh Hasankhani"
    ],
    "abstract": "Accurate prediction of molecular solubility is a cornerstone of early-stage\ndrug discovery, yet conventional machine learning models face significant\nchallenges due to limited labeled data and the high-dimensional nature of\nmolecular descriptors. To address these issues, we propose LatMixSol, a novel\nlatent space augmentation framework that combines autoencoder-based feature\ncompression with guided interpolation to enrich training data. Our approach\nfirst encodes molecular descriptors into a low-dimensional latent space using a\ntwo-layer autoencoder. Spectral clustering is then applied to group chemically\nsimilar molecules, enabling targeted MixUp-style interpolation within clusters.\nSynthetic samples are generated by blending latent vectors of cluster members\nand decoding them back to the original feature space. Evaluated on the\nHuuskonen solubility benchmark, LatMixSol demonstrates consistent improvements\nacross three of four gradient-boosted regressors (CatBoost, LightGBM,\nHistGradientBoosting), achieving RMSE reductions of 3.2-7.6% and R-squared\nincreases of 0.5-1.5%. Notably, HistGradientBoosting shows the most significant\nenhancement with a 7.6% RMSE improvement. Our analysis confirms that\ncluster-guided latent space augmentation preserves chemical validity while\nexpanding dataset diversity, offering a computationally efficient strategy to\nenhance predictive models in resource-constrained drug discovery pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2506.00223v1",
    "published": "2025-05-30T20:54:57+00:00",
    "categories": [
      "q-bio.QM",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2506.03189v1",
    "title": "Continual Learning in Vision-Language Models via Aligned Model Merging",
    "authors": [
      "Ghada Sokar",
      "Gintare Karolina Dziugaite",
      "Anurag Arnab",
      "Ahmet Iscen",
      "Pablo Samuel Castro",
      "Cordelia Schmid"
    ],
    "abstract": "Continual learning is conventionally tackled through sequential fine-tuning,\na process that, while enabling adaptation, inherently favors plasticity over\nthe stability needed to retain prior knowledge. While existing approaches\nattempt to mitigate catastrophic forgetting, a bias towards recent tasks\npersists as they build upon this sequential nature. In this work we present a\nnew perspective based on model merging to maintain stability while still\nretaining plasticity. Rather than just sequentially updating the model weights,\nwe propose merging newly trained task parameters with previously learned ones,\npromoting a better balance. To maximize the effectiveness of the merging\nprocess, we propose a simple mechanism that promotes learning aligned weights\nwith previous ones, thereby avoiding interference when merging. We evaluate\nthis approach on large Vision-Language Models (VLMs), and demonstrate its\neffectiveness in reducing forgetting, increasing robustness to various task\norders and similarities, and improving generalization.",
    "pdf_url": "http://arxiv.org/pdf/2506.03189v1",
    "published": "2025-05-30T20:52:21+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00221v1",
    "title": "Integrating Expert Knowledge and Recursive Bayesian Inference: A Framework for Spatial and Spatio-Temporal Data Challenges",
    "authors": [
      "Mario Figueira",
      "David Conesa",
      "Antonio López-Quílez",
      "Håvard Rue"
    ],
    "abstract": "Expert elicitation is a critical approach for addressing data scarcity across\nvarious disciplines. But moreover, it can also complement big data analytics by\nmitigating the limitations of observational data, such as incompleteness and\nreliability issues, thereby enhancing model estimates through the integration\nof disparate or conflicting data sources. The paper also outlines various\nstrategies for integrating prior information within the Integrated Nested\nLaplace Approximation method and proposes a recursive approach that allows for\nthe analysis of new data as it arrives. This paper presents a comprehensive\napproach to expert elicitation, with a particular emphasis on spatial and\nspatio-temporal contexts. Specifically, it introduces a typology of\nexpert-based model implementations that addresses different change of support\nscenarios between observational and expert data. Detailed examples illustrating\nclear and replicable procedures for implementing expert elicitation and\nrecursive inference are also presented.",
    "pdf_url": "http://arxiv.org/pdf/2506.00221v1",
    "published": "2025-05-30T20:51:06+00:00",
    "categories": [
      "stat.ME",
      "62",
      "G.3"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.00220v1",
    "title": "Curate, Connect, Inquire: A System for Findable Accessible Interoperable and Reusable (FAIR) Human-Robot Centered Datasets",
    "authors": [
      "Xingru Zhou",
      "Sadanand Modak",
      "Yao-Cheng Chan",
      "Zhiyun Deng",
      "Luis Sentis",
      "Maria Esteva"
    ],
    "abstract": "The rapid growth of AI in robotics has amplified the need for high-quality,\nreusable datasets, particularly in human-robot interaction (HRI) and\nAI-embedded robotics. While more robotics datasets are being created, the\nlandscape of open data in the field is uneven. This is due to a lack of\ncuration standards and consistent publication practices, which makes it\ndifficult to discover, access, and reuse robotics data. To address these\nchallenges, this paper presents a curation and access system with two main\ncontributions: (1) a structured methodology to curate, publish, and integrate\nFAIR (Findable, Accessible, Interoperable, Reusable) human-centered robotics\ndatasets; and (2) a ChatGPT-powered conversational interface trained with the\ncurated datasets metadata and documentation to enable exploration, comparison\nrobotics datasets and data retrieval using natural language. Developed based on\npractical experience curating datasets from robotics labs within Texas Robotics\nat the University of Texas at Austin, the system demonstrates the value of\nstandardized curation and persistent publication of robotics data. The system's\nevaluation suggests that access and understandability of human-robotics data\nare significantly improved. This work directly aligns with the goals of the\nHCRL @ ICRA 2025 workshop and represents a step towards more human-centered\naccess to data for embodied AI.",
    "pdf_url": "http://arxiv.org/pdf/2506.00220v1",
    "published": "2025-05-30T20:48:32+00:00",
    "categories": [
      "cs.IR",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00219v1",
    "title": "Revisiting the CMB homogeneity scale: low multipoles removal effect and extragalactic foreground masking",
    "authors": [
      "Xiaoyun Shao",
      "Facundo Toscano",
      "Diego Garcia Lambas",
      "Rodrigo S. Gonçalves",
      "Carlos A. P. Bengaly",
      "Heliana E. Luparello",
      "Frode K. Hansen",
      "Jailson Alcaniz"
    ],
    "abstract": "The Cosmic Microwave Background (CMB) reaches homogeneity at relatively\nmodest angular scales compared to the expectation of the standard $\\Lambda$CDM\nmodel revealing an important challenge to the theoretical predictions. We\nanalyze this inconsistency through the homogeneity scale $H$ and the slope of\nthe homogeneity index at $\\theta = 90^\\circ$. We find that the removal of low\nmultipoles, in particular the quadrupole, from both the data and the\n$\\Lambda$CDM synthetic CMB maps, significantly improve the consistency between\nmodels and observations. This adds to indications of the relevant contribution\nof the low value of the CMB quadrupole to the observed anomalies in the\nhomogeneity scale. Due to the presence of a new extragalactic foreground in the\nCMB maps, we have performed statistical analyses with different masking taking\ninto account the regions mostly affected. In particular we consider galaxies in\nthe local neighborhood which are expected to affect more significantly the\nlarge angular scales. We find that by masking these regions, the analysis\ncannot solve the discrepancy between the observations and the $\\Lambda$CDM\nmodel in spite of a small improvement of their mutual consistency. The studies\nwith both foreground masking and low-$\\ell$ removed CMB maps show similar\nresults than those of the full CMB map indicating that the main discrepancy\nbetween theory and observations is associated to the quadrupole anomaly and may\nrequire more exhaustive analysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.00219v1",
    "published": "2025-05-30T20:46:32+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00218v1",
    "title": "Evaluating the Contextual Integrity of False Positives in Algorithmic Travel Surveillance",
    "authors": [
      "Alina Wernick",
      "Alan Medlar",
      "Sofia Söderholm",
      "Dorota Głowacka"
    ],
    "abstract": "International air travel is highly surveilled. While surveillance is deemed\nnecessary for law enforcement to prevent and detect terrorism and other serious\ncrimes, even the most accurate algorithmic mass surveillance systems produce\nhigh numbers of false positives. Despite the potential impact of false\npositives on the fundamental rights of millions of passengers, algorithmic\ntravel surveillance is lawful in the EU. However, as the system's processing\npractices and accuracy are kept secret by law, it is unknown to what degree\npassengers are accepting of the system's interference with their rights to\nprivacy and data protection.\n  We conducted a nationally representative survey of the adult population of\nFinland (N=1550) to assess their attitudes towards algorithmic mass\nsurveillance in air travel and its potential expansion to other travel\ncontexts. Furthermore, we developed a novel approach for estimating the\nthreshold, beyond which, the number of false positives breaches individuals'\nperception of contextual integrity. Surprisingly, when faced with a trade-off\nbetween privacy and security, even very high false positive counts were\nperceived as legitimate. This result could be attributed to Finland's\nhigh-trust cultural context, but also raises questions about people's capacity\nto account for privacy harms that happen to other people. We conclude by\ndiscussing how legal and ethical approaches to legitimising algorithmic\nsurveillance based on individual rights may overlook the statistical or\nsystemic properties of mass surveillance.",
    "pdf_url": "http://arxiv.org/pdf/2506.00218v1",
    "published": "2025-05-30T20:45:30+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.02034v1",
    "title": "High-throughput viscometry via machine-learning from videos of inverted vials",
    "authors": [
      "Ignacio Arretche",
      "Mohammad Tanver Hossain",
      "Ramdas Tiwari",
      "Abbie Kim",
      "Mya G. Mills",
      "Connor D. Armstrong",
      "Jacob J. Lessard",
      "Sameh H. Tawfick",
      "Randy H. Ewoldt"
    ],
    "abstract": "Although the inverted vial test has been widely used as a qualitative method\nfor estimating fluid viscosity, quantitative rheological characterization has\nremained limited due to its complex, uncontrolled flow - driven by gravity,\nsurface tension, inertia, and initial conditions. Here, we present a computer\nvision (CV) viscometer that automates the inverted vial test and enables\nquantitative viscosity inference across nearly five orders of magnitude\n(0.01-1000 Pas), without requiring direct velocity field measurements. The\nsystem simultaneously inverts multiple vials and records videos of the evolving\nfluid, which are fed into a neural network that approximates the inverse\nfunction from visual features and known fluid density. Despite the complex,\nmulti-regime flow within the vial, our approach achieves relative errors below\n25%, improving to 15% for viscosities above 0.1 Pas. When tested on\nnon-Newtonian polymer solutions, the method reliably estimates zero-shear\nviscosity as long as viscoelastic or shear-thinning behaviors remain negligible\nwithin the flow regime. Moreover, high standard deviations in the inferred\nvalues may serve as a proxy for identifying fluids with strong non-Newtonian\nbehavior. The CV viscometer requires only one camera and one motor, is\ncontactless and low-cost, and can be easily integrated into high-throughput\nexperimental automated and manual workflows. Transcending traditional\ncharacterization paradigms, our method leverages uncontrolled flows and visual\nfeatures to achieve simplicity and scalability, enabling high-throughput\nviscosity inference that can meet the growing demand of data-driven material\nmodels while remaining accessible to lower resource environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.02034v1",
    "published": "2025-05-30T20:45:05+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00217v2",
    "title": "Static Electric Dipole Polarizability and Hyperpolarizability Tensors from Mean-Field Cavity Quantum Electrodynamics Approaches",
    "authors": [
      "A. Eugene DePrince III",
      "Stephen H. Yuwono"
    ],
    "abstract": "First-order electric dipole response functions are implemented for cavity\nquantum electrodynamics (QED) generalizations of Hartree-Fock (HF) and\nKohn-Sham density functional theory (DFT) in order to assess the degree to\nwhich static molecular response properties are impacted by interactions between\nelectronic degrees of freedom and an optical cavity mode. Isotropically\naveraged static electric dipole polarizability tensors from QED-HF and QED-DFT\nare found to be somewhat insensitive to the presence of the cavity under\nrealistic single-molecule coupling strengths. In contrast, the first\nhyperpolarizability tensor computed using QED-HF can be significantly modified\nby the cavity, depending on the relative orientation of the molecule and cavity\nmode polarization axis. For example, compared to the isolated molecule case,\nthe isotropically averaged hyperpolarizability for $p$-nitroaniline decreases\nby more than 20% when the molecule is coupled to a single-mode optical cavity\nwith a coupling strength of $|\\lambda| = 0.05$ a.u. and when the cavity mode is\npolarized along the principal molecular axis. On the other hand, with this\ncoupling strength and polarization, the isotropically averaged static dipole\npolarizability from QED-HF or QED-DFT decreases by only $\\approx$ 2--5%,\ndepending on the choice of DFT functional.",
    "pdf_url": "http://arxiv.org/pdf/2506.00217v2",
    "published": "2025-05-30T20:43:27+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00216v1",
    "title": "AniTrack: A Power-Efficient, Time-Slotted and Robust UWB Localization System for Animal Tracking in a Controlled Setting",
    "authors": [
      "Victor Luder",
      "Lukas Schulthess",
      "Silvano Cortesi",
      "Leyla Rivero Davis",
      "Michele Magno"
    ],
    "abstract": "Accurate localization is essential for a wide range of applications,\nincluding asset tracking, smart agriculture, and animal monitoring. While\ntraditional localization methods, such as Global Navigation Satellite System\n(GNSS), Wi-Fi, and Bluetooth Low Energy (BLE), offer varying levels of accuracy\nand coverage, they have drawbacks regarding power consumption, infrastructure\nrequirements, and deployment flexibility. Ultra-Wideband (UWB) is emerging as\nan alternative, offering centimeter-level accuracy and energy efficiency,\nespecially suitable for medium to large field monitoring with capabilities to\nwork indoors and outdoors. However, existing UWB localization systems require\ninfrastructure with mains power to supply the anchors, which impedes their\nscalability and ease of deployment. This underscores the need for a fully\nbattery-powered and energy-efficient localization system. This paper presents\nan energy-optimized, battery-operated UWB localization system that leverages\nLong Range Wide Area Network (LoRaWAN) for data transmission to a server\nbackend. By employing single-sided two-way ranging (SS-TWR) in a time-slotted\nlocalization approach, the power consumption both on the anchor and the tag is\nreduced, while maintaining high accuracy. With a low average power consumption\nof 20.44 mW per anchor and 7.19 mW per tag, the system allows fully\nbattery-powered operation for up to 25 days, achieving average accuracy of\n13.96 cm with self-localizing anchors on a 600 m2 testing ground. To validate\nits effectiveness and ease of installation in a challenging application\nscenario, ten anchors and two tags were successfully deployed in a tropical\nzoological biome where they could be used to track Aldabra Giant Tortoises\n(Aldabrachelys gigantea).",
    "pdf_url": "http://arxiv.org/pdf/2506.00216v1",
    "published": "2025-05-30T20:42:40+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.03188v1",
    "title": "Multi-Analyte, Swab-based Automated Wound Monitor with AI",
    "authors": [
      "Madhu Babu Sikha",
      "Lalith Appari",
      "Gurudatt Nanjanagudu Ganesh",
      "Amay Bandodkar",
      "Imon Banerjee"
    ],
    "abstract": "Diabetic foot ulcers (DFUs), a class of chronic wounds, affect ~750,000\nindividuals every year in the US alone and identifying non-healing DFUs that\ndevelop to chronic wounds early can drastically reduce treatment costs and\nminimize risks of amputation. There is therefore a pressing need for diagnostic\ntools that can detect non-healing DFUs early. We develop a low cost,\nmulti-analyte 3D printed assays seamlessly integrated on swabs that can\nidentify non-healing DFUs and a Wound Sensor iOS App - an innovative mobile\napplication developed for the controlled acquisition and automated analysis of\nwound sensor data. By comparing both the original base image (before exposure\nto the wound) and the wound-exposed image, we developed automated computer\nvision techniques to compare density changes between the two assay images,\nwhich allow us to automatically determine the severity of the wound. The iOS\napp ensures accurate data collection and presents actionable insights, despite\nchallenges such as variations in camera configurations and ambient conditions.\nThe proposed integrated sensor and iOS app will allow healthcare professionals\nto monitor wound conditions real-time, track healing progress, and assess\ncritical parameters related to wound care.",
    "pdf_url": "http://arxiv.org/pdf/2506.03188v1",
    "published": "2025-05-30T20:42:37+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00214v1",
    "title": "Diff-SPORT: Diffusion-based Sensor Placement Optimization and Reconstruction of Turbulent flows in urban environments",
    "authors": [
      "Abhijeet Vishwasrao",
      "Sai Bharath Chandra Gutha",
      "Andres Cremades",
      "Klas Wijk",
      "Aakash Patil",
      "Catherine Gorle",
      "Beverley J McKeon",
      "Hossein Azizpour",
      "Ricardo Vinuesa"
    ],
    "abstract": "Rapid urbanization demands accurate and efficient monitoring of turbulent\nwind patterns to support air quality, climate resilience and infrastructure\ndesign. Traditional sparse reconstruction and sensor placement strategies face\nmajor accuracy degradations under practical constraints. Here, we introduce\nDiff-SPORT, a diffusion-based framework for high-fidelity flow reconstruction\nand optimal sensor placement in urban environments. Diff-SPORT combines a\ngenerative diffusion model with a maximum a posteriori (MAP) inference scheme\nand a Shapley-value attribution framework to propose a scalable and\ninterpretable solution. Compared to traditional numerical methods, Diff-SPORT\nachieves significant speedups while maintaining both statistical and\ninstantaneous flow fidelity. Our approach offers a modular, zero-shot\nalternative to retraining-intensive strategies, supporting fast and reliable\nurban flow monitoring under extreme sparsity. Diff-SPORT paves the way for\nintegrating generative modeling and explainability in sustainable urban\nintelligence.",
    "pdf_url": "http://arxiv.org/pdf/2506.00214v1",
    "published": "2025-05-30T20:41:50+00:00",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.00215v1",
    "title": "Symbolic Hamiltonian Compiler for Hybrid Qubit-Boson Processors",
    "authors": [
      "Ethan Decker",
      "Erik Gustafson",
      "Evan McKinney",
      "Alex K. Jones",
      "Lucas Goetz",
      "Ang Li",
      "Alexander Schuckert",
      "Samuel Stein",
      "Gushu Li",
      "Eleanor Crane"
    ],
    "abstract": "Quantum simulation of the interactions of fermions and bosons -- the\nfundamental particles of nature -- is essential for modeling complex quantum\nsystems in material science, chemistry and high-energy physics and has been\nproposed as a promising application of fermion-boson quantum computers, which\novercome the overhead encountered in mapping fermions and bosons to qubits.\nHowever, compiling the simulation of specific fermion-boson Hamiltonians into\nthe natively available fermion-boson gate set is challenging. In particular,\nthe large local dimension of bosons renders matrix-based compilation methods,\nas used for qubits and in existing tools such as Bosonic Qiskit or OpenFermion,\nchallenging. We overcome this issue by introducing a novel symbolic compiler\nbased on matrix-free symbolic manipulation of second quantised Hamiltonians,\nwhich automates the decomposition of fermion-boson second quantized problems\ninto qubit-boson instruction set architectures. This integration establishes a\ncomprehensive pipeline for simulating quantum systems on emerging qubit-boson\nand fermion-boson hardware, paving the way for their large-scale usage.",
    "pdf_url": "http://arxiv.org/pdf/2506.00215v1",
    "published": "2025-05-30T20:41:50+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00213v1",
    "title": "Impacto del desorden en los estados cuánticos de dos fotones generados en arreglos de guías de onda no lineales",
    "authors": [
      "Jefferson Delgado-Quesada",
      "Edgar A. Rojas-González"
    ],
    "abstract": "In an array of nonlinear waveguides, quantum states can be generated from\nclassical states through spontaneous parametric down-conversion of photons.\nThis work simulates and analyzes the effect of disorder on light propagation\nand its quantum correlations, implementing disorder in three system parameters:\ncoupling, injection amplitude, and injection phase. It is determined that when\nlight is injected into only one waveguide, disorder in the coupling increases\nlocalization and reduces dispersion. Moreover, in this case, propagation tends\nto remain ballistic, a characteristic feature of waveguide arrays. Conversely,\ndisorder in the injection amplitude and phase tends to delocalize the wave\nfunction, with the latter having a more pronounced effect. Finally, it is\nobserved that quantum correlations, obtained from the correlation matrix, are\nrobust in the presence of disorder, particularly the null elements.\n  -- En un arreglo de gu\\'ias de onda no lineales se pueden generar estados\ncu\\'anticos a partir de estados cl\\'asicos mediante la conversi\\'on\nparam\\'etrica descendente espont\\'anea de fotones. En este trabajo se simula y\nanaliza el efecto del desorden en la propagaci\\'on de la luz y sus\ncorrelaciones cu\\'anticas, implementando desorden en tres perfiles del sistema:\nacoplamiento, amplitud de inyecci\\'on y fase de inyecci\\'on. Se determina que,\ncuando se inyecta solamente una gu\\'ia de onda, el desorden en el acoplamiento\naumenta la localizaci\\'on y disminuye la dispersi\\'on. Adem\\'as, en este caso\nse preserva la propagaci\\'on con tendencia a ser bal\\'istica, lo cual es\ncaracter\\'istico de arreglos de gu\\'ias de onda. Contrariamente, el desorden en\nla amplitud y fase de inyecci\\'on tienden a deslocalizar la funci\\'on de onda,\nsiendo el efecto mayor en el \\'ultimo caso. Finalmente, se observa que las\ncorrelaciones cu\\'anticas, obtenidas a partir de la matriz de correlaci\\'on,\nson robustas ante la presencia de desorden, en particular los elementos nulos.",
    "pdf_url": "http://arxiv.org/pdf/2506.00213v1",
    "published": "2025-05-30T20:38:08+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00212v1",
    "title": "Concerning the Responsible Use of AI in the US Criminal Justice System",
    "authors": [
      "Cristopher Moore",
      "Catherine Gill",
      "Nadya Bliss",
      "Kevin Butler",
      "Stephanie Forrest",
      "Daniel Lopresti",
      "Mary Lou Maher",
      "Helena Mentis",
      "Shashi Shekhar",
      "Amanda Stent",
      "Matthew Turk"
    ],
    "abstract": "Artificial intelligence (AI) is increasingly being adopted in most\nindustries, and for applications such as note taking and checking grammar,\nthere is typically not a cause for concern. However, when constitutional rights\nare involved, as in the justice system, transparency is paramount. While AI can\nassist in areas such as risk assessment and forensic evidence generation, its\n\"black box\" nature raises significant questions about how decisions are made\nand whether they can be contested. This paper explores the implications of AI\nin the justice system, emphasizing the need for transparency in AI\ndecision-making processes to uphold constitutional rights and ensure procedural\nfairness. The piece advocates for clear explanations of AI's data, logic, and\nlimitations, and calls for periodic audits to address bias and maintain\naccountability in AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00212v1",
    "published": "2025-05-30T20:33:42+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00211v1",
    "title": "The Impact of Uniform Circular Array on Near-field ISAC",
    "authors": [
      "Na Xue",
      "Xidong Mu",
      "Yue Chen",
      "Yuanwei Liu"
    ],
    "abstract": "A novel uniform circular array (UCA) based near-field (NF) integrated sensing\nand communication (ISAC) framework is proposed, where the Cylindrical\ncoordinate is invoked to evaluate the joint positioning performance. The joint\nsquared position error bound (SPEB) of the sensing target (ST) is derived for\nthe coplanar and non-coplanar cases. For the coplanar case, where the ST is\nlocated in the coplanar region of the UCA, the approximate Cram{\\'e}r-Rao bound\n(CRB) expressions for the separate angle and distance estimation are given by\nexploiting the uniform spherical wavefront model. A SPEB minimization problem\nis formulated with the constraints of communication requirement and power\nbudget, where the closed-form solution to minimize the CRB of the angle is\nderived. Inspired by the close-form expression, a low complexity vector-based\nquadratic transformation (VQF) algorithm is proposed by invoking the Rayleigh\nquotient. For the non-coplanar case, where the ST is located beyond the\ncoplanar region of the UCA, the separate CRBs over three-dimensional\ncoordinates and the joint SPEB approximations are derived. To minimize the SPEB\nperformance, the semi-definite relaxation (SDR) method and extended\nlow-complexity VQF algorithm are proposed. Numerical results validated that i)\nthe Fisher Information Matrix about angle and distance in NF propagation can be\napproximated as a diagonal matrix with the trinity loss; ii) Compared with the\nuniform planar array, the UCA achieve better positioning performance when ST\nlocated in the coplanar of the antenna array; and iii) the proposed VQF\nalgorithms reach higher solution precision than conventional SDR algorithm with\nmuch less computation complexity.",
    "pdf_url": "http://arxiv.org/pdf/2506.00211v1",
    "published": "2025-05-30T20:33:31+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00210v1",
    "title": "REIC: RAG-Enhanced Intent Classification at Scale",
    "authors": [
      "Ziji Zhang",
      "Michael Yang",
      "Zhiyu Chen",
      "Yingying Zhuang",
      "Shu-Ting Pi",
      "Qun Liu",
      "Rajashekar Maragoud",
      "Vy Nguyen",
      "Anurag Beniwal"
    ],
    "abstract": "Accurate intent classification is critical for efficient routing in customer\nservice, ensuring customers are connected with the most suitable agents while\nreducing handling times and operational costs. However, as companies expand\ntheir product lines, intent classification faces scalability challenges due to\nthe increasing number of intents and variations in taxonomy across different\nverticals. In this paper, we introduce REIC, a Retrieval-augmented generation\nEnhanced Intent Classification approach, which addresses these challenges\neffectively. REIC leverages retrieval-augmented generation (RAG) to dynamically\nincorporate relevant knowledge, enabling precise classification without the\nneed for frequent retraining. Through extensive experiments on real-world\ndatasets, we demonstrate that REIC outperforms traditional fine-tuning,\nzero-shot, and few-shot methods in large-scale customer service settings. Our\nresults highlight its effectiveness in both in-domain and out-of-domain\nscenarios, demonstrating its potential for real-world deployment in adaptive\nand large-scale intent classification systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00210v1",
    "published": "2025-05-30T20:32:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00209v1",
    "title": "Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models",
    "authors": [
      "Liwen Sun",
      "Hao-Ren Yao",
      "Gary Gao",
      "Ophir Frieder",
      "Chenyan Xiong"
    ],
    "abstract": "Cancer screening, leading to early detection, saves lives. Unfortunately,\nexisting screening techniques require expensive and intrusive medical\nprocedures, not globally available, resulting in too many lost would-be-saved\nlives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation\nModels, a cancer pre-screening methodology that identifies high-risk patients\nfor further screening solely based on their historical medical records. With\nmillions of electronic healthcare records (EHR), we establish the scaling law\nof EHR foundation models pretrained on medical code sequences, pretrain\ncompute-optimal foundation models of up to 2.4 billion parameters, and finetune\nthem on clinician-curated cancer risk prediction cohorts. In our retrospective\nevaluation comprising of thirty thousand patients, CATCH-FM achieved strong\nefficacy (60% sensitivity) with low risk (99% specificity and Negative\nPredictive Value), outperforming feature-based tree models as well as general\nand medical large language models by large margins. Despite significant\ndemographic, healthcare system, and EHR coding differences, CATCH-FM achieves\nstate-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot\nleaderboard, outperforming EHR foundation models pretrained using on-site\npatient data. Our analysis demonstrates the robustness of CATCH-FM in various\npatient distributions, the benefits of operating in the ICD code space, and its\nability to capture non-trivial cancer risk factors. Our code will be\nopen-sourced.",
    "pdf_url": "http://arxiv.org/pdf/2506.00209v1",
    "published": "2025-05-30T20:31:09+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00208v1",
    "title": "FastCAR: Fast Classification And Regression for Task Consolidation in Multi-Task Learning to Model a Continuous Property Variable of Detected Object Class",
    "authors": [
      "Anoop Kini",
      "Andreas Jansche",
      "Timo Bernthaler",
      "Gerhard Schneider"
    ],
    "abstract": "FastCAR is a novel task consolidation approach in Multi-Task Learning (MTL)\nfor a classification and a regression task, despite the non-triviality of task\nheterogeneity with only a subtle correlation. The approach addresses the\nclassification of a detected object (occupying the entire image frame) and\nregression for modeling a continuous property variable (for instances of an\nobject class), a crucial use case in science and engineering. FastCAR involves\na label transformation approach that is amenable for use with only a\nsingle-task regression network architecture. FastCAR outperforms traditional\nMTL model families, parametrized in the landscape of architecture and loss\nweighting schemes, when learning both tasks are collectively considered\n(classification accuracy of 99.54%, regression mean absolute percentage error\nof 2.4%). The experiments performed used \"Advanced Steel Property Dataset\"\ncontributed by us https://github.com/fastcandr/AdvancedSteel-Property-Dataset.\nThe dataset comprises 4536 images of 224x224 pixels, annotated with discrete\nobject classes and its hardness property that can take continuous values. Our\nproposed FastCAR approach for task consolidation achieves training time\nefficiency (2.52x quicker) and reduced inference latency (55% faster) than\nbenchmark MTL networks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00208v1",
    "published": "2025-05-30T20:31:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00207v1",
    "title": "On general and complete multidimensional Riemann solvers for nonlinear systems of hyperbolic conservation laws",
    "authors": [
      "Elena Gaburro",
      "Mario Ricchiuto",
      "Michael Dumbser"
    ],
    "abstract": "In this work, we introduce a framework to design multidimensional Riemann\nsolvers for nonlinear systems of hyperbolic conservation laws on general\nunstructured polygonal Voronoi-like tessellations. In this framework we propose\ntwo simple but complete solvers. The first method is a direct extension of the\nOsher-Solomon Riemann solver to multiple space dimensions. Here, the\nmultidimensional numerical dissipation is obtained by integrating the absolute\nvalue of the flux Jacobians over a dual triangular mesh around each node of the\nprimal polygonal grid. The required nodal gradient is then evaluated on a local\ncomputational simplex involving the d+1 neighbors meeting at each corner. The\nsecond method is a genuinely multidimensional upwind flux. By introducing a\nfluctuation form of finite volume methods with corner fluxes, we show an\nequivalence with residual distribution schemes (RD). This naturally allows to\nconstruct genuinely multidimensional upwind corner fluxes starting from\nexisting and well-known RD fluctuations. In particular, we explore the use of\ncorner fluxes obtained from the so-called N scheme, i.e. the Roe's original\noptimal multidimensional upwind advection scheme.\n  Both methods use the full eigenstructure of the underlying hyperbolic system\nand are therefore complete by construction. A simple higher order extension up\nto fourth order in space and time is then introduced at the aid of a CWENO\nreconstruction in space and an ADER approach in time, leading to a family of\nhigh order accurate fully-discrete one-step schemes based on genuinely\nmultidimensional Riemann solvers.\n  We present applications of our new numerical schemes to several test problems\nfor the compressible Euler equations of gas-dyanamics. In particular, we show\nthat the proposed schemes are at the same time carbuncle-free and preserve\ncertain stationary shear waves exactly.",
    "pdf_url": "http://arxiv.org/pdf/2506.00207v1",
    "published": "2025-05-30T20:27:24+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00206v1",
    "title": "Residual Income Valuation and Stock Returns: Evidence from a Value-to-Price Investment Strategy",
    "authors": [
      "Ahmad Haboub",
      "Aris Kartsaklas",
      "Vasilis Sarafidis"
    ],
    "abstract": "We hypothesize that portfolio sorts based on the V/P ratio generate excess\nreturns and consist of companies that are undervalued for prolonged periods.\nResults, for the US market show that high V/P portfolios outperform low V/P\nportfolios across horizons extending from one to three years. The V/P ratio is\npositively correlated to future stock returns after controlling for firm\ncharacteristics, which are well known risk proxies. Findings also indicate that\nprofitability and investment add explanatory power to the Fama and French three\nfactor model and for stocks with V/P ratio close to 1. However, these factors\ncannot explain all variation in excess returns especially for years two and\nthree and for stocks with high V/P ratio. Finally, portfolios with the highest\nV/P stocks select companies that are significantly mispriced relative to their\nequity (investment) and profitability growth persistence in the future.",
    "pdf_url": "http://arxiv.org/pdf/2506.00206v1",
    "published": "2025-05-30T20:26:37+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00205v1",
    "title": "Unlocking the Power of Rehearsal in Continual Learning: A Theoretical Perspective",
    "authors": [
      "Junze Deng",
      "Qinhang Wu",
      "Peizhong Ju",
      "Sen Lin",
      "Yingbin Liang",
      "Ness Shroff"
    ],
    "abstract": "Rehearsal-based methods have shown superior performance in addressing\ncatastrophic forgetting in continual learning (CL) by storing and training on a\nsubset of past data alongside new data in current task. While such a concurrent\nrehearsal strategy is widely used, it remains unclear if this approach is\nalways optimal. Inspired by human learning, where sequentially revisiting tasks\nhelps mitigate forgetting, we explore whether sequential rehearsal can offer\ngreater benefits for CL compared to standard concurrent rehearsal. To address\nthis question, we conduct a theoretical analysis of rehearsal-based CL in\noverparameterized linear models, comparing two strategies: 1) Concurrent\nRehearsal, where past and new data are trained together, and 2) Sequential\nRehearsal, where new data is trained first, followed by revisiting past data\nsequentially. By explicitly characterizing forgetting and generalization error,\nwe show that sequential rehearsal performs better when tasks are less similar.\nThese insights further motivate a novel Hybrid Rehearsal method, which trains\nsimilar tasks concurrently and revisits dissimilar tasks sequentially. We\ncharacterize its forgetting and generalization performance, and our experiments\nwith deep neural networks further confirm that the hybrid approach outperforms\nstandard concurrent rehearsal. This work provides the first comprehensive\ntheoretical analysis of rehearsal-based CL.",
    "pdf_url": "http://arxiv.org/pdf/2506.00205v1",
    "published": "2025-05-30T20:23:15+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00204v1",
    "title": "Structure-Aware Fill-in-the-Middle Pretraining for Code",
    "authors": [
      "Linyuan Gong",
      "Alvin Cheung",
      "Mostafa Elhoushi",
      "Sida Wang"
    ],
    "abstract": "Fill-in-the-Middle (FIM) is a common pretraining method for code LLMs, where\nmodels complete code segments given surrounding context. However, existing LLMs\ntreat code as plain text and mask random character spans. We propose and\nevaluate AST-FIM, a pretraining strategy that leverages Abstract Syntax Trees\n(ASTs) to mask complete syntactic structures at scale, ensuring coherent\ntraining examples better aligned with universal code structures and common code\nediting patterns such as blocks, expressions, or functions. To evaluate\nreal-world fill-in-the-middle (FIM) programming tasks, we introduce\nReal-FIM-Eval, a benchmark derived from 30,000+ GitHub commits across 12\nlanguages. On infilling tasks, experiments on 1B and 8B parameter models show\nthat AST-FIM is particularly beneficial for real-world code editing as it\noutperforms standard random-character FIM by up to 5 pts on standard FIM\nbenchmarks. Our code is publicly available at\nhttps://github.com/gonglinyuan/ast_fim.",
    "pdf_url": "http://arxiv.org/pdf/2506.00204v1",
    "published": "2025-05-30T20:19:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00203v1",
    "title": "The World As Large Language Models See It: Exploring the reliability of LLMs in representing geographical features",
    "authors": [
      "Omid Reza Abbasi",
      "Franz Welscher",
      "Georg Weinberger",
      "Johannes Scholz"
    ],
    "abstract": "As large language models (LLMs) continue to evolve, questions about their\ntrustworthiness in delivering factual information have become increasingly\nimportant. This concern also applies to their ability to accurately represent\nthe geographic world. With recent advancements in this field, it is relevant to\nconsider whether and to what extent LLMs' representations of the geographical\nworld can be trusted. This study evaluates the performance of GPT-4o and Gemini\n2.0 Flash in three key geospatial tasks: geocoding, elevation estimation, and\nreverse geocoding. In the geocoding task, both models exhibited systematic and\nrandom errors in estimating the coordinates of St. Anne's Column in Innsbruck,\nAustria, with GPT-4o showing greater deviations and Gemini 2.0 Flash\ndemonstrating more precision but a significant systematic offset. For elevation\nestimation, both models tended to underestimate elevations across Austria,\nthough they captured overall topographical trends, and Gemini 2.0 Flash\nperformed better in eastern regions. The reverse geocoding task, which involved\nidentifying Austrian federal states from coordinates, revealed that Gemini 2.0\nFlash outperformed GPT-4o in overall accuracy and F1-scores, demonstrating\nbetter consistency across regions. Despite these findings, neither model\nachieved an accurate reconstruction of Austria's federal states, highlighting\npersistent misclassifications. The study concludes that while LLMs can\napproximate geographic information, their accuracy and reliability are\ninconsistent, underscoring the need for fine-tuning with geographical\ninformation to enhance their utility in GIScience and Geoinformatics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00203v1",
    "published": "2025-05-30T20:14:17+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00202v3",
    "title": "What do professional software developers need to know to succeed in an age of Artificial Intelligence?",
    "authors": [
      "Matthew Kam",
      "Cody Miller",
      "Miaoxin Wang",
      "Abey Tidwell",
      "Irene A. Lee",
      "Joyce Malyn-Smith",
      "Beatriz Perez",
      "Vikram Tiwari",
      "Joshua Kenitzer",
      "Andrew Macvean",
      "Erin Barrar"
    ],
    "abstract": "Generative AI is showing early evidence of productivity gains for software\ndevelopers, but concerns persist regarding workforce disruption and deskilling.\nWe describe our research with 21 developers at the cutting edge of using AI,\nsummarizing 12 of their work goals we uncovered, together with 75 associated\ntasks and the skills & knowledge for each, illustrating how developers use AI\nat work. From all of these, we distilled our findings in the form of 5\ninsights. We found that the skills & knowledge to be a successful AI-enhanced\ndeveloper are organized into four domains (using Generative AI effectively,\ncore software engineering, adjacent engineering, and adjacent non-engineering)\ndeployed at critical junctures throughout a 6-step task workflow. In order to\n\"future proof\" developers for this age of AI, on-the-job learning initiatives\nand computer science degree programs will need to target both \"soft\" skills and\nthe technical skills & knowledge in all four domains to reskill, upskill and\nsafeguard against deskilling.",
    "pdf_url": "http://arxiv.org/pdf/2506.00202v3",
    "published": "2025-05-30T20:14:03+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00201v1",
    "title": "Hush! Protecting Secrets During Model Training: An Indistinguishability Approach",
    "authors": [
      "Arun Ganesh",
      "Brendan McMahan",
      "Milad Nasr",
      "Thomas Steinke",
      "Abhradeep Thakurta"
    ],
    "abstract": "We consider the problem of secret protection, in which a business or\norganization wishes to train a model on their own data, while attempting to not\nleak secrets potentially contained in that data via the model. The standard\nmethod for training models to avoid memorization of secret information is via\ndifferential privacy (DP). However, DP requires a large loss in utility or a\nlarge dataset to achieve its strict privacy definition, which may be\nunnecessary in our setting where the data curator and data owner are the same\nentity. We propose an alternate definition of secret protection that instead of\ntargeting DP, instead targets a bound on the posterior probability of secret\nreconstruction. We then propose and empirically evaluate an algorithm for model\ntraining with this secret protection definition. Our algorithm solves a linear\nprogram to assign weights to examples based on the desired per-secret\nprotections, and then performs Poisson sampling using these weights. We show\nour algorithm significantly outperforms the baseline of running DP-SGD on the\nwhole dataset.",
    "pdf_url": "http://arxiv.org/pdf/2506.00201v1",
    "published": "2025-05-30T20:14:02+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00200v2",
    "title": "Structuring Radiology Reports: Challenging LLMs with Lightweight Models",
    "authors": [
      "Johannes Moll",
      "Louisa Fay",
      "Asfandyar Azhar",
      "Sophie Ostmeier",
      "Tim Lueth",
      "Sergios Gatidis",
      "Curtis Langlotz",
      "Jean-Benoit Delbrouck"
    ],
    "abstract": "Radiology reports are critical for clinical decision-making but often lack a\nstandardized format, limiting both human interpretability and machine learning\n(ML) applications. While large language models (LLMs) have shown strong\ncapabilities in reformatting clinical text, their high computational\nrequirements, lack of transparency, and data privacy concerns hinder practical\ndeployment. To address these challenges, we explore lightweight encoder-decoder\nmodels (<300M parameters)-specifically T5 and BERT2BERT-for structuring\nradiology reports from the MIMIC-CXR and CheXpert Plus datasets. We benchmark\nthese models against eight open-source LLMs (1B-70B), adapted using prefix\nprompting, in-context learning (ICL), and low-rank adaptation (LoRA)\nfinetuning. Our best-performing lightweight model outperforms all LLMs adapted\nusing prompt-based techniques on a human-annotated test set. While some\nLoRA-finetuned LLMs achieve modest gains over the lightweight model on the\nFindings section (BLEU 6.4%, ROUGE-L 4.8%, BERTScore 3.6%, F1-RadGraph 1.1%,\nGREEN 3.6%, and F1-SRR-BERT 4.3%), these improvements come at the cost of\nsubstantially greater computational resources. For example, LLaMA-3-70B\nincurred more than 400 times the inference time, cost, and carbon emissions\ncompared to the lightweight model. These results underscore the potential of\nlightweight, task-specific models as sustainable and privacy-preserving\nsolutions for structuring clinical text in resource-constrained healthcare\nsettings.",
    "pdf_url": "http://arxiv.org/pdf/2506.00200v2",
    "published": "2025-05-30T20:12:51+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00199v1",
    "title": "A chip-scale atomic beam source for non-classical light",
    "authors": [
      "Braden J. Larsen",
      "Hagan Hensley",
      "Gabriela D. Martinez",
      "Alexander Staron",
      "William R. McGehee",
      "John Kitching",
      "James K. Thompson"
    ],
    "abstract": "Room temperature thermal atoms have proven to be a powerful resource for\nmagnetometry, electrometry, atom-entanglement generation, and robust atomic\nclocks. Recent efforts have sought to realize compact and highly manufacturable\natomic vapors and atomic beams for chip-scale magnetometry and atomic clocks.\nHere, we show that a chip-scale rubidium beam source can be integrated with a\nhigh finesse cavity-QED system to generate non-classical light. By\ndemonstrating the compatibility of these two technologies, we open a new path\nfor distributed sources of non-classical light and set the stage for using\ncavity-QED to enhance the performance of chip-scale magnetometers and atomic\nclocks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00199v1",
    "published": "2025-05-30T20:09:19+00:00",
    "categories": [
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00198v1",
    "title": "MOFGPT: Generative Design of Metal-Organic Frameworks using Language Models",
    "authors": [
      "Srivathsan Badrinarayanan",
      "Rishikesh Magar",
      "Akshay Antony",
      "Radheesh Sharma Meda",
      "Amir Barati Farimani"
    ],
    "abstract": "The discovery of Metal-Organic Frameworks (MOFs) with application-specific\nproperties remains a central challenge in materials chemistry, owing to the\nimmense size and complexity of their structural design space. Conventional\ncomputational screening techniques such as molecular simulations and density\nfunctional theory (DFT), while accurate, are computationally prohibitive at\nscale. Machine learning offers an exciting alternative by leveraging\ndata-driven approaches to accelerate materials discovery. The complexity of\nMOFs, with their extended periodic structures and diverse topologies, creates\nboth opportunities and challenges for generative modeling approaches. To\naddress these challenges, we present a reinforcement learning-enhanced,\ntransformer-based framework for the de novo design of MOFs. Central to our\napproach is MOFid, a chemically-informed string representation encoding both\nconnectivity and topology, enabling scalable generative modeling. Our pipeline\ncomprises three components: (1) a generative GPT model trained on MOFid\nsequences, (2) MOFormer, a transformer-based property predictor, and (3) a\nreinforcement learning (RL) module that optimizes generated candidates via\nproperty-guided reward functions. By integrating property feedback into\nsequence generation, our method drives the model toward synthesizable,\ntopologically valid MOFs with desired functional attributes. This work\ndemonstrates the potential of large language models, when coupled with\nreinforcement learning, to accelerate inverse design in reticular chemistry and\nunlock new frontiers in computational MOF discovery.",
    "pdf_url": "http://arxiv.org/pdf/2506.00198v1",
    "published": "2025-05-30T20:09:11+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00197v1",
    "title": "When GPT Spills the Tea: Comprehensive Assessment of Knowledge File Leakage in GPTs",
    "authors": [
      "Xinyue Shen",
      "Yun Shen",
      "Michael Backes",
      "Yang Zhang"
    ],
    "abstract": "Knowledge files have been widely used in large language model (LLM) agents,\nsuch as GPTs, to improve response quality. However, concerns about the\npotential leakage of knowledge files have grown significantly. Existing studies\ndemonstrate that adversarial prompts can induce GPTs to leak knowledge file\ncontent. Yet, it remains uncertain whether additional leakage vectors exist,\nparticularly given the complex data flows across clients, servers, and\ndatabases in GPTs. In this paper, we present a comprehensive risk assessment of\nknowledge file leakage, leveraging a novel workflow inspired by Data Security\nPosture Management (DSPM). Through the analysis of 651,022 GPT metadata, 11,820\nflows, and 1,466 responses, we identify five leakage vectors: metadata, GPT\ninitialization, retrieval, sandboxed execution environments, and prompts. These\nvectors enable adversaries to extract sensitive knowledge file data such as\ntitles, content, types, and sizes. Notably, the activation of the built-in tool\nCode Interpreter leads to a privilege escalation vulnerability, enabling\nadversaries to directly download original knowledge files with a 95.95% success\nrate. Further analysis reveals that 28.80% of leaked files are copyrighted,\nincluding digital copies from major publishers and internal materials from a\nlisted company. In the end, we provide actionable solutions for GPT builders\nand platform providers to secure the GPT data supply chain.",
    "pdf_url": "http://arxiv.org/pdf/2506.00197v1",
    "published": "2025-05-30T20:08:08+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00196v1",
    "title": "Proximal Iterative Hard Thresholding Algorithm for Sparse Group $\\ell_0$-Regularized Optimization with Box Constraint",
    "authors": [
      "Yuge Ye",
      "Qingna Li"
    ],
    "abstract": "This paper investigates a general class of problems in which a lower bounded\nsmooth convex function incorporating $\\ell_{0}$ and $\\ell_{2,0}$ regularization\nis minimized over a box constraint. Although such problems arise frequently in\npractical applications, their inherent non-convexity poses significant\nchallenges for solution methods. In particular, we focus on the proximal\noperator associated with these regularizations, which incorporates both\ngroup-sparsity and element-wise sparsity terms. Besides, we introduce the\nconcepts of $\\tau$-stationary point and support optimal (SO) point then analyze\ntheir relationship with the minimizer of the considered problem. Based on the\nproximal operator, we propose a novel proximal iterative hard thresholding\nalgorithm to solve the problem. Furthermore, we establish the global\nconvergence and the computational complexity analysis of the proposed method.\nFinally, extensive experiments demonstrate the effectiveness and efficiency of\nour method.",
    "pdf_url": "http://arxiv.org/pdf/2506.00196v1",
    "published": "2025-05-30T20:07:43+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00195v1",
    "title": "Let Them Down Easy! Contextual Effects of LLM Guardrails on User Perceptions and Preferences",
    "authors": [
      "Mingqian Zheng",
      "Wenjia Hu",
      "Patrick Zhao",
      "Motahhare Eslami",
      "Jena D. Hwang",
      "Faeze Brahman",
      "Carolyn Rose",
      "Maarten Sap"
    ],
    "abstract": "Current LLMs are trained to refuse potentially harmful input queries\nregardless of whether users actually had harmful intents, causing a tradeoff\nbetween safety and user experience. Through a study of 480 participants\nevaluating 3,840 query-response pairs, we examine how different refusal\nstrategies affect user perceptions across varying motivations. Our findings\nreveal that response strategy largely shapes user experience, while actual user\nmotivation has negligible impact. Partial compliance -- providing general\ninformation without actionable details -- emerges as the optimal strategy,\nreducing negative user perceptions by over 50% to flat-out refusals.\nComplementing this, we analyze response patterns of 9 state-of-the-art LLMs and\nevaluate how 6 reward models score different refusal strategies, demonstrating\nthat models rarely deploy partial compliance naturally and reward models\ncurrently undervalue it. This work demonstrates that effective guardrails\nrequire focusing on crafting thoughtful refusals rather than detecting intent,\noffering a path toward AI safety mechanisms that ensure both safety and\nsustained user engagement.",
    "pdf_url": "http://arxiv.org/pdf/2506.00195v1",
    "published": "2025-05-30T20:07:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00194v1",
    "title": "Demonstration of a reconfigurable ground to space quantum networking scheme",
    "authors": [
      "Stéphane Vinet",
      "Duncan England",
      "Chang-qing Xu",
      "Thomas Jennewein"
    ],
    "abstract": "We experimentally demonstrate a reconfigurable quantum network architecture\nsuitable for integrating satellite links in metropolitan quantum networks. The\nnetwork architecture is designed such that once a satellite is in range, it is\nconfigured in a multipoint-to-point topology where all ground nodes establish\nentanglement with the satellite receiver using time multiplexing to optimize\nlong-distance transmission. Otherwise, the satellite up-link is rerouted to the\nground nodes to form a pair-wise ground network. Leveraging both the time and\nfrequency correlations of our photon-pair source, we demonstrate an increased\ncoincidence-to-accidental ratio without additional resource overhead in a\nfive-node network. To contextualize these experimental findings, we project\ntheir performance in a quantum key distribution scenario and outline a feasible\nroute towards field deployment, using integrated photonics to enable network\nintegration of up to 72 users.",
    "pdf_url": "http://arxiv.org/pdf/2506.00194v1",
    "published": "2025-05-30T20:07:04+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00193v1",
    "title": "Statistics of Strongly Coupled Defects in Superconducting Qubits",
    "authors": [
      "S. Weeden",
      "D. C. Harrison",
      "S. Patel",
      "M. Snyder",
      "E. J. Blackwell",
      "G. Spahn",
      "S. Abdullah",
      "Y. Takeda",
      "B. L. T. Plourde",
      "J. M. Martinis",
      "R. McDermott"
    ],
    "abstract": "Decoherence in superconducting qubits is dominated by defects that reside at\namorphous interfaces. Interaction with discrete defects results in dropouts\nthat complicate qubit operation and lead to nongaussian tails in the\ndistribution of qubit energy relaxation time $T_1$ that degrade system\nperformance. Spectral diffusion of defects over time leads to fluctuations in\n$T_1$, posing a challenge for calibration. In this work, we measure the energy\nrelaxation of flux-tunable transmons over a range of operating frequencies. We\nvary qubit geometry to change the interface participation ratio by more than an\norder of magnitude. Our results are consistent with loss dominated by discrete\ninterfacial defects. Moreover, we are able to localize the dominant defects to\nwithin 500 nm of the qubit junctions, where residues from liftoff are present.\nThese results motivate new approaches to qubit junction fabrication that avoid\nthe residues intrinsic to the liftoff process.",
    "pdf_url": "http://arxiv.org/pdf/2506.00193v1",
    "published": "2025-05-30T20:05:19+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00192v1",
    "title": "STARS-assisted Near-field ISAC: Sensor Deployment and Beamforming Design",
    "authors": [
      "Na Xue",
      "Xidong Mu",
      "Yue Chen",
      "Yuanwei Liu"
    ],
    "abstract": "A simultaneously transmitting and reflecting surface (STARS) assisted\nnear-field (NF) integrated sensing and communication (ISAC) framework is\nproposed, where the radio sensors are installed on the STARS to directly\nconduct the distance-domain sensing by exploiting the characteristic spherical\nwavefront. A new squared position error bound (SPEB) expression is derived to\nreveal the dependence on beamforming (BF) design and sensor deployment. To\nbalance the trade-off between the SPEB and the sensor deployment cost, a cost\nfunction minimization problem, a cost function minimization problem is\nformulated to jointly optimize the sensor deployment, the active and passive\nBF, subject to communication and power consumption constraints. For the sensor\ndeployment optimization, a joint sensor deployment algorithm is proposed by\ninvoking the successive convex approximation. Under a specific relationship\nbetween the sensor numbers and BF design, we derive the optimal sensor interval\nin a closed-form expression. For the joint BF optimization, a penalty-based\nmethod is invoked. Simulation results validated that the derived SPEB\nexpression is close to the exact SPEB, which reveals the Fisher information\nMatrix of position estimation in NF can be approximated as a diagonal matrix.\nFurthermore, the proposed algorithms achieve the best SPEB performance than the\nbenchmark schemes accompanying the lowest deployment cost.",
    "pdf_url": "http://arxiv.org/pdf/2506.00192v1",
    "published": "2025-05-30T20:02:56+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00191v1",
    "title": "Heterogeneous Graph Backdoor Attack",
    "authors": [
      "Jiawei Chen",
      "Lusi Li",
      "Daniel Takabi",
      "Masha Sosonkina",
      "Rui Ning"
    ],
    "abstract": "Heterogeneous Graph Neural Networks (HGNNs) excel in modeling complex,\nmulti-typed relationships across diverse domains, yet their vulnerability to\nbackdoor attacks remains unexplored. To address this gap, we conduct the first\ninvestigation into the susceptibility of HGNNs to existing graph backdoor\nattacks, revealing three critical issues: (1) high attack budget required for\neffective backdoor injection, (2) inefficient and unreliable backdoor\nactivation, and (3) inaccurate attack effectiveness evaluation. To tackle these\nissues, we propose the Heterogeneous Graph Backdoor Attack (HGBA), the first\nbackdoor attack specifically designed for HGNNs, introducing a novel\nrelation-based trigger mechanism that establishes specific connections between\na strategically selected trigger node and poisoned nodes via the backdoor\nmetapath. HGBA achieves efficient and stealthy backdoor injection with minimal\nstructural modifications and supports easy backdoor activation through two\nflexible strategies: Self-Node Attack and Indiscriminate Attack. Additionally,\nwe improve the ASR measurement protocol, enabling a more accurate assessment of\nattack effectiveness. Extensive experiments demonstrate that HGBA far surpasses\nmultiple state-of-the-art graph backdoor attacks in black-box settings,\nefficiently attacking HGNNs with low attack budgets. Ablation studies show that\nthe strength of HBGA benefits from our trigger node selection method and\nbackdoor metapath selection strategy. In addition, HGBA shows superior\nrobustness against node feature perturbations and multiple types of existing\ngraph backdoor defense mechanisms. Finally, extension experiments demonstrate\nthat the relation-based trigger mechanism can effectively extend to tasks in\nhomogeneous graph scenarios, thereby posing severe threats to broader\nsecurity-critical domains.",
    "pdf_url": "http://arxiv.org/pdf/2506.00191v1",
    "published": "2025-05-30T20:02:43+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00190v1",
    "title": "On the regularization property of Levenberg-Marquardt method with Singular Scaling for nonlinear inverse problems",
    "authors": [
      "Rafaela Filippozzi",
      "Everton Boos",
      "Douglas S. Gonçalves",
      "Fermin S. V. Bazán"
    ],
    "abstract": "Recently, in Applied Mathematics and Computation 474 (2024) 128688, a\nLevenberg-Marquardt method (LMM) with Singular Scaling was analyzed and\nsuccessfully applied in parameter estimation problems in heat conduction where\nthe use of a particular singular scaling matrix (semi-norm regularizer)\nprovided approximate solutions of better quality than those of the classic LMM.\nHere we propose a regularization framework for the Levenberg-Marquardt method\nwith Singular Scaling (LMMSS) applied to nonlinear inverse problems with noisy\ndata. Assuming that the noise-free problem admits exact solutions\n(zero-residual case), we consider the LMMSS iteration where the regularization\neffect is induced by the choice of a possibly singular scaling matrix and an\nimplicit control of the regularization parameter. The discrepancy principle is\nused to define a stopping index that ensures stability of the computed\nsolutions with respect to data perturbations. Under a new Tangent Cone\nCondition, we prove that the iterates obtained with noisy data converge to a\nsolution of the unperturbed problem as the noise level tends to zero. This work\nrepresents a first step toward the analysis of regularizing properties of the\nLMMSS method and extends previous results in the literature on regularizing\nLM-type methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00190v1",
    "published": "2025-05-30T19:59:47+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.OC",
      "49M37, 65K05, 90C30"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00189v1",
    "title": "Control-R: Towards controllable test-time scaling",
    "authors": [
      "Di Zhang",
      "Weida Wang",
      "Junxian Li",
      "Xunzhi Wang",
      "Jiatong Li",
      "Jianbo Wu",
      "Jingdi Lei",
      "Haonan He",
      "Peng Ye",
      "Shufei Zhang",
      "Wanli Ouyang",
      "Yuqiang Li",
      "Dongzhan Zhou"
    ],
    "abstract": "This paper target in addressing the challenges of underthinking and\noverthinking in long chain-of-thought (CoT) reasoning for Large Reasoning\nModels (LRMs) by introducing Reasoning Control Fields (RCF)--a novel test-time\napproach that injects structured control signals to guide reasoning from a tree\nsearch perspective. RCF enables models to adjust reasoning effort according to\ngiven control conditions when solving complex tasks. Additionally, we present\nthe Control-R-4K dataset, which consists of challenging problems annotated with\ndetailed reasoning processes and corresponding control fields. To further\nenhance reasoning control, we propose a Conditional Distillation Finetuning\n(CDF) method, which trains model--particularly Control-R-32B--to effectively\nadjust reasoning effort during test time. Experimental results on benchmarks\nsuch as AIME2024 and MATH500 demonstrate that our approach achieves\nstate-of-the-art performance at the 32B scale while enabling a controllable\nLong CoT reasoning process (L-CoT). Overall, this work introduces an effective\nparadigm for controllable test-time scaling reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2506.00189v1",
    "published": "2025-05-30T19:59:44+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00188v1",
    "title": "Cluster-Aware Causal Mixer for Online Anomaly Detection in Multivariate Time Series",
    "authors": [
      "Md Mahmuddun Nabi Murad",
      "Yasin Yilmaz"
    ],
    "abstract": "Early and accurate detection of anomalies in time series data is critical,\ngiven the significant risks associated with false or missed detections. While\nMLP-based mixer models have shown promise in time series analysis, they lack a\ncausality mechanism to preserve temporal dependencies inherent in the system.\nMoreover, real-world multivariate time series often contain numerous channels\nwith diverse inter-channel correlations. A single embedding mechanism for all\nchannels does not effectively capture these complex relationships. To address\nthese challenges, we propose a novel cluster-aware causal mixer to effectively\ndetect anomalies in multivariate time series. Our model groups channels into\nclusters based on their correlations, with each cluster processed through a\ndedicated embedding layer. In addition, we introduce a causal mixer in our\nmodel, which mixes the information while maintaining causality. Furthermore, we\npresent an anomaly detection framework that accumulates the anomaly evidence\nover time to prevent false positives due to nominal outliers. Our proposed\nmodel operates in an online fashion, making it suitable for real-time\ntime-series anomaly detection tasks. Experimental evaluations across six public\nbenchmark datasets demonstrate that our model consistently achieves superior F1\nscores.",
    "pdf_url": "http://arxiv.org/pdf/2506.00188v1",
    "published": "2025-05-30T19:56:54+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.06329v1",
    "title": "The Hype Index: an NLP-driven Measure of Market News Attention",
    "authors": [
      "Zheng Cao",
      "Wanchaloem Wunkaew",
      "Helyette Geman"
    ],
    "abstract": "This paper introduces the Hype Index as a novel metric to quantify media\nattention toward large-cap equities, leveraging advances in Natural Language\nProcessing (NLP) for extracting predictive signals from financial news. Using\nthe S&P 100 as the focus universe, we first construct a News Count-Based Hype\nIndex, which measures relative media exposure by computing the share of news\narticles referencing each stock or sector. We then extend it to the\nCapitalization Adjusted Hype Index, adjusts for economic size by taking the\nratio of a stock's or sector's media weight to its market capitalization weight\nwithin its industry or sector. We compute both versions of the Hype Index at\nthe stock and sector levels, and evaluate them through multiple lenses: (1)\ntheir classification into different hype groups, (2) their associations with\nreturns, volatility, and VIX index at various lags, (3) their signaling power\nfor short-term market movements, and (4) their empirical properties including\ncorrelations, samplings, and trends. Our findings suggest that the Hype Index\nfamily provides a valuable set of tools for stock volatility analysis, market\nsignaling, and NLP extensions in Finance.",
    "pdf_url": "http://arxiv.org/pdf/2506.06329v1",
    "published": "2025-05-30T19:55:54+00:00",
    "categories": [
      "q-fin.ST",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.00187v1",
    "title": "1D Transition Metal Oxide Chains as a Challenging Model for Ab Initio Calculations",
    "authors": [
      "Jila Amini",
      "Mojtaba Alaei",
      "Stefano de Gironcoli"
    ],
    "abstract": "Providing highly simplified models of strongly correlated electronic systems\nthat challenge {\\it ab initio} calculations can serve as a valuable testing\nground to improve these methods. In this study, we present a comprehensive\nstudy of the structural, magnetic, and electronic properties of one-dimensional\ntransition metal mono-oxide chains (VO, CrO, MnO, FeO, CoO, and NiO) using\ndensity functional theory (DFT), DFT+$U$, and coupled-cluster singles and\ndoubles (CCSD) calculations. The Hubbard $U$ parameter for DFT+$U$ is\ndetermined using the linear response theory. In all systems studied except MnO,\nthe presence of multiple local minima -- primarily due to the electronic\ndegrees of freedom associated with the d-orbitals -- leads to significant\nchallenges for DFT, DFT+U, and Hartree-Fock methods in finding the global\nminimum in ab initio calculations. Our results indicate that the\nantiferromagnetic (AFM) state is energetically favored for all chains, except\nCrO, when using DFT+$U$ and PBE. We analyze the electronic band structures and\nfind that while the PBE approximation often predicts metallic or half-metallic\nground states for the ferromagnetic (FM) state, DFT+$U$ approach successfully\nopens band gaps, correctly predicting insulating behavior in all cases.\nFurthermore, we compared the energy differences between the AFM and FM states\nusing DFT+$U$ and CCSD for CrO, MnO, FeO, CoO and NiO. Our findings indicate\nthat CCSD predicts larger energy differences in some cases compared to DFT+$U$,\nsuggesting that the Hubbard $U$ parameter obtained through linear response\ntheory may be overestimated when used to calculate energy differences between\ndifferent magnetic states. For CrO, CCSD predicts an AFM ground state, in\ncontrast to the predictions from DFT+$U$ and PBE methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00187v1",
    "published": "2025-05-30T19:55:51+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.00186v1",
    "title": "Hall algebras and Hecke modifications of vector bundles",
    "authors": [
      "Roberto Alvarenga",
      "Leonardo Moço"
    ],
    "abstract": "In this article, we investigate Hecke modifications of vector bundles on a\nsmooth projective curve $X$ defined over an arbitrary field. We obtain\nstructural results that allow us to reduce the classification problem of Hecke\nmodifications to the case of vector bundles of lower rank. Moreover, when the\nbase field is a finite field and $X$ is the projective line, we apply the Hall\nalgebra of coherent sheaves to provide a full classification of the Hecke\nmodifications, including their multiplicities. These results are applied to\nstudy the space of unramified automorphic forms for $\\mathrm{PGL}_n$ over the\nprojective line, leading to a proof that the space of unramified toroidal\nautomorphic forms is trivial.",
    "pdf_url": "http://arxiv.org/pdf/2506.00186v1",
    "published": "2025-05-30T19:45:30+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00185v1",
    "title": "Pushing the Limits of Beam Search Decoding for Transducer-based ASR models",
    "authors": [
      "Lilit Grigoryan",
      "Vladimir Bataev",
      "Andrei Andrusenko",
      "Hainan Xu",
      "Vitaly Lavrukhin",
      "Boris Ginsburg"
    ],
    "abstract": "Transducer models have emerged as a promising choice for end-to-end ASR\nsystems, offering a balanced trade-off between recognition accuracy, streaming\ncapabilities, and inference speed in greedy decoding. However, beam search\nsignificantly slows down Transducers due to repeated evaluations of key network\ncomponents, limiting practical applications. This paper introduces a universal\nmethod to accelerate beam search for Transducers, enabling the implementation\nof two optimized algorithms: ALSD++ and AES++. The proposed method utilizes\nbatch operations, a tree-based hypothesis structure, novel blank scoring for\nenhanced shallow fusion, and CUDA graph execution for efficient GPU inference.\nThis narrows the speed gap between beam and greedy modes to only 10-20% for the\nwhole system, achieves 14-30% relative improvement in WER compared to greedy\ndecoding, and improves shallow fusion for low-resource up to 11% compared to\nexisting implementations. All the algorithms are open sourced.",
    "pdf_url": "http://arxiv.org/pdf/2506.00185v1",
    "published": "2025-05-30T19:42:48+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00184v1",
    "title": "$\\mathrm{SL}(2,\\mathbb{R})$ families of Kerr black holes",
    "authors": [
      "Robert Penna"
    ],
    "abstract": "The stationary, axisymmetric sector of vacuum general relativity (with zero\ncosmological constant) enjoys an $\\mathrm{SL}(2,\\mathbb{R})$ symmetry called\nthe Matzner-Misner group. We study the action of the Matzner-Misner group on\nthe Kerr black hole. We show that the group acts naturally on a three parameter\ngeneralization of the usual two parameter Kerr solution. The new parameter\nrepresents a large diffeomorphism which gives the spacetime an asymptotic\nangular velocity. We explain how the $\\mathrm{SL}(2,\\mathbb{R})$ symmetry\norganizes the space of three parameter Kerr solutions into the classical\nanalogue of principal series representations. We show that the\n$\\mathrm{SL}(2,\\mathbb{R})$ Casimir operator is the Bekenstein-Hawking entropy.\nThe Matzner-Misner group sits inside a much larger Kac-Moody symmetry called\nthe Geroch group. We show that the Kac-Moody level of the Kerr black hole is\nthe Bekenstein-Hawking entropy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00184v1",
    "published": "2025-05-30T19:42:08+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.00183v1",
    "title": "A remark on inverse limits of effective subshifts",
    "authors": [
      "Sebastián Barbieri",
      "Leo Poirier"
    ],
    "abstract": "We show that, for every finitely generated group with decidable word problem\nand undecidable domino problem, there exists a sequence of effective subshifts\nwhose inverse limit is not the topological factor of any effective dynamical\nsystem. This follows from considerations on the universality under topological\nfactors for this class of dynamical systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00183v1",
    "published": "2025-05-30T19:41:39+00:00",
    "categories": [
      "math.DS",
      "37B10, 20F10"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00182v1",
    "title": "Overfitting has a limitation: a model-independent generalization error bound based on Rényi entropy",
    "authors": [
      "Atsushi Suzuki"
    ],
    "abstract": "Will further scaling up of machine learning models continue to bring success?\nA significant challenge in answering this question lies in understanding\ngeneralization error, which is the impact of overfitting. Understanding\ngeneralization error behavior of increasingly large-scale machine learning\nmodels remains a significant area of investigation, as conventional analyses\noften link error bounds to model complexity, failing to fully explain the\nsuccess of extremely large architectures. This research introduces a novel\nperspective by establishing a model-independent upper bound for generalization\nerror applicable to algorithms whose outputs are determined solely by the\ndata's histogram, such as empirical risk minimization or gradient-based\nmethods. Crucially, this bound is shown to depend only on the R\\'enyi entropy\nof the data-generating distribution, suggesting that a small generalization\nerror can be maintained even with arbitrarily large models, provided the data\nquantity is sufficient relative to this entropy. This framework offers a direct\nexplanation for the phenomenon where generalization performance degrades\nsignificantly upon injecting random noise into data, where the performance\ndegrade is attributed to the consequent increase in the data distribution's\nR\\'enyi entropy. Furthermore, we adapt the no-free-lunch theorem to be\ndata-distribution-dependent, demonstrating that an amount of data corresponding\nto the R\\'enyi entropy is indeed essential for successful learning, thereby\nhighlighting the tightness of our proposed generalization bound.",
    "pdf_url": "http://arxiv.org/pdf/2506.00182v1",
    "published": "2025-05-30T19:41:37+00:00",
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00181v1",
    "title": "On the Interaction of Noise, Compression Role, and Adaptivity under $(L_0, L_1)$-Smoothness: An SDE-based Approach",
    "authors": [
      "Enea Monzio Compagnoni",
      "Rustem Islamov",
      "Antonio Orvieto",
      "Eduard Gorbunov"
    ],
    "abstract": "Using stochastic differential equation (SDE) approximations, we study the\ndynamics of Distributed SGD, Distributed Compressed SGD, and Distributed\nSignSGD under $(L_0,L_1)$-smoothness and flexible noise assumptions. Our\nanalysis provides insights -- which we validate through simulation -- into the\nintricate interactions between batch noise, stochastic gradient compression,\nand adaptivity in this modern theoretical setup. For instance, we show that\n\\textit{adaptive} methods such as Distributed SignSGD can successfully converge\nunder standard assumptions on the learning rate scheduler, even under\nheavy-tailed noise. On the contrary, Distributed (Compressed) SGD with\npre-scheduled decaying learning rate fails to achieve convergence, unless such\na schedule also accounts for an inverse dependency on the gradient norm -- de\nfacto falling back into an adaptive method.",
    "pdf_url": "http://arxiv.org/pdf/2506.00181v1",
    "published": "2025-05-30T19:35:15+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00180v2",
    "title": "Empirical Validation of the Independent Chip Model",
    "authors": [
      "Juho Kim"
    ],
    "abstract": "The independent chip model (ICM) forms a cornerstone of all modern poker\ntournament strategy. However, despite its prominence, the ICM's performance in\nthe real world has not been sufficiently scrutinized, especially at a large\nscale. In this paper, we introduce our new dataset of poker tournaments,\nconsisting of results of over ten thousand events. Then, using this dataset, we\nperform two experiments as part of a large-scale empirical validation of the\nICM. First, we verify that the ICM performs more accurately than a baseline we\npropose. Second, we obtain empirical evidence of the ICM underestimating the\nperformances of players with larger stacks while overestimating those who are\nshort-stacked. Our contributions may be useful to future researchers developing\nnew algorithms for estimating a player's value in poker tournaments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00180v2",
    "published": "2025-05-30T19:34:02+00:00",
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00179v1",
    "title": "Impact of surface roughness on the stability of nanoelectromechanical pressure sensors in the Casimir regime",
    "authors": [
      "G. L. Klimchitskaya",
      "A. S. Korotkov",
      "V. V. Loboda",
      "V. M. Mostepanenko"
    ],
    "abstract": "The stability of nanoelectromechanical pressure sensors working in the\nCasimir regime is considered with account of surface roughness on both the\nsensor membrane and the ground plate. The equilibrium positions of the sensor\nmembrane are found from the balance between the external measured, elastic,\nelectric pressures, and the Casimir pressure computed by means of the Lifshitz\ntheory. It is shown that the stable equilibrium position of the sensor membrane\nis nearly independent of the surface roughness, whereas its unstable\nequilibrium position is shifted to larger membrane-plate separations. The use\nof these results for creatign pressure sensors with further shrinked dimensions\nis discussed.",
    "pdf_url": "http://arxiv.org/pdf/2506.00179v1",
    "published": "2025-05-30T19:33:44+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00178v2",
    "title": "Tournament of Prompts: Evolving LLM Instructions Through Structured Debates and Elo Ratings",
    "authors": [
      "Anirudh Nair",
      "Adi Banerjee",
      "Laurent Mombaerts",
      "Matthew Hagen",
      "Tarik Borogovac"
    ],
    "abstract": "Prompt engineering represents a critical bottleneck to harness the full\npotential of Large Language Models (LLMs) for solving complex tasks, as it\nrequires specialized expertise, significant trial-and-error, and manual\nintervention. This challenge is particularly pronounced for tasks involving\nsubjective quality assessment, where defining explicit optimization objectives\nbecomes fundamentally problematic. Existing automated prompt optimization\nmethods falter in these scenarios, as they typically require well-defined\ntask-specific numerical fitness functions or rely on generic templates that\ncannot capture the nuanced requirements of complex use cases. We introduce\nDEEVO (DEbate-driven EVOlutionary prompt optimization), a novel framework that\nguides prompt evolution through a debate-driven evaluation with an Elo-based\nselection. Contrary to prior work, DEEVOs approach enables exploration of the\ndiscrete prompt space while preserving semantic coherence through intelligent\ncrossover and strategic mutation operations that incorporate debate-based\nfeedback, combining elements from both successful and unsuccessful prompts\nbased on identified strengths rather than arbitrary splicing. Using Elo ratings\nas a fitness proxy, DEEVO simultaneously drives improvement and preserves\nvaluable diversity in the prompt population. Experimental results demonstrate\nthat DEEVO significantly outperforms both manual prompt engineering and\nalternative state-of-the-art optimization approaches on open-ended tasks and\nclose-ended tasks despite using no ground truth feedback. By connecting LLMs\nreasoning capabilities with adaptive optimization, DEEVO represents a\nsignificant advancement in prompt optimization research by eliminating the need\nof predetermined metrics to continuously improve AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00178v2",
    "published": "2025-05-30T19:33:41+00:00",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00177v1",
    "title": "Creation of a degenerate Bose-Bose mixture of erbium and lithium atoms",
    "authors": [
      "Jasmine Kalia",
      "Jared Rivera",
      "Rubaiya R Emran",
      "William J Solorio Hernandez",
      "Kiryang Kwon",
      "Richard J Fletcher"
    ],
    "abstract": "We report the realization of a degenerate mixture of $^{166}$Er and $^{7}$Li\natoms in their lowest spin state. The two species are sequentially laser-cooled\nand loaded into an optical dipole trap, then transported to a glass cell in\nwhich further cooling to degeneracy occurs. Since Er is more weakly trapped, it\nserves as a coolant for Li, and we observe efficient sympathetic cooling\nfacilitated by a large interspecies elastic scattering cross section.\nThree-body losses are found to be small at the magnetic fields explored, making\nthis platform promising for the study of interacting mixtures with large mass\nimbalance.",
    "pdf_url": "http://arxiv.org/pdf/2506.00177v1",
    "published": "2025-05-30T19:33:36+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "physics.atom-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2506.02033v1",
    "title": "Smartphone-Based Food Traceability System Using NoSQL Database",
    "authors": [
      "Muhammad Syafrudin",
      "Ganjar Alfian",
      "Norma Latif Fitriyani"
    ],
    "abstract": "With growing consumer health awareness, ensuring food safety and quality\nthroughout the supply chain is crucial, particularly for perishable goods.\nContamination can occur during production, processing, or distribution, making\nreal-time monitoring essential. This study proposes an affordable\nSmartphone-based food traceability system (FTS) that utilizes RFID technology\nand smartphone sensors. A smartphone-based RFID reader tracks products, while\nintegrated sensors monitor temperature, humidity, and location during storage\nand transport. The system is assessed in the kimchi supply chain in Korea,\nproviding real-time data to both managers and consumers. It offered\ncomprehensive product tracking, including temperature and humidity records,\nensuring transparency and safety. Compared to traditional methods, the proposed\nsystem demonstrated improved efficiency in handling large volumes of data while\nmaintaining accurate traceability. The results highlight its potential for\nenhancing food safety and quality across supply chains.",
    "pdf_url": "http://arxiv.org/pdf/2506.02033v1",
    "published": "2025-05-30T19:31:24+00:00",
    "categories": [
      "cs.OH",
      "cs.CY"
    ],
    "primary_category": "cs.OH"
  },
  {
    "id": "http://arxiv.org/abs/2506.03187v1",
    "title": "Comparing Retrieval Strategies to Capture Interdisciplinary Scientific Research: A Bibliometric Evaluation of the Integration of Neuroscience and Computer Science",
    "authors": [
      "Malena Mendez Isla",
      "Agustin Mauro",
      "Diego Kozlowski"
    ],
    "abstract": "Interdisciplinary scientific research is increasingly important in knowledge\nproduction, funding policies, and academic discussions on scholarly\ncommunication. While many studies focus on interdisciplinary corpora defined a\npriori - usually through keyword-based searches within assumed\ninterdisciplinary domains - few explore interdisciplinarity as an emergent\nintersection between two distinct fields. Thus, methodological proposals for\nbuilding databases at the intersection of two fields of knowledge are scarce.\nThe goal of this article is to develop and compare different strategies for\ndefining an interdisciplinary corpus between two bodies of knowledge. As a case\nstudy, we focus on the intersection between neuroscience and computer science.\nTo this end, we develop and compare four retrieval strategies, two of them\nbased on keywords and two based on citation and reference patterns. Our results\nshow that keyword-based strategies provide both better precision and recall.\nWhile we focus on comparing strategies for the study of the intersection\nbetween the fields of neuroscience and computer science, this proposed\nmethodological reflection is applicable to a wide range of interdisciplinary\ndomains.",
    "pdf_url": "http://arxiv.org/pdf/2506.03187v1",
    "published": "2025-05-30T19:29:18+00:00",
    "categories": [
      "cs.DL",
      "cs.IR"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00176v2",
    "title": "Self-ion implantation and structural relaxation in amorphous silicon",
    "authors": [
      "J. M. Gibson",
      "Robe Elliman",
      "T. Susi",
      "C. Mangler"
    ],
    "abstract": "Self-ion implantation amorphization is an established approach to study the\nstructure and properties of amorphous silicon (a-Si). Fluctuation Electron\nMicroscopy (FEM) has consistently observed Medium-Range Order (MRO) in this\nsystem that is not consistent with the Continuous Random Network (CRN) model.\nUsing this technique we find that the degree of MRO first increases on thermal\nannealing and then decreases before finally recrystallizing. We discuss this\nnew result in the light of previous experimental studies and recent theoretical\nobservations on the favorability of the paracrystalline (PC) model over the CRN\nin a-Si. At ion doses far above the minimum required to amorphize, a high\ndefect density is found in the PC phase, which anneals out at 500oC. The PC\nstructure after 500oC annealing is independent of the initial implantation\nconditions and appears to represent a metastable and highly-ordered structure.\nHigher-temperature annealing causes a reduction in the degree of MRO and the\nstructure approaches but does not reach a fully continuous random network\nbefore eventually crystallizing above 600oC. The effect of high dose\nimplantation is to increase the defect density in the as-implanted state and\nthe annealing of these defects is likely responsible for the large\ncharacteristic heat evolution at low temperature.",
    "pdf_url": "http://arxiv.org/pdf/2506.00176v2",
    "published": "2025-05-30T19:28:49+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00175v3",
    "title": "Who Gets Credit or Blame? Attributing Accountability in Modern AI Systems",
    "authors": [
      "Shichang Zhang",
      "Hongzhe Du",
      "Jiaqi W. Ma",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Modern AI systems are typically developed through multiple\nstages-pretraining, fine-tuning rounds, and subsequent adaptation or alignment,\nwhere each stage builds on the previous ones and updates the model in distinct\nways. This raises a critical question of accountability: when a deployed model\nsucceeds or fails, which stage is responsible, and to what extent? We pose the\naccountability attribution problem for tracing model behavior back to specific\nstages of the model development process. To address this challenge, we propose\na general framework that answers counterfactual questions about stage effects:\nhow would the model's behavior have changed if the updates from a particular\nstage had not occurred? Within this framework, we introduce estimators that\nefficiently quantify stage effects without retraining the model, accounting for\nboth the data and key aspects of model optimization dynamics, including\nlearning rate schedules, momentum, and weight decay. We demonstrate that our\napproach successfully quantifies the accountability of each stage to the\nmodel's behavior. Based on the attribution results, our method can identify and\nremove spurious correlations learned during image classification and text\ntoxicity detection tasks that were developed across multiple stages. Our\napproach provides a practical tool for model analysis and represents a\nsignificant step toward more accountable AI development.",
    "pdf_url": "http://arxiv.org/pdf/2506.00175v3",
    "published": "2025-05-30T19:27:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.06328v1",
    "title": "Is BERTopic Better than PLSA for Extracting Key Topics in Aviation Safety Reports?",
    "authors": [
      "Aziida Nanyonga",
      "Joiner Keith",
      "Turhan Ugur",
      "Wild Graham"
    ],
    "abstract": "This study compares the effectiveness of BERTopic and Probabilistic Latent\nSemantic Analysis (PLSA) in extracting meaningful topics from aviation safety\nreports aiming to enhance the understanding of patterns in aviation incident\ndata. Using a dataset of over 36,000 National Transportation Safety Board\n(NTSB) reports from 2000 to 2020, BERTopic employed transformer based\nembeddings and hierarchical clustering, while PLSA utilized probabilistic\nmodelling through the Expectation-Maximization (EM) algorithm. Results showed\nthat BERTopic outperformed PLSA in topic coherence, achieving a Cv score of\n0.41 compared to PLSA 0.37, while also demonstrating superior interpretability\nas validated by aviation safety experts. These findings underscore the\nadvantages of modern transformer based approaches in analyzing complex aviation\ndatasets, paving the way for enhanced insights and informed decision-making in\naviation safety. Future work will explore hybrid models, multilingual datasets,\nand advanced clustering techniques to further improve topic modelling in this\ndomain.",
    "pdf_url": "http://arxiv.org/pdf/2506.06328v1",
    "published": "2025-05-30T19:27:11+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00174v1",
    "title": "Constrained Bayesian Optimization under Bivariate Gaussian Process with Application to Cure Process Optimization",
    "authors": [
      "Yezhuo Li",
      "Qiong Zhang",
      "Madhura Limaye",
      "Gang Li"
    ],
    "abstract": "Bayesian Optimization, leveraging Gaussian process models, has proven to be a\npowerful tool for minimizing expensive-to-evaluate objective functions by\nefficiently exploring the search space. Extensions such as constrained Bayesian\nOptimization have further enhanced Bayesian Optimization's utility in practical\nscenarios by focusing the search within feasible regions defined by a black-box\nconstraint function. However, constrained Bayesian Optimization in is developed\nbased on the independence Gaussian processes assumption between objective and\nconstraint functions, which may not hold in real-world applications. To address\nthis issue, we use the bivariate Gaussian process model to characterize the\ndependence between the objective and constraint functions and developed the\nconstrained expected improvement acquisition function under this model\nassumption. We show case the performance of the proposed approach with an\napplication to cure process optimization in Manufacturing.",
    "pdf_url": "http://arxiv.org/pdf/2506.00174v1",
    "published": "2025-05-30T19:24:54+00:00",
    "categories": [
      "stat.CO",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00173v1",
    "title": "MotionPersona: Characteristics-aware Locomotion Control",
    "authors": [
      "Mingyi Shi",
      "Wei Liu",
      "Jidong Mei",
      "Wangpok Tse",
      "Rui Chen",
      "Xuelin Chen",
      "Taku Komura"
    ],
    "abstract": "We present MotionPersona, a novel real-time character controller that allows\nusers to characterize a character by specifying attributes such as physical\ntraits, mental states, and demographics, and projects these properties into the\ngenerated motions for animating the character. In contrast to existing deep\nlearning-based controllers, which typically produce homogeneous animations\ntailored to a single, predefined character, MotionPersona accounts for the\nimpact of various traits on human motion as observed in the real world. To\nachieve this, we develop a block autoregressive motion diffusion model\nconditioned on SMPLX parameters, textual prompts, and user-defined locomotion\ncontrol signals. We also curate a comprehensive dataset featuring a wide range\nof locomotion types and actor traits to enable the training of this\ncharacteristic-aware controller. Unlike prior work, MotionPersona is the first\nmethod capable of generating motion that faithfully reflects user-specified\ncharacteristics (e.g., an elderly person's shuffling gait) while responding in\nreal time to dynamic control inputs. Additionally, we introduce a few-shot\ncharacterization technique as a complementary conditioning mechanism, enabling\ncustomization via short motion clips when language prompts fall short. Through\nextensive experiments, we demonstrate that MotionPersona outperforms existing\nmethods in characteristics-aware locomotion control, achieving superior motion\nquality and diversity. Results, code, and demo can be found at:\nhttps://motionpersona25.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2506.00173v1",
    "published": "2025-05-30T19:24:43+00:00",
    "categories": [
      "cs.GR",
      "cs.RO"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00172v1",
    "title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents",
    "authors": [
      "Kaivalya Hariharan",
      "Uzay Girit",
      "Atticus Wang",
      "Jacob Andreas"
    ],
    "abstract": "Benchmarks for large language models (LLMs) have predominantly assessed\nshort-horizon, localized reasoning. Existing long-horizon suites (e.g.\nSWE-bench) rely on manually curated issues, so expanding or tuning difficulty\ndemands expensive human effort and evaluations quickly saturate. However, many\nreal-world tasks, such as software engineering or scientific research, require\nagents to rapidly comprehend and manipulate novel, complex structures\ndynamically; evaluating these capabilities requires the ability to construct\nlarge and varied sets of problems for agents to solve. We introduce Breakpoint,\na benchmarking methodology that automatically generates code-repair tasks by\nadversarially corrupting functions within real-world software repositories.\nBreakpoint systematically controls task difficulty along two clear dimensions:\nlocal reasoning (characterized by code complexity metrics such as cyclomatic\ncomplexity) and system-level reasoning (characterized by call-graph centrality\nand the number of simultaneously corrupted interdependent functions). In\nexperiments across more than 900 generated tasks we demonstrate that our\nmethodology can scale to arbitrary difficulty, with state-of-the-art models'\nsuccess rates ranging from 55% on the easiest tasks down to 0% on the hardest.",
    "pdf_url": "http://arxiv.org/pdf/2506.00172v1",
    "published": "2025-05-30T19:23:51+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00171v1",
    "title": "Minimax Rates for the Estimation of Eigenpairs of Weighted Laplace-Beltrami Operators on Manifolds",
    "authors": [
      "Nicolás García Trillos",
      "Chenghui Li",
      "Raghavendra Venkatraman"
    ],
    "abstract": "We study the problem of estimating eigenpairs of elliptic differential\noperators from samples of a distribution $\\rho$ supported on a manifold $M$.\nThe operators discussed in the paper are relevant in unsupervised learning and\nin particular are obtained by taking suitable scaling limits of widely used\ngraph Laplacians over data clouds. We study the minimax risk for this eigenpair\nestimation problem and explore the rates of approximation that can be achieved\nby commonly used graph Laplacians built from random data. More concretely,\nassuming that $\\rho$ belongs to a certain family of distributions with\ncontrolled second derivatives, and assuming that the $d$-dimensional manifold\n$M$ where $\\rho$ is supported has bounded geometry, we prove that the\nstatistical minimax rate for approximating eigenvalues and eigenvectors in the\n$H^1(M)$-sense is $n^{-2/(d+4)}$, a rate that matches the minimax rate for a\nclosely related density estimation problem. We then revisit the literature\nstudying Laplacians over proximity graphs in the large data limit and prove\nthat, under slightly stronger regularity assumptions on the data generating\nmodel, eigenpairs of graph Laplacians induce manifold agnostic estimators with\nan error of approximation that, up to logarithmic corrections, matches our\nlower bounds. Our analysis allows us to expand the existing literature on\ngraph-based learning in at least two significant ways: 1) we consider stronger\nnorms to measure the error of approximation than the ones that had been\nanalyzed in the past; 2) our rates of convergence are uniform over a family of\nsmooth distributions and do not just apply to densities with special\nsymmetries, and, as a consequence of our lower bounds, are essentially sharp\nwhen the connectivity of the graph is sufficiently high.",
    "pdf_url": "http://arxiv.org/pdf/2506.00171v1",
    "published": "2025-05-30T19:19:25+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.AP"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00170v1",
    "title": "The Free Functional Calculus in General",
    "authors": [
      "Julian Bushelli"
    ],
    "abstract": "The classical theory of free analysis generalizes the noncommutative (nc)\npolynomials and rational functions, easily providing such results as an nc\nanalogue of the Jacobian conjecture. However, the classical theory misses out\non important functions, such as the Schur complement. This paper presents a\ngeneralization of free functions, viewing them as a natural categorial\nstructure: functors between functor categories that commute with natural\ntransformation. We study this construction on general additive categories; we\ndefine, characterize and categorize certain sorts of free maps, such as\npolynomials and rational expressions, and then prove an analogue of the inverse\nfunction theorem, demonstrating a natural lifting of a proof into this broader\ncontext.\n  We then provide some algebraic basis for this theory, constructing vector\nspaces, an additive category of free polynomials, and defining a class of\nproducts that allows us to form true ring structures on any vector space of\nfree nc polynomials.",
    "pdf_url": "http://arxiv.org/pdf/2506.00170v1",
    "published": "2025-05-30T19:16:21+00:00",
    "categories": [
      "math.CT",
      "math.FA",
      "math.OA",
      "18A25 (primary) 47A60, 46M15, 32A38, 46H30 (secondary)"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00169v1",
    "title": "Utilizing AI for Aviation Post-Accident Analysis Classification",
    "authors": [
      "Aziida Nanyonga",
      "Graham Wild"
    ],
    "abstract": "The volume of textual data available in aviation safety reports presents a\nchallenge for timely and accurate analysis. This paper examines how Artificial\nIntelligence (AI) and, specifically, Natural Language Processing (NLP) can\nautomate the process of extracting valuable insights from this data, ultimately\nenhancing aviation safety. The paper reviews ongoing efforts focused on the\napplication of NLP and deep learning to aviation safety reports, with the goal\nof classifying the level of damage to an aircraft and identifying the phase of\nflight during which safety occurrences happen. Additionally, the paper explores\nthe use of Topic Modeling (TM) to uncover latent thematic structures within\naviation incident reports, aiming to identify recurring patterns and potential\nareas for safety improvement. The paper compares and contrasts the performance\nof various deep learning models and TM techniques applied to datasets from the\nNational Transportation Safety Board (NTSB) and the Australian Transport Safety\nBureau (ATSB), as well as the Aviation Safety Network (ASN), discussing the\nimpact of dataset size and source on the accuracy of the analysis. The findings\ndemonstrate that both NLP and deep learning, as well as TM, can significantly\nimprove the efficiency and accuracy of aviation safety analysis, paving the way\nfor more proactive safety management and risk mitigation strategies.",
    "pdf_url": "http://arxiv.org/pdf/2506.00169v1",
    "published": "2025-05-30T19:15:04+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00168v2",
    "title": "A novel sensitivity analysis method for agent-based models stratifies in-silico tumor spheroid simulations",
    "authors": [
      "Edward H. Rohr",
      "John T. Nardini"
    ],
    "abstract": "Agent-based models (ABMs) are widely used in biology to understand how\nindividual actions scale into emergent population behavior. Modelers employ\nsensitivity analysis (SA) algorithms to quantify input parameters' impact on\nmodel outputs, however, it is hard to perform SA for ABMs due to their\ncomputational and complex nature. In this work, we develop the Simulate,\nSummarize, Reduce, Cluster, and Analyze (SSRCA) methodology, a machine-learning\nbased pipeline designed to facilitate SA for ABMs. In particular, SSRCA can\nachieve the following tasks for ABMS: 1) identify sensitive model parameters,\n2) reveal common output model patterns, and 3) determine which input parameter\nvalues generate these patterns. We use an example ABM of tumor spheroid growth\nto showcase how SSRCA provides similar SA results to the popular Sobol' Method\nwhile also identifying four common patterns from the ABM and the parameter\nregions that generate these outputs. This analysis could streamline data-driven\ntasks, such as parameter estimation, for ABMs by reducing parameter space.\nWhile we highlight these results with an ABM on tumor spheroid formation, the\nSSRCA methodology is broadly applicable to biological ABMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00168v2",
    "published": "2025-05-30T19:12:45+00:00",
    "categories": [
      "q-bio.QM",
      "q-bio.CB",
      "stat.ML"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00167v1",
    "title": "Cyrus+: A DRL-based Puncturing Solution to URLLC/eMBB Multiplexing in O-RAN",
    "authors": [
      "Ehsan Ghoreishi",
      "Bahman Abolhassani",
      "Yan Huang",
      "Shiva Acharya",
      "Wenjing Lou",
      "Y. Thomas Hou"
    ],
    "abstract": "Puncturing is a promising technique in 3GPP to multiplex Enhanced Mobile\nBroadband (eMBB) and Ultra-Reliable Low Latency Communications (URLLC) traffic\non the same 5G New Radio (NR) air interface. The essence of puncturing is to\ntransmit URLLC packets on demand upon their arrival, by preempting the radio\nresources (or subcarriers) that are already allocated to eMBB traffic. Although\nit is considered most bandwidth efficient, puncturing URLLC data on eMBB can\nlead to degradation of eMBB's performance. Most of the state-of-the-art\nresearch addressing this problem employ raw eMBB data throughput as performance\nmetric. This is inadequate as, after puncturing, eMBB data may or may not be\nsuccessfully decoded at its receiver. This paper presents Cyrus+, a deep\nreinforcement learning (DRL)-based puncturing solution that employs goodput\n(through feedback from a receiver's decoder), rather than estimated raw\nthroughput, in its design of reward function. Further, Cyrus+ is tailored\nspecifically for the Open RAN (O-RAN) architecture and fully leverages O-RAN's\nthree control loops at different time scales in its design of DRL. In the\nNon-Real-Time (Non-RT) RAN Intelligent Controller (RIC), Cyrus+ initializes the\npolicy network that will be used in the RT Open Distributed Unit (O-DU). In the\nNear-RT RIC, Cyrus+ refines the policy based on dynamic network conditions and\nfeedback from the receivers. In the RT O-DU, Cyrus+ generates a puncturing\ncodebook by considering all possible URLLC arrivals. We build a\nstandard-compliant link-level 5G NR simulator to demonstrate the efficacy of\nCyrus+. Experimental results show that Cyrus+ outperforms benchmark puncturing\nalgorithms and meets the stringent timing requirement in 5G NR (numerology 3).",
    "pdf_url": "http://arxiv.org/pdf/2506.00167v1",
    "published": "2025-05-30T19:12:26+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00166v1",
    "title": "Disentangled Safety Adapters Enable Efficient Guardrails and Flexible Inference-Time Alignment",
    "authors": [
      "Kundan Krishna",
      "Joseph Y Cheng",
      "Charles Maalouf",
      "Leon A Gatys"
    ],
    "abstract": "Existing paradigms for ensuring AI safety, such as guardrail models and\nalignment training, often compromise either inference efficiency or development\nflexibility. We introduce Disentangled Safety Adapters (DSA), a novel framework\naddressing these challenges by decoupling safety-specific computations from a\ntask-optimized base model. DSA utilizes lightweight adapters that leverage the\nbase model's internal representations, enabling diverse and flexible safety\nfunctionalities with minimal impact on inference cost. Empirically, DSA-based\nsafety guardrails substantially outperform comparably sized standalone models,\nnotably improving hallucination detection (0.88 vs. 0.61 AUC on Summedits) and\nalso excelling at classifying hate speech (0.98 vs. 0.92 on ToxiGen) and unsafe\nmodel inputs and responses (0.93 vs. 0.90 on AEGIS2.0 & BeaverTails).\nFurthermore, DSA-based safety alignment allows dynamic, inference-time\nadjustment of alignment strength and a fine-grained trade-off between\ninstruction following performance and model safety. Importantly, combining the\nDSA safety guardrail with DSA safety alignment facilitates context-dependent\nalignment strength, boosting safety on StrongReject by 93% while maintaining\n98% performance on MTBench -- a total reduction in alignment tax of 8\npercentage points compared to standard safety alignment fine-tuning. Overall,\nDSA presents a promising path towards more modular, efficient, and adaptable AI\nsafety and alignment.",
    "pdf_url": "http://arxiv.org/pdf/2506.00166v1",
    "published": "2025-05-30T19:11:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00165v1",
    "title": "Randomized Dimensionality Reduction for Euclidean Maximization and Diversity Measures",
    "authors": [
      "Jie Gao",
      "Rajesh Jayaram",
      "Benedikt Kolbe",
      "Shay Sapir",
      "Chris Schwiegelshohn",
      "Sandeep Silwal",
      "Erik Waingarten"
    ],
    "abstract": "Randomized dimensionality reduction is a widely-used algorithmic technique\nfor speeding up large-scale Euclidean optimization problems. In this paper, we\nstudy dimension reduction for a variety of maximization problems, including\nmax-matching, max-spanning tree, max TSP, as well as various measures for\ndataset diversity. For these problems, we show that the effect of dimension\nreduction is intimately tied to the \\emph{doubling dimension} $\\lambda_X$ of\nthe underlying dataset $X$ -- a quantity measuring intrinsic dimensionality of\npoint sets. Specifically, we prove that a target dimension of $O(\\lambda_X)$\nsuffices to approximately preserve the value of any near-optimal solution,which\nwe also show is necessary for some of these problems. This is in contrast to\nclassical dimension reduction results, whose dependence increases with the\ndataset size $|X|$. We also provide empirical results validating the quality of\nsolutions found in the projected space, as well as speedups due to\ndimensionality reduction.",
    "pdf_url": "http://arxiv.org/pdf/2506.00165v1",
    "published": "2025-05-30T19:11:03+00:00",
    "categories": [
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00164v1",
    "title": "Efficient Endangered Deer Species Monitoring with UAV Aerial Imagery and Deep Learning",
    "authors": [
      "Agustín Roca",
      "Gabriel Torre",
      "Juan I. Giribet",
      "Gastón Castro",
      "Leonardo Colombo",
      "Ignacio Mas",
      "Javier Pereira"
    ],
    "abstract": "This paper examines the use of Unmanned Aerial Vehicles (UAVs) and deep\nlearning for detecting endangered deer species in their natural habitats. As\ntraditional identification processes require trained manual labor that can be\ncostly in resources and time, there is a need for more efficient solutions.\nLeveraging high-resolution aerial imagery, advanced computer vision techniques\nare applied to automate the identification process of deer across two distinct\nprojects in Buenos Aires, Argentina. The first project, Pantano Project,\ninvolves the marsh deer in the Paran\\'a Delta, while the second, WiMoBo,\nfocuses on the Pampas deer in Campos del Tuy\\'u National Park. A tailored\nalgorithm was developed using the YOLO framework, trained on extensive datasets\ncompiled from UAV-captured images. The findings demonstrate that the algorithm\neffectively identifies marsh deer with a high degree of accuracy and provides\ninitial insights into its applicability to Pampas deer, albeit with noted\nlimitations. This study not only supports ongoing conservation efforts but also\nhighlights the potential of integrating AI with UAV technology to enhance\nwildlife monitoring and management practices.",
    "pdf_url": "http://arxiv.org/pdf/2506.00164v1",
    "published": "2025-05-30T19:09:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00163v1",
    "title": "Computing Witnesses Using the SCAN Algorithm (Extended Preprint)",
    "authors": [
      "Fabian Achammer",
      "Stefan Hetzl",
      "Renate A. Schmidt"
    ],
    "abstract": "Second-order quantifier-elimination is the problem of finding, given a\nformula with second-order quantifiers, a logically equivalent first-order\nformula. While such formulas are not computable in general, there are practical\nalgorithms and subclasses with applications throughout computational logic. One\nof the most prominent algorithms for second-order quantifier elimination is the\nSCAN algorithm which is based on saturation theorem proving. In this paper we\nshow how the SCAN algorithm on clause sets can be extended to solve a more\ngeneral problem: namely, finding an instance of the second-order quantifiers\nthat results in a logically equivalent first-order formula. In addition we\nprovide a prototype implementation of the proposed method. This work paves the\nway for applying the SCAN algorithm to new problems in application domains such\nas modal correspondence theory, knowledge representation, and verification.",
    "pdf_url": "http://arxiv.org/pdf/2506.00163v1",
    "published": "2025-05-30T19:08:00+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00162v1",
    "title": "Efficient detection of genuine multipartite entanglement using moments of positive maps",
    "authors": [
      "Saheli Mukherjee",
      "Bivas Mallick",
      "Sahil Gopalkrishna Naik",
      "Ananda G. Maity",
      "A. S. Majumdar"
    ],
    "abstract": "Genuine multipartite entanglement (GME) represents the strongest form of\nentanglement in multipartite systems, providing significant advantages in\nvarious quantum information processing tasks. In this work, we propose an\nefficient and experimentally feasible scheme for detecting GME, based on the\ntruncated moments of positive maps. Our method avoids the need for full state\ntomography, making it scalable for larger systems. We provide illustrative\nexamples of both pure and mixed states to demonstrate the efficacy of our\nformalism in detecting inequivalent classes of tripartite genuine entanglement.\nFinally, we present a proposal for realising these moments in real experiments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00162v1",
    "published": "2025-05-30T19:07:53+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00161v1",
    "title": "Transition from Optically Excited to Intrinsic Spin Polarization in WSe$_2$",
    "authors": [
      "Sebastian Hedwig",
      "Gregor Zinke",
      "Jürgen Braun",
      "Benito Arnoldi",
      "Aki Pulkkinen",
      "Ján Minár",
      "Hubert Ebert",
      "Martin Aeschlimann",
      "Benjamin Stadtmüller"
    ],
    "abstract": "Layered 2D van der Waals materials, such as transition metal dichalcogenides,\nare promising for nanoscale spintronic and optoelectronic applications.\nHarnessing their full potential requires understanding both intrinsic transport\nand the dynamics of optically excited spin and charge carriers -- particularly\nthe transition between excited spin polarization and the conduction band's\nintrinsic spin texture. Here, we investigate the spin polarization of the\nconduction bands of bulk WSe$_2$ using static and time-resolved spin-resolved\nphotoemission spectroscopy, complemented by photocurrent calculations. Electron\ndoping reveals the intrinsic spin polarization, while time-resolved\nmeasurements trace the evolution of excited spin carriers. We find that\nintervalley scattering is spin-conserving, with spin transport initially\ngoverned by photoexcited carriers and aligning with the intrinsic conduction\nband polarization after $\\sim$150 fs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00161v1",
    "published": "2025-05-30T19:02:54+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.00160v2",
    "title": "Verbal Werewolf: Engage Users with Verbalized Agentic Werewolf Game Framework",
    "authors": [
      "Qihui Fan",
      "Wenbo Li",
      "Enfu Nan",
      "Yixiao Chen",
      "Lei Lu",
      "Pu Zhao",
      "Yanzhi Wang"
    ],
    "abstract": "The growing popularity of social deduction games has created an increasing\nneed for intelligent frameworks where humans can collaborate with AI agents,\nparticularly in post-pandemic contexts with heightened psychological and social\npressures. Social deduction games like Werewolf, traditionally played through\nverbal communication, present an ideal application for Large Language Models\n(LLMs) given their advanced reasoning and conversational capabilities. Prior\nstudies have shown that LLMs can outperform humans in Werewolf games, but their\nreliance on external modules introduces latency that left their contribution in\nacademic domain only, and omit such game should be user-facing. We propose\n\\textbf{Verbal Werewolf}, a novel LLM-based Werewolf game system that optimizes\ntwo parallel pipelines: gameplay powered by state-of-the-art LLMs and a\nfine-tuned Text-to-Speech (TTS) module that brings text output to life. Our\nsystem operates in near real-time without external decision-making modules,\nleveraging the enhanced reasoning capabilities of modern LLMs like DeepSeek V3\nto create a more engaging and anthropomorphic gaming experience that\nsignificantly improves user engagement compared to existing text-only\nframeworks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00160v2",
    "published": "2025-05-30T18:58:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00159v1",
    "title": "HelioIndex: A Directory of Active Researchers in Solar and Heliospheric Physics",
    "authors": [
      "Peter R. Young"
    ],
    "abstract": "HelioIndex is a directory of authors who are active in solar and heliospheric\nphysics (SHP). It is available at the webpage HelioIndex.org, and it includes\nseveral derived products such as publication lists, country and institute data,\njournal data, and lists of the most cited articles in the field. HelioIndex is\nbuilt from ORCID identifiers and publication data obtained from the\nAstrophysics Data System and ORCID. Selection criteria have been chosen to\napproximately correspond to a researcher having completed a PhD and published\noriginal research in a refereed journal. HelioIndex is intended to be a\ncomprehensive directory of SHP authors that is generated and maintained through\nsoftware procedures, with minimal human intervention. At the time of writing,\n1910 SHP researchers are listed in HelioIndex and they belong to 55 countries.\nThe countries with the largest numbers of researchers are the US, China and the\nUK, with 29%, 15%, and 8% of the total, respectively. HelioIndex authors\naverage 0.69 first author papers per year over their careers, and the median\ncitations for a paper is 15. Based on journal keyword data, it is estimated\nthat 57% and 28% of HelioIndex authors belong to solar physics and heliospheric\nphysics, respectively, with the remainder overlapping both disciplines.",
    "pdf_url": "http://arxiv.org/pdf/2506.00159v1",
    "published": "2025-05-30T18:55:35+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00158v1",
    "title": "Privacy Amplification in Differentially Private Zeroth-Order Optimization with Hidden States",
    "authors": [
      "Eli Chien",
      "Wei-Ning Chen",
      "Pan Li"
    ],
    "abstract": "Zeroth-order optimization has emerged as a promising approach for fine-tuning\nlarge language models on domain-specific data, particularly under differential\nprivacy (DP) and memory constraints. While first-order methods have been\nextensively studied from a privacy perspective, the privacy analysis and\nalgorithmic design for zeroth-order methods remain significantly underexplored.\nA critical open question concerns hidden-state DP analysis: although convergent\nprivacy bounds are known for first-order methods, it has remained unclear\nwhether similar guarantees can be established for zeroth-order methods. In this\nwork, we provide an affirmative answer by proving a convergent DP bound for\nzeroth-order optimization. Our analysis generalizes the celebrated privacy\namplification-by-iteration framework to the setting of smooth loss functions in\nzeroth-order optimization. Furthermore, it induces better DP zeroth-order\nalgorithmic designs that are previously unknown to the literature.",
    "pdf_url": "http://arxiv.org/pdf/2506.00158v1",
    "published": "2025-05-30T18:55:32+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00157v1",
    "title": "Transporting results from a trial to an external target population when trial participation impacts adherence",
    "authors": [
      "Rachael K. Ross",
      "Ivan Diaz",
      "Amy J. Pitts",
      "Elizabeth A. Stuart",
      "Kara E. Rudolph"
    ],
    "abstract": "Randomized clinical trials are considered the gold standard for informing\ntreatment guidelines, but results may not generalize to real-world populations.\nGeneralizability is hindered by distributional differences in baseline\ncovariates and treatment-outcome mediators. Approaches to address differences\nin covariates are well established, but approaches to address differences in\nmediators are more limited. Here we consider the setting where trial activities\nthat differ from usual care settings (e.g., monetary compensation, follow-up\nvisits frequency) affect treatment adherence. When treatment and adherence data\nare unavailable for the real-world target population, we cannot identify the\nmean outcome under a specific treatment assignment (i.e., mean potential\noutcome) in the target. Therefore, we propose a sensitivity analysis in which a\nparameter for the relative difference in adherence to a specific treatment\nbetween the trial and the target, possibly conditional on covariates, must be\nspecified. We discuss options for specification of the sensitivity analysis\nparameter based on external knowledge including setting a range to estimate\nbounds or specifying a probability distribution from which to repeatedly draw\nparameter values (i.e., use Monte Carlo sampling). We introduce two estimators\nfor the mean counterfactual outcome in the target that incorporates this\nsensitivity parameter, a plug-in estimator and a one-step estimator that is\ndouble robust and supports the use of machine learning for estimating nuisance\nmodels. Finally, we apply the proposed approach to the motivating application\nwhere we transport the risk of relapse under two different medications for the\ntreatment of opioid use disorder from a trial to a real-world population.",
    "pdf_url": "http://arxiv.org/pdf/2506.00157v1",
    "published": "2025-05-30T18:55:31+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.00156v1",
    "title": "Effects of higher-order interactions and homophily on information access inequality",
    "authors": [
      "Moritz Laber",
      "Samantha Dies",
      "Joseph Ehlert",
      "Brennan Klein",
      "Tina Eliassi-Rad"
    ],
    "abstract": "The spread of information through socio-technical systems determines which\nindividuals are the first to gain access to opportunities and insights. Yet,\nthe pathways through which information flows can be skewed, leading to\nsystematic differences in access across social groups. These inequalities\nremain poorly characterized in settings involving nonlinear social contagion\nand higher-order interactions that exhibit homophily. We introduce a enerative\nmodel for hypergraphs with hyperedge homophily, a hyperedge size-dependent\nproperty, and tunable degree distribution, called the $\\texttt{H3}$ model,\nalong with a model for nonlinear social contagion that incorporates asymmetric\ntransmission between in-group and out-group nodes. Using stochastic simulations\nof a social contagion process on hypergraphs from the $\\texttt{H3}$ model and\ndiverse empirical datasets, we show that the interaction between social\ncontagion dynamics and hyperedge homophily -- an effect unique to higher-order\nnetworks due to its dependence on hyperedge size -- can critically shape\ngroup-level differences in information access. By emphasizing how hyperedge\nhomophily shapes interaction patterns, our findings underscore the need to\nrethink socio-technical system design through a higher-order perspective and\nsuggest that dynamics-informed, targeted interventions at specific hyperedge\nsizes, embedded in a platform architecture, offer a powerful lever for reducing\ninequality.",
    "pdf_url": "http://arxiv.org/pdf/2506.00156v1",
    "published": "2025-05-30T18:49:02+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00155v3",
    "title": "Expressivity of determinantal ansatzes for neural network wave functions",
    "authors": [
      "Ni Zhan",
      "William A. Wheeler",
      "Gil Goldshlager",
      "Elif Ertekin",
      "Ryan P. Adams",
      "Lucas K. Wagner"
    ],
    "abstract": "Neural network wave functions have shown promise as a way to achieve high\naccuracy on the many-body quantum problem. These wave functions most commonly\nuse a determinant or sum of determinants to antisymmetrize many-body orbitals\nwhich are described by a neural network. In many cases, the wave function is\nprojected onto a fixed-spin state. Such a treatment is allowed for\nspin-independent operators; however, it cannot be applied to spin-dependent\nproblems, such as Hamiltonians containing spin-orbit interactions. We show that\nfor spin-independent Hamiltonians, a strict upper bound property is obeyed\nbetween a traditional Hartree-Fock like determinant, full spinor wave function,\nthe full determinant wave function, and a generalized spinor wave function. The\nrelationship between a spinor wave function and the full determinant arises\nbecause the full determinant wave function is the spinor wave function\nprojected onto a fixed-spin, after which antisymmetry is implicitly restored in\nthe spin-independent case. For spin-dependent Hamiltonians, the full\ndeterminant wave function is not applicable, because it is not antisymmetric.\nNumerical experiments on the H$_3$ molecule and two-dimensional homogeneous\nelectron gas confirm the bounds.",
    "pdf_url": "http://arxiv.org/pdf/2506.00155v3",
    "published": "2025-05-30T18:48:56+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.00154v1",
    "title": "Detection of Endangered Deer Species Using UAV Imagery: A Comparative Study Between Efficient Deep Learning Approaches",
    "authors": [
      "Agustín Roca",
      "Gastón Castro",
      "Gabriel Torre",
      "Leonardo J. Colombo",
      "Ignacio Mas",
      "Javier Pereira",
      "Juan I. Giribet"
    ],
    "abstract": "This study compares the performance of state-of-the-art neural networks\nincluding variants of the YOLOv11 and RT-DETR models for detecting marsh deer\nin UAV imagery, in scenarios where specimens occupy a very small portion of the\nimage and are occluded by vegetation. We extend previous analysis adding\nprecise segmentation masks for our datasets enabling a fine-grained training of\na YOLO model with a segmentation head included. Experimental results show the\neffectiveness of incorporating the segmentation head achieving superior\ndetection performance. This work contributes valuable insights for improving\nUAV-based wildlife monitoring and conservation strategies through scalable and\naccurate AI-driven detection systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00154v1",
    "published": "2025-05-30T18:45:42+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00153v2",
    "title": "How important is the dielectric constant in water modeling? Evaluation of the performance of the TIP4P/$\\varepsilon$ force field and its compatibility with the Joung-Cheatham NaCl model",
    "authors": [
      "Łukasz Baran",
      "Cosmin A. Dicu-Gohoreanu",
      "Luis G. MacDowell"
    ],
    "abstract": "Efficient large-scale computer simulations of aqueous solutions require the\nuse of accurate but simple empirical force fields for water. However, the\ncomplexity of these systems evidences the difficulties in describing solution\nproperties without due account of polarization. Different strategies to remedy\nthis problem are parametrizing water force fields to the dielectric constant or\ncharge scaling of solvated ions. In this work, we compare results from\nTIP4P/$\\varepsilon$ and OPC models, which are parametrized to predict the\ndielectric constant, with results from TIP4P/2005, which is closer in spirit to\nthe charge scaling strategy. The performance of the models is rated according\nto the Vega-Abascal benchmark. Our results show that TIP4P/$\\varepsilon$ and\nTIP4P/2005 perform equally well, with the OPC model lying significantly behind.\nTIP4P/$\\varepsilon$ can predict bulk phase properties (transport properties,\nthermal expansion coefficients, densities) of both liquid water and ice\npolymorphs, but also surface tensions, with an accuracy very similar to\nTIP4P/2005, while performing very well for dielectric constants over a wide\nrange of pressures and temperatures. On the other hand, TIP4P/2005 provides a\nbetter description of phase boundaries, including liquid-vapor and freezing\ntransitions. However, the accurate prediction of dielectric constants allows\nTIP4P/$\\varepsilon$ to describe densities of NaCl solutions for models\nparametrized to their crystal and melt properties only. This is achieved\nwithout the need to rescale charges, modify the Lorentz-Berthelot rule or tune\nthe ion's Lennard-Jones parameters. Our findings hinge on the significance of\ndielectric constants as a target property and show that a robust\nparametrization can be achieved without invoking the concept of charge scaling.",
    "pdf_url": "http://arxiv.org/pdf/2506.00153v2",
    "published": "2025-05-30T18:45:36+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.app-ph",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2506.00152v1",
    "title": "Aligning Language Models with Observational Data: Opportunities and Risks from a Causal Perspective",
    "authors": [
      "Erfan Loghmani"
    ],
    "abstract": "Large language models are being widely used across industries to generate\ncontent that contributes directly to key performance metrics, such as\nconversion rates. Pretrained models, however, often fall short when it comes to\naligning with human preferences or optimizing for business objectives. As a\nresult, fine-tuning with good-quality labeled data is essential to guide models\nto generate content that achieves better results. Controlled experiments, like\nA/B tests, can provide such data, but they are often expensive and come with\nsignificant engineering and logistical challenges. Meanwhile, companies have\naccess to a vast amount of historical (observational) data that remains\nunderutilized. In this work, we study the challenges and opportunities of\nfine-tuning LLMs using observational data. We show that while observational\noutcomes can provide valuable supervision, directly fine-tuning models on such\ndata can lead them to learn spurious correlations. We present empirical\nevidence of this issue using various real-world datasets and propose\nDeconfoundLM, a method that explicitly removes the effect of known confounders\nfrom reward signals. Using simulation experiments, we demonstrate that\nDeconfoundLM improves the recovery of causal relationships and mitigates\nfailure modes found in fine-tuning methods that ignore or naively incorporate\nconfounding variables. Our findings highlight that while observational data\npresents risks, with the right causal corrections, it can be a powerful source\nof signal for LLM alignment. Please refer to the project page for code and\nrelated resources.",
    "pdf_url": "http://arxiv.org/pdf/2506.00152v1",
    "published": "2025-05-30T18:44:09+00:00",
    "categories": [
      "cs.LG",
      "econ.EM",
      "stat.ML",
      "I.2.6; I.2.7; H.4.0; J.4"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00151v1",
    "title": "Spectroscopic Mapping of Callisto with HST/STIS and Implications for its Surface Composition",
    "authors": [
      "M. Ryleigh Davis",
      "Samantha K. Trumbo",
      "Michael E. Brown",
      "Matthew Belyakov"
    ],
    "abstract": "We present global, spatially resolved ultraviolet-visible spectra of Callisto\nobtained with HST/STIS and explore possible compositions of Callisto's surface\nmaterial. We map the strength of a widespread downturn toward the near-UV and\nthe NIR spectral slope from 700 to 1000 nm, which varies from slightly blue\n(reflectance decreasing from 700 to 1000 nm) to red (reflectance increasing)\nacross Callisto's surface. Globally, bright water-ice-rich regions tend to have\nneutral or blue NIR slopes and a shallower near-UV downturn, while darker\nmaterial is associated with red NIR slopes and stronger near-UV absorption.\nBroad absorptions near 820 and 930 nm are spatially correlated with the Asgard\nand Valhalla impact basins and may be associated with iron-bearing silicates.\nAn absorption edge near 275 nm maps primarily to Callisto's trailing\nhemisphere, and a 320 nm absorption most prevalent within and surrounding\nAsgard and Valhalla may be related to organics. We report two new absorption\nfeatures near 230 and 450 nm which might be attributed to irradiated NaCl. We\nfind little evidence for sulfur-bearing species at UV-visible wavelengths and\nsuggest that a 280 nm band seen only in leading/trailing hemisphere ratio\nspectra and previously attributed to SO2 is better explained as a consequence\nof dividing the unrelated 320 nm leading hemisphere band by the trailing\nhemisphere 275 nm absorption edge. Spatial variations in spectral features\nsuggest that Callisto's dark material composition varies regionally, reflecting\na mix of endogenic and exogenic sources and radiolytic alteration.",
    "pdf_url": "http://arxiv.org/pdf/2506.00151v1",
    "published": "2025-05-30T18:42:29+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00150v1",
    "title": "Supporting architecture evaluation for ATAM scenarios with LLMs",
    "authors": [
      "Rafael Capilla",
      "J. Andrés Díaz-Pace",
      "Yamid Ramírez",
      "Jennifer Pérez",
      "Vanessa Rodríguez-Horcajo"
    ],
    "abstract": "Architecture evaluation methods have long been used to evaluate software\ndesigns. Several evaluation methods have been proposed and used to analyze\ntradeoffs between different quality attributes. Having competing qualities\nleads to conflicts for selecting which quality-attribute scenarios are the most\nsuitable ones that an architecture should tackle and for prioritizing the\nscenarios required by the stakeholders. In this context, architecture\nevaluation is carried out manually, often involving long brainstorming sessions\nto decide which are the most adequate quality scenarios. To reduce this effort\nand make the assessment and selection of scenarios more efficient, we suggest\nthe usage of LLMs to partially automate evaluation activities. As a first step\nto validate this hypothesis, this work studies MS Copilot as an LLM tool to\nanalyze quality scenarios suggested by students in a software architecture\ncourse and compares the students' results with the assessment provided by the\nLLM. Our initial study reveals that the LLM produces in most cases better and\nmore accurate results regarding the risks, sensitivity points and tradeoff\nanalysis of the quality scenarios. Overall, the use of generative AI has the\npotential to partially automate and support the architecture evaluation tasks,\nimproving the human decision-making process.",
    "pdf_url": "http://arxiv.org/pdf/2506.00150v1",
    "published": "2025-05-30T18:42:12+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00149v1",
    "title": "Generalizing causal effects with noncompliance: Application to deep canvassing experiments",
    "authors": [
      "Zhongren Chen",
      "Melody Huang"
    ],
    "abstract": "Standard approaches in generalizability often focus on generalizing the\nintent-to-treat (ITT). However, in practice, a more policy-relevant quantity is\nthe generalized impact of an intervention across compliers. While instrumental\nvariable (IV) methods are commonly used to estimate the complier average causal\neffect (CACE) within samples, standard approaches cannot be applied to a target\npopulation with a different distribution from the study sample. This paper\nmakes several key contributions. First, we introduce a new set of identifying\nassumptions in the form of a population-level exclusion restriction that allows\nfor identification of the target complier average causal effect (T-CACE) in\nboth randomized experiments and observational studies. This allows researchers\nto identify the T-CACE without relying on standard principal ignorability\nassumptions. Second, we propose a class of inverse-weighted estimators for the\nT-CACE and derive their asymptotic properties. We provide extensions for\nsettings in which researchers have access to auxiliary compliance information\nacross the target population. Finally, we introduce a sensitivity analysis for\nresearchers to evaluate the robustness of the estimators in the presence of\nunmeasured confounding. We illustrate our proposed method through extensive\nsimulations and a study evaluating the impact of deep canvassing on reducing\nexclusionary attitudes.",
    "pdf_url": "http://arxiv.org/pdf/2506.00149v1",
    "published": "2025-05-30T18:41:22+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.00148v1",
    "title": "Measuring the ferromagnetic resonance cone angle via static dipolar fields using diamond spins",
    "authors": [
      "B. A. McCullian",
      "M. Chilcote",
      "H. Yusuf",
      "E. Johnston-Halperin",
      "G. D. Fuchs"
    ],
    "abstract": "We demonstrate quantitative measurement of the ferromagnetic resonance (FMR)\nprecession cone angle of a micro-scale sample of vanadium tetracyanoethylene\n(V[TCNE]$_{x\\sim 2}$) using diamond spins. V[TCNE]$_{x\\sim 2}$ is a\nlow-damping, low-magnetization ferrimagnet with potential for scalable\nspintronics applications. Our study is motivated by the persistent need for\nquantitative metrology to accurately characterize magnetic dynamics and\nrelaxation. Recently, diamond spins have emerged as sensitive probes of static\nand dynamic magnetic signals. Unlike analog sensors that require additional\ncalibration, diamond spins respond to magnetic fields via a frequency shift\nthat can be compared with frequency standards. We use a spin echo-based\napproach to measure the precession-induced change to the static stray dipolar\nfield of a pair of V[TCNE]$_{x\\sim 2}$ discs under FMR excitation. Using these\nstray dipolar field measurements and micromagnetic simulations, we extract the\nprecession cone angle. Additionally, we quantitatively measure the microwave\nfield amplitude using the same diamond spins, thus forming a quantitative link\nbetween drive and response. We find that our V[TCNE]$_{x\\sim 2}$ sample can be\ndriven to a cone angle of at least 6$^{\\circ}$ with a microwave field amplitude\nof only 0.53 G. This work highlights the power of diamond spins for local,\nquantitative magnetic characterization.",
    "pdf_url": "http://arxiv.org/pdf/2506.00148v1",
    "published": "2025-05-30T18:40:37+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00147v1",
    "title": "State-aware protein-ligand complex prediction using AlphaFold3 with purified sequences",
    "authors": [
      "Enming Xing",
      "Junjie Zhang",
      "Shen Wang",
      "Xiaolin Cheng"
    ],
    "abstract": "Deep learning-based prediction of protein-ligand complexes has advanced\nsignificantly with the development of architectures such as AlphaFold3,\nBoltz-1, Chai-1, Protenix, and NeuralPlexer. Multiple sequence alignment (MSA)\nhas been a key input, providing coevolutionary information critical for\nstructural inference. However, recent benchmarks reveal a major limitation:\nthese models often memorize ligand poses from training data and perform poorly\non novel chemotypes or dynamic binding events involving substantial\nconformational changes in binding pockets. To overcome this, we introduced a\nstate-aware protein-ligand prediction strategy leveraging purified sequence\nsubsets generated by AF-ClaSeq - a method previously developed by our group.\nAF-ClaSeq isolates coevolutionary signals and selects sequences that\npreferentially encode distinct structural states as predicted by AlphaFold2. By\napplying MSA-derived conformational restraints, we observed significant\nimprovements in predicting ligand poses. In cases where AlphaFold3 previously\nfailed-producing incorrect ligand placements and associated protein\nconformations-we were able to correct the predictions by using sequence subsets\ncorresponding to the relevant functional state, such as the inactive form of an\nenzyme bound to a negative allosteric modulator. We believe this approach\nrepresents a powerful and generalizable strategy for improving protein-ligand\ncomplex predictions, with potential applications across a broad range of\nmolecular modeling tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00147v1",
    "published": "2025-05-30T18:39:19+00:00",
    "categories": [
      "q-bio.BM"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00146v1",
    "title": "A DNA Methylation Classification Model Predicts Organ and Disease Site",
    "authors": [
      "Keng-Jung Lee",
      "Dharanya Sampath",
      "Konstantinos Mavrommatis"
    ],
    "abstract": "Cell-free DNA (cfDNA) analysis is a powerful, minimally invasive tool for\nmonitoring disease progression, treatment response, and early detection. A\nmajor challenge, however, is accurately determining the tissue of origin,\nespecially in complex or heterogeneous disease contexts. To address this, we\ndeveloped a machine learning framework that leverages tissue-specific DNA\nmethylation signatures to classify both tissue and disease origin from cfDNA\ndata. Our model integrates methylation datasets across diverse epigenomic\nplatforms, including Whole Genome Bisulfite Sequencing (WGBS), Illumina\nInfinium Bead Arrays, and Enzymatic Methyl-seq (EM-seq). To account for\nplatform variability and data sparsity, we applied imputation strategies and\nharmonized CpG features to enable cross-platform learning. Dimensionality\nreduction revealed clear tissue-specific clustering of methylation profiles. A\nrandom forest classifier trained on these features achieved consistent\nclassification performance (accuracy 0.75-0.8 across test sets and platforms).\nNotably, our model distinguished clinically relevant tissues such as inflamed\nsynovium and peripheral blood mononuclear cells (PBMCs) in arthritis patients\nand deconvoluted synthetic cfDNA mixtures mimicking real-world liquid biopsy\nsamples. The predicted tissue proportions closely matched the true values,\ndemonstrating the model's potential for both classification and quantitative\ninference. These results support the feasibility of using cross-platform\nmethylation data and machine learning for scalable, generalizable cfDNA\ndiagnostics and lay the groundwork for future integration of disease-specific\nepigenetic features to guide clinical decision-making in precision medicine.",
    "pdf_url": "http://arxiv.org/pdf/2506.00146v1",
    "published": "2025-05-30T18:38:26+00:00",
    "categories": [
      "q-bio.GN"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.00145v1",
    "title": "Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry",
    "authors": [
      "Sujeet Kumar",
      "Pretam Ray",
      "Abhinay Beerukuri",
      "Shrey Kamoji",
      "Manoj Balaji Jagadeeshan",
      "Pawan Goyal"
    ],
    "abstract": "Sanskrit, an ancient language with a rich linguistic heritage, presents\nunique challenges for automatic speech recognition (ASR) due to its phonemic\ncomplexity and the phonetic transformations that occur at word junctures,\nsimilar to the connected speech found in natural conversations. Due to these\ncomplexities, there has been limited exploration of ASR in Sanskrit,\nparticularly in the context of its poetic verses, which are characterized by\nintricate prosodic and rhythmic patterns. This gap in research raises the\nquestion: How can we develop an effective ASR system for Sanskrit, particularly\none that captures the nuanced features of its poetic form? In this study, we\nintroduce Vedavani, the first comprehensive ASR study focused on Sanskrit Vedic\npoetry. We present a 54-hour Sanskrit ASR dataset, consisting of 30,779\nlabelled audio samples from the Rig Veda and Atharva Veda. This dataset\ncaptures the precise prosodic and rhythmic features that define the language.\nWe also benchmark the dataset on various state-of-the-art multilingual speech\nmodels.$^{1}$ Experimentation revealed that IndicWhisper performed the best\namong the SOTA models.",
    "pdf_url": "http://arxiv.org/pdf/2506.00145v1",
    "published": "2025-05-30T18:36:54+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00144v1",
    "title": "Three fast-spinning medium-sized Hilda asteroids uncovered by TESS",
    "authors": [
      "Nóra Takács",
      "Csaba Kiss",
      "Róbert Szakáts",
      "Emese Plachy",
      "Csilla E. Kalup",
      "Gyula M. Szabó",
      "László Molnár",
      "Krisztián Sárneczky",
      "Róbert Szabó",
      "Attila Bódi",
      "András Pál"
    ],
    "abstract": "Hilda asteroids, which orbit in a 3:2 resonance with Jupiter, serve as key\nindicators of dynamical processes in the early solar system. Their spin rates,\nan important probe of these mechanisms, can constrain their density and\ncollisional evolution, offering valuable insights into their origin. In this\npaper, we report on the identification of three fast-rotating Hilda asteroids\nwith spin periods in the 3.2--3.7 h range using data from the Transiting\nExoplanet Survey Satellite. These rotation periods are significantly shorter\nthan the previous $\\sim$5.0 h shortest rotation periods obtained from\nground-based observations in the $\\sim$10 km size range, and are comparable\nwith the $\\sim$3.0 h breakup limit of Hildas a few km in size, derived from the\nFOSSIL survey. These fast-rotating asteroids require either considerable\ncohesion (in the order of a few kPa), or densities $\\rho$ $\\gtrsim$1.5\n$gm^{-3}$, in contrast to the typically assumed $\\rho$ $\\lesssim$1 $gm^{-3}$,\nto prevent rotational break-up. C-type asteroids, which are common in the outer\nmain belt, have densities of $\\rho$ $\\approx$1.5 $gm^{-3}$ and are known to\ncomprise a small but notable fraction of Hildas. The observed occurrence rate\nof the $\\leq$4 h rotation periods may be explained by the 10-15% fraction of\nC-type asteroids, likely mixed into these populations from the outer main belt\nduring giant planet dynamical interactions in the early solar system.",
    "pdf_url": "http://arxiv.org/pdf/2506.00144v1",
    "published": "2025-05-30T18:35:20+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00143v1",
    "title": "MRDust: Wireless Implant Data Uplink & Localization via Magnetic Resonance Image Modulation",
    "authors": [
      "Biqi Rebekah Zhao",
      "Alexander Chou",
      "Robert Peltekov",
      "Elad Alon",
      "Chunlei Liu",
      "Rikky Muller",
      "Michael Lustig"
    ],
    "abstract": "Magnetic resonance imaging (MRI) exhibits rich and clinically useful\nendogenous contrast mechanisms, which can differentiate soft tissues and are\nsensitive to flow, diffusion, magnetic susceptibility, blood oxygenation level,\nand more. However, MRI sensitivity is ultimately constrained by Nuclear\nMagnetic Resonance (NMR) physics, and its spatiotemporal resolution is limited\nby SNR and spatial encoding. On the other hand, miniaturized implantable\nsensors offer highly localized physiological information, yet communication and\nlocalization can be challenging when multiple implants are present. This paper\nintroduces the MRDust, an active ``contrast agent\" that integrates active\nsensor implants with MRI, enabling the direct encoding of highly localized\nphysiological data into MR images to augment the anatomical images. MRDust\nemploys a micrometer-scale on-chip coil to actively modulate the local magnetic\nfield, enabling MR signal amplitude and phase modulation for digital data\ntransmission. Since MRI inherently captures the anatomical tissue structure,\nthis method has the potential to enable simultaneous data communication,\nlocalization, and image registration with multiple implants. This paper\npresents the underlying physical principles, design tradeoffs, and design\nmethodology for this approach. To validate the concept, a 900 $\\times$ 990\n$\\mu$m$^2$ chip was designed using TSMC 28 nm technology, with an on-chip coil\nmeasuring 630 $\\mu$m in diameter. The chip was tested with custom hardware in\nan MR750W GE3T MRI scanner. Successful voxel amplitude modulation is\ndemonstrated with Spin-Echo Echo-Planar-Imaging (SE-EPI) sequence, achieving a\ncontrast-to-noise ratio (CNR) of 25.58 with a power consumption of 130 $\\mu$W.",
    "pdf_url": "http://arxiv.org/pdf/2506.00143v1",
    "published": "2025-05-30T18:29:08+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00142v1",
    "title": "Understanding Underrepresented Groups in Open Source Software",
    "authors": [
      "Reydne Santos",
      "Rafa Prado",
      "Ana Paula de Holanda Silva",
      "Kiev Gama",
      "Fernando Castor",
      "Ronnie de Souza Santos"
    ],
    "abstract": "Context: Diversity can impact team communication, productivity, cohesiveness,\nand creativity. Analyzing the existing knowledge about diversity in open source\nsoftware (OSS) projects can provide directions for future research and raise\nawareness about barriers and biases against underrepresented groups in OSS.\nObjective: This study aims to analyze the knowledge about minority groups in\nOSS projects. We investigated which groups were studied in the OSS literature,\nthe study methods used, their implications, and their recommendations to\npromote the inclusion of minority groups in OSS projects. Method: To achieve\nthis goal, we performed a systematic literature review study that analyzed 42\npapers that directly study underrepresented groups in OSS projects. Results:\nMost papers focus on gender (62.3%), while others like age or ethnicity are\nrarely studied. The neurodiversity dimension, have not been studied in the\ncontext of OSS. Our results also reveal that diversity in OSS projects faces\nseveral barriers but brings significant benefits, such as promoting safe and\nwelcoming environments. Conclusion: Most analyzed papers adopt a myopic\nperspective that sees gender as strictly binary. Dimensions of diversity that\naffect how individuals interact and function in an OSS project, such as age,\ntenure, and ethnicity, have received very little attention.",
    "pdf_url": "http://arxiv.org/pdf/2506.00142v1",
    "published": "2025-05-30T18:28:09+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00141v1",
    "title": "Quasilinear Wave \"Reflection\" Due to Proton Heating by an Imbalanced Turbulent Cascade",
    "authors": [
      "Philip A. Isenberg",
      "Bernard J. Vasquez",
      "Benjamin D. G. Chandran",
      "Peera Pongkitiwanichakul"
    ],
    "abstract": "We investigate the quasilinear effects of the resonant wave-particle\ninteraction under conditions of imbalanced turbulent heating in the\ncollisionless coronal hole. We find that velocity-space transport of protons\nfrom the heated part of the distribution leads to strong wave growth in the\nminority (sunward) direction. In the present quasilinear analysis, the\n\"reflected\" waves grow to unphysical levels, indicating the necessity of\nincluding nonlinear processes. This mechanism is likely to be important in\ndevelopment of the fast solar wind, and may explain the puzzling minor ion\nobservations of Landi & Cranmer (2009).",
    "pdf_url": "http://arxiv.org/pdf/2506.00141v1",
    "published": "2025-05-30T18:25:03+00:00",
    "categories": [
      "physics.space-ph"
    ],
    "primary_category": "physics.space-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00140v2",
    "title": "Balancing Profit and Fairness in Risk-Based Pricing Markets",
    "authors": [
      "Jesse Thibodeau",
      "Hadi Nekoei",
      "Afaf Taïk",
      "Janarthanan Rajendran",
      "Golnoosh Farnadi"
    ],
    "abstract": "Dynamic, risk-based pricing can systematically exclude vulnerable consumer\ngroups from essential resources such as health insurance and consumer credit.\nWe show that a regulator can realign private incentives with social objectives\nthrough a learned, interpretable tax schedule. First, we provide a formal\nproposition that bounding each firm's \\emph{local} demographic gap implicitly\nbounds the \\emph{global} opt-out disparity, motivating firm-level penalties.\nBuilding on this insight we introduce \\texttt{MarketSim} -- an open-source,\nscalable simulator of heterogeneous consumers and profit-maximizing firms --\nand train a reinforcement learning (RL) social planner (SP) that selects a\nbracketed fairness-tax while remaining close to a simple linear prior via an\n$\\mathcal{L}_1$ regularizer. The learned policy is thus both transparent and\neasily interpretable. In two empirically calibrated markets, i.e., U.S.\nhealth-insurance and consumer-credit, our planner simultaneously raises\ndemand-fairness by up to $16\\%$ relative to unregulated Free Market while\noutperforming a fixed linear schedule in terms of social welfare without\nexplicit coordination. These results illustrate how AI-assisted regulation can\nconvert a competitive social dilemma into a win-win equilibrium, providing a\nprincipled and practical framework for fairness-aware market oversight.",
    "pdf_url": "http://arxiv.org/pdf/2506.00140v2",
    "published": "2025-05-30T18:24:08+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00139v2",
    "title": "Role of thermal fluctuations in nucleation of three-flavor quark matter",
    "authors": [
      "Mirco Guerrini",
      "Giuseppe Pagliara",
      "Andrea Lavagno",
      "Alessandro Drago"
    ],
    "abstract": "We present a framework that aims to investigate the role of thermal\nfluctuations of the matter composition and color-superconductivity in the\nnucleation of three-flavor deconfined quark matter in the typical conditions of\nhigh-energy astrophysical systems related to compact stars. It is usually\nassumed that the flavor composition is locally fixed during the formation of\nthe first seed of deconfined quark matter since weak interaction acts too\nslowly to re-equilibrate flavors. However, the matter composition fluctuates\naround its average equilibrium values at the typical temperatures of\nhigh-energy astrophysical processes. Here, we extend our previous two-flavor\nnucleation formalism to a three-flavor case. We develop a thermodynamic\nframework incorporating finite-size effects and thermal fluctuations of local\ncomposition to compute the nucleation probability as the product of droplet\nformation and composition fluctuation rates. Moreover, we discuss the role of\ncolor-superconductivity in nucleation, arguing that it can play a role only in\nsystems larger than the typical coherence length of diquark pairs. We found\nthat thermal fluctuations of the matter composition lead to lowering the\npotential barrier between the metastable hadronic phase and the stable quark\nphase. Moreover, the formation of diquark pairs reduces the critical radius and\nthus the potential barrier in the low baryon density and temperature regime.",
    "pdf_url": "http://arxiv.org/pdf/2506.00139v2",
    "published": "2025-05-30T18:23:30+00:00",
    "categories": [
      "nucl-th",
      "astro-ph.HE"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.00138v1",
    "title": "Autonomous Behavior and Whole-Brain Dynamics Emerge in Embodied Zebrafish Agents with Model-based Intrinsic Motivation",
    "authors": [
      "Reece Keller",
      "Alyn Tornell",
      "Felix Pei",
      "Xaq Pitkow",
      "Leo Kozachkov",
      "Aran Nayebi"
    ],
    "abstract": "Autonomy is a hallmark of animal intelligence, enabling adaptive and\nintelligent behavior in complex environments without relying on external reward\nor task structure. Existing reinforcement learning approaches to exploration in\nsparse reward and reward-free environments, including class of methods known as\nintrinsic motivation, exhibit inconsistent exploration patterns and thus fail\nto produce robust autonomous behaviors observed in animals. Moreover, systems\nneuroscience has largely overlooked the neural basis of autonomy, focusing\ninstead on experimental paradigms where animals are motivated by external\nreward rather than engaging in unconstrained, naturalistic and task-independent\nbehavior. To bridge these gaps, we introduce a novel model-based intrinsic\ndrive explicitly designed to capture robust autonomous exploration observed in\nanimals. Our method (3M-Progress) motivates naturalistic behavior by tracking\ndivergence between the agent's current world model and an ethological prior. We\ndemonstrate that artificial embodied agents trained with 3M-Progress capture\nthe explainable variance in behavioral patterns and whole-brain neural-glial\ndynamics recorded from autonomously-behaving larval zebrafish, introducing the\nfirst goal-driven, population-level model of neural-glial computation. Our\nfindings establish a computational framework connecting model-based intrinsic\nmotivation to naturalistic behavior, providing a foundation for building\nartificial agents with animal-like autonomy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00138v1",
    "published": "2025-05-30T18:21:40+00:00",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00137v1",
    "title": "LaMP-QA: A Benchmark for Personalized Long-form Question Answering",
    "authors": [
      "Alireza Salemi",
      "Hamed Zamani"
    ],
    "abstract": "Personalization is essential for question answering systems that are\nuser-centric. Despite its importance, personalization in answer generation has\nbeen relatively underexplored. This is mainly due to lack of resources for\ntraining and evaluating personalized question answering systems. We address\nthis gap by introducing LaMP-QA -- a benchmark designed for evaluating\npersonalized long-form answer generation. The benchmark covers questions from\nthree major categories: (1) Arts & Entertainment, (2) Lifestyle & Personal\nDevelopment, and (3) Society & Culture, encompassing over 45 subcategories in\ntotal. To assess the quality and potential impact of the LaMP-QA benchmark for\npersonalized question answering, we conduct comprehensive human and automatic\nevaluations, to compare multiple evaluation strategies for evaluating generated\npersonalized responses and measure their alignment with human preferences.\nFurthermore, we benchmark a number of non-personalized and personalized\napproaches based on open-source and proprietary large language models (LLMs).\nOur results show that incorporating the personalized context provided leads to\nperformance improvements of up to 39%. The benchmark is publicly released to\nsupport future research in this area.",
    "pdf_url": "http://arxiv.org/pdf/2506.00137v1",
    "published": "2025-05-30T18:16:03+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00136v1",
    "title": "On Designing Diffusion Autoencoders for Efficient Generation and Representation Learning",
    "authors": [
      "Magdalena Proszewska",
      "Nikolay Malkin",
      "N. Siddharth"
    ],
    "abstract": "Diffusion autoencoders (DAs) are variants of diffusion generative models that\nuse an input-dependent latent variable to capture representations alongside the\ndiffusion process. These representations, to varying extents, can be used for\ntasks such as downstream classification, controllable generation, and\ninterpolation. However, the generative performance of DAs relies heavily on how\nwell the latent variables can be modelled and subsequently sampled from. Better\ngenerative modelling is also the primary goal of another class of diffusion\nmodels -- those that learn their forward (noising) process. While effective at\nadjusting the noise process in an input-dependent manner, they must satisfy\nadditional constraints derived from the terminal conditions of the diffusion\nprocess. Here, we draw a connection between these two classes of models and\nshow that certain design decisions (latent variable choice, conditioning\nmethod, etc.) in the DA framework -- leading to a model we term DMZ -- allow us\nto obtain the best of both worlds: effective representations as evaluated on\ndownstream tasks, including domain transfer, as well as more efficient\nmodelling and generation with fewer denoising steps compared to standard DMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00136v1",
    "published": "2025-05-30T18:14:09+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00135v1",
    "title": "Tradeoffs between Mistakes and ERM Oracle Calls in Online and Transductive Online Learning",
    "authors": [
      "Idan Attias",
      "Steve Hanneke",
      "Arvind Ramaswami"
    ],
    "abstract": "We study online and transductive online learning when the learner interacts\nwith the concept class only via Empirical Risk Minimization (ERM) or weak\nconsistency oracles on arbitrary instance subsets. This contrasts with standard\nonline models, where the learner knows the entire class. The ERM oracle returns\na hypothesis minimizing loss on a given subset, while the weak consistency\noracle returns a binary signal indicating whether the subset is realizable by\nsome concept. The learner is evaluated by the number of mistakes and oracle\ncalls. In the standard online setting with ERM access, we prove tight lower\nbounds in both realizable and agnostic cases: $\\Omega(2^{d_{VC}})$ mistakes and\n$\\Omega(\\sqrt{T 2^{d_{LD}}})$ regret, where $T$ is the number of timesteps and\n$d_{LD}$ is the Littlestone dimension. We further show that existing online\nlearning results with ERM access carry over to the weak consistency setting,\nincurring an additional $O(T)$ in oracle calls. We then consider the\ntransductive online model, where the instance sequence is known but labels are\nrevealed sequentially. For general Littlestone classes, we show that optimal\nrealizable and agnostic mistake bounds can be achieved using $O(T^{d_{VC}+1})$\nweak consistency oracle calls. On the negative side, we show that limiting the\nlearner to $\\Omega(T)$ weak consistency queries is necessary for transductive\nonline learnability, and that restricting the learner to $\\Omega(T)$ ERM\nqueries is necessary to avoid exponential dependence on the Littlestone\ndimension. Finally, for certain concept classes, we reduce oracle calls via\nrandomized algorithms while maintaining similar mistake bounds. In particular,\nfor Thresholds on an unknown ordering, $O(\\log T)$ ERM queries suffice; for\n$k$-Intervals, $O(T^3 2^{2k})$ weak consistency queries suffice.",
    "pdf_url": "http://arxiv.org/pdf/2506.00135v1",
    "published": "2025-05-30T18:11:58+00:00",
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00134v1",
    "title": "Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models",
    "authors": [
      "Fardin Ahsan Sakib",
      "Ziwei Zhu",
      "Karen Trister Grace",
      "Meliha Yetisgen",
      "Ozlem Uzuner"
    ],
    "abstract": "Social determinants of health (SDOH) extraction from clinical text is\ncritical for downstream healthcare analytics. Although large language models\n(LLMs) have shown promise, they may rely on superficial cues leading to\nspurious predictions. Using the MIMIC portion of the SHAC (Social History\nAnnotation Corpus) dataset and focusing on drug status extraction as a case\nstudy, we demonstrate that mentions of alcohol or smoking can falsely induce\nmodels to predict current/past drug use where none is present, while also\nuncovering concerning gender disparities in model performance. We further\nevaluate mitigation strategies - such as prompt engineering and\nchain-of-thought reasoning - to reduce these false positives, providing\ninsights into enhancing LLM reliability in health domains.",
    "pdf_url": "http://arxiv.org/pdf/2506.00134v1",
    "published": "2025-05-30T18:11:33+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00133v1",
    "title": "A Reinforcement Learning-Based Telematic Routing Protocol for the Internet of Underwater Things",
    "authors": [
      "Mohammadhossein Homaei",
      "Mehran Tarif",
      "Agustin Di Bartolo",
      "Oscar Mogollon Gutierrez",
      "Mar Avila"
    ],
    "abstract": "The Internet of Underwater Things (IoUT) faces major challenges such as low\nbandwidth, high latency, mobility, and limited energy resources. Traditional\nrouting protocols like RPL, which were designed for land-based networks, do not\nperform well in these underwater conditions. This paper introduces RL-RPL-UA, a\nnew routing protocol that uses reinforcement learning to improve performance in\nunderwater environments. Each node includes a lightweight RL agent that selects\nthe best parent node based on local information such as packet delivery ratio,\nbuffer level, link quality, and remaining energy. RL-RPL-UA keeps full\ncompatibility with standard RPL messages and adds a dynamic objective function\nto support real-time decision-making. Simulations using Aqua-Sim show that\nRL-RPL-UA increases packet delivery by up to 9.2%, reduces energy use per\npacket by 14.8%, and extends network lifetime by 80 seconds compared to\ntraditional methods. These results suggest that RL-RPL-UA is a promising and\nenergy-efficient routing solution for underwater networks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00133v1",
    "published": "2025-05-30T18:11:31+00:00",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00132v1",
    "title": "Productionizing Quantum Mass Production",
    "authors": [
      "William J. Huggins",
      "Tanuj Khattar",
      "Nathan Wiebe"
    ],
    "abstract": "For many practical applications of quantum computing, the most costly steps\ninvolve coherently accessing classical data. We help address this challenge by\napplying mass production techniques, which can reduce the cost of applying an\noperation multiple times in parallel. We combine these techniques with modern\napproaches for classical data loading based on \"quantum read-only memory\"\n(QROM). We find that we can polynomially reduce the total number of gates\nrequired for data loading, but we find no advantage in cost models that only\ncount the number of non-Clifford gates. Furthermore, for realistic cost models\nand problem sizes, we find that it is possible to reduce the cost of parallel\ndata loading by an order of magnitude or more. We present several applications\nof quantum mass production, including a scheme that uses parallel phase\nestimation to asymptotically reduce the gate complexity of state-of-the-art\nalgorithms for estimating eigenvalues of the quantum chemical Hamiltonian,\nincluding both Clifford and non-Clifford gates, from\n$\\widetilde{\\mathcal{O}}\\left(N_{orb}^2\\right)$ to\n$\\widetilde{\\mathcal{O}}\\left(N_{orb}^{\\log_2 3}\\right)$, where $N_{orb}$\ndenotes the number of orbitals. We also show that mass production can be used\nto reduce the cost of serial calls to the same data loading oracle by\nprecomputing several copies of a novel QROM resource state.",
    "pdf_url": "http://arxiv.org/pdf/2506.00132v1",
    "published": "2025-05-30T18:10:50+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00131v1",
    "title": "Adapting Offline Reinforcement Learning with Online Delays",
    "authors": [
      "Simon Sinong Zhan",
      "Qingyuan Wu",
      "Frank Yang",
      "Xiangyu Shi",
      "Chao Huang",
      "Qi Zhu"
    ],
    "abstract": "Offline-to-online deployment of reinforcement-learning (RL) agents must\nbridge two gaps: (1) the sim-to-real gap, where real systems add latency and\nother imperfections not present in simulation, and (2) the interaction gap,\nwhere policies trained purely offline face out-of-distribution states during\nonline execution because gathering new interaction data is costly or risky.\nAgents therefore have to generalize from static, delay-free datasets to\ndynamic, delay-prone environments. Standard offline RL learns from delay-free\nlogs yet must act under delays that break the Markov assumption and hurt\nperformance. We introduce DT-CORL (Delay-Transformer belief policy Constrained\nOffline RL), an offline-RL framework built to cope with delayed dynamics at\ndeployment. DT-CORL (i) produces delay-robust actions with a transformer-based\nbelief predictor even though it never sees delayed observations during\ntraining, and (ii) is markedly more sample-efficient than na\\\"ive\nhistory-augmentation baselines. Experiments on D4RL benchmarks with several\ndelay settings show that DT-CORL consistently outperforms both\nhistory-augmentation and vanilla belief-based methods, narrowing the\nsim-to-real latency gap while preserving data efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2506.00131v1",
    "published": "2025-05-30T18:09:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00130v1",
    "title": "Romanesco codes: Bias-tailored qLDPC codes from fractal codes",
    "authors": [
      "Catherine Leroux",
      "Joseph K. Iverson"
    ],
    "abstract": "We introduce and analyze a family of Clifford-deformed bivariate bicycle\ncodes that are tailored for biased noise. Our qLDPC codes are defined on a\nbipartite hexagonal lattice with limited-range gates and low-weight\nstabilizers. The code is non-CSS, featuring stabilizer generators that are each\nhalf X and half Z. We find small examples with high encoding rate that perform\nwell for a large range of bias. In the limit of large noise bias, the code\nreduces to two independent classical cellular automaton codes, giving a\ndistance scaling better than is possible with 2D topological quantum codes. Our\nconstruction combines two classical cellular automaton codes, LDPC codes that\nwere recently proposed for use with noise-biased cat qubits, related to each\nother by a reflection. Each stabilizer in the quantum code is obtained by\nmultiplying an all-X stabilizer from the first code with an all-Z stabilizer\nfrom the second code, or the other way around. The result is a self-dual\nquantum code with a number of qubits equal to the sum of the input codes and\nstabilizer weight and locality determined by the input codes. Under strong\nnoise bias, the effective distance of the quantum code approaches the distance\nof the input codes. We simulate the logical performance of our qLDPC codes\nunder code-capacity noise and find strong suppression of the logical error\nrate.",
    "pdf_url": "http://arxiv.org/pdf/2506.00130v1",
    "published": "2025-05-30T18:06:24+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00129v1",
    "title": "Geo-Sign: Hyperbolic Contrastive Regularisation for Geometrically Aware Sign Language Translation",
    "authors": [
      "Edward Fish",
      "Richard Bowden"
    ],
    "abstract": "Recent progress in Sign Language Translation (SLT) has focussed primarily on\nimproving the representational capacity of large language models to incorporate\nSign Language features. This work explores an alternative direction: enhancing\nthe geometric properties of skeletal representations themselves. We propose\nGeo-Sign, a method that leverages the properties of hyperbolic geometry to\nmodel the hierarchical structure inherent in sign language kinematics. By\nprojecting skeletal features derived from Spatio-Temporal Graph Convolutional\nNetworks (ST-GCNs) into the Poincar\\'e ball model, we aim to create more\ndiscriminative embeddings, particularly for fine-grained motions like finger\narticulations. We introduce a hyperbolic projection layer, a weighted Fr\\'echet\nmean aggregation scheme, and a geometric contrastive loss operating directly in\nhyperbolic space. These components are integrated into an end-to-end\ntranslation framework as a regularisation function, to enhance the\nrepresentations within the language model. This work demonstrates the potential\nof hyperbolic geometry to improve skeletal representations for Sign Language\nTranslation, improving on SOTA RGB methods while preserving privacy and\nimproving computational efficiency. Code available here:\nhttps://github.com/ed-fish/geo-sign.",
    "pdf_url": "http://arxiv.org/pdf/2506.00129v1",
    "published": "2025-05-30T18:05:33+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00128v1",
    "title": "Applying Large Language Models to Issue Classification: Revisiting with Extended Data and New Models",
    "authors": [
      "Gabriel Aracena",
      "Kyle Luster",
      "Fabio Santos",
      "Igor Steinmacher",
      "Marco A. Gerosa"
    ],
    "abstract": "Effective prioritization of issue reports in software engineering helps to\noptimize resource allocation and information recovery. However, manual issue\nclassification is laborious and lacks scalability. As an alternative, many open\nsource software (OSS) projects employ automated processes for this task, yet\nthis method often relies on large datasets for adequate training.\nTraditionally, machine learning techniques have been used for issue\nclassification. More recently, large language models (LLMs) have emerged as\npowerful tools for addressing a range of software engineering challenges,\nincluding code and test generation, mapping new requirements to legacy software\nendpoints, and conducting code reviews. The following research investigates an\nautomated approach to issue classification based on LLMs. By leveraging the\ncapabilities of such models, we aim to develop a robust system for prioritizing\nissue reports, mitigating the necessity for extensive training data while also\nmaintaining reliability in classification. In our research, we developed an\nLLM-based approach for accurately labeling issues by selecting two of the most\nprominent large language models. We then compared their performance across\nmultiple datasets. Our findings show that GPT-4o achieved the best results in\nclassifying issues from the NLBSE 2024 competition. Moreover, GPT-4o\noutperformed DeepSeek R1, achieving an F1 score 20% higher when both models\nwere trained on the same dataset from the NLBSE 2023 competition, which was ten\ntimes larger than the NLBSE 2024 dataset. The fine-tuned GPT-4o model attained\nan average F1 score of 80.7%, while the fine-tuned DeepSeek R1 model achieved\n59.33%. Increasing the dataset size did not improve the F1 score, reducing the\ndependence on massive datasets for building an efficient solution to issue\nclassification.",
    "pdf_url": "http://arxiv.org/pdf/2506.00128v1",
    "published": "2025-05-30T18:02:55+00:00",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00127v1",
    "title": "Reconfigurable Non-Hermitian Soliton Combs using Dissipative Couplings and Topological Windings",
    "authors": [
      "Seyed Danial Hashemi",
      "Sunil Mittal"
    ],
    "abstract": "The emergence of dissipative Kerr solitons (DKS) in nonlinear resonators has\nrevolutionized the generation of on-chip coherent optical frequency combs. The\nformation of DKS in conventional single resonators hinges on balancing the\nresonator dissipation against the parametric gain and balancing the resonator\ndispersion against the resonance frequency shifts introduced by the Kerr\nnonlinearity. Here, we theoretically introduce a new class of non-Hermitian\nsoliton combs that are enabled by engineering the dissipation and dispersion of\na coupled resonator array with nonreciprocal couplings. We show that these\nnon-Hermitian soliton combs allow unprecedented post-fabrication agile\nreconfigurability of the soliton comb spectrum, where the number of comb lines,\nas well as their frequency spacing, can be drastically tuned by simply tuning\nthe hopping phases between resonators. Such reconfigurable non-Hermitian combs\ngenerated using coupled resonator arrays could enable new functionalities for a\nmultitude of comb applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00127v1",
    "published": "2025-05-30T18:02:03+00:00",
    "categories": [
      "physics.optics",
      "nlin.PS"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.00126v2",
    "title": "Absence of topological order in the $U(1)$ checkerboard toric code",
    "authors": [
      "M. Vieweg",
      "V. Kott",
      "L. Lenke",
      "A. Schellenberger",
      "K. P. Schmidt"
    ],
    "abstract": "We investigate the $U(1)$ checkerboard toric code which corresponds to the\n$U(1)$-symmetry enriched toric code with two distinct star sublattices. One can\ntherefore tune from the limit of isolated stars to the uniform system. The\nuniform system has been conjectured to possess non-Abelian topological order\nbased on quantum Monte Carlo simulations suggesting a non-trivial ground-state\ndegeneracy depending on the compactification of the finite clusters. Here we\nshow that these non-trivial properties can be naturally explained in the\nperturbative limit of isolated stars. Indeed, the compactification dependence\nof the ground-state degeneracy can be traced back to geometric constraints\nstemming from the plaquette operators. Further, the ground-state degeneracy is\nfully lifted in fourth-order degenerate perturbation theory giving rise to a\nnon-topological phase with confined fracton excitations. These fractons are\nconfined for small perturbations so that they cannot exist as single low-energy\nexcitation in the thermodynamic limit but only as topologically trivially\ncomposite particles. However, the confinement scale is shown to be surprisingly\nlarge so that finite-size gaps are extremely small on finite clusters up to the\nuniform limit which is calculated explicitly by high-order series expansions.\nOur findings suggest that these gaps were not distinguished from finite-size\neffects by the recent quantum Monte Carlo simulation in the uniform limit. All\nour results therefore point towards the absence of topological order in the\n$U(1)$ checkerboard toric code along the whole parameter axis.",
    "pdf_url": "http://arxiv.org/pdf/2506.00126v2",
    "published": "2025-05-30T18:02:02+00:00",
    "categories": [
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.00125v1",
    "title": "Galileo Project Observatory Class System Architecture",
    "authors": [
      "Phillip Bridgham",
      "Alex Delacroix",
      "Laura Domine",
      "Andriy Fedorenko",
      "Ezra Kelderman",
      "Sarah Little",
      "Abraham Loeb",
      "Robert Lundstrom",
      "Eric Masson",
      "Andrew Mead",
      "Michael W Prior",
      "Matthew Szenher",
      "Foteini Vervelidou",
      "Wesley Andres Watters"
    ],
    "abstract": "Scientific investigation of Unidentified Anomalous Phenomena (UAP) is limited\nby poor data quality and a lack of transparency. Existing data are often\nfragmented, uncalibrated, and missing critical metadata. To address these\nlimitations, the authors present the Observatory Class Integrated Computing\nPlatform (OCICP), a system designed for the systematic and scientific study of\nUAPs. OCICP employs multiple sensors to collect and analyze data on aerial\nphenomena. The OCICP system consists of two subsystems. The first is the Edge\nComputing Subsystem which is located within the observatory site. This\nsubsystem performs real-time data acquisition, sensor optimization, and data\nprovenance management. The second is the Post-Processing Subsystem which\nresides outside the observatory. This subsystem supports data analysis\nworkflows, including commissioning, census operations, science operations, and\nsystem effectiveness monitoring. This design and implementation paper describes\nthe system lifecycle, associated processes, design, implementation, and\npreliminary results of OCICP, emphasizing the ability of the system to collect\ncomprehensive, calibrated, and scientifically sound data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00125v1",
    "published": "2025-05-30T18:01:54+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00124v1",
    "title": "randextract: a Reference Library to Test and Validate Privacy Amplification Implementations",
    "authors": [
      "Iyán Méndez Veiga",
      "Esther Hänggi"
    ],
    "abstract": "Quantum cryptographic protocols do not rely only on quantum-physical\nresources, they also require reliable classical communication and computation.\nIn particular, the secrecy of any quantum key distribution protocol critically\ndepends on the correct execution of the privacy amplification step. This is a\nclassical post-processing procedure transforming a partially secret bit string,\nknown to be somewhat correlated with an adversary, into a shorter bit string\nthat is close to uniform and independent of the adversary's knowledge. It is\ntypically implemented using randomness extractors. Standardization efforts in\nquantum cryptography have focused on the security of physical devices and\nquantum operations. Future efforts should also consider all algorithms used in\nclassical post-processing, especially in privacy amplification, due to its\ncritical role in ensuring the final security of the key. We present\nrandextract, a reference library to test and validate privacy amplification\nimplementations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00124v1",
    "published": "2025-05-30T18:01:50+00:00",
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00123v1",
    "title": "Visual Embodied Brain: Let Multimodal Large Language Models See, Think, and Control in Spaces",
    "authors": [
      "Gen Luo",
      "Ganlin Yang",
      "Ziyang Gong",
      "Guanzhou Chen",
      "Haonan Duan",
      "Erfei Cui",
      "Ronglei Tong",
      "Zhi Hou",
      "Tianyi Zhang",
      "Zhe Chen",
      "Shenglong Ye",
      "Lewei Lu",
      "Jingbo Wang",
      "Wenhai Wang",
      "Jifeng Dai",
      "Yu Qiao",
      "Rongrong Ji",
      "Xizhou Zhu"
    ],
    "abstract": "The remarkable progress of Multimodal Large Language Models (MLLMs) has\nattracted increasing attention to extend them to physical entities like legged\nrobot. This typically requires MLLMs to not only grasp multimodal understanding\nabilities, but also integrate visual-spatial reasoning and physical interaction\ncapabilities. Nevertheless,existing methods struggle to unify these\ncapabilities due to their fundamental differences.In this paper, we present the\nVisual Embodied Brain (VeBrain), a unified framework for perception, reasoning,\nand control in real world. VeBrain reformulates robotic control into common\ntext-based MLLM tasks in the 2D visual space, thus unifying the objectives and\nmapping spaces of different tasks. Then, a novel robotic adapter is proposed to\nconvert textual control signals from MLLMs to motion policies of real robots.\nFrom the data perspective, we further introduce VeBrain-600k, a high-quality\ninstruction dataset encompassing various capabilities of VeBrain. In\nVeBrain-600k, we take hundreds of hours to collect, curate and annotate the\ndata, and adopt multimodal chain-of-thought(CoT) to mix the different\ncapabilities into a single conversation. Extensive experiments on 13 multimodal\nbenchmarks and 5 spatial intelligence benchmarks demonstrate the superior\nperformance of VeBrain to existing MLLMs like Qwen2.5-VL. When deployed to\nlegged robots and robotic arms, VeBrain shows strong adaptability, flexibility,\nand compositional capabilities compared to existing methods. For example,\ncompared to Qwen2.5-VL, VeBrain not only achieves substantial gains on MMVet by\n+5.6%, but also excels in legged robot tasks with +50% average gains.",
    "pdf_url": "http://arxiv.org/pdf/2506.00123v1",
    "published": "2025-05-30T18:00:34+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00122v2",
    "title": "Some functors preserving exceptionality",
    "authors": [
      "Dajun Liu",
      "Hanpeng Gao",
      "Yu-Zhe Liu"
    ],
    "abstract": "We constructed some tensor functors that send each exceptional sequence in a\nmodule category to another exceptional sequence in another module category by\nusing split extensions and recollements.",
    "pdf_url": "http://arxiv.org/pdf/2506.00122v2",
    "published": "2025-05-30T18:00:32+00:00",
    "categories": [
      "math.RT",
      "math.CT",
      "16E30, 16G10, 16S70"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00121v1",
    "title": "SPLASH: A Rapid Host-Based Supernova Classifier for Wide-Field Time-Domain Surveys",
    "authors": [
      "Adam Boesky",
      "V. Ashley Villar",
      "Alexander Gagliano",
      "Brian Hsu"
    ],
    "abstract": "The upcoming Legacy Survey of Space and Time (LSST) conducted by the Vera C.\nRubin Observatory will detect millions of supernovae (SNe) and generate\nmillions of nightly alerts, far outpacing available spectroscopic resources.\nRapid, scalable photometric classification methods are therefore essential for\nidentifying young SNe for follow-up and enabling large-scale population\nstudies. We present SPLASH, a host-based classification pipeline that infers\nsupernova classes using only host galaxy photometry. SPLASH first associates\nSNe with their hosts (yielding a redshift estimate), then infers host galaxy\nstellar mass and star formation rate using deep learning, and finally\nclassifies SNe using a random forest trained on these inferred properties,\nalong with host-SN angular separation and redshift. SPLASH achieves a binary\n(Type Ia vs. core-collapse) classification accuracy of $76\\%$ and an F1-score\nof $69\\%$, comparable to other state-of-the-art methods. By selecting only the\nmost confident predictions, SPLASH can return highly pure subsets of all major\nSN types, making it well-suited for targeted follow-up. Its efficient design\nallows classification of $\\sim 500$ SNe per second, making it ideal for\nnext-generation surveys. Moreover, its intermediate inference step enables\nselection of transients by host environment, providing a tool not only for\nclassification but also for probing the demographics of stellar death.",
    "pdf_url": "http://arxiv.org/pdf/2506.00121v1",
    "published": "2025-05-30T18:00:18+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00120v2",
    "title": "Type II RR string fields and exotic diffeomorphisms",
    "authors": [
      "Raji Ashenafi Mamade",
      "Barton Zwiebach"
    ],
    "abstract": "We study the theory of massless fields of type II strings arising from the\nstring field theory that uses two string fields, a physical one and an extra\none that allows the writing of an action, but whose degrees of freedom\nultimately decouple. The mechanism allowing the description of the self-dual\nfive-form of type IIB, anticipated by Sen, is used by the SFT to describe all\nRamond-Ramond forms in type IIB and IIA in a manifestly duality-invariant way.\nWe find explicit expressions for the leading terms in the gauge transformation\nof the RR fields and focus on diffeomorphisms, which are exotic for both the\nphysical and the extra fields, perhaps as needed to describe propagating\ndegrees of freedom that do not gravitate. The algebra of diffeomorphisms\nincludes field-dependent structure constants and only closes on-shell, as\npredicted by the type II SFT gauge algebra.",
    "pdf_url": "http://arxiv.org/pdf/2506.00120v2",
    "published": "2025-05-30T18:00:10+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.00119v1",
    "title": "Generator Based Inference (GBI)",
    "authors": [
      "Chi Lung Cheng",
      "Ranit Das",
      "Runze Li",
      "Radha Mastandrea",
      "Vinicius Mikuni",
      "Benjamin Nachman",
      "David Shih",
      "Gup Singh"
    ],
    "abstract": "Statistical inference in physics is often based on samples from a generator\n(sometimes referred to as a ``forward model\") that emulate experimental data\nand depend on parameters of the underlying theory. Modern machine learning has\nsupercharged this workflow to enable high-dimensional and unbinned analyses to\nutilize much more information than ever before. We propose a general framework\nfor describing the integration of machine learning with generators called\nGenerator Based Inference (GBI). A well-studied special case of this setup is\nSimulation Based Inference (SBI) where the generator is a physics-based\nsimulator. In this work, we examine other methods within the GBI toolkit that\nuse data-driven methods to build the generator. In particular, we focus on\nresonant anomaly detection, where the generator describing the background is\nlearned from sidebands. We show how to perform machine learning-based parameter\nestimation in this context with data-derived generators. This transforms the\nstatistical outputs of anomaly detection to be directly interpretable and the\nperformance on the LHCO community benchmark dataset establishes a new\nstate-of-the-art for anomaly detection sensitivity.",
    "pdf_url": "http://arxiv.org/pdf/2506.00119v1",
    "published": "2025-05-30T18:00:08+00:00",
    "categories": [
      "hep-ph",
      "cs.LG",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00118v2",
    "title": "Mid-circuit measurement as an algorithmic primitive",
    "authors": [
      "Antoine Lemelin",
      "Christophe Pere",
      "Olivier Landon-Cardinal",
      "Camille Coti"
    ],
    "abstract": "We explore the usefulness of mid-circuit measurements to enhance quantum\nalgorithmics. Specifically, we assess how quantum phase estimation (QPE) and\nmid-circuit measurements can improve the performance of variational quantum\nalgorithms. Our focus is on the single-qubit version of QPE namely, the\nHadamard test applied to the Quantum Approximate Optimization Algorithm (QAOA)\nansatz. We demonstrate that a mid-circuit measurement acts as a low-energy\nfilter when the desired outcome is obtained. When the other outcome is measured\nwe heuristically rely on the mixer to repopulate the low energy states.\nNumerical simulations show that this method effectively amplifies the ground\nstate. We validate our approach on real quantum hardware namely the IBM Quantum\nsystem one ibm_quebec.",
    "pdf_url": "http://arxiv.org/pdf/2506.00118v2",
    "published": "2025-05-30T18:00:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00117v2",
    "title": "Binarity at LOw Metallicity (BLOeM): Pipeline-Determined Physical Properties of OB Stars",
    "authors": [
      "J. M. Bestenlehner",
      "Paul A. Crowther",
      "V. A. Bronner",
      "S. Simon-Diaz",
      "D. J. Lennon",
      "J. Bodensteiner",
      "N. Langer",
      "P. Marchant",
      "H. Sana",
      "F. R. N. Schneider",
      "T. Shenar"
    ],
    "abstract": "We aim to determine the physical properties of OB stars from the multi-epoch\nVLT/FLAMES BLOeM spectroscopic survey of the Small Magellanic Cloud. We apply a\npipeline designed to analyse large spectroscopic samples of OB stars to the\nco-added, initial 9 epochs of the BLOeM survey, utilising grids of synthetic\nmodel spectra computed with the stellar atmosphere code FASTWIND. 69 OB stars\nare excluded from the analysis owing to disk emission or significant\ncontamination by secondaries in SB2 binaries. We determine physical properties\nof 778 OB stars, including Teff, log g, log L/Lsun and v_e sin i. There appears\nto be a bimodality in v_e sin i of single O stars, while v_e sin i\ndistributions of OB stars are strikingly different for single (median 78 km/s)\nand binary (median 200 km/s) systems. Inferred temperatures are broadly in\nagreement with literature results for stars in common, plus results from a\ngrid-based automization tool for a subset of O and early B stars, although\nuncertainties are larger for surface gravities. Rotational velocities are\nbroadly in line with an independent tool applied to the same subset. We recover\nthe anticipated lower mass cutoff at 8 Msun from the survey design using a\nBayesian inference method coupled with SMC metallicity evolutionary models,\nwith median masses of 12.6 Msun (19.8 Msun) for B-type (O-type) stars.\nSpectroscopic masses exceed evolutionary masses, albeit with large\nuncertainties in surface gravities. We also provide an updated catalogue of O\nstars in the SMC since half of the 159 BLOeM O stars are newly classified as\nO-type stars.",
    "pdf_url": "http://arxiv.org/pdf/2506.00117v2",
    "published": "2025-05-30T18:00:02+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00114v1",
    "title": "Symmetry-deformed toric codes and the quantum dimer model",
    "authors": [
      "Jiaxin Qiao",
      "Yoshito Watanabe",
      "Simon Trebst"
    ],
    "abstract": "Motivated by the recent introduction of a $U(1)$-symmetric toric code model,\nwe investigate symmetry-based deformations of topological order by\nsystematically deconstructing the Gauss-law-enforcing star terms of the toric\ncode (TC) Hamiltonian. This \"term-dropping\" protocol introduces global\nsymmetries that go beyond the alternative framework of \"ungauging\" topological\norder in symmetry-deformed models and gives rise to models such as the $U(1)$TC\nor $XY$TC. These models inherit (emergent) subsystem symmetries (from the\noriginal 1-form symmetry of the TC) that can give rise to (subextensive)\nground-state degeneracies, which can still be organized by the eigenvalues of\nWilson loop operators. However, we demonstrate that these models do not support\ntopological or fracton order (as has been conjectured in the literature) due to\nthe loss of (emergent) gauge symmetry. An extreme deformation of the TC is the\nquantum dimer model (QDM), which we discuss along the family of\nsymmetry-deformed models from the perspective of subsystem symmetries,\nsublattice modulation, and quantum order-by-disorder mechanisms resulting in\nrich phase diagrams. For the QDM, this allows us to identify an emergent SO(2)\nsymmetry for what appears to be a gapless ground state (by numerical standards)\nthat is unstable to the formation of a plaquette valence bond solid upon\nsublattice modulation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00114v1",
    "published": "2025-05-30T18:00:01+00:00",
    "categories": [
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.00115v1",
    "title": "Dark Matter Haloscope with a Disordered Dielectric Absorber",
    "authors": [
      "Stewart Koppell",
      "Otavio D. A. R. Bittencourt",
      "Dip Joti Paul",
      "Junwu Huang",
      "Masha Baryakhtar",
      "Karl K. Berggren"
    ],
    "abstract": "Light dark matter candidates such as axions and dark photons generically\ncouple to electromagnetism, yielding dark-matter-to-photon conversion as a key\nsearch strategy. In addition to resonant conversion in cavities and circuits,\nlight dark matter bosons efficiently convert to photons on material interfaces,\nwith a broadband power proportional to the total area of these interfaces. In\nthis work, we make use of interface conversion to develop a new experimental\ndark matter detector design: the disordered dielectric detector. We show that a\nvolume filled with dielectric powder is an efficient, robust, and broadband\ntarget for axion-to-photon or dark-photon-to-photon conversion. We perform\nsemi-analytical and numerical studies in small-volume 2D and 3D disordered\nsystems to compute the conversion power as a function of dark matter mass. We\nalso discuss the power gathered onto a sensitive photodetector in terms of the\nbulk properties of the disordered material, making it possible to characterize\nthe predicted dark-matter-to-photon conversion rate across a wide range of\nwavelengths. Finally, we propose DPHaSE: the Dielectric Powder Haloscope SNSPD\nExperiment which is composed of a disordered dielectric target, a veto system,\nand a photon collection chamber to maximize the coupling between the powder\ntarget and a low noise superconducting nanowire single photon detector (SNSPD).\nThe projected reach, in the 10 meV-eV mass range, is sensitive to QCD\naxion-photon couplings and exceeds current constraints on dark photon dark\nmatter by up to 5 orders of magnitude.",
    "pdf_url": "http://arxiv.org/pdf/2506.00115v1",
    "published": "2025-05-30T18:00:01+00:00",
    "categories": [
      "hep-ph",
      "cond-mat.mes-hall",
      "hep-ex",
      "physics.ins-det"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00116v1",
    "title": "Fermionic Magic Resources of Quantum Many-Body Systems",
    "authors": [
      "Piotr Sierant",
      "Paolo Stornati",
      "Xhek Turkeshi"
    ],
    "abstract": "Understanding the computational complexity of quantum states is a central\nchallenge in quantum many-body physics. In qubit systems, fermionic Gaussian\nstates can be efficiently simulated on classical computers and hence can be\nemployed as a natural baseline for evaluating quantum complexity. In this work,\nwe develop a framework for quantifying fermionic magic resources, also referred\nto as fermionic non-Gaussianity, which constitutes an essential resource for\nuniversal quantum computation. We leverage the algebraic structure of the\nfermionic commutant to define the fermionic antiflatness (FAF)-an efficiently\ncomputable and experimentally accessible measure of non-Gaussianity, with a\nclear physical interpretation in terms of Majorana fermion correlation\nfunctions. Studying systems in equilibrium, we show that FAF detects phase\ntransitions, reveals universal features of critical points, and uncovers\nspecial solvable points in many-body systems. Extending the analysis to\nout-of-equilibrium settings, we demonstrate that fermionic magic resources\nbecome more abundant in highly excited eigenstates of many-body systems. We\nfurther investigate the growth and saturation of FAF under ergodic many-body\ndynamics, highlighting the roles of conservation laws and locality in\nconstraining the increase of non-Gaussianity during unitary evolution. This\nwork provides a framework for probing quantum many-body complexity from the\nperspective of fermionic Gaussian states and opens up new directions for\ninvestigating fermionic magic resources in many-body systems. Our results\nestablish fermionic non-Gaussianity, alongside entanglement and\nnon-stabilizerness, as a resource relevant not only to foundational studies but\nalso to experimental platforms aiming to achieve quantum advantage.",
    "pdf_url": "http://arxiv.org/pdf/2506.00116v1",
    "published": "2025-05-30T18:00:01+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00108v1",
    "title": "On the analogue of Einstein-Gauss-Bonnet theory in 3+1 dimensions",
    "authors": [
      "Giorgi Tukhashvili"
    ],
    "abstract": "Higher curvature corrections to the Einstein-Hilbert term may play an\nimportant role in probing the strong-field regime of gravity. In this letter,\nwe demonstrate that the local effective action reproducing the trace anomaly\ncan resemble the Einstein-Gauss-Bonnet theory in four dimensions on specific\nbackgrounds. The two key observations support this claim: 1) the covariant\nequation of the trace anomaly coincides with the trace of the metric variation\nin Einstein-Gauss-Bonnet theory, and 2) on the FRW space-time, the\nFriedmann-like equations in both frameworks coincide, with this correspondence\nextending to the quadratic and cubic perturbations. As an intrinsically\nfour-dimensional construct, the trace anomaly effective action emerges as a\npromising framework for exploring higher curvature corrections to Einstein's\nGeneral Relativity in a self-consistent manner.",
    "pdf_url": "http://arxiv.org/pdf/2506.00108v1",
    "published": "2025-05-30T18:00:00+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.00109v1",
    "title": "Radiation-magnetohydrodynamic Simulations of Accretion Flow Formation After a Tidal Disruption Event",
    "authors": [
      "Maria Renee Meza",
      "Xiaoshan Huang",
      "Shane W. Davis",
      "Yan-Fei Jiang"
    ],
    "abstract": "We perform 3D radiation-magnetohydrodynamic simulations of the evolution of\nthe fallback debris after a tidal disruption event. We focus on studying the\neffects of magnetic fields on the formation and early evolution of the\naccretion flow. We find that large magnetic fields can increase the debris\nstream thickness, moderately reducing the efficiency of the radiative\nacceleration of outflows during the first self-intersecting collisions. As gas\naccumulates and the collisions happen instead between the infalling stream and\nthe accretion flow, magnetized and nonmagnetized systems evolve similarly at\nthese early times: radiation-driven outflows dominate early after the initial\nstream-stream collision and a few days later, the accretion rate exceeds the\nmass outflow rate. We find that the MRI does not play a significant role in\nangular momentum transport and dissipation. Nor do we find evidence of a\nmagnetocentrifugal driven outflow. Instead, collisions continue to dissipate\nkinetic energy into radiation that launches outflows and powers TDE\nluminosities reaching $L\\sim4-6\\times10^{44}$ erg s$^{-1}$. Shock-driven\noutflows and inflows redistribute angular momentum throughout the extent\n($\\sim50 r_s$) of the forming eccentric disk. Even in the presence of magnetic\nstresses, the accretion flow remains mostly eccentric with $e\\sim0.2-0.3$ for\n$r\\lesssim8r_s$ and $e\\sim0.4-0.5$ for $10\\lesssim r\\,(r_s)\\lesssim50$. Lastly,\nwe find a polar angle-dependent density structure compatible with the\nviewing-angle effect, along with an additional azimuthal angle dependence\nestablished by the collisions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00109v1",
    "published": "2025-05-30T18:00:00+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00110v1",
    "title": "Holon metal, charge-density-wave and chiral superconductor from doping fractional Chern insulator and SU(3)$_1$ chiral spin liquid",
    "authors": [
      "Ya-Hui Zhang"
    ],
    "abstract": "Recent experiment observed a superconductor proximate to the\n$\\nu_h=-\\frac{2}{3}=-1+\\frac{1}{3}$ fractional quantum anomalous Hall (FQAH)\ninsulator in twisted MoTe$_2$. One critical question is whether the normal\nstate is a Fermi liquid with large Fermi surface, or a strongly correlated\nmetallic state with small carrier density. In this work we develop a theory of\npossible phases from doping the $\\nu=-\\frac{2}{3}$ fractional Chern insulator\n(FCI). We also point out that the problem is dual to doping a SU(3)$_1$ chiral\nspin liquid(CSL) if we assume that the spin gap is finite. For both problems, a\nnatural phase upon doping is a holon metal with three small Fermi pockets. The\npocket is formed by a spinless charge $-e$ holon in the doped CSL case and a\ncharge $-e/3$ fractionalized hole in the doped FCI case. The holon metal is\nlikely unstable to pairing due to gauge field fluctuations, leading to a charge\ndensity wave (CDW) metal, but may be stabilized by magnetic field and shows an\nunusual quantum oscillation period. Two different chiral superconductors are\npossible, emerging from the CDW metal phase or directly from the holon metal.\nWe note that a superconductor directly from anyon gas seems unlikely if the\ncheapest anyon is the elementary one with $e/3$ charge.",
    "pdf_url": "http://arxiv.org/pdf/2506.00110v1",
    "published": "2025-05-30T18:00:00+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.00111v1",
    "title": "Simulating High-Velocity Clouds in the Observational Plane: An Initial Study with the Smith Cloud",
    "authors": [
      "Lori E. Porter",
      "Matthew Abruzzo",
      "Greg L. Bryan",
      "Mary Putman",
      "Yong Zheng",
      "Drummond Fielding"
    ],
    "abstract": "High-velocity clouds (HVCs) may fuel future star formation in the Milky Way,\nbut they must first survive their passage through the hot halo. While recent\nwork has improved our understanding of the survival criterion for cloud-wind\ninteractions, few observational comparisons exist that test this criterion. We\ntherefore present an initial comparison of simulations with the Smith Cloud\n(SC; $d=$ 12.4 kpc, $l, b = 40^{\\circ}, -13^{\\circ}$) as mapped with the\nGALFA-HI survey. We use the Smith Cloud's observed properties to motivate\nsimulations of comparable clouds in wind tunnel simulations with Enzo-E, an MHD\ncode. For both observations and simulations, we generate moment maps,\ncharacterize turbulence through a projected first-order velocity structure\nfunction (VSF), and do the same for HI column density with a normalized\nautocovariance function. We explore how initial cloud conditions (such as\nradius, metallicity, thermal pressure, viewing angle, and distance) affect\nthese statistics, demonstrating that the small-scale VSF is sensitive to cloud\nturbulence while large scales depend on cloud bulk velocity and viewing angle.\nWe find that some simulations reproduce key observational features\n(particularly the correlation between column density and velocity dispersion)\nbut none match all observational probes at the same time (the large scales of\nthe column density autocovariance is particularly challenging). We find that\nthe simulated cloud (cloud C) showing growth via a turbulent radiative mixing\nlayer (TRML) is the best match, implying the importance of TRML-mediated\ncooling for Milky Way HVCs. We conclude by suggesting improvements for\nsimulations to better match observed HVCs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00111v1",
    "published": "2025-05-30T18:00:00+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00112v2",
    "title": "Copenhagenish interpretations of quantum mechanics",
    "authors": [
      "David Schmid",
      "Yìlè Yīng",
      "Matthew Leifer"
    ],
    "abstract": "We define a class of Copenhagenish interpretations encompassing modern\ninterpretations that follow the Copenhagen spirit. These interpretations are\ncharacterized by four postulates: Observers Observe, Universality,\nAnti-$\\psi$-ontology, and Completeness. We explain why such interpretations are\nnot equivalent to the textbook (or orthodox) interpretation, nor to the view\nthat one should shut up and calculate, nor to strict operationalism. We then\ndiscuss what lessons are implied for Copenhagenish interpretations by the\nmeasurement problem, the Wigner's friend thought experiment, and the simple\nvariants of the Wigner's friend thought experiment that we term Wigner's enemy,\nstalkee, and penpal. In particular, we discuss how Copenhagenish\ninterpretations give multiple distinct descriptions of each experiment, where\nthese descriptions are each individually true, yet cannot be combined into any\nsingle description. To make such interpretations consistent, then, one requires\nepistemological constraints forbidding certain perspectives from being\ncombined. We discuss these constraints, their motivations, and some of the\nchallenges they introduce.",
    "pdf_url": "http://arxiv.org/pdf/2506.00112v2",
    "published": "2025-05-30T18:00:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00113v1",
    "title": "Frequentist Uncertainties on Neural Density Ratios with wifi Ensembles",
    "authors": [
      "Sean Benevedes",
      "Jesse Thaler"
    ],
    "abstract": "We introduce wifi ensembles as a novel framework to obtain asymptotic\nfrequentist uncertainties on density ratios, with a particular focus on neural\nratio estimation in the context of high-energy physics. When the density ratio\nof interest is a likelihood ratio conditioned on parameters, wifi ensembles can\nbe used to perform simulation-based inference on those parameters. After\ntraining the basis functions f_i(x), uncertainties on the weights w_i can be\nstraightforwardly propagated to the estimated parameters without requiring\nextraneous bootstraps. To demonstrate this approach, we present an application\nin quantum chromodynamics at the Large Hadron Collider, using wifi ensembles to\nestimate the likelihood ratio between generated quark and gluon jets. We use\nthis learned likelihood ratio to estimate the quark fraction in a synthetic\nmixed quark/gluon sample, showing that the resultant uncertainties empirically\nsatisfy the desired coverage properties.",
    "pdf_url": "http://arxiv.org/pdf/2506.00113v1",
    "published": "2025-05-30T18:00:00+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "physics.data-an"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24878v1",
    "title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents",
    "authors": [
      "Yaxin Luo",
      "Zhaoyi Li",
      "Jiacheng Liu",
      "Jiacheng Cui",
      "Xiaohan Zhao",
      "Zhiqiang Shen"
    ],
    "abstract": "CAPTCHAs have been a critical bottleneck for deploying web agents in\nreal-world applications, often blocking them from completing end-to-end\nautomation tasks. While modern multimodal LLM agents have demonstrated\nimpressive performance in static perception tasks, their ability to handle\ninteractive, multi-step reasoning challenges like CAPTCHAs is largely untested.\nTo address this gap, we introduce Open CaptchaWorld, the first web-based\nbenchmark and platform specifically designed to evaluate the visual reasoning\nand interaction capabilities of MLLM-powered agents through diverse and dynamic\nCAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225\nCAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth,\nwhich quantifies the number of cognitive and motor steps required to solve each\npuzzle. Experimental results show that humans consistently achieve near-perfect\nscores, state-of-the-art MLLM agents struggle significantly, with success rates\nat most 40.0% by Browser-Use Openai-o3, far below human-level performance,\n93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing\nthe limits of current multimodal agents and guiding the development of more\nrobust multimodal reasoning systems. Code and Data are available at this https\nURL.",
    "pdf_url": "http://arxiv.org/pdf/2505.24878v1",
    "published": "2025-05-30T17:59:55+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24877v1",
    "title": "AdaHuman: Animatable Detailed 3D Human Generation with Compositional Multiview Diffusion",
    "authors": [
      "Yangyi Huang",
      "Ye Yuan",
      "Xueting Li",
      "Jan Kautz",
      "Umar Iqbal"
    ],
    "abstract": "Existing methods for image-to-3D avatar generation struggle to produce highly\ndetailed, animation-ready avatars suitable for real-world applications. We\nintroduce AdaHuman, a novel framework that generates high-fidelity animatable\n3D avatars from a single in-the-wild image. AdaHuman incorporates two key\ninnovations: (1) A pose-conditioned 3D joint diffusion model that synthesizes\nconsistent multi-view images in arbitrary poses alongside corresponding 3D\nGaussian Splats (3DGS) reconstruction at each diffusion step; (2) A\ncompositional 3DGS refinement module that enhances the details of local body\nparts through image-to-image refinement and seamlessly integrates them using a\nnovel crop-aware camera ray map, producing a cohesive detailed 3D avatar. These\ncomponents allow AdaHuman to generate highly realistic standardized A-pose\navatars with minimal self-occlusion, enabling rigging and animation with any\ninput motion. Extensive evaluation on public benchmarks and in-the-wild images\ndemonstrates that AdaHuman significantly outperforms state-of-the-art methods\nin both avatar reconstruction and reposing. Code and models will be publicly\navailable for research purposes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24877v1",
    "published": "2025-05-30T17:59:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24876v1",
    "title": "Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks",
    "authors": [
      "Tajamul Ashraf",
      "Amal Saqib",
      "Hanan Ghani",
      "Muhra AlMahri",
      "Yuhao Li",
      "Noor Ahsan",
      "Umair Nawaz",
      "Jean Lahoud",
      "Hisham Cholakkal",
      "Mubarak Shah",
      "Philip Torr",
      "Fahad Shahbaz Khan",
      "Rao Muhammad Anwer",
      "Salman Khan"
    ],
    "abstract": "Deep reasoning is fundamental for solving complex tasks, especially in\nvision-centric scenarios that demand sequential, multimodal understanding.\nHowever, existing benchmarks typically evaluate agents with fully synthetic,\nsingle-turn queries, limited visual modalities, and lack a framework to assess\nreasoning quality over multiple steps as required in real-world settings. To\naddress this, we introduce Agent-X, a large-scale benchmark for evaluating\nvision-centric agents multi-step and deep reasoning capabilities in real-world,\nmultimodal settings. Agent- X features 828 agentic tasks with authentic visual\ncontexts, including images, multi-image comparisons, videos, and instructional\ntext. These tasks span six major agentic environments: general visual\nreasoning, web browsing, security and surveillance, autonomous driving, sports,\nand math reasoning. Our benchmark requires agents to integrate tool use with\nexplicit, stepwise decision-making in these diverse settings. In addition, we\npropose a fine-grained, step-level evaluation framework that assesses the\ncorrectness and logical coherence of each reasoning step and the effectiveness\nof tool usage throughout the task. Our results reveal that even the\nbest-performing models, including GPT, Gemini, and Qwen families, struggle to\nsolve multi-step vision tasks, achieving less than 50% full-chain success.\nThese findings highlight key bottlenecks in current LMM reasoning and tool-use\ncapabilities and identify future research directions in vision-centric agentic\nreasoning models. Our data and code are publicly available at\nhttps://github.com/mbzuai-oryx/Agent-X",
    "pdf_url": "http://arxiv.org/pdf/2505.24876v1",
    "published": "2025-05-30T17:59:53+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24875v2",
    "title": "ReasonGen-R1: CoT for Autoregressive Image generation models through SFT and RL",
    "authors": [
      "Yu Zhang",
      "Yunqi Li",
      "Yifan Yang",
      "Rui Wang",
      "Yuqing Yang",
      "Dai Qi",
      "Jianmin Bao",
      "Dongdong Chen",
      "Chong Luo",
      "Lili Qiu"
    ],
    "abstract": "Although chain-of-thought reasoning and reinforcement learning (RL) have\ndriven breakthroughs in NLP, their integration into generative vision models\nremains underexplored. We introduce ReasonGen-R1, a two-stage framework that\nfirst imbues an autoregressive image generator with explicit text-based\n\"thinking\" skills via supervised fine-tuning on a newly generated reasoning\ndataset of written rationales, and then refines its outputs using Group\nRelative Policy Optimization. To enable the model to reason through text before\ngenerating images, We automatically generate and release a corpus of model\ncrafted rationales paired with visual prompts, enabling controlled planning of\nobject layouts, styles, and scene compositions. Our GRPO algorithm uses reward\nsignals from a pretrained vision language model to assess overall visual\nquality, optimizing the policy in each update. Evaluations on GenEval, DPG, and\nthe T2I benchmark demonstrate that ReasonGen-R1 consistently outperforms strong\nbaselines and prior state-of-the-art models. More: aka.ms/reasongen.",
    "pdf_url": "http://arxiv.org/pdf/2505.24875v2",
    "published": "2025-05-30T17:59:48+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24874v1",
    "title": "The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models",
    "authors": [
      "Adam Stein",
      "Aaditya Naik",
      "Neelay Velingker",
      "Mayur Naik",
      "Eric Wong"
    ],
    "abstract": "Neuro-symbolic learning was proposed to address challenges with training\nneural networks for complex reasoning tasks with the added benefits of\ninterpretability, reliability, and efficiency. Neuro-symbolic learning methods\ntraditionally train neural models in conjunction with symbolic programs, but\nthey face significant challenges that limit them to simplistic problems. On the\nother hand, purely-neural foundation models now reach state-of-the-art\nperformance through prompting rather than training, but they are often\nunreliable and lack interpretability. Supplementing foundation models with\nsymbolic programs, which we call neuro-symbolic prompting, provides a way to\nuse these models for complex reasoning tasks. Doing so raises the question:\nWhat role does specialized model training as part of neuro-symbolic learning\nhave in the age of foundation models? To explore this question, we highlight\nthree pitfalls of traditional neuro-symbolic learning with respect to the\ncompute, data, and programs leading to generalization problems. This position\npaper argues that foundation models enable generalizable neuro-symbolic\nsolutions, offering a path towards achieving the original goals of\nneuro-symbolic learning without the downsides of training from scratch.",
    "pdf_url": "http://arxiv.org/pdf/2505.24874v1",
    "published": "2025-05-30T17:59:46+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24873v1",
    "title": "MiniMax-Remover: Taming Bad Noise Helps Video Object Removal",
    "authors": [
      "Bojia Zi",
      "Weixuan Peng",
      "Xianbiao Qi",
      "Jianan Wang",
      "Shihao Zhao",
      "Rong Xiao",
      "Kam-Fai Wong"
    ],
    "abstract": "Recent advances in video diffusion models have driven rapid progress in video\nediting techniques. However, video object removal, a critical subtask of video\nediting, remains challenging due to issues such as hallucinated objects and\nvisual artifacts. Furthermore, existing methods often rely on computationally\nexpensive sampling procedures and classifier-free guidance (CFG), resulting in\nslow inference. To address these limitations, we propose MiniMax-Remover, a\nnovel two-stage video object removal approach. Motivated by the observation\nthat text condition is not best suited for this task, we simplify the\npretrained video generation model by removing textual input and cross-attention\nlayers, resulting in a more lightweight and efficient model architecture in the\nfirst stage. In the second stage, we distilled our remover on successful videos\nproduced by the stage-1 model and curated by human annotators, using a minimax\noptimization strategy to further improve editing quality and inference speed.\nSpecifically, the inner maximization identifies adversarial input noise (\"bad\nnoise\") that makes failure removals, while the outer minimization step trains\nthe model to generate high-quality removal results even under such challenging\nconditions. As a result, our method achieves a state-of-the-art video object\nremoval results with as few as 6 sampling steps and doesn't rely on CFG,\nsignificantly improving inference efficiency. Extensive experiments demonstrate\nthe effectiveness and superiority of MiniMax-Remover compared to existing\nmethods. Codes and Videos are available at: https://minimax-remover.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2505.24873v1",
    "published": "2025-05-30T17:59:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24872v1",
    "title": "ProxyThinker: Test-Time Guidance through Small Visual Reasoners",
    "authors": [
      "Zilin Xiao",
      "Jaywon Koo",
      "Siru Ouyang",
      "Jefferson Hernandez",
      "Yu Meng",
      "Vicente Ordonez"
    ],
    "abstract": "Recent advancements in reinforcement learning with verifiable rewards have\npushed the boundaries of the visual reasoning capabilities in large\nvision-language models (LVLMs). However, training LVLMs with reinforcement\nfine-tuning (RFT) is computationally expensive, posing a significant challenge\nto scaling model size. In this work, we propose ProxyThinker, an inference-time\ntechnique that enables large models to inherit the visual reasoning\ncapabilities from small, slow-thinking visual reasoners without any training.\nBy subtracting the output distributions of base models from those of RFT\nreasoners, ProxyThinker modifies the decoding dynamics and successfully elicits\nthe slow-thinking reasoning demonstrated by the emerged sophisticated behaviors\nsuch as self-verification and self-correction. ProxyThinker consistently boosts\nperformance on challenging visual benchmarks on spatial, mathematical, and\nmulti-disciplinary reasoning, enabling untuned base models to compete with the\nperformance of their full-scale RFT counterparts. Furthermore, our\nimplementation efficiently coordinates multiple language models with\nparallelism techniques and achieves up to 38 $\\times$ faster inference compared\nto previous decoding-time methods, paving the way for the practical deployment\nof ProxyThinker. Code is available at\nhttps://github.com/MrZilinXiao/ProxyThinker.",
    "pdf_url": "http://arxiv.org/pdf/2505.24872v1",
    "published": "2025-05-30T17:59:43+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24871v2",
    "title": "MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning",
    "authors": [
      "Yiqing Liang",
      "Jielin Qiu",
      "Wenhao Ding",
      "Zuxin Liu",
      "James Tompkin",
      "Mengdi Xu",
      "Mengzhou Xia",
      "Zhengzhong Tu",
      "Laixi Shi",
      "Jiacheng Zhu"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as\na powerful paradigm for post-training large language models (LLMs), achieving\nstate-of-the-art performance on tasks with structured, verifiable answers.\nApplying RLVR to Multimodal LLMs (MLLMs) presents significant opportunities but\nis complicated by the broader, heterogeneous nature of vision-language tasks\nthat demand nuanced visual, logical, and spatial capabilities. As such,\ntraining MLLMs using RLVR on multiple datasets could be beneficial but creates\nchallenges with conflicting objectives from interaction among diverse datasets,\nhighlighting the need for optimal dataset mixture strategies to improve\ngeneralization and reasoning. We introduce a systematic post-training framework\nfor Multimodal LLM RLVR, featuring a rigorous data mixture problem formulation\nand benchmark implementation. Specifically, (1) We developed a multimodal RLVR\nframework for multi-dataset post-training by curating a dataset that contains\ndifferent verifiable vision-language problems and enabling multi-domain online\nRL learning with different verifiable rewards; (2) We proposed a data mixture\nstrategy that learns to predict the RL fine-tuning outcome from the data\nmixture distribution, and consequently optimizes the best mixture.\nComprehensive experiments showcase that multi-domain RLVR training, when\ncombined with mixture prediction strategies, can significantly boost MLLM\ngeneral reasoning capacities. Our best mixture improves the post-trained\nmodel's accuracy on out-of-distribution benchmarks by an average of 5.24%\ncompared to the same model post-trained with uniform data mixture, and by a\ntotal of 20.74% compared to the pre-finetuning baseline.",
    "pdf_url": "http://arxiv.org/pdf/2505.24871v2",
    "published": "2025-05-30T17:59:38+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24870v2",
    "title": "GenSpace: Benchmarking Spatially-Aware Image Generation",
    "authors": [
      "Zehan Wang",
      "Jiayang Xu",
      "Ziang Zhang",
      "Tianyu Pang",
      "Chao Du",
      "Hengshuang Zhao",
      "Zhou Zhao"
    ],
    "abstract": "Humans can intuitively compose and arrange scenes in the 3D space for\nphotography. However, can advanced AI image generators plan scenes with similar\n3D spatial awareness when creating images from text or image prompts? We\npresent GenSpace, a novel benchmark and evaluation pipeline to comprehensively\nassess the spatial awareness of current image generation models. Furthermore,\nstandard evaluations using general Vision-Language Models (VLMs) frequently\nfail to capture the detailed spatial errors. To handle this challenge, we\npropose a specialized evaluation pipeline and metric, which reconstructs 3D\nscene geometry using multiple visual foundation models and provides a more\naccurate and human-aligned metric of spatial faithfulness. Our findings show\nthat while AI models create visually appealing images and can follow general\ninstructions, they struggle with specific 3D details like object placement,\nrelationships, and measurements. We summarize three core limitations in the\nspatial perception of current state-of-the-art image generation models: 1)\nObject Perspective Understanding, 2) Egocentric-Allocentric Transformation and\n3) Metric Measurement Adherence, highlighting possible directions for improving\nspatial intelligence in image generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24870v2",
    "published": "2025-05-30T17:59:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24869v1",
    "title": "SiLVR: A Simple Language-based Video Reasoning Framework",
    "authors": [
      "Ce Zhang",
      "Yan-Bo Lin",
      "Ziyang Wang",
      "Mohit Bansal",
      "Gedas Bertasius"
    ],
    "abstract": "Recent advances in test-time optimization have led to remarkable reasoning\ncapabilities in Large Language Models (LLMs), enabling them to solve highly\ncomplex problems in math and coding. However, the reasoning capabilities of\nmultimodal LLMs (MLLMs) still significantly lag, especially for complex\nvideo-language tasks. To address this issue, we present SiLVR, a Simple\nLanguage-based Video Reasoning framework that decomposes complex video\nunderstanding into two stages. In the first stage, SiLVR transforms raw video\ninto language-based representations using multisensory inputs, such as short\nclip captions and audio/speech subtitles. In the second stage, language\ndescriptions are fed into a powerful reasoning LLM to solve complex\nvideo-language understanding tasks. To handle long-context multisensory inputs,\nwe use an adaptive token reduction scheme, which dynamically determines the\ntemporal granularity with which to sample the tokens. Our simple, modular, and\ntraining-free video reasoning framework achieves the best-reported results on\nVideo-MME (long), Video-MMMU (comprehension), Video-MMLU, CGBench, and EgoLife.\nFurthermore, our empirical study focused on video reasoning capabilities shows\nthat, despite not being explicitly trained on video, strong reasoning LLMs can\neffectively aggregate multisensory input information from video, speech, and\naudio for complex temporal, causal, long-context, and knowledge acquisition\nreasoning tasks in video. Code is available at https://github.com/CeeZh/SILVR.",
    "pdf_url": "http://arxiv.org/pdf/2505.24869v1",
    "published": "2025-05-30T17:59:19+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24868v1",
    "title": "Consistent line clustering using geometric hypergraphs",
    "authors": [
      "Kalle Alaluusua",
      "Konstantin Avrachenkov",
      "B. R. Vinay Kumar",
      "Lasse Leskelä"
    ],
    "abstract": "Traditional data analysis often represents data as a weighted graph with\npairwise similarities, but many problems do not naturally fit this framework.\nIn line clustering, points in a Euclidean space must be grouped so that each\ncluster is well approximated by a line segment. Since any two points define a\nline, pairwise similarities fail to capture the structure of the problem,\nnecessitating the use of higher-order interactions modeled by geometric\nhypergraphs. We encode geometry into a 3-uniform hypergraph by treating sets of\nthree points as hyperedges whenever they are approximately collinear. The\nresulting hypergraph contains information about the underlying line segments,\nwhich can then be extracted using community recovery algorithms. In contrast to\nclassical hypergraph block models, latent geometric constraints in this\nconstruction introduce significant dependencies between hyperedges, which\nrestricts the applicability of many standard theoretical tools. We aim to\ndetermine the fundamental limits of line clustering and evaluate\nhypergraph-based line clustering methods. To this end, we derive\ninformation-theoretic thresholds for exact and almost exact recovery for data\ngenerated from intersecting lines on a plane with additive Gaussian noise. We\ndevelop a polynomial-time spectral algorithm and show that it succeeds under\nnoise conditions that match the information-theoretic bounds up to a\npolylogarithmic factor.",
    "pdf_url": "http://arxiv.org/pdf/2505.24868v1",
    "published": "2025-05-30T17:59:17+00:00",
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH",
      "62H30, 62R10, 62C20, 05C65, 05C80, 62H12, 94A15, 90B15"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.24867v1",
    "title": "Time Blindness: Why Video-Language Models Can't See What Humans Can?",
    "authors": [
      "Ujjwal Upadhyay",
      "Mukul Ranjan",
      "Zhiqiang Shen",
      "Mohamed Elhoseiny"
    ],
    "abstract": "Recent advances in vision-language models (VLMs) have made impressive strides\nin understanding spatio-temporal relationships in videos. However, when spatial\ninformation is obscured, these models struggle to capture purely temporal\npatterns. We introduce $\\textbf{SpookyBench}$, a benchmark where information is\nencoded solely in temporal sequences of noise-like frames, mirroring natural\nphenomena from biological signaling to covert communication. Interestingly,\nwhile humans can recognize shapes, text, and patterns in these sequences with\nover 98% accuracy, state-of-the-art VLMs achieve 0% accuracy. This performance\ngap highlights a critical limitation: an over-reliance on frame-level spatial\nfeatures and an inability to extract meaning from temporal cues. Furthermore,\nwhen trained in data sets with low spatial signal-to-noise ratios (SNR),\ntemporal understanding of models degrades more rapidly than human perception,\nespecially in tasks requiring fine-grained temporal reasoning. Overcoming this\nlimitation will require novel architectures or training paradigms that decouple\nspatial dependencies from temporal processing. Our systematic analysis shows\nthat this issue persists across model scales and architectures. We release\nSpookyBench to catalyze research in temporal pattern recognition and bridge the\ngap between human and machine video understanding. Dataset and code has been\nmade available on our project website: https://timeblindness.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.24867v1",
    "published": "2025-05-30T17:59:12+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24866v1",
    "title": "TalkingHeadBench: A Multi-Modal Benchmark & Analysis of Talking-Head DeepFake Detection",
    "authors": [
      "Xinqi Xiong",
      "Prakrut Patel",
      "Qingyuan Fan",
      "Amisha Wadhwa",
      "Sarathy Selvam",
      "Xiao Guo",
      "Luchao Qi",
      "Xiaoming Liu",
      "Roni Sengupta"
    ],
    "abstract": "The rapid advancement of talking-head deepfake generation fueled by advanced\ngenerative models has elevated the realism of synthetic videos to a level that\nposes substantial risks in domains such as media, politics, and finance.\nHowever, current benchmarks for deepfake talking-head detection fail to reflect\nthis progress, relying on outdated generators and offering limited insight into\nmodel robustness and generalization. We introduce TalkingHeadBench, a\ncomprehensive multi-model multi-generator benchmark and curated dataset\ndesigned to evaluate the performance of state-of-the-art detectors on the most\nadvanced generators. Our dataset includes deepfakes synthesized by leading\nacademic and commercial models and features carefully constructed protocols to\nassess generalization under distribution shifts in identity and generator\ncharacteristics. We benchmark a diverse set of existing detection methods,\nincluding CNNs, vision transformers, and temporal models, and analyze their\nrobustness and generalization capabilities. In addition, we provide error\nanalysis using Grad-CAM visualizations to expose common failure modes and\ndetector biases. TalkingHeadBench is hosted on\nhttps://huggingface.co/datasets/luchaoqi/TalkingHeadBench with open access to\nall data splits and protocols. Our benchmark aims to accelerate research\ntowards more robust and generalizable detection models in the face of rapidly\nevolving generative techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.24866v1",
    "published": "2025-05-30T17:59:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24865v1",
    "title": "Quantum Acoustics with Tunable Nonlinearity in the Superstrong Coupling Regime",
    "authors": [
      "Marco Scigliuzzo",
      "Léo Peyruchat",
      "Riccardo Maria Marabini",
      "Carla Becker",
      "Vincent Jouanny",
      "Per Delsing",
      "Pasquale Scarlino"
    ],
    "abstract": "Precise control of mechanical modes in the quantum regime is a key resource\nfor quantum technologies, offering promising pathways for quantum sensing with\nmacroscopic systems and scalable architectures for quantum simulation. In this\nwork, we realise a multimode mechanical cavity coupled to a superconducting\nKerr resonator, which induces nonlinearity in the mechanical modes. The Kerr\nmode is realised by a flux-tunable SQUID array resonator, while the mechanical\nmodes are implemented by a surface acoustic wave (SAW) cavity. Both mechanical\nand electromagnetic modes are individually addressable via dedicated\nmeasurement lines, enabling full spectroscopic characterisation. We introduce a\nstraightforward protocol to measure the SQUID array resonator's participation\nratio in the hybrid acoustic modes, quantifying the degree of hybridisation.\nThe participation ratio reveals that our device operates at the onset of the\nmultimode coupling regime, where multiple acoustic modes simultaneously\ninteract with the nonlinear superconducting element. Furthermore, this platform\nallows controllable Kerr-type nonlinearities in multiple acoustic modes, with\nthe participation ratio serving as the key parameter determining both the\ndissipation rates and nonlinear strengths of these hybridised modes. Close to\nthe resonant regime, we measure a cross-Kerr interaction between seven pairs of\nmechanical modes, which is controllable via the SQUID array resonator detuning.\nThese results establish a platform for engineering nonlinear multimode\nmechanical interactions, offering potential for future integration with\nsuperconducting qubits and implementation of multiple mechanical qubits.",
    "pdf_url": "http://arxiv.org/pdf/2505.24865v1",
    "published": "2025-05-30T17:59:03+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24864v1",
    "title": "ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models",
    "authors": [
      "Mingjie Liu",
      "Shizhe Diao",
      "Ximing Lu",
      "Jian Hu",
      "Xin Dong",
      "Yejin Choi",
      "Jan Kautz",
      "Yi Dong"
    ],
    "abstract": "Recent advances in reasoning-centric language models have highlighted\nreinforcement learning (RL) as a promising method for aligning models with\nverifiable rewards. However, it remains contentious whether RL truly expands a\nmodel's reasoning capabilities or merely amplifies high-reward outputs already\nlatent in the base model's distribution, and whether continually scaling up RL\ncompute reliably leads to improved reasoning performance. In this work, we\nchallenge prevailing assumptions by demonstrating that prolonged RL (ProRL)\ntraining can uncover novel reasoning strategies that are inaccessible to base\nmodels, even under extensive sampling. We introduce ProRL, a novel training\nmethodology that incorporates KL divergence control, reference policy\nresetting, and a diverse suite of tasks. Our empirical analysis reveals that\nRL-trained models consistently outperform base models across a wide range of\npass@k evaluations, including scenarios where base models fail entirely\nregardless of the number of attempts. We further show that reasoning boundary\nimprovements correlates strongly with task competence of base model and\ntraining duration, suggesting that RL can explore and populate new regions of\nsolution space over time. These findings offer new insights into the conditions\nunder which RL meaningfully expands reasoning boundaries in language models and\nestablish a foundation for future work on long-horizon RL for reasoning. We\nrelease model weights to support further research:\nhttps://huggingface.co/nvidia/Nemotron-Research-Reasoning-Qwen-1.5B",
    "pdf_url": "http://arxiv.org/pdf/2505.24864v1",
    "published": "2025-05-30T17:59:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.15711v1",
    "title": "Shadow defense against gradient inversion attack in federated learning",
    "authors": [
      "Le Jiang",
      "Liyan Ma",
      "Guang Yang"
    ],
    "abstract": "Federated learning (FL) has emerged as a transformative framework for\nprivacy-preserving distributed training, allowing clients to collaboratively\ntrain a global model without sharing their local data. This is especially\ncrucial in sensitive fields like healthcare, where protecting patient data is\nparamount. However, privacy leakage remains a critical challenge, as the\ncommunication of model updates can be exploited by potential adversaries.\nGradient inversion attacks (GIAs), for instance, allow adversaries to\napproximate the gradients used for training and reconstruct training images,\nthus stealing patient privacy. Existing defense mechanisms obscure gradients,\nyet lack a nuanced understanding of which gradients or types of image\ninformation are most vulnerable to such attacks. These indiscriminate\ncalibrated perturbations result in either excessive privacy protection\ndegrading model accuracy, or insufficient one failing to safeguard sensitive\ninformation. Therefore, we introduce a framework that addresses these\nchallenges by leveraging a shadow model with interpretability for identifying\nsensitive areas. This enables a more targeted and sample-specific noise\ninjection. Specially, our defensive strategy achieves discrepancies of 3.73 in\nPSNR and 0.2 in SSIM compared to the circumstance without defense on the\nChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover,\nit minimizes adverse effects on model performance, with less than 1\\% F1\nreduction compared to SOTA methods. Our extensive experiments, conducted across\ndiverse types of medical images, validate the generalization of the proposed\nframework. The stable defense improvements for FedAvg are consistently over\n1.5\\% times in LPIPS and SSIM. It also offers a universal defense against\nvarious GIA types, especially for these sensitive areas in images.",
    "pdf_url": "http://arxiv.org/pdf/2506.15711v1",
    "published": "2025-05-30T17:58:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24863v1",
    "title": "AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time",
    "authors": [
      "Junyu Zhang",
      "Runpei Dong",
      "Han Wang",
      "Xuying Ning",
      "Haoran Geng",
      "Peihao Li",
      "Xialin He",
      "Yutong Bai",
      "Jitendra Malik",
      "Saurabh Gupta",
      "Huan Zhang"
    ],
    "abstract": "This paper presents AlphaOne ($\\alpha$1), a universal framework for\nmodulating reasoning progress in large reasoning models (LRMs) at test time.\n$\\alpha$1 first introduces $\\alpha$ moment, which represents the scaled\nthinking phase with a universal parameter $\\alpha$. Within this scaled\npre-$\\alpha$ moment phase, it dynamically schedules slow thinking transitions\nby modeling the insertion of reasoning transition tokens as a Bernoulli\nstochastic process. After the $\\alpha$ moment, $\\alpha$1 deterministically\nterminates slow thinking with the end-of-thinking token, thereby fostering fast\nreasoning and efficient answer generation. This approach unifies and\ngeneralizes existing monotonic scaling methods by enabling flexible and dense\nslow-to-fast reasoning modulation. Extensive empirical studies on various\nchallenging benchmarks across mathematical, coding, and scientific domains\ndemonstrate $\\alpha$1's superior reasoning capability and efficiency. Project\npage: https://alphaone-project.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.24863v1",
    "published": "2025-05-30T17:58:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24862v3",
    "title": "ViStoryBench: Comprehensive Benchmark Suite for Story Visualization",
    "authors": [
      "Cailin Zhuang",
      "Ailin Huang",
      "Wei Cheng",
      "Jingwei Wu",
      "Yaoqi Hu",
      "Jiaqi Liao",
      "Hongyuan Wang",
      "Xinyao Liao",
      "Weiwei Cai",
      "Hengyuan Xu",
      "Xuanyang Zhang",
      "Xianfang Zeng",
      "Zhewei Huang",
      "Gang Yu",
      "Chi Zhang"
    ],
    "abstract": "Story visualization aims to generate coherent image sequences that faithfully\ndepict a narrative and align with character references. Despite progress in\ngenerative models, existing benchmarks are narrow in scope, often limited to\nshort prompts, no character reference, or single-image cases, and fall short of\nreal-world storytelling complexity. This hinders a nuanced understanding of\nmodel capabilities and limitations. We present ViStoryBench, a comprehensive\nbenchmark designed to evaluate story visualization models across diverse\nnarrative structures, visual styles, and character settings. The benchmark\nfeatures richly annotated multi-shot scripts derived from curated stories\nspanning literature, film, and folklore. Large language models assist in story\nsummarization and script generation, with all outputs verified by humans to\nensure coherence and fidelity. Character references are carefully curated to\nmaintain intra-story consistency across varying artistic styles. To enable\nthorough evaluation, ViStoryBench introduces a set of automated metrics that\nassess character consistency, style similarity, prompt adherence, aesthetic\nquality, and generation artifacts such as copy-paste behavior. These metrics\nare validated through human studies, and used to benchmark a broad range of\nopen-source and commercial models. ViStoryBench offers a high-fidelity,\nmulti-dimensional evaluation suite that facilitates systematic analysis and\nfosters future progress in visual storytelling.",
    "pdf_url": "http://arxiv.org/pdf/2505.24862v3",
    "published": "2025-05-30T17:58:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24861v2",
    "title": "A localized consensus-based sampling algorithm",
    "authors": [
      "Arne Bouillon",
      "Alexander Bodard",
      "Panagiotis Patrinos",
      "Dirk Nuyens",
      "Giovanni Samaey"
    ],
    "abstract": "We develop a novel interacting-particle method for sampling from non-Gaussian\ndistributions. As a first step, we propose a new way to derive the\nconsensus-based sampling (CBS) algorithm, starting from ensemble-preconditioned\nLangevin diffusions. We approximate the target potential by its Moreau\nenvelope, such that the gradient in the Langevin equation can be replaced by a\nproximal operator. We then approximate the proximal operator by a weighted\nmean, and finally assume that the initial and target distributions are\nGaussian, resulting in the CBS dynamics. If we keep only those approximations\nthat can be justified in the non-Gaussian setting, the result is a new\ninteracting-particle method for sampling, which we call localized\nconsensus-based sampling. We prove that our algorithm is affine-invariant and\nexact for Gaussian distributions in the mean-field setting. Numerical tests\nillustrate that localized CBS compares favorably to alternative methods in\nterms of affine-invariance and performance on non-Gaussian distributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24861v2",
    "published": "2025-05-30T17:58:20+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.OC",
      "62F15 (Primary) 65C05, 65C35, 82C31 (Secondary)"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24860v1",
    "title": "PB&J: Peanut Butter and Joints for Damped Articulation",
    "authors": [
      "Avery S. Williamson",
      "Michael J. Bennington",
      "Ravesh Sukhnandan",
      "Mrinali Nakhre",
      "Yuemin Mao",
      "Victoria A. Webster-Wood"
    ],
    "abstract": "Many bioinspired robots mimic the rigid articulated joint structure of the\nhuman hand for grasping tasks, but experience high-frequency mechanical\nperturbations that can destabilize the system and negatively affect precision\nwithout a high-frequency controller. Despite having bandwidth-limited\ncontrollers that experience time delays between sensing and actuation,\nbiological systems can respond successfully to and mitigate these\nhigh-frequency perturbations. Human joints include damping and stiffness that\nmany rigid articulated bioinspired hand robots lack. To enable researchers to\nexplore the effects of joint viscoelasticity in joint control, we developed a\nhuman-hand-inspired grasping robot with viscoelastic structures that utilizes\naccessible and bioderived materials to reduce the economic and environmental\nimpact of prototyping novel robotic systems. We demonstrate that an elastic\nelement at the finger joints is necessary to achieve concurrent flexion, which\nenables secure grasping of spherical objects. To significantly damp the\nmanufactured finger joints, we modeled, manufactured, and characterized rotary\ndampers using peanut butter as an organic analog joint working fluid. Finally,\nwe demonstrated that a real-time position-based controller could be used to\nsuccessfully catch a lightweight falling ball. We developed this open-source,\nlow-cost grasping platform that abstracts the morphological and mechanical\nproperties of the human hand to enable researchers to explore questions about\nbiomechanics in roboto that would otherwise be difficult to test in simulation\nor modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.24860v1",
    "published": "2025-05-30T17:57:21+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24859v2",
    "title": "Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization",
    "authors": [
      "Joschka Braun",
      "Carsten Eickhoff",
      "Seyed Ali Bahrainian"
    ],
    "abstract": "Steering vectors are a lightweight method for controlling text properties by\nadding a learned bias to language model activations at inference time. So far,\nsteering vectors have predominantly been evaluated in multiple-choice settings,\nwhile their effectiveness in free-form generation tasks remains understudied.\nMoving \"Beyond Multiple Choice,\" we thoroughly evaluate the effectiveness of\nsteering vectors in adaptively controlling topical focus, sentiment, toxicity,\nand readability in abstractive summaries of the NEWTS dataset. We find that\nsteering effectively controls the targeted summary properties, but high\nsteering strengths consistently degrade both intrinsic and extrinsic text\nquality. Compared to steering, prompting offers weaker control, while\npreserving text quality. Combining steering and prompting yields the strongest\ncontrol over text properties and offers the most favorable efficacy-quality\ntrade-off at moderate steering strengths. Our results underscore the practical\ntrade-off between control strength and text quality preservation when applying\nsteering vectors to free-form generation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24859v2",
    "published": "2025-05-30T17:57:15+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.15710v1",
    "title": "RAST: Reasoning Activation in LLMs via Small-model Transfer",
    "authors": [
      "Siru Ouyang",
      "Xinyu Zhu",
      "Zilin Xiao",
      "Minhao Jiang",
      "Yu Meng",
      "Jiawei Han"
    ],
    "abstract": "Reinforcement learning (RL) has become a powerful approach for improving the\nreasoning capabilities of large language models (LLMs), as evidenced by recent\nsuccesses such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale\nremains intimidatingly resource-intensive, requiring multiple model copies and\nextensive GPU workloads. On the other hand, while being powerful, recent\nstudies suggest that RL does not fundamentally endow models with new knowledge;\nrather, it primarily reshapes the model's output distribution to activate\nreasoning capabilities latent in the base model. Building on this insight, we\nhypothesize that the changes in output probabilities induced by RL are largely\nmodel-size invariant, opening the door to a more efficient paradigm: training a\nsmall model with RL and transferring its induced probability shifts to larger\nbase models. To verify our hypothesis, we conduct a token-level analysis of\ndecoding trajectories and find high alignment in RL-induced output\ndistributions across model scales, validating our hypothesis. Motivated by\nthis, we propose RAST, a simple yet effective method that transfers reasoning\nbehaviors by injecting RL-induced probability adjustments from a small\nRL-trained model into larger models. Experiments across multiple mathematical\nreasoning benchmarks show that RAST substantially and consistently enhances the\nreasoning capabilities of base models while requiring significantly lower GPU\nmemory than direct RL training, sometimes even yielding better performance than\nthe RL-trained counterparts. Our findings offer new insights into the nature of\nRL-driven reasoning and practical strategies for scaling its benefits without\nincurring its full computational cost. The project page of RAST is available at\nhttps://ozyyshr.github.io/RAST/.",
    "pdf_url": "http://arxiv.org/pdf/2506.15710v1",
    "published": "2025-05-30T17:57:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24858v1",
    "title": "MetaFaith: Faithful Natural Language Uncertainty Expression in LLMs",
    "authors": [
      "Gabrielle Kaili-May Liu",
      "Gal Yona",
      "Avi Caciularu",
      "Idan Szpektor",
      "Tim G. J. Rudner",
      "Arman Cohan"
    ],
    "abstract": "A critical component in the trustworthiness of LLMs is reliable uncertainty\ncommunication, yet LLMs often use assertive language when conveying false\nclaims, leading to over-reliance and eroded trust. We present the first\nsystematic study of $\\textit{faithful confidence calibration}$ of LLMs,\nbenchmarking models' ability to use linguistic expressions of uncertainty that\n$\\textit{faithfully reflect}$ their intrinsic uncertainty, across a\ncomprehensive array of models, datasets, and prompting strategies. Our results\ndemonstrate that LLMs largely fail at this task, and that existing\ninterventions are insufficient: standard prompt approaches provide only\nmarginal gains, and existing, factuality-based calibration techniques can even\nharm faithful calibration. To address this critical gap, we introduce\nMetaFaith, a novel prompt-based calibration approach inspired by human\nmetacognition. We show that MetaFaith robustly improves faithful calibration\nacross diverse models and task domains, enabling up to 61% improvement in\nfaithfulness and achieving an 83% win rate over original generations as judged\nby humans.",
    "pdf_url": "http://arxiv.org/pdf/2505.24858v1",
    "published": "2025-05-30T17:54:08+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24857v1",
    "title": "Accelerated Sampling from Masked Diffusion Models via Entropy Bounded Unmasking",
    "authors": [
      "Heli Ben-Hamu",
      "Itai Gat",
      "Daniel Severo",
      "Niklas Nolte",
      "Brian Karrer"
    ],
    "abstract": "Recent masked diffusion models (MDMs) have shown competitive performance\ncompared to autoregressive models (ARMs) for language modeling. While most\nliterature has focused on performance enhancing sampling procedures, efficient\nsampling from MDMs has been scarcely explored. We make the observation that\noften a given sequence of partially masked tokens determines the values of\nmultiple unknown tokens deterministically, meaning that a single prediction of\na masked model holds additional information unused by standard sampling\nprocedures. Based on this observation, we introduce EB-Sampler, a simple\ndrop-in replacement for existing samplers, utilizing an Entropy Bounded\nunmasking procedure that dynamically unmasks multiple tokens in one function\nevaluation with predefined approximate error tolerance. We formulate the\nEB-Sampler as part of a broad family of adaptive samplers for which we provide\nan error analysis that motivates our algorithmic choices. EB-Sampler\naccelerates sampling from current state of the art MDMs by roughly 2-3x on\nstandard coding and math reasoning benchmarks without loss in performance. We\nalso validate the same procedure works well on smaller reasoning tasks\nincluding maze navigation and Sudoku, tasks ARMs often struggle with.",
    "pdf_url": "http://arxiv.org/pdf/2505.24857v1",
    "published": "2025-05-30T17:52:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24856v1",
    "title": "The SPHEREx Sky Simulator: Science Data Modeling for the First All-Sky Near-Infrared Spectral Survey",
    "authors": [
      "Brendan P. Crill",
      "Yoonsoo P. Bach",
      "Sean A. Bryan",
      "Jean Choppin de Janvry",
      "Ari J. Cukierman",
      "C. Darren Dowell",
      "Spencer W. Everett",
      "Candice Fazar",
      "Tatiana Goldina",
      "Zhaoyu Huai",
      "Howard Hui",
      "Woong-Seob Jeong",
      "Jae Hwan Kang",
      "Phillip M. Korngut",
      "Jae Joon Lee",
      "Daniel C. Masters",
      "Chi H. Nguyen",
      "Jeonghyun Pyo",
      "Teresa Symons",
      "Yujin Yang",
      "Michael Zemcov",
      "Rachel Akeson",
      "Matthew L. N. Ashby",
      "James J. Bock",
      "Tzu-Ching Chang",
      "Yun-Ting Cheng",
      "Yi-Kuan Chang",
      "Asantha Cooray",
      "Olivier Doré",
      "Andreas L. Faisst",
      "Richard M. Feder",
      "Michael W. Werner"
    ],
    "abstract": "We describe the SPHEREx Sky Simulator, a software tool designed to model\nscience data for NASA's SPHEREx mission that will carry out a series of all-sky\nspectrophotometric surveys at $\\sim$6'' spatial resolution in 102 spectral\nchannels spanning 0.75 to 5 $\\mu$m. The Simulator software implements models\nfor astrophysical emission, instrument characteristics, and survey strategy to\ngenerate realistic infrared sky scenes as they will be observed by SPHEREx. The\nsimulated data includes a variety of realistic noise and systematic effects\nthat are estimated using up-to-date astrophysical measurements and information\nfrom pre-launch instrument characterization campaigns. Through the pre-flight\nmission phases the Simulator has been critical in predicting the impact of\nvarious effects on SPHEREx science performance, and has played an important\nrole guiding the development of the SPHEREx data analysis pipeline. In this\npaper, we describe the \\skysim\\ architecture, pre-flight instrument and sky\nmodels, and summarize high-level predictions from the Simulator, including a\npre-launch prediction for the 5$\\sigma$ point source sensitivity of SPHEREx,\nwhich we estimate to be $m_{\\rm AB}$ 18.5--19 from 0.75 to 3.8~$\\mu$m and\n$m_{\\rm AB}$ 16.6--18 from 3.8 to 5 $\\mu$m, with the sensitivity limited by the\nzodiacal light background at all wavelengths. In the future, on-orbit data will\nbe used to improve the Simulator, which will form the basis of a variety of\nforward-modeling tools that will be used to model myriad instrumental and\nastrophysical processes to characterize their systematic effects on our final\ndata products and analyses.",
    "pdf_url": "http://arxiv.org/pdf/2505.24856v1",
    "published": "2025-05-30T17:52:18+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24855v1",
    "title": "Active Gaussian Network Model: a non-equilibrium description of protein fluctuations and allosteric behavior",
    "authors": [
      "Giulio Costantini",
      "Lorenzo Caprini",
      "Umberto Marini Bettolo Marconi",
      "Fabio Cecconi"
    ],
    "abstract": "Understanding the link between structure and function in proteins is\nfundamental in molecular biology and proteomics. A central question in this\ncontext is whether allostery - where the binding of a molecule at one site\naffects the activity of a distant site - emerges as a further manifestation of\nthe intricate interplay between structure, function, and intrinsic dynamics.\nThis study explores how allosteric regulation is modified when intrinsic\nprotein dynamics operate under out-of-equilibrium conditions. To this purpose,\nwe introduce a simple nonequilibrium model of protein dynamics, inspired by\nactive matter systems, by generalizing the widely employed Gaussian Network\nModel (GNM) to incorporate non-thermal effects. Our approach underscores the\nadvantage of framing allostery as a causal process by using, as a benchmark\nsystem, the second PDZ domain of the human phosphatase hPT1E that mediates\nprotein-protein interactions. We employ causal indicators, such as response\nfunctions and transfer entropy, to identify the network of PDZ2 residues\nthrough which the allosteric signal propagates across the protein structure.\nThese indicators reveal specific regions that align well with experimental\nobservations. Furthermore, our results suggest that deviations from purely\nthermal fluctuations can significantly influence allosteric communication by\nintroducing distinct timescales and memory effects. This influence is\nparticularly relevant when the allosteric response unfolds on timescales\nincompatible with relaxation to equilibrium. Accordingly, non-thermal\nfluctuations may become essential for accurately describing protein responses\nto ligand binding and developing a comprehensive understanding of allosteric\nregulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24855v1",
    "published": "2025-05-30T17:51:29+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.24854v2",
    "title": "Practical primary thermometry via alkali-metal-vapour Doppler broadening",
    "authors": [
      "Nicola Agnew",
      "Veronika Vohníková",
      "Erling Riis",
      "Graham Machin",
      "Aidan S. Arnold"
    ],
    "abstract": "Doppler-broadening thermometry (DBT) can be used as a calibration-free\nprimary reference suitable for practical applications, e.g. reliably measuring\ntemperatures over long periods of time in environments where sensor retrieval\nis impractical. We report on our proof-of-concept investigations into DBT with\nalkali metal vapour cells, with a particular focus on both absorption and\nfrequency accuracy during scans. We reach sub-kelvin temperature accuracy, and\nexperimental absorption fit residuals below $0.05\\,\\%$, in a simple setup. The\noutlook for portable, practical devices is bright, with clear prospects for\nfuture improvement.",
    "pdf_url": "http://arxiv.org/pdf/2505.24854v2",
    "published": "2025-05-30T17:50:35+00:00",
    "categories": [
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24853v1",
    "title": "DexMachina: Functional Retargeting for Bimanual Dexterous Manipulation",
    "authors": [
      "Zhao Mandi",
      "Yifan Hou",
      "Dieter Fox",
      "Yashraj Narang",
      "Ajay Mandlekar",
      "Shuran Song"
    ],
    "abstract": "We study the problem of functional retargeting: learning dexterous\nmanipulation policies to track object states from human hand-object\ndemonstrations. We focus on long-horizon, bimanual tasks with articulated\nobjects, which is challenging due to large action space, spatiotemporal\ndiscontinuities, and embodiment gap between human and robot hands. We propose\nDexMachina, a novel curriculum-based algorithm: the key idea is to use virtual\nobject controllers with decaying strength: an object is first driven\nautomatically towards its target states, such that the policy can gradually\nlearn to take over under motion and contact guidance. We release a simulation\nbenchmark with a diverse set of tasks and dexterous hands, and show that\nDexMachina significantly outperforms baseline methods. Our algorithm and\nbenchmark enable a functional comparison for hardware designs, and we present\nkey findings informed by quantitative and qualitative results. With the recent\nsurge in dexterous hand development, we hope this work will provide a useful\nplatform for identifying desirable hardware capabilities and lower the barrier\nfor contributing to future research. Videos and more at\nhttps://project-dexmachina.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.24853v1",
    "published": "2025-05-30T17:50:23+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24852v2",
    "title": "Chameleon: A MatMul-Free Temporal Convolutional Network Accelerator for End-to-End Few-Shot and Continual Learning from Sequential Data",
    "authors": [
      "Douwe den Blanken",
      "Charlotte Frenkel"
    ],
    "abstract": "On-device learning at the edge enables low-latency, private personalization\nwith improved long-term robustness and reduced maintenance costs. Yet,\nachieving scalable, low-power end-to-end on-chip learning, especially from\nreal-world sequential data with a limited number of examples, is an open\nchallenge. Indeed, accelerators supporting error backpropagation optimize for\nlearning performance at the expense of inference efficiency, while simplified\nlearning algorithms often fail to reach acceptable accuracy targets. In this\nwork, we present Chameleon, leveraging three key contributions to solve these\nchallenges. (i) A unified learning and inference architecture supports few-shot\nlearning (FSL), continual learning (CL) and inference at only 0.5% area\noverhead to the inference logic. (ii) Long temporal dependencies are\nefficiently captured with temporal convolutional networks (TCNs), enabling the\nfirst demonstration of end-to-end on-chip FSL and CL on sequential data and\ninference on 16-kHz raw audio. (iii) A dual-mode, matrix-multiplication-free\ncompute array allows either matching the power consumption of state-of-the-art\ninference-only keyword spotting (KWS) accelerators or enabling $4.3\\times$\nhigher peak GOPS. Fabricated in 40-nm CMOS, Chameleon sets new accuracy records\non Omniglot for end-to-end on-chip FSL (96.8%, 5-way 1-shot, 98.8%, 5-way\n5-shot) and CL (82.2% final accuracy for learning 250 classes with 10 shots),\nwhile maintaining an inference accuracy of 93.3% on the 12-class Google Speech\nCommands dataset at an extreme-edge power budget of 3.1 $\\mu$W.",
    "pdf_url": "http://arxiv.org/pdf/2505.24852v2",
    "published": "2025-05-30T17:49:30+00:00",
    "categories": [
      "cs.AR",
      "cs.LG",
      "C.3; B.6.0; B.7.0; I.2.6; B.5.0"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24851v2",
    "title": "Realistic quantum network simulation for experimental BBM92 key distribution",
    "authors": [
      "Michelle Chalupnik",
      "Brian Doolittle",
      "Suparna Seshadri",
      "Eric G. Brown",
      "Keith Kenemer",
      "Daniel Winton",
      "Daniel Sanchez-Rosales",
      "Matthew Skrzypczyk",
      "Cara Alexander",
      "Eric Ostby",
      "Michael Cubeddu"
    ],
    "abstract": "Quantum key distribution (QKD) can provide secure key material between two\nparties without relying on assumptions about the computational power of an\neavesdropper. QKD is performed over quantum links and quantum networks, systems\nwhich are resource-intensive to deploy and maintain. To evaluate and optimize\nperformance prior to, during, and after deployment, realistic simulations with\nattention to physical realism are necessary. Quantum network simulators can\nsimulate a variety of quantum and classical protocols and can assist in quantum\nnetwork design and optimization by offering realism and flexibility beyond\nmathematical models which rely on simplifying assumptions and can be\nintractable to solve as network complexity increases. We use a versatile\ndiscrete event quantum network simulator to simulate the entanglement-based QKD\nprotocol BBM92 and compare it to our experimental implementation and to\nexisting theory. Furthermore, we simulate secure key rates in a repeater key\ndistribution scenario for which no experimental implementations exist.",
    "pdf_url": "http://arxiv.org/pdf/2505.24851v2",
    "published": "2025-05-30T17:49:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24850v1",
    "title": "Harnessing Negative Signals: Reinforcement Distillation from Teacher Data for LLM Reasoning",
    "authors": [
      "Shuyao Xu",
      "Cheng Peng",
      "Jiangxuan Long",
      "Weidi Xu",
      "Wei Chu",
      "Yuan Qi"
    ],
    "abstract": "Recent advances in model distillation demonstrate that data from advanced\nreasoning models (e.g., DeepSeek-R1, OpenAI's o1) can effectively transfer\ncomplex reasoning abilities to smaller, efficient student models. However,\nstandard practices employ rejection sampling, discarding incorrect reasoning\nexamples -- valuable, yet often underutilized data. This paper addresses the\ncritical question: How can both positive and negative distilled reasoning\ntraces be effectively leveraged to maximize LLM reasoning performance in an\noffline setting? To this end, We propose Reinforcement Distillation (REDI), a\ntwo-stage framework. Stage 1 learns from positive traces via Supervised\nFine-Tuning (SFT). Stage 2 further refines the model using both positive and\nnegative traces through our proposed REDI objective. This novel objective is a\nsimple, reference-free loss function that outperforms established methods like\nDPO and SimPO in this distillation context. Our empirical evaluations\ndemonstrate REDI's superiority over baseline Rejection Sampling SFT or SFT\ncombined with DPO/SimPO on mathematical reasoning tasks. Notably, the\nQwen-REDI-1.5B model, post-trained on just 131k positive and negative examples\nfrom the open Open-R1 dataset, achieves an 83.1% score on MATH-500 (pass@1).\nIts performance matches or surpasses that of DeepSeek-R1-Distill-Qwen-1.5B (a\nmodel post-trained on 800k proprietary data) across various mathematical\nreasoning benchmarks, establishing a new state-of-the-art for 1.5B models\npost-trained offline with openly available data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24850v1",
    "published": "2025-05-30T17:47:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24849v1",
    "title": "Statistical mechanics of extensive-width Bayesian neural networks near interpolation",
    "authors": [
      "Jean Barbier",
      "Francesco Camilli",
      "Minh-Toan Nguyen",
      "Mauro Pastore",
      "Rudy Skerk"
    ],
    "abstract": "For three decades statistical mechanics has been providing a framework to\nanalyse neural networks. However, the theoretically tractable models, e.g.,\nperceptrons, random features models and kernel machines, or multi-index models\nand committee machines with few neurons, remained simple compared to those used\nin applications. In this paper we help reducing the gap between practical\nnetworks and their theoretical understanding through a statistical physics\nanalysis of the supervised learning of a two-layer fully connected network with\ngeneric weight distribution and activation function, whose hidden layer is\nlarge but remains proportional to the inputs dimension. This makes it more\nrealistic than infinitely wide networks where no feature learning occurs, but\nalso more expressive than narrow ones or with fixed inner weights. We focus on\nthe Bayes-optimal learning in the teacher-student scenario, i.e., with a\ndataset generated by another network with the same architecture. We operate\naround interpolation, where the number of trainable parameters and of data are\ncomparable and feature learning emerges. Our analysis uncovers a rich\nphenomenology with various learning transitions as the number of data\nincreases. In particular, the more strongly the features (i.e., hidden neurons\nof the target) contribute to the observed responses, the less data is needed to\nlearn them. Moreover, when the data is scarce, the model only learns non-linear\ncombinations of the teacher weights, rather than \"specialising\" by aligning its\nweights with the teacher's. Specialisation occurs only when enough data becomes\navailable, but it can be hard to find for practical training algorithms,\npossibly due to statistical-to-computational~gaps.",
    "pdf_url": "http://arxiv.org/pdf/2505.24849v1",
    "published": "2025-05-30T17:46:59+00:00",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24848v2",
    "title": "Reading Recognition in the Wild",
    "authors": [
      "Charig Yang",
      "Samiul Alam",
      "Shakhrul Iman Siam",
      "Michael J. Proulx",
      "Lambert Mathias",
      "Kiran Somasundaram",
      "Luis Pesqueira",
      "James Fort",
      "Sheroze Sheriffdeen",
      "Omkar Parkhi",
      "Carl Ren",
      "Mi Zhang",
      "Yuning Chai",
      "Richard Newcombe",
      "Hyo Jin Kim"
    ],
    "abstract": "To enable egocentric contextual AI in always-on smart glasses, it is crucial\nto be able to keep a record of the user's interactions with the world,\nincluding during reading. In this paper, we introduce a new task of reading\nrecognition to determine when the user is reading. We first introduce the\nfirst-of-its-kind large-scale multimodal Reading in the Wild dataset,\ncontaining 100 hours of reading and non-reading videos in diverse and realistic\nscenarios. We then identify three modalities (egocentric RGB, eye gaze, head\npose) that can be used to solve the task, and present a flexible transformer\nmodel that performs the task using these modalities, either individually or\ncombined. We show that these modalities are relevant and complementary to the\ntask, and investigate how to efficiently and effectively encode each modality.\nAdditionally, we show the usefulness of this dataset towards classifying types\nof reading, extending current reading understanding studies conducted in\nconstrained settings to larger scale, diversity and realism.",
    "pdf_url": "http://arxiv.org/pdf/2505.24848v2",
    "published": "2025-05-30T17:46:13+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24847v1",
    "title": "Nematicity in iron pnictides: phase competition and emergent symmetry",
    "authors": [
      "Yiming Wang",
      "Changle Liu",
      "Shan Wu",
      "Jianda Wu",
      "Qimiao Si",
      "Rong Yu"
    ],
    "abstract": "The phase diagram of iron-based superconductors contains a host of electronic\norders, which are intimately connected with their superconductivity. Here we\nanalyze the fluctuations of one type of nematic order in another. Our analysis\nleads to an emergent U(1) symmetry at a first-order transition between a\nnematic phase and a $C_4$-symmetric charge-ordered phase. We characterize the\ncontinuous symmetry in terms of a certain hidden Lie algebra that links the\ndifferent orders. This emergent symmetry leads to a Goldstone mode at the\ntransition and causes softening of excitations in the nematic and charge\nsectors near the transition. The underlying physics bears a resemblance to the\nanisotropic XZ spin model, with the nematic order and charge $C_4$ order\nparameters playing the roles of the $x$ and $z$ components of the magnetization\nvector, respectively. We provide the experimental evidence in support of the\nproposed effects, and discuss the general implications of our results for the\nphysics of iron-based superconductors and other correlated systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24847v1",
    "published": "2025-05-30T17:46:02+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.02032v1",
    "title": "Towards Secure MLOps: Surveying Attacks, Mitigation Strategies, and Research Challenges",
    "authors": [
      "Raj Patel",
      "Himanshu Tripathi",
      "Jasper Stone",
      "Noorbakhsh Amiri Golilarz",
      "Sudip Mittal",
      "Shahram Rahimi",
      "Vini Chaudhary"
    ],
    "abstract": "The rapid adoption of machine learning (ML) technologies has driven\norganizations across diverse sectors to seek efficient and reliable methods to\naccelerate model development-to-deployment. Machine Learning Operations (MLOps)\nhas emerged as an integrative approach addressing these requirements by\nunifying relevant roles and streamlining ML workflows. As the MLOps market\ncontinues to grow, securing these pipelines has become increasingly critical.\nHowever, the unified nature of MLOps ecosystem introduces vulnerabilities,\nmaking them susceptible to adversarial attacks where a single misconfiguration\ncan lead to compromised credentials, severe financial losses, damaged public\ntrust, and the poisoning of training data. Our paper presents a systematic\napplication of the MITRE ATLAS (Adversarial Threat Landscape for\nArtificial-Intelligence Systems) framework, a comprehensive and continuously\nupdated catalog of AI-focused attacks, to systematically assess attacks across\ndifferent phases of the MLOps ecosystem. We begin by examining the preparatory\nphases during which adversaries acquire the essential intelligence required to\ninitiate their attacks. We then present a structured taxonomy of attack\ntechniques explicitly mapped to corresponding phases of the MLOps ecosystem,\nsupported by examples drawn from red-teaming exercises and real-world\nincidents. This is followed by a taxonomy of mitigation strategies aligned with\nthese attack categories, offering actionable early-stage defenses to strengthen\nthe security of MLOps ecosystem. Given the rapid evolution and adoption of\nMLOps, we further highlight key research gaps that require immediate attention.\nOur work emphasizes the importance of implementing robust security protocols\nfrom the outset, empowering practitioners to safeguard MLOps ecosystem against\nevolving cyber attacks.",
    "pdf_url": "http://arxiv.org/pdf/2506.02032v1",
    "published": "2025-05-30T17:45:31+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24846v1",
    "title": "MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning",
    "authors": [
      "Jingyan Shen",
      "Jiarui Yao",
      "Rui Yang",
      "Yifan Sun",
      "Feng Luo",
      "Rui Pan",
      "Tong Zhang",
      "Han Zhao"
    ],
    "abstract": "Reward modeling is a key step in building safe foundation models when\napplying reinforcement learning from human feedback (RLHF) to align Large\nLanguage Models (LLMs). However, reward modeling based on the Bradley-Terry\n(BT) model assumes a global reward function, failing to capture the inherently\ndiverse and heterogeneous human preferences. Hence, such oversimplification\nlimits LLMs from supporting personalization and pluralistic alignment.\nTheoretically, we show that when human preferences follow a mixture\ndistribution of diverse subgroups, a single BT model has an irreducible error.\nWhile existing solutions, such as multi-objective learning with fine-grained\nannotations, help address this issue, they are costly and constrained by\npredefined attributes, failing to fully capture the richness of human values.\nIn this work, we introduce MiCRo, a two-stage framework that enhances\npersonalized preference learning by leveraging large-scale binary preference\ndatasets without requiring explicit fine-grained annotations. In the first\nstage, MiCRo introduces context-aware mixture modeling approach to capture\ndiverse human preferences. In the second stage, MiCRo integrates an online\nrouting strategy that dynamically adapts mixture weights based on specific\ncontext to resolve ambiguity, allowing for efficient and scalable preference\nadaptation with minimal additional supervision. Experiments on multiple\npreference datasets demonstrate that MiCRo effectively captures diverse human\npreferences and significantly improves downstream personalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.24846v1",
    "published": "2025-05-30T17:44:28+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24845v1",
    "title": "A Planar Huygens Antenna Utilizing Crossed Electric and Magnetic Dipoles",
    "authors": [
      "Muhammad Rizwan Akram",
      "Abbas Semnani"
    ],
    "abstract": "The natural source of a magnetic dipole in antennas is typically an\nelectrically small loop, which can be utilized in conjunction with an electric\ndipole to realize an electrically small Huygens' antenna. However, these\nantennas suffer from low radiation efficiency and their theoretical directivity\nlimit is 4.8 dBi. Magnetic dipoles with an electrical size larger than\n0.5lambda are highly desirable for high-gain applications. This paper builds on\nthe development of a magnetic dipole source that utilizes a 0.5lambda slot\npositioned near a printed dipole with a length twice that of the slot. Such a\ncombination of electric and magnetic dipoles yields a highly directive\nradiation pattern, resulting in a higher gain than a uniformly illuminated\nantenna of similar size. The prototype is designed to operate at 4.5 GHz, with\na directivity of up to 8.37 dBi. The analytical, numerical, and measured\nresults agree fully. This high-gain superdirective antenna is highly desirable\ndue to its excellent features, including being low-profile, PCB compatible, and\nhaving a low-complexity feeding topology, compared to the existing approach of\nthe two-element end-fire array.",
    "pdf_url": "http://arxiv.org/pdf/2505.24845v1",
    "published": "2025-05-30T17:43:17+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24844v1",
    "title": "Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning",
    "authors": [
      "Wanyun Xie",
      "Francesco Tonin",
      "Volkan Cevher"
    ],
    "abstract": "Training data mixtures greatly impact the generalization performance of large\nlanguage models. Existing domain reweighting methods often rely on costly\nweight computations and require retraining when new data is introduced. To this\nend, we introduce a flexible and efficient data mixing framework, Chameleon,\nthat employs leverage scores to quantify domain importance within a learned\nembedding space. We first construct a domain affinity matrix over domain\nembeddings. The induced leverage scores determine a mixture that upweights\ndomains sharing common representations in embedding space. This formulation\nallows direct transfer to new data by computing the new domain embeddings. In\nexperiments, we demonstrate improvements over three key scenarios: (i) our\ncomputed weights improve performance on pretraining domains with a fraction of\nthe compute of existing methods; (ii) Chameleon can adapt to data changes\nwithout proxy retraining, boosting few-shot reasoning accuracies when\ntransferred to new data; (iii) our method enables efficient domain reweighting\nin finetuning, consistently improving test perplexity on all finetuning domains\nover uniform mixture. Our code is available at\nhttps://github.com/LIONS-EPFL/Chameleon.",
    "pdf_url": "http://arxiv.org/pdf/2505.24844v1",
    "published": "2025-05-30T17:43:10+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24843v1",
    "title": "From Invariant Representations to Invariant Data: Provable Robustness to Spurious Correlations via Noisy Counterfactual Matching",
    "authors": [
      "Ruqi Bai",
      "Yao Ji",
      "Zeyu Zhou",
      "David I. Inouye"
    ],
    "abstract": "Spurious correlations can cause model performance to degrade in new\nenvironments. Prior causality-inspired works aim to learn invariant\nrepresentations (e.g., IRM) but typically underperform empirical risk\nminimization (ERM). Recent alternatives improve robustness by leveraging\ntest-time data, but such data may be unavailable in practice. To address these\nissues, we take a data-centric approach by leveraging invariant data pairs,\npairs of samples that would have the same prediction with the optimally robust\nclassifier. We prove that certain counterfactual pairs will naturally satisfy\nthis invariance property and introduce noisy counterfactual matching (NCM), a\nsimple constraint-based method for leveraging invariant pairs for enhanced\nrobustness, even with a small set of noisy pairs-in the ideal case, each pair\ncan eliminate one spurious feature. For linear causal models, we prove that the\ntest domain error can be upper bounded by the in-domain error and a term that\ndepends on the counterfactuals' diversity and quality. We validate on a\nsynthetic dataset and demonstrate on real-world benchmarks that linear probing\non a pretrained backbone improves robustness.",
    "pdf_url": "http://arxiv.org/pdf/2505.24843v1",
    "published": "2025-05-30T17:42:32+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24842v1",
    "title": "Cascading Adversarial Bias from Injection to Distillation in Language Models",
    "authors": [
      "Harsh Chaudhari",
      "Jamie Hayes",
      "Matthew Jagielski",
      "Ilia Shumailov",
      "Milad Nasr",
      "Alina Oprea"
    ],
    "abstract": "Model distillation has become essential for creating smaller, deployable\nlanguage models that retain larger system capabilities. However, widespread\ndeployment raises concerns about resilience to adversarial manipulation. This\npaper investigates vulnerability of distilled models to adversarial injection\nof biased content during training. We demonstrate that adversaries can inject\nsubtle biases into teacher models through minimal data poisoning, which\npropagates to student models and becomes significantly amplified. We propose\ntwo propagation modes: Untargeted Propagation, where bias affects multiple\ntasks, and Targeted Propagation, focusing on specific tasks while maintaining\nnormal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning\nrate), student models generate biased responses 76.9% of the time in targeted\nscenarios - higher than 69.4% in teacher models. For untargeted propagation,\nadversarial bias appears 6x-29x more frequently in student models on unseen\ntasks. We validate findings across six bias types (targeted advertisements,\nphishing links, narrative manipulations, insecure coding practices), various\ndistillation methods, and different modalities spanning text and code\ngeneration. Our evaluation reveals shortcomings in current defenses -\nperplexity filtering, bias detection systems, and LLM-based autorater\nframeworks - against these attacks. Results expose significant security\nvulnerabilities in distilled models, highlighting need for specialized\nsafeguards. We propose practical design principles for building effective\nadversarial bias mitigation strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.24842v1",
    "published": "2025-05-30T17:41:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24841v1",
    "title": "pySTARBURST99: The Next Generation of STARBURST99",
    "authors": [
      "Calum Hawcroft",
      "Claus Leitherer",
      "Oskar Arangure",
      "John Chisholm",
      "Sylvia Ekstrom",
      "Sebastien Martinet",
      "Lucimara Martins",
      "Georges Meynet",
      "Christophe Morisset",
      "Andreas Sander",
      "Aida Wofford"
    ],
    "abstract": "STARBURST99 is a population synthesis code tailored to predict the integrated\nproperties or observational characteristics of star-forming galaxies. Here we\npresent an update to STARBURST99 where we port the code to python, include new\nevolutionary tracks both rotating and non-rotating at a range of low\nmetallicity environments. We complement these tracks with a corresponding grid\nof new synthetic SEDs. Additionally we include both evolutionary and spectral\nmodels of stars up to 300-500Msol. Synthesis models made with the python\nversion of the code and new input stellar models are labelled pySTARBURST99. We\nmake new predictions for many properties, such as ionising flux, SED,\nbolometric luminosity, wind power, hydrogen line equivalent widths and the UV\nbeta-slope. These properties are all assessed over wider coverage in\nmetallicity, mass and resolution than in previous versions of STARBURST99. A\nnotable finding from these updates is an increase in H I ionising flux of 0.3\ndex in the first 2Myr when increasing the upper mass limit from 120 to 300Msol.\nChanging metallicity has little impact on H I in the first 2Myr (range of 0.015\ndex from Z = 0.02 to 0.0) but lower metallicities have higher H I by 1 dex\n(comparing Z = 0.02 to 0.0004) at later times, with Z = 0.0 having even higher\nH I at later times. Rotating models have significantly higher H I than their\nequivalent non-rotating models at any time after 2Myr. Similar trends are found\nfor He I and He II, bolometric luminosity and wind momentum, with more complex\nrelations found for hydrogen line equivalent widths and UV beta-slopes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24841v1",
    "published": "2025-05-30T17:40:56+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24840v1",
    "title": "Vision LLMs Are Bad at Hierarchical Visual Understanding, and LLMs Are the Bottleneck",
    "authors": [
      "Yuwen Tan",
      "Yuan Qing",
      "Boqing Gong"
    ],
    "abstract": "This paper reveals that many state-of-the-art large language models (LLMs)\nlack hierarchical knowledge about our visual world, unaware of even\nwell-established biology taxonomies. This shortcoming makes LLMs a bottleneck\nfor vision LLMs' hierarchical visual understanding (e.g., recognizing Anemone\nFish but not Vertebrate). We arrive at these findings using about one million\nfour-choice visual question answering (VQA) tasks constructed from six\ntaxonomies and four image datasets. Interestingly, finetuning a vision LLM\nusing our VQA tasks reaffirms LLMs' bottleneck effect to some extent because\nthe VQA tasks improve the LLM's hierarchical consistency more than the vision\nLLM's. We conjecture that one cannot make vision LLMs understand visual\nconcepts fully hierarchical until LLMs possess corresponding taxonomy\nknowledge.",
    "pdf_url": "http://arxiv.org/pdf/2505.24840v1",
    "published": "2025-05-30T17:40:46+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24839v1",
    "title": "Novel methodology to obtain transonic solutions for dissipative flows around compact objects",
    "authors": [
      "Shilpa Sarkar"
    ],
    "abstract": "A novel methodology to obtain global transonic solutions around compact\nobjects is reported here. A unified methodology to obtain accretion as well as\nwind solutions around these objects has been presented. Flows around compact\nobjects are dissipative, and the conservation equations are therefore stiff. In\nsuch conditions, obtaining of sonic point(s) and hence, the transonic solution\nis not trivial. The conserved equations of motion fail to integrate in the\npresence of realistic viscosity, thereby making it difficult to obtain a global\nsolution. This inhibits one from getting an actual picture of an astrophysical\nflow. The current work addresses this long-standing issue of obtaining\nsolutions for both accretion and wind. The methodology developed utilises the\ninner boundary conditions and takes recourse to implicit-explicit (ImEx)\nintegration schemes, to obtain general global transonic accretion and wind\nsolutions. This is the first time such an attempt has been made. Current work\nconsiders the different cooling processes like bremsstrahlung, synchrotron and\ntheir inverse-Comptonizations, which are found to affect the thermodynamics of\nthe flow. This methodology could successfully generate all topologies of global\nsolutions, multiple sonic point regime, as well as shocks. A broad parameter\nspace study has been done in this work. In an upcoming part II of the paper, a\ndetailed discussion on the spectra and luminosity of the accretion and wind\nsolutions has been presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.24839v1",
    "published": "2025-05-30T17:40:40+00:00",
    "categories": [
      "astro-ph.HE",
      "hep-th",
      "physics.comp-ph",
      "physics.plasm-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.05375v1",
    "title": "State Estimation and Control of Dynamic Systems from High-Dimensional Image Data",
    "authors": [
      "Ashik E Rasul",
      "Hyung-Jin Yoon"
    ],
    "abstract": "Accurate state estimation is critical for optimal policy design in dynamic\nsystems. However, obtaining true system states is often impractical or\ninfeasible, complicating the policy learning process. This paper introduces a\nnovel neural architecture that integrates spatial feature extraction using\nconvolutional neural networks (CNNs) and temporal modeling through gated\nrecurrent units (GRUs), enabling effective state representation from sequences\nof images and corresponding actions. These learned state representations are\nused to train a reinforcement learning agent with a Deep Q-Network (DQN).\nExperimental results demonstrate that our proposed approach enables real-time,\naccurate estimation and control without direct access to ground-truth states.\nAdditionally, we provide a quantitative evaluation methodology for assessing\nthe accuracy of the learned states, highlighting their impact on policy\nperformance and control stability.",
    "pdf_url": "http://arxiv.org/pdf/2506.05375v1",
    "published": "2025-05-30T17:40:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24838v1",
    "title": "VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software",
    "authors": [
      "Brandon Man",
      "Ghadi Nehme",
      "Md Ferdous Alam",
      "Faez Ahmed"
    ],
    "abstract": "Computer-Aided Design (CAD) is a time-consuming and complex process,\nrequiring precise, long-horizon user interactions with intricate 3D interfaces.\nWhile recent advances in AI-driven user interface (UI) agents show promise,\nmost existing datasets and methods focus on short, low-complexity tasks in\nmobile or web applications, failing to capture the demands of professional\nengineering tools. In this work, we introduce VideoCAD, the first attempt at\nengineering UI interaction learning for precision tasks. Specifically, VideoCAD\nis a large-scale synthetic dataset consisting of over 41K annotated video\nrecordings of CAD operations, generated using an automated framework for\ncollecting high-fidelity UI action data from human-made CAD designs. Compared\nto existing datasets, VideoCAD offers an order of magnitude higher complexity\nin UI interaction learning for real-world engineering tasks, having up to a 20x\nlonger time horizon than other datasets. We show two important downstream\napplications of VideoCAD: learning UI interactions from professional precision\n3D CAD tools and a visual question-answering (VQA) benchmark designed to\nevaluate multimodal large language models' (LLM) spatial reasoning and video\nunderstanding abilities. To learn the UI interactions, we propose\nVideoCADFormer - a state-of-the-art model in learning CAD interactions directly\nfrom video, which outperforms multiple behavior cloning baselines. Both\nVideoCADFormer and the VQA benchmark derived from VideoCAD reveal key\nchallenges in the current state of video-based UI understanding, including the\nneed for precise action grounding, multi-modal and spatial reasoning, and\nlong-horizon dependencies.",
    "pdf_url": "http://arxiv.org/pdf/2505.24838v1",
    "published": "2025-05-30T17:39:52+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24837v1",
    "title": "Zero-Shot Chinese Character Recognition with Hierarchical Multi-Granularity Image-Text Aligning",
    "authors": [
      "Yinglian Zhu",
      "Haiyang Yu",
      "Qizao Wang",
      "Wei Lu",
      "Xiangyang Xue",
      "Bin Li"
    ],
    "abstract": "Chinese Character Recognition (CCR) is a fundamental technology for\nintelligent document processing. Unlike Latin characters, Chinese characters\nexhibit unique spatial structures and compositional rules, allowing for the use\nof fine-grained semantic information in representation. However, existing\napproaches are usually based on auto-regressive as well as edit distance\npost-process and typically rely on a single-level character representation. In\nthis paper, we propose a Hierarchical Multi-Granularity Image-Text Aligning\n(Hi-GITA) framework based on a contrastive paradigm. To leverage the abundant\nfine-grained semantic information of Chinese characters, we propose\nmulti-granularity encoders on both image and text sides. Specifically, the\nImage Multi-Granularity Encoder extracts hierarchical image representations\nfrom character images, capturing semantic cues from localized strokes to\nholistic structures. The Text Multi-Granularity Encoder extracts stroke and\nradical sequence representations at different levels of granularity. To better\ncapture the relationships between strokes and radicals, we introduce\nMulti-Granularity Fusion Modules on the image and text sides, respectively.\nFurthermore, to effectively bridge the two modalities, we further introduce a\nFine-Grained Decoupled Image-Text Contrastive loss, which aligns image and text\nrepresentations across multiple granularities. Extensive experiments\ndemonstrate that our proposed Hi-GITA significantly outperforms existing\nzero-shot CCR methods. For instance, it brings about 20% accuracy improvement\nin handwritten character and radical zero-shot settings. Code and models will\nbe released soon.",
    "pdf_url": "http://arxiv.org/pdf/2505.24837v1",
    "published": "2025-05-30T17:39:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24836v1",
    "title": "Study of the structural and electronic properties of the Heusler Co2FeGe alloy by DFT approach",
    "authors": [
      "A. Jamraoui",
      "Y. Selmani",
      "A. Jabar",
      "L. Bahmad"
    ],
    "abstract": "In this work we reported the structural and electronic properties of the\nHeusler compound Co2FeGe using the AKAI-KKR code under the GGA approximation.\nWe established that this material presents not only magnetic character but also\nhas a metallic behavior. Our calculations have been conducted using the DFT\nmethod in the framework of the AKAI-KKR code. This study enabled us to define\ncertain characteristics and initial parameters for creating a model of the\nsystem. The method used allowed us to apply fundamental concepts to the studied\nsystem in the form of modeling. The main results, of the studied Heusler\ncompound Co2FeGe are: i) this material is magnetic; ii) The band structure of\nthe material predicts a metallic character; iii) the origin of magnetism comes\nmainly from the transition metals Co and Fe atoms. These results, assure that\nthe studied quaternary Heusler Co2FeGe stands for a strong candidate for\ndifferent spintronics applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.24836v1",
    "published": "2025-05-30T17:37:14+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24835v3",
    "title": "Timing is Important: Risk-aware Fund Allocation based on Time-Series Forecasting",
    "authors": [
      "Fuyuan Lyu",
      "Linfeng Du",
      "Yunpeng Weng",
      "Qiufang Ying",
      "Zhiyan Xu",
      "Wen Zou",
      "Haolun Wu",
      "Xiuqiang He",
      "Xing Tang"
    ],
    "abstract": "Fund allocation has been an increasingly important problem in the financial\ndomain. In reality, we aim to allocate the funds to buy certain assets within a\ncertain future period. Naive solutions such as prediction-only or\nPredict-then-Optimize approaches suffer from goal mismatch. Additionally, the\nintroduction of the SOTA time series forecasting model inevitably introduces\nadditional uncertainty in the predicted result. To solve both problems\nmentioned above, we introduce a Risk-aware Time-Series Predict-and-Allocate\n(RTS-PnO) framework, which holds no prior assumption on the forecasting models.\nSuch a framework contains three features: (i) end-to-end training with\nobjective alignment measurement, (ii) adaptive forecasting uncertainty\ncalibration, and (iii) agnostic towards forecasting models. The evaluation of\nRTS-PnO is conducted over both online and offline experiments. For offline\nexperiments, eight datasets from three categories of financial applications are\nused: Currency, Stock, and Cryptos. RTS-PnO consistently outperforms other\ncompetitive baselines. The online experiment is conducted on the Cross-Border\nPayment business at FiT, Tencent, and an 8.4\\% decrease in regret is witnessed\nwhen compared with the product-line approach. The code for the offline\nexperiment is available at https://github.com/fuyuanlyu/RTS-PnO.",
    "pdf_url": "http://arxiv.org/pdf/2505.24835v3",
    "published": "2025-05-30T17:36:45+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24834v1",
    "title": "Multilinguality Does not Make Sense: Investigating Factors Behind Zero-Shot Transfer in Sense-Aware Tasks",
    "authors": [
      "Roksana Goworek",
      "Haim Dubossarsky"
    ],
    "abstract": "Cross-lingual transfer allows models to perform tasks in languages unseen\nduring training and is often assumed to benefit from increased multilinguality.\nIn this work, we challenge this assumption in the context of two underexplored,\nsense-aware tasks: polysemy disambiguation and lexical semantic change. Through\na large-scale analysis across 28 languages, we show that multilingual training\nis neither necessary nor inherently beneficial for effective transfer. Instead,\nwe find that confounding factors - such as fine-tuning data composition and\nevaluation artifacts - better account for the perceived advantages of\nmultilinguality. Our findings call for more rigorous evaluations in\nmultilingual NLP. We release fine-tuned models and benchmarks to support\nfurther research, with implications extending to low-resource and typologically\ndiverse languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.24834v1",
    "published": "2025-05-30T17:36:20+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24833v1",
    "title": "Cryogenic scanning photocurrent spectroscopy for materials responses to structured optical fields",
    "authors": [
      "Duxing Hao",
      "Chun-I Lu",
      "Ziqi Sun",
      "Yu-Chen Chang",
      "Wen-Hao Chang",
      "Ye-Ru Chen",
      "Akiyoshi Park",
      "Beining Rao",
      "Siyuan Qiu",
      "Yann-Wen Lan",
      "Ting-Hua Lu",
      "Nai-Chang Yeh"
    ],
    "abstract": "Circular dichroism spectroscopy is known to provide important insights into\nthe interplay of different degrees of freedom in quantum materials, and yet\nspectroscopic study of the optoelectronic responses of quantum materials to\nstructured optical fields, such as light with finite spin and orbital angular\nmomentum, has not yet been widely explored, particularly at cryogenic\ntemperature. Here we demonstrate the design and application of a novel\ninstrument that integrates scanning spectroscopic photocurrent measurements\nwith structured light of controlled spin and orbital angular momentum. For\nstructured photons with wavelengths between 500 nm to 700 nm, this instrument\ncan perform spatially resolved photocurrent measurements of two-dimensional\nmaterials or thin crystals under magnetic fields up to $\\pm$ 14 Tesla, at\ntemperatures from 300 K down to 3 K, with either spin angular momentum $\\pm\n\\hbar$ ororbital angular momentum $\\pm \\ell \\hbar$ (where $\\ell$=1,2,3... is\nthe topological charge), and over a (35 $\\times$ 25) $\\mu m^2$ area with ~ 1\n$\\mu m$ spatial resolution. These capabilities of the instrument are\nexemplified by magneto-photocurrent spectroscopic measurements of monolayer\n2H-$MoS_2$ field-effect transistors, which not only reveal the excitonic\nspectra but also demonstrate monotonically increasing photocurrents with\nincreasing |$\\ell $| as well as excitonic Zeeman splitting and an enhanced\nLand\\'e g-factor due to the enhanced formation of intervalley dark excitons\nunder magnetic field. These studies thus demonstrate the versatility of the\nscanning photocurrent spectrometry for investigating excitonic physics, optical\nselection rules, and optoelectronic responses of novel quantum materials and\nengineered quantum devices to structured light.",
    "pdf_url": "http://arxiv.org/pdf/2505.24833v1",
    "published": "2025-05-30T17:35:04+00:00",
    "categories": [
      "cond-mat.other",
      "physics.ins-det"
    ],
    "primary_category": "cond-mat.other"
  },
  {
    "id": "http://arxiv.org/abs/2505.24832v3",
    "title": "How much do language models memorize?",
    "authors": [
      "John X. Morris",
      "Chawin Sitawarin",
      "Chuan Guo",
      "Narine Kokhlikyan",
      "G. Edward Suh",
      "Alexander M. Rush",
      "Kamalika Chaudhuri",
      "Saeed Mahloujifar"
    ],
    "abstract": "We propose a new method for estimating how much a model knows about a\ndatapoint and use it to measure the capacity of modern language models. Prior\nstudies of language model memorization have struggled to disentangle\nmemorization from generalization. We formally separate memorization into two\ncomponents: unintended memorization, the information a model contains about a\nspecific dataset, and generalization, the information a model contains about\nthe true data-generation process. When we completely eliminate generalization,\nwe can compute the total memorization, which provides an estimate of model\ncapacity: our measurements estimate that GPT-style models have a capacity of\napproximately 3.6 bits per parameter. We train language models on datasets of\nincreasing size and observe that models memorize until their capacity fills, at\nwhich point \"grokking\" begins, and unintended memorization decreases as models\nbegin to generalize. We train hundreds of transformer language models ranging\nfrom $500K$ to $1.5B$ parameters and produce a series of scaling laws relating\nmodel capacity and data size to membership inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.24832v3",
    "published": "2025-05-30T17:34:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24831v1",
    "title": "Optimising cryptocurrency portfolios through stable clustering of price correlation networks",
    "authors": [
      "Ruixue Jing",
      "Ryota Kobayashi",
      "Luis Enrique Correa Rocha"
    ],
    "abstract": "The emerging cryptocurrency market presents unique challenges for investment\ndue to its unregulated nature and inherent volatility. However, collective\nprice movements can be explored to maximise profits with minimal risk using\ninvestment portfolios. In this paper, we develop a technical framework that\nutilises historical data on daily closing prices and integrates network\nanalysis, price forecasting, and portfolio theory to identify cryptocurrencies\nfor building profitable portfolios under uncertainty. Our method utilises the\nLouvain network community algorithm and consensus clustering to detect robust\nand temporally stable clusters of highly correlated cryptocurrencies, from\nwhich the chosen cryptocurrencies are selected. A price prediction step using\nthe ARIMA model guarantees that the portfolio performs well for up to 14 days\nin the investment horizon. Empirical analysis over a 5-year period shows that\ndespite the high volatility in the crypto market, hidden price patterns can be\neffectively utilised to generate consistently profitable, time-agnostic\ncryptocurrency portfolios.",
    "pdf_url": "http://arxiv.org/pdf/2505.24831v1",
    "published": "2025-05-30T17:33:12+00:00",
    "categories": [
      "physics.pop-ph",
      "physics.soc-ph",
      "q-fin.PM"
    ],
    "primary_category": "physics.pop-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24830v1",
    "title": "Improving Reliability and Explainability of Medical Question Answering through Atomic Fact Checking in Retrieval-Augmented LLMs",
    "authors": [
      "Juraj Vladika",
      "Annika Domres",
      "Mai Nguyen",
      "Rebecca Moser",
      "Jana Nano",
      "Felix Busch",
      "Lisa C. Adams",
      "Keno K. Bressem",
      "Denise Bernhardt",
      "Stephanie E. Combs",
      "Kai J. Borm",
      "Florian Matthes",
      "Jan C. Peeken"
    ],
    "abstract": "Large language models (LLMs) exhibit extensive medical knowledge but are\nprone to hallucinations and inaccurate citations, which pose a challenge to\ntheir clinical adoption and regulatory compliance. Current methods, such as\nRetrieval Augmented Generation, partially address these issues by grounding\nanswers in source documents, but hallucinations and low fact-level\nexplainability persist. In this work, we introduce a novel atomic fact-checking\nframework designed to enhance the reliability and explainability of LLMs used\nin medical long-form question answering. This method decomposes LLM-generated\nresponses into discrete, verifiable units called atomic facts, each of which is\nindependently verified against an authoritative knowledge base of medical\nguidelines. This approach enables targeted correction of errors and direct\ntracing to source literature, thereby improving the factual accuracy and\nexplainability of medical Q&A. Extensive evaluation using multi-reader\nassessments by medical experts and an automated open Q&A benchmark demonstrated\nsignificant improvements in factual accuracy and explainability. Our framework\nachieved up to a 40% overall answer improvement and a 50% hallucination\ndetection rate. The ability to trace each atomic fact back to the most relevant\nchunks from the database provides a granular, transparent explanation of the\ngenerated responses, addressing a major gap in current medical AI applications.\nThis work represents a crucial step towards more trustworthy and reliable\nclinical applications of LLMs, addressing key prerequisites for clinical\napplication and fostering greater confidence in AI-assisted healthcare.",
    "pdf_url": "http://arxiv.org/pdf/2505.24830v1",
    "published": "2025-05-30T17:33:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24829v1",
    "title": "Accurate and efficient likelihood modeling for large-scale CMB data",
    "authors": [
      "Giacomo Galloni",
      "Paolo Campeti",
      "Luca Pagano",
      "Martina Gerbino",
      "Massimiliano Lattanzi",
      "Paolo Natoli"
    ],
    "abstract": "Accurate parameter estimation from cosmic microwave background data requires\nreliable likelihood modeling, particularly at large angular scales where\nangular power spectrum estimators exhibit non-Gaussian statistics. We present a\nnovel approach, based on the Hamimeche-Lewis formalism, that marginalizes over\nauto-spectra, thus reducing residual biases from noise misestimation and\npartial sky coverage. We validate our approach by simulating three independent\nCMB channels, or data splits, in a multi-field setting, comparing to the\npixel-based likelihood ground truth estimates for the optical depth $\\tau$ and\nthe tensor-to-scalar ratio $r$. We benchmark our method against the main power\nspectrum based alternatives available in the literature, showing that it\noutperforms all of them in terms of accuracy, while remaining fast and\ncomputationally efficient.",
    "pdf_url": "http://arxiv.org/pdf/2505.24829v1",
    "published": "2025-05-30T17:33:02+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24828v1",
    "title": "Coherent structures in long range FPUT lattices, Part I: Solitary Waves",
    "authors": [
      "J. Douglas Wright",
      "Udoh Akpan"
    ],
    "abstract": "We consider long range variants of Fermi-Pasta-Ulam-Tsingou lattice and in\nparticular allow for particles to interact over arbitrarily long distances. We\ndevelop sufficient conditions which allow for the construction of solitary wave\nsolutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24828v1",
    "published": "2025-05-30T17:32:31+00:00",
    "categories": [
      "math.AP",
      "math.DS"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24827v2",
    "title": "Preserved reptile scales retain microscopic features, revealing a new instance of convergent evolution",
    "authors": [
      "Calvin A. Riiska",
      "Gordon W. Schuett",
      "Joseph R. Mendelson III",
      "Jennifer M. Rieser"
    ],
    "abstract": "Small-scale structures on biological surfaces can profoundly impact how\nanimals move, appear, and interact with their environments. Such textures may\nbe especially important for limbless reptiles, such as snakes and legless\nlizards, because their skin serves as the primary interface with the world\naround them. Here, we examine ventral microstructures of several limbless\nreptiles, which are hypothesized to be highly specialized to aid locomotion via\nfrictional interactions. Inspired by prior studies that investigated potential\nlinks between microtextures, phylogeny, habitat, and locomotion -- but that\nwere limited by their reliance on shed skins -- we characterized the structures\npresent on preserved museum specimens and found that they are quantitatively\nsimilar to those found on shed skins. Using this result, we confirmed a\npreviously hypothesized -- but untested due to the lack of shed skins -- third\nindependent evolution of sidewinding-specific isotropic microtexture.\nSpecifically, we examined a museum-preserved \\textit{Bitis peringueyi} specimen\nand identified a new instance of convergent evolution in sidewinding viper\nmicrostructures: the loss of micro-spikes (present on many snake species) and\nthe appearance of micro-pits with a characteristic spacing. Our results reveal\nthat museum-preserved specimens retain intact microtextures, greatly expanding\nthe availability of samples for evolutionary studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.24827v2",
    "published": "2025-05-30T17:31:24+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24826v1",
    "title": "LegalEval-Q: A New Benchmark for The Quality Evaluation of LLM-Generated Legal Text",
    "authors": [
      "Li yunhan",
      "Wu gengshen"
    ],
    "abstract": "As large language models (LLMs) are increasingly used in legal applications,\ncurrent evaluation benchmarks tend to focus mainly on factual accuracy while\nlargely neglecting important linguistic quality aspects such as clarity,\ncoherence, and terminology. To address this gap, we propose three steps: First,\nwe develop a regression model to evaluate the quality of legal texts based on\nclarity, coherence, and terminology. Second, we create a specialized set of\nlegal questions. Third, we analyze 49 LLMs using this evaluation framework.\n  Our analysis identifies three key findings: First, model quality levels off\nat 14 billion parameters, with only a marginal improvement of $2.7\\%$ noted at\n72 billion parameters. Second, engineering choices such as quantization and\ncontext length have a negligible impact, as indicated by statistical\nsignificance thresholds above 0.016. Third, reasoning models consistently\noutperform base architectures. A significant outcome of our research is the\nrelease of a ranking list and Pareto analysis, which highlight the Qwen3 series\nas the optimal choice for cost-performance tradeoffs. This work not only\nestablishes standardized evaluation protocols for legal LLMs but also uncovers\nfundamental limitations in current training data refinement approaches. Code\nand models are available at: https://github.com/lyxx3rd/LegalEval-Q.",
    "pdf_url": "http://arxiv.org/pdf/2505.24826v1",
    "published": "2025-05-30T17:30:18+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24825v1",
    "title": "Approximate Light Spanners in Planar Graphs",
    "authors": [
      "Hung Le",
      "Shay Solomon",
      "Cuong Than",
      "Csaba D. Tóth",
      "Tianyi Zhang"
    ],
    "abstract": "In their seminal paper, Alth\\\"{o}fer et al. (DCG 1993) introduced the {\\em\ngreedy spanner} and showed that, for any weighted planar graph $G$, the weight\nof the greedy $(1+\\epsilon)$-spanner is at most $(1+\\frac{2}{\\epsilon}) \\cdot\nw(MST(G))$, where $w(MST(G))$ is the weight of a minimum spanning tree $MST(G)$\nof $G$. This bound is optimal in an {\\em existential sense}: there exist planar\ngraphs $G$ for which any $(1+\\epsilon)$-spanner has a weight of at least\n$(1+\\frac{2}{\\epsilon}) \\cdot w(MST(G))$.\n  However, as an {\\em approximation algorithm}, even for a {\\em bicriteria}\napproximation, the weight approximation factor of the greedy spanner is\nessentially as large as the existential bound: There exist planar graphs $G$\nfor which the greedy $(1+x \\epsilon)$-spanner (for any $1\\leq x =\nO(\\epsilon^{-1/2})$) has a weight of $\\Omega(\\frac{1}{\\epsilon \\cdot x^2})\\cdot\nw(G_{OPT, \\epsilon})$, where $G_{OPT, \\epsilon}$ is a $(1+\\epsilon)$-spanner of\n$G$ of minimum weight.\n  Despite the flurry of works over the past three decades on approximation\nalgorithms for spanners as well as on light(-weight) spanners, there is still\nno (possibly bicriteria) approximation algorithm for light spanners in weighted\nplanar graphs that outperforms the existential bound. As our main contribution,\nwe present a polynomial time algorithm for constructing, in any weighted planar\ngraph $G$, a $(1+\\epsilon\\cdot 2^{O(\\log^* 1/\\epsilon)})$-spanner for $G$ of\ntotal weight $O(1)\\cdot w(G_{OPT, \\epsilon})$.\n  To achieve this result, we develop a new technique, which we refer to as {\\em\niterative planar pruning}. It iteratively modifies a spanner [...]",
    "pdf_url": "http://arxiv.org/pdf/2505.24825v1",
    "published": "2025-05-30T17:30:12+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24824v1",
    "title": "Segmenting France Across Four Centuries",
    "authors": [
      "Marta López-Rauhut",
      "Hongyu Zhou",
      "Mathieu Aubry",
      "Loic Landrieu"
    ],
    "abstract": "Historical maps offer an invaluable perspective into territory evolution\nacross past centuries--long before satellite or remote sensing technologies\nexisted. Deep learning methods have shown promising results in segmenting\nhistorical maps, but publicly available datasets typically focus on a single\nmap type or period, require extensive and costly annotations, and are not\nsuited for nationwide, long-term analyses. In this paper, we introduce a new\ndataset of historical maps tailored for analyzing large-scale, long-term land\nuse and land cover evolution with limited annotations. Spanning metropolitan\nFrance (548,305 km^2), our dataset contains three map collections from the\n18th, 19th, and 20th centuries. We provide both comprehensive modern labels and\n22,878 km^2 of manually annotated historical labels for the 18th and 19th\ncentury maps. Our dataset illustrates the complexity of the segmentation task,\nfeaturing stylistic inconsistencies, interpretive ambiguities, and significant\nlandscape changes (e.g., marshlands disappearing in favor of forests). We\nassess the difficulty of these challenges by benchmarking three approaches: a\nfully-supervised model trained with historical labels, and two\nweakly-supervised models that rely only on modern annotations. The latter\neither use the modern labels directly or first perform image-to-image\ntranslation to address the stylistic gap between historical and contemporary\nmaps. Finally, we discuss how these methods can support long-term environment\nmonitoring, offering insights into centuries of landscape transformation. Our\nofficial project repository is publicly available at\nhttps://github.com/Archiel19/FRAx4.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.24824v1",
    "published": "2025-05-30T17:26:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24823v1",
    "title": "PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models",
    "authors": [
      "Yinggan Xu",
      "Yue Liu",
      "Zhiqiang Gao",
      "Changnan Peng",
      "Di Luo"
    ],
    "abstract": "Large language models (LLMs) have rapidly advanced and are increasingly\ncapable of tackling complex scientific problems, including those in physics.\nDespite this progress, current LLMs often fail to emulate the concise,\nprinciple-based reasoning characteristic of human experts, instead generating\nlengthy and opaque solutions. This discrepancy highlights a crucial gap in\ntheir ability to apply core physical principles for efficient and interpretable\nproblem solving. To systematically investigate this limitation, we introduce\nPhySense, a novel principle-based physics reasoning benchmark designed to be\neasily solvable by experts using guiding principles, yet deceptively difficult\nfor LLMs without principle-first reasoning. Our evaluation across multiple\nstate-of-the-art LLMs and prompt types reveals a consistent failure to align\nwith expert-like reasoning paths, providing insights for developing AI systems\nwith efficient, robust and interpretable principle-based scientific reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.24823v1",
    "published": "2025-05-30T17:25:20+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24822v1",
    "title": "Wess-Zumino-Witten Interactions of Axions: Three-Flavor",
    "authors": [
      "Yang Bai",
      "Ting-Kuo Chen",
      "Jia Liu",
      "Xiaolin Ma"
    ],
    "abstract": "We present a complete Lagrangian describing axion interactions with\npseudoscalar and (axial-)vector mesons within the three light-flavor quark\nframework. This formulation incorporates both the standard chiral Lagrangian\nand the full Wess-Zumino-Witten (WZW) term. By including instanton effects\nassociated with the anomalous $U(1)_A$ symmetry, we demonstrate that physical\nobservables remain invariant under arbitrary chiral phase rotations of the\nquark fields. This comprehensive Lagrangian provides a robust and consistent\nframework for exploring axion phenomenology through its interactions with\nmesons and gauge bosons. As a demonstration, we compute the decay widths of\nGeV-scale axions into various mesonic final states for several benchmark axion\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.24822v1",
    "published": "2025-05-30T17:24:14+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24821v2",
    "title": "Asymptotics for the harmonic descent chain and applications to critical beta-splitting trees",
    "authors": [
      "Anna Brandenberger",
      "Byron Chin",
      "Elchanan Mossel"
    ],
    "abstract": "Motivated by the connection to a probabilistic model of phylogenetic trees\nintroduced by Aldous, we study the recursive sequence governed by the rule $x_n\n= \\sum_{i=1}^{n-1} \\frac{1}{h_{n-1}(n-i)} x_i$ where $h_{n-1} =\n\\sum_{j=1}^{n-1} 1/j$, known as the harmonic descent chain. While it is known\nthat this sequence converges to an explicit limit $x$, not much is known about\nthe rate of convergence. We first show that a class of recursive sequences\nincluding the above are decreasing and use this to bound the rate of\nconvergence. Moreover, for the harmonic descent chain we prove the asymptotic\n$x_n - x = n^{-\\gamma_* + o(1)}$ for an implicit exponent $\\gamma_*$. As a\nconsequence, we deduce central limit theorems for various statistics of the\ncritical beta-splitting random tree. This answers a number of questions of\nAldous, Janson, and Pittel.",
    "pdf_url": "http://arxiv.org/pdf/2505.24821v2",
    "published": "2025-05-30T17:23:55+00:00",
    "categories": [
      "math.PR",
      "math.CO",
      "60C05, 60F05, 05C05"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02031v1",
    "title": "Effective Versions of Strong Measure Zero",
    "authors": [
      "Matthew Rayman"
    ],
    "abstract": "Effective versions of strong measure zero sets are developed for various\nlevels of complexity and computability. It is shown that the sets can be\nequivalently defined using a generalization of supermartingales called odds\nsupermartingales, success rates on supermartingales, predictors, and coverings.\nWe show Borel's conjecture of a set having strong measure zero if and only if\nit is countable holds in the time and space bounded setting. At the level of\ncomputability this does not hold. We show the computable level contains\nsequences at arbitrary levels of the hyperarithmetical hierarchy by proving a\ncorrespondence principle yielding a condition for the sets of computable strong\nmeasure zero to agree with the classical sets of strong measure zero. An\nalgorithmic version of strong measure zero using lower semicomputability is\ndefined. We show that this notion is equivalent to the set of NCR reals studied\nby Reimann and Slaman, thereby giving new characterizations of this set.\nEffective strong packing dimension zero is investigated requiring success with\nrespect to the limit inferior instead of the limit superior. It is proven that\nevery sequence in the corresponding algorithmic class is decidable. At the\nlevel of computability, the sets coincide with a notion of weak countability\nthat we define.",
    "pdf_url": "http://arxiv.org/pdf/2506.02031v1",
    "published": "2025-05-30T17:23:47+00:00",
    "categories": [
      "math.LO",
      "cs.CC",
      "cs.LO"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24820v1",
    "title": "Masked Self-distilled Transducer-based Keyword Spotting with Semi-autoregressive Decoding",
    "authors": [
      "Yu Xi",
      "Xiaoyu Gu",
      "Haoyu Li",
      "Jun Song",
      "Bo Zheng",
      "Kai Yu"
    ],
    "abstract": "RNN-T-based keyword spotting (KWS) with autoregressive decoding~(AR) has\ngained attention due to its streaming architecture and superior performance.\nHowever, the simplicity of the prediction network in RNN-T poses an overfitting\nissue, especially under challenging scenarios, resulting in degraded\nperformance. In this paper, we propose a masked self-distillation (MSD)\ntraining strategy that avoids RNN-Ts overly relying on prediction networks to\nalleviate overfitting. Such training enables masked non-autoregressive (NAR)\ndecoding, which fully masks the RNN-T predictor output during KWS decoding. In\naddition, we propose a semi-autoregressive (SAR) decoding approach to integrate\nthe advantages of AR and NAR decoding. Our experiments across multiple KWS\ndatasets demonstrate that MSD training effectively alleviates overfitting. The\nSAR decoding method preserves the superior performance of AR decoding while\nbenefits from the overfitting suppression of NAR decoding, achieving excellent\nresults.",
    "pdf_url": "http://arxiv.org/pdf/2505.24820v1",
    "published": "2025-05-30T17:22:39+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24819v1",
    "title": "Bi-Manual Joint Camera Calibration and Scene Representation",
    "authors": [
      "Haozhan Tang",
      "Tianyi Zhang",
      "Matthew Johnson-Roberson",
      "Weiming Zhi"
    ],
    "abstract": "Robot manipulation, especially bimanual manipulation, often requires setting\nup multiple cameras on multiple robot manipulators. Before robot manipulators\ncan generate motion or even build representations of their environments, the\ncameras rigidly mounted to the robot need to be calibrated. Camera calibration\nis a cumbersome process involving collecting a set of images, with each\ncapturing a pre-determined marker. In this work, we introduce the Bi-Manual\nJoint Calibration and Representation Framework (Bi-JCR). Bi-JCR enables\nmultiple robot manipulators, each with cameras mounted, to circumvent taking\nimages of calibration markers. By leveraging 3D foundation models for dense,\nmarker-free multi-view correspondence, Bi-JCR jointly estimates: (i) the\nextrinsic transformation from each camera to its end-effector, (ii) the\ninter-arm relative poses between manipulators, and (iii) a unified,\nscale-consistent 3D representation of the shared workspace, all from the same\ncaptured RGB image sets. The representation, jointly constructed from images\ncaptured by cameras on both manipulators, lives in a common coordinate frame\nand supports collision checking and semantic segmentation to facilitate\ndownstream bimanual coordination tasks. We empirically evaluate the robustness\nof Bi-JCR on a variety of tabletop environments, and demonstrate its\napplicability on a variety of downstream tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24819v1",
    "published": "2025-05-30T17:22:00+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24818v1",
    "title": "Symmetry breaking in minimum dissipation networks",
    "authors": [
      "Aarathi Parameswaran",
      "Iva Bačić",
      "Andrea Benigni",
      "Dirk Witthaut"
    ],
    "abstract": "Both natural and man-made supply networks exhibit universal structural\npatterns, such as the formation of loops. These patterns can be understood in\nterms of optimization models, assuming that biological networks evolved to\noptimal states and technical networks are designed to function optimally. In\nthis article, we analyze networks that minimize dissipation under a research\nconstraint. We demonstrate spontaneous symmetry breaking in optimal network\nstructures as a function of resource scaling. We show that fluctuations\nintricately impact the structure and can lead to a reentrant transition from a\nsymmetry-broken state to a symmetric state and back again.",
    "pdf_url": "http://arxiv.org/pdf/2505.24818v1",
    "published": "2025-05-30T17:21:31+00:00",
    "categories": [
      "nlin.AO",
      "physics.soc-ph"
    ],
    "primary_category": "nlin.AO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24817v1",
    "title": "Focused axisymmetric spatially chirped beams",
    "authors": [
      "Eric C. Nelson",
      "Kyle J. Charbonnet",
      "Haytham H. Effarah",
      "Trevor Reutershan",
      "Kyle D. Chesnut",
      "Christopher P. J. Barty"
    ],
    "abstract": "A characterization of the focused space-time structures of radially chirped\nbeams is provided, detailing different tunable properties such as: variable\non-axis centroid velocity, symmetric pulse front tilt, transverse intensity\nmodulations, and polarization states. While the practical generation of ideal\nradially chirped beams and polarizations can be problematic, it is shown that\nthe primary characteristics of these beams can be mimicked with simple arrays\nof axisymmetric, 1D spatially chirped beams.",
    "pdf_url": "http://arxiv.org/pdf/2505.24817v1",
    "published": "2025-05-30T17:21:29+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24816v1",
    "title": "CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning",
    "authors": [
      "Jiangpeng He",
      "Zhihao Duan",
      "Fengqing Zhu"
    ],
    "abstract": "Class-Incremental Learning (CIL) aims to learn new classes sequentially while\nretaining the knowledge of previously learned classes. Recently, pre-trained\nmodels (PTMs) combined with parameter-efficient fine-tuning (PEFT) have shown\nremarkable performance in rehearsal-free CIL without requiring exemplars from\nprevious tasks. However, existing adapter-based methods, which incorporate\nlightweight learnable modules into PTMs for CIL, create new adapters for each\nnew task, leading to both parameter redundancy and failure to leverage shared\nknowledge across tasks. In this work, we propose ContinuaL Low-Rank Adaptation\n(CL-LoRA), which introduces a novel dual-adapter architecture combining\n\\textbf{task-shared adapters} to learn cross-task knowledge and\n\\textbf{task-specific adapters} to capture unique features of each new task.\nSpecifically, the shared adapters utilize random orthogonal matrices and\nleverage knowledge distillation with gradient reassignment to preserve\nessential shared knowledge. In addition, we introduce learnable block-wise\nweights for task-specific adapters, which mitigate inter-task interference\nwhile maintaining the model's plasticity. We demonstrate CL-LoRA consistently\nachieves promising performance under multiple benchmarks with reduced training\nand inference computation, establishing a more efficient and scalable paradigm\nfor continual learning with pre-trained models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24816v1",
    "published": "2025-05-30T17:19:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24815v1",
    "title": "Convex Approximations of Random Constrained Markov Decision Processes",
    "authors": [
      "V Varagapriya",
      "Vikas Vikram Singh",
      "Abdel Lisser"
    ],
    "abstract": "Constrained Markov decision processes (CMDPs) are used as a decision-making\nframework to study the long-run performance of a stochastic system. It is\nwell-known that a stationary optimal policy of a CMDP problem under discounted\ncost criterion can be obtained by solving a linear programming problem when\nrunning costs and transition probabilities are exactly known. In this paper, we\nconsider a discounted cost CMDP problem where the running costs and transition\nprobabilities are defined using random variables. Consequently, both the\nobjective function and constraints become random. We use chance constraints to\nmodel these uncertainties and formulate the uncertain CMDP problem as a joint\nchance-constrained Markov decision process (JCCMDP). Under random running\ncosts, we assume that the dependency among random constraint vectors is driven\nby a Gumbel-Hougaard copula. Using standard probability inequalities, we\nconstruct convex upper bound approximations of the JCCMDP problem under certain\nconditions on random running costs. In addition, we propose a linear\nprogramming problem whose optimal value gives a lower bound to the optimal\nvalue of the JCCMDP problem. When both running costs and transition\nprobabilities are random, we define the latter variables as a sum of their\nmeans and random perturbations. Under mild conditions on the random\nperturbations and random running costs, we construct convex upper and lower\nbound approximations of the JCCMDP problem. We analyse the quality of the\nderived bounds through numerical experiments on a queueing control problem for\nrandom running costs. For the case when both running costs and transition\nprobabilities are random, we choose randomly generated Markov decision problems\ncalled Garnets for numerical experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24815v1",
    "published": "2025-05-30T17:18:34+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24814v1",
    "title": "Closed-form survival probabilities for biased random walks at arbitrary step number",
    "authors": [
      "Debendro Mookerjee",
      "Sarah Kostinski"
    ],
    "abstract": "We present a closed-form expression for the survival probability of a biased\nrandom walker to first reach a target site on a 1D lattice. The expression\nholds for any step number $N$ and is computationally faster than\nnon-closed-form results in the literature. Because our result is exact even in\nthe intermediate step number range, it serves as a tool to study convergence to\nthe large $N$ limit. We also obtain a closed-form expression for the\nprobability of last passage. In contrast to predictions of the large $N$\napproximation, the new expression reveals a critical value of the bias beyond\nwhich the tail of the last-passage probability decays monotonically.",
    "pdf_url": "http://arxiv.org/pdf/2505.24814v1",
    "published": "2025-05-30T17:17:12+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "physics.data-an"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.24813v1",
    "title": "Critical demand in a stochastic model of flows in supply networks",
    "authors": [
      "Yannick Feld",
      "Marc Barthelemy"
    ],
    "abstract": "Supply networks are essential for modern production, yet their critical\nproperties remain understudied. We present a stochastic model with random\nproduction capacities to analyze material flow to a root node, focusing on\ntopology and buffer stocks. The critical demand, where unsatisfied demand\ndiverges, is examined mostly through numerical simulations. Without stocks,\nminimal production dictates behavior, making topology irrelevant. With stocks,\nmemory effects arise, making topology crucial. Increased local connectivity is\nbeneficial: firms should favor broad, short supply chains over long, narrow\nones.",
    "pdf_url": "http://arxiv.org/pdf/2505.24813v1",
    "published": "2025-05-30T17:17:10+00:00",
    "categories": [
      "physics.soc-ph",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24812v1",
    "title": "Substructural Abstract Syntax with Variable Binding and Single-Variable Substitution",
    "authors": [
      "Marcelo Fiore",
      "Sanjiv Ranchod"
    ],
    "abstract": "We develop a unified categorical theory of substructural abstract syntax with\nvariable binding and single-variable (capture-avoiding) substitution. This is\ndone for the gamut of context structural rules given by exchange (linear\ntheory) with weakening (affine theory) or with contraction (relevant theory)\nand with both (cartesian theory). Specifically, in all four scenarios, we\nuniformly: define abstract syntax with variable binding as free algebras for\nbinding-signature endofunctors over variables; provide finitary algebraic\naxiomatisations of the laws of substitution; construct single-variable\nsubstitution operations by generalised structural recursion; and prove their\ncorrectness, establishing their universal abstract character as initial\nsubstitution algebras.",
    "pdf_url": "http://arxiv.org/pdf/2505.24812v1",
    "published": "2025-05-30T17:16:53+00:00",
    "categories": [
      "cs.LO",
      "math.CT"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24811v1",
    "title": "Locally Differentially Private Two-Sample Testing",
    "authors": [
      "Alexander Kent",
      "Thomas B. Berrett",
      "Yi Yu"
    ],
    "abstract": "We consider the problem of two-sample testing under a local differential\nprivacy constraint where a permutation procedure is used to calibrate the\ntests. We develop testing procedures which are optimal up to logarithmic\nfactors, for general discrete distributions and continuous distributions\nsubject to a smoothness constraint. Both non-interactive and interactive tests\nare considered, and we show allowing interactivity results in an improvement in\nthe minimax separation rates. Our results show that permutation procedures\nremain feasible in practice under local privacy constraints, despite the\ninability to permute the non-private data directly and only the private views.\nFurther, through a refined theoretical analysis of the permutation procedure,\nwe are able to avoid an equal sample size assumption which has been made in the\npermutation testing literature regardless of the presence of the privacy\nconstraint. Lastly, we conduct numerical experiments which demonstrate the\nperformance of our proposed test and verify the theoretical findings,\nespecially the improved performance enabled by allowing interactivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.24811v1",
    "published": "2025-05-30T17:15:47+00:00",
    "categories": [
      "math.ST",
      "stat.ME",
      "stat.TH",
      "62F03, 62G10"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.24810v1",
    "title": "New Physics Search at the CEPC: a General Perspective",
    "authors": [
      "Stefan Antusch",
      "Peter Athron",
      "Daniele Barducci",
      "Long Chen",
      "Mingshui Chen",
      "Xiang Chen",
      "Huajie Cheng",
      "Kingman Cheung",
      "Joao Guimaraes da Costa",
      "Arindam Das",
      "Frank F. Deppisch",
      "P. S. Bhupal Dev",
      "Xiaokang Du",
      "Yong Du",
      "Yaquan Fang",
      "Andrew Fowlie",
      "Yu Gao",
      "Bruce Mellado Garcia",
      "Shao-Feng Ge",
      "Jiayin Gu",
      "Yu-Chen Guo",
      "Jan Hajer",
      "Chengcheng Han",
      "Tao Han",
      "Sven Heinemeyer",
      "Fa Peng Huang",
      "Yanping Huang",
      "Jianfeng Jiang",
      "Shan Jin",
      "Liang Li",
      "Lingfeng Li",
      "Tong Li",
      "Tianjun Li",
      "Xin-Qiang Li",
      "Zhao Li",
      "Zhijun Liang",
      "Hongbo Liao",
      "Jiajun Liao",
      "Jia Liu",
      "Tao Liu",
      "Wei Liu",
      "Yang Liu",
      "Zhen Liu",
      "Zuowei Liu",
      "Xinchou Lou",
      "Chih-Ting Lu",
      "Feng Lyu",
      "Kai Ma",
      "Lianliang Ma",
      "Ying-nan Mao",
      "Sanjoy Mandal",
      "Roberto A. Morales",
      "Manimala Mitra",
      "Miha Nemevšek",
      "Takaaki Nomura",
      "Michael Ramsey-Musolf",
      "C. J. Ouseph",
      "Craig D. Roberts",
      "Manqi Ruan",
      "Liangliang Shang",
      "Sujay Shil",
      "Shufang Su",
      "Wei Su",
      "Xiaohu Sun",
      "Zheng Sun",
      "Van Que Tran",
      "Yuexin Wang",
      "Zeren Simon Wang",
      "Kechen Wang",
      "Peiwen Wu",
      "Yongcheng Wu",
      "Sai Wang",
      "Lei Wu",
      "Fei Wang",
      "Jianchun Wang",
      "Xiao-Ping Wang",
      "Guotao Xia",
      "Ke-Pan Xie",
      "Da Xu",
      "Jin Min Yang",
      "Shuo Yang",
      "Jiarong Yuan",
      "Chongxing Yue",
      "Yuanfang Yue",
      "Hao Zhang",
      "Mengchao Zhang",
      "Xuai Zhuang",
      "Yu Zhang",
      "Yang Zhang",
      "Yongchao Zhang",
      "Jing-Yu Zhu",
      "Pengxuan Zhu",
      "Rui Zhu"
    ],
    "abstract": "The Circular Electron-Positron Collider (CEPC), a proposed next-generation\nHiggs factory, provides new opportunities to explore physics beyond the\nStandard Model (SM). With its clean electron-positron collision environment and\nthe ability to collect large samples of Higgs, W, and Z bosons, the CEPC\nenables precision measurements and searches for new physics. This white paper\noutlines the CEPC's discovery potential, including studies of exotic decays of\nthe Higgs, Z, and top quarks, dark matter and dark sector phenomena, long-lived\nparticles, supersymmetry, and neutrino-related signatures. Advanced detector\ntechnologies and reconstruction techniques, such as one-to-one correspondence\nreconstruction and jet origin identification, significantly improve sensitivity\nto rare and weakly interacting processes. The CEPC is particularly well suited\nto probe the electroweak phase transition and test models of electroweak\nbaryogenesis and dark sector interactions. In addition, global fit analyses\nhighlight the CEPC's complementary role in constraining a wide range of new\nphysics scenarios. These features position the CEPC as a powerful tool for\nexploring the next frontier in fundamental particle physics in the post-Higgs\ndiscovery era.",
    "pdf_url": "http://arxiv.org/pdf/2505.24810v1",
    "published": "2025-05-30T17:15:31+00:00",
    "categories": [
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.24809v1",
    "title": "Ultrafast electron dynamics upon above band-gap excitation in epitaxial LaFeO$_3$(001) thin films",
    "authors": [
      "Friederike Elisa Wührl",
      "Antonia Rieche",
      "Anne Oelschläger",
      "Kathrin Dörr",
      "Wolf Widdra"
    ],
    "abstract": "Strong electron correlations in perovskite oxides give rise to rich and often\nunexpected electronic phenomena. In this study, we present a comprehensive\nsurface-science investigation of epitaxial thin films of the charge-transfer\ninsulator LaFeO$_3$(001). The characterization includes low-energy electron\ndiffraction (LEED), high-resolution electron energy loss spectroscopy (HREELS),\nand photoemission spectroscopy. We map both the occupied and unoccupied\nelectronic states using two-photon photoemission (2PPE) spectroscopy.\nFurthermore, we probe electron dynamics through an ultraviolet-ultraviolet\n(UV-UV) pump-probe experiment, exciting electrons from hybridized O~$2p$/Fe\n$3d$ states to Fe minority-spin states above the band gap. Our results reveal\nthree distinct unoccupied states, which we assign to Fe $t_{2g\\downarrow}$, Fe\n$e_{g\\downarrow}$, and La $5d$ orbitals. Notably, the conduction band minimum\nexhibits a biexponential decay with time constants of 39\\,fs and 1100\\,fs,\nsuggesting the presence of two independent decay pathways.",
    "pdf_url": "http://arxiv.org/pdf/2505.24809v1",
    "published": "2025-05-30T17:15:29+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24808v1",
    "title": "RealDrive: Retrieval-Augmented Driving with Diffusion Models",
    "authors": [
      "Wenhao Ding",
      "Sushant Veer",
      "Yuxiao Chen",
      "Yulong Cao",
      "Chaowei Xiao",
      "Marco Pavone"
    ],
    "abstract": "Learning-based planners generate natural human-like driving behaviors by\nlearning to reason about nuanced interactions from data, overcoming the rigid\nbehaviors that arise from rule-based planners. Nonetheless, data-driven\napproaches often struggle with rare, safety-critical scenarios and offer\nlimited controllability over the generated trajectories. To address these\nchallenges, we propose RealDrive, a Retrieval-Augmented Generation (RAG)\nframework that initializes a diffusion-based planning policy by retrieving the\nmost relevant expert demonstrations from the training dataset. By interpolating\nbetween current observations and retrieved examples through a denoising\nprocess, our approach enables fine-grained control and safe behavior across\ndiverse scenarios, leveraging the strong prior provided by the retrieved\nscenario. Another key insight we produce is that a task-relevant retrieval\nmodel trained with planning-based objectives results in superior planning\nperformance in our framework compared to a task-agnostic retriever.\nExperimental results demonstrate improved generalization to long-tail events\nand enhanced trajectory diversity compared to standard learning-based planners\n-- we observe a 40% reduction in collision rate on the Waymo Open Motion\ndataset with RAG.",
    "pdf_url": "http://arxiv.org/pdf/2505.24808v1",
    "published": "2025-05-30T17:15:03+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24807v1",
    "title": "PySEQM 2.0: Accelerated Semiempirical Excited State Calculations on Graphical Processing Units",
    "authors": [
      "Vishikh Athavale",
      "Nikita Fedik",
      "William Colglazier",
      "Anders M. N. Niklasson",
      "Maksim Kulichenko",
      "Sergei Tretiak"
    ],
    "abstract": "We report the implementation of electronic excited states for semi-empirical\nquantum chemical methods at the configuration interaction singles (CIS) and\ntime-dependent Hartree-Fock (TDHF) level of theory in the PySEQM software.\nBuilt on PyTorch, this implementation leverages GPU acceleration to\nsignificantly speed up molecular property calculations. Benchmark tests\ndemonstrate that our approach can compute excited states for molecules with\nnearly a thousand atoms in under a minute. Additionally, the implementation\nalso includes a machine learning interface to enable parameters re-optimization\nand neural network training for future machine learning applications for\nexcited state dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24807v1",
    "published": "2025-05-30T17:14:43+00:00",
    "categories": [
      "physics.chem-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24806v1",
    "title": "Optimizing Server Load Distribution in Multimedia IoT Environments through LSTM-Based Predictive Algorithms",
    "authors": [
      "Somaye Imanpour",
      "Ahmadreza Montazerolghaem",
      "Saeed Afshari"
    ],
    "abstract": "The Internet of Multimedia Things (IoMT) represents a significant advancement\nin the evolution of IoT technologies, focusing on the transmission and\nmanagement of multimedia streams. As the volume of data continues to surge and\nthe number of connected devices grows exponentially, internet traffic has\nreached unprecedented levels, resulting in challenges such as server overloads\nand deteriorating service quality. Traditional computer network architectures\nwere not designed to accommodate this rapid increase in demand, leading to the\nnecessity for innovative solutions. In response, Software-Defined Networks\n(SDNs) have emerged as a promising framework, offering enhanced management\ncapabilities by decoupling the control layer from the data layer. This study\nexplores the load balancing of servers within software-defined multimedia IoT\nnetworks. The Long Short-Term Memory (LSTM) prediction algorithm is employed to\naccurately estimate server loads and fuzzy systems are integrated to optimize\nload distribution across servers. The findings from the simulations indicate\nthat the proposed approach enhances the optimization and management of IoT\nnetworks, resulting in improved service quality, reduced operational costs, and\nincreased productivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.24806v1",
    "published": "2025-05-30T17:14:34+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24805v1",
    "title": "Input-Power-to-State Stability of Time-Varying Systems",
    "authors": [
      "Hernan Haimovich",
      "Shenyu Liu",
      "Antonio Russo",
      "Jose L. Mancilla-Aguilar"
    ],
    "abstract": "When the state of a system may remain bounded even if both the input\namplitude and energy are unbounded, then the state bounds given by the standard\ninput-to-state stability (ISS) and integral-ISS (iISS) properties may provide\nno useful information. This paper considers an ISS-related concept suitable in\nsuch a case: input-power-to-state stability (IPSS). Necessary and sufficient\nconditions for IPSS are developed for time-varying systems under very mild\nassumptions on the dynamics. More precisely, it is shown that (a) the existence\nof a dissipation-form ISS-Lyapunov function implies IPSS, but not necessarily\nthat of an implication-form one, (b) iISS with exponential class-$\\KL$ function\nimplies IPSS, and (c) ISS and stronger assumptions on the dynamics imply the\nexistence of a dissipation-form ISS-Lyapunov function and hence IPSS. The\nlatter result is based on a converse Lyapunov theorem for time-varying systems\nwhose dynamics (i.e. state derivative) is not necessarily continuous with\nrespect to time.",
    "pdf_url": "http://arxiv.org/pdf/2505.24805v1",
    "published": "2025-05-30T17:09:44+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC",
      "93C10, 93D99"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24804v1",
    "title": "Coordinated Beamforming for RIS-Empowered ISAC Systems over Secure Low-Altitude Networks",
    "authors": [
      "Chunjie Wang",
      "Xuhui Zhang",
      "Wenchao Liu",
      "Jinke Ren",
      "Huijun Xing",
      "Shuqiang Wang",
      "Yanyan Shen"
    ],
    "abstract": "Emerging as a cornerstone for next-generation wireless networks, integrated\nsensing and communication (ISAC) systems demand innovative solutions to balance\nspectral efficiency and sensing accuracy. In this paper, we propose a\ncoordinated beamforming framework for a reconfigurable intelligent surface\n(RIS)-empowered ISAC system, where the active precoding at the dual-functional\nbase station (DFBS) and the passive beamforming at the RIS are jointly\noptimized to provide communication services for legitimate unmanned aerial\nvehicles (UAVs) while sensing the unauthorized UAVs. The sum-rate of all\nlegitimate UAVs are maximized, while satisfying the radar sensing\nsignal-to-noise ratio requirements, the transmit power constraints, and the\nreflection coefficients of the RIS. To address the inherent non-convexity from\ncoupled variables, we propose a low-complexity algorithm integrating fractional\nprogramming with alternating optimization, featuring convergence guarantees.\nNumerical results demonstrate that the proposed algorithm achieves higher data\nrate compared to disjoint optimization benchmarks. This underscores RIS's\npivotal role in harmonizing communication and target sensing functionalities\nfor low-altitude networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24804v1",
    "published": "2025-05-30T17:09:20+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24803v2",
    "title": "Guiding Generative Storytelling with Knowledge Graphs",
    "authors": [
      "Zhijun Pan",
      "Antonios Andronis",
      "Eva Hayek",
      "Oscar AP Wilkinson",
      "Ilya Lasy",
      "Annette Parry",
      "Guy Gadney",
      "Tim J. Smith",
      "Mick Grierson"
    ],
    "abstract": "Large Language Models (LLMs) have shown great potential in automated story\ngeneration, but challenges remain in maintaining long-form coherence and\nproviding users with intuitive and effective control. Retrieval-Augmented\nGeneration (RAG) has proven effective in reducing hallucinations in text\ngeneration; however, the use of structured data to support generative\nstorytelling remains underexplored. This paper investigates how knowledge\ngraphs (KGs) can enhance LLM-based storytelling by improving narrative quality\nand enabling user-driven modifications. We propose a KG-assisted storytelling\npipeline and evaluate its effectiveness through a user study with 15\nparticipants. Participants created their own story prompts, generated stories,\nand edited knowledge graphs to shape their narratives. Through quantitative and\nqualitative analysis, our findings demonstrate that knowledge graphs\nsignificantly enhance story quality in action-oriented and structured\nnarratives within our system settings. Additionally, editing the knowledge\ngraph increases users' sense of control, making storytelling more engaging,\ninteractive, and playful.",
    "pdf_url": "http://arxiv.org/pdf/2505.24803v2",
    "published": "2025-05-30T17:08:21+00:00",
    "categories": [
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24802v1",
    "title": "ByzFL: Research Framework for Robust Federated Learning",
    "authors": [
      "Marc González",
      "Rachid Guerraoui",
      "Rafael Pinot",
      "Geovani Rizk",
      "John Stephan",
      "François Taïani"
    ],
    "abstract": "We present ByzFL, an open-source Python library for developing and\nbenchmarking robust federated learning (FL) algorithms. ByzFL provides a\nunified and extensible framework that includes implementations of\nstate-of-the-art robust aggregators, a suite of configurable attacks, and tools\nfor simulating a variety of FL scenarios, including heterogeneous data\ndistributions, multiple training algorithms, and adversarial threat models. The\nlibrary enables systematic experimentation via a single JSON-based\nconfiguration file and includes built-in utilities for result visualization.\nCompatible with PyTorch tensors and NumPy arrays, ByzFL is designed to\nfacilitate reproducible research and rapid prototyping of robust FL solutions.\nByzFL is available at https://byzfl.epfl.ch/, with source code hosted on\nGitHub: https://github.com/LPD-EPFL/byzfl.",
    "pdf_url": "http://arxiv.org/pdf/2505.24802v1",
    "published": "2025-05-30T17:08:15+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24801v1",
    "title": "Why Academics Are Leaving Twitter for Bluesky",
    "authors": [
      "Dorian Quelle",
      "Frederic Denker",
      "Prashant Garg",
      "Alexandre Bovet"
    ],
    "abstract": "We analyse the migration of 300,000 academic users from Twitter/X to Bluesky\nbetween 2023 and early 2025, combining rich bibliometric data, longitudinal\nsocial-media activity, and a novel cross-platform identity-matching pipeline.\nWe show that 18% of scholars in our sample transitioned, with transition rates\nvarying sharply by discipline, political expression, and Twitter engagement but\nnot by traditional academic metrics. Using time-varying Cox models and a\nmatched-pairs design, we isolate genuine peer influence from homophily. We\nuncover a striking asymmetry whereby information sources drive migration far\nmore powerfully than audience, with this influence decaying exponentially\nwithin a week. We further develop an ego-level contagion classifier, revealing\nthat simple contagion drives two-thirds of all exits, shock-driven bursts\naccount for 16%, and complex contagion plays a marginal role. Finally, we show\nthat scholars who rebuild a higher fraction of their former Twitter networks on\nBluesky remain significantly more active and engaged. Our findings provide new\ninsights onto theories of network externalities, directional influence, and\nplatform migration, highlighting information sources' central role in\novercoming switching costs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24801v1",
    "published": "2025-05-30T17:03:21+00:00",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24800v1",
    "title": "Strong coupling of chiral light with chiral matter: a macroscopic study",
    "authors": [
      "Sergey A. Dyakov",
      "Ilia A. Smagin",
      "Natalia S. Salakhova",
      "Oleg Blokhin",
      "Denis G. Baranov",
      "Ilia M. Fradkin",
      "Nikolay A. Gippius"
    ],
    "abstract": "Maximizing the interaction between chiral light and chiral matter is pivotal\nfor the advancement of technologies enabling optical detection that\ndistinguishes between different handedness in chiral organic molecules. One\nstrategy involves developing a resonator that sustains photonic modes with\nnon-zero electromagnetic handedness, which interact differently with chiral\nmolecules of opposite enantiomers. When chiral molecules are positioned in\nresonator hotspots, they can alter the system's characteristics due to their\ninherent electric and magnetic transition dipole moments. In this study, we\nexplore this interaction by incorporating the Lorentz pole into the macroscopic\nparameters of the chiral medium: dielectric permittivity, magnetic\npermeability, and chirality coefficient. The latter, also known as the Pasteur\nparameter, is a dimensionless macroscopic measure indicating the medium's\nchirality, interlinking electric and magnetic fields in the constitutive\nrelations. We show that introducing the Lorentz pole into these macroscopic\nmaterial parameters of the chiral medium results in chiral strong coupling\nbetween light and matter, with the strength of coupling determined by both the\nmedium's chirality and the photonic mode's chirality.",
    "pdf_url": "http://arxiv.org/pdf/2505.24800v1",
    "published": "2025-05-30T17:03:07+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.other"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24799v2",
    "title": "Beyond Pretty Pictures: Combined Single- and Multi-Image Super-resolution for Sentinel-2 Images",
    "authors": [
      "Aditya Retnanto",
      "Son Le",
      "Sebastian Mueller",
      "Armin Leitner",
      "Michael Riffler",
      "Konrad Schindler",
      "Yohan Iddawela"
    ],
    "abstract": "Super-resolution aims to increase the resolution of satellite images by\nreconstructing high-frequency details, which go beyond na\\\"ive upsampling. This\nhas particular relevance for Earth observation missions like Sentinel-2, which\noffer frequent, regular coverage at no cost; but at coarse resolution. Its\npixel footprint is too large to capture small features like houses, streets, or\nhedge rows. To address this, we present SEN4X, a hybrid super-resolution\narchitecture that combines the advantages of single-image and multi-image\ntechniques. It combines temporal oversampling from repeated Sentinel-2\nacquisitions with a learned prior from high-resolution Pl\\'eiades Neo data. In\ndoing so, SEN4X upgrades Sentinel-2 imagery to 2.5 m ground sampling distance.\nWe test the super-resolved images on urban land-cover classification in Hanoi,\nVietnam. We find that they lead to a significant performance improvement over\nstate-of-the-art super-resolution baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.24799v2",
    "published": "2025-05-30T17:02:56+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24798v1",
    "title": "Accurate grain boundary plane distributions for textured microstructures from stereological analysis of orthogonal two-dimensional electron backscatter diffraction orientation maps",
    "authors": [
      "Martin Folwarczny",
      "Ao Li",
      "Rushvi Shah",
      "Aaron Chote",
      "Alexandra C. Austin",
      "Yimin Zhu",
      "Gregory S. Rohrer",
      "Michael A. Jackson",
      "Souhardh Kotakadi",
      "Katharina Marquardt"
    ],
    "abstract": "We present a method for obtaining qualitatively accurate grain boundary plane\ndistributions (GBPD) for textured microstructures using a stereological\ncalculation applied to two-dimensional electron backscatter diffraction (EBSD)\norientation maps. Stereology, applied to 2D EBSD orientation maps, is currently\nthe fastest method of obtaining GBPDs. Existing stereological methods are not\ndirectly applicable to textured microstructures because of the biased viewing\nperspectives for different grain boundary types supplied from a single planar\norientation map. The method presented in this work successfully removes part of\nthis bias by combining data from three orthogonal EBSD orientation maps for\nstereology. This is shown here to produce qualitatively correct GBPDs for\nheavily textured synthetic microstructures with hexagonal and tetragonal\ncrystal symmetries. Synthetic microstructures were generated to compare the\nstereological GBPD to a known ground truth, as the true GBPD could be obtained\nfrom a triangular mesh of the full grain boundary network in 3D. The triangle\nmesh data contained all five macroscopic parameters to fully describe the grain\nboundary structure. It was observed that our stereological method overestimated\nthe GBPD anisotropy. However, qualitative analysis of the GBPD remains useful.\nFurthermore, it was found that combining data from three orthogonal sections\ngives reliable results when sectioning the texture's primary axes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24798v1",
    "published": "2025-05-30T17:02:44+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.06327v1",
    "title": "Wine Quality Prediction with Ensemble Trees: A Unified, Leak-Free Comparative Study",
    "authors": [
      "Zilang Chen"
    ],
    "abstract": "Accurate and reproducible wine-quality assessment is critical for production\ncontrol yet remains dominated by subjective, labour-intensive tasting panels.\nWe present the first unified benchmark of five ensemble learners (Random\nForest, Gradient Boosting, XGBoost, LightGBM, CatBoost) on the canonical Vinho\nVerde red- and white-wine datasets (1,599 and 4,898 instances, 11\nphysicochemical attributes). Our leakage-free workflow employs an 80:20\nstratified train-test split, five-fold StratifiedGroupKFold within the training\nset, per-fold standardisation, SMOTE-Tomek resampling, inverse-frequency cost\nweighting, Optuna hyper-parameter search (120-200 trials per model) and a\ntwo-stage feature-selection refit. Final scores on untouched test sets are\nreported with weighted F1 as the headline metric. Gradient Boosting achieves\nthe highest accuracy (weighted F1 0.693 +/- 0.028 for red and 0.664 +/- 0.016\nfor white), followed within three percentage points by Random Forest and\nXGBoost. Limiting each model to its five top-ranked variables lowers\ndimensionality by 55 percent while reducing weighted F1 by only 2.6 percentage\npoints for red and 3.0 percentage points for white, indicating that alcohol,\nvolatile acidity, sulphates, free SO2 and chlorides capture most predictive\nsignal. Runtime profiling on an EPYC 9K84/H20 node reveals a steep efficiency\ngradient: Gradient Boosting averages 12 h per five-fold study, XGBoost and\nLightGBM require 2-3 h, CatBoost 1 h, and Random Forest under 50 min. We\ntherefore recommend Random Forest as the most cost-effective production model,\nXGBoost and LightGBM as GPU-efficient alternatives, and Gradient Boosting as\nthe accuracy ceiling for offline benchmarking. The fully documented pipeline\nand metric set provide a reproducible baseline for future work on imbalanced\nmulti-class wine-quality prediction.",
    "pdf_url": "http://arxiv.org/pdf/2506.06327v1",
    "published": "2025-05-30T17:02:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24797v1",
    "title": "Search for a new 17 MeV resonance via $e^+e^-$ annihilation with the PADME Experiment",
    "authors": [
      "F. Bossi",
      "R. De Sangro",
      "C. Di Giulio",
      "E. Di Meco",
      "D. Domenici",
      "G. Finocchiaro",
      "L. G. Foggetta",
      "M. Garattini",
      "P. Gianotti",
      "M. Mancini",
      "I. Sarra",
      "T. Spadaro",
      "C. Taruggi",
      "E. Vilucchi",
      "K. Dimitrova",
      "S. Ivanov",
      "Sv. Ivanov",
      "K. Kostova",
      "V. Kozhuharov",
      "R. Simeonov",
      "F. Ferrarotto",
      "E. Leonardi",
      "P. Valente",
      "E. Long",
      "G. C. Organtini",
      "M. Raggi",
      "A. Frankenthal"
    ],
    "abstract": "The PADME Experiment at the Frascati DA$\\Phi$NE LINAC has searched for a\nhypothetical particle with mass around 17 MeV, commonly referred to as the X17,\nusing a positron beam incident on a fixed target. The beam energy was varied\nbetween 262 and 296 MeV, corresponding to center-of-mass energies $\\sqrt{s}$\nbetween 16.4 and 17.4 MeV. The X17 should be produced resonantly via $e^+e^-$\nannihilation when $\\sqrt{s}$ approaches its mass, inducing an excess of events\nwith a two-body final state over the background expectation. The beam energy\nspacing was fixed to less than half the expected width of the resonance's line\nshape. Uncertainties below 1% per $\\sqrt{s}$ point were achieved. A blind\nanalysis has been performed. The data are consistent with the expected\nbackground in most of the explored energy range, and limits are set in\npreviously unexplored regions of the available parameter space. The most\nsignificant deviation is found for $\\sqrt{s} \\approx 16.90$ MeV, corresponding\nto a global significance of approximately 2 standard deviations over the null\nhypothesis expectation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24797v1",
    "published": "2025-05-30T17:01:50+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.24796v1",
    "title": "TC-GS: A Faster Gaussian Splatting Module Utilizing Tensor Cores",
    "authors": [
      "Zimu Liao",
      "Jifeng Ding",
      "Rong Fu",
      "Siwei Cui",
      "Ruixuan Gong",
      "Li Wang",
      "Boni Hu",
      "Yi Wang",
      "Hengjie Li",
      "XIngcheng Zhang",
      "Hui Wang"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) renders pixels by rasterizing Gaussian\nprimitives, where conditional alpha-blending dominates the time cost in the\nrendering pipeline. This paper proposes TC-GS, an algorithm-independent\nuniversal module that expands Tensor Core (TCU) applicability for 3DGS, leading\nto substantial speedups and seamless integration into existing 3DGS\noptimization frameworks. The key innovation lies in mapping alpha computation\nto matrix multiplication, fully utilizing otherwise idle TCUs in existing 3DGS\nimplementations. TC-GS provides plug-and-play acceleration for existing\ntop-tier acceleration algorithms tightly coupled with rendering pipeline\ndesigns, like Gaussian compression and redundancy elimination algorithms.\nAdditionally, we introduce a global-to-local coordinate transformation to\nmitigate rounding errors from quadratic terms of pixel coordinates caused by\nTensor Core half-precision computation. Extensive experiments demonstrate that\nour method maintains rendering quality while providing an additional 2.18x\nspeedup over existing Gaussian acceleration algorithms, thus reaching up to a\ntotal 5.6x acceleration. The code is currently available at anonymous\n\\href{https://github.com/TensorCore3DGS/3DGSTensorCore}",
    "pdf_url": "http://arxiv.org/pdf/2505.24796v1",
    "published": "2025-05-30T16:58:18+00:00",
    "categories": [
      "cs.GR",
      "cs.CV",
      "cs.DC",
      "I.3.6; I.3.2; D.1.3"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00107v1",
    "title": "Gated Multimodal Graph Learning for Personalized Recommendation",
    "authors": [
      "Sibei Liu",
      "Yuanzhe Zhang",
      "Xiang Li",
      "Yunbo Liu",
      "Chengwei Feng",
      "Hao Yang"
    ],
    "abstract": "Multimodal recommendation has emerged as a promising solution to alleviate\nthe cold-start and sparsity problems in collaborative filtering by\nincorporating rich content information, such as product images and textual\ndescriptions. However, effectively integrating heterogeneous modalities into a\nunified recommendation framework remains a challenge. Existing approaches often\nrely on fixed fusion strategies or complex architectures , which may fail to\nadapt to modality quality variance or introduce unnecessary computational\noverhead.\n  In this work, we propose RLMultimodalRec, a lightweight and modular\nrecommendation framework that combines graph-based user modeling with adaptive\nmultimodal item encoding. The model employs a gated fusion module to\ndynamically balance the contribution of visual and textual modalities, enabling\nfine-grained and content-aware item representations. Meanwhile, a two-layer\nLightGCN encoder captures high-order collaborative signals by propagating\nembeddings over the user-item interaction graph without relying on nonlinear\ntransformations.\n  We evaluate our model on a real-world dataset from the Amazon product domain.\nExperimental results demonstrate that RLMultimodalRec consistently outperforms\nseveral competitive baselines, including collaborative filtering, visual-aware,\nand multimodal GNN-based methods. The proposed approach achieves significant\nimprovements in top-K recommendation metrics while maintaining scalability and\ninterpretability, making it suitable for practical deployment.",
    "pdf_url": "http://arxiv.org/pdf/2506.00107v1",
    "published": "2025-05-30T16:57:17+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24795v1",
    "title": "Early warning signals in rumor models",
    "authors": [
      "Eva Rifà",
      "Julian Vicens",
      "Emanuele Cozzo"
    ],
    "abstract": "We study the emission and control of a rumor using the modified Maki-Thomson\nmodel. A key challenge in social networks is distinguishing between natural\nincreases in transmissibility and artificial injections of rumor spreaders,\nsuch as through broadcast events or astroturfing. Using stochastic simulations,\nwe compare two scenarios: one with organic growth in transmissibility, and\nanother with externally injected spreaders. Although both lead to high\nautocorrelation, only the organic growth produces oscillatory patterns in\nautocorrelation at multiple lags, an effect we can analytically explain using\nthe N-intertwined mean-field (NIMFA) approximation. This distinction offers a\npractical tool to identify the origin of rumor virality and also infer its\ntransmissibility. Our approach is validated analytically and tested on\nreal-world data from Twitter during the announcement of the Higgs boson\ndiscovery. In addition to detection, we also explore control strategies. We\nshow that the average lifetime of a rumor can be manipulated through targeted\ninterventions: placing spreaders at specific locations in the network.\nDepending on their placement, these interventions can either extend or shorten\nthe lifespan of the rumor.",
    "pdf_url": "http://arxiv.org/pdf/2505.24795v1",
    "published": "2025-05-30T16:56:47+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24794v1",
    "title": "Cardinalities of the total number of independent sets",
    "authors": [
      "Benedek Kovács",
      "Zoltán Lóránt Nagy"
    ],
    "abstract": "We study the set of numbers the total number of independent sets can admit in\n$n$-vertex graphs. In this paper, we prove that the cardinality of this set\n$\\mathcal{N}i(n)$ is very close to $2^n$ in the following sense:\n$\\mathcal{N}i(n)/2^n = O(n^{-1/5})$ while for infinitely many $n$, we have\n$\\log_2(\\mathcal{N}i(n)/2^n)\\ge -2^{(1+o(1)\\sqrt{\\log_2 n}}$. This set is also\nprecisely the set of possible values of the independence polynomial $I_G(x)$ at\n$x=1$ for $n$-vertex graphs $G$. As an application, we address an additive\ncombinatorial problem on subsets of a given vector space that avoid certain\nintersection patterns with respect to subspaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.24794v1",
    "published": "2025-05-30T16:56:33+00:00",
    "categories": [
      "math.CO",
      "05C69 (Primary) 05C30, 05C31, 05C76, 51E21 (Secondary)"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24793v2",
    "title": "AFIRE: Accurate and Fast Image Reconstruction Algorithm for Geometric-inconsistent Multispectral CT",
    "authors": [
      "Yu Gao",
      "Chong Chen"
    ],
    "abstract": "For nonlinear multispectral computed tomography (CT), accurate and fast image\nreconstruction is challenging when the scanning geometries under different\nX-ray energy spectra are inconsistent or mismatched. Motivated by this, we\npropose an Accurate and Fast Image REconstruction (AFIRE) algorithm to address\nsuch problems in the case of mildly full scan. From the continuous (resp.\ndiscrete) setting, we discover that the derivative operator (gradient) of the\ninvolved nonlinear mapping at some special points, for example, at zero, can be\nrepresented as a composition (block multiplication) of a diagonal operator\n(matrix) composed of X-ray transforms (projection matrices) and a very\nsmall-scale matrix. Based on these insights, the AFIRE algorithm is proposed by\nleveraging the simplified Newton method. Under proper conditions, we establish\nthe convergence theory of the proposed algorithm. Furthermore, numerical\nexperiments are also carried out to verify that the proposed algorithm can\naccurately and effectively reconstruct the basis images in completely\ngeometric-inconsistent dual-energy CT with noiseless and noisy projection data.\nParticularly, the proposed algorithm significantly outperforms some\nstate-of-the-art methods in terms of accuracy and efficiency. Finally, the\nflexibility and extensibility of the proposed algorithm are also demonstrated.",
    "pdf_url": "http://arxiv.org/pdf/2505.24793v2",
    "published": "2025-05-30T16:55:23+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.med-ph",
      "65J15, 65R32, 65J22, 68U10"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24792v1",
    "title": "Lightweight Relational Embedding in Task-Interpolated Few-Shot Networks for Enhanced Gastrointestinal Disease Classification",
    "authors": [
      "Xinliu Zhong",
      "Leo Hwa Liang",
      "Angela S. Koh",
      "Yeo Si Yong"
    ],
    "abstract": "Traditional diagnostic methods like colonoscopy are invasive yet critical\ntools necessary for accurately diagnosing colorectal cancer (CRC). Detection of\nCRC at early stages is crucial for increasing patient survival rates. However,\ncolonoscopy is dependent on obtaining adequate and high-quality endoscopic\nimages. Prolonged invasive procedures are inherently risky for patients, while\nsuboptimal or insufficient images hamper diagnostic accuracy. These images,\ntypically derived from video frames, often exhibit similar patterns, posing\nchallenges in discrimination. To overcome these challenges, we propose a novel\nDeep Learning network built on a Few-Shot Learning architecture, which includes\na tailored feature extractor, task interpolation, relational embedding, and a\nbi-level routing attention mechanism. The Few-Shot Learning paradigm enables\nour model to rapidly adapt to unseen fine-grained endoscopic image patterns,\nand the task interpolation augments the insufficient images artificially from\nvaried instrument viewpoints. Our relational embedding approach discerns\ncritical intra-image features and captures inter-image transitions between\nconsecutive endoscopic frames, overcoming the limitations of Convolutional\nNeural Networks (CNNs). The integration of a light-weight attention mechanism\nensures a concentrated analysis of pertinent image regions. By training on\ndiverse datasets, the model's generalizability and robustness are notably\nimproved for handling endoscopic images. Evaluated on Kvasir dataset, our model\ndemonstrated superior performance, achieving an accuracy of 90.1\\%, precision\nof 0.845, recall of 0.942, and an F1 score of 0.891. This surpasses current\nstate-of-the-art methods, presenting a promising solution to the challenges of\ninvasive colonoscopy by optimizing CRC detection through advanced image\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.24792v1",
    "published": "2025-05-30T16:54:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24791v1",
    "title": "Inference Acceleration of Autoregressive Normalizing Flows by Selective Jacobi Decoding",
    "authors": [
      "Jiaru Zhang",
      "Juanwu Lu",
      "Ziran Wang",
      "Ruqi Zhang"
    ],
    "abstract": "Normalizing flows are promising generative models with advantages such as\ntheoretical rigor, analytical log-likelihood computation, and end-to-end\ntraining. However, the architectural constraints to ensure invertibility and\ntractable Jacobian computation limit their expressive power and practical\nusability. Recent advancements utilize autoregressive modeling, significantly\nenhancing expressive power and generation quality. However, such sequential\nmodeling inherently restricts parallel computation during inference, leading to\nslow generation that impedes practical deployment. In this paper, we first\nidentify that strict sequential dependency in inference is unnecessary to\ngenerate high-quality samples. We observe that patches in sequential modeling\ncan also be approximated without strictly conditioning on all preceding\npatches. Moreover, the models tend to exhibit low dependency redundancy in the\ninitial layer and higher redundancy in subsequent layers. Leveraging these\nobservations, we propose a selective Jacobi decoding (SeJD) strategy that\naccelerates autoregressive inference through parallel iterative optimization.\nTheoretical analyses demonstrate the method's superlinear convergence rate and\nguarantee that the number of iterations required is no greater than the\noriginal sequential approach. Empirical evaluations across multiple datasets\nvalidate the generality and effectiveness of our acceleration technique.\nExperiments demonstrate substantial speed improvements up to 4.7 times faster\ninference while keeping the generation quality and fidelity.",
    "pdf_url": "http://arxiv.org/pdf/2505.24791v1",
    "published": "2025-05-30T16:53:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24790v1",
    "title": "Towards model-based design of causal manipulations of brain circuits with high spatiotemporal precision",
    "authors": [
      "Anandita De",
      "Roozbeh Kiani",
      "Luca Mazzucato"
    ],
    "abstract": "Recent advancements in neurotechnology enable precise spatiotemporal patterns\nof microstimulations with single-cell resolution. The choice of perturbation\nsites must satisfy two key criteria: efficacy in evoking significant responses\nand selectivity for the desired target effects. This choice is currently based\non laborious trial-and-error procedures, unfeasible for sequences of multi-site\nstimulations. Efficient methods to design complex perturbation patterns are\nurgently needed. Can we design a spatiotemporal pattern of stimulation to steer\nneural activity and behavior towards a desired target? We outline a method for\nachieving this goal in two steps. First, we identify the most effective\nperturbation sites, or hubs, only based on short observations of spontaneous\nneural activity. Second, we provide an efficient method to design multi-site\nstimulation patterns by combining approaches from nonlinear dynamical systems,\ncontrol theory and data-driven methods. We demonstrate the feasibility of our\napproach using multi-site stimulation patterns in recurrent network models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24790v1",
    "published": "2025-05-30T16:52:44+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24789v1",
    "title": "The effects of the spin and quadrupole moment of SgrA* on the orbits of S stars",
    "authors": [
      "K. Abd El Dayem",
      "F. H. Vincent",
      "G. Heissel",
      "T. Paumard",
      "G. Perrin"
    ],
    "abstract": "Measuring the astrometric and spectroscopic data of stars orbiting the\ncentral black hole in our galaxy (Sgr A*) offers a promising way to measure\nrelativistic effects. In principle, the \"no-hair\" theorem can be tested at the\nGalactic Center by monitoring the orbital precession of S-stars due to the\nangular momentum (spin) and quadrupole moment of Sgr A*. Closer-in stars, more\nstrongly affected by the black hole's rotation, may be required. GRAVITY+ could\ndetect such stars that are currently too faint for GRAVITY. We aim to\nanalytically and numerically characterize orbital reorientations induced by\nspin-related effects of Sgr A* up to the second post-Newtonian (2PN) order. We\nuse the two-timescale method to derive the 2PN analytical expressions of the\nsecular evolution of the orbital parameters that are related to the observer.\nTo study the interaction between the orbital and spin orientations, we\nintroduce observer-independent quantities that offer insight into the Kerr\ngeometry. We also use the post-Newtonian code OOGRE to simulate hypothetical\nstars orbiting closer to Sgr A*, where spin and quadrupole effects are\nstronger. This enables comparison with our analytical predictions. We exhibit\nthree orbital-timescale precession rates that encode the in-plane pericenter\nshift and the out-of-plane redirection of the osculating ellipse. We provide\nthe 2PN expressions of these precession rates and express the orbit-integrated\nassociated angular shifts of the pericenter and of the ellipse axes. We relate\nthese orbital-timescale precession rates to the secular-timescale precession of\nthe orbital angular momentum around the black hole spin axis. We consider that\nthe theoretical insight we provide in this article will be useful in\nconstraining the spin effect of Sgr A* with GRAVITY+ observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24789v1",
    "published": "2025-05-30T16:48:40+00:00",
    "categories": [
      "astro-ph.GA",
      "gr-qc"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24788v1",
    "title": "Drop Dropout on Single-Epoch Language Model Pretraining",
    "authors": [
      "Houjun Liu",
      "John Bauer",
      "Christopher D. Manning"
    ],
    "abstract": "Originally, dropout was seen as a breakthrough regularization technique that\nreduced overfitting and improved performance in almost all applications of deep\nlearning by reducing overfitting. Yet, single-epoch pretraining tasks common to\nmodern LLMs yield minimal overfitting, leading to dropout not being used for\nlarge LLMs. Nevertheless, no thorough empirical investigation has been done on\nthe role of dropout in LM pretraining. Through experiments in single-epoch\npretraining of both masked (BERT) and autoregressive (Pythia 160M and 1.4B) LMs\nwith varying levels of dropout, we find that downstream performance in language\nmodeling, morpho-syntax (BLiMP), question answering (SQuAD), and\nnatural-language inference (MNLI) improves when dropout is not applied during\npretraining. We additionally find that the recently-introduced \"early dropout\"\nalso degrades performance over applying no dropout at all. We further\ninvestigate the models' editability, and find that models trained without\ndropout are more successful in gradient-based model editing (MEND) and\nequivalent in representation-based model editing (ReFT). Therefore, we advocate\nto drop dropout during single-epoch pretraining.",
    "pdf_url": "http://arxiv.org/pdf/2505.24788v1",
    "published": "2025-05-30T16:48:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24787v1",
    "title": "Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for Complex Instruction-based Image Generation",
    "authors": [
      "Yucheng Zhou",
      "Jiahao Yuan",
      "Qianning Wang"
    ],
    "abstract": "Recent advancements in text-to-image (T2I) generation have enabled models to\nproduce high-quality images from textual descriptions. However, these models\noften struggle with complex instructions involving multiple objects,\nattributes, and spatial relationships. Existing benchmarks for evaluating T2I\nmodels primarily focus on general text-image alignment and fail to capture the\nnuanced requirements of complex, multi-faceted prompts. Given this gap, we\nintroduce LongBench-T2I, a comprehensive benchmark specifically designed to\nevaluate T2I models under complex instructions. LongBench-T2I consists of 500\nintricately designed prompts spanning nine diverse visual evaluation\ndimensions, enabling a thorough assessment of a model's ability to follow\ncomplex instructions. Beyond benchmarking, we propose an agent framework\n(Plan2Gen) that facilitates complex instruction-driven image generation without\nrequiring additional model training. This framework integrates seamlessly with\nexisting T2I models, using large language models to interpret and decompose\ncomplex prompts, thereby guiding the generation process more effectively. As\nexisting evaluation metrics, such as CLIPScore, fail to adequately capture the\nnuances of complex instructions, we introduce an evaluation toolkit that\nautomates the quality assessment of generated images using a set of\nmulti-dimensional metrics. The data and code are released at\nhttps://github.com/yczhou001/LongBench-T2I.",
    "pdf_url": "http://arxiv.org/pdf/2505.24787v1",
    "published": "2025-05-30T16:48:14+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24786v1",
    "title": "DiG-Net: Enhancing Quality of Life through Hyper-Range Dynamic Gesture Recognition in Assistive Robotics",
    "authors": [
      "Eran Bamani Beeri",
      "Eden Nissinman",
      "Avishai Sintov"
    ],
    "abstract": "Dynamic hand gestures play a pivotal role in assistive human-robot\ninteraction (HRI), facilitating intuitive, non-verbal communication,\nparticularly for individuals with mobility constraints or those operating\nrobots remotely. Current gesture recognition methods are mostly limited to\nshort-range interactions, reducing their utility in scenarios demanding robust\nassistive communication from afar. In this paper, we introduce a novel approach\ndesigned specifically for assistive robotics, enabling dynamic gesture\nrecognition at extended distances of up to 30 meters, thereby significantly\nimproving accessibility and quality of life. Our proposed Distance-aware\nGesture Network (DiG-Net) effectively combines Depth-Conditioned Deformable\nAlignment (DADA) blocks with Spatio-Temporal Graph modules, enabling robust\nprocessing and classification of gesture sequences captured under challenging\nconditions, including significant physical attenuation, reduced resolution, and\ndynamic gesture variations commonly experienced in real-world assistive\nenvironments. We further introduce the Radiometric Spatio-Temporal Depth\nAttenuation Loss (RSTDAL), shown to enhance learning and strengthen model\nrobustness across varying distances. Our model demonstrates significant\nperformance improvement over state-of-the-art gesture recognition frameworks,\nachieving a recognition accuracy of 97.3% on a diverse dataset with challenging\nhyper-range gestures. By effectively interpreting gestures from considerable\ndistances, DiG-Net significantly enhances the usability of assistive robots in\nhome healthcare, industrial safety, and remote assistance scenarios, enabling\nseamless and intuitive interactions for users regardless of physical\nlimitations",
    "pdf_url": "http://arxiv.org/pdf/2505.24786v1",
    "published": "2025-05-30T16:47:44+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24785v2",
    "title": "EXP-Bench: Can AI Conduct AI Research Experiments?",
    "authors": [
      "Patrick Tser Jern Kon",
      "Jiachen Liu",
      "Xinyi Zhu",
      "Qiuyi Ding",
      "Jingjia Peng",
      "Jiarong Xing",
      "Yibo Huang",
      "Yiming Qiu",
      "Jayanth Srinivasa",
      "Myungjin Lee",
      "Mosharaf Chowdhury",
      "Matei Zaharia",
      "Ang Chen"
    ],
    "abstract": "Automating AI research holds immense potential for accelerating scientific\nprogress, yet current AI agents struggle with the complexities of rigorous,\nend-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed\nto systematically evaluate AI agents on complete research experiments sourced\nfrom influential AI publications. Given a research question and incomplete\nstarter code, EXP-Bench challenges AI agents to formulate hypotheses, design\nand implement experimental procedures, execute them, and analyze results. To\nenable the creation of such intricate and authentic tasks with high-fidelity,\nwe design a semi-autonomous pipeline to extract and structure crucial\nexperimental details from these research papers and their associated\nopen-source code. With the pipeline, EXP-Bench curated 461 AI research tasks\nfrom 51 top-tier AI research papers. Evaluations of leading LLM-based agents,\nsuch as OpenHands and IterativeAgent on EXP-Bench demonstrate partial\ncapabilities: while scores on individual experimental aspects such as design or\nimplementation correctness occasionally reach 20-35%, the success rate for\ncomplete, executable experiments was a mere 0.5%. By identifying these\nbottlenecks and providing realistic step-by-step experiment procedures,\nEXP-Bench serves as a vital tool for future AI agents to improve their ability\nto conduct AI research experiments. EXP-Bench is open-sourced at\nhttps://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench.",
    "pdf_url": "http://arxiv.org/pdf/2505.24785v2",
    "published": "2025-05-30T16:46:29+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24784v1",
    "title": "AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models",
    "authors": [
      "Conor Heins",
      "Toon Van de Maele",
      "Alexander Tschantz",
      "Hampus Linander",
      "Dimitrije Markovic",
      "Tommaso Salvatori",
      "Corrado Pezzato",
      "Ozan Catal",
      "Ran Wei",
      "Magnus Koudahl",
      "Marco Perin",
      "Karl Friston",
      "Tim Verbelen",
      "Christopher Buckley"
    ],
    "abstract": "Current deep reinforcement learning (DRL) approaches achieve state-of-the-art\nperformance in various domains, but struggle with data efficiency compared to\nhuman learning, which leverages core priors about objects and their\ninteractions. Active inference offers a principled framework for integrating\nsensory information with prior knowledge to learn a world model and quantify\nthe uncertainty of its own beliefs and predictions. However, active inference\nmodels are usually crafted for a single task with bespoke knowledge, so they\nlack the domain flexibility typical of DRL approaches. To bridge this gap, we\npropose a novel architecture that integrates a minimal yet expressive set of\ncore priors about object-centric dynamics and interactions to accelerate\nlearning in low-data regimes. The resulting approach, which we call AXIOM,\ncombines the usual data efficiency and interpretability of Bayesian approaches\nwith the across-task generalization usually associated with DRL. AXIOM\nrepresents scenes as compositions of objects, whose dynamics are modeled as\npiecewise linear trajectories that capture sparse object-object interactions.\nThe structure of the generative model is expanded online by growing and\nlearning mixture models from single events and periodically refined through\nBayesian model reduction to induce generalization. AXIOM masters various games\nwithin only 10,000 interaction steps, with both a small number of parameters\ncompared to DRL, and without the computational expense of gradient-based\noptimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.24784v1",
    "published": "2025-05-30T16:46:20+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24783v1",
    "title": "Paired comparison models with strength-dependent ties and order effects",
    "authors": [
      "Mark E. Glickman"
    ],
    "abstract": "Paired comparison models, such as the Bradley-Terry (1952) model and its\nvariants, are commonly used to measure competitor strength in games and sports.\nExtensions have been proposed to account for order effects (e.g., home-field\nadvantage) as well as the possibility of a tie as a separate outcome, but such\nmodels are rarely adopted in practice due to poor fit with actual data. We\npropose a novel paired comparison model that accounts not only for ties and\norder effects, but recognizes two phenomena that are not addressed with\ncommonly used models. First, the probability of a tie may be greater for\nstronger pairs of competitors. Second, order effects may be more pronounced for\nstronger competitors. This model is motivated in the context of tournament\nchess game outcomes. The models are demonstrated on the results of US Chess\nOpen game outcomes from 2006 to 2019, large tournaments consisting of players\nof wide-ranging strengths.",
    "pdf_url": "http://arxiv.org/pdf/2505.24783v1",
    "published": "2025-05-30T16:45:37+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24782v2",
    "title": "Context is Gold to find the Gold Passage: Evaluating and Training Contextual Document Embeddings",
    "authors": [
      "Max Conti",
      "Manuel Faysse",
      "Gautier Viaud",
      "Antoine Bosselut",
      "Céline Hudelot",
      "Pierre Colombo"
    ],
    "abstract": "A limitation of modern document retrieval embedding methods is that they\ntypically encode passages (chunks) from the same documents independently, often\noverlooking crucial contextual information from the rest of the document that\ncould greatly improve individual chunk representations.\n  In this work, we introduce ConTEB (Context-aware Text Embedding Benchmark), a\nbenchmark designed to evaluate retrieval models on their ability to leverage\ndocument-wide context. Our results show that state-of-the-art embedding models\nstruggle in retrieval scenarios where context is required. To address this\nlimitation, we propose InSeNT (In-sequence Negative Training), a novel\ncontrastive post-training approach which combined with late chunking pooling\nenhances contextual representation learning while preserving computational\nefficiency. Our method significantly improves retrieval quality on ConTEB\nwithout sacrificing base model performance. We further find chunks embedded\nwith our method are more robust to suboptimal chunking strategies and larger\nretrieval corpus sizes. We open-source all artifacts at\nhttps://github.com/illuin-tech/contextual-embeddings.",
    "pdf_url": "http://arxiv.org/pdf/2505.24782v2",
    "published": "2025-05-30T16:43:28+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24781v1",
    "title": "Efficient Estimation of Regularized Tyler's M-Estimator Using Approximate LOOCV",
    "authors": [
      "Karim Abou-Moustafa"
    ],
    "abstract": "We consider the problem of estimating a regularization parameter, or a\nshrinkage coefficient $\\alpha \\in (0,1)$ for Regularized Tyler's M-estimator\n(RTME). In particular, we propose to estimate an optimal shrinkage coefficient\nby setting $\\alpha$ as the solution to a suitably chosen objective function;\nnamely the leave-one-out cross-validated (LOOCV) log-likelihood loss. Since\nLOOCV is computationally prohibitive even for moderate sample size $n$, we\npropose a computationally efficient approximation for the LOOCV log-likelihood\nloss that eliminates the need for invoking the RTME procedure $n$ times for\neach sample left out during the LOOCV procedure. This approximation yields an\n$O(n)$ reduction in the running time complexity for the LOOCV procedure, which\nresults in a significant speedup for computing the LOOCV estimate. We\ndemonstrate the efficiency and accuracy of the proposed approach on synthetic\nhigh-dimensional data sampled from heavy-tailed elliptical distributions, as\nwell as on real high-dimensional datasets for object recognition, face\nrecognition, and handwritten digit's recognition. Our experiments show that the\nproposed approach is efficient and consistently more accurate than other\nmethods in the literature for shrinkage coefficient estimation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24781v1",
    "published": "2025-05-30T16:43:14+00:00",
    "categories": [
      "stat.ML",
      "cs.CE",
      "cs.CV",
      "cs.LG",
      "eess.SP",
      "I.2.0; I.2.6"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24780v1",
    "title": "QGAN-based data augmentation for hybrid quantum-classical neural networks",
    "authors": [
      "Run-Ze He",
      "Jun-Jian Su",
      "Su-Juan Qin",
      "Zheng-Ping Jin",
      "Fei Gao"
    ],
    "abstract": "Quantum neural networks converge faster and achieve higher accuracy than\nclassical models. However, data augmentation in quantum machine learning\nremains underexplored. To tackle data scarcity, we integrate quantum generative\nadversarial networks (QGANs) with hybrid quantum-classical neural networks\n(HQCNNs) to develop an augmentation framework. We propose two strategies: a\ngeneral approach to enhance data processing and classification across HQCNNs,\nand a customized strategy that dynamically generates samples tailored to the\nHQCNN's performance on specific data categories, improving its ability to learn\nfrom complex datasets. Simulation experiments on the MNIST dataset demonstrate\nthat QGAN outperforms traditional data augmentation methods and classical GANs.\nCompared to baseline DCGAN, QGAN achieves comparable performance with half the\nparameters, balancing efficiency and effectiveness. This suggests that QGANs\ncan simplify models and generate high-quality data, enhancing HQCNN accuracy\nand performance. These findings pave the way for applying quantum data\naugmentation techniques in machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.24780v1",
    "published": "2025-05-30T16:42:31+00:00",
    "categories": [
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24779v2",
    "title": "EVA-MILP: Towards Standardized Evaluation of MILP Instance Generation",
    "authors": [
      "Yidong Luo",
      "Chenguang Wang",
      "Jiahao Yang",
      "Fanzeng Xia",
      "Tianshu Yu"
    ],
    "abstract": "Mixed-Integer Linear Programming (MILP) is fundamental to solving complex\ndecision-making problems. The proliferation of MILP instance generation\nmethods, driven by machine learning's demand for diverse optimization datasets\nand the limitations of static benchmarks, has significantly outpaced\nstandardized evaluation techniques. Consequently, assessing the fidelity and\nutility of synthetic MILP instances remains a critical, multifaceted challenge.\nThis paper introduces a comprehensive benchmark framework designed for the\nsystematic and objective evaluation of MILP instance generation methods. Our\nframework provides a unified and extensible methodology, assessing instance\nquality across crucial dimensions: mathematical validity, structural\nsimilarity, computational hardness, and utility in downstream machine learning\ntasks. A key innovation is its in-depth analysis of solver-internal features --\nparticularly by comparing distributions of key solver outputs including root\nnode gap, heuristic success rates, and cut plane usage -- leveraging the\nsolver's dynamic solution behavior as an `expert assessment' to reveal nuanced\ncomputational resemblances. By offering a structured approach with clearly\ndefined solver-independent and solver-dependent metrics, our benchmark aims to\nfacilitate robust comparisons among diverse generation techniques, spur the\ndevelopment of higher-quality instance generators, and ultimately enhance the\nreliability of research reliant on synthetic MILP data. The framework's\neffectiveness in systematically comparing the fidelity of instance sets is\ndemonstrated using contemporary generative models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24779v2",
    "published": "2025-05-30T16:42:15+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24778v2",
    "title": "Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?",
    "authors": [
      "Jiayu Liu",
      "Qing Zong",
      "Weiqi Wang",
      "Yangqiu Song"
    ],
    "abstract": "As large language models (LLMs) are increasingly used in high-stakes domains,\naccurately assessing their confidence is crucial. Humans typically express\nconfidence through epistemic markers (e.g., \"fairly confident\") instead of\nnumerical values. However, it remains unclear whether LLMs consistently use\nthese markers to reflect their intrinsic confidence due to the difficulty of\nquantifying uncertainty associated with various markers. To address this gap,\nwe first define marker confidence as the observed accuracy when a model employs\nan epistemic marker. We evaluate its stability across multiple\nquestion-answering datasets in both in-distribution and out-of-distribution\nsettings for open-source and proprietary LLMs. Our results show that while\nmarkers generalize well within the same distribution, their confidence is\ninconsistent in out-of-distribution scenarios. These findings raise significant\nconcerns about the reliability of epistemic markers for confidence estimation,\nunderscoring the need for improved alignment between marker based confidence\nand actual model uncertainty. Our code is available at\nhttps://github.com/HKUST-KnowComp/MarCon.",
    "pdf_url": "http://arxiv.org/pdf/2505.24778v2",
    "published": "2025-05-30T16:41:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24777v1",
    "title": "Emergent boundary supersymmetry in a one dimensional superconductor",
    "authors": [
      "Parameshwar R. Pasnoori",
      "Patrick Azaria",
      "Colin Rylands",
      "Natan Andrei"
    ],
    "abstract": "The interplay between bulk properties and boundary conditions in\none-dimensional quantum systems, gives rise to many intriguing phenomena. These\ninclude the emergence of zero energy modes which are of significant interest to\na variety of fields. In this work we investigate the presence of such zero\nmodes in cases where the boundary conditions are dynamical and arise due to the\ncoupling to some quantum degrees of freedom. In particular, we study a\none-dimensional spin-singlet superconductor, modeled by the Gross-Neveu field\ntheory, coupled to spin $\\frac{1}{2}$ magnetic impurities at its boundaries via\na spin-exchange interaction. We solve the model exactly for arbitrary values of\nthe bulk and the impurity coupling strengths using nested coordinate Bethe\nansatz and show that the system exhibits a rich boundary phase structure. For a\nrange of couplings, the low energy degrees of freedom form irreducible\nrepresentations of the supersymmetric $spl(2,1)\\otimes spl(2,1)$ algebra which\nbecome degenerate at a specific point, indicating the emergence of\nsupersymmetry in the low energy boundary degrees of freedom. We show that at\nthe supersymmetric point there exist exact zero energy modes that map one\nground state with the other. We express these in terms of the generators of the\nalgebra.",
    "pdf_url": "http://arxiv.org/pdf/2505.24777v1",
    "published": "2025-05-30T16:40:28+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.24776v1",
    "title": "Diffusion-Based Symbolic Regression",
    "authors": [
      "Zachary Bastiani",
      "Robert M. Kirby",
      "Jacob Hochhalter",
      "Shandian Zhe"
    ],
    "abstract": "Diffusion has emerged as a powerful framework for generative modeling,\nachieving remarkable success in applications such as image and audio synthesis.\nEnlightened by this progress, we propose a novel diffusion-based approach for\nsymbolic regression. We construct a random mask-based diffusion and denoising\nprocess to generate diverse and high-quality equations. We integrate this\ngenerative processes with a token-wise Group Relative Policy Optimization\n(GRPO) method to conduct efficient reinforcement learning on the given\nmeasurement dataset. In addition, we introduce a long short-term risk-seeking\npolicy to expand the pool of top-performing candidates, further enhancing\nperformance. Extensive experiments and ablation studies have demonstrated the\neffectiveness of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.24776v1",
    "published": "2025-05-30T16:39:29+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24775v1",
    "title": "Numerical Simulation Informed Rapid Cure Process Optimization of Composite Structures using Constrained Bayesian Optimization",
    "authors": [
      "Madhura Limaye",
      "Yezhuo Li",
      "Qiong Zhang",
      "Gang Li"
    ],
    "abstract": "The present study aimed to solve the cure optimization problem of laminated\ncomposites through a statistical approach. The approach consisted of using\nconstrained Bayesian Optimization (cBO) along with a Gaussian process model as\na surrogate to rapidly solve the cure optimization problem. The approach was\nimplemented to two case studies including the cure of a simpler flat\nrectangular laminate and a more complex L-shaped laminate. The cure\noptimization problem with the objective to minimize cure induced distortion was\ndefined for both case studies. The former case study was two-variable that is\nused two cure cycle parameters as design variables and was constrained to\nachieve full cure, while the latter was four-variable and had to satisfy\nconstraints of full cure as well as other cure cycle parameters. The\nperformance of cBO for both case studies was compared to the traditional\noptimization approach based on Genetic Algorithm (GA). The comparison of\nresults from GA and cBO including deformation and final degree of cure showed\nsignificant agreement (error < 4%). The computational efficiency of cBO was\ncalculated by comparing the convergence steps for GA (>1000) and cBO (<50). The\ncomputational efficiency of cBO for all optimization cases was found to be >\n96%. The case studies conclude that cBO is promising in terms of computational\ntime and accuracy for solving the cure optimization problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.24775v1",
    "published": "2025-05-30T16:38:40+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24774v1",
    "title": "A studentized permutation test for the treatment effect in individual participant data meta-analysis",
    "authors": [
      "Phuc Thien Tran",
      "Long-Hao Xu",
      "Christian Röver",
      "Tim Friede"
    ],
    "abstract": "Meta-analysis is a well-established tool used to combine data from several\nindependent studies, each of which usually compares the effect of an\nexperimental treatment with a control group. While meta-analyses are often\nperformed using aggregated study summaries, they may also be conducted using\nindividual participant data (IPD). Classical meta-analysis models may be\ngeneralized to handle continuous IPD by formulating them within a linear mixed\nmodel framework. IPD meta-analyses are commonly based on a small number of\nstudies. Technically, inference for the overall treatment effect can be\nperformed using Student-t approximation. However, as some approaches may not\nadequately control the type I error, Satterthwaite's or Kenward-Roger's method\nhave been suggested to set the degrees-of-freedom parameter. The latter also\nadjusts the standard error of the treatment effect estimator. Nevertheless,\nthese methods may be conservative. Since permutation tests are known to control\nthe type I error and offer robustness to violations of distributional\nassumptions, we propose a studentized permutation test for the treatment effect\nbased on permutations of standardized residuals across studies in IPD\nmeta-analysis. Also, we construct confidence intervals for the treatment effect\nbased on this test. The first interval is derived from the percentiles of the\npermutation distribution. The second interval is obtained by searching values\nclosest to the effect estimate that are just significantly different from the\ntrue effect. In a simulation study, we demonstrate satisfactory performance of\nthe proposed methods, often producing shorter confidence intervals compared\nwith competitors.",
    "pdf_url": "http://arxiv.org/pdf/2505.24774v1",
    "published": "2025-05-30T16:36:25+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24773v2",
    "title": "AFLoRA: Adaptive Federated Fine-Tuning of Large Language Models with Resource-Aware Low-Rank Adaption",
    "authors": [
      "Yajie Zhou",
      "Xiaoyi Pang",
      "Zhibo Wang"
    ],
    "abstract": "Federated fine-tuning has emerged as a promising approach to adapt foundation\nmodels to downstream tasks using decentralized data. However, real-world\ndeployment remains challenging due to the high computational and communication\ndemands of fine-tuning Large Language Models (LLMs) on clients with data and\nsystem resources that are heterogeneous and constrained. In such settings, the\nglobal model's performance is often bottlenecked by the weakest clients and\nfurther degraded by the non-IID nature of local data. Although existing methods\nleverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) to\nreduce communication and computation overhead, they often fail to\nsimultaneously ensure accurate aggregation of low-rank updates and maintain low\nsystem costs, thereby hindering overall performance. To address these\nchallenges, we propose AFLoRA, an adaptive and lightweight federated\nfine-tuning framework for LLMs. AFLoRA decouples shared and client-specific\nupdates to reduce overhead and improve aggregation accuracy, incorporates\ndiagonal matrix-based rank pruning to better utilize local resources, and\nemploys rank-aware aggregation with public data refinement to strengthen\ngeneralization under data heterogeneity. Extensive experiments demonstrate that\nAFLoRA outperforms state-of-the-art methods in both accuracy and efficiency,\nproviding a practical solution for efficient LLM adaptation in heterogeneous\nenvironments in the real world.",
    "pdf_url": "http://arxiv.org/pdf/2505.24773v2",
    "published": "2025-05-30T16:35:32+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24772v2",
    "title": "Mixed state concurrence for symmetric systems",
    "authors": [
      "S. H. Curnoe",
      "D. Gajera",
      "C. Wei"
    ],
    "abstract": "We present a method to quantify entanglement in mixed states of highly\nsymmetric systems. Symmetry constrains interactions between parts and predicts\nthe degeneracies of the states. While symmetry alone produces entangled\neigenstates, the thermal mixed state (density) which contains all of the\neigenstate densities weighted by their Boltzmann factors is not necessarily as\nentangled as the eigenstates themselves because generally the mixed state can\nbe re-expressed as a sum over densities which are less entangled. The\nentanglement of the mixed state is the minimum obtained by considering all such\nre-expressions, but there is no well-defined approach to solving this problem\ngenerally. Our method uses symmetry to explicitly construct unentangled\ndensities, which are then optimally included in the thermal mixed state,\nresulting in a quantitative measure of entanglement that accounts for the\nreduction of entanglement arising from degenerate states. We present results\nfor several small spin systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24772v2",
    "published": "2025-05-30T16:34:27+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.other"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24771v1",
    "title": "Supporting product launching decisions with adversarial risk analysis",
    "authors": [
      "Pablo G. Arce",
      "Sonali Das",
      "David Ríos Insua"
    ],
    "abstract": "In a world of utility-driven marketing, each company acts as an adversary to\nother contenders, with all having competing interests. A major challenge for\ncompanies launching a new product is that, despite testing, flaws in their\nproduct can remain, potentially risking a loss in market share. However,\ndelayed launch decisions can lead to losing first-mover advantages.\nFurthermore, each company generally has incomplete information on the launch\nstrategy and the product quality of competing brands. From a buyer's\nperspective, along with the price, customers need to make their buying\ndecisions based on noisy signals, e.g.\\ regarding the quality of competing\nbrands. This paper proposes how to support product launch decisions by a\ncompany in the presence of several competitors and multiple buyers, with the\naid of adversarial risk analysis methods. We illustrate applications in two\nsoftware launch cases that require deciding about timing, pricing, and quality,\nreferring to single and multiple product purchases.",
    "pdf_url": "http://arxiv.org/pdf/2505.24771v1",
    "published": "2025-05-30T16:33:41+00:00",
    "categories": [
      "stat.AP",
      "62P30"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24770v1",
    "title": "Phase estimation in lossy optical interferometry without a reference beam",
    "authors": [
      "Jun Tang",
      "Dong-Qing Wang",
      "Wei Zhong",
      "Lan Zhou",
      "Yu-Bo Sheng"
    ],
    "abstract": "We investigate phase estimation in a lossy interferometer using entangled\ncoherent states, with particular focus on a scenario where no reference beam is\nemployed. By calculating the quantum Fisher information, we reveal two key\nresults: (1) the metrological equivalence between scenarios with and without a\nreference beam, established under ideal lossless conditions for the\ntwo-phase-shifting configuration,breaks down in the presence of photon loss,\nand (2) the pronounced inferior performance of entangled coherent states\nrelative to NOON states, observed in the presence of a reference beam,\ndisappears in its absence.",
    "pdf_url": "http://arxiv.org/pdf/2505.24770v1",
    "published": "2025-05-30T16:33:18+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24769v1",
    "title": "Generalization Dynamics of Linear Diffusion Models",
    "authors": [
      "Claudia Merger",
      "Sebastian Goldt"
    ],
    "abstract": "Diffusion models trained on finite datasets with $N$ samples from a target\ndistribution exhibit a transition from memorisation, where the model reproduces\ntraining examples, to generalisation, where it produces novel samples that\nreflect the underlying data distribution. Understanding this transition is key\nto characterising the sample efficiency and reliability of generative models,\nbut our theoretical understanding of this transition is incomplete. Here, we\nanalytically study the memorisation-to-generalisation transition in a simple\nmodel using linear denoisers, which allow explicit computation of test errors,\nsampling distributions, and Kullback-Leibler divergences between samples and\ntarget distribution. Using these measures, we predict that this transition\noccurs roughly when $N \\asymp d$, the dimension of the inputs. When $N$ is\nsmaller than the dimension of the inputs $d$, so that only a fraction of\nrelevant directions of variation are present in the training data, we\ndemonstrate how both regularization and early stopping help to prevent\noverfitting. For $N > d$, we find that the sampling distributions of linear\ndiffusion models approach their optimum (measured by the Kullback-Leibler\ndivergence) linearly with $d/N$, independent of the specifics of the data\ndistribution. Our work clarifies how sample complexity governs generalisation\nin a simple model of diffusion-based generative models and provides insight\ninto the training dynamics of linear denoisers.",
    "pdf_url": "http://arxiv.org/pdf/2505.24769v1",
    "published": "2025-05-30T16:31:58+00:00",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24768v1",
    "title": "From Macro to Micro: Probing Dataset Diversity in Language Model Fine-Tuning",
    "authors": [
      "Haoyu Li",
      "Xuhong Li",
      "Yiming Dong",
      "Kun Liu"
    ],
    "abstract": "Dataset diversity plays a pivotal role for the successful training of many\nmachine learning models, particularly in the supervised fine-tuning (SFT) stage\nof large language model (LLM) development. Despite increasing recognition of\nits importance, systematic analyses of dataset diversity still remain\nunderexplored. To address this gap, this work presents a systematic taxonomy of\nexisting diversity-control strategies, which primarily focus on the instruction\ncomponent, operating at either macroscopic (entire instruction semantics) or\nmesoscopic levels (instruction units), and furthermore introduces a novel\nanalysis of microscopic diversity within the response component, specifically\nanalyzing the statistical distribution of tokens in SFT training samples. In\nthe experimental evaluation, we construct fixed-size datasets (e.g., 10,000\nsamples each) from a corpus of 117,000 open-source SFT samples, incorporating\nsix distinct diversity-control strategies spanning macro-, meso-, and\nmicroscopic levels applied to both instructions and responses. We then\nfine-tune LLMs on these datasets to assess the six diversity-control\nstrategies. Results reveal that while macroscopic and mesoscopic strategies\nlead to higher performance with increasing diversity, the microscopic strategy\nin responses exhibits both a stronger correlation between model performance and\nthe degree of diversity and superior performance with maximum diversity across\nall strategies. These findings offer actionable insights for constructing\nhigh-performance SFT datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.24768v1",
    "published": "2025-05-30T16:31:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24767v1",
    "title": "A survey of using EHR as real-world evidence for discovering and validating new drug indications",
    "authors": [
      "Nabasmita Talukdar",
      "Xiaodan Zhang",
      "Shreya Paithankar",
      "Hui Wang",
      "Bin Chen"
    ],
    "abstract": "Electronic Health Records (EHRs) have been increasingly used as real-world\nevidence (RWE) to support the discovery and validation of new drug indications.\nThis paper surveys current approaches to EHR-based drug repurposing, covering\ndata sources, processing methodologies, and representation techniques. It\ndiscusses study designs and statistical frameworks for evaluating drug\nefficacy. Key challenges in validation are discussed, with emphasis on the role\nof large language models (LLMs) and target trial emulation. By synthesizing\nrecent developments and methodological advances, this work provides a\nfoundational resource for researchers aiming to translate real-world data into\nactionable drug-repurposing evidence.",
    "pdf_url": "http://arxiv.org/pdf/2505.24767v1",
    "published": "2025-05-30T16:30:54+00:00",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24766v1",
    "title": "Identification of New Candidate Be/X-Ray Binary Systems in the Small Magellanic Cloud via Analysis of S-CUBED Source Catalog",
    "authors": [
      "Thomas M. Gaudin",
      "Jamie A. Kennea",
      "Malcolm J. Coe",
      "Phil A. Evans"
    ],
    "abstract": "It has long been known that a large population of Be/X-ray Binaries (BeXRBs)\nexists in the Milky Way's neighboring dwarf galaxy, the Small Magellanic Cloud\n(SMC), due to a recent period of intense star formation. Since 2016, efforts\nhave been made to monitor this population and identify new BeXRBs through the\nSwift SMC Survey (S-CUBED). S-CUBED's weekly observation cadence has identified\nmany new BeXRBs that exist within the SMC, but evidence suggests that more\nsystems exist that have thusfar escaped detection. A major challenge in\nidentifying new BeXRBs is their transient nature at high-energy wavelengths,\nwhich prevents them from being detected via their X-ray emission\ncharacteristics when not in outburst. In order to identify sources that may\nhave been missed due to a long period of quiescence, it becomes necessary to\ndevise methods of detection that rely on wavelengths at which BeXRBs are more\npersistent emitters. In this work, we attempt to use archival analysis of\ninfrared, optical, and ultraviolet observations to identify new candidate\nBeXRBs that have been overlooked within the S-CUBED source catalog. Using\nX-ray/optical selection of source properties, unsupervised clustering,\nSED-fitting to VizieR archival measurements, and ultraviolet light curve\nanalysis, we are able to identify six new candidate BeXRB systems that\notherwise would have been missed by automated analysis pipelines. Using these\nresults, we demonstrate the use of ultraviolet through near-infrared\nobservational data in identifying candidate BeXRBs when they cannot be\nidentified using their X-ray emission.",
    "pdf_url": "http://arxiv.org/pdf/2505.24766v1",
    "published": "2025-05-30T16:30:44+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24765v5",
    "title": "Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications",
    "authors": [
      "Srikanth Thudumu",
      "Jason Fisher",
      "Hung Du"
    ],
    "abstract": "Supervised Quantum Machine Learning (QML) represents an intersection of\nquantum computing and classical machine learning, aiming to use quantum\nresources to support model training and inference. This paper reviews recent\ndevelopments in supervised QML, focusing on methods such as variational quantum\ncircuits, quantum neural networks, and quantum kernel methods, along with\nhybrid quantum-classical workflows. We examine recent experimental studies that\nshow partial indications of quantum advantage and describe current limitations\nincluding noise, barren plateaus, scalability issues, and the lack of formal\nproofs of performance improvement over classical methods. The main contribution\nis a ten-year outlook (2025-2035) that outlines possible developments in\nsupervised QML, including a roadmap describing conditions under which QML may\nbe used in applied research and enterprise systems over the next decade.",
    "pdf_url": "http://arxiv.org/pdf/2505.24765v5",
    "published": "2025-05-30T16:29:12+00:00",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24764v1",
    "title": "Entanglement Detection with Variational Quantum Interference: Theory and Experiment",
    "authors": [
      "Rui Zhang",
      "Zhenhuan Liu",
      "Chendi Yang",
      "Yue-Yang Fei",
      "Xu-Fei Yin",
      "Yingqiu Mao",
      "Li Li",
      "Nai-Le Liu",
      "Yu-Ao Chen",
      "Jian-Wei Pan"
    ],
    "abstract": "Entanglement detection serves as a fundamental task in quantum information\nscience, playing a critical role in quantum benchmarking and foundational\nstudies. As the number of controllable qubits continues to increase, there\nemerges a pressing demand for scalable and robust entanglement detection\nprotocols that can maintain high detection capability while requiring minimal\nresources. By integrating the positive partial transposition criterion with\nvariational quantum interference, we develop an entanglement detection protocol\nthat requires moderate classical and quantum computation resources. Numerical\nsimulations demonstrate that this protocol attains high detection capability\nusing only shallow quantum circuits, outperforming several widely-used\nentanglement detection methods. The protocol also exhibits strong resilience to\ncircuit noise, ensuring its applicability across different physical platforms.\nExperimental implementation on a linear optical platform successfully\nidentifies entanglement in a three-qubit mixed state that cannot be detected by\nconventional entanglement witnesses. Drawing upon the full potential of quantum\nand classical resources, our protocol paves a new path for efficient\nentanglement detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.24764v1",
    "published": "2025-05-30T16:26:25+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24763v1",
    "title": "Detecting Airborne Objects with 5G NR Radars",
    "authors": [
      "Steve Blandino",
      "Nada Golmie",
      "Anirudha Sahoo",
      "Thao Nguyen",
      "Tanguy Ropitault",
      "David Griffith",
      "Amala Sonny"
    ],
    "abstract": "The integration of sensing capabilities into 5G New Radio (5G NR) networks\noffers an opportunity to enable the detection of airborne objects without the\nneed for dedicated radars. This paper investigates the feasibility of using\nstandardized Positioning Reference Signals (PRS) to detect UAVs in Urban Micro\n(UMi) and Urban Macro (UMa) propagation environments. A full 5G NR radar\nprocessing chain is implemented, including clutter suppression, angle and range\nestimation, and 3D position reconstruction. Simulation results show that\nperformance strongly depends on the propagation environment. 5G NR radars\nexhibit the highest missed detection rate, up to 16%, in UMi, due to severe\nclutter. Positioning error increases with target distance, resulting in larger\nerrors in UMa scenarios and at higher UAV altitudes. In particular, the system\nachieves a position error within 4m in the UMi environment and within 8m in\nUMa. The simulation platform has been released as open-source software to\nsupport reproducible research in integrated sensing and communication (ISAC)\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24763v1",
    "published": "2025-05-30T16:26:09+00:00",
    "categories": [
      "eess.SP",
      "cs.NI"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24762v4",
    "title": "Branched $α$-combinatorial Ricci flows on closed surfaces with Euler characteristic $χ\\le 0$",
    "authors": [
      "Wenjun Li",
      "Rongyuan Liu",
      "Guohao Chen",
      "Aijin Lin"
    ],
    "abstract": "In this paper we introduce the branched $\\alpha$-flows on closed surfaces\nwith Euler characteristic \\(\\chi \\leq 0\\). Based on the strict convexity of the\nbranched $\\alpha$-potentials, we establish the long time existence and\nconvergence of the solutions to the branched $\\alpha$-flows, which generalizes\nGe and Xu's main results \\cite{2015,2015A} on the $\\alpha$-flows. In addtion,\nwe study the prescribed curvature problems under the relaxed precondition\n$\\chi(M)\\in \\mathbb{Z}$ via alternative $\\alpha$-flows, establishing\nadmissibility conditions for prescribed curvatures and their exponential\nconvergence to target metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24762v4",
    "published": "2025-05-30T16:20:49+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24761v1",
    "title": "On Strong Markushevich bases $\\{t^{λ_n}\\}_{n=1}^{\\infty}$ in their closed span in $L^2 (0, 1)$ and characterizing a subspace of $H^2 (\\mathbb{D})$",
    "authors": [
      "Elias Zikkos"
    ],
    "abstract": "Let $\\Lambda=\\{\\lambda_n\\}_{n=1}^{\\infty}$ be a strictly increasing sequence\nof positive real numbers such that\n$\\sum_{n=1}^{\\infty}\\frac{1}{\\lambda_n}<\\infty$ and\n$\\inf(\\lambda_{n+1}-\\lambda_n)>0$. We investigate properties of the closed span\nof the system $\\{t^{\\lambda_n}\\}_{n=1}^{\\infty}$ in $L^2 (0,1)$, denoted by\n$\\overline{M_{\\Lambda}}$, and of the unique biorthogonal family $\\{r_n\n(t)\\}_{n=1}^{\\infty}$ to the system $\\{t^{\\lambda_n}\\}_{n=1}^{\\infty}$ in\n$\\overline{M_{\\Lambda}}$. We show that the system\n$\\{t^{\\lambda_n}\\}_{n=1}^{\\infty}$ is a strong Markushevich basis in\n$\\overline{M_{\\Lambda}}$ and we obtain a series representation for functions in\n$\\overline{M_{\\Lambda}}$. We also construct a general class of operators on\n$\\overline{M_{\\Lambda}}$ that admit spectral synthesis. In particular, for all\n$\\rho \\in (0,1)$ the operator $T_{\\rho}(f)=f(\\rho x)$ on\n$\\overline{M_{\\Lambda}}$ admits spectral synthesis. In addition, we\ncharacterize a certain subspace of the classical Hardy space $H^2\n(\\mathbb{D})$. Under the extra assumption that $\\Lambda\\subset\\mathbb{N}$, let\n$H^2(\\mathbb{D}, \\Lambda)$ consist of functions $f$ in $H^2(\\mathbb{D})$ so\nthat the Fourier coefficients $c_n$ of the boundary function $f(e^{i\\theta})$\nvanish for all $n\\notin \\Lambda$. We prove that $f\\in H^2(\\mathbb{D}, \\Lambda)$\nif and only if $f\\in\\overline{M_{\\Lambda}}$ and $\\sum_{n=1}^{\\infty}\\left|\n\\langle f, r_n\\rangle \\right|^2<\\infty$, where $\\langle f, g\\rangle=\n\\int_{0}^{1} f(t)\\cdot \\overline{g(t)}\\, dt$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24761v1",
    "published": "2025-05-30T16:20:25+00:00",
    "categories": [
      "math.FA",
      "math.CV",
      "30B60, 30B50, 47A10"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24760v1",
    "title": "REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards",
    "authors": [
      "Zafir Stojanovski",
      "Oliver Stanley",
      "Joe Sharratt",
      "Richard Jones",
      "Abdulhakeem Adefioye",
      "Jean Kaddour",
      "Andreas Köpf"
    ],
    "abstract": "We introduce Reasoning Gym (RG), a library of reasoning environments for\nreinforcement learning with verifiable rewards. It provides over 100 data\ngenerators and verifiers spanning multiple domains including algebra,\narithmetic, computation, cognition, geometry, graph theory, logic, and various\ncommon games. Its key innovation is the ability to generate virtually infinite\ntraining data with adjustable complexity, unlike most previous reasoning\ndatasets, which are typically fixed. This procedural generation approach allows\nfor continuous evaluation across varying difficulty levels. Our experimental\nresults demonstrate the efficacy of RG in both evaluating and reinforcement\nlearning of reasoning models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24760v1",
    "published": "2025-05-30T16:20:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24759v2",
    "title": "Unsupervised Evolutionary Cell Type Matching via Entropy-Minimized Optimal Transport",
    "authors": [
      "Mu Qiao"
    ],
    "abstract": "Identifying evolutionary correspondences between cell types across species is\na fundamental challenge in comparative genomics and evolutionary biology.\nExisting approaches often rely on either reference-based matching, which\nimposes asymmetry by designating one species as the reference, or\nprojection-based matching, which may increase computational complexity and\nobscure biological interpretability at the cell-type level. Here, we present\nOT-MESH, an unsupervised computational framework leveraging entropy-regularized\noptimal transport (OT) to systematically determine cross-species cell type\nhomologies. Our method uniquely integrates the Minimize Entropy of Sinkhorn\n(MESH) technique to refine the OT plan, transforming diffuse transport matrices\ninto sparse, interpretable correspondences. Through systematic evaluation on\nsynthetic datasets, we demonstrate that OT-MESH achieves near-optimal matching\naccuracy with computational efficiency, while maintaining remarkable robustness\nto noise. Compared to other OT-based methods like RefCM, OT-MESH provides\nspeedup while achieving comparable accuracy. Applied to retinal bipolar cells\n(BCs) and retinal ganglion cells (RGCs) from mouse and macaque, OT-MESH\naccurately recovers known evolutionary relationships and uncovers novel\ncorrespondences, one of which was independently validated experimentally. Thus,\nour framework offers a principled, scalable, and interpretable solution for\nevolutionary cell type mapping, facilitating deeper insights into cellular\nspecialization and conservation across species.",
    "pdf_url": "http://arxiv.org/pdf/2505.24759v2",
    "published": "2025-05-30T16:20:00+00:00",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24758v2",
    "title": "Survey: Graph Databases",
    "authors": [
      "Miguel E. Coimbra",
      "Lucie Svitáková",
      "Alexandre P. Francisco",
      "Luís Veiga"
    ],
    "abstract": "Graph databases have become essential tools for managing complex and\ninterconnected data, which is common in areas like social networks,\nbioinformatics, and recommendation systems. Unlike traditional relational\ndatabases, graph databases offer a more natural way to model and query\nintricate relationships, making them particularly effective for applications\nthat demand flexibility and efficiency in handling interconnected data.\n  Despite their increasing use, graph databases face notable challenges. One\nsignificant issue is the irregular nature of graph data, often marked by\nstructural sparsity, such as in its adjacency matrix representation, which can\nlead to inefficiencies in data read and write operations. Other obstacles\ninclude the high computational demands of traversal-based queries, especially\nwithin large-scale networks, and complexities in managing transactions in\ndistributed graph environments. Additionally, the reliance on traditional\ncentralized architectures limits the scalability of Online Transaction\nProcessing (OLTP), creating bottlenecks due to contention, CPU overhead, and\nnetwork bandwidth constraints.\n  This paper presents a thorough survey of graph databases. It begins by\nexamining property models, query languages, and storage architectures,\noutlining the foundational aspects that users and developers typically engage\nwith. Following this, it provides a detailed analysis of recent advancements in\ngraph database technologies, evaluating these in the context of key aspects\nsuch as architecture, deployment, usage, and development, which collectively\ndefine the capabilities of graph database solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24758v2",
    "published": "2025-05-30T16:18:58+00:00",
    "categories": [
      "cs.DB",
      "cs.DC"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.24757v2",
    "title": "LGAR: Zero-Shot LLM-Guided Neural Ranking for Abstract Screening in Systematic Literature Reviews",
    "authors": [
      "Christian Jaumann",
      "Andreas Wiedholz",
      "Annemarie Friedrich"
    ],
    "abstract": "The scientific literature is growing rapidly, making it hard to keep track of\nthe state-of-the-art. Systematic literature reviews (SLRs) aim to identify and\nevaluate all relevant papers on a topic. After retrieving a set of candidate\npapers, the abstract screening phase determines initial relevance. To date,\nabstract screening methods using large language models (LLMs) focus on binary\nclassification settings; existing question answering (QA) based ranking\napproaches suffer from error propagation. LLMs offer a unique opportunity to\nevaluate the SLR's inclusion and exclusion criteria, yet, existing benchmarks\ndo not provide them exhaustively. We manually extract these criteria as well as\nresearch questions for 57 SLRs, mostly in the medical domain, enabling\nprincipled comparisons between approaches. Moreover, we propose LGAR, a\nzero-shot LLM Guided Abstract Ranker composed of an LLM based graded relevance\nscorer and a dense re-ranker. Our extensive experiments show that LGAR\noutperforms existing QA-based methods by 5-10 pp. in mean average precision.\nOur code and data is publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.24757v2",
    "published": "2025-05-30T16:18:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24756v1",
    "title": "TESTQUEST: A Web Gamification Tool to Improve Locators and Page Objects Quality",
    "authors": [
      "Dario Olianas",
      "Diego Clerissi",
      "Maurizio Leotta",
      "Filippo Ricca"
    ],
    "abstract": "Web applications play a crucial role in our daily lives, making it essential\nto employ testing methods that ensure their quality. Typically, Web testing\nautomation frameworks rely on locators to interact with the graphical user\ninterface, acting as connection points to the elements on a Web page.\nNevertheless, locators are widely recognized as a major vulnerability in Web\ntesting, as they are highly sensitive to the frequent changes in Web page\nstructures caused by rapid software evolution. The adoption of the Page Object\npattern to separate test logic from structural layout - supporting code reuse\nand maintainability - has generally led to more robust test cases. However,\ntheir implementation is a manually intensive task, and even automated support\nmay require manual realignment efforts. Although gamification strategies have\nrecently been integrated into the Web testing process to boost user engagement,\nusing tasks and rewards aligned with testing activities, they have not yet been\nemployed to enhance the robustness of locators and support the implementation\nof Page Objects.\n  In this paper, we introduce TESTQUEST, a tool designed to improve test\nrobustness by applying gamification to locators and Page Objects, boosting user\nengagement while guiding them toward the adoption of best practices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24756v1",
    "published": "2025-05-30T16:18:10+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24755v2",
    "title": "Systematically Measuring Ultra-Diffuse Galaxies. VIII. Misfits, Miscasts, and Miscreants",
    "authors": [
      "Dennis Zaritsky",
      "Richard Donnerstein",
      "Donghyeon J. Khim"
    ],
    "abstract": "We re-examine the 7,070 candidate ultra-diffuse galaxies (UDGs) in the\nSMUDGes survey and provide classifications based on their visual morphology.\nAmong the more interesting cases, we identify objects along a low surface\nbrightness galaxy merger sequence (ongoing mergers (8) and post-mergers (7))\nand a distinct set of dwarf ring galaxies (29). The ring galaxies are\nhypothesized to be the result of nearly polar-axis collisions, but the\nresponsible companions are undetected. We also highlight objects in the catalog\nthat appear to be tidally affected (66), thereby cautioning that their\ncataloged parameters may be unreliable. Finally, we identify contaminants of\nvarious types in the catalog, leaving 6,553 as viable undisturbed UDG\ncandidates. We discuss all categories and provide example images of the more\ninteresting ones.",
    "pdf_url": "http://arxiv.org/pdf/2505.24755v2",
    "published": "2025-05-30T16:16:44+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.12057v1",
    "title": "Mathematical reflections on modified fractional counting",
    "authors": [
      "Leo Egghe",
      "Ronald Rousseau"
    ],
    "abstract": "We make precise what is meant by stating that modified fractional counting\n(MFC) lies between full counting and complete-normalized fractional counting by\nproving that for individuals, the MFC-values are weighted geometric averages of\nthese two extremes. There are two essentially different ways to consider the\nproduction of institutes in multi-institutional articles, namely participation\nand actual number of contributions. Starting from an idea published by\nSivertsen, Rousseau and Zhang in 2019 we present three formulae for measuring\nthe production of institutes in multi-institutional articles. It is shown that\nthe one proposed by Sivertsen, Rousseau and Zhang is situated between the two\nother ways. Less obvious properties of MFC are proven using the majorization\norder.",
    "pdf_url": "http://arxiv.org/pdf/2506.12057v1",
    "published": "2025-05-30T16:16:24+00:00",
    "categories": [
      "math.HO",
      "91D30"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24754v1",
    "title": "Don't Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation",
    "authors": [
      "Yingchaojie Feng",
      "Yiqun Sun",
      "Yandong Sun",
      "Minfeng Zhu",
      "Qiang Huang",
      "Anthony K. H. Tung",
      "Wei Chen"
    ],
    "abstract": "In this work, we investigate an important task named instruction-following\ntext embedding, which generates dynamic text embeddings that adapt to user\ninstructions, highlighting specific attributes of text. Despite recent\nadvancements, existing approaches suffer from significant computational\noverhead, as they require re-encoding the entire corpus for each new\ninstruction. To address this challenge, we propose GSTransform, a novel\ninstruction-following text embedding framework based on Guided Space\nTransformation. Our key observation is that instruction-relevant information is\ninherently encoded in generic embeddings but remains underutilized. Instead of\nrepeatedly encoding the corpus for each instruction, GSTransform is a\nlightweight transformation mechanism that adapts pre-computed embeddings in\nreal time to align with user instructions, guided by a small amount of text\ndata with instruction-focused label annotation. We conduct extensive\nexperiments on three instruction-awareness downstream tasks across nine\nreal-world datasets, demonstrating that GSTransform improves\ninstruction-following text embedding quality over state-of-the-art methods\nwhile achieving dramatic speedups of 6~300x in real-time processing on\nlarge-scale datasets. The source code is available at\nhttps://github.com/YingchaojieFeng/GSTransform.",
    "pdf_url": "http://arxiv.org/pdf/2505.24754v1",
    "published": "2025-05-30T16:16:22+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24753v1",
    "title": "Heavy Ion Double Charge Exchange Reactions as Probes for Two-Body Transition Densities",
    "authors": [
      "Jessica I. Bellone",
      "Maria Colonna",
      "Danilo Gambacurta",
      "Horst Lenske"
    ],
    "abstract": "Collisional heavy ion double charge exchange (DCE) reactions, induced by\nsecond order nucleon-nucleon interactions, are shown to provide access to the\ntwo-body transition densities of the complementary DCE transitions in the\ninteracting nuclei. Corresponding two-body operators are introduced, treating\nthe second order distorted wave reaction amplitude in the s-channel interaction\nform. The theoretical results are applied to the reaction $^{18}O+{}^{76}Se\\to\n{} ^{18}Ne+{}^{76}Ge$ at $T_{lab}=270$~MeV, being $^{76}Ge$ a candidate for\nneutrino--less double beta decay.",
    "pdf_url": "http://arxiv.org/pdf/2505.24753v1",
    "published": "2025-05-30T16:15:23+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24752v1",
    "title": "On Noether's Degree Bound for Finite Group Schemes",
    "authors": [
      "Gregor Kemper",
      "Christian Liedtke",
      "Christiane Ott"
    ],
    "abstract": "This paper establishes Noether's classical degree bound $\\beta(G) \\le |G|$\nfor finite and linearly reductive group schemes. On the other hand, we provide\nexamples of infinitesimal group schemes where $\\beta(G)$ is unbounded. We also\ngeneralize Molien's formula to finite and linearly reductive group schemes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24752v1",
    "published": "2025-05-30T16:13:20+00:00",
    "categories": [
      "math.AC",
      "13A50, 14L24, 14L15"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00106v4",
    "title": "Notes on a Gaussian-Based Distribution Algebra for the Non-linear Wave Equation of the Shift Vector in Quantum Foam",
    "authors": [
      "Claes Cramer"
    ],
    "abstract": "In these notes, a non-linear distributional renormalisation algebra is\ndeveloped, tailored to the geometry of Gaussian Quantum Foam. The construction\nis based on sequences of smooth Gaussian functions restricted to spacelike\nhypersurfaces in a sequence of homotopic and globally hyperbolic spacetimes,\nconverging in the sense of distributions to Quantum Foam. A restricted subspace\nof Schwartz functions is defined, consisting of finite products of scaled\nGaussians supported on the hypersurfaces. An associated distribution space is\nintroduced as the space of distributional limits of such sequences. The\nrenormalisation algebra is closed under addition, multiplication, and\narbitrary-order differentiation, with all non-linear operations defined at the\nlevel of smooth representatives prior to taking the limit. This algebra is\napplied to the non-linear scalar wave equation governing the shift vector\nfield. In the distributional limit, the wave operator acting on the Gaussian\nsequence yields a linear combination of the Dirac measure and its second-order\nderivative, which encode the singular curvature response of the collapsing\nQuantum Foam. The presence of the second-order derivative signals a sharply\nlocalised curvature impulse, consistent with a quantum geometric source driving\nthe displacement of the vacuum. The measure term corresponds to a uniform shift\nacross the hypersurfaces, reflecting residual translation in the emerging\nclassical geometry. In the classical limit, the wave equation reduces to the\nmassless vacuum Klein-Gordon equation, linking the quantum and classical\nregimes through a unified distributional formalism. In this setting, the\nclassical notion of singularity is replaced by a sharply localised but\nwell-defined distributional structure. The singular support of the shift vector\nfield defines the locus of curvature concentration, without any geometric\nbreakdown.",
    "pdf_url": "http://arxiv.org/pdf/2506.00106v4",
    "published": "2025-05-30T16:12:23+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.24751v1",
    "title": "EL-AGHF: Extended Lagrangian Affine Geometric Heat Flow",
    "authors": [
      "Sangmin Kim",
      "Hae-Won Park"
    ],
    "abstract": "We propose a constrained Affine Geometric Heat Flow (AGHF) method that\nevolves so as to suppress the dynamics gaps associated with inadmissible\ncontrol directions. AGHF provides a unified framework applicable to a wide\nrange of motion planning problems, including both holonomic and non-holonomic\nsystems. However, to generate admissible trajectories, it requires assigning\ninfinite penalties to inadmissible control directions. This design choice,\nwhile theoretically valid, often leads to high computational cost or numerical\ninstability when the penalty becomes excessively large. To overcome this\nlimitation, we extend AGHF in an Augmented Lagrangian method approach by\nintroducing a dual trajectory related to dynamics gaps in inadmissible control\ndirections. This method solves the constrained variational problem as an\nextended parabolic partial differential equation defined over both the state\nand dual trajectorys, ensuring the admissibility of the resulting trajectory.\nWe demonstrate the effectiveness of our algorithm through simulation examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.24751v1",
    "published": "2025-05-30T16:12:20+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24750v1",
    "title": "The critical temperature $T_{cr}$(Ising) is constructive",
    "authors": [
      "Senya Shlosman"
    ],
    "abstract": "We show that the Dobrushin-Shlosman conditions $C_{V}$ for the uniqueness of\nthe Gibbs state provide an exact estimate for the critical temperature of the\n$d$-dimensional Ising model. Our method also shows that the $d$-dimensional\nIsing model with a magnetic field is Completely Analytic above its critical\ntemperature.",
    "pdf_url": "http://arxiv.org/pdf/2505.24750v1",
    "published": "2025-05-30T16:10:34+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "60G60"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24749v1",
    "title": "SUMO: Subspace-Aware Moment-Orthogonalization for Accelerating Memory-Efficient LLM Training",
    "authors": [
      "Yehonathan Refael",
      "Guy Smorodinsky",
      "Tom Tirer",
      "Ofir Lindenbaum"
    ],
    "abstract": "Low-rank gradient-based optimization methods have significantly improved\nmemory efficiency during the training of large language models (LLMs), enabling\noperations within constrained hardware without sacrificing performance.\nHowever, these methods primarily emphasize memory savings, often overlooking\npotential acceleration in convergence due to their reliance on standard\nisotropic steepest descent techniques, which can perform suboptimally in the\nhighly anisotropic landscapes typical of deep networks, particularly LLMs. In\nthis paper, we propose SUMO (Subspace-Aware Moment-Orthogonalization), an\noptimizer that employs exact singular value decomposition (SVD) for moment\northogonalization within a dynamically adapted low-dimensional subspace,\nenabling norm-inducing steepest descent optimization steps. By explicitly\naligning optimization steps with the spectral characteristics of the loss\nlandscape, SUMO effectively mitigates approximation errors associated with\ncommonly used methods like Newton-Schulz orthogonalization approximation. We\ntheoretically establish an upper bound on these approximation errors, proving\ntheir dependence on the condition numbers of moments, conditions we\nanalytically demonstrate are encountered during LLM training. Furthermore, we\nboth theoretically and empirically illustrate that exact orthogonalization via\nSVD substantially improves convergence rates while reducing overall complexity.\nEmpirical evaluations confirm that SUMO accelerates convergence, enhances\nstability, improves performance, and reduces memory requirements by up to 20%\ncompared to state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24749v1",
    "published": "2025-05-30T16:08:40+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24748v1",
    "title": "Equidistribution and arithmetic $Λ$-distributions",
    "authors": [
      "Matthew Bertucci",
      "Sean Howe"
    ],
    "abstract": "We formulate an abstract notion of equidistribution for families of\n$\\lambda$-probability spaces parameterized by admissible $\\mathbb{Z}$-sets.\nUnder the assumption of equidistribution, we show that the $\\sigma$-moment\ngenerating functions of certain infinite sums of random variables can be\ncomputed as motivic Euler products. Combining this result with earlier\ngeneralizations of Poonen's sieve, we compute the asymptotic\n$\\Lambda$-distributions for several natural families of function field\n$L$-functions and zeta functions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24748v1",
    "published": "2025-05-30T16:08:26+00:00",
    "categories": [
      "math.NT",
      "math.AG"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24747v1",
    "title": "First principles computations of the Stark shift of a defect-bound exciton: the case of the T center in silicon",
    "authors": [
      "Louis Alaerts",
      "Yihuang Xiong",
      "Sinéad M. Griffin",
      "Geoffroy Hautier"
    ],
    "abstract": "The T center in silicon has recently drawn a lot of attention for its\npotential in quantum information science. The sensitivity of the zero-phonon\nline (ZPL) to electrical field was recently investigated by a combination of\ndifferent experimental methods but there is still no first principles study on\nthe Stark shift of the T center. Dealing with the defect-bound exciton nature\nof the excited state is particularly challenging using density functional\ntheory because of the large spatial delocalization associated with the\nwavefunction. Here, we tackle this issue by performing a convergence study over\nthe supercell size. We obtain an exciton binding energy of 28.5meV, in good\nagreement with experimental results. We then calculate the Stark shift through\nthe dipole moment change of the ZPL transition of the T center using the modern\ntheory of polarization formalism and find a modest linear coefficient of\n$\\Delta \\mu$=0.79D along X and $\\Delta \\mu$=0.03D along Y. We discuss our\nresults in light of the recent experimental measurements of the Stark shift.\nOur analysis suggests that bound-exciton defects could be particularly\nsensitive to local field effect as a result of their large spatial extent.",
    "pdf_url": "http://arxiv.org/pdf/2505.24747v1",
    "published": "2025-05-30T16:06:37+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24746v1",
    "title": "Tackling View-Dependent Semantics in 3D Language Gaussian Splatting",
    "authors": [
      "Jiazhong Cen",
      "Xudong Zhou",
      "Jiemin Fang",
      "Changsong Wen",
      "Lingxi Xie",
      "Xiaopeng Zhang",
      "Wei Shen",
      "Qi Tian"
    ],
    "abstract": "Recent advancements in 3D Gaussian Splatting (3D-GS) enable high-quality 3D\nscene reconstruction from RGB images. Many studies extend this paradigm for\nlanguage-driven open-vocabulary scene understanding. However, most of them\nsimply project 2D semantic features onto 3D Gaussians and overlook a\nfundamental gap between 2D and 3D understanding: a 3D object may exhibit\nvarious semantics from different viewpoints--a phenomenon we term\nview-dependent semantics. To address this challenge, we propose LaGa (Language\nGaussians), which establishes cross-view semantic connections by decomposing\nthe 3D scene into objects. Then, it constructs view-aggregated semantic\nrepresentations by clustering semantic descriptors and reweighting them based\non multi-view semantics. Extensive experiments demonstrate that LaGa\neffectively captures key information from view-dependent semantics, enabling a\nmore comprehensive understanding of 3D scenes. Notably, under the same\nsettings, LaGa achieves a significant improvement of +18.7% mIoU over the\nprevious SOTA on the LERF-OVS dataset. Our code is available at:\nhttps://github.com/SJTU-DeepVisionLab/LaGa.",
    "pdf_url": "http://arxiv.org/pdf/2505.24746v1",
    "published": "2025-05-30T16:06:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24745v1",
    "title": "Spin-dependent transport through edge states in 2D semi-Dirac materials with Rashba spin-orbit coupling and band inversion",
    "authors": [
      "Marta García-Olmos",
      "Yuriko Baba",
      "Alexander López",
      "Mario Amado",
      "Rafael A. Molina"
    ],
    "abstract": "We investigate the bulk-boundary correspondence in two-dimensional type-I\nsemi-Dirac materials with band inversion and Rashba spin-orbit coupling.\nEmploying a dimensional reduction framework, we identify the Zak phase along\nthe quadratically dispersing direction as a topological invariant that captures\nthe presence of edge states. In the non-trivial topological regime, systems\nwith finite width exhibit energy-dependent edge states that are topologically\nprotected only at specific momenta. At kx equal to zero, symmetry-protected\nedge states emerge, analogous to the Rashba-free case. At finite kx, the\ninterplay of spin-orbit coupling and band structure gives rise to\nspin-dependent edge states, localized on specific edges based on its spin and\nparticle-hole character. We compute spin-resolved conductance through these\nedge channels and observe robust, tunable oscillations attributable to spin\nprecession induced by the effective Rashba magnetic field. These results reveal\nhow spin-orbit interactions enrich the edge physics of semi-Dirac systems and\nprovide a platform for spintronic control in anisotropic topological materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.24745v1",
    "published": "2025-05-30T16:04:06+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24744v1",
    "title": "Neural Network-based Universal Formulas for Control",
    "authors": [
      "Pol Mestres",
      "Jorge Cortés",
      "Eduardo D. Sontag"
    ],
    "abstract": "We study the problem of designing a controller that satisfies an arbitrary\nnumber of affine inequalities at every point in the state space. This is\nmotivated by the use of guardrails in autonomous systems. Indeed, a variety of\nkey control objectives, such as stability, safety, and input saturation, are\nguaranteed by closed-loop systems whose controllers satisfy such inequalities.\nMany works in the literature design such controllers as the solution to a\nstate-dependent quadratic program (QP) whose constraints are precisely the\ninequalities. When the input dimension and number of constraints are high,\ncomputing a solution of this QP in real time can become computationally\nburdensome. Additionally, the solution of such optimization problems is not\nsmooth in general, which can degrade the performance of the system. This paper\nprovides a novel method to design a smooth controller that satisfies an\narbitrary number of affine constraints. This why we refer to it as a universal\nformula for control. The controller is given at every state as the minimizer of\na strictly convex function. To avoid computing the minimizer of such function\nin real time, we introduce a method based on neural networks (NN) to\napproximate the controller. Remarkably, this NN can be used to solve the\ncontroller design problem for any task with less than a fixed input dimension\nand number of affine constraints, and is completely independent of the state\ndimension. Additionally, we show that the NN-based controller only needs to be\ntrained with datapoints from a compact set in the state space, which\nsignificantly simplifies the training process. Various simulations showcase the\nperformance of the proposed solution.",
    "pdf_url": "http://arxiv.org/pdf/2505.24744v1",
    "published": "2025-05-30T16:02:05+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24743v2",
    "title": "What solves the Hubble tension in phenomenological dark energy models at background level?",
    "authors": [
      "Manosh T. Manoharan"
    ],
    "abstract": "Few phenomenological models tend to favour higher values of the Hubble\nparameter, often at the expense of invoking phantom transitions. These models\nachieve this without introducing additional parameters, akin to the simplicity\nof the concordance $\\Lambda$CDM model. In this work, we investigate two such\nmodels -- Phenomenologically Emergent Dark Energy (PEDE) and Granda-Oliveros\nHolographic Dark Energy (GOHDE) -- to assess how correlations between $H_0$ and\n$\\Omega_m$, as well as the choice of datasets, influence conclusions regarding\ntheir potential to address the Hubble tension at the background level. We find\nthat minimally extended versions of these models favour notably low values for\nthe Hubble parameter, with the perceived preference for higher values driven by\nthe associated prior. Excluding BAO Ly$\\alpha$-$H(z)$ data points at a redshift\nof $\\sim 2.3$ results in a Hubble parameter that remains in significant tension\nwith SH0ES measurements. In contrast, including these data points favours a\nhigher $H_0$, as they suggest a relatively lower matter density within the\nframework of the assumed fiducial cosmology. Additionally, recent DESI DR1 and\nDR2 data exhibit mild tension with BAO-$H(z)$ estimates from SDSS. We\ndemonstrate that the inclusion of stringent constraints, such as the CMB\nshift-parameter along with Pantheon$^+$, on the effective pressure less matter\ndensity significantly impacts the estimation of the Hubble parameter. Finally,\nreinterpreting these models in terms of interacting dark sectors with $Q =\n3H\\gamma_{\\Lambda}\\tilde{\\rho}_{m}$ reveals that addressing the Hubble tension\nnecessitates a varying $\\gamma_{\\Lambda}$ characterised by a singular\nsign-switch behaviour. This phantom behaviour, or equivalently, the onset of\nviolation of the null energy condition in the future, is crucial for minimal\nmodels to solve the Hubble tension.",
    "pdf_url": "http://arxiv.org/pdf/2505.24743v2",
    "published": "2025-05-30T16:01:50+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24742v1",
    "title": "Authentication and authorization in Data Spaces: A relationship-based access control approach for policy specification based on ODRL",
    "authors": [
      "Irene Plaza-Ortiz",
      "Andres Munoz-Arcentales",
      "Joaquín Salvachúa",
      "Carlos Aparicio",
      "Gabriel Huecas",
      "Enrique Barra"
    ],
    "abstract": "Data has become a crucial resource in the digital economy, fostering\ninitiatives for secure and sovereign data sharing frameworks such as Data\nSpaces. However, these distributed environments require fine-grained access\ncontrol mechanisms that balance openness with sovereignty and security. This\npaper proposes an extension of the Open Digital Rights Language (ODRL)\nstandard, the ODRL Data Spaces (ODS) profile, aimed at supporting authorization\nand complementing existing authentication mechanisms throughout the data\nlifecycle. Additionally, a policy execution engine is introduced to translate\nODRL policies into executable formats, enabling effective enforcement. The\napproach is validated through a use case involving OpenFGA, demonstrating its\napplicability to relationship-based access control scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.24742v1",
    "published": "2025-05-30T16:00:24+00:00",
    "categories": [
      "cs.CR",
      "cs.ET"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24741v1",
    "title": "Cone-jet Stokes solutions in strong viscous flows: the vanishing flow rate limit",
    "authors": [
      "Alfonso M. Ganan-Calvo",
      "Miguel A. Herrada",
      "Jens Eggers"
    ],
    "abstract": "Steady tip streaming in the vanishing flow rate limit has been evidenced both\nexperimentally and numerically in the literature. However, local conical Stokes\nflow solutions supporting these results at vanishing small scales around the\nemitting tip have remained elusive. This work presents approximate local\nconical solutions in liquid-liquid flow focusing and tip streaming, in general,\nas the limit of a macroscopic vanishing issued flow rate. This provides\nmathematical foundations for the existence of an asymptotically vanishing scale\nat the tip of an intermediate conical flow geometry with angle $\\alpha$. For a\nsufficiently small inner-to-outer liquid viscosity ratio $\\lambda$, these\nsolutions exhibit a universal power-law relationship between this ratio and the\ncone angle as $\\alpha=k \\lambda^{1/2}$, where the prefactor $k$, of the order\nof unity, depends on the geometric details of the macroscopic flow. This\nconfirms the existing proposals that anticipate the use of flow focusing and\ntip streaming technologies for tight control of microscopic scales, down to\nthose where diffuse liquid-liquid interfaces become manifested.",
    "pdf_url": "http://arxiv.org/pdf/2505.24741v1",
    "published": "2025-05-30T15:59:06+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24740v1",
    "title": "Cluster Reconstruction in Electromagnetic Calorimeters Using Machine Learning Methods",
    "authors": [
      "Kalina Dimitrova",
      "Venelin Kozhuharov",
      "Ruslan Nastaev",
      "Peicho Petkov"
    ],
    "abstract": "Machine-learning-based methods can be developed for the reconstruction of\nclusters in segmented detectors for high energy physics experiments.\nConvolutional neural networks with autoencoder architecture trained on labeled\ndata from a simulated dataset reconstruct events by providing information about\nthe hit point and energy of each particle that has entered the detector. The\ncorrect reconstruction of the positionand the energy of the incident particles\nis crucial for the accurate events reconstruction. The presented method shows\nthe ability to reconstruct the impact point within the same segment as the true\nposition and determines the particle energy with good precision. It can be\napplied in a wide range of cases of event reconstruction where the good\nseparation of overlapping signals plays a key role in the data analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.24740v1",
    "published": "2025-05-30T15:58:18+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.24739v3",
    "title": "Contrast-Invariant Self-supervised Segmentation for Quantitative Placental MRI",
    "authors": [
      "Xinliu Zhong",
      "Ruiying Liu",
      "Emily S. Nichols",
      "Xuzhe Zhang",
      "Andrew F. Laine",
      "Emma G. Duerden",
      "Yun Wang"
    ],
    "abstract": "Accurate placental segmentation is essential for quantitative analysis of the\nplacenta. However, this task is particularly challenging in T2*-weighted\nplacental imaging due to: (1) weak and inconsistent boundary contrast across\nindividual echoes; (2) the absence of manual ground truth annotations for all\necho times; and (3) motion artifacts across echoes caused by fetal and maternal\nmovement. In this work, we propose a contrast-augmented segmentation framework\nthat leverages complementary information across multi-echo T2*-weighted MRI to\nlearn robust, contrast-invariant representations. Our method integrates: (i)\nmasked autoencoding (MAE) for self-supervised pretraining on unlabeled\nmulti-echo slices; (ii) masked pseudo-labeling (MPL) for unsupervised domain\nadaptation across echo times; and (iii) global-local collaboration to align\nfine-grained features with global anatomical context. We further introduce a\nsemantic matching loss to encourage representation consistency across echoes of\nthe same subject. Experiments on a clinical multi-echo placental MRI dataset\ndemonstrate that our approach generalizes effectively across echo times and\noutperforms both single-echo and naive fusion baselines. To our knowledge, this\nis the first work to systematically exploit multi-echo T2*-weighted MRI for\nplacental segmentation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24739v3",
    "published": "2025-05-30T15:58:14+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24738v1",
    "title": "Polariton-mediated light emission induced by electric current flow in nanostructured polyaniline",
    "authors": [
      "Jerzy J. Langer",
      "Ewelina Frackowiak",
      "Katarzyna Ratajczak"
    ],
    "abstract": "We present here a new mechanism of light emission induced by the electric\ncurrent in polyaniline micro- and nanostructures. This process involves the\nformation of excitons, exciton-polaritons and finally an exciton-polariton\ncondensate, leading to laser-like emission.",
    "pdf_url": "http://arxiv.org/pdf/2505.24738v1",
    "published": "2025-05-30T15:57:39+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24737v1",
    "title": "Adapting to Linear Separable Subsets with Large-Margin in Differentially Private Learning",
    "authors": [
      "Erchi Wang",
      "Yuqing Zhu",
      "Yu-Xiang Wang"
    ],
    "abstract": "This paper studies the problem of differentially private empirical risk\nminimization (DP-ERM) for binary linear classification. We obtain an efficient\n$(\\varepsilon,\\delta)$-DP algorithm with an empirical zero-one risk bound of\n$\\tilde{O}\\left(\\frac{1}{\\gamma^2\\varepsilon n} +\n\\frac{|S_{\\mathrm{out}}|}{\\gamma n}\\right)$ where $n$ is the number of data\npoints, $S_{\\mathrm{out}}$ is an arbitrary subset of data one can remove and\n$\\gamma$ is the margin of linear separation of the remaining data points (after\n$S_{\\mathrm{out}}$ is removed). Here, $\\tilde{O}(\\cdot)$ hides only logarithmic\nterms. In the agnostic case, we improve the existing results when the number of\noutliers is small. Our algorithm is highly adaptive because it does not require\nknowing the margin parameter $\\gamma$ or outlier subset $S_{\\mathrm{out}}$. We\nalso derive a utility bound for the advanced private hyperparameter tuning\nalgorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.24737v1",
    "published": "2025-05-30T15:56:58+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24736v1",
    "title": "\"Dyadosyncrasy\", Idiosyncrasy and Demographic Factors in Turn-Taking",
    "authors": [
      "Julio Cesar Cavalcanti",
      "Gabriel Skantze"
    ],
    "abstract": "Turn-taking in dialogue follows universal constraints but also varies\nsignificantly. This study examines how demographic (sex, age, education) and\nindividual factors shape turn-taking using a large dataset of US English\nconversations (Fisher). We analyze Transition Floor Offset (TFO) and find\nnotable interspeaker variation. Sex and age have small but significant effects\nfemale speakers and older individuals exhibit slightly shorter offsets - while\neducation shows no effect. Lighter topics correlate with shorter TFOs. However,\nindividual differences have a greater impact, driven by a strong idiosyncratic\nand an even stronger \"dyadosyncratic\" component - speakers in a dyad resemble\neach other more than they resemble themselves in different dyads. This suggests\nthat the dyadic relationship and joint activity are the strongest determinants\nof TFO, outweighing demographic influences.",
    "pdf_url": "http://arxiv.org/pdf/2505.24736v1",
    "published": "2025-05-30T15:55:47+00:00",
    "categories": [
      "eess.AS",
      "cs.CL"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24735v1",
    "title": "A Computational Search for Minimal Obstruction Graphs for the Lovász--Schrijver SDP Hierarchy",
    "authors": [
      "Yu Hin Au",
      "Levent Tunçel"
    ],
    "abstract": "We study the lift-and-project relaxations of the stable set polytope of\ngraphs generated by $\\text{LS}_+$, the SDP lift-and-project operator devised by\nLov\\'{a}sz and Schrijver. In particular, we focus on searching for\n$\\ell$-minimal graphs, which are graphs on $3\\ell$ vertices whose stable set\npolytope has rank $\\ell$ with respect to $\\text{LS}_+$. These are the graphs\nwhich are the most challenging for the $\\text{LS}_+$ operator according to one\nof the main complexity measures (smallest graphs with largest\n$\\text{LS}_+$-rank). We introduce the notion of $\\text{LS}_+$ certificate\npackages, which is a framework that allows for efficient and reliable\nverification of membership of points in $\\text{LS}_+$-relaxations. Using this\nframework, we present numerical certificates which (combined with other\nresults) show that there are at least $49$ $3$-minimal graphs, as well as over\n$4000$ $4$-minimal graphs. This marks a significant leap from the $14$\n$3$-minimal and $588$ $4$-minimal graphs known before this work, with many of\nthe newly-discovered graphs containing novel structures which helps enrich and\nrecalibrate our understanding of $\\ell$-minimal graphs. Some of this\ncomputational work leads to interesting conjectures. We also find all of the\nsmallest vertex-transitive graphs with $\\text{LS}_+$-rank $\\ell$ for every\n$\\ell \\leq 4$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24735v1",
    "published": "2025-05-30T15:55:45+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "math.OC",
      "90C22, 90C27"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24734v1",
    "title": "Real syntomic cohomology",
    "authors": [
      "Gabriel Angelini-Knoll",
      "Hana Jia Kong",
      "J. D. Quigley"
    ],
    "abstract": "We introduce a theory of syntomic cohomology for ring spectra with\ninvolution, which we call Real syntomic cohomology. We show that our\nconstruction extends the theory of syntomic cohomology for rings with\ninvolution due to Park. Our construction also refines syntomic cohomology as\ndeveloped by Bhatt--Morrow--Scholze, Morin, Bhatt--Lurie, and\nHahn--Raksit--Wilson. We compute the Real syntomic cohomology of Real\ntopological K-theory and topological modular forms with level structure.",
    "pdf_url": "http://arxiv.org/pdf/2505.24734v1",
    "published": "2025-05-30T15:55:14+00:00",
    "categories": [
      "math.AT",
      "math.KT",
      "19D55, 55Q51, 19G38, 14F30, 19D50 (Primary) 13D03, 55P91, 16W10,\n  55T25 (Secondary)"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24733v1",
    "title": "DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds",
    "authors": [
      "Jiaxu Zhang",
      "Xianfang Zeng",
      "Xin Chen",
      "Wei Zuo",
      "Gang Yu",
      "Guosheng Lin",
      "Zhigang Tu"
    ],
    "abstract": "This paper presents DreamDance, a novel character art animation framework\ncapable of producing stable, consistent character and scene motion conditioned\non precise camera trajectories. To achieve this, we re-formulate the animation\ntask as two inpainting-based steps: Camera-aware Scene Inpainting and\nPose-aware Video Inpainting. The first step leverages a pre-trained image\ninpainting model to generate multi-view scene images from the reference art and\noptimizes a stable large-scale Gaussian field, which enables coarse background\nvideo rendering with camera trajectories. However, the rendered video is rough\nand only conveys scene motion. To resolve this, the second step trains a\npose-aware video inpainting model that injects the dynamic character into the\nscene video while enhancing background quality. Specifically, this model is a\nDiT-based video generation model with a gating strategy that adaptively\nintegrates the character's appearance and pose information into the base\nbackground video. Through extensive experiments, we demonstrate the\neffectiveness and generalizability of DreamDance, producing high-quality and\nconsistent character animations with remarkable camera dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24733v1",
    "published": "2025-05-30T15:54:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24732v1",
    "title": "The Quintom theory of dark energy after DESI DR2",
    "authors": [
      "Yifu Cai",
      "Xin Ren",
      "Taotao Qiu",
      "Mingzhe Li",
      "Xinmin Zhang"
    ],
    "abstract": "Observations from DESI DR2 are challenging the $\\Lambda$CDM paradigm by\nsuggesting that the equation-of-state parameter of dark energy evolves across\n$w = -1$, a phenomenon known as the Quintom scenario. Inspired by this\ndevelopment, we present a staged review of Quintom cosmology including its\ntheoretical foundations, observational supports, and implications as well as\npossible extensions. We first trace the historical progression from Einstein's\nstatic cosmological constant to modern dynamical dark energy, summarizing\nrecent cosmological constraints that favor an evolving $w(z)$ along time. A key\nfocus is the theoretical no-go theorem for dark energy showing that no single\ncanonical field or perfect fluid model can smoothly cross the $w = -1$\nboundary. We then survey viable Quintom constructions, including two-field\nmodels, single-scalar fields with higher derivatives, modified gravity\nframeworks, and an effective field theory approach that unifies these\nmechanisms. Possible interactions of Quintom fields with ordinary matter and\nthe potential roles in yielding non-singular universe solutions are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.24732v1",
    "published": "2025-05-30T15:54:16+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24731v1",
    "title": "Circuit Stability Characterizes Language Model Generalization",
    "authors": [
      "Alan Sun"
    ],
    "abstract": "Extensively evaluating the capabilities of (large) language models is\ndifficult. Rapid development of state-of-the-art models induce benchmark\nsaturation, while creating more challenging datasets is labor-intensive.\nInspired by the recent developments in mechanistic interpretability, we\nintroduce circuit stability as a new way to assess model performance. Circuit\nstability refers to a model's ability to apply a consistent reasoning\nprocess-its circuit-across various inputs. We mathematically formalize circuit\nstability and circuit equivalence. Then, through three case studies, we\nempirically show that circuit stability and the lack thereof can characterize\nand predict different aspects of generalization. Our proposed methods offer a\nstep towards rigorously relating the generality of models to their\ninterpretability.",
    "pdf_url": "http://arxiv.org/pdf/2505.24731v1",
    "published": "2025-05-30T15:53:56+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24730v1",
    "title": "Emergent Dynamics of Active Systems on Curved Environments",
    "authors": [
      "Euan D. Mackay",
      "Giulia Janzen",
      "D. A. Matoz Fernandez",
      "Rastko Sknepnek"
    ],
    "abstract": "Curvature plays a central role in the proper function of many biological\nprocesses. With active matter being a standard framework for understanding many\naspects of the physics of life, it is natural to ask what effect curvature has\non the collective behaviour of active matter. In this paper, we use the\nclassical theory of surfaces to explore the active motion of self-propelled\nagents confined to move on a smooth curved two-dimensional surface embedded in\nEuclidean space. Even without interactions and alignment, the motion is\nnon-trivially affected by the presence of curvature, leading to effects akin,\ne.g.\\ to gravitational lensing and tidal forces. Such effects can lead to\nintermittent trapping of particles and profoundly affect their flocking\nbehaviour.",
    "pdf_url": "http://arxiv.org/pdf/2505.24730v1",
    "published": "2025-05-30T15:53:23+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.24729v1",
    "title": "Feature Attribution from First Principles",
    "authors": [
      "Magamed Taimeskhanov",
      "Damien Garreau"
    ],
    "abstract": "Feature attribution methods are a popular approach to explain the behavior of\nmachine learning models. They assign importance scores to each input feature,\nquantifying their influence on the model's prediction. However, evaluating\nthese methods empirically remains a significant challenge. To bypass this\nshortcoming, several prior works have proposed axiomatic frameworks that any\nfeature attribution method should satisfy. In this work, we argue that such\naxioms are often too restrictive, and propose in response a new feature\nattribution framework, built from the ground up. Rather than imposing axioms,\nwe start by defining attributions for the simplest possible models, i.e.,\nindicator functions, and use these as building blocks for more complex models.\nWe then show that one recovers several existing attribution methods, depending\non the choice of atomic attribution. Subsequently, we derive closed-form\nexpressions for attribution of deep ReLU networks, and take a step toward the\noptimization of evaluation metrics with respect to feature attributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24729v1",
    "published": "2025-05-30T15:53:11+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24728v1",
    "title": "Robust Federated Learning against Model Perturbation in Edge Networks",
    "authors": [
      "Dongzi Jin",
      "Yong Xiao",
      "Yingyu Li"
    ],
    "abstract": "Federated Learning (FL) is a promising paradigm for realizing edge\nintelligence, allowing collaborative learning among distributed edge devices by\nsharing models instead of raw data. However, the shared models are often\nassumed to be ideal, which would be inevitably violated in practice due to\nvarious perturbations, leading to significant performance degradation. To\novercome this challenge, we propose a novel method, termed Sharpness-Aware\nMinimization-based Robust Federated Learning (SMRFL), which aims to improve\nmodel robustness against perturbations by exploring the geometrical property of\nthe model landscape. Specifically, SMRFL solves a min-max optimization problem\nthat promotes model convergence towards a flat minimum by minimizing the\nmaximum loss within a neighborhood of the model parameters. In this way, model\nsensitivity to perturbations is reduced, and robustness is enhanced since\nmodels in the neighborhood of the flat minimum also enjoy low loss values. The\ntheoretical result proves that SMRFL can converge at the same rate as FL\nwithout perturbations. Extensive experimental results show that SMRFL\nsignificantly enhances robustness against perturbations compared to three\nbaseline methods on two real-world datasets under three perturbation scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.24728v1",
    "published": "2025-05-30T15:52:05+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24727v1",
    "title": "Knockoff-Guided Compressive Sensing: A Statistical Machine Learning Framework for Support-Assured Signal Recovery",
    "authors": [
      "Xiaochen Zhang",
      "Haoyi Xiong"
    ],
    "abstract": "This paper introduces a novel Knockoff-guided compressive sensing framework,\nreferred to as \\TheName{}, which enhances signal recovery by leveraging precise\nfalse discovery rate (FDR) control during the support identification phase.\nUnlike LASSO, which jointly performs support selection and signal estimation\nwithout explicit error control, our method guarantees FDR control in finite\nsamples, enabling more reliable identification of the true signal support. By\nseparating and controlling the support recovery process through statistical\nKnockoff filters, our framework achieves more accurate signal reconstruction,\nespecially in challenging scenarios where traditional methods fail. We\nestablish theoretical guarantees demonstrating how FDR control directly ensures\nrecovery performance under weaker conditions than traditional $\\ell_1$-based\ncompressive sensing methods, while maintaining accurate signal reconstruction.\nExtensive numerical experiments demonstrate that our proposed Knockoff-based\nmethod consistently outperforms LASSO-based and other state-of-the-art\ncompressive sensing techniques. In simulation studies, our method improves\nF1-score by up to 3.9x over baseline methods, attributed to principled false\ndiscovery rate (FDR) control and enhanced support recovery. The method also\nconsistently yields lower reconstruction and relative errors. We further\nvalidate the framework on real-world datasets, where it achieves top downstream\npredictive performance across both regression and classification tasks, often\nnarrowing or even surpassing the performance gap relative to uncompressed\nsignals. These results establish \\TheName{} as a robust and practical\nalternative to existing approaches, offering both theoretical guarantees and\nstrong empirical performance through statistically grounded support selection.",
    "pdf_url": "http://arxiv.org/pdf/2505.24727v1",
    "published": "2025-05-30T15:50:58+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24726v1",
    "title": "Reflect, Retry, Reward: Self-Improving LLMs via Reinforcement Learning",
    "authors": [
      "Shelly Bensal",
      "Umar Jamil",
      "Christopher Bryant",
      "Melisa Russak",
      "Kiran Kamble",
      "Dmytro Mozolevskyi",
      "Muayad Ali",
      "Waseem AlShikh"
    ],
    "abstract": "We explore a method for improving the performance of large language models\nthrough self-reflection and reinforcement learning. By incentivizing the model\nto generate better self-reflections when it answers incorrectly, we demonstrate\nthat a model's ability to solve complex, verifiable tasks can be enhanced even\nwhen generating synthetic data is infeasible and only binary feedback is\navailable. Our framework operates in two stages: first, upon failing a given\ntask, the model generates a self-reflective commentary analyzing its previous\nattempt; second, the model is given another attempt at the task with the\nself-reflection in context. If the subsequent attempt succeeds, the tokens\ngenerated during the self-reflection phase are rewarded. Our experimental\nresults show substantial performance gains across a variety of model\narchitectures, as high as 34.7% improvement at math equation writing and 18.1%\nimprovement at function calling. Notably, smaller fine-tuned models (1.5\nbillion to 7 billion parameters) outperform models in the same family that are\n10 times larger. Our novel paradigm is thus an exciting pathway to more useful\nand reliable language models that can self-improve on challenging tasks with\nlimited external feedback.",
    "pdf_url": "http://arxiv.org/pdf/2505.24726v1",
    "published": "2025-05-30T15:49:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24725v1",
    "title": "From Pixels to Camera: Scaling Superconducting Nanowire Single-Photon Detectors for Imaging at the Quantum-Limit",
    "authors": [
      "Jun Gao",
      "Jin Chang",
      "Bruno Lopez Rodriguez",
      "Iman Esmaeil Zadeh",
      "Val Zwiller",
      "Ali W. Elshaari"
    ],
    "abstract": "Superconducting nanowire single-photon detectors (SNSPDs) have emerged as\nessential devices that push the boundaries of photon detection with\nunprecedented sensitivity, ultrahigh timing precision, and broad spectral\nresponse. Recent advancements in materials engineering, superconducting\nelectronics integration, and cryogenic system design are enabling the evolution\nof SNSPDs from single-pixel detectors toward scalable arrays and large-format\nsingle-photon time tagging cameras. This perspective article surveys the\nrapidly evolving technological landscape underpinning this transition, focusing\non innovative superconducting materials, advanced multiplexed read-out schemes,\nand emerging cryo-compatible electronics. We highlight how these developments\nare set to profoundly impact diverse applications, including quantum\ncommunication networks, deep-tissue biomedical imaging, single-molecule\nspectroscopy, remote sensing with unprecedented resolution, and the detection\nof elusive dark matter signals. By critically discussing both current\nchallenges and promising solutions, we aim to articulate a clear, coherent\nvision for the next generation of SNSPD-based quantum imaging systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24725v1",
    "published": "2025-05-30T15:48:11+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.supr-con",
      "physics.app-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24724v1",
    "title": "Talking Transactions: Decentralized Communication through Ethereum Input Data Messages (IDMs)",
    "authors": [
      "Xihan Xiong",
      "Zhipeng Wang",
      "Qin Wang",
      "Endong Liu",
      "Pascal Berrang",
      "William Knottenbelt"
    ],
    "abstract": "Can you imagine, blockchain transactions can talk! In this paper, we study\nhow they talk and what they talk about. We focus on the input data field of\nEthereum transactions, which is designed to allow external callers to interact\nwith smart contracts. In practice, this field also enables users to embed\nnatural language messages into transactions. Users can leverage these Input\nData Messages (IDMs) for peer-to-peer communication. This means that, beyond\nEthereum's well-known role as a financial infrastructure, it also serves as a\ndecentralized communication medium.\n  We present the first large-scale analysis of Ethereum IDMs from the genesis\nblock to February 2024 (3134 days). We filter IDMs to extract 867,140\ntransactions with informative IDMs and use LLMs for language detection. We find\nthat English (95.4%) and Chinese (4.4%) dominate the use of natural languages\nin IDMs. Interestingly, English IDMs center on security and scam warnings (24%)\nwith predominantly negative emotions, while Chinese IDMs emphasize emotional\nexpression and social connection (44%) with a more positive tone. We also\nobserve that longer English IDMs often transfer high ETH values for\nprotocol-level purposes, while longer Chinese IDMs tend to involve symbolic\ntransfer amounts for emotional intent. Moreover, we find that the IDM\nparticipants tend to form small, loosely connected communities (59.99%). Our\nfindings highlight culturally and functionally divergent use cases of the IDM\nchannel across user communities. We further examine the security relevance of\nIDMs in on-chain attacks. Many victims use them to appeal to attackers for fund\nrecovery. IDMs containing negotiations or reward offers are linked to higher\nreply rates. We also analyze IDMs' regulatory implications. Their misuse for\nabuse, threats, and sexual solicitation reveals the urgent need for content\nmoderation and regulation in decentralized systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24724v1",
    "published": "2025-05-30T15:47:13+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24723v1",
    "title": "A Standing-Wave Model for the Low-Frequency Dynamics of a Turbulent Separation Bubble",
    "authors": [
      "Lukas M. Fuchs",
      "Ben Steinfurth",
      "Jakob G. R. von Saldern",
      "Julien Weiss",
      "Kilian Oberleithner"
    ],
    "abstract": "This study investigates the low-frequency dynamics of a turbulent separation\nbubble (TSB) forming over a backward-facing ramp, with a focus on\nvery-large-scale coherent structures associated with the so-called 'breathing\nmotion'. Using time-resolved particle image velocimetry (PIV) in both\nstreamwise and spanwise planes, we examine the role of sidewall confinement, an\naspect largely overlooked in previous research. Spectral proper orthogonal\ndecomposition (SPOD) of the streamwise velocity field reveals a dominant\nlow-rank mode at very low Strouhal numbers ($St =$ 0.01-0.05), consistent with\nprior observations of TSB breathing. Strikingly, the spanwise-oriented PIV data\nuncover a previously unreported standing wave pattern, characterized by\ndiscrete spanwise wavenumbers and nodal/antinodal structures, suggesting the\npresence of spanwise resonance. To explain these observations, we construct a\nresolvent-based model that imposes free-slip conditions at the sidewall\nlocations by superposing left- and right-traveling three-dimensional modes. The\nmodel accurately reproduces the spanwise structure and frequency content of the\nmeasured SPOD modes, demonstrating that sidewall reflections lead to the\nformation of standing wave-like patterns. The analysis further indicates that\nthe observed dynamics are caused by the lift-up mechanism driving the formation\nof large-scale streaks that span the domain width. Our findings highlight the\ncritical influence of spanwise boundary conditions on the selection and\nstructure of low-frequency modes in TSBs. This has direct implications for both\nexperimental and numerical studies, particularly those relying on\nspanwise-periodic boundary conditions, and offers a low-order framework for\npredicting sidewall-induced modal dynamics in separated flows.",
    "pdf_url": "http://arxiv.org/pdf/2505.24723v1",
    "published": "2025-05-30T15:43:34+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24722v1",
    "title": "HELM: Hyperbolic Large Language Models via Mixture-of-Curvature Experts",
    "authors": [
      "Neil He",
      "Rishabh Anand",
      "Hiren Madhu",
      "Ali Maatouk",
      "Smita Krishnaswamy",
      "Leandros Tassiulas",
      "Menglin Yang",
      "Rex Ying"
    ],
    "abstract": "Large language models (LLMs) have shown great success in text modeling tasks\nacross domains. However, natural language exhibits inherent semantic\nhierarchies and nuanced geometric structure, which current LLMs do not capture\ncompletely owing to their reliance on Euclidean operations. Recent studies have\nalso shown that not respecting the geometry of token embeddings leads to\ntraining instabilities and degradation of generative capabilities. These\nfindings suggest that shifting to non-Euclidean geometries can better align\nlanguage models with the underlying geometry of text. We thus propose to\noperate fully in Hyperbolic space, known for its expansive, scale-free, and\nlow-distortion properties. We thus introduce HELM, a family of HypErbolic Large\nLanguage Models, offering a geometric rethinking of the Transformer-based LLM\nthat addresses the representational inflexibility, missing set of necessary\noperations, and poor scalability of existing hyperbolic LMs. We additionally\nintroduce a Mixture-of-Curvature Experts model, HELM-MICE, where each expert\noperates in a distinct curvature space to encode more fine-grained geometric\nstructure from text, as well as a dense model, HELM-D. For HELM-MICE, we\nfurther develop hyperbolic Multi-Head Latent Attention (HMLA) for efficient,\nreduced-KV-cache training and inference. For both models, we develop essential\nhyperbolic equivalents of rotary positional encodings and RMS normalization. We\nare the first to train fully hyperbolic LLMs at billion-parameter scale, and\nevaluate them on well-known benchmarks such as MMLU and ARC, spanning STEM\nproblem-solving, general knowledge, and commonsense reasoning. Our results show\nconsistent gains from our HELM architectures -- up to 4% -- over popular\nEuclidean architectures used in LLaMA and DeepSeek, highlighting the efficacy\nand enhanced reasoning afforded by hyperbolic geometry in large-scale LM\npretraining.",
    "pdf_url": "http://arxiv.org/pdf/2505.24722v1",
    "published": "2025-05-30T15:42:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24721v1",
    "title": "Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach",
    "authors": [
      "Nick Rossenbach",
      "Benedikt Hilmes",
      "Leon Brackmann",
      "Moritz Gunz",
      "Ralf Schlüter"
    ],
    "abstract": "Memristor-based hardware offers new possibilities for energy-efficient\nmachine learning (ML) by providing analog in-memory matrix multiplication.\nCurrent hardware prototypes cannot fit large neural networks, and related\nliterature covers only small ML models for tasks like MNIST or single word\nrecognition. Simulation can be used to explore how hardware properties affect\nlarger models, but existing software assumes simplified hardware. We propose a\nPyTorch-based library based on \"Synaptogen\" to simulate neural network\nexecution with accurately captured memristor hardware properties. For the first\ntime, we show how an ML system with millions of parameters would behave on\nmemristor hardware, using a Conformer trained on the speech recognition task\nTED-LIUMv2 as example. With adjusted quantization-aware training, we limit the\nrelative degradation in word error rate to 25% when using a 3-bit weight\nprecision to execute linear operations via simulated analog computation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24721v1",
    "published": "2025-05-30T15:42:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AR",
      "cs.ET"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24720v1",
    "title": "Birational equivalence of Severi-Brauer varieties",
    "authors": [
      "János Kollár"
    ],
    "abstract": "We prove Amitsur's conjecture for Severi-Brauer varieties whose index is not\na prime power.",
    "pdf_url": "http://arxiv.org/pdf/2505.24720v1",
    "published": "2025-05-30T15:42:29+00:00",
    "categories": [
      "math.AG",
      "math.RA"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24719v1",
    "title": "On the geometry of holomorphic curves and complex surface",
    "authors": [
      "Amanda Dias Falqueto",
      "Farid Tari"
    ],
    "abstract": "We investigate the geometry of holomorphic curves and complex surfaces from\nthe perspective of singularity theory. We show that, with a suitable choice of\na complex bilinear symmetric form, the families of functions and mappings that\nmeasure the contact between curves or surfaces and model objects become\nholomorphic. This allows the application of singularity theory, yielding\nanalogues of classical results from the real case. Our approach enables the\ndefinition of geometric invariants of curves, which we call the $C$-curvature\nand $C$-torsion, as well as surface invariants such as the $C$-principal\ncurvature and $C$-Gaussian curvature. It also gives geometric meaning to the\ncomplexification of of the families measuring contact of analytic surfaces in\n$\\mathbb R^3$ with lines, planes and spheres.",
    "pdf_url": "http://arxiv.org/pdf/2505.24719v1",
    "published": "2025-05-30T15:42:21+00:00",
    "categories": [
      "math.DG",
      "57R45, 53B99"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24718v3",
    "title": "Reinforcing Video Reasoning with Focused Thinking",
    "authors": [
      "Jisheng Dang",
      "Jingze Wu",
      "Teng Wang",
      "Xuanhui Lin",
      "Nannan Zhu",
      "Hongbo Chen",
      "Wei-Shi Zheng",
      "Meng Wang",
      "Tat-Seng Chua"
    ],
    "abstract": "Recent advancements in reinforcement learning, particularly through Group\nRelative Policy Optimization (GRPO), have significantly improved multimodal\nlarge language models for complex reasoning tasks. However, two critical\nlimitations persist: 1) they often produce unfocused, verbose reasoning chains\nthat obscure salient spatiotemporal cues and 2) binary rewarding fails to\naccount for partially correct answers, resulting in high reward variance and\ninefficient learning. In this paper, we propose TW-GRPO, a novel framework that\nenhances visual reasoning with focused thinking and dense reward granularity.\nSpecifically, we employs a token weighting mechanism that prioritizes tokens\nwith high informational density (estimated by intra-group information entropy),\nsuppressing redundant tokens like generic reasoning prefixes. Furthermore, we\nreformulate RL training by shifting from single-choice to multi-choice QA\ntasks, where soft rewards enable finer-grained gradient estimation by\ndistinguishing partial correctness. Additionally, we propose question-answer\ninversion, a data augmentation strategy to generate diverse multi-choice\nsamples from existing benchmarks. Experiments demonstrate state-of-the-art\nperformance on several video reasoning and general understanding benchmarks.\nNotably, TW-GRPO achieves 50.4\\% accuracy on CLEVRER (18.8\\% improvement over\nVideo-R1) and 65.8\\% on MMVU. Our codes are available at\n\\href{https://github.com/longmalongma/TW-GRPO}.",
    "pdf_url": "http://arxiv.org/pdf/2505.24718v3",
    "published": "2025-05-30T15:42:19+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24717v1",
    "title": "PDE-Transformer: Efficient and Versatile Transformers for Physics Simulations",
    "authors": [
      "Benjamin Holzschuh",
      "Qiang Liu",
      "Georg Kohl",
      "Nils Thuerey"
    ],
    "abstract": "We introduce PDE-Transformer, an improved transformer-based architecture for\nsurrogate modeling of physics simulations on regular grids. We combine recent\narchitectural improvements of diffusion transformers with adjustments specific\nfor large-scale simulations to yield a more scalable and versatile\ngeneral-purpose transformer architecture, which can be used as the backbone for\nbuilding large-scale foundation models in physical sciences. We demonstrate\nthat our proposed architecture outperforms state-of-the-art transformer\narchitectures for computer vision on a large dataset of 16 different types of\nPDEs. We propose to embed different physical channels individually as\nspatio-temporal tokens, which interact via channel-wise self-attention. This\nhelps to maintain a consistent information density of tokens when learning\nmultiple types of PDEs simultaneously. We demonstrate that our pre-trained\nmodels achieve improved performance on several challenging downstream tasks\ncompared to training from scratch and also beat other foundation model\narchitectures for physics simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24717v1",
    "published": "2025-05-30T15:39:54+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24716v1",
    "title": "Towards Scalable Schema Mapping using Large Language Models",
    "authors": [
      "Christopher Buss",
      "Mahdis Safari",
      "Arash Termehchy",
      "Stefan Lee",
      "David Maier"
    ],
    "abstract": "The growing need to integrate information from a large number of diverse\nsources poses significant scalability challenges for data integration systems.\nThese systems often rely on manually written schema mappings, which are\ncomplex, source-specific, and costly to maintain as sources evolve. While\nrecent advances suggest that large language models (LLMs) can assist in\nautomating schema matching by leveraging both structural and natural language\ncues, key challenges remain. In this paper, we identify three core issues with\nusing LLMs for schema mapping: (1) inconsistent outputs due to sensitivity to\ninput phrasing and structure, which we propose methods to address through\nsampling and aggregation techniques; (2) the need for more expressive mappings\n(e.g., GLaV), which strain the limited context windows of LLMs; and (3) the\ncomputational cost of repeated LLM calls, which we propose to mitigate through\nstrategies like data type prefiltering.",
    "pdf_url": "http://arxiv.org/pdf/2505.24716v1",
    "published": "2025-05-30T15:36:56+00:00",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2506.06326v1",
    "title": "Memory OS of AI Agent",
    "authors": [
      "Jiazheng Kang",
      "Mingming Ji",
      "Zhe Zhao",
      "Ting Bai"
    ],
    "abstract": "Large Language Models (LLMs) face a crucial challenge from fixed context\nwindows and inadequate memory management, leading to a severe shortage of\nlong-term memory capabilities and limited personalization in the interactive\nexperience with AI agents. To overcome this challenge, we innovatively propose\na Memory Operating System, i.e., MemoryOS, to achieve comprehensive and\nefficient memory management for AI agents. Inspired by the memory management\nprinciples in operating systems, MemoryOS designs a hierarchical storage\narchitecture and consists of four key modules: Memory Storage, Updating,\nRetrieval, and Generation. Specifically, the architecture comprises three\nlevels of storage units: short-term memory, mid-term memory, and long-term\npersonal memory. Key operations within MemoryOS include dynamic updates between\nstorage units: short-term to mid-term updates follow a dialogue-chain-based\nFIFO principle, while mid-term to long-term updates use a segmented page\norganization strategy. Our pioneering MemoryOS enables hierarchical memory\nintegration and dynamic updating. Extensive experiments on the LoCoMo benchmark\nshow an average improvement of 49.11% on F1 and 46.18% on BLEU-1 over the\nbaselines on GPT-4o-mini, showing contextual coherence and personalized memory\nretention in long conversations. The implementation code is open-sourced at\nhttps://github.com/BAI-LAB/MemoryOS.",
    "pdf_url": "http://arxiv.org/pdf/2506.06326v1",
    "published": "2025-05-30T15:36:51+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24715v1",
    "title": "CoRet: Improved Retriever for Code Editing",
    "authors": [
      "Fabio Fehr",
      "Prabhu Teja Sivaprasad",
      "Luca Franceschi",
      "Giovanni Zappella"
    ],
    "abstract": "In this paper, we introduce CoRet, a dense retrieval model designed for\ncode-editing tasks that integrates code semantics, repository structure, and\ncall graph dependencies. The model focuses on retrieving relevant portions of a\ncode repository based on natural language queries such as requests to implement\nnew features or fix bugs. These retrieved code chunks can then be presented to\na user or to a second code-editing model or agent. To train CoRet, we propose a\nloss function explicitly designed for repository-level retrieval. On SWE-bench\nand Long Code Arena's bug localisation datasets, we show that our model\nsubstantially improves retrieval recall by at least 15 percentage points over\nexisting models, and ablate the design choices to show their importance in\nachieving these results.",
    "pdf_url": "http://arxiv.org/pdf/2505.24715v1",
    "published": "2025-05-30T15:36:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24714v1",
    "title": "FinMME: Benchmark Dataset for Financial Multi-Modal Reasoning Evaluation",
    "authors": [
      "Junyu Luo",
      "Zhizhuo Kou",
      "Liming Yang",
      "Xiao Luo",
      "Jinsheng Huang",
      "Zhiping Xiao",
      "Jingshu Peng",
      "Chengzhong Liu",
      "Jiaming Ji",
      "Xuanzhe Liu",
      "Sirui Han",
      "Ming Zhang",
      "Yike Guo"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have experienced rapid development\nin recent years. However, in the financial domain, there is a notable lack of\neffective and specialized multimodal evaluation datasets. To advance the\ndevelopment of MLLMs in the finance domain, we introduce FinMME, encompassing\nmore than 11,000 high-quality financial research samples across 18 financial\ndomains and 6 asset classes, featuring 10 major chart types and 21 subtypes. We\nensure data quality through 20 annotators and carefully designed validation\nmechanisms. Additionally, we develop FinScore, an evaluation system\nincorporating hallucination penalties and multi-dimensional capability\nassessment to provide an unbiased evaluation. Extensive experimental results\ndemonstrate that even state-of-the-art models like GPT-4o exhibit\nunsatisfactory performance on FinMME, highlighting its challenging nature. The\nbenchmark exhibits high robustness with prediction variations under different\nprompts remaining below 1%, demonstrating superior reliability compared to\nexisting datasets. Our dataset and evaluation protocol are available at\nhttps://huggingface.co/datasets/luojunyu/FinMME and\nhttps://github.com/luo-junyu/FinMME.",
    "pdf_url": "http://arxiv.org/pdf/2505.24714v1",
    "published": "2025-05-30T15:36:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24713v1",
    "title": "Voice Conversion Improves Cross-Domain Robustness for Spoken Arabic Dialect Identification",
    "authors": [
      "Badr M. Abdullah",
      "Matthew Baas",
      "Bernd Möbius",
      "Dietrich Klakow"
    ],
    "abstract": "Arabic dialect identification (ADI) systems are essential for large-scale\ndata collection pipelines that enable the development of inclusive speech\ntechnologies for Arabic language varieties. However, the reliability of current\nADI systems is limited by poor generalization to out-of-domain speech. In this\npaper, we present an effective approach based on voice conversion for training\nADI models that achieves state-of-the-art performance and significantly\nimproves robustness in cross-domain scenarios. Evaluated on a newly collected\nreal-world test set spanning four different domains, our approach yields\nconsistent improvements of up to +34.1% in accuracy across domains.\nFurthermore, we present an analysis of our approach and demonstrate that voice\nconversion helps mitigate the speaker bias in the ADI dataset. We release our\nrobust ADI model and cross-domain evaluation dataset to support the development\nof inclusive speech technologies for Arabic.",
    "pdf_url": "http://arxiv.org/pdf/2505.24713v1",
    "published": "2025-05-30T15:36:08+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24712v1",
    "title": "HESEIA: A community-based dataset for evaluating social biases in large language models, co-designed in real school settings in Latin America",
    "authors": [
      "Guido Ivetta",
      "Marcos J. Gomez",
      "Sofía Martinelli",
      "Pietro Palombini",
      "M. Emilia Echeveste",
      "Nair Carolina Mazzeo",
      "Beatriz Busaniche",
      "Luciana Benotti"
    ],
    "abstract": "Most resources for evaluating social biases in Large Language Models are\ndeveloped without co-design from the communities affected by these biases, and\nrarely involve participatory approaches. We introduce HESEIA, a dataset of\n46,499 sentences created in a professional development course. The course\ninvolved 370 high-school teachers and 5,370 students from 189 Latin-American\nschools. Unlike existing benchmarks, HESEIA captures intersectional biases\nacross multiple demographic axes and school subjects. It reflects local\ncontexts through the lived experience and pedagogical expertise of educators.\nTeachers used minimal pairs to create sentences that express stereotypes\nrelevant to their school subjects and communities. We show the dataset\ndiversity in term of demographic axes represented and also in terms of the\nknowledge areas included. We demonstrate that the dataset contains more\nstereotypes unrecognized by current LLMs than previous datasets. HESEIA is\navailable to support bias assessments grounded in educational communities.",
    "pdf_url": "http://arxiv.org/pdf/2505.24712v1",
    "published": "2025-05-30T15:32:48+00:00",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24711v2",
    "title": "Dense gas tracers in and between spiral arms: from Giant Molecular Filaments to star-forming clumps",
    "authors": [
      "O. Feher",
      "S. E. Ragan",
      "F. D. Priestley",
      "P. C. Clark"
    ],
    "abstract": "Giant Molecular Filaments are opportune locations in our Galaxy to study the\nstar-forming interstellar matter and its accumulation on spatial scales\ncomparable to those now becoming available for external galaxies. We mapped the\nemission of HCN(1$-$0), HCO$^+$(1$-$0), and N$_2$H$^+$(1$-$0) towards two of\nthese filaments, one associated with the Sagittarius arm and one with an\ninterarm area. Using the data alongside the COHRS $^{12}$CO(3$-$2), the CHIMPS\n$^{13}$CO(3$-$2), and $\\textit{Herschel}$-based column density maps, we\nevaluate the dense gas tracer emission characteristics and find that although\nits filling factor is the smallest among the studied species, N$_2$H$^+$ is the\nbest at tracing the truly dense gas. Significant differences can be seen\nbetween the $^{13}$CO, HCN, and $N$(H$_2$)$_{\\mathrm{dust}}$ levels of the arm\nand interarm, while the N$_2$H$^+$ emission is more uniform regardless of\nlocation, meaning that the observed variations in line ratios like\nN$_2$H$^+$/HCN or N$_2$H$^+$/$^{13}$CO are driven by species tracing\nmoderate-density gas and not the star-forming gas. In many cases, greater\nvariation in molecular emission and ratios exist between regions inside a\nfilament than between the arm and interarm environments. The choice of measure\nof the dense gas and the available spatial resolution have deep impact on the\nmulti-scale view of different environments inside a galaxy regarding molecular\nemissions, ratios, and thus the estimated star formation activity.",
    "pdf_url": "http://arxiv.org/pdf/2505.24711v2",
    "published": "2025-05-30T15:32:27+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00105v1",
    "title": "Motivando el uso y aprendizaje de Bash a través de concursos de programación",
    "authors": [
      "Luis Costero",
      "Jorge Villarrubia",
      "Francisco D. Igual"
    ],
    "abstract": "Command line learning and Bash usage are fundamental skills in systems\nadministration, software development, and data science environments. However,\ntheir teaching has been neglected in many curricula, despite its relevance in\nthe professional field. To address this gap, we developed an interactive\ncompetition that encourages students to improve their Bash skills through\npractical and competitive challenges. This gamified approach seeks to motivate\nautonomous learning and reinforce command line proficiency in a dynamic\ncontext. The results have been promising: of the 26 participating students, 85%\nconsidered the activity useful to improve their knowledge, and 71% expressed\nthe need to delve deeper into Bash for their academic and professional future.\nThese findings suggest that such initiatives may be an effective strategy to\nfoster Bash learning in academic settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.00105v1",
    "published": "2025-05-30T15:31:32+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24710v1",
    "title": "Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting",
    "authors": [
      "Wei Chen",
      "Jiahao Zhang",
      "Haipeng Zhu",
      "Boyan Xu",
      "Zhifeng Hao",
      "Keli Zhang",
      "Junjian Ye",
      "Ruichu Cai"
    ],
    "abstract": "Large language models (LLMs) have shown great potential in decision-making\ndue to the vast amount of knowledge stored within the models. However, these\npre-trained models are prone to lack reasoning abilities and are difficult to\nadapt to new environments, further hindering their application to complex\nreal-world tasks. To address these challenges, inspired by the human cognitive\nprocess, we propose Causal-aware LLMs, which integrate the structural causal\nmodel (SCM) into the decision-making process to model, update, and utilize\nstructured knowledge of the environment in a ``learning-adapting-acting\"\nparadigm. Specifically, in the learning stage, we first utilize an LLM to\nextract the environment-specific causal entities and their causal relations to\ninitialize a structured causal model of the environment. Subsequently,in the\nadapting stage, we update the structured causal model through external feedback\nabout the environment, via an idea of causal intervention. Finally, in the\nacting stage, Causal-aware LLMs exploit structured causal knowledge for more\nefficient policy-making through the reinforcement learning agent. The above\nprocesses are performed iteratively to learn causal knowledge, ultimately\nenabling the causal-aware LLMs to achieve a more accurate understanding of the\nenvironment and make more efficient decisions. Experimental results across 22\ndiverse tasks within the open-world game ``Crafter\" validate the effectiveness\nof our proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.24710v1",
    "published": "2025-05-30T15:30:44+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24709v1",
    "title": "On Symmetric Losses for Robust Policy Optimization with Noisy Preferences",
    "authors": [
      "Soichiro Nishimori",
      "Yu-Jie Zhang",
      "Thanawat Lodkaew",
      "Masashi Sugiyama"
    ],
    "abstract": "Optimizing policies based on human preferences is key to aligning language\nmodels with human intent. This work focuses on reward modeling, a core\ncomponent in reinforcement learning from human feedback (RLHF), and offline\npreference optimization, such as direct preference optimization. Conventional\napproaches typically assume accurate annotations. However, real-world\npreference data often contains noise due to human errors or biases. We propose\na principled framework for robust policy optimization under noisy preferences,\nviewing reward modeling as a classification problem. This allows us to leverage\nsymmetric losses, known for their robustness to label noise in classification,\nleading to our Symmetric Preference Optimization (SymPO) method. We prove that\nsymmetric losses enable successful policy optimization even under noisy labels,\nas the resulting reward remains rank-preserving -- a property sufficient for\npolicy improvement. Experiments on synthetic and real-world tasks demonstrate\nthe effectiveness of SymPO.",
    "pdf_url": "http://arxiv.org/pdf/2505.24709v1",
    "published": "2025-05-30T15:30:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24708v1",
    "title": "Efficient Bayesian multi-fidelity inverse analysis for expensive and non-differentiable physics-based simulations in high stochastic dimensions",
    "authors": [
      "Jonas Nitzler",
      "Bugrahan Z. Temür",
      "Phaedon-Stelios Koutsourelakis",
      "Wolfgang A. Wall"
    ],
    "abstract": "High-dimensional Bayesian inverse analysis (dim >> 100) is mostly unfeasible\nfor computationally demanding, nonlinear physics-based high-fidelity (HF)\nmodels. Usually, the use of more efficient gradient-based inference schemes is\nimpeded if the multi-physics models are provided by complex legacy codes.\nAdjoint-based derivatives are either exceedingly cumbersome to derive or\nnon-existent for practically relevant large-scale nonlinear and coupled\nmulti-physics problems. Similarly, holistic automated differentiation w.r.t.\nprimary variables of multi-physics codes is usually not yet an option and\nrequires extensive code restructuring if not considered from the outset in the\nsoftware design. This absence of differentiability further exacerbates the\nalready present computational challenges. To overcome the existing limitations,\nwe propose a novel inference approach called Bayesian multi-fidelity inverse\nanalysis (BMFIA), which leverages simpler and computationally cheaper\nlower-fidelity (LF) models that are designed to provide model derivatives.\nBMFIA learns a simple, probabilistic dependence of the LF and HF models, which\nis then employed in an altered likelihood formulation to statistically correct\nthe inaccurate LF response. From a Bayesian viewpoint, this dependence\nrepresents a multi-fidelity conditional density (discriminative model). We\ndemonstrate how this multi-fidelity conditional density can be learned robustly\nin the small data regime from only a few HF and LF simulations (50 to 300),\nwhich would not be sufficient for naive surrogate approaches. The formulation\nis fully differentiable and allows the flexible design of a wide range of LF\nmodels. We demonstrate that BMFIA solves Bayesian inverse problems for\nscenarios that used to be prohibitive, such as finely-resolved spatial\nreconstruction problems for nonlinear and transient coupled poro-elastic media\nphysics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24708v1",
    "published": "2025-05-30T15:29:36+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24707v1",
    "title": "Vulnerability Measures and Zagreb Indices of Graphs",
    "authors": [
      "Sanju Vaidya",
      "Cheng Chang"
    ],
    "abstract": "This paper establishes sharp bounds for the vulnerability measures of\ncloseness and generalized closeness in graphs and identifies graphs that attain\nthese bounds. It further develops bounds incorporating Zagreb indices for\ntriangle- and quadrangle-free graphs, yielding formulas for closeness and\ngeneralized closeness in such graphs with diameter at most 3. Moreover, using\nZagreb indices, we derive bounds for trees and connected graphs with girth at\nleast 7, which are attained by graphs with diameter at most 4. Finally,\nformulas for closeness and generalized closeness in specific trees are\nestablished using Zagreb indices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24707v1",
    "published": "2025-05-30T15:28:59+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24706v1",
    "title": "The quantitative semi-classical limit of a large Fermi system at zero temperature",
    "authors": [
      "Esteban Cárdenas"
    ],
    "abstract": "In this article we consider a large system of fermions in a combined\nmean-field and semiclassical limit, in three dimensions. We investigate the\nconvergence of the Wigner function of the ground state, towards the classical\nThomas-Fermi theory. The main novelty of the present article is quantifying the\nconvergence rate with respect to the semi-classical parameter. One of the main\ningredients is a recent result on the validity of semi-classical commutator\nestimates satisfied by the Hartree theory. Singular potentials, up to the\nCoulomb interaction, are included.",
    "pdf_url": "http://arxiv.org/pdf/2505.24706v1",
    "published": "2025-05-30T15:27:16+00:00",
    "categories": [
      "math-ph",
      "math.AP",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24705v1",
    "title": "RT-X Net: RGB-Thermal cross attention network for Low-Light Image Enhancement",
    "authors": [
      "Raman Jha",
      "Adithya Lenka",
      "Mani Ramanagopal",
      "Aswin Sankaranarayanan",
      "Kaushik Mitra"
    ],
    "abstract": "In nighttime conditions, high noise levels and bright illumination sources\ndegrade image quality, making low-light image enhancement challenging. Thermal\nimages provide complementary information, offering richer textures and\nstructural details. We propose RT-X Net, a cross-attention network that fuses\nRGB and thermal images for nighttime image enhancement. We leverage\nself-attention networks for feature extraction and a cross-attention mechanism\nfor fusion to effectively integrate information from both modalities. To\nsupport research in this domain, we introduce the Visible-Thermal Image\nEnhancement Evaluation (V-TIEE) dataset, comprising 50 co-located visible and\nthermal images captured under diverse nighttime conditions. Extensive\nevaluations on the publicly available LLVIP dataset and our V-TIEE dataset\ndemonstrate that RT-X Net outperforms state-of-the-art methods in low-light\nimage enhancement. The code and the V-TIEE can be found here\nhttps://github.com/jhakrraman/rt-xnet.",
    "pdf_url": "http://arxiv.org/pdf/2505.24705v1",
    "published": "2025-05-30T15:26:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24704v1",
    "title": "K$^2$IE: Kernel Method-based Kernel Intensity Estimators for Inhomogeneous Poisson Processes",
    "authors": [
      "Hideaki Kim",
      "Tomoharu Iwata",
      "Akinori Fujino"
    ],
    "abstract": "Kernel method-based intensity estimators, formulated within reproducing\nkernel Hilbert spaces (RKHSs), and classical kernel intensity estimators (KIEs)\nhave been among the most easy-to-implement and feasible methods for estimating\nthe intensity functions of inhomogeneous Poisson processes. While both\napproaches share the term \"kernel\", they are founded on distinct theoretical\nprinciples, each with its own strengths and limitations. In this paper, we\npropose a novel regularized kernel method for Poisson processes based on the\nleast squares loss and show that the resulting intensity estimator involves a\nspecialized variant of the representer theorem: it has the dual coefficient of\nunity and coincides with classical KIEs. This result provides new theoretical\ninsights into the connection between classical KIEs and kernel method-based\nintensity estimators, while enabling us to develop an efficient KIE by\nleveraging advanced techniques from RKHS theory. We refer to the proposed model\nas the kernel method-based kernel intensity estimator (K$^2$IE). Through\nexperiments on synthetic datasets, we show that K$^2$IE achieves comparable\npredictive performance while significantly surpassing the state-of-the-art\nkernel method-based estimator in computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.24704v1",
    "published": "2025-05-30T15:26:35+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24703v1",
    "title": "PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches",
    "authors": [
      "Dennis Jacob",
      "Chong Xiang",
      "Prateek Mittal"
    ],
    "abstract": "Deep learning techniques have enabled vast improvements in computer vision\ntechnologies. Nevertheless, these models are vulnerable to adversarial patch\nattacks which catastrophically impair performance. The physically realizable\nnature of these attacks calls for certifiable defenses, which feature provable\nguarantees on robustness. While certifiable defenses have been successfully\napplied to single-label classification, limited work has been done for\nmulti-label classification. In this work, we present PatchDEMUX, a certifiably\nrobust framework for multi-label classifiers against adversarial patches. Our\napproach is a generalizable method which can extend any existing certifiable\ndefense for single-label classification; this is done by considering the\nmulti-label classification task as a series of isolated binary classification\nproblems to provably guarantee robustness. Furthermore, in the scenario where\nan attacker is limited to a single patch we propose an additional certification\nprocedure that can provide tighter robustness bounds. Using the current\nstate-of-the-art (SOTA) single-label certifiable defense PatchCleanser as a\nbackbone, we find that PatchDEMUX can achieve non-trivial robustness on the\nMS-COCO and PASCAL VOC datasets while maintaining high clean performance",
    "pdf_url": "http://arxiv.org/pdf/2505.24703v1",
    "published": "2025-05-30T15:25:51+00:00",
    "categories": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24702v1",
    "title": "Relative non-pluripolar product of currents on compact Hermitian manifolds",
    "authors": [
      "Zhenghao Li",
      "Shuang Su"
    ],
    "abstract": "On a class of compact Hermitian manifolds including compact K\\\"{a}hler\nmanifolds, we prove that the the relative non-pluripolar product is always\nwell-defined. We also prove the monotonicity of the relative non-pluripolar\nproduct in terms of masses on such manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2505.24702v1",
    "published": "2025-05-30T15:25:07+00:00",
    "categories": [
      "math.DG",
      "math.CV"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24701v1",
    "title": "Multi-Domain ABSA Conversation Dataset Generation via LLMs for Real-World Evaluation and Model Comparison",
    "authors": [
      "Tejul Pandit",
      "Meet Raval",
      "Dhvani Upadhyay"
    ],
    "abstract": "Aspect-Based Sentiment Analysis (ABSA) offers granular insights into opinions\nbut often suffers from the scarcity of diverse, labeled datasets that reflect\nreal-world conversational nuances. This paper presents an approach for\ngenerating synthetic ABSA data using Large Language Models (LLMs) to address\nthis gap. We detail the generation process aimed at producing data with\nconsistent topic and sentiment distributions across multiple domains using\nGPT-4o. The quality and utility of the generated data were evaluated by\nassessing the performance of three state-of-the-art LLMs (Gemini 1.5 Pro,\nClaude 3.5 Sonnet, and DeepSeek-R1) on topic and sentiment classification\ntasks. Our results demonstrate the effectiveness of the synthetic data,\nrevealing distinct performance trade-offs among the models: DeepSeekR1 showed\nhigher precision, Gemini 1.5 Pro and Claude 3.5 Sonnet exhibited strong recall,\nand Gemini 1.5 Pro offered significantly faster inference. We conclude that\nLLM-based synthetic data generation is a viable and flexible method for\ncreating valuable ABSA resources, facilitating research and model evaluation\nwithout reliance on limited or inaccessible real-world labeled data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24701v1",
    "published": "2025-05-30T15:24:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24700v1",
    "title": "Elliptic Calogero-Sutherland model and conformal field theory",
    "authors": [
      "Edwin Langmann"
    ],
    "abstract": "In a project with Gordon Semenoff on 1+1 dimensional QCD many years ago (when\nhe was my postdoc advisor), we stumbled over a method to solve\nCalogero-Moser-Sutherland models using gauge theories. Since then, these models\nhave reappeared in different forms in many of my research projects. In this\ncontribution, I describe a recent such project where a second quantization of\nthe elliptic Calogero-Sutherland model led us to a new soliton equation and a\nnon-relativistic variant of the Coleman correspondence. (Work with Bjorn\nBerntson and Jonatan Lenells.)",
    "pdf_url": "http://arxiv.org/pdf/2505.24700v1",
    "published": "2025-05-30T15:23:13+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24699v1",
    "title": "Geometric Littlewood-Offord problems via lattice point counting",
    "authors": [
      "Alexandr Grebennikov",
      "Matthew Kwan"
    ],
    "abstract": "Consider nonzero vectors $a_{1},\\dots,a_{n}\\in\\mathbb{C}^{k}$, independent\nRademacher random variables $\\xi_{1},\\dots,\\xi_{n}$, and a set\n$S\\subseteq\\mathbb{C}^{k}$. What upper bounds can we prove on the probability\nthat the random sum $\\xi_{1}a_{1}+\\dots+\\xi_{n}a_{n}$ lies in $S$? We develop a\ngeneral framework that allows us to reduce problems of this type to counting\nlattice points in $S$. We apply this framework with known results from\ndiophantine geometry to prove various bounds when $S$ is a set of points in\nconvex position, an algebraic variety, or a semialgebraic set. In particular,\nthis resolves conjectures of Fox-Kwan-Spink and Kwan-Sauermann.\n  We also obtain some corollaries for the polynomial Littlewood-Offord problem,\nfor polynomials that have bounded Chow rank (i.e., can be written as a\npolynomial of a bounded number of linear forms). For example, one of our\nresults confirms a conjecture of Nguyen and Vu in the special case of\npolynomials with bounded Chow rank: if a bounded-degree polynomial\n$F\\in\\mathbb{C}[x_{1},\\dots,x_{n}]$ has bounded Chow rank and ''robustly\ndepends on at least $b$ of its variables'', then\n$\\mathbb{P}[F(\\xi_{1},\\dots,\\xi_{n})=0]\\le O(1/\\sqrt{b})$. We also prove\nsignificantly stronger bounds when $F$ is ''robustly irreducible'', towards a\nconjecture of Costello.",
    "pdf_url": "http://arxiv.org/pdf/2505.24699v1",
    "published": "2025-05-30T15:22:29+00:00",
    "categories": [
      "math.CO",
      "math.NT",
      "math.PR"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24698v1",
    "title": "Next Generation Authentication for Data Spaces: An Authentication Flow Based On Grant Negotiation And Authorization Protocol For Verifiable Presentations (GNAP4VP)",
    "authors": [
      "Rodrigo Menéndez",
      "Andres Munoz-Arcentales",
      "Joaquín Salvachúa",
      "Carlos Aparicio",
      "Irene Plaza",
      "Gabriel Huecas"
    ],
    "abstract": "Identity verification in Data Spaces is a fundamental aspect of ensuring\nsecurity and privacy in digital environments. This paper presents an identity\nverification protocol tailored for shared data environments within Data Spaces.\nThis protocol extends the Grant Negotiation and Authorization Protocol (GNAP)\nand integrates OpenID Connect for Verifiable Presentations (OIDC4VP) along with\nsupport for Linked Verifiable Presentations (LVP), providing a robust\nfoundation for secure and privacy-preserving interactions. The proposed\nsolution adheres to the principles of Self-Sovereign Identity (SSI) to\nfacilitate decentralized, user-centric identity management while maintaining\nflexibility through protocol negotiation. Two alternative interaction flows are\nintroduced: a \"Wallet-Driven Interaction\" utilizing OIDC4VP, and a \"LVP\nAuthorization\" model for fully automated machine-to-machine communication.\nThese flows address critical challenges encountered in Data Spaces, including\nprivacy, interoperability, and regulatory compliance while simultaneously\nensuring scalability and minimizing trust assumptions. The paper provides a\ndetailed technical design, outlining the implementation considerations, and\ndemonstrating how the proposed flows guarantee verifiable, secure, and\nefficient interactions between participants. This work contributes towards the\nestablishment of a more trustworthy and sovereign digital infrastructure, in\nalignment with emerging European data governance initiatives.",
    "pdf_url": "http://arxiv.org/pdf/2505.24698v1",
    "published": "2025-05-30T15:20:39+00:00",
    "categories": [
      "cs.CR",
      "cs.ET"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24697v1",
    "title": "Towards a unified user modeling language for engineering human centered AI systems",
    "authors": [
      "Aaron Conrardy",
      "Alfredo Capozucca",
      "Jordi Cabot"
    ],
    "abstract": "In today's digital society, personalization has become a crucial aspect of\nsoftware applications, significantly impacting user experience and engagement.\nA new wave of intelligent user interfaces, such as AI-based conversational\nagents, has the potential to enable such personalization beyond what other\ntypes of interfaces could offer in the past. Personalization requires the\nability to specify a complete user profile, covering as many dimensions as\npossible, such as potential accessibility constraints, interaction preferences,\nand even hobbies. In this sense, this paper presents the concepts of a unified\nuser modeling language, aimed to combine previous approaches in a single\nproposal. Additionally, a proof of concept has been developed that leverages\nuser profiles modeled using our language to automatically adapt a\nconversational agent.",
    "pdf_url": "http://arxiv.org/pdf/2505.24697v1",
    "published": "2025-05-30T15:20:15+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24696v2",
    "title": "Cohomotopy and flux quantization in $M$-theory",
    "authors": [
      "Daniel Grady"
    ],
    "abstract": "We identify some of the $k$-invariants for the Postnikov tower of the stable\nand unstable 4-sphere. Assuming the stable Hypothesis H of\nFiorenza--Sati--Schreiber, we use the resulting obstruction theory to prove\nthat the Chern--Simons term in the effective action of M-theory is well\ndefined. In particular, we do not assume the presence of an $E_8$-gauge field.",
    "pdf_url": "http://arxiv.org/pdf/2505.24696v2",
    "published": "2025-05-30T15:19:36+00:00",
    "categories": [
      "math.AT",
      "hep-th"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24695v1",
    "title": "Likelihoods for Stochastic Gravitational Wave Background Data Analysis",
    "authors": [
      "Gabriele Franciolini",
      "Mauro Pieroni",
      "Angelo Ricciardone",
      "Joseph D. Romano"
    ],
    "abstract": "We present a systematic study of likelihood functions used for Stochastic\nGravitational Wave Background (SGWB) searches. By dividing the data into many\nshort segments, one customarily takes advantage of the Central Limit Theorem to\njustify a Gaussian crosscorrelation likelihood. We show, with a hierarchy of\never more realistic examples, beginning with a single frequency bin and one\ndetector, and then moving to two and three detectors with white and colored\nsignal and noise, that approximating the exact Whittle likelihood by various\nGaussian alternatives can induce systematic biases in the estimation of the\nSGWB parameters. We derive several approximations for the full likelihood and\nidentify regimes where Gaussianity breaks down. We also discuss the possibility\nof conditioning the full likelihood on fiducial noise estimates to produce\nunbiased SGWB parameter estimation. We show that for some segment durations and\nbandwidths, particularly in space-based and pulsar-timing arrays, the bias can\nexceed the statistical uncertainty. Our results provide practical guidance for\nsegment choice, likelihood selection, and data-compression strategies to ensure\nrobust SGWB inference in current and next-generation gravitational wave\ndetectors.",
    "pdf_url": "http://arxiv.org/pdf/2505.24695v1",
    "published": "2025-05-30T15:18:51+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.15709v3",
    "title": "Studying and Improving Graph Neural Network-based Motif Estimation",
    "authors": [
      "Pedro C. Vieira",
      "Miguel E. P. Silva",
      "Pedro Manuel Pinto Ribeiro"
    ],
    "abstract": "Graph Neural Networks (GNNs) are a predominant method for graph\nrepresentation learning. However, beyond subgraph frequency estimation, their\napplication to network motif significance-profile (SP) prediction remains\nunder-explored, with no established benchmarks in the literature. We propose to\naddress this problem, framing SP estimation as a task independent of subgraph\nfrequency estimation. Our approach shifts from frequency counting to direct SP\nestimation and modulates the problem as multitarget regression. The\nreformulation is optimised for interpretability, stability and scalability on\nlarge graphs. We validate our method using a large synthetic dataset and\nfurther test it on real-world graphs. Our experiments reveal that 1-WL limited\nmodels struggle to make precise estimations of SPs. However, they can\ngeneralise to approximate the graph generation processes of networks by\ncomparing their predicted SP with the ones originating from synthetic\ngenerators. This first study on GNN-based motif estimation also hints at how\nusing direct SP estimation can help go past the theoretical limitations that\nmotif estimation faces when performed through subgraph counting.",
    "pdf_url": "http://arxiv.org/pdf/2506.15709v3",
    "published": "2025-05-30T15:17:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24694v1",
    "title": "Bayesian nonparametric clustering for spatio-temporal data, with an application to air pollution",
    "authors": [
      "Luca Aiello",
      "Raffaele Argiento",
      "Sirio Legramanti",
      "Lucia Paci"
    ],
    "abstract": "Air pollution is a major global health hazard, with fine particulate matter\n(PM10) linked to severe respiratory and cardiovascular diseases. Hence,\nanalyzing and clustering spatio-temporal air quality data is crucial for\nunderstanding pollution dynamics and guiding policy interventions. This work\nprovides a review of Bayesian nonparametric clustering methods, with a\nparticular focus on their application to spatio-temporal data, which are\nubiquitous in environmental sciences. We first introduce key modeling\napproaches for point-referenced spatio-temporal data, highlighting their\nflexibility in capturing complex spatial and temporal dependencies. We then\nreview recent advancements in Bayesian clustering, focusing on spatial product\npartition models, which incorporate spatial structure into the clustering\nprocess. We illustrate the proposed methods on PM10 monitoring data from\nNorthern Italy, demonstrating their ability to identify meaningful pollution\npatterns. This review highlights the potential of Bayesian nonparametric\nmethods for environmental risk assessment and offers insights into future\nresearch directions in spatio-temporal clustering for public health and\nenvironmental science.",
    "pdf_url": "http://arxiv.org/pdf/2505.24694v1",
    "published": "2025-05-30T15:16:44+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24693v1",
    "title": "Conformal Prediction for Zero-Shot Models",
    "authors": [
      "Julio Silva-Rodríguez",
      "Ismail Ben Ayed",
      "Jose Dolz"
    ],
    "abstract": "Vision-language models pre-trained at large scale have shown unprecedented\nadaptability and generalization to downstream tasks. Although its\ndiscriminative potential has been widely explored, its reliability and\nuncertainty are still overlooked. In this work, we investigate the capabilities\nof CLIP models under the split conformal prediction paradigm, which provides\ntheoretical guarantees to black-box models based on a small, labeled\ncalibration set. In contrast to the main body of literature on conformal\npredictors in vision classifiers, foundation models exhibit a particular\ncharacteristic: they are pre-trained on a one-time basis on an inaccessible\nsource domain, different from the transferred task. This domain drift\nnegatively affects the efficiency of the conformal sets and poses additional\nchallenges. To alleviate this issue, we propose Conf-OT, a transfer learning\nsetting that operates transductive over the combined calibration and query\nsets. Solving an optimal transport problem, the proposed method bridges the\ndomain gap between pre-training and adaptation without requiring additional\ndata splits but still maintaining coverage guarantees. We comprehensively\nexplore this conformal prediction strategy on a broad span of 15 datasets and\nthree non-conformity scores. Conf-OT provides consistent relative improvements\nof up to 20% on set efficiency while being 15 times faster than popular\ntransductive approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.24693v1",
    "published": "2025-05-30T15:16:19+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24692v1",
    "title": "Quick-Draw Bandits: Quickly Optimizing in Nonstationary Environments with Extremely Many Arms",
    "authors": [
      "Derek Everett",
      "Fred Lu",
      "Edward Raff",
      "Fernando Camacho",
      "James Holt"
    ],
    "abstract": "Canonical algorithms for multi-armed bandits typically assume a stationary\nreward environment where the size of the action space (number of arms) is\nsmall. More recently developed methods typically relax only one of these\nassumptions: existing non-stationary bandit policies are designed for a small\nnumber of arms, while Lipschitz, linear, and Gaussian process bandit policies\nare designed to handle a large (or infinite) number of arms in stationary\nreward environments under constraints on the reward function. In this\nmanuscript, we propose a novel policy to learn reward environments over a\ncontinuous space using Gaussian interpolation. We show that our method\nefficiently learns continuous Lipschitz reward functions with\n$\\mathcal{O}^*(\\sqrt{T})$ cumulative regret. Furthermore, our method naturally\nextends to non-stationary problems with a simple modification. We finally\ndemonstrate that our method is computationally favorable (100-10000x faster)\nand experimentally outperforms sliding Gaussian process policies on datasets\nwith non-stationarity and an extremely large number of arms.",
    "pdf_url": "http://arxiv.org/pdf/2505.24692v1",
    "published": "2025-05-30T15:15:18+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24691v1",
    "title": "Speech-to-Text Translation with Phoneme-Augmented CoT: Enhancing Cross-Lingual Transfer in Low-Resource Scenarios",
    "authors": [
      "Gerard I. Gállego",
      "Oriol Pareras",
      "Martí Cortada Garcia",
      "Lucas Takanori",
      "Javier Hernando"
    ],
    "abstract": "We propose a Speech-to-Text Translation (S2TT) approach that integrates\nphoneme representations into a Chain-of-Thought (CoT) framework to improve\ntranslation in low-resource and zero-resource settings. By introducing phoneme\nrecognition as an intermediate step, we enhance cross-lingual transfer,\nenabling translation even for languages with no labeled speech data. Our system\nbuilds on a multilingual LLM, which we extend to process speech and phonemes.\nTraining follows a curriculum learning strategy that progressively introduces\nmore complex tasks. Experiments on multilingual S2TT benchmarks show that\nphoneme-augmented CoT improves translation quality in low-resource conditions\nand enables zero-resource translation, while slightly impacting high-resource\nperformance. Despite this trade-off, our findings demonstrate that\nphoneme-based CoT is a promising step toward making S2TT more accessible across\ndiverse languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.24691v1",
    "published": "2025-05-30T15:15:00+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24690v1",
    "title": "Learning reusable concepts across different egocentric video understanding tasks",
    "authors": [
      "Simone Alberto Peirone",
      "Francesca Pistilli",
      "Antonio Alliegro",
      "Tatiana Tommasi",
      "Giuseppe Averta"
    ],
    "abstract": "Our comprehension of video streams depicting human activities is naturally\nmultifaceted: in just a few moments, we can grasp what is happening, identify\nthe relevance and interactions of objects in the scene, and forecast what will\nhappen soon, everything all at once. To endow autonomous systems with such\nholistic perception, learning how to correlate concepts, abstract knowledge\nacross diverse tasks, and leverage tasks synergies when learning novel skills\nis essential. In this paper, we introduce Hier-EgoPack, a unified framework\nable to create a collection of task perspectives that can be carried across\ndownstream tasks and used as a potential source of additional insights, as a\nbackpack of skills that a robot can carry around and use when needed.",
    "pdf_url": "http://arxiv.org/pdf/2505.24690v1",
    "published": "2025-05-30T15:14:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24689v1",
    "title": "BPE Stays on SCRIPT: Structured Encoding for Robust Multilingual Pretokenization",
    "authors": [
      "Sander Land",
      "Catherine Arnett"
    ],
    "abstract": "Byte Pair Encoding (BPE) tokenizers, widely used in Large Language Models,\nface challenges in multilingual settings, including penalization of non-Western\nscripts and the creation of tokens with partial UTF-8 sequences.\nPretokenization, often reliant on complex regular expressions, can also\nintroduce fragility and unexpected edge cases. We propose SCRIPT (Script\nCategory Representation in PreTokenization), a novel encoding scheme that\nbypasses UTF-8 byte conversion by using initial tokens based on Unicode script\nand category properties. This approach enables a simple, rule-based\npretokenization strategy that respects script boundaries, offering a robust\nalternative to pretokenization strategies based on regular expressions. We also\nintroduce and validate a constrained BPE merging strategy that enforces\ncharacter integrity, applicable to both SCRIPT-BPE and byte-based BPE. Our\nexperiments demonstrate that SCRIPT-BPE achieves competitive compression while\neliminating encoding-based penalties for non-Latin-script languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.24689v1",
    "published": "2025-05-30T15:12:41+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24688v3",
    "title": "Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration",
    "authors": [
      "Qinglin Zhu",
      "Runcong Zhao",
      "Hanqi Yan",
      "Yulan He",
      "Yudong Chen",
      "Lin Gui"
    ],
    "abstract": "Large Language Models (LLMs) struggle with complex reasoning due to limited\ndiversity and inefficient search. We propose Soft Reasoning, an embedding-based\nsearch framework that optimises the embedding of the first token to guide\ngeneration. It combines (1) embedding perturbation for controlled exploration\nand (2) Bayesian optimisation to refine embeddings via a verifier-guided\nobjective, balancing exploration and exploitation. This approach improves\nreasoning accuracy and coherence while avoiding reliance on heuristic search.\nExperiments demonstrate superior correctness with minimal computation, making\nit a scalable, model-agnostic solution. The code is released at\nhttps://github.com/alickzhu/Soft-Reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.24688v3",
    "published": "2025-05-30T15:11:52+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24687v1",
    "title": "TumorGen: Boundary-Aware Tumor-Mask Synthesis with Rectified Flow Matching",
    "authors": [
      "Shengyuan Liu",
      "Wenting Chen",
      "Boyun Zheng",
      "Wentao Pan",
      "Xiang Li",
      "Yixuan Yuan"
    ],
    "abstract": "Tumor data synthesis offers a promising solution to the shortage of annotated\nmedical datasets. However, current approaches either limit tumor diversity by\nusing predefined masks or employ computationally expensive two-stage processes\nwith multiple denoising steps, causing computational inefficiency.\nAdditionally, these methods typically rely on binary masks that fail to capture\nthe gradual transitions characteristic of tumor boundaries. We present\nTumorGen, a novel Boundary-Aware Tumor-Mask Synthesis with Rectified Flow\nMatching for efficient 3D tumor synthesis with three key components: a\nBoundary-Aware Pseudo Mask Generation module that replaces strict binary masks\nwith flexible bounding boxes; a Spatial-Constraint Vector Field Estimator that\nsimultaneously synthesizes tumor latents and masks using rectified flow\nmatching to ensure computational efficiency; and a VAE-guided mask refiner that\nenhances boundary realism. TumorGen significantly improves computational\nefficiency by requiring fewer sampling steps while maintaining pathological\naccuracy through coarse and fine-grained spatial constraints. Experimental\nresults demonstrate TumorGen's superior performance over existing tumor\nsynthesis methods in both efficiency and realism, offering a valuable\ncontribution to AI-driven cancer diagnostics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24687v1",
    "published": "2025-05-30T15:11:25+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24686v2",
    "title": "Synergistic Motifs in Gaussian Systems",
    "authors": [
      "Enrico Caprioglio",
      "Pedro A. M. Mediano",
      "Luc Berthouze"
    ],
    "abstract": "High-order interdependencies are central features of complex systems, yet a\nmechanistic explanation for their emergence remains elusive. Currently, it is\nunknown under what conditions high-order interdependencies, quantified by the\ninformation-theoretic construct of synergy, arise in systems governed by\npairwise interactions. We solve this problem by providing precise sufficient\nand necessary conditions for when synergy prevails over low-order\ninterdependencies, namely, we prove that antibalanced (highly frustrated)\ncorrelational structures in Gaussian systems are sufficient for\nsynergy-dominance and that antibalanced interaction motifs in\nOrnstein-Uhlenbeck processes are necessary for synergy-dominance. We validate\nthe applicability of these analytical insights in Ising, oscillatory, and\nempirical networks from multiple domains. Our results demonstrate that pairwise\ninteractions can give rise to synergistic information in the absence of\nexplicit high-order mechanisms, and highlight structural balance theory as an\ninstrumental conceptual framework to study high-order interdependencies.",
    "pdf_url": "http://arxiv.org/pdf/2505.24686v2",
    "published": "2025-05-30T15:10:39+00:00",
    "categories": [
      "physics.soc-ph",
      "nlin.AO"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24685v1",
    "title": "So, I climbed to the top of the pyramid of pain -- now what?",
    "authors": [
      "Vasilis Katos",
      "Emily Rosenorn-Lanng",
      "Jane Henriksen-Bulmer",
      "Ala Yankouskaya"
    ],
    "abstract": "This paper explores the evolving dynamics of cybersecurity in the age of\nadvanced AI, from the perspective of the introduced Human Layer Kill Chain\nframework. As traditional attack models like Lockheed Martin's Cyber Kill Chain\nbecome inadequate in addressing human vulnerabilities exploited by modern\nadversaries, the Humal Layer Kill Chain offers a nuanced approach that\nintegrates human psychology and behaviour into the analysis of cyber threats.\nWe detail the eight stages of the Human Layer Kill Chain, illustrating how\nAI-enabled techniques can enhance psychological manipulation in attacks. By\nmerging the Human Layer with the Cyber Kill Chain, we propose a Sociotechnical\nKill Plane that allows for a holistic examination of attackers' tactics,\ntechniques, and procedures (TTPs) across the sociotechnical landscape. This\nframework not only aids cybersecurity professionals in understanding\nadversarial methods, but also empowers non-technical personnel to engage in\nthreat identification and response. The implications for incident response and\norganizational resilience are significant, particularly as AI continues to\nshape the threat landscape.",
    "pdf_url": "http://arxiv.org/pdf/2505.24685v1",
    "published": "2025-05-30T15:09:03+00:00",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24684v1",
    "title": "Disentangling Granularity: An Implicit Inductive Bias in Factorized VAEs",
    "authors": [
      "Zihao Chen",
      "Yu Xiang",
      "Wenyong Wang"
    ],
    "abstract": "Despite the success in learning semantically meaningful, unsupervised\ndisentangled representations, variational autoencoders (VAEs) and their\nvariants face a fundamental theoretical challenge: substantial evidence\nindicates that unsupervised disentanglement is unattainable without implicit\ninductive bias, yet such bias remains elusive. In this work, we focus on\nexploring the implicit inductive bias that drive disentanglement in VAEs with\nfactorization priors. By analyzing the total correlation in \\b{eta}-TCVAE, we\nuncover a crucial implicit inductive bias called disentangling granularity,\nwhich leads to the discovery of an interesting \"V\"-shaped optimal Evidence\nLower Bound (ELBO) trajectory within the parameter space. This finding is\nvalidated through over 100K experiments using factorized VAEs and our newly\nproposed model, \\b{eta}-STCVAE. Notably, experimental results reveal that\nconventional factorized VAEs, constrained by fixed disentangling granularity,\ninherently tend to disentangle low-complexity feature. Whereas, appropriately\ntuning disentangling granularity, as enabled by \\b{eta}-STCVAE, broadens the\nrange of disentangled representations, allowing for the disentanglement of\nhigh-complexity features. Our findings unveil that disentangling granularity as\nan implicit inductive bias in factorized VAEs influence both disentanglement\nperformance and the inference of the ELBO, offering fresh insights into the\ninterpretability and inherent biases of VAEs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24684v1",
    "published": "2025-05-30T15:08:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24683v2",
    "title": "Should I Share this Translation? Evaluating Quality Feedback for User Reliance on Machine Translation",
    "authors": [
      "Dayeon Ki",
      "Kevin Duh",
      "Marine Carpuat"
    ],
    "abstract": "As people increasingly use AI systems in work and daily life, feedback\nmechanisms that help them use AI responsibly are urgently needed, particularly\nin settings where users are not equipped to assess the quality of AI\npredictions. We study a realistic Machine Translation (MT) scenario where\nmonolingual users decide whether to share an MT output, first without and then\nwith quality feedback. We compare four types of quality feedback: explicit\nfeedback that directly give users an assessment of translation quality using\n(1) error highlights and (2) LLM explanations, and implicit feedback that helps\nusers compare MT inputs and outputs through (3) backtranslation and (4)\nquestion-answer (QA) tables. We find that all feedback types, except error\nhighlights, significantly improve both decision accuracy and appropriate\nreliance. Notably, implicit feedback, especially QA tables, yields\nsignificantly greater gains than explicit feedback in terms of decision\naccuracy, appropriate reliance, and user perceptions, receiving the highest\nratings for helpfulness and trust, and the lowest for mental burden.",
    "pdf_url": "http://arxiv.org/pdf/2505.24683v2",
    "published": "2025-05-30T15:08:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24682v2",
    "title": "Operation of a dual-phase xenon detector with wavelength sensitivity from ultraviolet to infrared",
    "authors": [
      "Robert Hammann",
      "Kai Böse",
      "Steffen Form",
      "Luisa Hötzsch",
      "Teresa Marrodán Undagoitia"
    ],
    "abstract": "Xenon, in both its gaseous and liquid phase, offers excellent scintillation\nand ionization properties, making it an ideal target medium for rare event\nsearches. We report on measurements performed with a dual-phase xenon time\nprojection chamber sensitive to wavelengths from 170 nm to 1700 nm. In addition\nto the well-established ultraviolet (UV) scintillation, we observe coincident\nsignals in a photomultiplier tube sensitive to infrared (IR) light, associated\nwith both prompt scintillation in the liquid and electroluminescence in the\ngas. We study the time response of the IR signals and their dependence on the\napplied amplification field in the gas. Our findings support the observation of\nIR emission from electroluminescence and reveal a time response distinct from\nthat previously reported for $\\alpha$-particles in gas. The results suggest\nthat IR scintillation could provide enhanced signal identification and\nbackground rejection in future xenon-based detectors.",
    "pdf_url": "http://arxiv.org/pdf/2505.24682v2",
    "published": "2025-05-30T15:08:05+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.24681v1",
    "title": "Generative Knowledge Production Pipeline Driven by Academic Influencers",
    "authors": [
      "Katalin Feher",
      "Marton Demeter"
    ],
    "abstract": "Generative AI transforms knowledge production, validation, and dissemination,\nraising academic integrity and credibility concerns. This study examines 53\nacademic influencer videos that reached 5.3 million viewers to identify an\nemerging, structured, implementation-ready pipeline balancing originality,\nethical compliance, and human-AI collaboration despite the disruptive impacts.\nFindings highlight generative AI's potential to automate publication workflows\nand democratize participation in knowledge production while challenging\ntraditional scientific norms. Academic influencers emerge as key intermediaries\nin this paradigm shift, connecting bottom-up practices with institutional\npolicies to improve adaptability. Accordingly, the study proposes a generative\npublication production pipeline and a policy framework for co-intelligence\nadaptation and reinforcing credibility-centered standards in AI-powered\nresearch. These insights support scholars, educators, and policymakers in\nunderstanding AI's transformative impact by advocating responsible and\ninnovation-driven knowledge production. Additionally, they reveal pathways for\nautomating best practices, optimizing scholarly workflows, and fostering\ncreativity in academic research and publication.",
    "pdf_url": "http://arxiv.org/pdf/2505.24681v1",
    "published": "2025-05-30T15:07:01+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.SI",
      "1.2, J.4, K.4"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24680v1",
    "title": "A Simple Linear Patch Revives Layer-Pruned Large Language Models",
    "authors": [
      "Xinrui Chen",
      "Haoli Bai",
      "Tao Yuan",
      "Ruikang Liu",
      "Kang Zhao",
      "Xianzhi Yu",
      "Lu Hou",
      "Tian Guan",
      "Yonghong He",
      "Chun Yuan"
    ],
    "abstract": "Layer pruning has become a popular technique for compressing large language\nmodels (LLMs) due to its simplicity. However, existing layer pruning methods\noften suffer from significant performance drops. We identify that this\ndegradation stems from the mismatch of activation magnitudes across layers and\ntokens at the pruning interface. To address this, we propose LinearPatch, a\nsimple plug-and-play technique to revive the layer-pruned LLMs. The proposed\nmethod adopts Hadamard transformation to suppress massive outliers in\nparticular tokens, and channel-wise scaling to align the activation magnitudes.\nThese operations can be fused into a single matrix, which functions as a patch\nto bridge the pruning interface with negligible inference overhead. LinearPatch\nretains up to 94.15% performance of the original model when pruning 5 layers of\nLLaMA-3-8B on the question answering benchmark, surpassing existing\nstate-of-the-art methods by 4%. In addition, the patch matrix can be further\noptimized with memory efficient offline knowledge distillation. With only 5K\nsamples, the retained performance of LinearPatch can be further boosted to\n95.16% within 30 minutes on a single computing card.",
    "pdf_url": "http://arxiv.org/pdf/2505.24680v1",
    "published": "2025-05-30T15:06:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24679v1",
    "title": "Beyond FACS: Data-driven Facial Expression Dictionaries, with Application to Predicting Autism",
    "authors": [
      "Evangelos Sariyanidi",
      "Lisa Yankowitz",
      "Robert T. Schultz",
      "John D. Herrington",
      "Birkan Tunc",
      "Jeffrey Cohn"
    ],
    "abstract": "The Facial Action Coding System (FACS) has been used by numerous studies to\ninvestigate the links between facial behavior and mental health. The laborious\nand costly process of FACS coding has motivated the development of machine\nlearning frameworks for Action Unit (AU) detection. Despite intense efforts\nspanning three decades, the detection accuracy for many AUs is considered to be\nbelow the threshold needed for behavioral research. Also, many AUs are excluded\naltogether, making it impossible to fulfill the ultimate goal of FACS-the\nrepresentation of any facial expression in its entirety. This paper considers\nan alternative approach. Instead of creating automated tools that mimic FACS\nexperts, we propose to use a new coding system that mimics the key properties\nof FACS. Specifically, we construct a data-driven coding system called the\nFacial Basis, which contains units that correspond to localized and\ninterpretable 3D facial movements, and overcomes three structural limitations\nof automated FACS coding. First, the proposed method is completely\nunsupervised, bypassing costly, laborious and variable manual annotation.\nSecond, Facial Basis reconstructs all observable movement, rather than relying\non a limited repertoire of recognizable movements (as in automated FACS).\nFinally, the Facial Basis units are additive, whereas AUs may fail detection\nwhen they appear in a non-additive combination. The proposed method outperforms\nthe most frequently used AU detector in predicting autism diagnosis from\nin-person and remote conversations, highlighting the importance of encoding\nfacial behavior comprehensively. To our knowledge, Facial Basis is the first\nalternative to FACS for deconstructing facial expressions in videos into\nlocalized movements. We provide an open source implementation of the method at\ngithub.com/sariyanidi/FacialBasis.",
    "pdf_url": "http://arxiv.org/pdf/2505.24679v1",
    "published": "2025-05-30T15:06:01+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24678v1",
    "title": "All-optical diode via nonreciprocal nonlinear absorption and interfacial charge transfer in two-dimensional van der Waals heterostructures",
    "authors": [
      "Erkang Li",
      "Jinhong Liu",
      "Yanqing Ge",
      "Mingjian Shi",
      "Yijie Wang",
      "Chunhui Lu",
      "Yixuan Zhou",
      "Xinlong Xu"
    ],
    "abstract": "Nonreciprocity is fundamental to photonic and optoelectronic devices such as\nall-optical diodes for ultrafast optical signal processing. However, previous\nnonreciprocity is mainly based on linear optical response instead of nonlinear\noptical response based on recently developed two-dimensional (2D) van der Waals\nheterostructures. Herein, an all-optical diode prototype based on nonreciprocal\nnonlinear absorption and interfacial charge transfer is proposed and designed\nby both simulation and experiment based on ready van der Waals\nheterostructures. The giant saturable absorption from 2D MXenes (NbC) and\nreverse saturable absorption from 2D chalcogenides (GaS) play a synergistic\nrole in the designed all-optical diodes, which is characterized by a\nfemtosecond laser based Z-scan system. The comprehensive physical mechanism of\nthis all-optical diode based on 2D van der Waals NbC/GaS heterostructure\ndesigned by simulations, is consistent with experiments under the consideration\nof both nonreciprocal nonlinear absorption and interfacial effect. This\nall-optical diode based on the 2D van der Waals heterostructure features the\nsimplicity, scalability, stability, integration, and compatibility with the\ncomplementary planar fabrication technology, which can further extend and\nminiaturize the nonlinear photonic and optoelectric devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24678v1",
    "published": "2025-05-30T15:05:13+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.00104v1",
    "title": "Epidemic dynamics in physical-information-social multilayer networks",
    "authors": [
      "Mengshou Wang",
      "Liangrong Peng",
      "Baoguo Jia",
      "Liu Hong"
    ],
    "abstract": "During epidemic outbreaks, information dissemination enhances individual\nprotection, while social institutions influence the transmission through\nmeasures like government interventions, media campaigns, and hospital resource\nallocation. Here we develop a tripartite physical-information-social epidemic\nmodel and derive the corresponding kinetic equations in different scales by\nusing the Microscopic Markov Chain Approach and mean-field approximations. The\nbasic reproduction number and epidemic thresholds are explicitly derived by the\nnext generation matrix method. Our results reveal that (1) active information\nexchange curbs disease transmission, (2) earlier and stronger government\nresponses reduce the epidemic size, and (3) stronger governmental influence on\nmedia and hospitals further decreases disease transmission, particularly in\nhospital nodes. In fixed community structures, groups with frequent physical\ncontact but weak information access (e.g., students) exhibit higher infection\nrates. For diverse communities, weaker physical layer heterogeneity but\nstronger information layer heterogeneity (e.g., high internet penetration in\nrural areas) inhibits epidemic outbreaks. These findings offer valuable\ninsights for epidemic prevention and control strategies.",
    "pdf_url": "http://arxiv.org/pdf/2506.00104v1",
    "published": "2025-05-30T15:05:07+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24677v1",
    "title": "Robust Distribution Network Reconfiguration Using Mapping-based Column-and-Constraint Generation",
    "authors": [
      "Runjie Zhang",
      "Kaiping Qu",
      "Changhong Zhao",
      "Wanjun Huang"
    ],
    "abstract": "The integration of intermittent renewable energy sources into distribution\nnetworks introduces significant uncertainties and fluctuations, challenging\ntheir operational security, stability, and efficiency. This paper considers\nrobust distribution network reconfiguration (RDNR) with renewable generator\nresizing, modeled as a two-stage robust optimization (RO) problem with\ndecision-dependent uncertainty (DDU). Our model optimizes resizing decisions as\nthe upper bounds of renewable generator outputs, while also optimizing the\nnetwork topology. We design a mapping-based column-and-constraint generation\n(C&CG) algorithm to address the computational challenges raised by DDU.\nSensitivity analyses further explore the impact of uncertainty set parameters\non optimal solutions. Case studies demonstrate the effectiveness of the\nproposed algorithm in reducing computational complexity while ensuring solution\noptimality.",
    "pdf_url": "http://arxiv.org/pdf/2505.24677v1",
    "published": "2025-05-30T15:04:53+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24676v1",
    "title": "Predicting the Past: Estimating Historical Appraisals with OCR and Machine Learning",
    "authors": [
      "Mihir Bhaskar",
      "Jun Tao Luo",
      "Zihan Geng",
      "Asmita Hajra",
      "Junia Howell",
      "Matthew R. Gormley"
    ],
    "abstract": "Despite well-documented consequences of the U.S. government's 1930s housing\npolicies on racial wealth disparities, scholars have struggled to quantify its\nprecise financial effects due to the inaccessibility of historical property\nappraisal records. Many counties still store these records in physical formats,\nmaking large-scale quantitative analysis difficult. We present an approach\nscholars can use to digitize historical housing assessment data, applying it to\nbuild and release a dataset for one county. Starting from publicly available\nscanned documents, we manually annotated property cards for over 12,000\nproperties to train and validate our methods. We use OCR to label data for an\nadditional 50,000 properties, based on our two-stage approach combining\nclassical computer vision techniques with deep learning-based OCR. For cases\nwhere OCR cannot be applied, such as when scanned documents are not available,\nwe show how a regression model based on building feature data can estimate the\nhistorical values, and test the generalizability of this model to other\ncounties. With these cost-effective tools, scholars, community activists, and\npolicy makers can better analyze and understand the historical impacts of\nredlining.",
    "pdf_url": "http://arxiv.org/pdf/2505.24676v1",
    "published": "2025-05-30T15:04:21+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24675v1",
    "title": "Trustworthy Provenance for Big Data Science: a Modular Architecture Leveraging Blockchain in Federated Settings",
    "authors": [
      "Nicola Giuseppe Marchioro",
      "Yannis Velegrakis",
      "Valentine Anantharaj",
      "Ian Foster",
      "Sandro Luigi Fiore"
    ],
    "abstract": "Ensuring the trustworthiness and long-term verifiability of scientific data\nis a foundational challenge in the era of data-intensive, collaborative\nresearch. Provenance metadata plays a key role in this context, capturing the\norigin, transformation, and usage of research artifacts. However, existing\nsolutions often fall short when applied to distributed, multi-institutional\nsettings. This paper introduces a modular, domain-agnostic architecture for\nprovenance tracking in federated environments, leveraging permissioned\nblockchain infrastructure to guarantee integrity, immutability, and\nauditability. The system supports decentralized interaction, persistent\nidentifiers for artifact traceability, and a provenance versioning model that\npreserves the history of updates. Designed to interoperate with diverse\nscientific domains, the architecture promotes transparency, accountability, and\nreproducibility across organizational boundaries. Ongoing work focuses on\nvalidating the system through a distributed prototype and exploring its\nperformance in collaborative settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.24675v1",
    "published": "2025-05-30T15:04:09+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24674v1",
    "title": "A review on recent progresses in the study of low energy $ππ$ and $πN$ scatterings",
    "authors": [
      "Qu-Zhi Li",
      "Zhiguang Xiao",
      "Han-Qing Zheng"
    ],
    "abstract": "We summarize new results on the studies of $\\pi\\pi$ and $\\pi N$ scatterings.\nThey include the finding of a negative-parity nucleon pole with a mass lower\nthan the nucleon mass, and the pole trajectory of $f_0(500)$ with respect to\nvarying pion masses. The results are obtained from model-independent dispersion\nanalyses. We also study the thermal properties of $f_0(500)$ based on the\n$O(N)$ $\\sigma$ model and $N/D$ method.",
    "pdf_url": "http://arxiv.org/pdf/2505.24674v1",
    "published": "2025-05-30T15:02:52+00:00",
    "categories": [
      "hep-ph",
      "hep-lat",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24673v1",
    "title": "Finite-time scaling on low-dimensional map bifurcations",
    "authors": [
      "Daniel A. Martin",
      "Qian-Yuan Tang",
      "Dante R. Chialvo"
    ],
    "abstract": "Recent work has introduced the concept of finite-time scaling to characterize\nbifurcation diagrams at finite times in deterministic discrete dynamical\nsystems, drawing an analogy with finite-size scaling used to study critical\nbehavior in finite systems. In this work, we extend the finite-time scaling\napproach in several key directions. First, we present numerical results for 1D\nmaps exhibiting period-doubling bifurcations and discontinuous transitions,\nanalyzing selected paradigmatic examples. We then define two observables, the\nfinite-time susceptibility and the finite-time Lyapunov exponent, that also\ndisplay consistent scaling near bifurcation points. The method is further\ngeneralized to special cases of 2D maps including the 2D Chialvo map, capturing\nits bifurcation between a fixed point and a periodic orbit, while accounting\nfor discontinuities and asymmetric periodic orbits. These results underscore\nfundamental connections between temporal and spatial observables in complex\nsystems, suggesting new avenues for studying complex dynamical behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.24673v1",
    "published": "2025-05-30T15:02:50+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "nlin.AO",
      "q-bio.NC"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24672v1",
    "title": "TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis",
    "authors": [
      "Xiaorui Wu",
      "Xiaofeng Mao",
      "Fei Li",
      "Xin Zhang",
      "Xuanhong Li",
      "Chong Teng",
      "Donghong Ji",
      "Zhuang Li"
    ],
    "abstract": "Large Language Models (LLMs) excel in various natural language processing\ntasks but remain vulnerable to generating harmful content or being exploited\nfor malicious purposes. Although safety alignment datasets have been introduced\nto mitigate such risks through supervised fine-tuning (SFT), these datasets\noften lack comprehensive risk coverage. Most existing datasets focus primarily\non lexical diversity while neglecting other critical dimensions. To address\nthis limitation, we propose a novel analysis framework to systematically\nmeasure the risk coverage of alignment datasets across three essential\ndimensions: Lexical Diversity, Malicious Intent, and Jailbreak Tactics. We\nfurther introduce TRIDENT, an automated pipeline that leverages persona-based,\nzero-shot LLM generation to produce diverse and comprehensive instructions\nspanning these dimensions. Each harmful instruction is paired with an ethically\naligned response, resulting in two datasets: TRIDENT-Core, comprising 26,311\nexamples, and TRIDENT-Edge, with 18,773 examples. Fine-tuning Llama 3.1-8B on\nTRIDENT-Edge demonstrates substantial improvements, achieving an average 14.29%\nreduction in Harm Score, and a 20% decrease in Attack Success Rate compared to\nthe best-performing baseline model fine-tuned on the WildBreak dataset.",
    "pdf_url": "http://arxiv.org/pdf/2505.24672v1",
    "published": "2025-05-30T15:02:21+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24671v2",
    "title": "Multiple LLM Agents Debate for Equitable Cultural Alignment",
    "authors": [
      "Dayeon Ki",
      "Rachel Rudinger",
      "Tianyi Zhou",
      "Marine Carpuat"
    ],
    "abstract": "Large Language Models (LLMs) need to adapt their predictions to diverse\ncultural contexts to benefit diverse communities across the world. While\nprevious efforts have focused on single-LLM, single-turn approaches, we propose\nto exploit the complementary strengths of multiple LLMs to promote cultural\nadaptability. We introduce a Multi-Agent Debate framework, where two LLM-based\nagents debate over a cultural scenario and collaboratively reach a final\ndecision. We propose two variants: one where either LLM agents exclusively\ndebate and another where they dynamically choose between self-reflection and\ndebate during their turns. We evaluate these approaches on 7 open-weight LLMs\n(and 21 LLM combinations) using the NormAd-ETI benchmark for social etiquette\nnorms in 75 countries. Experiments show that debate improves both overall\naccuracy and cultural group parity over single-LLM baselines. Notably,\nmulti-agent debate enables relatively small LLMs (7-9B) to achieve accuracies\ncomparable to that of a much larger model (27B parameters).",
    "pdf_url": "http://arxiv.org/pdf/2505.24671v2",
    "published": "2025-05-30T15:01:52+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24670v1",
    "title": "The Schur multiplier norm and its dual norm",
    "authors": [
      "Erik Christensen"
    ],
    "abstract": "We present a formula for the Schur multiplier norm of a complex self-adjoint\nmatrix, and a formula for the norm, which is dual to the Schur multiplier norm,\nof a self-adjoint matrix.\n  For a complex self-adjoint $n \\times n $ matrix $X$ we show that its Schur\nmultiplier norm is determined by $$ \\|X\\|_S = \\min \\{\\,\n\\|\\mathrm{diag}(P)\\|_\\infty \\, :\\, - P \\leq X \\leq P \\, \\}.$$\n  The dual space of $( M_n(\\bc), \\|.\\|_S)$ is $(M_n(\\bc), \\|.\\|_{cbB}).$ For\n$X=X^*:$ $$ \\|X\\|_{cbB} = \\min \\{ \\, \\mathrm{Tr}_n\\big(\\Delta(\\lambda)\\big)\\,\n:\\, \\lambda \\in \\br^n, \\, - \\Delta(\\lambda) \\leq X \\leq \\Delta(\\lambda)\\,\\}. $$",
    "pdf_url": "http://arxiv.org/pdf/2505.24670v1",
    "published": "2025-05-30T15:01:47+00:00",
    "categories": [
      "math.FA",
      "math.OA",
      "15A39, 15A45, 15A60, 46L07, 47A30, 81P47"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24669v1",
    "title": "6D Pose Estimation on Point Cloud Data through Prior Knowledge Integration: A Case Study in Autonomous Disassembly",
    "authors": [
      "Chengzhi Wu",
      "Hao Fu",
      "Jan-Philipp Kaiser",
      "Erik Tabuchi Barczak",
      "Julius Pfrommer",
      "Gisela Lanza",
      "Michael Heizmann",
      "Jürgen Beyerer"
    ],
    "abstract": "The accurate estimation of 6D pose remains a challenging task within the\ncomputer vision domain, even when utilizing 3D point cloud data. Conversely, in\nthe manufacturing domain, instances arise where leveraging prior knowledge can\nyield advancements in this endeavor. This study focuses on the disassembly of\nstarter motors to augment the engineering of product life cycles. A pivotal\nobjective in this context involves the identification and 6D pose estimation of\nbolts affixed to the motors, facilitating automated disassembly within the\nmanufacturing workflow. Complicating matters, the presence of occlusions and\nthe limitations of single-view data acquisition, notably when motors are placed\nin a clamping system, obscure certain portions and render some bolts\nimperceptible. Consequently, the development of a comprehensive pipeline\ncapable of acquiring complete bolt information is imperative to avoid oversight\nin bolt detection. In this paper, employing the task of bolt detection within\nthe scope of our project as a pertinent use case, we introduce a meticulously\ndevised pipeline. This multi-stage pipeline effectively captures the 6D\ninformation with regard to all bolts on the motor, thereby showcasing the\neffective utilization of prior knowledge in handling this challenging task. The\nproposed methodology not only contributes to the field of 6D pose estimation\nbut also underscores the viability of integrating domain-specific insights to\ntackle complex problems in manufacturing and automation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24669v1",
    "published": "2025-05-30T14:58:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24668v1",
    "title": "Impact of Bottleneck Layers and Skip Connections on the Generalization of Linear Denoising Autoencoders",
    "authors": [
      "Jonghyun Ham",
      "Maximilian Fleissner",
      "Debarghya Ghoshdastidar"
    ],
    "abstract": "Modern deep neural networks exhibit strong generalization even in highly\noverparameterized regimes. Significant progress has been made to understand\nthis phenomenon in the context of supervised learning, but for unsupervised\ntasks such as denoising, several open questions remain. While some recent works\nhave successfully characterized the test error of the linear denoising problem,\nthey are limited to linear models (one-layer network). In this work, we focus\non two-layer linear denoising autoencoders trained under gradient flow,\nincorporating two key ingredients of modern deep learning architectures: A\nlow-dimensional bottleneck layer that effectively enforces a rank constraint on\nthe learned solution, as well as the possibility of a skip connection that\nbypasses the bottleneck. We derive closed-form expressions for all critical\npoints of this model under product regularization, and in particular describe\nits global minimizer under the minimum-norm principle. From there, we derive\nthe test risk formula in the overparameterized regime, both for models with and\nwithout skip connections. Our analysis reveals two interesting phenomena:\nFirstly, the bottleneck layer introduces an additional complexity measure akin\nto the classical bias-variance trade-off -- increasing the bottleneck width\nreduces bias but introduces variance, and vice versa. Secondly, skip connection\ncan mitigate the variance in denoising autoencoders -- especially when the\nmodel is mildly overparameterized. We further analyze the impact of skip\nconnections in denoising autoencoder using random matrix theory and support our\nclaims with numerical evidence.",
    "pdf_url": "http://arxiv.org/pdf/2505.24668v1",
    "published": "2025-05-30T14:58:02+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24667v1",
    "title": "Decoupled Competitive Framework for Semi-supervised Medical Image Segmentation",
    "authors": [
      "Jiahe Chen",
      "Jiahe Ying",
      "Shen Wang",
      "Jianwei Zheng"
    ],
    "abstract": "Confronting the critical challenge of insufficiently annotated samples in\nmedical domain, semi-supervised medical image segmentation (SSMIS) emerges as a\npromising solution. Specifically, most methodologies following the Mean Teacher\n(MT) or Dual Students (DS) architecture have achieved commendable results.\nHowever, to date, these approaches face a performance bottleneck due to two\ninherent limitations, \\textit{e.g.}, the over-coupling problem within MT\nstructure owing to the employment of exponential moving average (EMA)\nmechanism, as well as the severe cognitive bias between two students of DS\nstructure, both of which potentially lead to reduced efficacy, or even model\ncollapse eventually. To mitigate these issues, a Decoupled Competitive\nFramework (DCF) is elaborated in this work, which utilizes a straightforward\ncompetition mechanism for the update of EMA, effectively decoupling students\nand teachers in a dynamical manner. In addition, the seamless exchange of\ninvaluable and precise insights is facilitated among students, guaranteeing a\nbetter learning paradigm. The DCF introduced undergoes rigorous validation on\nthree publicly accessible datasets, which encompass both 2D and 3D datasets.\nThe results demonstrate the superiority of our method over previous\ncutting-edge competitors. Code will be available at\nhttps://github.com/JiaheChen2002/DCF.",
    "pdf_url": "http://arxiv.org/pdf/2505.24667v1",
    "published": "2025-05-30T14:56:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24666v1",
    "title": "Could a Primordial Black Hole Explosion Explain the KM3NeT Event?",
    "authors": [
      "Lua F. T. Airoldi",
      "Gustavo F. S. Alves",
      "Yuber F. Perez-Gonzalez",
      "Gabriel M. Salla",
      "Renata Zukanovich Funchal"
    ],
    "abstract": "A black hole is expected to end its lifetime in a cataclysmic runaway burst\nof Hawking radiation, emitting all Standard Model particles with ultra-high\nenergies. Thus, the explosion of a nearby primordial black hole (PBH) has been\nproposed as a possible explanation for the $\\sim 220$ PeV neutrino-like event\nrecently reported by the KM3NeT collaboration. Assuming a PBH origin, we find\nthat the source would need to lie at a distance of approximately $4 \\times\n10^{-5}$ pc, i.e., within the Solar System, to produce the observed event. At\nsuch proximity, the resulting flux of gamma-rays and cosmic rays would be\ndetectable at Earth. By incorporating the time-dependent field of view of\ngamma-ray observatories, we show that LHAASO should have recorded on the order\nof ${\\cal O}(10^8)$ events between fourteen and seven hours prior to the KM3NeT\ndetection. IceCube should also have detected about 100 events at the time of\nthe burst. The absence of any such multi-messenger signal, particularly in\ngamma-ray data, strongly disfavors the interpretation of the KM3-230213A event\nas arising from evaporation in a minimal four-dimensional Schwarzschild\nscenario.",
    "pdf_url": "http://arxiv.org/pdf/2505.24666v1",
    "published": "2025-05-30T14:54:39+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.HE"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24665v1",
    "title": "Learning geometry and topology via multi-chart flows",
    "authors": [
      "Hanlin Yu",
      "Søren Hauberg",
      "Marcelo Hartmann",
      "Arto Klami",
      "Georgios Arvanitidis"
    ],
    "abstract": "Real world data often lie on low-dimensional Riemannian manifolds embedded in\nhigh-dimensional spaces. This motivates learning degenerate normalizing flows\nthat map between the ambient space and a low-dimensional latent space. However,\nif the manifold has a non-trivial topology, it can never be correctly learned\nusing a single flow. Instead multiple flows must be `glued together'. In this\npaper, we first propose the general training scheme for learning such a\ncollection of flows, and secondly we develop the first numerical algorithms for\ncomputing geodesics on such manifolds. Empirically, we demonstrate that this\nleads to highly significant improvements in topology estimation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24665v1",
    "published": "2025-05-30T14:54:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24664v1",
    "title": "Learning Distributions over Permutations and Rankings with Factorized Representations",
    "authors": [
      "Daniel Severo",
      "Brian Karrer",
      "Niklas Nolte"
    ],
    "abstract": "Learning distributions over permutations is a fundamental problem in machine\nlearning, with applications in ranking, combinatorial optimization, structured\nprediction, and data association. Existing methods rely on mixtures of\nparametric families or neural networks with expensive variational inference\nprocedures. In this work, we propose a novel approach that leverages\nalternative representations for permutations, including Lehmer codes,\nFisher-Yates draws, and Insertion-Vectors. These representations form a\nbijection with the symmetric group, allowing for unconstrained learning using\nconventional deep learning techniques, and can represent any probability\ndistribution over permutations. Our approach enables a trade-off between\nexpressivity of the model family and computational requirements. In the least\nexpressive and most computationally efficient case, our method subsumes\nprevious families of well established probabilistic models over permutations,\nincluding Mallow's and the Repeated Insertion Model. Experiments indicate our\nmethod significantly outperforms current approaches on the jigsaw puzzle\nbenchmark, a common task for permutation learning. However, we argue this\nbenchmark is limited in its ability to assess learning probability\ndistributions, as the target is a delta distribution (i.e., a single correct\nsolution exists). We therefore propose two additional benchmarks: learning\ncyclic permutations and re-ranking movies based on user preference. We show\nthat our method learns non-trivial distributions even in the least expressive\nmode, while traditional models fail to even generate valid permutations in this\nsetting.",
    "pdf_url": "http://arxiv.org/pdf/2505.24664v1",
    "published": "2025-05-30T14:53:40+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.08026v2",
    "title": "TIP-Search: Time-Predictable Inference Scheduling for Market Prediction under Uncertain Load",
    "authors": [
      "Xibai Wang"
    ],
    "abstract": "This paper proposes TIP-Search, a time-predictable inference scheduling\nframework for real-time market prediction under uncertain workloads. Motivated\nby the strict latency demands in high-frequency financial systems, TIP-Search\ndynamically selects a deep learning model from a heterogeneous pool, aiming to\nmaximize predictive accuracy while satisfying per-task deadline constraints.\nOur approach profiles latency and generalization performance offline, then\nperforms online task-aware selection without relying on explicit input domain\nlabels. We evaluate TIP-Search on three real-world limit order book datasets\n(FI-2010, Binance BTC/USDT, LOBSTER AAPL) and demonstrate that it outperforms\nstatic baselines with up to 8.5% improvement in accuracy and 100% deadline\nsatisfaction. Our results highlight the effectiveness of TIP-Search in robust\nlow-latency financial inference under uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2506.08026v2",
    "published": "2025-05-30T14:52:01+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "q-fin.CP"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24663v1",
    "title": "Explaining Sustained Blockchain Decentralization with Quasi-Experiments: Resource Flexibility of Consensus Mechanisms",
    "authors": [
      "Harang Ju",
      "Madhav Kumar",
      "Ehsan Valavi",
      "Sinan Aral"
    ],
    "abstract": "Decentralization is a fundamental design element of the Web3 economy.\nBlockchains and distributed consensus mechanisms are touted as fault-tolerant,\nattack-resistant, and collusion-proof because they are decentralized. Recent\nanalyses, however, find some blockchains are decentralized, others are\ncentralized, and that there are trends towards both centralization and\ndecentralization in the blockchain economy. Despite the importance and\nvariability of decentralization across blockchains, we still know little about\nwhat enables or constrains blockchain decentralization. We hypothesize that the\nresource flexibility of consensus mechanisms is a key enabler of the sustained\ndecentralization of blockchain networks. We test this hypothesis using three\nquasi-experimental shocks -- policy-related, infrastructure-related, and\ntechnical -- to resources used in consensus. We find strong suggestive evidence\nthat the resource flexibility of consensus mechanisms enables sustained\nblockchain decentralization and discuss the implications for the design,\nregulation, and implementation of blockchains.",
    "pdf_url": "http://arxiv.org/pdf/2505.24663v1",
    "published": "2025-05-30T14:51:09+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24662v1",
    "title": "From Group Operations to Geometric Structures: Amalgamations, HNN-Extensions, and Twisting in Coset Geometries",
    "authors": [
      "Claudio Alexandre Piedade",
      "Philippe Tranchida"
    ],
    "abstract": "Coset incidence geometries, introduced by Jacques Tits, provide a versatile\nframework for studying the interplay between group theory and geometry.\n  In this article, we build upon that idea by extending classical\ngroup-theoretic constructions (amalgamated products, HNN-extensions,\nsemi-direct products, and twisting) to the setting of coset geometries. This\ngives a general way to glue together incidence geometries in various ways. This\nprovides a general framework for combining or gluing incidence geometries in\ndifferent ways while preserving essential properties such as flag-transitivity\nand residual connectedness.\n  Using these techniques, we analyze families of Shephard groups, which\ngeneralize both Coxeter and Artin-Tits groups, and their associated simplicial\ncomplexes.\n  Our results also point to the existence of a Bass-Serre theory for coset\ngeometries and of a fundamental geometry of a graph of coset geometries.",
    "pdf_url": "http://arxiv.org/pdf/2505.24662v1",
    "published": "2025-05-30T14:50:42+00:00",
    "categories": [
      "math.GR",
      "math.CO",
      "math.GT",
      "20E06, 51E30, 20F55, 20F36"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24661v1",
    "title": "Super-additivity of quantum capacity in simple channels",
    "authors": [
      "Zhen Wu",
      "Qi Zhao",
      "Zhihao Ma"
    ],
    "abstract": "The super-additivity of quantum channel capacity is an important feature of\nquantum information theory different from classical theory, which has been\nattracting attention. Recently a special channel called ``platypus channel''\nexhibits super-additive quantum capacity when combined with qudit erasure\nchannels. Here we consider the ``generalized platypus channel'', prove that it\nhas computable channel capacities, such as both private and classical capacity\nequal to $1$, and in particular, the generalized platypus channel still\ndisplays the super-additivity of quantum capacity when combined with qudit\nerasure channels and multilevel amplitude damping channels respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.24661v1",
    "published": "2025-05-30T14:48:32+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24660v1",
    "title": "CGCS 6306, another X-ray-emitting asymptotic giant branch star confirmed to be a symbiotic binary",
    "authors": [
      "Jaroslav Merc",
      "Martín A. Guerrero",
      "Jesús A. Toalá",
      "Roberto Ortiz"
    ],
    "abstract": "A number of asymptotic giant branch (AGB) stars are known to exhibit UV\nexcess and/or X-ray emission. These have been considered signposts of a hot\nwhite dwarf (WD) companion in a symbiotic system (SySt), but AGB stars are so\nbright that they easily outshine these companions hampering their detection at\noptical wavelengths. A recent multi-wavelength investigation on the\nX-ray-emitting AGB (X-AGB) star Y Gem has confirmed the presence of a WD\ncompanion and, thus, its SySt nature. Our goal is to explore the true nature of\nanother X-AGB star, namely CGCS 6306, to investigate whether some objects from\nthis group may in fact be unnoticed symbiotic systems with AGB donors. Optical\nspectra and photometric data, together with X-ray observations, have been\nanalyzed to investigate the properties of the stellar components and accretion\nprocess in CGCS 6306. CGCS 6306 is a carbon Mira with a pulsation period of 362\ndays. Its optical spectrum exhibits the typical saw-shaped features of\nmolecular absorptions in addition to H I and He I recombination and [O I] and\n[O III] forbidden emission lines. The H$\\alpha$ line profile is broad, which\ncan be interpreted as evidence for an accretion disk. The X-ray spectrum is\nhard, typical of highly-extincted hot plasma emission, and the X-ray luminosity\nis $\\approx10^{32}$ erg s$^{-1}$. The detection of high-excitation optical\nemission lines and the X-ray properties of CGCS 6306 confirm the presence of a\nWD companion, making it a bona-fide $\\delta$-type X-SySt. Its X-ray luminosity\nis comparable to that of Y Gem, the other X-AGB confirmed to be a SySt, which\nwas found to exhibit a high accretion rate. The lack of suitable information on\nthe UV and blue optical properties of CGCS 6306, however, precludes a\ndefinitive estimate of the accretion rate in this system. Since CGCS 6306 is a\ncarbon Mira, it adds to the small group of Galactic carbon SySts.",
    "pdf_url": "http://arxiv.org/pdf/2505.24660v1",
    "published": "2025-05-30T14:47:28+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24659v1",
    "title": "Magnetoimpedance properties of CoNbZr, multilayer CoNbZr/Au and multilayer NiFe/Au thin films",
    "authors": [
      "Indujan Sivanesarajah",
      "Leon Abelmann",
      "Uwe Hartmann"
    ],
    "abstract": "Thin-film magnetic sensors using the giant magnetoimpedance (GMI) effect show\ngreat promise for sensitive low-field magnetic measurements. Optimising sensor\nperformance requires a thorough understanding of the properties of various soft\nmagnetic materials. This study examines the electric, magnetic, and GMI\nproperties of sputtered single-layer amorphous CoNbZr, multilayer amorphous\nCoNbZr/Au, and crystalline NiFe/Au thin films. GMI measurements reveal distinct\nferromagnetic resonance (FMR) frequencies: 1.4 GHz for CoNbZr, 0.7 GHz for\nCoNbZr/Au, and 0.5 GHz for NiFe/Au. Au interlayers improve the GMI response,\nincreasing the GMI ratio by 50% and reducing FMR frequency compared to\nsingle-layer CoNbZr. The highest GMI ratio of 300% occurs in a 20 $\\mu$m x 5000\n$\\mu$m CoNbZr/Au strip at 1.8 GHz under 2 mT, while NiFe/Au exhibits 280% at 4\nmT. These differences are linked to variations in in-plane demagnetising\nfactors and saturation magnetisations, emphasising the role of material and\ngeometry in GMI sensor performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.24659v1",
    "published": "2025-05-30T14:46:29+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24658v1",
    "title": "Can LLMs and humans be friends? Uncovering factors affecting human-AI intimacy formation",
    "authors": [
      "Yeseon Hong",
      "Junhyuk Choi",
      "Minju Kim",
      "Bugeun Kim"
    ],
    "abstract": "Large language models (LLMs) are increasingly being used in conversational\nroles, yet little is known about how intimacy emerges in human-LLM\ninteractions. Although previous work emphasized the importance of\nself-disclosure in human-chatbot interaction, it is questionable whether\ngradual and reciprocal self-disclosure is also helpful in human-LLM\ninteraction. Thus, this study examined three possible aspects contributing to\nintimacy formation: gradual self-disclosure, reciprocity, and naturalness.\nStudy 1 explored the impact of mutual, gradual self-disclosure with 29 users\nand a vanilla LLM. Study 2 adopted self-criticism methods for more natural\nresponses and conducted a similar experiment with 53 users. Results indicate\nthat gradual self-disclosure significantly enhances perceived social intimacy,\nregardless of persona reciprocity. Moreover, participants perceived utterances\ngenerated with self-criticism as more natural compared to those of vanilla\nLLMs; self-criticism fostered higher intimacy in early stages. Also, we\nobserved that excessive empathetic expressions occasionally disrupted\nimmersion, pointing to the importance of response calibration during intimacy\nformation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24658v1",
    "published": "2025-05-30T14:46:22+00:00",
    "categories": [
      "cs.HC",
      "H.5.2; I.2.7"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24657v1",
    "title": "A note on multi-transitivity in non-autonomous discrete systems",
    "authors": [
      "Hongbo Zeng"
    ],
    "abstract": "This paper is concerned with some stronger forms of transitivity in\nnon-autonomous discrete systems$(f_{ 1,\\infty})$ generated by a uniformly\nconvergent sequence of continuous self maps. Firstly, we present two\ncounterexamples to show that Theorem 3.1 obtained by Salman and Das in\n[Multi-transitivity in nonautonomous discrete systems Topol. Appl.\n278(2020)107237] is not true. Then, we introduce and study mildly mixing in\nnon-autonomous discrete systems, which is stronger than mixing. We obtain that\nmulti-transitivity implies Li-Yorke chaos and that mildly mixing implies\nmulti-transitivity, which answer the open problems 1 and 2 in the paper above.\nAdditionally, we give a counterexample which shows that Theorem 2.3 and Theorem\n2.4 given by Sharma and Raghav in [On dynamics generated by a uniformly\nconvergent sequence of maps Topol. Appl. 247 (2018)81-90] are both incorrect\nand give the correct proofs of them. Finally, some counterexamples are\nconstructed justifying that some results related to stronger forms of\ntransitivity which are true for autonomous systems but fail in non-autonomous\nsystems, and establish a sufficient condition under which the results still\nhold in non-autonomous systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24657v1",
    "published": "2025-05-30T14:46:12+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24656v2",
    "title": "MSDA: Combining Pseudo-labeling and Self-Supervision for Unsupervised Domain Adaptation in ASR",
    "authors": [
      "Dimitrios Damianos",
      "Georgios Paraskevopoulos",
      "Alexandros Potamianos"
    ],
    "abstract": "In this work, we investigate the Meta PL unsupervised domain adaptation\nframework for Automatic Speech Recognition (ASR). We introduce a Multi-Stage\nDomain Adaptation pipeline (MSDA), a sample-efficient, two-stage adaptation\napproach that integrates self-supervised learning with semi-supervised\ntechniques. MSDA is designed to enhance the robustness and generalization of\nASR models, making them more adaptable to diverse conditions. It is\nparticularly effective for low-resource languages like Greek and in weakly\nsupervised scenarios where labeled data is scarce or noisy. Through extensive\nexperiments, we demonstrate that Meta PL can be applied effectively to ASR\ntasks, achieving state-of-the-art results, significantly outperforming\nstate-of-the-art methods, and providing more robust solutions for unsupervised\ndomain adaptation in ASR. Our ablations highlight the necessity of utilizing a\ncascading approach when combining self-supervision with self-training.",
    "pdf_url": "http://arxiv.org/pdf/2505.24656v2",
    "published": "2025-05-30T14:46:05+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24655v1",
    "title": "Adaptable Cardiovascular Disease Risk Prediction from Heterogeneous Data using Large Language Models",
    "authors": [
      "Frederike Lübeck",
      "Jonas Wildberger",
      "Frederik Träuble",
      "Maximilian Mordig",
      "Sergios Gatidis",
      "Andreas Krause",
      "Bernhard Schölkopf"
    ],
    "abstract": "Cardiovascular disease (CVD) risk prediction models are essential for\nidentifying high-risk individuals and guiding preventive actions. However,\nexisting models struggle with the challenges of real-world clinical practice as\nthey oversimplify patient profiles, rely on rigid input schemas, and are\nsensitive to distribution shifts. We developed AdaCVD, an adaptable CVD risk\nprediction framework built on large language models extensively fine-tuned on\nover half a million participants from the UK Biobank. In benchmark comparisons,\nAdaCVD surpasses established risk scores and standard machine learning\napproaches, achieving state-of-the-art performance. Crucially, for the first\ntime, it addresses key clinical challenges across three dimensions: it flexibly\nincorporates comprehensive yet variable patient information; it seamlessly\nintegrates both structured data and unstructured text; and it rapidly adapts to\nnew patient populations using minimal additional data. In stratified analyses,\nit demonstrates robust performance across demographic, socioeconomic, and\nclinical subgroups, including underrepresented cohorts. AdaCVD offers a\npromising path toward more flexible, AI-driven clinical decision support tools\nsuited to the realities of heterogeneous and dynamic healthcare environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24655v1",
    "published": "2025-05-30T14:42:02+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24654v1",
    "title": "Black-box Adversarial Attacks on CNN-based SLAM Algorithms",
    "authors": [
      "Maria Rafaela Gkeka",
      "Bowen Sun",
      "Evgenia Smirni",
      "Christos D. Antonopoulos",
      "Spyros Lalis",
      "Nikolaos Bellas"
    ],
    "abstract": "Continuous advancements in deep learning have led to significant progress in\nfeature detection, resulting in enhanced accuracy in tasks like Simultaneous\nLocalization and Mapping (SLAM). Nevertheless, the vulnerability of deep neural\nnetworks to adversarial attacks remains a challenge for their reliable\ndeployment in applications, such as navigation of autonomous agents. Even\nthough CNN-based SLAM algorithms are a growing area of research there is a\nnotable absence of a comprehensive presentation and examination of adversarial\nattacks targeting CNN-based feature detectors, as part of a SLAM system. Our\nwork introduces black-box adversarial perturbations applied to the RGB images\nfed into the GCN-SLAM algorithm. Our findings on the TUM dataset [30] reveal\nthat even attacks of moderate scale can lead to tracking failure in as many as\n76% of the frames. Moreover, our experiments highlight the catastrophic impact\nof attacking depth instead of RGB input images on the SLAM system.",
    "pdf_url": "http://arxiv.org/pdf/2505.24654v1",
    "published": "2025-05-30T14:41:38+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "68T40, 68T45, 68M25,"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24653v1",
    "title": "Minimizing Ray Tracing Memory Traffic through Quantized Structures and Ray Stream Tracing",
    "authors": [
      "Moritz Grauer",
      "Johannes Hanika",
      "Carsten Dachsbacher"
    ],
    "abstract": "Memory bandwidth constraints continue to be a significant limiting factor in\nray tracing performance, particularly as scene complexity grows and\ncomputational capabilities outpace memory access speeds. This paper presents a\nmemory-efficient ray tracing methodology that integrates compressed data\nstructures with ray stream techniques to reduce memory traffic. The approach\nimplements compressed BVH and triangle representations to minimize acceleration\nstructure size in combination with ray stream tracing to reduce traversal stack\nmemory traffic. The technique employs fixed-point arithmetic for intersection\ntests for prospective hardware with tailored integer operations. Despite using\nreduced precision, geometric holes are avoided by leveraging fixed-point\narithmetic instead of encountering the floating-point rounding errors common in\ntraditional approaches. Quantitative analysis demonstrates significant memory\ntraffic reduction across various scene complexities and BVH configurations. The\npresented 8-wide BVH ray stream implementation reduces memory traffic to only\n18% of traditional approaches by using 8-bit quantization for box and triangle\ncoordinates and directly ray tracing these quantized structures. These\nreductions are especially beneficial for bandwidth-constrained hardware\nenvironments such as mobile devices. This integrated approach addresses both\nmemory bandwidth limitations and numerical precision challenges inherent to\nmodern ray tracing applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.24653v1",
    "published": "2025-05-30T14:41:25+00:00",
    "categories": [
      "cs.GR",
      "cs.AR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24652v1",
    "title": "Chasing Serendipity: Tackling Transient Sources with Neutrino Telescopes",
    "authors": [
      "Lua F. T. Airoldi",
      "Gustavo F. S. Alves",
      "Yuber F. Perez-Gonzalez",
      "Gabriel M. Salla",
      "Renata Zukanovich Funchal"
    ],
    "abstract": "The discovery of ultra-high-energy neutrinos by IceCube marked the beginning\nof neutrino astronomy. Yet, the origin and production mechanisms of these\nneutrinos remain open questions. With the recent observation of the\nhighest-energy neutrino event to date by the KM3NeT collaboration, transient\nsources - astrophysical objects that emit particles in brief, localized bursts\n- have emerged as promising candidates. In this work, we revisit the\nidentification of such sources in IceCube and future neutrino telescopes,\nfocusing on how both the timing and sky localization of the source affect the\ndetection sensitivity. We highlight the crucial role of the source's right\nascension in determining the effective area of detectors not located at the\npoles, such as KM3NeT, and present a framework to consistently account for this\ndependence. As a case study, we investigate evaporating primordial black holes\n(PBHs) as transient neutrino sources, showing that the detection prospects and\nlocalization accuracy are strongly influenced by the PBH's position in the sky.\nOur results emphasize the complementarity between neutrino and gamma-ray\nobservatories and showcase the potential of a global network of neutrino\ndetectors to identify and localize transient events that might be missed by\ntraditional photon-based instruments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24652v1",
    "published": "2025-05-30T14:40:17+00:00",
    "categories": [
      "astro-ph.HE",
      "hep-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24651v1",
    "title": "Robust Distributed Phase Retrieval for Multi-View Compressive Networked Sensing With Outliers",
    "authors": [
      "Ming-Hsun Yang"
    ],
    "abstract": "This work examines the multi-view compressive phase retrieval problem in a\ndistributed sensor network, where each sensor device, limited by storage and\nsensing capabilities, can access only intensity measurements from an unknown\npart of the global sparse vector. The goal is to enable each sensor to recover\nits observable sparse signal when measurements are corrupted by outliers. To\nachieve reliable local signal recovery with limited data access, we propose a\ndistributed reconstruction algorithm that enables collaboration among sensor\ndevices without the need to share individual raw data. The proposed scheme\nemploys a two-stage approach that first recovers the amplitude of the global\nsignal (at a central server) and subsequently estimates the observable nonzero\nsignal entries (at each local device). Our analytic results show that perfect\nglobal signal amplitude recovery can be achieved under mild conditions on the\nsupport size of sparse outliers and the view blockage level. In addition, the\nexact reconstruction of locally observed signal components is shown to be\nattainable in the noise-free case by solving a binary optimization problem,\nsubject to a mild requirement on the structure of the sensing matrix. Computer\nsimulations are provided to illustrate the effectiveness of the proposed\nscheme.",
    "pdf_url": "http://arxiv.org/pdf/2505.24651v1",
    "published": "2025-05-30T14:39:12+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24649v1",
    "title": "BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models",
    "authors": [
      "Huu-Thien Tran",
      "Thanh-Dat Truong",
      "Khoa Luu"
    ],
    "abstract": "Large vision-language models have become widely adopted to advance in various\ndomains. However, developing a trustworthy system with minimal interpretable\ncharacteristics of large-scale models presents a significant challenge. One of\nthe most prevalent terms associated with the fallacy functions caused by these\nsystems is hallucination, where the language model generates a response that\ndoes not correspond to the visual content. To mitigate this problem, several\napproaches have been developed, and one prominent direction is to ameliorate\nthe decoding process. In this paper, we propose a new Bijective Maximum\nLikelihood Learning (BIMA) approach to hallucination mitigation using\nnormalizing flow theories. The proposed BIMA method can efficiently mitigate\nthe hallucination problem in prevailing vision-language models, resulting in\nsignificant improvements. Notably, BIMA achieves the average F1 score of 85.06%\non POPE benchmark and remarkably reduce CHAIRS and CHAIRI by 7.6% and 2.6%,\nrespectively. To the best of our knowledge, this is one of the first studies\nthat contemplates the bijection means to reduce hallucination induced by large\nvision-language models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24649v1",
    "published": "2025-05-30T14:38:07+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24648v1",
    "title": "Dicritical divisors and hypercurvettes",
    "authors": [
      "Enrique Artal Bartolo",
      "Willem Veys"
    ],
    "abstract": "Germs of rational functions~$h$ on points $p$ of smooth varieties~$S$ define\ngerms of rational maps to the projective line. Assume that $p$ is in the\nindeterminacy locus of $h$. If $\\pi:\\hat{S}\\to S$ is a birational map which is\nan isomorphism outside $p$, then $h$ lifts to a germ of a rational map on\n$(\\hat{S}, \\pi^{-1}(p))$. The exceptional components $E_i$ of $\\pi^{-1}(p)$ are\nclassified according to the restriction of (the lift of) $h$ to $E_i$; the\ndicritical components are those where this restriction induces a dominant map.\nIn a series of papers, Abhyankar and the first named author studied this\nsetting in dimension $2$, where the main result is that, for any given $\\pi$,\nthere is a rational function $h$ with a prescribed subset of exceptional\ncomponents that are dicritical of some given degree. The concept of curvette of\nan exceptional component played a key role in the proof. The second named\nauthor extended previously the concept of curvette to the higher dimensional\ncase. Here we use this concept to generalize the above result to arbitrary\ndimension.",
    "pdf_url": "http://arxiv.org/pdf/2505.24648v1",
    "published": "2025-05-30T14:35:37+00:00",
    "categories": [
      "math.AG",
      "14E05, 32S45"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00103v2",
    "title": "Writing-Zero: Bridge the Gap Between Non-verifiable Tasks and Verifiable Rewards",
    "authors": [
      "Ruipeng Jia",
      "Yunyi Yang",
      "Yongbo Gai",
      "Kai Luo",
      "Shihao Huang",
      "Jianhe Lin",
      "Xiaoxi Jiang",
      "Guanjun Jiang"
    ],
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has enabled large\nlanguage models (LLMs) to achieve remarkable breakthroughs in reasoning tasks\nwith objective ground-truth answers, such as mathematics and code generation.\nHowever, a significant gap remains for non-verifiable tasks, like creative\nwriting and open-ended dialogue, where quality assessment is inherently\nsubjective and lacks definitive references. Existing approaches for these\ndomains often rely on scalar reward models trained with human preferences,\nwhich suffer from limited generalization and are prone to reward hacking, such\nas over-explanation and length bias. In this work, we propose a unified\nRLVR-based training paradigm that bridges the gap between non-verifiable tasks\nand verifiable rewards. We introduce a writing-principle-based pairwise\nGenerative Reward Model (GenRM) and a novel Bootstrapped Relative Policy\nOptimization (BRPO) algorithm. The pairwise writing GenRM leverages\nself-principled critique to transform subjective assessments into reliable,\nverifiable rewards, while BRPO enables dynamic, reference-free pairwise\ncomparison by leveraging a bootstrapped response as temporary reference from\nwithin group rollouts during RL training. Our approach empowers LLMs to develop\nrobust writing capabilities without supervised fine-tuning, as demonstrated by\nWriting-Zero, which shows consistent improvement and strong resistance to\nreward hacking compared to scalar reward baselines. Furthermore, our method\nachieves competitive results on both in-house and open-source writing\nbenchmarks. Our findings suggest the potential to unify rule-based,\nreference-based, and reference-free reward modeling under the RLVR framework,\nthus paving the way for a comprehensive and scalable RL training paradigm\napplicable across all language tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00103v2",
    "published": "2025-05-30T14:34:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24647v1",
    "title": "Square Entropy and Uniform n-to-1 Bernoulli Transformations",
    "authors": [
      "Pouya Mehdipour",
      "Somayeh Jangjooye Shaldehi"
    ],
    "abstract": "In this paper, we define the so-called square entropy and prove that n-to-1\nfull zip shift maps are intrinsically ergodic. Furthermore, we show that square\nentropy characterizes uniform n-to-1 transformations of $(m,l)$-Bernoulli type\nthat are extended Bernoulli transformations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24647v1",
    "published": "2025-05-30T14:32:12+00:00",
    "categories": [
      "math.DS",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24646v1",
    "title": "PRISM: A Framework for Producing Interpretable Political Bias Embeddings with Political-Aware Cross-Encoder",
    "authors": [
      "Yiqun Sun",
      "Qiang Huang",
      "Anthony K. H. Tung",
      "Jun Yu"
    ],
    "abstract": "Semantic Text Embedding is a fundamental NLP task that encodes textual\ncontent into vector representations, where proximity in the embedding space\nreflects semantic similarity. While existing embedding models excel at\ncapturing general meaning, they often overlook ideological nuances, limiting\ntheir effectiveness in tasks that require an understanding of political bias.\nTo address this gap, we introduce PRISM, the first framework designed to\nProduce inteRpretable polItical biaS eMbeddings. PRISM operates in two key\nstages: (1) Controversial Topic Bias Indicator Mining, which systematically\nextracts fine-grained political topics and their corresponding bias indicators\nfrom weakly labeled news data, and (2) Cross-Encoder Political Bias Embedding,\nwhich assigns structured bias scores to news articles based on their alignment\nwith these indicators. This approach ensures that embeddings are explicitly\ntied to bias-revealing dimensions, enhancing both interpretability and\npredictive power. Through extensive experiments on two large-scale datasets, we\ndemonstrate that PRISM outperforms state-of-the-art text embedding models in\npolitical bias classification while offering highly interpretable\nrepresentations that facilitate diversified retrieval and ideological analysis.\nThe source code is available at https://github.com/dukesun99/ACL-PRISM.",
    "pdf_url": "http://arxiv.org/pdf/2505.24646v1",
    "published": "2025-05-30T14:31:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24645v2",
    "title": "Intrinsic static/dynamic triboelectric pressure sensor for continuous and event-triggered control",
    "authors": [
      "Kequan Xia",
      "Song Yang",
      "Jianguo Lu",
      "Min Yu"
    ],
    "abstract": "Conventional pressure sensors often integrate two distinct mechanisms to\ndetect static and dynamic stimuli, hindering the development of high fidelity\nhuman-machine interfaces. Here, we present an intrinsic static/dynamic\ntriboelectric sensor (iSD Sensor) capable of reliably perceiving both\ncontinuous static pressure and transient mechanical shocks through a DC/AC\nsignal decoupling strategy. By pairing hydrophobic expanded\npolytetrafluoroethylene (ePTFE) with elastic conductive sponge, a\npressure-adaptive triboelectric interface is formed, where microscale and\nlarge-scale separations enable static and dynamic pressure sensing,\nrespectively. Furthermore, by employing a charge excitation strategy, the\ndevice delivers enhanced voltage outputs over 25X in static and 15X in dynamic\nmodes. Combined with a 3D gradient conductive sponge structure, the sensor\nachieves multi-region sensitivities of 34.7 V/kPa (static) and 48.4 V/kPa\n(dynamic) under low pressure (less than 1.8 kPa), and a detection limit as low\nas 6.13 Pa. By perceiving continuous static pressure and transient shocks\napplied by the human hand, the iSD Sensor enables robotic arm control via\nproportional grasping and dynamic, trigger-based sign language communication.\nThis work advances high-sensitivity, self-powered pressure sensors toward\nintelligent, closed-loop human-machine interaction.",
    "pdf_url": "http://arxiv.org/pdf/2505.24645v2",
    "published": "2025-05-30T14:30:51+00:00",
    "categories": [
      "cs.RO",
      "physics.app-ph"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24644v1",
    "title": "Structural Stability of Sulfur Depleted MoS2",
    "authors": [
      "Ygor M. Jaques",
      "Cristiano F. Woellner",
      "Lucas M. Sassi",
      "Marcelo L. Pereira Jr",
      "Luiz A. Ribeiro Jr",
      "Pulickel M. Ajayan",
      "Douglas S. Galvão"
    ],
    "abstract": "Transition metal dichalcogenides (TMDs), particularly monolayer MoS2, have\nreceived increased attention in materials science and have been exploited in\ndiverse applications from photonics to catalysis. Defects in TMDs play a\ncrucial role in modulating their properties, and understanding defect-induced\ndynamics is of great importance. This study investigates the dynamics of sulfur\ndepletion in defective monolayer MoS2, which yields stable MoS monolayers.\nVarious defect sizes, temperature regimes, and substrate effects were\ninvestigated. Through comprehensive classical molecular (ReaxFF) molecular\ndynamics (MD) and ab initio MD (AIMD) simulations, we elucidate the dynamics of\nsulfur vacancy formation in MoS2 lattices. After removing all sulfur atoms from\nthe top layer, several sulfur atoms from the bottom layer spontaneously migrate\nto the top layer as a response to increase structural stability, thus creating\na MoSx alloy. These findings deepen our understanding of defect dynamics in\nTMDs, offering valuable insights into the controlled engineering of their\nproperties for nanotechnology applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.24644v1",
    "published": "2025-05-30T14:30:46+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall",
      "00-XX",
      "I.2; J.6"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24643v1",
    "title": "Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching",
    "authors": [
      "Juan Wisznia",
      "Cecilia Bolaños",
      "Juan Tollo",
      "Giovanni Marraffini",
      "Agustín Gianolini",
      "Noe Hsueh",
      "Luciano Del Corro"
    ],
    "abstract": "We introduce a novel framework for analyzing sorting algorithms in pairwise\nranking prompting (PRP), re-centering the cost model around LLM inferences\nrather than traditional pairwise comparisons. While classical metrics based on\ncomparison counts have traditionally been used to gauge efficiency, our\nanalysis reveals that expensive LLM inferences overturn these predictions;\naccordingly, our framework encourages strategies such as batching and caching\nto mitigate inference costs. We show that algorithms optimal in the classical\nsetting can lose efficiency when LLM inferences dominate the cost under certain\noptimizations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24643v1",
    "published": "2025-05-30T14:29:55+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24642v1",
    "title": "WILTing Trees: Interpreting the Distance Between MPNN Embeddings",
    "authors": [
      "Masahiro Negishi",
      "Thomas Gärtner",
      "Pascal Welke"
    ],
    "abstract": "We investigate the distance function learned by message passing neural\nnetworks (MPNNs) in specific tasks, aiming to capture the functional distance\nbetween prediction targets that MPNNs implicitly learn. This contrasts with\nprevious work, which links MPNN distances on arbitrary tasks to structural\ndistances on graphs that ignore task-specific information. To address this gap,\nwe distill the distance between MPNN embeddings into an interpretable graph\ndistance. Our method uses optimal transport on the Weisfeiler Leman Labeling\nTree (WILT), where the edge weights reveal subgraphs that strongly influence\nthe distance between embeddings. This approach generalizes two well-known graph\nkernels and can be computed in linear time. Through extensive experiments, we\ndemonstrate that MPNNs define the relative position of embeddings by focusing\non a small set of subgraphs that are known to be functionally important in the\ndomain.",
    "pdf_url": "http://arxiv.org/pdf/2505.24642v1",
    "published": "2025-05-30T14:28:41+00:00",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24641v1",
    "title": "A Cross Branch Fusion-Based Contrastive Learning Framework for Point Cloud Self-supervised Learning",
    "authors": [
      "Chengzhi Wu",
      "Qianliang Huang",
      "Kun Jin",
      "Julius Pfrommer",
      "Jürgen Beyerer"
    ],
    "abstract": "Contrastive learning is an essential method in self-supervised learning. It\nprimarily employs a multi-branch strategy to compare latent representations\nobtained from different branches and train the encoder. In the case of\nmulti-modal input, diverse modalities of the same object are fed into distinct\nbranches. When using single-modal data, the same input undergoes various\naugmentations before being fed into different branches. However, all existing\ncontrastive learning frameworks have so far only performed contrastive\noperations on the learned features at the final loss end, with no information\nexchange between different branches prior to this stage. In this paper, for\npoint cloud unsupervised learning without the use of extra training data, we\npropose a Contrastive Cross-branch Attention-based framework for Point cloud\ndata (termed PoCCA), to learn rich 3D point cloud representations. By\nintroducing sub-branches, PoCCA allows information exchange between different\nbranches before the loss end. Experimental results demonstrate that in the case\nof using no extra training data, the representations learned with our\nself-supervised model achieve state-of-the-art performances when used for\ndownstream tasks on point clouds.",
    "pdf_url": "http://arxiv.org/pdf/2505.24641v1",
    "published": "2025-05-30T14:28:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24640v1",
    "title": "Efficient Text Encoders for Labor Market Analysis",
    "authors": [
      "Jens-Joris Decorte",
      "Jeroen Van Hautte",
      "Chris Develder",
      "Thomas Demeester"
    ],
    "abstract": "Labor market analysis relies on extracting insights from job advertisements,\nwhich provide valuable yet unstructured information on job titles and\ncorresponding skill requirements. While state-of-the-art methods for skill\nextraction achieve strong performance, they depend on large language models\n(LLMs), which are computationally expensive and slow. In this paper, we propose\n\\textbf{ConTeXT-match}, a novel contrastive learning approach with token-level\nattention that is well-suited for the extreme multi-label classification task\nof skill classification. \\textbf{ConTeXT-match} significantly improves skill\nextraction efficiency and performance, achieving state-of-the-art results with\na lightweight bi-encoder model. To support robust evaluation, we introduce\n\\textbf{Skill-XL}, a new benchmark with exhaustive, sentence-level skill\nannotations that explicitly address the redundancy in the large label space.\nFinally, we present \\textbf{JobBERT V2}, an improved job title normalization\nmodel that leverages extracted skills to produce high-quality job title\nrepresentations. Experiments demonstrate that our models are efficient,\naccurate, and scalable, making them ideal for large-scale, real-time labor\nmarket analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.24640v1",
    "published": "2025-05-30T14:27:25+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24639v1",
    "title": "Nematic ordering in active fluids driven by substrate deformations: Mechanisms and patterning regimes",
    "authors": [
      "Varun Venkatesh",
      "Amin Doostmohammadi"
    ],
    "abstract": "The interplay between active matter and its environment is central to\nunderstanding emergent behavior in biological and synthetic systems. Here, we\nshow that coupling active nematic flows to small-amplitude deformations of a\ncompliant substrate can fundamentally reorganize the system's dynamics. Using a\nmodel that combines active nematohydrodynamics with substrate mechanics, we\nfind that contractile active nematics-normally disordered in flat\ngeometries-undergo a sharp transition to long-range orientational order when\nthe environment is deformable. This environmentally induced ordering is robust\nand enables distinct patterning regimes, with wrinkle morphologies reflecting\nthe nature of the active stresses. Our results reveal a generic mechanism by\nwhich mechanical feedback from soft environments can lead to ordering in active\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24639v1",
    "published": "2025-05-30T14:26:43+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.24638v1",
    "title": "Cloud Optical Thickness Retrievals Using Angle Invariant Attention Based Deep Learning Models",
    "authors": [
      "Zahid Hassan Tushar",
      "Adeleke Ademakinwa",
      "Jianwu Wang",
      "Zhibo Zhang",
      "Sanjay Purushotham"
    ],
    "abstract": "Cloud Optical Thickness (COT) is a critical cloud property influencing\nEarth's climate, weather, and radiation budget. Satellite radiance measurements\nenable global COT retrieval, but challenges like 3D cloud effects, viewing\nangles, and atmospheric interference must be addressed to ensure accurate\nestimation. Traditionally, the Independent Pixel Approximation (IPA) method,\nwhich treats individual pixels independently, has been used for COT estimation.\nHowever, IPA introduces significant bias due to its simplified assumptions.\nRecently, deep learning-based models have shown improved performance over IPA\nbut lack robustness, as they are sensitive to variations in radiance intensity,\ndistortions, and cloud shadows. These models also introduce substantial errors\nin COT estimation under different solar and viewing zenith angles. To address\nthese challenges, we propose a novel angle-invariant, attention-based deep\nmodel called Cloud-Attention-Net with Angle Coding (CAAC). Our model leverages\nattention mechanisms and angle embeddings to account for satellite viewing\ngeometry and 3D radiative transfer effects, enabling more accurate retrieval of\nCOT. Additionally, our multi-angle training strategy ensures angle invariance.\nThrough comprehensive experiments, we demonstrate that CAAC significantly\noutperforms existing state-of-the-art deep learning models, reducing cloud\nproperty retrieval errors by at least a factor of nine.",
    "pdf_url": "http://arxiv.org/pdf/2505.24638v1",
    "published": "2025-05-30T14:26:30+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24637v1",
    "title": "Note on the size of a stable matching",
    "authors": [
      "Gregory Z. Gutin",
      "Philip R. Neary",
      "Anders Yeo"
    ],
    "abstract": "Consider a one-to-one two-sided matching market with workers on one side and\nsingle-position firms on the other, and suppose that the largest individually\nrational matching contains $n$ pairs. We show that the number of workers\nemployed and positions filled in every stable matching is bounded from below by\n$\\lceil\\frac{n}{2}\\rceil$ and we characterise the class of preferences that\nattain the bound.",
    "pdf_url": "http://arxiv.org/pdf/2505.24637v1",
    "published": "2025-05-30T14:25:54+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.24636v1",
    "title": "Category-Level 6D Object Pose Estimation in Agricultural Settings Using a Lattice-Deformation Framework and Diffusion-Augmented Synthetic Data",
    "authors": [
      "Marios Glytsos",
      "Panagiotis P. Filntisis",
      "George Retsinas",
      "Petros Maragos"
    ],
    "abstract": "Accurate 6D object pose estimation is essential for robotic grasping and\nmanipulation, particularly in agriculture, where fruits and vegetables exhibit\nhigh intra-class variability in shape, size, and texture. The vast majority of\nexisting methods rely on instance-specific CAD models or require depth sensors\nto resolve geometric ambiguities, making them impractical for real-world\nagricultural applications. In this work, we introduce PLANTPose, a novel\nframework for category-level 6D pose estimation that operates purely on RGB\ninput. PLANTPose predicts both the 6D pose and deformation parameters relative\nto a base mesh, allowing a single category-level CAD model to adapt to unseen\ninstances. This enables accurate pose estimation across varying shapes without\nrelying on instance-specific data. To enhance realism and improve\ngeneralization, we also leverage Stable Diffusion to refine synthetic training\nimages with realistic texturing, mimicking variations due to ripeness and\nenvironmental factors and bridging the domain gap between synthetic data and\nthe real world. Our evaluations on a challenging benchmark that includes\nbananas of various shapes, sizes, and ripeness status demonstrate the\neffectiveness of our framework in handling large intraclass variations while\nmaintaining accurate 6D pose predictions, significantly outperforming the\nstate-of-the-art RGB-based approach MegaPose.",
    "pdf_url": "http://arxiv.org/pdf/2505.24636v1",
    "published": "2025-05-30T14:25:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24635v1",
    "title": "Disentangling Language and Culture for Evaluating Multilingual Large Language Models",
    "authors": [
      "Jiahao Ying",
      "Wei Tang",
      "Yiran Zhao",
      "Yixin Cao",
      "Yu Rong",
      "Wenxuan Zhang"
    ],
    "abstract": "This paper introduces a Dual Evaluation Framework to comprehensively assess\nthe multilingual capabilities of LLMs. By decomposing the evaluation along the\ndimensions of linguistic medium and cultural context, this framework enables a\nnuanced analysis of LLMs' ability to process questions within both native and\ncross-cultural contexts cross-lingually. Extensive evaluations are conducted on\na wide range of models, revealing a notable \"CulturalLinguistic Synergy\"\nphenomenon, where models exhibit better performance when questions are\nculturally aligned with the language. This phenomenon is further explored\nthrough interpretability probing, which shows that a higher proportion of\nspecific neurons are activated in a language's cultural context. This\nactivation proportion could serve as a potential indicator for evaluating\nmultilingual performance during model training. Our findings challenge the\nprevailing notion that LLMs, primarily trained on English data, perform\nuniformly across languages and highlight the necessity of culturally and\nlinguistically model evaluations. Our code can be found at\nhttps://yingjiahao14. github.io/Dual-Evaluation/.",
    "pdf_url": "http://arxiv.org/pdf/2505.24635v1",
    "published": "2025-05-30T14:25:45+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24634v2",
    "title": "NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation",
    "authors": [
      "Xuzhi Wang",
      "Wei Feng",
      "Lingdong Kong",
      "Liang Wan"
    ],
    "abstract": "LiDAR semantic segmentation plays a vital role in autonomous driving.\nExisting voxel-based methods for LiDAR semantic segmentation apply uniform\npartition to the 3D LiDAR point cloud to form a structured representation based\non cartesian/cylindrical coordinates. Although these methods show impressive\nperformance, the drawback of existing voxel-based methods remains in two\naspects: (1) it requires a large enough input voxel resolution, which brings a\nlarge amount of computation cost and memory consumption. (2) it does not well\nhandle the unbalanced point distribution of LiDAR point cloud. In this paper,\nwe propose a non-uniform cylindrical partition network named NUC-Net to tackle\nthe above challenges. Specifically, we propose the Arithmetic Progression of\nInterval (API) method to non-uniformly partition the radial axis and generate\nthe voxel representation which is representative and efficient. Moreover, we\npropose a non-uniform multi-scale aggregation method to improve contextual\ninformation. Our method achieves state-of-the-art performance on SemanticKITTI\nand nuScenes datasets with much faster speed and much less training time. And\nour method can be a general component for LiDAR semantic segmentation, which\nsignificantly improves both the accuracy and efficiency of the uniform\ncounterpart by $4 \\times$ training faster and $2 \\times$ GPU memory reduction\nand $3 \\times$ inference speedup. We further provide theoretical analysis\ntowards understanding why NUC is effective and how point distribution affects\nperformance. Code is available at\n\\href{https://github.com/alanWXZ/NUC-Net}{https://github.com/alanWXZ/NUC-Net}.",
    "pdf_url": "http://arxiv.org/pdf/2505.24634v2",
    "published": "2025-05-30T14:25:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24633v2",
    "title": "Sphere amplitudes and observing the universe's size",
    "authors": [
      "Andreas Blommaert",
      "Adam Levine"
    ],
    "abstract": "Sine dilaton gravity is holographically related to DSSYK. We explain how to\ninterpret sine dilaton as 2d quantum cosmology. This paves the way for using\ntwo copies of DSSYK as hologram for Big-Bang cosmologies. We study the most\nbasic cosmological observable: the sphere amplitude. Via canonical quantization\nwe find a finite answer that matches the on-shell action of a dual matrix\nintegral. The sphere amplitude (or the norm of the no-boundary wavefunction)\nalso gives a prediction for the universe's size. In the context of slow-roll\ninflation, the no-boundary state is non-normalizable, and predicts a small\nuniverse, in contradiction with experiments. We argue that an avatar of these\nissues exists in dS JT gravity. By considering sine dilaton as a UV completion\nof dS JT gravity, the state becomes normalizable. We then consider the\nobserver's no-boundary state and show that this prefers neither small nor large\nuniverses. The resulting distribution is flat.",
    "pdf_url": "http://arxiv.org/pdf/2505.24633v2",
    "published": "2025-05-30T14:25:28+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24632v2",
    "title": "Weak localization as probe of spin-orbit-induced spin-split bands in bilayer graphene proximity coupled to WSe$_2$",
    "authors": [
      "E. Icking",
      "F. Wörtche",
      "A. W. Cummings",
      "A. Wörtche",
      "K. Watanabe",
      "T. Taniguchi",
      "C. Volk",
      "B. Beschoten",
      "C. Stampfer"
    ],
    "abstract": "Proximity coupling of bilayer graphene (BLG) to transition metal\ndichalcogenides (TMDs) offers a promising route to engineer gate-tunable\nspin-orbit coupling (SOC) while preserving BLG's exceptional electronic\nproperties. This tunability arises from the layer-asymmetric electronic\nstructure of gapped BLG, where SOC acts predominantly on the layer in contact\nwith the TMD. Here, we present high-quality BLG/WSe$_2$ devices with a\nproximity-induced SOC gap and excellent electrostatic control. Operating in a\nquasi-ballistic regime, our double-gated heterostructures allow to form\ngate-defined p-n-p cavities and show clear weak anti-localization (WAL)\nfeatures consistent with Rashba-type SOC. At lower hole densities, a transition\nto weak localization (WL) is observed, signaling transport through a single\nspin-split valence band. These findings - in agreement with calculations -\nprovide direct spectroscopic evidence of proximity-induced spin-split band in\nBLG and underscore the potential of BLG/TMD heterostructures for spintronics\nand spin-based quantum technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.24632v2",
    "published": "2025-05-30T14:25:07+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24631v1",
    "title": "Cascades on Constrained Multiplex Networks",
    "authors": [
      "Christian Kluge",
      "Christian Kuehn"
    ],
    "abstract": "We consider a version of the Watts cascade model on directed multiplex\nconfiguration model networks, and present a detailed analysis of the cascade\nsize, single-seed cascade probability and cascade condition. We then introduce\na smaller class of network models that we call constrained multiplex networks,\nwhich allows us to induce patterns in the node activity, i.e. in the\nparticipation of nodes on different layers. We find that the choice of induced\npatterns affects the phase transitions of the cascade model in a variety of\nways.",
    "pdf_url": "http://arxiv.org/pdf/2505.24631v1",
    "published": "2025-05-30T14:24:56+00:00",
    "categories": [
      "nlin.AO",
      "cs.SI",
      "math.PR",
      "physics.soc-ph"
    ],
    "primary_category": "nlin.AO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24630v1",
    "title": "The Hallucination Dilemma: Factuality-Aware Reinforcement Learning for Large Reasoning Models",
    "authors": [
      "Junyi Li",
      "Hwee Tou Ng"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced in reasoning tasks\nthrough reinforcement learning (RL) optimization, achieving impressive\ncapabilities across various challenging benchmarks. However, our empirical\nanalysis reveals a critical drawback: reasoning-oriented RL fine-tuning\nsignificantly increases the prevalence of hallucinations. We theoretically\nanalyze the RL training dynamics, identifying high-variance gradient,\nentropy-induced randomness, and susceptibility to spurious local optima as key\nfactors leading to hallucinations. To address this drawback, we propose\nFactuality-aware Step-wise Policy Optimization (FSPO), an innovative RL\nfine-tuning algorithm incorporating explicit factuality verification at each\nreasoning step. FSPO leverages automated verification against given evidence to\ndynamically adjust token-level advantage values, incentivizing factual\ncorrectness throughout the reasoning process. Experiments across mathematical\nreasoning and hallucination benchmarks using Qwen2.5 and Llama models\ndemonstrate that FSPO effectively reduces hallucinations while enhancing\nreasoning accuracy, substantially improving both reliability and performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.24630v1",
    "published": "2025-05-30T14:23:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24629v1",
    "title": "Stop Guessing: Optimizing Goalkeeper Policies for Soccer Penalty Kicks",
    "authors": [
      "Lotte Bransen",
      "Tim Janssen",
      "Jesse Davis"
    ],
    "abstract": "Penalties are fraught and game-changing moments in soccer games that teams\nexplicitly prepare for. Consequently, there has been substantial interest in\nanalyzing them in order to provide advice to practitioners. From a data science\nperspective, such analyses suffer from a significant limitation: they make the\nunrealistic simplifying assumption that goalkeepers and takers select their\naction -- where to dive and where to the place the kick -- independently of\neach other. In reality, the choices that some goalkeepers make depend on the\ntaker's movements and vice-versa. This adds substantial complexity to the\nproblem because not all players have the same action capacities, that is, only\nsome players are capable of basing their decisions on their opponent's\nmovements. However, the small sample sizes on the player level mean that one\nmay have limited insights into a specific opponent's capacities. We address\nthese challenges by developing a player-agnostic simulation framework that can\nevaluate the efficacy of different goalkeeper strategies. It considers a rich\nset of choices and incorporates information about a goalkeeper's skills. Our\nwork is grounded in a large dataset of penalties that were annotated by penalty\nexperts and include aspects of both kicker and goalkeeper strategies. We show\nhow our framework can be used to optimize goalkeeper policies in real-world\nsituations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24629v1",
    "published": "2025-05-30T14:23:12+00:00",
    "categories": [
      "cs.LG",
      "cs.GT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24628v2",
    "title": "Three-Dimensional Hieratical Twists in Polar Fluids: Chirality Regulation by Ultra-Low Electric Field",
    "authors": [
      "Hiroya Nishikawa",
      "Dennis Kwaria",
      "Atsuko Nihonyanagi",
      "Fumito Araoka"
    ],
    "abstract": "Recently discovered helical polar fluid adopts a spontaneous chiral symmetry\nbreaking (CSB) driven by polarization escape and conformational chirality.\nFerroelectric nematic and smectic phases are intrinsically chiral in the ground\nstate and can be stabilized in an extrinsic twisted configuration through\nsurface anchoring. Herein, we introduce extrinsic CSB as a novel technique in\nchiral engineering. To demonstrate this concept, we constructed the extrinsic\nstructure of a helielectric conical mesophase (HEC)-three-dimensional chiral\nsystem. Considering the challenges of controlling chirality at the macroscopic\nscale owing to magnetic fields, light, and fluid vortex motion, the proposed\nthree-dimensional chiral system enables chirality (twist) modulation through an\nultralow electric field, thereby controlling unique diffraction pattern and\ncircular polarized light-switching capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.24628v2",
    "published": "2025-05-30T14:21:40+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24627v2",
    "title": "Rethinking Neural Combinatorial Optimization for Vehicle Routing Problems with Different Constraint Tightness Degrees",
    "authors": [
      "Fu Luo",
      "Yaoxin Wu",
      "Zhi Zheng",
      "Zhenkun Wang"
    ],
    "abstract": "Recent neural combinatorial optimization (NCO) methods have shown promising\nproblem-solving ability without requiring domain-specific expertise. Most\nexisting NCO methods use training and testing data with a fixed constraint\nvalue and lack research on the effect of constraint tightness on the\nperformance of NCO methods. This paper takes the capacity-constrained vehicle\nrouting problem (CVRP) as an example to empirically analyze the NCO performance\nunder different tightness degrees of the capacity constraint. Our analysis\nreveals that existing NCO methods overfit the capacity constraint, and they can\nonly perform satisfactorily on a small range of the constraint values but\npoorly on other values. To tackle this drawback of existing NCO methods, we\ndevelop an efficient training scheme that explicitly considers varying degrees\nof constraint tightness and proposes a multi-expert module to learn a generally\nadaptable solving strategy. Experimental results show that the proposed method\ncan effectively overcome the overfitting issue, demonstrating superior\nperformances on the CVRP and CVRP with time windows (CVRPTW) with various\nconstraint tightness degrees.",
    "pdf_url": "http://arxiv.org/pdf/2505.24627v2",
    "published": "2025-05-30T14:21:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00102v1",
    "title": "Tensor Network for Anomaly Detection in the Latent Space of Proton Collision Events at the LHC",
    "authors": [
      "Ema Puljak",
      "Maurizio Pierini",
      "Artur Garcia-Saez"
    ],
    "abstract": "The pursuit of discovering new phenomena at the Large Hadron Collider (LHC)\ndemands constant innovation in algorithms and technologies. Tensor networks are\nmathematical models on the intersection of classical and quantum machine\nlearning, which present a promising and efficient alternative for tackling\nthese challenges. In this work, we propose a tensor network-based strategy for\nanomaly detection at the LHC and demonstrate its superior performance in\nidentifying new phenomena compared to established quantum methods. Our model is\na parametrized Matrix Product State with an isometric feature map, processing a\nlatent representation of simulated LHC data generated by an autoencoder. Our\nresults highlight the potential of tensor networks to enhance new-physics\ndiscovery.",
    "pdf_url": "http://arxiv.org/pdf/2506.00102v1",
    "published": "2025-05-30T14:18:53+00:00",
    "categories": [
      "hep-ph",
      "cond-mat.stat-mech",
      "cs.LG",
      "hep-ex",
      "quant-ph",
      "stat.ML"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24626v1",
    "title": "Co-designed Quantum Discrete Adiabatic Linear System Solver Via Dynamic Circuits",
    "authors": [
      "Boxuan Ai",
      "Shuo He",
      "Xiang Zhao",
      "Lin Yang",
      "Guozhen Liu",
      "Pengfei Gao",
      "Hongbao Liu",
      "Tao Tang",
      "Jiecheng Yang",
      "Jie Wu"
    ],
    "abstract": "Existing quantum discrete adiabatic approaches are hindered by circuit depth\nthat increases linearly with the number of evolution steps, a significant\nchallenge for current quantum hardware with limited coherence times. To address\nthis, we propose a co-designed framework that synergistically integrates\ndynamic circuit capabilities with real-time classical processing. This\nframework reformulates the quantum adiabatic evolution into discrete,\ndynamically adjustable segments. The unitary operator for each segment is\noptimized on-the-fly using classical computation, and circuit multiplexing\ntechniques are leveraged to reduce the overall circuit depth scaling from\n$O(\\text{steps}\\times\\text{depth}(U))$ to $O(\\text{depth}(U))$. We implement\nand benchmark a quantum discrete adiabatic linear solver based on this\nframework for linear systems of $W \\in \\{2,4,8,16\\}$ dimensions with condition\nnumbers $\\kappa \\in \\{10,20,30,40,50\\}$. Our solver successfully overcomes\nprevious depth limitations, maintaining over 80% solution fidelity even under\nrealistic noise models. Key algorithmic optimizations contributing to this\nperformance include a first-order approximation of the discrete evolution\noperator, a tailored dynamic circuit design exploiting real-imaginary component\nseparation, and noise-resilient post-processing techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.24626v1",
    "published": "2025-05-30T14:18:42+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24625v2",
    "title": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors",
    "authors": [
      "Duo Zheng",
      "Shijia Huang",
      "Yanyang Li",
      "Liwei Wang"
    ],
    "abstract": "Previous research has investigated the application of Multimodal Large\nLanguage Models (MLLMs) in understanding 3D scenes by interpreting them as\nvideos. These approaches generally depend on comprehensive 3D data inputs, such\nas point clouds or reconstructed Bird's-Eye View (BEV) maps. In our research,\nwe advance this field by enhancing the capability of MLLMs to understand and\nreason in 3D spaces directly from video data, without the need for additional\n3D input. We propose a novel and efficient method, the Video-3D Geometry Large\nLanguage Model (VG LLM). Our approach employs a 3D visual geometry encoder that\nextracts 3D prior information from video sequences. This information is\nintegrated with visual tokens and fed into the MLLM. Extensive experiments have\nshown that our method has achieved substantial improvements in various tasks\nrelated to 3D scene understanding and spatial reasoning, all directly learned\nfrom video sources. Impressively, our 4B model, which does not rely on explicit\n3D data inputs, achieves competitive results compared to existing\nstate-of-the-art methods, and even surpasses the Gemini-1.5-Pro in the\nVSI-Bench evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24625v2",
    "published": "2025-05-30T14:16:41+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24624v2",
    "title": "Online Budget-Feasible Mechanism Design with Predictions",
    "authors": [
      "Georgios Amanatidis",
      "Evangelos Markakis",
      "Christodoulos Santorinaios",
      "Guido Schäfer",
      "Panagiotis Tsamopoulos",
      "Artem Tsikiridis"
    ],
    "abstract": "Augmenting the input of algorithms with predictions is an algorithm design\nparadigm that suggests leveraging a (possibly erroneous) prediction to improve\nworst-case performance guarantees when the prediction is perfect (consistency),\nwhile also providing a performance guarantee when the prediction fails\n(robustness). Recently, Xu and Lu [2022] and Agrawal et al. [2024] proposed to\nconsider settings with strategic agents under this framework. In this paper, we\ninitiate the study of budget-feasible mechanism design with predictions. These\nmechanisms model a procurement auction scenario in which an auctioneer (buyer)\nwith a strict budget constraint seeks to purchase goods or services from a set\nof strategic agents, so as to maximize her own valuation function. We focus on\nthe online version of the problem where the arrival order of agents is random.\nWe design mechanisms that are truthful, budget-feasible, and achieve a\nsignificantly improved competitive ratio for both monotone and non-monotone\nsubmodular valuation functions compared to their state-of-the-art counterparts\nwithout predictions. Our results assume access to a prediction for the value of\nthe optimal solution to the offline problem. We complement our positive results\nby showing that for the offline version of the problem, access to predictions\nis mostly ineffective in improving approximation guarantees.",
    "pdf_url": "http://arxiv.org/pdf/2505.24624v2",
    "published": "2025-05-30T14:16:03+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24623v1",
    "title": "Hyperbolic Dataset Distillation",
    "authors": [
      "Wenyuan Li",
      "Guang Li",
      "Keisuke Maeda",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "abstract": "To address the computational and storage challenges posed by large-scale\ndatasets in deep learning, dataset distillation has been proposed to synthesize\na compact dataset that replaces the original while maintaining comparable model\nperformance. Unlike optimization-based approaches that require costly bi-level\noptimization, distribution matching (DM) methods improve efficiency by aligning\nthe distributions of synthetic and original data, thereby eliminating nested\noptimization. DM achieves high computational efficiency and has emerged as a\npromising solution. However, existing DM methods, constrained to Euclidean\nspace, treat data as independent and identically distributed points,\noverlooking complex geometric and hierarchical relationships. To overcome this\nlimitation, we propose a novel hyperbolic dataset distillation method, termed\nHDD. Hyperbolic space, characterized by negative curvature and exponential\nvolume growth with distance, naturally models hierarchical and tree-like\nstructures. HDD embeds features extracted by a shallow network into the Lorentz\nhyperbolic space, where the discrepancy between synthetic and original data is\nmeasured by the hyperbolic (geodesic) distance between their centroids. By\noptimizing this distance, the hierarchical structure is explicitly integrated\ninto the distillation process, guiding synthetic samples to gravitate towards\nthe root-centric regions of the original data distribution while preserving\ntheir underlying geometric characteristics. Furthermore, we find that pruning\nin hyperbolic space requires only 20% of the distilled core set to retain model\nperformance, while significantly improving training stability. Notably, HDD is\nseamlessly compatible with most existing DM methods, and extensive experiments\non different datasets validate its effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.24623v1",
    "published": "2025-05-30T14:14:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24622v1",
    "title": "Random Rule Forest (RRF): Interpretable Ensembles of LLM-Generated Questions for Predicting Startup Success",
    "authors": [
      "Ben Griffin",
      "Joseph Ternasky",
      "Fuat Alican",
      "Yigit Ihlamur"
    ],
    "abstract": "Predicting startup success requires models that are both accurate and\ninterpretable. We present a lightweight ensemble framework that combines YES/NO\nquestions generated by large language models (LLMs), forming a transparent\ndecision-making system. Each question acts as a weak heuristic, and by\nfiltering, ranking, and aggregating them through a threshold-based voting\nmechanism, we construct a strong ensemble predictor. On a test set where 10% of\nstartups are classified as successful, our approach achieves a precision rate\nof 50%, representing a 5x improvement over random selection, while remaining\nfully transparent. When we incorporate expert-guided heuristics into the\ngeneration process, performance improves further to 54% precision. These\nresults highlight the value of combining LLM reasoning with human insight and\ndemonstrate that simple, interpretable ensembles can support high-stakes\ndecisions in domains such as venture capital (VC).",
    "pdf_url": "http://arxiv.org/pdf/2505.24622v1",
    "published": "2025-05-30T14:13:21+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24621v1",
    "title": "Benchmarking Large Language Models for Cryptanalysis and Mismatched-Generalization",
    "authors": [
      "Utsav Maskey",
      "Chencheng Zhu",
      "Usman Naseem"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have transformed natural\nlanguage understanding and generation, leading to extensive benchmarking across\ndiverse tasks. However, cryptanalysis a critical area for data security and\nencryption has not yet been thoroughly explored in LLM evaluations. To address\nthis gap, we evaluate cryptanalytic potential of state of the art LLMs on\nencrypted texts generated using a range of cryptographic algorithms. We\nintroduce a novel benchmark dataset comprising diverse plain texts spanning\nvarious domains, lengths, writing styles, and topics paired with their\nencrypted versions. Using zero-shot and few shot settings, we assess multiple\nLLMs for decryption accuracy and semantic comprehension across different\nencryption schemes. Our findings reveal key insights into the strengths and\nlimitations of LLMs in side-channel communication while raising concerns about\ntheir susceptibility to jailbreaking attacks. This research highlights the\ndual-use nature of LLMs in security contexts and contributes to the ongoing\ndiscussion on AI safety and security.",
    "pdf_url": "http://arxiv.org/pdf/2505.24621v1",
    "published": "2025-05-30T14:12:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24620v1",
    "title": "Covariant diffusion and drift of the stochastic GW background with LISA",
    "authors": [
      "Giorgio Mentasti",
      "Arad Nasiri"
    ],
    "abstract": "We study the covariant diffusion and drift of massless particles on the light\ncone within the context of quantum gravity phenomenology. Unlike modified\ndispersion relations that violate Lorentz invariance and grow with frequency,\nthis model introduces a stochastic correction to the massless geodesic equation\nwhile preserving Lorentz invariance, and is dominant at lower frequencies due\nto the larger spacetime support of long-wavelength modes. The effect is\nphenomenologically described by just two diffusion and drift parameters,\n$\\kappa_1$ and $\\kappa_2$, whose values are already constrained by measurements\nof the CMB blackbody spectrum. We show that a direct measurement and\ncharacterization of a gravitational wave (GW) background frequency spectrum can\nimprove bounds on these diffusion and drift parameters by over 12 orders of\nmagnitude compared to those from the CMB. In particular, we find that detecting\na GW background sourced by realistic models of first-order phase transitions or\nprimordial black holes (PBH) with LISA can constrain the parameters down to a\nvalue of $\\kappa_1,\\,\\kappa_2\\lesssim\n10^{-56}\\,\\text{kg}\\,\\text{m}^2\\text{s}^{-3}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24620v1",
    "published": "2025-05-30T14:11:50+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.24619v1",
    "title": "Interpretable phenotyping of Heart Failure patients with Dutch discharge letters",
    "authors": [
      "Vittorio Torri",
      "Machteld J. Boonstra",
      "Marielle C. van de Veerdonk",
      "Deborah N. Kalkman",
      "Alicia Uijl",
      "Francesca Ieva",
      "Ameen Abu-Hanna",
      "Folkert W. Asselbergs",
      "Iacer Calixto"
    ],
    "abstract": "Objective: Heart failure (HF) patients present with diverse phenotypes\naffecting treatment and prognosis. This study evaluates models for phenotyping\nHF patients based on left ventricular ejection fraction (LVEF) classes, using\nstructured and unstructured data, assessing performance and interpretability.\n  Materials and Methods: The study analyzes all HF hospitalizations at both\nAmsterdam UMC hospitals (AMC and VUmc) from 2015 to 2023 (33,105\nhospitalizations, 16,334 patients). Data from AMC were used for model training,\nand from VUmc for external validation. The dataset was unlabelled and included\ntabular clinical measurements and discharge letters. Silver labels for LVEF\nclasses were generated by combining diagnosis codes, echocardiography results,\nand textual mentions. Gold labels were manually annotated for 300 patients for\ntesting. Multiple Transformer-based (black-box) and Aug-Linear (white-box)\nmodels were trained and compared with baselines on structured and unstructured\ndata. To evaluate interpretability, two clinicians annotated 20 discharge\nletters by highlighting information they considered relevant for LVEF\nclassification. These were compared to SHAP and LIME explanations from\nblack-box models and the inherent explanations of Aug-Linear models.\n  Results: BERT-based and Aug-Linear models, using discharge letters alone,\nachieved the highest classification results (AUC=0.84 for BERT, 0.81 for\nAug-Linear on external validation), outperforming baselines. Aug-Linear\nexplanations aligned more closely with clinicians' explanations than post-hoc\nexplanations on black-box models.\n  Conclusions: Discharge letters emerged as the most informative source for\nphenotyping HF patients. Aug-Linear models matched black-box performance while\nproviding clinician-aligned interpretability, supporting their use in\ntransparent clinical decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2505.24619v1",
    "published": "2025-05-30T14:11:32+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "68T50",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24618v1",
    "title": "Distributed Intelligence in the Computing Continuum with Active Inference",
    "authors": [
      "Victor Casamayor Pujol",
      "Boris Sedlak",
      "Tommaso Salvatori",
      "Karl Friston",
      "Schahram Dustdar"
    ],
    "abstract": "The Computing Continuum (CC) is an emerging Internet-based computing paradigm\nthat spans from local Internet of Things sensors and constrained edge devices\nto large-scale cloud data centers. Its goal is to orchestrate a vast array of\ndiverse and distributed computing resources to support the next generation of\nInternet-based applications. However, the distributed, heterogeneous, and\ndynamic nature of CC platforms demands distributed intelligence for adaptive\nand resilient service management. This article introduces a distributed stream\nprocessing pipeline as a CC use case, where each service is managed by an\nActive Inference (AIF) agent. These agents collaborate to fulfill service needs\nspecified by SLOiDs, a term we introduce to denote Service Level Objectives\nthat are aware of its deployed devices, meaning that non-functional\nrequirements must consider the characteristics of the hosting device. We\ndemonstrate how AIF agents can be modeled and deployed alongside distributed\nservices to manage them autonomously. Our experiments show that AIF agents\nachieve over 90% SLOiD fulfillment when using tested transition models, and\naround 80% when learning the models during deployment. We compare their\nperformance to a multi-agent reinforcement learning algorithm, finding that\nwhile both approaches yield similar results, MARL requires extensive training,\nwhereas AIF agents can operate effectively from the start. Additionally, we\nevaluate the behavior of AIF agents in offloading scenarios, observing a strong\ncapacity for adaptation. Finally, we outline key research directions to advance\nAIF integration in CC platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.24618v1",
    "published": "2025-05-30T14:10:33+00:00",
    "categories": [
      "cs.DC",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24617v2",
    "title": "Probing emergent axion electrodynamics with waveguide apparatus",
    "authors": [
      "André H. Gomes",
      "Winder A. Moura-Melo"
    ],
    "abstract": "We demonstrate that a conventional hollow conductor waveguide filled with a\nmaterial exhibiting the coexistence of chiral magnetic and anomalous quantum\nHall effects supports the propagation of transverse electromagnetic modes. This\nsimple setup provides a direct and optically feasible method to probe the\nsimultaneous presence of these phenomena, potentially enabling the detection of\nan emergent axion-like field within condensed matter systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24617v2",
    "published": "2025-05-30T14:09:31+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "hep-ph",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24616v3",
    "title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX",
    "authors": [
      "Nikita Martynov",
      "Anastasia Mordasheva",
      "Dmitriy Gorbetskiy",
      "Danil Astafurov",
      "Ulyana Isaeva",
      "Elina Basyrova",
      "Sergey Skachkov",
      "Victoria Berestova",
      "Nikolay Ivanov",
      "Valeriia Zanina",
      "Alena Fenogenova"
    ],
    "abstract": "We introduce POLLUX, a comprehensive open-source benchmark designed to\nevaluate the generative capabilities of large language models (LLMs) in\nRussian. Our main contribution is a novel evaluation methodology that enhances\nthe interpretability of LLM assessment. For each task type, we define a set of\ndetailed criteria and develop a scoring protocol where models evaluate\nresponses and provide justifications for their ratings. This enables\ntransparent, criteria-driven evaluation beyond traditional resource-consuming,\nside-by-side human comparisons. POLLUX includes a detailed, fine-grained\ntaxonomy of 35 task types covering diverse generative domains such as code\ngeneration, creative writing, and practical assistant use cases, totaling 2,100\nmanually crafted and professionally authored prompts. Each task is categorized\nby difficulty (easy/medium/hard), with experts constructing the dataset\nentirely from scratch. We also release a family of LLM-as-a-Judge (7B and 32B)\nevaluators trained for nuanced assessment of generative outputs. This approach\nprovides scalable, interpretable evaluation and annotation tools for model\ndevelopment, effectively replacing costly and less precise human judgments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24616v3",
    "published": "2025-05-30T14:08:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24615v1",
    "title": "Harnessing Large Language Models for Scientific Novelty Detection",
    "authors": [
      "Yan Liu",
      "Zonglin Yang",
      "Soujanya Poria",
      "Thanh-Son Nguyen",
      "Erik Cambria"
    ],
    "abstract": "In an era of exponential scientific growth, identifying novel research ideas\nis crucial and challenging in academia. Despite potential, the lack of an\nappropriate benchmark dataset hinders the research of novelty detection. More\nimportantly, simply adopting existing NLP technologies, e.g., retrieving and\nthen cross-checking, is not a one-size-fits-all solution due to the gap between\ntextual similarity and idea conception. In this paper, we propose to harness\nlarge language models (LLMs) for scientific novelty detection (ND), associated\nwith two new datasets in marketing and NLP domains. To construct the\nconsiderate datasets for ND, we propose to extract closure sets of papers based\non their relationship, and then summarize their main ideas based on LLMs. To\ncapture idea conception, we propose to train a lightweight retriever by\ndistilling the idea-level knowledge from LLMs to align ideas with similar\nconception, enabling efficient and accurate idea retrieval for LLM novelty\ndetection. Experiments show our method consistently outperforms others on the\nproposed benchmark datasets for idea retrieval and ND tasks. Codes and data are\navailable at https://anonymous.4open.science/r/NoveltyDetection-10FB/.",
    "pdf_url": "http://arxiv.org/pdf/2505.24615v1",
    "published": "2025-05-30T14:08:13+00:00",
    "categories": [
      "cs.CL",
      "H.4.0"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24614v1",
    "title": "High-charge relativistic electrons by vacuum laser acceleration from plasma mirrors using flying focus pulses",
    "authors": [
      "Jiaxin Liu",
      "Zeyue Pang",
      "Hehanlin Wang",
      "Zi-Yu Chen"
    ],
    "abstract": "Relativistic electron beams produced by intense lasers over short distances\nhave important applications in high energy density physics and medical\ntechnologies. Vacuum laser acceleration with plasma mirrors injectors has\ngarnered substantial research interest recently. However, a persistent\nchallenge remains unresolved that electrons inevitably detach from the laser\nacceleration phase due to velocity mismatch. Here, we employ flying focus\nlasers to address this limitation. Through three-dimensional particle-in-cell\nsimulations, we demonstrate that flying focus lasers can achieve a substantial\nenhancement in relativistic electron charge yield compared to conventional\nGaussian lasers. This improvement stems from two key attributes: (1) The\nsubluminal propagation velocity of the peak intensity keeps a larger electron\npopulation synchronized within the longitudinal ponderomotive acceleration\nregion, and (2) Flying focus lasers sustain higher magnitudes of the\nlongitudinal ponderomotive force over longer distances in comparison to\nGaussian lasers. This approach offers high-charge relativistic electron sources\nideal for demanding applications such as high-flux Thomson scattering and\nradiography.",
    "pdf_url": "http://arxiv.org/pdf/2505.24614v1",
    "published": "2025-05-30T14:06:24+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24613v1",
    "title": "When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation",
    "authors": [
      "Daniela Occhipinti",
      "Marco Guerini",
      "Malvina Nissim"
    ],
    "abstract": "Endowing dialogue agents with persona information has proven to significantly\nimprove the consistency and diversity of their generations. While much focus\nhas been placed on aligning dialogues with provided personas, the adaptation to\nthe interlocutor's profile remains largely underexplored. In this work, we\ninvestigate three key aspects: (1) a model's ability to align responses with\nboth the provided persona and the interlocutor's; (2) its robustness when\ndealing with familiar versus unfamiliar interlocutors and topics, and (3) the\nimpact of additional fine-tuning on specific persona-based dialogues. We\nevaluate dialogues generated with diverse speaker pairings and topics, framing\nthe evaluation as an author identification task and employing both\nLLM-as-a-judge and human evaluations. By systematically masking or disclosing\ninformation about the interlocutor, we assess its impact on dialogue\ngeneration. Results show that access to the interlocutor's persona improves the\nrecognition of the target speaker, while masking it does the opposite. Although\nmodels generalise well across topics, they struggle with unfamiliar\ninterlocutors. Finally, we found that in zero-shot settings, LLMs often copy\nbiographical details, facilitating identification but trivialising the task.",
    "pdf_url": "http://arxiv.org/pdf/2505.24613v1",
    "published": "2025-05-30T14:04:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24612v1",
    "title": "Multi-criteria Rank-based Aggregation for Explainable AI",
    "authors": [
      "Sujoy Chatterjee",
      "Everton Romanzini Colombo",
      "Marcos Medeiros Raimundo"
    ],
    "abstract": "Explainability is crucial for improving the transparency of black-box machine\nlearning models. With the advancement of explanation methods such as LIME and\nSHAP, various XAI performance metrics have been developed to evaluate the\nquality of explanations. However, different explainers can provide contrasting\nexplanations for the same prediction, introducing trade-offs across conflicting\nquality metrics. Although available aggregation approaches improve robustness,\nreducing explanations' variability, very limited research employed a\nmulti-criteria decision-making approach. To address this gap, this paper\nintroduces a multi-criteria rank-based weighted aggregation method that\nbalances multiple quality metrics simultaneously to produce an ensemble of\nexplanation models. Furthermore, we propose rank-based versions of existing XAI\nmetrics (complexity, faithfulness and stability) to better evaluate ranked\nfeature importance explanations. Extensive experiments on publicly available\ndatasets demonstrate the robustness of the proposed model across these metrics.\nComparative analyses of various multi-criteria decision-making and rank\naggregation algorithms showed that TOPSIS and WSUM are the best candidates for\nthis use case.",
    "pdf_url": "http://arxiv.org/pdf/2505.24612v1",
    "published": "2025-05-30T14:02:59+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24611v1",
    "title": "Electroluminescence and charge multiplication in liquid xenon with a VCC-like Microstrip Plate",
    "authors": [
      "Gonzalo Martínez-Lema",
      "Vitaly Chepel",
      "Amos Breskin"
    ],
    "abstract": "We report on the first observation of electroluminescence and charge\namplification with a Virtual Cathode Chamber (VCC) microstrips plate immersed\nin liquid xenon. Both were observed in an intense non-uniform electric field in\nthe vicinity of 2-$\\mu$m narrow anode strips deposited, with a 2~mm pitch, on a\nsemiconductive glass substrate (S8900), with a cathode film on its backside. An\ninitial light yield of $\\sim$460 VUV photons per drifting electron was\nmeasured, which degraded within tens of minutes stabilizing at\n(27.0~$\\pm$~3.1)~photons per electron. The electroluminescence was accompanied\nby electron multiplication with an estimated charge gain $<$10. Further\ninvestigations are necessary to understand and mitigate the light yield\ndegradation phenomenon. We expect other substrate materials, including\nVUV-transparent ones, to provide large stable photon yields, compatible with\nour model predictions. The VCC configuration has demonstrated great potential\nin single-phase noble-liquid detectors, particularly for dark-matter searches,\nneutrino physics and other fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.24611v1",
    "published": "2025-05-30T14:02:19+00:00",
    "categories": [
      "physics.ins-det",
      "astro-ph.IM",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.24610v1",
    "title": "Potential Effects of Loading Terminal Locations on Surface Trajectories of Oil Spill Transport",
    "authors": [
      "Shoshana Reich",
      "Edward Buskey",
      "Clint Dawson",
      "Eirik Valseth"
    ],
    "abstract": "We present an investigation comparing the potential impacts of offshore and\nonshore crude oil loading sites on surface trajectories of spilled oil\nparticles in the regions near the Port of Corpus Christi, Texas. Oil transport\nis established in a two step procedure. First, the circulation and flow\ncharacteristics of seawater throughout the coastal ocean are established for\nvarious flow conditions, including current and proposed channel depth,\nseasonality changes, and extreme weather events. Then, spilled oil is modeled\nas distinct particles released at either the proposed onshore or offshore\nloading locations. The particle trajectories are tracked and used to assess the\nspread into diverse coastal ecosystems with extensive plant, sea, and land\nlife. The models indicate that the extent of spread of these simulated oil\nspills to ecologically significant regions is greater when initiated at the\nonshore loading site than at the offshore site.",
    "pdf_url": "http://arxiv.org/pdf/2505.24610v1",
    "published": "2025-05-30T14:01:42+00:00",
    "categories": [
      "physics.comp-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24609v1",
    "title": "Explainable Depression Detection using Masked Hard Instance Mining",
    "authors": [
      "Patawee Prakrankamanant",
      "Shinji Watanabe",
      "Ekapol Chuangsuwanich"
    ],
    "abstract": "This paper addresses the critical need for improved explainability in\ntext-based depression detection. While offering predictive outcomes, current\nsolutions often overlook the understanding of model predictions which can\nhinder trust in the system. We propose the use of Masked Hard Instance Mining\n(MHIM) to enhance the explainability in the depression detection task. MHIM\nstrategically masks attention weights within the model, compelling it to\ndistribute attention across a wider range of salient features. We evaluate MHIM\non two datasets representing distinct languages: Thai (Thai-Maywe) and English\n(DAIC-WOZ). Our results demonstrate that MHIM significantly improves\nperformance in terms of both prediction accuracy and explainability metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24609v1",
    "published": "2025-05-30T14:01:20+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24608v1",
    "title": "GARLIC: GAussian Representation LearnIng for spaCe partitioning",
    "authors": [
      "Panagiotis Rigas",
      "Panagiotis Drivas",
      "Charalambos Tzamos",
      "Ioannis Chamodrakas",
      "George Ioannakis",
      "Leonidas J. Guibas",
      "Ioannis Z. Emiris"
    ],
    "abstract": "We introduce GARLIC (GAussian Representation LearnIng for spaCe\npartitioning), a novel indexing structure based on \\(N\\)-dimensional Gaussians\nfor efficiently learning high-dimensional vector spaces. Our approach is\ninspired from Gaussian splatting techniques, typically used in 3D rendering,\nwhich we adapt for high-dimensional search and classification. We optimize\nGaussian parameters using information-theoretic objectives that balance\ncoverage, assignment confidence, and structural and semantic consistency. A key\ncontribution is to progressively refine the representation through split and\nclone operations, handling hundreds of dimensions, thus handling varying data\ndensities. GARLIC offers the fast building times of traditional space\npartitioning methods (e.g., under \\(\\sim5\\) min build time for SIFT1M) while\nachieving \\(\\sim50\\%\\) Recall10@10 in low-candidate regimes. Experimental\nresults on standard benchmarks demonstrate our method's consistency in (a)\n\\(k\\)-NN retrieval, outperforming methods, such as Faiss-IVF, in fast-recall by\nusing about half their probes for the same Recall10@10 in Fashion-MNIST, and\n(b) in classification tasks, beating by \\(\\sim15\\%\\) accuracy other majority\nvoting methods. Further, we show strong generalization capabilities,\nmaintaining high accuracy even with downsampled training data: using just\n\\(1\\%\\) of the training data returns \\(\\sim 45\\%\\) Recall@1, thus making GARLIC\nquite powerful for applications requiring both speed and accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.24608v1",
    "published": "2025-05-30T13:55:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24607v1",
    "title": "Resonance density range governs two-plasmon decay saturation and enables hot-electron prediction in inertial confinement fusion",
    "authors": [
      "C. Yao",
      "J. Li",
      "L. Hao",
      "R. Yan",
      "T. Tao",
      "G-N. Zheng",
      "Q. Jia",
      "Y-K. Ding",
      "J. Zheng"
    ],
    "abstract": "The saturation level of parametric instabilities critically determines their\nimpact on fusion plasmas. We identify the resonance density range of\ntwo-plasmon decay as the critical parameter governing nonlinear saturation of\nion density fluctuations and Langmuir waves, which drive hot-electron\ngeneration. Using this insight, we develop a predictive scaling model for the\nhot-electron energy fraction f_{hot} that depends only on the laser intensity\nI, with plasma conditions encoded via plasma ablation theory. The model can\nwork for various experimental configurations-requiring only two (I, f_{hot})\ndata points to calibrate coefficients-and successfully reproduces results from\nprior OMEGA and OMEGA-EP experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24607v1",
    "published": "2025-05-30T13:55:12+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24606v1",
    "title": "Muochrony: Exploring Time and Frequency Applications of Cosmic Muons",
    "authors": [
      "G. Cerretto",
      "E. Cantoni",
      "M. Sellone",
      "C. E. Calosso",
      "I. Gnesi",
      "H. K. M. Tanaka"
    ],
    "abstract": "This study outlines the progress of a collaborative effort between INRIM and\nMUOGRAPHIX-The University of Tokyo, focusing on using muons from\ncosmic-ray-induced Extensive Air Showers (EAS) to synchronize atomic clocks and\ndisseminate atomic time references. The approach, known as the Cosmic Time\nSynchronizer (CTS), proposed by the University of Tokyo, serves as the\nfoundation for a new field of study called Muochrony. The paper details the CTS\ntechnology, underlying principles, and the prototype system installed at the\nINRIM RadioNavigation Laboratory. Additionally, it reports on the initial\nmetrological evaluation and the first experiments conducted to synchronize\ndiverse atomic clock types and disseminate the UTC(IT) timescale using cosmic\nmuons. CTS has the potential to synchronize and disseminate time references in\ncritical applications securely and could also complement GNSS in areas not\ncovered by RF signals.",
    "pdf_url": "http://arxiv.org/pdf/2505.24606v1",
    "published": "2025-05-30T13:54:58+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.24605v1",
    "title": "Model-Guided Network with Cluster-Based Operators for Spatio-Spectral Super-Resolution",
    "authors": [
      "Ivan Pereira-Sánchez",
      "Julia Navarro",
      "Ana Belén Petro",
      "Joan Duran"
    ],
    "abstract": "This paper addresses the problem of reconstructing a high-resolution\nhyperspectral image from a low-resolution multispectral observation. While\nspatial super-resolution and spectral super-resolution have been extensively\nstudied, joint spatio-spectral super-resolution remains relatively explored. We\npropose an end-to-end model-driven framework that explicitly decomposes the\njoint spatio-spectral super-resolution problem into spatial super-resolution,\nspectral super-resolution and fusion tasks. Each sub-task is addressed by\nunfolding a variational-based approach, where the operators involved in the\nproximal gradient iterative scheme are replaced with tailored learnable\nmodules. In particular, we design an upsampling operator for spatial\nsuper-resolution based on classical back-projection algorithms, adapted to\nhandle arbitrary scaling factors. Spectral reconstruction is performed using\nlearnable cluster-based upsampling and downsampling operators. For image\nfusion, we integrate low-frequency estimation and high-frequency injection\nmodules to combine the spatial and spectral information from spatial\nsuper-resolution and spectral super-resolution outputs. Additionally, we\nintroduce an efficient nonlocal post-processing step that leverages image\nself-similarity by combining a multi-head attention mechanism with residual\nconnections. Extensive evaluations on several datasets and sampling factors\ndemonstrate the effectiveness of our approach. The source code will be\navailable at https://github.com/TAMI-UIB/JSSUNet",
    "pdf_url": "http://arxiv.org/pdf/2505.24605v1",
    "published": "2025-05-30T13:54:47+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24604v1",
    "title": "Non-Gaussian enhancement of precision in quantum batteries",
    "authors": [
      "Beatriz Polo",
      "Federico Centrone"
    ],
    "abstract": "We investigate the fundamental limits of converting light into useful work,\nwith a focus on the role of quantum resources in energy harvesting processes.\nSpecifically, we analyze how quantum coherence, non-Gaussianity, and\nentanglement affect the fluctuations in the energy output of bosonic quantum\nbatteries. Our findings reveal potential pathways to enhance the efficiency and\nstability of energy extraction from quantum batteries, with implications for\nthe development of quantum thermal machines at the nanoscale. Moreover, this\nwork highlights a tangible thermodynamic quantum advantage, demonstrating how\nquantum effects can be harnessed to improve the performance of practical energy\nconversion tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24604v1",
    "published": "2025-05-30T13:54:10+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24603v2",
    "title": "The Gaussian Mixing Mechanism: Renyi Differential Privacy via Gaussian Sketches",
    "authors": [
      "Omri Lev",
      "Vishwak Srinivasan",
      "Moshe Shenfeld",
      "Katrina Ligett",
      "Ayush Sekhari",
      "Ashia C. Wilson"
    ],
    "abstract": "Gaussian sketching, which consists of pre-multiplying the data with a random\nGaussian matrix, is a widely used technique for multiple problems in data\nscience and machine learning, with applications spanning computationally\nefficient optimization, coded computing, and federated learning. This operation\nalso provides differential privacy guarantees due to its inherent randomness.\nIn this work, we revisit this operation through the lens of Renyi Differential\nPrivacy (RDP), providing a refined privacy analysis that yields significantly\ntighter bounds than prior results. We then demonstrate how this improved\nanalysis leads to performance improvement in different linear regression\nsettings, establishing theoretical utility guarantees. Empirically, our methods\nimprove performance across multiple datasets and, in several cases, reduce\nruntime.",
    "pdf_url": "http://arxiv.org/pdf/2505.24603v2",
    "published": "2025-05-30T13:52:48+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24602v1",
    "title": "Well-posedness for a two-phase Stefan problem with radiation",
    "authors": [
      "Elena Demattè",
      "Juan J. L. Velázquez"
    ],
    "abstract": "In this paper we consider a free boundary problem for the melting of ice\nwhere we assume that the heat is transported by conduction in both the liquid\nand the solid part of the material and also by radiation in the solid.\nSpecifically, we study a one-dimensional two-phase Stefan-like problem which\ncontains a non-local integral operator in the equation describing the\ntemperature distribution of the solid. We will prove the local well-posedness\nof this free boundary problem combining the Banach fixed-point theorem and\nclassical parabolic theory. Moreover, constructing suitable stationary sub- and\nsupersolutions we will develop a global well-posedness theory for a large class\nof initial data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24602v1",
    "published": "2025-05-30T13:51:10+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24601v1",
    "title": "Taxonomic Networks: A Representation for Neuro-Symbolic Pairing",
    "authors": [
      "Zekun Wang",
      "Ethan L. Haarer",
      "Nicki Barari",
      "Christopher J. MacLellan"
    ],
    "abstract": "We introduce the concept of a \\textbf{neuro-symbolic pair} -- neural and\nsymbolic approaches that are linked through a common knowledge representation.\nNext, we present \\textbf{taxonomic networks}, a type of discrimination network\nin which nodes represent hierarchically organized taxonomic concepts. Using\nthis representation, we construct a novel neuro-symbolic pair and evaluate its\nperformance. We show that our symbolic method learns taxonomic nets more\nefficiently with less data and compute, while the neural method finds\nhigher-accuracy taxonomic nets when provided with greater resources. As a\nneuro-symbolic pair, these approaches can be used interchangeably based on\nsituational needs, with seamless translation between them when necessary. This\nwork lays the foundation for future systems that more fundamentally integrate\nneural and symbolic computation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24601v1",
    "published": "2025-05-30T13:48:34+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24600v1",
    "title": "SARD: A Large-Scale Synthetic Arabic OCR Dataset for Book-Style Text Recognition",
    "authors": [
      "Omer Nacar",
      "Yasser Al-Habashi",
      "Serry Sibaee",
      "Adel Ammar",
      "Wadii Boulila"
    ],
    "abstract": "Arabic Optical Character Recognition (OCR) is essential for converting vast\namounts of Arabic print media into digital formats. However, training modern\nOCR models, especially powerful vision-language models, is hampered by the lack\nof large, diverse, and well-structured datasets that mimic real-world book\nlayouts. Existing Arabic OCR datasets often focus on isolated words or lines or\nare limited in scale, typographic variety, or structural complexity found in\nbooks. To address this significant gap, we introduce SARD (Large-Scale\nSynthetic Arabic OCR Dataset). SARD is a massive, synthetically generated\ndataset specifically designed to simulate book-style documents. It comprises\n843,622 document images containing 690 million words, rendered across ten\ndistinct Arabic fonts to ensure broad typographic coverage. Unlike datasets\nderived from scanned documents, SARD is free from real-world noise and\ndistortions, offering a clean and controlled environment for model training.\nIts synthetic nature provides unparalleled scalability and allows for precise\ncontrol over layout and content variation. We detail the dataset's composition\nand generation process and provide benchmark results for several OCR models,\nincluding traditional and deep learning approaches, highlighting the challenges\nand opportunities presented by this dataset. SARD serves as a valuable resource\nfor developing and evaluating robust OCR and vision-language models capable of\nprocessing diverse Arabic book-style texts.",
    "pdf_url": "http://arxiv.org/pdf/2505.24600v1",
    "published": "2025-05-30T13:47:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24599v1",
    "title": "Wild Betti sheaves",
    "authors": [
      "Peter Scholze"
    ],
    "abstract": "In this note, we consider the problem of constructing an enlargement of the\ncategory of Betti sheaves that supports an ``exponential local system'' on\n$\\mathbb R$, and a Fourier equivalence defined on all sheaves. We show that\nthere is a universal solution, recovering a construction of Tamarkin known also\nas ``enhanced sheaves''. The universality property implies that the category of\ncoefficients of this theory is, in a suitable sense, a nontrivial $\\mathbb\nR_{>0}$-torsor over $\\mathrm{Spec}(\\mathbb Z)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24599v1",
    "published": "2025-05-30T13:46:58+00:00",
    "categories": [
      "math.AG",
      "math.AT",
      "math.NT",
      "math.SG",
      "14F25, 55N30, 53D37"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24598v1",
    "title": "Anosov actions: minimality of foliations or suspension action",
    "authors": [
      "Rodrigo R. Lopes",
      "Carlos Maquera",
      "Régis Varão"
    ],
    "abstract": "We prove that an Anosov action of $\\mathbb{R}^k$ over a compact manifold $M$\ntransitive on regular sub-cones satisfies the dichotomy: each stable and\nunstable leaf is dense or the Anosov action is topologically conjugated to a\nsuspension of a $\\mathbb{Z}^k$-Anosov action. This represents an important\nprogress toward addressing Verjovsky's extended conjecture for Anosov actions,\nas developed by Barbot and Maquera.",
    "pdf_url": "http://arxiv.org/pdf/2505.24598v1",
    "published": "2025-05-30T13:46:20+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24597v1",
    "title": "Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction",
    "authors": [
      "Shuai Liu",
      "Ning Cao",
      "Yile Chen",
      "Yue Jiang",
      "Gao Cong"
    ],
    "abstract": "Next location prediction plays a critical role in understanding human\nmobility patterns. However, existing approaches face two core limitations: (1)\nthey fall short in capturing the complex, multi-functional semantics of\nreal-world locations; and (2) they lack the capacity to model heterogeneous\nbehavioral dynamics across diverse user groups. To tackle these challenges, we\nintroduce NextLocMoE, a novel framework built upon large language models (LLMs)\nand structured around a dual-level Mixture-of-Experts (MoE) design. Our\narchitecture comprises two specialized modules: a Location Semantics MoE that\noperates at the embedding level to encode rich functional semantics of\nlocations, and a Personalized MoE embedded within the Transformer backbone to\ndynamically adapt to individual user mobility patterns. In addition, we\nincorporate a history-aware routing mechanism that leverages long-term\ntrajectory data to enhance expert selection and ensure prediction stability.\nEmpirical evaluations across several real-world urban datasets show that\nNextLocMoE achieves superior performance in terms of predictive accuracy,\ncross-domain generalization, and interpretability",
    "pdf_url": "http://arxiv.org/pdf/2505.24597v1",
    "published": "2025-05-30T13:45:19+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24596v1",
    "title": "Thermodynamic Signatures of Gaussian Entanglement Beyond Entropy",
    "authors": [
      "Beatriz Polo",
      "Federico Centrone",
      "Mir Alimuddin",
      "Gerardo Adesso"
    ],
    "abstract": "Continuous-variable quantum thermodynamics in the Gaussian regime provides a\npromising framework for investigating the energetic role of quantum\ncorrelations, particularly in optical systems. In this work, we introduce an\nentropy-free criterion for entanglement detection in bipartite Gaussian states,\nrooted in a distinct thermodynamic quantity: ergotropy -- the maximum\nextractable work via unitary operations. By defining the relative ergotropic\ngap, which quantifies the disparity between global and local ergotropy, we\nderive two independent analytical bounds that distinguish entangled from\nseparable states. We show that for a broad class of quantum states, the bounds\ncoincide, making the criterion both necessary and sufficient. We further extend\nour analysis to certain non-Gaussian states and observe analogous energy-based\nsignatures of quantum correlations. These findings establish a direct\noperational link between entanglement and energy storage, offering an\nexperimentally accessible approach to entanglement detection in\ncontinuous-variable optical platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.24596v1",
    "published": "2025-05-30T13:43:36+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24595v3",
    "title": "BinConv: A Neural Architecture for Ordinal Encoding in Time-Series Forecasting",
    "authors": [
      "Andrei Chernov",
      "Vitaliy Pozdnyakov",
      "Ilya Makarov"
    ],
    "abstract": "Recent work in time series forecasting has explored reformulating regression\nas a classification task. By discretizing the continuous target space into bins\nand predicting over a fixed set of classes, these approaches benefit from more\nstable training, improved uncertainty modeling, and compatibility with modern\ndeep learning architectures. However, most existing methods rely on one-hot\nencoding, which ignores the inherent ordinal structure of the target values. As\na result, they fail to convey information about the relative distance between\npredicted and true values during training. In this paper, we address this\nlimitation by applying \\textbf{Cumulative Binary Encoding} (CBE), a monotonic\nbinary representation that transforms both model inputs and outputs. CBE\nimplicitly preserves ordinal and magnitude information, allowing models to\nlearn distance aware representations while operating within a classification\nframework. To leverage CBE effectively, we propose \\textbf{BinConv}, a fully\nconvolutional neural network architecture designed for probabilistic\nforecasting. We demonstrate that standard fully connected layers are not only\nless computationally efficient than convolutional layers when used with CBE,\nbut also degrade forecasting performance. Our experiments on standard benchmark\ndatasets show that BinConv achieves superior performance compared to widely\nused baselines in both point and probabilistic forecasting, while requiring\nfewer parameters and enabling faster training.",
    "pdf_url": "http://arxiv.org/pdf/2505.24595v3",
    "published": "2025-05-30T13:41:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24594v1",
    "title": "Two-stage MCMC for Fast Bayesian Inference of Large Spatio-temporal Ordinal Data, with Application to US Drought",
    "authors": [
      "Staci Hepler",
      "Rob Erhardt"
    ],
    "abstract": "High dimensional space-time data pose known computational challenges when\nfitting spatio-temporal models. Such data show dependence across several\ndimensions of space as well as in time, and can easily involve hundreds of\nthousands of observations. Many spatio-temporal models result in a dependence\nstructure across all observations and can be fit only at a substantial\ncomputational cost, arising from dense matrix inversion, high dimensional\nparameter spaces, poor mixing in Markov Chain Monte Carlo, or the impossibility\nof utilizing parallel computing due to a lack of independence anywhere in the\nmodel fitting process. These computational challenges are exacerbated when the\nresponse variable is ordinal, and especially as the number of ordered\ncategories grows. Some spatio-temporal models achieve computational feasibility\nfor large datasets but only through overly restrictive model simplifications,\nwhich we seek to avoid here. In this paper we demonstrate a two-stage algorithm\nto fit a Bayesian spatio-temporal model to large datasets when the response\nvariable is ordinal. The first stage models locations independently in space,\ncapturing temporal dependence, and can be run in parallel. The second stage\nresamples from the first stage posterior distributions with an acceptance\nprobability computed to impose spatial dependence from the full spatio-temporal\nmodel. The result is fast Bayesian inference which samples from the full\nspatio-temporal posterior and is computationally feasible even for large\ndatasets. We quantify the substantial computational gains our approach\nachieves, and demonstrate the preservation of the posterior distribution as\ncompared to the more costly single-stage model fit. We apply our approach to a\nlarge spatio-temporal drought dataset in the United States, a dataset too large\nfor many existing spatio-temporal methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24594v1",
    "published": "2025-05-30T13:41:34+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24593v2",
    "title": "Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis",
    "authors": [
      "Junzhuo Li",
      "Bo Wang",
      "Xiuze Zhou",
      "Peijie Jiang",
      "Jia Liu",
      "Xuming Hu"
    ],
    "abstract": "The interpretability of Mixture-of-Experts (MoE) models, especially those\nwith heterogeneous designs, remains underexplored. Existing attribution methods\nfor dense models fail to capture dynamic routing-expert interactions in sparse\nMoE architectures. To address this issue, we propose a cross-level attribution\nalgorithm to analyze sparse MoE architectures (Qwen 1.5-MoE, OLMoE,\nMixtral-8x7B) against dense models (Qwen 1.5-7B, Llama-7B, Mistral-7B). Results\nshow MoE models achieve 37% higher per-layer efficiency via a \"mid-activation,\nlate-amplification\" pattern: early layers screen experts, while late layers\nrefine knowledge collaboratively. Ablation studies reveal a \"basic-refinement\"\nframework--shared experts handle general tasks (entity recognition), while\nrouted experts specialize in domain-specific processing (geographic\nattributes). Semantic-driven routing is evidenced by strong correlations\nbetween attention heads and experts (r=0.68), enabling task-aware coordination.\nNotably, architectural depth dictates robustness: deep Qwen 1.5-MoE mitigates\nexpert failures (e.g., 43% MRR drop in geographic tasks when blocking top-10\nexperts) through shared expert redundancy, whereas shallow OLMoE suffers severe\ndegradation (76% drop). Task sensitivity further guides design: core-sensitive\ntasks (geography) require concentrated expertise, while distributed-tolerant\ntasks (object attributes) leverage broader participation. These insights\nadvance MoE interpretability, offering principles to balance efficiency,\nspecialization, and robustness.",
    "pdf_url": "http://arxiv.org/pdf/2505.24593v2",
    "published": "2025-05-30T13:40:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24592v1",
    "title": "A Flat Minima Perspective on Understanding Augmentations and Model Robustness",
    "authors": [
      "Weebum Yoo",
      "Sung Whan Yoon"
    ],
    "abstract": "Model robustness indicates a model's capability to generalize well on\nunforeseen distributional shifts, including data corruption, adversarial\nattacks, and domain shifts. Data augmentation is one of the prevalent and\neffective ways to enhance robustness. Despite the great success of\naugmentations in different fields, a general theoretical understanding of their\nefficacy in improving model robustness is lacking. We offer a unified\ntheoretical framework to clarify how augmentations can enhance model robustness\nthrough the lens of loss surface flatness and PAC generalization bound. Our\nwork diverges from prior studies in that our analysis i) broadly encompasses\nmuch of the existing augmentation methods, and ii) is not limited to specific\ntypes of distribution shifts like adversarial attacks. We confirm our theories\nthrough simulations on the existing common corruption and adversarial\nrobustness benchmarks based on the CIFAR and ImageNet datasets, as well as\ndomain generalization benchmarks including PACS and OfficeHome.",
    "pdf_url": "http://arxiv.org/pdf/2505.24592v1",
    "published": "2025-05-30T13:40:44+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24591v1",
    "title": "Diversity of Cold Worlds: A Near Complete Spectral Energy Distribution for 2MASS J04151954-0935066 using JWST",
    "authors": [
      "Sherelyn Alejandro Merchan",
      "Jacqueline K. Faherty",
      "Genaro Suárez",
      "Kelle L. Cruz",
      "Adam J. Burgasser",
      "Jonathan Gagné",
      "Callie E. Hood",
      "Eileen C. Gonzales",
      "Daniella C. Bardalez Gagliuffi",
      "Jolie L'Heureux",
      "Johanna M. Vos",
      "Adam C. Schneider",
      "Aaron M. Meisner",
      "Caroline Morley",
      "J. Davy Kirkpatrick",
      "Federico Marocco",
      "Rocio Kiman",
      "Charles A. Beichman",
      "Ben Burningham",
      "Dan Caselden",
      "Peter R. Eisenhardt",
      "Christopher R. Gelino",
      "Ehsan Gharib-Nezhad",
      "Marc J. Kuchner",
      "Brianna Lacy",
      "Austin Rothermich",
      "Melanie J. Rowland",
      "Niall Whiteford"
    ],
    "abstract": "We present the a near complete spectral energy distribution (SED) for an\nextrasolar world: the T8 brown dwarf 2MASS~J04151954$-$0935066. Spanning from\noptical to mid-infrared (0.7--20.4 micron) wavelengths, the SED for this\nsubstellar atmosphere is constructed from new JWST NIRSpec G395H ($R\\sim$2700)\nand Magellan FIRE echelle ($R\\sim$8000) near-infrared spectra, along with MIRI\nmid-infrared photometry complemented by spectra from Keck I, IRTF, Magellan,\nAKARI, Spitzer and photometry from various surveys and missions. The NIRSpec\nG395H spectrum reveals strong molecular absorptions from NH$_{3}$, CH$_{4}$,\nH$_{2}$S, CO$_{2}$ and H$_{2}$O at approximately 3.00, 3.35, 3.95, 4.25, and\n5.00 micron respectively, along with the presence of a CO absorption feature\ndetected mainly at $\\sim$ 4.6 micron. We detect no absorption of near-infrared\nK I doublets in the $R\\sim8000$ FIRE spectra. In the mid-infrared IRS spectrum,\nwe tentatively identify a new CO$_{2}$ feature at 14--16 micron. The\ncomprehensive SED allows us to empirically constrain bolometric luminosity,\neffective temperature, mass and radius. Additionally, we demonstrate that the\nNIRSpec G395H resolution, the highest allowable by JWST, enables a precise\nradial velocity measurement of $47.1\\pm1.8$ km s$^{-1}$ for the object, in\nagreement with previous measurements.",
    "pdf_url": "http://arxiv.org/pdf/2505.24591v1",
    "published": "2025-05-30T13:40:13+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00101v1",
    "title": "EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning",
    "authors": [
      "Chi-Hsi Kung",
      "Frangil Ramirez",
      "Juhyung Ha",
      "Yi-Ting Chen",
      "David Crandall",
      "Yi-Hsuan Tsai"
    ],
    "abstract": "Understanding a procedural activity requires modeling both how action steps\ntransform the scene, and how evolving scene transformations can influence the\nsequence of action steps, even those that are accidental or erroneous. Yet,\nexisting work on procedure-aware video representations fails to explicitly\nlearned the state changes (scene transformations). In this work, we study\nprocedure-aware video representation learning by incorporating state-change\ndescriptions generated by LLMs as supervision signals for video encoders.\nMoreover, we generate state-change counterfactuals that simulate hypothesized\nfailure outcomes, allowing models to learn by imagining the unseen ``What if''\nscenarios. This counterfactual reasoning facilitates the model's ability to\nunderstand the cause and effect of each step in an activity. To verify the\nprocedure awareness of our model, we conduct extensive experiments on\nprocedure-aware tasks, including temporal action segmentation, error detection,\nand more. Our results demonstrate the effectiveness of the proposed\nstate-change descriptions and their counterfactuals, and achieve significant\nimprovements on multiple tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00101v1",
    "published": "2025-05-30T13:39:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24590v1",
    "title": "$δn$ formalism: A new formulation for the probability density of the curvature perturbation",
    "authors": [
      "Diego Cruces",
      "Shi Pi",
      "Misao Sasaki"
    ],
    "abstract": "$\\delta N$ formalism is a useful method to calculate the curvature\nperturbation. Contrary to what it is typically done in the literature, we\nre-formulate the $\\delta N$ formalism by using the $e$-folding number $n$\ncounted forward in time. For a fixed initial time $\\bar{n}_0$, the probability\ndensity function (PDF) of the initial conditions $\\delta\\phi_0$ and\n$\\delta\\pi_0$ are specified by the solutions of the perturbation equation on\nsubhorizon scales. As $\\delta\\pi_0$ is fully correlated with $\\delta\\phi_0$\nafter horizon exit, we find a simple formula to calculate the curvature\nperturbation as well as its PDF by using the $\\delta N$ method reformulated in\nterms of $n$, the $\\delta n$ formalism.",
    "pdf_url": "http://arxiv.org/pdf/2505.24590v1",
    "published": "2025-05-30T13:39:09+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24589v1",
    "title": "Frequency-Domain Joint Monitoring of Differential Group Delay and Dependent Loss of Optical Singleand Few-Mode Fiber Channels Based on CAZAC Sequences",
    "authors": [
      "Linsheng Fan",
      "Gao Ye",
      "Zhongliang Sun",
      "Lingguo Cao",
      "Hao Shi",
      "Jianwei Tang",
      "Shunfeng Wang",
      "Hengying Xu",
      "Chenglin Bai",
      "Jian Zhao",
      "Weisheng Hu",
      "Jinlong Wei"
    ],
    "abstract": "This paper addresses the challenges of monitoring optical-fiber channels\nsubject to complex, multidimensional impairments-such as dynamic interference\nacross polarization or modal dimensions-where conventional methods suffer from\nhigh equipment costs, poor impairment discrimination and limited scalability.\nWe propose an in-service, frequency-domain joint monitoring scheme based on\nconstant-amplitude zero-autocorrelation (CAZAC) sequences. Exploiting their\nflat spectra and ideal autocorrelation, we model the channel as a multi-input\nmulti-output (MIMO) system and estimate its frequency response to extract both\ndifferential group delay (DGD) and dimension-dependent loss (DL) regardless of\ndimensionality. Experimental validation in polarization-division-multiplexing\n(PDM) and mode-division-multiplexing (MDM) scenarios demonstrates robust\nperformance: in a 2x2 PDM setup, polarization-dependent loss (PDL) error stays\nbelow 0.3 dB and polarization-mode dispersion (PMD) accuracy is 0.3 ps; in a\n4x4 MDM system, mode-dependent loss (MDL) and differential mode-group delay\n(DMGD) errors remain around 0.3 dB and 0.3 ps, respectively. Fully compatible\nwith existing coherent DSP without additional hardware, the scheme enables\ncontinuous, cost-effective, real-time monitoring of multidimensional optical\nchannels.",
    "pdf_url": "http://arxiv.org/pdf/2505.24589v1",
    "published": "2025-05-30T13:36:46+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24588v1",
    "title": "On compact sets possessing $q$-convex functions",
    "authors": [
      "Thomas Pawlaschyk",
      "Nikolay Shcherbina"
    ],
    "abstract": "We show that there exists a $q$-convex function in a neighborhood of a\ncompact set $K$ in a complex manifold $\\mathcal{M}$ if and only if the\n$q$-nucleus of this compact set is empty. The latter can be characterized as\nthe maximal $q$-pseudoconcave subset of $K$, i.e., a subset of $K$ containing\nall other compact $q$-pseudoconcave subsets in $K$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24588v1",
    "published": "2025-05-30T13:36:17+00:00",
    "categories": [
      "math.CV",
      "32U05, 32F10, 32Q99"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24587v1",
    "title": "Sample-optimal learning of quantum states using gentle measurements",
    "authors": [
      "Cristina Butucea",
      "Jan Johannes",
      "Henning Stein"
    ],
    "abstract": "Gentle measurements of quantum states do not entirely collapse the initial\nstate. Instead, they provide a post-measurement state at a prescribed trace\ndistance $\\alpha$ from the initial state together with a random variable used\nfor quantum learning of the initial state. We introduce here the class of\n$\\alpha-$locally-gentle measurements ($\\alpha-$LGM) on a finite dimensional\nquantum system which are product measurements on product states and prove a\nstrong quantum Data-Processing Inequality (qDPI) on this class using an\nimproved relation between gentleness and quantum differential privacy. We\nfurther show a gentle quantum Neyman-Pearson lemma which implies that our qDPI\nis asymptotically optimal (for small $\\alpha$). This inequality is employed to\nshow that the necessary number of quantum states for prescribed accuracy\n$\\epsilon$ is of order $1/(\\epsilon^2 \\alpha^2)$ for both quantum tomography\nand quantum state certification. Finally, we propose an $\\alpha-$LGM called\nquantum Label Switch that attains these bounds. It is a general implementable\nmethod to turn any two-outcome measurement into an $\\alpha-$LGM.",
    "pdf_url": "http://arxiv.org/pdf/2505.24587v1",
    "published": "2025-05-30T13:34:11+00:00",
    "categories": [
      "quant-ph",
      "math.ST",
      "stat.ML",
      "stat.TH",
      "81P15 (Primary), 68P27 (Secondary)"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24586v2",
    "title": "All-sky search for individual Primordial Black Hole bursts with LHAASO",
    "authors": [
      "Zhen Cao",
      "F. Aharonian",
      "Y. X. Bai",
      "Y. W. Bao",
      "D. Bastieri",
      "X. J. Bi",
      "Y. J. Bi",
      "W. Bian",
      "A. V. Bukevich",
      "C. M. Cai",
      "W. Y. Cao",
      "Zhe Cao",
      "J. Chang",
      "J. F. Chang",
      "A. M. Chen",
      "E. S. Chen",
      "G. H. Chen",
      "H. X. Chen",
      "Liang Chen",
      "Long Chen",
      "M. J. Chen",
      "M. L. Chen",
      "Q. H. Chen",
      "S. Chen",
      "S. H. Chen",
      "S. Z. Chen",
      "T. L. Chen",
      "X. B. Chen",
      "X. J. Chen",
      "Y. Chen",
      "N. Cheng",
      "Y. D. Cheng",
      "M. C. Chu",
      "M. Y. Cui",
      "S. W. Cui",
      "X. H. Cui",
      "Y. D. Cui",
      "B. Z. Dai",
      "H. L. Dai",
      "Z. G. Dai",
      "Danzengluobu",
      "Y. X. Diao",
      "X. Q. Dong",
      "K. K. Duan",
      "J. H. Fan",
      "Y. Z. Fan",
      "J. Fang",
      "J. H. Fang",
      "K. Fang",
      "C. F. Feng",
      "H. Feng",
      "L. Feng",
      "S. H. Feng",
      "X. T. Feng",
      "Y. Feng",
      "Y. L. Feng",
      "S. Gabici",
      "B. Gao",
      "C. D. Gao",
      "Q. Gao",
      "W. Gao",
      "W. K. Gao",
      "M. M. Ge",
      "T. T. Ge",
      "L. S. Geng",
      "G. Giacinti",
      "G. H. Gong",
      "Q. B. Gou",
      "M. H. Gu",
      "F. L. Guo",
      "J. Guo",
      "X. L. Guo",
      "Y. Q. Guo",
      "Y. Y. Guo",
      "Y. A. Han",
      "O. A. Hannuksela",
      "M. Hasan",
      "H. H. He",
      "H. N. He",
      "J. Y. He",
      "X. Y. He",
      "Y. He",
      "S. Hernández-Cadena",
      "B. W. Hou",
      "C. Hou",
      "X. Hou",
      "H. B. Hu",
      "S. C. Hu",
      "C. Huang",
      "D. H. Huang",
      "J. J. Huang",
      "T. Q. Huang",
      "W. J. Huang",
      "X. T. Huang",
      "X. Y. Huang",
      "Y. Huang",
      "Y. Y. Huang",
      "X. L. Ji",
      "H. Y. Jia",
      "K. Jia",
      "H. B. Jiang",
      "K. Jiang",
      "X. W. Jiang",
      "Z. J. Jiang",
      "M. Jin",
      "S. Kaci",
      "M. M. Kang",
      "I. Karpikov",
      "D. Khangulyan",
      "D. Kuleshov",
      "K. Kurinov",
      "B. B. Li",
      "Cheng Li",
      "Cong Li",
      "D. Li",
      "F. Li",
      "H. B. Li",
      "H. C. Li",
      "Jian Li",
      "Jie Li",
      "K. Li",
      "L. Li",
      "R. L. Li",
      "S. D. Li",
      "T. Y. Li",
      "W. L. Li",
      "X. R. Li",
      "Xin Li",
      "Y. Li",
      "Y. Z. Li",
      "Zhe Li",
      "Zhuo Li",
      "E. W. Liang",
      "Y. F. Liang",
      "S. J. Lin",
      "B. Liu",
      "C. Liu",
      "D. Liu",
      "D. B. Liu",
      "H. Liu",
      "H. D. Liu",
      "J. Liu",
      "J. L. Liu",
      "J. R. Liu",
      "M. Y. Liu",
      "R. Y. Liu",
      "S. M. Liu",
      "W. Liu",
      "X. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. N. Liu",
      "Y. Q. Lou",
      "Q. Luo",
      "Y. Luo",
      "H. K. Lv",
      "B. Q. Ma",
      "L. L. Ma",
      "X. H. Ma",
      "J. R. Mao",
      "Z. Min",
      "W. Mitthumsiri",
      "G. B. Mou",
      "H. J. Mu",
      "A. Neronov",
      "K. C. Y. Ng",
      "M. Y. Ni",
      "L. Nie",
      "L. J. Ou",
      "P. Pattarakijwanich",
      "Z. Y. Pei",
      "J. C. Qi",
      "M. Y. Qi",
      "J. J. Qin",
      "A. Raza",
      "C. Y. Ren",
      "D. Ruffolo",
      "A. Sáiz",
      "D. Semikoz",
      "L. Shao",
      "O. Shchegolev",
      "Y. Z. Shen",
      "X. D. Sheng",
      "Z. D. Shi",
      "F. W. Shu",
      "H. C. Song",
      "Yu. V. Stenkin",
      "V. Stepanov",
      "Y. Su",
      "D. X. Sun",
      "H. Sun",
      "Q. N. Sun",
      "X. N. Sun",
      "Z. B. Sun",
      "N. H. Tabasam",
      "J. Takata",
      "P. H. T. Tam",
      "H. B. Tan",
      "Q. W. Tang",
      "R. Tang",
      "Z. B. Tang",
      "W. W. Tian",
      "C. N. Tong",
      "L. H. Wan",
      "C. Wang",
      "G. W. Wang",
      "H. G. Wang",
      "J. C. Wang",
      "K. Wang",
      "Kai Wang",
      "Kai Wang",
      "L. P. Wang",
      "L. Y. Wang",
      "L. Y. Wang",
      "R. Wang",
      "W. Wang",
      "X. G. Wang",
      "X. J. Wang",
      "X. Y. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Z. H. Wang",
      "Z. X. Wang",
      "Zheng Wang",
      "D. M. Wei",
      "J. J. Wei",
      "Y. J. Wei",
      "T. Wen",
      "S. S. Weng",
      "C. Y. Wu",
      "H. R. Wu",
      "Q. W. Wu",
      "S. Wu",
      "X. F. Wu",
      "Y. S. Wu",
      "S. Q. Xi",
      "J. Xia",
      "J. J. Xia",
      "G. M. Xiang",
      "D. X. Xiao",
      "G. Xiao",
      "Y. L. Xin",
      "Y. Xing",
      "D. R. Xiong",
      "Z. Xiong",
      "D. L. Xu",
      "R. F. Xu",
      "R. X. Xu",
      "W. L. Xu",
      "L. Xue",
      "D. H. Yan",
      "T. Yan",
      "C. W. Yang",
      "C. Y. Yang",
      "F. F. Yang",
      "L. L. Yang",
      "M. J. Yang",
      "R. Z. Yang",
      "W. X. Yang",
      "Z. H. Yang",
      "Z. G. Yao",
      "X. A. Ye",
      "L. Q. Yin",
      "N. Yin",
      "X. H. You",
      "Z. Y. You",
      "Q. Yuan",
      "H. Yue",
      "H. D. Zeng",
      "T. X. Zeng",
      "W. Zeng",
      "X. T. Zeng",
      "M. Zha",
      "B. B. Zhang",
      "B. T. Zhang",
      "C. Zhang",
      "F. Zhang",
      "H. Zhang",
      "H. M. Zhang",
      "H. Y. Zhang",
      "J. L. Zhang",
      "Li Zhang",
      "P. F. Zhang",
      "P. P. Zhang",
      "R. Zhang",
      "S. R. Zhang",
      "S. S. Zhang",
      "W. Y. Zhang",
      "X. Zhang",
      "X. P. Zhang",
      "Yi Zhang",
      "Yong Zhang",
      "Z. P. Zhang",
      "J. Zhao",
      "L. Zhao",
      "L. Z. Zhao",
      "S. P. Zhao",
      "X. H. Zhao",
      "Z. H. Zhao",
      "F. Zheng",
      "W. J. Zhong",
      "B. Zhou",
      "H. Zhou",
      "J. N. Zhou",
      "M. Zhou",
      "P. Zhou",
      "R. Zhou",
      "X. X. Zhou",
      "X. X. Zhou",
      "B. Y. Zhu",
      "C. G. Zhu",
      "F. R. Zhu",
      "H. Zhu",
      "K. J. Zhu",
      "Y. C. Zou",
      "X. Zuo",
      "S. Wang",
      "Xin. Zhang"
    ],
    "abstract": "Primordial Black Holes~(PBHs) are hypothetical black holes with a wide range\nof masses that formed in the early universe. As a result, they may play an\nimportant cosmological role and provide a unique probe of the early universe. A\nPBH with an initial mass of approximately $10^{15}$~g is expected to explode\ntoday in a final burst of Hawking radiation. In this work, we conduct an\nall-sky search for individual PBH burst events using the data collected from\nMarch 2021 to July 2024 by the Water Cherenkov Detector Array of the Large High\nAltitude Air Shower Observatory (LHAASO). Three PBH burst durations, 10~s,\n20~s, and 100~s, are searched, with no significant PBH bursts observed. The\nupper limit on the local PBH burst rate density is set to be as low as\n181~pc$^{-3}$~yr$^{-1}$ at 99$\\%$ confidence level, representing the most\nstringent limit achieved to date.",
    "pdf_url": "http://arxiv.org/pdf/2505.24586v2",
    "published": "2025-05-30T13:33:16+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24585v1",
    "title": "CHESS Compact Wiggler construction report",
    "authors": [
      "Alexander Temnykh",
      "Ivan Temnykh"
    ],
    "abstract": "We developed, built, characterized on bench and beam-tested a permanent\nmagnet (PM) Compact Wiggler (CW) prototype with a hydraulic assist\ngap-controlling mechanism. The prototype is of ~50cm long, 20cm wide and 40cm\nhigh and weights ~50kg. Magnetic structure has a 76.2mm period. At 6.5mm\nminimal gap the structure demonstrated ~2.3 Tesla peak field. At this gap, the\nmagnet arrays attract each other with 7,990 N (1,796 lbf) force. Hydraulic\nsystem is employed to balance the attractive forces. Here we describe the\nmechanical and magnetic design, present some construction details and provide\ntest results.",
    "pdf_url": "http://arxiv.org/pdf/2505.24585v1",
    "published": "2025-05-30T13:33:03+00:00",
    "categories": [
      "physics.ins-det",
      "physics.acc-ph"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.24584v3",
    "title": "AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up",
    "authors": [
      "Sakhinana Sagar Srinivas",
      "Shivam Gupta",
      "Venkataramana Runkana"
    ],
    "abstract": "Recent advances in generative AI have accelerated the discovery of novel\nchemicals and materials. However, scaling these discoveries to industrial\nproduction remains a major bottleneck due to the synthesis gap -- the need to\ndevelop entirely new manufacturing processes. This challenge requires detailed\nengineering blueprints: PFDs for equipment layouts and material/energy flows,\nand PIDs for process plant operations. Current AI systems cannot yet reliably\ngenerate these critical engineering schematics, creating a fundamental obstacle\nto manufacturing scale-up of novel discoveries. We present a closed-loop,\nphysics-aware framework for automated generation of industrially viable PFDs\nand PIDs. The framework integrates three key components: (1) domain-specialized\nsmall language models (SLMs) trained for auto-generation of PFDs and PIDs, (2)\na hierarchical knowledge graph containing process flow and instrumentation\ndescriptions for 1,020+ chemicals for Graph Retrieval-Augmented Generation\n(GRAG), and (3) an open-source chemical process simulator for modeling,\nsimulation, optimization, and analysis of novel chemical processes. The SLMs\nare trained through a multi-stage pipeline on synthetic datasets, with process\nsimulator-in-the-loop validation ensuring feasibility. To enhance computational\nefficiency, the framework implements structural pruning (width and depth)\nguided by importance heuristics to reduce language model size while preserving\naccuracy, followed by advanced inference optimizations including\nFlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization,\nand Test-Time Inference Scaling. Experimental results demonstrate that our\nframework generates simulator-validated process descriptions with high\nfidelity.",
    "pdf_url": "http://arxiv.org/pdf/2505.24584v3",
    "published": "2025-05-30T13:32:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24583v1",
    "title": "Cognitive-Radio Functionality: A Novel Configuration for STAR-RIS assisted RSMA Networks",
    "authors": [
      "Saeed Ibrahim",
      "Yue Xiao",
      "Dimitrios Tyrovolas",
      "Sotiris A. Tegos",
      "Panagiotis D. Diamantoulakis",
      "Zheng Ma",
      "George K. Karagiannidis",
      "Pinghzi Fan"
    ],
    "abstract": "Cognitive radio rate-splitting multiple access (CR-RSMA) has emerged as a\npromising multiple access framework that can efficiently manage interference\nand adapt dynamically to heterogeneous quality-of-service (QoS) requirements.\nTo effectively support such demanding access schemes, programmable wireless\nenvironments have attracted considerable attention, especially through\nsimultaneously transmitting and reflecting reconfigurable intelligent surfaces\n(STAR-RISs), which can enable full-space control of signal propagation in\nasymmetric user deployments. In this paper, we propose the cognitive radio (CR)\nfunctionality for STAR-RIS-assisted CR-RSMA systems, leveraging the unique\ncapability of the STAR-RIS to combine element and power splitting for adaptive\ncontrol of transmission and reflection in CR scenarios. Specifically, the\nproposed CR functionality partitions the STAR-RIS into two regions\nindependently controlling the transmission and reflection of signals,\nsimultaneously ensuring the required QoS for the primary user and enhancing the\nperformance of the secondary user. To accurately characterize the system\nperformance, we derive analytical expressions for the ergodic rate of the\nsecondary user and the outage rate of the primary user under Nakagami-m fading.\nFinally, simulation results show that the proposed approach effectively manages\ninterference, guarantees the QoS of the primary user, and significantly\nimproves the throughput of the secondary user, highlighting STAR-RIS as an\nefficient solution for CR-RSMA-based services.",
    "pdf_url": "http://arxiv.org/pdf/2505.24583v1",
    "published": "2025-05-30T13:30:37+00:00",
    "categories": [
      "cs.ET",
      "eess.SP"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2506.12056v1",
    "title": "Input-to-state stability-based chemical reaction networks composition for molecular computations",
    "authors": [
      "Renlei Jiang",
      "Yuzhen Fan",
      "Di Fan",
      "Chuanhou Gao",
      "Denis Dochain"
    ],
    "abstract": "Molecular computation based on chemical reaction networks (CRNs) has emerged\nas a promising paradigm for designing programmable biochemical systems.\nHowever, the implementation of complex computations still requires excessively\nlarge and intricate network structures, largely due to the limited\nunderstanding of composability, that is, how multiple subsystems can be coupled\nwhile preserving computational functionality. Existing composability frameworks\nprimarily focus on rate-independent CRNs, whose computational capabilities are\nseverely restricted. This article aims to establish a systematic framework for\ncomposable CRNs governed by mass-action kinetics, a common type of\nrate-dependent CRNs. Drawing upon the concepts of composable rate-independent\nCRNs, we introduce the notions of mass-action chemical reaction computers\n(msCRCs), dynamic computation and dynamic composability to establish a rigorous\nmathematical framework for composing two or more msCRCs to achieve\nlayer-by-layer computation of composite functions. Further, we derive several\nsufficient conditions based on the notions of input-to-state stability (ISS) to\ncharacterize msCRCs that can be composed to implement desired molecular\ncomputations, thereby providing theoretical support for this framework. Some\nexamples are presented to illustrate the efficiency of our method. Finally,\ncomparative results demonstrate that the proposed method exhibits notable\nadvantages in both computational ability and accuracy over the state-of-the-art\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2506.12056v1",
    "published": "2025-05-30T13:30:28+00:00",
    "categories": [
      "q-bio.MN"
    ],
    "primary_category": "q-bio.MN"
  },
  {
    "id": "http://arxiv.org/abs/2505.24582v1",
    "title": "The Dynamics of Infall and Accretion Shocks in the Outer Disk",
    "authors": [
      "Susan Terebey",
      "Loraine Sandoval Ascencio",
      "Lizxandra Flores-Rivera",
      "Neal Turner",
      "Andrew Barajas"
    ],
    "abstract": "High-spatial-resolution observations of disks around young stars suggest\nplanetary systems begin forming early, during the protostellar phase (< 1 Myr)\nwhen stars accrete most of their mass via infall from the surrounding cloud.\nDuring this era shocks are expected to be ubiquitous around the gaseous\naccretion disk due to supersonic infall that strikes the disk. We investigate\nthe role of shocks using a theoretical and modeling framework we call the shock\ntwist-angle Keplerian (STAK) disk, connecting the disk and infalling envelope\ngas via a shock using general physical principles. Briefly, at the shock,\nenergy is dissipated while angular momentum is conserved, so that the infalling\ngas must change direction sharply, yielding a bend or twist in the streamlines.\nThe model's pre-shock gas follows free-fall parabolic trajectories, while the\npost-shock gas is on lower-energy, elliptical orbits.\n  We construct synthetic observations and find that the deviations from\ncircular Keplerian orbits are detectable in Doppler-shifted molecular spectral\nlines using radio interferometers such as ALMA. Specifically, the STAK model\nleads to line emission intensity and velocity-moment maps that are asymmetric\nand offset with respect to the disk structure traced by the dust continuum. We\nexamine archival ALMA data for the class 0/I protostar L1527 and find the\nC$^{18}$O velocity moment map has features resembling the disk plus envelope\nemission that naturally arise when the two are connected by a shock. Thus,\nspectral line observations having sub-km/s spectral resolution and angular\nresolution sufficient to fully resolve the disk can reveal protostars'\nenvelope-disk shocks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24582v1",
    "published": "2025-05-30T13:29:48+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24581v1",
    "title": "GATE: General Arabic Text Embedding for Enhanced Semantic Textual Similarity with Matryoshka Representation Learning and Hybrid Loss Training",
    "authors": [
      "Omer Nacar",
      "Anis Koubaa",
      "Serry Sibaee",
      "Yasser Al-Habashi",
      "Adel Ammar",
      "Wadii Boulila"
    ],
    "abstract": "Semantic textual similarity (STS) is a critical task in natural language\nprocessing (NLP), enabling applications in retrieval, clustering, and\nunderstanding semantic relationships between texts. However, research in this\narea for the Arabic language remains limited due to the lack of high-quality\ndatasets and pre-trained models. This scarcity of resources has restricted the\naccurate evaluation and advance of semantic similarity in Arabic text. This\npaper introduces General Arabic Text Embedding (GATE) models that achieve\nstate-of-the-art performance on the Semantic Textual Similarity task within the\nMTEB benchmark. GATE leverages Matryoshka Representation Learning and a hybrid\nloss training approach with Arabic triplet datasets for Natural Language\nInference, which are essential for enhancing model performance in tasks that\ndemand fine-grained semantic understanding. GATE outperforms larger models,\nincluding OpenAI, with a 20-25% performance improvement on STS benchmarks,\neffectively capturing the unique semantic nuances of Arabic.",
    "pdf_url": "http://arxiv.org/pdf/2505.24581v1",
    "published": "2025-05-30T13:29:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24580v1",
    "title": "Surface waves and axoplasmic pressure waves in action potential propagation: fundamentally different physics or two sides of the same coin?",
    "authors": [
      "Marat M. Rvachev",
      "Benjamin Drukarch"
    ],
    "abstract": "We argue that El Hady and Machta's \"surface wave\" model describes the same\nunderlying process as the \"axoplasmic pressure wave\" model introduced earlier\nby Rvachev.\n  Note. We, the authors, contacted A. El Hady and B. Machta for comment on the\nideas presented herein. They suggested that we \"submit a Matters Arising Letter\nto Nature Communications and we will be asked to respond in due time.\" Nature\nCommunications ultimately rejected the manuscript, citing:\n  \"... Our main criterion for consideration of Matters Arising is the degree to\nwhich the piece provides interesting and timely scientific criticism and\nclarification of a Nature Communications publication. In the present case,\nwhile we appreciate the interest of your comments to the community, we do not\nfeel that they advance or clarify understanding of the article in question to\nthe extent required for publication in Nature Communications.\"\n  We are posting the submitted version online in accordance with the journal's\nsubmission guidelines, which state:\n  \"Authors who have had a submission declined are encouraged to post it as an\nonline comment to the paper concerned at the journal's website and/or on an\nappropriate preprint server.\"",
    "pdf_url": "http://arxiv.org/pdf/2505.24580v1",
    "published": "2025-05-30T13:28:17+00:00",
    "categories": [
      "physics.bio-ph",
      "q-bio.NC"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24579v1",
    "title": "Conservation-preserved Fourier Neural Operator through Adaptive Correction",
    "authors": [
      "Chaoyu Liu",
      "Yangming Li",
      "Zhongying Deng",
      "Chris Budd",
      "Carola-Bibiane Schönlieb"
    ],
    "abstract": "Fourier Neural Operators (FNOs) have recently emerged as a promising and\nefficient approach for learning the numerical solutions to partial differential\nequations (PDEs) from data. However, standard FNO often fails to preserve key\nconservation laws, such as mass conservation, momentum conservation, norm\nconservation, etc., which are crucial for accurately modeling physical systems.\nExisting methods for incorporating these conservation laws into Fourier neural\noperators are achieved by designing related loss function or incorporating\npost-processing method at the training time. None of them can both exactly and\nadaptively correct the outputs to satisfy conservation laws, and our\nexperiments show that these methods can lead to inferior performance while\npreserving conservation laws. In this work, we propose a novel adaptive\ncorrection approach to ensure the conservation of fundamental quantities. Our\nmethod introduces a learnable matrix to adaptively adjust the solution to\nsatisfy the conservation law during training. It ensures that the outputs\nexactly satisfy the goal conservation law and allow for more flexibility and\nadaptivity for the model to correct the outputs. We theoretically show that\napplying our adaptive correction to an unconstrained FNO yields a solution with\ndata loss no worse than that of the best conservation-satisfying FNO. We\ncompare our approach with existing methods on a range of representative PDEs.\nExperiment results show that our method consistently outperform other methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24579v1",
    "published": "2025-05-30T13:28:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24578v1",
    "title": "Neuro-Symbolic Operator for Interpretable and Generalizable Characterization of Complex Piezoelectric Systems",
    "authors": [
      "Abhishek Chandra",
      "Taniya Kapoor",
      "Mitrofan Curti",
      "Koen Tiels",
      "Elena A. Lomonova"
    ],
    "abstract": "Complex piezoelectric systems are foundational in industrial applications.\nTheir performance, however, is challenged by the nonlinear voltage-displacement\nhysteretic relationships. Efficient characterization methods are, therefore,\nessential for reliable design, monitoring, and maintenance. Recently proposed\nneural operator methods serve as surrogates for system characterization but\nface two pressing issues: interpretability and generalizability.\nState-of-the-art (SOTA) neural operators are black-boxes, providing little\ninsight into the learned operator. Additionally, generalizing them to novel\nvoltages and predicting displacement profiles beyond the training domain is\nchallenging, limiting their practical use. To address these limitations, this\npaper proposes a neuro-symbolic operator (NSO) framework that derives the\nanalytical operators governing hysteretic relationships. NSO first learns a\nFourier neural operator mapping voltage fields to displacement profiles,\nfollowed by a library-based sparse model discovery method, generating white-box\nparsimonious models governing the underlying hysteresis. These models enable\naccurate and interpretable prediction of displacement profiles across varying\nand out-of-distribution voltage fields, facilitating generalizability. The\npotential of NSO is demonstrated by accurately predicting voltage-displacement\nhysteresis, including butterfly-shaped relationships. Moreover, NSO predicts\ndisplacement profiles even for noisy and low-fidelity voltage data, emphasizing\nits robustness. The results highlight the advantages of NSO compared to SOTA\nneural operators and model discovery methods on several evaluation metrics.\nConsequently, NSO contributes to characterizing complex piezoelectric systems\nwhile improving the interpretability and generalizability of neural operators,\nessential for design, monitoring, maintenance, and other real-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.24578v1",
    "published": "2025-05-30T13:28:11+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24577v1",
    "title": "The Weak Version of the Graph Complement Conjecture and Partial Results for the Delta Conjecture",
    "authors": [
      "Francesco Barioli",
      "Shaun M. Fallat",
      "Himanshu Gupta",
      "Zhongshan Li"
    ],
    "abstract": "Since the transformative workshop by the American Institute of Mathematics on\nthe minimum rank of a graph, two longstanding open problems have captivated the\ncommunity interested in the minimum rank of graphs: the graph complement\nconjecture and the $\\delta$-conjecture. In this paper, we use a classical\nresult of Mader (1972) to establish a weak version of the graph complement\nconjecture for all key minimum rank parameters. In addition, again using the\nsame result of Mader, we present some extremal resolutions of the\n$\\delta$-conjecture. Furthermore, we incorporate the assumption of the\n$\\delta$-conjecture and extensive work on graph degeneracy to improve the bound\nin the weak version of the graph complement conjecture. We conclude with a list\nof conjectured bounds on the positive semidefinite variant of the Colin de\nVerdi\\`ere number.",
    "pdf_url": "http://arxiv.org/pdf/2505.24577v1",
    "published": "2025-05-30T13:26:45+00:00",
    "categories": [
      "math.CO",
      "05C50, 15A03, 05C35"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24576v1",
    "title": "A Composite Predictive-Generative Approach to Monaural Universal Speech Enhancement",
    "authors": [
      "Jie Zhang",
      "Haoyin Yan",
      "Xiaofei Li"
    ],
    "abstract": "It is promising to design a single model that can suppress various\ndistortions and improve speech quality, i.e., universal speech enhancement\n(USE). Compared to supervised learning-based predictive methods,\ndiffusion-based generative models have shown greater potential due to the\ngenerative capacities from degraded speech with severely damaged information.\nHowever, artifacts may be introduced in highly adverse conditions, and\ndiffusion models often suffer from a heavy computational burden due to many\nsteps for inference. In order to jointly leverage the superiority of prediction\nand generation and overcome the respective defects, in this work we propose a\nuniversal speech enhancement model called PGUSE by combining predictive and\ngenerative modeling. Our model consists of two branches: the predictive branch\ndirectly predicts clean samples from degraded signals, while the generative\nbranch optimizes the denoising objective of diffusion models. We utilize the\noutput fusion and truncated diffusion scheme to effectively integrate\npredictive and generative modeling, where the former directly combines results\nfrom both branches and the latter modifies the reverse diffusion process with\ninitial estimates from the predictive branch. Extensive experiments on several\ndatasets verify the superiority of the proposed model over state-of-the-art\nbaselines, demonstrating the complementarity and benefits of combining\npredictive and generative modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.24576v1",
    "published": "2025-05-30T13:26:42+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24575v1",
    "title": "NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization",
    "authors": [
      "Hyuntak Kim",
      "Byung-Hak Kim"
    ],
    "abstract": "Summarizing long-form narratives--such as books, movies, and TV\nscripts--requires capturing intricate plotlines, character interactions, and\nthematic coherence, a task that remains challenging for existing LLMs. We\nintroduce NexusSum, a multi-agent LLM framework for narrative summarization\nthat processes long-form text through a structured, sequential\npipeline--without requiring fine-tuning. Our approach introduces two key\ninnovations: (1) Dialogue-to-Description Transformation: A narrative-specific\npreprocessing method that standardizes character dialogue and descriptive text\ninto a unified format, improving coherence. (2) Hierarchical Multi-LLM\nSummarization: A structured summarization pipeline that optimizes chunk\nprocessing and controls output length for accurate, high-quality summaries. Our\nmethod establishes a new state-of-the-art in narrative summarization, achieving\nup to a 30.0% improvement in BERTScore (F1) across books, movies, and TV\nscripts. These results demonstrate the effectiveness of multi-agent LLMs in\nhandling long-form content, offering a scalable approach for structured\nsummarization in diverse storytelling domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.24575v1",
    "published": "2025-05-30T13:26:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24574v1",
    "title": "Bias-field-free operation of nitrogen-vacancy ensembles in diamond for accurate vector magnetometry",
    "authors": [
      "Lilian Childress",
      "Vincent Halde",
      "Kayla Johnson",
      "Andrew Lowther",
      "David Roy-Guay",
      "Romain Ruhlmann",
      "Adrian Solyom"
    ],
    "abstract": "Accurate measurement of vector magnetic fields is critical for applications\nincluding navigation, geoscience, and space exploration. Nitrogen-vacancy (NV)\ncenter spin ensembles offer a promising solution for high-sensitivity vector\nmagnetometry, as their different orientations in the diamond lattice measure\ndifferent components of the magnetic field. However, the bias magnetic field\ntypically used to separate signals from each NV orientation introduces\ninaccuracy from drifts in permanent magnets or coils. Here, we present a novel\nbias-field-free approach that labels the NV orientations via the direction of\nthe microwave (MW) field in a variable-pulse-duration Ramsey sequence used to\nmanipulate the spin ensemble. Numerical simulations demonstrate the possibility\nto isolate each orientation's signal with sub-nT accuracy even without precise\nMW field calibration, at only a moderate cost to sensitivity. We also provide\nproof-of-principle experimental validation, observing relevant features that\nevolve as expected with applied magnetic field. Looking forward, by removing a\nkey source of drift, the proposed protocol lays the groundwork for future\ndeployment of NV magnetometers in high-accuracy or long-duration missions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24574v1",
    "published": "2025-05-30T13:26:10+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24573v1",
    "title": "Maximally recoverable codes with locality and availability",
    "authors": [
      "Umberto Martínez-Peñas",
      "V. Lalitha"
    ],
    "abstract": "In this work, we introduce maximally recoverable codes with locality and\navailability. We consider locally repairable codes (LRCs) where certain subsets\nof $ t $ symbols belong each to $ N $ local repair sets, which are pairwise\ndisjoint after removing the $ t $ symbols, and which are of size $ r+\\delta-1 $\nand can correct $ \\delta-1 $ erasures locally. Classical LRCs with $ N $\ndisjoint repair sets and LRCs with $ N $-availability are recovered when\nsetting $ t = 1 $ and $ t=\\delta-1=1 $, respectively. Allowing $ t > 1 $\nenables our codes to reduce the storage overhead for the same locality and\navailability. In this setting, we define maximally recoverable LRCs (MR-LRCs)\nas those that can correct any globally correctable erasure pattern given the\nlocality and availability constraints. We provide three explicit constructions,\nbased on MSRD codes, each attaining the smallest finite-field sizes for some\nparameter regime. Finally, we extend the known lower bound on finite-field\nsizes from classical MR-LRCs to our setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.24573v1",
    "published": "2025-05-30T13:25:44+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24572v1",
    "title": "Fine-tuning for Data-enabled Predictive Control of Noisy Systems by Reinforcement Learning",
    "authors": [
      "Jinbao Wang",
      "Shiliang Zhang",
      "Jun Liu",
      "Xuehui Ma",
      "Haolin Liu"
    ],
    "abstract": "Data-enabled predictive control (DeePC) leverages system measurements in\ncharacterizing system dynamics for optimal control. The performance of DeePC\nrelies on optimizing its hyperparameters, especially in noisy systems where the\noptimal hyperparameters adapt over time. Existing hyperparameter tuning\napproaches for DeePC are more than often computationally inefficient or overly\nconservative. This paper proposes an adaptive DeePC where we guide its\nhyperparameters adaption through reinforcement learning. We start with\nestablishing the relationship between the system I/O behavior and DeePC\nhyperparameters. Then we formulate the hyperparameter tuning as a sequential\ndecision-making problem, and we address the decision-making through\nreinforcement learning. We implement offline training to gain a reinforcement\nlearning model, and we integrate the trained model with DeePC to adjust its\nhyperparameters adaptively in real time. We conduct numerical simulations with\ndiverse noisy conditions, and the results demonstrate the identification of\nnear-optimal hyperparameters and the robustness of the proposed approach\nagainst noises in the control.",
    "pdf_url": "http://arxiv.org/pdf/2505.24572v1",
    "published": "2025-05-30T13:24:58+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24571v1",
    "title": "Identifying Primary Stress Across Related Languages and Dialects with Transformer-based Speech Encoder Models",
    "authors": [
      "Nikola Ljubešić",
      "Ivan Porupski",
      "Peter Rupnik"
    ],
    "abstract": "Automating primary stress identification has been an active research field\ndue to the role of stress in encoding meaning and aiding speech comprehension.\nPrevious studies relied mainly on traditional acoustic features and English\ndatasets. In this paper, we investigate the approach of fine-tuning a\npre-trained transformer model with an audio frame classification head. Our\nexperiments use a new Croatian training dataset, with test sets in Croatian,\nSerbian, the Chakavian dialect, and Slovenian. By comparing an SVM classifier\nusing traditional acoustic features with the fine-tuned speech transformer, we\ndemonstrate the transformer's superiority across the board, achieving\nnear-perfect results for Croatian and Serbian, with a 10-point performance drop\nfor the more distant Chakavian and Slovenian. Finally, we show that only a few\nhundred multi-syllabic training words suffice for strong performance. We\nrelease our datasets and model under permissive licenses.",
    "pdf_url": "http://arxiv.org/pdf/2505.24571v1",
    "published": "2025-05-30T13:23:46+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24570v2",
    "title": "Hydrogen defects and band alignment in metal-organic frameworks",
    "authors": [
      "Khang Hoang"
    ],
    "abstract": "Band alignment, namely the prediction of band-edge positions of\nsemiconductors and insulators in aqueous solutions, is an important problem in\nphysics and chemistry. Such a prediction is especially challenging for complex\nmaterials. Here we present an approach to align band structure of metal-organic\nframeworks (MOFs) on an absolute energy scale which can be used for direct\ncomparison with experiments. Hydrogen defects are used as probes into the\nchemical bonding of the covalently bonded hybrid materials. An effective defect\nenergy level, defined as the average of the charge-state transition levels of\nthe defects at the linker and at the secondary building unit, is identified as\na charge neutrality level to align band structures. This level captures subtle\nchemical details at both the organic and inorganic building blocks and provides\nresults that are in agreement with experiments in a wide range of different\nMOFs. We also compare with results obtained from using other approaches\ninvolving surface calculations and average pore-center electrostatic\npotentials.",
    "pdf_url": "http://arxiv.org/pdf/2505.24570v2",
    "published": "2025-05-30T13:23:28+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24569v1",
    "title": "Observability of modified threshold behavior near unitarity",
    "authors": [
      "Michael D. Higgins",
      "J. Golak",
      "R. Skibinski",
      "K. Topolnicki",
      "H. Witala",
      "H. Kamada",
      "Chris H. Greene"
    ],
    "abstract": "A number of recent references have pointed out that an N-particle system\nhaving short-range interactions at S-wave and/or P-wave unitarity can exhibit\nmodified threshold behavior for various reactive processes. But the question of\nhow close to unitarity one must get in order to observe such modifications has\nnot been addressed. The present study quantities this question by treating\ncases involving 3- or 4-neutrons, at the physical value of the neutron-neutron\nsinglet scattering length a and at artificially altered values. One major\nconclusion is that the neutron-neutron scattering length is not yet\nsufficiently large for the 3n or 4n systems to demonstrate the unitarity\nthreshold exponent.",
    "pdf_url": "http://arxiv.org/pdf/2505.24569v1",
    "published": "2025-05-30T13:22:06+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24568v1",
    "title": "On the rate of convergence for Landau type Schrödinger Operators",
    "authors": [
      "Yucheng Pan",
      "Wenchang Sun"
    ],
    "abstract": "We study the pointwise convergence of Landau type Schr\\\"odinger operators\nwithin the fractional Sobolev space $W^{s,p}(\\mathbb R)$. Our results extend\nthose established by Bailey (Rev. Mat. Iberoam., 29 (2): 531-546, 2013) and\nYuan, Zhao and Zheng (Nonlinear Anal., 208: Paper No. 112312, 28, 2021).\nFurthermore, we also analyze the convergence rate of Landau type Schr\\\"odinger\noperators along curves and derive a sharp result for the case of convergence\nalong vertical lines.",
    "pdf_url": "http://arxiv.org/pdf/2505.24568v1",
    "published": "2025-05-30T13:21:18+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00100v2",
    "title": "Children's Voice Privacy: First Steps And Emerging Challenges",
    "authors": [
      "Ajinkya Kulkarni",
      "Francisco Teixeira",
      "Enno Hermann",
      "Thomas Rolland",
      "Isabel Trancoso",
      "Mathew Magimai Doss"
    ],
    "abstract": "Children are one of the most under-represented groups in speech technologies,\nas well as one of the most vulnerable in terms of privacy. Despite this,\nanonymization techniques targeting this population have received little\nattention. In this study, we seek to bridge this gap, and establish a baseline\nfor the use of voice anonymization techniques designed for adult speech when\napplied to children's voices. Such an evaluation is essential, as children's\nspeech presents a distinct set of challenges when compared to that of adults.\nThis study comprises three children's datasets, six anonymization methods, and\nobjective and subjective utility metrics for evaluation. Our results show that\nexisting systems for adults are still able to protect children's voice privacy,\nbut suffer from much higher utility degradation. In addition, our subjective\nstudy displays the challenges of automatic evaluation methods for speech\nquality in children's speech, highlighting the need for further research.",
    "pdf_url": "http://arxiv.org/pdf/2506.00100v2",
    "published": "2025-05-30T13:21:18+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24567v1",
    "title": "Unleashing the Power of Intermediate Domains for Mixed Domain Semi-Supervised Medical Image Segmentation",
    "authors": [
      "Qinghe Ma",
      "Jian Zhang",
      "Lei Qi",
      "Qian Yu",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "abstract": "Both limited annotation and domain shift are prevalent challenges in medical\nimage segmentation. Traditional semi-supervised segmentation and unsupervised\ndomain adaptation methods address one of these issues separately. However, the\ncoexistence of limited annotation and domain shift is quite common, which\nmotivates us to introduce a novel and challenging scenario: Mixed Domain\nSemi-supervised medical image Segmentation (MiDSS), where limited labeled data\nfrom a single domain and a large amount of unlabeled data from multiple\ndomains. To tackle this issue, we propose the UST-RUN framework, which fully\nleverages intermediate domain information to facilitate knowledge transfer. We\nemploy Unified Copy-paste (UCP) to construct intermediate domains, and propose\na Symmetric GuiDance training strategy (SymGD) to supervise unlabeled data by\nmerging pseudo-labels from intermediate samples. Subsequently, we introduce a\nTraining Process aware Random Amplitude MixUp (TP-RAM) to progressively\nincorporate style-transition components into intermediate samples. To generate\nmore diverse intermediate samples, we further select reliable samples with\nhigh-quality pseudo-labels, which are then mixed with other unlabeled data.\nAdditionally, we generate sophisticated intermediate samples with high-quality\npseudo-labels for unreliable samples, ensuring effective knowledge transfer for\nthem. Extensive experiments on four public datasets demonstrate the superiority\nof UST-RUN. Notably, UST-RUN achieves a 12.94% improvement in Dice score on the\nProstate dataset. Our code is available at https://github.com/MQinghe/UST-RUN",
    "pdf_url": "http://arxiv.org/pdf/2505.24567v1",
    "published": "2025-05-30T13:21:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24566v1",
    "title": "2D PZT MEMS Resonant Scanner Using a Three-Mask Process",
    "authors": [
      "Mehrdad Khodapanahandeh",
      "Parviz Zolfaghari",
      "Hakan Urey"
    ],
    "abstract": "This work presents the design, simulation, fabrication, and characterization\nof a novel architectural compact two-dimensional (2D) resonant MEMS scanning\nmirror actuated by thin-film lead zirconate titanate (PZT). The device employs\nan innovative mechanically coupled dual-axis architecture fabricated using a\nthree-mask process on an SOI-PZT deposited wafer, significantly reducing system\ncomplexity while achieving high performance. The scanner integrates a 1\n$\\times$ 1.4 mm oval mirror within a 7 $\\times$ 4.7 mm die, actuated by PZT\nthin-film elements optimized for resonant operation at 3.6 kHz (vertical) and\n54.2 kHz (horizontal) under 12 V$_{\\mathrm{p-p}}$ periodic pulse driving. The\nsystem achieves optical scan angles of 4.8$^\\circ$ and 11.5$^\\circ$ in vertical\nand horizontal directions, respectively, with quality factors of 750 (vertical)\nand 1050 (horizontal). These values contribute to high scanning\nbandwidth-efficiency products of 24.2 deg$\\cdot$mm$\\cdot$kHz (vertical) and 623\ndeg$\\cdot$mm$\\cdot$kHz (horizontal), among the higher values reported for 2D\nPZT-MEMS scanners. Finite element analysis confirmed minimal stress and mirror\ndeformation, and experimental validation demonstrated excellent agreement with\nsimulation results. This architecture demonstrates the feasibility of\nhigh-resolution laser scanning, as required in applications such as OCT, LiDAR,\nand displays, by achieving performance levels in line with those used in such\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24566v1",
    "published": "2025-05-30T13:20:10+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24565v1",
    "title": "Counting the number of $\\mathbb{Z}_{p}$-and $\\mathbb{F}_{p}[t]$-fixed points of a discrete dynamical system with applications from arithmetic statistics, III",
    "authors": [
      "Brian Kintu"
    ],
    "abstract": "In this follow-up paper, we again inspect a surprising relationship between\nthe set of fixed points of a polynomial map $\\varphi_{d, c}$ defined by\n$\\varphi_{d, c}(z) = z^d + c$ for all $c, z \\in \\mathcal{O}_{K}$ or $c, z \\in\n\\mathbb{Z}_{p}$ or $c, z \\in \\mathbb{F}_{p}[t]$ and the coefficient $c$, where\n$K$ is any number field (not necessarily real) of degree $n > 1$, $p>2$ is any\nprime integer, and $d>2$ is an integer. As in \\cite{BK1,BK2} we again wish to\nstudy here counting problems that are inspired by exhilarating advances in\narithmetic statistics, and also partly by point-counting results of Narkiewicz\non totally complex $K$-periodic points and of Adam-Fares on\n$\\mathbb{Q}_{p}$-periodic points (orbits) in arithmetic dynamics. In doing so,\nwe then first prove that for any given prime $p\\geq 3$ and any $\\ell \\in\n\\mathbb{Z}^{+}$, the average number of distinct fixed points of any\n$\\varphi_{p^{\\ell}, c}$ modulo prime ideal $p\\mathcal{O}_{K}$ (modulo\n$p\\mathbb{Z}_{p}$) is bounded (if $\\ell \\in \\mathbb{Z}^{+}\\setminus\\{1, p\\}$)\nor zero or unbounded (if $\\ell \\in \\{1, p\\}$) as $c\\to \\infty$. Motivated\nfurther by an $\\mathbb{F}_{p}(t)$-periodic point-counting result of Benedetto,\nwe also find that the average number in $\\mathbb{F}_{p}[t]$-setting behaves in\nthe same way as in $\\mathcal{O}_{K}$-setting. Finally, we then apply counting\nand statistical results from arithmetic statistics to immediately deduce here\nseveral counting and statistical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.24565v1",
    "published": "2025-05-30T13:20:06+00:00",
    "categories": [
      "math.NT",
      "math.DS"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24564v2",
    "title": "Quantum-Ready Microwave Detection with Scalable Graphene Bolometers in the Strong Localization Regime",
    "authors": [
      "Yu-Cheng Chang",
      "Federico Chianese",
      "Naveen Shetty",
      "Johanna Huhtasaari",
      "Aditya Jayaraman",
      "Joonas T. Peltonen",
      "Samuel Lara-Avila",
      "Bayan Karimi",
      "Andrey Danilov",
      "Jukka P. Pekola",
      "Sergey Kubatkin"
    ],
    "abstract": "Exploiting quantum interference of charge carriers, epitaxial graphene grown\non silicon carbide emerges as a game-changing platform for ultra-sensitive\nbolometric sensing, featuring an intrinsic resistive thermometer response\nunmatched by any other graphene variant. By achieving low and uniform carrier\ndensities, we have accessed a new regime of strong charge localization that\ndramatically reduces thermal conductance, significantly enhancing bolometer\nperformance. Here we present scalable graphene-based bolometers engineered for\ndetecting GHz-range photons, a frequency domain essential for superconducting\nquantum processors. Our devices deliver a state-of-the-art noise equivalent\npower of 40 zW$/\\sqrt{\\rm Hz}$ at $T=40~$mK, enabled by the steep temperature\ndependence of thermal conductance, $G_{\\rm th}\\sim T^4$ for $T<100~$mK. These\nresults establish epitaxial graphene bolometers as versatile and\nlow-back-action detectors, unlocking new possibilities for next-generation\nquantum processors and pioneering investigations into the thermodynamics and\nthermalization pathways of strongly entangled quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24564v2",
    "published": "2025-05-30T13:18:33+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el",
      "physics.ins-det"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24563v1",
    "title": "Molecular Chiral Response Enhanced by Crosstalking Quasi-Bound States in the Continuum",
    "authors": [
      "Diana Shakirova",
      "Adrià Canós Valero",
      "Daniil Riabov",
      "Hatice Altug",
      "Andrey Bogdanov",
      "Thomas Weiss"
    ],
    "abstract": "Identifying the handedness of chiral molecules is of fundamental importance\nin chemistry, biology, pharmacy, and medicine. Nanophotonic structures allow us\nto control light at the nanoscale and offer powerful tools for chiral sensing,\nenabling the detection of small analyte volumes and low molecular\nconcentrations by harnessing optical resonances. Most existing strategies rely\non intuitive concepts such as strong local field enhancement or large local\noptical chirality, often achieved by engineering electric and magnetic Mie\nresonances in dielectric or plasmonic nanostructures. Recent insights, however,\nreveal that the chiroptical response of resonant systems is governed not only\nby local field effects, but also by less obvious mechanisms such as modal\ncrosstalk. In this work, we present a dielectric metasurface engineered to\namplify the modal crosstalk by supporting two nearly degenerate,\nhigh-quality-factor resonant states known as quasi-bound states in the\ncontinuum. Our theoretical and numerical analysis predicts a pronounced\ndifferential transmittance that exceeds the detection threshold of standard\nspectrometers. In particular, the differential transmittance reaches up to\n$10^{-2}$ for the Pasteur parameter $\\kappa = 1\\cdot10^{-4}$. These findings\nadvance the capabilities of nanophotonic sensors for chiral detection, paving\nthe way toward ultrasensitive identification of molecular handedness in\nincreasingly smaller volumes and concentrations at the experimentally visible\nlevel.",
    "pdf_url": "http://arxiv.org/pdf/2505.24563v1",
    "published": "2025-05-30T13:17:46+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24562v1",
    "title": "Gravity driven traveling bore wave solutions to the free boundary incompressible Navier-Stokes equations",
    "authors": [
      "Noah Stevenson",
      "Ian Tice"
    ],
    "abstract": "We give the first mathematical construction of two-dimensional traveling bore\nwave solutions to the free boundary incompressible Navier-Stokes equations for\na single finite depth layer of constant density fluid. Our construction is\nbased on a rigorous justification of the formal shallow water limit, which\npostulates that in a certain scaling regime the full free boundary traveling\nNavier-Stokes system of PDEs reduces to a governing system of ODEs. We find\nheteroclinic orbits solving these ODEs and, through a delicate fixed point\nargument employing the Stokes problem in thin domains and a nonautonomous\norbital perturbation theory, use these ODE solutions as the germs from which we\nbuild bore PDE solutions for sufficiently shallow layers.",
    "pdf_url": "http://arxiv.org/pdf/2505.24562v1",
    "published": "2025-05-30T13:17:00+00:00",
    "categories": [
      "math.AP",
      "Primary 35Q35, 35C07, 76D33, Secondary 35B40, 35J66, 76A20, 76L05,\n  34C37, 35A24"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24561v1",
    "title": "Improving Language and Modality Transfer in Translation by Character-level Modeling",
    "authors": [
      "Ioannis Tsiamas",
      "David Dale",
      "Marta R. Costa-jussà"
    ],
    "abstract": "Current translation systems, despite being highly multilingual, cover only 5%\nof the world's languages. Expanding language coverage to the long-tail of\nlow-resource languages requires data-efficient methods that rely on\ncross-lingual and cross-modal knowledge transfer. To this end, we propose a\ncharacter-based approach to improve adaptability to new languages and\nmodalities. Our method leverages SONAR, a multilingual fixed-size embedding\nspace with different modules for encoding and decoding. We use a\nteacher-student approach with parallel translation data to obtain a\ncharacter-level encoder. Then, using ASR data, we train a lightweight adapter\nto connect a massively multilingual CTC ASR model (MMS), to the character-level\nencoder, potentially enabling speech translation from 1,000+ languages.\nExperimental results in text translation for 75 languages on FLORES+\ndemonstrate that our character-based approach can achieve better language\ntransfer than traditional subword-based models, especially outperforming them\nin low-resource settings, and demonstrating better zero-shot generalizability\nto unseen languages. Our speech adaptation, maximizing knowledge transfer from\nthe text modality, achieves state-of-the-art results in speech-to-text\ntranslation on the FLEURS benchmark on 33 languages, surpassing previous\nsupervised and cascade models, albeit being a zero-shot model with minimal\nsupervision from ASR data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24561v1",
    "published": "2025-05-30T13:16:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24560v3",
    "title": "Benchmark brown dwarfs -- I. A blue M2 + T5 wide binary and a probable young [M4 + M4] + [T7 + T8] hierarchical quadruple",
    "authors": [
      "Z. H. Zhang",
      "F. Navarete",
      "M. C. Galvez-Ortiz",
      "H. R. A. Jones",
      "A. J. Burgasser",
      "P. Cruz",
      "F. Marocco",
      "N. Lodieu",
      "Y. Shan",
      "B. Gauza",
      "R. Raddi",
      "M. R. Huang",
      "R. L. Smart",
      "S. Baig",
      "G. Cheng",
      "D. J. Pinfield"
    ],
    "abstract": "Benchmark brown dwarfs in wide binary systems are crucial for characterizing\nsubstellar objects and calibrating atmospheric and evolutionary models.\nHowever, brown dwarf benchmarks with subsolar metallicity, very cool\ntemperatures, or suitability for dynamical mass measurements are rare, limiting\nour understanding across the full range of mass, age, and metallicity. We\npresent the discovery of two new multiple systems containing T dwarf\ncompanions, identified through a targeted search using CatWISE2020 and Gaia\ncatalogues. L 122-88 AB is a wide binary comprising a mildly metal-poor M2\ndwarf and a T5 dwarf, separated by 215.6 arcsec at a distance of 33.106+/-0.014\npc. Atmospheric model fitting to the near infrared spectrum of L 122-88 A\nsuggests a mildly metal-poor composition ([Fe/H] = -0.2). UPM J1040-3551 AB is\na candidate hierarchical quadruple system at 25.283+/-0.013 pc, consisting of a\nlikely astrometric binary of two M4 dwarfs and a probable unresolved spectral\nbinary of T7 and T8 dwarfs, separated by 65.48 arcsec from the primary. The\nH-alpha emission detected in UPM J1040-3551 A indicates an age range of 0.3-2.0\nGyr. This age estimate suggests that the T8 component has a mass between 9 and\n28 Jupiter masses, potentially classifying it as a planetary-mass object. These\nsystems augment the sample of benchmark brown dwarfs, particularly in the\nunderexplored regime of cool temperature, providing valuable opportunities for\nrefining our understanding of substellar objects.",
    "pdf_url": "http://arxiv.org/pdf/2505.24560v3",
    "published": "2025-05-30T13:13:32+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24559v2",
    "title": "The Samples and Binary Fractions of Red Supergiant in M31 and M33 by the HST Observations",
    "authors": [
      "Min Dai",
      "Shu Wang",
      "Biwei Jiang",
      "Ying Li"
    ],
    "abstract": "The binarity of red supergiants (RSGs) influences their evolution and the\nfate of supernovae. We investigate the binary fraction of RSGs in the Andromeda\nGalaxy (M31) and Triangulum Galaxy (M33) using photometry from the Hubble Space\nTelescope (HST), which offers high spatial resolution to resolve more RSGs. A\npreliminary step involves identifying a reliable and complete RSG sample using\nthe F110W $-$ F160W versus F160W diagram, yielding 2,612 RSGs from the\nPanchromatic Hubble Andromeda Treasury (PHAT) survey of M31 3,294 RSGs from the\nPanchromatic Hubble Andromeda Treasury: Triangulum Extended Region (PHATTER)\nsurvey of M33. These samples suggest total RSG populations in M31 and M33 of\n6,563 and 7,572, respectively. These estimates significantly exceed previous\nones from the ground-based observations, an increase attributed to the superior\nspatial resolution of the HST. The stellar parameters of these RSGs, including\neffective temperature ($T_{\\mathrm{eff}}$), radius ($R$), and luminosity ($L$),\nare derived by fitting their spectral energy distribution (SED) across optical\nand near-infrared bands. Binary candidates are identified by detecting\nultraviolet (UV) excesses in their SEDs compared to the single-star RSG model\nprediction. The binary fraction is determined to be 33.4% $\\pm$ 0.9% for M31\nand 30.9% $\\pm$ 0.8% for M33. For more luminous RSGs with log $L/L_{\\odot} >\n4.0$, the binary fraction decreases to 31.6% $\\pm$ 1.9% in M31 and increases to\n34.7% $\\pm$ 1.8% in M33, respectively. These results are in good agreement with\npredictions from the BPASS binary evolution model.",
    "pdf_url": "http://arxiv.org/pdf/2505.24559v2",
    "published": "2025-05-30T13:13:16+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24558v1",
    "title": "Optimal Weighted Convolution for Classification and Denosing",
    "authors": [
      "Simone Cammarasana",
      "Giuseppe Patanè"
    ],
    "abstract": "We introduce a novel weighted convolution operator that enhances traditional\nconvolutional neural networks (CNNs) by integrating a spatial density function\ninto the convolution operator. This extension enables the network to\ndifferentially weight neighbouring pixels based on their relative position to\nthe reference pixel, improving spatial characterisation and feature extraction.\nThe proposed operator maintains the same number of trainable parameters and is\nfully compatible with existing CNN architectures. Although developed for 2D\nimage data, the framework is generalisable to signals on regular grids of\narbitrary dimensions, such as 3D volumetric data or 1D time series. We propose\nan efficient implementation of the weighted convolution by pre-computing the\ndensity function and achieving execution times comparable to standard\nconvolution layers. We evaluate our method on two deep learning tasks: image\nclassification using the CIFAR-100 dataset [KH+09] and image denoising using\nthe DIV2K dataset [AT17]. Experimental results with state-of-the-art\nclassification (e.g., VGG [SZ15], ResNet [HZRS16]) and denoising (e.g., DnCNN\n[ZZC+17], NAFNet [CCZS22]) methods show that the weighted convolution improves\nperformance with respect to standard convolution across different quantitative\nmetrics. For example, VGG achieves an accuracy of 66.94% with weighted\nconvolution versus 56.89% with standard convolution on the classification\nproblem, while DnCNN improves the PSNR value from 20.17 to 22.63 on the\ndenoising problem. All models were trained on the CINECA Leonardo cluster to\nreduce the execution time and improve the tuning of the density function\nvalues. The PyTorch implementation of the weighted convolution is publicly\navailable at: https://github.com/cammarasana123/weightedConvolution2.0.",
    "pdf_url": "http://arxiv.org/pdf/2505.24558v1",
    "published": "2025-05-30T13:10:46+00:00",
    "categories": [
      "cs.CV",
      "68T05"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24557v1",
    "title": "Optical frequency division referenced to microhertz-linewidth quantum-noise-limited lasers",
    "authors": [
      "Jiahao Hu",
      "Yanlan Xiao",
      "Honglei Yang",
      "Siyi Xue",
      "Wenchan Dong",
      "Kunpeng Zhai",
      "Sha Zhu",
      "Kun Qiu",
      "Shengkang Zhang",
      "Jun Ge",
      "Ninghua Zhu",
      "Xiaoshun Jiang",
      "Jing Xu",
      "Huashun Wen",
      "Heng Zhou"
    ],
    "abstract": "Optical frequency division (OFD) implements the conversion of ultra-stable\noptical frequencies into microwave frequencies through an optical frequency\ncomb flywheel, generating microwave oscillators with record-low phase noise and\ntime jitter. However, conventional OFD systems face significant trade-off\nbetween division complexity and noise suppression due to severe thermal noise\nand technical noise in the optical frequency references. Here, we address this\nchallenge by generating common-cavity bi-color Brillouin lasers as the optical\nfrequency references, which operate at the fundamental quantum noise limit with\nSchawlow-Townes linewidth on the 10 {\\mu}Hz level. Enabled by these\nultra-coherent reference lasers, our OFD system uses a dramatically simplified\ncomb divider with an unprecedented small division factor of 10, and\nsuccessfully generates 10 GHz microwave signal with exceptional phase noise of\n-65 dBc/Hz at 1Hz, -151 dBc/Hz at 10 kHz, and -170 dBc/Hz at 10 MHz offset. Our\nwork redefines the trade-off between noise suppression and division complexity\nin OFD, paving the way for compact, high-performance microwave synthesis for\nnext-generation atomic clocks, quantum sensors, and low-noise radar systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24557v1",
    "published": "2025-05-30T13:09:21+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.02030v1",
    "title": "Adaptive Privacy-Preserving SSD",
    "authors": [
      "Na Young Ahn",
      "Dong Hoon Lee"
    ],
    "abstract": "Data remanence in NAND flash complicates complete deletion on IoT SSDs. We\ndesign an adaptive architecture offering four privacy levels (PL0-PL3) that\nselect among address, data, and parity deletion techniques. Quantitative\nanalysis balances efficacy, latency, endurance, and cost. Machine-learning\nadjusts levels contextually, boosting privacy with negligible performance\noverhead and complexity.",
    "pdf_url": "http://arxiv.org/pdf/2506.02030v1",
    "published": "2025-05-30T13:08:42+00:00",
    "categories": [
      "cs.CR",
      "H.3"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24555v1",
    "title": "Computing finite Weyl groupoids",
    "authors": [
      "Iván Angiono",
      "Leandro Vendramin"
    ],
    "abstract": "We present algorithms to compute generalized root systems of Nichols algebras\nof diagonal type and of contragredient Lie superalgebras. As a consequence, we\nobtain an algorithm to compute the Lyndon words in the Kharchenko PBW basis\nassociated to each positive root, along with their corresponding hyperwords.\nThis data is essential for obtaining a minimal presentation of Nichols algebras\nof diagonal type with a finite root system.",
    "pdf_url": "http://arxiv.org/pdf/2505.24555v1",
    "published": "2025-05-30T13:05:46+00:00",
    "categories": [
      "math.RT",
      "math.QA",
      "math.RA"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2506.06325v1",
    "title": "Evolutionary model for energy trading in community microgrids using Hawk-Dove strategies",
    "authors": [
      "Viorica Rozina Chifu",
      "Tudor Cioara",
      "Cristina Bianca Pop",
      "Ionut Anghel"
    ],
    "abstract": "This paper proposes a decentralized model of energy cooperation between\nmicrogrids, in which decisions are made locally, at the level of the microgrid\ncommunity. Each microgrid is modeled as an autonomous agent that adopts a Hawk\nor Dove strategy, depending on the level of energy stored in the battery and\nits role in the energy trading process. The interactions between selling and\nbuying microgrids are modeled through an evolutionary algorithm. An individual\nin the algorithm population is represented as an energy trading matrix that\nencodes the amounts of energy traded between the selling and buying microgrids.\nThe population evolution is achieved by recombination and mutation operators.\nRecombination uses a specialized operator for matrix structures, and mutation\nis applied to the matrix elements according to a Gaussian distribution. The\nevaluation of an individual is made with a multi-criteria fitness function that\nconsiders the seller profit, the degree of energy stability at the community\nlevel, penalties for energy imbalance at the community level and for the\ndegradation of microgrids batteries. The method was tested on a simulated\nscenario with 100 microgrids, each with its own selling and buying thresholds,\nto reflect a realistic environment with variable storage characteristics of\nmicrogrids batteries. By applying the algorithm on this scenario, 95 out of the\n100 microgrids reached a stable energy state. This result confirms the\neffectiveness of the proposed model in achieving energy balance both at the\nindividual level, for each microgrid, and at the level of the entire community.",
    "pdf_url": "http://arxiv.org/pdf/2506.06325v1",
    "published": "2025-05-30T13:04:01+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24554v2",
    "title": "Bench4KE: Benchmarking Automated Competency Question Generation",
    "authors": [
      "Anna Sofia Lippolis",
      "Minh Davide Ragagni",
      "Paolo Ciancarini",
      "Andrea Giovanni Nuzzolese",
      "Valentina Presutti"
    ],
    "abstract": "The availability of Large Language Models (LLMs) presents a unique\nopportunity to reinvigorate research on Knowledge Engineering (KE) automation,\na trend already evident in recent efforts developing LLM-based methods and\ntools for the automatic generation of Competency Questions (CQs). However, the\nevaluation of these tools lacks standardisation. This undermines the\nmethodological rigour and hinders the replication and comparison of results. To\naddress this gap, we introduce Bench4KE, an extensible API-based benchmarking\nsystem for KE automation. Its first release focuses on evaluating tools that\ngenerate CQs automatically. CQs are natural language questions used by ontology\nengineers to define the functional requirements of an ontology. Bench4KE\nprovides a curated gold standard consisting of CQ datasets from four real-world\nontology projects. It uses a suite of similarity metrics to assess the quality\nof the CQs generated. We present a comparative analysis of four recent CQ\ngeneration systems, which are based on LLMs, establishing a baseline for future\nresearch. Bench4KE is also designed to accommodate additional KE automation\ntasks, such as SPARQL query generation, ontology testing and drafting. Code and\ndatasets are publicly available under the Apache 2.0 license.",
    "pdf_url": "http://arxiv.org/pdf/2505.24554v2",
    "published": "2025-05-30T13:03:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24553v1",
    "title": "CREFT: Sequential Multi-Agent LLM for Character Relation Extraction",
    "authors": [
      "Ye Eun Chun",
      "Taeyoon Hwang",
      "Seung-won Hwang",
      "Byung-Hak Kim"
    ],
    "abstract": "Understanding complex character relations is crucial for narrative analysis\nand efficient script evaluation, yet existing extraction methods often fail to\nhandle long-form narratives with nuanced interactions. To address this\nchallenge, we present CREFT, a novel sequential framework leveraging\nspecialized Large Language Model (LLM) agents. First, CREFT builds a base\ncharacter graph through knowledge distillation, then iteratively refines\ncharacter composition, relation extraction, role identification, and group\nassignments. Experiments on a curated Korean drama dataset demonstrate that\nCREFT significantly outperforms single-agent LLM baselines in both accuracy and\ncompleteness. By systematically visualizing character networks, CREFT\nstreamlines narrative comprehension and accelerates script review -- offering\nsubstantial benefits to the entertainment, publishing, and educational sectors.",
    "pdf_url": "http://arxiv.org/pdf/2505.24553v1",
    "published": "2025-05-30T13:01:36+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24552v1",
    "title": "Design and Analysis of Power Consumption Models for Open-RAN Architectures",
    "authors": [
      "Urooj Tariq",
      "Rishu Raj",
      "Dan Kilper"
    ],
    "abstract": "The open radio access network (O-RAN) Alliance developed an architecture and\nspecifications for open and disaggregated cellular networks including many\nelements that are being widely adopted and implemented in both commercial and\nresearch networks. In this paper, we develop transaction-based power\nconsumption models of a centralized O-RAN architecture based on commercial\nhardware and considering the full end-to-end data path from the radio unit to\nthe data center. We focus on recent fanout limitations and early baseband\nprocessing requirements related to current implementations of O-RAN and assess\nthe power consumption impact when baseband processing is employed at different\ncentralization points in the network. Additionally, we explore how greater\nfanout and sharing deeper into the network impact the balance of processing and\ntransmission. Low processing fanout restrictions motivate greater\ncentralization of the processing. At the same time, allowing for more open\nradio units per open distributed unit will quickly increase the transmission\ncapacity requirements and related energy use.",
    "pdf_url": "http://arxiv.org/pdf/2505.24552v1",
    "published": "2025-05-30T13:00:57+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24551v3",
    "title": "Melding the Serverless Control Plane with the Conventional Cluster Manager for Speed and Resource Efficiency",
    "authors": [
      "Leonid Kondrashov",
      "Lazar Cvetković",
      "Hancheng Wang",
      "Boxi Zhou",
      "Dhairya Rungta",
      "Dmitrii Ustiugov"
    ],
    "abstract": "Serverless platforms face a trade-off: conventional cluster managers like\nKubernetes offer compatibility for co-locating Function-as-a-Service (FaaS) and\nBackend-as-a-Service (BaaS) components of serverless applications at the cost\nof high cold-start latency, while specialized FaaS-only systems like Dirigent\nachieve low latency by sacrificing compatibility, which prevents integrated\nmanagement and optimization. Our analysis reveals FaaS traffic is bimodal:\npredictable, sustainable traffic consumes >98% of cluster resources, while\nsporadic excessive bursts stress the control plane's scaling latency, not its\nthroughput.\n  With these insights, we design PulseNet, a serverless architecture that\nemploys a dual-track control plane tailoring to both traffic types. PulseNet's\nstandard track manages sustainable traffic with long-lived, full-featured\nRegular Instances under a conventional cluster manager, preserving\ncompatibility and robust features for the majority of the workload. To handle\nexcessive traffic, an expedited track bypasses the slow manager to rapidly\ncreate short-lived, disposable Emergency Instances, minimizing cold-start\nlatency and resource waste from idle instances. This hybrid approach achieves\n35% better performance than Dirigent, a FaaS-only system, at the same cost and\noutperforms other Kubernetes-compatible systems by 1.5-3.5x at a 3-70% lower\ncost.",
    "pdf_url": "http://arxiv.org/pdf/2505.24551v3",
    "published": "2025-05-30T13:00:27+00:00",
    "categories": [
      "cs.DC",
      "68",
      "D.4.4"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24550v1",
    "title": "A*-Thought: Efficient Reasoning via Bidirectional Compression for Low-Resource Settings",
    "authors": [
      "Xiaoang Xu",
      "Shuo Wang",
      "Xu Han",
      "Zhenghao Liu",
      "Huijia Wu",
      "Peipei Li",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Zhaofeng He"
    ],
    "abstract": "Large Reasoning Models (LRMs) achieve superior performance by extending the\nthought length. However, a lengthy thinking trajectory leads to reduced\nefficiency. Most of the existing methods are stuck in the assumption of\noverthinking and attempt to reason efficiently by compressing the\nChain-of-Thought, but this often leads to performance degradation. To address\nthis problem, we introduce A*-Thought, an efficient tree search-based unified\nframework designed to identify and isolate the most essential thoughts from the\nextensive reasoning chains produced by these models. It formulates the\nreasoning process of LRMs as a search tree, where each node represents a\nreasoning span in the giant reasoning space. By combining the A* search\nalgorithm with a cost function specific to the reasoning path, it can\nefficiently compress the chain of thought and determine a reasoning path with\nhigh information density and low cost. In addition, we also propose a\nbidirectional importance estimation mechanism, which further refines this\nsearch process and enhances its efficiency beyond uniform sampling. Extensive\nexperiments on several advanced math tasks show that A*-Thought effectively\nbalances performance and efficiency over a huge search space. Specifically,\nA*-Thought can improve the performance of QwQ-32B by 2.39$\\times$ with\nlow-budget and reduce the length of the output token by nearly 50% with\nhigh-budget. The proposed method is also compatible with several other LRMs,\ndemonstrating its generalization capability. The code can be accessed at:\nhttps://github.com/AI9Stars/AStar-Thought.",
    "pdf_url": "http://arxiv.org/pdf/2505.24550v1",
    "published": "2025-05-30T12:58:34+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24549v1",
    "title": "Strongly driven transmon as an incoherent noise source",
    "authors": [
      "Linda Greggio",
      "Rémi Robin",
      "Mazyar Mirrahimi",
      "Alexandru Petrescu"
    ],
    "abstract": "Under strong drives, which are becoming necessary for fast high-fidelity\noperations, transmons can be structurally unstable. Due to chaotic effects, the\ncomputational manifold is no longer well separated from the remainder of the\nspectrum, which correlates with enhanced offset-charge sensitivity and\ndestructive effects in readout. We show here that these detrimental effects can\nfurther propagate to other degrees of freedom, for example to neighboring\nqubits in a multi-qubit system. Specifically, a coherently driven transmon can\nact as a source of incoherent noise to another circuit element coupled to it.\nBy using a full quantum model and a semiclassical analysis, we perform the\nnoise spectroscopy of the driven transmon coupled to a spectator two-level\nsystem (TLS), and we show that, in a certain limit, the interaction with the\ndriven transmon can be modeled as a stochastic diffusive process driving the\nTLS.",
    "pdf_url": "http://arxiv.org/pdf/2505.24549v1",
    "published": "2025-05-30T12:57:57+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24547v1",
    "title": "Accelerated ultrafast demagnetization of an interlayer-exchange-coupled Co/Mn/Co trilayer",
    "authors": [
      "Jendrik Gördes",
      "Ivar Kumberg",
      "Chowdhury S. Awsaf",
      "Marcel Walter",
      "Tauqir Shinwari",
      "Sangeeta Thakur",
      "Sangeeta Sharma",
      "Christian Schüßler-Langeheine",
      "Niko Pontius",
      "Wolfgang Kuch"
    ],
    "abstract": "We investigate the ultrafast magnetization dynamics of an\ninterlayer-exchange-coupled Co/Mn/Co trilayer system after excitation with an\nultrafast optical pump. We probe element- and time-resolved ferromagnetic order\nby X-ray magnetic circular dichroism in resonant reflectivity. We observe an\naccelerated Co demagnetization time in the case of weak total parallel\ninterlayer coupling at 9.5 ML Mn thickness for antiparallel alignment of both\nCo layers compared to parallel alignment as well as for parallel alignment in\nthe case of strong parallel interlayer coupling at 11 ML of Mn. From ab initio\ntime-dependent density functional theory calculations, we conclude that\noptically induced intersite spin transfer of spin-polarized electrons from Co\ninto Mn acts as a decay channel to enhance and accelerate ultrafast\ndemagnetization. This spin transfer can only take place in case of a collinear\nMn spin structure. We argue that this is the case for antiparallel alignment of\nboth Co layers at 9.5 ML Mn thickness and parallel alignment in case of 11 ML\nof Mn. Our results point out that an antiferromagnetic spacer layer and its\nspin structure have a significant effect on the magnetization dynamics of\nadjacent ferromagnetic layers. Our findings provide further insight into\nfundamental mechanisms of ultrafast demagnetization and may lead to improve\ndynamics in multilayered systems for faster optical switching of magnetic\norder.",
    "pdf_url": "http://arxiv.org/pdf/2505.24547v1",
    "published": "2025-05-30T12:54:13+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24546v2",
    "title": "Weil polynomials of small degree",
    "authors": [
      "Stefano Marseglia"
    ],
    "abstract": "Honda and Tate showed that the isogeny classes of abelian varieties of\ndimension $g$ over a finite field $\\mathbb{F}_q$ are classified in terms of\n$q$-Weil polynomials of degree $2g$, that is, monic integer polynomials whose\nset of complex roots consists of $g$ conjugate pairs of absolute value\n$\\sqrt{q}$. There are descriptions of the space of such polynomials for $g \\leq\n5$, but for $g=3$, $4$ and $5$, these results contain mistakes. We correct\nthese statements. Our proofs build on a criterion that determines when a real\npolynomial has only real roots in terms of the non-necessarily distinct roots\nof its first derivative.",
    "pdf_url": "http://arxiv.org/pdf/2505.24546v2",
    "published": "2025-05-30T12:54:11+00:00",
    "categories": [
      "math.NT",
      "14K15, 12D10, 26C10"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24545v1",
    "title": "Pretraining Multi-Speaker Identification for Neural Speaker Diarization",
    "authors": [
      "Shota Horiguchi",
      "Atsushi Ando",
      "Marc Delcroix",
      "Naohiro Tawara"
    ],
    "abstract": "End-to-end speaker diarization enables accurate overlap-aware diarization by\njointly estimating multiple speakers' speech activities in parallel. This\napproach is data-hungry, requiring a large amount of labeled conversational\ndata, which cannot be fully obtained from real datasets alone. To address this\nissue, large-scale simulated data is often used for pretraining, but it\nrequires enormous storage and I/O capacity, and simulating data that closely\nresembles real conversations remains challenging. In this paper, we propose\npretraining a model to identify multiple speakers from an input fully\noverlapped mixture as an alternative to pretraining a diarization model. This\nmethod eliminates the need to prepare a large-scale simulated dataset while\nleveraging large-scale speaker recognition datasets for training. Through\ncomprehensive experiments, we demonstrate that the proposed method enables a\nhighly accurate yet lightweight local diarization model without simulated\nconversational data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24545v1",
    "published": "2025-05-30T12:53:27+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24544v1",
    "title": "Cross-Attention Speculative Decoding",
    "authors": [
      "Wei Zhong",
      "Manasa Bharadwaj",
      "Yixiao Wang",
      "Nikhil Verma",
      "Yipeng Ji",
      "Chul Lee"
    ],
    "abstract": "Speculative decoding (SD) is a widely adopted approach for accelerating\ninference in large language models (LLMs), particularly when the draft and\ntarget models are well aligned. However, state-of-the-art SD methods typically\nrely on tightly coupled, self-attention-based Transformer decoders, often\naugmented with auxiliary pooling or fusion layers. This coupling makes them\nincreasingly complex and harder to generalize across different models. We\npresent Budget EAGLE (Beagle), the first, to our knowledge,\ncross-attention-based Transformer decoder SD model that achieves performance on\npar with leading self-attention SD models (EAGLE-v2) while eliminating the need\nfor pooling or auxiliary components, simplifying the architecture, improving\ntraining efficiency, and maintaining stable memory usage during training-time\nsimulation. To enable effective training of this novel architecture, we propose\nTwo-Stage Block-Attention Training, a new method that achieves training\nstability and convergence efficiency in block-level attention scenarios.\nExtensive experiments across multiple LLMs and datasets show that Beagle\nachieves competitive inference speedups and higher training efficiency than\nEAGLE-v2, offering a strong alternative for architectures in speculative\ndecoding.",
    "pdf_url": "http://arxiv.org/pdf/2505.24544v1",
    "published": "2025-05-30T12:52:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24543v1",
    "title": "Revisiting the temperature evolution law of the CMB with gaussian processes",
    "authors": [
      "Felipe Avila",
      "Alexander Bonilla Rivera",
      "Rafael C. Nunes",
      "R. F. L. Holanda",
      "Armando Bernui"
    ],
    "abstract": "In this work, we perform a statistical inference of the classical background\nlaw governing the evolution of the temperature of the cosmic microwave\nbackground radiation (CMB), given by $T_{\\rm CMB}(z) = T_0(1 + z)$. To this\nend, we employ Gaussian Process (GP) regression techniques to reconstruct the\ntemperature evolution based on two observational datasets: (i)\nCMB-Sunyaev-Zel'dovich (SZ) cluster measurements and (ii) CMB-interstellar\nmedium (ISM) interaction data. Our analysis reveals interesting results that\nmay suggest potential deviations from the standard temperature-redshift\nrelation, particularly at low redshifts ($z < 0.5$), where discrepancies up to\n$\\sim$2$\\sigma$ are observed. Additionally, we identify a mild but noteworthy\ntension, also at the $\\sim$2$\\sigma$ level, between our GP inferred value of\nthe present-day CMB temperature, $T_{\\rm CMB}(z=0)$, and the precise direct\nmeasurement from the COBE/FIRAS experiment. We also explore possible\nphenomenological implications of our findings, including interpretations\nassociated with possible variations in fundamental constants, such as the\nfine-structure constant $\\alpha$, which could provide a physical explanation\nfor the observed deviations at low redshift.",
    "pdf_url": "http://arxiv.org/pdf/2505.24543v1",
    "published": "2025-05-30T12:50:16+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24542v1",
    "title": "Heavy mesons in an effective quark model with a nonlocal interaction",
    "authors": [
      "A. Friesen",
      "Yu. Kalinovsky",
      "A. Khmelev"
    ],
    "abstract": "We discuss the properties of light and heavy mesons in the framework of a\nmodel with nonlocal interaction. We start from the Bethe-Salpeter equation,\nchoosing the interaction kernel in a nonlocal form with the Gaussian meson\nvertex function. We fix the model parameters using electromagnetic and leptonic\ndecay constants. Within this model, we consider the neutral pion transition\nform factor ${F}_{\\pi\\gamma }$and apply the model to the transition form\nfactors of heavy pseudoscalar mesons $\\eta_c$ and $\\eta_b$. Finally, we\nreproduce the radiative decays of the $\\rho$-meson and heavy quarkonia.",
    "pdf_url": "http://arxiv.org/pdf/2505.24542v1",
    "published": "2025-05-30T12:49:32+00:00",
    "categories": [
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24541v1",
    "title": "Mixpert: Mitigating Multimodal Learning Conflicts with Efficient Mixture-of-Vision-Experts",
    "authors": [
      "Xin He",
      "Xumeng Han",
      "Longhui Wei",
      "Lingxi Xie",
      "Qi Tian"
    ],
    "abstract": "Multimodal large language models (MLLMs) require a nuanced interpretation of\ncomplex image information, typically leveraging a vision encoder to perceive\nvarious visual scenarios. However, relying solely on a single vision encoder to\nhandle diverse task domains proves difficult and inevitably leads to conflicts.\nRecent work enhances data perception by directly integrating multiple\ndomain-specific vision encoders, yet this structure adds complexity and limits\nthe potential for joint optimization. In this paper, we introduce Mixpert, an\nefficient mixture-of-vision-experts architecture that inherits the joint\nlearning advantages from a single vision encoder while being restructured into\na multi-expert paradigm for task-specific fine-tuning across different visual\ntasks. Additionally, we design a dynamic routing mechanism that allocates input\nimages to the most suitable visual expert. Mixpert effectively alleviates\ndomain conflicts encountered by a single vision encoder in multi-task learning\nwith minimal additional computational cost, making it more efficient than\nmultiple encoders. Furthermore, Mixpert integrates seamlessly into any MLLM,\nwith experimental results demonstrating substantial performance gains across\nvarious tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24541v1",
    "published": "2025-05-30T12:48:07+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24540v1",
    "title": "Automatic detection and characterization of random telegraph noise in sCMOS sensors",
    "authors": [
      "Arda Özdoğru",
      "Sergey Karpov",
      "Asen Christov",
      "Stanislav Vítek"
    ],
    "abstract": "Scientific CMOS (sCMOS) image sensors are a modern alternative to typical CCD\ndetectors and are rapidly gaining popularity in observational astronomy due to\ntheir large sizes, low read-out noise, high frame rates, and cheap\nmanufacturing. However, numerous challenges remain in using them due to\nfundamental differences between CCD and CMOS architectures, especially\nconcerning the pixel-dependent and non-Gaussian nature of their read-out noise.\nOne of the main components of the latter is the random telegraph noise (RTN)\ncaused by the charge traps introduced by the defects close to the oxide-silicon\ninterface in sCMOS image sensors, which manifests itself as discrete jumps in a\npixel's output signal, degrading the overall image fidelity. In this work, we\npresent a statistical method to detect and characterize RTN-affected pixels\nusing a series of dark frames. Identifying RTN contaminated pixels enables\npost-processing strategies that mitigate their impact and the development of\nmanufacturing quality metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24540v1",
    "published": "2025-05-30T12:47:24+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24539v3",
    "title": "Localizing Persona Representations in LLMs",
    "authors": [
      "Celia Cintas",
      "Miriam Rateike",
      "Erik Miehling",
      "Elizabeth Daly",
      "Skyler Speakman"
    ],
    "abstract": "We present a study on how and where personas -- defined by distinct sets of\nhuman characteristics, values, and beliefs -- are encoded in the representation\nspace of large language models (LLMs). Using a range of dimension reduction and\npattern recognition methods, we first identify the model layers that show the\ngreatest divergence in encoding these representations. We then analyze the\nactivations within a selected layer to examine how specific personas are\nencoded relative to others, including their shared and distinct embedding\nspaces. We find that, across multiple pre-trained decoder-only LLMs, the\nanalyzed personas show large differences in representation space only within\nthe final third of the decoder layers. We observe overlapping activations for\nspecific ethical perspectives -- such as moral nihilism and utilitarianism --\nsuggesting a degree of polysemy. In contrast, political ideologies like\nconservatism and liberalism appear to be represented in more distinct regions.\nThese findings help to improve our understanding of how LLMs internally\nrepresent information and can inform future efforts in refining the modulation\nof specific human traits in LLM outputs. Warning: This paper includes\npotentially offensive sample statements.",
    "pdf_url": "http://arxiv.org/pdf/2505.24539v3",
    "published": "2025-05-30T12:46:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24538v1",
    "title": "Don't Erase, Inform! Detecting and Contextualizing Harmful Language in Cultural Heritage Collections",
    "authors": [
      "Orfeas Menis Mastromichalakis",
      "Jason Liartis",
      "Kristina Rose",
      "Antoine Isaac",
      "Giorgos Stamou"
    ],
    "abstract": "Cultural Heritage (CH) data hold invaluable knowledge, reflecting the\nhistory, traditions, and identities of societies, and shaping our understanding\nof the past and present. However, many CH collections contain outdated or\noffensive descriptions that reflect historical biases. CH Institutions (CHIs)\nface significant challenges in curating these data due to the vast scale and\ncomplexity of the task. To address this, we develop an AI-powered tool that\ndetects offensive terms in CH metadata and provides contextual insights into\ntheir historical background and contemporary perception. We leverage a\nmultilingual vocabulary co-created with marginalized communities, researchers,\nand CH professionals, along with traditional NLP techniques and Large Language\nModels (LLMs). Available as a standalone web app and integrated with major CH\nplatforms, the tool has processed over 7.9 million records, contextualizing the\ncontentious terms detected in their metadata. Rather than erasing these terms,\nour approach seeks to inform, making biases visible and providing actionable\ninsights for creating more inclusive and accessible CH collections.",
    "pdf_url": "http://arxiv.org/pdf/2505.24538v1",
    "published": "2025-05-30T12:44:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24537v2",
    "title": "ASP Chef grows Mustache to look better",
    "authors": [
      "Mario Alviano",
      "Wolfgang Faber",
      "Luis Angel Rodriguez Reiners"
    ],
    "abstract": "We present ASP Chef Mustache, an extension of ASP Chef that enhances\ntemplate-based rendering of ASP solutions using a logic-less templating system\ninspired by Mustache. Our approach integrates data visualization frameworks\nsuch as Tabulator, Chart.js, and vis.js, enabling interactive representations\nof ASP interpretations as tables, charts, and graphs. Mustache queries in\ntemplates support advanced constructs for formatting, sorting, and multi-stage\nexpansion, facilitating the generation of rich, structured outputs. We\ndemonstrate the power of this framework through a series of use cases,\nincluding data analysis for the Italian VQR, visualization of blocking sets in\ngraphs, and scheduling problems. The result is a versatile tool for bridging\ndeclarative problem solving and modern web-based visual analytics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24537v2",
    "published": "2025-05-30T12:42:10+00:00",
    "categories": [
      "cs.LO",
      "03B70",
      "F.4.1"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24536v1",
    "title": "CHIP: Chameleon Hash-based Irreversible Passport for Robust Deep Model Ownership Verification and Active Usage Control",
    "authors": [
      "Chaohui Xu",
      "Qi Cui",
      "Chip-Hong Chang"
    ],
    "abstract": "The pervasion of large-scale Deep Neural Networks (DNNs) and their enormous\ntraining costs make their intellectual property (IP) protection of paramount\nimportance. Recently introduced passport-based methods attempt to steer DNN\nwatermarking towards strengthening ownership verification against ambiguity\nattacks by modulating the affine parameters of normalization layers.\nUnfortunately, neither watermarking nor passport-based methods provide a\nholistic protection with robust ownership proof, high fidelity, active usage\nauthorization and user traceability for offline access distributed models and\nmulti-user Machine-Learning as a Service (MLaaS) cloud model. In this paper, we\npropose a Chameleon Hash-based Irreversible Passport (CHIP) protection\nframework that utilizes the cryptographic chameleon hash function to achieve\nall these goals. The collision-resistant property of chameleon hash allows for\nstrong model ownership claim upon IP infringement and liable user traceability,\nwhile the trapdoor-collision property enables hashing of multiple user\npassports and licensee certificates to the same immutable signature to realize\nactive usage control. Using the owner passport as an oracle, multiple\nuser-specific triplets, each contains a passport-aware user model, a user\npassport, and a licensee certificate can be created for secure offline\ndistribution. The watermarked master model can also be deployed for MLaaS with\nusage permission verifiable by the provision of any trapdoor-colliding user\npassports. CHIP is extensively evaluated on four datasets and two architectures\nto demonstrate its protection versatility and robustness. Our code is released\nat https://github.com/Dshm212/CHIP.",
    "pdf_url": "http://arxiv.org/pdf/2505.24536v1",
    "published": "2025-05-30T12:41:51+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24535v1",
    "title": "Beyond Linear Steering: Unified Multi-Attribute Control for Language Models",
    "authors": [
      "Narmeen Oozeer",
      "Luke Marks",
      "Fazl Barez",
      "Amirali Abdullah"
    ],
    "abstract": "Controlling multiple behavioral attributes in large language models (LLMs) at\ninference time is a challenging problem due to interference between attributes\nand the limitations of linear steering methods, which assume additive behavior\nin activation space and require per-attribute tuning. We introduce K-Steering,\na unified and flexible approach that trains a single non-linear multi-label\nclassifier on hidden activations and computes intervention directions via\ngradients at inference time. This avoids linearity assumptions, removes the\nneed for storing and tuning separate attribute vectors, and allows dynamic\ncomposition of behaviors without retraining. To evaluate our method, we propose\ntwo new benchmarks, ToneBank and DebateMix, targeting compositional behavioral\ncontrol. Empirical results across 3 model families, validated by both\nactivation-based classifiers and LLM-based judges, demonstrate that K-Steering\noutperforms strong baselines in accurately steering multiple behaviors.",
    "pdf_url": "http://arxiv.org/pdf/2505.24535v1",
    "published": "2025-05-30T12:41:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24534v1",
    "title": "HLSAD: Hodge Laplacian-based Simplicial Anomaly Detection",
    "authors": [
      "Florian Frantzen",
      "Michael T. Schaub"
    ],
    "abstract": "In this paper, we propose HLSAD, a novel method for detecting anomalies in\ntime-evolving simplicial complexes. While traditional graph anomaly detection\ntechniques have been extensively studied, they often fail to capture changes in\nhigher-order interactions that are crucial for identifying complex structural\nanomalies. These higher-order interactions can arise either directly from the\nunderlying data itself or through graph lifting techniques. Our approach\nleverages the spectral properties of Hodge Laplacians of simplicial complexes\nto effectively model multi-way interactions among data points. By incorporating\nhigher-dimensional simplicial structures into our method, our method enhances\nboth detection accuracy and computational efficiency. Through comprehensive\nexperiments on both synthetic and real-world datasets, we demonstrate that our\napproach outperforms existing graph methods in detecting both events and change\npoints.",
    "pdf_url": "http://arxiv.org/pdf/2505.24534v1",
    "published": "2025-05-30T12:41:08+00:00",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24533v1",
    "title": "Directional Non-Commutative Monoidal Structures with Interchange Law via Commutative Generators",
    "authors": [
      "Mahesh Godavarti"
    ],
    "abstract": "We introduce a novel framework consisting of a class of algebraic structures\nthat generalize one-dimensional monoidal systems into higher dimensions by\ndefining per-axis composition operators subject to non-commutativity and a\nglobal interchange law. These structures, defined recursively from a base case\nof vector-matrix pairs, model directional composition in multiple dimensions\nwhile preserving structural coherence through commutative linear operators.\n  We show that the framework that unifies several well-known linear transforms\nin signal processing and data analysis. In this framework, data indices are\nembedded into a composite structure that decomposes into simpler components. We\nshow that classic transforms such as the Discrete Fourier Transform (DFT), the\nWalsh transform, and the Hadamard transform are special cases of our algebraic\nstructure. The framework provides a systematic way to derive these transforms\nby appropriately choosing vector and matrix pairs. By subsuming classical\ntransforms within a common structure, the framework also enables the\ndevelopment of learnable transformations tailored to specific data modalities\nand tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24533v1",
    "published": "2025-05-30T12:40:01+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC",
      "20-XX, 08A02",
      "F.4.1; I.2"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24532v1",
    "title": "DEEPQUESTION: Systematic Generation of Real-World Challenges for Evaluating LLMs Performance",
    "authors": [
      "Ali Khoramfar",
      "Ali Ramezani",
      "Mohammad Mahdi Mohajeri",
      "Mohammad Javad Dousti",
      "Majid Nili Ahmadabadi",
      "Heshaam Faili"
    ],
    "abstract": "LLMs often excel on standard benchmarks but falter on real-world tasks. We\nintroduce DeepQuestion, a scalable automated framework that augments existing\ndatasets based on Bloom's taxonomy and creates novel questions that trace\noriginal solution paths to probe evaluative and creative skills. Extensive\nexperiments across ten open-source and proprietary models, covering both\ngeneral-purpose and reasoning LLMs, reveal substantial performance drops (even\nup to 70% accuracy loss) on higher-order tasks, underscoring persistent gaps in\ndeep reasoning. Our work highlights the need for cognitively diverse benchmarks\nto advance LLM progress. DeepQuestion and related datasets will be released\nupon acceptance of the paper.",
    "pdf_url": "http://arxiv.org/pdf/2505.24532v1",
    "published": "2025-05-30T12:39:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24531v1",
    "title": "Transformers Are Universally Consistent",
    "authors": [
      "Sagar Ghosh",
      "Kushal Bose",
      "Swagatam Das"
    ],
    "abstract": "Despite their central role in the success of foundational models and\nlarge-scale language modeling, the theoretical foundations governing the\noperation of Transformers remain only partially understood. Contemporary\nresearch has largely focused on their representational capacity for language\ncomprehension and their prowess in in-context learning, frequently under\nidealized assumptions such as linearized attention mechanisms. Initially\nconceived to model sequence-to-sequence transformations, a fundamental and\nunresolved question is whether Transformers can robustly perform functional\nregression over sequences of input tokens. This question assumes heightened\nimportance given the inherently non-Euclidean geometry underlying real-world\ndata distributions. In this work, we establish that Transformers equipped with\nsoftmax-based nonlinear attention are uniformly consistent when tasked with\nexecuting Ordinary Least Squares (OLS) regression, provided both the inputs and\noutputs are embedded in hyperbolic space. We derive deterministic upper bounds\non the empirical error which, in the asymptotic regime, decay at a provable\nrate of $\\mathcal{O}(t^{-1/2d})$, where $t$ denotes the number of input tokens\nand $d$ the embedding dimensionality. Notably, our analysis subsumes the\nEuclidean setting as a special case, recovering analogous convergence\nguarantees parameterized by the intrinsic dimensionality of the data manifold.\nThese theoretical insights are corroborated through empirical evaluations on\nreal-world datasets involving both continuous and categorical response\nvariables.",
    "pdf_url": "http://arxiv.org/pdf/2505.24531v1",
    "published": "2025-05-30T12:39:26+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24530v1",
    "title": "A Combinatorial Study of the Fixed Point Index",
    "authors": [
      "Jesús A. Álvarez López",
      "Alejandro O. Majadas-Moure",
      "David Mosquera-Lois"
    ],
    "abstract": "We introduce a theory of integration with respect to the fixed point index,\noffering a substantial improvement over previous approaches based on the\nLefschetz number. This framework eliminates several restrictive assumptions --\nsuch as the need for definability, openness, or f-invariance of subspaces --\nthereby allowing broader applicability. We also present a natural combinatorial\nadaptation of the fixed point index that extends the combinatorial Lefschetz\nnumber. This extension yields new topological and homotopical invariance\nresults and facilitates the integration of real-valued functions with respect\nto fixed points.",
    "pdf_url": "http://arxiv.org/pdf/2505.24530v1",
    "published": "2025-05-30T12:38:53+00:00",
    "categories": [
      "math.AT"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24529v1",
    "title": "Density Ratio Permutation Tests with connections to distributional shifts and conditional two-sample testing",
    "authors": [
      "Alberto Bordino",
      "Thomas B. Berrett"
    ],
    "abstract": "We introduce novel hypothesis tests to allow for statistical inference for\ndensity ratios. More precisely, we introduce the Density Ratio Permutation Test\n(DRPT) for testing $H_0: g \\propto r f$ based on independent data drawn from\ndistributions with densities $f$ and $g$, where the hypothesised density ratio\n$r$ is a fixed function. The proposed test employs an efficient Markov Chain\nMonte Carlo algorithm to draw permutations of the combined dataset according to\na distribution determined by $r$, producing exchangeable versions of the whole\nsample and thereby establishing finite-sample validity. Regarding the test's\nbehaviour under the alternative hypothesis, we begin by demonstrating that if\nthe test statistic is chosen as an Integral Probability Metric (IPM), the DRPT\nis consistent under mild assumptions on the function class that defines the\nIPM. We then narrow our focus to the setting where the function class is a\nReproducing Kernel Hilbert Space, and introduce a generalisation of the\nclassical Maximum Mean Discrepancy (MMD), which we term Shifted-MMD. For\ncontinuous data, assuming that a normalised version of $g - rf$ lies in a\nSobolev ball, we establish the minimax optimality of the DRPT based on the\nShifted-MMD. We further extend our approach to scenarios with an unknown shift\nfactor $r$, estimating it from part of the data using Density Ratio Estimation\ntechniques, and derive Type-I error bounds based on estimation error.\nAdditionally, we demonstrate how the DRPT can be adapted for conditional\ntwo-sample testing, establishing it as a versatile tool for assessing modelling\nassumptions on importance weights, covariate shifts and related scenarios,\nwhich frequently arise in contexts such as transfer learning and causal\ninference. Finally, we validate our theoretical findings through experiments on\nboth simulated and real-world datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.24529v1",
    "published": "2025-05-30T12:38:32+00:00",
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.TH",
      "62G09 62G10"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.00099v2",
    "title": "Finance as Extended Biology: Reciprocity as the Cognitive Substrate of Financial Behavior",
    "authors": [
      "Egil Diau"
    ],
    "abstract": "A central challenge in economics and artificial intelligence is explaining\nhow financial behaviors-such as credit, insurance, and trade-emerge without\nformal institutions. We argue that these functions are not products of\ninstitutional design, but structured extensions of a single behavioral\nsubstrate: reciprocity. Far from being a derived strategy, reciprocity served\nas the foundational logic of early human societies-governing the circulation of\ngoods, regulation of obligation, and maintenance of long-term cooperation well\nbefore markets, money, or formal rules. Trade, commonly regarded as the origin\nof financial systems, is reframed here as the canonical form of reciprocity:\nsimultaneous, symmetric, and partner-contingent. Building on this logic, we\nreconstruct four core financial functions-credit, insurance, token exchange,\nand investment-as expressions of the same underlying principle under varying\nconditions. By grounding financial behavior in minimal, simulateable dynamics\nof reciprocal interaction, this framework shifts the focus from institutional\nengineering to behavioral computation-offering a new foundation for modeling\ndecentralized financial behavior in both human and artificial agents.",
    "pdf_url": "http://arxiv.org/pdf/2506.00099v2",
    "published": "2025-05-30T12:37:52+00:00",
    "categories": [
      "cs.CY",
      "cs.MA",
      "physics.soc-ph"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.03186v1",
    "title": "Lightweight Convolutional Neural Networks for Retinal Disease Classification",
    "authors": [
      "Duaa Kareem Qasim",
      "Sabah Abdulazeez Jebur",
      "Lafta Raheem Ali",
      "Abdul Jalil M. Khalaf",
      "Abir Jaafar Hussain"
    ],
    "abstract": "Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH)\nsignificantly impact vision and affect millions worldwide. Early detection is\ncrucial, as DR, a complication of diabetes, damages retinal blood vessels,\npotentially leading to blindness, while MH disrupts central vision, affecting\ntasks like reading and facial recognition. This paper employed two lightweight\nand efficient Convolution Neural Network architectures, MobileNet and\nNASNetMobile, for the classification of Normal, DR, and MH retinal images. The\nmodels were trained on the RFMiD dataset, consisting of 3,200 fundus images,\nafter undergoing preprocessing steps such as resizing, normalization, and\naugmentation. To address data scarcity, this study leveraged transfer learning\nand data augmentation techniques, enhancing model generalization and\nperformance. The experimental results demonstrate that MobileNetV2 achieved the\nhighest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5%\naccuracy. These findings highlight the effectiveness of CNNs in retinal disease\nclassification, providing a foundation for AI-assisted ophthalmic diagnosis and\nearly intervention.",
    "pdf_url": "http://arxiv.org/pdf/2506.03186v1",
    "published": "2025-05-30T12:36:45+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24528v1",
    "title": "Geospatial Foundation Models to Enable Progress on Sustainable Development Goals",
    "authors": [
      "Pedram Ghamisi",
      "Weikang Yu",
      "Xiaokang Zhang",
      "Aldino Rizaldy",
      "Jian Wang",
      "Chufeng Zhou",
      "Richard Gloaguen",
      "Gustau Camps-Valls"
    ],
    "abstract": "Foundation Models (FMs) are large-scale, pre-trained AI systems that have\nrevolutionized natural language processing and computer vision, and are now\nadvancing geospatial analysis and Earth Observation (EO). They promise improved\ngeneralization across tasks, scalability, and efficient adaptation with minimal\nlabeled data. However, despite the rapid proliferation of geospatial FMs, their\nreal-world utility and alignment with global sustainability goals remain\nunderexplored. We introduce SustainFM, a comprehensive benchmarking framework\ngrounded in the 17 Sustainable Development Goals with extremely diverse tasks\nranging from asset wealth prediction to environmental hazard detection. This\nstudy provides a rigorous, interdisciplinary assessment of geospatial FMs and\noffers critical insights into their role in attaining sustainability goals. Our\nfindings show: (1) While not universally superior, FMs often outperform\ntraditional approaches across diverse tasks and datasets. (2) Evaluating FMs\nshould go beyond accuracy to include transferability, generalization, and\nenergy efficiency as key criteria for their responsible use. (3) FMs enable\nscalable, SDG-grounded solutions, offering broad utility for tackling complex\nsustainability challenges. Critically, we advocate for a paradigm shift from\nmodel-centric development to impact-driven deployment, and emphasize metrics\nsuch as energy efficiency, robustness to domain shifts, and ethical\nconsiderations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24528v1",
    "published": "2025-05-30T12:36:38+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24527v1",
    "title": "Optimal Density Functions for Weighted Convolution in Learning Models",
    "authors": [
      "Simone Cammarasana",
      "Giuseppe Patanè"
    ],
    "abstract": "The paper introduces the weighted convolution, a novel approach to the\nconvolution for signals defined on regular grids (e.g., 2D images) through the\napplication of an optimal density function to scale the contribution of\nneighbouring pixels based on their distance from the central pixel. This choice\ndiffers from the traditional uniform convolution, which treats all neighbouring\npixels equally. Our weighted convolution can be applied to convolutional neural\nnetwork problems to improve the approximation accuracy. Given a convolutional\nnetwork, we define a framework to compute the optimal density function through\na minimisation model. The framework separates the optimisation of the\nconvolutional kernel weights (using stochastic gradient descent) from the\noptimisation of the density function (using DIRECT-L). Experimental results on\na learning model for an image-to-image task (e.g., image denoising) show that\nthe weighted convolution significantly reduces the loss (up to 53% improvement)\nand increases the test accuracy compared to standard convolution. While this\nmethod increases execution time by 11%, it is robust across several\nhyperparameters of the learning model. Future work will apply the weighted\nconvolution to real-case 2D and 3D image convolutional learning problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24527v1",
    "published": "2025-05-30T12:36:36+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "42A85"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24526v1",
    "title": "Spaces with the maximal projection constant revisited",
    "authors": [
      "Tomasz Kobos"
    ],
    "abstract": "Let $n \\geq 2$ be an integer such that an equiangular set of vectors $w_1,\n\\ldots, w_d$ of the maximal possible cardinality (in relation to the the\ngeneral Gerzon upper bound) exists in $\\mathbb{K}^n$, where\n$\\mathbb{K}=\\mathbb{R}$ or $\\mathbb{K}=\\mathbb{C}$ (i.e. $d=\\frac{n(n+1)}{2}$\nin the real and $d=n^2$ in the complex case). We provide a complete\ncharacterization of $n$-dimensional normed spaces $X$ having a maximal absolute\nprojection constant among all $n$-dimensional normed spaces over $\\mathbb{K}$.\nThe characterization states that $X$ has a maximal projection constant if and\nonly if it is isometric to a space, for which the unit ball of the dual space\nis contained between the absolutely convex hull of the vectors $w_1, \\ldots,\nw_d$ and an appropriately rescaled zonotope generated by the same vectors. As a\nconsequence, we obtain that in the considered situations, the case of $n=2$ and\n$\\mathbb{K}=\\mathbb{R}$ is the only one, where there is a unique norm in\n$\\mathbb{K}^n$ (up to an isometry) with the maximal projection constant. In\nthis case, the unit ball is an affine regular hexagon in $\\mathbb{R}^2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24526v1",
    "published": "2025-05-30T12:35:15+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24525v1",
    "title": "Limited-Resource Adapters Are Regularizers, Not Linguists",
    "authors": [
      "Marcell Fekete",
      "Nathaniel R. Robinson",
      "Ernests Lavrinovics",
      "E. Djeride Jean-Baptiste",
      "Raj Dabre",
      "Johannes Bjerva",
      "Heather Lent"
    ],
    "abstract": "Cross-lingual transfer from related high-resource languages is a\nwell-established strategy to enhance low-resource language technologies. Prior\nwork has shown that adapters show promise for, e.g., improving low-resource\nmachine translation (MT). In this work, we investigate an adapter souping\nmethod combined with cross-attention fine-tuning of a pre-trained MT model to\nleverage language transfer for three low-resource Creole languages, which\nexhibit relatedness to different language groups across distinct linguistic\ndimensions. Our approach improves performance substantially over baselines.\nHowever, we find that linguistic relatedness -- or even a lack thereof -- does\nnot covary meaningfully with adapter performance. Surprisingly, our\ncross-attention fine-tuning approach appears equally effective with randomly\ninitialized adapters, implying that the benefit of adapters in this setting\nlies in parameter regularization, and not in meaningful information transfer.\nWe provide analysis supporting this regularization hypothesis. Our findings\nunderscore the reality that neural language processing involves many success\nfactors, and that not all neural methods leverage linguistic knowledge in\nintuitive ways.",
    "pdf_url": "http://arxiv.org/pdf/2505.24525v1",
    "published": "2025-05-30T12:34:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24524v1",
    "title": "A new addition to the zoo of isolated symplectic singularities",
    "authors": [
      "Callum Berry"
    ],
    "abstract": "We give details of a new isolated symplectic singularity found in an affine\nchart in a crepant partial resolution of $\\mathbb{C}^4/G_5$, which is\n4-dimensional, isolated, and locally simply-connected. We distinguish the new\nsingularity among all known such by the fact that the projective tangent cone\nat the singularity is non-reduced. We also find all 12 of its\n$\\mathbb{Q}$-factorial terminalisations, in the process finding 24 for the\nquotient singularity $\\mathbb{C}^4/G_5$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24524v1",
    "published": "2025-05-30T12:33:52+00:00",
    "categories": [
      "math.AG",
      "math.RT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24523v1",
    "title": "Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors",
    "authors": [
      "Andrea Pedrotti",
      "Michele Papucci",
      "Cristiano Ciaccio",
      "Alessio Miaschi",
      "Giovanni Puccetti",
      "Felice Dell'Orletta",
      "Andrea Esuli"
    ],
    "abstract": "Recent advancements in Generative AI and Large Language Models (LLMs) have\nenabled the creation of highly realistic synthetic content, raising concerns\nabout the potential for malicious use, such as misinformation and manipulation.\nMoreover, detecting Machine-Generated Text (MGT) remains challenging due to the\nlack of robust benchmarks that assess generalization to real-world scenarios.\nIn this work, we present a pipeline to test the resilience of state-of-the-art\nMGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed\nadversarial attacks. To challenge the detectors, we fine-tune language models\nusing Direct Preference Optimization (DPO) to shift the MGT style toward\nhuman-written text (HWT). This exploits the detectors' reliance on stylistic\nclues, making new generations more challenging to detect. Additionally, we\nanalyze the linguistic shifts induced by the alignment and which features are\nused by detectors to detect MGT texts. Our results show that detectors can be\neasily fooled with relatively few examples, resulting in a significant drop in\ndetection performance. This highlights the importance of improving detection\nmethods and making them robust to unseen in-domain texts.",
    "pdf_url": "http://arxiv.org/pdf/2505.24523v1",
    "published": "2025-05-30T12:33:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24522v1",
    "title": "Chemical tagging of tidal tail star candidates of NGC 6362",
    "authors": [
      "Andrés E. Piatti"
    ],
    "abstract": "The inner Milky Way disk globular cluster NGC~6362 appears to exhibit tidal\ntails composed of stars that have proper motions and positions in the\ncolor-magnitude diagram similar to those of cluster stars. Because recent\nresults seem also to show that these stars are distributed across the regions\nleast affected by interstellar absorption and reproduce the observed composite\nstar field density map, we carried out a detailed spectroscopic analysis of a\nnumber of chemical element abundances of tidal tail star candidates in order to\ninvestigate the relationship of them with NGC~6362. From European Southern\nObservatory's VLT@FLAMES spectra we found that the red giant branch stars\nselected as cluster's tidal tail stars do not have overall metallicities nor\nabundances of Mg, Ca, Sc, Ti, Cr, Ni and Ba similar to the cluster's ones.\nMoreover, they are mainly alike to stars that belong to the Milky Way thick\ndisk, some of them could be part of the thin disk and a minor percentage could\nbelong to the Milky Way halo star population. On the other hand, since the\nresulting radial velocities do not exhibit a distribution function similar to\nthat of cluster's stars, we concluded that looking for kinematic properties\nsimilar to those of the cluster would not seem to be an approach for selecting\ncluster's tidal tail stars as suitable as previously thought.",
    "pdf_url": "http://arxiv.org/pdf/2505.24522v1",
    "published": "2025-05-30T12:33:00+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24521v1",
    "title": "UniGeo: Taming Video Diffusion for Unified Consistent Geometry Estimation",
    "authors": [
      "Yang-Tian Sun",
      "Xin Yu",
      "Zehuan Huang",
      "Yi-Hua Huang",
      "Yuan-Chen Guo",
      "Ziyi Yang",
      "Yan-Pei Cao",
      "Xiaojuan Qi"
    ],
    "abstract": "Recently, methods leveraging diffusion model priors to assist monocular\ngeometric estimation (e.g., depth and normal) have gained significant attention\ndue to their strong generalization ability. However, most existing works focus\non estimating geometric properties within the camera coordinate system of\nindividual video frames, neglecting the inherent ability of diffusion models to\ndetermine inter-frame correspondence. In this work, we demonstrate that,\nthrough appropriate design and fine-tuning, the intrinsic consistency of video\ngeneration models can be effectively harnessed for consistent geometric\nestimation. Specifically, we 1) select geometric attributes in the global\ncoordinate system that share the same correspondence with video frames as the\nprediction targets, 2) introduce a novel and efficient conditioning method by\nreusing positional encodings, and 3) enhance performance through joint training\non multiple geometric attributes that share the same correspondence. Our\nresults achieve superior performance in predicting global geometric attributes\nin videos and can be directly applied to reconstruction tasks. Even when\ntrained solely on static video data, our approach exhibits the potential to\ngeneralize to dynamic video scenes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24521v1",
    "published": "2025-05-30T12:31:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24520v1",
    "title": "Strain-induced manipulation of non-collinear antiferromagnets",
    "authors": [
      "Mithuss Tharmalingam",
      "Feodor Svetlanov Konomaev",
      "Kjetil M. D. Hals"
    ],
    "abstract": "In recent years, there has been growing interest in harnessing non-collinear\nantiferromagnets (NCAFMs) for applications in antiferromagnetic spintronics. A\nkey requirement for their practical use is the ability to control the spin\norder in a reliable and tunable manner. In this work, we investigate how the\nspin order in kagome antiferromagnets -- an important class of NCAFMs -- can be\nmanipulated via strain. Starting from a microscopic spin Hamiltonian, we derive\nan effective action for the kagome antiferromagnet that captures the coupling\nbetween the spin order and the system's strain tensor. At the microscopic\nlevel, this coupling arises from strain-induced modifications of the\nDzyaloshinskii-Moriya and exchange interactions. Using this effective\ndescription, we explore two strain-driven phenomena: (1) strain-induced\nswitching of the antiferromagnetic spin order and (2) the piezomagnetic\nresponse. We numerically show that strain facilitates thermally assisted\nswitching between spin configurations of opposite chirality. Specifically, we\nfind that uniform tensile and compressive strain govern both the average\nswitching time and the preferred switching direction between chiral states.\nFurthermore, we demonstrate that strain induces a net magnetization and provide\nan experimentally testable prediction of this effect for a typical NCAFM. Our\nresults provide a theoretical framework for modeling strain-induced\nmanipulation of kagome antiferromagnets, underscoring strain as a promising\nroute for functional control of NCAFMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24520v1",
    "published": "2025-05-30T12:31:11+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24519v1",
    "title": "AMIA: Automatic Masking and Joint Intention Analysis Makes LVLMs Robust Jailbreak Defenders",
    "authors": [
      "Yuqi Zhang",
      "Yuchun Miao",
      "Zuchao Li",
      "Liang Ding"
    ],
    "abstract": "We introduce AMIA, a lightweight, inference-only defense for Large\nVision-Language Models (LVLMs) that (1) Automatically Masks a small set of\ntext-irrelevant image patches to disrupt adversarial perturbations, and (2)\nconducts joint Intention Analysis to uncover and mitigate hidden harmful\nintents before response generation. Without any retraining, AMIA improves\ndefense success rates across diverse LVLMs and jailbreak benchmarks from an\naverage of 52.4% to 81.7%, preserves general utility with only a 2% average\naccuracy drop, and incurs only modest inference overhead. Ablation confirms\nboth masking and intention analysis are essential for a robust safety-utility\ntrade-off.",
    "pdf_url": "http://arxiv.org/pdf/2505.24519v1",
    "published": "2025-05-30T12:30:50+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24518v1",
    "title": "ARECHO: Autoregressive Evaluation via Chain-Based Hypothesis Optimization for Speech Multi-Metric Estimation",
    "authors": [
      "Jiatong Shi",
      "Yifan Cheng",
      "Bo-Hao Su",
      "Hye-jin Shim",
      "Jinchuan Tian",
      "Samuele Cornell",
      "Yiwen Zhao",
      "Siddhant Arora",
      "Shinji Watanabe"
    ],
    "abstract": "Speech signal analysis poses significant challenges, particularly in tasks\nsuch as speech quality evaluation and profiling, where the goal is to predict\nmultiple perceptual and objective metrics. For instance, metrics like PESQ\n(Perceptual Evaluation of Speech Quality), STOI (Short-Time Objective\nIntelligibility), and MOS (Mean Opinion Score) each capture different aspects\nof speech quality. However, these metrics often have different scales,\nassumptions, and dependencies, making joint estimation non-trivial. To address\nthese issues, we introduce ARECHO (Autoregressive Evaluation via Chain-based\nHypothesis Optimization), a chain-based, versatile evaluation system for speech\nassessment grounded in autoregressive dependency modeling. ARECHO is\ndistinguished by three key innovations: (1) a comprehensive speech information\ntokenization pipeline; (2) a dynamic classifier chain that explicitly captures\ninter-metric dependencies; and (3) a two-step confidence-oriented decoding\nalgorithm that enhances inference reliability. Experiments demonstrate that\nARECHO significantly outperforms the baseline framework across diverse\nevaluation scenarios, including enhanced speech analysis, speech generation\nevaluation, and noisy speech evaluation. Furthermore, its dynamic dependency\nmodeling improves interpretability by capturing inter-metric relationships.",
    "pdf_url": "http://arxiv.org/pdf/2505.24518v1",
    "published": "2025-05-30T12:30:04+00:00",
    "categories": [
      "cs.SD",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24517v1",
    "title": "un$^2$CLIP: Improving CLIP's Visual Detail Capturing Ability via Inverting unCLIP",
    "authors": [
      "Yinqi Li",
      "Jiahe Zhao",
      "Hong Chang",
      "Ruibing Hou",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has become a foundation model\nand has been applied to various vision and multimodal tasks. However, recent\nworks indicate that CLIP falls short in distinguishing detailed differences in\nimages and shows suboptimal performance on dense-prediction and vision-centric\nmultimodal tasks. Therefore, this work focuses on improving existing CLIP\nmodels, aiming to capture as many visual details in images as possible. We find\nthat a specific type of generative models, unCLIP, provides a suitable\nframework for achieving our goal. Specifically, unCLIP trains an image\ngenerator conditioned on the CLIP image embedding. In other words, it inverts\nthe CLIP image encoder. Compared to discriminative models like CLIP, generative\nmodels are better at capturing image details because they are trained to learn\nthe data distribution of images. Additionally, the conditional input space of\nunCLIP aligns with CLIP's original image-text embedding space. Therefore, we\npropose to invert unCLIP (dubbed un$^2$CLIP) to improve the CLIP model. In this\nway, the improved image encoder can gain unCLIP's visual detail capturing\nability while preserving its alignment with the original text encoder\nsimultaneously. We evaluate our improved CLIP across various tasks to which\nCLIP has been applied, including the challenging MMVP-VLM benchmark, the\ndense-prediction open-vocabulary segmentation task, and multimodal large\nlanguage model tasks. Experiments show that un$^2$CLIP significantly improves\nthe original CLIP and previous CLIP improvement methods. Code and models will\nbe available at https://github.com/LiYinqi/un2CLIP.",
    "pdf_url": "http://arxiv.org/pdf/2505.24517v1",
    "published": "2025-05-30T12:29:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24516v1",
    "title": "A General Version of Carathéodory's Existence and Uniqueness Theorem",
    "authors": [
      "Paulo M. de Carvalho-Neto",
      "Cícero L. Frota",
      "Pedro G. P. Torelli"
    ],
    "abstract": "In this paper, we establish a general version of Carath\\'{e}odory's existence\nand uniqueness theorem for a semilinear system of integro-differential\nequations arising from differential equations with distinct orders of Caputo\nfractional derivative. The main result of our work demonstrates that the\nintegrability order of the Carath\\'{e}odory function $f$ must be at least\ngreater than the maximum of the reciprocals of all differentiation orders in\nthe system; otherwise, even the existence of a solution cannot be guaranteed.",
    "pdf_url": "http://arxiv.org/pdf/2505.24516v1",
    "published": "2025-05-30T12:29:17+00:00",
    "categories": [
      "math.CA",
      "math.FA",
      "26A33, 34A08, 34A12"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24515v1",
    "title": "Structure and dynamics of erupting solar prominences using the Rolling Hough Transform: Toward a feature-oriented classification",
    "authors": [
      "Harry Birch",
      "Stéphane Régnier"
    ],
    "abstract": "The classification of solar prominences has proven to be challenging due to\ntheir diverse morphologies and dynamical behaviour. Complexity is heightened\nwhen considering eruptive prominences, where the dynamics demand methods\ncapable of capturing detailed structural information. While there exists a\nrange of line-of-sight (LOS) and plane-of-sky (POS) techniques which have\nadvanced our understanding of prominence motions, they are subject to\nlimitations, emphasising the need for effective methods of extracting\nstructural information from prominence dynamics. We present a proof-ofconcept\nfor the spatial Rolling Hough Transform (RHT) algorithm, which identifies\nfinescale structural orientation in the POS, applied to prominence structure\nand dynamics. We demonstrate the RHT approach using two contrasting prominence\ndynamics events using SDO/AIA 304 \\r{A} observations: (1) a quiet-Sun eruption,\n(2) activation (swirl) of a polar-crown prominence. By analysing the light\ncurves and movies from each event, we divide the events into distinct dynamical\nphases: from slow rise to drainage. The spatial RHT method enables us to\nextract structural information and localised dynamics for both events and the\ndifferent evolution phases. We develop a classification to label the\nprominences as either radially or tangentially oriented structures. The\nquiet-Sun eruption has a predominately tangential structure in the slow-rise\nphase, but displays greater radial features during/after the eruption. The\npolar-swirl activation initially shows a strong radial contribution, which\ndiminishes as more tangential structures appear during/after the activation.\nOur results demonstrate the successful application of the spatial RHT to\nprominences, leading to the classification of individual prominences and an\ninsight into their dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24515v1",
    "published": "2025-05-30T12:26:10+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24514v1",
    "title": "Digital twins enable full-reference quality assessment of photoacoustic image reconstructions",
    "authors": [
      "Janek Gröhl",
      "Leonid Kunyansky",
      "Jenni Poimala",
      "Thomas R. Else",
      "Francesca Di Cecio",
      "Sarah E. Bohndiek",
      "Ben T. Cox",
      "Andreas Hauptmann"
    ],
    "abstract": "Quantitative comparison of the quality of photoacoustic image reconstruction\nalgorithms remains a major challenge. No-reference image quality measures are\noften inadequate, but full-reference measures require access to an ideal\nreference image. While the ground truth is known in simulations, it is unknown\nin vivo, or in phantom studies, as the reference depends on both the phantom\nproperties and the imaging system. We tackle this problem by using numerical\ndigital twins of tissue-mimicking phantoms and the imaging system to perform a\nquantitative calibration to reduce the simulation gap. The contributions of\nthis paper are two-fold: First, we use this digital-twin framework to compare\nmultiple state-of-the-art reconstruction algorithms. Second, among these is a\nFourier transform-based reconstruction algorithm for circular detection\ngeometries, which we test on experimental data for the first time. Our results\ndemonstrate the usefulness of digital phantom twins by enabling assessment of\nthe accuracy of the numerical forward model and enabling comparison of image\nreconstruction schemes with full-reference image quality assessment. We show\nthat the Fourier transform-based algorithm yields results comparable to those\nof iterative time reversal, but at a lower computational cost. All data and\ncode are publicly available on Zenodo: https://doi.org/10.5281/zenodo.15388429.",
    "pdf_url": "http://arxiv.org/pdf/2505.24514v1",
    "published": "2025-05-30T12:25:36+00:00",
    "categories": [
      "physics.med-ph",
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24513v1",
    "title": "Airborne Neural Network",
    "authors": [
      "Paritosh Ranjan",
      "Surajit Majumder",
      "Prodip Roy"
    ],
    "abstract": "Deep Learning, driven by neural networks, has led to groundbreaking\nadvancements in Artificial Intelligence by enabling systems to learn and adapt\nlike the human brain. These models have achieved remarkable results,\nparticularly in data-intensive domains, supported by massive computational\ninfrastructure. However, deploying such systems in Aerospace, where real time\ndata processing and ultra low latency are critical, remains a challenge due to\ninfrastructure limitations. This paper proposes a novel concept: the Airborne\nNeural Network a distributed architecture where multiple airborne devices each\nhost a subset of neural network neurons. These devices compute collaboratively,\nguided by an airborne network controller and layer specific controllers,\nenabling real-time learning and inference during flight. This approach has the\npotential to revolutionize Aerospace applications, including airborne air\ntraffic control, real-time weather and geographical predictions, and dynamic\ngeospatial data processing. By enabling large-scale neural network operations\nin airborne environments, this work lays the foundation for the next generation\nof AI powered Aerospace systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24513v1",
    "published": "2025-05-30T12:22:02+00:00",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24512v1",
    "title": "Dynamical thermal near-field routing with the non-reciprocal Weyl semi-metal Co$_3$Sn$_2$S$_2$",
    "authors": [
      "A. Naeimi",
      "S. -A. Biehs"
    ],
    "abstract": "We demonstrate theoretically the non-reciprocal heating dynamics of two\nnanoparticles in the vicinity of a substrate all made of the ferromagnetic Weyl\nsemi-metal Co$_3$Sn$_2$S$_2$. We show that the thermal routing effect is due to\na spin-spin coupling mechanism between the nanoparticle resonances and the\nnon-reciprocal surface modes of the substrate. Our numerical results indicate\nthat the non-reciprocal heating effect is on the order of 22.5% of the applied\ntemperature differences. This strong rounting effect paves the way for first\nexperimental realizations employing Weyl semi-metals and applications in\nnanoscale thermal management.",
    "pdf_url": "http://arxiv.org/pdf/2505.24512v1",
    "published": "2025-05-30T12:20:22+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.00098v2",
    "title": "Interactive Imitation Learning for Dexterous Robotic Manipulation: Challenges and Perspectives -- A Survey",
    "authors": [
      "Edgar Welte",
      "Rania Rayyes"
    ],
    "abstract": "Dexterous manipulation is a crucial yet highly complex challenge in humanoid\nrobotics, demanding precise, adaptable, and sample-efficient learning methods.\nAs humanoid robots are usually designed to operate in human-centric\nenvironments and interact with everyday objects, mastering dexterous\nmanipulation is critical for real-world deployment. Traditional approaches,\nsuch as reinforcement learning and imitation learning, have made significant\nstrides, but they often struggle due to the unique challenges of real-world\ndexterous manipulation, including high-dimensional control, limited training\ndata, and covariate shift. This survey provides a comprehensive overview of\nthese challenges and reviews existing learning-based methods for real-world\ndexterous manipulation, spanning imitation learning, reinforcement learning,\nand hybrid approaches. A promising yet underexplored direction is interactive\nimitation learning, where human feedback actively refines a robots behavior\nduring training. While interactive imitation learning has shown success in\nvarious robotic tasks, its application to dexterous manipulation remains\nlimited. To address this gap, we examine current interactive imitation learning\ntechniques applied to other robotic tasks and discuss how these methods can be\nadapted to enhance dexterous manipulation. By synthesizing state-of-the-art\nresearch, this paper highlights key challenges, identifies gaps in current\nmethodologies, and outlines potential directions for leveraging interactive\nimitation learning to improve dexterous robotic skills.",
    "pdf_url": "http://arxiv.org/pdf/2506.00098v2",
    "published": "2025-05-30T12:19:32+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24511v2",
    "title": "Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting",
    "authors": [
      "Jiahao Wang",
      "Mingyue Cheng",
      "Qi Liu"
    ],
    "abstract": "Time series forecasting (TSF) is a fundamental and widely studied task,\nspanning methods from classical statistical approaches to modern deep learning\nand multimodal language modeling. Despite their effectiveness, these methods\noften follow a fast thinking paradigm emphasizing pattern extraction and direct\nvalue mapping, while overlooking explicit reasoning over temporal dynamics and\ncontextual dependencies. Meanwhile, emerging slow-thinking LLMs (e.g.,\nChatGPT-o1, DeepSeek-R1) have demonstrated impressive multi-step reasoning\ncapabilities across diverse domains, suggesting a new opportunity for reframing\nTSF as a structured reasoning task. This motivates a key question: can\nslow-thinking LLMs effectively reason over temporal patterns to support time\nseries forecasting, even in zero-shot manner? To investigate this, in this\npaper, we propose TimeReasoner, an extensive empirical study that formulates\nTSF as a conditional reasoning task. We design a series of prompting strategies\nto elicit inference-time reasoning from pretrained slow-thinking LLMs and\nevaluate their performance across diverse TSF benchmarks. Our findings reveal\nthat slow-thinking LLMs exhibit non-trivial zero-shot forecasting capabilities,\nespecially in capturing high-level trends and contextual shifts. While\npreliminary, our study surfaces important insights into the reasoning behaviors\nof LLMs in temporal domains highlighting both their potential and limitations.\nWe hope this work catalyzes further research into reasoning-based forecasting\nparadigms and paves the way toward more interpretable and generalizable TSF\nframeworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24511v2",
    "published": "2025-05-30T12:19:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24510v1",
    "title": "How can AI reduce wrist injuries in the workplace?",
    "authors": [
      "Roberto F. Pitzalis",
      "Nicholas Cartocci",
      "Christian Di Natali",
      "Darwin G. Caldwell",
      "Giovanni Berselli",
      "Jesús Ortiz"
    ],
    "abstract": "This paper explores the development of a control and sensor strategy for an\nindustrial wearable wrist exoskeleton by classifying and predicting workers'\nactions. The study evaluates the correlation between exerted force and effort\nintensity, along with sensor strategy optimization, for designing purposes.\nUsing data from six healthy subjects in a manufacturing plant, this paper\npresents EMG-based models for wrist motion classification and force prediction.\nWrist motion recognition is achieved through a pattern recognition algorithm\ndeveloped with surface EMG data from an 8-channel EMG sensor (Myo Armband);\nwhile a force regression model uses wrist and hand force measurements from a\ncommercial handheld dynamometer (Vernier GoDirect Hand Dynamometer). This\ncontrol strategy forms the foundation for a streamlined exoskeleton\narchitecture designed for industrial applications, focusing on simplicity,\nreduced costs, and minimal sensor use while ensuring reliable and effective\nassistance.",
    "pdf_url": "http://arxiv.org/pdf/2505.24510v1",
    "published": "2025-05-30T12:18:05+00:00",
    "categories": [
      "eess.SP",
      "cs.RO"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24509v1",
    "title": "Bi-SamplerZ: A Hardware-Efficient Gaussian Sampler Architecture for Quantum-Resistant Falcon Signatures",
    "authors": [
      "Binke Zhao",
      "Ghada Alsuhi",
      "Hani Saleh",
      "Baker Mohammad"
    ],
    "abstract": "FALCON is a standardized quantum-resistant digital signature scheme that\noffers advantages over other schemes, but features more complex signature\ngeneration process. This paper presents Bi-Samplerz, a fully\nhardware-implemented, high-efficiency dual-path discrete Gaussian sampler\ndesigned to accelerate Falcon signature generation. Observing that the SamplerZ\nsubroutine is consistently invoked in pairs during each signature generation,\nwe propose a dual-datapath architecture capable of generating two sampling\nresults simultaneously. To make the best use of coefficient correlation and the\ninherent properties of rejection sampling, we introduce an assistance mechanism\nthat enables effective collaboration between the two datapaths, rather than\nsimply duplicating the sampling process. Additionally, we incorporate several\narchitectural optimizations over existing designs to further enhance speed,\narea efficiency, and resource utilization. Experimental results demonstrate\nthat Bi-SamplerZ achieves the lowest sampling latency to date among existing\ndesigns, benefiting from fine-grained pipeline optimization and efficient\ncontrol coordination. Compared with the state-of-the-art full hardware\nimplementations, Bi-SamplerZ reduces the sampling cycle count by 54.1\\% while\nincurring only a moderate increase in hardware resource consumption, thereby\nachieving the best-known area-time product (ATP) for fully hardware-based\nsampler designs. In addition, to facilitate comparison with existing works, we\nprovide both ASIC and FPGA implementations. Together, these results highlight\nthe suitability of Bi-SamplerZ as a high-performance sampling engine in\nstandardized post-quantum cryptographic systems such as Falcon.",
    "pdf_url": "http://arxiv.org/pdf/2505.24509v1",
    "published": "2025-05-30T12:17:39+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00097v1",
    "title": "Entanglement for Pattern Learning in Temporal Data with Logarithmic Complexity: Benchmarking on IBM Quantum Hardware",
    "authors": [
      "Mostafizur Rahaman Laskar",
      "Richa Goel"
    ],
    "abstract": "Time series forecasting is foundational in scientific and technological\ndomains, from climate modelling to molecular dynamics. Classical approaches\nhave significantly advanced sequential prediction, including autoregressive\nmodels and deep learning architectures such as temporal convolutional networks\n(TCNs) and Transformers. Yet, they remain resource-intensive and often scale\npoorly in data-limited or hardware-constrained settings. We propose a\nquantum-native time series forecasting framework that harnesses\nentanglement-based parameterized quantum circuits to learn temporal\ndependencies. Our Quantum Time Series (QTS) model encodes normalized sequential\ndata into single-qubit rotations and embeds temporal structure through\nstructured entanglement patterns. This design considers predictive performance\nwith logarithmic complexity in training data and parameter count. We benchmark\nQTS against classical models on synthetic and real-world datasets, including\ngeopotential height fields used in numerical weather prediction. Experiments on\nthe noisy backend and real IBM quantum hardware demonstrate that QTS can\ncapture temporal patterns using fewer data points. Hardware benchmarking\nresults establish quantum entanglement as a practical computational resource\nfor temporal modelling, with potential near-term applications in nano-scale\nsystems, quantum sensor networks, and other forecasting scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.00097v1",
    "published": "2025-05-30T12:16:08+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.03185v1",
    "title": "DLiPath: A Benchmark for the Comprehensive Assessment of Donor Liver Based on Histopathological Image Dataset",
    "authors": [
      "Liangrui Pan",
      "Xingchen Li",
      "Zhongyi Chen",
      "Ling Chu",
      "Shaoliang Peng"
    ],
    "abstract": "Pathologists comprehensive evaluation of donor liver biopsies provides\ncrucial information for accepting or discarding potential grafts. However,\nrapidly and accurately obtaining these assessments intraoperatively poses a\nsignificant challenge for pathologists. Features in donor liver biopsies, such\nas portal tract fibrosis, total steatosis, macrovesicular steatosis, and\nhepatocellular ballooning are correlated with transplant outcomes, yet\nquantifying these indicators suffers from substantial inter- and intra-observer\nvariability. To address this, we introduce DLiPath, the first benchmark for\ncomprehensive donor liver assessment based on a histopathology image dataset.\nWe collected and publicly released 636 whole slide images from 304 donor liver\npatients at the Department of Pathology, the Third Xiangya Hospital, with\nexpert annotations for key pathological features (including cholestasis, portal\ntract fibrosis, portal inflammation, total steatosis, macrovesicular steatosis,\nand hepatocellular ballooning). We selected nine state-of-the-art\nmultiple-instance learning (MIL) models based on the DLiPath dataset as\nbaselines for extensive comparative analysis. The experimental results\ndemonstrate that several MIL models achieve high accuracy across donor liver\nassessment indicators on DLiPath, charting a clear course for future automated\nand intelligent donor liver assessment research. Data and code are available at\nhttps://github.com/panliangrui/ACM_MM_2025.",
    "pdf_url": "http://arxiv.org/pdf/2506.03185v1",
    "published": "2025-05-30T12:13:00+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24508v1",
    "title": "Laser-driven ion acceleration in long-lived optically shaped gaseous targets enhanced by magnetic vortices",
    "authors": [
      "I. Tazes",
      "S. Passalidis",
      "G. Andrianaki",
      "A. Skoulakis",
      "C. Karvounis",
      "D. Mancelli",
      "J. Pasley",
      "E. Kaselouris",
      "I. Fitilis",
      "M. Bakarezos",
      "E. P. Benis",
      "N. A. Papadogiannis",
      "V. Dimitriou",
      "M. Tatarakis"
    ],
    "abstract": "This research demonstrates high-repetition-rate laser-accelerated ion beams\nvia dual, intersecting, counterpropagating laser-driven blast waves to\nprecisely shape underdense gas into long-lived near-critical density targets.\nThe collision of the shock fronts compresses the gas and forms steep density\ngradients with scale lengths of a few tens of microns. The compressed target\npersists for several nanoseconds, eliminating laser synchronization\nconstraints. Measurements of multi-MeV ion energy spectra are reported. 3D\nhydrodynamic simulations are used to optimize the density profile and assess\nthe influence of the Amplified Spontaneous Emission of the femtosecond\naccelerating laser pulse. A synthetic optical probing model is applied to\ndirectly compare simulations with experimental data. 3D Particle-In-Cell\nsimulations reveal the formation of multi-kT, azimuthal magnetic fields,\nindicating Magnetic Vortex Acceleration as the main acceleration mechanism.",
    "pdf_url": "http://arxiv.org/pdf/2505.24508v1",
    "published": "2025-05-30T12:10:52+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.12055v1",
    "title": "Towards Unified Neural Decoding with Brain Functional Network Modeling",
    "authors": [
      "Di Wu",
      "Linghao Bu",
      "Yifei Jia",
      "Lu Cao",
      "Siyuan Li",
      "Siyu Chen",
      "Yueqian Zhou",
      "Sheng Fan",
      "Wenjie Ren",
      "Dengchang Wu",
      "Kang Wang",
      "Yue Zhang",
      "Yuehui Ma",
      "Jie Yang",
      "Mohamad Sawan"
    ],
    "abstract": "Recent achievements in implantable brain-computer interfaces (iBCIs) have\ndemonstrated the potential to decode cognitive and motor behaviors with\nintracranial brain recordings; however, individual physiological and electrode\nimplantation heterogeneities have constrained current approaches to neural\ndecoding within single individuals, rendering interindividual neural decoding\nelusive. Here, we present Multi-individual Brain Region-Aggregated Network\n(MIBRAIN), a neural decoding framework that constructs a whole functional brain\nnetwork model by integrating intracranial neurophysiological recordings across\nmultiple individuals. MIBRAIN leverages self-supervised learning to derive\ngeneralized neural prototypes and supports group-level analysis of brain-region\ninteractions and inter-subject neural synchrony. To validate our framework, we\nrecorded stereoelectroencephalography (sEEG) signals from a cohort of\nindividuals performing Mandarin syllable articulation. Both real-time online\nand offline decoding experiments demonstrated significant improvements in both\naudible and silent articulation decoding, enhanced decoding accuracy with\nincreased multi-subject data integration, and effective generalization to\nunseen subjects. Furthermore, neural predictions for regions without direct\nelectrode coverage were validated against authentic neural data. Overall, this\nframework paves the way for robust neural decoding across individuals and\noffers insights for practical clinical applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.12055v1",
    "published": "2025-05-30T12:10:37+00:00",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24507v1",
    "title": "How can AI reduce fall injuries in the workplace?",
    "authors": [
      "Nicholas Cartocci",
      "Antonios E. Gkikakis",
      "Roberto F. Pitzalis",
      "Fabio Pera",
      "Maria Teresa Settino",
      "Darwin G. Caldwell",
      "Jesús Ortiz"
    ],
    "abstract": "Fall-caused injuries are common in all types of work environments, including\noffices. They are the main cause of absences longer than three days, especially\nfor small and medium-sized businesses (SMEs). However, data, data amount, data\nheterogeneity, and stringent processing time constraints continue to pose\nchallenges to real-time fall detection. This work proposes a new approach based\non a recurrent neural network (RNN) for Fall Detection and a Kolmogorov-Arnold\nNetwork (KAN) to estimate the time of impact of the fall. The approach is\ntested on SisFall, a dataset consisting of 2706 Activities of Daily Living\n(ADLs) and 1798 falls recorded by three sensors. The results show that the\nproposed approach achieves an average TPR of 82.6% and TNR of 98.4% for fall\nsequences and 94.4% in ADL. Besides, the Root Mean Squared Error of the\nestimated time of impact is approximately 160ms.",
    "pdf_url": "http://arxiv.org/pdf/2505.24507v1",
    "published": "2025-05-30T12:09:38+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24506v1",
    "title": "Enhancing the Accuracy of Spatio-Temporal Models for Wind Speed Prediction by Incorporating Bias-Corrected Crowdsourced Data",
    "authors": [
      "Eamonn Organ",
      "Maeve Upton",
      "Denis Allard",
      "Lionel Benoit",
      "James Sweeney"
    ],
    "abstract": "Accurate high-resolution spatial and temporal wind speed data is critical for\nestimating the wind energy potential of a location. For real-time wind speed\nprediction, statistical models typically depend on high-quality (near)\nreal-time data from official meteorological stations to improve forecasting\naccuracy. Personal weather stations (PWS) offer an additional source of\nreal-time data and broader spatial coverage than offical stations. However,\nthey are not subject to rigorous quality control and may exhibit bias or\nmeasurement errors. This paper presents a framework for incorporating PWS data\ninto statistical models for validated official meteorological station data via\na two-stage approach. First, bias correction is performed on PWS wind speed\ndata using reanalysis data. Second, we implement a Bayesian hierarchical\nspatio-temporal model that accounts for varying measurement error in the PWS\ndata. This enables wind speed prediction across a target area, and is\nparticularly beneficial for improving predictions in regions sparse in official\nmonitoring stations. Our results show that including bias-corrected PWS data\nimproves prediction accuracy compared to using meteorological station data\nalone, with a 7% reduction in prediction error on average across all sites. The\nresults are comparable with popular reanalysis products, but unlike these\nnumerical weather models our approach is available in real-time and offers\nimproved uncertainty quantification.",
    "pdf_url": "http://arxiv.org/pdf/2505.24506v1",
    "published": "2025-05-30T12:09:14+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24505v1",
    "title": "Learning to Optimally Dispatch Power: Performance on a Nation-Wide Real-World Dataset",
    "authors": [
      "Ignacio Boero",
      "Santiago Diaz",
      "Tomás Vázquez",
      "Enzo Coppes",
      "Pablo Belzarena",
      "Federico Larroca"
    ],
    "abstract": "The Optimal Reactive Power Dispatch (ORPD) problem plays a crucial role in\npower system operations, ensuring voltage stability and minimizing power\nlosses. Recent advances in machine learning, particularly within the ``learning\nto optimize'' framework, have enabled fast and efficient approximations of ORPD\nsolutions, typically by training models on precomputed optimization results.\nWhile these approaches have demonstrated promising performance on synthetic\ndatasets, their effectiveness under real-world grid conditions remains largely\nunexplored. This paper makes two key contributions. First, we introduce a\npublicly available power system dataset that includes both the structural\ncharacteristics of Uruguay's electrical grid and nearly two years of real-world\noperational data, encompassing actual demand and generation profiles. Given\nUruguay's high penetration of renewable energy, the ORPD problem has become the\nprimary optimization challenge in its power network. Second, we assess the\nimpact of real-world data on learning-based ORPD solutions, revealing a\nsignificant increase in prediction errors when transitioning from synthetic to\nactual demand and generation inputs. Our results highlight the limitations of\nexisting models in learning under the complex statistical properties of real\ngrid conditions and emphasize the need for more expressive architectures. By\nproviding this dataset, we aim to facilitate further research into robust\nlearning-based optimization techniques for power system management.",
    "pdf_url": "http://arxiv.org/pdf/2505.24505v1",
    "published": "2025-05-30T12:07:38+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24504v1",
    "title": "Jacobian-free Multigrid Preconditioner for Discontinuous Galerkin Methods applied to Numerical Weather Prediction",
    "authors": [
      "Philipp Birken",
      "Andreas Dedner",
      "Robert Klöfkorn"
    ],
    "abstract": "Discontinuous Galerkin (DG) methods are promising high order discretizations\nfor unsteady compressible flows. Here, we focus on Numerical Weather Prediction\n(NWP). These flows are characterized by a fine resolution in $z$-direction and\nlow Mach numbers, making the system stiff. Thus, implicit time integration is\nrequired and for this a fast, highly parallel, low-memory iterative solver for\nthe resulting algebraic systems. As a basic framework, we use inexact\nJacobian-Free Newton-GMRES with a preconditioner.\n  For low order finite volume discretizations, multigrid methods have been\nsuccessfully applied to steady and unsteady fluid flows. However, for high\norder DG methods, such solvers are currently lacking. %The lack of efficient\nsolvers suitable for contemporary computer architectures inhibits wider\nadoption of DG methods. This motivates our research to construct a\nJacobian-free precondtioner for high order DG discretizations. The\npreconditioner is based on a multigrid method constructed for a low order\nfinite volume discretization defined on a subgrid of the DG mesh. We design a\ncomputationally efficient and mass conservative mapping between the grids. As\nsmoothers, explicit Runge-Kutta pseudo time iterations are used, which can be\nimplemented in parallel in a Jacobian-free low-memory manner.\n  We consider DG Methods for the Euler equations and for viscous flow equations\nin 2D, both with gravity, in a well balanced formulation. Numerical experiments\nin the software framework DUNE-FEM on atmospheric flow problems show the\nbenefit of this approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.24504v1",
    "published": "2025-05-30T12:06:38+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.comp-ph",
      "65M55, 65M60"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24503v1",
    "title": "Online Fair Division with Additional Information",
    "authors": [
      "Tzeh Yuan Neoh",
      "Jannik Peters",
      "Nicholas Teh"
    ],
    "abstract": "We study the problem of fairly allocating indivisible goods to agents in an\nonline setting, where goods arrive sequentially and must be allocated\nirrevocably to agents. Focusing on the popular fairness notions of\nenvy-freeness, proportionality, and maximin share fairness (and their\napproximate variants), we ask how the availability of information on future\ngoods influences the existence and approximability of fair allocations. In the\nabsence of any such information, we establish strong impossibility results,\ndemonstrating the inherent difficulty of achieving even approximate fairness\nguarantees. In contrast, we demonstrate that knowledge of additional\ninformation -- such as aggregate of each agent's total valuations\n(equivalently, normalized valuations) or the multiset of future goods values\n(frequency predictions) -- would enable the design of fairer online algorithms.\nGiven normalization information, we propose an algorithm that achieves stronger\nfairness guarantees than previously known results. Given frequency predictions,\nwe introduce a meta-algorithm that leverages frequency predictions to match the\nbest-known offline guarantees for a broad class of ''share-based'' fairness\nnotions. Our complementary impossibility results in each setting underscore\nboth the limitations imposed by uncertainty about future goods and the\npotential of leveraging structured information to achieve fairer outcomes in\nonline fair division.",
    "pdf_url": "http://arxiv.org/pdf/2505.24503v1",
    "published": "2025-05-30T12:06:16+00:00",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24502v3",
    "title": "Predictability of quantum observables: Applications in QKD and top quarks",
    "authors": [
      "Dennis I. Martínez-Moreno",
      "Miguel Castillo-Celeita",
      "Diego G. Bussandri"
    ],
    "abstract": "We deepen our understanding of transmitting classical information using\nquantum means by analyzing the prediction of local quantum observables enhanced\nby quantum correlations. Our approach focuses on two complementary measures of\nprediction error, the Bayes risk and the inference variance, both rooted in\nstatistical learning theory. We provide, to our knowledge, the first analytical\nminimizations of these quantities for arbitrary two-qubit states, together with\nthe optimal measurement strategies. We further analyze their averaged forms,\nrevealing a direct connection to Einstein-Podolsky-Rosen steering criteria. We\nalso embed our Bayes risk minimization into an entanglement-based quantum key\ndistribution protocol, demonstrating higher secure-key rates than the standard\nBB84 scheme under realistic noise. Finally, we illustrate our results for (i)\namplitude-damped Bell pairs, and (ii) spin correlations in top-antitop quark\npairs produced in high-energy collisions, highlighting quantum states produced\nin colliders as a novel platform for quantum information tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24502v3",
    "published": "2025-05-30T12:03:59+00:00",
    "categories": [
      "quant-ph",
      "hep-ex",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24501v1",
    "title": "Inhomogeneous mark correlation functions for general marked point processes",
    "authors": [
      "Mehdi Moradi",
      "Matthias Eckardt"
    ],
    "abstract": "Spatial phenomena in environmental and biological contexts often involve\nevents that are unevenly distributed across space and carry attributes, whose\nassociations/variations are space-dependent. In this paper, we introduce the\nclass of inhomogeneous mark correlation functions, capturing mark\nassociations/variations, while explicitly accounting for the spatial\ninhomogeneity of events. The proposed functions are designed to quantify how,\non average, marks vary or associate with one another as a function of pairwise\nspatial distances. We develop nonparametric estimators and evaluate their\nperformance through simulation studies covering a range of scenarios with mark\nassociation or variation, spanning from nonstationary point patterns without\nspatial interaction to those characterised by clustering tendencies. Our\nsimulations reveal the shortcomings of traditional methods in the presence of\nspatial inhomogeneity, underscoring the necessity of our approach. Furthermore,\nthe results show that our estimators accurately identify both the\npositivity/negativity and effective spatial range for detected mark\nassociations/variations. The proposed inhomogeneous mark correlation functions\nare then applied to two distinct forest ecosystems: Longleaf pine trees in\nsouthern Georgia, USA, marked by their diameter at breast height, and Scots\npine trees in Pfynwald, Switzerland, marked by their height. Our findings\nreveal that the inhomogeneous mark correlation functions provide deeper and\nmore detailed insights into tree growth patterns compared to traditional\nmethods",
    "pdf_url": "http://arxiv.org/pdf/2505.24501v1",
    "published": "2025-05-30T12:02:19+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24500v1",
    "title": "TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning for Enhancing LLMs' Social Intelligence",
    "authors": [
      "Guiyang Hou",
      "Xing Gao",
      "Yuchuan Wu",
      "Xiang Huang",
      "Wenqi Zhang",
      "Zhe Zheng",
      "Yongliang Shen",
      "Jialu Du",
      "Fei Huang",
      "Yongbin Li",
      "Weiming Lu"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have made significant progress in\nIQ-related domains that require careful thinking, such as mathematics and\ncoding. However, enhancing LLMs' cognitive development in social domains,\nparticularly from a post-training perspective, remains underexplored.\nRecognizing that the social world follows a distinct timeline and requires a\nricher blend of cognitive modes (from intuitive reactions (System 1) and\nsurface-level thinking to deliberate thinking (System 2)) than mathematics,\nwhich primarily relies on System 2 cognition (careful, step-by-step reasoning),\nwe introduce Temporal-aware Hierarchical Cognitive Reinforcement Learning\n(TimeHC-RL) for enhancing LLMs' social intelligence. In our experiments, we\nsystematically explore improving LLMs' social intelligence and validate the\neffectiveness of the TimeHC-RL method, through five other post-training\nparadigms and two test-time intervention paradigms on eight datasets with\ndiverse data patterns. Experimental results reveal the superiority of our\nproposed TimeHC-RL method compared to the widely adopted System 2 RL method. It\ngives the 7B backbone model wings, enabling it to rival the performance of\nadvanced models like DeepSeek-R1 and OpenAI-O3. Additionally, the systematic\nexploration from post-training and test-time interventions perspectives to\nimprove LLMs' social intelligence has uncovered several valuable insights.",
    "pdf_url": "http://arxiv.org/pdf/2505.24500v1",
    "published": "2025-05-30T12:01:06+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24499v1",
    "title": "Reason-SVG: Hybrid Reward RL for Aha-Moments in Vector Graphics Generation",
    "authors": [
      "Ximing Xing",
      "Yandong Guan",
      "Jing Zhang",
      "Dong Xu",
      "Qian Yu"
    ],
    "abstract": "Generating high-quality Scalable Vector Graphics (SVGs) is challenging for\nLarge Language Models (LLMs), as it requires advanced reasoning for structural\nvalidity, semantic faithfulness, and visual coherence -- capabilities in which\ncurrent LLMs often fall short. In this work, we introduce Reason-SVG, a novel\nframework designed to enhance LLM reasoning for SVG generation. Reason-SVG\npioneers the \"Drawing-with-Thought\" (DwT) paradigm, in which models generate\nboth SVG code and explicit design rationales, mimicking the human creative\nprocess. Reason-SVG adopts a two-stage training strategy: First, Supervised\nFine-Tuning (SFT) trains the LLM on the DwT paradigm to activate foundational\nreasoning abilities. Second, Reinforcement Learning (RL), utilizing Group\nRelative Policy Optimization (GRPO), empowers the model to generate both DwT\nand SVGs rationales through refined, reward-driven reasoning. To facilitate\nreasoning-driven SVG generation, we design a Hybrid Reward function that\nevaluates the presence and utility of DwT reasoning, along with structural\nvalidity, semantic alignment, and visual quality. We also introduce the\nSVGX-DwT-10k dataset, a high-quality corpus of 10,000 SVG-DwT pairs, where each\nSVG code is generated based on explicit DwT reasoning. By integrating DwT, SFT,\nand Hybrid Reward-guided RL, Reason-SVG significantly improves LLM performance\nin generating accurate and visually compelling SVGs, potentially fostering \"Aha\nmoments\" in design.",
    "pdf_url": "http://arxiv.org/pdf/2505.24499v1",
    "published": "2025-05-30T11:57:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00096v1",
    "title": "PathGene: Benchmarking Driver Gene Mutations and Exon Prediction Using Multicenter Lung Cancer Histopathology Image Dataset",
    "authors": [
      "Liangrui Pan",
      "Qingchun Liang",
      "Shen Zhao",
      "Songqing Fan",
      "Shaoliang Peng"
    ],
    "abstract": "Accurately predicting gene mutations, mutation subtypes and their exons in\nlung cancer is critical for personalized treatment planning and prognostic\nassessment. Faced with regional disparities in medical resources and the high\ncost of genomic assays, using artificial intelligence to infer these mutations\nand exon variants from routine histopathology images could greatly facilitate\nprecision therapy. Although some prior studies have shown that deep learning\ncan accelerate the prediction of key gene mutations from lung cancer pathology\nslides, their performance remains suboptimal and has so far been limited mainly\nto early screening tasks. To address these limitations, we have assembled\nPathGene, which comprises histopathology images paired with next-generation\nsequencing reports from 1,576 patients at the Second Xiangya Hospital, Central\nSouth University, and 448 TCGA-LUAD patients. This multi-center dataset links\nwhole-slide images to driver gene mutation status, mutation subtypes, exon, and\ntumor mutational burden (TMB) status, with the goal of leveraging pathology\nimages to predict mutations, subtypes, exon locations, and TMB for early\ngenetic screening and to advance precision oncology. Unlike existing datasets,\nwe provide molecular-level information related to histopathology images in\nPathGene to facilitate the development of biomarker prediction models. We\nbenchmarked 11 multiple-instance learning methods on PathGene for mutation,\nsubtype, exon, and TMB prediction tasks. These experimental methods provide\nvaluable alternatives for early genetic screening of lung cancer patients and\nassisting clinicians to quickly develop personalized precision targeted\ntreatment plans for patients. Code and data are available at\nhttps://github.com/panliangrui/NIPS2025/.",
    "pdf_url": "http://arxiv.org/pdf/2506.00096v1",
    "published": "2025-05-30T11:51:11+00:00",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.24498v1",
    "title": "Efficient Neural and Numerical Methods for High-Quality Online Speech Spectrogram Inversion via Gradient Theorem",
    "authors": [
      "Andres Fernandez",
      "Juan Azcarreta",
      "Cagdas Bilen",
      "Jesus Monge Alvarez"
    ],
    "abstract": "Recent work in online speech spectrogram inversion effectively combines Deep\nLearning with the Gradient Theorem to predict phase derivatives directly from\nmagnitudes. Then, phases are estimated from their derivatives via least\nsquares, resulting in a high quality reconstruction. In this work, we introduce\nthree innovations that drastically reduce computational cost, while maintaining\nhigh quality: Firstly, we introduce a novel neural network architecture with\njust 8k parameters, 30 times smaller than previous state of the art. Secondly,\nincreasing latency by 1 hop size allows us to further halve the cost of the\nneural inference step. Thirdly, we we observe that the least squares problem\nfeatures a tridiagonal matrix and propose a linear-complexity solver for the\nleast squares step that leverages tridiagonality and positive-semidefiniteness,\nachieving a speedup of several orders of magnitude. We release samples online.",
    "pdf_url": "http://arxiv.org/pdf/2505.24498v1",
    "published": "2025-05-30T11:51:05+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24497v1",
    "title": "Localized atomic vibrations caused by point impurity in long chains of noble gas atoms adsorbed in outer grooves of carbon nanobundle",
    "authors": [
      "E. V. Manzhelii",
      "S. B. Feodosyev"
    ],
    "abstract": "The characteristics of discrete vibrational levels caused by a point\nthree-parameter substitutional impurity in long linear chain of inert gas atoms\nadsorbed in groove on the surface of carbon nanobundle are studied. The\nimpurity atom differs from the atoms of the chain in the following parameters:\nthe mass, the parameter of interaction with neighboring atoms and the parameter\nof interaction with the substrate. Analytical expressions for the frequencies\nof the localized vibrations and the intensities of these vibrations are\nobtained. The conditions for the existence of localized vibrations both below\nand above the band of the quasi-continuous spectrum of the adsorbed chain are\nalso obtained.",
    "pdf_url": "http://arxiv.org/pdf/2505.24497v1",
    "published": "2025-05-30T11:48:42+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24496v1",
    "title": "Speech Token Prediction via Compressed-to-fine Language Modeling for Speech Generation",
    "authors": [
      "Wenrui Liu",
      "Qian Chen",
      "Wen Wang",
      "Yafeng Chen",
      "Jin Xu",
      "Zhifang Guo",
      "Guanrou Yang",
      "Weiqin Li",
      "Xiaoda Yang",
      "Tao Jin",
      "Minghui Fang",
      "Jialong Zuo",
      "Bai Jionghao",
      "Zemin Liu"
    ],
    "abstract": "Neural audio codecs, used as speech tokenizers, have demonstrated remarkable\npotential in the field of speech generation. However, to ensure high-fidelity\naudio reconstruction, neural audio codecs typically encode audio into long\nsequences of speech tokens, posing a significant challenge for downstream\nlanguage models in long-context modeling. We observe that speech token\nsequences exhibit short-range dependency: due to the monotonic alignment\nbetween text and speech in text-to-speech (TTS) tasks, the prediction of the\ncurrent token primarily relies on its local context, while long-range tokens\ncontribute less to the current token prediction and often contain redundant\ninformation. Inspired by this observation, we propose a\n\\textbf{compressed-to-fine language modeling} approach to address the challenge\nof long sequence speech tokens within neural codec language models: (1)\n\\textbf{Fine-grained Initial and Short-range Information}: Our approach retains\nthe prompt and local tokens during prediction to ensure text alignment and the\nintegrity of paralinguistic information; (2) \\textbf{Compressed Long-range\nContext}: Our approach compresses long-range token spans into compact\nrepresentations to reduce redundant information while preserving essential\nsemantics. Extensive experiments on various neural audio codecs and downstream\nlanguage models validate the effectiveness and generalizability of the proposed\napproach, highlighting the importance of token compression in improving speech\ngeneration within neural codec language models. The demo of audio samples will\nbe available at\nhttps://anonymous.4open.science/r/SpeechTokenPredictionViaCompressedToFinedLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.24496v1",
    "published": "2025-05-30T11:47:29+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24495v1",
    "title": "Convexity of the Berezin range of operators on $\\mathcal{H}_γ (\\mathbb{D})$",
    "authors": [
      "Sandip Kumar Maiti",
      "Satyajit Sahoo",
      "Gorachand Chakraborty"
    ],
    "abstract": "In this paper, we characterize the convexity of the Berezin range for\nfinite-rank operators acting on the weighted Hardy space $\\mathcal{H}_\\gamma\n(\\mathbb{D})$ over the unit disc $\\mathbb{D}$. We provide a complete\nclassification in terms of convexity for concrete operators. Additionally, we\naddress dynamical properties of finite-rank operators on Hardy and Bergman\nspaces. Several illustrative examples are discussed to support our theoretical\nfindings. Additionally, geometrical interpretations have also been employed.",
    "pdf_url": "http://arxiv.org/pdf/2505.24495v1",
    "published": "2025-05-30T11:46:43+00:00",
    "categories": [
      "math.FA",
      "47B32, 52A10"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24494v3",
    "title": "The Minkowski problem for the $k$-torsional rigidity",
    "authors": [
      "Xia Zhao",
      "Peibiao Zhao"
    ],
    "abstract": "P. Salani [Adv. Math., 229 (2012)] introduced the $k$-torsional rigidity\nassociated with a $k$-Hessian equation and obtained the Brunn-Minkowski\ninequalities $w.r.t.$ the torsional rigidity in $\\mathbb{R}^3$. Following this\nwork, we first construct, in the present paper, a Hadamard variational formula\nfor the $k$-torsional rigidity with $1\\leq k\\leq n-1$, then we can deduce a\n$k$-torsional measure from the Hadamard variational formula. Based on the\n$k$-torsional measure, we propose the Minkowski problem for the $k$-torsional\nrigidity and confirm the existence of its smooth non-even solutions by the\nmethod of a curvature flow. Specially, a new proof method for the uniform lower\nbound estimation in the $C^0$ estimation for the solution to the curvature flow\nis presented with the help of invariant functional $\\Phi(\\Omega_t)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24494v3",
    "published": "2025-05-30T11:46:27+00:00",
    "categories": [
      "math.DG",
      "52A20 \\ \\ 35K96 \\ \\ 58J35"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24493v1",
    "title": "MELT: Towards Automated Multimodal Emotion Data Annotation by Leveraging LLM Embedded Knowledge",
    "authors": [
      "Xin Jing",
      "Jiadong Wang",
      "Iosif Tsangko",
      "Andreas Triantafyllopoulos",
      "Björn W. Schuller"
    ],
    "abstract": "Although speech emotion recognition (SER) has advanced significantly with\ndeep learning, annotation remains a major hurdle. Human annotation is not only\ncostly but also subject to inconsistencies annotators often have different\npreferences and may lack the necessary contextual knowledge, which can lead to\nvaried and inaccurate labels. Meanwhile, Large Language Models (LLMs) have\nemerged as a scalable alternative for annotating text data. However, the\npotential of LLMs to perform emotional speech data annotation without human\nsupervision has yet to be thoroughly investigated. To address these problems,\nwe apply GPT-4o to annotate a multimodal dataset collected from the sitcom\nFriends, using only textual cues as inputs. By crafting structured text\nprompts, our methodology capitalizes on the knowledge GPT-4o has accumulated\nduring its training, showcasing that it can generate accurate and contextually\nrelevant annotations without direct access to multimodal inputs. Therefore, we\npropose MELT, a multimodal emotion dataset fully annotated by GPT-4o. We\ndemonstrate the effectiveness of MELT by fine-tuning four self-supervised\nlearning (SSL) backbones and assessing speech emotion recognition performance\nacross emotion datasets. Additionally, our subjective experiments\\' results\ndemonstrate a consistence performance improvement on SER.",
    "pdf_url": "http://arxiv.org/pdf/2505.24493v1",
    "published": "2025-05-30T11:45:36+00:00",
    "categories": [
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24492v2",
    "title": "Object Centric Concept Bottlenecks",
    "authors": [
      "David Steinmann",
      "Wolfgang Stammer",
      "Antonia Wüst",
      "Kristian Kersting"
    ],
    "abstract": "Developing high-performing, yet interpretable models remains a critical\nchallenge in modern AI. Concept-based models (CBMs) attempt to address this by\nextracting human-understandable concepts from a global encoding (e.g., image\nencoding) and then applying a linear classifier on the resulting concept\nactivations, enabling transparent decision-making. However, their reliance on\nholistic image encodings limits their expressiveness in object-centric\nreal-world settings and thus hinders their ability to solve complex vision\ntasks beyond single-label classification. To tackle these challenges, we\nintroduce Object-Centric Concept Bottlenecks (OCB), a framework that combines\nthe strengths of CBMs and pre-trained object-centric foundation models,\nboosting performance and interpretability. We evaluate OCB on complex image\ndatasets and conduct a comprehensive ablation study to analyze key components\nof the framework, such as strategies for aggregating object-concept encodings.\nThe results show that OCB outperforms traditional CBMs and allows one to make\ninterpretable decisions for complex visual tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24492v2",
    "published": "2025-05-30T11:45:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24491v1",
    "title": "Generalized chord diagrams and weight systems",
    "authors": [
      "M. Kazarian",
      "E. Krasilnikov",
      "S. Lando",
      "M. Shapiro"
    ],
    "abstract": "Weight systems are functions on chord diagrams satisfying Vassiliev's\n$4$-term relations. They originate in the theory of finite type knot\ninvariants. Recent developments in understanding weight systems arising from\nLie algebras are based on extending these weight systems from chord diagrams\n(which can be interpreted as involutions without fixed points, considered\nmodulo cyclic shifts) to arbitrary permutations (also modulo cyclic shifts). We\nsuggest relations for functions on permutations, which generalize Vassiliev's\nrelations. We show that the $gl$- and $so$- weight systems satisfy these\nrelations. We also analyze certain properties of these weight systems and study\nrealted Hopf algebras of permutations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24491v1",
    "published": "2025-05-30T11:43:56+00:00",
    "categories": [
      "math.CO",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24490v1",
    "title": "On the maximum number of edges of outer k-planar graphs",
    "authors": [
      "Maximilian Pfister"
    ],
    "abstract": "We study the maximum number of straight-line segments connecting $n$ points\nin convex position in the plane, so that each segment intersects at most $k$\nothers. This question can also be framed as the maximum number of edges of an\nouter $k$-planar graph on $n$ vertices. We outline several approaches to tackle\nthe problem with the best approach yielding an upper bound of\n$(\\sqrt{2}+\\varepsilon)\\sqrt{k}n$ edges (with $\\varepsilon \\rightarrow 0$ for\nsufficiently large $k$). We further investigate the case where the points are\narbitrarily bicolored and segments always connect two different colors (i.e.,\nthe corresponding graph has to be bipartite). To this end, we also consider the\nmaximum cut problem for the circulant graph $C_n^{1,2,\\dots,r}$ which might be\nof independent interest.",
    "pdf_url": "http://arxiv.org/pdf/2505.24490v1",
    "published": "2025-05-30T11:43:14+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "05C10, 05C62",
      "G.2.2"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24489v1",
    "title": "Deformable Attention Mechanisms Applied to Object Detection, case of Remote Sensing",
    "authors": [
      "Anasse Boutayeb",
      "Iyad Lahsen-cherif",
      "Ahmed El Khadimi"
    ],
    "abstract": "Object detection has recently seen an interesting trend in terms of the most\ninnovative research work, this task being of particular importance in the field\nof remote sensing, given the consistency of these images in terms of\ngeographical coverage and the objects present. Furthermore, Deep Learning (DL)\nmodels, in particular those based on Transformers, are especially relevant for\nvisual computing tasks in general, and target detection in particular. Thus,\nthe present work proposes an application of Deformable-DETR model, a specific\narchitecture using deformable attention mechanisms, on remote sensing images in\ntwo different modes, especially optical and Synthetic Aperture Radar (SAR). To\nachieve this objective, two datasets are used, one optical, which is Pleiades\nAircraft dataset, and the other SAR, in particular SAR Ship Detection Dataset\n(SSDD). The results of a 10-fold stratified validation showed that the proposed\nmodel performed particularly well, obtaining an F1 score of 95.12% for the\noptical dataset and 94.54% for SSDD, while comparing these results with several\nmodels detections, especially those based on CNNs and transformers, as well as\nthose specifically designed to detect different object classes in remote\nsensing images.",
    "pdf_url": "http://arxiv.org/pdf/2505.24489v1",
    "published": "2025-05-30T11:43:09+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24488v1",
    "title": "Relative-phase dependence of dynamically assisted electron-positron pair creation in the superposition of strong oscillating electric-field pulses",
    "authors": [
      "J. Braß",
      "D. M. Müller",
      "S. Villalba-Chávez",
      "K. Krajewska",
      "C. Müller"
    ],
    "abstract": "Production of electron-positron pairs in the superposition of oscillating\nelectric-field pulses with largely different frequencies is studied, focussing\non the impact of relative phases between the pulses. Various field\nconfigurations are considered: superpositions of either two or three pulses of\nequal duration as well as combinations of a long low-frequency and a short\nhigh-frequency pulse. We show that the relative phase of superimposed\nhigh-frequency modes can exert a sizeable effect on the total numbers of\nproduced pairs, enhancing them by about 10-30% for the considered field\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.24488v1",
    "published": "2025-05-30T11:42:30+00:00",
    "categories": [
      "physics.atom-ph",
      "hep-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24487v1",
    "title": "Real-time Fall Prevention system for the Next-generation of Workers",
    "authors": [
      "Nicholas Cartocci",
      "Antonios E. Gkikakis",
      "Darwin G. Caldwell",
      "Jesús Ortiz"
    ],
    "abstract": "Developing a general-purpose wearable real-time fall-detection system is\nstill a challenging task, especially for healthy and strong subjects, such as\nindustrial workers that work in harsh environments. In this work, we present a\nhybrid approach for fall detection and prevention, which uses the dynamic model\nof an inverted pendulum to generate simulations of falling that are then fed to\na deep learning framework. The output is a signal to activate a fall mitigation\nmechanism when the subject is at risk of harm. The advantage of this approach\nis that abstracted models can be used to efficiently generate training data for\nthousands of different subjects with different falling initial conditions,\nsomething that is practically impossible with real experiments. This approach\nis suitable for a specific type of fall, where the subjects fall without\nchanging their initial configuration significantly, and it is the first step\ntoward a general-purpose wearable device, with the aim of reducing\nfall-associated injuries in industrial environments, which can improve the\nsafety of workers.",
    "pdf_url": "http://arxiv.org/pdf/2505.24487v1",
    "published": "2025-05-30T11:41:16+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24486v1",
    "title": "Rehearsal with Auxiliary-Informed Sampling for Audio Deepfake Detection",
    "authors": [
      "Falih Gozi Febrinanto",
      "Kristen Moore",
      "Chandra Thapa",
      "Jiangang Ma",
      "Vidya Saikrishna",
      "Feng Xia"
    ],
    "abstract": "The performance of existing audio deepfake detection frameworks degrades when\nconfronted with new deepfake attacks. Rehearsal-based continual learning (CL),\nwhich updates models using a limited set of old data samples, helps preserve\nprior knowledge while incorporating new information. However, existing\nrehearsal techniques don't effectively capture the diversity of audio\ncharacteristics, introducing bias and increasing the risk of forgetting. To\naddress this challenge, we propose Rehearsal with Auxiliary-Informed Sampling\n(RAIS), a rehearsal-based CL approach for audio deepfake detection. RAIS\nemploys a label generation network to produce auxiliary labels, guiding diverse\nsample selection for the memory buffer. Extensive experiments show RAIS\noutperforms state-of-the-art methods, achieving an average Equal Error Rate\n(EER) of 1.953 % across five experiences. The code is available at:\nhttps://github.com/falihgoz/RAIS.",
    "pdf_url": "http://arxiv.org/pdf/2505.24486v1",
    "published": "2025-05-30T11:40:50+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24485v1",
    "title": "Neutrino emission from neutron star matter",
    "authors": [
      "Omar Benhar",
      "Lucas Tonetto"
    ],
    "abstract": "The temperature of a newly formed neutron star is believed to be as high as\n$10^{11}$~K, corresponding to a thermal energy of about $10$ MeV. After a time\n$t \\sim 50 \\ {\\rm s}$, the neutrino mean free path in nuclear matter exceeds\nthe typical star radius, R~$\\sim$~10 Km, and neutrino emission becomes the\ndominant mechanism of energy loss, eventually bringing the temperature down to\n$\\sim10^{8}$~K. Neutrinos also play a critical role in determining the\ncomposition of matter in the star interior, consisting primarily of a\ncharge-neutral mixture of neutrons, protons and leptons in $\\beta$-equilibrium.\nThis article provides an introduction to the weak interactions of nucleons in\nnuclear matter, as well as a concise review of the neutrino emission reactions\ntaking place in the neutron star core. The approximations involved in the\nstandard theoretical treatment of thermal and dynamical effects are analysed in\nthe light of the recent progress of the field, and the prospects for future\ndevelopments are outlined.",
    "pdf_url": "http://arxiv.org/pdf/2505.24485v1",
    "published": "2025-05-30T11:38:54+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24484v1",
    "title": "On the Transfer of Completeness and Projection Properties in Truncated Vector Lattices",
    "authors": [
      "Mohamed Habibi",
      "Hamza Hafsi"
    ],
    "abstract": "In this work we investigate the transfer of fundamental order and\ncompleteness properties between truncated Riesz spaces and their unitizations.\nSpecifically, we provide characterizations and equivalences for several notions\nof completeness: the Archimedean property, relatively uniform completeness,\nDedekind completeness, lateral completeness, universal completeness, and the\nprojection property. Counterexamples are presented to illustrate the necessity\nof assumptions and the independence of various completeness notions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24484v1",
    "published": "2025-05-30T11:38:04+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24483v1",
    "title": "First-Passage-Time Asymmetry for Biased Run-and-Tumble Processes",
    "authors": [
      "Yonathan Sarmiento",
      "Benjamin Walter",
      "Debraj Das",
      "Samvit Mahapatra",
      "Édgar Roldán",
      "Rosemary J. Harris"
    ],
    "abstract": "We explore first-passage phenomenology for biased active processes with a\nrenewal-type structure, focusing in particular on paradigmatic run-and-tumble\nmodels in both discrete and continuous state spaces. In general, we show there\nis no symmetry between distributions of first-passage times to symmetric\nbarriers positioned in and against the bias direction; however, we give\nconditions for such a duality to be restored asymptotically (in the limit of a\nlarge barrier distance) and highlight connections to the Gallavotti-Cohen\nfluctuation relation and the method of images. Our general trajectory arguments\nare supported by exact analytical calculations of first-passage-time\ndistributions for asymmetric run-and-tumble processes escaping from an interval\nof arbitrary width, and these calculations are confirmed with high accuracy via\nextensive numerics. Furthermore, we quantify the degree of violation of\nfirst-passage duality using Kullback-Leibler divergence and signal-to-noise\nratios associated with the first-passage times to the two barriers. We reveal\nan intriguing dependence of such measures of first-passage asymmetry on the\nunderlying tumbling dynamics which may inspire inference techniques based on\nfirst-passage-time statistics in active systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24483v1",
    "published": "2025-05-30T11:36:31+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2506.00095v3",
    "title": "ClinBench-HPB: A Clinical Benchmark for Evaluating LLMs in Hepato-Pancreato-Biliary Diseases",
    "authors": [
      "Yuchong Li",
      "Xiaojun Zeng",
      "Chihua Fang",
      "Jian Yang",
      "Fucang Jia",
      "Lei Zhang"
    ],
    "abstract": "Hepato-pancreato-biliary (HPB) disorders represent a global public health\nchallenge due to their high morbidity and mortality. Although large language\nmodels (LLMs) have shown promising performance in general medical\nquestion-answering tasks, the current evaluation benchmarks are mostly derived\nfrom standardized examinations or manually designed questions, lacking HPB\ncoverage and clinical cases. To address these issues, we systematically\neatablish an HPB disease evaluation benchmark comprising 3,535 closed-ended\nmultiple-choice questions and 337 open-ended real diagnosis cases, which\nencompasses all the 33 main categories and 465 subcategories of HPB diseases\ndefined in the International Statistical Classification of Diseases, 10th\nRevision (ICD-10). The multiple-choice questions are curated from public\ndatasets and synthesized data, and the clinical cases are collected from\nprestigious medical journals, case-sharing platforms, and collaborating\nhospitals. By evalauting commercial and open-source general and medical LLMs on\nour established benchmark, namely ClinBench-HBP, we find that while commercial\nLLMs perform competently on medical exam questions, they exhibit substantial\nperformance degradation on HPB diagnosis tasks, especially on complex,\ninpatient clinical cases. Those medical LLMs also show limited generalizability\nto HPB diseases. Our results reveal the critical limitations of current LLMs in\nthe domain of HPB diseases, underscoring the imperative need for future medical\nLLMs to handle real, complex clinical diagnostics rather than simple medical\nexam questions. The benchmark will be released at\nhttps://clinbench-hpb.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2506.00095v3",
    "published": "2025-05-30T11:35:05+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24482v1",
    "title": "Balancing incentives in committee-based blockchains",
    "authors": [
      "Arian Baloochestani",
      "Leander Jehl"
    ],
    "abstract": "Blockchain protocols incentivize participation through monetary rewards,\nassuming rational actors behave honestly to maximize their gains. However,\nattackers may attempt to harm others even at personal cost. These denial of\nprofit attacks aim to reduce the rewards of honest participants, potentially\nforcing them out of the system. While existing work has largely focused on the\nprofitability of attacks, they often neglect the potential harm inflicted on\nthe victim, which can be significant even when the attacker gains little or\nnothing.\n  This paper introduces a framework to quantify denial of profit attacks by\nmeasuring both attacker cost and victim loss. We model these attacks as a game\nand introduce relevant metrics to quantify these attacks. We then focus on\ncommittee-based blockchains and model vote collection as a game. We show that\nin the vote collection game, disincentivizing one denial of profit attack will\nmake another attack more appealing, and therefore, attacks have to be balanced.\nWe apply our framework to analyze real-world reward mechanisms in Ethereum and\nCosmos. Our framework reveals imbalances in Cosmos that can make correct\nbehavior suboptimal in practice. While Ethereum provides stronger protections,\nour framework shows that it is also not complete, and we propose alternative\nparameter settings to improve the balance between attacks. Our findings\nhighlight the need for better-balanced reward designs to defend against denial\nof profit attacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24482v1",
    "published": "2025-05-30T11:32:47+00:00",
    "categories": [
      "cs.GT",
      "cs.DC"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24481v1",
    "title": "ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation",
    "authors": [
      "Jing Huang",
      "Yongkang Zhao",
      "Yuhan Li",
      "Zhitao Dai",
      "Cheng Chen",
      "Qiying Lai"
    ],
    "abstract": "The U-shaped encoder-decoder architecture with skip connections has become a\nprevailing paradigm in medical image segmentation due to its simplicity and\neffectiveness. While many recent works aim to improve this framework by\ndesigning more powerful encoders and decoders, employing advanced convolutional\nneural networks (CNNs) for local feature extraction, Transformers or state\nspace models (SSMs) such as Mamba for global context modeling, or hybrid\ncombinations of both, these methods often struggle to fully utilize pretrained\nvision backbones (e.g., ResNet, ViT, VMamba) due to structural mismatches. To\nbridge this gap, we introduce ACM-UNet, a general-purpose segmentation\nframework that retains a simple UNet-like design while effectively\nincorporating pretrained CNNs and Mamba models through a lightweight adapter\nmechanism. This adapter resolves architectural incompatibilities and enables\nthe model to harness the complementary strengths of CNNs and SSMs-namely,\nfine-grained local detail extraction and long-range dependency modeling.\nAdditionally, we propose a hierarchical multi-scale wavelet transform module in\nthe decoder to enhance feature fusion and reconstruction fidelity. Extensive\nexperiments on the Synapse and ACDC benchmarks demonstrate that ACM-UNet\nachieves state-of-the-art performance while remaining computationally\nefficient. Notably, it reaches 85.12% Dice Score and 13.89mm HD95 on the\nSynapse dataset with 17.93G FLOPs, showcasing its effectiveness and\nscalability. Code is available at: https://github.com/zyklcode/ACM-UNet.",
    "pdf_url": "http://arxiv.org/pdf/2505.24481v1",
    "published": "2025-05-30T11:30:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24480v1",
    "title": "Towards Effective Code-Integrated Reasoning",
    "authors": [
      "Fei Bai",
      "Yingqian Min",
      "Beichen Zhang",
      "Zhipeng Chen",
      "Wayne Xin Zhao",
      "Lei Fang",
      "Zheng Liu",
      "Zhongyuan Wang",
      "Ji-Rong Wen"
    ],
    "abstract": "In this paper, we investigate code-integrated reasoning, where models\ngenerate code when necessary and integrate feedback by executing it through a\ncode interpreter. To acquire this capability, models must learn when and how to\nuse external code tools effectively, which is supported by tool-augmented\nreinforcement learning (RL) through interactive learning. Despite its benefits,\ntool-augmented RL can still suffer from potential instability in the learning\ndynamics. In light of this challenge, we present a systematic approach to\nimproving the training effectiveness and stability of tool-augmented RL for\ncode-integrated reasoning. Specifically, we develop enhanced training\nstrategies that balance exploration and stability, progressively building\ntool-use capabilities while improving reasoning performance. Through extensive\nexperiments on five mainstream mathematical reasoning benchmarks, our model\ndemonstrates significant performance improvements over multiple competitive\nbaselines. Furthermore, we conduct an in-depth analysis of the mechanism and\neffect of code-integrated reasoning, revealing several key insights, such as\nthe extension of model's capability boundaries and the simultaneous improvement\nof reasoning efficiency through code integration. All data and code for\nreproducing this work are available at: https://github.com/RUCAIBox/CIR.",
    "pdf_url": "http://arxiv.org/pdf/2505.24480v1",
    "published": "2025-05-30T11:30:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24479v1",
    "title": "Leveraging Knowledge Graphs and LLMs for Structured Generation of Misinformation",
    "authors": [
      "Sania Nayab",
      "Marco Simoni",
      "Giulio Rossolini"
    ],
    "abstract": "The rapid spread of misinformation, further amplified by recent advances in\ngenerative AI, poses significant threats to society, impacting public opinion,\ndemocratic stability, and national security. Understanding and proactively\nassessing these threats requires exploring methodologies that enable structured\nand scalable misinformation generation. In this paper, we propose a novel\napproach that leverages knowledge graphs (KGs) as structured semantic resources\nto systematically generate fake triplets. By analyzing the structural\nproperties of KGs, such as the distance between entities and their predicates,\nwe identify plausibly false relationships. These triplets are then used to\nguide large language models (LLMs) in generating misinformation statements with\nvarying degrees of credibility. By utilizing structured semantic relationships,\nour deterministic approach produces misinformation inherently challenging for\nhumans to detect, drawing exclusively upon publicly available KGs (e.g.,\nWikiGraphs).\n  Additionally, we investigate the effectiveness of LLMs in distinguishing\nbetween genuine and artificially generated misinformation. Our analysis\nhighlights significant limitations in current LLM-based detection methods,\nunderscoring the necessity for enhanced detection strategies and a deeper\nexploration of inherent biases in generative models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24479v1",
    "published": "2025-05-30T11:29:10+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24478v1",
    "title": "Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning",
    "authors": [
      "Vasilije Markovic",
      "Lazar Obradovic",
      "Laszlo Hajdu",
      "Jovan Pavlovic"
    ],
    "abstract": "Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) results\nin complex systems with numerous hyperparameters that directly affect\nperformance. While such systems are increasingly common in retrieval-augmented\ngeneration, the role of systematic hyperparameter optimization remains\nunderexplored. In this paper, we study this problem in the context of Cognee, a\nmodular framework for end-to-end KG construction and retrieval. Using three\nmulti-hop QA benchmarks (HotPotQA, TwoWikiMultiHop, and MuSiQue) we optimize\nparameters related to chunking, graph construction, retrieval, and prompting.\nEach configuration is scored using established metrics (exact match, F1, and\nDeepEval's LLM-based correctness metric). Our results demonstrate that\nmeaningful gains can be achieved through targeted tuning. While the gains are\nconsistent, they are not uniform, with performance varying across datasets and\nmetrics. This variability highlights both the value of tuning and the\nlimitations of standard evaluation measures. While demonstrating the immediate\npotential of hyperparameter tuning, we argue that future progress will depend\nnot only on architectural advances but also on clearer frameworks for\noptimization and evaluation in complex, modular systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24478v1",
    "published": "2025-05-30T11:27:59+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24477v1",
    "title": "Evaluating Gemini in an arena for learning",
    "authors": [
      "LearnLM Team",
      "Abhinit Modi",
      "Aditya Srikanth Veerubhotla",
      "Aliya Rysbek",
      "Andrea Huber",
      "Ankit Anand",
      "Avishkar Bhoopchand",
      "Brett Wiltshire",
      "Daniel Gillick",
      "Daniel Kasenberg",
      "Eleni Sgouritsa",
      "Gal Elidan",
      "Hengrui Liu",
      "Holger Winnemoeller",
      "Irina Jurenka",
      "James Cohan",
      "Jennifer She",
      "Julia Wilkowski",
      "Kaiz Alarakyia",
      "Kevin R. McKee",
      "Komal Singh",
      "Lisa Wang",
      "Markus Kunesch",
      "Miruna Pîslar",
      "Niv Efron",
      "Parsa Mahmoudieh",
      "Pierre-Alexandre Kamienny",
      "Sara Wiltberger",
      "Shakir Mohamed",
      "Shashank Agarwal",
      "Shubham Milind Phal",
      "Sun Jae Lee",
      "Theofilos Strinopoulos",
      "Wei-Jen Ko",
      "Yael Gold-Zamir",
      "Yael Haramaty",
      "Yannis Assael"
    ],
    "abstract": "Artificial intelligence (AI) is poised to transform education, but the\nresearch community lacks a robust, general benchmark to evaluate AI models for\nlearning. To assess state-of-the-art support for educational use cases, we ran\nan \"arena for learning\" where educators and pedagogy experts conduct blind,\nhead-to-head, multi-turn comparisons of leading AI models. In particular, $N =\n189$ educators drew from their experience to role-play realistic learning use\ncases, interacting with two models sequentially, after which $N = 206$ experts\njudged which model better supported the user's learning goals. The arena\nevaluated a slate of state-of-the-art models: Gemini 2.5 Pro, Claude 3.7\nSonnet, GPT-4o, and OpenAI o3. Excluding ties, experts preferred Gemini 2.5 Pro\nin 73.2% of these match-ups -- ranking it first overall in the arena. Gemini\n2.5 Pro also demonstrated markedly higher performance across key principles of\ngood pedagogy. Altogether, these results position Gemini 2.5 Pro as a leading\nmodel for learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.24477v1",
    "published": "2025-05-30T11:26:32+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24476v1",
    "title": "Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model",
    "authors": [
      "Yuting Zhang",
      "Hao Lu",
      "Qingyong Hu",
      "Yin Wang",
      "Kaishen Yuan",
      "Xin Liu",
      "Kaishun Wu"
    ],
    "abstract": "Periodic or quasi-periodic phenomena reveal intrinsic characteristics in\nvarious natural processes, such as weather patterns, movement behaviors,\ntraffic flows, and biological signals. Given that these phenomena span multiple\nmodalities, the capabilities of Multimodal Large Language Models (MLLMs) offer\npromising potential to effectively capture and understand their complex nature.\nHowever, current MLLMs struggle with periodic tasks due to limitations in: 1)\nlack of temporal modelling and 2) conflict between short and long periods. This\npaper introduces Period-LLM, a multimodal large language model designed to\nenhance the performance of periodic tasks across various modalities, and\nconstructs a benchmark of various difficulty for evaluating the cross-modal\nperiodic capabilities of large models. Specially, We adopt an \"Easy to Hard\nGeneralization\" paradigm, starting with relatively simple text-based tasks and\nprogressing to more complex visual and multimodal tasks, ensuring that the\nmodel gradually builds robust periodic reasoning capabilities. Additionally, we\npropose a \"Resisting Logical Oblivion\" optimization strategy to maintain\nperiodic reasoning abilities during semantic alignment. Extensive experiments\ndemonstrate the superiority of the proposed Period-LLM over existing MLLMs in\nperiodic tasks. The code is available at\nhttps://github.com/keke-nice/Period-LLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.24476v1",
    "published": "2025-05-30T11:23:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24475v1",
    "title": "SPPSFormer: High-quality Superpoint-based Transformer for Roof Plane Instance Segmentation from Point Clouds",
    "authors": [
      "Cheng Zeng",
      "Xiatian Qi",
      "Chi Chen",
      "Kai Sun",
      "Wangle Zhang",
      "Yuxuan Liu",
      "Yan Meng",
      "Bisheng Yang"
    ],
    "abstract": "Transformers have been seldom employed in point cloud roof plane instance\nsegmentation, which is the focus of this study, and existing superpoint\nTransformers suffer from limited performance due to the use of low-quality\nsuperpoints. To address this challenge, we establish two criteria that\nhigh-quality superpoints for Transformers should satisfy and introduce a\ncorresponding two-stage superpoint generation process. The superpoints\ngenerated by our method not only have accurate boundaries, but also exhibit\nconsistent geometric sizes and shapes, both of which greatly benefit the\nfeature learning of superpoint Transformers. To compensate for the limitations\nof deep learning features when the training set size is limited, we incorporate\nmultidimensional handcrafted features into the model. Additionally, we design a\ndecoder that combines a Kolmogorov-Arnold Network with a Transformer module to\nimprove instance prediction and mask extraction. Finally, our network's\npredictions are refined using traditional algorithm-based postprocessing. For\nevaluation, we annotated a real-world dataset and corrected annotation errors\nin the existing RoofN3D dataset. Experimental results show that our method\nachieves state-of-the-art performance on our dataset, as well as both the\noriginal and reannotated RoofN3D datasets. Moreover, our model is not sensitive\nto plane boundary annotations during training, significantly reducing the\nannotation burden. Through comprehensive experiments, we also identified key\nfactors influencing roof plane segmentation performance: in addition to roof\ntypes, variations in point cloud density, density uniformity, and 3D point\nprecision have a considerable impact. These findings underscore the importance\nof incorporating data augmentation strategies that account for point cloud\nquality to enhance model robustness under diverse and challenging conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24475v1",
    "published": "2025-05-30T11:23:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24474v1",
    "title": "Finsler and sub-Finsler geodesics with chattering",
    "authors": [
      "L. V. Lokutsievskiy",
      "M. I. Zelikin"
    ],
    "abstract": "In this paper, we provide examples of Finsler and sub-Finsler manifolds whose\ngeodesics exhibit chattering, that is, a countable number of switches over an\narbitrarily small time interval. We also present an explicit left-invariant\nstructure on a Carnot group whose geodesics exhibit chattering. This provides a\nnegative answer to Le Donne's question. Furthermore, the paper presents a\nsufficient condition for normal Pontryagin maximum principle extremals in\n(sub-)Finsler problems to exhibit chattering.",
    "pdf_url": "http://arxiv.org/pdf/2505.24474v1",
    "published": "2025-05-30T11:22:36+00:00",
    "categories": [
      "math.DG",
      "math.MG",
      "math.OC"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24473v2",
    "title": "Train One Sparse Autoencoder Across Multiple Sparsity Budgets to Preserve Interpretability and Accuracy",
    "authors": [
      "Nikita Balagansky",
      "Yaroslav Aksenov",
      "Daniil Laptev",
      "Vadim Kurochkin",
      "Gleb Gerasimov",
      "Nikita Koryagin",
      "Daniil Gavrilov"
    ],
    "abstract": "Sparse Autoencoders (SAEs) have proven to be powerful tools for interpreting\nneural networks by decomposing hidden representations into disentangled,\ninterpretable features via sparsity constraints. However, conventional SAEs are\nconstrained by the fixed sparsity level chosen during training; meeting\ndifferent sparsity requirements therefore demands separate models and increases\nthe computational footprint during both training and evaluation. We introduce a\nnovel training objective, \\emph{HierarchicalTopK}, which trains a single SAE to\noptimise reconstructions across multiple sparsity levels simultaneously.\nExperiments with Gemma-2 2B demonstrate that our approach achieves\nPareto-optimal trade-offs between sparsity and explained variance,\noutperforming traditional SAEs trained at individual sparsity levels. Further\nanalysis shows that HierarchicalTopK preserves high interpretability scores\neven at higher sparsity. The proposed objective thus closes an important gap\nbetween flexibility and interpretability in SAE design.",
    "pdf_url": "http://arxiv.org/pdf/2505.24473v2",
    "published": "2025-05-30T11:20:44+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24472v1",
    "title": "VietMix: A Naturally Occurring Vietnamese-English Code-Mixed Corpus with Iterative Augmentation for Machine Translation",
    "authors": [
      "Hieu Tran",
      "Phuong-Anh Nguyen-Le",
      "Huy Nghiem",
      "Quang-Nhan Nguyen",
      "Wei Ai",
      "Marine Carpuat"
    ],
    "abstract": "Machine translation systems fail when processing code-mixed inputs for\nlow-resource languages. We address this challenge by curating VietMix, a\nparallel corpus of naturally occurring code-mixed Vietnamese text paired with\nexpert English translations. Augmenting this resource, we developed a\ncomplementary synthetic data generation pipeline. This pipeline incorporates\nfiltering mechanisms to ensure syntactic plausibility and pragmatic\nappropriateness in code-mixing patterns. Experimental validation shows our\nnaturalistic and complementary synthetic data boost models' performance,\nmeasured by translation quality estimation scores, of up to 71.84 on COMETkiwi\nand 81.77 on XCOMET. Triangulating positive results with LLM-based assessments,\naugmented models are favored over seed fine-tuned counterparts in approximately\n49% of judgments (54-56% excluding ties). VietMix and our augmentation\nmethodology advance ecological validity in neural MT evaluations and establish\na framework for addressing code-mixed translation challenges across other\nlow-resource pairs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24472v1",
    "published": "2025-05-30T11:18:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24471v1",
    "title": "Crystal Growth & Physical Property Characterization of Mixed Topological Insulator BiSbTe$_3$",
    "authors": [
      "Dinesh Kumar",
      "Kapil Kumar",
      "N. K. Karn",
      "Ganesh Gurjar",
      "V. P. S. Awana",
      "Sudesh"
    ],
    "abstract": "This article reports the synthesis of a single crystalline mixed topological\ninsulator (TI) BiSbTe$_3$ and its detailed structural and magneto-transport\nproperties. The single crystalline samples of BiSbTe$_3$ are grown by the\nmelt-growth process and characterized by X-ray diffraction (XRD), Energy\ndispersive X-ray analysis (EDAX) and Raman spectroscopy. The single crystal XRD\npeaks dictated the growth direction along the c-axis. The Raman spectrum\nelucidated the characteristic peaks of the mixed topological insulator. The\nbroadening of Raman peaks exhibited the formation of Te-Bi-Te and Te-Sb-Te\nbonds and associated vibrational modes. The single crystals are characterized\nby magneto-transport measurements down to 2 K and up to 14 Tesla transverse\nmagnetic field. The residual resistance ratio (R200 K/R0 K) is found to be\n3.64, which endorses the metallic nature of the synthesized crystal. The\nrelative resistance turns out to be higher for the mixed TI than the pure TIs\ni.e., Bi$_2$Te$_3$ or Sb$_2$Te$_3$. The lower Debye temperature (82.64 K) of\nBiSbTe$_3$ connotes the presence of effective electron-phonon interaction at\nquite low temperatures in comparison to pure TI, which explains the observed\nsuppression in magnetoresistance (MR) for the mixed TI. At 2 K, an MR of 150\npercent is observed for BiSbTe$_3$, which is suppressed in contrast to the pure\nTIs i.e., Bi$_2$Te$_3$ or Sb$_2$Te$_3$. Though the MR% is suppressed\nsignificantly, its non-saturating linear behavior indicates the topological\nnature of the studied mixed TI. The modified Hikami-Larkin-Nagaoka (HLN)\nequation analysis of magneto-conductivity of mixed TI revealed that the\nconductivity has not only a surface states driven 2D component but also\ncontributions from the bulk charge carriers and quantum scattering.",
    "pdf_url": "http://arxiv.org/pdf/2505.24471v1",
    "published": "2025-05-30T11:16:07+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24470v1",
    "title": "Study of Curvature-Matter Coupling in Modified Gravity",
    "authors": [
      "Lakhan V. Jaybhaye"
    ],
    "abstract": "Over the past century, General Relativity (GR) has been a cornerstone of\ngravitational theory. However, recent cosmological observations, such as the\naccelerated expansion of the Universe, challenge its completeness and the\nstandard $\\Lambda$CDM model. This has motivated the development of alternative\napproaches, including dynamical dark energy and modifications to gravity. This\nthesis investigates the $f(R, L_m)$ gravity framework, which extends $f(R)$\ngravity by introducing curvature-matter coupling, to address unresolved issues\nin modern cosmology.\n  Chapter 1 reviews the foundations of cosmology, GR, and $\\Lambda$CDM,\ndiscussing their challenges and introducing modified gravity theories. Chapter\n2 studies cosmic expansion in a specific non-linear $f(R, L_m)$ model,\nanalyzing its dynamics using updated $H(z)$ and Pantheon datasets and\ndemonstrating a deceleration-to-acceleration transition. Chapter 3 introduces a\nmodel-independent Hubble parameter parametrization and explores cosmological\nvariables using MCMC and combined data. Chapter 4 incorporates bulk viscosity\ninto $f(R, L_m)$ models to explain late-time acceleration and applies Om\ndiagnostics and energy conditions. Chapter 5 examines non-singular matter\nbounce cosmologies, analyzing bouncing dynamics and the evolution of\ncosmographic parameters. Chapter 6 addresses gravitational baryogenesis and\nshows how $f(R, L_m)$ gravity supports the observed baryon-to-entropy ratio.\nChapter 7 summarizes the results and suggests directions for future work.",
    "pdf_url": "http://arxiv.org/pdf/2505.24470v1",
    "published": "2025-05-30T11:15:41+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.24469v1",
    "title": "Smooth Model Compression without Fine-Tuning",
    "authors": [
      "Christina Runkel",
      "Natacha Kuete Meli",
      "Jovita Lukasik",
      "Ander Biguri",
      "Carola-Bibiane Schönlieb",
      "Michael Moeller"
    ],
    "abstract": "Compressing and pruning large machine learning models has become a critical\nstep towards their deployment in real-world applications. Standard pruning and\ncompression techniques are typically designed without taking the structure of\nthe network's weights into account, limiting their effectiveness. We explore\nthe impact of smooth regularization on neural network training and model\ncompression. By applying nuclear norm, first- and second-order derivative\npenalties of the weights during training, we encourage structured smoothness\nwhile preserving predictive performance on par with non-smooth models. We find\nthat standard pruning methods often perform better when applied to these smooth\nmodels. Building on this observation, we apply a\nSingular-Value-Decomposition-based compression method that exploits the\nunderlying smooth structure and approximates the model's weight tensors by\nsmaller low-rank tensors. Our approach enables state-of-the-art compression\nwithout any fine-tuning - reaching up to $91\\%$ accuracy on a smooth ResNet-18\non CIFAR-10 with $70\\%$ fewer parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.24469v1",
    "published": "2025-05-30T11:13:48+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24468v2",
    "title": "Decoupling Electric Field and Temperature-Driven Atomistic Forming Mechanisms in TaOx/HfO2-Based ReRAMs using Reactive Molecular Dynamics Simulations",
    "authors": [
      "Simanta Lahkar",
      "Valeria Bragaglia",
      "Behnaz Bagheri",
      "Donato Francesco Falcone",
      "Matteo Galetta",
      "Marilyne Sousa",
      "Aida Todri-Sanial"
    ],
    "abstract": "Resistive random access memories (ReRAMs) with a bilayer TaOx/HfO2 stack\nstructure have shown unique multi-level resistive switching capabilities.\nHowever, the physical processes governing their behavior, and specifically the\natomistic mechanisms of forming, remain poorly understood. In this work, we\npresent a detailed analysis of the forming mechanism at the atomic level using\nmolecular dynamics (MD) simulations. An extended charge equilibration scheme,\nbased on a combination of the charge transfer ionic potential (CTIP) formalism\nand the electrochemical dynamics with implicit degrees of freedom (EChemDID)\nmethod, is employed to model the localized effects of applied voltage. Our\nsimulations reveal that tantalum ions exhibit the highest displacement under\napplied voltage, followed by hafnium ions, while oxygen ions respond only\nminimally. This results in the formation of a tantalum-depleted, oxygen-rich\nzone near the positive top electrode (anode), and the clustering of oxygen\nvacancies near the negative bottom electrode (cathode), where the conductive\nfilament nucleates. This ionic segregation partially shields the bulk\ndielectric from the applied electric field, hindering further migration of ions\nin the vertical direction. We find that a minimum threshold voltage is required\nto initiate vacancy clustering. Filament growth proceeds through a localized\nmechanism, driven by thermally activated generation of oxygen vacancy defects,\nwhich are stabilized near the edge of the nucleated filament at the cathode.",
    "pdf_url": "http://arxiv.org/pdf/2505.24468v2",
    "published": "2025-05-30T11:13:11+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24467v1",
    "title": "A universal constraint for relaxation rates for quantum Markov generators: complete positivity and beyond",
    "authors": [
      "Dariusz Chruściński",
      "Frederik vom Ende",
      "Gen Kimura",
      "Paolo Muratore-Ginanneschi"
    ],
    "abstract": "Relaxation rates are key characteristics of quantum processes, as they\ndetermine how quickly a quantum system thermalizes, equilibrates, decoheres,\nand dissipates. While they play a crucial role in theoretical analyses,\nrelaxation rates are also often directly accessible through experimental\nmeasurements. Recently, it was shown that for quantum processes governed by\nMarkovian semigroups, the relaxation rates satisfy a universal constraint: the\nmaximal rate is upper-bounded by the sum of all rates divided by the dimension\nof the Hilbert space. This bound, initially conjectured a few years ago, was\nonly recently proven using classical Lyapunov theory. In this work, we present\na new, purely algebraic proof of this constraint. Remarkably, our approach is\nnot only more direct but also allows for a natural generalization beyond\ncompletely positive semigroups. We show that complete positivity can be relaxed\nto 2-positivity without affecting the validity of the constraint. This reveals\nthat the bound is more subtle than previously understood: 2-positivity is\nnecessary, but even when further relaxed to Schwarz maps, a slightly weaker --\nyet still non-trivial -- universal constraint still holds. Finally, we explore\nthe connection between these bounds and the number of steady states in quantum\nprocesses, uncovering a deeper structure underlying their behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.24467v1",
    "published": "2025-05-30T11:11:40+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24466v2",
    "title": "SA-Person: Text-Based Person Retrieval with Scene-aware Re-ranking",
    "authors": [
      "Yingjia Xu",
      "Jinlin Wu",
      "Zhen Chen",
      "Daming Gao",
      "Yang Yang",
      "Zhen Lei",
      "Min Cao"
    ],
    "abstract": "Text-based person retrieval aims to identify a target individual from a\ngallery of images based on a natural language description. It presents a\nsignificant challenge due to the complexity of real-world scenes and the\nambiguity of appearance-related descriptions. Existing methods primarily\nemphasize appearance-based cross-modal retrieval, often neglecting the\ncontextual information embedded within the scene, which can offer valuable\ncomplementary insights for retrieval. To address this, we introduce\nSCENEPERSON-13W, a large-scale dataset featuring over 100,000 scenes with rich\nannotations covering both pedestrian appearance and environmental cues. Based\non this, we propose SA-Person, a two-stage retrieval framework. In the first\nstage, it performs discriminative appearance grounding by aligning textual cues\nwith pedestrian-specific regions. In the second stage, it introduces\nSceneRanker, a training-free, scene-aware re-ranking method leveraging\nmultimodal large language models to jointly reason over pedestrian appearance\nand the global scene context. Experiments on SCENEPERSON-13W validate the\neffectiveness of our framework in challenging scene-level retrieval scenarios.\nThe code and dataset will be made publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.24466v2",
    "published": "2025-05-30T11:10:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24465v1",
    "title": "Robust Evidence for Dynamical Dark Energy from DESI Galaxy-CMB Lensing Cross-Correlation and Geometric Probes",
    "authors": [
      "Miguel A. Sabogal",
      "Rafael C. Nunes"
    ],
    "abstract": "Recent analyses joining data from the Cosmic Microwave Background (CMB),\nBaryon Acoustic Oscillations (BAO), and Type Ia Supernovae (SNIa) have provided\nstrong evidence in favor of dynamical dark energy (DDE) over a simple\ncosmological constant. Motivated by these findings, we present new\nobservational constraints on DDE based on the cross-correlation between DESI\nLuminous Red Galaxies (LRG) samples and CMB lensing ($\\mathrm{CMB}_{\\kappa}\n\\times \\mathrm{LRG}$), which effectively probes the impact of cosmological\nparameters on the growth of structure at the perturbative level. We demonstrate\nthat, when combined with geometric measurements such as BAO and SNIa, this\ncross-correlation yields compelling statistical evidence for DDE exceeding\n$4\\sigma$, including within simpler parametrizations such as the $w$CDM model.\nRemarkably, this evidence is independent of constraints from primary Planck CMB\nanisotropies data. These results highlight the robustness and potential of\nGalaxy-CMB lensing cross-correlation as a powerful observational probe of the\ndark sector, particularly when used in conjunction with geometric observables.",
    "pdf_url": "http://arxiv.org/pdf/2505.24465v1",
    "published": "2025-05-30T11:09:02+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24464v1",
    "title": "Distributed gradient methods under heavy-tailed communication noise",
    "authors": [
      "Manojlo Vukovic",
      "Dusan Jakovetic",
      "Dragana Bajovic",
      "Soummya Kar"
    ],
    "abstract": "We consider a standard distributed optimization problem in which networked\nnodes collaboratively minimize the sum of their locally known convex costs. For\nthis setting, we address for the first time the fundamental problem of design\nand analysis of distributed methods to solve the above problem when inter-node\ncommunication is subject to \\emph{heavy-tailed} noise. Heavy-tailed noise is\nhighly relevant and frequently arises in densely deployed wireless sensor and\nInternet of Things (IoT) networks. Specifically, we design a distributed\ngradient-type method that features a carefully balanced mixed time-scale\ntime-varying consensus and gradient contribution step sizes and a bounded\nnonlinear operator on the consensus update to limit the effect of heavy-tailed\nnoise. Assuming heterogeneous strongly convex local costs with mutually\ndifferent minimizers that are arbitrarily far apart, we show that the proposed\nmethod converges to a neighborhood of the network-wide problem solution in the\nmean squared error (MSE) sense, and we also characterize the corresponding\nconvergence rate. We further show that the asymptotic MSE can be made\narbitrarily small through consensus step-size tuning, possibly at the cost of\nslowing down the transient error decay. Numerical experiments corroborate our\nfindings and demonstrate the resilience of the proposed method to heavy-tailed\n(and infinite variance) communication noise. They also show that existing\ndistributed methods, designed for finite-communication-noise-variance settings,\nfail in the presence of infinite variance noise.",
    "pdf_url": "http://arxiv.org/pdf/2505.24464v1",
    "published": "2025-05-30T11:07:21+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "90C25, 65K05"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24463v1",
    "title": "Assessing Future Wind Energy Potential under Climate Change: The Critical Role of Multi-Model Ensembles in Robustness Assessment",
    "authors": [
      "Andrea Lira-Loarca",
      "Francesco Ferrari",
      "Andrea Mazzino"
    ],
    "abstract": "Accurate projections of wind energy potential under climate change are\ncritical for effective long-term energy planning. While previous studies have\nhighlighted the value of multi-model ensembles, they often fall short in\ncapturing the full spectrum of uncertainties and temporal dynamics relevant to\nwind resource reliability. This paper presents one of the most comprehensive\nassessments to date, leveraging a large ensemble of 21 high-resolution RCM-GCM\ncombinations from the EURO-CORDEX initiative to evaluate future wind energy\nconditions across Europe under the RCP8.5 scenario. Moving beyond mean values,\nwe incorporate a novel event-based framework to analyze persistent high- and\nlow-wind episodes using ERA5-derived percentile thresholds -- capturing\noperationally critical conditions that influence turbine performance and grid\nstability. To ensure statistical rigor, we apply the IPCC AR6 `Approach C' for\nrobustness assessment, distinguishing climate signals from internal variability\nand quantifying model agreement. Crucially, we demonstrate that projections\nbased on limited sub-ensembles can lead to contradictory or misleading\nconclusions, underscoring the essential role of ensemble diversity. The\ncombination of spatial granularity, temporal detail, and formal uncertainty\nquantification makes this study a significant advancement in climate-informed\nwind energy research and a valuable tool for resilient energy system design.",
    "pdf_url": "http://arxiv.org/pdf/2505.24463v1",
    "published": "2025-05-30T11:07:18+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24462v1",
    "title": "JWST NIRISS Transmission Spectroscopy of the Super-Earth GJ 357b, a Favourable Target for Atmospheric Retention",
    "authors": [
      "Jake Taylor",
      "Michael Radica",
      "Richard D. Chatterjee",
      "Mark Hammond",
      "Tobias Meier",
      "Suzanne Aigrain",
      "Ryan J. MacDonald",
      "Loic Albert",
      "Björn Benneke",
      "Louis-Philippe Coulombe",
      "Nicolas B. Cowan",
      "Lisa Dang",
      "René Doyon",
      "Laura Flagg",
      "Doug Johnstone",
      "Lisa Kaltenegger",
      "David Lafrenière",
      "Stefan Pelletier",
      "Caroline Piaulet-Ghorayeb",
      "Jason F. Rowe",
      "Pierre-Alexis Roy"
    ],
    "abstract": "We present a JWST NIRISS/SOSS transmission spectrum of the super-Earth GJ 357\nb: the first atmospheric observation of this exoplanet. Despite missing the\nfirst $\\sim$40 % of the transit due to using an out-of-date ephemeris, we still\nrecover a transmission spectrum that does not display any clear signs of\natmospheric features. We perform a search for Gaussian-shaped absorption\nfeatures within the data but find that this analysis yields comparable fits to\nthe observations as a flat line. We compare the transmission spectrum to a grid\nof atmosphere models and reject, to 3-$\\sigma$ confidence, atmospheres with\nmetallicities $\\lesssim$100$\\times$ solar ($\\sim$4 g/mol) with clouds at\npressures down to 0.01 bar. We analyse how the retention of a secondary\natmosphere on GJ 357 b may be possible due to its higher escape velocity\ncompared to an Earth-sized planet and the exceptional inactivity of its host\nstar relative to other M2.5V stars. The star's XUV luminosity decays below the\nthreshold for rapid atmospheric escape early enough that the volcanic revival\nof an atmosphere of several bars of CO$_2$ is plausible, though subject to\nconsiderable uncertainty. Finally, we model the feasibility of detecting an\natmosphere on GJ 357 b with MIRI/LRS, MIRI photometry, and NIRSpec/G395H. We\nfind that, with two eclipses, it would be possible to detect features\nindicative of an atmosphere or surface. Further to this, with 3-4 transits, it\nwould be possible to detect a 1 bar nitrogen-rich atmosphere with 1000 ppm of\nCO$_2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24462v1",
    "published": "2025-05-30T11:05:38+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.03184v1",
    "title": "Impact of Tuning Parameters in Deep Convolutional Neural Network Using a Crack Image Dataset",
    "authors": [
      "Mahe Zabin",
      "Ho-Jin Choi",
      "Md. Monirul Islam",
      "Jia Uddin"
    ],
    "abstract": "The performance of a classifier depends on the tuning of its parame ters. In\nthis paper, we have experimented the impact of various tuning parameters on the\nperformance of a deep convolutional neural network (DCNN). In the ex perimental\nevaluation, we have considered a DCNN classifier that consists of 2\nconvolutional layers (CL), 2 pooling layers (PL), 1 dropout, and a dense layer.\nTo observe the impact of pooling, activation function, and optimizer tuning pa\nrameters, we utilized a crack image dataset having two classes: negative and\npos itive. The experimental results demonstrate that with the maxpooling, the\nDCNN demonstrates its better performance for adam optimizer and tanh activation\nfunc tion.",
    "pdf_url": "http://arxiv.org/pdf/2506.03184v1",
    "published": "2025-05-30T10:58:31+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24461v2",
    "title": "Logits-Based Finetuning",
    "authors": [
      "Jingyao Li",
      "Senqiao Yang",
      "Sitong Wu",
      "Han Shi",
      "Chuanyang Zheng",
      "Hong Xu",
      "Jiaya Jia"
    ],
    "abstract": "In recent years, developing compact and efficient large language models\n(LLMs) has emerged as a thriving area of research. Traditional Supervised\nFine-Tuning (SFT), which relies on singular ground truth labels, often fails to\ncapture token-level dependencies and linguistic diversity. To address these\nlimitations, we propose a logits-based fine-tuning framework that integrates\nthe strengths of supervised learning and knowledge distillation. Our approach\nconstructs enriched training targets by combining teacher logits with ground\ntruth labels, preserving both correctness and linguistic diversity. This\nensures more reliable and effective training. We constructed a large-scale 1.2M\nlogits dataset and trained a series of science-focused models. Experimental\nresults demonstrate that our method achieves significant improvements, with\naccuracy gains of 18% on Mawps and 22.7% on TabMWP. Across nine widely used\nmathematical benchmarks, our method consistently outperforms prior SFT models,\nachieving an average improvement of 7.28%. Codes are available at\nhttps://github.com/dvlab-research/Logits-Based-Finetuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.24461v2",
    "published": "2025-05-30T10:57:09+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.15708v1",
    "title": "Refined Causal Graph Structure Learning via Curvature for Brain Disease Classification",
    "authors": [
      "Falih Gozi Febrinanto",
      "Adonia Simango",
      "Chengpei Xu",
      "Jingjing Zhou",
      "Jiangang Ma",
      "Sonika Tyagi",
      "Feng Xia"
    ],
    "abstract": "Graph neural networks (GNNs) have been developed to model the relationship\nbetween regions of interest (ROIs) in brains and have shown significant\nimprovement in detecting brain diseases. However, most of these frameworks do\nnot consider the intrinsic relationship of causality factor between brain ROIs,\nwhich is arguably more essential to observe cause and effect interaction\nbetween signals rather than typical correlation values. We propose a novel\nframework called CGB (Causal Graphs for Brains) for brain disease\nclassification/detection, which models refined brain networks based on the\ncausal discovery method, transfer entropy, and geometric curvature strategy.\nCGB unveils causal relationships between ROIs that bring vital information to\nenhance brain disease classification performance. Furthermore, CGB also\nperforms a graph rewiring through a geometric curvature strategy to refine the\ngenerated causal graph to become more expressive and reduce potential\ninformation bottlenecks when GNNs model it. Our extensive experiments show that\nCGB outperforms state-of-the-art methods in classification tasks on brain\ndisease datasets, as measured by average F1 scores.",
    "pdf_url": "http://arxiv.org/pdf/2506.15708v1",
    "published": "2025-05-30T10:50:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24460v1",
    "title": "Frictions and Welfare in Monopolistic Competition",
    "authors": [
      "Francesco Del Prato",
      "Paolo Zacchia"
    ],
    "abstract": "In a heterogeneous firm economy with monopolistic competition, could\ninformational asymmetries between entrepreneurs and financial intermediaries\nsometimes improve welfare? We study this question by developing a model where\nbanks finance entrepreneurs under asymmetric information. While aggregate\nproductivity decreases with informational frictions, we find that welfare can\nbe maximized at intermediate levels of information asymmetry due to a trade-off\nbetween productivity and product variety. Additionally, moderate input cost\ndistortions can improve welfare when financial frictions are severe by\noffsetting the resulting weak firm selection.",
    "pdf_url": "http://arxiv.org/pdf/2505.24460v1",
    "published": "2025-05-30T10:47:57+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.24459v1",
    "title": "Quantum Search for Gravitational Wave of Massive Black Hole Binaries",
    "authors": [
      "Fangzhou Guo",
      "Jibo He"
    ],
    "abstract": "Matched filtering is a common method for detecting gravitational waves.\nHowever, the computational costs of searching large template banks limit the\nefficiency of classical algorithms when searching for massive black hole binary\n(MBHB) systems. In this work, a quantum matched filtering algorithm based on\nGrover's algorithm is applied to the MBHB signals. It is demonstrated that the\nquantum approach can reduce the computational complexity from $O(N)$ to\n$O(\\sqrt{N})$ theoretically, where $N$ is the size of the template bank.\nSimulated results indicate that the quantum-enhanced approach significantly\nreduces computational costs. However, it is also found that the performance can\ndegrade in some cases due to instability of the algorithm. This highlights the\nneed for more robust and stable quantum search strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.24459v1",
    "published": "2025-05-30T10:47:37+00:00",
    "categories": [
      "astro-ph.IM",
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24458v1",
    "title": "SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors",
    "authors": [
      "Tianlong Yu",
      "Chenghang Ye",
      "Zheyu Yang",
      "Ziyi Zhou",
      "Cui Tang",
      "Zui Tao",
      "Jun Zhang",
      "Kailong Wang",
      "Liting Zhou",
      "Yang Yang",
      "Ting Bi"
    ],
    "abstract": "The SEAR Dataset is a novel multimodal resource designed to study the\nemerging threat of social engineering (SE) attacks orchestrated through\naugmented reality (AR) and multimodal large language models (LLMs). This\ndataset captures 180 annotated conversations across 60 participants in\nsimulated adversarial scenarios, including meetings, classes and networking\nevents. It comprises synchronized AR-captured visual/audio cues (e.g., facial\nexpressions, vocal tones), environmental context, and curated social media\nprofiles, alongside subjective metrics such as trust ratings and susceptibility\nassessments. Key findings reveal SEAR's alarming efficacy in eliciting\ncompliance (e.g., 93.3% phishing link clicks, 85% call acceptance) and\nhijacking trust (76.7% post-interaction trust surge). The dataset supports\nresearch in detecting AR-driven SE attacks, designing defensive frameworks, and\nunderstanding multimodal adversarial manipulation. Rigorous ethical safeguards,\nincluding anonymization and IRB compliance, ensure responsible use. The SEAR\ndataset is available at https://github.com/INSLabCN/SEAR-Dataset.",
    "pdf_url": "http://arxiv.org/pdf/2505.24458v1",
    "published": "2025-05-30T10:46:13+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24457v1",
    "title": "Climate impacts and monetary costs of healthy diets worldwide",
    "authors": [
      "Yan Bai",
      "Elena M. Martinez",
      "Mizuki Yamanaka",
      "Marko Rissanen",
      "Anna Herforth",
      "William A. Masters"
    ],
    "abstract": "About 2.8 billion people worldwide cannot afford the least expensive foods\nrequired for a healthy diet. Since 2020, the Cost and Affordability of a\nHealthy Diet (CoAHD) has been published for all countries by FAO and the World\nBank and is widely used to guide social protection, agricultural, and public\nhealth and nutrition policies. Here, we measure how healthy diets could be\nobtained with the lowest possible greenhouse gas (GHG) emissions, in ways that\ncould further inform food choice and policy decisions toward sustainability\ngoals. We find that the lowest possible GHG emissions for a healthy diet in\n2021 would emit 0.67 kg CO2e (SD=0.10) and cost USD 6.95 (SD=1.86) per day,\nwhile each country's lowest-priced items would emit 1.65 kg CO2e (SD=0.56) and\ncost USD 3.68 (SD=0.75). Healthy diets with foods in proportions actually\nconsumed in each country would emit 2.44 kg CO2e (SD=1.27) and cost USD 9.96\n(SD=4.92). Differences in emissions are driven by item selection within\nanimal-source foods, and starchy staples to a lesser extent, with only minor\ndifferences in other food groups. Results show how changes in agricultural\npolicy and food choice can most cost-effectively support healthier and more\nsustainable diets worldwide.",
    "pdf_url": "http://arxiv.org/pdf/2505.24457v1",
    "published": "2025-05-30T10:44:03+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.24456v1",
    "title": "CaMMT: Benchmarking Culturally Aware Multimodal Machine Translation",
    "authors": [
      "Emilio Villa-Cueva",
      "Sholpan Bolatzhanova",
      "Diana Turmakhan",
      "Kareem Elzeky",
      "Henok Biadglign Ademtew",
      "Alham Fikri Aji",
      "Israel Abebe Azime",
      "Jinheon Baek",
      "Frederico Belcavello",
      "Fermin Cristobal",
      "Jan Christian Blaise Cruz",
      "Mary Dabre",
      "Raj Dabre",
      "Toqeer Ehsan",
      "Naome A Etori",
      "Fauzan Farooqui",
      "Jiahui Geng",
      "Guido Ivetta",
      "Thanmay Jayakumar",
      "Soyeong Jeong",
      "Zheng Wei Lim",
      "Aishik Mandal",
      "Sofia Martinelli",
      "Mihail Minkov Mihaylov",
      "Daniil Orel",
      "Aniket Pramanick",
      "Sukannya Purkayastha",
      "Israfel Salazar",
      "Haiyue Song",
      "Tiago Timponi Torrent",
      "Debela Desalegn Yadeta",
      "Injy Hamed",
      "Atnafu Lambebo Tonja",
      "Thamar Solorio"
    ],
    "abstract": "Cultural content poses challenges for machine translation systems due to the\ndifferences in conceptualizations between cultures, where language alone may\nfail to convey sufficient context to capture region-specific meanings. In this\nwork, we investigate whether images can act as cultural context in multimodal\ntranslation. We introduce CaMMT, a human-curated benchmark of over 5,800\ntriples of images along with parallel captions in English and regional\nlanguages. Using this dataset, we evaluate five Vision Language Models (VLMs)\nin text-only and text+image settings. Through automatic and human evaluations,\nwe find that visual context generally improves translation quality, especially\nin handling Culturally-Specific Items (CSIs), disambiguation, and correct\ngender usage. By releasing CaMMT, we aim to support broader efforts in building\nand evaluating multimodal translation systems that are better aligned with\ncultural nuance and regional variation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24456v1",
    "published": "2025-05-30T10:42:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24455v1",
    "title": "Domain Pre-training Impact on Representations",
    "authors": [
      "Cesar Gonzalez-Gutierrez",
      "Ariadna Quattoni"
    ],
    "abstract": "This empirical study analyzes the effects of the pre-training corpus on the\nquality of learned transformer representations. We focus on the representation\nquality induced solely through pre-training. Our experiments show that\npre-training on a small, specialized corpus can yield effective\nrepresentations, and that the success of combining a generic and a specialized\ncorpus depends on the distributional similarity between the target task and the\nspecialized corpus.",
    "pdf_url": "http://arxiv.org/pdf/2505.24455v1",
    "published": "2025-05-30T10:42:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24454v1",
    "title": "An inverse problem for the Standard Model of particle physics",
    "authors": [
      "Xi Chen",
      "Matti Lassas",
      "Lauri Oksanen",
      "Gabriel P. Paternain"
    ],
    "abstract": "We pose and solve an inverse problem for the classical field equations that\narise in the Standard Model of particle physics. Our main result describes\nnatural conditions on the representations, so that it is possible to recover\nall the fields from measurements in a small set within a causal domain in\nMinkowski space. These conditions are satisfied for the representations arising\nin the Standard Model.",
    "pdf_url": "http://arxiv.org/pdf/2505.24454v1",
    "published": "2025-05-30T10:38:53+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "35R30"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24453v1",
    "title": "Disordering a permutation symmetric system: revivals, thermalization and chaos",
    "authors": [
      "Manju C",
      "Uma Divakaran",
      "Arul Lakshminarayan"
    ],
    "abstract": "This study explores the effects of introducing a symmetry breaking disorder\non the dynamics of a system invariant under particle permutation. The disorder\nforces quantum states, confined to the $N+1$ dimensional completely symmetric\nspace to penetrate the exponentially large $2^N$ dimensional Hilbert space of\n$N$ particles. In particular, we focus on the quantum kicked top as a Floquet\nsystem of $N$ qubits, and use linear entropy, measuring single qubit\nentanglement, to investigate the changes in the time scales and values of\nsaturation when disorder is introduced. In the near-integrable regime of the\nkicked top, we study the robustness of quantum revivals to disorder. We also\nfind that a classical calculation yields the quantum single qubit entanglement\nto remarkable accuracy in the disorder free limit. The disorder, on the other\nhand, is modeled in the form of noise which again fits well with the numerical\ncalculations. We measure the extent to which the dynamics is retained within\nthe symmetric subspace and its spreading to the full Hilbert space using\ndifferent quantities. We show that increasing disorder drives the system to a\nchaotic phase in full Hilbert space, as also supported by the spectral\nstatistics. We find that there is robustness to disorder in the system, and\nthis is a function of how chaotic the kicked top is.",
    "pdf_url": "http://arxiv.org/pdf/2505.24453v1",
    "published": "2025-05-30T10:38:07+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "nlin.CD"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24452v3",
    "title": "Stepsize anything: A unified learning rate schedule for budgeted-iteration training",
    "authors": [
      "Anda Tang",
      "Yiming Dong",
      "Yutao Zeng",
      "zhou Xun",
      "Zhouchen Lin"
    ],
    "abstract": "The expanding computational costs and limited resources underscore the\ncritical need for budgeted-iteration training, which aims to achieve optimal\nlearning within predetermined iteration budgets. While learning rate schedules\nfundamentally govern the performance of different networks and tasks,\nparticularly in budgeted-iteration scenarios, their design remains largely\nheuristic, lacking theoretical foundations. In addition, the optimal learning\nrate schedule requires extensive trial-and-error selection, making the training\nprocess inefficient. In this work, we propose the Unified Budget-Aware (UBA)\nschedule, a theoretically grounded learning rate schedule that consistently\noutperforms commonly-used schedules among diverse architectures and tasks under\ndifferent constrained training budgets. First, we bridge the gap by\nconstructing a novel training budget-aware optimization framework, which\nexplicitly accounts for the robustness to landscape curvature variations. From\nthis framework, we derive the UBA schedule, controlled by a single\nhyper-parameter \\varphi that provides a trade-off between flexibility and\nsimplicity, eliminating the need for per-network numerical optimization.\nMoreover, we establish a theoretical connection between \\varphi and the\ncondition number, adding interpretation and justification to our approach.\nBesides, we prove the convergence for different values of \\varphi. We offer\npractical guidelines for its selection via theoretical analysis and empirical\nresults. Extensive experimental results show that UBA consistently surpasses\nthe commonly-used schedules across diverse vision and language tasks, spanning\nnetwork architectures (e.g., ResNet, OLMo) and scales, under different\ntraining-iteration budgets.",
    "pdf_url": "http://arxiv.org/pdf/2505.24452v3",
    "published": "2025-05-30T10:38:03+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24451v1",
    "title": "LPASS: Linear Probes as Stepping Stones for vulnerability detection using compressed LLMs",
    "authors": [
      "Luis Ibanez-Lissen",
      "Lorena Gonzalez-Manzano",
      "Jose Maria de Fuentes",
      "Nicolas Anciaux"
    ],
    "abstract": "Large Language Models (LLMs) are being extensively used for cybersecurity\npurposes. One of them is the detection of vulnerable codes. For the sake of\nefficiency and effectiveness, compression and fine-tuning techniques are being\ndeveloped, respectively. However, they involve spending substantial\ncomputational efforts. In this vein, we analyse how Linear Probes (LPs) can be\nused to provide an estimation on the performance of a compressed LLM at an\nearly phase -- before fine-tuning. We also show their suitability to set the\ncut-off point when applying layer pruning compression. Our approach, dubbed\n$LPASS$, is applied in BERT and Gemma for the detection of 12 of MITRE's Top 25\nmost dangerous vulnerabilities on 480k C/C++ samples. LPs can be computed in\n142.97 s. and provide key findings: (1) 33.3 \\% and 72.2\\% of layers can be\nremoved, respectively, with no precision loss; (2) they provide an early\nestimate of the post-fine-tuning and post-compression model effectiveness, with\n3\\% and 8.68\\% as the lowest and average precision errors, respectively.\n$LPASS$-based LLMs outperform the state of the art, reaching 86.9\\% of accuracy\nin multi-class vulnerability detection. Interestingly, $LPASS$-based compressed\nversions of Gemma outperform the original ones by 1.6\\% of F1-score at a\nmaximum while saving 29.4 \\% and 23.8\\% of training and inference time and\n42.98\\% of model size.",
    "pdf_url": "http://arxiv.org/pdf/2505.24451v1",
    "published": "2025-05-30T10:37:14+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24450v2",
    "title": "SuPseudo: A Pseudo-supervised Learning Method for Neural Speech Enhancement in Far-field Speech Recognition",
    "authors": [
      "Longjie Luo",
      "Lin Li",
      "Qingyang Hong"
    ],
    "abstract": "Due to the lack of target speech annotations in real-recorded far-field\nconversational datasets, speech enhancement (SE) models are typically trained\non simulated data. However, the trained models often perform poorly in\nreal-world conditions, hindering their application in far-field speech\nrecognition. To address the issue, we (a) propose direct sound estimation (DSE)\nto estimate the oracle direct sound of real-recorded data for SE; and (b)\npresent a novel pseudo-supervised learning method, SuPseudo, which leverages\nDSE-estimates as pseudo-labels and enables SE models to directly learn from and\nadapt to real-recorded data, thereby improving their generalization capability.\nFurthermore, an SE model called FARNET is designed to fully utilize SuPseudo.\nExperiments on the MISP2023 corpus demonstrate the effectiveness of SuPseudo,\nand our system significantly outperforms the previous state-of-the-art. A demo\nof our method can be found at https://EeLLJ.github.io/SuPseudo/.",
    "pdf_url": "http://arxiv.org/pdf/2505.24450v2",
    "published": "2025-05-30T10:36:32+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24449v1",
    "title": "When Large Multimodal Models Confront Evolving Knowledge:Challenges and Pathways",
    "authors": [
      "Kailin Jiang",
      "Yuntao Du",
      "Yukai Ding",
      "Yuchen Ren",
      "Ning Jiang",
      "Zhi Gao",
      "Zilong Zheng",
      "Lei Liu",
      "Bin Li",
      "Qing Li"
    ],
    "abstract": "Large language/multimodal models (LLMs/LMMs) store extensive pre-trained\nknowledge but struggle to maintain consistency with real-world updates, making\nit difficult to avoid catastrophic forgetting while acquiring evolving\nknowledge. Previous work focused on constructing textual knowledge datasets and\nexploring knowledge injection in LLMs, lacking exploration of multimodal\nevolving knowledge injection in LMMs. To address this, we propose the EVOKE\nbenchmark to evaluate LMMs' ability to inject multimodal evolving knowledge in\nreal-world scenarios. Meanwhile, a comprehensive evaluation of multimodal\nevolving knowledge injection revealed two challenges: (1) Existing knowledge\ninjection methods perform terribly on evolving knowledge. (2) Supervised\nfine-tuning causes catastrophic forgetting, particularly instruction following\nability is severely compromised. Additionally, we provide pathways and find\nthat: (1) Text knowledge augmentation during the training phase improves\nperformance, while image augmentation cannot achieve it. (2) Continual learning\nmethods, especially Replay and MoELoRA, effectively mitigate forgetting. Our\nfindings indicate that current knowledge injection methods have many\nlimitations on evolving knowledge, which motivates further research on more\nefficient and stable knowledge injection methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24449v1",
    "published": "2025-05-30T10:36:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24448v1",
    "title": "Exploring the Impact of Occupational Personas on Domain-Specific QA",
    "authors": [
      "Eojin Kang",
      "Jaehyuk Yu",
      "Juae Kim"
    ],
    "abstract": "Recent studies on personas have improved the way Large Language Models (LLMs)\ninteract with users. However, the effect of personas on domain-specific\nquestion-answering (QA) tasks remains a subject of debate. This study analyzes\nwhether personas enhance specialized QA performance by introducing two types of\npersona: Profession-Based Personas (PBPs) (e.g., scientist), which directly\nrelate to domain expertise, and Occupational Personality-Based Personas (OPBPs)\n(e.g., scientific person), which reflect cognitive tendencies rather than\nexplicit expertise. Through empirical evaluations across multiple scientific\ndomains, we demonstrate that while PBPs can slightly improve accuracy, OPBPs\noften degrade performance, even when semantically related to the task. Our\nfindings suggest that persona relevance alone does not guarantee effective\nknowledge utilization and that they may impose cognitive constraints that\nhinder optimal knowledge application. Future research can explore how nuanced\ndistinctions in persona representations guide LLMs, potentially contributing to\nreasoning and knowledge retrieval that more closely mirror human social\nconceptualization.",
    "pdf_url": "http://arxiv.org/pdf/2505.24448v1",
    "published": "2025-05-30T10:35:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24447v1",
    "title": "Frustrated vacancy ordering creates novel quantum properties in Kutinaite, $\\mathrm{Ag}_{6}\\mathrm{Cu}_{14.4}\\mathrm{As}_7$",
    "authors": [
      "Kim-Khuong Huynh",
      "Rasmus Baden Stubkjær",
      "Ventrapati Pavankumar",
      "Emilie Skytte Vosegaard",
      "Karl Omer Rimon Juul",
      "Kasper Rasmussen Borup",
      "Yong P. Chen",
      "Bo Brummerstedt Iversen"
    ],
    "abstract": "Ideal crystals are fully ordered, but real-world crystals always contain\ndefects breaking translational symmetry. Random defects in crystals have\nimportant implications and they e.g. provide the foundation for\nsemiconductor-based electronic devices. Structurally correlated defects\nintroduce an additional level of complexity, which may lead to novel materials\nproperties, but rationalization of relations between correlated disorder and\nthe emergent material properties are very rare. Here we report that the defect\nstructure of the mineral Kutinaite, Ag6Cu14.4As7, exhibits unprecedented\nmetallic diamagnetism, a hallmark of non-trivial electronic states that require\ndelicate symmetrical protection. Using a combination of X-ray scattering\nmethodologies, simulations, and physical property measurements, we deduced and\nverified subtle frustrated vacancy ordering of the Cu sublattice when cooling\ncrystals below ~300 K. The vacancy frustration in Kutinaite leads to unique\nquantum properties, and our study calls for a reconsideration of the role of\nvacancies as quasi-chemical species in crystals.",
    "pdf_url": "http://arxiv.org/pdf/2505.24447v1",
    "published": "2025-05-30T10:35:38+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2506.02029v1",
    "title": "Axioms of Quantum Mechanics in light of Continuous Model Theory",
    "authors": [
      "Boris Zilber"
    ],
    "abstract": "The aim of this note is to recast somewhat informal axiom system of quantum\nmechanics used by physicists (Dirac calculus) in the language of Continuous\nLogic.\n  We note an analogy between Tarski's notion of cylindric algebras, as a tool\nof algebraisation of first order logic, and Hilbert spaces which can serve the\nsame purpose for continuous logic of physics. The aim of this note is to recast\nsomewhat informal axiom system of quantum mechanics used by physicists (Dirac\ncalculus) in the language of Continuous Logic.\n  We note an analogy between Tarski's notion of cylindric algebras, as a tool\nof algebraisation of first order logic, and Hilbert spaces which can serve the\nsame purpose for continuous logic of physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.02029v1",
    "published": "2025-05-30T10:33:56+00:00",
    "categories": [
      "math.LO",
      "quant-ph",
      "03C66,"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24446v2",
    "title": "Pseudo Labels-based Neural Speech Enhancement for the AVSR Task in the MISP-Meeting Challenge",
    "authors": [
      "Longjie Luo",
      "Shenghui Lu",
      "Lin Li",
      "Qingyang Hong"
    ],
    "abstract": "This paper presents our system for the MISP-Meeting Challenge Track 2. The\nprimary difficulty lies in the dataset, which contains strong background noise,\nreverberation, overlapping speech, and diverse meeting topics. To address these\nissues, we (a) designed G-SpatialNet, a speech enhancement (SE) model to\nimprove Guided Source Separation (GSS) signals; (b) proposed TLS, a framework\ncomprising time alignment, level alignment, and signal-to-noise ratio\nfiltering, to generate signal-level pseudo labels for real-recorded far-field\naudio data, thereby facilitating SE models' training; and (c) explored\nfine-tuning strategies, data augmentation, and multimodal information to\nenhance the performance of pre-trained Automatic Speech Recognition (ASR)\nmodels in meeting scenarios. Finally, our system achieved character error rates\n(CERs) of 5.44% and 9.52% on the Dev and Eval sets, respectively, with relative\nimprovements of 64.8% and 52.6% over the baseline, securing second place.",
    "pdf_url": "http://arxiv.org/pdf/2505.24446v2",
    "published": "2025-05-30T10:33:54+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.00094v1",
    "title": "Feeling Guilty Being a c(ai)borg: Navigating the Tensions Between Guilt and Empowerment in AI Use",
    "authors": [
      "Konstantin Aal",
      "Tanja Aal",
      "Vasil Navumau",
      "David Unbehaun",
      "Claudia Müller",
      "Volker Wulf",
      "Sarah Rüller"
    ],
    "abstract": "This paper explores the emotional, ethical and practical dimensions of\nintegrating Artificial Intelligence (AI) into personal and professional\nworkflows, focusing on the concept of feeling guilty as a 'c(ai)borg' - a human\naugmented by AI. Inspired by Donna Haraway's Cyborg Manifesto, the study\nexplores how AI challenges traditional notions of creativity, originality and\nintellectual labour. Using an autoethnographic approach, the authors reflect on\ntheir year-long experiences with AI tools, revealing a transition from initial\nguilt and reluctance to empowerment through skill-building and transparency.\nKey findings highlight the importance of basic academic skills, advanced AI\nliteracy and honest engagement with AI results. The c(ai)borg vision advocates\nfor a future where AI is openly embraced as a collaborative partner, fostering\ninnovation and equity while addressing issues of access and agency. By\nreframing guilt as growth, the paper calls for a thoughtful and inclusive\napproach to AI integration.",
    "pdf_url": "http://arxiv.org/pdf/2506.00094v1",
    "published": "2025-05-30T10:33:04+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "K.4.3"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24445v1",
    "title": "Learning Safety Constraints for Large Language Models",
    "authors": [
      "Xin Chen",
      "Yarden As",
      "Andreas Krause"
    ],
    "abstract": "Large language models (LLMs) have emerged as powerful tools but pose\nsignificant safety risks through harmful outputs and vulnerability to\nadversarial attacks. We propose SaP, short for Safety Polytope, a geometric\napproach to LLM safety that learns and enforces multiple safety constraints\ndirectly in the model's representation space. We develop a framework that\nidentifies safe and unsafe regions via the polytope's facets, enabling both\ndetection and correction of unsafe outputs through geometric steering. Unlike\nexisting approaches that modify model weights, SaP operates post-hoc in the\nrepresentation space, preserving model capabilities while enforcing safety\nconstraints. Experiments across multiple LLMs demonstrate that our method can\neffectively detect unethical inputs, reduce adversarial attack success rates\nwhile maintaining performance on standard tasks, thus highlighting the\nimportance of having an explicit geometric model for safety. Analysis of the\nlearned polytope facets reveals emergence of specialization in detecting\ndifferent semantic notions of safety, providing interpretable insights into how\nsafety is captured in LLMs' representation space.",
    "pdf_url": "http://arxiv.org/pdf/2505.24445v1",
    "published": "2025-05-30T10:30:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.05374v2",
    "title": "A New Representation of Binary Sequences by means of Boolean Functions",
    "authors": [
      "S. D. Cardell",
      "A. Fuúter-Sabater",
      "V. Requena",
      "M. Beltrá"
    ],
    "abstract": "Boolean functions and binary sequences are main tools used in cryptography.\nIn this work, we introduce a new bijection between the set of Boolean functions\nand the set of binary sequences with period a power of two. We establish a\nconnection between them which allows us to study some properties of Boolean\nfunctions through binary sequences and vice versa. Then, we define a new\nrepresentation of sequences, based on Boolean functions and derived from the\nalgebraic normal form, named reverse-ANF. Next, we study the relation between\nsuch a representation and other representations of Boolean functions as well as\nbetween such a representation and the binary sequences. Finally, we analyse the\ngeneralized self-shrinking sequences in terms of Boolean functions and some of\ntheir properties using the different representations.",
    "pdf_url": "http://arxiv.org/pdf/2506.05374v2",
    "published": "2025-05-30T10:28:45+00:00",
    "categories": [
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24444v1",
    "title": "Simulation of pulsed dynamic nuclear polarization in the steady state",
    "authors": [
      "Shebha Anandhi Jegadeesan",
      "Yujie Zhao",
      "Graham M. Smith",
      "Ilya Kuprov",
      "Guinevere Mathies"
    ],
    "abstract": "In pulsed dynamic nuclear polarization (DNP), enhancement of the polarization\nof bulk nuclei requires the repeated application of a microwave pulse sequence.\nSo far, analysis of a one-time transfer of electron spin polarization to a\ndipolar-coupled nuclear spin has guided the design of DNP pulse sequences. This\nhas obvious shortcomings, such as an inability to predict the optimal\nrepetition time. In an actual pulsed DNP experiment, a balance is reached\nbetween the polarization arriving from the unpaired electrons and nuclear\nrelaxation. In this article, we explore three algorithms to compute this\nstroboscopic steady state: (1) explicit time evolution by propagator squaring,\n(2) generation of an effective propagator using the matrix logarithm, and (3)\ndirect calculation of the steady state with the Newton-Raphson method.\nAlgorithm (2) is numerically unstable for this purpose. Algorithm (1) and (3)\nare both stable; algorithm (3) is the most efficient. We compare the\nsteady-state simulations to existing experimental results at 0.34 T and 1.2 T\nand to the first experimental observation of X-inverse-X (XiX) DNP at 3.4 T:\nagreement is good, and improves further when electron-proton distance and\nelectron Rabi frequency distributions are accounted for. We demonstrate that\nthe trajectory of the spin system during one-time application of a microwave\npulse sequence differs from the steady orbit. This has implications for DNP\npulse sequence design.",
    "pdf_url": "http://arxiv.org/pdf/2505.24444v1",
    "published": "2025-05-30T10:25:17+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24443v1",
    "title": "Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers",
    "authors": [
      "Heejo Kong",
      "Sung-Jin Kim",
      "Gunho Jung",
      "Seong-Whan Lee"
    ],
    "abstract": "Conventional semi-supervised learning (SSL) ideally assumes that labeled and\nunlabeled data share an identical class distribution, however in practice, this\nassumption is easily violated, as unlabeled data often includes unknown class\ndata, i.e., outliers. The outliers are treated as noise, considerably degrading\nthe performance of SSL models. To address this drawback, we propose a novel\nframework, Diversify and Conquer (DAC), to enhance SSL robustness in the\ncontext of open-set semi-supervised learning. In particular, we note that\nexisting open-set SSL methods rely on prediction discrepancies between inliers\nand outliers from a single model trained on labeled data. This approach can be\neasily failed when the labeled data is insufficient, leading to performance\ndegradation that is worse than naive SSL that do not account for outliers. In\ncontrast, our approach exploits prediction disagreements among multiple models\nthat are differently biased towards the unlabeled distribution. By leveraging\nthe discrepancies arising from training on unlabeled data, our method enables\nrobust outlier detection even when the labeled data is underspecified. Our key\ncontribution is constructing a collection of differently biased models through\na single training process. By encouraging divergent heads to be differently\nbiased towards outliers while making consistent predictions for inliers, we\nexploit the disagreement among these heads as a measure to identify unknown\nconcepts. Our code is available at https://github.com/heejokong/DivCon.",
    "pdf_url": "http://arxiv.org/pdf/2505.24443v1",
    "published": "2025-05-30T10:24:30+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24442v1",
    "title": "RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation",
    "authors": [
      "Zhentao Xie",
      "Chengcheng Han",
      "Jinxin Shi",
      "Wenjun Cui",
      "Xin Zhao",
      "Xingjiao Wu",
      "Jiabao Zhao"
    ],
    "abstract": "Although multi-agent systems based on large language models show strong\ncapabilities on multiple tasks, they are still limited by high computational\noverhead, information loss, and robustness. Inspired by ResNet's residual\nlearning, we propose Residual Mixture-of-Agents (RMoA), integrating residual\nconnections to optimize efficiency and reliability. To maximize information\nutilization from model responses while minimizing computational costs, we\ninnovatively design an embedding-based diversity selection mechanism that\ngreedily selects responses via vector similarity. Furthermore, to mitigate\niterative information degradation, we introduce a Residual Extraction Agent to\npreserve cross-layer incremental information by capturing inter-layer response\ndifferences, coupled with a Residual Aggregation Agent for hierarchical\ninformation integration. Additionally, we propose an adaptive termination\nmechanism that dynamically halts processing based on residual convergence,\nfurther improving inference efficiency. RMoA achieves state-of-the-art\nperformance on the benchmarks of across alignment, mathematical reasoning, code\ngeneration, and multitasking understanding, while significantly reducing\ncomputational overhead. Code is available at\nhttps://github.com/mindhunter01/RMoA.",
    "pdf_url": "http://arxiv.org/pdf/2505.24442v1",
    "published": "2025-05-30T10:23:11+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24441v1",
    "title": "SORCE: Small Object Retrieval in Complex Environments",
    "authors": [
      "Chunxu Liu",
      "Chi Xie",
      "Xiaxu Chen",
      "Wei Li",
      "Feng Zhu",
      "Rui Zhao",
      "Limin Wang"
    ],
    "abstract": "Text-to-Image Retrieval (T2IR) is a highly valuable task that aims to match a\ngiven textual query to images in a gallery. Existing benchmarks primarily focus\non textual queries describing overall image semantics or foreground salient\nobjects, possibly overlooking inconspicuous small objects, especially in\ncomplex environments. Such small object retrieval is crucial, as in real-world\napplications, the targets of interest are not always prominent in the image.\nThus, we introduce SORCE (Small Object Retrieval in Complex Environments), a\nnew subfield of T2IR, focusing on retrieving small objects in complex images\nwith textual queries. We propose a new benchmark, SORCE-1K, consisting of\nimages with complex environments and textual queries describing less\nconspicuous small objects with minimal contextual cues from other salient\nobjects. Preliminary analysis on SORCE-1K finds that existing T2IR methods\nstruggle to capture small objects and encode all the semantics into a single\nembedding, leading to poor retrieval performance on SORCE-1K. Therefore, we\npropose to represent each image with multiple distinctive embeddings. We\nleverage Multimodal Large Language Models (MLLMs) to extract multiple\nembeddings for each image instructed by a set of Regional Prompts (ReP).\nExperimental results show that our multi-embedding approach through MLLM and\nReP significantly outperforms existing T2IR methods on SORCE-1K. Our\nexperiments validate the effectiveness of SORCE-1K for benchmarking SORCE\nperformances, highlighting the potential of multi-embedding representation and\ntext-customized MLLM features for addressing this task.",
    "pdf_url": "http://arxiv.org/pdf/2505.24441v1",
    "published": "2025-05-30T10:23:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24440v1",
    "title": "The Cost of Restaking vs. Proof-of-Stake",
    "authors": [
      "Akaki Mamageishvili",
      "Benny Sudakov"
    ],
    "abstract": "We compare the efficiency of restaking and Proof-of-Stake (PoS) protocols in\nterms of stake requirements. First, we consider the sufficient condition for\nthe restaking graph to be secure. We show that the condition implies that it is\nalways possible to transform such a restaking graph into secure PoS protocols.\nNext, we derive two main results, giving upper and lower bounds on required\nextra stakes that one needs to add to validators of the secure restaking graph\nto be able to transform it into secure PoS protocols. In particular, we show\nthat the restaking savings compared to PoS protocols can be very large and can\nasymptotically grow in the worst case as a square root of the number of\nvalidators. We also study a complementary question of transforming secure PoS\nprotocols into an aggregate secure restaking graph and provide lower and upper\nbounds on the PoS savings compared to restaking.",
    "pdf_url": "http://arxiv.org/pdf/2505.24440v1",
    "published": "2025-05-30T10:22:55+00:00",
    "categories": [
      "cs.CR",
      "econ.TH"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24439v1",
    "title": "Magnetic Circular Dichroism at the Oxygen K edge in Microcrystals of Spinels Grown on Ru(0001)",
    "authors": [
      "A. Mandziak",
      "V. Sosa",
      "P. Nita",
      "L. Martín-García",
      "J. E. Prieto",
      "M. Foerster",
      "M. A. Niño",
      "L. Aballe",
      "C. Granados-Miralles",
      "A. Quesada",
      "C. Tejera-Centeno",
      "S. Gallego",
      "J. de la Figuera"
    ],
    "abstract": "We have measured the circular magnetic dichroism in the x-ray absorption at\nthe K-edge of oxygen in microcrystals of different spinel oxides. The\nmicrocrystals are islands of micrometric size and nanometric thickness, grown\non Ru(0001) substrates using high-temperature oxygen-assisted molecular beam\nepitaxy. The domains observed in the oxygen K-edge dichroism have the same\ndistribution and orientation as those observed in x-ray magnetic circular\ndichroism at the L$_{3}$ edge of the octahedral cations. Integrating the area\nfrom a single domain, x-ray magnetic circular dichroic spectra of oxygen were\nmeasured and, by the application of the K-edge sum rule, non vanishing orbital\nmagnetic moments aligned with the octahedral cations were found. Density\nfunctional theory calculations, which did not show any orbital moment at the\noxygen anions, indicate that the energy ranges where oxygen dichroism is\nobserved correspond to those with significant hybridization with the cations d\nbands. They also show a correlation between the magnitude of the measured value\nof the oxygen orbital moment and the theoretical one for the cations, and\ndemonstrate that this trend is preserved in the presence of Fe excess in the\nsamples. Our experimental XMCD suggest, following the DFT calculations, that\nthe origin of the oxygen magnetic moment lies in the hybridization of the\noxygen unoccupied p-derived bands with the cation bands, mostly with the\nd-derived ones.",
    "pdf_url": "http://arxiv.org/pdf/2505.24439v1",
    "published": "2025-05-30T10:22:16+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24438v2",
    "title": "Weisfeiler and Leman Follow the Arrow of Time: Expressive Power of Message Passing in Temporal Event Graphs",
    "authors": [
      "Franziska Heeg",
      "Jonas Sauer",
      "Petra Mutzel",
      "Ingo Scholtes"
    ],
    "abstract": "An important characteristic of temporal graphs is how the directed arrow of\ntime influences their causal topology, i.e., which nodes can possibly influence\neach other causally via time-respecting paths. The resulting patterns are often\nneglected by temporal graph neural networks (TGNNs). To formally analyze the\nexpressive power of TGNNs, we lack a generalization of graph isomorphism to\ntemporal graphs that fully captures their causal topology. Addressing this gap,\nwe introduce the notion of consistent event graph isomorphism, which utilizes a\ntime-unfolded representation of time-respecting paths in temporal graphs. We\ncompare this definition with existing notions of temporal graph isomorphisms.\nWe illustrate and highlight the advantages of our approach and develop a\ntemporal generalization of the Weisfeiler-Leman algorithm to heuristically\ndistinguish non-isomorphic temporal graphs. Building on this theoretical\nfoundation, we derive a novel message passing scheme for temporal graph neural\nnetworks that operates on the event graph representation of temporal graphs. An\nexperimental evaluation shows that our approach performs well in a temporal\ngraph classification experiment.",
    "pdf_url": "http://arxiv.org/pdf/2505.24438v2",
    "published": "2025-05-30T10:20:30+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24437v3",
    "title": "SwitchCodec: A High-Fidelity Nerual Audio Codec With Sparse Quantization",
    "authors": [
      "Jin Wang",
      "Wenbin Jiang",
      "Xiangbo Wang",
      "Yubo You",
      "Sheng Fang"
    ],
    "abstract": "Neural audio compression has emerged as a promising technology for\nefficiently representing speech, music, and general audio. However, existing\nmethods suffer from significant performance degradation at limited bitrates,\nwhere the available embedding space is sharply constrained. To address this, we\npropose a universal high-fidelity neural audio compression algorithm featuring\nResidual Experts Vector Quantization (REVQ), which substantially expands the\nembedding space with minimal impact on bandwidth. A gentle load-balancing\nstrategy is introduced to ensure the full utilization of this expanded space.\nFurthermore, we develop a novel multi-tiered discriminator that periodically\nstratifies STFT spectra, guiding the generator to focus on critical spectral\nregions. To support multiple bitrates without quality loss at the lower end, we\nadopt an efficient post-training strategy. Our proposed model achieves\nimpressive performance, with PESQ and ViSQOL scores of 2.87 and 4.27,\nrespectively, at 2.67 kbps bandwidth. The approach effectively reduces spectral\nblur, decreasing the distance to the original mel-spectrogram by 13%. Notably,\nour post-training strategy achieves performance comparable to dedicated\nfixed-bitrate models while reducing the required training time by half.\nExtensive ablation studies confirm the superiority of our method over\nbaselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.24437v3",
    "published": "2025-05-30T10:20:04+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24436v1",
    "title": "Joint space-time modelling for upper daily maximum and minimum temperature record-breaking",
    "authors": [
      "Jorge Castillo-Mateo",
      "Zeus Gracia-Tabuenca",
      "Jesús Asín",
      "Ana C. Cebrián",
      "Alan E. Gelfand"
    ],
    "abstract": "Record-breaking temperature events are now frequently in the news, proffered\nas evidence of climate change, and often bring significant economic and human\nimpacts. Our previous work undertook the first substantial spatial modelling\ninvestigation of temperature record-breaking across years for any given day\nwithin the year, employing a dataset consisting of over sixty years of daily\nmaximum temperatures across peninsular Spain. That dataset also supplies daily\nminimum temperatures (which, in fact, are now available through 2023). Here,\nthe dataset is converted into a daily pair of binary events, indicators, for\nthat day, of whether a yearly record was broken for the daily maximum\ntemperature and/or for the daily minimum temperature. Joint modelling addresses\nseveral inference issues: (i) defining/modelling record-breaking with bivariate\ntime series of yearly indicators, (ii) strength of relationship between\nrecord-breaking events, (iii) prediction of joint, conditional and marginal\nrecord-breaking, (iv) persistence in record-breaking across days, (v) spatial\ninterpolation across peninsular Spain. We substantially expand our previous\nwork to enable investigation of these issues. We observe strong correlation\nbetween both processes but a growing trend of climate change that is well\ndifferentiated between them both spatially and temporally as well as different\nstrengths of persistence and spatial dependence.",
    "pdf_url": "http://arxiv.org/pdf/2505.24436v1",
    "published": "2025-05-30T10:20:00+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24435v1",
    "title": "Path-dependent option pricing with two-dimensional PDE using MPDATA",
    "authors": [
      "Paweł Magnuszewski",
      "Sylwester Arabas"
    ],
    "abstract": "In this paper, we discuss a simple yet robust PDE method for evaluating\npath-dependent Asian-style options using the non-oscillatory forward-in-time\nsecond-order MPDATA finite-difference scheme. The valuation methodology\ninvolves casting the Black-Merton-Scholes equation as a transport problem by\nfirst transforming it into a homogeneous advection-diffusion PDE via variable\nsubstitution, and then expressing the diffusion term as an advective flux using\nthe pseudo-velocity technique. As a result, all terms of the\nBlack-Merton-Sholes equation are consistently represented using a single\nhigh-order numerical scheme for the advection operator. We detail the\nadditional steps required to solve the two-dimensional valuation problem\ncompared to MPDATA valuations of vanilla instruments documented in a prior\nstudy. Using test cases employing fixed-strike instruments, we validate the\nsolutions against Monte Carlo valuations, as well as against an approximate\nanalytical solution in which geometric instead of arithmetic averaging is used.\nThe analysis highlights the critical importance of the MPDATA corrective steps\nthat improve the solution over the underlying first-order \"upwind\" step. The\nintroduced valuation scheme is robust: conservative, non-oscillatory, and\npositive-definite; yet lucid: explicit in time, engendering intuitive\nstability-condition interpretation and inflow/outflow boundary-condition\nheuristics. MPDATA is particularly well suited for two-dimensional problems as\nit is not a dimensionally split scheme. The documented valuation workflow also\nconstitutes a useful two-dimensional case for testing advection schemes\nfeaturing both Monte Carlo solutions and analytic bounds. An implementation of\nthe introduced valuation workflow, based on the PyMPDATA package and the Numba\nJust-In-Time compiler for Python, is provided as free and open source software.",
    "pdf_url": "http://arxiv.org/pdf/2505.24435v1",
    "published": "2025-05-30T10:19:12+00:00",
    "categories": [
      "q-fin.CP"
    ],
    "primary_category": "q-fin.CP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24434v2",
    "title": "Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields",
    "authors": [
      "Md Shahriar Rahim Siddiqui",
      "Moshe Eliasof",
      "Eldad Haber"
    ],
    "abstract": "Flow matching casts sample generation as learning a continuous-time velocity\nfield that transports noise to data. Existing flow matching networks typically\npredict each point's velocity independently, considering only its location and\ntime along its flow trajectory, and ignoring neighboring points. However, this\npointwise approach may overlook correlations between points along the\ngeneration trajectory that could enhance velocity predictions, thereby\nimproving downstream generation quality. To address this, we propose Graph Flow\nMatching (GFM), a lightweight enhancement that decomposes the learned velocity\ninto a reaction term -- any standard flow matching network -- and a diffusion\nterm that aggregates neighbor information via a graph neural module. This\nreaction-diffusion formulation retains the scalability of deep flow models\nwhile enriching velocity predictions with local context, all at minimal\nadditional computational cost. Operating in the latent space of a pretrained\nvariational autoencoder, GFM consistently improves Fr\\'echet Inception Distance\n(FID) and recall across five image generation benchmarks (LSUN Church, LSUN\nBedroom, FFHQ, AFHQ-Cat, and CelebA-HQ at $256\\times256$), demonstrating its\neffectiveness as a modular enhancement to existing flow matching architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.24434v2",
    "published": "2025-05-30T10:17:50+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24433v1",
    "title": "Testing Paradox May Explain Increased Observed Prevalence of Bacterial STIs among MSM on HIV PrEP: A Modeling Study",
    "authors": [
      "Laura Müller",
      "Piklu Mallick",
      "Antonio B. Marín-Carballo",
      "Philipp Dönges",
      "Robyn J. N. Kettlitz",
      "Carolina J. Klett-Tammen",
      "Mirjam Kretzschmar",
      "Viola Priesemann",
      "Seba Contreras"
    ],
    "abstract": "HIV pre-exposure Prophylaxis (PrEP) has become essential for global HIV\ncontrol, but its implementation coincides with rising bacterial STI rates among\nmen who have sex with men (MSM). While risk-compensation behavioral changes\nlike reduced condom use are frequently reported, we examine whether intensified\nasymptomatic screening in PrEP programs creates surveillance artifacts that\ncould be misinterpreted. We developed a compartmental model to represent the\nsimultaneous spread of HIV and chlamydia (as an example of a curable STI),\nintegrating three mechanisms: 1) risk-mediated self-protective behavior, 2)\ncondom use reduction post-PrEP initiation, and 3) PrEP-related asymptomatic STI\nscreening. Increasing PrEP uptake may help to reduce chlamydia prevalence, only\nif the PrEP-related screening is frequent enough. Otherwise, the effect of PrEP\ncan be disadvantageous, as the drop in self-protective actions caused by larger\nPrEP uptake cannot be compensated for. Additionally, the change in testing\nbehavior may lead to situations where the trend in the number of positive tests\nis not a reliable sign of the actual dynamics. We found a plausible mechanism\nto reconcile conflicting observational evidence on the effect of PrEP on STI\nrates, showing that simultaneous changes in testing and spreading rates may\ngenerate conflicting signals, i.e., that observed trends increase while true\nprevalence decreases. Asymptomatic screening, together with personalized\ninfection treatment to minimize putative pressure to generate antibiotic\nresistance, is one of the key determinants of the positive side effects of PrEP\nin reducing STI incidence.",
    "pdf_url": "http://arxiv.org/pdf/2505.24433v1",
    "published": "2025-05-30T10:13:06+00:00",
    "categories": [
      "q-bio.PE",
      "physics.soc-ph"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24432v2",
    "title": "50 years of spin glass theory",
    "authors": [
      "David Sherrington",
      "Scott Kirkpatrick"
    ],
    "abstract": "In 1975, two papers were published that together sparked major new\ndirections, conceptual, mathematical and practically applicable, in several\npreviously disparate fields of science. In this short review, we expose key\naspects of their thinking, implementations and implications, along with a\nselection of further crucial and consequential developments. These papers were\n`Theory of spin glasses' by S.F.Edwards and P.W.Anderson (EA)[1] and `Solvable\nModel of a Spin-Glass', by D.Sherrington and S.Kirkpatrick (SK)[2], both\nconcerned with trying to understand recent experiments that suggested a new\nphase of matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.24432v2",
    "published": "2025-05-30T10:12:01+00:00",
    "categories": [
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24431v1",
    "title": "Bridging 3D Anomaly Localization and Repair via High-Quality Continuous Geometric Representation",
    "authors": [
      "Bozhong Zheng",
      "Jinye Gan",
      "Xiaohao Xu",
      "Wenqiao Li",
      "Xiaonan Huang",
      "Na Ni",
      "Yingna Wu"
    ],
    "abstract": "3D point cloud anomaly detection is essential for robust vision systems but\nis challenged by pose variations and complex geometric anomalies. Existing\npatch-based methods often suffer from geometric fidelity issues due to discrete\nvoxelization or projection-based representations, limiting fine-grained anomaly\nlocalization. We introduce Pose-Aware Signed Distance Field (PASDF), a novel\nframework that integrates 3D anomaly detection and repair by learning a\ncontinuous, pose-invariant shape representation. PASDF leverages a Pose\nAlignment Module for canonicalization and a SDF Network to dynamically\nincorporate pose, enabling implicit learning of high-fidelity anomaly repair\ntemplates from the continuous SDF. This facilitates precise pixel-level anomaly\nlocalization through an Anomaly-Aware Scoring Module. Crucially, the continuous\n3D representation in PASDF extends beyond detection, facilitating in-situ\nanomaly repair. Experiments on Real3D-AD and Anomaly-ShapeNet demonstrate\nstate-of-the-art performance, achieving high object-level AUROC scores of 80.2%\nand 90.0%, respectively. These results highlight the effectiveness of\ncontinuous geometric representations in advancing 3D anomaly detection and\nfacilitating practical anomaly region repair. The code is available at\nhttps://github.com/ZZZBBBZZZ/PASDF to support further research.",
    "pdf_url": "http://arxiv.org/pdf/2505.24431v1",
    "published": "2025-05-30T10:11:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24430v1",
    "title": "Some Properties of Twisted Chevalley Groups",
    "authors": [
      "Deep H. Makadiya"
    ],
    "abstract": "This thesis investigates certain structural properties of twisted Chevalley\ngroups over commutative rings, focusing on three key problems.\n  Let $R$ be a commutative ring satisfying mild conditions. Let $G_{\\pi,\\sigma}\n(\\Phi, R)$ denote a twisted Chevalley group over $R$, and let $E'_{\\pi, \\sigma}\n(\\Phi, R)$ denote its elementary subgroup. The first problem concerns the\nnormality of $E'_{\\pi, \\sigma} (\\Phi, R, J)$, the relative elementary subgroups\nat level $J$, in the group $G_{\\pi, \\sigma} (\\Phi, R)$. The second problem\naddresses the classification of the subgroups of $G_{\\pi, \\sigma}(\\Phi, R)$\nthat are normalized by $E'_{\\pi, \\sigma}(\\Phi, R)$. This classification\nprovides a comprehensive characterization of the normal subgroups of $E'_{\\pi,\n\\sigma}(\\Phi, R)$. Lastly, the third problem investigates the normalizers of\n$E'_{\\pi, \\sigma}(\\Phi, R)$ and $G_{\\pi, \\sigma}(\\Phi, R)$ in the bigger group\n$G_{\\pi, \\sigma}(\\Phi, S)$, where $S$ is a ring extension of $R$. We prove that\nthese normalizers coincide. Moreover, for groups of adjoint type, we show that\nthey are precisely equal to $G_{\\pi, \\sigma}(\\Phi, R)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24430v1",
    "published": "2025-05-30T10:10:53+00:00",
    "categories": [
      "math.GR",
      "20G35, 17B20, 17B22"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24429v2",
    "title": "Deep Learning Weather Models for Subregional Ocean Forecasting: A Case Study on the Canary Current Upwelling System",
    "authors": [
      "Giovanny A. Cuervo-Londoño",
      "Javier Sánchez",
      "Ángel Rodríguez-Santana"
    ],
    "abstract": "Oceanographic forecasting impacts various sectors of society by supporting\nenvironmental conservation and economic activities. Based on global circulation\nmodels, traditional forecasting methods are computationally expensive and slow,\nlimiting their ability to provide rapid forecasts. Recent advances in deep\nlearning offer faster and more accurate predictions, although these data-driven\nmodels are often trained with global data from numerical simulations, which may\nnot reflect reality. The emergence of such models presents great potential for\nimproving ocean prediction at a subregional domain. However, their ability to\npredict fine-scale ocean processes, like mesoscale structures, remains largely\nunknown. This work aims to adapt a graph neural network initially developed for\nglobal weather forecasting to improve subregional ocean prediction,\nspecifically focusing on the Canary Current upwelling system. The model is\ntrained with satellite data and compared to state-of-the-art physical ocean\nmodels to assess its performance in capturing ocean dynamics. Our results show\nthat the deep learning model surpasses traditional methods in precision despite\nsome challenges in upwelling areas. It demonstrated superior performance in\nreducing RMSE errors compared to ConvLSTM and the GLORYS reanalysis,\nparticularly in regions with complex oceanic dynamics such as Cape Ghir, Cape\nBojador, and Cape Blanc. The model achieved improvements of up to 26.5%\nrelative to ConvLSTM and error reductions of up to 76% in 5-day forecasts\ncompared to the GLORYS reanalysis at these critical locations, highlighting its\nenhanced capability to capture spatial variability and improve predictive\naccuracy in complex areas. These findings suggest the viability of adapting\nmeteorological data-driven models for improving subregional medium-term ocean\nforecasting.",
    "pdf_url": "http://arxiv.org/pdf/2505.24429v2",
    "published": "2025-05-30T10:10:40+00:00",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00093v1",
    "title": "On a Family of Nested Recurrences and Their Arithmetical Solutions",
    "authors": [
      "Benoit Cloitre"
    ],
    "abstract": "A family of nested recurrence relations $a(n+1) = n - a^{(m)}(n) +\na^{(m+1)}(n)$, parameterized by an integer $m \\ge 1$ with initial condition\n$a(1)=1$, is studied. We prove that $a(n)=n-h(n)$ is the unique solution\nsatisfying this condition, where $h(n)$ is an arithmetical sequence in which\neach non-negative integer $k$ appears $mk+1$ times, with $h(n)$ 1-indexed such\nthat $h(1)=0$. An explicit floor formula for $h(n)$ (and thus for $a(n)$) is\nderived. The proof of the main theorem involves establishing a key identity for\n$h(n)$ that arises from the recurrence; this identity is then proved using\narithmetical properties of $h(n)$ and the iterated function $a^{(m)}(n)$ at\ncritical boundary points. Combinatorial interpretations for $a(n)$ and its\npartial sums (for $m=2$), and connections to The On-Line Encyclopedia of\nInteger Sequences (OEIS), including generalizations of Connell's sequence, are\nalso discussed.",
    "pdf_url": "http://arxiv.org/pdf/2506.00093v1",
    "published": "2025-05-30T10:09:14+00:00",
    "categories": [
      "math.CO",
      "Primary 11B37, Secondary 05A19, 11B39, 11B83"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24428v1",
    "title": "Model Unlearning via Sparse Autoencoder Subspace Guided Projections",
    "authors": [
      "Xu Wang",
      "Zihao Li",
      "Benyou Wang",
      "Yan Hu",
      "Difan Zou"
    ],
    "abstract": "Large language models (LLMs) store vast amounts of information, making them\npowerful yet raising privacy and safety concerns when selective knowledge\nremoval is required. Existing unlearning strategies, ranging from\ngradient-based fine-tuning and model editing to sparse autoencoder (SAE)\nsteering, either lack interpretability or fail to provide a robust defense\nagainst adversarial prompts. We propose SAE-Guided Subspace Projection\nUnlearning (SSPU), a novel framework that leverages SAE features to drive\ntargeted updates in the model's parameter space, enabling precise,\ninterpretable, and robust unlearning. SSPU's three-stage pipeline performs\ndata-driven layer and feature selection, subspace construction via QR\ndecomposition, and constrained optimization that controls activations into an\n\"irrelevant\" subspace while preserving retained knowledge. Overall, we use SAE\nfeatures to construct a subspace that supervises unlearning, refining the loss\nand adding a regularization term to guide interpretable parameter updates. In\nexperiments on the WMDP-Cyber forget set and three utility benchmarks (MMLU,\nTruthfulQA, GSM8K), SSPU reduces harmful knowledge accuracy by 3.22% compared\nto the strongest baseline. It also improves adversarial robustness, lowering\nmalicious accuracy under jailbreak prompts compared to baselines. Our findings\nexpose the limitations of prior unlearning methods and demonstrate how\ninterpretable subspace-guided optimization can achieve robust, controllable\nmodel behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.24428v1",
    "published": "2025-05-30T10:07:52+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24427v1",
    "title": "Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts",
    "authors": [
      "Christopher Bagdon",
      "Aidan Combs",
      "Carina Silberer",
      "Roman Klinger"
    ],
    "abstract": "Accurate modeling of subjective phenomena such as emotion expression requires\ndata annotated with authors' intentions. Commonly such data is collected by\nasking study participants to donate and label genuine content produced in the\nreal world, or create content fitting particular labels during the study.\nAsking participants to create content is often simpler to implement and\npresents fewer risks to participant privacy than data donation. However, it is\nunclear if and how study-created content may differ from genuine content, and\nhow differences may impact models. We collect study-created and genuine\nmultimodal social media posts labeled for emotion and compare them on several\ndimensions, including model performance. We find that compared to genuine\nposts, study-created posts are longer, rely more on their text and less on\ntheir images for emotion expression, and focus more on emotion-prototypical\nevents. The samples of participants willing to donate versus create posts are\ndemographically different. Study-created data is valuable to train models that\ngeneralize well to genuine data, but realistic effectiveness estimates require\ngenuine data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24427v1",
    "published": "2025-05-30T10:07:34+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24426v1",
    "title": "P: A Universal Measure of Predictive Intelligence",
    "authors": [
      "David Gamez"
    ],
    "abstract": "Over the last thirty years, considerable progress has been made with the\ndevelopment of systems that can drive cars, play games, predict protein folding\nand generate natural language. These systems are described as intelligent and\nthere has been a great deal of talk about the rapid increase in artificial\nintelligence and its potential dangers. However, our theoretical understanding\nof intelligence and ability to measure it lag far behind our capacity for\nbuilding systems that mimic intelligent human behaviour. There is no commonly\nagreed definition of the intelligence that AI systems are said to possess.\nNo-one has developed a practical measure that would enable us to compare the\nintelligence of humans, animals and AIs on a single ratio scale.\n  This paper sets out a new universal measure of intelligence that is based on\nthe hypothesis that prediction is the most important component of intelligence.\nAs an agent interacts with its normal environment, the accuracy of its\npredictions is summed up and the complexity of its predictions and perceived\nenvironment is accounted for using Kolmogorov complexity. Two experiments were\ncarried out to evaluate the practical feasibility of the algorithm. These\ndemonstrated that it could measure the intelligence of an agent embodied in a\nvirtual maze and an agent that makes predictions about time-series data. This\nuniversal measure could be the starting point for a new comparative science of\nintelligence that ranks humans, animals and AIs on a single ratio scale.",
    "pdf_url": "http://arxiv.org/pdf/2505.24426v1",
    "published": "2025-05-30T10:05:54+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24425v1",
    "title": "The Multivariate Herglotz-Nevanlinna Class: Superresolution",
    "authors": [
      "Mainak Bhowmik",
      "Mihai Putinar"
    ],
    "abstract": "Unique solutions of bounded, or equivalently, non-negative real part,\nholomorphic interpolation in several complex variables with finite prescribed\ndata are very rare, with rational inner functions in a polydisk as the best\nunderstood examples. We analyze the continuity of global solutions as functions\nof the finite interpolation data in neighborhoods of elements distinguished by\nthis uniqueness property. Our study covers rational inner functions in the\npolydisk and automorphisms of the Euclidean ball. The proof of the main\nsuperresolution result is derived from optimization theory techniques and\nvolume estimates of sublevel sets of real polynomials, both emerging from\nMarkov's multivariable moment problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.24425v1",
    "published": "2025-05-30T10:04:34+00:00",
    "categories": [
      "math.FA",
      "32E30, 31B20, 32A17, 30E05, 44A60"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24424v1",
    "title": "Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning",
    "authors": [
      "Amit Peleg",
      "Naman Deep Singh",
      "Matthias Hein"
    ],
    "abstract": "Vision-language models like CLIP have demonstrated remarkable zero-shot\ncapabilities in classification and retrieval. However, these models often\nstruggle with compositional reasoning - the ability to understand the\nrelationships between concepts. A recent benchmark, SugarCrepe++, reveals that\nprevious works on improving compositionality have mainly improved lexical\nsensitivity but neglected semantic understanding. In addition, downstream\nretrieval performance often deteriorates, although one would expect that\nimproving compositionality should enhance retrieval. In this work, we introduce\nCLIC (Compositionally-aware Learning in CLIP), a fine-tuning method based on a\nnovel training technique combining multiple images and their associated\ncaptions. CLIC improves compositionality across architectures as well as\ndifferently pre-trained CLIP models, both in terms of lexical and semantic\nunderstanding, and achieves consistent gains in retrieval performance. This\neven applies to the recent CLIPS, which achieves SOTA retrieval performance.\nNevertheless, the short fine-tuning with CLIC leads to an improvement in\nretrieval and to the best compositional CLIP model on SugarCrepe++. All our\nmodels and code are available at https://clic-compositional-clip.github.io",
    "pdf_url": "http://arxiv.org/pdf/2505.24424v1",
    "published": "2025-05-30T10:04:00+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24423v1",
    "title": "MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs",
    "authors": [
      "Zhiwei Liu",
      "Lingfei Qian",
      "Qianqian Xie",
      "Jimin Huang",
      "Kailai Yang",
      "Sophia Ananiadou"
    ],
    "abstract": "Large language models and vision-language models (which we jointly call LMs)\nhave transformed NLP and CV, demonstrating remarkable potential across various\nfields. However, their capabilities in affective analysis (i.e. sentiment\nanalysis and emotion detection) remain underexplored. This gap is largely due\nto the absence of comprehensive evaluation benchmarks, and the inherent\ncomplexity of affective analysis tasks. In this paper, we introduce MMAFFBen,\nthe first extensive open-source benchmark for multilingual multimodal affective\nanalysis. MMAFFBen encompasses text, image, and video modalities across 35\nlanguages, covering four key affective analysis tasks: sentiment polarity,\nsentiment intensity, emotion classification, and emotion intensity. Moreover,\nwe construct the MMAFFIn dataset for fine-tuning LMs on affective analysis\ntasks, and further develop MMAFFLM-3b and MMAFFLM-7b based on it. We evaluate\nvarious representative LMs, including GPT-4o-mini, providing a systematic\ncomparison of their affective understanding capabilities. This project is\navailable at https://github.com/lzw108/MMAFFBen.",
    "pdf_url": "http://arxiv.org/pdf/2505.24423v1",
    "published": "2025-05-30T10:02:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24422v1",
    "title": "Three Kinds of Negation in Knowledge and Their Mathematical Foundations",
    "authors": [
      "Zhenghua Pan",
      "Yong Wang"
    ],
    "abstract": "In the field of artificial intelligence, understanding, distinguishing,\nexpressing, and computing the negation in knowledge is a fundamental issue in\nknowledge processing and research. In this paper, we examine and analyze the\nunderstanding and characteristics of negation in various fields such as\nphilosophy, logic, and linguistics etc. Based on the distinction between the\nconcepts of contradiction and opposition, we propose that there are three\ndifferent types of negation in knowledge from a conceptual perspective:\ncontradictory negation, opposite negation, and intermediary negation. To\nestablish a mathematical foundation that fully reflects the intrinsic\nconnections, properties, and laws of these different forms of negation, we\nintroduce SCOI: sets with contradictory negation, opposite negation and\nintermediary negation, and LCOI: logic with contradictory negation, opposite\nnegation and intermediary negation, and we proved the main operational\nproperties of SCOI as well as the formal inference relations in LCOI.",
    "pdf_url": "http://arxiv.org/pdf/2505.24422v1",
    "published": "2025-05-30T10:01:37+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24421v1",
    "title": "pyMEAL: A Multi-Encoder Augmentation-Aware Learning for Robust and Generalizable Medical Image Translation",
    "authors": [
      "Abdul-mojeed Olabisi Ilyas",
      "Adeleke Maradesa",
      "Jamal Banzi",
      "Jianpan Huang",
      "Henry K. F. Mak",
      "Kannie W. Y. Chan"
    ],
    "abstract": "Medical imaging is critical for diagnostics, but clinical adoption of\nadvanced AI-driven imaging faces challenges due to patient variability, image\nartifacts, and limited model generalization. While deep learning has\ntransformed image analysis, 3D medical imaging still suffers from data scarcity\nand inconsistencies due to acquisition protocols, scanner differences, and\npatient motion. Traditional augmentation uses a single pipeline for all\ntransformations, disregarding the unique traits of each augmentation and\nstruggling with large data volumes.\n  To address these challenges, we propose a Multi-encoder Augmentation-Aware\nLearning (MEAL) framework that leverages four distinct augmentation variants\nprocessed through dedicated encoders. Three fusion strategies such as\nconcatenation (CC), fusion layer (FL), and adaptive controller block (BD) are\nintegrated to build multi-encoder models that combine augmentation-specific\nfeatures before decoding. MEAL-BD uniquely preserves augmentation-aware\nrepresentations, enabling robust, protocol-invariant feature learning.\n  As demonstrated in a Computed Tomography (CT)-to-T1-weighted Magnetic\nResonance Imaging (MRI) translation study, MEAL-BD consistently achieved the\nbest performance on both unseen- and predefined-test data. On both geometric\ntransformations (like rotations and flips) and non-augmented inputs, MEAL-BD\noutperformed other competing methods, achieving higher mean peak\nsignal-to-noise ratio (PSNR) and structural similarity index measure (SSIM)\nscores. These results establish MEAL as a reliable framework for preserving\nstructural fidelity and generalizing across clinically relevant variability. By\nreframing augmentation as a source of diverse, generalizable features, MEAL\nsupports robust, protocol-invariant learning, advancing clinically reliable\nmedical imaging solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24421v1",
    "published": "2025-05-30T10:01:23+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24420v2",
    "title": "Unifying Cosmic Epochs via Quantum-Corrected Expansion with Brane-World Parallels",
    "authors": [
      "Farzin Safarzadeh-Maleki"
    ],
    "abstract": "We present an exact, non-perturbative and non-singular ansatz for the\nuniverse's expansion history through a novel analytic scale factor,\n$a(t)=e^{H(t)} { (1-e^{-k(t)t}) }^{b(t)}$, which reproduces the observed\nsequence of cosmic epochs and bridges inflation to late-time acceleration, as a\nunified solution, eliminating ad hoc $\\Lambda$CDM epoch splicing. The model's\ndynamically constrained parameters $(H(t), k(t), b(t))$ ensure smooth phase\ntransitions, as confirmed by analytical and numerical analysis of the expansion\nhistory.\n  The derived Hubble parameter incorporates quantum-inspired corrections\nthrough its functional form, offering a phenomenological approach to integrate\nquantum effects into classical cosmic evolution. While not derived from\nfundamental theory, it provides a well motivated framework within brane\ninspired cosmology with structure exhibiting parallels to brane-world\nscenarios: the parameter $k(t)$ acts as an effective screening scale, and the\nnon-monotonic $k(t)t$ implies epoch-dependent gravitational coupling. The\nscaling relation $\\sim \\rho(t)\\lambda(t)$ emerges naturally, offering a unified\ndescription of constant and variable-tension brane-like behavior at the\nphenomenological level.",
    "pdf_url": "http://arxiv.org/pdf/2505.24420v2",
    "published": "2025-05-30T09:59:05+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24419v1",
    "title": "Observation of ferron transport in ferroelectrics",
    "authors": [
      "Kaiwen Shen",
      "Ping Tang",
      "Xianzhe Chen",
      "Yifan Gao",
      "Yuanfei Fan",
      "Zejing Guo",
      "Yingfen Wei",
      "Hao Jiang",
      "Xumeng Zhang",
      "Ming Wang",
      "Pan He",
      "Wu Shi",
      "Jiahao Han",
      "Yizheng Wu",
      "Jian Shen",
      "Qi Liu",
      "Gerrit E. W. Bauer",
      "Ming Liu"
    ],
    "abstract": "Ferroelectrics feature spontaneous electric dipolar order reconfigurable via\nelectric fields. Recent theoretical studies of the collective excitations of\nthis electric dipolar order give rise to the hope that \"ferron\" quasiparticles\nmay complement the magnons of magnetic materials in information and heat\nmanagement technologies. Yet direct experimental evidence of ferron transport\nremains elusive. Here we demonstrate efficient ferron injection and detection\nenabled by ferromagnetic metal contacts, achieving nonlocal signal transmission\nover micrometer distances in a prototypical ferroelectric PMN-PT. The\ntransmission efficiency can be switched by external magnetic fields that couple\nto the contacts and gate electric fields that control the ferron excitations.\nFerron-based devices open new power saving strategies that employ ferroelectric\nmaterials in a future sustainable information society.",
    "pdf_url": "http://arxiv.org/pdf/2505.24419v1",
    "published": "2025-05-30T09:57:08+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24418v1",
    "title": "Front propagation on a general metric graph",
    "authors": [
      "Hiroshi Matano",
      "Shuichi Jimbo"
    ],
    "abstract": "We consider a bistable reaction-diffusion equation on a metric graph that is\na generalization of the so-called star graphs. More precisely, our graph\n$\\Omega$ consists of a bounded finite metric graph $D$ of arbitrary\nconfiguration and a finite number of branches $\\Omega_1,\\ldots,\\Omega_N\\,(N\\geq\n2)$ of infinite length emanating from some of the vertices of $D$. Each\n$\\Omega_i\\,(i=1,\\ldots,N)$ is called an ``outer path''. Our goal is to\ninvestigate the behavior of the front coming from infinity along a given outer\npath $\\Omega_i$ and to discuss whether or not the front propagates into other\nouter paths $\\Omega_j\\,(j\\ne i)$. Unlike the case of star graphs, where $D$ is\na single vertex, the dynamics of solutions can be far more complex and may\ndepend sensitively on the configuration of the center graph $D$. We first focus\non general principles that hold regardless of the structure of the center graph\n$D$. Among other things, we introduce the notion ``limit profile'', which\nallows us to define ``propagation'' and ``blocking'' without ambiguity, then we\nprove transient properties, that is, propagation $\\Omega_i\\to \\Omega_j$ and\n$\\Omega_j\\to \\Omega_k$ imply propagation $\\Omega_i\\to \\Omega_k$. Next we\nconsider perturbations of the graph $D$ while fixing the outer paths\n$\\Omega_1,\\ldots,\\Omega_N$ and prove that if, for a given choice of $i,j$,\npropagation $\\Omega_i\\to \\Omega_j$ occurs for a graph $D$, then the same holds\nfor any graph $D'$ that is sufficiently close to $D$ (robustness under\nperturbation). We also consider several specific classes of graphs, such as\nthose with a ``reservoir'' type subgraph, and study their intriguing\nproperties.",
    "pdf_url": "http://arxiv.org/pdf/2505.24418v1",
    "published": "2025-05-30T09:56:44+00:00",
    "categories": [
      "math.AP",
      "35R02, 35K57, 35K58, 35C07, 35B08"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24417v1",
    "title": "EasyText: Controllable Diffusion Transformer for Multilingual Text Rendering",
    "authors": [
      "Runnan Lu",
      "Yuxuan Zhang",
      "Jiaming Liu",
      "Haofan Wang",
      "Yiren Song"
    ],
    "abstract": "Generating accurate multilingual text with diffusion models has long been\ndesired but remains challenging. Recent methods have made progress in rendering\ntext in a single language, but rendering arbitrary languages is still an\nunexplored area. This paper introduces EasyText, a text rendering framework\nbased on DiT (Diffusion Transformer), which connects denoising latents with\nmultilingual character tokens encoded as character tokens. We propose character\npositioning encoding and position encoding interpolation techniques to achieve\ncontrollable and precise text rendering. Additionally, we construct a\nlarge-scale synthetic text image dataset with 1 million multilingual image-text\nannotations as well as a high-quality dataset of 20K annotated images, which\nare used for pretraining and fine-tuning respectively. Extensive experiments\nand evaluations demonstrate the effectiveness and advancement of our approach\nin multilingual text rendering, visual quality, and layout-aware text\nintegration.",
    "pdf_url": "http://arxiv.org/pdf/2505.24417v1",
    "published": "2025-05-30T09:55:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24416v1",
    "title": "Hilbert polynomials of configuration spaces over graphs of circumference at most 1",
    "authors": [
      "Byung Hee An",
      "Jang Soo Kim"
    ],
    "abstract": "The $ k $-configuration space $ B_k\\Gamma $ of a topological space $ \\Gamma $\nis the space of sets of $ k $ distinct points in $ \\Gamma $. In this paper, we\nconsider the case where $ \\Gamma $ is a graph of circumference at most $1$. We\nshow that for all $ k\\ge0 $, the $ i $-th Betti number of $ B_k\\Gamma $ is\ngiven by a polynomial $P_\\Gamma^i(k)$ in $ k $, called the Hilbert polynomial\nof $ \\Gamma $. We find an expression for the Hilbert polynomial $P_\\Gamma^i(k)$\nin terms of those coming from the canonical $1$-bridge decomposition of $\n\\Gamma $. We also give a combinatorial description of the coefficients of\n$P_\\Gamma^i(k)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24416v1",
    "published": "2025-05-30T09:54:45+00:00",
    "categories": [
      "math.GT",
      "math.AT",
      "math.CO",
      "Primary: 20F36, 55R80, Secondary: 05C10, 13E15"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24415v1",
    "title": "Boosting Automatic Exercise Evaluation Through Musculoskeletal Simulation-Based IMU Data Augmentation",
    "authors": [
      "Andreas Spilz",
      "Heiko Oppel",
      "Michael Munz"
    ],
    "abstract": "Automated evaluation of movement quality holds significant potential for\nenhancing physiotherapeutic treatments and sports training by providing\nobjective, real-time feedback. However, the effectiveness of deep learning\nmodels in assessing movements captured by inertial measurement units (IMUs) is\noften hampered by limited data availability, class imbalance, and label\nambiguity. In this work, we present a novel data augmentation method that\ngenerates realistic IMU data using musculoskeletal simulations integrated with\nsystematic modifications of movement trajectories. Crucially, our approach\nensures biomechanical plausibility and allows for automatic, reliable labeling\nby combining inverse kinematic parameters with a knowledge-based evaluation\nstrategy. Extensive evaluations demonstrate that augmented variants closely\nresembles real-world data, significantly improving the classification accuracy\nand generalization capability of neural network models. Additionally, we\nhighlight the benefits of augmented data for patient-specific fine-tuning\nscenarios, particularly when only limited subject-specific training examples\nare available. Our findings underline the practicality and efficacy of this\naugmentation method in overcoming common challenges faced by deep learning\napplications in physiotherapeutic exercise evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24415v1",
    "published": "2025-05-30T09:53:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24414v1",
    "title": "Thinning algorithms for the Monte Carlo simulation of kinetic Ising models",
    "authors": [
      "V. I. Tokar",
      "H. Dreyssé"
    ],
    "abstract": "The thinning method for numerical generation of the nonhomogeneous Poisson\nprocess (NHPP) arrival times has been adapted to accelerate Monte Carlo\nsimulations of the kinetic Ising models (KIMs) with the Glauber spin-flip\ndynamics. The performance of the suggested algorithms has been illustrated by\nsimulation of the decay of metastable states in stationary KIMs and of\nhysteresis in KIMs in a periodic external field. The thinning has been\nimplemented by means of piecewise constant majorizing functions which exceed or\nare equal to NHPP rate. It has been shown that in favorable cases the use of\nthinning makes possible the simulations of hysteresis at frequencies in tens\nnanohertz and the decay of metastable states with lifetimes by many orders\nexceeding those in previous simulations. Good agreement of simulated results\nwith low-temperature analytic theories has been established. Though the\nalgorithm acceleration has been shown to enhance with lowering temperature, the\nhysteresis has been simulated at moderately low temperatures of practical\ninterest estimated to cover the range from below the room temperature up to\ntemperatures used in hyperthermia applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.24414v1",
    "published": "2025-05-30T09:53:21+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.24413v1",
    "title": "Multi-task Learning for Heterogeneous Multi-source Block-Wise Missing Data",
    "authors": [
      "Yang Sui",
      "Qi Xu",
      "Yang Bai",
      "Annie Qu"
    ],
    "abstract": "Multi-task learning (MTL) has emerged as an imperative machine learning tool\nto solve multiple learning tasks simultaneously and has been successfully\napplied to healthcare, marketing, and biomedical fields. However, in order to\nborrow information across different tasks effectively, it is essential to\nutilize both homogeneous and heterogeneous information. Among the extensive\nliterature on MTL, various forms of heterogeneity are presented in MTL\nproblems, such as block-wise, distribution, and posterior heterogeneity.\nExisting methods, however, struggle to tackle these forms of heterogeneity\nsimultaneously in a unified framework. In this paper, we propose a two-step\nlearning strategy for MTL which addresses the aforementioned heterogeneity.\nFirst, we impute the missing blocks using shared representations extracted from\nhomogeneous source across different tasks. Next, we disentangle the mappings\nbetween input features and responses into a shared component and a\ntask-specific component, respectively, thereby enabling information borrowing\nthrough the shared component. Our numerical experiments and real-data analysis\nfrom the ADNI database demonstrate the superior MTL performance of the proposed\nmethod compared to other competing methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24413v1",
    "published": "2025-05-30T09:52:03+00:00",
    "categories": [
      "cs.LG",
      "stat.CO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24412v2",
    "title": "A Time-Scaled ETAS Model for Earthquake Forecasting",
    "authors": [
      "Agniva Das",
      "Muralidharan K"
    ],
    "abstract": "The Himalayan region, including Nepal, is prone to frequent and large\nearthquakes. Accurate forecasting of these earthquakes is crucial for\nminimizing loss of life and damage to infrastructure. In this study, we propose\nvarious time-scaled Epidemic Type Aftershock Sequence (ETAS) models to forecast\nearthquakes in Nepal. The ETAS model is a statistical model that describes the\ntemporal and spatial patterns of aftershocks following a main shock. A dataset\nof earthquake occurrences in Nepal from 2000 to 2020 was collected, and this\ndata was used to fit the models showcased in this article. Our results show\nthat the time-scaled ETAS model is able to accurately forecast earthquake\noccurrences in Nepal, and could be a useful tool for earthquake early warning\nsystems in the region.",
    "pdf_url": "http://arxiv.org/pdf/2505.24412v2",
    "published": "2025-05-30T09:51:43+00:00",
    "categories": [
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24411v1",
    "title": "PCIE_Pose Solution for EgoExo4D Pose and Proficiency Estimation Challenge",
    "authors": [
      "Feng Chen",
      "Kanokphan Lertniphonphan",
      "Qiancheng Yan",
      "Xiaohui Fan",
      "Jun Xie",
      "Tao Zhang",
      "Zhepeng Wang"
    ],
    "abstract": "This report introduces our team's (PCIE_EgoPose) solutions for the EgoExo4D\nPose and Proficiency Estimation Challenges at CVPR2025. Focused on the\nintricate task of estimating 21 3D hand joints from RGB egocentric videos,\nwhich are complicated by subtle movements and frequent occlusions, we developed\nthe Hand Pose Vision Transformer (HP-ViT+). This architecture synergizes a\nVision Transformer and a CNN backbone, using weighted fusion to refine the hand\npose predictions. For the EgoExo4D Body Pose Challenge, we adopted a multimodal\nspatio-temporal feature integration strategy to address the complexities of\nbody pose estimation across dynamic contexts. Our methods achieved remarkable\nperformance: 8.31 PA-MPJPE in the Hand Pose Challenge and 11.25 MPJPE in the\nBody Pose Challenge, securing championship titles in both competitions. We\nextended our pose estimation solutions to the Proficiency Estimation task,\napplying core technologies such as transformer-based architectures. This\nextension enabled us to achieve a top-1 accuracy of 0.53, a SOTA result, in the\nDemonstrator Proficiency Estimation competition.",
    "pdf_url": "http://arxiv.org/pdf/2505.24411v1",
    "published": "2025-05-30T09:51:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24410v2",
    "title": "$C^{1,α}$ regularity of the solution for the obstacle problem for the linearized Monge-Ampère operator",
    "authors": [
      "Meng Ji"
    ],
    "abstract": "In this paper, we study the regularity of the solution for the obstacle\nproblem associated with the linearized Monge-Amp\\`ere operator: \\begin{align*}\n  \\begin{cases}\n  &u\\geq\\varphi \\text{\\quad in } \\Omega\n  &L_{ w}u=\\tr( W D^{2}u)\\leq 0 \\text{\\quad in } \\Omega\n  &L_{ w}u= 0 \\text{\\quad in } \\{u>\\varphi\\}\n  &u=0 \\text{\\quad on } \\partial\\Omega,\n  \\end{cases} \\end{align*} where $ W=(\\det D^{2} w) D^{2} w^{-1}$ is the matrix\nof cofactor of $D^{2} w$, $w$ satisfies $\\lambda \\leq \\det D^{2} w \\leq\n\\Lambda$ and $ w=0$ on $\\partial \\Omega$, $\\varphi$ is the obstacle with at\nleast $C^{2}(\\bar{\\Omega})$ smoothness, $\\Omega$ is an open bounded convex\ndomain. We show the existence and uniqueness of a viscosity solution by using\nPerron's method and the comparison principle. Our primary result is to prove\nthat the solution exhibits local $C^{1,\\gamma}$ regularity for any $\\gamma \\in\n(0,1)$, provided that it is a strong solution in\n$W^{2,n}_{\\text{loc}}(\\Omega)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24410v2",
    "published": "2025-05-30T09:49:35+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24409v1",
    "title": "LLMs Are Globally Multilingual Yet Locally Monolingual: Exploring Knowledge Transfer via Language and Thought Theory",
    "authors": [
      "Eojin Kang",
      "Juae Kim"
    ],
    "abstract": "Multilingual large language models (LLMs) open up new possibilities for\nleveraging information across languages, but their factual knowledge recall\nremains inconsistent depending on the input language. While previous studies\nhave attempted to address this issue through English-based prompting and\nevaluation, we explore non-English to English transfer via Language and Thought\nTheory. This perspective allows us to examine language-thought binding in LLMs\nand uncover why factual knowledge often fails to transfer effectively. We\npropose the Language-to-Thought (L2T) prompting strategy, which analyzes the\nrelationship between input language, internal cognitive processes, and\nknowledge. Experimental results challenge the assumption that English-based\napproaches consistently outperform other languages and offer a novel insight\nthat aligning the model's internal thought with the knowledge required for the\ntask is critical for successful cross-lingual transfer. Furthermore, we show\nthat applying L2T during training can alleviate LLMs' reliance on the input\nlanguage and facilitate cross-linguistic knowledge integration without\ntranslation-based learning. Code and datasets will be available.",
    "pdf_url": "http://arxiv.org/pdf/2505.24409v1",
    "published": "2025-05-30T09:47:25+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24408v1",
    "title": "A White Paper on The Multi-Messenger Science Landscape in India",
    "authors": [
      "Samsuzzaman Afroz",
      "Sanjib Kumar Agarwalla",
      "Dipankar Bhattacharya",
      "Soumya Bhattacharya",
      "Subir Bhattacharyya",
      "Varun Bhalerao",
      "Debanjan Bose",
      "Chinmay Borwanker",
      "Ishwara Chandra C. H.",
      "Aniruddha Chakraborty",
      "Indranil Chakraborty",
      "Sovan Chakraborty",
      "Debarati Chatterjee",
      "Varsha Chitnis",
      "Moon Moon Devi",
      "Sanjeev Dhurandhar",
      "Amol Dighe",
      "Bitan Ghosal",
      "Sourendu Gupta",
      "Arpan Hait",
      "Md Emanuel Hoque",
      "Pratik Majumdar",
      "Nilmani Mathur",
      "Harsh Mehta",
      "Subhendra Mohanty",
      "Reetanjali Moharana",
      "Arunava Mukherjee",
      "Suvodip Mukherjee",
      "Dhruv Pathak",
      "Tirthankar Roy Choudhury",
      "Mohit Raj Sah",
      "Prantik Sarmah",
      "Krishna Kumar Singh",
      "Rishi Sharma",
      "Swarnim Shirke",
      "Shriharsh P. Tendulkar",
      "Gaurav Waratkar",
      "Kuldeep Yadav"
    ],
    "abstract": "The multi-messenger science using different observational windows to the\nUniverse such as Gravitational Waves (GWs), Electromagnetic Waves (EMs), Cosmic\nRays (CRs), and Neutrinos offer an opportunity to study from the scale of a\nneutron star to cosmological scales over a large cosmic time. At the smallest\nscales, we can explore the structure of the neutron star and the different\nenergetics involved in the transition of a pre-merger neutron star to a\npost-merger neutron star. This will open up a window to study the properties of\nmatter in extreme conditions and a guaranteed discovery space. On the other\nhand, at the largest cosmological scales, multi-messenger observations allow us\nto study the long-standing problems in physical cosmology related to the Hubble\nconstant, dark matter, and dark energy by mapping the expansion history of the\nUniverse using GW sources. Moreover, the multi-messenger studies of\nastrophysical systems such as white dwarfs, neutron stars, and black holes of\ndifferent masses, all the way up to a high redshift Universe, will bring\ninsightful understanding into the physical processes associated with them that\nare inaccessible otherwise. This white paper discusses the key cases in the\ndomain of multi-messenger astronomy and the role of observatories in India\nwhich can explore uncharted territories and open discovery spaces in different\nbranches of physics ranging from nuclear physics to astrophysics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24408v1",
    "published": "2025-05-30T09:46:42+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.CO",
      "astro-ph.GA",
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24407v3",
    "title": "Efficient RAW Image Deblurring with Adaptive Frequency Modulation",
    "authors": [
      "Wenlong Jiao",
      "Binglong Li",
      "Wei Shang",
      "Ping Wang",
      "Dongwei Ren"
    ],
    "abstract": "Image deblurring plays a crucial role in enhancing visual clarity across\nvarious applications. Although most deep learning approaches primarily focus on\nsRGB images, which inherently lose critical information during the image signal\nprocessing pipeline, RAW images, being unprocessed and linear, possess superior\nrestoration potential but remain underexplored. Deblurring RAW images presents\nunique challenges, particularly in handling frequency-dependent blur while\nmaintaining computational efficiency. To address these issues, we propose\nFrequency Enhanced Network (FrENet), a framework specifically designed for\nRAW-to-RAW deblurring that operates directly in the frequency domain. We\nintroduce a novel Adaptive Frequency Positional Modulation module, which\ndynamically adjusts frequency components according to their spectral positions,\nthereby enabling precise control over the deblurring process. Additionally,\nfrequency domain skip connections are adopted to further preserve\nhigh-frequency details. Experimental results demonstrate that FrENet surpasses\nstate-of-the-art deblurring methods in RAW image deblurring, achieving\nsignificantly better restoration quality while maintaining high efficiency in\nterms of reduced MACs. Furthermore, FrENet's adaptability enables it to be\nextended to sRGB images, where it delivers comparable or superior performance\ncompared to methods specifically designed for sRGB data. The code will be\navailable at https://github.com/WenlongJiao/FrENet .",
    "pdf_url": "http://arxiv.org/pdf/2505.24407v3",
    "published": "2025-05-30T09:46:39+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24406v1",
    "title": "IRBridge: Solving Image Restoration Bridge with Pre-trained Generative Diffusion Models",
    "authors": [
      "Hanting Wang",
      "Tao Jin",
      "Wang Lin",
      "Shulei Wang",
      "Hai Huang",
      "Shengpeng Ji",
      "Zhou Zhao"
    ],
    "abstract": "Bridge models in image restoration construct a diffusion process from\ndegraded to clear images. However, existing methods typically require training\na bridge model from scratch for each specific type of degradation, resulting in\nhigh computational costs and limited performance. This work aims to efficiently\nleverage pretrained generative priors within existing image restoration bridges\nto eliminate this requirement. The main challenge is that standard generative\nmodels are typically designed for a diffusion process that starts from pure\nnoise, while restoration tasks begin with a low-quality image, resulting in a\nmismatch in the state distributions between the two processes. To address this\nchallenge, we propose a transition equation that bridges two diffusion\nprocesses with the same endpoint distribution. Based on this, we introduce the\nIRBridge framework, which enables the direct utilization of generative models\nwithin image restoration bridges, offering a more flexible and adaptable\napproach to image restoration. Extensive experiments on six image restoration\ntasks demonstrate that IRBridge efficiently integrates generative priors,\nresulting in improved robustness and generalization performance. Code will be\navailable at GitHub.",
    "pdf_url": "http://arxiv.org/pdf/2505.24406v1",
    "published": "2025-05-30T09:45:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24405v1",
    "title": "Variation of Bose surface by Filling in Cooper pair Bose metal",
    "authors": [
      "Jiahao Su",
      "Ji Liu",
      "Jianyu Li",
      "Zhangkai Cao",
      "Tao Ying",
      "Ho-Kin Tang"
    ],
    "abstract": "The Cooper pair Bose metal (CPBM) is a non-superfluid quantum phase in which\nuncondensed fermion pairs form a \"Bose surface\" in momentum space. We\ninvestigate the CPBM in the two-dimensional spin-anisotropic attractive Hubbard\nmodel by tuning the next-nearest-neighbor (NNN) hopping t', carrier filling n,\nand spin anisotropy alpha, using large-scale constrained-path quantum Monte\nCarlo simulations. A moderate NNN hopping (t'/t = 0.2) substantially enlarges\nthe CPBM region: the phase extends into weaker anisotropy regimes and coexists\nwith a commensurate charge-density wave (CDW) near half-filling (n > 0.95),\nwhere CDW order would otherwise dominate at t' = 0. Interestingly, t'\nsuppresses the overall CDW peak amplitude and introduces a geometric\ncorrelation between the orientations of the Fermi and Bose surfaces: for weak\nFermi-surface rotations, the Bose surface remains aligned with the lattice\naxes, while larger distortions drive both surfaces to rotate in tandem.\nMomentum-resolved pairing distributions reveal that the bosonic pairing\nchannels are jointly controlled by t' and carrier filling n. For small t',\nd_xy-wave correlations dominate across the entire filling range. In contrast,\nfor larger t', the dominant pairing symmetry varies with n, reflecting a\nnontrivial interplay between frustration and density. These findings establish\ncarrier filling and NNN hopping as complementary levers for manipulating CPBM\nstability and provide concrete criteria for identifying non-superfluid bosonic\nmatter in cold-atom and correlated-electron systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24405v1",
    "published": "2025-05-30T09:36:52+00:00",
    "categories": [
      "physics.comp-ph",
      "cond-mat.str-el"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24404v1",
    "title": "PCIE_Interaction Solution for Ego4D Social Interaction Challenge",
    "authors": [
      "Kanokphan Lertniphonphan",
      "Feng Chen",
      "Junda Xu",
      "Fengbu Lan",
      "Jun Xie",
      "Tao Zhang",
      "Zhepeng Wang"
    ],
    "abstract": "This report presents our team's PCIE_Interaction solution for the Ego4D\nSocial Interaction Challenge at CVPR 2025, addressing both Looking At Me (LAM)\nand Talking To Me (TTM) tasks. The challenge requires accurate detection of\nsocial interactions between subjects and the camera wearer, with LAM relying\nexclusively on face crop sequences and TTM combining speaker face crops with\nsynchronized audio segments. In the LAM track, we employ face quality\nenhancement and ensemble methods. For the TTM task, we extend visual\ninteraction analysis by fusing audio and visual cues, weighted by a visual\nquality score. Our approach achieved 0.81 and 0.71 mean average precision (mAP)\non the LAM and TTM challenges leader board. Code is available at\nhttps://github.com/KanokphanL/PCIE_Ego4D_Social_Interaction",
    "pdf_url": "http://arxiv.org/pdf/2505.24404v1",
    "published": "2025-05-30T09:35:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24403v2",
    "title": "On the Lipschitz Continuity of Set Aggregation Functions and Neural Networks for Sets",
    "authors": [
      "Giannis Nikolentzos",
      "Konstantinos Skianis"
    ],
    "abstract": "The Lipschitz constant of a neural network is connected to several important\nproperties of the network such as its robustness and generalization. It is thus\nuseful in many settings to estimate the Lipschitz constant of a model. Prior\nwork has focused mainly on estimating the Lipschitz constant of multi-layer\nperceptrons and convolutional neural networks. Here we focus on data modeled as\nsets or multisets of vectors and on neural networks that can handle such data.\nThese models typically apply some permutation invariant aggregation function,\nsuch as the sum, mean or max operator, to the input multisets to produce a\nsingle vector for each input sample. In this paper, we investigate whether\nthese aggregation functions are Lipschitz continuous with respect to three\ndistance functions for unordered multisets, and we compute their Lipschitz\nconstants. In the general case, we find that each aggregation function is\nLipschitz continuous with respect to only one of the three distance functions.\nThen, we build on these results to derive upper bounds on the Lipschitz\nconstant of neural networks that can process multisets of vectors, while we\nalso study their stability to perturbations and generalization under\ndistribution shifts. To empirically verify our theoretical analysis, we conduct\na series of experiments on datasets from different domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.24403v2",
    "published": "2025-05-30T09:34:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24402v2",
    "title": "Leveraging Intermediate Features of Vision Transformer for Face Anti-Spoofing",
    "authors": [
      "Mika Feng",
      "Koichi Ito",
      "Takafumi Aoki",
      "Tetsushi Ohki",
      "Masakatsu Nishigaki"
    ],
    "abstract": "Face recognition systems are designed to be robust against changes in head\npose, illumination, and blurring during image capture. If a malicious person\npresents a face photo of the registered user, they may bypass the\nauthentication process illegally. Such spoofing attacks need to be detected\nbefore face recognition. In this paper, we propose a spoofing attack detection\nmethod based on Vision Transformer (ViT) to detect minute differences between\nlive and spoofed face images. The proposed method utilizes the intermediate\nfeatures of ViT, which have a good balance between local and global features\nthat are important for spoofing attack detection, for calculating loss in\ntraining and score in inference. The proposed method also introduces two data\naugmentation methods: face anti-spoofing data augmentation and patch-wise data\naugmentation, to improve the accuracy of spoofing attack detection. We\ndemonstrate the effectiveness of the proposed method through experiments using\nthe OULU-NPU and SiW datasets. The project page is available at:\nhttps://gsisaoki.github.io/FAS-ViT-CVPRW/ .",
    "pdf_url": "http://arxiv.org/pdf/2505.24402v2",
    "published": "2025-05-30T09:33:01+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24401v1",
    "title": "S3CE-Net: Spike-guided Spatiotemporal Semantic Coupling and Expansion Network for Long Sequence Event Re-Identification",
    "authors": [
      "Xianheng Ma",
      "Hongchen Tan",
      "Xiuping Liu",
      "Yi Zhang",
      "Huasheng Wang",
      "Jiang Liu",
      "Ying Chen",
      "Hantao Liu"
    ],
    "abstract": "In this paper, we leverage the advantages of event cameras to resist harsh\nlighting conditions, reduce background interference, achieve high time\nresolution, and protect facial information to study the long-sequence\nevent-based person re-identification (Re-ID) task. To this end, we propose a\nsimple and efficient long-sequence event Re-ID model, namely the Spike-guided\nSpatiotemporal Semantic Coupling and Expansion Network (S3CE-Net). To better\nhandle asynchronous event data, we build S3CE-Net based on spiking neural\nnetworks (SNNs). The S3CE-Net incorporates the Spike-guided Spatial-temporal\nAttention Mechanism (SSAM) and the Spatiotemporal Feature Sampling Strategy\n(STFS). The SSAM is designed to carry out semantic interaction and association\nin both spatial and temporal dimensions, leveraging the capabilities of SNNs.\nThe STFS involves sampling spatial feature subsequences and temporal feature\nsubsequences from the spatiotemporal dimensions, driving the Re-ID model to\nperceive broader and more robust effective semantics. Notably, the STFS\nintroduces no additional parameters and is only utilized during the training\nstage. Therefore, S3CE-Net is a low-parameter and high-efficiency model for\nlong-sequence event-based person Re-ID. Extensive experiments have verified\nthat our S3CE-Net achieves outstanding performance on many mainstream\nlong-sequence event-based person Re-ID datasets. Code is available\nat:https://github.com/Mhsunshine/SC3E_Net.",
    "pdf_url": "http://arxiv.org/pdf/2505.24401v1",
    "published": "2025-05-30T09:32:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24400v1",
    "title": "An MCMC hypothesis test to check a claimed sampler: applied to a claimed sampler for the G-Wishart distribution",
    "authors": [
      "Håkon Tjelmeland",
      "Hanna Bu Kvaløy"
    ],
    "abstract": "Suppose we have a distribution of interest, with density $p(x),x\\in {\\cal X}$\nsay, and an algorithm\n  claimed to generate samples from $p(x)$. Moreover, assume we have available a\nMetropolis--Hastings\n  transition kernel fulfilling detail balance with respect to $p(x)$. In such a\nsituation we\n  formulate a hypothesis test where $H_0$ is that the claimed sampler really\ngenerates\n  correct samples from $p(x)$. We use that if initialising the\nMetropolis--Hastings algorithm with a\n  sample generated by the claimed sampler and run the chain for a fixed number\nof updates, the\n  initial and final states are exchangeable if $H_0$ is true. Combining this\nidea with the\n  permutation strategy we define a natural test statistic and a valid p-value.\n  Our motivation for considering the hypothesis test situation is a proposed\nsampler in the\n  literature, claimed to generate samples from G-Wishart distribution. As no\nproper\n  proof for the validity of this sampler seems to be available, we are exactly\nin the hypothesis\n  test situation discussed above. We therefore apply the defined hypothesis\ntest to the\n  claimed sampler. For comparison we also apply the hypothesis test to a known\nexact sampler\n  for a subset of G-Wishart distributions. The obtained p-values clearly show\nthat\n  the sampler claimed to be able to generate samples from any G-Wishart\ndistribution is\n  in fact not sampling from the specified distribution. In contrast, and as one\nshould expect,\n  the p-values obtained when using the known exact algorithm does not indicate\nany problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24400v1",
    "published": "2025-05-30T09:30:08+00:00",
    "categories": [
      "stat.CO"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24399v1",
    "title": "LightSAM: Parameter-Agnostic Sharpness-Aware Minimization",
    "authors": [
      "Yifei Cheng",
      "Li Shen",
      "Hao Sun",
      "Nan Yin",
      "Xiaochun Cao",
      "Enhong Chen"
    ],
    "abstract": "Sharpness-Aware Minimization (SAM) optimizer enhances the generalization\nability of the machine learning model by exploring the flat minima landscape\nthrough weight perturbations. Despite its empirical success, SAM introduces an\nadditional hyper-parameter, the perturbation radius, which causes the\nsensitivity of SAM to it. Moreover, it has been proved that the perturbation\nradius and learning rate of SAM are constrained by problem-dependent parameters\nto guarantee convergence. These limitations indicate the requirement of\nparameter-tuning in practical applications. In this paper, we propose the\nalgorithm LightSAM which sets the perturbation radius and learning rate of SAM\nadaptively, thus extending the application scope of SAM. LightSAM employs three\npopular adaptive optimizers, including AdaGrad-Norm, AdaGrad and Adam, to\nreplace the SGD optimizer for weight perturbation and model updating, reducing\nsensitivity to parameters. Theoretical results show that under weak\nassumptions, LightSAM could converge ideally with any choices of perturbation\nradius and learning rate, thus achieving parameter-agnostic. We conduct\npreliminary experiments on several deep learning tasks, which together with the\ntheoretical findings validate the the effectiveness of LightSAM.",
    "pdf_url": "http://arxiv.org/pdf/2505.24399v1",
    "published": "2025-05-30T09:28:38+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24398v1",
    "title": "Wall roughness and viscous dissipation effects in microchannel heat sinks with semicircular cross-section",
    "authors": [
      "A. Barletta",
      "M. Celli",
      "P. V. Brandão"
    ],
    "abstract": "A statistical analysis of the wall roughness effect is carried out to\ndetermine the impact of the shape uncertainty on the Poiseuille number and\nNusselt number of laminar forced convection. The focus is on the fully\ndeveloped regime in a semicircular microchannel where the heat transfer occurs\nfrom the diametrical plane boundary, modelled as a perfectly smooth surface. On\nthe other hand, the curved semicircular boundary is devised as rough and with a\nnegligible wall heat flux. Three types of thermal boundary conditions are\nimplemented: the T condition, the H1 condition and the H2 condition. The T\ncondition serves to model a case where the fluid temperature does not undergo\nany change in the streamwise direction, while the H1 and H2 conditions are\nemployed to describe a net heating of the fluid. A statistical sample of\nseveral different rough microchannels is used to detect the actual effects of\nroughness on the Poiseuille number and on the Nusselt number, through the\nevaluation of their average values and standard deviations. The governing local\nmomentum and energy balance equations are solved numerically by a finite\nelement method taking into account the viscous dissipation contribution to the\nlocal energy balance.",
    "pdf_url": "http://arxiv.org/pdf/2505.24398v1",
    "published": "2025-05-30T09:26:26+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24397v1",
    "title": "Bayesian Inference for Spatially-Temporally Misaligned Data Using Predictive Stacking",
    "authors": [
      "Soumyakanti Pan",
      "Sudipto Banerjee"
    ],
    "abstract": "Air pollution remains a major environmental risk factor that is often\nassociated with adverse health outcomes. However, quantifying and evaluating\nits effects on human health is challenging due to the complex nature of\nexposure data. Recent technological advances have led to the collection of\nvarious indicators of air pollution at increasingly high spatial-temporal\nresolutions (e.g., daily averages of pollutant levels at spatial locations\nreferenced by latitude-longitude). However, health outcomes are typically\naggregated over several spatial-temporal coordinates (e.g., annual prevalence\nfor a county) to comply with survey regulations. This article develops a\nBayesian hierarchical model to analyze such spatially-temporally misaligned\nexposure and health outcome data. We introduce Bayesian predictive stacking,\nwhich optimally combines multiple predictive spatial-temporal models and avoids\niterative estimation algorithms such as Markov chain Monte Carlo that struggle\ndue to convergence issues inflicted by the presence of weakly identified\nparameters. We apply our proposed method to study the effects of ozone on\nasthma in the state of California.",
    "pdf_url": "http://arxiv.org/pdf/2505.24397v1",
    "published": "2025-05-30T09:26:20+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24396v1",
    "title": "Reactive Aerobatic Flight via Reinforcement Learning",
    "authors": [
      "Zhichao Han",
      "Xijie Huang",
      "Zhuxiu Xu",
      "Jiarui Zhang",
      "Yuze Wu",
      "Mingyang Wang",
      "Tianyue Wu",
      "Fei Gao"
    ],
    "abstract": "Quadrotors have demonstrated remarkable versatility, yet their full aerobatic\npotential remains largely untapped due to inherent underactuation and the\ncomplexity of aggressive maneuvers. Traditional approaches, separating\ntrajectory optimization and tracking control, suffer from tracking\ninaccuracies, computational latency, and sensitivity to initial conditions,\nlimiting their effectiveness in dynamic, high-agility scenarios. Inspired by\nrecent breakthroughs in data-driven methods, we propose a reinforcement\nlearning-based framework that directly maps drone states and aerobatic\nintentions to control commands, eliminating modular separation to enable\nquadrotors to perform end-to-end policy optimization for extreme aerobatic\nmaneuvers. To ensure efficient and stable training, we introduce an automated\ncurriculum learning strategy that dynamically adjusts aerobatic task\ndifficulty. Enabled by domain randomization for robust zero-shot sim-to-real\ntransfer, our approach is validated in demanding real-world experiments,\nincluding the first demonstration of a drone autonomously performing continuous\ninverted flight while reactively navigating a moving gate, showcasing\nunprecedented agility.",
    "pdf_url": "http://arxiv.org/pdf/2505.24396v1",
    "published": "2025-05-30T09:24:30+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24394v1",
    "title": "Refining Platelet Purification Methods: Enhancing Proteomics for Clinical Applications",
    "authors": [
      "Vibecke Markhus",
      "Katarina Fritz-Wallace",
      "Olav Mjaavatten",
      "Einar K. Kristoffersen",
      "Dorota Goplen",
      "Frode Selheim"
    ],
    "abstract": "Background: Platelet proteomics offers valuable insights for clinical\nresearch, yet isolating high-purity platelets remains a challenge. Current\nmethods often lead to contamination or platelet loss, compromising data quality\nand reproducibility.\n  Objectives: This study aimed to optimize a platelet isolation technique that\nyields high-purity samples with minimal loss and to identify the most effective\nmass spectrometry-based proteomic method for analyzing platelet proteins with\noptimal coverage and sensitivity.\n  Methods: We refined an isolation protocol by adjusting centrifugation time to\nreduce blood volume requirements while preserving platelet yield and purity.\nUsing this optimized method, we evaluated three proteomic approaches:\nLabel-free Quantification with Data-Independent Acquisition (LFQ-DIA),\nLabel-free Quantification with Data-Dependent Acquisition (LFQ-DDA), and Tandem\nMass Tag labeling with DDA (TMT-DDA).\n  Results: LFQ-DIA demonstrated superior protein coverage and sensitivity\ncompared to LFQ-DDA and TMT-DDA. The refined isolation protocol effectively\nminimized contamination and platelet loss. Additionally, age-related\ndifferences in platelet protein composition were observed, highlighting the\nimportance of using age-matched controls in biomarker discovery studies.\n  Conclusions: The optimized platelet isolation protocol provides a\ncost-effective and reliable method for preparing high-purity samples for\nproteomics. LFQ-DIA is the most suitable approach for comprehensive platelet\nprotein analysis. Age-related variation in platelet proteomes underscores the\nneed for demographic matching in clinical proteomic research.",
    "pdf_url": "http://arxiv.org/pdf/2505.24394v1",
    "published": "2025-05-30T09:24:18+00:00",
    "categories": [
      "q-bio.BM",
      "q-bio.GN"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24395v1",
    "title": "Correcting for the effects of the point spread function in intra-halo light measurements and application to deep Hyper Suprime-Cam data",
    "authors": [
      "L. P. Garate-Nuñez",
      "A. S. G. Robotham",
      "S. Bellstedt",
      "L. J. M. Davies"
    ],
    "abstract": "The intra-halo light (IHL) is the diffuse stellar component that surrounds\ngalaxies, groups, and clusters. Its formation is intimately linked to the\nhierarchical assembly of the system, making it a key tracer of galaxy\nevolution. However, the low surface brightness (LSB) of the IHL makes it\nchallenging to detect and also to distinguish from the point spread function\n(PSF) effect of the telescope. In this paper, we present two independent\ntechniques that, when combined, provide a statistically robust estimation of\nthe IHL component in galaxy groups and clusters. The first technique corrects\nfor the PSF-scattering effect to obtain unbiased LSB measurements, while the\nsecond fits an exponential model to the IHL component using a Markov Chain\nMonte Carlo (MCMC) optimiser algorithm. To test our methodology, we build a set\nof 5440 Hyper Suprime-Cam Subaru Strategic Program Public Data Release 3\n(HSC-SSP PDR3) mock observations of Galaxy And Mass Assembly (GAMA) groups,\neach containing an IHL component with a flux fraction ($\\mathrm{f_{IHL}}$)\nranging from 0.01 to 0.5. Our results demonstrate the importance of properly\nremoving the PSF-scattered flux, especially at lower $\\mathrm{f_{IHL}}$.\nWithout the PSF correction, our IHL model overestimates the true flux by up to\na factor of 100, and the effective radius by up to a factor of 10. Finally, we\napply our methodology to real observations and estimate the $\\mathrm{f_{IHL}}$\nof the GAMA group G400138 using HSC-PDR3 UD data in the $\\textit{g,r}$ and\n$\\textit{i}$-bands, finding median IHL fractions of: $\\mathrm{f_{g,IHL}}$\n$\\sim$ 0.19$^{+0.09}_{-0.01}$, $\\mathrm{f_{r,IHL}}$ $\\sim$\n0.08$^{+0.06}_{-0.02}$ and $\\mathrm{f_{i,IHL}}$ $\\sim$ 0.06$^{+0.04}_{-0.02}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24395v1",
    "published": "2025-05-30T09:24:18+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24393v1",
    "title": "Looking for Attention: Randomized Attention Test Design for Validator Monitoring in Optimistic Rollups",
    "authors": [
      "Suhyeon Lee"
    ],
    "abstract": "Optimistic Rollups (ORUs) significantly enhance blockchain scalability but\ninherently suffer from the verifier's dilemma, particularly concerning\nvalidator attentiveness. Current systems lack mechanisms to proactively ensure\nvalidators are diligently monitoring L2 state transitions, creating a\nvulnerability where fraudulent states could be finalized. This paper introduces\nthe Randomized Attention Test (RAT), a novel L1-based protocol designed to\nprobabilistically challenge validators in ORUs, thereby verifying their\nliveness and computational readiness. Our game-theoretic analysis demonstrates\nthat an Ideal Security Equilibrium, where all validators are attentive and\nproposers are honest, can be achieved with RAT. Notably, this equilibrium is\nattainable and stable with relatively low economic penalties (e.g., under\n$1000) for non-responsive validators and a low attention test frequency (e.g.,\nunder 1% per epoch). RAT thus provides a crucial, practical mechanism to\nenforce validator diligence, fortifying the overall security and integrity of\nORU systems with minimizing additional costs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24393v1",
    "published": "2025-05-30T09:24:09+00:00",
    "categories": [
      "cs.CR",
      "cs.CE",
      "cs.GT",
      "K.6.5; C.2.2; F.2"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24392v1",
    "title": "Complex wave functions, CPT and quantum field theory for classical generalized Ising models",
    "authors": [
      "Christof Wetterich"
    ],
    "abstract": "The quantum or quantum field theory concept of a complex wave function is\nuseful for understanding the information transport in classical statistical\ngeneralized Ising models.\n  We relate complex conjugation to the discrete transformations charge\nconjugation ($C$), parity ($P$) and time reversal ($T$).\n  A subclass of generalized Ising models are probabilistic cellular automata\n(PCA) with deterministic updating and probabilistic initial conditions.\n  Two-dimensional PCA correspond to discretized quantum field theories for\nMajorana--Weyl, Weyl or Dirac fermions.\n  Momentum and energy are conserved statistical observables.\n  For PCA describing free massless fermions we investigate the vacuum and field\noperators for particle excitations.\n  These automata admit probabilistic boundary conditions that correspond to\nthermal equilibrium with the quantum Fermi--Dirac distribution.\n  PCA with updating sequences of propagation and interaction steps can realize\na rich variety of discrete quantum field theories for fermions with\ninteractions.\n  For information theory the quantum formalism for PCA sheds new light on\ndeterministic computing or signal processing with probabilistic input.",
    "pdf_url": "http://arxiv.org/pdf/2505.24392v1",
    "published": "2025-05-30T09:23:50+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "hep-lat",
      "hep-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24391v1",
    "title": "Quantum Point Contact with Local Two-body Loss",
    "authors": [
      "Kensuke Kakimoto",
      "Shun Uchino"
    ],
    "abstract": "Motivated by recent advances in ultracold atomic gas experiments, we\ninvestigate a two-terminal mesoscopic system in which two-body loss occurs\nlocally at the center of a one-dimensional chain. By means of the\nself-consistent Born approximation in the Keldysh formalism, we uncover\nmesoscopic current formulas that are experimentally relevant and applicable to\nthe weak dissipation regime. Although these formulas are analogous to those for\nsystems with one-body loss, it turns out that the channel transmittance and\nloss probability depend on the nonequilibrium occupation at the lossy site. We\ndemonstrate that this occupation dependence leads to a weaker suppression of\ncurrents in the presence of two-body loss compared to one-body loss, in\nagreement with a recent experimental observation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24391v1",
    "published": "2025-05-30T09:21:03+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.24390v1",
    "title": "SAH-Drive: A Scenario-Aware Hybrid Planner for Closed-Loop Vehicle Trajectory Generation",
    "authors": [
      "Yuqi Fan",
      "Zhiyong Cui",
      "Zhenning Li",
      "Yilong Ren",
      "Haiyang Yu"
    ],
    "abstract": "Reliable planning is crucial for achieving autonomous driving. Rule-based\nplanners are efficient but lack generalization, while learning-based planners\nexcel in generalization yet have limitations in real-time performance and\ninterpretability. In long-tail scenarios, these challenges make planning\nparticularly difficult. To leverage the strengths of both rule-based and\nlearning-based planners, we proposed the Scenario-Aware Hybrid Planner\n(SAH-Drive) for closed-loop vehicle trajectory planning. Inspired by human\ndriving behavior, SAH-Drive combines a lightweight rule-based planner and a\ncomprehensive learning-based planner, utilizing a dual-timescale decision\nneuron to determine the final trajectory. To enhance the computational\nefficiency and robustness of the hybrid planner, we also employed a diffusion\nproposal number regulator and a trajectory fusion module. The experimental\nresults show that the proposed method significantly improves the generalization\ncapability of the planning system, achieving state-of-the-art performance in\ninterPlan, while maintaining computational efficiency without incurring\nsubstantial additional runtime.",
    "pdf_url": "http://arxiv.org/pdf/2505.24390v1",
    "published": "2025-05-30T09:19:39+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24389v2",
    "title": "Leadership Assessment in Pediatric Intensive Care Unit Team Training",
    "authors": [
      "Liangyang Ouyang",
      "Yuki Sakai",
      "Ryosuke Furuta",
      "Hisataka Nozawa",
      "Hikoro Matsui",
      "Yoichi Sato"
    ],
    "abstract": "This paper addresses the task of assessing PICU team's leadership skills by\ndeveloping an automated analysis framework based on egocentric vision. We\nidentify key behavioral cues, including fixation object, eye contact, and\nconversation patterns, as essential indicators of leadership assessment. In\norder to capture these multimodal signals, we employ Aria Glasses to record\negocentric video, audio, gaze, and head movement data. We collect one-hour\nvideos of four simulated sessions involving doctors with different roles and\nlevels. To automate data processing, we propose a method leveraging REMoDNaV,\nSAM, YOLO, and ChatGPT for fixation object detection, eye contact detection,\nand conversation classification. In the experiments, significant correlations\nare observed between leadership skills and behavioral metrics, i.e., the output\nof our proposed methods, such as fixation time, transition patterns, and direct\norders in speech. These results indicate that our proposed data collection and\nanalysis framework can effectively solve skill assessment for training PICU\nteams.",
    "pdf_url": "http://arxiv.org/pdf/2505.24389v2",
    "published": "2025-05-30T09:19:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24388v1",
    "title": "ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation",
    "authors": [
      "Hao Chen",
      "Yukun Yan",
      "Sen Mei",
      "Wanxiang Che",
      "Zhenghao Liu",
      "Qi Shi",
      "Xinze Li",
      "Yuchun Fan",
      "Pengcheng Huang",
      "Qiushi Xiong",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs)\nwith external knowledge to improve factuality. However, existing RAG systems\nfrequently underutilize the retrieved documents, failing to extract and\nintegrate the key clues needed to support faithful and interpretable reasoning,\nespecially in cases where relevant evidence is implicit, scattered, or obscured\nby noise. To address this issue, we propose ClueAnchor, a novel framework for\nenhancing RAG via clue-anchored reasoning exploration and optimization.\nClueAnchor extracts key clues from retrieved content and generates multiple\nreasoning paths based on different knowledge configurations, optimizing the\nmodel by selecting the most effective one through reward-based preference\noptimization. Experiments show that ClueAnchor significantly outperforms prior\nRAG baselines in reasoning completeness and robustness. Further analysis\nconfirms its strong resilience to noisy or partially relevant retrieved\ncontent, as well as its capability to identify supporting evidence even in the\nabsence of explicit clue supervision during inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.24388v1",
    "published": "2025-05-30T09:18:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24387v1",
    "title": "Multi-bubble solutions for the Brezis-Nirenberg problem in four dimensions",
    "authors": [
      "Angela Pistoia",
      "Giuseppe Mario Rago",
      "Giusi Vaira"
    ],
    "abstract": "The paper addresses the existence of multi-bubble solutions for the\nwell-known Brezis-Nirenberg problem. Although there is extensive literature on\nthe subject, the existence of solutions that blow up at multiple points in a 4D\nbounded domain remains an open problem. The goal of the present paper is to\nresolve this longstanding issue. In particular, we exhibit examples of domains\nwhere a large number of multi-bubble solutions exist. Our result can also be\nseen as the counterpart of the asymptotic analysis carried out by Konig and\nLaurin in Ann. Inst. H. Poincar\\`e C Anal. Non Lin\\`eaire, 2024.",
    "pdf_url": "http://arxiv.org/pdf/2505.24387v1",
    "published": "2025-05-30T09:18:04+00:00",
    "categories": [
      "math.AP",
      "35B44, 35B33, 35J25"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24386v1",
    "title": "Incremental Gain Computation and Regulation of Discrete-time Positive Luré Systems using Linear Programming",
    "authors": [
      "Jared Miller"
    ],
    "abstract": "This work approaches the problem of computing incremental $\\ell_1$ and\n$\\ell_\\infty$ gains for discrete-time positive systems in \\lure feedback with\nstatic memoryless nonlinearities, and regulating the $\\ell_\\infty$ gain through\nthe design of a state-feedback controller. Finite incremental gains provide a\nquantitative measure of robustness for trajectories, and will ensure that all\npairs of trajectories will converge to a fixed point or will diverge together\nin the absence of an applied input. Upper-bounds on these incremental gains can\nbe computed through linear programming. Computation and regulation of the\n$\\ell_1$ and $\\ell_\\infty$ incremental gains are verified by numerical\nexamples.",
    "pdf_url": "http://arxiv.org/pdf/2505.24386v1",
    "published": "2025-05-30T09:16:53+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24385v1",
    "title": "Fe contribution to the magnetic anisotropy of $L{1_0}$-ordered FePt thin films studied by angle-dependent x-ray magnetic circular dichroism",
    "authors": [
      "Goro Shibata",
      "Keisuke Ikeda",
      "Takeshi Seki",
      "Shoya Sakamoto",
      "Yosuke Nonaka",
      "Zhendong Chi",
      "Yuxuan Wan",
      "Masahiro Suzuki",
      "Tsuneharu Koide",
      "Hiroki Wadati",
      "Koki Takanashi",
      "Atsushi Fujimori"
    ],
    "abstract": "Among magnetic thin films with perpendicular magnetic anisotropy (PMA),\n$L1_0$-ordered FePt has attracted significant attention because of its\nexceptionally strong PMA. However, the microscopic origin of its strong PMA has\nnot been elucidated experimentally. We have investigated the contribution of\nthe Fe $3d$ electrons to its magnetic anisotropy energy by angle-dependent\nx-ray magnetic circular dichroism at the Fe $L_{2,3}$ edge. By this technique,\none can deduce the magnetic dipole moment $m_\\text{T}$, which represents the\nanisotropic spatial distribution of spin-polarized electrons, and the orbital\nmoment anisotropy (OMA) of Fe $3d$ electrons. Detected finite $m_\\text{T}$\nindicates that the spin-polarized Fe $3d$ electrons are distributed\npreferentially in the out-of-plane direction of the films. This $m_\\text{T}$ of\nFe overwhelms the positive contribution of OMA to PMA, and reduces the PMA of\n$L1_0$-ordered FePt thin films, consistent with a previous first-principles\ncalculation. The present result implies that a large positive contribution of\nthe non-magnetic element Pt rather than Fe governs the PMA of $L1_0$-ordered\nFePt thin films.",
    "pdf_url": "http://arxiv.org/pdf/2505.24385v1",
    "published": "2025-05-30T09:16:36+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24384v1",
    "title": "Provably convergent stochastic fixed-point algorithm for free-support Wasserstein barycenter of continuous non-parametric measures",
    "authors": [
      "Zeyi Chen",
      "Ariel Neufeld",
      "Qikun Xiang"
    ],
    "abstract": "We propose a provably convergent algorithm for approximating the\n2-Wasserstein barycenter of continuous non-parametric probability measures. Our\nalgorithm is inspired by the fixed-point iterative scheme of \\'Alvarez-Esteban\net al. (2016) whose convergence to the 2-Wasserstein barycenter relies on\nobtaining exact optimal transport (OT) maps. However, typically in practice, OT\nmaps are only approximately computed and exact computation of OT maps between\ncontinuous probability measures is only tractable for certain restrictive\nparametric families. To circumvent the need to compute exact OT maps between\ngeneral non-parametric measures, we develop a tailored iterative scheme that\nutilizes consistent estimators of the OT maps instead of the exact OT maps.\nThis gives rise to a computationally tractable stochastic fixed-point algorithm\nwhich is provably convergent to the 2-Wasserstein barycenter. Our algorithm\nremarkably does not restrict the support of the 2-Wasserstein barycenter to be\nany fixed finite set and can be implemented in a distributed computing\nenvironment, which makes it suitable for large-scale data aggregation problems.\nIn our numerical experiments, we propose a method of generating non-trivial\ninstances of 2-Wasserstein barycenter problems where the ground-truth\nbarycenter measure is known. Our numerical results showcase the capability of\nour algorithm in developing high-quality approximations of the 2-Wasserstein\nbarycenter, as well as its superiority over state-of-the-art methods based on\ngenerative neural networks in terms of accuracy, stability, and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.24384v1",
    "published": "2025-05-30T09:13:57+00:00",
    "categories": [
      "math.OC",
      "cs.NA",
      "math.NA",
      "math.PR"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24383v1",
    "title": "Neural Drift Estimation for Ergodic Diffusions: Non-parametric Analysis and Numerical Exploration",
    "authors": [
      "Simone Di Gregorio",
      "Francesco Iafrate"
    ],
    "abstract": "We take into consideration generalization bounds for the problem of the\nestimation of the drift component for ergodic stochastic differential\nequations, when the estimator is a ReLU neural network and the estimation is\nnon-parametric with respect to the statistical model. We show a practical way\nto enforce the theoretical estimation procedure, enabling inference on noisy\nand rough functional data. Results are shown for a simulated It\\^o-Taylor\napproximation of the sample paths.",
    "pdf_url": "http://arxiv.org/pdf/2505.24383v1",
    "published": "2025-05-30T09:12:49+00:00",
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.24382v1",
    "title": "MagicGripper: A Multimodal Sensor-Integrated Gripper for Contact-Rich Robotic Manipulation",
    "authors": [
      "Wen Fan",
      "Haoran Li",
      "Dandan Zhang"
    ],
    "abstract": "Contact-rich manipulation in unstructured environments demands precise,\nmultimodal perception to enable robust and adaptive control. Vision-based\ntactile sensors (VBTSs) have emerged as an effective solution; however,\nconventional VBTSs often face challenges in achieving compact, multi-modal\nfunctionality due to hardware constraints and algorithmic complexity. In this\nwork, we present MagicGripper, a multimodal sensor-integrated gripper designed\nfor contact-rich robotic manipulation. Building on our prior design, MagicTac,\nwe develop a compact variant, mini-MagicTac, which features a\nthree-dimensional, multi-layered grid embedded in a soft elastomer.\nMagicGripper integrates mini-MagicTac, enabling high-resolution tactile\nfeedback alongside proximity and visual sensing within a compact,\ngripper-compatible form factor. We conduct a thorough evaluation of\nmini-MagicTac's performance, demonstrating its capabilities in spatial\nresolution, contact localization, and force regression. We also assess its\nrobustness across manufacturing variability, mechanical deformation, and\nsensing performance under real-world conditions. Furthermore, we validate the\neffectiveness of MagicGripper through three representative robotic tasks: a\nteleoperated assembly task, a contact-based alignment task, and an autonomous\nrobotic grasping task. Across these experiments, MagicGripper exhibits reliable\nmultimodal perception, accurate force estimation, and high adaptability to\nchallenging manipulation scenarios. Our results highlight the potential of\nMagicGripper as a practical and versatile tool for embodied intelligence in\ncomplex, contact-rich environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24382v1",
    "published": "2025-05-30T09:10:31+00:00",
    "categories": [
      "cs.RO",
      "eess.SP"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24381v1",
    "title": "The stability of independence polynomials of complete bipartite graphs",
    "authors": [
      "Guo Chen",
      "Bo Ning",
      "Jianhua Tu"
    ],
    "abstract": "The independence polynomial of a graph is termed {\\it stable} if all its\nroots are located in the left half-plane $\\{z \\in \\mathbb{C} : \\mathrm{Re}(z)\n\\leq 0\\}$, and the graph itself is also referred to as stable. Brown and\nCameron (Electron. J. Combin. 25(1) (2018) \\#P1.46) proved that the complete\nbipartite graph $K_{1,n}$ is stable and posed the question: \\textbf{Are all\ncomplete bipartite graphs stable?}\n  We answer this question by establishing the following results:\n  \\begin{itemize}\n  \\item The complete bipartite graphs $K_{2,n}$ and $K_{3,n}$ are stable.\n  \\item For any integer $k\\geq0$, there exists an integer $N(k)\\in \\mathbb{N}$\nsuch that $K_{m,m+k}$ is stable for all $m>N(k)$.\n  \\item For any rational $\\ell> 1$, there exists an integer $N(\\ell) \\in\n\\mathbb{N}$ such that whenever $m >N(\\ell)$ and $\\ell \\cdot m$ is an integer,\n$K_{m, \\ell \\cdot m}$ is \\textbf{not} stable.\n  \\end{itemize}",
    "pdf_url": "http://arxiv.org/pdf/2505.24381v1",
    "published": "2025-05-30T09:10:28+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24380v2",
    "title": "SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification",
    "authors": [
      "Zheng Wang"
    ],
    "abstract": "Fine-grained bird image classification (FBIC) is not only of great\nsignificance for ecological monitoring and species identification, but also\nholds broad research value in the fields of image recognition and fine-grained\nvisual modeling. Compared with general image classification tasks, FBIC poses\nmore formidable challenges: 1) the differences in species size and imaging\ndistance result in the varying sizes of birds presented in the images; 2)\ncomplex natural habitats often introduce strong background interference; 3) and\nhighly flexible poses such as flying, perching, or foraging result in\nsubstantial intra-class variability. These factors collectively make it\ndifficult for traditional methods to stably extract discriminative features,\nthereby limiting the generalizability and interpretability of models in\nreal-world applications. To address these challenges, this paper proposes a\nfine-grained bird classification framework based on strip-aware spatial\nperception, which aims to capture long-range spatial dependencies across entire\nrows or columns in bird images, thereby enhancing the model's robustness and\ninterpretability. The proposed method incorporates two novel modules:\nextensional perception aggregator (EPA) and channel semantic weaving (CSW).\nSpecifically, EPA integrates local texture details with global structural cues\nby aggregating information across horizontal and vertical spatial directions.\nCSW further refines the semantic representations by adaptively fusing\nlong-range and short-range information along the channel dimension. Built upon\na ResNet-50 backbone, the model enables jump-wise connection of extended\nstructural features across the spatial domain. Experimental results on the\nCUB-200-2011 dataset demonstrate that our framework achieves significant\nperformance improvements while maintaining architectural efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.24380v2",
    "published": "2025-05-30T09:10:12+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24379v1",
    "title": "Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models",
    "authors": [
      "Xiaoyu Wu",
      "Yifei Pang",
      "Terrance Liu",
      "Zhiwei Steven Wu"
    ],
    "abstract": "Large language models are typically trained on datasets collected from the\nweb, which may inadvertently contain harmful or sensitive personal information.\nTo address growing privacy concerns, unlearning methods have been proposed to\nremove the influence of specific data from trained models. Of these, exact\nunlearning -- which retrains the model from scratch without the target data --\nis widely regarded the gold standard, believed to be robust against\nprivacy-related attacks. In this paper, we challenge this assumption by\nintroducing a novel data extraction attack that compromises even exact\nunlearning. Our method leverages both the pre- and post-unlearning models: by\nguiding the post-unlearning model using signals from the pre-unlearning model,\nwe uncover patterns that reflect the removed data distribution. Combining model\nguidance with a token filtering strategy, our attack significantly improves\nextraction success rates -- doubling performance in some cases -- across common\nbenchmarks such as MUSE, TOFU, and WMDP. Furthermore, we demonstrate our\nattack's effectiveness on a simulated medical diagnosis dataset to highlight\nreal-world privacy risks associated with exact unlearning. In light of our\nfindings, which suggest that unlearning may, in a contradictory way, increase\nthe risk of privacy leakage, we advocate for evaluation of unlearning methods\nto consider broader threat models that account not only for post-unlearning\nmodels but also for adversarial access to prior checkpoints.",
    "pdf_url": "http://arxiv.org/pdf/2505.24379v1",
    "published": "2025-05-30T09:09:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24378v1",
    "title": "Mastering Massive Multi-Task Reinforcement Learning via Mixture-of-Expert Decision Transformer",
    "authors": [
      "Yilun Kong",
      "Guozheng Ma",
      "Qi Zhao",
      "Haoyu Wang",
      "Li Shen",
      "Xueqian Wang",
      "Dacheng Tao"
    ],
    "abstract": "Despite recent advancements in offline multi-task reinforcement learning\n(MTRL) have harnessed the powerful capabilities of the Transformer\narchitecture, most approaches focus on a limited number of tasks, with scaling\nto extremely massive tasks remaining a formidable challenge. In this paper, we\nfirst revisit the key impact of task numbers on current MTRL method, and\nfurther reveal that naively expanding the parameters proves insufficient to\ncounteract the performance degradation as the number of tasks escalates.\nBuilding upon these insights, we propose M3DT, a novel mixture-of-experts (MoE)\nframework that tackles task scalability by further unlocking the model's\nparameter scalability. Specifically, we enhance both the architecture and the\noptimization of the agent, where we strengthen the Decision Transformer (DT)\nbackbone with MoE to reduce task load on parameter subsets, and introduce a\nthree-stage training mechanism to facilitate efficient training with optimal\nperformance. Experimental results show that, by increasing the number of\nexperts, M3DT not only consistently enhances its performance as model expansion\non the fixed task numbers, but also exhibits remarkable task scalability,\nsuccessfully extending to 160 tasks with superior performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.24378v1",
    "published": "2025-05-30T09:08:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24377v1",
    "title": "LLM Inference Enhanced by External Knowledge: A Survey",
    "authors": [
      "Yu-Hsuan Lin",
      "Qian-Hui Chen",
      "Yi-Jie Cheng",
      "Jia-Ren Zhang",
      "Yi-Hung Liu",
      "Liang-Yu Hsia",
      "Yun-Nung Chen"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have enhanced\nnatural-language reasoning. However, their limited parametric memory and\nsusceptibility to hallucination present persistent challenges for tasks\nrequiring accurate, context-based inference. To overcome these limitations, an\nincreasing number of studies have proposed leveraging external knowledge to\nenhance LLMs. This study offers a systematic exploration of strategies for\nusing external knowledge to enhance LLMs, beginning with a taxonomy that\ncategorizes external knowledge into unstructured and structured data. We then\nfocus on structured knowledge, presenting distinct taxonomies for tables and\nknowledge graphs (KGs), detailing their integration paradigms with LLMs, and\nreviewing representative methods. Our comparative analysis further highlights\nthe trade-offs among interpretability, scalability, and performance, providing\ninsights for developing trustworthy and generalizable knowledge-enhanced LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24377v1",
    "published": "2025-05-30T09:08:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24376v2",
    "title": "QCD sum rule study on excited light meson operators",
    "authors": [
      "Wei-Han Tan",
      "Wen-Ying Liu",
      "Hong-Zhou Xi",
      "Hua-Xing Chen"
    ],
    "abstract": "We apply the QCD sum rule method to systematically study excited light meson\noperators and calculate their decay constants. These operators are constructed\nby explicitly adding one covariant derivative to the quark-antiquark pair. In\ntotal, twelve such operators are constructed, among which ten are subjected to\ndetailed numerical analyses. The considered quark contents include $\\bar{q}q$,\n$\\bar{q}s$, and $\\bar{s}s$ ($q = u/d$), allowing the formation of various\n$SU(3)$ flavor nonets. For instance, our results support the interpretation\nthat the $a_2(1320)$, $f_2(1270)$, $f_2^\\prime(1525)$, and $K_2^*(1430)$\nconstitute a flavor nonet with quantum numbers $J^{P(C)} = 2^{+(+)}$. In\naddition, we predict several excited meson states, whose masses and decay\nconstants are determined using the QCD sum rule method.",
    "pdf_url": "http://arxiv.org/pdf/2505.24376v2",
    "published": "2025-05-30T09:08:08+00:00",
    "categories": [
      "hep-ph",
      "hep-lat"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24375v1",
    "title": "Spatiotemporal Analysis of Forest Machine Operations Using 3D Video Classification",
    "authors": [
      "Maciej Wielgosz",
      "Simon Berg",
      "Heikki Korpunen",
      "Stephan Hoffmann"
    ],
    "abstract": "This paper presents a deep learning-based framework for classifying forestry\noperations from dashcam video footage. Focusing on four key work elements -\ncrane-out, cutting-and-to-processing, driving, and processing - the approach\nemploys a 3D ResNet-50 architecture implemented with PyTorchVideo. Trained on a\nmanually annotated dataset of field recordings, the model achieves strong\nperformance, with a validation F1 score of 0.88 and precision of 0.90. These\nresults underscore the effectiveness of spatiotemporal convolutional networks\nfor capturing both motion patterns and appearance in real-world forestry\nenvironments.\n  The system integrates standard preprocessing and augmentation techniques to\nimprove generalization, but overfitting is evident, highlighting the need for\nmore training data and better class balance. Despite these challenges, the\nmethod demonstrates clear potential for reducing the manual workload associated\nwith traditional time studies, offering a scalable solution for operational\nmonitoring and efficiency analysis in forestry.\n  This work contributes to the growing application of AI in natural resource\nmanagement and sets the foundation for future systems capable of real-time\nactivity recognition in forest machinery. Planned improvements include dataset\nexpansion, enhanced regularization, and deployment trials on embedded systems\nfor in-field use.",
    "pdf_url": "http://arxiv.org/pdf/2505.24375v1",
    "published": "2025-05-30T09:07:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24374v2",
    "title": "Newtonian-like behavior of starting vortex flow in superfluid helium at high Reynolds numbers",
    "authors": [
      "J. Blaha",
      "L. Xu",
      "M. La Mantia"
    ],
    "abstract": "We study experimentally the starting vortices shed by airfoils accelerating\nuniformly from rest in superfluid helium-4 (He II). The vortices behave\napparently as if they were moving in a classical Newtonian fluid, such as air\nor water. Specifically, the starting vortex positions obtained from the\nexperimental data are found to be very close to those computed numerically in a\nNewtonian fluid, at sufficiently small times, when self-similar behavior is\nexpected to occur, and for Reynolds numbers ranging approximately between $5\n\\times 10^2$ and $5 \\times 10^5$. The result indicates neatly that turbulent\nflows of He II can be very similar to classical flows of Newtonian fluids, when\nthermal effects can be neglected and at sufficiently large flow scales, i.e.\nthe study demonstrates that superfluid helium-4 could also be employed to study\nclassical Newtonian flows.",
    "pdf_url": "http://arxiv.org/pdf/2505.24374v2",
    "published": "2025-05-30T09:06:04+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24373v2",
    "title": "Signatures of Fuzzy Dark Matter Inside Radial Critical Curves",
    "authors": [
      "J. M. Palencia",
      "Paloma Morilla",
      "Sung Kei Li",
      "J. M. Diego",
      "Amruth Alfred",
      "Thomas J. Broadhurst",
      "B. J. Kavanagh",
      "Jeremy Lim"
    ],
    "abstract": "We investigate the strong gravitational lensing properties of fuzzy dark\nmatter (FDM) halos, focusing on the magnification properties near radial\ncritical curves (CCs). Using simulated lenses we compute magnification maps for\na range of axion masses and halo configurations. We show that FDM produces\nenhanced central magnification and secondary CCs that are not easily reproduced\nby standard cold dark matter (CDM), even when including subhalos. The strength\nand scale of these effects depend primarily on the de~Broglie wavelength,\ngoverned by the axion and halo masses. We find that axion masses in the range\n$m_\\psi \\sim 10^{-22}$--$10^{-21}\\,\\mathrm{eV}$ in galaxy-mass halos lead to\ndistinctive magnification distributions. Our results suggest that observations\nof highly magnified, compact sources near radial arcs, such as quasars or\nsupernovae, could serve as a powerful test for the presence of FDM.",
    "pdf_url": "http://arxiv.org/pdf/2505.24373v2",
    "published": "2025-05-30T09:05:50+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.15707v1",
    "title": "Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling",
    "authors": [
      "Xinglin Wang",
      "Yiwei Li",
      "Shaoxiong Feng",
      "Peiwen Yuan",
      "Yueqi Zhang",
      "Jiayi Shi",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Test-Time Scaling (TTS) improves the performance of Large Language Models\n(LLMs) by using additional inference-time computation to explore multiple\nreasoning paths through search. Yet how to allocate a fixed rollout budget most\neffectively during search remains underexplored, often resulting in inefficient\nuse of compute at test time. To bridge this gap, we formulate test-time search\nas a resource allocation problem and derive the optimal allocation strategy\nthat maximizes the probability of obtaining a correct solution under a fixed\nrollout budget. Within this formulation, we reveal a core limitation of\nexisting search methods: solution-level allocation tends to favor reasoning\ndirections with more candidates, leading to theoretically suboptimal and\ninefficient use of compute. To address this, we propose Direction-Oriented\nResource Allocation (DORA), a provably optimal method that mitigates this bias\nby decoupling direction quality from candidate count and allocating resources\nat the direction level. To demonstrate DORA's effectiveness, we conduct\nextensive experiments on challenging mathematical reasoning benchmarks\nincluding MATH500, AIME2024, and AIME2025. The empirical results show that DORA\nconsistently outperforms strong baselines with comparable computational cost,\nachieving state-of-the-art accuracy. We hope our findings contribute to a\nbroader understanding of optimal TTS for LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.15707v1",
    "published": "2025-05-30T09:05:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24372v1",
    "title": "D2AF: A Dual-Driven Annotation and Filtering Framework for Visual Grounding",
    "authors": [
      "Yichi Zhang",
      "Gongwei Chen",
      "Jun Zhu",
      "Jia Wan"
    ],
    "abstract": "Visual Grounding is a task that aims to localize a target region in an image\nbased on a free-form natural language description. With the rise of Transformer\narchitectures, there is an increasing need for larger datasets to boost\nperformance. However, the high cost of manual annotation poses a challenge,\nhindering the scale of data and the ability of large models to enhance their\neffectiveness. Previous pseudo label generation methods heavily rely on\nhuman-labeled captions of the original dataset, limiting scalability and\ndiversity. To address this, we propose D2AF, a robust annotation framework for\nvisual grounding using only input images. This approach overcomes dataset size\nlimitations and enriches both the quantity and diversity of referring\nexpressions. Our approach leverages multimodal large models and object\ndetection models. By implementing dual-driven annotation strategies, we\neffectively generate detailed region-text pairs using both closed-set and\nopen-set approaches. We further conduct an in-depth analysis of data quantity\nand data distribution. Our findings demonstrate that increasing data volume\nenhances model performance. However, the degree of improvement depends on how\nwell the pseudo labels broaden the original data distribution. Based on these\ninsights, we propose a consistency and distribution aware filtering method to\nfurther improve data quality by effectively removing erroneous and redundant\ndata. This approach effectively eliminates noisy data, leading to improved\nperformance. Experiments on three visual grounding tasks demonstrate that our\nmethod significantly improves the performance of existing models and achieves\nstate-of-the-art results.",
    "pdf_url": "http://arxiv.org/pdf/2505.24372v1",
    "published": "2025-05-30T09:04:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24371v3",
    "title": "Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering",
    "authors": [
      "Md Intisar Chowdhury",
      "Kittinun Aukkapinyo",
      "Hiroshi Fujimura",
      "Joo Ann Woo",
      "Wasu Wasusatein",
      "Fadoua Ghourabi"
    ],
    "abstract": "In this paper, we propose a Grid-based Local and Global Area Transcription\n(Grid-LoGAT) system for Video Question Answering (VideoQA). The system operates\nin two phases. First, extracting text transcripts from video frames using a\nVision-Language Model (VLM). Next, processing questions using these transcripts\nto generate answers through a Large Language Model (LLM). This design ensures\nimage privacy by deploying the VLM on edge devices and the LLM in the cloud. To\nimprove transcript quality, we propose grid-based visual prompting, which\nextracts intricate local details from each grid cell and integrates them with\nglobal information. Evaluation results show that Grid-LoGAT, using the\nopen-source VLM (LLaVA-1.6-7B) and LLM (Llama-3.1-8B), outperforms\nstate-of-the-art methods with similar baseline models on NExT-QA and STAR-QA\ndatasets with an accuracy of 65.9% and 50.11% respectively. Additionally, our\nmethod surpasses the non-grid version by 24 points on localization-based\nquestions we created using NExT-QA. (This paper is accepted by IEEE ICIP 2025.)",
    "pdf_url": "http://arxiv.org/pdf/2505.24371v3",
    "published": "2025-05-30T09:04:30+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24370v1",
    "title": "A system of 2 nonlinearly coupled ODEs which is explicitly solvable and possibly isochronous provided its coefficients are suitably restricted",
    "authors": [
      "Fabio Briscese",
      "Francesco Calogero",
      "Farrin Payandeh"
    ],
    "abstract": "In this paper we discuss some remarkable properties of the autonomous system\nof 2 first-order Ordinary Differential Equations (ODEs), which equates the\nderivatives $\\dot{x}_n(t)$ ($n = 1, 2$) of the 2 dependent variables $x_n(t)$\nto the ratios of polynomials (with constant coefficients) in the 2 variables\n$x_n (t)$: each of the 2 (a priori different) polynomials $P_3^{(n)}(x_1, x_2)$\nin the 2 numerators is of degree 3; the 2 denominators are instead given by the\nsame polynomial $P_1(x_1, x_2)$ of degree 1. Hence this system features 23 a\npriori arbitrary input numbers, namely the 23 coefficients defining these 3\npolynomials. Our main finding is to show that if these 23 coefficients are\ngiven by 23 (explicitly provided) formulas in terms of 15 a priori arbitrary\nparameters, then the initial values problem (with arbitrary initial data $x_n\n(0)$) for this dynamical system can be explicitly solved. We also show that it\nis possible (with the help of Mathematica) to identify 12 explicit constraints\non these 23 coefficients, which are sufficient to guarantee that this system\nbelongs to the class of systems we are focusing on. Several such explicitly\nsolvable systems of ODEs are treated (including the subcase with $P_1(x_1, x_2)\n= 1$, implying that the right-hand sides of the ODEs are just cubic\npolynomials: no denominators!). Examples of the solutions of several of these\nsystems are reported and displayed, including cases in which the solutions are\nisochronous.",
    "pdf_url": "http://arxiv.org/pdf/2505.24370v1",
    "published": "2025-05-30T09:03:47+00:00",
    "categories": [
      "nlin.SI",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "nlin.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24369v1",
    "title": "Adversarial Preference Learning for Robust LLM Alignment",
    "authors": [
      "Yuanfu Wang",
      "Pengyu Wang",
      "Chenyang Xi",
      "Bo Tang",
      "Junyi Zhu",
      "Wenqiang Wei",
      "Chen Chen",
      "Chao Yang",
      "Jingfeng Zhang",
      "Chaochao Lu",
      "Yijun Niu",
      "Keming Mao",
      "Zhiyu Li",
      "Feiyu Xiong",
      "Jie Hu",
      "Mingchuan Yang"
    ],
    "abstract": "Modern language models often rely on Reinforcement Learning from Human\nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to\nadversarial attacks due to three key limitations: (1) the inefficiency and high\ncost of human annotation, (2) the vast diversity of potential adversarial\nattacks, and (3) the risk of feedback bias and reward hacking. To address these\nchallenges, we introduce Adversarial Preference Learning (APL), an iterative\nadversarial training method incorporating three key innovations. First, a\ndirect harmfulness metric based on the model's intrinsic preference\nprobabilities, eliminating reliance on external assessment. Second, a\nconditional generative attacker that synthesizes input-specific adversarial\nvariations. Third, an iterative framework with automated closed-loop feedback,\nenabling continuous adaptation through vulnerability discovery and mitigation.\nExperiments on Mistral-7B-Instruct-v0.3 demonstrate that APL significantly\nenhances robustness, achieving 83.33% harmlessness win rate over the base model\n(evaluated by GPT-4o), reducing harmful outputs from 5.88% to 0.43% (measured\nby LLaMA-Guard), and lowering attack success rate by up to 65% according to\nHarmBench. Notably, APL maintains competitive utility, with an MT-Bench score\nof 6.59 (comparable to the baseline 6.78) and an LC-WinRate of 46.52% against\nthe base model.",
    "pdf_url": "http://arxiv.org/pdf/2505.24369v1",
    "published": "2025-05-30T09:02:07+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24368v1",
    "title": "Relaxed uniqueness conditions for the parabolic Schrodinger equation on Riemannian manifolds",
    "authors": [
      "Fabio Punzo"
    ],
    "abstract": "We study uniqueness for solutions to the Cauchy problem associated with the\nparabolic Schr\\\"odinger equation on complete noncompact Riemannian manifolds,\nunder suitable integral conditions on the solution. We show that, under\nsuitable assumptions on the potential V, the required integrability condition\ncan be significantly relaxed compared to the case without potential. This\nimprovement is achieved by exploiting the decay of positive solutions to the\nassociated stationary Schrodinger equation. To the best of our knowledge,\nidentifying how the behavior of the potential influences the uniqueness\nintegral condition, through the decay properties of solutions to the\ncorresponding stationary equation, constitutes a novel contribution to the\ntheory.",
    "pdf_url": "http://arxiv.org/pdf/2505.24368v1",
    "published": "2025-05-30T09:02:03+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24367v1",
    "title": "High resolution up-conversion imaging in the 10 μm band under incoherent illumination",
    "authors": [
      "Zhao-Qi-Zhi Han",
      "Xiao-Hua Wang",
      "Jin-Peng Li",
      "Bo-Wen Liu",
      "Zheng-He Zhou",
      "He Zhang",
      "Yin-Hai Li",
      "Zhi-Yuan Zhou",
      "Bao-Sen Shi"
    ],
    "abstract": "Long-wavelength infrared band exhibits significant utility in thermal\nsignature acquisition and molecular spectral analysis, among other\napplications. The up-conversion detection technique enables effective signal\ntransduction into the detection bandwidth of silicon-based photodetectors,\nthereby facilitating high-sensitivity photonic measurements. We realized\nhigh-resolution up-conversion imaging for incoherent thermal targets in the 10\n{\\mu}m spectral regime for the first time. Furthermore, this work presents the\nfirst derivation of analytical models characterizing depth of field and\nastigmatic aberration in up-conversion imaging systems, which show excellent\nagreement between theoretical and experimental results. The results demonstrate\ngeneralisability to various up-conversion imaging systems, thus providing\ncritical insights for the design and optimisation of such systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24367v1",
    "published": "2025-05-30T09:01:45+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24366v1",
    "title": "Spin vs. position conjugation in quantum simulations with atoms: application to quantum chemistry",
    "authors": [
      "N. A. Moroz",
      "K. S. Tikhonov",
      "L. V. Gerasimov",
      "A. D. Manukhova",
      "I. B. Bobrov",
      "S. S. Straupe",
      "D. V. Kupriyanov"
    ],
    "abstract": "The permutation symmetry is a fundamental attribute of the collective\nwavefunction of indistinguishable particles. It makes a difference for the\nbehavior of collective systems having different quantum statistics but existing\nin the same environment. Here we show that for some specific quantum\nconjugation between the spin and spatial degrees of freedom the\nindistinguishable particles can behave similarly for either quantum statistics.\nIn particular, a mesoscopically scaled collection of atomic qubits, mediated by\noptical tweezers, can model the behavior of a valent electronic shell\ncompounded with nuclear centers in molecules. This makes possible quantum\nsimulations of mono and divalent bonds in quantum chemistry by manipulation of\nup to four bosonic atoms confined with optical microtraps.",
    "pdf_url": "http://arxiv.org/pdf/2505.24366v1",
    "published": "2025-05-30T08:58:34+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24365v1",
    "title": "Anomaly Detection and Improvement of Clusters using Enhanced K-Means Algorithm",
    "authors": [
      "Vardhan Shorewala",
      "Shivam Shorewala"
    ],
    "abstract": "This paper introduces a unified approach to cluster refinement and anomaly\ndetection in datasets. We propose a novel algorithm that iteratively reduces\nthe intra-cluster variance of N clusters until a global minimum is reached,\nyielding tighter clusters than the standard k-means algorithm. We evaluate the\nmethod using intrinsic measures for unsupervised learning, including the\nsilhouette coefficient, Calinski-Harabasz index, and Davies-Bouldin index, and\nextend it to anomaly detection by identifying points whose assignment causes a\nsignificant variance increase. External validation on synthetic data and the\nUCI Breast Cancer and UCI Wine Quality datasets employs the Jaccard similarity\nscore, V-measure, and F1 score. Results show variance reductions of 18.7% and\n88.1% on the synthetic and Wine Quality datasets, respectively, along with\naccuracy and F1 score improvements of 22.5% and 20.8% on the Wine Quality\ndataset.",
    "pdf_url": "http://arxiv.org/pdf/2505.24365v1",
    "published": "2025-05-30T08:56:53+00:00",
    "categories": [
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24364v1",
    "title": "A first view on the density of 5-planar graphs",
    "authors": [
      "Aaron Büngener",
      "Jakob Franz",
      "Michael Kaufmann",
      "Maximilian Pfister"
    ],
    "abstract": "$k$-planar graphs are generalizations of planar graphs that can be drawn in\nthe plane with at most $k > 0$ crossings per edge. One of the central research\nquestions of $k$-planarity is the maximum edge density, i.e., the maximum\nnumber of edges a $k$-planar graph on $n$ vertices may have. While there are\nnumerous results for the classes of general $k$-planar graphs for $k\\leq 2$,\nthere are only very few results for increasing $k=3$ or $4$ due to the\ncomplexity of the classes. We make a first step towards even larger $k>4$ by\nexploring the class of $5$-planar graphs. While our main tool is still the\ndischarging technique, a better understanding of the structure of the denser\nparts leads to corresponding density bounds in a much simpler way.\n  We first apply a simplified version of our technique to outer $5$-planar\ngraphs and use the resulting density bound to assert that the structure of\nmaximally dense $5$-planar graphs differs from the uniform structure when $k$\nis small. As the central result of this paper, we then show that simple\n$5$-planar graphs have at most $\\frac{340}{49}(n-2) \\approx 6.94(n-2)$ edges,\nwhich is a drastic improvement from the previous best bound of $\\approx8.3n$.\nThis even implies a small improvement of the leading constant in the Crossing\nLemma $cr(G) \\ge c \\frac{m^3}{n^2}$ from $c=\\frac{1}{27.48}$ to\n$c=\\frac{1}{27.19}$. To demonstrate the potential of our new technique, we also\napply it to other graph classes, such as 4-planar and 6-planar graphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24364v1",
    "published": "2025-05-30T08:55:29+00:00",
    "categories": [
      "cs.DM",
      "math.CO",
      "05C62, 05C10",
      "G.2.2"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24363v1",
    "title": "Ramping Up Open-Source RISC-V Cores: Assessing the Energy Efficiency of Superscalar, Out-of-Order Execution",
    "authors": [
      "Zexin Fu",
      "Riccardo Tedeschi",
      "Gianmarco Ottavi",
      "Nils Wistoff",
      "César Fuguet",
      "Davide Rossi",
      "Luca Benini"
    ],
    "abstract": "Open-source RISC-V cores are increasingly demanded in domains like automotive\nand space, where achieving high instructions per cycle (IPC) through\nsuperscalar and out-of-order (OoO) execution is crucial. However,\nhigh-performance open-source RISC-V cores face adoption challenges: some (e.g.\nBOOM, Xiangshan) are developed in Chisel with limited support from industrial\nelectronic design automation (EDA) tools. Others, like the XuanTie C910 core,\nuse proprietary interfaces and protocols, including non-standard AXI protocol\nextensions, interrupts, and debug support.\n  In this work, we present a modified version of the OoO C910 core to achieve\nfull RISC-V standard compliance in its debug, interrupt, and memory interfaces.\nWe also introduce CVA6S+, an enhanced version of the dual-issue,\nindustry-supported open-source CVA6 core. CVA6S+ achieves 34.4% performance\nimprovement over CVA6 core.\n  We conduct a detailed performance, area, power, and energy analysis on the\nsuperscalar out-of-order C910, superscalar in-order CVA6S+ and vanilla,\nsingle-issue in-order CVA6, all implemented in a 22nm technology and integrated\ninto Cheshire, an open-source modular SoC. We examine the performance and\nefficiency of different microarchitectures using the same ISA, SoC, and\nimplementation with identical technology, tools, and methodologies. The area\nand performance rankings of CVA6, CVA6S+, and C910 follow expected trends:\ncompared to the scalar CVA6, CVA6S+ shows an area increase of 6% and an IPC\nimprovement of 34.4%, while C910 exhibits a 75% increase in area and a 119.5%\nimprovement in IPC. However, efficiency analysis reveals that CVA6S+ leads in\narea efficiency (GOPS/mm2), while the C910 is highly competitive in energy\nefficiency (GOPS/W). This challenges the common belief that high performance in\nsuperscalar and out-of-order cores inherently comes at a significant cost in\narea and energy efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.24363v1",
    "published": "2025-05-30T08:54:47+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24362v2",
    "title": "Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion",
    "authors": [
      "Anum Afzal",
      "Florian Matthes",
      "Gal Chechik",
      "Yftah Ziser"
    ],
    "abstract": "We investigate whether the success of a zero-shot Chain-of-Thought (CoT)\nprocess can be predicted before completion. We discover that a probing\nclassifier, based on LLM representations, performs well \\emph{even before a\nsingle token is generated}, suggesting that crucial information about the\nreasoning process is already present in the initial steps representations. In\ncontrast, a strong BERT-based baseline, which relies solely on the generated\ntokens, performs worse, likely because it depends on shallow linguistic cues\nrather than deeper reasoning dynamics. Surprisingly, using later reasoning\nsteps does not always improve classification. When additional context is\nunhelpful, earlier representations resemble later ones more, suggesting LLMs\nencode key information early. This implies reasoning can often stop early\nwithout loss. To test this, we conduct early stopping experiments, showing that\ntruncating CoT reasoning still improves performance over not using CoT at all,\nthough a gap remains compared to full reasoning. However, approaches like\nsupervised learning or reinforcement learning designed to shorten CoT chains\ncould leverage our classifier's guidance to identify when early stopping is\neffective. Our findings provide insights that may support such methods, helping\nto optimize CoT's efficiency while preserving its benefits.",
    "pdf_url": "http://arxiv.org/pdf/2505.24362v2",
    "published": "2025-05-30T08:54:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00092v1",
    "title": "Complete survey of r-process conditions: the (un-)robustness of the r-process(-es)",
    "authors": [
      "Jan Kuske",
      "Almudena Arcones",
      "Moritz Reichert"
    ],
    "abstract": "Heavy elements are synthesized by the r-process in neutron star mergers and\npotentially in rare supernovae linked to strong magnetic fields. Expensive\nhydrodynamic simulations of these extreme environments are usually\npost-processed to calculate the nucleosynthesis. In contrast, here we follow a\nsite-independent approach based on three key parameters: electron fraction,\nentropy, and expansion timescale. Our model reproduces the results based on\nhydrodynamic simulations. Moreover, the 120 000 astrophysical conditions\nanalyzed allow us to systematically and generally explore the astrophysical\nconditions of the r-process, also beyond those found in current simulations.\nOur results show that a wide range of conditions produce very similar abundance\npatterns explaining the observed robustness of the r-process between the second\nand third peak. Furthermore, we cannot find a single condition that produces\nthe full r-process from first to third peak. Instead, a superposition of at\nleast two or three conditions or components is required to reproduce the\ntypical r-process pattern as observed in the solar system and very old stars.\nThe different final abundances are grouped into eight nucleosynthesis clusters,\nwhich can be used to select representative conditions for comparisons to\nobservations and investigations of the nuclear physics input.",
    "pdf_url": "http://arxiv.org/pdf/2506.00092v1",
    "published": "2025-05-30T08:54:21+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24361v1",
    "title": "Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation",
    "authors": [
      "Roger Ferrod",
      "Cássio F. Dantas",
      "Luigi Di Caro",
      "Dino Ienco"
    ],
    "abstract": "Multi-modal RGB and Depth (RGBD) data are predominant in many domains such as\nrobotics, autonomous driving and remote sensing. The combination of these\nmulti-modal data enhances environmental perception by providing 3D spatial\ncontext, which is absent in standard RGB images. Although RGBD multi-modal data\ncan be available to train computer vision models, accessing all sensor\nmodalities during the inference stage may be infeasible due to sensor failures\nor resource constraints, leading to a mismatch between data modalities\navailable during training and inference. Traditional Cross-Modal Knowledge\nDistillation (CMKD) frameworks, developed to address this task, are typically\nbased on a teacher/student paradigm, where a multi-modal teacher distills\nknowledge into a single-modality student model. However, these approaches face\nchallenges in teacher architecture choices and distillation process selection,\nthus limiting their adoption in real-world scenarios. To overcome these issues,\nwe introduce CroDiNo-KD (Cross-Modal Disentanglement: a New Outlook on\nKnowledge Distillation), a novel cross-modal knowledge distillation framework\nfor RGBD semantic segmentation. Our approach simultaneously learns\nsingle-modality RGB and Depth models by exploiting disentanglement\nrepresentation, contrastive learning and decoupled data augmentation with the\naim to structure the internal manifolds of neural network models through\ninteraction and collaboration. We evaluated CroDiNo-KD on three RGBD datasets\nacross diverse domains, considering recent CMKD frameworks as competitors. Our\nfindings illustrate the quality of CroDiNo-KD, and they suggest reconsidering\nthe conventional teacher/student paradigm to distill information from\nmulti-modal data to single-modality neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24361v1",
    "published": "2025-05-30T08:53:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24360v3",
    "title": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning",
    "authors": [
      "Stepan Shabalin",
      "Ayush Panda",
      "Dmitrii Kharlapenko",
      "Abdur Raheem Ali",
      "Yixiong Hao",
      "Arthur Conmy"
    ],
    "abstract": "Sparse autoencoders are a promising new approach for decomposing language\nmodel activations for interpretation and control. They have been applied\nsuccessfully to vision transformer image encoders and to small-scale diffusion\nmodels. Inference-Time Decomposition of Activations (ITDA) is a recently\nproposed variant of dictionary learning that takes the dictionary to be a set\nof data points from the activation distribution and reconstructs them with\ngradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large\ntext-to-image diffusion model, Flux 1, and consider the interpretability of\nembeddings of both by introducing a visual automated interpretation pipeline.\nWe find that SAEs accurately reconstruct residual stream embeddings and beat\nMLP neurons on interpretability. We are able to use SAE features to steer image\ngeneration through activation addition. We find that ITDA has comparable\ninterpretability to SAEs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24360v3",
    "published": "2025-05-30T08:53:27+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24359v1",
    "title": "Revisiting the Topological Nature of TaIrTe4, SrSi2, and Cu2XY3: An ab-initio Investigation",
    "authors": [
      "Prakash Pandey",
      "Sudhir K. Pandey"
    ],
    "abstract": "Several topological electronic materials have been theoretically predicted,\nleading to a comprehensive catalog systematically characterized by their band\ncrossings. Researchers have attempted to experimentally verify the topological\nnature of some materials from the present catalogs, but not all efforts have\nyielded positive results. Here, we introduce a possible reason for the\ndiscrepancies between theoretical and experimental results. In this direction,\nfirstly we have revisited the nature of the well-known topological materials\nTaIrTe$_4$ and SrSi$_2$ using \\textit{state-of-the-art ab-initio} calculations,\nand found additional Weyl points in both materials that were missing in\npreviously reported studies. Then we have verified the recently predicted\ntopological states of the \\textit{Imm2}-phase of Cu$_2$XY$_3$ (X=Si, Ge, Sn \\&\nY=S, Se, Te). Contrary to previously reported results, we did not find any Weyl\npoints or nodal arcs in Cu$_2$SnTe$_3$. Notably, our theoretical results reveal\nthat Cu$_2$SiTe$_3$, Cu$_2$GeTe$_3$ and Cu$_2$GeSe$_3$ each host four small\nnodal rings, eight Weyl points, and eight nodal arcs, respectively, which\ndiffer from previous studies. Considering Cu$_2$SnS$_3$ as an example, we have\nalso investigated the robustness of the topological phase against local strain.\nOur study provides insights into the inconsistencies between theoretical\npredictions and experimental results, and demonstrates how the topological\nphase is sensitive to changes in lattice parameters, atomic positions, and\nexchange-correlation functionals.",
    "pdf_url": "http://arxiv.org/pdf/2505.24359v1",
    "published": "2025-05-30T08:50:58+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24358v1",
    "title": "Cartesian Prime Graphs and Cospectral Families",
    "authors": [
      "Abhinav Bitragunta",
      "Hareshkumar Jadav",
      "Ranveer Singh"
    ],
    "abstract": "We introduce a method for constructing larger families of connected\ncospectral graphs from two given cospectral families of sizes $p$ and $q$. The\nresulting family size depends on the Cartesian primality of the input graphs\nand can be one of $pq$, $p + q - 1$, or $\\max(p, q)$, based on the strictness\nof the applied conditions. Under the strictest condition, our method generates\n$O(p^3q^3)$ new cospectral triplets, while the more relaxed conditions yield\n$\\varOmega(pq^3 + qp^3)$ such triplets. We also use the existence of specific\ncospectral families to establish that of larger ones.",
    "pdf_url": "http://arxiv.org/pdf/2505.24358v1",
    "published": "2025-05-30T08:49:56+00:00",
    "categories": [
      "cs.DM"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24357v2",
    "title": "ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration",
    "authors": [
      "Xianglong Yan",
      "Zhiteng Li",
      "Tianao Zhang",
      "Linghe Kong",
      "Yulun Zhang",
      "Xiaokang Yang"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable performance, yet their\ncapability on long-context reasoning is often constrained by the excessive\nmemory required to store the Key-Value (KV) cache. This makes KV cache\ncompression an essential step toward enabling efficient long-context reasoning.\nRecent methods have explored reducing the hidden dimensions of the KV cache,\nbut many introduce additional computation through projection layers or suffer\nfrom significant performance degradation under high compression ratios. To\naddress these challenges, we propose ReCalKV, a post-training KV cache\ncompression method that reduces the hidden dimensions of the KV cache. We\ndevelop distinct compression strategies for Keys and Values based on their\ndifferent roles and varying importance in the attention mechanism. For Keys, we\npropose Head-wise Similarity-aware Reordering (HSR), which clusters similar\nheads and applies grouped SVD to the key projection matrix, reducing additional\ncomputation while preserving accuracy. For Values, we propose Offline\nCalibration and Matrix Fusion (OCMF) to preserve accuracy without extra\ncomputational overhead. Experiments show that ReCalKV outperforms existing\nlow-rank compression methods, achieving high compression ratios with minimal\nperformance loss. The code and models will be available at:\nhttps://github.com/XIANGLONGYAN/ReCalKV.",
    "pdf_url": "http://arxiv.org/pdf/2505.24357v2",
    "published": "2025-05-30T08:49:27+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24356v1",
    "title": "Joint Transmit and Receive Beamforming for Tri-directional Coil-Based Magnetic Induction Communications",
    "authors": [
      "Jinyang Li",
      "Jianyu Wang",
      "Wenchi Cheng",
      "Yudong Fang",
      "Wei Guo"
    ],
    "abstract": "In this paper, we enhance the omnidirectional coverage performance of\ntri-directional coil-based magnetic induction communication (TC-MIC) and reduce\nthe pathloss with a joint transmit and receive magnetic beamforming method. An\niterative optimization algorithm incorporating the transmit current vector and\nreceive weight matrix is developed to minimize the pathloss under constant\ntransmit power constraints. We formulate the mathematical models for the mutual\ninductance of tri-directional coils, receive power, and pathloss. The\noptimization problem is decomposed into Rayleigh quotient extremum optimization\nfor transmit currents and Cauchy-Schwarz inequality-constrained optimization\nfor receive weights, with an alternating iterative algorithm to approach the\nglobal optimum. Numerical results demonstrate that the proposed algorithm\nconverges within an average of 13.6 iterations, achieving up to 54% pathloss\nreduction compared with equal power allocation schemes. The joint optimization\napproach exhibits superior angular robustness, maintaining pathloss fluctuation\nsmaller than 2 dB, and reducing fluctuation of pathloss by approximately 45%\ncompared with single-parameter optimization methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24356v1",
    "published": "2025-05-30T08:47:56+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24355v1",
    "title": "Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model",
    "authors": [
      "Sihan Tan",
      "Taro Miyazaki",
      "Kazuhiro Nakadai"
    ],
    "abstract": "Sign Language Translation (SLT) aims to convert sign language (SL) videos\ninto spoken language text, thereby bridging the communication gap between the\nsign and the spoken community. While most existing works focus on translating a\nsingle sign language into a single spoken language (one-to-one SLT), leveraging\nmultilingual resources could mitigate low-resource issues and enhance\naccessibility. However, multilingual SLT (MLSLT) remains unexplored due to\nlanguage conflicts and alignment difficulties across SLs and spoken languages.\nTo address these challenges, we propose a multilingual gloss-free model with\ndual CTC objectives for token-level SL identification and spoken text\ngeneration. Our model supports 10 SLs and handles one-to-one, many-to-one, and\nmany-to-many SLT tasks, achieving competitive performance compared to\nstate-of-the-art methods on three widely adopted benchmarks: multilingual\nSP-10, PHOENIX14T, and CSL-Daily.",
    "pdf_url": "http://arxiv.org/pdf/2505.24355v1",
    "published": "2025-05-30T08:47:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24354v1",
    "title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research",
    "authors": [
      "Qianqian Zhang",
      "Jiajia Liao",
      "Heting Ying",
      "Yibo Ma",
      "Haozhan Shen",
      "Jingcheng Li",
      "Peng Liu",
      "Lu Zhang",
      "Chunxin Fang",
      "Kyusong Lee",
      "Ruochen Xu",
      "Tiancheng Zhao"
    ],
    "abstract": "Language agents powered by large language models (LLMs) have demonstrated\nremarkable capabilities in understanding, reasoning, and executing complex\ntasks. However, developing robust agents presents significant challenges:\nsubstantial engineering overhead, lack of standardized components, and\ninsufficient evaluation frameworks for fair comparison. We introduce Agent\nGraph-based Orchestration for Reasoning and Assessment (AGORA), a flexible and\nextensible framework that addresses these challenges through three key\ncontributions: (1) a modular architecture with a graph-based workflow engine,\nefficient memory management, and clean component abstraction; (2) a\ncomprehensive suite of reusable agent algorithms implementing state-of-the-art\nreasoning approaches; and (3) a rigorous evaluation framework enabling\nsystematic comparison across multiple dimensions. Through extensive experiments\non mathematical reasoning and multimodal tasks, we evaluate various agent\nalgorithms across different LLMs, revealing important insights about their\nrelative strengths and applicability. Our results demonstrate that while\nsophisticated reasoning approaches can enhance agent capabilities, simpler\nmethods like Chain-of-Thought often exhibit robust performance with\nsignificantly lower computational overhead. AGORA not only simplifies language\nagent development but also establishes a foundation for reproducible agent\nresearch through standardized evaluation protocols.",
    "pdf_url": "http://arxiv.org/pdf/2505.24354v1",
    "published": "2025-05-30T08:46:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24353v1",
    "title": "Cartan Networks: Group theoretical Hyperbolic Deep Learning",
    "authors": [
      "Federico Milanesio",
      "Matteo Santoro",
      "Pietro G. Fré",
      "Guido Sanguinetti"
    ],
    "abstract": "Hyperbolic deep learning leverages the metric properties of hyperbolic spaces\nto develop efficient and informative embeddings of hierarchical data. Here, we\nfocus on the solvable group structure of hyperbolic spaces, which follows\nnaturally from their construction as symmetric spaces. This dual nature of Lie\ngroup and Riemannian manifold allows us to propose a new class of hyperbolic\ndeep learning algorithms where group homomorphisms are interleaved with\nmetric-preserving diffeomorphisms. The resulting algorithms, which we call\nCartan networks, show promising results on various benchmark data sets and open\nthe way to a novel class of hyperbolic deep learning architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.24353v1",
    "published": "2025-05-30T08:45:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24352v1",
    "title": "Approximation of starshaped sets using polynomials",
    "authors": [
      "Chiara Meroni",
      "Jared Miller",
      "Mauricio Velasco"
    ],
    "abstract": "We introduce polystar bodies: compact starshaped sets whose gauge or radial\nfunctions are expressible by polynomials, enabling tractable computations, such\nas that of intersection bodies. We prove that polystar bodies are uniformly\ndense in starshaped sets and obtain asymptotically optimal approximation\nguarantees. We develop tools for the construction of polystar approximations\nand illustrate them via several computational examples, including numerical\nestimations of largest volume slices and widths.",
    "pdf_url": "http://arxiv.org/pdf/2505.24352v1",
    "published": "2025-05-30T08:45:28+00:00",
    "categories": [
      "math.OC",
      "math.MG",
      "51M16, 52A40, 52-08"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24351v1",
    "title": "A Novel Coronary Artery Registration Method Based on Super-pixel Particle Swarm Optimization",
    "authors": [
      "Peng Qi",
      "Wenxi Qu",
      "Tianliang Yao",
      "Haonan Ma",
      "Dylan Wintle",
      "Yinyi Lai",
      "Giorgos Papanastasiou",
      "Chengjia Wang"
    ],
    "abstract": "Percutaneous Coronary Intervention (PCI) is a minimally invasive procedure\nthat improves coronary blood flow and treats coronary artery disease. Although\nPCI typically requires 2D X-ray angiography (XRA) to guide catheter placement\nat real-time, computed tomography angiography (CTA) may substantially improve\nPCI by providing precise information of 3D vascular anatomy and status. To\nleverage real-time XRA and detailed 3D CTA anatomy for PCI, accurate multimodal\nimage registration of XRA and CTA is required, to guide the procedure and avoid\ncomplications. This is a challenging process as it requires registration of\nimages from different geometrical modalities (2D -> 3D and vice versa), with\nvariations in contrast and noise levels. In this paper, we propose a novel\nmultimodal coronary artery image registration method based on a swarm\noptimization algorithm, which effectively addresses challenges such as large\ndeformations, low contrast, and noise across these imaging modalities. Our\nalgorithm consists of two main modules: 1) preprocessing of XRA and CTA images\nseparately, and 2) a registration module based on feature extraction using the\nSteger and Superpixel Particle Swarm Optimization algorithms. Our technique was\nevaluated on a pilot dataset of 28 pairs of XRA and CTA images from 10 patients\nwho underwent PCI. The algorithm was compared with four state-of-the-art (SOTA)\nmethods in terms of registration accuracy, robustness, and efficiency. Our\nmethod outperformed the selected SOTA baselines in all aspects. Experimental\nresults demonstrate the significant effectiveness of our algorithm, surpassing\nthe previous benchmarks and proposes a novel clinical approach that can\npotentially have merit for improving patient outcomes in coronary artery\ndisease.",
    "pdf_url": "http://arxiv.org/pdf/2505.24351v1",
    "published": "2025-05-30T08:44:46+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24350v1",
    "title": "Selection rules for charged lepton flavour violating processes from residual flavour groups",
    "authors": [
      "Lorenzo Calibbi",
      "Claudia Hagedorn",
      "Michael A. Schmidt",
      "James Vandeleur"
    ],
    "abstract": "We systematically investigate the possible phenomenological impact of\nresidual flavour groups in the charged lepton sector. We consider all possible\nflavour charge assignments for abelian residual symmetries up to Z8. The\nallowed flavour structures of operators in Standard Model Effective Field\nTheory (up to dimension six) lead to distinctive and observable patterns of\ncharged lepton flavour violating processes. We illustrate the relevance of such\nselection rules displaying the current bounds on and the future sensitivities\nto the new physics scale. These results demonstrate, in particular, the\nimportance and discriminating power of searches for lepton flavour violating\ntau lepton decays and muonium to antimuonium conversion.",
    "pdf_url": "http://arxiv.org/pdf/2505.24350v1",
    "published": "2025-05-30T08:44:21+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24349v1",
    "title": "The Use of Alendronate to Enhance Transcranial Transmission of Focused Ultrasound for Successful Ablations in Brain",
    "authors": [
      "G. Sakharova",
      "A. Krokhmal",
      "R. Galimova",
      "A. Khatmullina",
      "D. Nabiullina",
      "I. Buzaev",
      "D. Avzaletdinova",
      "D. Chupova",
      "V. Khokhlova"
    ],
    "abstract": "Objective: The aim of this study was to evaluate the efficacy of alendronate\ntherapy in improving bone density distribution in skull bones and corresponding\nultrasound permeability in patients who had previously experienced unsuccessful\ntranscranial MR-guided focused ultrasound (MRgFUS) ablation. The ability of\nalendronate treatment to modify skull bone characteristics and enhance the\nsuccess rate of repeat MRgFUS procedures was assessed.\n  Methods: Five patients with initially unsuccessful MRgFUS ablations underwent\na 6-12 month regimen of alendronate to improve bone density. Repeat MRgFUS\nprocedures were performed, and changes in skull density ratio (SDR) and peak\nfocal temperatures were evaluated statistically using CT and MR imaging.\nHistograms of skull bone density were introduced and analysed as an additional\nmetric.\n  Results: After therapy, SDR increased in four out of five patients (from\n0.378$\\pm$0.037 to 0.424$\\pm$0.045, p>0.05). All repeated procedures were\nsuccessful. The maximum focal temperature, averaged over sonications, increased\nfrom 53.6$\\pm$4.0{\\deg}C to 55.7$\\pm$4.1{\\deg}C (p=0.018), while the maximum\ntemperature per patient rose from 57.0$\\pm$2.4{\\deg}C to 60.2$\\pm$1.8{\\deg}C\n(p=0.031). Histograms of CT scans showed a reduction in low-density voxels,\nindicating trabecular bone densification. 3D CT scan registration revealed\nlocal density changes, defect filling, and void reduction.\n  Conclusions: Alendronate therapy enhanced skull bone density distribution and\nthus ultrasound permeability, which has facilitated successful repeat MRgFUS.\nBy visually analysing CT changes, healthcare professionals can better inform\ntheir decision-making regarding repeat surgeries. This method broadens the pool\nof patients with low SDR eligible for MRgFUS treatment and underscores the\npotential benefits of alendronate in improving treatment outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24349v1",
    "published": "2025-05-30T08:43:48+00:00",
    "categories": [
      "physics.med-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24348v1",
    "title": "A 3D Mobile Crowdsensing Framework for Sustainable Urban Digital Twins",
    "authors": [
      "Taku Yamazaki",
      "Kaito Watanabe",
      "Tatsuya Kase",
      "Kenta Hasegawa",
      "Koki Saida",
      "Takumi Miyoshi"
    ],
    "abstract": "In this article, we propose a 3D mobile crowdsensing (3D-MCS) framework aimed\nat sustainable urban digital twins (UDTs). The framework comprises four key\nmechanisms: (1) the 3D-MCS mechanism, consisting of active and passive models;\n(2) the Geohash-based spatial information management mechanism; (3) the dynamic\npoint cloud integration mechanism for UDTs; and (4) the web-based real-time\nvisualizer for 3D-MCS and UDTs. The active sensing model features a gamified\n3D-MCS approach, where participants collect point cloud data through an\naugmented reality territory coloring game. In contrast, the passive sensing\nmodel employs a wearable 3D-MCS approach, where participants wear smartphones\naround their necks without disrupting daily activities. The spatial information\nmanagement mechanism efficiently partitions the space into regions using\nGeohash. The dynamic point cloud integration mechanism incorporates point\nclouds collected by 3D-MCS into UDTs through global and local point cloud\nregistration. Finally, we evaluated the proposed framework through real-world\nexperiments. We verified the effectiveness of the proposed 3D-MCS models from\nthe perspectives of subjective evaluation and data collection and analysis.\nFurthermore, we analyzed the performance of the dynamic point cloud integration\nusing a dataset.",
    "pdf_url": "http://arxiv.org/pdf/2505.24348v1",
    "published": "2025-05-30T08:42:24+00:00",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.15706v1",
    "title": "MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning",
    "authors": [
      "Yunze Lin"
    ],
    "abstract": "Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs) as it requires ensuring the correctness of each reasoning step.\nResearchers have been strengthening the mathematical reasoning abilities of\nLLMs through supervised fine-tuning, but due to the inability to suppress\nincorrect outputs, illusions can easily arise. Recently, Direct Preference\nOptimization (DPO) has been widely adopted for aligning human intent by using\npreference data to prevent LLMs from generating incorrect outputs. However, it\nhas shown limited benefits in long-chain mathematical reasoning, mainly because\nDPO struggles to effectively capture the differences between accepted and\nrejected answers from preferences in long-chain data. The inconsistency between\nDPO training and LLMs' generation metrics also affects the effectiveness of\nsuppressing incorrect outputs. We propose the Multi-Granularity Direct\nPreference Optimization (MDPO) method, optimizing the mathematical reasoning of\nLLMs at three granularities: Solution2Solution, Inference2Inference, and\nStep2Step. Solution2Solution focuses on the correctness of entire long-chain\nreasoning; Inference2Inference concentrates on logical reasoning between steps;\nStep2Step corrects computational errors in steps, enhancing the computational\ncapabilities of LLMs. Additionally, we unify the training objectives of the\nthree granularities to align with the generation metrics. We conducted\nexperiments on the open-source models Qwen2 and Llama3, achieving improvements\nof 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset,\noutperforming DPO and other DPO variant methods. Furthermore, we also provide a\npipeline for constructing MDPO training data that is simple and does not\nrequire manual annotation costs.",
    "pdf_url": "http://arxiv.org/pdf/2506.15706v1",
    "published": "2025-05-30T08:42:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24347v2",
    "title": "Fewer Hallucinations, More Verification: A Three-Stage LLM-Based Framework for ASR Error Correction",
    "authors": [
      "Yangui Fang",
      "Baixu Cheng",
      "Jing Peng",
      "Xu Li",
      "Yu Xi",
      "Chengwei Zhang",
      "Guohui Zhong"
    ],
    "abstract": "Automatic Speech Recognition (ASR) error correction aims to correct\nrecognition errors while preserving accurate text. Although traditional\napproaches demonstrate moderate effectiveness, LLMs offer a paradigm that\neliminates the need for training and labeled data. However, directly using LLMs\nwill encounter hallucinations problem, which may lead to the modification of\nthe correct text. To address this problem, we propose the Reliable LLM\nCorrection Framework (RLLM-CF), which consists of three stages: (1) error\npre-detection, (2) chain-of-thought sub-tasks iterative correction, and (3)\nreasoning process verification. The advantage of our method is that it does not\nrequire additional information or fine-tuning of the model, and ensures the\ncorrectness of the LLM correction under multi-pass programming. Experiments on\nAISHELL-1, AISHELL-2, and Librispeech show that the GPT-4o model enhanced by\nour framework achieves 21%, 11%, 9%, and 11.4% relative reductions in CER/WER.",
    "pdf_url": "http://arxiv.org/pdf/2505.24347v2",
    "published": "2025-05-30T08:40:49+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24346v1",
    "title": "VUDG: A Dataset for Video Understanding Domain Generalization",
    "authors": [
      "Ziyi Wang",
      "Zhi Gao",
      "Boxuan Yu",
      "Zirui Dai",
      "Yuxiang Song",
      "Qingyuan Lu",
      "Jin Chen",
      "Xinxiao Wu"
    ],
    "abstract": "Video understanding has made remarkable progress in recent years, largely\ndriven by advances in deep models and the availability of large-scale annotated\ndatasets. However, existing works typically ignore the inherent domain shifts\nencountered in real-world video applications, leaving domain generalization\n(DG) in video understanding underexplored. Hence, we propose Video\nUnderstanding Domain Generalization (VUDG), a novel dataset designed\nspecifically for evaluating the DG performance in video understanding. VUDG\ncontains videos from 11 distinct domains that cover three types of domain\nshifts, and maintains semantic similarity across different domains to ensure\nfair and meaningful evaluation. We propose a multi-expert progressive\nannotation framework to annotate each video with both multiple-choice and\nopen-ended question-answer pairs. Extensive experiments on 9 representative\nlarge video-language models (LVLMs) and several traditional video question\nanswering methods show that most models (including state-of-the-art LVLMs)\nsuffer performance degradation under domain shifts. These results highlight the\nchallenges posed by VUDG and the difference in the robustness of current models\nto data distribution shifts. We believe VUDG provides a valuable resource for\nprompting future research in domain generalization video understanding.",
    "pdf_url": "http://arxiv.org/pdf/2505.24346v1",
    "published": "2025-05-30T08:39:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24345v1",
    "title": "Additivity of non-acyclicity classes for constructible étale sheaves",
    "authors": [
      "Jiangnan Xiong"
    ],
    "abstract": "Using a bivariant version of cohomological correspondences, we establish a\ncategorical trace-like formula for the non-acyclicity classes introduced by\nYang and Zhao (arXiv:2209.11086). As an application, we prove the additivity\nfor the non-acyclicity classes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24345v1",
    "published": "2025-05-30T08:36:45+00:00",
    "categories": [
      "math.AG",
      "math.CT",
      "math.NT",
      "14F20, 18N60"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24344v2",
    "title": "Isospin-violating vacuum polarization in the muon $(g-2)$ with SU(3) flavour symmetry from lattice QCD",
    "authors": [
      "Dominik Erb",
      "Antoine Gérardin",
      "Harvey B. Meyer",
      "Julian Parrino",
      "Volodymyr Biloshytskyi",
      "Vladimir Pascalutsa"
    ],
    "abstract": "We compute the isospin-violating part $a_\\mu^{\\text{HVP}, 38}$ of the\nhadronic-vacuum-polarization (HVP) contribution to the muon $(g-2)$ in lattice\nQCD at the SU$(3)_{\\rm f}$-symmetric point where $M_\\pi=M_K\\simeq 416$ MeV. All\ndiagrams involving internal photons are evaluated in coordinate space,\nemploying a Pauli-Villars-regulated photon propagator with a cutoff scale\n$\\Lambda$ well below the lattice cutoff. The counterterm $(m_u-m_d)$, whose\n$\\Lambda$ dependence is consistent with the expected logarithmic behaviour, is\ncalibrated using the experimental kaon mass splitting as input. The bare\nelectromagnetic contribution at fixed $\\Lambda$ is compared to a\nphenomenological estimate based on the kaon-loop and pseudoscalar-pole\ncontributions to the forward light-by-light amplitude. An extension of these\ncalculations to physical pion and kaon masses appears promising.",
    "pdf_url": "http://arxiv.org/pdf/2505.24344v2",
    "published": "2025-05-30T08:35:46+00:00",
    "categories": [
      "hep-lat"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.24343v1",
    "title": "Minimising the numerical viscosity in Smoothed Particle Hydrodynamics simulations of discs",
    "authors": [
      "Cheng Chen",
      "C. J. Nixon"
    ],
    "abstract": "Simulations using the Smoothed Particle Hydrodynamics (SPH) technique\ntypically include numerical viscosity to model shocks and maintain particle\norder on the kernel scale. This numerical viscosity is composed of linear and\nquadratic terms, with coefficients $\\alpha_{\\rm SPH}$ and $\\beta_{\\rm SPH}$\nrespectively. Setting these coefficients too high results in excessive\nnumerical dissipation, whereas setting them too low may lead to unwanted\neffects such as particle penetration, which also leads to excess dissipation.\nIn this study, we simulate accretion discs using the SPH code {\\sc phantom} to\ninvestigate the effective disc viscosity arising from numerical viscosity. We\nmodel steady-state coplanar and circular discs with different values of\n$\\alpha_{\\rm SPH}$ and $\\beta_{\\rm SPH}$, from which we determine the\ncoefficients that lead to minimum levels of numerical viscosity by maximising\nthe steady-state disc surface density for the same mass input rate. We find\nthat, for planar and circular discs, the default values of the numerical\nviscosity parameters in the {\\sc phantom} code can be too high particularly for\nthe quadratic term. As higher values of the coefficients are required to\nadequately capture strong shocks in the flow, we suggest that the coefficient\nof the quadratic term should be time-dependent in a similar manner to the\npresently used ``switches'' on the linear term. This can be simply achieved by\nsetting $\\beta_{\\rm SPH}$ to be a constant multiple of $\\alpha_{\\rm SPH}$ with\n$\\alpha_{\\rm SPH}$ determined by an appropriate switch, as previously advocated\nin the literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.24343v1",
    "published": "2025-05-30T08:34:55+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24342v1",
    "title": "KEVER^2: Knowledge-Enhanced Visual Emotion Reasoning and Retrieval",
    "authors": [
      "Fanhang Man",
      "Xiaoyue Chen",
      "Huandong Wang",
      "Baining Zhao",
      "Han Li",
      "Xinlei Chen",
      "Yong Li"
    ],
    "abstract": "Understanding what emotions images evoke in their viewers is a foundational\ngoal in human-centric visual computing. While recent advances in\nvision-language models (VLMs) have shown promise for visual emotion analysis\n(VEA), several key challenges remain unresolved. Emotional cues in images are\noften abstract, overlapping, and entangled, making them difficult to model and\ninterpret. Moreover, VLMs struggle to align these complex visual patterns with\nemotional semantics due to limited supervision and sparse emotional grounding.\nFinally, existing approaches lack structured affective knowledge to resolve\nambiguity and ensure consistent emotional reasoning across diverse visual\ndomains.\n  To address these limitations, we propose \\textbf{K-EVER\\textsuperscript{2}},\na knowledge-enhanced framework for emotion reasoning and retrieval. Our\napproach introduces a semantically structured formulation of visual emotion\ncues and integrates external affective knowledge through multimodal alignment.\nWithout relying on handcrafted labels or direct emotion supervision,\nK-EVER\\textsuperscript{2} achieves robust and interpretable emotion predictions\nacross heterogeneous image types.\n  We validate our framework on three representative benchmarks, Emotion6,\nEmoSet, and M-Disaster, covering social media imagery, human-centric scenes,\nand disaster contexts. K-EVER\\textsuperscript{2} consistently outperforms\nstrong CNN and VLM baselines, achieving up to a \\textbf{19\\% accuracy gain} for\nspecific emotions and a \\textbf{12.3\\% average accuracy gain} across all\nemotion categories. Our results demonstrate a scalable and generalizable\nsolution for advancing emotional understanding of visual content.",
    "pdf_url": "http://arxiv.org/pdf/2505.24342v1",
    "published": "2025-05-30T08:33:32+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24341v1",
    "title": "Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings",
    "authors": [
      "Shujian Yang",
      "Shiyao Cui",
      "Chuanrui Hu",
      "Haicheng Wang",
      "Tianwei Zhang",
      "Minlie Huang",
      "Jialiang Lu",
      "Han Qiu"
    ],
    "abstract": "Detecting toxic content using language models is important but challenging.\nWhile large language models (LLMs) have demonstrated strong performance in\nunderstanding Chinese, recent studies show that simple character substitutions\nin toxic Chinese text can easily confuse the state-of-the-art (SOTA) LLMs. In\nthis paper, we highlight the multimodal nature of Chinese language as a key\nchallenge for deploying LLMs in toxic Chinese detection. First, we propose a\ntaxonomy of 3 perturbation strategies and 8 specific approaches in toxic\nChinese content. Then, we curate a dataset based on this taxonomy, and\nbenchmark 9 SOTA LLMs (from both the US and China) to assess if they can detect\nperturbed toxic Chinese text. Additionally, we explore cost-effective\nenhancement solutions like in-context learning (ICL) and supervised fine-tuning\n(SFT). Our results reveal two important findings. (1) LLMs are less capable of\ndetecting perturbed multimodal Chinese toxic contents. (2) ICL or SFT with a\nsmall number of perturbed examples may cause the LLMs \"overcorrect'':\nmisidentify many normal Chinese contents as toxic.",
    "pdf_url": "http://arxiv.org/pdf/2505.24341v1",
    "published": "2025-05-30T08:32:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24340v1",
    "title": "GeoVision Labeler: Zero-Shot Geospatial Classification with Vision and Language Models",
    "authors": [
      "Gilles Quentin Hacheme",
      "Girmaw Abebe Tadesse",
      "Caleb Robinson",
      "Akram Zaytar",
      "Rahul Dodhia",
      "Juan M. Lavista Ferres"
    ],
    "abstract": "Classifying geospatial imagery remains a major bottleneck for applications\nsuch as disaster response and land-use monitoring-particularly in regions where\nannotated data is scarce or unavailable. Existing tools (e.g., RS-CLIP) that\nclaim zero-shot classification capabilities for satellite imagery nonetheless\nrely on task-specific pretraining and adaptation to reach competitive\nperformance. We introduce GeoVision Labeler (GVL), a strictly zero-shot\nclassification framework: a vision Large Language Model (vLLM) generates rich,\nhuman-readable image descriptions, which are then mapped to user-defined\nclasses by a conventional Large Language Model (LLM). This modular, and\ninterpretable pipeline enables flexible image classification for a large range\nof use cases. We evaluated GVL across three benchmarks-SpaceNet v7, UC Merced,\nand RESISC45. It achieves up to 93.2% zero-shot accuracy on the binary\nBuildings vs. No Buildings task on SpaceNet v7. For complex multi-class\nclassification tasks (UC Merced, RESISC45), we implemented a recursive\nLLM-driven clustering to form meta-classes at successive depths, followed by\nhierarchical classification-first resolving coarse groups, then finer\ndistinctions-to deliver competitive zero-shot performance. GVL is open-sourced\nat https://github.com/microsoft/geo-vision-labeler to catalyze adoption in\nreal-world geospatial workflows.",
    "pdf_url": "http://arxiv.org/pdf/2505.24340v1",
    "published": "2025-05-30T08:32:37+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG",
      "I.2.10; I.2.7; I.4.8; I.5.3"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24339v1",
    "title": "Imitation Learning-Based Path Generation for the Complex Assembly of Deformable Objects",
    "authors": [
      "Yitaek Kim",
      "Christoffer Sloth"
    ],
    "abstract": "This paper investigates how learning can be used to ease the design of\nhigh-quality paths for the assembly of deformable objects. Object dynamics\nplays an important role when manipulating deformable objects; thus, detailed\nmodels are often used when conducting motion planning for deformable objects.\nWe propose to use human demonstrations and learning to enable motion planning\nof deformable objects with only simple dynamical models of the objects. In\nparticular, we use the offline collision-free path planning, to generate a\nlarge number of reference paths based on a simple model of the deformable\nobject. Subsequently, we execute the collision-free paths on a robot with a\ncompliant control such that a human can slightly modify the path to complete\nthe task successfully. Finally, based on the virtual path data sets and the\nhuman corrected ones, we use behavior cloning (BC) to create a dexterous policy\nthat follows one reference path to finish a given task.",
    "pdf_url": "http://arxiv.org/pdf/2505.24339v1",
    "published": "2025-05-30T08:29:03+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24338v2",
    "title": "Implications of the evidence for direct $\\mathbf{CP}$ violation in $D\\to π^+π^-$ decays",
    "authors": [
      "Rahul Sinha",
      "Thomas E. Browder",
      "N. G. Deshpande",
      "Dibyakrupa Sahoo",
      "Nita Sinha"
    ],
    "abstract": "The observation of CP violation in the difference of CP asymmetries between\n$D\\to K^+K^-$ and $D\\to \\pi^+\\pi^-$ has raised a debate whether the observed\nasymmetries can be regarded as a signal of physics beyond the standard model\n(SM). In this letter we show that the measured observables for $D\\to \\pi\\pi$\nunambiguously imply a very large penguin contribution that is larger than\n$10\\%$ of the amplitude for $D^0\\to\\pi^+ \\pi^-$ at a significance greater than\n$3.3\\sigma$. We present arguments based only on unitarity of re-scattering\namplitudes to show that large penguins are unlikely to arise from re-scattering\nand likely indicate physics beyond the SM. In a model independent approach, we\nshow how a very small contribution from physics beyond the SM with a large weak\nphase alleviates the problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.24338v2",
    "published": "2025-05-30T08:28:36+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00091v1",
    "title": "AGNI: A radiative-convective model for lava planet atmospheres",
    "authors": [
      "Harrison Nicholls",
      "Raymond Pierrehumbert",
      "Tim Lichtenberg"
    ],
    "abstract": "It is important that we are able to accurately model the atmospheres of\n(exo)planets. This is because atmospheres play a central role in setting a\nplanet's thermochemical environment at a given point in time, and also in\nregulating how it evolves over geological timescales. Additionally, it is\nprimarily by observation of their atmospheres that we are able to characterise\nexoplanets. There is particular demand for accurate models in the context of\nso-called lava worlds: planets with molten interiors (or `magma oceans').\n  AGNI is a Julia program designed to solve for the temperature and radiation\nenvironment within the atmospheres of rocky (exo)planets. It leverages a well\nestablished FORTRAN code to calculate radiative fluxes from a given atmospheric\ntemperature structure and composition, which -- alongside representations of\nconvection and other processes -- enables an energy-conserving numerical\nsolution for the atmospheric conditions. In contrast to most other numerical\natmosphere models, AGNI uses a Newton-Raphson optimisation method to obtain its\nsolution, which enables improved performance and scalability. Our model was\nspecifically developed for use alongside planetary interior models within a\ncoupled simulation framework. However, it can also be applied to scientific\nproblems standalone when used as an executable program; it reads TOML\nconfiguration files and outputs figures and NetCDF datasets. AGNI can also\nfunction as a software library; it is used in this sense within the Jupyter\nnotebook tutorials of our GitHub repository\n(https://nichollsh.github.io/AGNI/dev/)",
    "pdf_url": "http://arxiv.org/pdf/2506.00091v1",
    "published": "2025-05-30T08:26:49+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24337v1",
    "title": "Singularity Protocol for Cross Chain AMM without Intermediate Tokens or Bridges",
    "authors": [
      "Sumit Vohra"
    ],
    "abstract": "Automated Market Makers (AMMs) are decentralized exchange protocols that\nprovide continuous access to token liquidity without the need for order books\nor traditional market makers. However, this innovation has failed to scale when\nit comes to cross-chain swaps. Modern cross-chain swaps employ double-sided\nAMMs, which are not only inefficient due to liquidity fragmentation but also\nrequire an intermediate token. This introduces inherent volatility risk as well\nas blockchain and bridging risk, especially in the case of wrapped tokens. This\npaper describes the inefficiencies of existing AMM invariants, particularly\ntheir mixed polynomial nature, and derives a new class of AMMs that do not have\nbi-state dependency between the assets being swapped. We propose a novel method\nof value transfer swaps using the described invariant that mitigates the need\nfor bi-state dependency and eliminates the need for intermediate tokens or\nbridging. Furthermore, we show how this mechanism enables efficient cross-chain\nswaps with lower gas requirements and no bridging risks. The proposed\ntechnology is designed to support cross-chain swaps across any permutation of\nL1, L2, and L3 blockchains.",
    "pdf_url": "http://arxiv.org/pdf/2505.24337v1",
    "published": "2025-05-30T08:25:48+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24336v1",
    "title": "When Humans Growl and Birds Speak: High-Fidelity Voice Conversion from Human to Animal and Designed Sounds",
    "authors": [
      "Minsu Kang",
      "Seolhee Lee",
      "Choonghyeon Lee",
      "Namhyun Cho"
    ],
    "abstract": "Human to non-human voice conversion (H2NH-VC) transforms human speech into\nanimal or designed vocalizations. Unlike prior studies focused on dog-sounds\nand 16 or 22.05kHz audio transformation, this work addresses a broader range of\nnon-speech sounds, including natural sounds (lion-roars, birdsongs) and\ndesigned voice (synthetic growls). To accomodate generation of diverse\nnon-speech sounds and 44.1kHz high-quality audio transformation, we introduce a\npreprocessing pipeline and an improved CVAE-based H2NH-VC model, both optimized\nfor human and non-human voices. Experimental results showed that the proposed\nmethod outperformed baselines in quality, naturalness, and similarity MOS,\nachieving effective voice conversion across diverse non-human timbres. Demo\nsamples are available at\nhttps://nc-ai.github.io/speech/publications/nonhuman-vc/",
    "pdf_url": "http://arxiv.org/pdf/2505.24336v1",
    "published": "2025-05-30T08:24:41+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00090v2",
    "title": "Quantum theory of fractional topological pumping of lattice solitons",
    "authors": [
      "Julius Bohm",
      "Hugo Gerlitz",
      "Christina Jörg",
      "Michael Fleischhauer"
    ],
    "abstract": "One of the hallmarks of topological quantum systems is the robust\nquantization of particle transport, which is the origin of the integer-valued\nQuantum Hall conductivity. In the presence of interactions the topological\ntransport can also become fractional. Recent experiments on topological pumps\nconstructed by arrays of photonic waveguides have demonstrated both integer and\nfractional transport of lattice solitons. Here a background medium mediates\ninteractions between photons via a Kerr nonlinearity and leads to the formation\nof self-bound composites, called lattice solitons. Upon increasing the\ninteraction strength of these solitons a sequence of transitions was observed\nfrom a phase with integer transport in a pump cycle through different phases of\nfractional transport to a phase with no transport. We here present a full\nquantum description of topological pumps of solitons. This approach allows us\nto identify a topological invariant, a many-body Chern number, determined by\nthe band structure of the center-of-mass (COM) momentum of the solitons, which\nfully governs their transport. Increasing the interaction leads to a successive\nmerging of COM bands which explains the observed sequence of topological phase\ntransitions and also the potential for a breakdown of topological quantization\nfor intermediate interaction strength.",
    "pdf_url": "http://arxiv.org/pdf/2506.00090v2",
    "published": "2025-05-30T08:21:08+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.other",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24335v1",
    "title": "Numerical simulation of oscillatory magnetic reconnection modulated by solar convective motions",
    "authors": [
      "Yifu Wang",
      "Lei Ni",
      "Guanchong Cheng",
      "Jialiang Hu",
      "Yuhao Chen",
      "Abdullah Zafar"
    ],
    "abstract": "Oscillatory magnetic reconnection is a periodic magnetic reconnection\nprocess, during which the current sheet's orientation and the magnetic\nconnections change periodically. This periodic variation is generally\nconsidered to originate from the magnetic reconnection itself rather than from\nexternal driving processes. We conduct 2.5-dimensional radiative\nmagnetohydrodynamic simulations to investigate the emergence of a magnetic flux\ntube from the convection zone into the lower corona, where the emerging\nmagnetic fields reconnect with background ones. During the reconnection process\nwithin 5771 s, the current sheet's orientation has been reversed 41 times,\ncorresponding to 40 oscillation periods. Notably, the longest period is 30\nminutes, which is consistent with the previous observational results. We find\nthat the main factor leading to the reversal of the current sheet's orientation\nis the quasi-periodic external force provided by the emergence of plasma and\nmagnetic fields from the convection zone. We also find the shifting of the\nupward outflows from the reconnection region along the horizontal direction due\nto the alternating changes of the reconnection inflow and outflow regions. In\naddition to the quasi-periodic change of the current sheet orientation, the\nreconnection rate at the main X-point also oscillates with a period between\n100-400 s, which corresponds to the period of p-mode oscillations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24335v1",
    "published": "2025-05-30T08:18:59+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.plasm-ph",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24334v1",
    "title": "KairosAD: A SAM-Based Model for Industrial Anomaly Detection on Embedded Devices",
    "authors": [
      "Uzair Khan",
      "Franco Fummi",
      "Luigi Capogrosso"
    ],
    "abstract": "In the era of intelligent manufacturing, anomaly detection has become\nessential for maintaining quality control on modern production lines. However,\nwhile many existing models show promising performance, they are often too\nlarge, computationally demanding, and impractical to deploy on\nresource-constrained embedded devices that can be easily installed on the\nproduction lines of Small and Medium Enterprises (SMEs). To bridge this gap, we\npresent KairosAD, a novel supervised approach that uses the power of the Mobile\nSegment Anything Model (MobileSAM) for image-based anomaly detection. KairosAD\nhas been evaluated on the two well-known industrial anomaly detection datasets,\ni.e., MVTec-AD and ViSA. The results show that KairosAD requires 78% fewer\nparameters and boasts a 4x faster inference time compared to the leading\nstate-of-the-art model, while maintaining comparable AUROC performance. We\ndeployed KairosAD on two embedded devices, the NVIDIA Jetson NX, and the NVIDIA\nJetson AGX. Finally, KairosAD was successfully installed and tested on the real\nproduction line of the Industrial Computer Engineering Laboratory (ICE Lab) at\nthe University of Verona. The code is available at\nhttps://github.com/intelligolabs/KairosAD.",
    "pdf_url": "http://arxiv.org/pdf/2505.24334v1",
    "published": "2025-05-30T08:18:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24333v1",
    "title": "Two failure modes of deep transformers and how to avoid them: a unified theory of signal propagation at initialisation",
    "authors": [
      "Alessio Giorlandino",
      "Sebastian Goldt"
    ],
    "abstract": "Finding the right initialisation for neural networks is crucial to ensure\nsmooth training and good performance. In transformers, the wrong initialisation\ncan lead to one of two failure modes of self-attention layers: rank collapse,\nwhere all tokens collapse into similar representations, and entropy collapse,\nwhere highly concentrated attention scores lead to training instability. While\nthe right initialisation has been extensively studied in feed-forward networks,\nan exact description of signal propagation through a full transformer block has\nso far been lacking. Here, we provide an analytical theory of signal\npropagation through vanilla transformer blocks with self-attention layers,\nlayer normalisation, skip connections and ReLU MLP. To treat the self-attention\nlayer, we draw on a formal parallel with the Random Energy Model from\nstatistical physics. We identify and characterise two regimes governed by the\nvariance of the query and key initialisations: a low-variance regime, where we\nrecover the known rank collapse behaviour; and a previously unexplored\nhigh-variance regime, where signal is preserved but \\textit{entropy collapse}\noccurs. In the low-variance regime, we calculate the critical strength for the\nresidual connection to ensure signal propagation. Our theory yields\ntrainability diagrams that identify the correct choice of initialisation\nhyper-parameters for a given architecture. Experiments with BERT-style models\ntrained on TinyStories validate our predictions. Our theoretical framework\ngives a unified perspective on the two failure modes of self-attention and\ngives quantitative predictions on the scale of both weights and residual\nconnections that guarantees smooth training.",
    "pdf_url": "http://arxiv.org/pdf/2505.24333v1",
    "published": "2025-05-30T08:18:23+00:00",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24332v1",
    "title": "Pangu DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning",
    "authors": [
      "Wenxuan Shi",
      "Haochen Tan",
      "Chuqiao Kuang",
      "Xiaoguang Li",
      "Xiaozhe Ren",
      "Chen Zhang",
      "Hanting Chen",
      "Yasheng Wang",
      "Lifeng Shang",
      "Fisher Yu",
      "Yunhe Wang"
    ],
    "abstract": "Information seeking demands iterative evidence gathering and reflective\nreasoning, yet large language models (LLMs) still struggle with it in open-web\nquestion answering. Existing methods rely on static prompting rules or training\nwith Wikipedia-based corpora and retrieval environments, limiting adaptability\nto the real-world web environment where ambiguity, conflicting evidence, and\nnoise are prevalent. These constrained training settings hinder LLMs from\nlearning to dynamically decide when and where to search, and how to adjust\nsearch depth and frequency based on informational demands. We define this\nmissing capacity as Search Intensity Scaling (SIS)--the emergent skill to\nintensify search efforts under ambiguous or conflicting conditions, rather than\nsettling on overconfident, under-verification answers.\n  To study SIS, we introduce WebPuzzle, the first dataset designed to foster\ninformation-seeking behavior in open-world internet environments. WebPuzzle\nconsists of 24K training instances and 275 test questions spanning both\nwiki-based and open-web queries. Building on this dataset, we propose\nDeepDiver, a Reinforcement Learning (RL) framework that promotes SIS by\nencouraging adaptive search policies through exploration under a real-world\nopen-web environment. Experimental results show that Pangu-7B-Reasoner\nempowered by DeepDiver achieve performance on real-web tasks comparable to the\n671B-parameter DeepSeek-R1. We detail DeepDiver's training curriculum from\ncold-start supervised fine-tuning to a carefully designed RL phase, and present\nthat its capability of SIS generalizes from closed-form QA to open-ended tasks\nsuch as long-form writing. Our contributions advance adaptive information\nseeking in LLMs and provide a valuable benchmark and dataset for future\nresearch.",
    "pdf_url": "http://arxiv.org/pdf/2505.24332v1",
    "published": "2025-05-30T08:15:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24331v1",
    "title": "Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents",
    "authors": [
      "Fanhang Man",
      "Huandong Wang",
      "Jianjie Fang",
      "Zhaoyi Deng",
      "Baining Zhao",
      "Xinlei Chen",
      "Yong Li"
    ],
    "abstract": "User sentiment on social media reveals the underlying social trends, crises,\nand needs. Researchers have analyzed users' past messages to trace the\nevolution of sentiments and reconstruct sentiment dynamics. However, predicting\nthe imminent sentiment of an ongoing event is rarely studied. In this paper, we\naddress the problem of \\textbf{sentiment forecasting} on social media to\npredict the user's future sentiment in response to the development of the\nevent. We extract sentiment-related features to enhance the modeling skill and\npropose a multi-perspective role-playing framework to simulate the process of\nhuman response. Our preliminary results show significant improvement in\nsentiment forecasting on both microscopic and macroscopic levels.",
    "pdf_url": "http://arxiv.org/pdf/2505.24331v1",
    "published": "2025-05-30T08:13:33+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24330v2",
    "title": "Quasi-Homogeneous Integrable Systems: Free Parameters, Kovalevskaya Exponents, and the Painlevé Property",
    "authors": [
      "Changyu Zhou",
      "Hayato Chiba"
    ],
    "abstract": "This paper investigates quasi-homogeneous integrable systems by analyzing\ntheir Laurent series solutions near movable singularities, motivated by\npatterns observed in Kovalevskaya exponents of four-dimensional Painlev\\'e-type\nequations. We introduce a parameter space encoding the free coefficients in\nthese expansions and study its deformation under a commuting quasi-homogeneous\nvector field.\n  Within this framework, we derive lower indicial loci from the principal one\nand establish an arithmetic resonance condition on Kovalevskaya exponents that\ngoverns the emergence of fractional powers and the breakdown of the Painlev\\'e\nproperty. Moreover, we construct a Frobenius manifold structure on the\nparameter space via the initial value map, which becomes conformal when all\nweights coincide.\n  In the Hamiltonian context, we demonstrate that the induced flow on the\nparameter space preserves a symplectic form and yields a natural pairing of\nKovalevskaya exponents. These findings unify analytic and geometric aspects of\nquasi-homogeneous integrable systems and offer new insights into their\ndeformation theory and singularity structures. Our results provide a\ncomprehensive framework applicable to the classification and analysis of\nPainlev\\'e-type equations and related integrable models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24330v2",
    "published": "2025-05-30T08:13:30+00:00",
    "categories": [
      "nlin.SI",
      "math.DS"
    ],
    "primary_category": "nlin.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24329v2",
    "title": "DisTime: Distribution-based Time Representation for Video Large Language Models",
    "authors": [
      "Yingsen Zeng",
      "Zepeng Huang",
      "Yujie Zhong",
      "Chengjian Feng",
      "Jie Hu",
      "Lin Ma",
      "Yang Liu"
    ],
    "abstract": "Despite advances in general video understanding, Video Large Language Models\n(Video-LLMs) face challenges in precise temporal localization due to discrete\ntime representations and limited temporally aware datasets. Existing methods\nfor temporal expression either conflate time with text-based numerical values,\nadd a series of dedicated temporal tokens, or regress time using specialized\ntemporal grounding heads. To address these issues, we introduce DisTime, a\nlightweight framework designed to enhance temporal comprehension in Video-LLMs.\nDisTime employs a learnable token to create a continuous temporal embedding\nspace and incorporates a Distribution-based Time Decoder that generates\ntemporal probability distributions, effectively mitigating boundary ambiguities\nand maintaining temporal continuity. Additionally, the Distribution-based Time\nEncoder re-encodes timestamps to provide time markers for Video-LLMs. To\novercome temporal granularity limitations in existing datasets, we propose an\nautomated annotation paradigm that combines the captioning capabilities of\nVideo-LLMs with the localization expertise of dedicated temporal models. This\nleads to the creation of InternVid-TG, a substantial dataset with 1.25M\ntemporally grounded events across 179k videos, surpassing ActivityNet-Caption\nby 55 times. Extensive experiments demonstrate that DisTime achieves\nstate-of-the-art performance across benchmarks in three time-sensitive tasks\nwhile maintaining competitive performance in Video QA tasks. Code and data are\nreleased at https://github.com/josephzpng/DisTime.",
    "pdf_url": "http://arxiv.org/pdf/2505.24329v2",
    "published": "2025-05-30T08:10:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24328v1",
    "title": "Identifiability through special linear measurements",
    "authors": [
      "Fulvio Gesmundo",
      "Alexandros Grosdos",
      "André Uschmajew"
    ],
    "abstract": "We show that one can always identify a point on an algebraic variety $X$\nuniquely with $\\dim X +1$ generic linear measurements taken themselves from a\nvariety under minimal assumptions. As illustrated by several examples the\nresult is sharp, that is, $\\dim X$ measurements are in general not enough for\nunique identifiability.",
    "pdf_url": "http://arxiv.org/pdf/2505.24328v1",
    "published": "2025-05-30T08:09:55+00:00",
    "categories": [
      "math.AG",
      "cs.IT",
      "cs.NA",
      "math.IT",
      "math.NA",
      "14Q15, 15A29, 90C30"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24327v1",
    "title": "STAR-Net: An Interpretable Model-Aided Network for Remote Sensing Image Denoising",
    "authors": [
      "Jingjing Liu",
      "Jiashun Jin",
      "Xianchao Xiu",
      "Jianhua Zhang",
      "Wanquan Liu"
    ],
    "abstract": "Remote sensing image (RSI) denoising is an important topic in the field of\nremote sensing. Despite the impressive denoising performance of RSI denoising\nmethods, most current deep learning-based approaches function as black boxes\nand lack integration with physical information models, leading to limited\ninterpretability. Additionally, many methods may struggle with insufficient\nattention to non-local self-similarity in RSI and require tedious tuning of\nregularization parameters to achieve optimal performance, particularly in\nconventional iterative optimization approaches. In this paper, we first propose\na novel RSI denoising method named sparse tensor-aided representation network\n(STAR-Net), which leverages a low-rank prior to effectively capture the\nnon-local self-similarity within RSI. Furthermore, we extend STAR-Net to a\nsparse variant called STAR-Net-S to deal with the interference caused by\nnon-Gaussian noise in original RSI for the purpose of improving robustness.\nDifferent from conventional iterative optimization, we develop an alternating\ndirection method of multipliers (ADMM)-guided deep unrolling network, in which\nall regularization parameters can be automatically learned, thus inheriting the\nadvantages of both model-based and deep learning-based approaches and\nsuccessfully addressing the above-mentioned shortcomings. Comprehensive\nexperiments on synthetic and real-world datasets demonstrate that STAR-Net and\nSTAR-Net-S outperform state-of-the-art RSI denoising methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24327v1",
    "published": "2025-05-30T08:09:31+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24326v2",
    "title": "Principal minors of Fourier matrices of square-free order",
    "authors": [
      "Andrei Caragea",
      "Dae Gwan Lee",
      "Romanos Malikiosis",
      "Goetz E. Pfander"
    ],
    "abstract": "Chebotarev's theorem on roots of unity states that all minors of a Fourier\nmatrix are non-zero if and only if the order of the matrix is prime. We\nestablish cases in which all principal minors of Fourier matrices of\nsquare-free order are non-zero. In a subsequent paper we discuss the case of\ncomposites containing squares.",
    "pdf_url": "http://arxiv.org/pdf/2505.24326v2",
    "published": "2025-05-30T08:09:20+00:00",
    "categories": [
      "math.FA",
      "math.NT",
      "42C15, 42A99, 11R18"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24325v1",
    "title": "Cartan Isometries and Toeplitz Operators on Cartan domains",
    "authors": [
      "Surjit Kumar",
      "Milan Kumar Mal",
      "Paramita Pramanick"
    ],
    "abstract": "We provide a description of the Shilov boundary of the classical Cartan\ndomain in terms of Jordan triple determinant. As a consequence, we obtained an\nintrinsic characterization of Cartan isometries. Further, we obtain (i)\ninvariance of Cartan isometries under the action of the biholomorphic\nautomorphism group, and (ii) a Brown-Halmos type condition for Toeplitz\noperators on the Cartan domain. Also, we show that the zero operator is the\nonly compact Toeplitz operator. Finally, we study the $\\boldsymbol T$-Toeplitz\noperators and reflexivity of a Cartan isometry $\\boldsymbol T.$",
    "pdf_url": "http://arxiv.org/pdf/2505.24325v1",
    "published": "2025-05-30T08:07:28+00:00",
    "categories": [
      "math.FA",
      "Primary 47A13, 47B32, 47B35, Secondary 32M15"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24324v1",
    "title": "SwiftEval: Developing a Language-Specific Benchmark for LLM-generated Code Evaluation",
    "authors": [
      "Ivan Petrukha",
      "Yana Kurliak",
      "Nataliia Stulova"
    ],
    "abstract": "In recent years, large language models (LLMs) have showcased significant\nadvancements in code generation. However, most evaluation benchmarks are\nprimarily oriented towards Python, making it difficult to evaluate other\nprogramming languages, such as Swift, with high quality. By examining widely\nestablished multilingual benchmarks like HumanEval-XL and MultiPL-E, we\nidentified critical issues specific to their Swift components, making them\ninsufficient or even irrelevant for assessing LLM coding capabilities on Swift.\nUnlike these existing approaches, which prioritize rapid scaling and\ngeneralization by automatically translating Python-centric benchmarks with\nLLMs, we adopt a quality-over-quantity methodology. We present SwiftEval, the\nfirst Swift-oriented benchmark consisting of 28 carefully hand-crafted\nproblems, and evaluate 44 popular Code LLMs on it. Our results show significant\nLLM scores drop for problems requiring language-specific features, most\nnoticeable in the models of smaller sizes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24324v1",
    "published": "2025-05-30T08:06:30+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24323v1",
    "title": "A new shock in the pre-merging cluster pair 1E2215-2216",
    "authors": [
      "Yanling Chen",
      "Liyi Gu",
      "Aurora Simionescu",
      "Chunyang Jiang",
      "Rui Huang",
      "Wei Cui"
    ],
    "abstract": "The galaxy cluster pair 1E2216.0-0401 and 1E2215.7-0404 represents a major\ncluster merger in its early stages, a phase that has been scarcely explored in\nprevious studies. Within this system, both axial and equatorial merger shocks\nhave been identified. Recent XMM-Newton observations of the southern region of\nthe cluster pair have increased the total exposure time to approximately 300\nks, enhancing the sensitivity to detect faint shock features in the cluster\noutskirts. Through a combined analysis of XMM-Newton and Chandra data,\nincluding both imaging and spectral techniques, a new shock front has been\nidentified at approximately 2'.3 south of the X-ray brightness peak of 1E2215.\nThis shock front exhibits a surface brightness ratio of $1.33 \\pm 0.07$ and a\ntemperature ratio of $1.22^{+0.13}_{-0.14}$ in XMM-Newton, consistent with\nChandra results. The Mach number, independently calculated from both the\ntemperature and surface brightness discontinuities, yields consistent values of\n$\\mathcal{M} \\approx 1.2$ . The age, velocity, and spatial distribution of this\nshock suggest that it shares a common physical origin with the previously\nidentified equatorial shock.",
    "pdf_url": "http://arxiv.org/pdf/2505.24323v1",
    "published": "2025-05-30T08:06:14+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24322v1",
    "title": "Fourier ptychographic microscopy aided with transport of intensity equation for robust full phase spectrum reconstruction",
    "authors": [
      "Mikołaj Rogalski",
      "Juan Martinez-Carranza",
      "Bartosz Górski",
      "Piotr Arcab",
      "Michał Jóźwik",
      "Piotr Zdańkowski",
      "Magdalena Sobień",
      "Marzena Stefaniuk",
      "Shun Zhou",
      "Chao Zuo",
      "Maciej Trusiak"
    ],
    "abstract": "Fourier ptychographic microscopy (FPM) is a pivotal computational imaging\ntechnique that achieves phase and amplitude reconstruction with high resolution\nand wide field of view, using low numerical aperture objectives and LED array\nillumination. Despite its unique strengths, FPM remains fundamentally limited\nin retrieving low spatial frequency phase information due to the absence of\nphase encoding in all brightfield illumination angles. To overcome this, we\npresent a novel hybrid approach that combines FPM with the transport of\nintensity equation (TIE), enabling accurate, full-spectrum phase retrieval\nwithout compromising system simplicity. Our method extends standard FPM\nacquisitions with a single additional on-axis defocused image, from which\nlow-frequency phase components are reconstructed via TIE method, employing\nlarge defocus distance to suppress low-frequency artifacts and enhance\nrobustness to intensity noise. To additionally compensate for defocus-induced\nmagnification variations caused by spherical wavefront illumination, we employ\nan affine transform-based correction scheme upon image registration. Notably,\nby restoring the missing low-frequency content, our hybrid method appears\ncapable of recovering phase values beyond the conventional 0-2{\\pi} range - an\narea where conventional FPM techniques often struggle when dealing with\noptically thick samples. We validated our method using a quantitative phase\ntest target for benchmarking accuracy and biological cheek cells, mouse\nneurons, and mouse brain tissue slice samples to demonstrate applicability for\nin vitro bioimaging. Experimental results confirm substantial improvements in\nphase reconstruction fidelity across spatial frequencies, establishing this\nhybrid FPM+TIE framework as a practical and high-performance solution for\nquantitative phase imaging in biomedical and optical metrology applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.24322v1",
    "published": "2025-05-30T08:04:44+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24321v2",
    "title": "Online Fair Allocations with Binary Valuations and Beyond",
    "authors": [
      "Yuanyuan Wang",
      "Tianze Wei"
    ],
    "abstract": "In an online fair allocation problem, a sequence of indivisible items arrives\nonline and needs to be allocated to offline agents immediately and irrevocably.\nIn our paper, we study the online allocation of either goods or chores. We\nemploy popular fairness notions, including envy-freeness up to one item (EF1)\nand maximin share fairness (MMS) to capture fairness, and utilitarian social\nwelfare (USW) to measure efficiency. For both settings of items, we present a\nseries of positive results regarding the existence of fair and efficient\nallocations with widely studied classes of additive binary and personalized\nbi-valued valuation/cost functions. Furthermore, we complement our results by\nconstructing counterexamples to establish our results as among the best\nguarantees possible.",
    "pdf_url": "http://arxiv.org/pdf/2505.24321v2",
    "published": "2025-05-30T08:04:07+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24320v1",
    "title": "DTR: Delaunay Triangulation-based Racing for Scaled Autonomous Racing",
    "authors": [
      "Luca Tognoni",
      "Neil Reichlin",
      "Edoardo Ghignone",
      "Nicolas Baumann",
      "Steven Marty",
      "Liam Boyle",
      "Michele Magno"
    ],
    "abstract": "Reactive controllers for autonomous racing avoid the computational overhead\nof full ee-Think-Act autonomy stacks by directly mapping sensor input to\ncontrol actions, eliminating the need for localization and planning. A widely\nused reactive strategy is FTG, which identifies gaps in LiDAR range\nmeasurements and steers toward a chosen one. While effective on fully bounded\ncircuits, FTG fails in scenarios with incomplete boundaries and is prone to\ndriving into dead-ends, known as FTG-traps. This work presents DTR, a reactive\ncontroller that combines Delaunay triangulation, from raw LiDAR readings, with\ntrack boundary segmentation to extract a centerline while systematically\navoiding FTG-traps. Compared to FTG, the proposed method achieves lap times\nthat are 70\\% faster and approaches the performance of map-dependent methods.\nWith a latency of 8.95 ms and CPU usage of only 38.85\\% on the robot's OBC, DTR\nis real-time capable and has been successfully deployed and evaluated in field\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24320v1",
    "published": "2025-05-30T08:02:49+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24319v1",
    "title": "HiCaM: A Hierarchical-Causal Modification Framework for Long-Form Text Modification",
    "authors": [
      "Yuntao Shi",
      "Yi Luo",
      "Yeyun Gong",
      "Chen Lin"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in various\ndomains. However, when handling long-form text modification tasks, they still\nface two major problems: (1) producing undesired modifications by\ninappropriately altering or summarizing irrelevant content, and (2) missing\nnecessary modifications to implicitly related passages that are crucial for\nmaintaining document coherence. To address these issues, we propose HiCaM, a\nHierarchical-Causal Modification framework that operates through a hierarchical\nsummary tree and a causal graph. Furthermore, to evaluate HiCaM, we derive a\nmulti-domain dataset from various benchmarks, providing a resource for\nassessing its effectiveness. Comprehensive evaluations on the dataset\ndemonstrate significant improvements over strong LLMs, with our method\nachieving up to a 79.50\\% win rate. These results highlight the\ncomprehensiveness of our approach, showing consistent performance improvements\nacross multiple models and domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.24319v1",
    "published": "2025-05-30T08:02:48+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24318v1",
    "title": "Universal Phase Transitions of Matter Induced in Optically Driven Cavities",
    "authors": [
      "Tsan Huang",
      "Zhiyuan Sun"
    ],
    "abstract": "Optical cavities have been widely applied to manipulate the properties of\nsolid state materials inside it. We propose that in systems embedded within\noptical cavities driven by incident pump light, the pump induces generic phase\ntransitions into new non-equilibrium steady states. This effect arises from the\nponderomotive potential, the effective static potential exerted by the pump on\nthe low energy degrees of freedom, which exhibits a universal step-like\nstructure that pushes the matter degrees of freedom in the direction that\nred-shifts the cavity photon modes. For a two dimensional electron liquid in a\ndriven cavity, this step-like potential pushes the electron density to jump to\na smaller value so that a hybrid cavity photon mode is red shifted to slightly\nbelow the pump frequency. Similarly, for a disordered superconductor in such a\ndriven cavity, this potential acts on the superconducting order parameter and\ncauses a first order phase transition to a new steady state with a smaller gap.\nBy realistic electromagnetic modeling of the cavity, we construct the\nnon-equilibrium phase diagrams for experimentally relevant devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24318v1",
    "published": "2025-05-30T08:01:46+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.stat-mech",
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24317v1",
    "title": "ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving",
    "authors": [
      "Yongming Chen",
      "Miner Chen",
      "Liewen Liao",
      "Mingyang Jiang",
      "Xiang Zuo",
      "Hengrui Zhang",
      "Yuchen Xi",
      "Songan Zhang"
    ],
    "abstract": "Reinforcement learning (RL) in autonomous driving employs a trial-and-error\nmechanism, enhancing robustness in unpredictable environments. However,\ncrafting effective reward functions remains challenging, as conventional\napproaches rely heavily on manual design and demonstrate limited efficacy in\ncomplex scenarios. To address this issue, this study introduces a\nresponsibility-oriented reward function that explicitly incorporates traffic\nregulations into the RL framework. Specifically, we introduced a Traffic\nRegulation Knowledge Graph and leveraged Vision-Language Models alongside\nRetrieval-Augmented Generation techniques to automate reward assignment. This\nintegration guides agents to adhere strictly to traffic laws, thus minimizing\nrule violations and optimizing decision-making performance in diverse driving\nconditions. Experimental validations demonstrate that the proposed methodology\nsignificantly improves the accuracy of assigning accident responsibilities and\neffectively reduces the agent's liability in traffic incidents.",
    "pdf_url": "http://arxiv.org/pdf/2505.24317v1",
    "published": "2025-05-30T08:00:51+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24316v1",
    "title": "Some Characteristics of Almost $ω$-Bach Solitons",
    "authors": [
      "Paritosh Ghosh",
      "Hemangi Madhusudan Shah",
      "Arindam Bhattacharyya"
    ],
    "abstract": "In this article, we introduce $\\omega$-Bach tensor corresponding to one form\n$\\omega$ and correspondingly introduce almost $\\omega$-Bach solitons, thereby\ngeneralizing the existing notion of Bach tensor and almost Bach solitons. We\ncharacterize almost $\\omega$-Bach solitons, when the potential vector field of\nthe soliton generates an infinitesimal harmonic transformation or is an affine\nconformal vector field, or is a projective vector field or is a Killing vector\nfield, when the $\\omega$-Bach tensor is divergence free, or is a harmonic $1$\nform or is a Killing $1$-form. We generalize some of the results obtained by P.\nT. Ho and A. Ghosh. One of the main results of this paper is that we explicitly\nfind some of the gradient almost $\\omega$-Bach solitons on the product\nmanifolds ${\\mathbb S}^2\\times{\\mathbb H}^2$, $\\mathbb{R}^2\\times{\\mathbb H}^2$\nand $\\mathbb{R}^2\\times{\\mathbb S}^2$. Our gradient almost $\\omega$-Bach\nsolitons generalize the almost Bach solitons on $\\mathbb{R}^2\\times{\\mathbb\nH}^2$ and $\\mathbb{R}^2\\times{\\mathbb S}^2$ found by P. T. Ho. Moreover,\nfinding of our gradient almost $\\omega$-Bach solitons on ${\\mathbb\nS}^2\\times{\\mathbb H}^2$ is a novel one and complements to the existing almost\nBach solitons described by P. T. Ho.",
    "pdf_url": "http://arxiv.org/pdf/2505.24316v1",
    "published": "2025-05-30T07:58:47+00:00",
    "categories": [
      "math.DG",
      "53C20, 53C21, 53C25"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24315v1",
    "title": "InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing",
    "authors": [
      "Jinlu Zhang",
      "Yixin Chen",
      "Zan Wang",
      "Jie Yang",
      "Yizhou Wang",
      "Siyuan Huang"
    ],
    "abstract": "Recent advances in 3D human-aware generation have made significant progress.\nHowever, existing methods still struggle with generating novel Human Object\nInteraction (HOI) from text, particularly for open-set objects. We identify\nthree main challenges of this task: precise human-object relation reasoning,\naffordance parsing for any object, and detailed human interaction pose\nsynthesis aligning description and object geometry. In this work, we propose a\nnovel zero-shot 3D HOI generation framework without training on specific\ndatasets, leveraging the knowledge from large-scale pre-trained models.\nSpecifically, the human-object relations are inferred from large language\nmodels (LLMs) to initialize object properties and guide the optimization\nprocess. Then we utilize a pre-trained 2D image diffusion model to parse unseen\nobjects and extract contact points, avoiding the limitations imposed by\nexisting 3D asset knowledge. The initial human pose is generated by sampling\nmultiple hypotheses through multi-view SDS based on the input text and object\ngeometry. Finally, we introduce a detailed optimization to generate\nfine-grained, precise, and natural interaction, enforcing realistic 3D contact\nbetween the 3D object and the involved body parts, including hands in grasping.\nThis is achieved by distilling human-level feedback from LLMs to capture\ndetailed human-object relations from the text instruction. Extensive\nexperiments validate the effectiveness of our approach compared to prior works,\nparticularly in terms of the fine-grained nature of interactions and the\nability to handle open-set 3D objects.",
    "pdf_url": "http://arxiv.org/pdf/2505.24315v1",
    "published": "2025-05-30T07:53:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24314v1",
    "title": "DS-Codec: Dual-Stage Training with Mirror-to-NonMirror Architecture Switching for Speech Codec",
    "authors": [
      "Peijie Chen",
      "Wenhao Guan",
      "Kaidi Wang",
      "Weijie Wu",
      "Hukai Huang",
      "Qingyang Hong",
      "Lin Li"
    ],
    "abstract": "Neural speech codecs are essential for advancing text-to-speech (TTS)\nsystems. With the recent success of large language models in text generation,\ndeveloping high-quality speech tokenizers has become increasingly important.\nThis paper introduces DS-Codec, a novel neural speech codec featuring a\ndual-stage training framework with mirror and non-mirror architectures\nswitching, designed to achieve superior speech reconstruction. We conduct\nextensive experiments and ablation studies to evaluate the effectiveness of our\ntraining strategy and compare the performance of the two architectures. Our\nresults show that the mirrored structure significantly enhances the robustness\nof the learned codebooks, and the training strategy balances the advantages\nbetween mirrored and non-mirrored structures, leading to improved high-fidelity\nspeech reconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2505.24314v1",
    "published": "2025-05-30T07:53:01+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24313v1",
    "title": "On the Emergence of Weak-to-Strong Generalization: A Bias-Variance Perspective",
    "authors": [
      "Gengze Xu",
      "Wei Yao",
      "Ziqiao Wang",
      "Yong Liu"
    ],
    "abstract": "Weak-to-strong generalization (W2SG) refers to the phenomenon where a strong\nstudent model, trained on a dataset labeled by a weak teacher, ultimately\noutperforms the teacher on the target task. Recent studies attribute this\nperformance gain to the prediction misfit between the student and teacher\nmodels. In this work, we theoretically investigate the emergence of W2SG\nthrough a generalized bias-variance decomposition of Bregman divergence.\nSpecifically, we show that the expected population risk gap between the student\nand teacher is quantified by the expected misfit between the two models. While\nthis aligns with previous results, our analysis removes several restrictive\nassumptions, most notably, the convexity of the student's hypothesis class,\nrequired in earlier works. Moreover, we show that W2SG is more likely to emerge\nwhen the student model approximates its posterior mean teacher, rather than\nmimicking an individual teacher. Using a concrete example, we demonstrate that\nif the student model has significantly larger capacity than the teacher, it can\nindeed converge to this posterior mean. Our analysis also suggests that\navoiding overfitting to the teacher's supervision and reducing the entropy of\nstudent's prediction further facilitate W2SG. In addition, we show that the\nreverse cross-entropy loss, unlike the standard forward cross-entropy, is less\nsensitive to the predictive uncertainty of the teacher. Finally, we empirically\nverify our theoretical insights and demonstrate that incorporating the reverse\ncross-entropy loss consistently improves student performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.24313v1",
    "published": "2025-05-30T07:52:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24312v1",
    "title": "SSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index",
    "authors": [
      "Yirui Zhan",
      "Wen Nie",
      "Jun Gao"
    ],
    "abstract": "Accurate cardinality estimation of substring queries, which are commonly\nexpressed using the SQL LIKE predicate, is crucial for query optimization in\ndatabase systems. While both rule-based methods and machine learning-based\nmethods have been developed to optimize various aspects of cardinality\nestimation, their absence of error bounds may result in substantial estimation\nerrors, leading to suboptimal execution plans. In this paper, we propose\nSSCard, a novel SubString Cardinality estimator that leverages a\nspace-efficient FM-Index into flexible database applications. SSCard first\nextends the FM-Index to support multiple strings naturally, and then organizes\nthe FM-index using a pruned suffix tree. The suffix tree structure enables\nprecise cardinality estimation for short patterns and achieves high compression\nvia a pushup operation, especially on a large alphabet with skewed character\ndistributions. Furthermore, SSCard incorporates a spline interpolation method\nwith an error bound to balance space usage and estimation accuracy. Additional\ninnovations include a bidirectional estimation algorithm and incremental update\nstrategies. Extensive experimental results in five real-life datasets show that\nSSCard outperforms both traditional methods and recent learning-based methods,\nwhich achieves an average reduction of 20% in the average q-error, 80% in the\nmaximum q-error, and 50% in the construction time, compared with second-best\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.24312v1",
    "published": "2025-05-30T07:52:06+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.24311v2",
    "title": "Equilibrium Distribution for t-Distributed Stochastic Neighbor Embedding with Generalized Kernels",
    "authors": [
      "Yi Gu"
    ],
    "abstract": "T-distributed stochastic neighbor embedding (t-SNE) is a well-known algorithm\nfor visualizing high-dimensional data by finding low-dimensional\nrepresentations. In this paper, we study the convergence of t-SNE with\ngeneralized kernels and extend the results of Auffinger and Fletcher in 2023.\nOur work starts by giving a concrete formulation of generalized input and\noutput kernels. Then we prove that under certain conditions, the t-SNE\nalgorithm converges to an equilibrium distribution for a wide range of input\nand output kernels as the number of data points diverges.",
    "pdf_url": "http://arxiv.org/pdf/2505.24311v2",
    "published": "2025-05-30T07:50:09+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.PR",
      "math.ST",
      "stat.TH",
      "60"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24310v1",
    "title": "Progressive Class-level Distillation",
    "authors": [
      "Jiayan Li",
      "Jun Li",
      "Zhourui Zhang",
      "Jianhua Xu"
    ],
    "abstract": "In knowledge distillation (KD), logit distillation (LD) aims to transfer\nclass-level knowledge from a more powerful teacher network to a small student\nmodel via accurate teacher-student alignment at the logits level. Since\nhigh-confidence object classes usually dominate the distillation process,\nlow-probability classes which also contain discriminating information are\ndownplayed in conventional methods, leading to insufficient knowledge transfer.\nTo address this issue, we propose a simple yet effective LD method termed\nProgressive Class-level Distillation (PCD). In contrast to existing methods\nwhich perform all-class ensemble distillation, our PCD approach performs\nstage-wise distillation for step-by-step knowledge transfer. More specifically,\nwe perform ranking on teacher-student logits difference for identifying\ndistillation priority from scratch, and subsequently divide the entire LD\nprocess into multiple stages. Next, bidirectional stage-wise distillation\nincorporating fine-to-coarse progressive learning and reverse coarse-to-fine\nrefinement is conducted, allowing comprehensive knowledge transfer via\nsufficient logits alignment within separate class groups in different\ndistillation stages. Extension experiments on public benchmarking datasets\ndemonstrate the superiority of our method compared to state-of-the-arts for\nboth classification and detection tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24310v1",
    "published": "2025-05-30T07:49:01+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24309v1",
    "title": "Supporting Long-term Transactions in Smart Contracts Generated from Business Process Model and Notation (BPMN) Models",
    "authors": [
      "Christian Gang Liu"
    ],
    "abstract": "To alleviate difficulties in writing smart contracts for distributed\nblockchain applications, as other research, we propose transformation of\nBusiness Process Model and Notation (BPMN) models into blockchain smart\ncontracts. Unlike other research, we use Discrete Event Hierarchical State\nMachine (DE-HSM) multi-modal modeling to identify collaborative trade\ntransactions that need to be supported by the smart contract and describe how\nthe trade transactions, that may be nested, are supported by a transaction\nmechanism. We describe algorithms to (i) identify the nested trade transactions\nand to (ii) transform the BPMN model into blockchains smart contracts that\ninclude a transaction mechanism to enforce the transactional properties for the\nidentified trade transactions. The developed proof of concept shows that our\napproach to automated transformation of BPMN models into smart contracts with\nthe support of privacy and cross-chain interoperability is feasible. The thesis\nexamines and evaluates automatically generated alternative transaction\nmechanisms to support such transactions using three use cases of varying degree\nof complexity, namely order processing, supply chain management, and a\nmulti-faceted trade use case. The research enriches the academic dialogue on\nblockchain technology and smart contracts and proposes potential avenues for\nfuture research.",
    "pdf_url": "http://arxiv.org/pdf/2505.24309v1",
    "published": "2025-05-30T07:47:06+00:00",
    "categories": [
      "cs.SE",
      "cs.DC"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24308v2",
    "title": "Inferring Obscured Cosmic Black Hole Accretion History from AGN Found by JWST/MIRI CEERS Survey",
    "authors": [
      "Cheng-An Hsieh",
      "Tomotsugu Goto",
      "Chih-Teng Ling",
      "Seong Jin Kim",
      "Tetsuya Hashimoto",
      "Tom C. -C. Chien",
      "Amos Y. -A. Chen"
    ],
    "abstract": "This study presents the black hole accretion history (BHAH) of obscured\nactive galactic nuclei (AGNs) identified from the JWST CEERS survey by Chien et\nal. (2024) using mid-infrared (MIR) SED fitting. We compute black hole\naccretion rates (BHARs) to estimate the black hole accretion density (BHAD),\n$\\rho_{L_{\\mathrm{disk}}}$, across $0 < z < 4.25$. MIR luminosity functions\n(LFs) are also constructed for these sources, modeled with modified Schechter\nand double power law forms, and corresponding BHAD, $\\rho_{\\mathrm{LF}}$, is\nderived by integrating the LFs and multiplying by the luminosity. Both\n$\\rho_{\\mathrm{LF}}$ extend to luminosities as low as $10^7 \\, L_{\\odot}$, two\norders of magnitude fainter than pre-JWST studies. Our results show that BHAD\npeaks between redshifts 1 and 3, with the peak varying by method and model, $z\n\\approx 1$--2 for $\\rho_{L_{\\mathrm{disk}}}$ and the double power law, and $z\n\\approx 2$--3 for the modified Schechter function. A scenario where AGN\nactivity peaks before cosmic star formation would challenge existing black hole\nformation theories, but our present study, based on early JWST observations,\nprovides an initial exploration of this possibility. At $z \\sim 3$,\n$\\rho_{\\mathrm{LF}}$ appears higher than X-ray estimates, suggesting that MIR\nobservations are more effective in detecting obscured AGNs missed by X-ray\nobservations. However, given the overlapping error bars, this difference\nremains within the uncertainties and requires confirmation with larger samples.\nThese findings highlight the potential of JWST surveys to enhance the\nunderstanding of co-evolution between galaxies and AGNs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24308v2",
    "published": "2025-05-30T07:44:51+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24307v1",
    "title": "Multi-Waveguide Pinching Antennas for ISAC",
    "authors": [
      "Weihao Mao",
      "Yang Lu",
      "Yanqing Xu",
      "Bo Ai",
      "Octavia A. Dobre",
      "Dusit Niyato"
    ],
    "abstract": "Recently, a novel flexible-antenna technology, called pinching antennas, has\nattracted growing academic interest. By inserting discrete dielectric\nmaterials, pinching antennas can be activated at arbitrary points along\nwaveguides, allowing for flexible customization of large-scale path loss. This\npaper investigates a multi-waveguide pinching-antenna integrated sensing and\ncommunications (ISAC) system, where transmit pinching antennas (TPAs) and\nreceive pinching antennas (RPAs) coordinate to simultaneously detect one\npotential target and serve one downlink user. We formulate a communication rate\nmaximization problem subject to radar signal-to-noise ratio (SNR) requirement,\ntransmit power budget, and the allowable movement region of the TPAs, by\njointly optimizing TPA locations and transmit beamforming design. To address\nthe non-convexity of the problem, we propose a novel fine-tuning approximation\nmethod to reformulate it into a tractable form, followed by a successive convex\napproximation (SCA)-based algorithm to obtain the solution efficiently.\nExtensive simulations validate both the system design and the proposed\nalgorithm. Results show that the proposed method achieves near-optimal\nperformance compared with the computational-intensive exhaustive search-based\nbenchmark, and pinching-antenna ISAC systems exhibit a distinct\ncommunication-sensing trade-off compared with conventional systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24307v1",
    "published": "2025-05-30T07:41:31+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24306v2",
    "title": "GridRoute: A Benchmark for LLM-Based Route Planning with Cardinal Movement in Grid Environments",
    "authors": [
      "Kechen Li",
      "Yaotian Tao",
      "Ximing Wen",
      "Quanwei Sun",
      "Zifei Gong",
      "Chang Xu",
      "Xizhe Zhang",
      "Tianbo Ji"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated their\npotential in planning and reasoning tasks, offering a flexible alternative to\nclassical pathfinding algorithms. However, most existing studies focus on LLMs'\nindependent reasoning capabilities and overlook the potential synergy between\nLLMs and traditional algorithms. To fill this gap, we propose a comprehensive\nevaluation benchmark GridRoute to assess how LLMs can take advantage of\ntraditional algorithms. We also propose a novel hybrid prompting technique\ncalled Algorithm of Thought (AoT), which introduces traditional algorithms'\nguidance into prompting. Our benchmark evaluates six LLMs ranging from 7B to\n72B parameters across various map sizes, assessing their performance in\ncorrectness, optimality, and efficiency in grid environments with varying\nsizes. Our results show that AoT significantly boosts performance across all\nmodel sizes, particularly in larger or more complex environments, suggesting a\npromising approach to addressing path planning challenges. Our code is\nopen-sourced at https://github.com/LinChance/GridRoute.",
    "pdf_url": "http://arxiv.org/pdf/2505.24306v2",
    "published": "2025-05-30T07:40:59+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24305v3",
    "title": "SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping",
    "authors": [
      "Mingxu Zhang",
      "Xiaoqi Li",
      "Jiahui Xu",
      "Kaichen Zhou",
      "Hojin Bae",
      "Yan Shen",
      "Chuyan Xiong",
      "Hao Dong"
    ],
    "abstract": "Recent advancements in 3D robotic manipulation have improved grasping of\neveryday objects, but transparent and specular materials remain challenging due\nto depth sensing limitations. While several 3D reconstruction and depth\ncompletion approaches address these challenges, they suffer from setup\ncomplexity or limited observation information utilization. To address this,\nleveraging the power of single view 3D object reconstruction approaches, we\npropose a training free framework SR3D that enables robotic grasping of\ntransparent and specular objects from a single view observation. Specifically,\ngiven single view RGB and depth images, SR3D first uses the external visual\nmodels to generate 3D reconstructed object mesh based on RGB image. Then, the\nkey idea is to determine the 3D object's pose and scale to accurately localize\nthe reconstructed object back into its original depth corrupted 3D scene.\nTherefore, we propose view matching and keypoint matching mechanisms,which\nleverage both the 2D and 3D's inherent semantic and geometric information in\nthe observation to determine the object's 3D state within the scene, thereby\nreconstructing an accurate 3D depth map for effective grasp detection.\nExperiments in both simulation and real world show the reconstruction\neffectiveness of SR3D.",
    "pdf_url": "http://arxiv.org/pdf/2505.24305v3",
    "published": "2025-05-30T07:38:46+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24304v1",
    "title": "A Perception-Based L2 Speech Intelligibility Indicator: Leveraging a Rater's Shadowing and Sequence-to-sequence Voice Conversion",
    "authors": [
      "Haopeng Geng",
      "Daisuke Saito",
      "Nobuaki Minematsu"
    ],
    "abstract": "Evaluating L2 speech intelligibility is crucial for effective\ncomputer-assisted language learning (CALL). Conventional ASR-based methods\noften focus on native-likeness, which may fail to capture the actual\nintelligibility perceived by human listeners. In contrast, our work introduces\na novel, perception based L2 speech intelligibility indicator that leverages a\nnative rater's shadowing data within a sequence-to-sequence (seq2seq) voice\nconversion framework. By integrating an alignment mechanism and acoustic\nfeature reconstruction, our approach simulates the auditory perception of\nnative listeners, identifying segments in L2 speech that are likely to cause\ncomprehension difficulties. Both objective and subjective evaluations indicate\nthat our method aligns more closely with native judgments than traditional\nASR-based metrics, offering a promising new direction for CALL systems in a\nglobal, multilingual contexts.",
    "pdf_url": "http://arxiv.org/pdf/2505.24304v1",
    "published": "2025-05-30T07:35:40+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24303v1",
    "title": "NbTiN Nanowire Resonators for Spin-Photon Coupling on Solid Neon",
    "authors": [
      "Y. Tian",
      "I. Grytsenko",
      "A. Jennings",
      "J. Wang",
      "H. Ikegami",
      "X. Zhou",
      "S. Tamate",
      "H. Terai",
      "H. Kutsuma",
      "D. Jin",
      "M. Benito",
      "E. Kawakami"
    ],
    "abstract": "Electrons floating on a solid neon exhibit long charge coherence times,\nmaking them attractive for hybrid quantum systems. When combined with\nhigh-quality, high-impedance superconducting resonators and a local magnetic\nfield gradient, this platform enables strong charge-photon and spin-charge\ncoupling -- key ingredients for scalable spin qubit architectures. In this\nwork, we fabricated NbTiN superconducting nanowire resonators and measured\ninternal quality factors around $10^5$. We successfully deposited several\nhundred-nanometer-thick layers of solid neon, followed by gradual electron\nloading. The presence of neon and electrons was confirmed via resonance\nfrequency shifts without degradation of the resonator's quality factor. These\nresults demonstrate that NbTiN superconducting nanowire resonators are\ncompatible with electrons-on-neon systems and suitable for future qubit\nexperiments. We further performed a theoretical analysis of optimized\nmicro-magnet configurations, showing that spin qubit gate fidelities exceeding\n99.99% for single-qubit and 99.9% for two-qubit operations are achievable using\nnatural neon at the charge sweet spot.",
    "pdf_url": "http://arxiv.org/pdf/2505.24303v1",
    "published": "2025-05-30T07:31:20+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24302v2",
    "title": "ScienceMeter: Tracking Scientific Knowledge Updates in Language Models",
    "authors": [
      "Yike Wang",
      "Shangbin Feng",
      "Yulia Tsvetkov",
      "Hannaneh Hajishirzi"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used to support scientific\nresearch, but their knowledge of scientific advancements can quickly become\noutdated. We introduce ScienceMeter, a new framework for evaluating scientific\nknowledge update methods over scientific knowledge spanning the past, present,\nand future. ScienceMeter defines three metrics: knowledge preservation, the\nextent to which models' understanding of previously learned papers are\npreserved; knowledge acquisition, how well scientific claims from newly\nintroduced papers are acquired; and knowledge projection, the ability of the\nupdated model to anticipate or generalize to related scientific claims that may\nemerge in the future. Using ScienceMeter, we examine the scientific knowledge\nof LLMs on claim judgment and generation tasks across a curated dataset of\n15,444 scientific papers and 30,888 scientific claims from ten domains\nincluding medicine, biology, materials science, and computer science. We\nevaluate five representative knowledge update approaches including training-\nand inference-time methods. With extensive experiments, we find that the\nbest-performing knowledge update methods can preserve only 85.9% of existing\nknowledge, acquire 71.7% of new knowledge, and project 37.7% of future\nknowledge. Inference-based methods work for larger models, whereas smaller\nmodels require training to achieve comparable performance. Cross-domain\nanalysis reveals that performance on these objectives is correlated. Even when\napplying on specialized scientific LLMs, existing knowledge update methods fail\nto achieve these objectives collectively, underscoring that developing robust\nscientific knowledge update mechanisms is both crucial and challenging.",
    "pdf_url": "http://arxiv.org/pdf/2505.24302v2",
    "published": "2025-05-30T07:28:20+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24301v1",
    "title": "Category-aware EEG image generation based on wavelet transform and contrast semantic loss",
    "authors": [
      "Enshang Zhang",
      "Zhicheng Zhang",
      "Takashi Hanakawa"
    ],
    "abstract": "Reconstructing visual stimuli from EEG signals is a crucial step in realizing\nbrain-computer interfaces. In this paper, we propose a transformer-based EEG\nsignal encoder integrating the Discrete Wavelet Transform (DWT) and the gating\nmechanism. Guided by the feature alignment and category-aware fusion losses,\nthis encoder is used to extract features related to visual stimuli from EEG\nsignals. Subsequently, with the aid of a pre-trained diffusion model, these\nfeatures are reconstructed into visual stimuli. To verify the effectiveness of\nthe model, we conducted EEG-to-image generation and classification tasks using\nthe THINGS-EEG dataset. To address the limitations of quantitative analysis at\nthe semantic level, we combined WordNet-based classification and semantic\nsimilarity metrics to propose a novel semantic-based score, emphasizing the\nability of our model to transfer neural activities into visual representations.\nExperimental results show that our model significantly improves semantic\nalignment and classification accuracy, which achieves a maximum single-subject\naccuracy of 43\\%, outperforming other state-of-the-art methods. The source code\nand supplementary material is available at\nhttps://github.com/zes0v0inn/DWT_EEG_Reconstruction/tree/main.",
    "pdf_url": "http://arxiv.org/pdf/2505.24301v1",
    "published": "2025-05-30T07:24:58+00:00",
    "categories": [
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24300v1",
    "title": "Probing quasiparticle excitations in a doped Mott insulator via Friedel oscillations",
    "authors": [
      "Anurag Banerjee",
      "Emile Pangburn",
      "Catherine Pépin",
      "Cristina Bena"
    ],
    "abstract": "In this work, we investigate impurity-induced Friedel oscillations in the\ndoped two-dimensional Hubbard model, focusing on the role of holon and doublon\nexcitations. We show that weak impurities, due to the non-fermionic nature of\nthe underlying quasiparticles, induce Friedel oscillations whose behavior is\nconsistent with an effective non-interacting theory for these quasiparticles,\nand whose wavevector reflects the violation of Luttinger's theorem. At larger\nimpurity strength, the system transitions to a phase-separated state composed\nof coexisting Mott-insulating (half-filled) and hole-rich regions. Within the\ncomposite operator framework, this phase separation arises from a competition\nbetween the kinetic energy of holons and the tendency to form tightly bound\nholon-doublon pairs. Our results offer new insights into the nature of charge\ncarriers and the emergent electronic phases in the doped Mott regime.",
    "pdf_url": "http://arxiv.org/pdf/2505.24300v1",
    "published": "2025-05-30T07:20:08+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.24299v2",
    "title": "Ion-motion simulations of a plasma-wakefield experiment at FLASHForward",
    "authors": [
      "D. Kalvik",
      "P. Drobniak",
      "F. Peña",
      "C. A. Lindstrøm",
      "J. Beinortaite",
      "L. Boulton",
      "P. Caminal",
      "J. Garland",
      "G. Loisch",
      "J. Björklund Svensson",
      "M. Thévenet",
      "S. Wesch",
      "J. Wood",
      "J. Osterhoff",
      "R. D'Arcy",
      "S. Diederichs"
    ],
    "abstract": "In plasma-based acceleration, an ultra-relativistic particle\nbunch$\\unicode{x2014}$or an intense laser beam$\\unicode{x2014}$is used to expel\nelectrons from its propagation path, forming a wake that is devoid of\nelectrons. The ions, being significantly more massive, are often assumed to be\nstationary. However, both theory and simulations suggest that any sufficiently\ndense electron bunch can trigger ion motion, and its effect must be taken into\naccount. We simulate beam-driven plasma wakefields to identify key\nfeatures$\\unicode{x2014}$such as longitudinally dependent emittance\ngrowth$\\unicode{x2014}$that could be observed in an experiment using plasma and\nbeam parameters from the FLASHForward facility at DESY.",
    "pdf_url": "http://arxiv.org/pdf/2505.24299v2",
    "published": "2025-05-30T07:18:52+00:00",
    "categories": [
      "physics.acc-ph",
      "physics.plasm-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24298v3",
    "title": "AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning",
    "authors": [
      "Wei Fu",
      "Jiaxuan Gao",
      "Xujie Shen",
      "Chen Zhu",
      "Zhiyu Mei",
      "Chuyi He",
      "Shusheng Xu",
      "Guo Wei",
      "Jun Mei",
      "Jiashu Wang",
      "Tongkai Yang",
      "Binhang Yuan",
      "Yi Wu"
    ],
    "abstract": "Reinforcement learning (RL) has become a dominant paradigm for training large\nlanguage models (LLMs), particularly for reasoning tasks. Effective RL for LLMs\nrequires massive parallelization and poses an urgent need for efficient\ntraining systems. Most existing large-scale RL systems for LLMs are\nsynchronous, alternating generation and training in a batch setting where\nrollouts in each training batch are generated by the same model. This approach\nstabilizes RL training but suffers from severe system-level inefficiency:\ngeneration must wait until the longest output in the batch is completed before\nmodel updates, resulting in GPU underutilization. We present AReaL, a fully\nasynchronous RL system that completely decouples generation from training.\nRollout workers in AReaL continuously generate new outputs without waiting,\nwhile training workers update the model whenever a batch of data is collected.\nAReaL also incorporates a collection of system-level optimizations, leading to\nsubstantially higher GPU utilization. To stabilize RL training, AReaL balances\nthe workload of rollout and training workers to control data staleness, and\nadopts a staleness-enhanced PPO variant to better handle outdated training\nsamples. Extensive experiments on math and code reasoning benchmarks show that\nAReaL achieves up to 2.77$\\times$ training speedup compared to synchronous\nsystems with the same number of GPUs and matched or improved final performance.\nThe code of AReaL is available at https://github.com/inclusionAI/AReaL/.",
    "pdf_url": "http://arxiv.org/pdf/2505.24298v3",
    "published": "2025-05-30T07:18:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00089v1",
    "title": "TRAPDOC: Deceiving LLM Users by Injecting Imperceptible Phantom Tokens into Documents",
    "authors": [
      "Hyundong Jin",
      "Sicheol Sung",
      "Shinwoo Park",
      "SeungYeop Baik",
      "Yo-Sub Han"
    ],
    "abstract": "The reasoning, writing, text-editing, and retrieval capabilities of\nproprietary large language models (LLMs) have advanced rapidly, providing users\nwith an ever-expanding set of functionalities. However, this growing utility\nhas also led to a serious societal concern: the over-reliance on LLMs. In\nparticular, users increasingly delegate tasks such as homework, assignments, or\nthe processing of sensitive documents to LLMs without meaningful engagement.\nThis form of over-reliance and misuse is emerging as a significant social\nissue. In order to mitigate these issues, we propose a method injecting\nimperceptible phantom tokens into documents, which causes LLMs to generate\noutputs that appear plausible to users but are in fact incorrect. Based on this\ntechnique, we introduce TRAPDOC, a framework designed to deceive over-reliant\nLLM users. Through empirical evaluation, we demonstrate the effectiveness of\nour framework on proprietary LLMs, comparing its impact against several\nbaselines. TRAPDOC serves as a strong foundation for promoting more responsible\nand thoughtful engagement with language models. Our code is available at\nhttps://github.com/jindong22/TrapDoc.",
    "pdf_url": "http://arxiv.org/pdf/2506.00089v1",
    "published": "2025-05-30T07:16:53+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24297v1",
    "title": "Adams-Trudinger-Moser inequalities of Adimurthi-Druet type regulated by the vanishing phenomenon and its extremals",
    "authors": [
      "Abiel Costa Macedo",
      "José Francisco de Oliveira",
      "Fábio Sodré Rocha"
    ],
    "abstract": "Let $W^{m,\\frac{n}{m}}(\\mathbb{R}^n)$ with $1\\le m < n$ be the standard\nhigher order derivative Sobolev space in the critical exponential growth\nthreshold. We investigate a new Adams-Adimurthi-Druet type inequality on the\nwhole space $\\mathbb{R}^n$ which is strongly influenced by the vanishing\nphenomenon. Specifically, we prove\n  \\begin{equation}\\nonumber\n  \\sup_{\\underset{\\|\\nabla^{m}\nu\\|_{\\frac{n}{m}}^{^{\\frac{n}{m}}}+\\|u\\|_{\\frac{n}{m}}^{\\frac{n}{m}} \\leq\n1}{u\\in W^{m,\\frac{n}{m}}(\\mathbb{R}^n)}} \\int_{\\mathbb{R}^n}\\Phi\\left(\\beta\n\\left(\\frac{1+\\alpha\\|u\\|_{\\frac{n}{m}}^{\\frac{n}{m}}}{1-\\gamma\\alpha\\|u\\|_{\\frac{n}{m}}^{\\frac{n}{m}}}\\right)^{\\frac{m}{n-m}}|u|^{\\frac{n}{n-m}}\\right)\n\\mathrm{d}x<+\\infty.\n  \\end{equation}\n  where $0\\le \\alpha<1$, $0<\\gamma<\\frac{1}{\\alpha}-1$ for $\\alpha>0$,\n$\\nabla^{m} u$ is the $m$-th order gradient for $u$, $0\\le\\beta\\le \\beta_0$,\nwith $\\beta_0$ being the Adams critical constant, and $\\Phi(t) =\n\\operatorname{e}^{t}-\\sum_{j=0}^{j_{m,n}-2}\\frac{t^{j}}{j!}$ with\n$j_{m,n}=\\min\\{j\\in\\mathbb{N}\\;:\\: j\\ge n/m\\}$. In addition, we prove that the\nconstant $\\beta_0$ is sharp.\n  In the subcritical case $\\beta<\\beta_0$, the existence and non-existence of\nextremal function are investigated for $n=2m$ and attainability is proven for\n$n=4$ and $m=2$ in the critical case $\\beta=\\beta_0$. Our method to analyze the\nextremal problem is based on blow-up analysis, a truncation argument recently\nintroduced by DelaTorre-Mancini \\cite{DelaTorre} and some ideas by Chen-Lu-Zhu\n\\cite{luluzhu20}, who studied the critical Adams inequality in $\\mathbb{R}^4$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24297v1",
    "published": "2025-05-30T07:13:23+00:00",
    "categories": [
      "math.AP",
      "math.FA",
      "35J60, 35B33, 35J91, 35J30, 31A30, 26D10"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24296v1",
    "title": "Data Fusion for Partial Identification of Causal Effects",
    "authors": [
      "Quinn Lanners",
      "Cynthia Rudin",
      "Alexander Volfovsky",
      "Harsh Parikh"
    ],
    "abstract": "Data fusion techniques integrate information from heterogeneous data sources\nto improve learning, generalization, and decision making across data sciences.\nIn causal inference, these methods leverage rich observational data to improve\ncausal effect estimation, while maintaining the trustworthiness of randomized\ncontrolled trials. Existing approaches often relax the strong no unobserved\nconfounding assumption by instead assuming exchangeability of counterfactual\noutcomes across data sources. However, when both assumptions simultaneously\nfail - a common scenario in practice - current methods cannot identify or\nestimate causal effects. We address this limitation by proposing a novel\npartial identification framework that enables researchers to answer key\nquestions such as: Is the causal effect positive or negative? and How severe\nmust assumption violations be to overturn this conclusion? Our approach\nintroduces interpretable sensitivity parameters that quantify assumption\nviolations and derives corresponding causal effect bounds. We develop doubly\nrobust estimators for these bounds and operationalize breakdown frontier\nanalysis to understand how causal conclusions change as assumption violations\nincrease. We apply our framework to the Project STAR study, which investigates\nthe effect of classroom size on students' third-grade standardized test\nperformance. Our analysis reveals that the Project STAR results are robust to\nsimultaneous violations of key assumptions, both on average and across various\nsubgroups of interest. This strengthens confidence in the study's conclusions\ndespite potential unmeasured biases in the data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24296v1",
    "published": "2025-05-30T07:13:01+00:00",
    "categories": [
      "stat.ME",
      "cs.LG",
      "econ.EM"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24295v1",
    "title": "5G RAN Slicing with Load Balanced Handovers",
    "authors": [
      "Yongzhou Chen",
      "Muhammad Taimoor Tariq",
      "Haitham Hassanieh",
      "Radhika Mittal"
    ],
    "abstract": "With increasing density of small cells in modern multi-cell deployments, a\ngiven user can have multiple options for its serving cell. The serving cell for\neach user must be carefully chosen such that the user achieves reasonably high\nchannel quality from it, and the load on each cell is well balanced. It is\nrelatively straightforward to reason about this without slicing, where all\nusers can share a global load balancing criteria set by the network operator.\nIn this paper, we identify the unique challenges that arise when balancing load\nin a multi-cell setting with 5G slicing, where users are grouped into slices,\nand each slice has its own optimization criteria, resource quota, and demand\ndistributions, making it hard to even define which cells are overloaded vs\nunderloaded. We address these challenges through our system, RadioWeaver, that\nco-designs load balancing with dynamic quota allocation for each slice and each\ncell. RadioWeaver defines a novel global load balancing criteria across slices,\nthat allows it to easily determine which cells are overloaded despite the fact\nthat different slices optimize for different criteria. Our evaluation, using\nlarge-scale trace-driven simulations and a small-scale OpenRAN testbed, show\nhow RadioWeaver achieves 16-365% better performance when compared to several\nbaselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.24295v1",
    "published": "2025-05-30T07:12:29+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24294v1",
    "title": "A Novel Discrete Memristor-Coupled Heterogeneous Dual-Neuron Model and Its Application in Multi-Scenario Image Encryption",
    "authors": [
      "Yi Zou",
      "Mengjiao Wang",
      "Xinan Zhang",
      "Herbert Ho-Ching Iu"
    ],
    "abstract": "Simulating brain functions using neural networks is an important area of\nresearch. Recently, discrete memristor-coupled neurons have attracted\nsignificant attention, as memristors effectively mimic synaptic behavior, which\nis essential for learning and memory. This highlights the biological relevance\nof such models. This study introduces a discrete memristive heterogeneous\ndual-neuron network (MHDNN). The stability of the MHDNN is analyzed with\nrespect to initial conditions and a range of neuronal parameters. Numerical\nsimulations demonstrate complex dynamical behaviors. Various neuronal firing\npatterns are investigated under different coupling strengths, and\nsynchronization phenomena between neurons are explored. The MHDNN is\nimplemented and validated on the STM32 hardware platform. An image encryption\nalgorithm based on the MHDNN is proposed, along with two hardware platforms\ntailored for multi-scenario police image encryption. These solutions enable\nreal-time and secure transmission of police data in complex environments,\nreducing hacking risks and enhancing system security.",
    "pdf_url": "http://arxiv.org/pdf/2505.24294v1",
    "published": "2025-05-30T07:12:02+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24293v2",
    "title": "Large Language Models are Locally Linear Mappings",
    "authors": [
      "James R. Golden"
    ],
    "abstract": "We demonstrate that the inference operations of several open-weight large\nlanguage models (LLMs) can be mapped to an exactly equivalent linear system for\nan input sequence without modifying the model weights or altering output\npredictions. Extending techniques from image diffusion models that exhibit\nlocal or piecewise linearity, we strategically alter the gradient computation\nwith respect to a given input sequence for a next-token prediction such that\nthe Jacobian of the model nearly exactly reproduces the forward prediction with\na linear system. We demonstrate this approach across models (Llama 3, Gemma 3,\nQwen 3, Phi 4, Mistral Ministral and OLMo 2, up to Llama 3.3 70B Q4) and show\nthrough the singular value decomposition of the detached Jacobian that these\nLLMs operate in extremely low-dimensional subspaces where many of the largest\nsingular vectors decode to concepts related to the most-likely output token.\nThis approach also allows us to examine the operation of each successive layer\n(and its attention and MLP components) as nearly-exact linear systems and\nobserve the emergence of semantic concepts. Despite their expressive power and\nglobal nonlinearity, modern LLMs can be interpreted through nearly-exact\nlocally linear decompositions that provide insights into their internal\nrepresentations and reveal interpretable semantic structures in the next-token\nprediction process.",
    "pdf_url": "http://arxiv.org/pdf/2505.24293v2",
    "published": "2025-05-30T07:08:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24292v1",
    "title": "Mind the Quote: Enabling Quotation-Aware Dialogue in LLMs via Plug-and-Play Modules",
    "authors": [
      "Yueqi Zhang",
      "Peiwen Yuan",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Xinglin Wang",
      "Jiayi Shi",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Human-AI conversation frequently relies on quoting earlier text-\"check it\nwith the formula I just highlighted\"-yet today's large language models (LLMs)\nlack an explicit mechanism for locating and exploiting such spans. We formalise\nthe challenge as span-conditioned generation, decomposing each turn into the\ndialogue history, a set of token-offset quotation spans, and an intent\nutterance. Building on this abstraction, we introduce a quotation-centric data\npipeline that automatically synthesises task-specific dialogues, verifies\nanswer correctness through multi-stage consistency checks, and yields both a\nheterogeneous training corpus and the first benchmark covering five\nrepresentative scenarios. To meet the benchmark's zero-overhead and\nparameter-efficiency requirements, we propose QuAda, a lightweight\ntraining-based method that attaches two bottleneck projections to every\nattention head, dynamically amplifying or suppressing attention to quoted spans\nat inference time while leaving the prompt unchanged and updating < 2.8% of\nbackbone weights. Experiments across models show that QuAda is suitable for all\nscenarios and generalises to unseen topics, offering an effective,\nplug-and-play solution for quotation-aware dialogue.",
    "pdf_url": "http://arxiv.org/pdf/2505.24292v1",
    "published": "2025-05-30T07:06:11+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24291v1",
    "title": "Discl-VC: Disentangled Discrete Tokens and In-Context Learning for Controllable Zero-Shot Voice Conversion",
    "authors": [
      "Kaidi Wang",
      "Wenhao Guan",
      "Ziyue Jiang",
      "Hukai Huang",
      "Peijie Chen",
      "Weijie Wu",
      "Qingyang Hong",
      "Lin Li"
    ],
    "abstract": "Currently, zero-shot voice conversion systems are capable of synthesizing the\nvoice of unseen speakers. However, most existing approaches struggle to\naccurately replicate the speaking style of the source speaker or mimic the\ndistinctive speaking style of the target speaker, thereby limiting the\ncontrollability of voice conversion. In this work, we propose Discl-VC, a novel\nvoice conversion framework that disentangles content and prosody information\nfrom self-supervised speech representations and synthesizes the target\nspeaker's voice through in-context learning with a flow matching transformer.\nTo enable precise control over the prosody of generated speech, we introduce a\nmask generative transformer that predicts discrete prosody tokens in a\nnon-autoregressive manner based on prompts. Experimental results demonstrate\nthe superior performance of Discl-VC in zero-shot voice conversion and its\nremarkable accuracy in prosody control for synthesized speech.",
    "pdf_url": "http://arxiv.org/pdf/2505.24291v1",
    "published": "2025-05-30T07:04:23+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24290v1",
    "title": "All-optical mapping of ultrafast carrier dynamics in a Dirac semimetal",
    "authors": [
      "Zhaopin Chen",
      "Camilo Granados",
      "Ido Nisim",
      "Daniel Kroeger",
      "Ofer Neufeld",
      "Marcelo F. Ciappina",
      "Michael Krüger"
    ],
    "abstract": "High-harmonic generation (HHG), the hallmark effect of attosecond science, is\na nonperturbative nonlinear process leading to the emission of high harmonic\nlight from gases and solids. In gases, extreme driving laser pulse intensities\ncan deplete the ground state, suppressing harmonic emission during the trailing\nedge of the pulse. Here, we report pronounced ultrafast depletion dynamics\nduring HHG in a gapless Dirac semimetal -- highly oriented pyrolytic graphite\n(HOPG). Remarkably, HOPG supports nonperturbative harmonic generation at laser\nintensities as low as $10^{10}$ W cm$^{-2}$, facilitated by its vanishing\nbandgap. Using two-color spectroscopy, we reveal the excitation dynamics of\nDirac electron-hole pairs as it affects the emission of harmonics during the\npresence of the driving laser pulse. Notably, valence band depletion near the\nDirac points leads to a marked suppression of interband harmonics and induces\nmeasurable temporal shifts. These observations are supported by simulations\nbased on semiconductor Bloch equations. Our findings uncover a new regime of\nstrong-field light-matter interaction in gapless solids and establish HHG as a\nsensitive, all-optical probe of ultrafast carrier dynamics, offering new\nopportunities for ultrafast optoelectronics in Dirac materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.24290v1",
    "published": "2025-05-30T07:03:40+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24289v1",
    "title": "Verifiable Weighted Secret Sharing",
    "authors": [
      "Kareem Shehata",
      "Han Fangqi",
      "Sri AravindaKrishnan Thyagarajan"
    ],
    "abstract": "Traditionally, threshold secret sharing (TSS) schemes assume all parties have\nequal weight, yet emerging systems like blockchains reveal disparities in party\ntrustworthiness, such as stake or reputation. Weighted Secret Sharing (WSS)\naddresses this by assigning varying weights to parties, ensuring security even\nif adversaries control parties with total weight at most a threshold $t$.\nCurrent WSS schemes assume honest dealers, resulting in security from only\nhonest-but-curious behaviour but not protection from malicious adversaries for\ndownstream applications. \\emph{Verifiable} secret sharing (VSS) is a well-known\ntechnique to address this, but existing VSS schemes are either tailored to TSS,\nor require additional trust assumptions. We propose the first efficient\nverifiable WSS scheme that tolerates malicious dealers and is compatible with\nthe latest CRT-based WSS~\\cite{crypto_w_weights}. Our solution uses\nBulletproofs for efficient verification and introduces new privacy-preserving\ntechniques for proving relations between committed values, which may be of\nindependent interest. Evaluation on Ethereum show up to a $100\\times$\nimprovement in communication complexity compared to the current design and\n$20\\times$ improvement compared to unweighted VSS schemes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24289v1",
    "published": "2025-05-30T07:03:33+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24288v1",
    "title": "Factorization method for near-field inverse scattering problems in elastodynamics",
    "authors": [
      "Chun Liu",
      "Guanghui Hu",
      "Tao Yin",
      "Bo Zhang"
    ],
    "abstract": "Consider a time-harmonic elastic point source incident on a bounded obstacle\nwhich is embedded in an open space filled with a homogeneous and isotropic\nelastic medium. This paper is concerned with the inverse problem of recovering\nthe location and shape of the obstacle from near-field data generated by\ninfinitely many incident point source waves at a fixed energy. The incident\npoint sources and the receivers for recording scattered signals are both\nlocated on a spherical closed surface, on which an outgoing-to-incoming\noperator is defined for facilitating the factorization of the near-field\noperator. Numerical examples in 2D are presented to show the validity and\naccuracy of the inversion algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.24288v1",
    "published": "2025-05-30T07:02:06+00:00",
    "categories": [
      "math.AP",
      "cs.NA",
      "math.NA",
      "35R30, 65N21, 35P25"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24287v1",
    "title": "EgoExOR: An Ego-Exo-Centric Operating Room Dataset for Surgical Activity Understanding",
    "authors": [
      "Ege Özsoy",
      "Arda Mamur",
      "Felix Tristram",
      "Chantal Pellegrini",
      "Magdalena Wysocki",
      "Benjamin Busam",
      "Nassir Navab"
    ],
    "abstract": "Operating rooms (ORs) demand precise coordination among surgeons, nurses, and\nequipment in a fast-paced, occlusion-heavy environment, necessitating advanced\nperception models to enhance safety and efficiency. Existing datasets either\nprovide partial egocentric views or sparse exocentric multi-view context, but\ndo not explore the comprehensive combination of both. We introduce EgoExOR, the\nfirst OR dataset and accompanying benchmark to fuse first-person and\nthird-person perspectives. Spanning 94 minutes (84,553 frames at 15 FPS) of two\nemulated spine procedures, Ultrasound-Guided Needle Insertion and Minimally\nInvasive Spine Surgery, EgoExOR integrates egocentric data (RGB, gaze, hand\ntracking, audio) from wearable glasses, exocentric RGB and depth from RGB-D\ncameras, and ultrasound imagery. Its detailed scene graph annotations, covering\n36 entities and 22 relations (568,235 triplets), enable robust modeling of\nclinical interactions, supporting tasks like action recognition and\nhuman-centric perception. We evaluate the surgical scene graph generation\nperformance of two adapted state-of-the-art models and offer a new baseline\nthat explicitly leverages EgoExOR's multimodal and multi-perspective signals.\nThis new dataset and benchmark set a new foundation for OR perception, offering\na rich, multimodal resource for next-generation clinical perception.",
    "pdf_url": "http://arxiv.org/pdf/2505.24287v1",
    "published": "2025-05-30T07:02:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24286v1",
    "title": "Testing inter-electronic interaction in lithium-like tin",
    "authors": [
      "Jonathan Morgner",
      "Vladimir A. Yerokhin",
      "Charlotte M. Konig",
      "Fabian Heiße",
      "Bingsheng Tu",
      "Tim Sailer",
      "Bastian Sikora",
      "Zoltán Harman",
      "Jose R. Crespo López-Urrutia",
      "Christoph H. Keitel",
      "Sven Sturm",
      "Klaus Blaum"
    ],
    "abstract": "Magnetic moments of bound-electron systems are a sensitive tool for testing\nfundamental interactions. $g$ factors of lithium-like ions have been rigorously\nstudied in recent years, enabling insights into the relativistic\ninter-electronic effects. Here, we present the $g$-factor measurement of\nlithium-like tin, accurate to 0.5 parts per billion, as well as \\textit{ab\ninitio} theoretical calculations that include an advanced treatment of the\ninter-electronic interaction. We further improve the prediction by using the\nexperimental result for the hydrogen-like tin $g$ factor, inferring from it the\nunknown higher-order QED effects. The observed agreement independently confirms\nthe revised theory at a previously inaccessible high nuclear charge $Z$ of 50,\nwhere QED effects are significantly larger.",
    "pdf_url": "http://arxiv.org/pdf/2505.24286v1",
    "published": "2025-05-30T07:00:46+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24285v1",
    "title": "Variational-Adiabatic Quantum Solver for Systems of Linear Equations with Warm Starts",
    "authors": [
      "Claudio Sanavio",
      "Fabio Mascherpa",
      "Alessia Marruzzo",
      "Alfonso Amendola",
      "Sauro Succi"
    ],
    "abstract": "We propose a revisited variational quantum solver for linear systems,\ndesigned to circumvent the barren plateau phenomenon by combining two key\ntechniques: adiabatic evolution and warm starts. To this end, we define an\ninitial Hamiltonian with a known ground state which is easily implemented on\nthe quantum circuit, and then \"adiabatically\" evolve the Hamiltonian by tuning\na control variable in such a way that the final ground state matches the\nsolution to the given linear system. This evolution is carried out in\nincremental steps, and the ground state at each step is found by minimizing the\nenergy using the parameter values corresponding to the previous minimum as a\nwarm start to guide the search. As a first test case, the method is applied to\nseveral linear systems obtained by discretizing a one-dimensional heat flow\nequation with different physical assumptions and grid choices. Our method\nsuccessfully and reliably improves upon the solution to the same problem as\nobtained by a conventional quantum solver, reaching very close to the global\nminimum also in the case of very shallow circuit implementations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24285v1",
    "published": "2025-05-30T07:00:14+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24284v1",
    "title": "Transaction Proximity: A Graph-Based Approach to Blockchain Fraud Prevention",
    "authors": [
      "Gordon Y. Liao",
      "Ziming Zeng",
      "Mira Belenkiy",
      "Jacob Hirshman"
    ],
    "abstract": "This paper introduces a fraud-deterrent access validation system for public\nblockchains, leveraging two complementary concepts: \"Transaction Proximity\",\nwhich measures the distance between wallets in the transaction graph, and\n\"Easily Attainable Identities (EAIs)\", wallets with direct transaction\nconnections to centralized exchanges. Recognizing the limitations of\ntraditional approaches like blocklisting (reactive, slow) and strict allow\nlisting (privacy-invasive, adoption barriers), we propose a system that\nanalyzes transaction patterns to identify wallets with close connections to\ncentralized exchanges.\n  Our directed graph analysis of the Ethereum blockchain reveals that 56% of\nlarge USDC wallets (with a lifetime maximum balance greater than \\$10,000) are\nEAI and 88% are within one transaction hop of an EAI. For transactions\nexceeding \\$2,000, 91% involve at least one EAI. Crucially, an analysis of past\nexploits shows that 83% of the known exploiter addresses are not EAIs, with 21%\nbeing more than five hops away from any regulated exchange. We present three\nimplementation approaches with varying gas cost and privacy tradeoffs,\ndemonstrating that EAI-based access control can potentially prevent most of\nthese incidents while preserving blockchain openness. Importantly, our approach\ndoes not restrict access or share personally identifiable information, but it\nprovides information for protocols to implement their own validation or risk\nscoring systems based on specific needs. This middle-ground solution enables\nprogrammatic compliance while maintaining the core values of open blockchain.",
    "pdf_url": "http://arxiv.org/pdf/2505.24284v1",
    "published": "2025-05-30T07:00:07+00:00",
    "categories": [
      "cs.CR",
      "cs.CE",
      "econ.GN",
      "q-fin.EC",
      "H.3.5; K.4.4; H.2.8"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24283v1",
    "title": "Characterizing the limiting critical Potts measures on locally regular-tree-like expander graphs",
    "authors": [
      "Hang Du",
      "Yanxin Zhou"
    ],
    "abstract": "For any integers $d,q\\ge 3$, we consider the $q$-state ferromagnetic Potts\nmodel with an external field on a sequence of expander graphs that converges to\nthe $d$-regular tree $\\mathtt{T}_d$ in the Benjamini-Schramm sense. We show\nthat along the critical line, any subsequential local weak limit of the Potts\nmeasures is a mixture of the free and wired Potts Gibbs measures on\n$\\mathtt{T}_d$. Furthermore, we show the possibility of an arbitrary extent of\nstrong phase coexistence: for any $\\alpha\\in [0,1]$, there exists a sequence of\nlocally $\\mathtt{T}_d$-like expander graphs $\\{G_n\\}$, such that the Potts\nmeasures on $\\{G_n\\}$ locally weakly converges to the\n$(\\alpha,1-\\alpha)$-mixture of the free and wired Potts Gibbs measures. Our\nresult extends results of \\cite{HJP23} which restrict to the zero-field case\nand also require $q$ to be sufficiently large relative to $d$, and results of\n\\cite{BDS23} which restrict to the even $d$ case. We also confirm the phase\ncoexistence prediction of \\cite{BDS23}, asserting that the Potts local weak\nlimit is a genuine mixture of the free and wired states in a generic setting.\nWe further characterize the subsequential local weak limits of random cluster\nmeasures on such graph sequences, for any cluster parameter $q>2$ (not\nnecessarily integer).",
    "pdf_url": "http://arxiv.org/pdf/2505.24283v1",
    "published": "2025-05-30T07:00:04+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP",
      "60K35, 82B20, 82B27"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24282v1",
    "title": "LLM-powered Query Expansion for Enhancing Boundary Prediction in Language-driven Action Localization",
    "authors": [
      "Zirui Shang",
      "Xinxiao Wu",
      "Shuo Yang"
    ],
    "abstract": "Language-driven action localization in videos requires not only semantic\nalignment between language query and video segment, but also prediction of\naction boundaries.\n  However, the language query primarily describes the main content of an action\nand usually lacks specific details of action start and end boundaries, which\nincreases the subjectivity of manual boundary annotation and leads to boundary\nuncertainty in training data.\n  In this paper, on one hand, we propose to expand the original query by\ngenerating textual descriptions of the action start and end boundaries through\nLLMs, which can provide more detailed boundary cues for localization and thus\nreduce the impact of boundary uncertainty.\n  On the other hand, to enhance the tolerance to boundary uncertainty during\ntraining, we propose to model probability scores of action boundaries by\ncalculating the semantic similarities between frames and the expanded query as\nwell as the temporal distances between frames and the annotated boundary\nframes. They can provide more consistent boundary supervision, thus improving\nthe stability of training.\n  Our method is model-agnostic and can be seamlessly and easily integrated into\nany existing models of language-driven action localization in an off-the-shelf\nmanner. Experimental results on several datasets demonstrate the effectiveness\nof our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.24282v1",
    "published": "2025-05-30T06:59:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24281v1",
    "title": "Multi-task Learning for Heterogeneous Data via Integrating Shared and Task-Specific Encodings",
    "authors": [
      "Yang Sui",
      "Qi Xu",
      "Yang Bai",
      "Annie Qu"
    ],
    "abstract": "Multi-task learning (MTL) has become an essential machine learning tool for\naddressing multiple learning tasks simultaneously and has been effectively\napplied across fields such as healthcare, marketing, and biomedical research.\nHowever, to enable efficient information sharing across tasks, it is crucial to\nleverage both shared and heterogeneous information. Despite extensive research\non MTL, various forms of heterogeneity, including distribution and posterior\nheterogeneity, present significant challenges. Existing methods often fail to\naddress these forms of heterogeneity within a unified framework. In this paper,\nwe propose a dual-encoder framework to construct a heterogeneous latent factor\nspace for each task, incorporating a task-shared encoder to capture common\ninformation across tasks and a task-specific encoder to preserve unique task\ncharacteristics. Additionally, we explore the intrinsic similarity structure of\nthe coefficients corresponding to learned latent factors, allowing for adaptive\nintegration across tasks to manage posterior heterogeneity. We introduce a\nunified algorithm that alternately learns the task-specific and task-shared\nencoders and coefficients. In theory, we investigate the excess risk bound for\nthe proposed MTL method using local Rademacher complexity and apply it to a new\nbut related task. Through simulation studies, we demonstrate that the proposed\nmethod outperforms existing data integration methods across various settings.\nFurthermore, the proposed method achieves superior predictive performance for\ntime to tumor doubling across five distinct cancer types in PDX data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24281v1",
    "published": "2025-05-30T06:58:42+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24280v1",
    "title": "A double selection entanglement distillation-based state estimator",
    "authors": [
      "Joshua Carlo A. Casapao",
      "Ananda G. Maity",
      "Naphan Benchasattabuse",
      "Michal Hajdušek",
      "Akihito Soeda",
      "Rodney Van Meter",
      "David Elkouss"
    ],
    "abstract": "With the advent of practical quantum communication networks drawing closer,\nthere is a growing need for reliable estimation protocols that can efficiently\ncharacterize quantum resources with minimum resource overhead requirement. A\nnovel approach to this problem is to integrate an estimator into an existing\nnetwork task, thereby removing the need for an additional characterization\nprotocol. In this work, we show that the measurement statistics of a double\nselection distillation protocol alone can be used to efficiently estimate the\nBell-diagonal parameters of the undistilled states, as well as the resulting\ndistilled states after additional post-processing. We also demonstrate that\nthis novel estimator outperforms the previously proposed distillation-based\nestimator in terms of resource complexity.",
    "pdf_url": "http://arxiv.org/pdf/2505.24280v1",
    "published": "2025-05-30T06:58:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24279v1",
    "title": "On the Scaling of Robustness and Effectiveness in Dense Retrieval",
    "authors": [
      "Yu-An Liu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Maarten de Rijke",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "abstract": "Robustness and Effectiveness are critical aspects of developing dense\nretrieval models for real-world applications. It is known that there is a\ntrade-off between the two. Recent work has addressed scaling laws of\neffectiveness in dense retrieval, revealing a power-law relationship between\neffectiveness and the size of models and data. Does robustness follow scaling\nlaws too? If so, can scaling improve both robustness and effectiveness\ntogether, or do they remain locked in a trade-off?\n  To answer these questions, we conduct a comprehensive experimental study. We\nfind that:(i) Robustness, including out-of-distribution and adversarial\nrobustness, also follows a scaling law.(ii) Robustness and effectiveness\nexhibit different scaling patterns, leading to significant resource costs when\njointly improving both. Given these findings, we shift to the third factor that\naffects model performance, namely the optimization strategy, beyond the model\nsize and data size. We find that: (i) By fitting different optimization\nstrategies, the joint performance of robustness and effectiveness traces out a\nPareto frontier. (ii) When the optimization strategy strays from Pareto\nefficiency, the joint performance scales in a sub-optimal direction. (iii) By\nadjusting the optimization weights to fit the Pareto efficiency, we can achieve\nPareto training, where the scaling of joint performance becomes most efficient.\nEven without requiring additional resources, Pareto training is comparable to\nthe performance of scaling resources several times under optimization\nstrategies that overly prioritize either robustness or effectiveness. Finally,\nwe demonstrate that our findings can help deploy dense retrieval models in\nreal-world applications that scale efficiently and are balanced for robustness\nand effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.24279v1",
    "published": "2025-05-30T06:57:27+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24278v1",
    "title": "Chromospheric velocities in an M3.2 flare using He I 1083.0 nm and Ca II 854.2 nm",
    "authors": [
      "C. Kuckein",
      "M. Collados",
      "A. Asensio Ramos",
      "C. J. Díaz Baso",
      "T. Felipe",
      "C. Quintero Noda",
      "L. Kleint",
      "L. Fletcher",
      "S. Matthews"
    ],
    "abstract": "We study the chromospheric LOS velocities during the GOES M3.2 flare\n(SOL2013-05-17T08:43) using simultaneous spectroscopic data of the He I 1083.0\nnm triplet and Ca II 854.2 nm line. A filament was present in the flaring area.\nThe observational data were acquired with the VTT (Tenerife, Spain) and covered\nthe pre-flare, flare, and post-flare phases. Spectroscopic inversion techniques\n(HAZEL and STiC) were applied individually to He I and Ca II lines to recover\nthe atmospheric parameters. Different inversion configurations were tested for\nCa II and two families of solutions were found to explain the red asymmetry of\nthe profiles: a redshifted emission feature or a blueshifted absorption\nfeature. These solutions could explain two different flare scenarios\n(condensation vs. evaporation). The ambiguity was solved by comparing these\nresults to the He I inferred velocities. At the front of the flare ribbon, we\nobserved a thin, short-lived blueshifted layer. This is seen in both spectral\nregions but is much more pronounced in He I, with velocities of up to -10 km/s.\nIn addition, at the front we found the coexistence of multiple He I profiles\nwithin one pixel. The central part of the ribbon is dominated by He I and Ca II\nredshifted emission profiles. A flare-loop system, visible only in He I\nabsorption and not in Ca II, becomes visible in the post-flare phase and shows\nstrong downflows at the footpoints of up to 39 km/s. In the flare, the Ca II\nline represents lower heights compared to the quiet Sun, with peak sensitivity\nshifting from $\\log \\tau \\simeq -5.2$ to $\\log \\tau \\simeq -3.5$. The inferred\nLOS velocities support a cool-upflow scenario at the leading edge of the flare.\nThe solar filament in the region remained stable. The inclusion of the He I\ntriplet in the analysis helped resolve the ambiguity between two possible\nsolutions for the plasma velocities detected in the Ca II line.",
    "pdf_url": "http://arxiv.org/pdf/2505.24278v1",
    "published": "2025-05-30T06:55:17+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24277v1",
    "title": "Does rainfall create buoyant forcing at the ocean surface?",
    "authors": [
      "Dipanjan Chaudhuri",
      "Eric D'Asaro"
    ],
    "abstract": "Rain affects the buoyancy of the upper ocean in two ways: The freshwater flux\nin rain makes the water fresher and lighter, stabilizing the ocean (a negative\nbuoyancy flux). The convective systems that produce rain are often accompanied\nby cold, dry air, often called 'cold pools', and reduced short-wave radiation,\nwhich makes the water colder and heavier, destabilizing the ocean (a positive\nbuoyancy flux). We estimate net buoyancy fluxes using in situ measurements from\ntwenty-two moored buoys in the equatorial oceans under different rainfall\ncategories. We find that buoyancy fluxes tend to destabilize the ocean during\nlight rain (0.2-4 mm/hr) and stabilize the ocean during heavy rain (>4 mm/hr).\nFurthermore, buoyancy fluxes during rain tend to be more positive at night than\nduring the day, with nighttime rain twice as likely to cause instability\ncompared to daytime rain, even at the same rainfall intensity. Average buoyancy\nfluxes across the tropics during rain can have either sign. These findings\nchallenge the common assumption that rainfall makes the ocean surface lighter\nand provide a starting point for focusing on the overall effect of\nprecipitation on the ocean.",
    "pdf_url": "http://arxiv.org/pdf/2505.24277v1",
    "published": "2025-05-30T06:53:10+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24276v1",
    "title": "Versatile Lithium Niobate Platform for Photoacoustic/Thermoelastic Gas Sensing and Photodetection",
    "authors": [
      "Haoyang Lin",
      "Wenguo Zhu",
      "Yongchun Zhong",
      "Huihui Lu",
      "Jianhui Yu",
      "Huadan Zheng"
    ],
    "abstract": "We present a lithium niobate multi-functional platform (LN-MFP) that\nintegrates photoacoustic and thermoelastic spectroscopy with photodetection on\na single chip. Utilizing LN's piezoelectric and thermoelastic properties and an\noptimized design, it achieves high sensitivity across visible to long-wave\ninfrared wavelengths. We demonstrate photoacoustic/thermoelastic gas sensing\nand photodetection using LN-MFP. The compact, integrated system with custom\npackaging and direct wire bonding reduces complexity and size, enabling\nportable, scalable sensing for environmental and diagnostic applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.24276v1",
    "published": "2025-05-30T06:53:08+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.24275v1",
    "title": "GradPower: Powering Gradients for Faster Language Model Pre-Training",
    "authors": [
      "Mingze Wang",
      "Jinbo Wang",
      "Jiaqi Zhang",
      "Wei Wang",
      "Peng Pei",
      "Xunliang Cai",
      "Weinan E",
      "Lei Wu"
    ],
    "abstract": "We propose GradPower, a lightweight gradient-transformation technique for\naccelerating language model pre-training. Given a gradient vector $g=(g_i)_i$,\nGradPower first applies the elementwise sign-power transformation:\n$\\varphi_p(g)=({\\rm sign}(g_i)|g_i|^p)_{i}$ for a fixed $p>0$, and then feeds\nthe transformed gradient into a base optimizer. Notably, GradPower requires\nonly a single-line code change and no modifications to the base optimizer's\ninternal logic, including the hyperparameters. When applied to Adam (termed\nAdamPower), GradPower consistently achieves lower terminal loss across diverse\narchitectures (LLaMA, Qwen2MoE), parameter scales (66M to 2B), datasets (C4,\nOpenWebText), and learning-rate schedules (cosine, warmup-stable-decay). The\nmost pronounced gains are observed when training modern mixture-of-experts\nmodels with warmup-stable-decay schedules. GradPower also integrates seamlessly\nwith other state-of-the-art optimizers, such as Muon, yielding further\nimprovements. Finally, we provide theoretical analyses that reveal the\nunderlying mechanism of GradPower and highlights the influence of gradient\nnoise.",
    "pdf_url": "http://arxiv.org/pdf/2505.24275v1",
    "published": "2025-05-30T06:49:57+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24274v1",
    "title": "MGS3: A Multi-Granularity Self-Supervised Code Search Framework",
    "authors": [
      "Rui Li",
      "Junfeng Kang",
      "Qi Liu",
      "Liyang He",
      "Zheng Zhang",
      "Yunhao Sha",
      "Linbo Zhu",
      "Zhenya Huang"
    ],
    "abstract": "In the pursuit of enhancing software reusability and developer productivity,\ncode search has emerged as a key area, aimed at retrieving code snippets\nrelevant to functionalities based on natural language queries. Despite\nsignificant progress in self-supervised code pre-training utilizing the vast\namount of code data in repositories, existing methods have primarily focused on\nleveraging contrastive learning to align natural language with function-level\ncode snippets. These studies have overlooked the abundance of fine-grained\n(such as block-level and statement-level) code snippets prevalent within the\nfunction-level code snippets, which results in suboptimal performance across\nall levels of granularity. To address this problem, we first construct a\nmulti-granularity code search dataset called MGCodeSearchNet, which contains\n536K+ pairs of natural language and code snippets. Subsequently, we introduce a\nnovel Multi-Granularity Self-Supervised contrastive learning code Search\nframework (MGS$^{3}$}). First, MGS$^{3}$ features a Hierarchical\nMulti-Granularity Representation module (HMGR), which leverages syntactic\nstructural relationships for hierarchical representation and aggregates\nfine-grained information into coarser-grained representations. Then, during the\ncontrastive learning phase, we endeavor to construct positive samples of the\nsame granularity for fine-grained code, and introduce in-function negative\nsamples for fine-grained code. Finally, we conduct extensive experiments on\ncode search benchmarks across various granularities, demonstrating that the\nframework exhibits outstanding performance in code search tasks of multiple\ngranularities. These experiments also showcase its model-agnostic nature and\ncompatibility with existing pre-trained code representation models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24274v1",
    "published": "2025-05-30T06:49:39+00:00",
    "categories": [
      "cs.SE",
      "cs.IR"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24273v1",
    "title": "How Much Backtracking is Enough? Exploring the Interplay of SFT and RL in Enhancing LLM Reasoning",
    "authors": [
      "Hongyi James Cai",
      "Junlin Wang",
      "Xiaoyin Chen",
      "Bhuwan Dhingra"
    ],
    "abstract": "Recent breakthroughs in large language models (LLMs) have effectively\nimproved their reasoning abilities, particularly on mathematical and logical\nproblems that have verifiable answers, through techniques such as supervised\nfinetuning (SFT) and reinforcement learning (RL). Prior research indicates that\nRL effectively internalizes search strategies, enabling long chain-of-thought\n(CoT) reasoning, with backtracking emerging naturally as a learned capability.\nHowever, the precise benefits of backtracking, specifically, how significantly\nit contributes to reasoning improvements and the optimal extent of its use,\nremain poorly understood. In this work, we systematically investigate the\ndynamics between SFT and RL on eight reasoning tasks: Countdown, Sudoku, Arc\n1D, Geometry, Color Cube Rotation, List Functions, Zebra Puzzles, and Self\nReference. Our findings highlight that short CoT sequences used in SFT as a\nwarm-up do have moderate contribution to RL training, compared with cold-start\nRL; however such contribution diminishes when tasks become increasingly\ndifficult. Motivated by this observation, we construct synthetic datasets\nvarying systematically in the number of backtracking steps and conduct\ncontrolled experiments to isolate the influence of either the correctness\n(content) or the structure (i.e., backtrack frequency). We find that (1) longer\nCoT with backtracks generally induce better and more stable RL training, (2)\nmore challenging problems with larger search space tend to need higher numbers\nof backtracks during the SFT stage. Additionally, we demonstrate through\nexperiments on distilled data that RL training is largely unaffected by the\ncorrectness of long CoT sequences, suggesting that RL prioritizes structural\npatterns over content correctness. Collectively, our results offer practical\ninsights into designing optimal training strategies to effectively scale\nreasoning in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24273v1",
    "published": "2025-05-30T06:49:00+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24272v1",
    "title": "$g$ Factor of Boron-like Tin",
    "authors": [
      "J. Morgner",
      "B. Tu",
      "M. Moretti",
      "C. M. König",
      "F. Heiße",
      "T. Sailer",
      "V. A. Yerokhin",
      "B. Sikora",
      "N. S. Oreshkina",
      "Z. Harman",
      "C. H. Keitel",
      "S. Sturm",
      "K. Blaum"
    ],
    "abstract": "In the ALPHATRAP experiment, the $g$ factor of boron-like\n$^{118}\\mathrm{Sn}^{45+}$ has been measured with a $0.5$ parts-per-billion\nuncertainty. This is the first high-precision measurement of a heavy boron-like\n$g$ factor. The measured value of $0.644\\,703\\,826\\,5(4)$ is consistent with\nthe presented \\textit{ab initio} state-of-the-art theory calculations, which\npredict a value of $0.644\\,702\\,9(8)$. So far, the only boron-like $g$ factor\nmeasured with high precision has been $^{40}\\mathrm{Ar}^{13+}$. The measurement\npresented here therefore tests quantum electrodynamics as well as many-electron\ninteractions at much higher $Z$. Furthermore, we discuss the potential for an\nindependent determination of the fine-structure constant $\\alpha$, which can be\nachieved with a specific difference of $g$ factors, combining the presented\nresults with the recent electron $g$-factor measurement of hydrogen-like tin.",
    "pdf_url": "http://arxiv.org/pdf/2505.24272v1",
    "published": "2025-05-30T06:48:38+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24271v1",
    "title": "Revisiting Bourgain's probabilistic construction of solutions to the 2-$d$ cubic NLS",
    "authors": [
      "Tadahiro Oh",
      "Yuzhao Wang"
    ],
    "abstract": "In a seminal paper (1996), Bourgain proved invariance of the Gibbs measure\nfor the defocusing cubic nonlinear Schr\\\"odinger equation on the\ntwo-dimensional torus by constructing local-in-time solutions in a\nprobabilistic manner. In this note, we revisit and streamline his argument,\nusing the random tensor estimate developed by Deng, Nahmod, and Yue (2022).",
    "pdf_url": "http://arxiv.org/pdf/2505.24271v1",
    "published": "2025-05-30T06:48:06+00:00",
    "categories": [
      "math.AP",
      "math.PR",
      "35Q55, 60H15"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.11063v1",
    "title": "Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation",
    "authors": [
      "Jiayu Yao",
      "Shenghua Liu",
      "Yiwei Wang",
      "Lingrui Mei",
      "Baolong Bi",
      "Yuyao Ge",
      "Zhecheng Li",
      "Xueqi Cheng"
    ],
    "abstract": "Multimodal Retrieval-Augmented Generation (RAG) systems have become essential\nin knowledge-intensive and open-domain tasks. As retrieval complexity\nincreases, ensuring the robustness of these systems is critical. However,\ncurrent RAG models are highly sensitive to the order in which evidence is\npresented, often resulting in unstable performance and biased reasoning,\nparticularly as the number of retrieved items or modality diversity grows. This\nraises a central question: How does the position of retrieved evidence affect\nmultimodal RAG performance? To answer this, we present the first comprehensive\nstudy of position bias in multimodal RAG systems. Through controlled\nexperiments across text-only, image-only, and mixed-modality tasks, we observe\na consistent U-shaped accuracy curve with respect to evidence position. To\nquantify this bias, we introduce the Position Sensitivity Index ($PSI_p$) and\ndevelop a visualization framework to trace attention allocation patterns across\ndecoder layers. Our results reveal that multimodal interactions intensify\nposition bias compared to unimodal settings, and that this bias increases\nlogarithmically with retrieval range. These findings offer both theoretical and\nempirical foundations for position-aware analysis in RAG, highlighting the need\nfor evidence reordering or debiasing strategies to build more reliable and\nequitable generation systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.11063v1",
    "published": "2025-05-30T06:48:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24270v1",
    "title": "Nonlinear PDEs with modulated dispersion IV: normal form approach and unconditional uniqueness",
    "authors": [
      "Massimiliano Gubinelli",
      "Guopeng Li",
      "Jiawei Li",
      "Tadahiro Oh"
    ],
    "abstract": "We study the modulated Korteweg-de~Vries equation (KdV) on the circle with a\ntime non-homogeneous modulation acting on the linear dispersion term. By\nadapting the normal form approach to the modulated setting, we prove sharp\nunconditional uniqueness of solutions to the modulated KdV in $L^2(\\mathbb T)$\nif a modulation is sufficiently irregular. For example, this result implies\nthat if the modulation is given by a sample path of a fractional Brownian\nmotion with Hurst index $0 < H < \\frac 25$, the modulated KdV on the circle is\nunconditionally well-posed in $L^2(\\mathbb T)$. Our normal form approach\nprovides the construction of solutions to the modulated KdV (and the associated\nnonlinear Young integral) {\\it without} assuming any positive regularity in\ntime. As an interesting byproduct of our normal form approach, we extend the\nconstruction of the nonlinear Young integral to a much larger class of\nfunctions, and obtain an improved Euler approximation scheme as compared to the\nclassical sewing lemma approach. We also establish analogous sharp\nunconditional uniqueness results for the modulated Benjamin-Ono equation and\nthe modulated derivative nonlinear Schr\\\"odinger equation (NLS) with a\nquadratic nonlinearity. In the appendix, we prove sharp unconditional\nuniqueness of the cubic modulated NLS on the circle in $H^{\\frac 16}(\\mathbb\nT)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24270v1",
    "published": "2025-05-30T06:47:59+00:00",
    "categories": [
      "math.AP",
      "cs.NA",
      "math.NA",
      "math.PR",
      "35Q53, 35Q35, 35Q55, 60L20, 65M12, 65M15"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24269v2",
    "title": "INSIGHT: A Survey of In-Network Systems for Intelligent, High-Efficiency AI and Topology Optimization",
    "authors": [
      "Aleksandr Algazinov",
      "Joydeep Chandra",
      "Matt Laing"
    ],
    "abstract": "In-network computation represents a transformative approach to addressing the\nescalating demands of Artificial Intelligence (AI) workloads on network\ninfrastructure. By leveraging the processing capabilities of network devices\nsuch as switches, routers, and Network Interface Cards (NICs), this paradigm\nenables AI computations to be performed directly within the network fabric,\nsignificantly reducing latency, enhancing throughput, and optimizing resource\nutilization. This paper provides a comprehensive analysis of optimizing\nin-network computation for AI, exploring the evolution of programmable network\narchitectures, such as Software-Defined Networking (SDN) and Programmable Data\nPlanes (PDPs), and their convergence with AI. It examines methodologies for\nmapping AI models onto resource-constrained network devices, addressing\nchallenges like limited memory and computational capabilities through efficient\nalgorithm design and model compression techniques. The paper also highlights\nadvancements in distributed learning, particularly in-network aggregation, and\nthe potential of federated learning to enhance privacy and scalability.\nFrameworks like Planter and Quark are discussed for simplifying development,\nalongside key applications such as intelligent network monitoring, intrusion\ndetection, traffic management, and Edge AI. Future research directions,\nincluding runtime programmability, standardized benchmarks, and new\napplications paradigms, are proposed to advance this rapidly evolving field.\nThis survey underscores the potential of in-network AI to create intelligent,\nefficient, and responsive networks capable of meeting the demands of\nnext-generation AI applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.24269v2",
    "published": "2025-05-30T06:47:55+00:00",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24268v1",
    "title": "Heterodyne detection of low-frequency fields via Rydberg EIT with phase demodulation",
    "authors": [
      "Shenchao Jin",
      "Xiayang Fan",
      "Xin Wang",
      "Yi Song",
      "Yuan Sun"
    ],
    "abstract": "Recently, the rapid progress of quantum sensing research reveals that the\nRydberg atoms have great potentials in becoming high-precision centimeter-scale\nantenna of low-frequency fields. In order to facilitate efficient and reliable\ndetection of low-frequency fields via Rydberg atoms, we design, implement and\nanalyze a special but low-cost and scalable method based on heterodyning\nprocesses under the condition of electromagnetically induced transparency (EIT)\nembedded in typical two-photon ground-Rydberg transition. Instead of relying on\nobserving changes in absorption of light by Rydberg atoms, our method focuses\non the phase modulation effect on the probe laser induced by the low-frequency\nfields via the Rydberg EIT mechanism and utilizes a demodulation process to\naccurately retrieve the signal. The general principles of our method apply to\nboth electric and magnetic fields and it is even possible to realize the\ncombination of both functionalities in the same apparatus. In particular, we\nexperimentally demonstrate the full cycle of operations with respect to both\ncases. In the measurement of low-frequency electric fields, we discover that\nthe Rydberg dipole-dipole interaction among atoms induce linear superposition\nof Rydberg states with different angular momentum that generates a first-order\nresponse corresponding to the signature of linear Stark effect. As the Rydberg\natoms have excellent coupling strengths with electric fields, our results\nindicate that our method can hopefully reach high-precision performance for\npractical tasks in the future.",
    "pdf_url": "http://arxiv.org/pdf/2505.24268v1",
    "published": "2025-05-30T06:46:44+00:00",
    "categories": [
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24267v1",
    "title": "MUSE: Model-Agnostic Tabular Watermarking via Multi-Sample Selection",
    "authors": [
      "Liancheng Fang",
      "Aiwei Liu",
      "Henry Peng Zou",
      "Yankai Chen",
      "Hengrui Zhang",
      "Zhongfen Deng",
      "Philip S. Yu"
    ],
    "abstract": "We introduce MUSE, a watermarking algorithm for tabular generative models.\nPrevious approaches typically leverage DDIM invertibility to watermark tabular\ndiffusion models, but tabular diffusion models exhibit significantly poorer\ninvertibility compared to other modalities, compromising performance.\nSimultaneously, tabular diffusion models require substantially less computation\nthan other modalities, enabling a multi-sample selection approach to tabular\ngenerative model watermarking. MUSE embeds watermarks by generating multiple\ncandidate samples and selecting one based on a specialized scoring function,\nwithout relying on model invertibility. Our theoretical analysis establishes\nthe relationship between watermark detectability, candidate count, and dataset\nsize, allowing precise calibration of watermarking strength. Extensive\nexperiments demonstrate that MUSE achieves state-of-the-art watermark\ndetectability and robustness against various attacks while maintaining data\nquality, and remains compatible with any tabular generative model supporting\nrepeated sampling, effectively addressing key challenges in tabular data\nwatermarking. Specifically, it reduces the distortion rates on fidelity metrics\nby 81-89%, while achieving a 1.0 TPR@0.1%FPR detection rate. Implementation of\nMUSE can be found at https://github.com/fangliancheng/MUSE.",
    "pdf_url": "http://arxiv.org/pdf/2505.24267v1",
    "published": "2025-05-30T06:45:31+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.13771v1",
    "title": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization",
    "authors": [
      "Banseok Lee",
      "Dongkyu Kim",
      "Youngcheon You",
      "Youngmin Kim"
    ],
    "abstract": "Deploying large language models (LLMs) often faces challenges from\nsubstantial memory and computational costs. Quantization offers a solution, yet\nperformance degradation in the sub-1-bit regime remains particularly difficult.\nThis paper introduces LittleBit, a novel method for extreme LLM compression. It\ntargets levels like 0.1 bits per weight (BPW), achieving nearly 31$\\times$\nmemory reduction, e.g., Llama2-13B to under 0.9 GB. LittleBit represents\nweights in a low-rank form using latent matrix factorization, subsequently\nbinarizing these factors. To counteract information loss from this extreme\nprecision, it integrates a multi-scale compensation mechanism. This includes\nrow, column, and an additional latent dimension that learns per-rank\nimportance. Two key contributions enable effective training: Dual\nSign-Value-Independent Decomposition (Dual-SVID) for stable quantization-aware\ntraining (QAT) initialization, and integrated Residual Compensation to mitigate\nerrors. Extensive experiments confirm LittleBit's superiority in sub-1-bit\nquantization: e.g., its 0.1 BPW performance on Llama2-7B surpasses the leading\nmethod's 0.7 BPW. This establishes a superior size-performance trade-off, with\nkernel-level benchmarks indicating potential for a 5$\\times$ speedup compared\nto FP16. LittleBit paves the way for deploying powerful LLMs in\nresource-constrained environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.13771v1",
    "published": "2025-05-30T06:43:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24266v2",
    "title": "SignBot: Learning Human-to-Humanoid Sign Language Interaction",
    "authors": [
      "Guanren Qiao",
      "Sixu Lin",
      "Ronglai Zuo",
      "Zhizheng Wu",
      "Kui Jia",
      "Guiliang Liu"
    ],
    "abstract": "Sign language is a natural and visual form of language that uses movements\nand expressions to convey meaning, serving as a crucial means of communication\nfor individuals who are deaf or hard-of-hearing (DHH). However, the number of\npeople proficient in sign language remains limited, highlighting the need for\ntechnological advancements to bridge communication gaps and foster interactions\nwith minorities. Based on recent advancements in embodied humanoid robots, we\npropose SignBot, a novel framework for human-robot sign language interaction.\nSignBot integrates a cerebellum-inspired motion control component and a\ncerebral-oriented module for comprehension and interaction. Specifically,\nSignBot consists of: 1) Motion Retargeting, which converts human sign language\ndatasets into robot-compatible kinematics; 2) Motion Control, which leverages a\nlearning-based paradigm to develop a robust humanoid control policy for\ntracking sign language gestures; and 3) Generative Interaction, which\nincorporates translator, responser, and generator of sign language, thereby\nenabling natural and effective communication between robots and humans.\nSimulation and real-world experimental results demonstrate that SignBot can\neffectively facilitate human-robot interaction and perform sign language\nmotions with diverse robots and datasets. SignBot represents a significant\nadvancement in automatic sign language interaction on embodied humanoid robot\nplatforms, providing a promising solution to improve communication\naccessibility for the DHH community.",
    "pdf_url": "http://arxiv.org/pdf/2505.24266v2",
    "published": "2025-05-30T06:42:09+00:00",
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24265v1",
    "title": "R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning",
    "authors": [
      "Harsh Goel",
      "Mohammad Omama",
      "Behdad Chalaki",
      "Vaishnav Tadiparthi",
      "Ehsan Moradi Pari",
      "Sandeep Chinchali"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) has achieved significant progress\nin large-scale traffic control, autonomous vehicles, and robotics. Drawing\ninspiration from biological systems where roles naturally emerge to enable\ncoordination, role-based MARL methods have been proposed to enhance cooperation\nlearning for complex tasks. However, existing methods exclusively derive roles\nfrom an agent's past experience during training, neglecting their influence on\nits future trajectories. This paper introduces a key insight: an agent's role\nshould shape its future behavior to enable effective coordination. Hence, we\npropose Role Discovery and Diversity through Dynamics Models (R3DM), a novel\nrole-based MARL framework that learns emergent roles by maximizing the mutual\ninformation between agents' roles, observed trajectories, and expected future\nbehaviors. R3DM optimizes the proposed objective through contrastive learning\non past trajectories to first derive intermediate roles that shape intrinsic\nrewards to promote diversity in future behaviors across different roles through\na learned dynamics model. Benchmarking on SMAC and SMACv2 environments\ndemonstrates that R3DM outperforms state-of-the-art MARL approaches, improving\nmulti-agent coordination to increase win rates by up to 20%.",
    "pdf_url": "http://arxiv.org/pdf/2505.24265v1",
    "published": "2025-05-30T06:40:19+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24264v1",
    "title": "Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations",
    "authors": [
      "Xin Quan",
      "Marco Valentino",
      "Louise A. Dennis",
      "André Freitas"
    ],
    "abstract": "Natural language explanations play a fundamental role in Natural Language\nInference (NLI) by revealing how premises logically entail hypotheses. Recent\nwork has shown that the interaction of large language models (LLMs) with\ntheorem provers (TPs) can help verify and improve the validity of NLI\nexplanations. However, TPs require translating natural language into\nmachine-verifiable formal representations, a process that introduces the risk\nof semantic information loss and unfaithful interpretation, an issue compounded\nby LLMs' challenges in capturing critical logical structures with sufficient\nprecision. Moreover, LLMs are still limited in their capacity for rigorous and\nrobust proof construction within formal verification frameworks. To mitigate\nissues related to faithfulness and robustness, this paper investigates\nstrategies to (1) alleviate semantic loss during autoformalisation, (2)\nefficiently identify and correct syntactic errors in logical representations,\n(3) explicitly use logical expressions to guide LLMs in generating structured\nproof sketches, and (4) increase LLMs' capacity of interpreting TP's feedback\nfor iterative refinement. Our empirical results on e-SNLI, QASC and WorldTree\nusing different LLMs demonstrate that the proposed strategies yield significant\nimprovements in autoformalisation (+18.46%, +34.2%, +39.77%) and explanation\nrefinement (+29.5%, +51.5%, +41.25%) over the state-of-the-art model. Moreover,\nwe show that specific interventions on the hybrid LLM-TP architecture can\nsubstantially improve efficiency, drastically reducing the number of iterations\nrequired for successful verification.",
    "pdf_url": "http://arxiv.org/pdf/2505.24264v1",
    "published": "2025-05-30T06:38:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24263v1",
    "title": "Simulating Training Data Leakage in Multiple-Choice Benchmarks for LLM Evaluation",
    "authors": [
      "Naila Shafirni Hidayat",
      "Muhammad Dehan Al Kautsar",
      "Alfan Farizki Wicaksono",
      "Fajri Koto"
    ],
    "abstract": "The performance of large language models (LLMs) continues to improve, as\nreflected in rising scores on standard benchmarks. However, the lack of\ntransparency around training data raises concerns about potential overlap with\nevaluation sets and the fairness of reported results. Although prior work has\nproposed methods for detecting data leakage, these approaches primarily focus\non identifying outliers and have not been evaluated under controlled simulated\nleakage conditions. In this work, we compare existing leakage detection\ntechniques, namely permutation and n-gram-based methods, under a continual\npretraining setup that simulates real-world leakage scenarios, and additionally\nexplore a lightweight method we call semi-half question. Although semi-half\noffers a low-cost alternative, our analysis shows that the n-gram method\nconsistently achieves the highest F1-score. We also refine these techniques to\nsupport instance-level detection and reduce computational overhead. Leveraging\nthe best-performing method, we create cleaned versions of MMLU and HellaSwag,\nand re-evaluate several LLMs. Our findings present a practical path toward more\nreliable and transparent evaluations, and we recommend contamination checks as\na standard step before releasing benchmark results.",
    "pdf_url": "http://arxiv.org/pdf/2505.24263v1",
    "published": "2025-05-30T06:37:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24262v1",
    "title": "On Fairness of Task Arithmetic: The Role of Task Vectors",
    "authors": [
      "Hiroki Naganuma",
      "Kotaro Yoshida",
      "Laura Gomezjurado Gonzalez",
      "Takafumi Horie",
      "Yuji Naraki",
      "Ryotaro Shimizu"
    ],
    "abstract": "Model editing techniques, particularly task arithmetic using task vectors,\nhave shown promise in efficiently modifying pre-trained models through\narithmetic operations like task addition and negation. Despite computational\nadvantages, these methods may inadvertently affect model fairness, creating\nrisks in sensitive applications like hate speech detection. However, the\nfairness implications of task arithmetic remain largely unexplored, presenting\na critical gap in the existing literature. We systematically examine how\nmanipulating task vectors affects fairness metrics, including Demographic\nParity and Equalized Odds. To rigorously assess these effects, we benchmark\ntask arithmetic against full fine-tuning, a costly but widely used baseline,\nand Low-Rank Adaptation (LoRA), a prevalent parameter-efficient fine-tuning\nmethod. Additionally, we explore merging task vectors from models fine-tuned on\ndemographic subgroups vulnerable to hate speech, investigating whether fairness\noutcomes can be controlled by adjusting task vector coefficients, potentially\nenabling tailored model behavior. Our results offer novel insights into the\nfairness implications of model editing and establish a foundation for\nfairness-aware and responsible model editing practices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24262v1",
    "published": "2025-05-30T06:34:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24261v1",
    "title": "Taming Hyperparameter Sensitivity in Data Attribution: Practical Selection Without Costly Retraining",
    "authors": [
      "Weiyi Wang",
      "Junwei Deng",
      "Yuzheng Hu",
      "Shiyuan Zhang",
      "Xirui Jiang",
      "Runting Zhang",
      "Han Zhao",
      "Jiaqi W. Ma"
    ],
    "abstract": "Data attribution methods, which quantify the influence of individual training\ndata points on a machine learning model, have gained increasing popularity in\ndata-centric applications in modern AI. Despite a recent surge of new methods\ndeveloped in this space, the impact of hyperparameter tuning in these methods\nremains under-explored. In this work, we present the first large-scale\nempirical study to understand the hyperparameter sensitivity of common data\nattribution methods. Our results show that most methods are indeed sensitive to\ncertain key hyperparameters. However, unlike typical machine learning\nalgorithms -- whose hyperparameters can be tuned using computationally-cheap\nvalidation metrics -- evaluating data attribution performance often requires\nretraining models on subsets of training data, making such metrics\nprohibitively costly for hyperparameter tuning. This poses a critical open\nchallenge for the practical application of data attribution methods. To address\nthis challenge, we advocate for better theoretical understandings of\nhyperparameter behavior to inform efficient tuning strategies. As a case study,\nwe provide a theoretical analysis of the regularization term that is critical\nin many variants of influence function methods. Building on this analysis, we\npropose a lightweight procedure for selecting the regularization value without\nmodel retraining, and validate its effectiveness across a range of standard\ndata attribution benchmarks. Overall, our study identifies a fundamental yet\noverlooked challenge in the practical application of data attribution, and\nhighlights the importance of careful discussion on hyperparameter selection in\nfuture method development.",
    "pdf_url": "http://arxiv.org/pdf/2505.24261v1",
    "published": "2025-05-30T06:33:56+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24260v1",
    "title": "Generative AI for Urban Design: A Stepwise Approach Integrating Human Expertise with Multimodal Diffusion Models",
    "authors": [
      "Mingyi He",
      "Yuebing Liang",
      "Shenhao Wang",
      "Yunhan Zheng",
      "Qingyi Wang",
      "Dingyi Zhuang",
      "Li Tian",
      "Jinhua Zhao"
    ],
    "abstract": "Urban design is a multifaceted process that demands careful consideration of\nsite-specific constraints and collaboration among diverse professionals and\nstakeholders. The advent of generative artificial intelligence (GenAI) offers\ntransformative potential by improving the efficiency of design generation and\nfacilitating the communication of design ideas. However, most existing\napproaches are not well integrated with human design workflows. They often\nfollow end-to-end pipelines with limited control, overlooking the iterative\nnature of real-world design. This study proposes a stepwise generative urban\ndesign framework that integrates multimodal diffusion models with human\nexpertise to enable more adaptive and controllable design processes. Instead of\ngenerating design outcomes in a single end-to-end process, the framework\ndivides the process into three key stages aligned with established urban design\nworkflows: (1) road network and land use planning, (2) building layout\nplanning, and (3) detailed planning and rendering. At each stage, multimodal\ndiffusion models generate preliminary designs based on textual prompts and\nimage-based constraints, which can then be reviewed and refined by human\ndesigners. We design an evaluation framework to assess the fidelity,\ncompliance, and diversity of the generated designs. Experiments using data from\nChicago and New York City demonstrate that our framework outperforms baseline\nmodels and end-to-end approaches across all three dimensions. This study\nunderscores the benefits of multimodal diffusion models and stepwise generation\nin preserving human control and facilitating iterative refinements, laying the\ngroundwork for human-AI interaction in urban design solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24260v1",
    "published": "2025-05-30T06:33:48+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24259v1",
    "title": "Partially-shared Imaging Regression on Integrating Heterogeneous Brain-Cognition Associations across Alzheimer's Diagnoses",
    "authors": [
      "Yang Sui",
      "Qi Xu",
      "Ting Li",
      "Yang Bai",
      "Annie Qu"
    ],
    "abstract": "This paper is motivated by the heterogeneous associations among demographic\ncovariates, imaging data, and cognitive performances across different\ndiagnostic groups within the Alzheimer's Disease Neuroimaging Initiative (ADNI)\nstudy. We propose a novel PArtially-shared Imaging Regression (PAIR) model with\nsmooth spatial component integration to capture heterogeneous imaging\ncoefficients across multiple data sources. The model assumes that each imaging\ncoefficient can be represented as a weighted combination of a set of smooth\nspatial components. Additionally, we apply a Total Variation (TV) penalty on\neach component to capture complex spatial patterns and introduce a Selective\nIntegration Penalty (SIP) to adaptively learn the degree of partial-sharing\namong imaging coefficients. Applied to ADNI data, PAIR significantly improves\npredictive performance and uncovers distinct heterogeneous relationships. After\nadjusting for demographic covariates, hippocampal imaging minimally contributes\nto cognitive scores in the cognitively normal (CN) group but substantially in\nthe cognitively impaired (CI) group. Furthermore, the effects of demographic\ncovariates on cognitive scores remain stable among CN participants yet change\nnotably for CI participants after imaging adjustment, suggesting hippocampal\nstructural modulation. Imaging coefficient analysis reveals weak hippocampal\nsignals in CN subjects, whereas prominent positive signals in CA1, CA3, and\npresubiculum subfields characterize the CI group. These analyses facilitate\nfurther investigation into functional mechanisms underlying Alzheimer's disease\n(AD) progression.",
    "pdf_url": "http://arxiv.org/pdf/2505.24259v1",
    "published": "2025-05-30T06:33:28+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.24258v1",
    "title": "FABLE: A Novel Data-Flow Analysis Benchmark on Procedural Text for Large Language Model Evaluation",
    "authors": [
      "Vishal Pallagani",
      "Nitin Gupta",
      "John Aydin",
      "Biplav Srivastava"
    ],
    "abstract": "Understanding how data moves, transforms, and persists, known as data flow,\nis fundamental to reasoning in procedural tasks. Despite their fluency in\nnatural and programming languages, large language models (LLMs), although\nincreasingly being applied to decisions with procedural tasks, have not been\nsystematically evaluated for their ability to perform data-flow reasoning. We\nintroduce FABLE, an extensible benchmark designed to assess LLMs' understanding\nof data flow using structured, procedural text. FABLE adapts eight classical\ndata-flow analyses from software engineering: reaching definitions, very busy\nexpressions, available expressions, live variable analysis, interval analysis,\ntype-state analysis, taint analysis, and concurrency analysis. These analyses\nare instantiated across three real-world domains: cooking recipes, travel\nroutes, and automated plans. The benchmark includes 2,400 question-answer\npairs, with 100 examples for each domain-analysis combination. We evaluate\nthree types of LLMs: a reasoning-focused model (DeepSeek-R1 8B), a\ngeneral-purpose model (LLaMA 3.1 8B), and a code-specific model (Granite Code\n8B). Each model is tested using majority voting over five sampled completions\nper prompt. Results show that the reasoning model achieves higher accuracy, but\nat the cost of over 20 times slower inference compared to the other models. In\ncontrast, the general-purpose and code-specific models perform close to random\nchance. FABLE provides the first diagnostic benchmark to systematically\nevaluate data-flow reasoning and offers insights for developing models with\nstronger procedural understanding.",
    "pdf_url": "http://arxiv.org/pdf/2505.24258v1",
    "published": "2025-05-30T06:32:34+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24257v1",
    "title": "Out of Sight, Not Out of Context? Egocentric Spatial Reasoning in VLMs Across Disjoint Frames",
    "authors": [
      "Sahithya Ravi",
      "Gabriel Sarch",
      "Vibhav Vineet",
      "Andrew D. Wilson",
      "Balasaravanan Thoravi Kumaravel"
    ],
    "abstract": "An embodied AI assistant operating on egocentric video must integrate spatial\ncues across time - for instance, determining where an object A, glimpsed a few\nmoments ago lies relative to an object B encountered later. We introduce\nDisjoint-3DQA , a generative QA benchmark that evaluates this ability of VLMs\nby posing questions about object pairs that are not co-visible in the same\nframe. We evaluated seven state-of-the-art VLMs and found that models lag\nbehind human performance by 28%, with steeper declines in accuracy (60% to 30\n%) as the temporal gap widens. Our analysis further reveals that providing\ntrajectories or bird's-eye-view projections to VLMs results in only marginal\nimprovements, whereas providing oracle 3D coordinates leads to a substantial\n20% performance increase. This highlights a core bottleneck of multi-frame VLMs\nin constructing and maintaining 3D scene representations over time from visual\nsignals. Disjoint-3DQA therefore sets a clear, measurable challenge for\nlong-horizon spatial reasoning and aims to catalyze future research at the\nintersection of vision, language, and embodied AI.",
    "pdf_url": "http://arxiv.org/pdf/2505.24257v1",
    "published": "2025-05-30T06:32:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24256v1",
    "title": "GPU Implementation of Zippel Method for Feynman Integral Reconstruction",
    "authors": [
      "Alexander V. Smirnov",
      "Boris I. Rozhnov",
      "Vadim V. Voevodin"
    ],
    "abstract": "The Zippel algorithm performs a rational reconstruction of multivariate\npolynomials and aims specifically at the sparse case. It is applied in\ndifferent fields of science, lately becoming an important step in Feynman\nintegral reduction in elementary particle physics. In some cases with multiple\nvariables it might become a bottleneck for the whole evaluation so that\ndifferent optimizations are required. In this paper we describe how we ported\nthe classical Zippel algorithm together with its balanced version for rational\nfunctions to graphical processor units and perform its evaluation on several\nGPUs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24256v1",
    "published": "2025-05-30T06:28:16+00:00",
    "categories": [
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24255v1",
    "title": "Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games",
    "authors": [
      "Neemesh Yadav",
      "Palakorn Achananuparp",
      "Jing Jiang",
      "Ee-Peng Lim"
    ],
    "abstract": "Large Language Models (LLMs) have shown potential in simulating human\nbehaviors and performing theory-of-mind (ToM) reasoning, a crucial skill for\ncomplex social interactions. In this study, we investigate the role of ToM\nreasoning in aligning agentic behaviors with human norms in negotiation tasks,\nusing the ultimatum game as a controlled environment. We initialized LLM agents\nwith different prosocial beliefs (including Greedy, Fair, and Selfless) and\nreasoning methods like chain-of-thought (CoT) and varying ToM levels, and\nexamined their decision-making processes across diverse LLMs, including\nreasoning models like o3-mini and DeepSeek-R1 Distilled Qwen 32B. Results from\n2,700 simulations indicated that ToM reasoning enhances behavior alignment,\ndecision-making consistency, and negotiation outcomes. Consistent with previous\nfindings, reasoning models exhibit limited capability compared to models with\nToM reasoning, different roles of the game benefits with different orders of\nToM reasoning. Our findings contribute to the understanding of ToM's role in\nenhancing human-AI interaction and cooperative decision-making. The code used\nfor our experiments can be found at https://github.com/Stealth-py/UltimatumToM.",
    "pdf_url": "http://arxiv.org/pdf/2505.24255v1",
    "published": "2025-05-30T06:23:52+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24254v1",
    "title": "Rethinking Continual Learning with Progressive Neural Collapse",
    "authors": [
      "Zheng Wang",
      "Wanhao Yu",
      "Li Yang",
      "Sen Lin"
    ],
    "abstract": "Continual Learning (CL) seeks to build an agent that can continuously learn a\nsequence of tasks, where a key challenge, namely Catastrophic Forgetting,\npersists due to the potential knowledge interference among different tasks. On\nthe other hand, deep neural networks (DNNs) are shown to converge to a terminal\nstate termed Neural Collapse during training, where all class prototypes\ngeometrically form a static simplex equiangular tight frame (ETF). These\nmaximally and equally separated class prototypes make the ETF an ideal target\nfor model learning in CL to mitigate knowledge interference. Thus inspired,\nseveral studies have emerged very recently to leverage a fixed global ETF in\nCL, which however suffers from key drawbacks, such as impracticability and\nlimited performance.To address these challenges and fully unlock the potential\nof ETF in CL, we propose Progressive Neural Collapse (ProNC), a novel framework\nthat completely removes the need of a fixed global ETF in CL. Specifically,\nProNC progressively expands the ETF target in a principled way by adding new\nclass prototypes as vertices for new tasks, ensuring maximal separability\nacross all encountered classes with minimal shifts from the previous ETF. We\nnext develop a new CL framework by plugging ProNC into commonly used CL\nalgorithm designs, where distillation is further leveraged to balance between\ntarget shifting for old classes and target aligning for new classes. Extensive\nexperiments show that our approach significantly outperforms related baselines\nwhile maintaining superior flexibility, simplicity, and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.24254v1",
    "published": "2025-05-30T06:21:04+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00088v1",
    "title": "HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs",
    "authors": [
      "Qing Li",
      "Jiahui Geng",
      "Zongxiong Chen",
      "Derui Zhu",
      "Yuxia Wang",
      "Congbo Ma",
      "Chenyang Lyu",
      "Fakhri Karray"
    ],
    "abstract": "In recent years, large language models (LLMs) have made remarkable\nadvancements, yet hallucination, where models produce inaccurate or non-factual\nstatements, remains a significant challenge for real-world deployment. Although\ncurrent classification-based methods, such as SAPLMA, are highly efficient in\nmitigating hallucinations, they struggle when non-factual information arises in\nthe early or mid-sequence of outputs, reducing their reliability. To address\nthese issues, we propose Hallucination Detection-Neural Differential Equations\n(HD-NDEs), a novel method that systematically assesses the truthfulness of\nstatements by capturing the full dynamics of LLMs within their latent space.\nOur approaches apply neural differential equations (Neural DEs) to model the\ndynamic system in the latent space of LLMs. Then, the sequence in the latent\nspace is mapped to the classification space for truth assessment. The extensive\nexperiments across five datasets and six widely used LLMs demonstrate the\neffectiveness of HD-NDEs, especially, achieving over 14% improvement in AUC-ROC\non the True-False dataset compared to state-of-the-art techniques.",
    "pdf_url": "http://arxiv.org/pdf/2506.00088v1",
    "published": "2025-05-30T06:19:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24253v1",
    "title": "Interactive Video Generation via Domain Adaptation",
    "authors": [
      "Ishaan Rawal",
      "Suryansh Kumar"
    ],
    "abstract": "Text-conditioned diffusion models have emerged as powerful tools for\nhigh-quality video generation. However, enabling Interactive Video Generation\n(IVG), where users control motion elements such as object trajectory, remains\nchallenging. Recent training-free approaches introduce attention masking to\nguide trajectory, but this often degrades perceptual quality. We identify two\nkey failure modes in these methods, both of which we interpret as domain shift\nproblems, and propose solutions inspired by domain adaptation. First, we\nattribute the perceptual degradation to internal covariate shift induced by\nattention masking, as pretrained models are not trained to handle masked\nattention. To address this, we propose mask normalization, a pre-normalization\nlayer designed to mitigate this shift via distribution matching. Second, we\naddress initialization gap, where the randomly sampled initial noise does not\nalign with IVG conditioning, by introducing a temporal intrinsic diffusion\nprior that enforces spatio-temporal consistency at each denoising step.\nExtensive qualitative and quantitative evaluations demonstrate that mask\nnormalization and temporal intrinsic denoising improve both perceptual quality\nand trajectory control over the existing state-of-the-art IVG techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.24253v1",
    "published": "2025-05-30T06:19:47+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24252v1",
    "title": "A Reward-driven Automated Webshell Malicious-code Generator for Red-teaming",
    "authors": [
      "Yizhong Ding"
    ],
    "abstract": "Frequent cyber-attacks have elevated WebShell exploitation and defense to a\ncritical research focus within network security. However, there remains a\nsignificant shortage of publicly available, well-categorized malicious-code\ndatasets organized by obfuscation method. Existing malicious-code generation\nmethods, which primarily rely on prompt engineering, often suffer from limited\ndiversity and high redundancy in the payloads they produce. To address these\nlimitations, we propose \\textbf{RAWG}, a \\textbf{R}eward-driven\n\\textbf{A}utomated \\textbf{W}ebshell Malicious-code \\textbf{G}enerator designed\nfor red-teaming applications. Our approach begins by categorizing webshell\nsamples from common datasets into seven distinct types of obfuscation. We then\nemploy a large language model (LLM) to extract and normalize key tokens from\neach sample, creating a standardized, high-quality corpus. Using this curated\ndataset, we perform supervised fine-tuning (SFT) on an open-source large model\nto enable the generation of diverse, highly obfuscated webshell malicious\npayloads. To further enhance generation quality, we apply Proximal Policy\nOptimization (PPO), treating malicious-code samples as \"chosen\" data and benign\ncode as \"rejected\" data during reinforcement learning. Extensive experiments\ndemonstrate that RAWG significantly outperforms current state-of-the-art\nmethods in both payload diversity and escape effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.24252v1",
    "published": "2025-05-30T06:16:42+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24251v1",
    "title": "Proactive Guidance of Multi-Turn Conversation in Industrial Search",
    "authors": [
      "Xiaoyu Li",
      "Xiao Li",
      "Li Gao",
      "Yiding Liu",
      "Xiaoyang Wang",
      "Shuaiqiang Wang",
      "Junfeng Wang",
      "Dawei Yin"
    ],
    "abstract": "The evolution of Large Language Models (LLMs) has significantly advanced\nmulti-turn conversation systems, emphasizing the need for proactive guidance to\nenhance users' interactions. However, these systems face challenges in\ndynamically adapting to shifts in users' goals and maintaining low latency for\nreal-time interactions. In the Baidu Search AI assistant, an industrial-scale\nmulti-turn search system, we propose a novel two-phase framework to provide\nproactive guidance. The first phase, Goal-adaptive Supervised Fine-Tuning\n(G-SFT), employs a goal adaptation agent that dynamically adapts to user goal\nshifts and provides goal-relevant contextual information. G-SFT also\nincorporates scalable knowledge transfer to distill insights from LLMs into a\nlightweight model for real-time interaction. The second phase, Click-oriented\nReinforcement Learning (C-RL), adopts a generate-rank paradigm, systematically\nconstructs preference pairs from user click signals, and proactively improves\nclick-through rates through more engaging guidance. This dual-phase\narchitecture achieves complementary objectives: G-SFT ensures accurate goal\ntracking, while C-RL optimizes interaction quality through click signal-driven\nreinforcement learning. Extensive experiments demonstrate that our framework\nachieves 86.10% accuracy in offline evaluation (+23.95% over baseline) and\n25.28% CTR in online deployment (149.06% relative improvement), while reducing\ninference latency by 69.55% through scalable knowledge distillation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24251v1",
    "published": "2025-05-30T06:16:30+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24250v1",
    "title": "Winners vs. Losers: Momentum-based Strategies with Intertemporal Choice for ESG Portfolios",
    "authors": [
      "Ayush Jha",
      "Abootaleb Shirvani",
      "Ali Jaffri",
      "Svetlozar T. Rachev",
      "Frank J. Fabozzi"
    ],
    "abstract": "This paper introduces a state-dependent momentum framework that integrates\nESG regime switching with tail-risk-aware reward-risk metrics. Using a dynamic\nprogramming approach and solving a finite-horizon Bellman equation, we\nconstruct long-short momentum portfolios that adjust to changing ESG sentiment\nregimes. Unlike traditional momentum strategies based on historical returns,\nour approach incorporates the Stable Tail Adjusted Return ratio and Rachev\nratio to better capture downside risk in turbulent markets. We apply this\nframework across three asset classes, Russell 3000 equities, Dow Jones~30\nstocks, and cryptocurrencies, under both pro- and anti-ESG market regimes. We\nfind that ESG-loser portfolios significantly outperform ESG-winner portfolios\nin pro-ESG regimes, a counterintuitive result suggesting that market\noverreaction to ESG sentiment creates short-term pricing inefficiencies. This\npattern is robust across tail-sensitive performance metrics and is most\npronounced under a two-week formation and holding period. Our framework\nhighlights how ESG considerations and sentiment regimes alter return dynamics,\noffering practical guidance for investors seeking to implement responsive\nmomentum strategies under sustainability constraints. These findings challenge\nconventional assumptions about ESG investing and underscore the importance of\ndynamic, regime-aware portfolio construction in environments shaped by\nregulatory signals, investor flows, and behavioral biases.",
    "pdf_url": "http://arxiv.org/pdf/2505.24250v1",
    "published": "2025-05-30T06:15:05+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.24249v1",
    "title": "Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization",
    "authors": [
      "Qingyao Tian",
      "Huai Liao",
      "Xinyan Huang",
      "Bingyu Yang",
      "Hongbin Liu"
    ],
    "abstract": "Vision-based 6-DOF bronchoscopy localization offers a promising solution for\naccurate and cost-effective interventional guidance. However, existing methods\nstruggle with 1) limited generalization across patient cases due to scarce\nlabeled data, and 2) poor robustness under visual degradation, as bronchoscopy\nprocedures frequently involve artifacts such as occlusions and motion blur that\nimpair visual information. To address these challenges, we propose PANSv2, a\ngeneralizable and robust bronchoscopy localization framework. Motivated by PANS\nthat leverages multiple visual cues for pose likelihood measurement, PANSv2\nintegrates depth estimation, landmark detection, and centerline constraints\ninto a unified pose optimization framework that evaluates pose probability and\nsolves for the optimal bronchoscope pose. To further enhance generalization\ncapabilities, we leverage the endoscopic foundation model EndoOmni for depth\nestimation and the video foundation model EndoMamba for landmark detection,\nincorporating both spatial and temporal analyses. Pretrained on diverse\nendoscopic datasets, these models provide stable and transferable visual\nrepresentations, enabling reliable performance across varied bronchoscopy\nscenarios. Additionally, to improve robustness to visual degradation, we\nintroduce an automatic re-initialization module that detects tracking failures\nand re-establishes pose using landmark detections once clear views are\navailable. Experimental results on bronchoscopy dataset encompassing 10 patient\ncases show that PANSv2 achieves the highest tracking success rate, with an\n18.1% improvement in SR-5 (percentage of absolute trajectory error under 5 mm)\ncompared to existing methods, showing potential towards real clinical usage.",
    "pdf_url": "http://arxiv.org/pdf/2505.24249v1",
    "published": "2025-05-30T06:14:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24248v1",
    "title": "Probing the Robustness Properties of Neural Speech Codecs",
    "authors": [
      "Wei-Cheng Tseng",
      "David Harwath"
    ],
    "abstract": "Neural speech codecs have revolutionized speech coding, achieving higher\ncompression while preserving audio fidelity. Beyond compression, they have\nemerged as tokenization strategies, enabling language modeling on speech and\ndriving paradigm shifts across various speech processing tasks. Despite these\nadvancements, their robustness in noisy environments remains underexplored,\nraising concerns about their generalization to real-world scenarios. In this\nwork, we systematically evaluate neural speech codecs under various noise\nconditions, revealing non-trivial differences in their robustness. We further\nexamine their linearity properties, uncovering non-linear distortions which\npartly explain observed variations in robustness. Lastly, we analyze their\nfrequency response to identify factors affecting audio fidelity. Our findings\nprovide critical insights into codec behavior and future codec design, as well\nas emphasizing the importance of noise robustness for their real-world\nintegration.",
    "pdf_url": "http://arxiv.org/pdf/2505.24248v1",
    "published": "2025-05-30T06:12:52+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24247v2",
    "title": "50 Years of Automated Face Recognition",
    "authors": [
      "Minchul Kim",
      "Anil Jain",
      "Xiaoming Liu"
    ],
    "abstract": "Over the past 50 years, automated face recognition has evolved from\nrudimentary, handcrafted systems into sophisticated deep learning models that\nrival and often surpass human performance. This paper chronicles the history\nand technological progression of FR, from early geometric and statistical\nmethods to modern deep neural architectures leveraging massive real and\nAI-generated datasets. We examine key innovations that have shaped the field,\nincluding developments in dataset, loss function, neural network design and\nfeature fusion. We also analyze how the scale and diversity of training data\ninfluence model generalization, drawing connections between dataset growth and\nbenchmark improvements. Recent advances have achieved remarkable milestones:\nstate-of-the-art face verification systems now report False Negative\nIdentification Rates of 0.13% against a 12.4 million gallery in NIST FRVT\nevaluations for 1:N visa-to-border matching. While recent advances have enabled\nremarkable accuracy in high- and low-quality face scenarios, numerous\nchallenges persist. While remarkable progress has been achieved, several open\nresearch problems remain. We outline critical challenges and promising\ndirections for future face recognition research, including scalability,\nmulti-modal fusion, synthetic identity generation, and explainable systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24247v2",
    "published": "2025-05-30T06:10:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24246v2",
    "title": "Locating Risk: Task Designers and the Challenge of Risk Disclosure in RAI Content Work",
    "authors": [
      "Alice Qian",
      "Ryland Shaw",
      "Laura Dabbish",
      "Jina Suh",
      "Hong Shen"
    ],
    "abstract": "As AI systems are increasingly tested and deployed in open-ended and\nhigh-stakes domains, crowd workers are often tasked with responsible AI (RAI)\ncontent work. These tasks include labeling violent content, moderating\ndisturbing text, or simulating harmful behavior for red teaming exercises to\nshape AI system behaviors. While prior efforts have highlighted the risks to\nworker well-being associated with RAI content work, far less attention has been\npaid to how these risks are communicated to workers. Existing transparency\nframeworks and guidelines such as model cards, datasheets, and crowdworksheets\nfocus on documenting model information and dataset collection processes, but\nthey overlook an important aspect of disclosing well-being risks to workers. In\nthe absence of standard workflows or clear guidance, the consistent application\nof content warnings, consent flows, or other forms of well-being risk\ndisclosure remain unclear. This study investigates how task designers approach\nrisk disclosure in crowdsourced RAI tasks. Drawing on interviews with 23 task\ndesigners across academic and industry sectors, we examine how well-being risk\nis recognized, interpreted, and communicated in practice. Our findings surface\na need to support task designers in identifying and communicating well-being\nrisk not only to support crowdworker well-being but also to strengthen the\nethical integrity and technical efficacy of AI development pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2505.24246v2",
    "published": "2025-05-30T06:08:50+00:00",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24245v1",
    "title": "LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework",
    "authors": [
      "Xin Kang",
      "Zihan Zheng",
      "Lei Chu",
      "Yue Gao",
      "Jiahao Li",
      "Hao Pan",
      "Xuejin Chen",
      "Yan Lu"
    ],
    "abstract": "We present LTM3D, a Latent Token space Modeling framework for conditional 3D\nshape generation that integrates the strengths of diffusion and auto-regressive\n(AR) models. While diffusion-based methods effectively model continuous latent\nspaces and AR models excel at capturing inter-token dependencies, combining\nthese paradigms for 3D shape generation remains a challenge. To address this,\nLTM3D features a Conditional Distribution Modeling backbone, leveraging a\nmasked autoencoder and a diffusion model to enhance token dependency learning.\nAdditionally, we introduce Prefix Learning, which aligns condition tokens with\nshape latent tokens during generation, improving flexibility across modalities.\nWe further propose a Latent Token Reconstruction module with\nReconstruction-Guided Sampling to reduce uncertainty and enhance structural\nfidelity in generated shapes. Our approach operates in token space, enabling\nsupport for multiple 3D representations, including signed distance fields,\npoint clouds, meshes, and 3D Gaussian Splatting. Extensive experiments on\nimage- and text-conditioned shape generation tasks demonstrate that LTM3D\noutperforms existing methods in prompt fidelity and structural accuracy while\noffering a generalizable framework for multi-modal, multi-representation 3D\ngeneration.",
    "pdf_url": "http://arxiv.org/pdf/2505.24245v1",
    "published": "2025-05-30T06:08:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24244v1",
    "title": "Mamba Knockout for Unraveling Factual Information Flow",
    "authors": [
      "Nir Endy",
      "Idan Daniel Grosbard",
      "Yuval Ran-Milo",
      "Yonatan Slutzky",
      "Itay Tshuva",
      "Raja Giryes"
    ],
    "abstract": "This paper investigates the flow of factual information in Mamba State-Space\nModel (SSM)-based language models. We rely on theoretical and empirical\nconnections to Transformer-based architectures and their attention mechanisms.\nExploiting this relationship, we adapt attentional interpretability techniques\noriginally developed for Transformers--specifically, the Attention Knockout\nmethodology--to both Mamba-1 and Mamba-2. Using them we trace how information\nis transmitted and localized across tokens and layers, revealing patterns of\nsubject-token information emergence and layer-wise dynamics. Notably, some\nphenomena vary between mamba models and Transformer based models, while others\nappear universally across all models inspected--hinting that these may be\ninherent to LLMs in general. By further leveraging Mamba's structured\nfactorization, we disentangle how distinct \"features\" either enable\ntoken-to-token information exchange or enrich individual tokens, thus offering\na unified lens to understand Mamba internal operations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24244v1",
    "published": "2025-05-30T06:08:36+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24243v1",
    "title": "Model Informed Flows for Bayesian Inference of Probabilistic Programs",
    "authors": [
      "Joohwan Ko",
      "Justin Domke"
    ],
    "abstract": "Variational inference often struggles with the posterior geometry exhibited\nby complex hierarchical Bayesian models. Recent advances in flow-based\nvariational families and Variationally Inferred Parameters (VIP) each address\naspects of this challenge, but their formal relationship is unexplored. Here,\nwe prove that the combination of VIP and a full-rank Gaussian can be\nrepresented exactly as a forward autoregressive flow augmented with a\ntranslation term and input from the model's prior. Guided by this theoretical\ninsight, we introduce the Model-Informed Flow (MIF) architecture, which adds\nthe necessary translation mechanism, prior information, and hierarchical\nordering. Empirically, MIF delivers tighter posterior approximations and\nmatches or exceeds state-of-the-art performance across a suite of hierarchical\nand non-hierarchical benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24243v1",
    "published": "2025-05-30T06:08:00+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24242v1",
    "title": "Discovery of the Hybrid Response of Photoionized Gases",
    "authors": [
      "Zhicheng He",
      "Tinggui Wang",
      "Gary J. Ferland"
    ],
    "abstract": "Photoionized gases are prevalent throughout the universe. In such gases, the\nion concentration typically exhibits two response modes to radiation: a\npositive response in the low-ionization state and a negative response in the\nhigh-ionization state. Here, we report the discovery of a widespread\nmisalignment at the boundary between the above two response modes, and identify\na third mode-the hybrid response-through time-dependent photoionization\nsimulations. This phenomenon arises from the asynchrony among the ionization\nrate, recombination rate, and ion column density. Among these, only the\nionization rate can respond instantaneously to changes in radiation.\nConsequently, the initial rate of change in the column density of \\( N_i \\) ion\nis given by \\( -N_i I_i + N_{i-1} I_{i-1} \\). However, this quantity is\ntypically nonzero at the peak of \\( N_i \\), leading to a misalignment between\nthe boundaries of positive and negative responses. Such hybrid effects\nintroduce additional complexity in the interpretation of gas properties,\nhighlighting the need for further investigation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24242v1",
    "published": "2025-05-30T06:07:55+00:00",
    "categories": [
      "astro-ph.GA",
      "physics.plasm-ph"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24241v1",
    "title": "Advantageous Parameter Expansion Training Makes Better Large Language Models",
    "authors": [
      "Naibin Gu",
      "Yilong Chen",
      "Zhenyu Zhang",
      "Peng Fu",
      "Zheng Lin",
      "Shuohuan Wang",
      "Yu Sun",
      "Hua Wu",
      "Weiping Wang",
      "Haifeng Wang"
    ],
    "abstract": "Although scaling up the number of trainable parameters in both pre-training\nand fine-tuning can effectively improve the performance of large language\nmodels, it also leads to increased computational overhead. When delving into\nthe parameter difference, we find that a subset of parameters, termed\nadvantageous parameters, plays a crucial role in determining model performance.\nFurther analysis reveals that stronger models tend to possess more such\nparameters. In this paper, we propose Advantageous Parameter EXpansion Training\n(APEX), a method that progressively expands advantageous parameters into the\nspace of disadvantageous ones, thereby increasing their proportion and\nenhancing training effectiveness. Further theoretical analysis from the\nperspective of matrix effective rank explains the performance gains of APEX.\nExtensive experiments on both instruction tuning and continued pre-training\ndemonstrate that, in instruction tuning, APEX outperforms full-parameter tuning\nwhile using only 52% of the trainable parameters. In continued pre-training,\nAPEX achieves the same perplexity level as conventional training with just 33%\nof the training data, and yields significant improvements on downstream tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24241v1",
    "published": "2025-05-30T06:06:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24240v1",
    "title": "Long-term investigation of an open cluster Berkeley 65",
    "authors": [
      "Tarak Chand",
      "Saurabh Sharma",
      "Koshvendra Singh",
      "Jeewan Pandey",
      "Aayushi Verma",
      "Harmeen Kaur",
      "Mamta",
      "Manojit Chakraborty",
      "Devendra K. Ojha",
      "Ajay Kumar Singh"
    ],
    "abstract": "We present a decade-long investigation of a poorly studied cluster, Berkeley\n65 (Be 65), using deep optical data from the telescopes of ARIES, Nainital\nObservatory. We estimate its radius ($R_{cluster}$ = 1.6$^{'}$, aspect ratio of\n$\\sim$1.1), distance (2.0 $\\pm$ 0.1 kpc) and age ($\\sim$160 Myrs). A clear\nturn-off point at $\\sim$1.7 M$_\\odot$ in the mass function suggests the escape\nof low-mass stars, and the lower photometric mass compared to the dynamical\nmass indicates ongoing disruption due to external forces. Our long-baseline\noptical photometric data also identifies 64 periodic and 16 non-periodic stars\nin this region. We have presented the light curves and the classification of\nthose variables. The periodic stars have periods ranging from $\\sim$0.05 days\nto $\\sim$3.00 days and amplitude ranges from $\\sim$8 mmag to $\\sim$700 mmag.\nThe nonperiodic stars show variation from $\\sim$30 mmag to $\\sim$500 mmag. The\nperiodic stars include main-sequence pulsating variables such as Slow Pulsating\nB-type, $\\delta$ Scuti, RR Lyrae, and $\\gamma$ Doradus. We report a detached\nbinary system and rotating variables similar to BY Draconis-type stars\nexhibiting variable brightness caused by starspots, chromospheric activity, and\nmagnetic field-related phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2505.24240v1",
    "published": "2025-05-30T06:00:12+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24239v1",
    "title": "An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring",
    "authors": [
      "Sana Ebrahimi",
      "Mohsen Dehghankar",
      "Abolfazl Asudeh"
    ],
    "abstract": "While multi-agent LLM systems show strong capabilities in various domains,\nthey are highly vulnerable to adversarial and low-performing agents. To resolve\nthis issue, in this paper, we introduce a general and adversary-resistant\nmulti-agent LLM framework based on credibility scoring. We model the\ncollaborative query-answering process as an iterative game, where the agents\ncommunicate and contribute to a final system output. Our system associates a\ncredibility score that is used when aggregating the team outputs. The\ncredibility scores are learned gradually based on the past contributions of\neach agent in query answering. Our experiments across multiple tasks and\nsettings demonstrate our system's effectiveness in mitigating adversarial\ninfluence and enhancing the resilience of multi-agent cooperation, even in the\nadversary-majority settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.24239v1",
    "published": "2025-05-30T05:57:37+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00087v1",
    "title": "SwitchLingua: The First Large-Scale Multilingual and Multi-Ethnic Code-Switching Dataset",
    "authors": [
      "Peng Xie",
      "Xingyuan Liu",
      "Tsz Wai Chan",
      "Yequan Bie",
      "Yangqiu Song",
      "Yang Wang",
      "Hao Chen",
      "Kani Chen"
    ],
    "abstract": "Code-switching (CS) is the alternating use of two or more languages within a\nconversation or utterance, often influenced by social context and speaker\nidentity. This linguistic phenomenon poses challenges for Automatic Speech\nRecognition (ASR) systems, which are typically designed for a single language\nand struggle to handle multilingual inputs. The growing global demand for\nmultilingual applications, including Code-Switching ASR (CSASR), Text-to-Speech\n(CSTTS), and Cross-Lingual Information Retrieval (CLIR), highlights the\ninadequacy of existing monolingual datasets.\n  Although some code-switching datasets exist, most are limited to bilingual\nmixing within homogeneous ethnic groups, leaving a critical need for a\nlarge-scale, diverse benchmark akin to ImageNet in computer vision.\n  To bridge this gap, we introduce \\textbf{LinguaMaster}, a multi-agent\ncollaboration framework specifically designed for efficient and scalable\nmultilingual data synthesis. Leveraging this framework, we curate\n\\textbf{SwitchLingua}, the first large-scale multilingual and multi-ethnic\ncode-switching dataset, including: (1) 420K CS textual samples across 12\nlanguages, and (2) over 80 hours of audio recordings from 174 speakers\nrepresenting 18 countries/regions and 63 racial/ethnic backgrounds, based on\nthe textual data. This dataset captures rich linguistic and cultural diversity,\noffering a foundational resource for advancing multilingual and multicultural\nresearch. Furthermore, to address the issue that existing ASR evaluation\nmetrics lack sensitivity to code-switching scenarios, we propose the\n\\textbf{Semantic-Aware Error Rate (SAER)}, a novel evaluation metric that\nincorporates semantic information, providing a more accurate and context-aware\nassessment of system performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.00087v1",
    "published": "2025-05-30T05:54:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24238v2",
    "title": "MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM",
    "authors": [
      "Bowen Dong",
      "Minheng Ni",
      "Zitong Huang",
      "Guanglei Yang",
      "Wangmeng Zuo",
      "Lei Zhang"
    ],
    "abstract": "Multimodal hallucination in multimodal large language models (MLLMs)\nrestricts the correctness of MLLMs. However, multimodal hallucinations are\nmulti-sourced and arise from diverse causes. Existing benchmarks fail to\nadequately distinguish between perception-induced hallucinations and\nreasoning-induced hallucinations. This failure constitutes a significant issue\nand hinders the diagnosis of multimodal reasoning failures within MLLMs. To\naddress this, we propose the {\\dataset} benchmark, which isolates reasoning\nhallucinations by constructing questions where input images are correctly\nperceived by MLLMs yet reasoning errors persist. {\\dataset} introduces\nmulti-granular evaluation metrics: accuracy, factuality, and LLMs hallucination\nscore for hallucination quantification. Our analysis reveals that (1) the model\nscale, data scale, and training stages significantly affect the degree of\nlogical, fabrication, and factual hallucinations; (2) current MLLMs show no\neffective improvement on spatial hallucinations caused by misinterpreted\nspatial relationships, indicating their limited visual reasoning capabilities;\nand (3) question types correlate with distinct hallucination patterns,\nhighlighting targeted challenges and potential mitigation strategies. To\naddress these challenges, we propose {\\method}, a method that combines\ncurriculum reinforcement fine-tuning to encourage models to generate\nlogic-consistent reasoning chains by stepwise reducing learning difficulty, and\ncollaborative hint inference to reduce reasoning complexity. {\\method}\nestablishes a baseline on {\\dataset}, and reduces the logical hallucinations in\noriginal base models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24238v2",
    "published": "2025-05-30T05:54:36+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24237v1",
    "title": "Boundary bilinear control of semilinear parabolic PDEs: quadratic convergence of the SQP method",
    "authors": [
      "Eduardo Casas",
      "Mariano Mateos"
    ],
    "abstract": "We analyze a bilinear control problem governed by a semilinear parabolic\nequation. The control variable is the Robin coefficient on the boundary.\nFirst-order necessary and second-order sufficient optimality conditions are\nderived. A sequential quadratic programming algorithm is then proposed to\ncompute local solutions. Starting the iterations from an initial point in an\n$L^2$-neighborhood of the local solution we prove stability and quadratic\nconvergence of the algorithm in $L^p$ ($p < \\infty$) and $L^\\infty$ assuming\nthat the local solution satisfies a no-gap second-order sufficient optimality\ncondition and a strict complementarity condition.",
    "pdf_url": "http://arxiv.org/pdf/2505.24237v1",
    "published": "2025-05-30T05:53:05+00:00",
    "categories": [
      "math.OC",
      "math.AP",
      "35K58, 49K20, 49M15, 49M05"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24236v1",
    "title": "Logrithmic Versions of Ginzburg's Sharp Operation for Free Divisors",
    "authors": [
      "Xia Liao",
      "Xiping Zhang"
    ],
    "abstract": "Let $M$ be a complex manifold, $D\\subset M$ a free divisor and $U=M\\setminus\nD$ its complement. In this paper we study the characteristic cycle\n$\\textup{CC}(\\gamma\\cdot \\ind_U)$ of the restriction of a constructible\nfunction $\\gamma$ on $U$. We globalise Ginzburg's local sharp construction and\nintroduce the log transversality condition, which is a new transversality\ncondition about the relative position of $\\gamma$ and $D$. We prove that the\nlog transversality condition is satisfied if either $D$ is normal crossing and\n$\\gamma$ is arbitrary, or $D$ is holonomic strongly Euler homogheneous and\n$\\gamma$ is non-characteristic. Under the log transversality assumption we\nestablish a logarithmic pullback formula for $\\textup{CC}(\\gamma\\cdot \\ind_U)$.\nMixing Ginzburg's sharp construction with the logarithmic pullback, we obtain a\ndouble restriction formula for the Chern-Schwartz-MacPherson class\n$c_*(\\gamma\\cdot \\ind_{D\\cup V})$ where $V$ is any reduced hypersurface in $M$.\nApplications of our results include the non-negativity of Euler characteristics\nof effective constructible functions, and CSM classes of hypersurfaces in the\nopen manifold $\\mathbb{P}^n\\setminus D$ when $D$ is a linear free divisor or a\nfree hyperplane arrangement.",
    "pdf_url": "http://arxiv.org/pdf/2505.24236v1",
    "published": "2025-05-30T05:52:50+00:00",
    "categories": [
      "math.AG",
      "14B05, 14C17, 32S60, 32S05"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24235v1",
    "title": "Alternate Groundwater Modelling Strategies: A Multi-Faceted Data-Driven Approach",
    "authors": [
      "Muralidharan K.",
      "Agniva Das",
      "Shrey Pandya",
      "Jong Min Kim"
    ],
    "abstract": "The impact of statistical methodologies on studying groundwater has been\nsignificant in the last several decades, due to cheaper computational abilities\nand presence of technologies that enable us to extract and measure more and\nmore data. This paper focuses on the validation of statistical methodologies\nthat are in practice and continue to be at the earliest disposal of the\nresearcher, demonstrating how traditional time-series models and modern neural\nnetworks may be a viable option to analyze and make viable forecasts from data\ncommonly available in this domain, and suggesting a copula-based strategy to\nobtain directional dependencies of groundwater level, spatially. This paper\nalso proposes a sphere of model validation, seldom addressed in this domain:\nthe model longevity or the model shelf-life. Use of such validation techniques\nnot only ensure lower computational cost while maintaining reasonably high\naccuracy, but also, in some cases, ensure robust predictions or forecasts, and\nassist in comparing multiple models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24235v1",
    "published": "2025-05-30T05:51:13+00:00",
    "categories": [
      "stat.AP",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24234v1",
    "title": "The analytical general solutions of power-law inflation",
    "authors": [
      "Yao Yu",
      "Hong-Song Xie",
      "Bai-Cian Ke",
      "Han Zhang"
    ],
    "abstract": "Power-law inflation has stood as a classical model in inflationary cosmology\nsince the early 1980s, prized for its exact analytical solutions and ability to\nnaturally resolve the Big Bang theory's horizon and flatness problems through\nexponential expansion. However, its simplest form appears incompatible with\nmodern precision observations, motivating increasingly complex alternatives. In\nthis work, we demonstrate previous predictions with Power-law inflation\nconsidered only a particular solution of the field equations, and derive the\ncomplete set of general analytical solutions that satisfy current theoretical\nand observational constraints. This finding revitalizes Power-law inflation as\na viable framework, offering new possibilities for cosmological model-building\nwhile preserving its original mathematical elegance.",
    "pdf_url": "http://arxiv.org/pdf/2505.24234v1",
    "published": "2025-05-30T05:50:51+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24233v1",
    "title": "Forms of BRST symmetry on a Prototypical First-Class System",
    "authors": [
      "Sumit Kumar Rai",
      "Bhabani Prasad Mandal",
      "Ronaldo Thibes"
    ],
    "abstract": "We obtain the various forms of BRST symmetry by using the\nBatalin-Fradkin-Vilkovisky formalism in a prototypical first class system. We\nhave shown that the various forms of symmetry can be obtained through canonical\ntransformation in the ghost sector. The so called \"dual-BRST\" symmetry which is\nclaimed to be an independent symmetry due to its roots in differential geometry\nis obtained from usual BRST symmetry by making a canonical transformation in\nthe ghost sector.",
    "pdf_url": "http://arxiv.org/pdf/2505.24233v1",
    "published": "2025-05-30T05:49:06+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24232v1",
    "title": "From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models",
    "authors": [
      "Haibo Jin",
      "Peiyan Zhang",
      "Peiran Wang",
      "Man Luo",
      "Haohan Wang"
    ],
    "abstract": "Large foundation models (LFMs) are susceptible to two distinct\nvulnerabilities: hallucinations and jailbreak attacks. While typically studied\nin isolation, we observe that defenses targeting one often affect the other,\nhinting at a deeper connection.\n  We propose a unified theoretical framework that models jailbreaks as\ntoken-level optimization and hallucinations as attention-level optimization.\nWithin this framework, we establish two key propositions: (1) \\textit{Similar\nLoss Convergence} - the loss functions for both vulnerabilities converge\nsimilarly when optimizing for target-specific outputs; and (2) \\textit{Gradient\nConsistency in Attention Redistribution} - both exhibit consistent gradient\nbehavior driven by shared attention dynamics.\n  We validate these propositions empirically on LLaVA-1.5 and MiniGPT-4,\nshowing consistent optimization trends and aligned gradients. Leveraging this\nconnection, we demonstrate that mitigation techniques for hallucinations can\nreduce jailbreak success rates, and vice versa. Our findings reveal a shared\nfailure mode in LFMs and suggest that robustness strategies should jointly\naddress both vulnerabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.24232v1",
    "published": "2025-05-30T05:48:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24231v1",
    "title": "Dynamic Malware Classification of Windows PE Files using CNNs and Greyscale Images Derived from Runtime API Call Argument Conversion",
    "authors": [
      "Md Shahnawaz",
      "Bishwajit Prasad Gond",
      "Durga Prasad Mohapatra"
    ],
    "abstract": "Malware detection and classification remains a topic of concern for\ncybersecurity, since it is becoming common for attackers to use advanced\nobfuscation on their malware to stay undetected. Conventional static analysis\nis not effective against polymorphic and metamorphic malware as these change\ntheir appearance without modifying their behavior, thus defying the analysis by\ncode structure alone. This makes it important to use dynamic detection that\nmonitors malware behavior at runtime. In this paper, we present a dynamic\nmalware categorization framework that extracts API argument calls at the\nruntime execution of Windows Portable Executable (PE) files. Extracting and\nencoding the dynamic features of API names, argument return values, and other\nrelative features, we convert raw behavioral data to temporal patterns. To\nenhance feature portrayal, the generated patterns are subsequently converted\ninto grayscale pictures using a magma colormap. These improved photos are used\nto teach a Convolutional Neural Network (CNN) model discriminative features,\nwhich allows for reliable and accurate malware classification. Results from\nexperiments indicate that our method, with an average accuracy of 98.36% is\neffective in classifying different classes of malware and benign by integrating\ndynamic analysis and deep learning. It not only achieves high classification\naccuracy but also demonstrates significant resilience against typical evasion\nstrategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.24231v1",
    "published": "2025-05-30T05:48:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24230v1",
    "title": "ProofNet++: A Neuro-Symbolic System for Formal Proof Verification with Self-Correction",
    "authors": [
      "Murari Ambati"
    ],
    "abstract": "We propose ProofNet++, a neuro-symbolic framework that enhances automated\ntheorem proving by combining large language models (LLMs) with formal proof\nverification and self-correction mechanisms. Current LLM-based systems suffer\nfrom hallucinated logical steps and unverifiable reasoning. ProofNet++\nmitigates these limitations by integrating symbolic proof tree supervision, a\nreinforcement learning loop using verifiers as reward functions, and an\niterative self-correction module. Our experiments on miniF2F, Lean's mathlib,\nand HOL Light show that ProofNet++ significantly improves proof accuracy,\ncorrectness, and formal verifiability over prior models. We provide theoretical\nanalysis of the convergence and stability of the verifier-guided RL framework\nand release our datasets and codebase for future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.24230v1",
    "published": "2025-05-30T05:44:34+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24229v1",
    "title": "Dynamic Context-Aware Streaming Pretrained Language Model For Inverse Text Normalization",
    "authors": [
      "Luong Ho",
      "Khanh Le",
      "Vinh Pham",
      "Bao Nguyen",
      "Tan Tran",
      "Duc Chau"
    ],
    "abstract": "Inverse Text Normalization (ITN) is crucial for converting spoken Automatic\nSpeech Recognition (ASR) outputs into well-formatted written text, enhancing\nboth readability and usability. Despite its importance, the integration of\nstreaming ITN within streaming ASR remains largely unexplored due to challenges\nin accuracy, efficiency, and adaptability, particularly in low-resource and\nlimited-context scenarios. In this paper, we introduce a streaming pretrained\nlanguage model for ITN, leveraging pretrained linguistic representations for\nimproved robustness. To address streaming constraints, we propose Dynamic\nContext-Aware during training and inference, enabling adaptive chunk size\nadjustments and the integration of right-context information. Experimental\nresults demonstrate that our method achieves accuracy comparable to\nnon-streaming ITN and surpasses existing streaming ITN models on a Vietnamese\ndataset, all while maintaining low latency, ensuring seamless integration into\nASR systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24229v1",
    "published": "2025-05-30T05:41:03+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24228v1",
    "title": "Bose-Einstein Condensation, Fluctuations and Spontaneous Symmetry Breaking",
    "authors": [
      "A. Crisanti",
      "A. Sarracino",
      "M. Zannetti"
    ],
    "abstract": "The realisation of Bose-Einstein condensation under grand-canonical\nconditions has provided the experimental evidence for the simultaneous\noccurrence of macroscopic fluctuations and phase coherence of the condensate.\nThe observation of these two features, against a consolidated tradition which\nwants the fluctuations to be pathological (grand-canonical catastrophe) and\nincompatible with spontaneous symmetry braking, calls for a comprehensive\nrethinking of the approach to the problem. In this paper we consider the\nuniform ideal gas in a box and we present an alternative conceptual framework.\nWe show that the usually-employed Bogoliubov quasi-average construction fails\nto reproduce the broken-symmetry state. The observed features are accounted for\nby a different pattern of spontaneous symmetry breaking, characterised by\ncondensation of fluctuations and long-range correlations of the order\nparameter.",
    "pdf_url": "http://arxiv.org/pdf/2505.24228v1",
    "published": "2025-05-30T05:30:44+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.24227v1",
    "title": "Light as Deception: GPT-driven Natural Relighting Against Vision-Language Pre-training Models",
    "authors": [
      "Ying Yang",
      "Jie Zhang",
      "Xiao Lv",
      "Di Lin",
      "Tao Xiang",
      "Qing Guo"
    ],
    "abstract": "While adversarial attacks on vision-and-language pretraining (VLP) models\nhave been explored, generating natural adversarial samples crafted through\nrealistic and semantically meaningful perturbations remains an open challenge.\nExisting methods, primarily designed for classification tasks, struggle when\nadapted to VLP models due to their restricted optimization spaces, leading to\nineffective attacks or unnatural artifacts. To address this, we propose\n\\textbf{LightD}, a novel framework that generates natural adversarial samples\nfor VLP models via semantically guided relighting. Specifically, LightD\nleverages ChatGPT to propose context-aware initial lighting parameters and\nintegrates a pretrained relighting model (IC-light) to enable diverse lighting\nadjustments. LightD expands the optimization space while ensuring perturbations\nalign with scene semantics. Additionally, gradient-based optimization is\napplied to the reference lighting image to further enhance attack effectiveness\nwhile maintaining visual naturalness. The effectiveness and superiority of the\nproposed LightD have been demonstrated across various VLP models in tasks such\nas image captioning and visual question answering.",
    "pdf_url": "http://arxiv.org/pdf/2505.24227v1",
    "published": "2025-05-30T05:30:02+00:00",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24226v4",
    "title": "E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness",
    "authors": [
      "Yibo Zhao",
      "Jiapeng Zhu",
      "Ye Guo",
      "Kangkang He",
      "Xiang Li"
    ],
    "abstract": "Graph-based RAG methods like GraphRAG have shown promising global\nunderstanding of the knowledge base by constructing hierarchical entity graphs.\nHowever, they often suffer from inefficiency and rely on manually pre-defined\nquery modes, limiting practical use. In this paper, we propose E^2GraphRAG, a\nstreamlined graph-based RAG framework that improves both Efficiency and\nEffectiveness. During the indexing stage, E^2GraphRAG constructs a summary tree\nwith large language models and an entity graph with SpaCy based on document\nchunks. We then construct bidirectional indexes between entities and chunks to\ncapture their many-to-many relationships, enabling fast lookup during both\nlocal and global retrieval. For the retrieval stage, we design an adaptive\nretrieval strategy that leverages the graph structure to retrieve and select\nbetween local and global modes. Experiments show that E^2GraphRAG achieves up\nto 10 times faster indexing than GraphRAG and 100 times speedup over LightRAG\nin retrieval while maintaining competitive QA performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.24226v4",
    "published": "2025-05-30T05:27:40+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24225v1",
    "title": "Reasoning Can Hurt the Inductive Abilities of Large Language Models",
    "authors": [
      "Haibo Jin",
      "Peiyan Zhang",
      "Man Luo",
      "Haohan Wang"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable progress across domains,\nyet their ability to perform inductive reasoning - inferring latent rules from\nsparse examples - remains limited. It is often assumed that chain-of-thought\n(CoT) prompting, as used in Large Reasoning Models (LRMs), enhances such\nreasoning. We investigate this assumption with creating four controlled,\ndiagnostic game-based tasks - chess, Texas Hold'em, dice games, and blackjack -\nwith hidden human-defined rules. We find that CoT reasoning can degrade\ninductive performance, with LRMs often underperforming their non-reasoning\ncounterparts.\n  To explain this, we present a theoretical framework that reveals how\nreasoning steps can amplify error through three failure modes: incorrect\nsub-task decomposition, incorrect sub-task solving, and incorrect final answer\nsummarization. Based on our theoretical and empirical analysis, we introduce\nstructured interventions that adapt CoT generation according to our identified\nfailure types. These interventions improve inductive accuracy without\nretraining. Our findings suggest that effective (CoT) reasoning depends not\nonly on taking more steps but also on ensuring those steps are well-structured.",
    "pdf_url": "http://arxiv.org/pdf/2505.24225v1",
    "published": "2025-05-30T05:24:21+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24224v1",
    "title": "MOPSA: Mixture of Prompt-Experts Based Speaker Adaptation for Elderly Speech Recognition",
    "authors": [
      "Chengxi Deng",
      "Xurong Xie",
      "Shujie Hu",
      "Mengzhe Geng",
      "Yicong Jiang",
      "Jiankun Zhao",
      "Jiajun Deng",
      "Guinan Li",
      "Youjun Chen",
      "Huimeng Wang",
      "Haoning Xu",
      "Mingyu Cui",
      "Xunying Liu"
    ],
    "abstract": "This paper proposes a novel Mixture of Prompt-Experts based Speaker\nAdaptation approach (MOPSA) for elderly speech recognition. It allows\nzero-shot, real-time adaptation to unseen speakers, and leverages domain\nknowledge tailored to elderly speakers. Top-K most distinctive speaker prompt\nclusters derived using K-means serve as experts. A router network is trained to\ndynamically combine clustered prompt-experts. Acoustic and language level\nvariability among elderly speakers are modelled using separate encoder and\ndecoder prompts for Whisper. Experiments on the English DementiaBank Pitt and\nCantonese JCCOCC MoCA elderly speech datasets suggest that online MOPSA\nadaptation outperforms the speaker-independent (SI) model by statistically\nsignificant word error rate (WER) or character error rate (CER) reductions of\n0.86% and 1.47% absolute (4.21% and 5.40% relative). Real-time factor (RTF)\nspeed-up ratios of up to 16.12 times are obtained over offline batch-mode\nadaptation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24224v1",
    "published": "2025-05-30T05:23:16+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24223v2",
    "title": "Automated Structured Radiology Report Generation",
    "authors": [
      "Jean-Benoit Delbrouck",
      "Justin Xu",
      "Johannes Moll",
      "Alois Thomas",
      "Zhihong Chen",
      "Sophie Ostmeier",
      "Asfandyar Azhar",
      "Kelvin Zhenghao Li",
      "Andrew Johnston",
      "Christian Bluethgen",
      "Eduardo Reis",
      "Mohamed Muneer",
      "Maya Varma",
      "Curtis Langlotz"
    ],
    "abstract": "Automated radiology report generation from chest X-ray (CXR) images has the\npotential to improve clinical efficiency and reduce radiologists' workload.\nHowever, most datasets, including the publicly available MIMIC-CXR and CheXpert\nPlus, consist entirely of free-form reports, which are inherently variable and\nunstructured. This variability poses challenges for both generation and\nevaluation: existing models struggle to produce consistent, clinically\nmeaningful reports, and standard evaluation metrics fail to capture the nuances\nof radiological interpretation. To address this, we introduce Structured\nRadiology Report Generation (SRRG), a new task that reformulates free-text\nradiology reports into a standardized format, ensuring clarity, consistency,\nand structured clinical reporting. We create a novel dataset by restructuring\nreports using large language models (LLMs) following strict structured\nreporting desiderata. Additionally, we introduce SRR-BERT, a fine-grained\ndisease classification model trained on 55 labels, enabling more precise and\nclinically informed evaluation of structured reports. To assess report quality,\nwe propose F1-SRR-BERT, a metric that leverages SRR-BERT's hierarchical disease\ntaxonomy to bridge the gap between free-text variability and structured\nclinical reporting. We validate our dataset through a reader study conducted by\nfive board-certified radiologists and extensive benchmarking experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24223v2",
    "published": "2025-05-30T05:23:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24222v1",
    "title": "Unleashing High-Quality Image Generation in Diffusion Sampling Using Second-Order Levenberg-Marquardt-Langevin",
    "authors": [
      "Fangyikang Wang",
      "Hubery Yin",
      "Lei Qian",
      "Yinan Li",
      "Shaobin Zhuang",
      "Huminhao Zhu",
      "Yilin Zhang",
      "Yanlong Tang",
      "Chao Zhang",
      "Hanbin Zhao",
      "Hui Qian",
      "Chen Li"
    ],
    "abstract": "The diffusion models (DMs) have demonstrated the remarkable capability of\ngenerating images via learning the noised score function of data distribution.\nCurrent DM sampling techniques typically rely on first-order Langevin dynamics\nat each noise level, with efforts concentrated on refining inter-level\ndenoising strategies. While leveraging additional second-order Hessian geometry\nto enhance the sampling quality of Langevin is a common practice in Markov\nchain Monte Carlo (MCMC), the naive attempts to utilize Hessian geometry in\nhigh-dimensional DMs lead to quadratic-complexity computational costs,\nrendering them non-scalable. In this work, we introduce a novel\nLevenberg-Marquardt-Langevin (LML) method that approximates the diffusion\nHessian geometry in a training-free manner, drawing inspiration from the\ncelebrated Levenberg-Marquardt optimization algorithm. Our approach introduces\ntwo key innovations: (1) A low-rank approximation of the diffusion Hessian,\nleveraging the DMs' inherent structure and circumventing explicit\nquadratic-complexity computations; (2) A damping mechanism to stabilize the\napproximated Hessian. This LML approximated Hessian geometry enables the\ndiffusion sampling to execute more accurate steps and improve the image\ngeneration quality. We further conduct a theoretical analysis to substantiate\nthe approximation error bound of low-rank approximation and the convergence\nproperty of the damping mechanism. Extensive experiments across multiple\npretrained DMs validate that the LML method significantly improves image\ngeneration quality, with negligible computational overhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.24222v1",
    "published": "2025-05-30T05:21:44+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24221v1",
    "title": "FOCUS: Boosting Schema-aware Access for KV Stores via Hierarchical Data Management",
    "authors": [
      "Zhen Liu",
      "Wenzhe Zhu",
      "Yongkun Li",
      "Yinlong Xu"
    ],
    "abstract": "Persistent key-value (KV) stores are critical infrastructure for\ndata-intensive applications. Leveraging high-performance Non-Volatile Memory\n(NVM) to enhance KV stores has gained traction. However, previous work has\nprimarily focused on optimizing KV stores themselves, without adequately\naddressing their integration into applications. Consequently, existing\napplications, represented by NewSQL databases, still resort to a flat mapping\napproach, which simply maps structured records into flat KV pairs to use KV\nstores. Such semantic mismatch may cause significant I/O amplification and I/O\nsplitting under production workloads, harming the performance. To this end, we\npropose FOCUS, a log-structured KV store optimized for fine-grained\nhierarchical data organization and schema-aware access. FOCUS introduces a\nhierarchical KV model to provide native support for upper-layer structured\ndata. We implemented FOCUS from scratch. Experiments show that FOCUS can\nincrease throughput by 2.1-5.9x compared to mainstream NVM-backed KV stores\nunder YCSB SQL workloads.",
    "pdf_url": "http://arxiv.org/pdf/2505.24221v1",
    "published": "2025-05-30T05:17:44+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2506.00086v1",
    "title": "Does Newtonian dynamics need Euclidean space?",
    "authors": [
      "Alain Albouy"
    ],
    "abstract": "We present an elementary deduction of the Newtonian force from Kepler's laws.\nWe relate it to a generalization by Jacobi of the Keplerian motion, where the\nEuclidean form in the plane is replaced by some function with the same\nhomogeneity. We show how several convexity properties of the generalized\nKeplerian orbits appear in this context. We describe the generalized\nhodographs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00086v1",
    "published": "2025-05-30T05:10:26+00:00",
    "categories": [
      "physics.class-ph",
      "70F05 (Primary) 26B25 (Secondary)"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24220v1",
    "title": "Characterization of Hamamatsu R11410-23 Photomultiplier Tubes and Performance in the PandaX-4T Detector",
    "authors": [
      "Binbin Yan",
      "Di Huang",
      "Jianglai Liu",
      "Xiaoying Lu",
      "Anqing Wan",
      "Mengjiao Xiao"
    ],
    "abstract": "The PandaX-4T liquid xenon detector uses Hamamatsu 3-inch R11410-23\nphotomultiplier tubes (PMTs) as the light sensors for ultra-low radioactivity,\nhigh quantum efficiency, and long-term stability at cryogenic temperature. Each\nPMT was thoroughly tested in a dedicated chamber before being installed in the\ndetector to ensure compliance with experimental requirements. Main PMT\ncharacteristics, including gain, dark count rate, and after-pulse probability,\nwere measured and the distributions of these parameters were presented.\nAdditionally, all PMTs were tested in a cryogenic environment to simulate their\noperating conditions in an actual detector environment. Finally, we report the\nlong-term of all PMTs during the commissioning run of the PandaX-4T experiment,\nand most of the PMTs worded well.",
    "pdf_url": "http://arxiv.org/pdf/2505.24220v1",
    "published": "2025-05-30T05:10:18+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.24219v1",
    "title": "ERU-KG: Efficient Reference-aligned Unsupervised Keyphrase Generation",
    "authors": [
      "Lam Thanh Do",
      "Aaditya Bodke",
      "Pritom Saha Akash",
      "Kevin Chen-Chuan Chang"
    ],
    "abstract": "Unsupervised keyphrase prediction has gained growing interest in recent\nyears. However, existing methods typically rely on heuristically defined\nimportance scores, which may lead to inaccurate informativeness estimation. In\naddition, they lack consideration for time efficiency. To solve these problems,\nwe propose ERU-KG, an unsupervised keyphrase generation (UKG) model that\nconsists of an informativeness and a phraseness module. The former estimates\nthe relevance of keyphrase candidates, while the latter generate those\ncandidates. The informativeness module innovates by learning to model\ninformativeness through references (e.g., queries, citation contexts, and\ntitles) and at the term-level, thereby 1) capturing how the key concepts of\ndocuments are perceived in different contexts and 2) estimating informativeness\nof phrases more efficiently by aggregating term informativeness, removing the\nneed for explicit modeling of the candidates. ERU-KG demonstrates its\neffectiveness on keyphrase generation benchmarks by outperforming unsupervised\nbaselines and achieving on average 89\\% of the performance of a supervised\nmodel for top 10 predictions. Additionally, to highlight its practical utility,\nwe evaluate the model on text retrieval tasks and show that keyphrases\ngenerated by ERU-KG are effective when employed as query and document\nexpansions. Furthermore, inference speed tests reveal that ERU-KG is the\nfastest among baselines of similar model sizes. Finally, our proposed model can\nswitch between keyphrase generation and extraction by adjusting\nhyperparameters, catering to diverse application requirements.",
    "pdf_url": "http://arxiv.org/pdf/2505.24219v1",
    "published": "2025-05-30T05:09:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24218v1",
    "title": "$L^2$-Hodge theory of Hybrid Landau-Ginzburg models of Calabi-Yau complete intersections",
    "authors": [
      "Jeehoon Park",
      "Jaewon Yoo"
    ],
    "abstract": "Given a Calabi-Yau smooth projective complete intersection variety $V$ over\n$\\C$, a hybrid Landau-Ginzburg (LG) model may be associated using the Cayley\ntrick. This hybrid LG model comprises a non-compact Calabi-Yau manifold\n$X_{CY}$, and a holomorphic function $W$, defined on $X_{CY}$, such that the\ncritical locus of $W$ is isomorphic to $V$. We construct a complete K\\\"ahler\nmetric $\\mathfrak{g}$ and a bounded Calabi-Yau volume form ${\\Omega}$ on\n$X_{CY}$ such that $(X_{CY},\\mathfrak{g}, {\\Omega})$ is a bounded Calabi-Yau\ngeometry and the function $W$ is strongly elliptic; this enables us to apply\nthe $L^2$-Hodge theory of Li-Wen [18] to $(X_{CY},\\mathfrak{g}, {\\Omega})$ and\n$W$, which leads to a Frobenius manifold structure on the twisted de Rham\ncohomology associated to $(X_{CY},W)$. Furthermore, we prove that this twisted\nde Rham cohomology is isomorphic to the de Rham cohomology $H(V;\\C)$, which\nresults in a new $L^2$-Hodge theoretic construction of a Frobenius manifold\nstructure on $H(V;\\C)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24218v1",
    "published": "2025-05-30T05:09:02+00:00",
    "categories": [
      "math.AG",
      "14J32"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24217v1",
    "title": "Semi-structured LLM Reasoners Can Be Rigorously Audited",
    "authors": [
      "Jixuan Leng",
      "Cassandra A. Cohen",
      "Zhixian Zhang",
      "Chenyan Xiong",
      "William W. Cohen"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly capable at reasoning, the\nproblem of \"faithfulness\" persists: LLM \"reasoning traces\" can contain errors\nand omissions that are difficult to detect, and may obscure biases in model\noutputs. To address these limitations, we introduce Semi-Structured Reasoning\nModels (SSRMs), which internalize a semi-structured Chain-of-Thought (CoT)\nreasoning format within the model. Our SSRMs generate reasoning traces in a\nPythonic syntax. While SSRM traces are not executable, they adopt a restricted,\ntask-specific vocabulary to name distinct reasoning steps, and to mark each\nstep's inputs and outputs. Through extensive evaluation on ten benchmarks,\nSSRMs demonstrate strong performance and generality: they outperform comparably\nsized baselines by nearly ten percentage points on in-domain tasks while\nremaining competitive with specialized models on out-of-domain medical\nbenchmarks. Furthermore, we show that semi-structured reasoning is more\namenable to analysis: in particular, they can be automatically audited to\nidentify reasoning flaws. We explore both hand-crafted structured audits, which\ndetect task-specific problematic reasoning patterns, and learned typicality\naudits, which apply probabilistic models over reasoning patterns, and show that\nboth audits can be used to effectively flag probable reasoning errors.",
    "pdf_url": "http://arxiv.org/pdf/2505.24217v1",
    "published": "2025-05-30T05:06:10+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24216v1",
    "title": "Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation",
    "authors": [
      "Prasanna Reddy Pulakurthi",
      "Majid Rabbani",
      "Jamison Heard",
      "Sohail Dianat",
      "Celso M. de Melo",
      "Raghuveer Rao"
    ],
    "abstract": "This work investigates Source-Free Domain Adaptation (SFDA), where a model\nadapts to a target domain without access to source data. A new augmentation\ntechnique, Shuffle PatchMix (SPM), and a novel reweighting strategy are\nintroduced to enhance performance. SPM shuffles and blends image patches to\ngenerate diverse and challenging augmentations, while the reweighting strategy\nprioritizes reliable pseudo-labels to mitigate label noise. These techniques\nare particularly effective on smaller datasets like PACS, where overfitting and\npseudo-label noise pose greater risks. State-of-the-art results are achieved on\nthree major benchmarks: PACS, VisDA-C, and DomainNet-126. Notably, on PACS,\nimprovements of 7.3% (79.4% to 86.7%) and 7.2% are observed in single-target\nand multi-target settings, respectively, while gains of 2.8% and 0.7% are\nattained on DomainNet-126 and VisDA-C. This combination of advanced\naugmentation and robust pseudo-label reweighting establishes a new benchmark\nfor SFDA. The code is available at: https://github.com/PrasannaPulakurthi/SPM",
    "pdf_url": "http://arxiv.org/pdf/2505.24216v1",
    "published": "2025-05-30T05:02:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24215v1",
    "title": "Transformation formula of Dwork's $p$-adic hypergeometric function",
    "authors": [
      "Yusuke Nemoto"
    ],
    "abstract": "In this paper, we give a transformation formula of Dwork's $p$-adic\nhypergeometric function between $t$ and $t^{-1}$. As an appendix, we introduce\na finite analogue of this transformation formula, which implies the special\ncase of the above transformation formula.",
    "pdf_url": "http://arxiv.org/pdf/2505.24215v1",
    "published": "2025-05-30T04:54:58+00:00",
    "categories": [
      "math.NT",
      "33C20, 33E50"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00085v1",
    "title": "COSMIC: Generalized Refusal Direction Identification in LLM Activations",
    "authors": [
      "Vincent Siu",
      "Nicholas Crispino",
      "Zihao Yu",
      "Sam Pan",
      "Zhun Wang",
      "Yang Liu",
      "Dawn Song",
      "Chenguang Wang"
    ],
    "abstract": "Large Language Models (LLMs) encode behaviors such as refusal within their\nactivation space, yet identifying these behaviors remains a significant\nchallenge. Existing methods often rely on predefined refusal templates\ndetectable in output tokens or require manual analysis. We introduce\n\\textbf{COSMIC} (Cosine Similarity Metrics for Inversion of Concepts), an\nautomated framework for direction selection that identifies viable steering\ndirections and target layers using cosine similarity - entirely independent of\nmodel outputs. COSMIC achieves steering performance comparable to prior methods\nwithout requiring assumptions about a model's refusal behavior, such as the\npresence of specific refusal tokens. It reliably identifies refusal directions\nin adversarial settings and weakly aligned models, and is capable of steering\nsuch models toward safer behavior with minimal increase in false refusals,\ndemonstrating robustness across a wide range of alignment conditions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00085v1",
    "published": "2025-05-30T04:54:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24214v1",
    "title": "Benchmarking Foundation Models for Zero-Shot Biometric Tasks",
    "authors": [
      "Redwan Sony",
      "Parisa Farmanifard",
      "Hamzeh Alzwairy",
      "Nitish Shukla",
      "Arun Ross"
    ],
    "abstract": "The advent of foundation models, particularly Vision-Language Models (VLMs)\nand Multi-modal Large Language Models (MLLMs), has redefined the frontiers of\nartificial intelligence, enabling remarkable generalization across diverse\ntasks with minimal or no supervision. Yet, their potential in biometric\nrecognition and analysis remains relatively underexplored. In this work, we\nintroduce a comprehensive benchmark that evaluates the zero-shot and few-shot\nperformance of state-of-the-art publicly available VLMs and MLLMs across six\nbiometric tasks spanning the face and iris modalities: face verification, soft\nbiometric attribute prediction (gender and race), iris recognition,\npresentation attack detection (PAD), and face manipulation detection (morphs\nand deepfakes). A total of 41 VLMs were used in this evaluation. Experiments\nshow that embeddings from these foundation models can be used for diverse\nbiometric tasks with varying degrees of success. For example, in the case of\nface verification, a True Match Rate (TMR) of 96.77 percent was obtained at a\nFalse Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW)\ndataset, without any fine-tuning. In the case of iris recognition, the TMR at 1\npercent FMR on the IITD-R-Full dataset was 97.55 percent without any\nfine-tuning. Further, we show that applying a simple classifier head to these\nembeddings can help perform DeepFake detection for faces, Presentation Attack\nDetection (PAD) for irides, and extract soft biometric attributes like gender\nand ethnicity from faces with reasonably high accuracy. This work reiterates\nthe potential of pretrained models in achieving the long-term vision of\nArtificial General Intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2505.24214v1",
    "published": "2025-05-30T04:53:55+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24213v1",
    "title": "Tensor Resonance in $J/ψJ/ψ$ Scattering from Lattice QCD",
    "authors": [
      "Geng Li",
      "Chunjiang Shi",
      "Ying Chen",
      "Wei Sun"
    ],
    "abstract": "The $S$-wave scattering amplitudes of $J/\\psi J/\\psi$ with quantum numbers\n$J^{PC} = 0^{++}$ and $2^{++}$ are determined up to 6600\\,MeV using lattice QCD\ncalculations at $m_\\pi \\approx 420$ and 250\\,MeV. The ${}^1S_0$ $J/\\psi J/\\psi$\nsystem exhibits a near-threshold attractive interaction, resulting in a virtual\nbound state with a binding energy of approximately 30-40\\,MeV. In contrast, the\n${}^5S_2$ $J/\\psi J/\\psi$ system exhibits a repulsive interaction near\nthreshold. These behaviors are primarily dominated by the quark rearrangement\neffect. Most notably, a resonance is observed in the ${}^5S_2$ $J/\\psi J/\\psi$\nchannel, with a mass around 6540\\,MeV and a width of approximately 540\\,MeV.\nThe extracted mass and width are consistent with the $X(6600)$ (or $X(6400)$)\nobserved by the ATLAS and CMS collaborations, and show little dependence on the\nsea pion mass.",
    "pdf_url": "http://arxiv.org/pdf/2505.24213v1",
    "published": "2025-05-30T04:53:21+00:00",
    "categories": [
      "hep-lat"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.24212v1",
    "title": "Optimal Haar random fermionic linear optics circuits",
    "authors": [
      "Paolo Braccia",
      "N. L. Diaz",
      "Martin Larocca",
      "M. Cerezo",
      "Diego García-Martín"
    ],
    "abstract": "Sampling unitary Fermionic Linear Optics (FLO), or matchgate circuits, has\nbecome a fundamental tool in quantum information. Such capability enables a\nlarge number of applications ranging from randomized benchmarking of continuous\ngate sets, to fermionic classical shadows. In this work, we introduce optimal\nalgorithms to sample over the non-particle-preserving (active) and\nparticle-preserving (passive) FLO Haar measures. In particular, we provide\nappropriate distributions for the gates of $n$-qubit parametrized circuits\nwhich produce random active and passive FLO. In contrast to previous\napproaches, which either incur classical $\\mathcal{O}(n^3)$ compilation costs\nor have suboptimal depths, our methods directly output circuits which\nsimultaneously achieve an optimal down-to-the-constant-factor $\\Theta(n)$ depth\nand $\\Theta(n^2)$ gate count; with only a $\\Theta(n^2)$ classical overhead.\nFinally, we also provide quantum circuits to sample Clifford FLO with an\noptimal $\\Theta(n^2)$ gate count.",
    "pdf_url": "http://arxiv.org/pdf/2505.24212v1",
    "published": "2025-05-30T04:52:40+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24211v1",
    "title": "Are Any-to-Any Models More Consistent Across Modality Transfers Than Specialists?",
    "authors": [
      "Jiwan Chung",
      "Janghan Yoon",
      "Junhyeong Park",
      "Sangeyl Lee",
      "Joowon Yang",
      "Sooyeon Park",
      "Youngjae Yu"
    ],
    "abstract": "Any-to-any generative models aim to enable seamless interpretation and\ngeneration across multiple modalities within a unified framework, yet their\nability to preserve relationships across modalities remains uncertain. Do\nunified models truly achieve cross-modal coherence, or is this coherence merely\nperceived? To explore this, we introduce ACON, a dataset of 1,000 images (500\nnewly contributed) paired with captions, editing instructions, and Q&A pairs to\nevaluate cross-modal transfers rigorously. Using three consistency\ncriteria-cyclic consistency, forward equivariance, and conjugated\nequivariance-our experiments reveal that any-to-any models do not consistently\ndemonstrate greater cross-modal consistency than specialized models in\npointwise evaluations such as cyclic consistency. However, equivariance\nevaluations uncover weak but observable consistency through structured analyses\nof the intermediate latent space enabled by multiple editing operations. We\nrelease our code and data at https://github.com/JiwanChung/ACON.",
    "pdf_url": "http://arxiv.org/pdf/2505.24211v1",
    "published": "2025-05-30T04:51:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24210v1",
    "title": "STORK: Improving the Fidelity of Mid-NFE Sampling for Diffusion and Flow Matching Models",
    "authors": [
      "Zheng Tan",
      "Weizhen Wang",
      "Andrea L. Bertozzi",
      "Ernest K. Ryu"
    ],
    "abstract": "Diffusion models (DMs) have demonstrated remarkable performance in\nhigh-fidelity image and video generation. Because high-quality generations with\nDMs typically require a large number of function evaluations (NFEs), resulting\nin slow sampling, there has been extensive research successfully reducing the\nNFE to a small range (<10) while maintaining acceptable image quality. However,\nmany practical applications, such as those involving Stable Diffusion 3.5,\nFLUX, and SANA, commonly operate in the mid-NFE regime (20-50 NFE) to achieve\nsuperior results, and, despite the practical relevance, research on the\neffective sampling within this mid-NFE regime remains underexplored. In this\nwork, we propose a novel, training-free, and structure-independent DM ODE\nsolver called the Stabilized Taylor Orthogonal Runge--Kutta (STORK) method,\nbased on a class of stiff ODE solvers with a Taylor expansion adaptation.\nUnlike prior work such as DPM-Solver, which is dependent on the semi-linear\nstructure of the DM ODE, STORK is applicable to any DM sampling, including\nnoise-based and flow matching-based models. Within the 20-50 NFE range, STORK\nachieves improved generation quality, as measured by FID scores, across\nunconditional pixel-level generation and conditional latent-space generation\ntasks using models like Stable Diffusion 3.5 and SANA. Code is available at\nhttps://github.com/ZT220501/STORK.",
    "pdf_url": "http://arxiv.org/pdf/2505.24210v1",
    "published": "2025-05-30T04:46:34+00:00",
    "categories": [
      "cs.CV",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24209v1",
    "title": "Safety-Aware Robust Model Predictive Control for Robotic Arms in Dynamic Environments",
    "authors": [
      "Sanghyeon Nam",
      "Dongmin Kim",
      "Seung-Hwan Choi",
      "Chang-Hyun Kim",
      "Hyoeun Kwon",
      "Hiroaki Kawamoto",
      "Suwoong Lee"
    ],
    "abstract": "Robotic manipulators are essential for precise industrial pick-and-place\noperations, yet planning collision-free trajectories in dynamic environments\nremains challenging due to uncertainties such as sensor noise and time-varying\ndelays. Conventional control methods often fail under these conditions,\nmotivating the development of Robust MPC (RMPC) strategies with constraint\ntightening. In this paper, we propose a novel RMPC framework that integrates\nphase-based nominal control with a robust safety mode, allowing smooth\ntransitions between safe and nominal operations. Our approach dynamically\nadjusts constraints based on real-time predictions of moving\nobstacles\\textemdash whether human, robot, or other dynamic objects\\textemdash\nthus ensuring continuous, collision-free operation. Simulation studies\ndemonstrate that our controller improves both motion naturalness and safety,\nachieving faster task completion than conventional methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24209v1",
    "published": "2025-05-30T04:41:28+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24208v1",
    "title": "Bootstrapping LLM Robustness for VLM Safety via Reducing the Pretraining Modality Gap",
    "authors": [
      "Wenhan Yang",
      "Spencer Stice",
      "Ali Payani",
      "Baharan Mirzasoleiman"
    ],
    "abstract": "Ensuring Vision-Language Models (VLMs) generate safe outputs is crucial for\ntheir reliable deployment. However, LVLMs suffer from drastic safety\ndegradation compared to their LLM backbone. Even blank or irrelevant images can\ntrigger LVLMs to generate harmful responses to prompts that would otherwise be\nrefused in text-only contexts. The modality gap between image and text\nrepresentations has been recently hypothesized to contribute to safety\ndegradation of LVLMs. However, if and how the amount of modality gap affects\nLVLMs' safety is not studied. In this work, we show that the amount of modality\ngap is highly inversely correlated with VLMs' safety. Then, we show that this\nmodality gap is introduced during pretraining LVLMs and persists through\nfine-tuning. Inspired by this observation, we propose a regularization to\nreduce the modality gap during pretraining. Our extensive experiments on LLaVA\nv1.5, ShareGPT4V, and MiniGPT-4 show that our method substantially improves\nsafety alignment of LVLMs, reducing unsafe rate by up to 16.3% without\ncompromising performance, and can further boost existing defenses by up to\n18.2%.",
    "pdf_url": "http://arxiv.org/pdf/2505.24208v1",
    "published": "2025-05-30T04:40:08+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24207v1",
    "title": "Boosting All-in-One Image Restoration via Self-Improved Privilege Learning",
    "authors": [
      "Gang Wu",
      "Junjun Jiang",
      "Kui Jiang",
      "Xianming Liu"
    ],
    "abstract": "Unified image restoration models for diverse and mixed degradations often\nsuffer from unstable optimization dynamics and inter-task conflicts. This paper\nintroduces Self-Improved Privilege Learning (SIPL), a novel paradigm that\novercomes these limitations by innovatively extending the utility of privileged\ninformation (PI) beyond training into the inference stage. Unlike conventional\nPrivilege Learning, where ground-truth-derived guidance is typically discarded\nafter training, SIPL empowers the model to leverage its own preliminary outputs\nas pseudo-privileged signals for iterative self-refinement at test time.\nCentral to SIPL is Proxy Fusion, a lightweight module incorporating a learnable\nPrivileged Dictionary. During training, this dictionary distills essential\nhigh-frequency and structural priors from privileged feature representations.\nCritically, at inference, the same learned dictionary then interacts with\nfeatures derived from the model's initial restoration, facilitating a\nself-correction loop. SIPL can be seamlessly integrated into various backbone\narchitectures, offering substantial performance improvements with minimal\ncomputational overhead. Extensive experiments demonstrate that SIPL\nsignificantly advances the state-of-the-art on diverse all-in-one image\nrestoration benchmarks. For instance, when integrated with the PromptIR model,\nSIPL achieves remarkable PSNR improvements of +4.58 dB on composite degradation\ntasks and +1.28 dB on diverse five-task benchmarks, underscoring its\neffectiveness and broad applicability. Codes are available at our project page\nhttps://github.com/Aitical/SIPL.",
    "pdf_url": "http://arxiv.org/pdf/2505.24207v1",
    "published": "2025-05-30T04:36:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24206v2",
    "title": "On the time-decay with the diffusion wave phenomenon of the solution to the compressible Navier-Stokes-Korteweg system in critical spaces",
    "authors": [
      "Takayuki Kobayashi",
      "Ryosuke Nakasato"
    ],
    "abstract": "We consider the initial value problem of the compressible\nNavier-Stokes-Korteweg equations in the whole space $\\mathbb{R}^d$ ($d \\ge 2$).\nThe purposes of this paper are to obtain the global-in-time solution around the\nconstant equilibrium states $(\\rho_*,0)$ and investigate the $L^p$-$L^1$ type\ntime-decay estimates in a scaling critical framework, where $\\rho_*>0$ is a\nconstant. In addition, we study the diffusion wave property came from the wave\nequation with strong damping for the solution with the initial data belonging\nto the critical Besov space. The key idea of the proof is the derivation of the\ntime-decay for the Fourier-Besov norm with higher derivatives by using\n$L^1$-maximal regularity for the perturbed equations around $(\\rho_*,0)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24206v2",
    "published": "2025-05-30T04:36:07+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24205v1",
    "title": "On the Expressive Power of Mixture-of-Experts for Structured Complex Tasks",
    "authors": [
      "Mingze Wang",
      "Weinan E"
    ],
    "abstract": "Mixture-of-experts networks (MoEs) have demonstrated remarkable efficiency in\nmodern deep learning. Despite their empirical success, the theoretical\nfoundations underlying their ability to model complex tasks remain poorly\nunderstood. In this work, we conduct a systematic study of the expressive power\nof MoEs in modeling complex tasks with two common structural priors:\nlow-dimensionality and sparsity. For shallow MoEs, we prove that they can\nefficiently approximate functions supported on low-dimensional manifolds,\novercoming the curse of dimensionality. For deep MoEs, we show that\n$\\cO(L)$-layer MoEs with $E$ experts per layer can approximate piecewise\nfunctions comprising $E^L$ pieces with compositional sparsity, i.e., they can\nexhibit an exponential number of structured tasks. Our analysis reveals the\nroles of critical architectural components and hyperparameters in MoEs,\nincluding the gating mechanism, expert networks, the number of experts, and the\nnumber of layers, and offers natural suggestions for MoE variants.",
    "pdf_url": "http://arxiv.org/pdf/2505.24205v1",
    "published": "2025-05-30T04:35:03+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24204v1",
    "title": "Damping LFOs: Grid Following with Power Oscillation Damping vs. Grid Forming vs. PSS",
    "authors": [
      "Tamojit Chakraborty",
      "Anamitra Pal",
      "Sam Maleki"
    ],
    "abstract": "Low-frequency oscillations (LFOs) present a significant challenge to the\nstability and reliability of power systems, especially in grids with a high\npenetration of renewable energy sources. Traditional grid-following (GFL)\ninverters have proven less effective in damping such oscillations. This paper\npresents a GFL-power plant controller with an auxiliary power oscillation\ndamping control for damping LFOs. This approach is compared with a traditional\npower system stabilizer (PSS) for a two-area power system. Next, the research\nis extended by deploying grid forming (GFM) controls, which by actively\ncontrolling the voltage and frequency dynamics emulate the behavior of\ntraditional synchronous generators. The paper analyzes two GFM control\nstrategies: virtual synchronous machine (VSM) and droop control, and\ndemonstrates their effectiveness in damping LFOs in the test system. The\nsimulation results reveal that the performance of the proposed GFM-VSM rivals\nthat of the PSS and is better than the GFL-power oscillation damper.",
    "pdf_url": "http://arxiv.org/pdf/2505.24204v1",
    "published": "2025-05-30T04:33:56+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24203v1",
    "title": "Aligning Protein Conformation Ensemble Generation with Physical Feedback",
    "authors": [
      "Jiarui Lu",
      "Xiaoyin Chen",
      "Stephen Zhewen Lu",
      "Aurélie Lozano",
      "Vijil Chenthamarakshan",
      "Payel Das",
      "Jian Tang"
    ],
    "abstract": "Protein dynamics play a crucial role in protein biological functions and\nproperties, and their traditional study typically relies on time-consuming\nmolecular dynamics (MD) simulations conducted in silico. Recent advances in\ngenerative modeling, particularly denoising diffusion models, have enabled\nefficient accurate protein structure prediction and conformation sampling by\nlearning distributions over crystallographic structures. However, effectively\nintegrating physical supervision into these data-driven approaches remains\nchallenging, as standard energy-based objectives often lead to intractable\noptimization. In this paper, we introduce Energy-based Alignment (EBA), a\nmethod that aligns generative models with feedback from physical models,\nefficiently calibrating them to appropriately balance conformational states\nbased on their energy differences. Experimental results on the MD ensemble\nbenchmark demonstrate that EBA achieves state-of-the-art performance in\ngenerating high-quality protein ensembles. By improving the physical\nplausibility of generated structures, our approach enhances model predictions\nand holds promise for applications in structural biology and drug discovery.",
    "pdf_url": "http://arxiv.org/pdf/2505.24203v1",
    "published": "2025-05-30T04:33:39+00:00",
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24202v1",
    "title": "Relationship between prominence eruptions and coronal mass ejections during solar cycle 24",
    "authors": [
      "Pooja Devi",
      "Nat Gopalswamy",
      "Seiji Yashiro",
      "Sachiko Akiyama",
      "Ramesh Chandra",
      "Kostadinka Koleva"
    ],
    "abstract": "In this article, we present the relationship between prominence eruptions\n(PEs) and coronal mass ejections (CMEs) from May 2010 to December 2019 covering\nmost of solar cycle 24. We used data from the Atmospheric Imaging Assembly\n(AIA) for PEs and the Large Angle and Spectrometric Coronagraph (LASCO) for\nCMEs. We identified 1225 PEs, with 67% being radial, 32% transverse, and 1%\nfailed PEs. The radial, transverse PEs, and the combined set have average\nspeeds of ~53, 9, and 38 km/s, respectively. The PE association with CMEs is\nexamined by assigning a confidence level (CL) from 0 (no association) to 3\n(clear association). Out of 1225 PEs, 662 (54%) are found to be associated to\nCMEs including CL 1, 2, and 3. Our study reveals that the spatial and temporal\nrelationships between PEs and CMEs vary over the solar cycle. During solar\nminima, CMEs tend to deflect towards the equator, possibly due to a stronger\npolar field. Temporal offsets are larger during solar maxima and smaller during\nthe minima. This implies that the PEs appear in LASCO C2 FOV earlier during the\nminima than during the maxima. Among the 662 CMEs associated with PEs, 78% show\nclear bright core structures. Investigation of the morphological and temporal\nbehavior of these CMEs indicate that the prominences evolves into CME cores at\nhigher altitudes suggesting that PEs and CME cores are the same structure. The\naverage speeds of the PEs, CME core, and CME leading edge are 62, 390, and 525\nkm/s, respectively. The speed of CME cores are more than the speed of PEs\nbecause the former are observed at larger heights where they have accelerated\nto higher speeds.",
    "pdf_url": "http://arxiv.org/pdf/2505.24202v1",
    "published": "2025-05-30T04:29:23+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24201v1",
    "title": "SentinelAgent: Graph-based Anomaly Detection in Multi-Agent Systems",
    "authors": [
      "Xu He",
      "Di Wu",
      "Yan Zhai",
      "Kun Sun"
    ],
    "abstract": "The rise of large language model (LLM)-based multi-agent systems (MAS)\nintroduces new security and reliability challenges. While these systems show\ngreat promise in decomposing and coordinating complex tasks, they also face\nmulti-faceted risks across prompt manipulation, unsafe tool usage, and emergent\nagent miscoordination. Existing guardrail mechanisms offer only partial\nprotection, primarily at the input-output level, and fall short in addressing\nsystemic or multi-point failures in MAS. In this work, we present a\nsystem-level anomaly detection framework tailored for MAS, integrating\nstructural modeling with runtime behavioral oversight. Our approach consists of\ntwo components. First, we propose a graph-based framework that models agent\ninteractions as dynamic execution graphs, enabling semantic anomaly detection\nat node, edge, and path levels. Second, we introduce a pluggable SentinelAgent,\nan LLM-powered oversight agent that observes, analyzes, and intervenes in MAS\nexecution based on security policies and contextual reasoning. By bridging\nabstract detection logic with actionable enforcement, our method detects not\nonly single-point faults and prompt injections but also multi-agent collusion\nand latent exploit paths. We validate our framework through two case studies,\nincluding an email assistant and Microsoft's Magentic-One system, demonstrating\nits ability to detect covert risks and provide explainable root-cause\nattribution. Our work lays the foundation for more trustworthy, monitorable,\nand secure agent-based AI ecosystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24201v1",
    "published": "2025-05-30T04:25:19+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24200v2",
    "title": "Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC",
    "authors": [
      "Qingzheng Wang",
      "Jiancheng Sun",
      "Yifan Peng",
      "Shinji Watanabe"
    ],
    "abstract": "Multilingual speech processing with self-supervised or supervised pre-trained\nSpeech Foundation Models (SFM) has achieved strong performance on tasks like\nLanguage Identification (LID) and Automatic Speech Recognition (ASR). However,\nthese models struggle with limited resources during fine-tuning. This paper\nenhances multilingual LID and ASR on ML-SUPERB 2.0 by exploring multiple\nstrategies for adapting SFMs, including frozen upstream training, partial\nfine-tuning, and low-rank adaptation. Furthermore, we employ data augmentation\nto mitigate performance gaps in few-shot settings and introduce LID\nConnectionist Temporal Classification (CTC) loss for regularization. Our\napproach achieves a 14% relative improvement in LID accuracy and a 30% relative\nreduction in ASR CER over the baseline on ML-SUPERB 2.0, securing second place\nin the Interspeech 2025 ML-SUPERB 2.0 Challenge.",
    "pdf_url": "http://arxiv.org/pdf/2505.24200v2",
    "published": "2025-05-30T04:25:15+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24199v1",
    "title": "Intuitionistic Fuzzy Sets for Large Language Model Data Annotation: A Novel Approach to Side-by-Side Preference Labeling",
    "authors": [
      "Yimin Du"
    ],
    "abstract": "The quality of human preference data is crucial for training and evaluating\nlarge language models (LLMs), particularly in reinforcement learning from human\nfeedback (RLHF) and direct preference optimization (DPO) scenarios. Traditional\nside-by-side (SBS) annotation approaches often struggle with inherent\nuncertainty, annotator disagreement, and the complexity of preference\njudgments. This paper introduces a novel framework based on intuitionistic\nfuzzy sets (IFS) for modeling and aggregating human preferences in LLM data\nannotation tasks. Our approach captures not only the degree of preference but\nalso the uncertainty and hesitation inherent in human judgment through\nmembership, non-membership, and hesitation degrees. We propose an IFS-based\nannotation protocol that enables more nuanced preference modeling, develops\naggregation methods for handling annotator disagreement, and introduces quality\nmetrics for preference data assessment. Experimental validation on multiple\ndatasets demonstrates that our IFS-based approach significantly improves\nannotation consistency, reduces annotator fatigue, and produces higher-quality\npreference data compared to traditional binary and Likert-scale methods. The\nresulting preference datasets lead to improved model performance in downstream\ntasks, with 12.3\\% improvement in win-rate against baseline models and 15.7\\%\nreduction in annotation time. Our framework provides a principled approach to\nhandling uncertainty in human preference annotation and offers practical\nbenefits for large-scale LLM training.",
    "pdf_url": "http://arxiv.org/pdf/2505.24199v1",
    "published": "2025-05-30T04:20:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24198v2",
    "title": "Hold My Beer: Learning Gentle Humanoid Locomotion and End-Effector Stabilization Control",
    "authors": [
      "Yitang Li",
      "Yuanhang Zhang",
      "Wenli Xiao",
      "Chaoyi Pan",
      "Haoyang Weng",
      "Guanqi He",
      "Tairan He",
      "Guanya Shi"
    ],
    "abstract": "Can your humanoid walk up and hand you a full cup of beer, without spilling a\ndrop? While humanoids are increasingly featured in flashy demos like dancing,\ndelivering packages, traversing rough terrain, fine-grained control during\nlocomotion remains a significant challenge. In particular, stabilizing a filled\nend-effector (EE) while walking is far from solved, due to a fundamental\nmismatch in task dynamics: locomotion demands slow-timescale, robust control,\nwhereas EE stabilization requires rapid, high-precision corrections. To address\nthis, we propose SoFTA, a Slow-Fast Two-Agent framework that decouples\nupper-body and lower-body control into separate agents operating at different\nfrequencies and with distinct rewards. This temporal and objective separation\nmitigates policy interference and enables coordinated whole-body behavior.\nSoFTA executes upper-body actions at 100 Hz for precise EE control and\nlower-body actions at 50 Hz for robust gait. It reduces EE acceleration by 2-5x\nrelative to baselines and performs much closer to human-level stability,\nenabling delicate tasks such as carrying nearly full cups, capturing steady\nvideo during locomotion, and disturbance rejection with EE stability.",
    "pdf_url": "http://arxiv.org/pdf/2505.24198v2",
    "published": "2025-05-30T04:18:09+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24197v1",
    "title": "Learning API Functionality from Demonstrations for Tool-based Agents",
    "authors": [
      "Bhrij Patel",
      "Ashish Jagmohan",
      "Aditya Vempaty"
    ],
    "abstract": "Digital tool-based agents that invoke external Application Programming\nInterfaces (APIs) often rely on documentation to understand API functionality.\nHowever, such documentation is frequently missing, outdated, privatized, or\ninconsistent-hindering the development of reliable, general-purpose agents. In\nthis work, we propose learning API functionality directly from demonstrations\nas a new paradigm applicable in scenarios without documentation. Using existing\nAPI benchmarks, we collect demonstrations from both expert API-based agents and\nfrom self-exploration. To understand what information demonstrations must\nconvey for successful task completion, we extensively study how the number of\ndemonstrations and the use of LLM-generated summaries and evaluations affect\nthe task success rate of the API-based agent. Our experiments across 3 datasets\nand 5 models show that learning functionality from demonstrations remains a\nnon-trivial challenge, even for state-of-the-art LLMs. We find that providing\nexplicit function calls and natural language critiques significantly improves\nthe agent's task success rate due to more accurate parameter filling. We\nanalyze failure modes, identify sources of error, and highlight key open\nchallenges for future work in documentation-free, self-improving, API-based\nagents.",
    "pdf_url": "http://arxiv.org/pdf/2505.24197v1",
    "published": "2025-05-30T04:17:09+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24196v1",
    "title": "CLaSp: In-Context Layer Skip for Self-Speculative Decoding",
    "authors": [
      "Longze Chen",
      "Renke Shan",
      "Huiming Wang",
      "Lu Wang",
      "Ziqiang Liu",
      "Run Luo",
      "Jiawei Wang",
      "Hamid Alinejad-Rokny",
      "Min Yang"
    ],
    "abstract": "Speculative decoding (SD) is a promising method for accelerating the decoding\nprocess of Large Language Models (LLMs). The efficiency of SD primarily hinges\non the consistency between the draft model and the verify model. However,\nexisting drafting approaches typically require additional modules to be\ntrained, which can be challenging to implement and ensure compatibility across\nvarious LLMs. In this paper, we propose CLaSp, an in-context layer-skipping\nstrategy for self-speculative decoding. Unlike prior methods, CLaSp does not\nrequire additional drafting modules or extra training. Instead, it employs a\nplug-and-play mechanism by skipping intermediate layers of the verify model to\nconstruct a compressed draft model. Specifically, we develop a dynamic\nprogramming algorithm that optimizes the layer-skipping process by leveraging\nthe complete hidden states from the last verification stage as an objective.\nThis enables CLaSp to dynamically adjust its layer-skipping strategy after each\nverification stage, without relying on pre-optimized sets of skipped layers.\nExperimental results across diverse downstream tasks demonstrate that CLaSp\nachieves a speedup of 1.3x ~ 1.7x on LLaMA3 series models without altering the\noriginal distribution of the generated text.",
    "pdf_url": "http://arxiv.org/pdf/2505.24196v1",
    "published": "2025-05-30T04:15:06+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24195v2",
    "title": "WikiGap: Promoting Epistemic Equity by Surfacing Knowledge Gaps Between English Wikipedia and other Language Editions",
    "authors": [
      "Zining Wang",
      "Yuxuan Zhang",
      "Dongwook Yoon",
      "Nicholas Vincent",
      "Farhan Samir",
      "Vered Shwartz"
    ],
    "abstract": "With more than 11 times as many pageviews as the next, English Wikipedia\ndominates global knowledge access relative to other language editions. Readers\nare prone to assuming English Wikipedia as a superset of all language editions,\nleading many to prefer it even when their primary language is not English.\nOther language editions, however, comprise complementary facts rooted in their\nrespective cultures and media environments, which are marginalized in English\nWikipedia. While Wikipedia's user interface enables switching between language\neditions through its Interlanguage Link (ILL) system, it does not reveal to\nreaders that other language editions contain valuable, complementary\ninformation. We present WikiGap, a system that surfaces complementary facts\nsourced from other Wikipedias within the English Wikipedia interface.\nSpecifically, by combining a recent multilingual information-gap discovery\nmethod with a user-centered design, WikiGap enables access to complementary\ninformation from French, Russian, and Chinese Wikipedia. In a mixed-methods\nstudy (n=21), WikiGap significantly improved fact-finding accuracy, reduced\ntask time, and received a 32-point higher usability score relative to\nWikipedia's current ILL-based navigation system. Participants reported\nincreased awareness of the availability of complementary information in\nnon-English editions and reconsidered the completeness of English Wikipedia.\nWikiGap thus paves the way for improved epistemic equity across language\neditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.24195v2",
    "published": "2025-05-30T04:14:03+00:00",
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24194v1",
    "title": "Energy-Embedded Neural Solvers for One-Dimensional Quantum Systems",
    "authors": [
      "Yi-Qiang Wu",
      "Xuan Liu",
      "Hanlin Li",
      "Fuqiang Wang"
    ],
    "abstract": "Physics-informed neural networks (PINN) have been widely used in\ncomputational physics to solve partial differential equations (PDEs). In this\nstudy, we propose an energy-embedding-based physics-informed neural network\nmethod for solving the one-dimensional time-independent Schr\\\"{o}dinger\nequation to obtain ground- and excited-state wave functions, as well as energy\neigenvalues by incorporating an embedding layer to generate process-driven\ndata. The method demonstrates high accuracy for several well-known potentials,\nsuch as the infinite potential well, harmonic oscillator potential, Woods-Saxon\npotential, and double-well potential. Further validation shows that the method\nalso performs well in solving the radial Coulomb potential equation, showcasing\nits adaptability and extensibility. The proposed approach can be extended to\nsolve other partial differential equations beyond the Schr\\\"{o}dinger equation\nand holds promise for applications in high-dimensional quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24194v1",
    "published": "2025-05-30T04:13:26+00:00",
    "categories": [
      "physics.comp-ph",
      "quant-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24193v1",
    "title": "Improved Best-of-Both-Worlds Regret for Bandits with Delayed Feedback",
    "authors": [
      "Ofir Schlisselberg",
      "Tal Lancewicki",
      "Peter Auer",
      "Yishay Mansour"
    ],
    "abstract": "We study the multi-armed bandit problem with adversarially chosen delays in\nthe Best-of-Both-Worlds (BoBW) framework, which aims to achieve near-optimal\nperformance in both stochastic and adversarial environments. While prior work\nhas made progress toward this goal, existing algorithms suffer from significant\ngaps to the known lower bounds, especially in the stochastic settings. Our main\ncontribution is a new algorithm that, up to logarithmic factors, matches the\nknown lower bounds in each setting individually.\n  In the adversarial case, our algorithm achieves regret of\n$\\widetilde{O}(\\sqrt{KT} + \\sqrt{D})$, which is optimal up to logarithmic\nterms, where $T$ is the number of rounds, $K$ is the number of arms, and $D$ is\nthe cumulative delay. In the stochastic case, we provide a regret bound which\nscale as $\\sum_{i:\\Delta_i>0}\\left(\\log T/\\Delta_i\\right) + \\frac{1}{K}\\sum\n\\Delta_i \\sigma_{max}$, where $\\Delta_i$ is the sub-optimality gap of arm $i$\nand $\\sigma_{\\max}$ is the maximum number of missing observations.\n  To the best of our knowledge, this is the first BoBW algorithm to\nsimultaneously match the lower bounds in both stochastic and adversarial\nregimes in delayed environment. Moreover, even beyond the BoBW setting, our\nstochastic regret bound is the first to match the known lower bound under\nadversarial delays, improving the second term over the best known result by a\nfactor of $K$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24193v1",
    "published": "2025-05-30T04:05:52+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24192v1",
    "title": "Evidence for energy-dependent scattering dominating thermoelectricity in heavy fermion systems",
    "authors": [
      "Daiki Goto",
      "Kentaro Kuga",
      "Kiyohisa Tanaka",
      "Tsunehiro Takeuchi",
      "Masaharu Matsunami"
    ],
    "abstract": "In the field of thermoelectric materials and devices, improving energy\nconversion efficiency remains a long-standing challenge. As a promising\napproach to address this issue, tuning the electron-scattering mechanisms\nbeyond the ordinary constant relaxation time approximation (CRTA) has been\nproposed. However, direct experimental evidence for an energy-dependent\nscattering reflected in the Seebeck coefficient is still lacking. Here we\ndemonstrate using angle-resolved photoemission spectroscopy that the relaxation\ntime of heavy fermion quasiparticles is highly dependent on the energy near the\nFermi level. The observed energy dependence of the relaxation time is due to\nthe coherent Kondo scattering, describing the sign of the Seebeck coefficient\nreasonably well, which cannot be deduced from CRTA. Our findings provide not\nonly deeper insight into the understanding of thermoelectricity in correlated\nmaterials, but also new perspectives on possible orbital-selective engineering\nof thermoelectric materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.24192v1",
    "published": "2025-05-30T04:03:28+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.24191v1",
    "title": "Benchmarking Quantum Heuristics: Non-Variational QWOA for Weighted Maxcut",
    "authors": [
      "Tavis Bennett",
      "Aidan Smith",
      "Edric Matwiejew",
      "Jingbo Wang"
    ],
    "abstract": "We present benchmarking results for the non-variational Quantum Walk\nOptimisation Algorithm (non-variational QWOA) applied to the weighted maxcut\nproblem, using classical simulations for problem sizes up to $n = 31$. The\namplified quantum state, prepared using a quadratic number of alternating\nunitaries, achieves a constant average-case measurement probability for\nglobally optimal solutions across these problem sizes. This behaviour contrasts\nwith that of classical heuristics, which, for NP-hard optimisation problems,\ntypically exhibit solve probabilities that decay as problem size increases.\nPerformance comparisons with two local-search heuristics on the same benchmark\ninstances suggest that the non-variational QWOA may offer a meaningful\nadvantage by scaling more favourably with problem size. These results provide\nsupporting evidence for the potential of this quantum heuristic to achieve\nquantum advantage, though further work is needed to assess whether the observed\nperformance scaling persists at larger problem sizes, and to confirm whether\nsimilar performance trends are observed for the other problem classes to which\nthe non-variational QWOA is designed to generalise.",
    "pdf_url": "http://arxiv.org/pdf/2505.24191v1",
    "published": "2025-05-30T04:02:46+00:00",
    "categories": [
      "quant-ph",
      "physics.comp-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24190v2",
    "title": "Provably Improving Generalization of Few-Shot Models with Synthetic Data",
    "authors": [
      "Lan-Cuong Nguyen",
      "Quan Nguyen-Tri",
      "Bang Tran Khanh",
      "Dung D. Le",
      "Long Tran-Thanh",
      "Khoat Than"
    ],
    "abstract": "Few-shot image classification remains challenging due to the scarcity of\nlabeled training examples. Augmenting them with synthetic data has emerged as a\npromising way to alleviate this issue, but models trained on synthetic samples\noften face performance degradation due to the inherent gap between real and\nsynthetic distributions. To address this limitation, we develop a theoretical\nframework that quantifies the impact of such distribution discrepancies on\nsupervised learning, specifically in the context of image classification. More\nimportantly, our framework suggests practical ways to generate good synthetic\nsamples and to train a predictor with high generalization ability. Building\nupon this framework, we propose a novel theoretical-based algorithm that\nintegrates prototype learning to optimize both data partitioning and model\ntraining, effectively bridging the gap between real few-shot data and synthetic\ndata. Extensive experiments results show that our approach demonstrates\nsuperior performance compared to state-of-the-art methods, outperforming them\nacross multiple datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.24190v2",
    "published": "2025-05-30T03:59:45+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24189v2",
    "title": "Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows",
    "authors": [
      "Orlando Marquez Ayala",
      "Patrice Bechard",
      "Emily Chen",
      "Maggie Baird",
      "Jingfei Chen"
    ],
    "abstract": "Large Language Models (LLMs) such as GPT-4o can handle a wide range of\ncomplex tasks with the right prompt. As per token costs are reduced, the\nadvantages of fine-tuning Small Language Models (SLMs) for real-world\napplications -- faster inference, lower costs -- may no longer be clear. In\nthis work, we present evidence that, for domain-specific tasks that require\nstructured outputs, SLMs still have a quality advantage. We compare fine-tuning\nan SLM against prompting LLMs on the task of generating low-code workflows in\nJSON form. We observe that while a good prompt can yield reasonable results,\nfine-tuning improves quality by 10% on average. We also perform systematic\nerror analysis to reveal model limitations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24189v2",
    "published": "2025-05-30T03:59:35+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24188v1",
    "title": "Conformally compact metrics and the Lovelock tensors",
    "authors": [
      "Xinran Yu"
    ],
    "abstract": "We study conformally compact metrics satisfying the Lovelock equations, which\ngeneralize the Einstein equation. We show that these metrics admit\npolyhomogeneous expansions, thereby naturally realizing the Fefferman-Graham\nexpansion, which is an important tool in conformal geometry and the AdS/CFT\ncorrespondence. In even dimensions, we identify a boundary obstruction to\nsmoothness near the boundary that generalizes the ambient obstruction tensor in\nthe Einstein setting. Under appropriate regularity and curvature conditions, we\nalso construct a formal solution to the singular Yamabe-(2q) problem and\nprovide an index obstruction for the conformally compact Lovelock filling\nproblem of spin manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2505.24188v1",
    "published": "2025-05-30T03:59:19+00:00",
    "categories": [
      "math.DG",
      "53A30 (Primary) 83C99, 53C25, 35J08, 58J05 (Secondary)"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24187v1",
    "title": "Beyond Exponential Decay: Rethinking Error Accumulation in Large Language Models",
    "authors": [
      "Mikhail L. Arbuzov",
      "Alexey A. Shvets",
      "Sisong Beir"
    ],
    "abstract": "The prevailing assumption of an exponential decay in large language model\n(LLM) reliability with sequence length, predicated on independent per-token\nerror probabilities, posits an inherent limitation for long autoregressive\noutputs. Our research fundamentally challenges this view by synthesizing\nemerging evidence that LLM errors are not uniformly distributed but are\nconcentrated at sparse \"key tokens\" ($5-10\\%$ of total tokens) representing\ncritical decision junctions. By distinguishing these high-impact tokens from\nthe increasingly predictable majority, we introduce a new reliability formula\nexplaining the sustained coherence of modern LLMs over thousands of tokens.\nConverging research streams reveal that long-context performance primarily\ndepends on accurately navigating a few crucial semantic decision points rather\nthan on uniform token-level accuracy, enabling targeted strategies that\nsignificantly outperform brute-force approaches. We thus propose a framework\nfor next-generation systems centered on selective preservation of semantically\nvital tokens, dynamic computational allocation at uncertain decision\nboundaries, multi-path exploration at ambiguities, and architectures aligned\nwith natural semantic domains. This marks a fundamental shift from raw scaling\nto strategic reasoning, promising breakthrough performance without\nproportionate computational scaling and offering a more nuanced understanding\nthat supersedes the exponential decay hypothesis, thereby opening pathways\ntoward substantially more powerful and efficient language systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24187v1",
    "published": "2025-05-30T03:57:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24186v1",
    "title": "Photostriction-tunable Polarization and Structural Dynamics in Interlayer Sliding Ferroelectrics",
    "authors": [
      "Kun Yang",
      "Jianxin Yu",
      "Jia Zhang",
      "Sheng Meng",
      "Jin Zhang"
    ],
    "abstract": "Two-dimensional ferroelectrics with robust polarization offer promising\nopportunities for non-volatile memory, field-effect transistors, and\noptoelectronic devices. However, the impact of lattice deformation on\npolarization and photoinduced structural response remains poorly understood.\nHere, we employ first-principles calculations to demonstrate\nphotodoping-induced lattice expansion in rhombohedrally stacked bilayer MoS2,\nrevealing a strong coupling between photodoping carrier and lattice structure.\nWe identify a pronounced photostrictive response in sliding ferroelectrics,\nwherein electron-hole excitation leads to substantial in-plane expansion,\nincreased interlayer spacing, and enhanced ferroelectric polarization. This\nstrain-induced modulation drives significant bandgap renormalization. The\nphotostriction-tunable polarization and structural dynamics arise from the\nstrong electromechanical coupling inherent to the non-centrosymmetric\nrhombohedral stacking. The findings provide critical insights into the\nnonthermal lattice expansion governing sliding ferroelectrics at atomic-scale\ntimescales, while simultaneously laying the groundwork for next-generation\nelectronic and memory technologies by leveraging lattice-tunable polarization\nswitching.",
    "pdf_url": "http://arxiv.org/pdf/2505.24186v1",
    "published": "2025-05-30T03:55:03+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24185v1",
    "title": "Towards Unified Modeling in Federated Multi-Task Learning via Subspace Decoupling",
    "authors": [
      "Yipan Wei",
      "Yuchen Zou",
      "Yapeng Li",
      "Bo Du"
    ],
    "abstract": "Federated Multi-Task Learning (FMTL) enables multiple clients performing\nheterogeneous tasks without exchanging their local data, offering broad\npotential for privacy preserving multi-task collaboration. However, most\nexisting methods focus on building personalized models for each client and\nunable to support the aggregation of multiple heterogeneous tasks into a\nunified model. As a result, in real-world scenarios where task objectives,\nlabel spaces, and optimization paths vary significantly, conventional FMTL\nmethods struggle to achieve effective joint training. To address this\nchallenge, we propose FedDEA (Federated Decoupled Aggregation), an\nupdate-structure-aware aggregation method specifically designed for multi-task\nmodel integration. Our method dynamically identifies task-relevant dimensions\nbased on the response strength of local updates and enhances their optimization\neffectiveness through rescaling. This mechanism effectively suppresses\ncross-task interference and enables task-level decoupled aggregation within a\nunified global model. FedDEA does not rely on task labels or architectural\nmodifications, making it broadly applicable and deployment-friendly.\nExperimental results demonstrate that it can be easily integrated into various\nmainstream federated optimization algorithms and consistently delivers\nsignificant overall performance improvements on widely used NYUD-V2 and\nPASCAL-Context. These results validate the robustness and generalization\ncapabilities of FedDEA under highly heterogeneous task settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.24185v1",
    "published": "2025-05-30T03:53:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24184v1",
    "title": "Kohn-Rossi cohomology and the Bochner technique",
    "authors": [
      "Alex Tao"
    ],
    "abstract": "We prove a vanishing theorem of Betti numbers on compact, strictly\npseudoconvex pseudohermitian manifolds with non-negative curvature operator.\nThe proof is by an application of the Bochner technique to the setting of CR\nmanifolds.",
    "pdf_url": "http://arxiv.org/pdf/2505.24184v1",
    "published": "2025-05-30T03:53:14+00:00",
    "categories": [
      "math.DG",
      "math.CV"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24183v2",
    "title": "CodeV-R1: Reasoning-Enhanced Verilog Generation",
    "authors": [
      "Yaoyu Zhu",
      "Di Huang",
      "Hanqi Lyu",
      "Xiaoyun Zhang",
      "Chongxiao Li",
      "Wenxuan Shi",
      "Yutong Wu",
      "Jianan Mu",
      "Jinghua Wang",
      "Yang Zhao",
      "Pengwei Jin",
      "Shuyao Cheng",
      "Shengwen Liang",
      "Xishan Zhang",
      "Rui Zhang",
      "Zidong Du",
      "Qi Guo",
      "Xing Hu",
      "Yunji Chen"
    ],
    "abstract": "Large language models (LLMs) trained via reinforcement learning with\nverifiable reward (RLVR) have achieved breakthroughs on tasks with explicit,\nautomatable verification, such as software programming and mathematical\nproblems. Extending RLVR to electronic design automation (EDA), especially\nautomatically generating hardware description languages (HDLs) like Verilog\nfrom natural-language (NL) specifications, however, poses three key challenges:\nthe lack of automated and accurate verification environments, the scarcity of\nhigh-quality NL-code pairs, and the prohibitive computation cost of RLVR. To\nthis end, we introduce CodeV-R1, an RLVR framework for training Verilog\ngeneration LLMs. First, we develop a rule-based testbench generator that\nperforms robust equivalence checking against golden references. Second, we\npropose a round-trip data synthesis method that pairs open-source Verilog\nsnippets with LLM-generated NL descriptions, verifies code-NL-code consistency\nvia the generated testbench, and filters out inequivalent examples to yield a\nhigh-quality dataset. Third, we employ a two-stage \"distill-then-RL\" training\npipeline: distillation for the cold start of reasoning abilities, followed by\nadaptive DAPO, our novel RLVR algorithm that can reduce training cost by\nadaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves\n68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively,\nsurpassing prior state-of-the-art by 12~20%, while matching or even exceeding\nthe performance of 671B DeepSeek-R1. We will release our model, training\npipeline, and dataset to facilitate research in EDA and LLM communities.",
    "pdf_url": "http://arxiv.org/pdf/2505.24183v2",
    "published": "2025-05-30T03:51:06+00:00",
    "categories": [
      "cs.LG",
      "cs.AR",
      "cs.PL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24182v1",
    "title": "Seeing is Not Reasoning: MVPBench for Graph-based Evaluation of Multi-path Visual Physical CoT",
    "authors": [
      "Zhuobai Dong",
      "Junchao Yi",
      "Ziyuan Zheng",
      "Haochen Han",
      "Xiangxi Zheng",
      "Alex Jinpeng Wang",
      "Fangming Liu",
      "Linjie Li"
    ],
    "abstract": "Understanding the physical world - governed by laws of motion, spatial\nrelations, and causality - poses a fundamental challenge for multimodal large\nlanguage models (MLLMs). While recent advances such as OpenAI o3 and GPT-4o\ndemonstrate impressive perceptual and reasoning capabilities, our investigation\nreveals these models struggle profoundly with visual physical reasoning,\nfailing to grasp basic physical laws, spatial interactions, and causal effects\nin complex scenes. More importantly, they often fail to follow coherent\nreasoning chains grounded in visual evidence, especially when multiple steps\nare needed to arrive at the correct answer. To rigorously evaluate this\ncapability, we introduce MVPBench, a curated benchmark designed to rigorously\nevaluate visual physical reasoning through the lens of visual chain-of-thought\n(CoT). Each example features interleaved multi-image inputs and demands not\nonly the correct final answer but also a coherent, step-by-step reasoning path\ngrounded in evolving visual cues. This setup mirrors how humans reason through\nreal-world physical processes over time. To ensure fine-grained evaluation, we\nintroduce a graph-based CoT consistency metric that verifies whether the\nreasoning path of model adheres to valid physical logic. Additionally, we\nminimize shortcut exploitation from text priors, encouraging models to rely on\nvisual understanding. Experimental results reveal a concerning trend: even\ncutting-edge MLLMs exhibit poor visual reasoning accuracy and weak image-text\nalignment in physical domains. Surprisingly, RL-based post-training alignment -\ncommonly believed to improve visual reasoning performance - often harms spatial\nreasoning, suggesting a need to rethink current fine-tuning practices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24182v1",
    "published": "2025-05-30T03:48:59+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00084v1",
    "title": "Navigation of a Three-Link Microswimmer via Deep Reinforcement Learning",
    "authors": [
      "Yuyang Lai",
      "Sina Heydari",
      "On Shun Pak",
      "Yi Man"
    ],
    "abstract": "Motile microorganisms develop effective swimming gaits to adapt to complex\nbiological environments. Translating this adaptability to smart microrobots\npresents significant challenges in motion planning and stroke design. In this\nwork, we explore the use of reinforcement learning (RL) to develop stroke\npatterns for targeted navigation in a three-link swimmer model at low Reynolds\nnumbers. Specifically, we design two RL-based strategies: one focusing on\nmaximizing velocity (Velocity-Focused Strategy) and another balancing velocity\nwith energy consumption (Energy-Aware Strategy). Our results demonstrate how\nthe use of different reward functions influences the resulting stroke patterns\ndeveloped via RL, which are compared with those obtained from traditional\noptimization methods. Furthermore, we showcase the capability of the RL-powered\nswimmer in adapting its stroke patterns in performing different navigation\ntasks, including tracing complex trajectories and pursuing moving targets.\nTaken together, this work highlights the potential of reinforcement learning as\na versatile tool for designing efficient and adaptive microswimmers capable of\nsophisticated maneuvers in complex environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00084v1",
    "published": "2025-05-30T03:44:45+00:00",
    "categories": [
      "cs.RO",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24181v1",
    "title": "SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought",
    "authors": [
      "Guanghao Li",
      "Wenhao Jiang",
      "Mingfeng Chen",
      "Yan Li",
      "Hao Yu",
      "Shuting Dong",
      "Tao Ren",
      "Ming Tang",
      "Chun Yuan"
    ],
    "abstract": "Chain of Thought (CoT) prompting improves the reasoning performance of large\nlanguage models (LLMs) by encouraging step by step thinking. However, CoT-based\nmethods depend on intermediate reasoning steps, which limits scalability and\ngeneralization. Recent work explores recursive reasoning, where LLMs reuse\ninternal layers across iterations to refine latent representations without\nexplicit CoT supervision. While promising, these approaches often require\ncostly pretraining and lack a principled framework for how reasoning should\nevolve across iterations. We address this gap by introducing Flow Chain of\nThought (Flow CoT), a reasoning paradigm that models recursive inference as a\nprogressive trajectory of latent cognitive states. Flow CoT frames each\niteration as a distinct cognitive stage deepening reasoning across iterations\nwithout relying on manual supervision. To realize this, we propose SCOUT\n(Stepwise Cognitive Optimization Using Teachers), a lightweight fine tuning\nframework that enables Flow CoT style reasoning without the need for\npretraining. SCOUT uses progressive distillation to align each iteration with a\nteacher of appropriate capacity, and a cross attention based retrospective\nmodule that integrates outputs from previous iterations while preserving the\nmodels original computation flow. Experiments across eight reasoning benchmarks\nshow that SCOUT consistently improves both accuracy and explanation quality,\nachieving up to 1.8% gains under fine tuning. Qualitative analyses further\nreveal that SCOUT enables progressively deeper reasoning across iterations\nrefining both belief formation and explanation granularity. These results not\nonly validate the effectiveness of SCOUT, but also demonstrate the practical\nviability of Flow CoT as a scalable framework for enhancing reasoning in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24181v1",
    "published": "2025-05-30T03:43:24+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24180v1",
    "title": "On Graded Quasi-Cartan Pairs and Twisted Steinberg Algebras",
    "authors": [
      "Lisa Orloff Clark",
      "Lynnel D. Naingue",
      "Jocelyn P. Vilela"
    ],
    "abstract": "We generalise recent results about quasi-Cartan, Cartan and diagonal\nsubalgebras by introducing graded versions. We show that there is a\ncorrespondence between graded algebraic quasi-Cartan/ Cartan/ diagonal pairs\nand certain graded twisted Steinberg algebras and that the associated graded\ndiscrete twist is unique. Our results include all discrete group algebras, and\nso are more general than the ungraded version.",
    "pdf_url": "http://arxiv.org/pdf/2505.24180v1",
    "published": "2025-05-30T03:43:12+00:00",
    "categories": [
      "math.RA"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24179v1",
    "title": "SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling",
    "authors": [
      "Xiaodong Ji",
      "Hailin Zhang",
      "Fangcheng Fu",
      "Bin Cui"
    ],
    "abstract": "Many advanced Large Language Model (LLM) applications require long-context\nprocessing, but the self-attention module becomes a bottleneck during the\nprefilling stage of inference due to its quadratic time complexity with respect\nto sequence length. Existing sparse attention methods accelerate attention\ncomputation by skipping less significant regions of the attention map. However,\nthese approaches typically perform coarse-grained inspection of the attention\nmap, rendering considerable loss in model accuracy. In this paper, we propose\nSALE, a fine-grained sparse attention method that accelerates the long-context\nprefilling stage of LLM with negligible loss in model accuracy. SALE achieves\nfast and accurate fine-grained attention weight estimation through 4-bit\nquantized query-key products, followed by block-sparse attention to accelerate\nprefilling computations. For importance evaluation for query-key pairs, we\nadopt our Relative Attention Score metric, which offers significantly higher\nefficiency within our framework. We implement a custom CUDA kernel optimized\nfor our approach for hardware efficiency, reducing the additional overhead to\napproximately 11% of the full attention latency. Notably, SALE requires no\nparameter training and can be seamlessly integrated into existing systems with\ntrivial code modifications. Experiments on long-context benchmarks demonstrate\nthat our method outperforms existing approaches in accuracy-efficiency\ntrade-offs, achieving at least 3.36x speedups on Llama-3.1-8B for sequences\nlonger than 64K while maintaining model quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.24179v1",
    "published": "2025-05-30T03:40:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24178v1",
    "title": "Invariant Link Selector for Spatial-Temporal Out-of-Distribution Problem",
    "authors": [
      "Katherine Tieu",
      "Dongqi Fu",
      "Jun Wu",
      "Jingrui He"
    ],
    "abstract": "In the era of foundation models, Out-of- Distribution (OOD) problems, i.e.,\nthe data discrepancy between the training environments and testing\nenvironments, hinder AI generalization. Further, relational data like graphs\ndisobeying the Independent and Identically Distributed (IID) condition makes\nthe problem more challenging, especially much harder when it is associated with\ntime. Motivated by this, to realize the robust invariant learning over temporal\ngraphs, we want to investigate what components in temporal graphs are most\ninvariant and representative with respect to labels. With the Information\nBottleneck (IB) method, we propose an error-bounded Invariant Link Selector\nthat can distinguish invariant components and variant components during the\ntraining process to make the deep learning model generalizable for different\ntesting scenarios. Besides deriving a series of rigorous generalizable\noptimization functions, we also equip the training with task-specific loss\nfunctions, e.g., temporal link prediction, to make pretrained models solve\nreal-world application tasks like citation recommendation and merchandise\nrecommendation, as demonstrated in our experiments with state-of-the-art (SOTA)\nmethods. Our code is available at https://github.com/kthrn22/OOD-Linker.",
    "pdf_url": "http://arxiv.org/pdf/2505.24178v1",
    "published": "2025-05-30T03:40:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24177v1",
    "title": "Wideband channel sensing with holographic interference surfaces",
    "authors": [
      "Jindiao Huang",
      "Haifan Yin"
    ],
    "abstract": "The Holographic Interference Surface (HIS) opens up a new prospect for\nbuilding a more cost-effective wireless communication architecture by\nperforming Radio Frequency (RF) domain signal processing. In this paper, we\nestablish a wideband channel sensing architecture for electromagnetic wave\nreception and channel estimation based on the principle of holographic\ninterference theory. Dute to the nonlinear structure of holograms,\ninterferential fringes composed of wideband RF signals exhibit severe\nself-interference effects in the time-frequency domain, which are inherently\nresistant to the classical signal processing tools. To overcome the\nself-interference, we propose a holographic channel recovery method, which\nanalyzes the time-domain variation of holograms from a geometrical perspective\nand constructs an inverse mapping from wideband holograms to object waves.\nBased on the Wirtinger partial derivative and Armijo condition, we then develop\na wideband hologram-based maximum likelihood (WH-ML) estimation method for\nestimating the channel state information (CSI) from holograms. We also propose\na geometric rotation-based object wave sensing (GROWS) algorithm to address the\ncomplicated computation of ML estimation. Furthermore, we derive the\nCram\\'er-Rao lower bound (CRLB) for investigating the achievable performance of\nwideband holographic channel estimation. Simulation results show that under the\nwideband channel sensing architecture, our proposed algorithm can accurately\nestimate the CSI in wideband scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.24177v1",
    "published": "2025-05-30T03:37:00+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24176v1",
    "title": "ISMAF: Intrinsic-Social Modality Alignment and Fusion for Multimodal Rumor Detection",
    "authors": [
      "Zihao Yu",
      "Xiang Li",
      "Jing Zhang"
    ],
    "abstract": "The rapid dissemination of rumors on social media highlights the urgent need\nfor automatic detection methods to safeguard societal trust and stability.\nWhile existing multimodal rumor detection models primarily emphasize capturing\nconsistency between intrinsic modalities (e.g., news text and images), they\noften overlook the intricate interplay between intrinsic and social modalities.\nThis limitation hampers the ability to fully capture nuanced relationships that\nare crucial for a comprehensive understanding. Additionally, current methods\nstruggle with effectively fusing social context with textual and visual\ninformation, resulting in fragmented interpretations. To address these\nchallenges, this paper proposes a novel Intrinsic-Social Modality Alignment and\nFusion (ISMAF) framework for multimodal rumor detection. ISMAF first employs a\ncross-modal consistency alignment strategy to align complex interactions\nbetween intrinsic and social modalities. It then leverages a mutual learning\napproach to facilitate collaborative refinement and integration of\ncomplementary information across modalities. Finally, an adaptive fusion\nmechanism is incorporated to dynamically adjust the contribution of each\nmodality, tackling the complexities of three-modality fusion. Extensive\nexperiments on both English and Chinese real-world multimedia datasets\ndemonstrate that ISMAF consistently outperforms state-of-the-art models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24176v1",
    "published": "2025-05-30T03:36:32+00:00",
    "categories": [
      "cs.MM"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.24175v1",
    "title": "Photometric redshift estimation for emission line galaxies of DESI Legacy Imaging Surveys by CNN-MLP",
    "authors": [
      "Shirui Wei",
      "Changhua Li",
      "Yanxia Zhang",
      "Chenzhou Cui",
      "Chao Tang",
      "Jingyi Zhang",
      "Yongheng Zhao",
      "Xuebing Wu",
      "Yihan Tao",
      "Dongwei Fan",
      "Shanshan Li",
      "Yunfei Xu",
      "Maoyuan Huang",
      "Xingyu Yang",
      "Zihan Kang",
      "Jinghang Shi"
    ],
    "abstract": "Emission Line Galaxies (ELGs) are crucial for cosmological studies,\nparticularly in understanding the large-scale structure of the Universe and the\nrole of dark energy. ELGs form an essential component of the target catalogue\nfor the Dark Energy Spectroscopic Instrument (DESI), a major astronomical\nsurvey. However, the accurate selection of ELGs for such surveys is challenging\ndue to the inherent uncertainties in determining their redshifts with\nphotometric data. In order to improve the accuracy of photometric redshift\nestimation for ELGs, we propose a novel approach CNN-MLP that combines\nConvolutional Neural Networks (CNNs) with Multilayer Perceptrons (MLPs). This\napproach integrates both images and photometric data derived from the DESI\nLegacy Imaging Surveys Data Release 10. By leveraging the complementary\nstrengths of CNNs (for image data processing) and MLPs (for photometric feature\nintegration), the CNN-MLP model achieves a $\\sigma_{\\mathrm{NMAD}}$ (normalised\nmedian absolute deviation) of 0.0140 and an outlier fraction of 2.57%. Compared\nto other models, CNN-MLP demonstrates a significant improvement in the accuracy\nof ELG photometric redshift estimation, which directly benefits the target\nselection process for DESI. In addition, we explore the photometric redshifts\nof different galaxy types (Starforming, Starburst, AGN, Broadline).\nFurthermore, this approach will contribute to more reliable photometric\nredshift estimation in ongoing and future large-scale sky surveys (e.g. LSST,\nCSST, Euclid), enhancing the overall efficiency of cosmological research and\ngalaxy surveys.",
    "pdf_url": "http://arxiv.org/pdf/2505.24175v1",
    "published": "2025-05-30T03:36:09+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00083v1",
    "title": "Hi-Dyna Graph: Hierarchical Dynamic Scene Graph for Robotic Autonomy in Human-Centric Environments",
    "authors": [
      "Jiawei Hou",
      "Xiangyang Xue",
      "Taiping Zeng"
    ],
    "abstract": "Autonomous operation of service robotics in human-centric scenes remains\nchallenging due to the need for understanding of changing environments and\ncontext-aware decision-making. While existing approaches like topological maps\noffer efficient spatial priors, they fail to model transient object\nrelationships, whereas dense neural representations (e.g., NeRF) incur\nprohibitive computational costs. Inspired by the hierarchical scene\nrepresentation and video scene graph generation works, we propose Hi-Dyna\nGraph, a hierarchical dynamic scene graph architecture that integrates\npersistent global layouts with localized dynamic semantics for embodied robotic\nautonomy. Our framework constructs a global topological graph from posed RGB-D\ninputs, encoding room-scale connectivity and large static objects (e.g.,\nfurniture), while environmental and egocentric cameras populate dynamic\nsubgraphs with object position relations and human-object interaction patterns.\nA hybrid architecture is conducted by anchoring these subgraphs to the global\ntopology using semantic and spatial constraints, enabling seamless updates as\nthe environment evolves. An agent powered by large language models (LLMs) is\nemployed to interpret the unified graph, infer latent task triggers, and\ngenerate executable instructions grounded in robotic affordances. We conduct\ncomplex experiments to demonstrate Hi-Dyna Grap's superior scene representation\neffectiveness. Real-world deployments validate the system's practicality with a\nmobile manipulator: robotics autonomously complete complex tasks with no\nfurther training or complex rewarding in a dynamic scene as cafeteria\nassistant. See https://anonymous.4open.science/r/Hi-Dyna-Graph-B326 for video\ndemonstration and more details.",
    "pdf_url": "http://arxiv.org/pdf/2506.00083v1",
    "published": "2025-05-30T03:35:29+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24174v1",
    "title": "Adaptive LoRA Merge with Parameter Pruning for Low-Resource Generation",
    "authors": [
      "Ryota Miyano",
      "Yuki Arase"
    ],
    "abstract": "This study proposes a simple yet effective LoRA merge method to achieve LLM\nadaptation for low-resource language generation tasks. The LoRA merge\ntechnique, which integrates multiple LoRA modules trained on different tasks,\nhas gained attention as an effective and efficient approach for adapting LLMs\nto target tasks. However, previous methods are limited in adaptability as they\nkeep the LoRA parameters frozen. Additionally, the low-resource problem has\nbeen out of their scope. We propose a LoRA merge method that updates and prunes\nLoRA parameters through fine-tuning with minimal target task data, which allows\nfiner-grained adjustments of LoRA parameters and enhancement of task\nadaptability. Extensive experiments have been conducted taking summarization as\na benchmark task. Our datasets cover various domains and multiple languages of\nEnglish and Japanese. The results confirm that the proposed method achieves\nsignificant and consistent improvements in task adaptability over the previous\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24174v1",
    "published": "2025-05-30T03:34:25+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24173v1",
    "title": "DrVD-Bench: Do Vision-Language Models Reason Like Human Doctors in Medical Image Diagnosis?",
    "authors": [
      "Tianhong Zhou",
      "Yin Xu",
      "Yingtao Zhu",
      "Chuxi Xiao",
      "Haiyang Bian",
      "Lei Wei",
      "Xuegong Zhang"
    ],
    "abstract": "Vision-language models (VLMs) exhibit strong zero-shot generalization on\nnatural images and show early promise in interpretable medical image analysis.\nHowever, existing benchmarks do not systematically evaluate whether these\nmodels truly reason like human clinicians or merely imitate superficial\npatterns. To address this gap, we propose DrVD-Bench, the first multimodal\nbenchmark for clinical visual reasoning. DrVD-Bench consists of three modules:\nVisual Evidence Comprehension, Reasoning Trajectory Assessment, and Report\nGeneration Evaluation, comprising a total of 7,789 image-question pairs. Our\nbenchmark covers 20 task types, 17 diagnostic categories, and five imaging\nmodalities-CT, MRI, ultrasound, radiography, and pathology. DrVD-Bench is\nexplicitly structured to reflect the clinical reasoning workflow from modality\nrecognition to lesion identification and diagnosis. We benchmark 19 VLMs,\nincluding general-purpose and medical-specific, open-source and proprietary\nmodels, and observe that performance drops sharply as reasoning complexity\nincreases. While some models begin to exhibit traces of human-like reasoning,\nthey often still rely on shortcut correlations rather than grounded visual\nunderstanding. DrVD-Bench offers a rigorous and structured evaluation framework\nto guide the development of clinically trustworthy VLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24173v1",
    "published": "2025-05-30T03:33:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24172v1",
    "title": "Heterogeneous Graph Masked Contrastive Learning for Robust Recommendation",
    "authors": [
      "Lei Sang",
      "Yu Wang",
      "Yiwen Zhang"
    ],
    "abstract": "Heterogeneous graph neural networks (HGNNs) have demonstrated their\nsuperiority in exploiting auxiliary information for recommendation tasks.\nHowever, graphs constructed using meta-paths in HGNNs are usually too dense and\ncontain a large number of noise edges. The propagation mechanism of HGNNs\npropagates even small amounts of noise in a graph to distant neighboring nodes,\nthereby affecting numerous node embeddings. To address this limitation, we\nintroduce a novel model, named Masked Contrastive Learning (MCL), to enhance\nrecommendation robustness to noise. MCL employs a random masking strategy to\naugment the graph via meta-paths, reducing node sensitivity to specific\nneighbors and bolstering embedding robustness. Furthermore, MCL employs\ncontrastive cross-view on a Heterogeneous Information Network (HIN) from two\nperspectives: one-hop neighbors and meta-path neighbors. This approach acquires\nembeddings capturing both local and high-order structures simultaneously for\nrecommendation. Empirical evaluations on three real-world datasets confirm the\nsuperiority of our approach over existing recommendation methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24172v1",
    "published": "2025-05-30T03:32:26+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24171v2",
    "title": "A note on the Diversity Owen values",
    "authors": [
      "Songtao He",
      "Erfang Shan",
      "Xinyu Sun"
    ],
    "abstract": "B\\'eal et al. (Int J Game Theory 54, 2025) introduce the Diversity Owen value\nfor TU-games with diversity constraints, and provide axiomatic\ncharacterizations using the axioms of fairness and balanced contributions.\nHowever, there exist logical flaws in the proofs of the uniqueness of these\ncharacterizations. In this note we provide the corrected proofs of the\ncharacterizations by introducing the null player for diverse games axiom. Also,\nwe establish an alternative characterization of the Diversity Owen value by\nmodifying the axioms of the above characterizations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24171v2",
    "published": "2025-05-30T03:29:47+00:00",
    "categories": [
      "econ.TH",
      "91A12"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.24170v1",
    "title": "A Method for Analytical Solutions in the Lattice Boltzmann Method",
    "authors": [
      "Jordan Larson",
      "Alexander J. Wagner"
    ],
    "abstract": "Analytical solutions to the lattice Boltzmann Equation make it possible to\nstudy the method itself, explore the properties of its collision operator, and\nidentify implementations of boundary conditions. In this paper, we propose a\nmethod to find analytical solutions where the macroscopic flow profile is\nknown. We test this method on bulk Couette flow aligned and inclined to the\nsimulation lattice with the quadratic and entropic equilibrium distributions.\nOur method indeed provides an analytical solution to these flows when using the\nquadratic distribution. When the flow is aligned to the lattice, our method\nprovides an analytical solution using the entropic distribution for practical\nrelaxation times and shear rates. We show that a small even order truncation of\nthe formal solution is optimal for accuracy-compute-time trade-off. In the\ninclined case, our method does not conserve momentum, by a small relative\nerror, when using the entropic distribution. We also discover that entropic\nlattice Boltzmann method is not compatible with the angled Couette flow. We\ndiscuss the application of our method to more complicated flows.",
    "pdf_url": "http://arxiv.org/pdf/2505.24170v1",
    "published": "2025-05-30T03:29:21+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24169v1",
    "title": "A High-Performance Multilevel Framework for Quantum Layout Synthesis",
    "authors": [
      "Shuohao Ping",
      "Naren Sathishkumar",
      "Wan-Hsuan Lin",
      "Hanyu Wang",
      "Jason Cong"
    ],
    "abstract": "Quantum Layout Synthesis (QLS) is a critical compilation stage that adapts\nquantum circuits to hardware constraints with an objective of minimizing the\nSWAP overhead. While heuristic tools demonstrate good efficiency, they often\nproduce suboptimal solutions, and exact methods suffer from limited\nscalability. In this work, we propose ML-SABRE, a high-performance multilevel\nframework for QLS that improves both solution quality and compilation time\nthrough a hierarchical optimization approach. We employ the state-of-the-art\nheuristic method, LightSABRE, at all levels to ensure both efficiency and\nperformance. Our evaluation on real benchmarks and hardware architectures shows\nthat ML-SABRE decreases SWAP count by over 60%, circuit depth by 17%, and\ndelivers a 60% compilation time reduction compared to state-of-the-art solvers.\nFurther optimality studies reveal that ML-SABRE can significantly reduce the\noptimality gap by up to 82% for SWAP count and 49% for circuit depth, making it\nwell-suited for emerging quantum devices with increasing size and architectural\ncomplexity.",
    "pdf_url": "http://arxiv.org/pdf/2505.24169v1",
    "published": "2025-05-30T03:24:22+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24168v2",
    "title": "Rydberg Atomic Receivers for Multi-Band Communications and Sensing",
    "authors": [
      "Mingyao Cui",
      "Qunsong Zeng",
      "Zhanwei Wang",
      "Kaibin Huang"
    ],
    "abstract": "Harnessing multi-level electron transitions, Rydberg Atomic REceivers (RAREs)\ncan detect wireless signals across a wide range of frequency bands, from\nMegahertz to Terahertz, enabling multi-band communications and sensing\n(CommunSense). Current research on multi-band RAREs primarily focuses on\nexperimental demonstrations, lacking a tractable model to mathematically\ncharacterize their mechanisms. This issue leaves the multi-band RARE as a black\nbox, posing challenges in its practical CommunSense applications. To fill in\nthis gap, this paper investigates the underlying mechanism of multi-band RAREs\nand explores their optimal performance. For the first time, the closed-form\nexpression of the transfer function of a multi-band RARE is derived by solving\nthe quantum response of Rydberg atoms excited by multi-band signals. The\nfunction reveals that a multi-band RARE simultaneously serves as both a\nmulti-band atomic mixer for down-converting multi-band signals and a multi-band\natomic amplifier that reflects its sensitivity to each band. Further analysis\nof the atomic amplifier unveils that the gain factor at each frequency band can\nbe decoupled into a global gain term and a Rabi attention term. The former\ndetermines the overall sensitivity of a RARE to all frequency bands of wireless\nsignals. The latter influences the allocation of the overall sensitivity to\neach frequency band, representing a unique attention mechanism of multi-band\nRAREs. The optimal design of the global gain is provided to maximize the\noverall sensitivity of multi-band RAREs. Subsequently, the optimal Rabi\nattentions are also derived to maximize the practical multi-band CommunSense\nperformance. Numerical results confirm the effectiveness of the derived\ntransfer function and the superiority of multi-band RAREs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24168v2",
    "published": "2025-05-30T03:22:23+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24167v1",
    "title": "Pretraining Deformable Image Registration Networks with Random Images",
    "authors": [
      "Junyu Chen",
      "Shuwen Wei",
      "Yihao Liu",
      "Aaron Carass",
      "Yong Du"
    ],
    "abstract": "Recent advances in deep learning-based medical image registration have shown\nthat training deep neural networks~(DNNs) does not necessarily require medical\nimages. Previous work showed that DNNs trained on randomly generated images\nwith carefully designed noise and contrast properties can still generalize well\nto unseen medical data. Building on this insight, we propose using registration\nbetween random images as a proxy task for pretraining a foundation model for\nimage registration. Empirical results show that our pretraining strategy\nimproves registration accuracy, reduces the amount of domain-specific data\nneeded to achieve competitive performance, and accelerates convergence during\ndownstream training, thereby enhancing computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.24167v1",
    "published": "2025-05-30T03:22:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24166v1",
    "title": "Deep learning-derived arterial input function",
    "authors": [
      "Junyu Chen",
      "Zirui Jiang",
      "Jennifer M. Coughlin",
      "Martin G. Pomper",
      "Yong Du"
    ],
    "abstract": "Dynamic positron emission tomography (PET) imaging combined with radiotracer\nkinetic modeling is a powerful technique for visualizing biological processes\nin the brain, offering valuable insights into brain functions and neurological\ndisorders such as Alzheimer's and Parkinson's diseases. Accurate kinetic\nmodeling relies heavily on the use of a metabolite-corrected arterial input\nfunction (AIF), which typically requires invasive and labor-intensive arterial\nblood sampling. While alternative non-invasive approaches have been proposed,\nthey often compromise accuracy or still necessitate at least one invasive blood\nsampling. In this study, we present the deep learning-derived arterial input\nfunction (DLIF), a deep learning framework capable of estimating a\nmetabolite-corrected AIF directly from dynamic PET image sequences without any\nblood sampling. We validated DLIF using existing dynamic PET patient data. We\ncompared DLIF and resulting parametric maps against ground truth measurements.\nOur evaluation shows that DLIF achieves accurate and robust AIF estimation. By\nleveraging deep learning's ability to capture complex temporal dynamics and\nincorporating prior knowledge of typical AIF shapes through basis functions,\nDLIF provides a rapid, accurate, and entirely non-invasive alternative to\ntraditional AIF measurement methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24166v1",
    "published": "2025-05-30T03:16:04+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24165v1",
    "title": "Tag-Evol: Achieving Efficient Instruction Evolving via Tag Injection",
    "authors": [
      "Yixuan Wang",
      "Shiqi Zhou",
      "Chuanzhe Guo",
      "Qingfu Zhu"
    ],
    "abstract": "Evol-Instruct has made significant improvements as a data synthesis method in\nseveral areas. Existing methods typically rely on a fixed set of strategies to\nevolve, which require manual design and are monolithic in form. In addition,\niterative evolution also makes the acquisition of hard samples expensive. In\nview of this, we propose the Tag-Evol framework, a more diverse and efficient\ninstruction evolving method. Specifically, Tag-Evol uses diverse and specific\nknowledge tags as strategies to achieve controlled evolution by injecting\ndifferent combinations of tags into the original instructions. Experiments with\nmultiple backbones in diverse domain benchmarks show that the proposed method\ngenerates significantly better evolved data than other methods. Furthermore, we\nconduct a thorough analysis of the evolved data, demonstrating that Tag-Evol is\nnot only efficient but also generates more diverse and challenging data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24165v1",
    "published": "2025-05-30T03:14:17+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24164v1",
    "title": "Mixed-R1: Unified Reward Perspective For Reasoning Capability in Multimodal Large Language Models",
    "authors": [
      "Shilin Xu",
      "Yanwei Li",
      "Rui Yang",
      "Tao Zhang",
      "Yueyi Sun",
      "Wei Chow",
      "Linfeng Li",
      "Hang Song",
      "Qi Xu",
      "Yunhai Tong",
      "Xiangtai Li",
      "Hao Fei"
    ],
    "abstract": "Recent works on large language models (LLMs) have successfully demonstrated\nthe emergence of reasoning capabilities via reinforcement learning (RL).\nAlthough recent efforts leverage group relative policy optimization (GRPO) for\nMLLMs post-training, they constantly explore one specific aspect, such as\ngrounding tasks, math problems, or chart analysis. There are no works that can\nleverage multi-source MLLM tasks for stable reinforcement learning. In this\nwork, we present a unified perspective to solve this problem. We present\nMixed-R1, a unified yet straightforward framework that contains a mixed reward\nfunction design (Mixed-Reward) and a mixed post-training dataset (Mixed-45K).\nWe first design a data engine to select high-quality examples to build the\nMixed-45K post-training dataset. Then, we present a Mixed-Reward design, which\ncontains various reward functions for various MLLM tasks. In particular, it has\nfour different reward functions: matching reward for binary answer or\nmultiple-choice problems, chart reward for chart-aware datasets, IoU reward for\ngrounding problems, and open-ended reward for long-form text responses such as\ncaption datasets. To handle the various long-form text content, we propose a\nnew open-ended reward named Bidirectional Max-Average Similarity (BMAS) by\nleveraging tokenizer embedding matching between the generated response and the\nground truth. Extensive experiments show the effectiveness of our proposed\nmethod on various MLLMs, including Qwen2.5-VL and Intern-VL on various sizes.\nOur dataset and model are available at https://github.com/xushilin1/mixed-r1.",
    "pdf_url": "http://arxiv.org/pdf/2505.24164v1",
    "published": "2025-05-30T03:11:46+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.15705v2",
    "title": "Generalisation Bounds of Zero-Shot Economic Forecasting using Time Series Foundation Models",
    "authors": [
      "Jittarin Jetwiriyanon",
      "Teo Susnjak",
      "Surangika Ranathunga"
    ],
    "abstract": "This study investigates zero-shot forecasting capabilities of Time Series\nFoundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to\nforecasting economic indicators under univariate conditions, bypassing the need\nfor train bespoke econometric models using and extensive training datasets. Our\nexperiments were conducted on a case study dataset, without additional\ncustomisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos,\nTimeGPT and Moirai) under data-scarce conditions and structural breaks. Our\nresults demonstrate that appropriately engineered TSFMs can internalise rich\neconomic dynamics, accommodate regime shifts, and deliver well-behaved\nuncertainty estimates out of the box, while matching state-of-the-art\nmultivariate models on this domain. Our findings suggest that, without any\nfine-tuning, TSFMs can match or exceed classical models during stable economic\nconditions. However, they are vulnerable to degradation in performances during\nperiods of rapid shocks. The findings offer guidance to practitioners on when\nzero-shot deployments are viable for macroeconomic monitoring and strategic\nplanning.",
    "pdf_url": "http://arxiv.org/pdf/2506.15705v2",
    "published": "2025-05-30T03:10:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.06324v1",
    "title": "Mapping Human-Agent Co-Learning and Co-Adaptation: A Scoping Review",
    "authors": [
      "Shruti Kumar",
      "Xiaoyu Chen",
      "Xiaomei Wang"
    ],
    "abstract": "Several papers have delved into the challenges of human-AI-robot co-learning\nand co-adaptation. It has been noted that the terminology used to describe this\ncollaborative relationship in existing studies needs to be more consistent. For\nexample, the prefix \"co\" is used interchangeably to represent both\n\"collaborative\" and \"mutual,\" and the terms \"co-learning\" and \"co-adaptation\"\nare sometimes used interchangeably. However, they can reflect subtle\ndifferences in the focus of the studies. The current scoping review's primary\nresearch question (RQ1) aims to gather existing papers discussing this\ncollaboration pattern and examine the terms researchers use to describe this\nhuman-agent relationship. Given the relative newness of this area of study, we\nare also keen on exploring the specific types of intelligent agents and task\ndomains that have been considered in existing research (RQ2). This exploration\nis significant as it can shed light on the diversity of human-agent\ninteractions, from one-time to continuous learning/adaptation scenarios. It can\nalso help us understand the dynamics of human-agent interactions in different\ntask domains, guiding our expectations towards research situated in dynamic,\ncomplex domains. Our third objective (RQ3) is to investigate the cognitive\ntheories and frameworks that have been utilized in existing studies to measure\nhuman-agent co-learning and co-adaptation. This investigation is crucial as it\ncan help us understand the theoretical underpinnings of human-agent\ncollaboration and adaptation, and it can also guide us in identifying any new\nframeworks proposed specifically for this type of relationship.",
    "pdf_url": "http://arxiv.org/pdf/2506.06324v1",
    "published": "2025-05-30T03:10:44+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24163v1",
    "title": "LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency Parsing",
    "authors": [
      "Jiaqi Sun",
      "Shiyou Qian",
      "Zhangchi Han",
      "Wei Li",
      "Zelin Qian",
      "Dingyu Yang",
      "Jian Cao",
      "Guangtao Xue"
    ],
    "abstract": "Knowledge Graphs (KGs) structure real-world entities and their relationships\ninto triples, enhancing machine reasoning for various tasks. While\ndomain-specific KGs offer substantial benefits, their manual construction is\noften inefficient and requires specialized knowledge. Recent approaches for\nknowledge graph construction (KGC) based on large language models (LLMs), such\nas schema-guided KGC and reference knowledge integration, have proven\nefficient. However, these methods are constrained by their reliance on manually\ndefined schema, single-document processing, and public-domain references,\nmaking them less effective for domain-specific corpora that exhibit complex\nknowledge dependencies and specificity, as well as limited reference knowledge.\nTo address these challenges, we propose LKD-KGC, a novel framework for\nunsupervised domain-specific KG construction. LKD-KGC autonomously analyzes\ndocument repositories to infer knowledge dependencies, determines optimal\nprocessing sequences via LLM driven prioritization, and autoregressively\ngenerates entity schema by integrating hierarchical inter-document contexts.\nThis schema guides the unsupervised extraction of entities and relationships,\neliminating reliance on predefined structures or external knowledge. Extensive\nexperiments show that compared with state-of-the-art baselines, LKD-KGC\ngenerally achieves improvements of 10% to 20% in both precision and recall\nrate, demonstrating its potential in constructing high-quality domain-specific\nKGs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24163v1",
    "published": "2025-05-30T03:10:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00082v1",
    "title": "An AI-powered Knowledge Hub for Potato Functional Genomics",
    "authors": [
      "Jia Yuxin",
      "Li Jinye",
      "Jia Yudong",
      "Li Futing",
      "Su Xiaoqi",
      "Luo Jilin",
      "Dong Yarui",
      "Sun Chunyan",
      "Cui Qinghan",
      "Wang Li",
      "Li Axiu",
      "Shang Yi",
      "Zhu Yujuan",
      "Huang Sanwen"
    ],
    "abstract": "Potato functional genomics lags due to unsystematic gene information\ncuration, gene identifier inconsistencies across reference genome versions, and\nthe increasing volume of research publications. To address these limitations,\nwe developed the Potato Knowledge Hub (http://www.potato-ai.top), leveraging\nLarge Language Models (LLMs) and a systematically curated collection of over\n3,200 high-quality potato research papers spanning over 120 years. This\nplatform integrates two key modules: a functional gene database containing\n2,571 literature-reported genes, meticulously mapped to the latest DMv8.1\nreference genome with resolved nomenclature discrepancies and links to original\npublications; and a potato knowledge base. The knowledge base, built using a\nRetrieval-Augmented Generation (RAG) architecture, accurately answers research\nqueries with literature citations, mitigating LLM \"hallucination.\" Users can\ninteract with the hub via a natural language AI agent, \"Potato Research\nAssistant,\" for querying specialized knowledge, retrieving gene information,\nand extracting sequences. The continuously updated Potato Knowledge Hub aims to\nbe a comprehensive resource, fostering advancements in potato functional\ngenomics and supporting breeding programs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00082v1",
    "published": "2025-05-30T03:09:59+00:00",
    "categories": [
      "q-bio.GN",
      "cs.DB"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.12054v1",
    "title": "Interacting Geodesics on Discrete Manifolds",
    "authors": [
      "Oliver Knill"
    ],
    "abstract": "We define an evolution of multiple particles on a discrete manifold $G$. Each\nparticle alone moves on geodesics and particles can interact if they are on the\nsame facet. They move deterministically and reversibly on the frame bundle $P$\nof the abstract simplicial complex $G$. Particles are signed and each is\nrepresented by a totally ordered maximal simplex $p \\in P$ in $G$. The motion\nof divisors on $P$ also defines a time dependent reversible deformation of\nspace.",
    "pdf_url": "http://arxiv.org/pdf/2506.12054v1",
    "published": "2025-05-30T03:09:25+00:00",
    "categories": [
      "math.DS",
      "cs.DM",
      "math-ph",
      "math.MP",
      "55U10, 37B15"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24162v1",
    "title": "Training-free zero-shot 3D symmetry detection with visual features back-projected to geometry",
    "authors": [
      "Isaac Aguirre",
      "Ivan Sipiran"
    ],
    "abstract": "We present a simple yet effective training-free approach for zero-shot 3D\nsymmetry detection that leverages visual features from foundation vision models\nsuch as DINOv2. Our method extracts features from rendered views of 3D objects\nand backprojects them onto the original geometry. We demonstrate the symmetric\ninvariance of these features and use them to identify reflection-symmetry\nplanes through a proposed algorithm. Experiments on a subset of ShapeNet\ndemonstrate that our approach outperforms both traditional geometric methods\nand learning-based approaches without requiring any training data. Our work\ndemonstrates how foundation vision models can help in solving complex 3D\ngeometric problems such as symmetry detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.24162v1",
    "published": "2025-05-30T03:09:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24161v1",
    "title": "Proxy Target: Bridging the Gap Between Discrete Spiking Neural Networks and Continuous Control",
    "authors": [
      "Zijie Xu",
      "Tong Bu",
      "Zecheng Hao",
      "Jianhao Ding",
      "Zhaofei Yu"
    ],
    "abstract": "Spiking Neural Networks (SNNs) offer low-latency and energy-efficient\ndecision making through neuromorphic hardware, making them compelling for\nReinforcement Learning (RL) in resource-constrained edge devices. Recent\nstudies in this field directly replace Artificial Neural Networks (ANNs) by\nSNNs in existing RL frameworks, overlooking whether the RL algorithm is\nsuitable for SNNs. However, most RL algorithms in continuous control are\ndesigned tailored to ANNs, including the target network soft updates mechanism,\nwhich conflict with the discrete, non-differentiable dynamics of SNN spikes. We\nidentify that this mismatch destabilizes SNN training in continuous control\ntasks. To bridge this gap between discrete SNN and continuous control, we\npropose a novel proxy target framework. The continuous and differentiable\ndynamics of the proxy target enable smooth updates, bypassing the\nincompatibility of SNN spikes, stabilizing the RL algorithms. Since the proxy\nnetwork operates only during training, the SNN retains its energy efficiency\nduring deployment without inference overhead. Extensive experiments on\ncontinuous control benchmarks demonstrate that compared to vanilla SNNs, the\nproxy target framework enables SNNs to achieve up to 32% higher performance\nacross different spiking neurons. Notably, we are the first to surpass ANN\nperformance in continuous control with simple Leaky-Integrate-and-Fire (LIF)\nneurons. This work motivates a new class of SNN-friendly RL algorithms tailored\nto SNN's characteristics, paving the way for neuromorphic agents that combine\nhigh performance with low power consumption.",
    "pdf_url": "http://arxiv.org/pdf/2505.24161v1",
    "published": "2025-05-30T03:08:03+00:00",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24160v1",
    "title": "Beyond the LUMIR challenge: The pathway to foundational registration models",
    "authors": [
      "Junyu Chen",
      "Shuwen Wei",
      "Joel Honkamaa",
      "Pekka Marttinen",
      "Hang Zhang",
      "Min Liu",
      "Yichao Zhou",
      "Zuopeng Tan",
      "Zhuoyuan Wang",
      "Yi Wang",
      "Hongchao Zhou",
      "Shunbo Hu",
      "Yi Zhang",
      "Qian Tao",
      "Lukas Förner",
      "Thomas Wendler",
      "Bailiang Jian",
      "Benedikt Wiestler",
      "Tim Hable",
      "Jin Kim",
      "Dan Ruan",
      "Frederic Madesta",
      "Thilo Sentker",
      "Wiebke Heyer",
      "Lianrui Zuo",
      "Yuwei Dai",
      "Jing Wu",
      "Jerry L. Prince",
      "Harrison Bai",
      "Yong Du",
      "Yihao Liu",
      "Alessa Hering",
      "Reuben Dorent",
      "Lasse Hansen",
      "Mattias P. Heinrich",
      "Aaron Carass"
    ],
    "abstract": "Medical image challenges have played a transformative role in advancing the\nfield, catalyzing algorithmic innovation and establishing new performance\nstandards across diverse clinical applications. Image registration, a\nfoundational task in neuroimaging pipelines, has similarly benefited from the\nLearn2Reg initiative. Building on this foundation, we introduce the Large-scale\nUnsupervised Brain MRI Image Registration (LUMIR) challenge, a next-generation\nbenchmark designed to assess and advance unsupervised brain MRI registration.\nDistinct from prior challenges that leveraged anatomical label maps for\nsupervision, LUMIR removes this dependency by providing over 4,000 preprocessed\nT1-weighted brain MRIs for training without any label maps, encouraging\nbiologically plausible deformation modeling through self-supervision. In\naddition to evaluating performance on 590 held-out test subjects, LUMIR\nintroduces a rigorous suite of zero-shot generalization tasks, spanning\nout-of-domain imaging modalities (e.g., FLAIR, T2-weighted, T2*-weighted),\ndisease populations (e.g., Alzheimer's disease), acquisition protocols (e.g.,\n9.4T MRI), and species (e.g., macaque brains). A total of 1,158 subjects and\nover 4,000 image pairs were included for evaluation. Performance was assessed\nusing both segmentation-based metrics (Dice coefficient, 95th percentile\nHausdorff distance) and landmark-based registration accuracy (target\nregistration error). Across both in-domain and zero-shot tasks, deep\nlearning-based methods consistently achieved state-of-the-art accuracy while\nproducing anatomically plausible deformation fields. The top-performing deep\nlearning-based models demonstrated diffeomorphic properties and inverse\nconsistency, outperforming several leading optimization-based methods, and\nshowing strong robustness to most domain shifts, the exception being a drop in\nperformance on out-of-domain contrasts.",
    "pdf_url": "http://arxiv.org/pdf/2505.24160v1",
    "published": "2025-05-30T03:07:58+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24159v2",
    "title": "A Causation-Based Framework for Pricing and Cost Allocation of Energy, Reserves, and Transmission in Modern Power Systems",
    "authors": [
      "Luiza Ribeiro",
      "Alexandre Street",
      "Jose Manuel Arroyo",
      "Rodrigo Moreno"
    ],
    "abstract": "The increasing vulnerability of power systems has heightened the need for\noperating reserves to manage contingencies such as generator outages, line\nfailures, and sudden load variations. Unlike energy costs, driven by consumer\ndemand, operating reserve costs arise from addressing the most critical\ncredible contingencies - prompting the question: how should these costs be\nallocated through efficient pricing mechanisms? As an alternative to previously\nreported schemes, this paper presents a new causation-based pricing framework\nfor electricity markets based on contingency-constrained energy and reserve\nscheduling models. Major salient features include a novel security charge\nmechanism along with the explicit definition of prices for up-spinning\nreserves, down-spinning reserves, and transmission services. These features\nensure more comprehensive and efficient cost-reflective market operations.\nMoreover, the proposed nodal pricing scheme yields revenue adequacy and\nneutrality while promoting reliability incentives for generators based on the\ncost-causation principle. An additional salient aspect of the proposed\nframework is the economic incentive for transmission assets, which are\nremunerated based on their use to deliver energy and reserves across all\ncontingency states. Numerical results from two case studies illustrate the\nperformance of the proposed pricing scheme.",
    "pdf_url": "http://arxiv.org/pdf/2505.24159v2",
    "published": "2025-05-30T03:07:06+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "econ.TH",
      "math.OC",
      "q-fin.CP",
      "q-fin.PR"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24158v1",
    "title": "Threading Keyframe with Narratives: MLLMs as Strong Long Video Comprehenders",
    "authors": [
      "Bo Fang",
      "Wenhao Wu",
      "Qiangqiang Wu",
      "Yuxin Song",
      "Antoni B. Chan"
    ],
    "abstract": "Employing Multimodal Large Language Models (MLLMs) for long video\nunderstanding remains a challenging problem due to the dilemma between the\nsubstantial number of video frames (i.e., visual tokens) versus the limited\ncontext length of language models. Traditional uniform sampling often leads to\nselection of irrelevant content, while post-training MLLMs on thousands of\nframes imposes a substantial computational burden. In this paper, we propose\nthreading keyframes with narratives (Nar-KFC), a plug-and-play module to\nfacilitate effective and efficient long video perception. Nar-KFC generally\ninvolves two collaborative steps. First, we formulate the keyframe selection\nprocess as an integer quadratic programming problem, jointly optimizing\nquery-relevance and frame-diversity. To avoid its computational complexity, a\ncustomized greedy search strategy is designed as an efficient alternative.\nSecond, to mitigate the temporal discontinuity caused by sparse keyframe\nsampling, we further introduce interleaved textual narratives generated from\nnon-keyframes using off-the-shelf captioners. These narratives are inserted\nbetween keyframes based on their true temporal order, forming a coherent and\ncompact representation. Nar-KFC thus serves as a temporal- and content-aware\ncompression strategy that complements visual and textual modalities.\nExperimental results on multiple long-video benchmarks demonstrate that Nar-KFC\nsignificantly improves the performance of popular MLLMs. Code will be made\npublicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.24158v1",
    "published": "2025-05-30T03:04:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24157v1",
    "title": "Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents",
    "authors": [
      "Seungjoon Lee",
      "Suhwan Kim",
      "Minhyeon Oh",
      "Youngsik Yoon",
      "Jungseul Ok"
    ],
    "abstract": "Developing autonomous agents capable of mastering complex, multi-step tasks\nin unpredictable, interactive environments presents a significant challenge.\nWhile Large Language Models (LLMs) offer promise for planning, existing\napproaches often rely on problematic internal knowledge or make unrealistic\nenvironmental assumptions. Although recent work explores learning planning\nknowledge, they still retain limitations due to partial reliance on external\nknowledge or impractical setups. Indeed, prior research has largely overlooked\ndeveloping agents capable of acquiring planning knowledge from scratch,\ndirectly in realistic settings. While realizing this capability is necessary,\nit presents significant challenges, primarily achieving robustness given the\nsubstantial risk of incorporating LLMs' inaccurate knowledge. Moreover,\nefficiency is crucial for practicality as learning can demand prohibitive\nexploration. In response, we introduce Robust and Efficient Planning for\nOpen-world Agents (REPOA), a novel framework designed to tackle these issues.\nREPOA features three key components: adaptive dependency learning and\nfine-grained failure-aware operation memory to enhance robustness to knowledge\ninaccuracies, and difficulty-based exploration to improve learning efficiency.\nOur evaluation in two established open-world testbeds demonstrates REPOA's\nrobust and efficient planning, showcasing its capability to successfully obtain\nchallenging late-game items that were beyond the reach of prior approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.24157v1",
    "published": "2025-05-30T03:01:44+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24156v1",
    "title": "Towards a Generalizable Bimanual Foundation Policy via Flow-based Video Prediction",
    "authors": [
      "Chenyou Fan",
      "Fangzheng Yan",
      "Chenjia Bai",
      "Jiepeng Wang",
      "Chi Zhang",
      "Zhen Wang",
      "Xuelong Li"
    ],
    "abstract": "Learning a generalizable bimanual manipulation policy is extremely\nchallenging for embodied agents due to the large action space and the need for\ncoordinated arm movements. Existing approaches rely on Vision-Language-Action\n(VLA) models to acquire bimanual policies. However, transferring knowledge from\nsingle-arm datasets or pre-trained VLA models often fails to generalize\neffectively, primarily due to the scarcity of bimanual data and the fundamental\ndifferences between single-arm and bimanual manipulation. In this paper, we\npropose a novel bimanual foundation policy by fine-tuning the leading\ntext-to-video models to predict robot trajectories and training a lightweight\ndiffusion policy for action generation. Given the lack of embodied knowledge in\ntext-to-video models, we introduce a two-stage paradigm that fine-tunes\nindependent text-to-flow and flow-to-video models derived from a pre-trained\ntext-to-video model. Specifically, optical flow serves as an intermediate\nvariable, providing a concise representation of subtle movements between\nimages. The text-to-flow model predicts optical flow to concretize the intent\nof language instructions, and the flow-to-video model leverages this flow for\nfine-grained video prediction. Our method mitigates the ambiguity of language\nin single-stage text-to-video prediction and significantly reduces the\nrobot-data requirement by avoiding direct use of low-level actions. In\nexperiments, we collect high-quality manipulation data for real dual-arm robot,\nand the results of simulation and real-world experiments demonstrate the\neffectiveness of our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.24156v1",
    "published": "2025-05-30T03:01:21+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24155v1",
    "title": "Biological Pathway Guided Gene Selection Through Collaborative Reinforcement Learning",
    "authors": [
      "Ehtesamul Azim",
      "Dongjie Wang",
      "Tae Hyun Hwang",
      "Yanjie Fu",
      "Wei Zhang"
    ],
    "abstract": "Gene selection in high-dimensional genomic data is essential for\nunderstanding disease mechanisms and improving therapeutic outcomes.\nTraditional feature selection methods effectively identify predictive genes but\noften ignore complex biological pathways and regulatory networks, leading to\nunstable and biologically irrelevant signatures. Prior approaches, such as\nLasso-based methods and statistical filtering, either focus solely on\nindividual gene-outcome associations or fail to capture pathway-level\ninteractions, presenting a key challenge: how to integrate biological pathway\nknowledge while maintaining statistical rigor in gene selection? To address\nthis gap, we propose a novel two-stage framework that integrates statistical\nselection with biological pathway knowledge using multi-agent reinforcement\nlearning (MARL). First, we introduce a pathway-guided pre-filtering strategy\nthat leverages multiple statistical methods alongside KEGG pathway information\nfor initial dimensionality reduction. Next, for refined selection, we model\ngenes as collaborative agents in a MARL framework, where each agent optimizes\nboth predictive power and biological relevance. Our framework incorporates\npathway knowledge through Graph Neural Network-based state representations, a\nreward mechanism combining prediction performance with gene centrality and\npathway coverage, and collaborative learning strategies using shared memory and\na centralized critic component. Extensive experiments on multiple gene\nexpression datasets demonstrate that our approach significantly improves both\nprediction accuracy and biological interpretability compared to traditional\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.24155v1",
    "published": "2025-05-30T03:01:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24154v1",
    "title": "Major Mergers Mean Major Offset: Drivers of Intrinsic Scatter in The $M_{GCS}-M_h$ Scaling Relation for Massive Elliptical Galaxies",
    "authors": [
      "Veronika Dornan",
      "William E. Harris"
    ],
    "abstract": "In this work we determine the total globular cluster (GC) counts and globular\ncluster system (GCS) total mass estimates for 27 extremely massive elliptical\ngalaxies. The GC 2D spatial distributions of these galaxies were created from\nphotometry of HST images using DOLPHOT in the near-IR wavelength range. The\nprojected radial density profiles of these GCSs were determined using a Voronoi\ntessellation-based technique introduced in our previous paper. We then plot\nthese galaxies on the GCS - halo mass relation alongside previously studied\ngalaxies in the literature. The relation now extends across seven decades of\nhalo mass. We find that the 1:1 slope of this relation holds out to the highest\nmass galaxies, although extremely massive BCG galaxies are shifted to higher\nGCS masses than their lower-mass galaxy counterparts. We find a negative\ncorrelation with massive galaxies' offset from the GCS - halo mass relation and\nthe steepness of their GCS density profiles, and that this is being driven by\nthe red GC populations. We suggest that the biggest influence in intrinsic\nscatter in the GCS - halo mass relation for massive galaxies is through a few\nmajor mergers resulting in accretion of massive satellites with old, red GC\npopulations, rather than many accretions of small satellites with younger, blue\nGC populations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24154v1",
    "published": "2025-05-30T03:00:23+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24153v1",
    "title": "The incidence of magnetic cataclysmic variables can be explained by the late appearance of white dwarf magnetic fields",
    "authors": [
      "Matthias R. Schreiber",
      "Diogo Belloni"
    ],
    "abstract": "Assuming that white dwarf (WD) magnetic fields are generated by a\ncrystallization- and rotation-driven dynamo, the impact of the late appearance\nof WD magnetic fields in cataclysmic variables (CVs) has been shown to\npotentially solve several long-standing problems of CV evolution. However,\nrecent theoretical works show that the dynamo idea might not be viable and that\nthe late appearance of WD magnetic fields might be an age effect rather than\nrelated to the cooling of the core of the WD. We investigated the impact of the\nlate appearance of WD magnetic fields on CV evolution assuming that the fields\nappear at fixed WD ages. We performed CV population synthesis with the BSE code\nto determine the fractions of CVs that become magnetic atcdifferent\nevolutionary stages. These simulations were complemented with MESA tracks that\ntake into account the transfer of spin angular momentum to the orbit which can\ncause a detached phase. We find that the observed fraction of magnetic CVs as a\nfunction of orbital period is well reproduced by our simulations, and that in\nmany CVs the WD should become magnetic close to the period minimum. The\ndetached phase generated by the transfer of spin angular momentum is longest\nfor period bouncers. Interpreting the late appearance of strong WD magnetic\nfields as a simple age effect naturally explains the relative numbers of\nmagnetic CVs in observed samples. As many period bouncers might detach for\nseveral gigayears, the late appearance of WD magnetic fields at a fixed age and\nindependent of the core temperature of the WD can significantly reduce the\npredicted number of accreting period bouncers.",
    "pdf_url": "http://arxiv.org/pdf/2505.24153v1",
    "published": "2025-05-30T02:59:56+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24152v1",
    "title": "The understanding of the penetration and clusterization of 1-alkanol in bilayer membrane: An open outlook based on atomistic molecular dynamics simulation",
    "authors": [
      "Anirban Polley"
    ],
    "abstract": "1-alkanols are well known to have anesthetic and penetration properties,\nthough the mode of operation remains enigmatic. We perform extensive atomistic\nmolecular dynamics simulation to study the penetration of 1-alkanols of\ndifferent chain lengths in the dioleoyl-phosphatidylcholine (DOPC) bilayer\nmodel membrane. Our simulations show that the depth of penetration of 1-alkanol\nincreases with chain length, n, and the deuterium order of the DOPC tail\nincreases with the chain length of the acyl-chain of the 1-alkanol. We find a\ncut-off value for the length of the acyl-chain of 1-alkanol, n = 12, where\n1-alkanol with a chain length greater than the cut-off value takes longer to\npenetrate the membrane. Our simulation study also demonstrates that the\nmembrane exhibits clusters of 1-alkanols with acyl chains longer than the\ncut-off value, whereas 1-alkanols with acyl-chain shorter than the cut-off\nvalue are distributed homogeneously in the membrane and penetrate the membrane\nin a shorter time than longer-acyl-chain 1-alkanols. These findings add to our\nunderstanding of the anomalies in anesthetic molecule partitioning in the cell\nmembrane and may have implications for general anesthesia.",
    "pdf_url": "http://arxiv.org/pdf/2505.24152v1",
    "published": "2025-05-30T02:55:52+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.24151v1",
    "title": "Channel Knowledge Maps for 6G Wireless Networks: Construction, Applications, and Future Challenges",
    "authors": [
      "Xingchen Liu",
      "Shu Sun",
      "Meixia Tao",
      "Aryan Kaushik",
      "Hangsong Yan"
    ],
    "abstract": "The advent of 6G wireless networks promises unprecedented connectivity,\nsupporting ultra-high data rates, low latency, and massive device connectivity.\nHowever, these ambitious goals introduce significant challenges, particularly\nin channel estimation due to complex and dynamic propagation environments. This\npaper explores the concept of channel knowledge maps (CKMs) as a solution to\nthese challenges. CKMs enable environment-aware communications by providing\nlocation-specific channel information, reducing reliance on real-time pilot\nmeasurements. We categorize CKM construction techniques into measurement-based,\nmodel-based, and hybrid methods, and examine their key applications in\nintegrated sensing and communication systems, beamforming, trajectory\noptimization of unmanned aerial vehicles, base station placement, and resource\nallocation. Furthermore, we discuss open challenges and propose future research\ndirections to enhance the robustness, accuracy, and scalability of CKM-based\nsystems in the evolving 6G landscape.",
    "pdf_url": "http://arxiv.org/pdf/2505.24151v1",
    "published": "2025-05-30T02:54:55+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24150v1",
    "title": "Zener tunnelling in biased bilayer graphene via analytic continuation of semiclassical theory",
    "authors": [
      "Harley Scammell",
      "Oleg P. Sushkov"
    ],
    "abstract": "Employing a semiclassical method based on analytic continuation, we compute\nthe electron-hole pair production rate in biased bilayer graphene subject to an\nin-plane electric field. This approach, originally due to Zwaan, bypasses the\nneed for exact solutions at turning points, which are generally unavailable\nbeyond linear or quadratic band structures. Applying this technique to biased\nbilayer graphene reveals non-standard features of the asymptotic wavefunctions,\nin particular the necessity of retaining decaying components even in\nclassically allowed regions. By providing a fully analytic solution, this work\ncomplements and clarifies earlier results based on hybrid analytical-numerical\ntreatments, and importantly establishes the absolute normalisation of the pair\nproduction rate -- and hence of the tunnelling current.",
    "pdf_url": "http://arxiv.org/pdf/2505.24150v1",
    "published": "2025-05-30T02:52:59+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.24149v1",
    "title": "RCCDA: Adaptive Model Updates in the Presence of Concept Drift under a Constrained Resource Budget",
    "authors": [
      "Adam Piaseczny",
      "Md Kamran Chowdhury Shisher",
      "Shiqiang Wang",
      "Christopher G. Brinton"
    ],
    "abstract": "Machine learning (ML) algorithms deployed in real-world environments are\noften faced with the challenge of adapting models to concept drift, where the\ntask data distributions are shifting over time. The problem becomes even more\ndifficult when model performance must be maintained under adherence to strict\nresource constraints. Existing solutions often depend on drift-detection\nmethods that produce high computational overhead for resource-constrained\nenvironments, and fail to provide strict guarantees on resource usage or\ntheoretical performance assurances. To address these shortcomings, we propose\nRCCDA: a dynamic model update policy that optimizes ML training dynamics while\nensuring strict compliance to predefined resource constraints, utilizing only\npast loss information and a tunable drift threshold. In developing our policy,\nwe analytically characterize the evolution of model loss under concept drift\nwith arbitrary training update decisions. Integrating these results into a\nLyapunov drift-plus-penalty framework produces a lightweight policy based on a\nmeasurable accumulated loss threshold that provably limits update frequency and\ncost. Experimental results on three domain generalization datasets demonstrate\nthat our policy outperforms baseline methods in inference accuracy while\nadhering to strict resource constraints under several schedules of concept\ndrift, making our solution uniquely suited for real-time ML deployments.",
    "pdf_url": "http://arxiv.org/pdf/2505.24149v1",
    "published": "2025-05-30T02:49:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24148v1",
    "title": "Critical slowing down of black hole phase transition and kinetic crossover in supercritical regime",
    "authors": [
      "Ran Li",
      "Kun Zhang",
      "Jiayue Yang",
      "Robert B. Mann",
      "Jin Wang"
    ],
    "abstract": "Reissner-Nordstr\\\"{o}m-Anti-de Sitter (RNAdS) black holes in the extended\nphase space exhibit critical behavior analogous to the liquid-gas system, with\ncritical exponents matching those of van der Waals-type phase transitions.\nHowever, the kinetics of these transitions near spinodal and critical points\nremain poorly understood. We demonstrate that both the autocorrelation time and\nthe variance of trajectories increase significantly as the system approaches\nthese special points, signaling critical slowing down. This behavior is driven\nby the flattening of the free energy landscape, as further confirmed by the\nlowest eigenvalue of the Fokker-Planck equation. Moreover, we uncover a clear\ndynamical crossover separating gas-like and liquid-like regimes in the\nsupercritical region. This kinetic crossover defines the Widom line that\nclosely matches the thermodynamic one obtained from the maxima of the isobaric\nheat capacity. These findings contribute to a deeper understanding of the\nkinetics of RNAdS black holes in the vicinity of spinodal and critical points.",
    "pdf_url": "http://arxiv.org/pdf/2505.24148v1",
    "published": "2025-05-30T02:49:09+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.24147v1",
    "title": "Rationales Are Not Silver Bullets: Measuring the Impact of Rationales on Model Performance and Reliability",
    "authors": [
      "Chiwei Zhu",
      "Benfeng Xu",
      "An Yang",
      "Junyang Lin",
      "Quan Wang",
      "Chang Zhou",
      "Zhendong Mao"
    ],
    "abstract": "Training language models with rationales augmentation has been shown to be\nbeneficial in many existing works. In this paper, we identify that such a\nprevailing view does not hold consistently. We conduct comprehensive\ninvestigations to thoroughly inspect the impact of rationales on model\nperformance as well as a novel perspective of model reliability. The results\nlead to several key findings that add new insights upon existing\nunderstandings: 1) Rationales can, at times, deteriorate model performance; 2)\nRationales can, at times, improve model reliability, even outperforming their\nuntrained counterparts; 3) A linear correspondence exists in between the\nperformance and reliability improvements, while both are driven by the\nintrinsic difficulty of the task. These findings provide informative\nregulations on the broad utilization of rationales and raise critical\nimplications on the procedure of explicitly aligning language models with\nimplicit human thoughts. Codes can be found at\nhttps://github.com/Ignoramus0817/rationales.",
    "pdf_url": "http://arxiv.org/pdf/2505.24147v1",
    "published": "2025-05-30T02:39:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24146v2",
    "title": "Quantum anomalous Hall effects and emergent $\\rm{SU}(2)$ Hall ferromagnets at fractional filling of helical trilayer graphene",
    "authors": [
      "Sen Niu",
      "Jason Alicea",
      "D. N. Sheng",
      "Yang Peng"
    ],
    "abstract": "Helical trilayer graphene realizes a versatile moir\\'e system for exploring\ncorrelated topological states emerging from high Chern bands. Motivated by\nrecent experimental observations of anomalous Hall effects at fractional\nfillings of magic-angle helical trilayers, we focus on the higher Chern number\n$|C_{band}|=2$ band and explore gapped many-body Hall states beyond the\nconventional Landau level paradigm. Through extensive exact diagonalization, we\npredict novel phases unattainable in a single $|C_{band}|=1$ band. At filling\n$\\nu=2/3$ and $\\nu=1/3$, a $\\sqrt{3}\\times \\sqrt{3}$ charge-ordered quantum\nHall crystal and a Halperin fractional Chern insulator with Hall conductance\n$|\\sigma_{H}|=2e^2/3h$ are predicted respectively, indicating strong\nparticle-hole asymmetry of the system. At half-filling $\\nu=1/2$, an\nextensively degenerate pseudospin Hall ferromagnet featuring emergent\n$\\rm{SU}(2)$ symmetry is found without the band being flat. Inspired by\nstriking robustness of the ferromagnetic degeneracy, we develop a method to\nunveil and quantify the emergent symmetry via pseudospin operator construction\nin the presence of band dispersion and Coulomb interaction, and demonstrate\npersistence of the $\\rm{SU}(2)$ quantum numbers even far away from the chiral\nlimit. Incorporating spin-valley degrees of freedom, we identify an optimal\nfilling regime $\\nu_{\\rm{total}}=3+\\nu$ for realizing the above states.\nNotably, inter-flavor interactions renormalize the bandwidth and stabilize all\nthe gapped phases even in realistic sublattice corrugation parameter regimes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24146v2",
    "published": "2025-05-30T02:37:07+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.24145v1",
    "title": "Autoregressive regularized score-based diffusion models for multi-scenarios fluid flow prediction",
    "authors": [
      "Wilfried Genuist",
      "Éric Savin",
      "Filippo Gatti",
      "Didier Clouteau"
    ],
    "abstract": "Building on recent advances in scientific machine learning and generative\nmodeling for computational fluid dynamics, we propose a conditional score-based\ndiffusion model designed for multi-scenarios fluid flow prediction. Our model\nintegrates an energy constraint rooted in the statistical properties of\nturbulent flows, improving prediction quality with minimal training, while\nenabling efficient sampling at low cost. The method features a simple and\ngeneral architecture that requires no problem-specific design, supports\nplug-and-play enhancements, and enables fast and flexible solution generation.\nIt also demonstrates an efficient conditioning mechanism that simplifies\ntraining across different scenarios without demanding a redesign of existing\nmodels. We further explore various stochastic differential equation\nformulations to demonstrate how thoughtful design choices enhance performance.\nWe validate the proposed methodology through extensive experiments on complex\nfluid dynamics datasets encompassing a variety of flow regimes and\nconfigurations. Results demonstrate that our model consistently achieves\nstable, robust, and physically faithful predictions, even under challenging\nturbulent conditions. With properly tuned parameters, it achieves accurate\nresults across multiple scenarios while preserving key physical and statistical\nproperties. We present a comprehensive analysis of stochastic differential\nequation impact and discuss our approach across diverse fluid mechanics tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.24145v1",
    "published": "2025-05-30T02:37:05+00:00",
    "categories": [
      "cs.LG",
      "physics.flu-dyn",
      "65N75, 35Q30, 60H15, 76F55, 68T07",
      "I.2.6; G.1.7; I.6.1; I.6.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00081v1",
    "title": "Artificial Empathy: AI based Mental Health",
    "authors": [
      "Aditya Naik",
      "Jovi Thomas",
      "Teja Sree",
      "Himavant Reddy"
    ],
    "abstract": "Many people suffer from mental health problems but not everyone seeks\nprofessional help or has access to mental health care. AI chatbots have\nincreasingly become a go-to for individuals who either have mental disorders or\nsimply want someone to talk to. This paper presents a study on participants who\nhave previously used chatbots and a scenario-based testing of large language\nmodel (LLM) chatbots. Our findings indicate that AI chatbots were primarily\nutilized as a \"Five minute therapist\" or as a non-judgmental companion.\nParticipants appreciated the anonymity and lack of judgment from chatbots.\nHowever, there were concerns about privacy and the security of sensitive\ninformation. The scenario-based testing of LLM chatbots highlighted additional\nissues. Some chatbots were consistently reassuring, used emojis and names to\nadd a personal touch, and were quick to suggest seeking professional help.\nHowever, there were limitations such as inconsistent tone, occasional\ninappropriate responses (e.g., casual or romantic), and a lack of crisis\nsensitivity, particularly in recognizing red flag language and escalating\nresponses appropriately. These findings can inform both the technology and\nmental health care industries on how to better utilize AI chatbots to support\nindividuals during challenging emotional periods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00081v1",
    "published": "2025-05-30T02:36:56+00:00",
    "categories": [
      "q-bio.OT",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "q-bio.OT"
  },
  {
    "id": "http://arxiv.org/abs/2506.15704v1",
    "title": "Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding",
    "authors": [
      "Feiyu Yao",
      "Qian Wang"
    ],
    "abstract": "As large language models (LLMs) continue to support increasingly longer\ncontexts, the memory demand for key-value (KV) caches during decoding grows\nrapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe\nbandwidth. Sparse attention mechanisms alleviate this issue by computing\nattention weights only for selected key-value pairs. However, their indexing\ncomputation typically requires traversing all key vectors, resulting in\nsignificant computational and data transfer overhead. To reduce the cost of\nindex retrieval, existing methods often treat each decoding step as an\nindependent process, failing to exploit the temporal correlations embedded in\nhistorical decoding information. To this end, we propose LFPS(Learn From the\nPast for Sparse Indexing), an acceleration method that dynamically constructs\nsparse indexing candidates based on historical attention patterns. LFPS\ncaptures two prevalent trends in decoder attention -vertical patterns\n(attending to fixed positions) and slash patterns (attending to relative\npositions) -and incorporates a positional expansion strategy to effectively\npredict the Top-k indices for the current step. We validate LFPS on challenging\nlong-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as\nthe base model. Experimental results show that LFPS achieves up to 22.8$\\times$\nspeedup over full attention and 9.6$\\times$ speedup over exact Top-k retrieval\non an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively,\nwhile preserving generation accuracy. These results demonstrate that LFPS\noffers a practical and efficient solution for decoding optimization in\nlong-context LLM inference.",
    "pdf_url": "http://arxiv.org/pdf/2506.15704v1",
    "published": "2025-05-30T02:35:59+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24144v1",
    "title": "Sharp Concentration of Simple Random Tensors II: Asymmetry",
    "authors": [
      "Jiaheng Chen",
      "Daniel Sanz-Alonso"
    ],
    "abstract": "This paper establishes sharp concentration inequalities for simple random\ntensors. Our theory unveils a phenomenon that arises only for asymmetric\ntensors of order $p \\ge 3:$ when the effective ranks of the covariances of the\ncomponent random variables lie on both sides of a critical threshold, an\nadditional logarithmic factor emerges that is not present in sharp bounds for\nsymmetric tensors. To establish our results, we develop empirical process\ntheory for products of $p$ different function classes evaluated at $p$\ndifferent random variables, extending generic chaining techniques for quadratic\nand product empirical processes to higher-order settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.24144v1",
    "published": "2025-05-30T02:35:51+00:00",
    "categories": [
      "math.PR",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.03183v1",
    "title": "Edge Computing for Physics-Driven AI in Computational MRI: A Feasibility Study",
    "authors": [
      "Yaşar Utku Alçalar",
      "Yu Cao",
      "Mehmet Akçakaya"
    ],
    "abstract": "Physics-driven artificial intelligence (PD-AI) reconstruction methods have\nemerged as the state-of-the-art for accelerating MRI scans, enabling higher\nspatial and temporal resolutions. However, the high resolution of these scans\ngenerates massive data volumes, leading to challenges in transmission, storage,\nand real-time processing. This is particularly pronounced in functional MRI,\nwhere hundreds of volumetric acquisitions further exacerbate these demands.\nEdge computing with FPGAs presents a promising solution for enabling PD-AI\nreconstruction near the MRI sensors, reducing data transfer and storage\nbottlenecks. However, this requires optimization of PD-AI models for hardware\nefficiency through quantization and bypassing traditional FFT-based approaches,\nwhich can be a limitation due to their computational demands. In this work, we\npropose a novel PD-AI computational MRI approach optimized for FPGA-based edge\ncomputing devices, leveraging 8-bit complex data quantization and eliminating\nredundant FFT/IFFT operations. Our results show that this strategy improves\ncomputational efficiency while maintaining reconstruction quality comparable to\nconventional PD-AI methods, and outperforms standard clinical methods. Our\napproach presents an opportunity for high-resolution MRI reconstruction on\nresource-constrained devices, highlighting its potential for real-world\ndeployment.",
    "pdf_url": "http://arxiv.org/pdf/2506.03183v1",
    "published": "2025-05-30T02:35:43+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.AR",
      "cs.CV",
      "cs.LG",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24143v1",
    "title": "CrossICL: Cross-Task In-Context Learning via Unsupervised Demonstration Transfer",
    "authors": [
      "Jinglong Gao",
      "Xiao Ding",
      "Lingxiao Zou",
      "Bing Qin",
      "Ting Liu"
    ],
    "abstract": "In-Context Learning (ICL) enhances the performance of large language models\n(LLMs) with demonstrations. However, obtaining these demonstrations primarily\nrelies on manual effort. In most real-world scenarios, users are often\nunwilling or unable to provide such demonstrations. Inspired by the human\nanalogy, we explore a new ICL paradigm CrossICL to study how to utilize\nexisting source task demonstrations in the ICL for target tasks, thereby\nobtaining reliable guidance without any additional manual effort. To explore\nthis, we first design a two-stage alignment strategy to mitigate the\ninterference caused by gaps across tasks, as the foundation for our\nexperimental exploration. Based on it, we conduct comprehensive exploration of\nCrossICL, with 875 NLP tasks from the Super-NI benchmark and six types of LLMs,\nincluding GPT-4o. Experimental results demonstrate the effectiveness of\nCrossICL and provide valuable insights on questions like the criteria for\nselecting cross-task demonstrations, as well as the types of task-gap-induced\ninterference in CrossICL.",
    "pdf_url": "http://arxiv.org/pdf/2505.24143v1",
    "published": "2025-05-30T02:26:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24142v1",
    "title": "A highly sensitive SF$_6$-based leak test system for JUNO 3-inch PMT underwater electronics boxes",
    "authors": [
      "Ziliang Chu",
      "Diru Wu",
      "Miao He",
      "Jilei Xu",
      "Xiaoping Jing",
      "Jian Wang"
    ],
    "abstract": "A total of 25600 3-inch photomultiplier tubes (PMTs), along with their\ncorresponding frontend electronics, have been installed at the Jiangmen\nUnderground Neutrino Observatory (JUNO). These electronics are housed in 200\nstainless steel boxes that operate underwater. To verify the sealing integrity\nof the underwater boxes following integration, we developed an SF$_6$-based\nleak test system, opting against the typical helium-based system due to\nhelium's ability to penetrate the PMT glass. After a few hours of accumulating\nleaking SF$_6$ from the underwater boxes, a leak rate detection limit of\n$2.3\\times{10}^{-9}$~Pa$\\cdot$m$^3$/s in terms of SF$_6$ was achieved,\ncorresponding to $1.65\\times{10}^{-8}$~Pa$\\cdot$ m$^3$/s helium equivalent.\nThis meets the sensitivity requirement of 1$\\times$10$^{-7}$~Pa$\\cdot$m$^3$/s.\nThis system was critical in identifying and replacing a few cases of leaking\nunderwater boxes before installation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24142v1",
    "published": "2025-05-30T02:24:23+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.24141v1",
    "title": "The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models",
    "authors": [
      "Jiashuai Liu",
      "Yingjia Shang",
      "Yingkang Zhan",
      "Di Zhang",
      "Yi Niu",
      "Dong Wei",
      "Xian Wu",
      "Zeyu Gao",
      "Chen Li",
      "Yefeng Zheng"
    ],
    "abstract": "With the widespread adoption of pathology foundation models in both research\nand clinical decision support systems, exploring their security has become a\ncritical concern. However, despite their growing impact, the vulnerability of\nthese models to adversarial attacks remains largely unexplored. In this work,\nwe present the first systematic investigation into the security of pathology\nfoundation models for whole slide image~(WSI) analysis against adversarial\nattacks. Specifically, we introduce the principle of \\textit{local perturbation\nwith global impact} and propose a label-free attack framework that operates\nwithout requiring access to downstream task labels. Under this attack\nframework, we revise four classical white-box attack methods and redefine the\nperturbation budget based on the characteristics of WSI. We conduct\ncomprehensive experiments on three representative pathology foundation models\nacross five datasets and six downstream tasks. Despite modifying only 0.1\\% of\npatches per slide with imperceptible noise, our attack leads to downstream\naccuracy degradation that can reach up to 20\\% in the worst cases. Furthermore,\nwe analyze key factors that influence attack success, explore the relationship\nbetween patch-level vulnerability and semantic content, and conduct a\npreliminary investigation into potential defence strategies. These findings lay\nthe groundwork for future research on the adversarial robustness and reliable\ndeployment of pathology foundation models. Our code is publicly available at:\nhttps://github.com/Jiashuai-Liu-hmos/Attack-WSI-pathology-foundation-models.",
    "pdf_url": "http://arxiv.org/pdf/2505.24141v1",
    "published": "2025-05-30T02:23:46+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24140v1",
    "title": "B2LoRa: Boosting LoRa Transmission for Satellite-IoT Systems with Blind Coherent Combining",
    "authors": [
      "Yimin Zhao",
      "Weibo Wang",
      "Xiong Wang",
      "Linghe Kong",
      "Jiadi Yu",
      "Yifei Zhu",
      "Shiyuan Li",
      "Chong He",
      "Guihai Chen"
    ],
    "abstract": "With the rapid growth of Low Earth Orbit (LEO) satellite networks,\nsatellite-IoT systems using the LoRa technique have been increasingly deployed\nto provide widespread Internet services to low-power and low-cost ground\ndevices. However, the long transmission distance and adverse environments from\nIoT satellites to ground devices pose a huge challenge to link reliability, as\nevidenced by the measurement results based on our real-world setup. In this\npaper, we propose a blind coherent combining design named B2LoRa to boost LoRa\ntransmission performance. The intuition behind B2LoRa is to leverage the\nrepeated broadcasting mechanism inherent in satellite-IoT systems to achieve\ncoherent combining under the low-power and low-cost constraints, where each\nre-transmission at different times is regarded as the same packet transmitted\nfrom different antenna elements within an antenna array. Then, the problem is\ntranslated into aligning these packets at a fine granularity despite the time,\nfrequency, and phase offsets between packets in the case of frequent packet\nloss. To overcome this challenge, we present three designs - joint packet\nsniffing, frequency shift alignment, and phase drift mitigation to deal with\nultra-low SNRs and Doppler shifts featured in satellite-IoT systems,\nrespectively. Finally, experiment results based on our real-world deployments\ndemonstrate the high efficiency of B2LoRa.",
    "pdf_url": "http://arxiv.org/pdf/2505.24140v1",
    "published": "2025-05-30T02:22:59+00:00",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.24139v2",
    "title": "S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation",
    "authors": [
      "Yichen Xie",
      "Runsheng Xu",
      "Tong He",
      "Jyh-Jing Hwang",
      "Katie Luo",
      "Jingwei Ji",
      "Hubert Lin",
      "Letian Chen",
      "Yiren Lu",
      "Zhaoqi Leng",
      "Dragomir Anguelov",
      "Mingxing Tan"
    ],
    "abstract": "The latest advancements in multi-modal large language models (MLLMs) have\nspurred a strong renewed interest in end-to-end motion planning approaches for\nautonomous driving. Many end-to-end approaches rely on human annotations to\nlearn intermediate perception and prediction tasks, while purely\nself-supervised approaches--which directly learn from sensor inputs to generate\nplanning trajectories without human annotations often underperform the state of\nthe art. We observe a key gap in the input representation space: end-to-end\napproaches built on MLLMs are often pretrained with reasoning tasks in 2D image\nspace rather than the native 3D space in which autonomous vehicles plan. To\nthis end, we propose S4-Driver, a scalable self-supervised motion planning\nalgorithm with spatio-temporal visual representation, based on the popular PaLI\nmultimodal large language model. S4-Driver uses a novel sparse volume strategy\nto seamlessly transform the strong visual representation of MLLMs from\nperspective view to 3D space without the need to finetune the vision encoder.\nThis representation aggregates multi-view and multi-frame visual inputs and\nenables better prediction of planning trajectories in 3D space. To validate our\nmethod, we run experiments on both nuScenes and Waymo Open Motion Dataset (with\nin-house camera data). Results show that S4-Driver performs favorably against\nexisting supervised multi-task approaches while requiring no human annotations.\nIt also demonstrates great scalability when pretrained on large volumes of\nunannotated driving logs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24139v2",
    "published": "2025-05-30T02:20:14+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.15703v1",
    "title": "Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance",
    "authors": [
      "Guoqing Chao",
      "Zhenghao Zhang",
      "Lei Meng",
      "Jie Wen",
      "Dianhui Chu"
    ],
    "abstract": "Federated multi-view clustering has been proposed to mine the valuable\ninformation within multi-view data distributed across different devices and has\nachieved impressive results while preserving the privacy. Despite great\nprogress, most federated multi-view clustering methods only used global\npseudo-labels to guide the downstream clustering process and failed to exploit\nthe global information when extracting features. In addition, missing data\nproblem in federated multi-view clustering task is less explored. To address\nthese problems, we propose a novel Federated Incomplete Multi-view Clustering\nmethod with globally Fused Graph guidance (FIMCFG). Specifically, we designed a\ndual-head graph convolutional encoder at each client to extract two kinds of\nunderlying features containing global and view-specific information.\nSubsequently, under the guidance of the fused graph, the two underlying\nfeatures are fused into high-level features, based on which clustering is\nconducted under the supervision of pseudo-labeling. Finally, the high-level\nfeatures are uploaded to the server to refine the graph fusion and\npseudo-labeling computation. Extensive experimental results demonstrate the\neffectiveness and superiority of FIMCFG. Our code is publicly available at\nhttps://github.com/PaddiHunter/FIMCFG.",
    "pdf_url": "http://arxiv.org/pdf/2506.15703v1",
    "published": "2025-05-30T02:17:51+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24138v1",
    "title": "AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits",
    "authors": [
      "Yichen Shi",
      "Ze Zhang",
      "Hongyang Wang",
      "Zhuofu Tao",
      "Zhongyi Li",
      "Bingyu Chen",
      "Yaxin Wang",
      "Zhiping Yu",
      "Ting-Jung Lin",
      "Lei He"
    ],
    "abstract": "Analog/Mixed-Signal (AMS) circuits play a critical role in the integrated\ncircuit (IC) industry. However, automating Analog/Mixed-Signal (AMS) circuit\ndesign has remained a longstanding challenge due to its difficulty and\ncomplexity. Recent advances in Multi-modal Large Language Models (MLLMs) offer\npromising potential for supporting AMS circuit analysis and design. However,\ncurrent research typically evaluates MLLMs on isolated tasks within the domain,\nlacking a comprehensive benchmark that systematically assesses model\ncapabilities across diverse AMS-related challenges. To address this gap, we\nintroduce AMSbench, a benchmark suite designed to evaluate MLLM performance\nacross critical tasks including circuit schematic perception, circuit analysis,\nand circuit design. AMSbench comprises approximately 8000 test questions\nspanning multiple difficulty levels and assesses eight prominent models,\nencompassing both open-source and proprietary solutions such as Qwen 2.5-VL and\nGemini 2.5 Pro. Our evaluation highlights significant limitations in current\nMLLMs, particularly in complex multi-modal reasoning and sophisticated circuit\ndesign tasks. These results underscore the necessity of advancing MLLMs'\nunderstanding and effective application of circuit-specific knowledge, thereby\nnarrowing the existing performance gap relative to human expertise and moving\ntoward fully automated AMS circuit design workflows. Our data is released at\nhttps://huggingface.co/datasets/wwhhyy/AMSBench",
    "pdf_url": "http://arxiv.org/pdf/2505.24138v1",
    "published": "2025-05-30T02:17:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24137v2",
    "title": "Energy-Oriented Computing Architecture Simulator for SNN Training",
    "authors": [
      "Yunhao Ma",
      "Wanyi Jia",
      "Yanyu Lin",
      "Wenjie Lin",
      "Xueke Zhu",
      "Huihui Zhou",
      "Fengwei An"
    ],
    "abstract": "With the growing demand for intelligent computing, neuromorphic computing, a\nparadigm that mimics the structure and functionality of the human brain, offers\na promising approach to developing new high-efficiency intelligent computing\nsystems. Spiking Neural Networks (SNNs), the foundation of neuromorphic\ncomputing, have garnered significant attention due to their unique potential in\nenergy efficiency and biomimetic neural processing. However, current hardware\ndevelopment for efficient SNN training lags significantly. No systematic energy\nevaluation methods exist for SNN training tasks. Therefore, this paper proposes\nan Energy-Oriented Computing Architecture Simulator (EOCAS) for SNN training to\nidentify the optimal architecture. EOCAS investigates the high sparsity of\nspike signals, unique hardware design representations, energy assessment, and\ncomputation patterns to support energy optimization in various architectures.\nUnder the guidance of EOCAS, we implement the power-aimed optimal hardware\narchitecture through Verilog HDL and achieve low energy consumption using\nSynopsys Design Compiler with TSMC-28nm technology library under typical\nparameters. Compared with several State-Of-The-Art (SOTA) DNN and SNN works,\nour hardware architecture outstands others in various criteria.",
    "pdf_url": "http://arxiv.org/pdf/2505.24137v2",
    "published": "2025-05-30T02:17:32+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.24136v1",
    "title": "Sparsity-Driven Parallel Imaging Consistency for Improved Self-Supervised MRI Reconstruction",
    "authors": [
      "Yaşar Utku Alçalar",
      "Mehmet Akçakaya"
    ],
    "abstract": "Physics-driven deep learning (PD-DL) models have proven to be a powerful\napproach for improved reconstruction of rapid MRI scans. In order to train\nthese models in scenarios where fully-sampled reference data is unavailable,\nself-supervised learning has gained prominence. However, its application at\nhigh acceleration rates frequently introduces artifacts, compromising image\nfidelity. To mitigate this shortcoming, we propose a novel way to train PD-DL\nnetworks via carefully-designed perturbations. In particular, we enhance the\nk-space masking idea of conventional self-supervised learning with a novel\nconsistency term that assesses the model's ability to accurately predict the\nadded perturbations in a sparse domain, leading to more reliable and\nartifact-free reconstructions. The results obtained from the fastMRI knee and\nbrain datasets show that the proposed training strategy effectively reduces\naliasing artifacts and mitigates noise amplification at high acceleration\nrates, outperforming state-of-the-art self-supervised methods both visually and\nquantitatively.",
    "pdf_url": "http://arxiv.org/pdf/2505.24136v1",
    "published": "2025-05-30T02:11:25+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24135v1",
    "title": "Finitely Summable $K$-homology, the Index Pairing, and Cantor Minimal Systems",
    "authors": [
      "Levi Lorenzo"
    ],
    "abstract": "We study index pairings for crossed-product $C^*$-algebras arising from\nminimal actions on the Cantor set. We utilize Putnam's orbit-breaking\nAF-subalgebras and embeddings to show we can compute any index pairing for\nCantor minimal system crossed products using Connes' trace formulas. In the\ncase of odometers, we show that the associated algebras have uniformly finitely\nsummable $K$-homology.",
    "pdf_url": "http://arxiv.org/pdf/2505.24135v1",
    "published": "2025-05-30T02:11:23+00:00",
    "categories": [
      "math.OA",
      "math.KT",
      "19K33, 19K56"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24134v1",
    "title": "A Mathematical Perspective On Contrastive Learning",
    "authors": [
      "Ricardo Baptista",
      "Andrew M. Stuart",
      "Son Tran"
    ],
    "abstract": "Multimodal contrastive learning is a methodology for linking different data\nmodalities; the canonical example is linking image and text data. The\nmethodology is typically framed as the identification of a set of encoders, one\nfor each modality, that align representations within a common latent space. In\nthis work, we focus on the bimodal setting and interpret contrastive learning\nas the optimization of (parameterized) encoders that define conditional\nprobability distributions, for each modality conditioned on the other,\nconsistent with the available data. This provides a framework for multimodal\nalgorithms such as crossmodal retrieval, which identifies the mode of one of\nthese conditional distributions, and crossmodal classification, which is\nsimilar to retrieval but includes a fine-tuning step to make it task specific.\n  The framework we adopt also gives rise to crossmodal generative models. This\nprobabilistic perspective suggests two natural generalizations of contrastive\nlearning: the introduction of novel probabilistic loss functions, and the use\nof alternative metrics for measuring alignment in the common latent space. We\nstudy these generalizations of the classical approach in the multivariate\nGaussian setting. In this context we view the latent space identification as a\nlow-rank matrix approximation problem. This allows us to characterize the\ncapabilities of loss functions and alignment metrics to approximate natural\nstatistics, such as conditional means and covariances; doing so yields novel\nvariants on contrastive learning algorithms for specific mode-seeking and for\ngenerative tasks. The framework we introduce is also studied through numerical\nexperiments on multivariate Gaussians, the labeled MNIST dataset, and on a data\nassimilation application arising in oceanography.",
    "pdf_url": "http://arxiv.org/pdf/2505.24134v1",
    "published": "2025-05-30T02:09:37+00:00",
    "categories": [
      "stat.ML",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.24133v3",
    "title": "R-KV: Redundancy-aware KV Cache Compression for Reasoning Models",
    "authors": [
      "Zefan Cai",
      "Wen Xiao",
      "Hanshi Sun",
      "Cheng Luo",
      "Yikai Zhang",
      "Ke Wan",
      "Yucheng Li",
      "Yeyang Zhou",
      "Li-Wen Chang",
      "Jiuxiang Gu",
      "Zhen Dong",
      "Anima Anandkumar",
      "Abedelkadir Asi",
      "Junjie Hu"
    ],
    "abstract": "Reasoning models have demonstrated impressive performance in self-reflection\nand chain-of-thought reasoning. However, they often produce excessively long\noutputs, leading to prohibitively large key-value (KV) caches during inference.\nWhile chain-of-thought inference significantly improves performance on complex\nreasoning tasks, it can also lead to reasoning failures when deployed with\nexisting KV cache compression approaches. To address this, we propose\nRedundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel\nmethod specifically targeting redundant tokens in reasoning models. Our method\npreserves nearly 100% of the full KV cache performance using only 10% of the KV\ncache, substantially outperforming existing KV cache baselines, which reach\nonly 60% of the performance. Remarkably, R-KV even achieves 105% of full KV\ncache performance with 16% of the KV cache. This KV-cache reduction also leads\nto a 90% memory saving and a 6.6X throughput over standard chain-of-thought\nreasoning inference. Experimental results show that R-KV consistently\noutperforms existing KV cache compression baselines across two mathematical\nreasoning datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.24133v3",
    "published": "2025-05-30T02:03:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24132v2",
    "title": "Information-theoretic machine learning for time-varying mode decomposition of separated aerodynamic flows",
    "authors": [
      "Kai Fukami",
      "Ryo Araki"
    ],
    "abstract": "We perform an information-theoretic mode decomposition for separated\naerodynamic flows. The current data-driven approach based on a neural network\nreferred to as deep sigmoidal flow enables the extraction of an informative\ncomponent from a given flow field snapshot with respect to a target variable at\na future time stamp, thereby capturing the causality as a time-varying modal\nstructure. We consider four examples of separated flows around a wing, namely,\n1. laminar periodic wake at post-stall angles of attack, strong gust-wing\ninteractions of 2. numerical and 3. experimental measurements, and 4. a\nturbulent wake in a spanwise-periodic domain. The present approach reveals\ninformative vortical structures associated with a time-varying lift response.\nFor the periodic shedding cases, the informative structures vary in time\ncorresponding to the fluctuation level from their mean values. With the\nexamples of gust-wing interactions, how the effect of gust on a wing emerges in\nthe lift response over time is identified in an interpretable manner.\nFurthermore, for the case of turbulent wake, the present model highlights\nstructures near the wing and vortex cores as informative components based\nsolely on the information metric without any prior knowledge of aerodynamics\nand length scales. This study provides causality-based insights into a range of\nunsteady aerodynamic problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24132v2",
    "published": "2025-05-30T01:59:59+00:00",
    "categories": [
      "physics.flu-dyn",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24131v1",
    "title": "Existence of new self-similar solutions of the fast diffusion equation",
    "authors": [
      "Kin Ming Hui"
    ],
    "abstract": "Let $n\\ge 3$, $0<m<\\frac{n-2}{n}$, $\\eta>0$, $\\eta_0>0$, $\\rho_1>0$,\n$-\\frac{\\rho_1}{2}<\\beta<\\frac{m\\rho_1}{n-2-nm}$ and\n$\\alpha=\\frac{2\\beta+\\rho_1}{1-m}$. We will prove the existence of radially\nsymmetric solution of the equation $\\Delta(f^m/m)+\\alpha f+\\beta x\\cdot\\nabla\nf=0$, $f>0$, in $\\mathbb{R}^n$, which satisfies $f(0)=\\eta_0$, $f_r(0)=0$. When\n$\\beta<\\frac{m\\rho_1}{n-2-nm}$ holds instead, we will also prove the existence\nof radially symmetric solution of the equation $\\Delta(f^m/m)+\\alpha f+\\beta\nx\\cdot\\nabla f=0$, $f>0$, in $\\mathbb{R}^n\\setminus\\{0\\}$, which satisfies\n$\\lim_{x\\to\\infty}|x|^{\\frac{n-2}{m}}f(x)=\\eta$. As a consequence if $f_1$,\n$f_2$, are the solutions of the above two problems with $\\rho_1=1$, then the\nfunction $V_i(x,t)=(T-t)^{\\alpha}f_i(T-t)^{\\beta} x)$, $i=1,2$, are backward\nsimilar solutions of the fast diffusion equation $u_t=\\Delta (u^m/m)$ in\n$\\mathbb{R}^n\\times (-\\infty,T)$ and $(\\mathbb{R}^n\\setminus\\{0\\})\\times\n(-\\infty,T)$ respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.24131v1",
    "published": "2025-05-30T01:58:25+00:00",
    "categories": [
      "math.AP",
      "35J15, 35J70, 35K65"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24130v1",
    "title": "Instantons and topological order in two-leg electron ladders: A universality class",
    "authors": [
      "S. -R. Eric Yang",
      "Hyun Cheol Lee",
      "Hoang-Anh Le",
      "In-Hwan Lee"
    ],
    "abstract": "Our numerical study of the disordered Hubbard model with nearest-neighbor\nhopping shows that a two-leg electron ladder has a finite topological\nentanglement entropy in the regime where the density of states exhibits an\nexponentially decaying gap. The value of the topological entanglement entropy\nsuggests that two-leg ladders belong to the same universality class as graphene\nzigzag nanoribbons, despite several structural differences. A\nShankar-Witten-type bosonization Lagrangian with disorder captures several\nfeatures of the numerically obtained results for disordered two-leg ladders.\nAdditionally, we propose a Lagrangian in which the fusion of two semions\nresiding on different chains generates a fermion (instanton). We apply this\nLagrangian within the framework of the pinned charge-density-wave model and\ncompute the relevant Green's function using the bosonization method. This\napproach predicts a linear density of states at a critical disorder strength.\nBelow this threshold, a soft gap emerges, which is in qualitative agreement\nwith our numerical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.24130v1",
    "published": "2025-05-30T01:57:23+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.24129v1",
    "title": "Evolution of Gas Velocity Dispersion in Discs from $z\\sim8$ to $z\\sim0.5$",
    "authors": [
      "E. Wisnioski",
      "J. T. Mendel",
      "R. Leaman",
      "T. Tsukui",
      "H. Übler",
      "N. M. Förster Schreiber"
    ],
    "abstract": "Together optical/near infrared integral field spectroscopy and resolved\nsub-millimetre interferometry data have mapped the ionised and molecular gas\nmotions in nearly one thousand galaxies at redshifts $z>0.5$. While these\nmeasurements have revealed a number of key properties about the evolution of\ndisc structure and kinematics, heterogenous techniques and samples have led to\ndisparate findings - especially when comparing different dynamical tracers\n(e.g., H$\\alpha$, [C$\\scriptstyle\\rm~II$], CO). In this paper we present a\nliterature compilation of 237 disc galaxies with measurements of velocity\ndispersion and rotational velocity between $z=0.5-8$, a subset of 63 galaxies\nhave measurements of molecular gas fractions. We explore the connection between\ndisc velocity dispersion measurements over 8 Gyrs as traced by multiple phases\nwith the expectations from Toomre stability models. When sample properties are\ntaken into account (e.g., stellar mass, tracer) there is little evolution in\ndisc dispersions between $z\\sim1.5-8$, consistent with expectations from model\nassumptions. We find ionised gas dispersions are higher by $\\sim2\\times$ from\nmolecular gas dispersions at a fixed gas mass. These results are sensitive to\nthe molecular gas tracer with results from [C$\\scriptstyle\\rm~II$] showing\nmixed behaviour indicative of its multi-phase origin. The\n[C$\\scriptstyle\\rm~II$] kinematics can be reconciled with molecular and ionised\ngas tracers when star-formation rates are taken into account.",
    "pdf_url": "http://arxiv.org/pdf/2505.24129v1",
    "published": "2025-05-30T01:57:12+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24128v1",
    "title": "A Criterion for Magnetars Producing Giant Flares",
    "authors": [
      "Y. Meng",
      "Q. -S. Zhang",
      "J. Lin"
    ],
    "abstract": "In this work, the straight flux rope in the model of giant flares on\nmagnetars (Meng et al. 2014) was replaced with a curved one and the equilibrium\nbehavior of the flux rope was investigated. Two footpoints of the flux rope are\nanchored to the spherical surface of magnetar. The forces acting on the flux\nrope include magnetic tension, magnetic pressure, curvature force, gravity. The\nequilibrium in the flux rope, so as in the global configuration, is achieved as\nthese forces offset each other. Changes in the background environment drive the\nconfiguration to evolve through a set of equilibria in a quasi-static fashion\nuntil the critical point is reached and the loss of equilibrium in the\nconfiguration occurs, invoking a giant flare. We establish a criterion to\nidentify magnetars capable of producing giant flares. Among the four forces,\nthe curvature force as well as the magnetic compression tend to expel the flue\nrope outward. In a given magnetic configuration, the curvature force and\nmagnetic compression are proportional to the square of the current intensity of\nthe flux rope, which is determined by the frozen-flux condition and background\nmagnetic field strength. We find that only when $\\eta = G M m /\n({{{R^4}{B_0}^2}})< 0.48 $ is satisfied, the system reaches a critical point\nand potentially undergoes catastrophe. Here, $G, M, m, R$, and $B_{0}$ are the\ngravitational constant, the mass of neutron star, the mass of flux rope, the\nradius of neutron star, and the surface magnetic field strength of neutron\nstar, respectively. The physical meaning of this criterion is that when $\\eta\n\\propto m / B_{0}^{2}$ is small enough, the curvature force and magnetic\npressure can be sufficiently large to overcome gravitational confinement. This\ncriterion establishes a basis for identifying magnetars capable of producing\ngiant flares.",
    "pdf_url": "http://arxiv.org/pdf/2505.24128v1",
    "published": "2025-05-30T01:57:01+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR",
      "hep-th"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.24127v1",
    "title": "Estimating dynamic transmission rates with a Black-Karasinski process in stochastic SIHR models using particle MCMC",
    "authors": [
      "Avery Drennan",
      "Jeffrey Covington",
      "Dan Han",
      "Andrew Attilio",
      "Jaechoul Lee",
      "Richard Posner",
      "Eck Doerry",
      "Joseph Mihaljevic",
      "Ye Chen"
    ],
    "abstract": "Compartmental models are effective in modeling the spread of infectious\npathogens, but have remaining weaknesses in fitting to real datasets exhibiting\nstochastic effects. We propose a stochastic SIHR model with a dynamic\ntransmission rate, where the rate is modeled by the Black-Karasinski (BK)\nprocess - a mean-reverting stochastic process with a stable equilibrium\ndistribution, making it well-suited for modeling long-term epidemic dynamics.\nTo generate sample paths of the BK process and estimate static parameters of\nthe system, we employ particle Markov Chain Monte Carlo (pMCMC) methods due to\ntheir effectiveness in handling complex state-space models and jointly\nestimating parameters. We designed experiments on synthetic data to assess\nestimation accuracy and its impact on inferred transmission rates; all\nBK-process parameters were estimated accurately except the mean-reverting rate.\nWe also assess the sensitivity of pMCMC to misspecification of the\nmean-reversion rate. Our results show that estimation accuracy remains stable\nacross different mean-reversion rates, though smaller values increase error\nvariance and complicate inference results. Finally, we apply our model to\nArizona flu hospitalization data, finding that parameter estimates are\nconsistent with published survey data.",
    "pdf_url": "http://arxiv.org/pdf/2505.24127v1",
    "published": "2025-05-30T01:56:20+00:00",
    "categories": [
      "stat.ME",
      "q-bio.QM",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.15702v1",
    "title": "Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation",
    "authors": [
      "Peter Belcak",
      "Greg Heinrich",
      "Jan Kautz",
      "Pavlo Molchanov"
    ],
    "abstract": "Finetuning language models for a new domain inevitably leads to the\ndeterioration of their general performance. This becomes more pronounced the\nmore limited the finetuning data resource.\n  We introduce minifinetuning (MFT), a method for language model domain\nadaptation that considerably reduces the effects of overfitting-induced\ndegeneralization in low-data settings and which does so in the absence of any\npre-training data for replay. MFT demonstrates 2-10x more favourable\nspecialization-to-degeneralization ratios than standard finetuning across a\nwide range of models and domains and exhibits an intrinsic robustness to\noverfitting when data in the new domain is scarce and down to as little as 500\nsamples.\n  Employing corrective self-distillation that is individualized on the sample\nlevel, MFT outperforms parameter-efficient finetuning methods, demonstrates\nreplay-like degeneralization mitigation properties, and is composable with\neither for a combined effect.",
    "pdf_url": "http://arxiv.org/pdf/2506.15702v1",
    "published": "2025-05-30T01:54:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24126v3",
    "title": "How Students (Really) Use ChatGPT: Uncovering Experiences Among Undergraduate Students",
    "authors": [
      "Tawfiq Ammari",
      "Meilun Chen",
      "S M Mehedi Zaman",
      "Kiran Garimella"
    ],
    "abstract": "This study investigates how undergraduate students engage with ChatGPT in\nself-directed learning contexts. Analyzing naturalistic interaction logs, we\nidentify five dominant use categories of ChatGPT: information seeking, content\ngeneration, language refinement, metacognitive engagement, and conversational\nrepair. Behavioral modeling reveals that structured, goal-driven tasks like\ncoding, multiple-choice solving, and job application writing are strong\npredictors of continued use. Drawing on Self-Directed Learning (SDL) and the\nUses and Gratifications Theory (UGT), we show how students actively manage\nChatGPT's affordances and limitations through prompt adaptation, follow-ups,\nand emotional regulation. Rather than disengaging after breakdowns, students\noften persist through clarification and repair, treating the assistant as both\ntool and learning partner. We also offer design and policy recommendations to\nsupport transparent, responsive, and pedagogically grounded integration of\ngenerative AI in higher education.",
    "pdf_url": "http://arxiv.org/pdf/2505.24126v3",
    "published": "2025-05-30T01:51:08+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24125v1",
    "title": "Weak but influential: Nonlinear contributions of structural connectivity to human cognitive abilities and brain functions",
    "authors": [
      "Rong Wang",
      "Zhao Chang",
      "Xuechun Liu",
      "Daniel Kristanto",
      "Étienne Gérard Guy Gartner",
      "Xinyang Liu",
      "Mianxin Liu",
      "Ying Wu",
      "Ming Lui",
      "Changsong Zhou"
    ],
    "abstract": "Diverse human cognitive abilities are rooted in brain structural connectivity\nwhich has weights spanning several orders of magnitude. However, due to\nfalse-positive challenges in tractography, weak connectivity has been often\ntreated as noise and ignored - despite its prevalence across mammalian brains.\nHere we show that weak connectivity significantly predicts human cognitive\nabilities and supports brain functions through amplification of its small\nweight in a nonlinear manner. Using the Human Connectome Project dataset\n(n=999) and multiple tractography algorithms, we constructed the whole-brain\nstructural connectivity with heterogeneous weights of streamline numbers. We\nfound that weak connectivity involves high individual variability and\nsignificantly predicts general cognitive ability and memory in individuals, and\nit is also critical for whole-brain dynamic simulation and structure-function\ncoupling. Importantly, fusing two post-tractography filtering methods of\nstreamlines potentially results in more reliable connectivity that preserves\nweak links and outperforms conventional thresholding in predicting cognitive\nabilities and functional connectivity. At the network level, weak connectivity\nexpands the operational capacity of brain networks to enhance both global\nintegration and fine-grained segregation, thereby supporting a functional\nbalance essential for cognitive abilities. Finally, we identified a specific\ntype of weak connectivity mainly linking visual/motor to limbic areas with\nnegative gene co-expression, which has a disproportionately large impact on\ncognitive predictions and network dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.24125v1",
    "published": "2025-05-30T01:50:30+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24124v1",
    "title": "Symmetry-Breaking Magneto-Optical Effects in Altermagnets",
    "authors": [
      "Jiuyu Sun",
      "Yongping Du",
      "Erjun Kan"
    ],
    "abstract": "The recently discovered altermagnets (AMs), hosting momentum-dependent spin\nsplitting and vanishing net magnetization, have attracted intensive attention\nfor their promising application in novel spintronics. However, limited by\nfacility and material constraints, experimentally distinguishing them from\nconventional antiferromagnets (AFMs) remains a challenge, which hinders the\nhigh-throughput screening for AM candidates. Here, we predict strain-mediated\nmagneto-optical responses in AMs, which can serve as a universal and\nexperimentally accessible strategy for efficient identification of AMs.\nSymmetry analysis reveals that uniaxial strain can selectively breaks rotation\nor mirror symmetries in AMs while preserving $PT$ symmetry in AFMs, thereby\nactivating distinct linear magneto-optical responses (e.g., optical absorption\nand Kerr rotation) unique to AMs. First-principles calculations across\nprototypical systems -- including semiconducting V$_2$Se$_2$O monolayer and\nmetallic CrSb bulk -- show that the strain-induced optical signatures are\nsignificant enough for conventional optical measurements. Our work establishes\na rapid, non-invasive characterization methodology for altermagnetism across\nmaterial platforms, accelerating its exploration for spin-based technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.24124v1",
    "published": "2025-05-30T01:45:29+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24123v2",
    "title": "Meta-heuristic Hypergraph-Assisted Robustness Optimization for Higher-order Complex Systems",
    "authors": [
      "Xilong Qu",
      "Wenbin Pei",
      "Haifang Li",
      "Qiang Zhang",
      "Bing Xue",
      "Mengjie Zhang"
    ],
    "abstract": "In complex systems (e.g., communication, transportation, and biological\nnetworks), high robustness ensures sustained functionality and stability even\nwhen resisting attacks. However, the inherent structure complexity and the\nunpredictability of attacks make robustness optimization challenging.\nHypergraphs provide a framework for modeling complicated higher-order\ninteractions in complex systems naturally, but their potential has not been\nsystematically investigated. Therefore, we propose an effective method based on\ngenetic algorithms from Artificial Intelligence to optimize the robustness of\ncomplex systems modeled by hypergraphs. By integrating percolation-based\nmetrics with adaptive computational techniques, our method achieves improved\naccuracy and efficiency. Experiments on both synthetic and real-world\nhypergraphs demonstrate the effectiveness of the proposed method in mitigating\nmalicious attacks, with robustness improvements ranging from 16.6% to 205.2%.\nFurther in-depth analysis reveals that optimized hypergraph-based systems\nexhibit a preferential connection mechanism in which high-hyperdegree nodes\npreferentially connect to lower-cardinality hyperedges, forming a distinctive\nLotus topology that significantly improves robustness. Based on this finding,\nwe propose a robust hypergraph generation method that allows robustness to be\ncontrolled via a single parameter rb. Notably, for rb<-1, a distinct Cactus\ntopology emerges as an alternative to the Lotus topology observed for rb>1. The\ndiscovery of the Lotus and Cactus topologies offers valuable insights for\ndesigning robust higher-order networks while providing a useful foundation for\ninvestigating cascading failure dynamics in complex systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24123v2",
    "published": "2025-05-30T01:45:27+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24122v1",
    "title": "The superspace coinvariant ring of type B",
    "authors": [
      "Sutanay Bhattacharya"
    ],
    "abstract": "Given the rank $n$ superspace $\\Omega_n$, the ring of polynomial-valued\ndifferential forms on $\\mathbb C^n$, one can define an action of\nhyperoctahedral group $\\mathfrak B_n$ on it. This leads to a superspace\ncoinvariant ideal $SR_n^B$, defined as the quotient of $\\Omega_n$ by two-sided\nideal generated by all $\\mathfrak B_n$ invariants with vanishing constant\nterms. We derive the Hilbert series of $SR^B_n$ conjectured by Sagan and\nSwanson, and prove an operator theorem that yields a concrete description of\nthe superharmonic space $SH^B_n$ associated to $SR^B_n$ as conjectured by\nSwanson and Wallach. We also derive an explicit basis of $SR^B_n$ using the\ntheory of hyperplane arrangements.",
    "pdf_url": "http://arxiv.org/pdf/2505.24122v1",
    "published": "2025-05-30T01:39:54+00:00",
    "categories": [
      "math.CO",
      "math.AC",
      "math.RT",
      "05E10"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24121v1",
    "title": "Next-to-leading-order prediction for the neutrinoless double-beta decay",
    "authors": [
      "Y. L. Yang",
      "P. W. Zhao"
    ],
    "abstract": "The neutrinoless double-beta decay ($0\\nu\\beta\\beta$) of two neutrons$nn\n\\rightarrow ppee$ is the elementary subprocess of $0\\nu\\beta\\beta$ decay in\nnuclei. Accurate knowledge of the $nn \\rightarrow ppee$ amplitude is required\nto pin down the short-range contributions in the nuclear matrix elements of the\ncandidate nuclei for large-scale $0\\nu\\beta\\beta$ searches. In this Letter, we\nreport the first next-to-leading-order prediction of the nn \\rightarrow ppee\namplitude, with Bayesian uncertainty quantification. This is made possible by\nthe development of the relativistic chiral effective field theory, in which no\nunknown contact term is required up to next-to-leading order. The theory is\nvalidated by reproducing in a parameter-free way the available data on the\ncharge independence and charge symmetry breaking contributions in the\ntwo-nucleon scattering. The present work makes an essential step towards\naddressing the uncertainty in the theoretical calculations of the nuclear\nmatrix elements relevant for $0\\nu\\beta\\beta$ searches.",
    "pdf_url": "http://arxiv.org/pdf/2505.24121v1",
    "published": "2025-05-30T01:39:02+00:00",
    "categories": [
      "nucl-th",
      "hep-ex",
      "hep-ph",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24120v2",
    "title": "CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs",
    "authors": [
      "Ai Jian",
      "Weijie Qiu",
      "Xiaokun Wang",
      "Peiyu Wang",
      "Yunzhuo Hao",
      "Jiangbo Pei",
      "Yichen Wei",
      "Yi Peng",
      "Xuchen Song"
    ],
    "abstract": "Vision-Language Models (VLMs) have demonstrated remarkable progress in\nmultimodal understanding, yet their capabilities for scientific reasoning\nremain inadequately assessed. Current multimodal benchmarks predominantly\nevaluate generic image comprehension or text-driven reasoning, lacking\nauthentic scientific contexts that require domain-specific knowledge\nintegration with visual evidence analysis. To fill this gap, we present CSVQA,\na diagnostic multimodal benchmark specifically designed for evaluating\nscientific reasoning through domain-grounded visual question answering. Our\nbenchmark features 1,378 carefully constructed question-answer pairs spanning\ndiverse STEM disciplines, each demanding domain knowledge, integration of\nvisual evidence, and higher-order reasoning. Compared to prior multimodal\nbenchmarks, CSVQA places greater emphasis on real-world scientific content and\ncomplex reasoning. We additionally propose a rigorous evaluation protocol to\nsystematically assess whether model predictions are substantiated by valid\nintermediate reasoning steps based on curated explanations. Our comprehensive\nevaluation of 15 VLMs on this benchmark reveals notable performance\ndisparities, as even the top-ranked proprietary model attains only 49.6%\naccuracy. This empirical evidence underscores the pressing need for advancing\nscientific reasoning capabilities in VLMs. Our CSVQA is released at\nhttps://huggingface.co/datasets/Skywork/CSVQA",
    "pdf_url": "http://arxiv.org/pdf/2505.24120v2",
    "published": "2025-05-30T01:34:25+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00080v1",
    "title": "Bottom-Up Perspectives on AI Governance: Insights from User Reviews of AI Products",
    "authors": [
      "Stefan Pasch"
    ],
    "abstract": "With the growing importance of AI governance, numerous high-level frameworks\nand principles have been articulated by policymakers, institutions, and expert\ncommunities to guide the development and application of AI. While such\nframeworks offer valuable normative orientation, they may not fully capture the\npractical concerns of those who interact with AI systems in organizational and\noperational contexts. To address this gap, this study adopts a bottom-up\napproach to explore how governance-relevant themes are expressed in user\ndiscourse. Drawing on over 100,000 user reviews of AI products from G2.com, we\napply BERTopic to extract latent themes and identify those most semantically\nrelated to AI governance. The analysis reveals a diverse set of\ngovernance-relevant topics spanning both technical and non-technical domains.\nThese include concerns across organizational processes-such as planning,\ncoordination, and communication-as well as stages of the AI value chain,\nincluding deployment infrastructure, data handling, and analytics. The findings\nshow considerable overlap with institutional AI governance and ethics\nframeworks on issues like privacy and transparency, but also surface overlooked\nareas such as project management, strategy development, and customer\ninteraction. This highlights the need for more empirically grounded,\nuser-centered approaches to AI governance-approaches that complement normative\nmodels by capturing how governance unfolds in applied settings. By\nforegrounding how governance is enacted in practice, this study contributes to\nmore inclusive and operationally grounded approaches to AI governance and\ndigital policy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00080v1",
    "published": "2025-05-30T01:33:21+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24119v1",
    "title": "The State of Multilingual LLM Safety Research: From Measuring the Language Gap to Mitigating It",
    "authors": [
      "Zheng-Xin Yong",
      "Beyza Ermis",
      "Marzieh Fadaee",
      "Stephen H. Bach",
      "Julia Kreutzer"
    ],
    "abstract": "This paper presents a comprehensive analysis of the linguistic diversity of\nLLM safety research, highlighting the English-centric nature of the field.\nThrough a systematic review of nearly 300 publications from 2020--2024 across\nmajor NLP conferences and workshops at *ACL, we identify a significant and\ngrowing language gap in LLM safety research, with even high-resource\nnon-English languages receiving minimal attention. We further observe that\nnon-English languages are rarely studied as a standalone language and that\nEnglish safety research exhibits poor language documentation practice. To\nmotivate future research into multilingual safety, we make several\nrecommendations based on our survey, and we then pose three concrete future\ndirections on safety evaluation, training data generation, and crosslingual\nsafety generalization. Based on our survey and proposed directions, the field\ncan develop more robust, inclusive AI safety practices for diverse global\npopulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24119v1",
    "published": "2025-05-30T01:32:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24118v2",
    "title": "Systolic lattice extensions of classical Schottky groups",
    "authors": [
      "Junzhi Huang",
      "Matthew Zevenbergen"
    ],
    "abstract": "We produce lattice extensions of a dense family of classical Schottky\nsubgroups of the isometry group of $d$-dimensional hyperbolic space. The\nextensions produced are said to be systolic, since all loxodromic elements with\nshort translation length are conjugate into the Schottky groups. Various\ncorollaries are obtained, in particular showing that for all $d\\geq3$, the set\nof complex translation lengths realized by systoles of closed hyperbolic\n$d$-manifolds is dense inside the set of all possible complex translation\nlengths. We also consider complex translation lengths in arithmetic hyperbolic\n$d$-manifolds, and provide a new way to construct non-arithmetic lattices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24118v2",
    "published": "2025-05-30T01:29:30+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24117v1",
    "title": "Bounds on the Excess Minimum Risk via Generalized Information Divergence Measures",
    "authors": [
      "Ananya Omanwar",
      "Fady Alajaji",
      "Tamás Linder"
    ],
    "abstract": "Given finite-dimensional random vectors $Y$, $X$, and $Z$ that form a Markov\nchain in that order (i.e., $Y \\to X \\to Z$), we derive upper bounds on the\nexcess minimum risk using generalized information divergence measures. Here,\n$Y$ is a target vector to be estimated from an observed feature vector $X$ or\nits stochastically degraded version $Z$. The excess minimum risk is defined as\nthe difference between the minimum expected loss in estimating $Y$ from $X$ and\nfrom $Z$. We present a family of bounds that generalize the mutual information\nbased bound of Gy\\\"orfi et al. (2023), using the R\\'enyi and\n$\\alpha$-Jensen-Shannon divergences, as well as Sibson's mutual information.\nOur bounds are similar to those developed by Modak et al. (2021) and Aminian et\nal. (2024) for the generalization error of learning algorithms. However, unlike\nthese works, our bounds do not require the sub-Gaussian parameter to be\nconstant and therefore apply to a broader class of joint distributions over\n$Y$, $X$, and $Z$. We also provide numerical examples under both constant and\nnon-constant sub-Gaussianity assumptions, illustrating that our generalized\ndivergence based bounds can be tighter than the one based on mutual information\nfor certain regimes of the parameter $\\alpha$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24117v1",
    "published": "2025-05-30T01:28:18+00:00",
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24116v1",
    "title": "Humanoid Loco-Manipulations Pattern Generation and Stabilization Control",
    "authors": [
      "Masaki Murooka",
      "Kevin Chappellet",
      "Arnaud Tanguy",
      "Mehdi Benallegue",
      "Iori Kumagai",
      "Mitsuharu Morisawa",
      "Fumio Kanehiro",
      "Abderrahmane Kheddar"
    ],
    "abstract": "In order for a humanoid robot to perform loco-manipulation such as moving an\nobject while walking, it is necessary to account for sustained or alternating\nexternal forces other than ground-feet reaction, resulting from humanoid-object\ncontact interactions. In this letter, we propose a bipedal control strategy for\nhumanoid loco-manipulation that can cope with such external forces. First, the\nbasic formulas of the bipedal dynamics, i.e., linear inverted pendulum mode and\ndivergent component of motion, are derived, taking into account the effects of\nexternal manipulation forces. Then, we propose a pattern generator to plan\ncenter of mass trajectories consistent with the reference trajectory of the\nmanipulation forces, and a stabilizer to compensate for the error between\ndesired and actual manipulation forces. The effectiveness of our controller is\nassessed both in simulation and loco-manipulation experiments with real\nhumanoid robots.",
    "pdf_url": "http://arxiv.org/pdf/2505.24116v1",
    "published": "2025-05-30T01:27:09+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24115v1",
    "title": "FeatureSense: Protecting Speaker Attributes in Always-On Audio Sensing System",
    "authors": [
      "Bhawana Chhaglani",
      "Sarmistha Sarna Gomasta",
      "Yuvraj Agarwal",
      "Jeremy Gummeson",
      "Prashant Shenoy"
    ],
    "abstract": "Audio is a rich sensing modality that is useful for a variety of human\nactivity recognition tasks. However, the ubiquitous nature of smartphones and\nsmart speakers with always-on microphones has led to numerous privacy concerns\nand a lack of trust in deploying these audio-based sensing systems. This paper\naddresses this critical challenge of preserving user privacy when using audio\nfor sensing applications while maintaining utility. While prior work focuses\nprimarily on protecting recoverable speech content, we show that sensitive\nspeaker-specific attributes such as age and gender can still be inferred after\nmasking speech and propose a comprehensive privacy evaluation framework to\nassess this speaker attribute leakage. We design and implement FeatureSense, an\nopen-source library that provides a set of generalizable privacy-aware audio\nfeatures that can be used for wide range of sensing applications. We present an\nadaptive task-specific feature selection algorithm that optimizes the\nprivacy-utility-cost trade-off based on the application requirements. Through\nour extensive evaluation, we demonstrate the high utility of FeatureSense\nacross a diverse set of sensing tasks. Our system outperforms existing privacy\ntechniques by 60.6% in preserving user-specific privacy. This work provides a\nfoundational framework for ensuring trust in audio sensing by enabling\neffective privacy-aware audio classification systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24115v1",
    "published": "2025-05-30T01:26:31+00:00",
    "categories": [
      "cs.SD",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.24114v1",
    "title": "The 'Brazil-nut effect' in bidisperse particle laden flow on an incline",
    "authors": [
      "Jack Luong",
      "Sarah Cassie Burnett",
      "Andrea L. Bertozzi"
    ],
    "abstract": "We study bidisperse suspensions -- suspensions where there are two particle\nspecies of the same density but different sizes -- of a viscous fluid on an\nincline. We use a lubrication theory/thin film model to form a hyperbolic\nsystem of three conservation laws for the height and particle volume fractions.\nThe model predicts, over a range of parameters, that the larger particles rise\nto the top of the layer, consistent with the well-known `Brazil-nut effect' for\ngranular media. The model predicts well-separated fronts of the two species of\nparticles, behind a clear fluid front, at lower inclination angles and volume\nfractions. This corresponds to a triple shock structure in the system of\nconservations. At higher inclination angles and volume fractions the particles\ncongregate at a high concentration at the leading front corresponding to a\nsingular shock in the model. We find excellent agreement between theory and\nexperiments in terms of the overall dynamic structures as the parameters vary.",
    "pdf_url": "http://arxiv.org/pdf/2505.24114v1",
    "published": "2025-05-30T01:25:11+00:00",
    "categories": [
      "physics.flu-dyn",
      "cond-mat.soft",
      "35Q70, 76D08, 70-10"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.24113v1",
    "title": "Distributed Neural Policy Gradient Algorithm for Global Convergence of Networked Multi-Agent Reinforcement Learning",
    "authors": [
      "Pengcheng Dai",
      "Yuanqiu Mo",
      "Wenwu Yu",
      "Wei Ren"
    ],
    "abstract": "This paper studies the networked multi-agent reinforcement learning (NMARL)\nproblem, where the objective of agents is to collaboratively maximize the\ndiscounted average cumulative rewards. Different from the existing methods that\nsuffer from poor expression due to linear function approximation, we propose a\ndistributed neural policy gradient algorithm that features two innovatively\ndesigned neural networks, specifically for the approximate Q-functions and\npolicy functions of agents. This distributed neural policy gradient algorithm\nconsists of two key components: the distributed critic step and the\ndecentralized actor step. In the distributed critic step, agents receive the\napproximate Q-function parameters from their neighboring agents via a\ntime-varying communication networks to collaboratively evaluate the joint\npolicy. In contrast, in the decentralized actor step, each agent updates its\nlocal policy parameter solely based on its own approximate Q-function. In the\nconvergence analysis, we first establish the global convergence of agents for\nthe joint policy evaluation in the distributed critic step. Subsequently, we\nrigorously demonstrate the global convergence of the overall distributed neural\npolicy gradient algorithm with respect to the objective function. Finally, the\neffectiveness of the proposed algorithm is demonstrated by comparing it with a\ncentralized algorithm through simulation in the robot path planning\nenvironment.",
    "pdf_url": "http://arxiv.org/pdf/2505.24113v1",
    "published": "2025-05-30T01:23:14+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00079v1",
    "title": "Who Gets the Kidney? Human-AI Alignment, Indecision, and Moral Values",
    "authors": [
      "John P. Dickerson",
      "Hadi Hosseini",
      "Samarth Khanna",
      "Leona Pierce"
    ],
    "abstract": "The rapid integration of Large Language Models (LLMs) in high-stakes\ndecision-making -- such as allocating scarce resources like donor organs --\nraises critical questions about their alignment with human moral values. We\nsystematically evaluate the behavior of several prominent LLMs against human\npreferences in kidney allocation scenarios and show that LLMs: i) exhibit stark\ndeviations from human values in prioritizing various attributes, and ii) in\ncontrast to humans, LLMs rarely express indecision, opting for deterministic\ndecisions even when alternative indecision mechanisms (e.g., coin flipping) are\nprovided. Nonetheless, we show that low-rank supervised fine-tuning with few\nsamples is often effective in improving both decision consistency and\ncalibrating indecision modeling. These findings illustrate the necessity of\nexplicit alignment strategies for LLMs in moral/ethical domains.",
    "pdf_url": "http://arxiv.org/pdf/2506.00079v1",
    "published": "2025-05-30T01:23:11+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "I.2.1; I.2.7; I.2.11"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24112v2",
    "title": "Deception in Oligopoly Games via Adaptive Nash Seeking Systems",
    "authors": [
      "Michael Tang",
      "Miroslav Krstic",
      "Jorge Poveda"
    ],
    "abstract": "In the theory of multi-agent systems, deception refers to the strategic\nmanipulation of information to influence the behavior of other agents,\nultimately altering the long-term dynamics of the entire system. Recently, this\nconcept has been examined in the context of model-free Nash equilibrium seeking\n(NES) algorithms for noncooperative games. Specifically, it was demonstrated\nthat players can exploit knowledge of other players' exploration signals to\ndrive the system toward a ``deceptive\" Nash equilibrium, while maintaining the\nstability of the closed-loop system. To extend this insight beyond the duopoly\ncase, in this paper we conduct a comprehensive study of deception mechanisms in\nN-player oligopoly markets. By leveraging the structure of these games and\nemploying stability techniques for nonlinear dynamical systems, we provide\ngame-theoretic insights into deception and derive specialized results,\nincluding stability conditions. These results allow players to systematically\nadjust their NES dynamics by tuning gains and signal amplitudes, all while\nensuring closed-loop stability. Additionally, we introduce novel sufficient\nconditions to demonstrate that the (practically) stable equilibrium point of\nthe deceptive dynamics corresponds to a true Nash equilibrium of a different\ngame, which we term the ``deceptive game.\" Our results show that, under the\nproposed adaptive dynamics with deception, a victim firm may develop a\ndistorted perception of its competitors' product appeal, which could lead to\nsetting suboptimal prices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24112v2",
    "published": "2025-05-30T01:21:20+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24111v1",
    "title": "Fine-tune Before Structured Pruning: Towards Compact and Accurate Self-Supervised Models for Speaker Diarization",
    "authors": [
      "Jiangyu Han",
      "Federico Landini",
      "Johan Rohdin",
      "Anna Silnova",
      "Mireia Diez",
      "Jan Cernocky",
      "Lukas Burget"
    ],
    "abstract": "Self-supervised learning (SSL) models like WavLM can be effectively utilized\nwhen building speaker diarization systems but are often large and slow,\nlimiting their use in resource constrained scenarios. Previous studies have\nexplored compression techniques, but usually for the price of degraded\nperformance at high pruning ratios. In this work, we propose to compress SSL\nmodels through structured pruning by introducing knowledge distillation.\nDifferent from the existing works, we emphasize the importance of fine-tuning\nSSL models before pruning. Experiments on far-field single-channel AMI,\nAISHELL-4, and AliMeeting datasets show that our method can remove redundant\nparameters of WavLM Base+ and WavLM Large by up to 80% without any performance\ndegradation. After pruning, the inference speeds on a single GPU for the Base+\nand Large models are 4.0 and 2.6 times faster, respectively. Our source code is\npublicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.24111v1",
    "published": "2025-05-30T01:19:58+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24110v3",
    "title": "Neural Networks as Universal Finite-State Machines: A Constructive Feedforward Simulation Framework for NFAs",
    "authors": [
      "Sahil Rajesh Dhayalkar"
    ],
    "abstract": "We present a formal and constructive simulation framework for\nnondeterministic finite automata (NFAs) using standard feedforward neural\nnetworks. Unlike prior approaches that rely on recurrent architectures or post\nhoc extraction methods, our formulation symbolically encodes automaton states\nas binary vectors, transitions as sparse matrix transformations, and\nnondeterministic branching-including $\\varepsilon$-closures-as compositions of\nshared thresholded updates. We prove that every regular language can be\nrecognized exactly by a depth-unrolled feedforward network with shared\nparameters, independent of input length. Our construction yields not only\nformal equivalence between NFAs and neural networks, but also practical\ntrainability: we demonstrate that these networks can learn NFA acceptance\nbehavior through gradient descent using standard supervised data. Extensive\nexperiments validate all theoretical results, achieving perfect or near-perfect\nagreement on acceptance, state propagation, and closure dynamics. This work\nestablishes a new bridge between symbolic automata theory and modern neural\narchitectures, showing that feedforward networks can perform precise,\ninterpretable, and trainable symbolic computation.",
    "pdf_url": "http://arxiv.org/pdf/2505.24110v3",
    "published": "2025-05-30T01:18:35+00:00",
    "categories": [
      "cs.LG",
      "cs.FL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24109v1",
    "title": "Bernstein-type theorem for constant mean curvature surfaces in the isotropic 3-space",
    "authors": [
      "Shintaro Akamine",
      "Wonjoo Lee",
      "Seong-Deog Yang"
    ],
    "abstract": "There are many non-trivial entire spacelike graphs with constant mean\ncurvature $H$ (CMC $H$, for short) in the isotropic 3-space $\\mathbb{I}^3$. In\nthis paper, we show a value distribution theorem of Gaussian curvature of\ncomplete spacelike constant mean curvature surfaces in $\\mathbb{I}^3$, which\nimplies a Bernstein-type theorem for CMC $H$ graphs in $\\mathbb{I}^3$.",
    "pdf_url": "http://arxiv.org/pdf/2505.24109v1",
    "published": "2025-05-30T01:18:28+00:00",
    "categories": [
      "math.DG",
      "Primary 53A10, Secondary 53B30, 35B08"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24108v2",
    "title": "Federated Foundation Model for GI Endoscopy Images",
    "authors": [
      "Alina Devkota",
      "Annahita Amireskandari",
      "Joel Palko",
      "Shyam Thakkar",
      "Donald Adjeroh",
      "Xiajun Jiang",
      "Binod Bhattarai",
      "Prashnna K. Gyawali"
    ],
    "abstract": "Gastrointestinal (GI) endoscopy is essential in identifying GI tract\nabnormalities in order to detect diseases in their early stages and improve\npatient outcomes. Although deep learning has shown success in supporting GI\ndiagnostics and decision-making, these models require curated datasets with\nlabels that are expensive to acquire. Foundation models offer a promising\nsolution by learning general-purpose representations, which can be finetuned\nfor specific tasks, overcoming data scarcity. Developing foundation models for\nmedical imaging holds significant potential, but the sensitive and protected\nnature of medical data presents unique challenges. Foundation model training\ntypically requires extensive datasets, and while hospitals generate large\nvolumes of data, privacy restrictions prevent direct data sharing, making\nfoundation model training infeasible in most scenarios. In this work, we\npropose a FL framework for training foundation models for gastroendoscopy\nimaging, enabling data to remain within local hospital environments while\ncontributing to a shared model. We explore several established FL algorithms,\nassessing their suitability for training foundation models without relying on\ntask-specific labels, conducting experiments in both homogeneous and\nheterogeneous settings. We evaluate the trained foundation model on three\ncritical downstream tasks--classification, detection, and segmentation--and\ndemonstrate that it achieves improved performance across all tasks,\nhighlighting the effectiveness of our approach in a federated,\nprivacy-preserving setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.24108v2",
    "published": "2025-05-30T01:18:17+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "I.2.10; I.4; I.5"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24107v1",
    "title": "GPTFootprint: Increasing Consumer Awareness of the Environmental Impacts of LLMs",
    "authors": [
      "Nora Graves",
      "Vitus Larrieu",
      "Yingyue Trace Zhang",
      "Joanne Peng",
      "Varun Nagaraj Rao",
      "Yuhan Liu",
      "Andrés Monroy-Hernández"
    ],
    "abstract": "With the growth of AI, researchers are studying how to mitigate its\nenvironmental impact, primarily by proposing policy changes and increasing\nawareness among developers. However, research on AI end users is limited.\nTherefore, we introduce GPTFootprint, a browser extension that aims to increase\nconsumer awareness of the significant water and energy consumption of LLMs, and\nreduce unnecessary LLM usage. GPTFootprint displays a dynamically updating\nvisualization of the resources individual users consume through their ChatGPT\nqueries. After a user reaches a set query limit, a popup prompts them to take a\nbreak from ChatGPT. In a week-long user study, we found that GPTFootprint\nincreases people's awareness of environmental impact, but has limited success\nin decreasing ChatGPT usage. This research demonstrates the potential for\nindividual-level interventions to contribute to the broader goal of sustainable\nAI usage, and provides insights into the effectiveness of awareness-based\nbehavior modification strategies in the context of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.24107v1",
    "published": "2025-05-30T01:17:40+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24106v1",
    "title": "Controller Design for Bilinear Neural Feedback Loops",
    "authors": [
      "Dhruv Shah",
      "Jorge Cortés"
    ],
    "abstract": "This paper considers a class of bilinear systems with a neural network in the\nloop. These arise naturally when employing machine learning techniques to\napproximate general, non-affine in the input, control systems. We propose a\ncontroller design framework that combines linear fractional representations and\ntools from linear parameter varying control to guarantee local exponential\nstability of a desired equilibrium. The controller is obtained from the\nsolution of linear matrix inequalities, which can be solved offline, making the\napproach suitable for online applications. The proposed methodology offers\ntools for stability and robustness analysis of deep neural networks\ninterconnected with dynamical systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.24106v1",
    "published": "2025-05-30T01:13:46+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.24105v1",
    "title": "Training LLMs for EHR-Based Reasoning Tasks via Reinforcement Learning",
    "authors": [
      "Jiacheng Lin",
      "Zhenbang Wu",
      "Jimeng Sun"
    ],
    "abstract": "We present EHRMIND, a practical recipe for adapting large language models\n(LLMs) to complex clinical reasoning tasks using reinforcement learning with\nverifiable rewards (RLVR). While RLVR has succeeded in mathematics and coding,\nits application to healthcare contexts presents unique challenges due to the\nspecialized knowledge and reasoning required for electronic health record (EHR)\ninterpretation. Our pilot study on the MEDCALC benchmark reveals two key\nfailure modes: (1) misapplied knowledge, where models possess relevant medical\nknowledge but apply it incorrectly, and (2) missing knowledge, where models\nlack essential domain knowledge. To address these cases, EHRMIND applies a\ntwo-stage solution: a lightweight supervised fine-tuning (SFT) warm-up that\ninjects missing domain knowledge, stabilizes subsequent training, and\nencourages structured, interpretable outputs; followed by RLVR, which\nreinforces outcome correctness and refines the model's decision-making. We\ndemonstrate the effectiveness of our method across diverse clinical\napplications, including medical calculations (MEDCALC), patient-trial matching\n(TREC CLINICAL TRIALS), and disease diagnosis (EHRSHOT). EHRMIND delivers\nconsistent gains in accuracy, interpretability, and cross-task generalization.\nThese findings offer practical guidance for applying RLVR to enhance LLM\ncapabilities in healthcare settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.24105v1",
    "published": "2025-05-30T01:13:22+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24104v1",
    "title": "Radial and Non-Radial Oscillations of Protoneutron Stars with Hyperonic Composition",
    "authors": [
      "Prashant Thakur",
      "Adamu Issifu",
      "Ishfaq Ahmad Rather",
      "Y. Lim",
      "Tobias Frederico"
    ],
    "abstract": "This paper explores radial and non-radial oscillations of protoneutron stars\n(PNSs) as they evolve from hot, neutrino-rich configurations through\ndeleptonization to cold, catalyzed states. The equation of state (EoS) is\nmodeled using a density-dependent relativistic mean-field framework, with\nstellar evolution characterized by changes in entropy and lepton fraction. Both\nnucleonic and hyperonic compositions are considered. Non-radial $f$- and\n$p_1$-mode oscillations are computed using both the Cowling approximation and\nfull general relativity. Trapped neutrinos initially increase the error of the\nCowling approximation for $f$-modes, which decreases during deleptonization and\nrises again in the cold phase. In contrast, $p_1$-mode errors peak during\nintermediate stages due to evolving pressure and density gradients. The\nemergence of hyperons modestly raises oscillation frequencies in both modes.\nExisting universal relations for $f$-mode frequency and damping time lack model\nindependence for PNSs, motivating a more robust relation. In particular, our\nproposed universal relation involving the moment of inertia and $\\tilde{\\eta}$\nshows strong agreement across all evolutionary phases, offering a\ntemperature-sensitive, model-independent scaling for asteroseismology. Radial\noscillations of a $1.4,M_\\odot$ PNS are also studied for different EoSs. Our\nresults show that displacement ($\\xi$) and pressure perturbation ($\\eta$)\nprofiles are highly sensitive to thermal state, composition, and compactness.\nHyperonic stars show higher frequencies, altered node structures, and stronger\npressure perturbations due to EoS softening. Differences in frequency\nseparation $\\Delta \\nu_n$ and fundamental frequency $\\nu_0$ between nucleonic\nand hyperonic models provide clear observational diagnostics for probing PNS\ninteriors and constraining the dense matter EoS.",
    "pdf_url": "http://arxiv.org/pdf/2505.24104v1",
    "published": "2025-05-30T01:13:14+00:00",
    "categories": [
      "nucl-th",
      "astro-ph.HE"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24103v1",
    "title": "Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors",
    "authors": [
      "Peiran Xu",
      "Yadong Mu"
    ],
    "abstract": "In this work, we focus on the task of weakly supervised affordance grounding,\nwhere a model is trained to identify affordance regions on objects using\nhuman-object interaction images and egocentric object images without dense\nlabels. Previous works are mostly built upon class activation maps, which are\neffective for semantic segmentation but may not be suitable for locating\nactions and functions. Leveraging recent advanced foundation models, we develop\na supervised training pipeline based on pseudo labels. The pseudo labels are\ngenerated from an off-the-shelf part segmentation model, guided by a mapping\nfrom affordance to part names. Furthermore, we introduce three key enhancements\nto the baseline model: a label refining stage, a fine-grained feature alignment\nprocess, and a lightweight reasoning module. These techniques harness the\nsemantic knowledge of static objects embedded in off-the-shelf foundation\nmodels to improve affordance learning, effectively bridging the gap between\nobjects and actions. Extensive experiments demonstrate that the performance of\nthe proposed model has achieved a breakthrough improvement over existing\nmethods. Our codes are available at https://github.com/woyut/WSAG-PLSP .",
    "pdf_url": "http://arxiv.org/pdf/2505.24103v1",
    "published": "2025-05-30T01:12:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24102v1",
    "title": "Beyond the Prototype: Challenges of Long-Term Integration of Visual Analytics in Civic Spaces",
    "authors": [
      "Mahmood Jasim",
      "Narges Mahyar"
    ],
    "abstract": "Despite the recognized benefits of visual analytics systems in supporting\ndata-driven decision-making, their deployment in real-world civic contexts\noften faces significant barriers. Beyond technical challenges such as resource\nconstraints and development complexity, sociotechnical factors, including\norganizational hierarchies, misalignment between designers and stakeholders,\nand concerns around technology adoption hinder their sustained use. In this\nwork, we reflect on our collective experiences of designing, developing, and\ndeploying visual analytics systems in the civic domain and discuss challenges\nacross design and adoption aspects. We emphasize the need for deeper\nintegration strategies, equitable stakeholder engagement, and sustainable\nimplementation frameworks to bridge the gap between research and practice.",
    "pdf_url": "http://arxiv.org/pdf/2505.24102v1",
    "published": "2025-05-30T01:12:14+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24101v2",
    "title": "A SHAP-based explainable multi-level stacking ensemble learning method for predicting the length of stay in acute stroke",
    "authors": [
      "Zhenran Xu"
    ],
    "abstract": "Length of stay (LOS) prediction in acute stroke is critical for improving\ncare planning. Existing machine learning models have shown suboptimal\npredictive performance, limited generalisability, and have overlooked\nsystem-level factors. We aimed to enhance model efficiency, performance, and\ninterpretability by refining predictors and developing an interpretable\nmulti-level stacking ensemble model. Data were accessed from the biennial\nStroke Foundation Acute Audit (2015, 2017, 2019, 2021) in Australia. Models\nwere developed for ischaemic and haemorrhagic stroke separately. The outcome\nwas prolonged LOS (the LOS above the 75th percentile). Candidate predictors\n(ischaemic: n=89; haemorrhagic: n=83) were categorised into patient, clinical,\nand system domains. Feature selection with correlation-based approaches was\nused to refine key predictors. The evaluation of models included discrimination\n(AUC), calibration curves, and interpretability (SHAP plots). In ischaemic\nstroke (N=12,575), prolonged LOS was >=9 days, compared to >=11 days in\nhaemorrhagic stroke (N=1,970). The ensemble model achieved superior performance\n[AUC: 0.824 (95% CI: 0.801-0.846)] and statistically outperformed logistic\nregression [AUC: 0.805 (95% CI: 0.782-0.829); P=0.0004] for ischaemic. However,\nthe model [AUC: 0.843 (95% CI: 0.790-0.895)] did not statistically outperform\nlogistic regression [AUC: 0.828 (95% CI: 0.774-0.882); P=0.136] for\nhaemorrhagic. SHAP analysis identified shared predictors for both types of\nstroke: rehabilitation assessment, urinary incontinence, stroke unit care,\ninability to walk independently, physiotherapy, and stroke care coordinators\ninvolvement. An explainable ensemble model effectively predicted the prolonged\nLOS in ischaemic stroke. Further validation in larger cohorts is needed for\nhaemorrhagic stroke.",
    "pdf_url": "http://arxiv.org/pdf/2505.24101v2",
    "published": "2025-05-30T01:08:26+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24100v2",
    "title": "Halfway to induced saturation for even cycles",
    "authors": [
      "Xinyue Fan",
      "Sahab Hajebi",
      "Sepehr Hajebi",
      "Sophie Spirkl"
    ],
    "abstract": "For graphs $G$ and $H$, we say that $G$ is $H$-free if no induced subgraph of\n$G$ is isomorphic to $H$, and that $G$ is $H$-induced-saturated if $G$ is\n$H$-free but removing or adding any edge in $G$ creates an induced copy of $H$.\nA full characterization of graphs $H$ for which $H$-induced-saturated graphs\nexist remains elusive. Even the case where $H$ is a path -- now settled by the\ncollective results of Martin and Smith, Bonamy et al., and Dvo\\'{r}\\v{a}k --\nwas already quite challenging.\n  What if $H$ is a cycle? The complete answer for odd cycles was given by\nBehren et al., leaving the case of even cycles (except for the $4$-cycle) wide\nopen. Our main result is the first step toward closing this gap: We prove that\nfor every even cycle $H$, there is a graph $G$ with at least one edge such that\n$G$ is $H$-free but removing any edge from $G$ creates an induced copy of $H$\n(in fact, we construct $H$-induced-saturated graphs for every even cycle $H$ on\nat most 10 vertices).",
    "pdf_url": "http://arxiv.org/pdf/2505.24100v2",
    "published": "2025-05-30T01:03:32+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24099v1",
    "title": "Attractor learning for spatiotemporally chaotic dynamical systems using echo state networks with transfer learning",
    "authors": [
      "Mohammad Shah Alam",
      "William Ott",
      "Ilya Timofeyev"
    ],
    "abstract": "In this paper, we explore the predictive capabilities of echo state networks\n(ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypal\nnonlinear PDE that exhibits spatiotemporal chaos. We introduce a novel\nmethodology that integrates ESNs with transfer learning, aiming to enhance\npredictive performance across various parameter regimes of the gKS model. Our\nresearch focuses on predicting changes in long-term statistical patterns of the\ngKS model that result from varying the dispersion relation or the length of the\nspatial domain. We use transfer learning to adapt ESNs to different parameter\nsettings and successfully capture changes in the underlying chaotic attractor.",
    "pdf_url": "http://arxiv.org/pdf/2505.24099v1",
    "published": "2025-05-30T01:01:09+00:00",
    "categories": [
      "math.DS",
      "cs.AI",
      "cs.LG",
      "nlin.CD",
      "stat.ML",
      "37N99, 68T30"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.24098v1",
    "title": "HardTests: Synthesizing High-Quality Test Cases for LLM Coding",
    "authors": [
      "Zhongmou He",
      "Yee Man Choi",
      "Kexun Zhang",
      "Jiabao Ji",
      "Junting Zhou",
      "Dejia Xu",
      "Ivan Bercovich",
      "Aidan Zhang",
      "Lei Li"
    ],
    "abstract": "Verifiers play a crucial role in large language model (LLM) reasoning, needed\nby post-training techniques such as reinforcement learning. However, reliable\nverifiers are hard to get for difficult coding problems, because a\nwell-disguised wrong solution may only be detected by carefully human-written\nedge cases that are difficult to synthesize. To address this issue, we propose\nHARDTESTGEN, a pipeline for high-quality test synthesis using LLMs. With this\npipeline, we curate a comprehensive competitive programming dataset HARDTESTS\nwith 47k problems and synthetic high-quality tests. Compared with existing\ntests, HARDTESTGEN tests demonstrate precision that is 11.3 percentage points\nhigher and recall that is 17.5 percentage points higher when evaluating\nLLM-generated code. For harder problems, the improvement in precision can be as\nlarge as 40 points. HARDTESTS also proves to be more effective for model\ntraining, measured by downstream code generation performance. We will\nopen-source our dataset and synthesis pipeline at\nhttps://leililab.github.io/HardTests/.",
    "pdf_url": "http://arxiv.org/pdf/2505.24098v1",
    "published": "2025-05-30T01:00:34+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24097v1",
    "title": "Performative Risk Control: Calibrating Models for Reliable Deployment under Performativity",
    "authors": [
      "Victor Li",
      "Baiting Chen",
      "Yuzhen Mao",
      "Qi Lei",
      "Zhun Deng"
    ],
    "abstract": "Calibrating blackbox machine learning models to achieve risk control is\ncrucial to ensure reliable decision-making. A rich line of literature has been\nstudying how to calibrate a model so that its predictions satisfy explicit\nfinite-sample statistical guarantees under a fixed, static, and unknown\ndata-generating distribution. However, prediction-supported decisions may\ninfluence the outcome they aim to predict, a phenomenon named performativity of\npredictions, which is commonly seen in social science and economics. In this\npaper, we introduce Performative Risk Control, a framework to calibrate models\nto achieve risk control under performativity with provable theoretical\nguarantees. Specifically, we provide an iteratively refined calibration\nprocess, where we ensure the predictions are improved and risk-controlled\nthroughout the process. We also study different types of risk measures and\nchoices of tail bounds. Lastly, we demonstrate the effectiveness of our\nframework by numerical experiments on the task of predicting credit default\nrisk. To the best of our knowledge, this work is the first one to study\nstatistically rigorous risk control under performativity, which will serve as\nan important safeguard against a wide range of strategic manipulation in\ndecision-making processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.24097v1",
    "published": "2025-05-30T00:59:25+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00078v1",
    "title": "The Role of Berry Phases in the QCD Vacuum Structure",
    "authors": [
      "J. Gamboa"
    ],
    "abstract": "We revisit the origin of the vacuum angle $\\theta$ in QCD using the adiabatic\napproximation combined with Fujikawa's method. By implementing a local chiral\ntransformation and selecting a constant parameter $\\alpha(x) = \\theta$, we show\nthat the QCD $\\theta$-term emerges naturally in the effective action. This\nconstruction provides a non-perturbative interpretation of the axial anomaly\nand highlights the role of the adiabatic gauge condition in isolating the\ntopological sector of the theory. As a consequence, the physical states acquire\ntopological information encoded in the functional Berry phase $\\Delta \\alpha$,\nwhich manifests itself as a holonomy over the space of gauge configurations.\nThis result offers a geometric and dynamical perspective on the structure of\nthe QCD vacuum and its relation to anomaly-induced phases.",
    "pdf_url": "http://arxiv.org/pdf/2506.00078v1",
    "published": "2025-05-30T00:50:48+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24096v1",
    "title": "Towards Tangible Immersion for Cobot Programming-by-Demonstration: Visual, Tactile and Haptic Interfaces for Mixed-Reality Cobot Automation in Semiconductor Manufacturing",
    "authors": [
      "David I. Gonzalez-Aguirre",
      "Javier Felip Leon",
      "Javier Felix-Rendon",
      "Roderico Garcia-Leal",
      "Julio C. Zamora Esquivel"
    ],
    "abstract": "Sensor-based reactive and hybrid approaches have proven a promising line of\nstudy to address imperfect knowledge in grasping and manipulation. However the\nreactive approaches are usually tightly coupled to a particular embodiment\nmaking transfer of knowledge difficult. This paper proposes a paradigm for\nmodeling and execution of reactive manipulation actions, which makes knowledge\ntransfer to different embodiments possible while retaining the reactive\ncapabilities of the embodiments. The proposed approach extends the idea of\ncontrol primitives coordinated by a state machine by introducing an embodiment\nindependent layer of abstraction. Abstract manipulation primitives constitute a\nvocabulary of atomic, embodiment independent actions, which can be coordinated\nusing state machines to describe complex actions. To obtain embodiment specific\nmodels, the abstract state machines are automatically translated to embodiment\nspecific models, such that full capabilities of each platform can be utilized.\nThe strength of the manipulation primitives paradigm is demonstrated by\ndeveloping a set of corresponding embodiment specific primitives for object\ntransport, including a complex reactive grasping primitive. The robustness of\nthe approach is experimentally studied in emptying of a box filled with several\nunknown objects. The embodiment independence is studied by performing a\nmanipulation task on two different platforms using the same abstract\ndescription.",
    "pdf_url": "http://arxiv.org/pdf/2505.24096v1",
    "published": "2025-05-30T00:46:31+00:00",
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.24095v1",
    "title": "SkyLB: A Locality-Aware Cross-Region Load Balancer for LLM Inference",
    "authors": [
      "Tian Xia",
      "Ziming Mao",
      "Jamison Kerney",
      "Ethan J. Jackson",
      "Zhifei Li",
      "Jiarong Xing",
      "Scott Shenker",
      "Ion Stoica"
    ],
    "abstract": "Serving Large Language Models (LLMs) efficiently in multi-region setups\nremains a challenge. Due to cost and GPU availability concerns, providers\ntypically deploy LLMs in multiple regions using instance with long-term\ncommitments, like reserved instances or on-premise clusters, which are often\nunderutilized due to their region-local traffic handling and diurnal traffic\nvariance. In this paper, we introduce SkyLB, a locality-aware multi-region load\nbalancer for LLM inference that aggregates regional diurnal patterns through\ncross-region traffic handling. By doing so, SkyLB enables providers to reserve\ninstances based on expected global demand, rather than peak demand in each\nindividual region. Meanwhile, SkyLB preserves KV-Cache locality and a balanced\nload, ensuring cost efficiency without sacrificing performance. SkyLB achieves\nthis with a cache-aware cross-region traffic handler and a selective pushing\nload balancing mechanism based on checking pending requests. Our evaluation on\nreal-world workloads shows that it achieves 1.12-2.06x higher throughput and\n1.74-6.30x lower latency compared to existing load balancers, while reducing\ntotal serving cost by 25%.",
    "pdf_url": "http://arxiv.org/pdf/2505.24095v1",
    "published": "2025-05-30T00:46:18+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.24094v1",
    "title": "A generating set of Reidemeister moves of oriented virtual knots",
    "authors": [
      "Danish Ali"
    ],
    "abstract": "In oriented knot theory, verifying a quantity is an invariant involves\nchecking its invariance under all oriented Reidemeister moves, a process that\ncan be intricate and time-consuming. A generating set of oriented moves\nsimplifies this by requiring verification for only a minimal subset from which\nall other moves can be derived. While generating sets for classical oriented\nReidemeister moves are well-established, their virtual counterparts are less\nexplored. In this study, we enumerate the oriented virtual Reidemeister moves,\nidentifying seventeen distinct moves after accounting for redundancies due to\nrotational and combinatorial symmetries. We prove that a four-element subset\nserves as a generating set for these moves. This result offers a streamlined\napproach to verifying invariants of oriented virtual knots and lays the\ngroundwork for future advancements in virtual knot theory, particularly in the\nstudy of invariants and their computational properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.24094v1",
    "published": "2025-05-30T00:45:49+00:00",
    "categories": [
      "math.GT",
      "57K10, 57K12"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.24093v1",
    "title": "Very-wide-orbit planets from dynamical instabilities during the stellar birth cluster phase",
    "authors": [
      "André Izidoro",
      "Sean N. Raymond",
      "Nathan A. Kaib",
      "Alessandro Morbidelli",
      "Andrea Isella"
    ],
    "abstract": "Gas giant planets have been detected on eccentric orbits several hundreds of\nastronomical units in size around other stars. It has been proposed that even\nthe Sun hosts a wide-orbit planet of 5-10 Earth masses, often called Planet\nNine, which influences the dynamics of distant Trans-Neptunian objects.\nHowever, the formation mechanism of such planets remains uncertain. Here we use\nnumerical simulations to show that very wide-orbit planets are a natural\nbyproduct of dynamical instabilities that occur in planetary systems while\ntheir host stars are still embedded in natal stellar clusters. A planet is\nfirst brought to an eccentric orbit with an apoastron of several hundred au by\nrepeated gravitational scattering by other planets, then perturbations from\nnearby stellar flybys stabilise the orbit by decoupling the planet from the\ninteraction with the inner system. In our Solar System, the two main events\nlikely conducive to planetary scattering were the growth of Uranus and Neptune,\nand the giant planets instability. We estimate a 5-10% likelihood of creating a\nvery wide-orbit planet if either happened while the Sun was still in its birth\ncluster, rising to 40% if both were. In our simulated exoplanetary systems, the\ntrapping efficiency is 1-5\\%. Our results imply that planets on wide, eccentric\norbits occur at least $10^{-3}$ per star.",
    "pdf_url": "http://arxiv.org/pdf/2505.24093v1",
    "published": "2025-05-30T00:42:50+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.24092v2",
    "title": "Line and Planar Defects with Zero Formation Free Energy: Applications of the Phase Rule toward Ripening-Immune Microstructures",
    "authors": [
      "Ju Li",
      "Yuri Mishin"
    ],
    "abstract": "Extended one- and two-dimensional defects in crystalline materials are\nusually metastable. The thermodynamic ground state of the material is presumed\nto be defect-free. Here, we investigate the conditions under which extended\ndefects, such as grain boundaries, can exist in a multicomponent alloy when the\nlatter reaches the thermodynamic ground state allowed by the Gibbs phase rule.\nWe treat all extended defects as low-dimensional phases on the same footing as\nthe conventional bulk phases. Thermodynamic analysis shows that, in the ground\nstate, the formation free energies of all extended defects must be zero, and\nthe system must follow a generalized phase rule. The latter predicts that only\na finite number of symmetry-related defect types can coexist in the material in\nthe ground state. Guided by the phase rule, we discuss finite-size\npolycrystalline and/or polyphase microstructures that are fully immune to\ncoarsening and their possible transformations.",
    "pdf_url": "http://arxiv.org/pdf/2505.24092v2",
    "published": "2025-05-30T00:40:36+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.24091v1",
    "title": "Temporally Extending Existing Web Archive Collections for Longitudinal Analysis",
    "authors": [
      "Lesley Frew",
      "Michael L. Nelson",
      "Michele C. Weigle"
    ],
    "abstract": "The Environmental Governance and Data Initiative (EDGI) regularly crawled US\nfederal environmental websites between 2016 and 2020 to capture changes between\ntwo presidential administrations. However, because it does not include the\nprevious administration ending in 2008, the collection is unsuitable for\nanswering our research question, Were the website terms deleted by the Trump\nadministration (2017--2021) added by the Obama administration (2009--2017)?\nThus, like many researchers using the Wayback Machine's holdings for historical\nanalysis, we do not have access to a complete collection suiting our needs. To\nanswer our research question, we must extend the EDGI collection back to\nJanuary, 2008. This includes discovering relevant pages that were not included\nin the EDGI collection that persisted through 2020, not just going further back\nin time with the existing pages. We pieced together artifacts collected by\nvarious organizations for their purposes through many means (Save Page Now,\nArchive-It, and more) in order to curate a dataset sufficient for our\nintentions. In this paper, we contribute a methodology to extend existing web\narchive collections temporally to enable longitudinal analysis, including a\ndataset extended with this methodology. We use our new dataset to analyze our\nquestion, Were the website terms deleted by the Trump administration added by\nthe Obama administration? We find that 81 percent of the pages in the dataset\nchanged between 2008 and 2020, and that 87 percent of the pages with terms\ndeleted by the Trump administration were terms added during the Obama\nadministration.",
    "pdf_url": "http://arxiv.org/pdf/2505.24091v1",
    "published": "2025-05-30T00:38:28+00:00",
    "categories": [
      "cs.DL",
      "H.3.7"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24090v1",
    "title": "Searching Clinical Data Using Generative AI",
    "authors": [
      "Karan Hanswadkar",
      "Anika Kanchi",
      "Shivani Tripathi",
      "Shi Qiao",
      "Rony Chatterjee",
      "Alekh Jindal"
    ],
    "abstract": "Artificial Intelligence (AI) is making a major impact on healthcare,\nparticularly through its application in natural language processing (NLP) and\npredictive analytics. The healthcare sector has increasingly adopted AI for\ntasks such as clinical data analysis and medical code assignment. However,\nsearching for clinical information in large and often unorganized datasets\nremains a manual and error-prone process. Assisting this process with\nautomations can help physicians improve their operational productivity\nsignificantly.\n  In this paper, we present a generative AI approach, coined SearchAI, to\nenhance the accuracy and efficiency of searching clinical data. Unlike\ntraditional code assignment, which is a one-to-one problem, clinical data\nsearch is a one-to-many problem, i.e., a given search query can map to a family\nof codes. Healthcare professionals typically search for groups of related\ndiseases, drugs, or conditions that map to many codes, and therefore, they need\nsearch tools that can handle keyword synonyms, semantic variants, and broad\nopen-ended queries. SearchAI employs a hierarchical model that respects the\ncoding hierarchy and improves the traversal of relationships from parent to\nchild nodes. SearchAI navigates these hierarchies predictively and ensures that\nall paths are reachable without losing any relevant nodes.\n  To evaluate the effectiveness of SearchAI, we conducted a series of\nexperiments using both public and production datasets. Our results show that\nSearchAI outperforms default hierarchical traversals across several metrics,\nincluding accuracy, robustness, performance, and scalability. SearchAI can help\nmake clinical data more accessible, leading to streamlined workflows, reduced\nadministrative burden, and enhanced coding and diagnostic accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.24090v1",
    "published": "2025-05-30T00:33:51+00:00",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2506.15701v1",
    "title": "Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning",
    "authors": [
      "Haolin Pan",
      "Hongyu Lin",
      "Haoran Luo",
      "Yang Liu",
      "Kaichun Yao",
      "Libo Zhang",
      "Mingjie Xing",
      "Yanjun Wu"
    ],
    "abstract": "Compiler auto-tuning optimizes pass sequences to improve performance metrics\nsuch as Intermediate Representation (IR) instruction count. Although recent\nadvances leveraging Large Language Models (LLMs) have shown promise in\nautomating compiler tuning, two significant challenges still remain: the\nabsence of high-quality reasoning datasets for agents training, and limited\neffective interactions with the compilation environment. In this work, we\nintroduce Compiler-R1, the first reinforcement learning (RL)-driven framework\nspecifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1\nfeatures a curated, high-quality reasoning dataset and a novel two-stage\nend-to-end RL training pipeline, enabling efficient environment exploration and\nlearning through an outcome-based reward. Extensive experiments across seven\ndatasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction\ncount reduction compared to opt -Oz, showcasing the strong potential of\nRL-trained LLMs for compiler optimization. Our code and datasets are publicly\navailable at https://github.com/Panhaolin2001/Compiler-R1.",
    "pdf_url": "http://arxiv.org/pdf/2506.15701v1",
    "published": "2025-05-30T00:26:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24089v1",
    "title": "Practical Bayes-Optimal Membership Inference Attacks",
    "authors": [
      "Marcus Lassila",
      "Johan Östman",
      "Khac-Hoang Ngo",
      "Alexandre Graell i Amat"
    ],
    "abstract": "We develop practical and theoretically grounded membership inference attacks\n(MIAs) against both independent and identically distributed (i.i.d.) data and\ngraph-structured data. Building on the Bayesian decision-theoretic framework of\nSablayrolles et al., we derive the Bayes-optimal membership inference rule for\nnode-level MIAs against graph neural networks, addressing key open questions\nabout optimal query strategies in the graph setting. We introduce BASE and\nG-BASE, computationally efficient approximations of the Bayes-optimal attack.\nG-BASE achieves superior performance compared to previously proposed\nclassifier-based node-level MIA attacks. BASE, which is also applicable to\nnon-graph data, matches or exceeds the performance of prior state-of-the-art\nMIAs, such as LiRA and RMIA, at a significantly lower computational cost.\nFinally, we show that BASE and RMIA are equivalent under a specific\nhyperparameter setting, providing a principled, Bayes-optimal justification for\nthe RMIA attack.",
    "pdf_url": "http://arxiv.org/pdf/2505.24089v1",
    "published": "2025-05-30T00:23:01+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24087v1",
    "title": "The Special Locus",
    "authors": [
      "Tobi Ramella",
      "Nicholas P. Warner"
    ],
    "abstract": "The special locus plays an important role in the construction of the non-BPS\nmicrostate geometries known as microstrata. These supergravity solutions are\ndual to combinations of left-moving and right-moving momentum states in the\nD1-D5 CFT and because supersymmetry is broken the anomalous dimensions of these\nstates are not protected. This means even the simplest combinations of\nexcitations can create a cascade of frequency dependences through the\nnon-linearities of the supergravity interactions. Solutions on the special\nlocus manage to lock some of these anomalous dimensions together and allow one\nto construct complete solutions using gauged supergravity in three dimensions.\nIn the dual holographic CFT, the special locus has been shown to correspond to\ncreating a \"pure\" gas of single particle states, however, in supergravity the\nspecial locus remains mysterious especially because it does not seem to be\ndefined by a geometric symmetry. In this paper we reveal the supergravity\nstructure of the special locus, first in three-dimensional supergravity and\nthen in the uplift to six dimensions and IIB supergravity. The key insight is\nthat, in three dimensions, a family of dual vector fields must vanish, and this\nimplies that there are algebraic relations between tensor gauge fields in six\nand ten dimensions. These insights show how one can generalize the special\nlocus Ansatz to more general mode excitations of six-dimensional supergravity.\nWe also construct the full six-dimensional uplift of the simplest special\nlocus.",
    "pdf_url": "http://arxiv.org/pdf/2505.24087v1",
    "published": "2025-05-30T00:16:53+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.24088v1",
    "title": "Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting",
    "authors": [
      "Chen Huang",
      "Skyler Seto",
      "Hadi Pouransari",
      "Mehrdad Farajtabar",
      "Raviteja Vemulapalli",
      "Fartash Faghri",
      "Oncel Tuzel",
      "Barry-John Theobald",
      "Josh Susskind"
    ],
    "abstract": "Vision foundation models pre-trained on massive data encode rich\nrepresentations of real-world concepts, which can be adapted to downstream\ntasks by fine-tuning. However, fine-tuning foundation models on one task often\nleads to the issue of concept forgetting on other tasks. Recent methods of\nrobust fine-tuning aim to mitigate forgetting of prior knowledge without\naffecting the fine-tuning performance. Knowledge is often preserved by matching\nthe original and fine-tuned model weights or feature pairs. However, such\npoint-wise matching can be too strong, without explicit awareness of the\nfeature neighborhood structures that encode rich knowledge as well. We propose\na novel regularization method Proxy-FDA that explicitly preserves the\nstructural knowledge in feature space. Proxy-FDA performs Feature Distribution\nAlignment (using nearest neighbor graphs) between the pre-trained and\nfine-tuned feature spaces, and the alignment is further improved by informative\nproxies that are generated dynamically to increase data diversity. Experiments\nshow that Proxy-FDA significantly reduces concept forgetting during\nfine-tuning, and we find a strong correlation between forgetting and a\ndistributional distance metric (in comparison to L2 distance). We further\ndemonstrate Proxy-FDA's benefits in various fine-tuning settings (end-to-end,\nfew-shot and continual tuning) and across different tasks like image\nclassification, captioning and VQA.",
    "pdf_url": "http://arxiv.org/pdf/2505.24088v1",
    "published": "2025-05-30T00:16:53+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24086v1",
    "title": "ComposeAnything: Composite Object Priors for Text-to-Image Generation",
    "authors": [
      "Zeeshan Khan",
      "Shizhe Chen",
      "Cordelia Schmid"
    ],
    "abstract": "Generating images from text involving complex and novel object arrangements\nremains a significant challenge for current text-to-image (T2I) models.\nAlthough prior layout-based methods improve object arrangements using spatial\nconstraints with 2D layouts, they often struggle to capture 3D positioning and\nsacrifice quality and coherence. In this work, we introduce ComposeAnything, a\nnovel framework for improving compositional image generation without retraining\nexisting T2I models. Our approach first leverages the chain-of-thought\nreasoning abilities of LLMs to produce 2.5D semantic layouts from text,\nconsisting of 2D object bounding boxes enriched with depth information and\ndetailed captions. Based on this layout, we generate a spatial and depth aware\ncoarse composite of objects that captures the intended composition, serving as\na strong and interpretable prior that replaces stochastic noise initialization\nin diffusion-based T2I models. This prior guides the denoising process through\nobject prior reinforcement and spatial-controlled denoising, enabling seamless\ngeneration of compositional objects and coherent backgrounds, while allowing\nrefinement of inaccurate priors. ComposeAnything outperforms state-of-the-art\nmethods on the T2I-CompBench and NSR-1K benchmarks for prompts with 2D/3D\nspatial arrangements, high object counts, and surreal compositions. Human\nevaluations further demonstrate that our model generates high-quality images\nwith compositions that faithfully reflect the text.",
    "pdf_url": "http://arxiv.org/pdf/2505.24086v1",
    "published": "2025-05-30T00:13:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.24085v1",
    "title": "DeepBoost-AF: A Novel Unsupervised Feature Learning and Gradient Boosting Fusion for Robust Atrial Fibrillation Detection in Raw ECG Signals",
    "authors": [
      "Alireza Jafari",
      "Fereshteh Yousefirizi",
      "Vahid Seydi"
    ],
    "abstract": "Atrial fibrillation (AF) is a prevalent cardiac arrhythmia associated with\nelevated health risks, where timely detection is pivotal for mitigating\nstroke-related morbidity. This study introduces an innovative hybrid\nmethodology integrating unsupervised deep learning and gradient boosting models\nto improve AF detection. A 19-layer deep convolutional autoencoder (DCAE) is\ncoupled with three boosting classifiers-AdaBoost, XGBoost, and LightGBM\n(LGBM)-to harness their complementary advantages while addressing individual\nlimitations. The proposed framework uniquely combines DCAE with gradient\nboosting, enabling end-to-end AF identification devoid of manual feature\nextraction. The DCAE-LGBM model attains an F1-score of 95.20%, sensitivity of\n99.99%, and inference latency of four seconds, outperforming existing methods\nand aligning with clinical deployment requirements. The DCAE integration\nsignificantly enhances boosting models, positioning this hybrid system as a\nreliable tool for automated AF detection in clinical settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.24085v1",
    "published": "2025-05-30T00:08:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.24084v2",
    "title": "Complemented subspaces of Banach lattices",
    "authors": [
      "David de Hevia",
      "Pedro Tradacete"
    ],
    "abstract": "We survey recent developments on the structure of complemented subspaces of\nBanach lattices, including in particular the construction of a complemented\nsubspace of a $C(K)$-space which is not linearly isomorphic to any Banach\nlattice. Motivated by this, several natural questions and directions of future\nresearch are presented. We provide an approach to some of these problems using\ntools from the theory of free Banach lattices.",
    "pdf_url": "http://arxiv.org/pdf/2505.24084v2",
    "published": "2025-05-30T00:06:44+00:00",
    "categories": [
      "math.FA",
      "46B42, 46B03"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.24083v1",
    "title": "Purcell Enhancement and Suppression in Laser Cooling of Yb$^{3+}$:YLF Nanocrystals in a Fabry-Pérot Microcavity",
    "authors": [
      "Lucas Mendicino",
      "Franco Mayo",
      "Christian Schmiegelow",
      "Augusto Roncaglia"
    ],
    "abstract": "We investigate the improvement of anti-Stokes laser cooling of a\nYb$^{3+}$:YLF nanocrystal in a Fabry-P\\'erot microcavity via the Purcell\neffect. Our analysis accounts for both the enhancement of emission lines\nresonant with the cavity transmission and the suppression of off-resonance\nemissions. Using a quantum-mechanical framework, we modeled the Yb$^{3+}$ ions\nin a YLiF$_4$ matrix and the laser system to calculate the minimum achievable\ntemperature and cooling efficiency, incorporating cavity-induced modifications\nto experimental data on emission cross section. Our results indicate that for\ntemperatures below 100~K, the cooling efficiency ($\\eta_c$) is consistently\nenhanced, and the minimum achievable temperature is reduced comfortably below\nthe current limits. We also show how the inclusion of Purcell inhibition\neffects can lead to improvements in the cooling efficiency ranging from 25\\% to\n65\\%, with respect to the case when only Purcell enhancement is considered.",
    "pdf_url": "http://arxiv.org/pdf/2505.24083v1",
    "published": "2025-05-30T00:05:24+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.24082v3",
    "title": "Collimation of Fast Radio Burster 20201124A; Repeaters vs. Apparent Non-Repeaters",
    "authors": [
      "J. I. Katz"
    ],
    "abstract": "The recent report of a period in the active repeating Fast Radio Burster\n20201124A and of its spindown rate place bounds on the solid angle of its\nemission on the basis of energetics. The bound depends on the (unknown)\nefficiency of conversion of rotational energy to coherent radio emission and\nimplies a lower bound on the Lorentz factor of the radiating charges. Bursts\nmay be emitted along the magnetic dipole axis, in repeaters aligned with the\nrotational axis and the line of sight but misaligned in apparent non-repeaters.\nThis may explain the difficulty of finding periodicity in repeaters and the low\nduty cycle of apparent non-repeaters.",
    "pdf_url": "http://arxiv.org/pdf/2505.24082v3",
    "published": "2025-05-30T00:03:32+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  }
]