[
  {
    "id": "http://arxiv.org/abs/2505.16085v1",
    "title": "Distribution of antiferromagnetic rare-earth domains in multiferroic Dy$_{0.7}$Tb$_{0.3}$FeO$_3$",
    "authors": [
      "Yannik Zemp",
      "Ehsan Hassanpour",
      "Jan Gerrit Horstmann",
      "Yusuke Tokunaga",
      "Yasujiro Taguchi",
      "Yoshinori Tokura",
      "Thomas Lottermoser",
      "Mads C. Weber",
      "Manfred Fiebig"
    ],
    "abstract": "In many multiferroics, rare-earth and transition-metal orders exist side by\nside. For analyzing their interaction and its consequences for the multiferroic\nstate, the associated domain patterns and their spatial correlation can give\nvaluable insight. Unfortunately, this is often hampered by the lack of access\nto the domains of the rare-earth order. Here, we uncover such a domain pattern\nfor the antiferromagnetic and multiferroic Dy$_{0.7}$Tb$_{0.3}$FeO$_3$. Optical\nsecond harmonic generation reveals the formation of column-like Dy/Tb domains.\nInterestingly, the columns form perpendicular to the magnetically induced\nelectric polarization. Hence, the antiferromagnetic rare-earth order forces the\nferroelectric domains to form nominally charged head-to-head and tail-to-tail\ndomain walls, thus playing a leading role in the domain formation within the\nmultiferroic phase. In turn, to reduce energy cost, the ferroelectric order\ncauses a reduced rare-earth domain-wall density along the direction of the\nelectric polarization. This interplay highlights the multiferroic character of\nthe Dy$_{0.7}$Tb$_{0.3}$FeO$_3$ domain pattern. We position\nDy$_{0.7}$Tb$_{0.3}$FeO$_3$ within the broader landscape of rare-earth\nmultiferroics and identify three distinct scenarios for the role of rare-earth\norder in these.",
    "pdf_url": "http://arxiv.org/pdf/2505.16085v1",
    "published": "2025-05-21T23:57:32+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16084v2",
    "title": "Motion Priors Reimagined: Adapting Flat-Terrain Skills for Complex Quadruped Mobility",
    "authors": [
      "Zewei Zhang",
      "Chenhao Li",
      "Takahiro Miki",
      "Marco Hutter"
    ],
    "abstract": "Reinforcement learning (RL)-based motion imitation methods trained on\ndemonstration data can effectively learn natural and expressive motions with\nminimal reward engineering but often struggle to generalize to novel\nenvironments. We address this by proposing a hierarchical RL framework in which\na low-level policy is first pre-trained to imitate animal motions on flat\nground, thereby establishing motion priors. A subsequent high-level,\ngoal-conditioned policy then builds on these priors, learning residual\ncorrections that enable perceptive locomotion, local obstacle avoidance, and\ngoal-directed navigation across diverse and rugged terrains. Simulation\nexperiments illustrate the effectiveness of learned residuals in adapting to\nprogressively challenging uneven terrains while still preserving the locomotion\ncharacteristics provided by the motion priors. Furthermore, our results\ndemonstrate improvements in motion regularization over baseline models trained\nwithout motion priors under similar reward setups. Real-world experiments with\nan ANYmal-D quadruped robot confirm our policy's capability to generalize\nanimal-like locomotion skills to complex terrains, demonstrating smooth and\nefficient locomotion and local navigation performance amidst challenging\nterrains with obstacles.",
    "pdf_url": "http://arxiv.org/pdf/2505.16084v2",
    "published": "2025-05-21T23:56:11+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16083v1",
    "title": "FR-Mamba: Time-Series Physical Field Reconstruction Based on State Space Model",
    "authors": [
      "Jiahuan Long",
      "Wenzhe Zhang",
      "Ning Wang",
      "Tingsong Jiang",
      "Wen Yao"
    ],
    "abstract": "Physical field reconstruction (PFR) aims to predict the state distribution of\nphysical quantities (e.g., velocity, pressure, and temperature) based on\nlimited sensor measurements. It plays a critical role in domains such as fluid\ndynamics and thermodynamics. However, existing deep learning methods often fail\nto capture long-range temporal dependencies, resulting in suboptimal\nperformance on time-evolving physical systems. To address this, we propose\nFR-Mamba, a novel spatiotemporal flow field reconstruction framework based on\nstate space modeling. Specifically, we design a hybrid neural network\narchitecture that combines Fourier Neural Operator (FNO) and State Space Model\n(SSM) to capture both global spatial features and long-range temporal\ndependencies. We adopt Mamba, a recently proposed efficient SSM architecture,\nto model long-range temporal dependencies with linear time complexity. In\nparallel, the FNO is employed to capture non-local spatial features by\nleveraging frequency-domain transformations. The spatiotemporal representations\nextracted by these two components are then fused to reconstruct the full-field\ndistribution of the physical system. Extensive experiments demonstrate that our\napproach significantly outperforms existing PFR methods in flow field\nreconstruction tasks, achieving high-accuracy performance on long sequences.",
    "pdf_url": "http://arxiv.org/pdf/2505.16083v1",
    "published": "2025-05-21T23:54:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16082v1",
    "title": "Oh SnapMMD! Forecasting Stochastic Dynamics Beyond the Schr√∂dinger Bridge's End",
    "authors": [
      "Renato Berlinghieri",
      "Yunyi Shen",
      "Jialong Jiang",
      "Tamara Broderick"
    ],
    "abstract": "Scientists often want to make predictions beyond the observed time horizon of\n\"snapshot\" data following latent stochastic dynamics. For example, in time\ncourse single-cell mRNA profiling, scientists have access to cellular\ntranscriptional state measurements (snapshots) from different biological\nreplicates at different time points, but they cannot access the trajectory of\nany one cell because measurement destroys the cell. Researchers want to\nforecast (e.g.) differentiation outcomes from early state measurements of stem\ncells. Recent Schr\\\"odinger-bridge (SB) methods are natural for interpolating\nbetween snapshots. But past SB papers have not addressed forecasting -- likely\nsince existing methods either (1) reduce to following pre-set reference\ndynamics (chosen before seeing data) or (2) require the user to choose a fixed,\nstate-independent volatility since they minimize a Kullback-Leibler divergence.\nEither case can lead to poor forecasting quality. In the present work, we\npropose a new framework, SnapMMD, that learns dynamics by directly fitting the\njoint distribution of both state measurements and observation time with a\nmaximum mean discrepancy (MMD) loss. Unlike past work, our method allows us to\ninfer unknown and state-dependent volatilities from the observed data. We show\nin a variety of real and synthetic experiments that our method delivers\naccurate forecasts. Moreover, our approach allows us to learn in the presence\nof incomplete state measurements and yields an $R^2$-style statistic that\ndiagnoses fit. We also find that our method's performance at interpolation (and\ngeneral velocity-field reconstruction) is at least as good as (and often better\nthan) state-of-the-art in almost all of our experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16082v1",
    "published": "2025-05-21T23:52:57+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16081v1",
    "title": "BiasLab: Toward Explainable Political Bias Detection with Dual-Axis Annotations and Rationale Indicators",
    "authors": [
      "KMA Solaiman"
    ],
    "abstract": "We present BiasLab, a dataset of 300 political news articles annotated for\nperceived ideological bias. These articles were selected from a curated\n900-document pool covering diverse political events and source biases. Each\narticle is labeled by crowdworkers along two independent scales, assessing\nsentiment toward the Democratic and Republican parties, and enriched with\nrationale indicators. The annotation pipeline incorporates targeted worker\nqualification and was refined through pilot-phase analysis. We quantify\ninter-annotator agreement, analyze misalignment with source-level outlet bias,\nand organize the resulting labels into interpretable subsets. Additionally, we\nsimulate annotation using schema-constrained GPT-4o, enabling direct comparison\nto human labels and revealing mirrored asymmetries, especially in\nmisclassifying subtly right-leaning content. We define two modeling tasks:\nperception drift prediction and rationale type classification, and report\nbaseline performance to illustrate the challenge of explainable bias detection.\nBiasLab's rich rationale annotations provide actionable interpretations that\nfacilitate explainable modeling of political bias, supporting the development\nof transparent, socially aware NLP systems. We release the dataset, annotation\nschema, and modeling code to encourage research on human-in-the-loop\ninterpretability and the evaluation of explanation effectiveness in real-world\nsettings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16081v1",
    "published": "2025-05-21T23:50:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16080v1",
    "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation",
    "authors": [
      "Jiayue Liu",
      "Zhongchao Yi",
      "Zhengyang Zhou",
      "Qihe Huang",
      "Kuo Yang",
      "Xu Wang",
      "Yang Wang"
    ],
    "abstract": "Discovering regularities from spatiotemporal systems can benefit various\nscientific and social planning. Current spatiotemporal learners usually train\nan independent model from a specific source data that leads to limited\ntransferability among sources, where even correlated tasks requires new design\nand training. The key towards increasing cross-domain knowledge is to enable\ncollective intelligence and model evolution. In this paper, inspired by\nneuroscience theories, we theoretically derive the increased information\nboundary via learning cross-domain collective intelligence and propose a\nSynaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the\nmodel independence and enables cross-domain knowledge to be shared and\naggregated. Specifically, we first re-order the sample groups to imitate the\nhuman curriculum learning, and devise two complementary learners, elastic\ncommon container and task-independent extractor to allow model growth and\ntask-wise commonality and personality disentanglement. Then an adaptive dynamic\ncoupler with a new difference metric determines whether the new sample group\nshould be incorporated into common container to achieve model evolution under\nvarious domains. Experiments show that SynEVO improves the generalization\ncapacity by at most 42% under cross-domain scenarios and SynEVO provides a\nparadigm of NeuroAI for knowledge transfer and adaptation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16080v1",
    "published": "2025-05-21T23:45:51+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16079v1",
    "title": "Tight Practical Bounds for Subgraph Densities in Ego-centric Networks",
    "authors": [
      "Connor Mattes",
      "Esha Datta",
      "Ali Pinar"
    ],
    "abstract": "Subgraph densities play a crucial role in network analysis, especially for\nthe identification and interpretation of meaningful substructures in complex\ngraphs. Localized subgraph densities, in particular, can provide valuable\ninsights into graph structures. Distinguishing between\nmathematically-determined and domain-driven subgraph density features, however,\nposes challenges. For instance, the lack or presence of certain structures can\nbe explained by graph density or degree distribution. These differences are\nespecially meaningful in applied contexts as they allow us to identify\ninstances where the data induces specific network structures, such as\nfriendships in social networks. The goal of this paper is to measure these\ndifferences across various types of graphs, conducting social media analysis\nfrom a network perspective. To this end, we first provide tighter bounds on\nsubgraph densities. We then introduce the subgraph spread ratio to quantify the\nrealized subgraph densities of specific networks relative to the feasible\nbounds. Our novel approach combines techniques from flag algebras,\nmotif-counting, and topological data analysis. Crucially, effective adoption of\nthe state-of-the-art in the plain flag algebra method yields feasible regions\nup to three times tighter than prior best-known results, thereby enabling more\naccurate and direct comparisons across graphs. We additionally perform an\nempirical analysis of 11 real-world networks. We observe that social networks\nconsistently have smaller subgraph spread ratios than other types of networks,\nsuch as linkage-mapping networks for Wikipedia pages. This aligns with our\nintuition about social relationships: such networks have meaningful structure\nthat makes them distinct. The subgraph spread ratio enables the quantification\nof intuitive understandings of network structures and provides a metric for\ncomparing types of networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16079v1",
    "published": "2025-05-21T23:41:04+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16078v3",
    "title": "Small Language Models in the Real World: Insights from Industrial Text Classification",
    "authors": [
      "Lujun Li",
      "Lama Sleem",
      "Niccolo' Gentile",
      "Geoffrey Nichil",
      "Radu State"
    ],
    "abstract": "With the emergence of ChatGPT, Transformer models have significantly advanced\ntext classification and related tasks. Decoder-only models such as Llama\nexhibit strong performance and flexibility, yet they suffer from inefficiency\non inference due to token-by-token generation, and their effectiveness in text\nclassification tasks heavily depends on prompt quality. Moreover, their\nsubstantial GPU resource requirements often limit widespread adoption. Thus,\nthe question of whether smaller language models are capable of effectively\nhandling text classification tasks emerges as a topic of significant interest.\nHowever, the selection of appropriate models and methodologies remains largely\nunderexplored. In this paper, we conduct a comprehensive evaluation of prompt\nengineering and supervised fine-tuning methods for transformer-based text\nclassification. Specifically, we focus on practical industrial scenarios,\nincluding email classification, legal document categorization, and the\nclassification of extremely long academic texts. We examine the strengths and\nlimitations of smaller models, with particular attention to both their\nperformance and their efficiency in Video Random-Access Memory (VRAM)\nutilization, thereby providing valuable insights for the local deployment and\napplication of compact models in industrial settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16078v3",
    "published": "2025-05-21T23:39:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16077v1",
    "title": "Ensembling Sparse Autoencoders",
    "authors": [
      "Soham Gadgil",
      "Chris Lin",
      "Su-In Lee"
    ],
    "abstract": "Sparse autoencoders (SAEs) are used to decompose neural network activations\ninto human-interpretable features. Typically, features learned by a single SAE\nare used for downstream applications. However, it has recently been shown that\nSAEs trained with different initial weights can learn different features,\ndemonstrating that a single SAE captures only a limited subset of features that\ncan be extracted from the activation space. Motivated by this limitation, we\npropose to ensemble multiple SAEs through naive bagging and boosting.\nSpecifically, SAEs trained with different weight initializations are ensembled\nin naive bagging, whereas SAEs sequentially trained to minimize the residual\nerror are ensembled in boosting. We evaluate our ensemble approaches with three\nsettings of language models and SAE architectures. Our empirical results\ndemonstrate that ensembling SAEs can improve the reconstruction of language\nmodel activations, diversity of features, and SAE stability. Furthermore,\nensembling SAEs performs better than applying a single SAE on downstream tasks\nsuch as concept detection and spurious correlation removal, showing improved\npractical utility.",
    "pdf_url": "http://arxiv.org/pdf/2505.16077v1",
    "published": "2025-05-21T23:31:21+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16076v1",
    "title": "AudioMorphix: Training-free audio editing with diffusion probabilistic models",
    "authors": [
      "Jinhua Liang",
      "Yuanzhe Chen",
      "Yi Yuan",
      "Dongya Jia",
      "Xiaobin Zhuang",
      "Zhuo Chen",
      "Yuping Wang",
      "Yuxuan Wang"
    ],
    "abstract": "Editing sound with precision is a crucial yet underexplored challenge in\naudio content creation. While existing works can manipulate sounds by text\ninstructions or audio exemplar pairs, they often struggled to modify audio\ncontent precisely while preserving fidelity to the original recording. In this\nwork, we introduce a novel editing approach that enables localized\nmodifications to specific time-frequency regions while keeping the remaining of\nthe audio intact by operating on spectrograms directly. To achieve this, we\npropose AudioMorphix, a training-free audio editor that manipulates a target\nregion on the spectrogram by referring to another recording. Inspired by\nmorphing theory, we conceptualize audio mixing as a process where different\nsounds blend seamlessly through morphing and can be decomposed back into\nindividual components via demorphing. Our AudioMorphix optimizes the noised\nlatent conditioned on raw input and reference audio while rectifying the guided\ndiffusion process through a series of energy functions. Additionally, we\nenhance self-attention layers with a cache mechanism to preserve detailed\ncharacteristics from the original recordings. To advance audio editing\nresearch, we devise a new evaluation benchmark, which includes a curated\ndataset with a variety of editing instructions. Extensive experiments\ndemonstrate that AudioMorphix yields promising performance on various audio\nediting tasks, including addition, removal, time shifting and stretching, and\npitch shifting, achieving high fidelity and precision. Demo and code are\navailable at this url.",
    "pdf_url": "http://arxiv.org/pdf/2505.16076v1",
    "published": "2025-05-21T23:23:37+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16075v1",
    "title": "Spectroscopic study of globular and fuzzy clusters in Lenticular galaxy NGC 1023",
    "authors": [
      "Miguel A. L√≥pez-Santamar√≠a",
      "Y. D. Mayya",
      "Luis Lomel√≠-N√∫√±ez",
      "L. Rodr√≠guez-Merino",
      "Jairo A. Alzate",
      "Arianna Cortesi",
      "P. A. Ovando",
      "D. Rosa-Gonz√°lez"
    ],
    "abstract": "We here report the results from spectroscopic observations of a sample of 26\nglobular cluster (GC) and 21 faint fuzzy (FF) candidates in the lenticular\ngalaxy NGC 1023 using the 10.4-m Gran Telescopio Canarias. Using the\nrecessional velocities and stellar absorption features, we determine that 18\nand 9 of the observed candidates are bona fide GCs and FFs, respectively. The\nmajority of the rejected FF candidates are background emission line galaxies\nfor which we determine their redshifts. We used the spectroscopic data to\ndetermine velocity, age, metallicity and extinction of all bona fide clusters.\nWe find that FFs are clearly younger (age = 7-9 Gyr) than GCs (age > 10 Gyr).\nBoth kind of clusters in this galaxy are metal-rich ([Fe/H] = -0.58 $\\pm$\n0.33). The ages and metallicities of individual FFs reported here are the first\nsuch measurements in any galaxy and agree with the previously-reported\nmeasurement on stacked spectrum. The kinematical analysis reaffirms that the\nFFs belong to the disk of the galaxy, suggesting that their progenitors are\nmost likely massive, compact disk clusters that have been able to survive for\nlong timescales. We propose that the fuzzy appearance of FFs as compared to the\nGCs is a consequence of the dynamical evolution of their progenitor super star\nclusters in the disks of low-mass galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16075v1",
    "published": "2025-05-21T23:21:19+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16074v2",
    "title": "Bidirectional Variational Autoencoders",
    "authors": [
      "Bart Kosko",
      "Olaoluwa Adigun"
    ],
    "abstract": "We present the new bidirectional variational autoencoder (BVAE) network\narchitecture. The BVAE uses a single neural network both to encode and decode\ninstead of an encoder-decoder network pair. The network encodes in the forward\ndirection and decodes in the backward direction through the same synaptic web.\nSimulations compared BVAEs and ordinary VAEs on the four image tasks of image\nreconstruction, classification, interpolation, and generation. The image\ndatasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and\nCelebA-64 face images. The bidirectional structure of BVAEs cut the parameter\ncount by almost 50% and still slightly outperformed the unidirectional VAEs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16074v2",
    "published": "2025-05-21T23:19:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16073v1",
    "title": "Age-Energy Analysis in Multi-Source Systems with Wake-up Control and Packet Management",
    "authors": [
      "Jie Gong",
      "Jiajie Huang"
    ],
    "abstract": "In recent years, there has been an increasing focus on real-time mobile\napplications, such as news updates and weather forecast. In these applications,\ndata freshness is of significant importance, which can be measured by\nage-of-synchronization (AoS). At the same time, the reduction of carbon\nemission is increasingly required by the communication operators. Thus, how to\nreduce energy consumption while keeping the data fresh becomes a matter of\nconcern. In this paper, we study the age-energy trade-off in a multi-source\nsingle-server system, where the server can turn to sleep mode to save energy.\nWe adopt the stochastic hybrid system (SHS) method to analyze the average AoS\nand power consumption with three wake-up policies including N-policy,\nsingle-sleep policy and multi-sleep policy, and three packet preemption\nstrategies, including Last-Come-First-Serve with preemption-in-Service\n(LCFS-S), LCFS with preemption-only-in-Waiting (LCFS-W), and LCFS with\npreemption-and-Queueing (LCFS-Q). The trade-off performance is analyzed via\nboth closed-form expressions and numerical simulations. It is found that\nN-policy attains the best trade-off performance among all three sleep policies.\nAmong packet management strategies, LCFS-S is suitable for scenarios with high\nrequirements on energy saving and small arrival rate difference between\nsources. LCFS-Q is suitable for scenarios with high requirements on information\nfreshness and large arrival rate difference between sources.",
    "pdf_url": "http://arxiv.org/pdf/2505.16073v1",
    "published": "2025-05-21T23:17:57+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16072v1",
    "title": "Exploring Seismic Signal Detection and Source Identification of Atmospheric Entries: The Hayabusa2 Sample Return Capsule as a Benchmark",
    "authors": [
      "Iona Clemente",
      "Eleanor K. Sansom",
      "Hadrien A. R. Devillepoix",
      "Taichi Kawamura",
      "Benjamin A. Fernando",
      "Raphael F. Garcia",
      "Olivia Collet"
    ],
    "abstract": "This exploratory study investigates whether seismic signals can be used to\ninfer fragmentation during a fireball event. Re-entry objects, particularly\nsample return capsules (SRCs) such as the one from the Hayabusa2 mission,\nbehave similarly to slow meteors during atmospheric entry and provide valuable\ninsights into natural fireball events. In this study, we initially analyse\nseismic signals from the Hayabusa2 SRC re-entry, which took place on December\n5, 2020, over South Australia. The SRC's signature was captured by a dense\nnetwork of seismic stations (Eakin, 2018; O'Donnell et al., 2020), offering a\nunique opportunity to investigate the signals' characteristics and verify their\nconnection to the re-entry event. The ballistic trajectory was confirmed as the\nsource shock mechanism for this event. We isolate this signal and use it as a\nreference for a ballistic shock signature and compare it to three other\nfireball case studies, including a suborbital re-entry and two natural\nmeteoroids. Although factors such as local geology and atmospheric conditions\nwere not considered in this preliminary study, our results show promise, with\nhigh correlations for events with purely ballistic trajectories and lower\ncorrelations for those involving fragmentation or airbursts. This implies that\nseismic data may be able to disambiguate whether any particular fireball event\nunderwent significant fragmentation or airburst, key phenomena for assessing\nbody strengths.",
    "pdf_url": "http://arxiv.org/pdf/2505.16072v1",
    "published": "2025-05-21T23:15:53+00:00",
    "categories": [
      "astro-ph.EP",
      "physics.geo-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17128v1",
    "title": "Predicting At-Risk Programming Students in Small Imbalanced Datasets using Synthetic Data",
    "authors": [
      "Daniel Flood",
      "Matthew England",
      "Beate Grawemeyer"
    ],
    "abstract": "This study is part of a larger project focused on measuring, understanding,\nand improving student engagement in programming education. We investigate\nwhether synthetic data generation can help identify at-risk students earlier in\na small, imbalanced dataset from an introductory programming module. The\nanalysis used anonymised records from 379 students, with 15\\% marked as\nfailing, and applied several machine learning algorithms. The first experiments\nshowed poor recall for the failing group. However, using synthetic data\ngeneration methods led to a significant improvement in performance. Our results\nsuggest that machine learning can help identify at-risk students early in\nprogramming courses when combined with synthetic data. This research lays the\ngroundwork for validating and using these models with live student cohorts in\nthe future, to allow for timely and effective interventions that can improve\nstudent outcomes. It also includes feature importance analysis to refine\nformative tasks. Overall, this study contributes to developing practical\nworkflows that help detect disengagement early and improve student success in\nprogramming education.",
    "pdf_url": "http://arxiv.org/pdf/2505.17128v1",
    "published": "2025-05-21T23:14:25+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.16071v1",
    "title": "A Match Made in Heaven: Linking Observables in Inflationary Cosmology",
    "authors": [
      "David Stefanyszyn",
      "Xi Tong",
      "Yuhang Zhu"
    ],
    "abstract": "Cosmological correlation functions of inflaton and graviton perturbations are\nthe fundamental observables of early universe cosmology and remain a primary\ntarget for observations. In this work, we ask the following question: are these\nobservables independent of one another? We find that in the parity-odd sector\nof inflationary perturbation theory, the answer is a resounding no! In earlier\nwork we derived a correlator-to-correlator factorisation formula which states\nthat parity-odd correlators factorise into lower-point correlators under some\nmild assumptions on the underlying theory. In this work, we show that these\nassumptions are satisfied in dynamical Chern-Simons gravity where the action of\nminimal inflation is augmented by a coupling between the inflaton and the\ngravitational Chern-Simons term. Such a theory gives rise to a parity-odd\ntrispectrum of curvature perturbations, and we show that such a trispectrum can\nbe expressed solely in terms of the bispectrum that arises due to the minimal\ncoupling between the inflaton and graviton, and the graviton power spectrum\nwhich receives a parity-odd correction in this theory. The trispectrum is\nquadratic in this mixed inflaton-graviton bispectrum and can therefore be\ninterpreted as a ``double copy\". Our final expression for the parity-odd\ntrispectrum is a relatively simple function of the external momenta that is\nrational and factorised.",
    "pdf_url": "http://arxiv.org/pdf/2505.16071v1",
    "published": "2025-05-21T23:07:18+00:00",
    "categories": [
      "hep-th",
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16070v2",
    "title": "A Distributed Local Energy Market Clearing Framework Using a Two-Loop ADMM Method",
    "authors": [
      "Milad Kabirifar",
      "Biswarup Mukherjee",
      "S. Gokul Krishnan",
      "Charalambos Konstantinou",
      "Subhash Lakshminarayana"
    ],
    "abstract": "The diversity of prosumers' resources in energy communities can provide\nsignificant technical and economic benefits to both prosumers and the\ndistribution system operator (DSO). To maximize these benefits, a coordination\nframework is required to address all techno-economic constraints as well as the\nobjectives of all agents. This paper presents a fully distributed\nmarket-clearing scheme to coordinate the strategies of agents within a local\nenergy community. In the proposed framework, prosumers, the DSO, and the local\nmarket operator (LMO) are the participating agents. The framework addresses the\npreferences and techno-economic constraints of all actors while preserving\ntheir privacy. The proposed model is based on a modified alternating direction\nmethod of multipliers (ADMM) method with two outer and inner loops; the outer\nloop models the interactions between the LMO and prosumers, while the inner\nloop addresses the interactions between the LMO and the DSO. The model is\ndemonstrated on IEEE-69bus test network, showcasing its effectiveness from\nvarious perspectives.",
    "pdf_url": "http://arxiv.org/pdf/2505.16070v2",
    "published": "2025-05-21T23:01:58+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.17127v1",
    "title": "Pixels Versus Priors: Controlling Knowledge Priors in Vision-Language Models through Visual Counterfacts",
    "authors": [
      "Michal Golovanevsky",
      "William Rudman",
      "Michael Lepori",
      "Amir Bar",
      "Ritambhara Singh",
      "Carsten Eickhoff"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) perform well on tasks such as visual\nquestion answering, but it remains unclear whether their reasoning relies more\non memorized world knowledge or on the visual information present in the input\nimage. To investigate this, we introduce Visual CounterFact, a new dataset of\nvisually-realistic counterfactuals that put world knowledge priors (e.g, red\nstrawberry) into direct conflict with visual input (e.g, blue strawberry).\nUsing Visual CounterFact, we show that model predictions initially reflect\nmemorized priors, but shift toward visual evidence in mid-to-late layers. This\ndynamic reveals a competition between the two modalities, with visual input\nultimately overriding priors during evaluation. To control this behavior, we\npropose Pixels Versus Priors (PvP) steering vectors, a mechanism for\ncontrolling model outputs toward either world knowledge or visual input through\nactivation-level interventions. On average, PvP successfully shifts 92.5% of\ncolor and 74.6% of size predictions from priors to counterfactuals. Together,\nthese findings offer new tools for interpreting and controlling factual\nbehavior in multimodal models.",
    "pdf_url": "http://arxiv.org/pdf/2505.17127v1",
    "published": "2025-05-21T22:56:55+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16069v1",
    "title": "Central limit theorem for the determinantal point process with the confluent hypergeometric kernel",
    "authors": [
      "Sergei M. Gorbunov"
    ],
    "abstract": "We consider the convergence of additive functionals under the determinantal\npoint process with the confluent hypergeometric kernel, corresponding to a\nsufficiently smooth function $f(x/R)$, as $R\\to\\infty$. We show that these\nfunctionals approach Gaussian distribution and give an estimate on the\nKolmogorov-Smirnov distance. To obtain these results we derive an exact\nidentity for expectations of multiplicative functionals in terms of Fredholm\ndeterminants.",
    "pdf_url": "http://arxiv.org/pdf/2505.16069v1",
    "published": "2025-05-21T22:47:16+00:00",
    "categories": [
      "math.FA",
      "math-ph",
      "math.MP",
      "math.PR",
      "47B35 (Primary) 60G55 (Secondary)"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16068v1",
    "title": "Evaluating Voting Design Vulnerabilities for Retroactive Funding",
    "authors": [
      "Jay Yu",
      "Austin Bennett",
      "Billy Gao",
      "Rebecca Joseph"
    ],
    "abstract": "Retroactive Public Goods Funding (RetroPGF) rewards blockchain projects based\non proven impact rather than future promises. This paper reviews voting\nmechanisms for Optimism's RetroPGF, where \"badgeholders\" allocate rewards to\nvaluable projects. We explore Optimism's previous schemes for RetroPGF voting,\nincluding quadratic, mean, and median voting. We present a proof-based formal\nanalysis for vulnerabilities in these voting schemes, empirically validate\nthese vulnerabilities using voting simulations, and offer assessments and\npractical recommendations for future iterations of Optimism's system based on\nour findings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16068v1",
    "published": "2025-05-21T22:46:46+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.17126v1",
    "title": "Conformal Language Model Reasoning with Coherent Factuality",
    "authors": [
      "Maxon Rubin-Toles",
      "Maya Gambhir",
      "Keshav Ramji",
      "Aaron Roth",
      "Surbhi Goel"
    ],
    "abstract": "Language models are increasingly being used in important decision pipelines,\nso ensuring the correctness of their outputs is crucial. Recent work has\nproposed evaluating the \"factuality\" of claims decomposed from a language model\ngeneration and applying conformal prediction techniques to filter out those\nclaims that are not factual. This can be effective for tasks such as\ninformation retrieval, where constituent claims may be evaluated in isolation\nfor factuality, but is not appropriate for reasoning tasks, as steps of a\nlogical argument can be evaluated for correctness only within the context of\nthe claims that precede them. To capture this, we define \"coherent factuality\"\nand develop a conformal-prediction-based method to guarantee coherent\nfactuality for language model outputs. Our approach applies split conformal\nprediction to subgraphs within a \"deducibility\" graph\" that represents the\nsteps of a reasoning problem. We evaluate our method on mathematical reasoning\nproblems from the MATH and FELM datasets and find that our algorithm\nconsistently produces correct and substantiated orderings of claims, achieving\ncoherent factuality across target coverage levels. Moreover, we achieve 90%\nfactuality on our stricter definition while retaining 80% or more of the\noriginal claims, highlighting the utility of our deducibility-graph-guided\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2505.17126v1",
    "published": "2025-05-21T22:40:51+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16067v1",
    "title": "How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior",
    "authors": [
      "Zidi Xiong",
      "Yuping Lin",
      "Wenya Xie",
      "Pengfei He",
      "Jiliang Tang",
      "Himabindu Lakkaraju",
      "Zhen Xiang"
    ],
    "abstract": "Memory is a critical component in large language model (LLM)-based agents,\nenabling them to store and retrieve past executions to improve task performance\nover time. In this paper, we conduct an empirical study on how memory\nmanagement choices impact the LLM agents' behavior, especially their long-term\nperformance. Specifically, we focus on two fundamental memory operations that\nare widely used by many agent frameworks-addition, which incorporates new\nexperiences into the memory base, and deletion, which selectively removes past\nexperiences-to systematically study their impact on the agent behavior. Through\nour quantitative analysis, we find that LLM agents display an\nexperience-following property: high similarity between a task input and the\ninput in a retrieved memory record often results in highly similar agent\noutputs. Our analysis further reveals two significant challenges associated\nwith this property: error propagation, where inaccuracies in past experiences\ncompound and degrade future performance, and misaligned experience replay,\nwhere outdated or irrelevant experiences negatively influence current tasks.\nThrough controlled experiments, we show that combining selective addition and\ndeletion strategies can help mitigate these negative effects, yielding an\naverage absolute performance gain of 10% compared to naive memory growth.\nFurthermore, we highlight how memory management choices affect agents' behavior\nunder challenging conditions such as task distribution shifts and constrained\nmemory resources. Our findings offer insights into the behavioral dynamics of\nLLM agent memory systems and provide practical guidance for designing memory\ncomponents that support robust, long-term agent performance. We also release\nour code to facilitate further study.",
    "pdf_url": "http://arxiv.org/pdf/2505.16067v1",
    "published": "2025-05-21T22:35:01+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16066v1",
    "title": "Merge to Mix: Mixing Datasets via Model Merging",
    "authors": [
      "Zhixu Silvia Tao",
      "Kasper Vinken",
      "Hao-Wei Yeh",
      "Avi Cooper",
      "Xavier Boix"
    ],
    "abstract": "Mixing datasets for fine-tuning large models (LMs) has become critical for\nmaximizing performance on downstream tasks. However, composing effective\ndataset mixtures typically relies on heuristics and trial-and-error, often\nrequiring multiple fine-tuning runs to achieve the desired outcome. We propose\na novel method, $\\textit{Merge to Mix}$, that accelerates composing dataset\nmixtures through model merging. Model merging is a recent technique that\ncombines the abilities of multiple individually fine-tuned LMs into a single LM\nby using a few simple arithmetic operations. Our key insight is that merging\nmodels individually fine-tuned on each dataset in a mixture can effectively\nserve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix\nleverages this insight to accelerate selecting dataset mixtures without\nrequiring full fine-tuning on each candidate mixture. Our experiments\ndemonstrate that Merge to Mix surpasses state-of-the-art methods in dataset\nselection for fine-tuning LMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16066v1",
    "published": "2025-05-21T22:34:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.23782v1",
    "title": "4,500 Seconds: Small Data Training Approaches for Deep UAV Audio Classification",
    "authors": [
      "Andrew P. Berg",
      "Qian Zhang",
      "Mia Y. Wang"
    ],
    "abstract": "Unmanned aerial vehicle (UAV) usage is expected to surge in the coming\ndecade, raising the need for heightened security measures to prevent airspace\nviolations and security threats. This study investigates deep learning\napproaches to UAV classification focusing on the key issue of data scarcity. To\ninvestigate this we opted to train the models using a total of 4,500 seconds of\naudio samples, evenly distributed across a 9-class dataset. We leveraged\nparameter efficient fine-tuning (PEFT) and data augmentations to mitigate the\ndata scarcity. This paper implements and compares the use of convolutional\nneural networks (CNNs) and attention-based transformers. Our results show that,\nCNNs outperform transformers by 1-2\\% accuracy, while still being more\ncomputationally efficient. These early findings, however, point to potential in\nusing transformers models; suggesting that with more data and further\noptimizations they could outperform CNNs. Future works aims to upscale the\ndataset to better understand the trade-offs between these approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.23782v1",
    "published": "2025-05-21T22:34:07+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.16065v3",
    "title": "Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated Synthetic Data Augmentation",
    "authors": [
      "Ruijie Xi",
      "He Ba",
      "Hao Yuan",
      "Rishu Agrawal",
      "Yuxin Tian",
      "Ruoyan Kong",
      "Arul Prakash"
    ],
    "abstract": "Embedding-Based Retrieval (EBR) is an important technique in modern search\nengines, enabling semantic match between search queries and relevant results.\nHowever, search logging data on platforms like Facebook Marketplace lacks the\ndiversity and details needed for effective EBR model training, limiting the\nmodels' ability to capture nuanced search patterns. To address this challenge,\nwe propose Aug2Search, an EBR-based framework leveraging synthetic data\ngenerated by Generative AI (GenAI) models, in a multimodal and multitask\napproach to optimize query-product relevance. This paper investigates the\ncapabilities of GenAI, particularly Large Language Models (LLMs), in generating\nhigh-quality synthetic data, and analyzing its impact on enhancing EBR models.\nWe conducted experiments using eight Llama models and 100 million data points\nfrom Facebook Marketplace logs. Our synthetic data generation follows three\nstrategies: (1) generate queries, (2) enhance product listings, and (3)\ngenerate queries from enhanced listings. We train EBR models on three different\ndatasets: sampled engagement data or original data ((e.g., \"Click\" and \"Listing\nInteractions\")), synthetic data, and a mixture of both engagement and synthetic\ndata to assess their performance across various training sets. Our findings\nunderscore the robustness of Llama models in producing synthetic queries and\nlistings with high coherence, relevance, and diversity, while maintaining low\nlevels of hallucination. Aug2Search achieves an improvement of up to 4% in\nROC_AUC with 100 million synthetic data samples, demonstrating the\neffectiveness of our approach. Moreover, our experiments reveal that with the\nsame volume of training data, models trained exclusively on synthetic data\noften outperform those trained on original data only or a mixture of original\nand synthetic data.",
    "pdf_url": "http://arxiv.org/pdf/2505.16065v3",
    "published": "2025-05-21T22:33:40+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16064v1",
    "title": "Three Algorithms for Merging Hierarchical Navigable Small World Graphs",
    "authors": [
      "Alexander Ponomarenko"
    ],
    "abstract": "This paper addresses the challenge of merging hierarchical navigable small\nworld (HNSW) graphs, a critical operation for distributed systems, incremental\nindexing, and database compaction. We propose three algorithms for this task:\nNaive Graph Merge (NGM), Intra Graph Traversal Merge (IGTM), and Cross Graph\nTraversal Merge (CGTM). These algorithms differ in their approach to vertex\nselection and candidate collection during the merge process. We conceptualize\ngraph merging as an iterative process with four key steps: processing vertex\nselection, candidate collection, neighborhood construction, and information\npropagation. Our experimental evaluation on the SIFT1M dataset demonstrates\nthat IGTM and CGTM significantly reduce computational costs compared to naive\napproaches, requiring up to 70\\% fewer distance computations while maintaining\ncomparable search accuracy. Surprisingly, IGTM outperforms CGTM in efficiency,\ncontrary to our initial expectations. The proposed algorithms enable efficient\nconsolidation of separately constructed indices, supporting critical operations\nin modern vector databases and retrieval systems that rely on HNSW for\nsimilarity search.",
    "pdf_url": "http://arxiv.org/pdf/2505.16064v1",
    "published": "2025-05-21T22:33:27+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16063v1",
    "title": "Accurate Angle-Resolved Raman Spectroscopy Methodology: Quantifying the Dichroic Edge Filter Effect",
    "authors": [
      "Tehseen Adel",
      "Maria F. Munoz",
      "Thuc T. Mai",
      "Charlezetta E. Wilson-Stokes",
      "Riccardo Torsi",
      "Aur√©lien Thieffry",
      "Jeffrey R. Simpson",
      "Angela R. Hight Walker"
    ],
    "abstract": "Angle-resolved Raman spectroscopy (ARRS) is an effective method to analyze\nthe symmetry of phonons and other excitations in molecules and solid-state\ncrystals. While there are several configurations of ARRS instruments, the\nmeasurement system detailed here utilizes two pairs of linear polarizers and\nsuperachromatic half-wave plates. After the orientations of the linear\npolarizers are set to fixed angles, the two half-wave plates rotate\nindependently, through motorized control, enabling 2D linear polarization\nmapping. Described within is a protocol to achieve high quality ARRS\nmeasurements leveraging phonons from easily accessible test materials\n[molybdenum disulfide (MoS_2), sapphire (Al_2O_3) and silicon] to validate the\nsystem and operation. Quantitative polarized Raman data strongly depends on the\nquality of sample surface and the optics: the order of placement, alignment,\nand any distortion caused by their coatings. This study identifies the impact\nof commonly used edge filters on the polarization response of materials with an\nanisotropic response as emulated by the T_2g phonon in the Si(100). We detect\nand model the significant distortion of the T_2g phonon polarization response\noriginating from our dichroic edge filters, the results of which are broadly\napplicable to optics in any Raman instrument. This ARRS setup also enables\nhelicity-resolved Raman measurements by replacing the first half-wave plate\nwith a superachromatic quarter-wave plate; this configuration is also validated\nusing the Raman response of the aforementioned test materials. This paper aims\nto increase the quality and reproducibility of polarized Raman measurements\nthrough both instrumental considerations and methodology.",
    "pdf_url": "http://arxiv.org/pdf/2505.16063v1",
    "published": "2025-05-21T22:31:18+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.16062v1",
    "title": "WaveTouch: Active Tactile Sensing Using Vibro-Feedback for Classification of Variable Stiffness and Infill Density Objects",
    "authors": [
      "Danissa Sandykbayeva",
      "Valeriya Kostyukova",
      "Aditya Shekhar Nittala",
      "Zhanat Kappassov",
      "Bakhtiyar Orazbayev"
    ],
    "abstract": "The perception and recognition of the surroundings is one of the essential\ntasks for a robot. With preliminary knowledge about a target object, it can\nperform various manipulation tasks such as rolling motion, palpation, and force\ncontrol. Minimizing possible damage to the sensing system and testing objects\nduring manipulation are significant concerns that persist in existing research\nsolutions. To address this need, we designed a new type of tactile sensor based\non the active vibro-feedback for object stiffness classification. With this\napproach, the classification can be performed during the gripping process,\nenabling the robot to quickly estimate the appropriate level of gripping force\nrequired to avoid damaging or dropping the object. This contrasts with passive\nvibration sensing, which requires to be triggered by object movement and is\noften inefficient for establishing a secure grip. The main idea is to observe\nthe received changes in artificially injected vibrations that propagate through\nobjects with different physical properties and molecular structures. The\nexperiments with soft subjects demonstrated higher absorption of the received\nvibrations, while the opposite is true for the rigid subjects that not only\ndemonstrated low absorption but also enhancement of the vibration signal.",
    "pdf_url": "http://arxiv.org/pdf/2505.16062v1",
    "published": "2025-05-21T22:28:50+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16061v1",
    "title": "Internal and External Impacts of Natural Language Processing Papers",
    "authors": [
      "Yu Zhang"
    ],
    "abstract": "We investigate the impacts of NLP research published in top-tier conferences\n(i.e., ACL, EMNLP, and NAACL) from 1979 to 2024. By analyzing citations from\nresearch articles and external sources such as patents, media, and policy\ndocuments, we examine how different NLP topics are consumed both within the\nacademic community and by the broader public. Our findings reveal that language\nmodeling has the widest internal and external influence, while linguistic\nfoundations have lower impacts. We also observe that internal and external\nimpacts generally align, but topics like ethics, bias, and fairness show\nsignificant attention in policy documents with much fewer academic citations.\nAdditionally, external domains exhibit distinct preferences, with patents\nfocusing on practical NLP applications and media and policy documents engaging\nmore with the societal implications of NLP models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16061v1",
    "published": "2025-05-21T22:25:58+00:00",
    "categories": [
      "cs.CL",
      "cs.DL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16060v1",
    "title": "Few-Shot Test-Time Optimization Without Retraining for Semiconductor Recipe Generation and Beyond",
    "authors": [
      "Shangding Gu",
      "Donghao Ying",
      "Ming Jin",
      "Yu Joe Lu",
      "Jun Wang",
      "Javad Lavaei",
      "Costas Spanos"
    ],
    "abstract": "We introduce Model Feedback Learning (MFL), a novel test-time optimization\nframework for optimizing inputs to pre-trained AI models or deployed hardware\nsystems without requiring any retraining of the models or modifications to the\nhardware. In contrast to existing methods that rely on adjusting model\nparameters, MFL leverages a lightweight reverse model to iteratively search for\noptimal inputs, enabling efficient adaptation to new objectives under\ndeployment constraints. This framework is particularly advantageous in\nreal-world settings, such as semiconductor manufacturing recipe generation,\nwhere modifying deployed systems is often infeasible or cost-prohibitive. We\nvalidate MFL on semiconductor plasma etching tasks, where it achieves target\nrecipe generation in just five iterations, significantly outperforming both\nBayesian optimization and human experts. Beyond semiconductor applications, MFL\nalso demonstrates strong performance in chemical processes (e.g., chemical\nvapor deposition) and electronic systems (e.g., wire bonding), highlighting its\nbroad applicability. Additionally, MFL incorporates stability-aware\noptimization, enhancing robustness to process variations and surpassing\nconventional supervised learning and random search methods in high-dimensional\ncontrol settings. By enabling few-shot adaptation, MFL provides a scalable and\nefficient paradigm for deploying intelligent control in real-world\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16060v1",
    "published": "2025-05-21T22:24:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16059v1",
    "title": "Monitoring in the Dark: Privacy-Preserving Runtime Verification of Cyber-Physical Systems",
    "authors": [
      "Charles Koll",
      "Preston Tan Hang",
      "Mike Rosulek",
      "Houssam Abbas"
    ],
    "abstract": "In distributed Cyber-Physical Systems and Internet-of-Things applications,\nthe nodes of the system send measurements to a monitor that checks whether\nthese measurements satisfy given formal specifications. For instance in Urban\nAir Mobility, a local traffic authority will be monitoring drone traffic to\nevaluate its flow and detect emerging problematic patterns. Certain\napplications require both the specification and the measurements to be private\n-- i.e. known only to their owners. Examples include traffic monitoring,\ntesting of integrated circuit designs, and medical monitoring by wearable or\nimplanted devices. In this paper we propose a protocol that enables\nprivacy-preserving robustness monitoring. By following our protocol, both\nsystem (e.g. drone) and monitor (e.g. traffic authority) only learn the\nrobustness of the measured trace w.r.t. the specification. But the system\nlearns nothing about the formula, and the monitor learns nothing about the\nsignal monitored. We do this using garbled circuits, for specifications in\nSignal Temporal Logic interpreted over timed state sequences. We analyze the\nruntime and memory overhead of privacy preservation, the size of the circuits,\nand their practicality for three different usage scenarios: design testing,\noffline monitoring, and online monitoring of Cyber-Physical Systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16059v1",
    "published": "2025-05-21T22:20:25+00:00",
    "categories": [
      "cs.LO",
      "B.5.0; I.2.4"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16058v1",
    "title": "Mesh-free sparse identification of nonlinear dynamics",
    "authors": [
      "Mars Liyao Gao",
      "J. Nathan Kutz",
      "Bernat Font"
    ],
    "abstract": "Identifying the governing equations of a dynamical system is one of the most\nimportant tasks for scientific modeling. However, this procedure often requires\nhigh-quality spatio-temporal data uniformly sampled on structured grids. In\nthis paper, we propose mesh-free SINDy, a novel algorithm which leverages the\npower of neural network approximation as well as auto-differentiation to\nidentify governing equations from arbitrary sensor placements and non-uniform\ntemporal data sampling. We show that mesh-free SINDy is robust to high noise\nlevels and limited data while remaining computationally efficient. In our\nimplementation, the training procedure is straight-forward and nearly free of\nhyperparameter tuning, making mesh-free SINDy widely applicable to many\nscientific and engineering problems. In the experiments, we demonstrate its\neffectiveness on a series of PDEs including the Burgers' equation, the heat\nequation, the Korteweg-De Vries equation and the 2D advection-diffusion\nequation. We conduct detailed numerical experiments on all datasets, varying\nthe noise levels and number of samples, and we also compare our approach to\nprevious state-of-the-art methods. It is noteworthy that, even in high-noise\nand low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery,\nachieving successful identification with up to 75% noise for the Burgers'\nequation using 5,000 samples and with as few as 100 samples and 1% noise. All\nof this is achieved within a training time of under one minute.",
    "pdf_url": "http://arxiv.org/pdf/2505.16058v1",
    "published": "2025-05-21T22:18:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16057v1",
    "title": "Signals of Provenance: Practices & Challenges of Navigating Indicators in AI-Generated Media for Sighted and Blind Individuals",
    "authors": [
      "Ayae Ide",
      "Tory Park",
      "Jaron Mink",
      "Tanusree Sharma"
    ],
    "abstract": "AI-Generated (AIG) content has become increasingly widespread by recent\nadvances in generative models and the easy-to-use tools that have significantly\nlowered the technical barriers for producing highly realistic audio, images,\nand videos through simple natural language prompts. In response, platforms are\nadopting provable provenance with platforms recommending AIG to be\nself-disclosed and signaled to users. However, these indicators may be often\nmissed, especially when they rely solely on visual cues and make them\nineffective to users with different sensory abilities. To address the gap, we\nconducted semi-structured interviews (N=28) with 15 sighted and 13 BLV\nparticipants to examine their interaction with AIG content through\nself-disclosed AI indicators. Our findings reveal diverse mental models and\npractices, highlighting different strengths and weaknesses of content-based\n(e.g., title, description) and menu-aided (e.g., AI labels) indicators. While\nsighted participants leveraged visual and audio cues, BLV participants\nprimarily relied on audio and existing assistive tools, limiting their ability\nto identify AIG. Across both groups, they frequently overlooked menu-aided\nindicators deployed by platforms and rather interacted with content-based\nindicators such as title and comments. We uncovered usability challenges\nstemming from inconsistent indicator placement, unclear metadata, and cognitive\noverload. These issues were especially critical for BLV individuals due to the\ninsufficient accessibility of interface elements. We provide practical\nrecommendations and design implications for future AIG indicators across\nseveral dimensions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16057v1",
    "published": "2025-05-21T22:16:59+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16056v1",
    "title": "Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models",
    "authors": [
      "Jingcong Liang",
      "Siyuan Wang",
      "Miren Tian",
      "Yitong Li",
      "Duyu Tang",
      "Zhongyu Wei"
    ],
    "abstract": "Mixture-of-Experts (MoE) enables efficient scaling of large language models\n(LLMs) with sparsely activated experts during inference. To effectively deploy\nlarge MoE models on memory-constrained devices, many systems introduce *expert\noffloading* that caches a subset of experts in fast memory, leaving others on\nslow memory to run on CPU or load on demand. While some research has exploited\nthe locality of expert activations, where consecutive tokens activate similar\nexperts, the degree of this **local routing consistency** varies across models\nand remains understudied. In this paper, we propose two metrics to measure\nlocal routing consistency of MoE models: (1) **Segment Routing Best Performance\n(SRP)**, which evaluates how well a fixed group of experts can cover the needs\nof a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which\nmeasures the optimal segment-level cache hit rate under a given cache size\nlimit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found\nthat models that apply MoE on every layer and do not use shared experts exhibit\nthe highest local routing consistency. We further showed that\ndomain-specialized experts contribute more to routing consistency than\nvocabulary-specialized ones, and that most models can balance between cache\neffectiveness and efficiency with cache sizes approximately 2x the active\nexperts. These findings pave the way for memory-efficient MoE design and\ndeployment without compromising inference speed. We publish the code for\nreplicating experiments at https://github.com/ljcleo/moe-lrc .",
    "pdf_url": "http://arxiv.org/pdf/2505.16056v1",
    "published": "2025-05-21T22:13:09+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16055v2",
    "title": "Proactive Hierarchical Control Barrier Function-Based Safety Prioritization in Close Human-Robot Interaction Scenarios",
    "authors": [
      "Patanjali Maithani",
      "Aliasghar Arab",
      "Farshad Khorrami",
      "Prashanth Krishnamurthy"
    ],
    "abstract": "In collaborative human-robot environments, the unpredictable and dynamic\nnature of human motion can lead to situations where collisions become\nunavoidable. In such cases, it is essential for the robotic system to\nproactively mitigate potential harm through intelligent control strategies.\nThis paper presents a hierarchical control framework based on Control Barrier\nFunctions (CBFs) designed to ensure safe and adaptive operation of autonomous\nrobotic manipulators during close-proximity human-robot interaction. The\nproposed method introduces a relaxation variable that enables real-time\nprioritization of safety constraints, allowing the robot to dynamically manage\ncollision risks based on the criticality of different parts of the human body.\nA secondary constraint mechanism is incorporated to resolve infeasibility by\nincreasing the priority of imminent threats. The framework is experimentally\nvalidated on a Franka Research 3 robot equipped with a ZED2i AI camera for\nreal-time human pose and body detection. Experimental results confirm that the\nCBF-based controller, integrated with depth sensing, facilitates responsive and\nsafe human-robot collaboration, while providing detailed risk analysis and\nmaintaining robust performance in highly dynamic settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16055v2",
    "published": "2025-05-21T22:10:08+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16054v1",
    "title": "Multi-Unit Combinatorial Prophet Inequalities",
    "authors": [
      "Shuchi Chawla",
      "Trung Dang",
      "Zhiyi Huang",
      "Yifan Wang"
    ],
    "abstract": "We consider a combinatorial auction setting where buyers have fractionally\nsubadditive (XOS) valuations over the items and the seller's objective is to\nmaximize the social welfare. A prophet inequality in this setting bounds the\ncompetitive ratio of sequential allocation (often using item pricing) against\nthe hindsight optimum. We study the dependence of the competitive ratio on the\nnumber of copies, $k$, of each item.\n  We show that the multi-unit combinatorial setting is strictly harder than its\nsingle-item counterpart in that there is a gap between the competitive ratios\nachieved by static item pricings in the two settings. However, if the seller is\nallowed to change item prices dynamically, it becomes possible to\nasymptotically match the competitive ratio of a single-item static pricing. We\nalso develop a new non-adaptive anonymous multi-unit combinatorial prophet\ninequality where the item prices are determined up front but increase as the\nitem supply decreases. Setting the item prices in our prophet inequality\nrequires minimal information about the buyers' value distributions -- merely\n(an estimate of) the expected social welfare accrued by each item in the\nhindsight optimal solution suffices. Our non-adaptive pricing achieves a\ncompetitive ratio that increases strictly as a function of the item supply $k$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16054v1",
    "published": "2025-05-21T22:07:52+00:00",
    "categories": [
      "cs.GT",
      "cs.DS"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16053v1",
    "title": "Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs",
    "authors": [
      "Jan T√∂nshoff",
      "Martin Grohe"
    ],
    "abstract": "Boolean Satisfiability (SAT) solvers are foundational to computer science,\nyet their performance typically hinges on hand-crafted heuristics. This work\nintroduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm\nfor learning to guide SAT solver branching heuristics with Graph Neural\nNetworks (GNNs). Central to our approach is a novel and generic mechanism for\ninjecting inferred variable weights and polarities into the branching\nheuristics of existing SAT solvers. In a single forward pass, a GNN assigns\nthese parameters to all variables. Casting this one-shot guidance as a\nreinforcement learning problem lets us train the GNN with off-the-shelf\npolicy-gradient methods, such as GRPO, directly using the solver's\ncomputational cost as the sole reward signal. Extensive evaluations demonstrate\nthat RLAF-trained policies significantly reduce the mean solve times of\ndifferent base solvers across diverse SAT problem distributions, achieving more\nthan a 2x speedup in some cases, while generalizing effectively to larger and\nharder problems after training. Notably, these policies consistently outperform\nexpert-supervised approaches based on learning handcrafted weighting\nheuristics, offering a promising path towards data-driven heuristic design in\ncombinatorial optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.16053v1",
    "published": "2025-05-21T22:07:08+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16052v1",
    "title": "Coincident Learning for Beam-based RF Station Fault Identification Using Phase Information at the SLAC Linac Coherent Light Source",
    "authors": [
      "Jia Liang",
      "William Colocho",
      "Franz-Josef Decker",
      "Ryan Humble",
      "Ben Morris",
      "Finn H. O'Shea",
      "David A. Steele",
      "Zhe Zhang",
      "Eric Darve",
      "Daniel Ratner"
    ],
    "abstract": "Anomalies in radio-frequency (RF) stations can result in unplanned downtime\nand performance degradation in linear accelerators such as SLAC's Linac\nCoherent Light Source (LCLS). Detecting these anomalies is challenging due to\nthe complexity of accelerator systems, high data volume, and scarcity of\nlabeled fault data. Prior work identified faults using beam-based detection,\ncombining RF amplitude and beam-position monitor data. Due to the simplicity of\nthe RF amplitude data, classical methods are sufficient to identify faults, but\nthe recall is constrained by the low-frequency and asynchronous characteristics\nof the data. In this work, we leverage high-frequency, time-synchronous RF\nphase data to enhance anomaly detection in the LCLS accelerator. Due to the\ncomplexity of phase data, classical methods fail, and we instead train deep\nneural networks within the Coincident Anomaly Detection (CoAD) framework. We\nfind that applying CoAD to phase data detects nearly three times as many\nanomalies as when applied to amplitude data, while achieving broader coverage\nacross RF stations. Furthermore, the rich structure of phase data enables us to\ncluster anomalies into distinct physical categories. Through the integration of\nauxiliary system status bits, we link clusters to specific fault signatures,\nproviding additional granularity for uncovering the root cause of faults. We\nalso investigate interpretability via Shapley values, confirming that the\nlearned models focus on the most informative regions of the data and providing\ninsight for cases where the model makes mistakes. This work demonstrates that\nphase-based anomaly detection for RF stations improves both diagnostic coverage\nand root cause analysis in accelerator systems and that deep neural networks\nare essential for effective analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.16052v1",
    "published": "2025-05-21T22:05:49+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16051v1",
    "title": "PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals",
    "authors": [
      "Dongze Wu",
      "David I. Inouye",
      "Yao Xie"
    ],
    "abstract": "We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for\ncausal inference that jointly models potential outcomes and counterfactuals.\nTrained via flow matching, PO-Flow provides a unified framework for\nindividualized potential outcome prediction, counterfactual predictions, and\nuncertainty-aware density learning. Among generative models, it is the first to\nenable density learning of potential outcomes without requiring explicit\ndistributional assumptions (e.g., Gaussian mixtures), while also supporting\ncounterfactual prediction conditioned on factual outcomes in general\nobservational datasets. On benchmarks such as ACIC, IHDP, and IBM, it\nconsistently outperforms prior methods across a range of causal inference\ntasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including\ncounterfactual image generation, demonstrating its broad applicability.",
    "pdf_url": "http://arxiv.org/pdf/2505.16051v1",
    "published": "2025-05-21T22:02:48+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.16050v1",
    "title": "A Weight Function Lemma Heuristic for Graph Pebbling",
    "authors": [
      "G. A. Bridi",
      "F. L. Marquezino",
      "C. M. H. de Figueiredo"
    ],
    "abstract": "Graph pebbling is a problem in which pebbles are distributed across the\nvertices of a graph and moved according to a specific rule: two pebbles are\nremoved from a vertex to place one on an adjacent vertex. The goal is to\ndetermine the minimum number of pebbles required to ensure that any target\nvertex can be reached, known as the pebbling number. Computing the pebbling\nnumber lies beyond NP in the polynomial hierarchy, leading to bounding methods.\nOne of the most prominent techniques for upper bounds is the Weight Function\nLemma (WFL), which relies on costly integer linear optimization. To mitigate\nthis cost, an alternative approach is to consider the dual formulation of the\nproblem, which allows solutions to be constructed by hand through the selection\nof strategies given by subtrees with associated weight functions. To improve\nthe bounds, the weights should be distributed as uniformly as possible among\nthe vertices, balancing their individual contribution. However, despite its\nsimplicity, this approach lacks a formal framework. To fill this gap, we\nintroduce a novel heuristic method that refines the selection of balanced\nstrategies. The method is motivated by our theoretical analysis of the\nlimitations of the dual approach, in which we prove lower bounds on the best\nbounds achievable. Our theoretical analysis shows that the bottleneck lies in\nthe farthest vertices from the target, forcing surplus weight onto the closer\nneighborhoods. To minimize surplus weight beyond the theoretical minimum, our\nproposed heuristic prioritizes weight assignment to the farthest vertices,\nbuilding the subtrees starting from the shortest paths to them and then filling\nin the weights for the remaining vertices. Applying our heuristic to Flower\nsnarks and Blanu\\v{s}a snarks, we improve the best-known upper bounds,\ndemonstrating the effectiveness of a structured strategy selection when using\nthe WFL.",
    "pdf_url": "http://arxiv.org/pdf/2505.16050v1",
    "published": "2025-05-21T22:01:49+00:00",
    "categories": [
      "cs.DM"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.16049v1",
    "title": "A Non-Zero-Sum Game Model for Optimal Cyber Defense Strategies",
    "authors": [
      "Dongyoung Park",
      "Gaby G. Dagher"
    ],
    "abstract": "In the contemporary digital landscape, cybersecurity has become a critical\nissue due to the increasing frequency and sophistication of cyber attacks. This\nstudy utilizes a non-zero-sum game theoretical framework to model the strategic\ninteractions between cyber attackers and defenders, with the objective of\nidentifying optimal strategies for both. By defining precise payoff functions\nthat incorporate the probabilities and costs associated with various exploits,\nas well as the values of network nodes and the costs of deploying honeypots, we\nderive Nash equilibria that inform strategic decisions. The proposed model is\nvalidated through extensive simulations, demonstrating its effectiveness in\nenhancing network security. Our results indicate that high-probability,\nlow-cost exploits like Phishing and Social Engineering are more likely to be\nused by attackers, necessitating prioritized defense mechanisms. Our findings\nalso show that increasing the number of network nodes dilutes the attacker's\nefforts, thereby improving the defender's payoff. This study provides valuable\ninsights into optimizing resource allocation for cybersecurity and highlights\nthe scalability and practical applicability of the game-theoretic approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.16049v1",
    "published": "2025-05-21T22:00:58+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16048v2",
    "title": "SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution",
    "authors": [
      "Philipp D. Siedler"
    ],
    "abstract": "We introduce a novel dataset designed to benchmark the physical and spatial\nreasoning capabilities of Large Language Models (LLM) based on topology\noptimization, a method for computing optimal material distributions within a\ndesign space under prescribed loads and supports. In this dataset, LLMs are\nprovided with conditions such as 2D boundary, applied forces and supports, and\nmust reason about the resulting optimal material distribution. The dataset\nincludes a variety of tasks, ranging from filling in masked regions within\npartial structures to predicting complete material distributions. Solving these\ntasks requires understanding the flow of forces and the required material\ndistribution under given constraints, without access to simulation tools or\nexplicit physical models, challenging models to reason about structural\nstability and spatial organization. Our dataset targets the evaluation of\nspatial and physical reasoning abilities in 2D settings, offering a\ncomplementary perspective to traditional language and logic benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16048v2",
    "published": "2025-05-21T22:00:20+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16047v1",
    "title": "Bayesian adaptive randomization in the I-SPY2.2 sequential multiple assignment randomized trial",
    "authors": [
      "Peter Norwood",
      "Christina Yau",
      "Denise Wolf",
      "Anastasios Tsiatis",
      "Marie Davidian"
    ],
    "abstract": "The I-SPY2 phase 2 clinical trial is a\n  long-running platform trial evaluating neoadjuvant treatments for\n  locally advanced breast cancer, assigning subjects to tumor\n  subtype-specific experimental agents via a response-adaptive\n  randomization algorithm that updates randomization probabilities\n  based on accruing evidence of efficacy. Recently, I-SPY2 has been\n  reconfigured as a sequential multiple assignment randomized trial\n  (SMART), known as I-SPY2.2, in which subjects who are predicted to\n  not achieve a satisfactory response to an initial assigned therapy\n  are re-randomized to a second subtype-specific treatment followed by\n  standard rescue therapy if a satisfactory response is not predicted.\n  The I-SPY2.2 SMART thus supports evaluation of entire treatment\n  regimes that dictate the choice of treatments at each stage on the\n  basis of the outcome pathological complete response (pCR). The\n  transition of I-SPY2 to a SMART required development of a\n  trial-specific response-adaptive randomization scheme in which\n  randomization probabilities at each stage are updated based on\n  evolving evidence on the efficacy of full regimes, so as to skew\n  probabilities toward treatments involved in regimes that the current\n  evidence suggests are optimal in the sense of maximizing the\n  probability of pCR. The approach uses Thompson sampling, which\n  updates randomization probabilities based on the posterior\n  probability that treatments are implicated in optimal regimes. We\n  present the proposed algorithm and empirical studies that\n  demonstrate it improves within-trial regime-specific pCR rates and\n  recommends optimal regimes at similar rates relative to uniform,\n  nonadaptive randomization.",
    "pdf_url": "http://arxiv.org/pdf/2505.16047v1",
    "published": "2025-05-21T21:58:57+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.16046v1",
    "title": "Universal cumulants and conformal invariance in annihilating random walks with pair deposition",
    "authors": [
      "Dragi Karevski",
      "Gunter M Sch√ºtz",
      "Ali Zahra"
    ],
    "abstract": "We consider annihilating random walks on the finite one-dimensional integer\ntorus with deposition of pairs of particles, conditioned on an atypical jump\nactivity. All cumulants of the activity, defined as the number of particle\njumps up to some time t, are obtained in closed form to leading order in system\nsize L at the critical point, where in the thermodynamic limit the conditioned\nprocess undergoes a phase transition in the universality class of the\none-dimensional quantum Ising model in a transverse field. The generating\nfunction of the cumulants at a distance of order 1/L away from the critical\npoint is proved to be given by two universal quantities, viz., by the central\ncharge c = 1/2 of the Virasoro algebra that characterizes the Ising\nuniversality class and by an explicit universal scaling function.",
    "pdf_url": "http://arxiv.org/pdf/2505.16046v1",
    "published": "2025-05-21T21:58:07+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16045v1",
    "title": "Regularizing Ill-Posed Inverse Problems: Deblurring Barcodes",
    "authors": [
      "Mark Embree"
    ],
    "abstract": "This manuscript is designed to introduce students in applied mathematics and\ndata science to the concept of regularization for ill-posed inverse problems.\nConstruct a mathematical model that describes how an image gets blurred.\nConvert a calculus problem into a linear algebra problem by discretization.\nInverting the blurring process should sharpen up an image; this requires the\nsolution of a system of linear algebraic equations. Solving this linear system\nof equations turns out to be delicate, as deblurring is an example of an\nill-posed inverse problem. To address this challenge, recast the system as a\nregularized least squares problem (also known as ridge regression).",
    "pdf_url": "http://arxiv.org/pdf/2505.16045v1",
    "published": "2025-05-21T21:55:40+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65F22, 45Q05"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16044v2",
    "title": "Multimodal Biomarkers for Schizophrenia: Towards Individual Symptom Severity Estimation",
    "authors": [
      "Gowtham Premananth",
      "Philip Resnik",
      "Sonia Bansal",
      "Deanna L. Kelly",
      "Carol Espy-Wilson"
    ],
    "abstract": "Studies on schizophrenia assessments using deep learning typically treat it\nas a classification task to detect the presence or absence of the disorder,\noversimplifying the condition and reducing its clinical applicability. This\ntraditional approach overlooks the complexity of schizophrenia, limiting its\npractical value in healthcare settings. This study shifts the focus to\nindividual symptom severity estimation using a multimodal approach that\nintegrates speech, video, and text inputs. We develop unimodal models for each\nmodality and a multimodal framework to improve accuracy and robustness. By\ncapturing a more detailed symptom profile, this approach can help in enhancing\ndiagnostic precision and support personalized treatment, offering a scalable\nand objective tool for mental health assessment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16044v2",
    "published": "2025-05-21T21:55:35+00:00",
    "categories": [
      "eess.AS",
      "cs.LG",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.16043v1",
    "title": "Adaptive Honeypot Allocation in Multi-Attacker Networks via Bayesian Stackelberg Games",
    "authors": [
      "Dongyoung Park",
      "Gaby G. Dagher"
    ],
    "abstract": "Defending against sophisticated cyber threats demands strategic allocation of\nlimited security resources across complex network infrastructures. When the\ndefender has limited defensive resources, the complexity of coordinating\nhoneypot placements across hundreds of nodes grows exponentially. In this\npaper, we present a multi-attacker Bayesian Stackelberg framework modeling\nconcurrent adversaries attempting to breach a directed network of system\ncomponents. Our approach uniquely characterizes each adversary through distinct\ntarget preferences, exploit capabilities, and associated costs, while enabling\ndefenders to strategically deploy honeypots at critical network positions. By\nintegrating a multi-follower Stackelberg formulation with dynamic Bayesian\nbelief updates, our framework allows defenders to continuously refine their\nunderstanding of attacker intentions based on actions detected through\nIntrusion Detection Systems (IDS). Experimental results show that the proposed\nmethod prevents attack success within a few rounds and scales well up to\nnetworks of 500 nodes with more than 1,500 edges, maintaining tractable run\ntimes.",
    "pdf_url": "http://arxiv.org/pdf/2505.16043v1",
    "published": "2025-05-21T21:53:50+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.11049v4",
    "title": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning",
    "authors": [
      "Andrew P. Berg",
      "Qian Zhang",
      "Mia Y. Wang"
    ],
    "abstract": "As unmanned aerial vehicles (UAVs) become increasingly prevalent in both\nconsumer and defense applications, the need for reliable, modality-specific\nclassification systems grows in urgency. This paper addresses the challenge of\ndata scarcity in UAV audio classification by expanding on prior work through\nthe integration of pre-trained deep learning models, parameter-efficient\nfine-tuning (PEFT) strategies, and targeted data augmentation techniques. Using\na custom dataset of 3,100 UAV audio clips (15,500 seconds) spanning 31 distinct\ndrone types, we evaluate the performance of transformer-based and convolutional\nneural network (CNN) architectures under various fine-tuning configurations.\nExperiments were conducted with five-fold cross-validation, assessing accuracy,\ntraining efficiency, and robustness. Results show that full fine-tuning of the\nEfficientNet-B0 model with three augmentations achieved the highest validation\naccuracy (95.95), outperforming both the custom CNN and transformer-based\nmodels like AST. These findings suggest that combining lightweight\narchitectures with PEFT and well-chosen augmentations provides an effective\nstrategy for UAV audio classification on limited datasets. Future work will\nextend this framework to multimodal UAV classification using visual and radar\ntelemetry.",
    "pdf_url": "http://arxiv.org/pdf/2506.11049v4",
    "published": "2025-05-21T21:53:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16042v2",
    "title": "Reference Free Platform Adaptive Locomotion for Quadrupedal Robots using a Dynamics Conditioned Policy",
    "authors": [
      "David Rytz",
      "Suyoung Choi",
      "Wanming Yu",
      "Wolfgang Merkt",
      "Jemin Hwangbo",
      "Ioannis Havoutis"
    ],
    "abstract": "This article presents Platform Adaptive Locomotion (PAL), a unified control\nmethod for quadrupedal robots with different morphologies and dynamics. We\nleverage deep reinforcement learning to train a single locomotion policy on\nprocedurally generated robots. The policy maps proprioceptive robot state\ninformation and base velocity commands into desired joint actuation targets,\nwhich are conditioned using a latent embedding of the temporally local system\ndynamics. We explore two conditioning strategies - one using a GRU-based\ndynamics encoder and another using a morphology-based property estimator - and\nshow that morphology-aware conditioning outperforms temporal dynamics encoding\nregarding velocity task tracking for our hardware test on ANYmal C. Our results\ndemonstrate that both approaches achieve robust zero-shot transfer across\nmultiple unseen simulated quadrupeds. Furthermore, we demonstrate the need for\ncareful robot reference modelling during training: exposing the policy to a\ndiverse set of robot morphologies and dynamics leads to improved\ngeneralization, reducing the velocity tracking error by up to 30% compared to\nthe baseline method. Despite PAL not surpassing the best-performing\nreference-free controller in all cases, our analysis uncovers critical design\nchoices and informs improvements to the state of the art.",
    "pdf_url": "http://arxiv.org/pdf/2505.16042v2",
    "published": "2025-05-21T21:48:51+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16041v1",
    "title": "Physics-based machine learning for mantle convection simulations",
    "authors": [
      "Siddhant Agarwal",
      "Ali Can Bekar",
      "Christian H√ºttig",
      "David S. Greenberg",
      "Nicola Tosi"
    ],
    "abstract": "Mantle convection simulations are an essential tool for understanding how\nrocky planets evolve. However, the poorly known input parameters to these\nsimulations, the non-linear dependence of transport properties on pressure and\ntemperature, and the long integration times in excess of several billion years\nall pose a computational challenge for numerical solvers. We propose a\nphysics-based machine learning approach that predicts creeping flow velocities\nas a function of temperature while conserving mass, thereby bypassing the\nnumerical solution of the Stokes problem. A finite-volume solver then uses the\npredicted velocities to advect and diffuse the temperature field to the next\ntime-step, enabling autoregressive rollout at inference. For training, our\nmodel requires temperature-velocity snapshots from a handful of simulations\n(94). We consider mantle convection in a two-dimensional rectangular box with\nbasal and internal heating, pressure- and temperature-dependent viscosity.\nOverall, our model is up to 89 times faster than the numerical solver. We also\nshow the importance of different components in our convolutional neural network\narchitecture such as mass conservation, learned paddings on the boundaries, and\nloss scaling for the overall rollout performance. Finally, we test our approach\non unseen scenarios to demonstrate some of its strengths and weaknesses.",
    "pdf_url": "http://arxiv.org/pdf/2505.16041v1",
    "published": "2025-05-21T21:47:43+00:00",
    "categories": [
      "astro-ph.EP",
      "cs.LG"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.16040v3",
    "title": "On parameters of Hecke algebras for $p$-adic groups",
    "authors": [
      "Kazuma Ohara"
    ],
    "abstract": "Let $F$ be a non-archimedean local field with residue characteristic $p$ and\n$G$ be a connected reductive group defined over $F$. In earlier joint works\nwith Jeffrey D. Adler, Jessica Fintzen, and Manish Mishra, we proved that the\nHecke algebras attached to types constructed by Kim and Yu are isomorphic to\nthe Hecke algebras attached to depth-zero types. Note that if $G$ splits over a\ntamely ramified extension of $F$ and $p$ does not divide the order of the\nabsolute Weyl group of $G$, such Hecke algebras cover the Hecke algebras\nattached to arbitrary Bernstein blocks. We also proved that for a depth-zero\ntype $(K, \\rho)$, the corresponding Hecke algebra $\\mathcal{H}(G(F), (K,\n\\rho))$ has an explicit description as a semi-direct product of an affine Hecke\nalgebra $\\mathcal{H}(W(\\rho_M)_{\\mathrm{aff}}, q)$ with a twisted group algebra\n$\\mathbb{C}[\\Omega(\\rho_{M}), \\mu]$, generalizing prior work of Morris.\n  In this paper, we show that the affine Hecke algebra\n$\\mathcal{H}(W(\\rho_M)_{\\mathrm{aff}}, q)$ appearing in the description of the\nHecke algebra $\\mathcal{H}(G(F), (K, \\rho))$ attached to a depth-zero type $(K,\n\\rho)$ is isomorphic to the one attached to a unipotent type for a connected\nreductive group splitting over an unramified extension of $F$. This makes it\npossible to calculate the parameters of the affine Hecke algebras for\ndepth-zero types and types constructed by Kim and Yu explicitly. In particular,\nwe prove a version of Lusztig's conjecture that the parameters of the Hecke\nalgebra attached to an arbitrary Bernstein block agree with those of a\nunipotent Bernstein block under the assumption that $G$ splits over a tamely\nramified extension of $F$ and $p$ does not divide the order of the absolute\nWeyl group of $G$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16040v3",
    "published": "2025-05-21T21:44:04+00:00",
    "categories": [
      "math.RT",
      "math.NT",
      "22E50, 20C08, 20C33"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.16039v3",
    "title": "An Exploratory Approach Towards Investigating and Explaining Vision Transformer and Transfer Learning for Brain Disease Detection",
    "authors": [
      "Shuvashis Sarker",
      "Shamim Rahim Refat",
      "Faika Fairuj Preotee",
      "Shifat Islam",
      "Tashreef Muhammad",
      "Mohammad Ashraful Hoque"
    ],
    "abstract": "The brain is a highly complex organ that manages many important tasks,\nincluding movement, memory and thinking. Brain-related conditions, like tumors\nand degenerative disorders, can be hard to diagnose and treat. Magnetic\nResonance Imaging (MRI) serves as a key tool for identifying these conditions,\noffering high-resolution images of brain structures. Despite this, interpreting\nMRI scans can be complicated. This study tackles this challenge by conducting a\ncomparative analysis of Vision Transformer (ViT) and Transfer Learning (TL)\nmodels such as VGG16, VGG19, Resnet50V2, MobilenetV2 for classifying brain\ndiseases using MRI data from Bangladesh based dataset. ViT, known for their\nability to capture global relationships in images, are particularly effective\nfor medical imaging tasks. Transfer learning helps to mitigate data constraints\nby fine-tuning pre-trained models. Furthermore, Explainable AI (XAI) methods\nsuch as GradCAM, GradCAM++, LayerCAM, ScoreCAM, and Faster-ScoreCAM are\nemployed to interpret model predictions. The results demonstrate that ViT\nsurpasses transfer learning models, achieving a classification accuracy of\n94.39%. The integration of XAI methods enhances model transparency, offering\ncrucial insights to aid medical professionals in diagnosing brain diseases with\ngreater precision.",
    "pdf_url": "http://arxiv.org/pdf/2505.16039v3",
    "published": "2025-05-21T21:38:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16038v1",
    "title": "Initial-State Charge Density Predicts Final-State Net Charge Flow in Heavy-Ion Collisions",
    "authors": [
      "Jefferson Sousa",
      "Matthew D. Sievert",
      "Jacquelyn Noronha-Hostler",
      "Patrick Carzon",
      "Matthew Luzum"
    ],
    "abstract": "We propose a new class of charge-conjugation-odd flow observables and use\nthem to investigate the dynamics of conserved currents in simulations of\nrelativistic heavy-ion collisions. Inspired by the success of the initial\nenergy and momentum distributions at predicting final-state anisotropic flow,\nwe construct systematically-improvable initial-state estimators for final\nnet-charge flow observables, which we validate with numerical simulations. This\nopens the possibility of a multitude of new charge-dependent probes of\nheavy-ion collisions of different systems and energies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16038v1",
    "published": "2025-05-21T21:35:17+00:00",
    "categories": [
      "nucl-th",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16037v1",
    "title": "Causal LLM Routing: End-to-End Regret Minimization from Observational Data",
    "authors": [
      "Asterios Tsiourvas",
      "Wei Sun",
      "Georgia Perakis"
    ],
    "abstract": "LLM routing aims to select the most appropriate model for each query,\nbalancing competing performance metrics such as accuracy and cost across a pool\nof language models. Prior approaches typically adopt a decoupled strategy,\nwhere the metrics are first predicted and the model is then selected based on\nthese estimates. This setup is prone to compounding errors and often relies on\nfull-feedback data, where each query is evaluated by all candidate models,\nwhich is costly to obtain and maintain in practice. In contrast, we learn from\nobservational data, which records only the outcome of the model actually\ndeployed. We propose a causal end-to-end framework that learns routing policies\nby minimizing decision-making regret from observational data. To enable\nefficient optimization, we introduce two theoretically grounded surrogate\nobjectives: a classification-based upper bound, and a softmax-weighted regret\napproximation shown to recover the optimal policy at convergence. We further\nextend our framework to handle heterogeneous cost preferences via an\ninterval-conditioned architecture. Experiments on public benchmarks show that\nour method outperforms existing baselines, achieving state-of-the-art\nperformance across different embedding models.",
    "pdf_url": "http://arxiv.org/pdf/2505.16037v1",
    "published": "2025-05-21T21:34:18+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16036v1",
    "title": "OpenEthics: A Comprehensive Ethical Evaluation of Open-Source Generative Large Language Models",
    "authors": [
      "Burak Erin√ß √áetin",
      "Yƒ±ldƒ±rƒ±m √ñzen",
      "Elif Naz Demiryƒ±lmaz",
      "Kaan Eng√ºr",
      "Cagri Toraman"
    ],
    "abstract": "Generative large language models present significant potential but also raise\ncritical ethical concerns. Most studies focus on narrow ethical dimensions, and\nalso limited diversity of languages and models. To address these gaps, we\nconduct a broad ethical evaluation of 29 recent open-source large language\nmodels using a novel data collection including four ethical aspects:\nRobustness, reliability, safety, and fairness. We analyze model behavior in\nboth a commonly used language, English, and a low-resource language, Turkish.\nOur aim is to provide a comprehensive ethical assessment and guide safer model\ndevelopment by filling existing gaps in evaluation breadth, language coverage,\nand model diversity. Our experimental results, based on LLM-as-a-Judge, reveal\nthat optimization efforts for many open-source models appear to have\nprioritized safety and fairness, and demonstrated good robustness while\nreliability remains a concern. We demonstrate that ethical evaluation can be\neffectively conducted independently of the language used. In addition, models\nwith larger parameter counts tend to exhibit better ethical performance, with\nGemma and Qwen models demonstrating the most ethical behavior among those\nevaluated.",
    "pdf_url": "http://arxiv.org/pdf/2505.16036v1",
    "published": "2025-05-21T21:31:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16035v1",
    "title": "Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces",
    "authors": [
      "Alejandro Garc√≠a-Castellanos",
      "David R. Wessels",
      "Nicky J. van den Berg",
      "Remco Duits",
      "Dani√´l M. Pelt",
      "Erik J. Bekkers"
    ],
    "abstract": "We introduce Equivariant Neural Eikonal Solvers, a novel framework that\nintegrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our\napproach employs a single neural field where a unified shared backbone is\nconditioned on signal-specific latent variables - represented as point clouds\nin a Lie group - to model diverse Eikonal solutions. The ENF integration\nensures equivariant mapping from these latent representations to the solution\nfield, delivering three key benefits: enhanced representation efficiency\nthrough weight-sharing, robust geometric grounding, and solution steerability.\nThis steerability allows transformations applied to the latent point cloud to\ninduce predictable, geometrically meaningful modifications in the resulting\nEikonal solution. By coupling these steerable representations with\nPhysics-Informed Neural Networks (PINNs), our framework accurately models\nEikonal travel-time solutions while generalizing to arbitrary Riemannian\nmanifolds with regular group actions. This includes homogeneous spaces such as\nEuclidean, position-orientation, spherical, and hyperbolic manifolds. We\nvalidate our approach through applications in seismic travel-time modeling of\n2D and 3D benchmark datasets. Experimental results demonstrate superior\nperformance, scalability, adaptability, and user controllability compared to\nexisting Neural Operator-based Eikonal solver methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.16035v1",
    "published": "2025-05-21T21:29:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16034v1",
    "title": "\"AI just keeps guessing\": Using ARC Puzzles to Help Children Identify Reasoning Errors in Generative AI",
    "authors": [
      "Aayushi Dangol",
      "Runhua Zhao",
      "Robert Wolfe",
      "Trushaa Ramanan",
      "Julie A. Kientz",
      "Jason Yip"
    ],
    "abstract": "The integration of generative Artificial Intelligence (genAI) into everyday\nlife raises questions about the competencies required to critically engage with\nthese technologies. Unlike visual errors in genAI, textual mistakes are often\nharder to detect and require specific domain knowledge. Furthermore, AI's\nauthoritative tone and structured responses can create an illusion of\ncorrectness, leading to overtrust, especially among children. To address this,\nwe developed AI Puzzlers, an interactive system based on the Abstraction and\nReasoning Corpus (ARC), to help children identify and analyze errors in genAI.\nDrawing on Mayer & Moreno's Cognitive Theory of Multimedia Learning, AI\nPuzzlers uses visual and verbal elements to reduce cognitive overload and\nsupport error detection. Based on two participatory design sessions with 21\nchildren (ages 6 - 11), our findings provide both design insights and an\nempirical understanding of how children identify errors in genAI reasoning,\ndevelop strategies for navigating these errors, and evaluate AI outputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16034v1",
    "published": "2025-05-21T21:27:23+00:00",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16033v2",
    "title": "An Approach Towards Identifying Bangladeshi Leaf Diseases through Transfer Learning and XAI",
    "authors": [
      "Faika Fairuj Preotee",
      "Shuvashis Sarker",
      "Shamim Rahim Refat",
      "Tashreef Muhammad",
      "Shifat Islam"
    ],
    "abstract": "Leaf diseases are harmful conditions that affect the health, appearance and\nproductivity of plants, leading to significant plant loss and negatively\nimpacting farmers' livelihoods. These diseases cause visible symptoms such as\nlesions, color changes, and texture variations, making it difficult for farmers\nto manage plant health, especially in large or remote farms where expert\nknowledge is limited. The main motivation of this study is to provide an\nefficient and accessible solution for identifying plant leaf diseases in\nBangladesh, where agriculture plays a critical role in food security. The\nobjective of our research is to classify 21 distinct leaf diseases across six\nplants using deep learning models, improving disease detection accuracy while\nreducing the need for expert involvement. Deep Learning (DL) techniques,\nincluding CNN and Transfer Learning (TL) models like VGG16, VGG19, MobileNetV2,\nInceptionV3, ResNet50V2 and Xception are used. VGG19 and Xception achieve the\nhighest accuracies, with 98.90% and 98.66% respectively. Additionally,\nExplainable AI (XAI) techniques such as GradCAM, GradCAM++, LayerCAM, ScoreCAM\nand FasterScoreCAM are used to enhance transparency by highlighting the regions\nof the models focused on during disease classification. This transparency\nensures that farmers can understand the model's predictions and take necessary\naction. This approach not only improves disease management but also supports\nfarmers in making informed decisions, leading to better plant protection and\nincreased agricultural productivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.16033v2",
    "published": "2025-05-21T21:25:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16032v1",
    "title": "CUR Matrix Approximation through Convex Optimization for Feature Selection",
    "authors": [
      "Kathryn Linehan",
      "Radu Balan"
    ],
    "abstract": "The singular value decomposition (SVD) is commonly used in applications\nrequiring a low rank matrix approximation. However, the singular vectors cannot\nbe interpreted in terms of the original data. For applications requiring this\ntype of interpretation, e.g., selection of important data matrix columns or\nrows, the approximate CUR matrix factorization can be used. Work on the CUR\nmatrix approximation has generally focused on algorithm development,\ntheoretical guarantees, and applications. In this work, we present a novel\ndeterministic CUR formulation and algorithm with theoretical convergence\nguarantees. The algorithm utilizes convex optimization, finds important columns\nand rows separately, and allows the user to control the number of important\ncolumns and rows selected from the original data matrix. We present numerical\nresults and demonstrate the effectiveness of our CUR algorithm as a feature\nselection method on gene expression data. These results are compared to those\nusing the SVD and other CUR algorithms as the feature selection method. Lastly,\nwe present a novel application of CUR as a feature selection method to\ndetermine discriminant proteins when clustering protein expression data in a\nself-organizing map (SOM), and compare the performance of multiple CUR\nalgorithms in this application.",
    "pdf_url": "http://arxiv.org/pdf/2505.16032v1",
    "published": "2025-05-21T21:24:36+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65F55, 65K05"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16031v1",
    "title": "Children's Mental Models of AI Reasoning: Implications for AI Literacy Education",
    "authors": [
      "Aayushi Dangol",
      "Robert Wolfe",
      "Runhua Zhao",
      "JaeWon Kim",
      "Trushaa Ramanan",
      "Katie Davis",
      "Julie A. Kientz"
    ],
    "abstract": "As artificial intelligence (AI) advances in reasoning capabilities, most\nrecently with the emergence of Large Reasoning Models (LRMs), understanding how\nchildren conceptualize AI's reasoning processes becomes critical for fostering\nAI literacy. While one of the \"Five Big Ideas\" in AI education highlights\nreasoning algorithms as central to AI decision-making, less is known about\nchildren's mental models in this area. Through a two-phase approach, consisting\nof a co-design session with 8 children followed by a field study with 106\nchildren (grades 3-8), we identified three models of AI reasoning: Deductive,\nInductive, and Inherent. Our findings reveal that younger children (grades 3-5)\noften attribute AI's reasoning to inherent intelligence, while older children\n(grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions\nthat surfaced in children's understanding of AI reasoning and conclude with\nimplications for scaffolding AI curricula and designing explainable AI tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.16031v1",
    "published": "2025-05-21T21:20:12+00:00",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16030v1",
    "title": "Locally Subspace-Informed Neural Operators for Efficient Multiscale PDE Solving",
    "authors": [
      "Alexander Rudikov",
      "Vladimir Fanaskov",
      "Sergei Stepanov",
      "Buzheng Shan",
      "Ekaterina Muravleva",
      "Yalchin Efendiev",
      "Ivan Oseledets"
    ],
    "abstract": "Neural operators (NOs) struggle with high-contrast multiscale partial\ndifferential equations (PDEs), where fine-scale heterogeneities cause large\nerrors. To address this, we use the Generalized Multiscale Finite Element\nMethod (GMsFEM) that constructs localized spectral basis functions on coarse\ngrids. This approach efficiently captures dominant multiscale features while\nsolving heterogeneous PDEs accurately at reduced computational cost. However,\ncomputing these basis functions is computationally expensive. This gap\nmotivates our core idea: to use a NO to learn the subspace itself - rather than\nindividual basis functions - by employing a subspace-informed loss. On standard\nmultiscale benchmarks - namely a linear elliptic diffusion problem and the\nnonlinear, steady-state Richards equation - our hybrid method cuts solution\nerror by approximately $60\\%$ compared with standalone NOs and reduces\nbasis-construction time by about $60$ times relative to classical GMsFEM, while\nremaining independent of forcing terms and boundary conditions. The result\nfuses multiscale finite-element robustness with NO speed, yielding a practical\nsolver for heterogeneous PDEs.",
    "pdf_url": "http://arxiv.org/pdf/2505.16030v1",
    "published": "2025-05-21T21:18:28+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16029v1",
    "title": "Learning better representations for crowded pedestrians in offboard LiDAR-camera 3D tracking-by-detection",
    "authors": [
      "Shichao Li",
      "Peiliang Li",
      "Qing Lian",
      "Peng Yun",
      "Xiaozhi Chen"
    ],
    "abstract": "Perceiving pedestrians in highly crowded urban environments is a difficult\nlong-tail problem for learning-based autonomous perception. Speeding up 3D\nground truth generation for such challenging scenes is performance-critical yet\nvery challenging. The difficulties include the sparsity of the captured\npedestrian point cloud and a lack of suitable benchmarks for a specific system\ndesign study. To tackle the challenges, we first collect a new multi-view\nLiDAR-camera 3D multiple-object-tracking benchmark of highly crowded\npedestrians for in-depth analysis. We then build an offboard auto-labeling\nsystem that reconstructs pedestrian trajectories from LiDAR point cloud and\nmulti-view images. To improve the generalization power for crowded scenes and\nthe performance for small objects, we propose to learn high-resolution\nrepresentations that are density-aware and relationship-aware. Extensive\nexperiments validate that our approach significantly improves the 3D pedestrian\ntracking performance towards higher auto-labeling efficiency. The code will be\npublicly available at this HTTP URL.",
    "pdf_url": "http://arxiv.org/pdf/2505.16029v1",
    "published": "2025-05-21T21:18:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16028v2",
    "title": "Comprehensive Lung Disease Detection Using Deep Learning Models and Hybrid Chest X-ray Data with Explainable AI",
    "authors": [
      "Shuvashis Sarker",
      "Shamim Rahim Refat",
      "Faika Fairuj Preotee",
      "Tanvir Rouf Shawon",
      "Raihan Tanvir"
    ],
    "abstract": "Advanced diagnostic instruments are crucial for the accurate detection and\ntreatment of lung diseases, which affect millions of individuals globally. This\nstudy examines the effectiveness of deep learning and transfer learning models\nusing a hybrid dataset, created by merging four individual datasets from\nBangladesh and global sources. The hybrid dataset significantly enhances model\naccuracy and generalizability, particularly in detecting COVID-19, pneumonia,\nlung opacity, and normal lung conditions from chest X-ray images. A range of\nmodels, including CNN, VGG16, VGG19, InceptionV3, Xception, ResNet50V2,\nInceptionResNetV2, MobileNetV2, and DenseNet121, were applied to both\nindividual and hybrid datasets. The results showed superior performance on the\nhybrid dataset, with VGG16, Xception, ResNet50V2, and DenseNet121 each\nachieving an accuracy of 99%. This consistent performance across the hybrid\ndataset highlights the robustness of these models in handling diverse data\nwhile maintaining high accuracy. To understand the models implicit behavior,\nexplainable AI techniques were employed to illuminate their black-box nature.\nSpecifically, LIME was used to enhance the interpretability of model\npredictions, especially in cases of misclassification, contributing to the\ndevelopment of reliable and interpretable AI-driven solutions for medical\nimaging.",
    "pdf_url": "http://arxiv.org/pdf/2505.16028v2",
    "published": "2025-05-21T21:17:47+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16027v1",
    "title": "Benchmarking Chest X-ray Diagnosis Models Across Multinational Datasets",
    "authors": [
      "Qinmei Xu",
      "Yiheng Li",
      "Xianghao Zhan",
      "Ahmet Gorkem Er",
      "Brittany Dashevsky",
      "Chuanjun Xu",
      "Mohammed Alawad",
      "Mengya Yang",
      "Liu Ya",
      "Changsheng Zhou",
      "Xiao Li",
      "Haruka Itakura",
      "Olivier Gevaert"
    ],
    "abstract": "Foundation models leveraging vision-language pretraining have shown promise\nin chest X-ray (CXR) interpretation, yet their real-world performance across\ndiverse populations and diagnostic tasks remains insufficiently evaluated. This\nstudy benchmarks the diagnostic performance and generalizability of foundation\nmodels versus traditional convolutional neural networks (CNNs) on multinational\nCXR datasets. We evaluated eight CXR diagnostic models - five vision-language\nfoundation models and three CNN-based architectures - across 37 standardized\nclassification tasks using six public datasets from the USA, Spain, India, and\nVietnam, and three private datasets from hospitals in China. Performance was\nassessed using AUROC, AUPRC, and other metrics across both shared and\ndataset-specific tasks. Foundation models outperformed CNNs in both accuracy\nand task coverage. MAVL, a model incorporating knowledge-enhanced prompts and\nstructured supervision, achieved the highest performance on public (mean AUROC:\n0.82; AUPRC: 0.32) and private (mean AUROC: 0.95; AUPRC: 0.89) datasets,\nranking first in 14 of 37 public and 3 of 4 private tasks. All models showed\nreduced performance on pediatric cases, with average AUROC dropping from 0.88\n+/- 0.18 in adults to 0.57 +/- 0.29 in children (p = 0.0202). These findings\nhighlight the value of structured supervision and prompt design in radiologic\nAI and suggest future directions including geographic expansion and ensemble\nmodeling for clinical deployment. Code for all evaluated models is available at\nhttps://drive.google.com/drive/folders/1B99yMQm7bB4h1sVMIBja0RfUu8gLktCE",
    "pdf_url": "http://arxiv.org/pdf/2505.16027v1",
    "published": "2025-05-21T21:16:50+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "I.2"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16026v2",
    "title": "Edge modes of tetrad gravity: Unlike diffeomorphisms, all shifts are integrable",
    "authors": [
      "Simon Langenscheidt"
    ],
    "abstract": "We present an improved notion of internal tetrad shifts in 4 dimensions which\nis always integrable in the presence of corners. This allows us to study the\nfully extended corner symmetry algebra of gauge charges, which is a deformation\nof $ISO(1,3)^S$ involving spacetime curvature. We argue this implies corner\nnoncommutativity of the spin connection $\\omega$. The latter in particular\nhints that an extended BF theory might be a better way understand the dynamics\nof tetrad gravity. This result presents us with an integrable, complete set of\nedge modes for gravity in 4D, with potential ramifications for asymptotic\nsymmetries and quantisation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16026v2",
    "published": "2025-05-21T21:15:41+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.16025v2",
    "title": "CP-LLM: Context and Pixel Aware Large Language Model for Video Quality Assessment",
    "authors": [
      "Wen Wen",
      "Yaohong Wu",
      "Yue Sheng",
      "Neil Birkbeck",
      "Balu Adsumilli",
      "Yilin Wang"
    ],
    "abstract": "Video quality assessment (VQA) is a challenging research topic with broad\napplications. Effective VQA necessitates sensitivity to pixel-level distortions\nand a comprehensive understanding of video context to accurately determine the\nperceptual impact of distortions. Traditional hand-crafted and learning-based\nVQA models mainly focus on pixel-level distortions and lack contextual\nunderstanding, while recent LLM-based models struggle with sensitivity to small\ndistortions or handle quality scoring and description as separate tasks. To\naddress these shortcomings, we introduce CP-LLM: a Context and Pixel aware\nLarge Language Model. CP-LLM is a novel multimodal LLM architecture featuring\ndual vision encoders designed to independently analyze perceptual quality at\nboth high-level (video context) and low-level (pixel distortion) granularity,\nalong with a language decoder subsequently reasons about the interplay between\nthese aspects. This design enables CP-LLM to simultaneously produce robust\nquality scores and interpretable quality descriptions, with enhanced\nsensitivity to pixel distortions (e.g. compression artifacts). The model is\ntrained via a multi-task pipeline optimizing for score prediction, description\ngeneration, and pairwise comparisons. Experiment results demonstrate that\nCP-LLM achieves state-of-the-art cross-dataset performance on established VQA\nbenchmarks and superior robustness to pixel distortions, confirming its\nefficacy for comprehensive and practical video quality assessment in real-world\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.16025v2",
    "published": "2025-05-21T21:13:19+00:00",
    "categories": [
      "cs.CV",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16024v1",
    "title": "Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging",
    "authors": [
      "Weiguo Gao",
      "Ming Li"
    ],
    "abstract": "Diffusion trajectory distillation methods aim to accelerate sampling in\ndiffusion models, which produce high-quality outputs but suffer from slow\nsampling speeds. These methods train a student model to approximate the\nmulti-step denoising process of a pretrained teacher model in a single step,\nenabling one-shot generation. However, theoretical insights into the trade-off\nbetween different distillation strategies and generative quality remain\nlimited, complicating their optimization and selection. In this work, we take a\nfirst step toward addressing this gap. Specifically, we reinterpret trajectory\ndistillation as an operator merging problem in the linear regime, where each\nstep of the teacher model is represented as a linear operator acting on noisy\ndata. These operators admit a clear geometric interpretation as projections and\nrescalings corresponding to the noise schedule. During merging, signal\nshrinkage occurs as a convex combination of operators, arising from both\ndiscretization and limited optimization time of the student model. We propose a\ndynamic programming algorithm to compute the optimal merging strategy that\nmaximally preserves signal fidelity. Additionally, we demonstrate the existence\nof a sharp phase transition in the optimal strategy, governed by data\ncovariance structures. Our findings enhance the theoretical understanding of\ndiffusion trajectory distillation and offer practical insights for improving\ndistillation strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16024v1",
    "published": "2025-05-21T21:13:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16023v3",
    "title": "Prototypical Human-AI Collaboration Behaviors from LLM-Assisted Writing in the Wild",
    "authors": [
      "Sheshera Mysore",
      "Debarati Das",
      "Hancheng Cao",
      "Bahareh Sarrafzadeh"
    ],
    "abstract": "As large language models (LLMs) are used in complex writing workflows, users\nengage in multi-turn interactions to steer generations to better fit their\nneeds. Rather than passively accepting output, users actively refine, explore,\nand co-construct text. We conduct a large-scale analysis of this collaborative\nbehavior for users engaged in writing tasks in the wild with two popular AI\nassistants, Bing Copilot and WildChat. Our analysis goes beyond simple task\nclassification or satisfaction estimation common in prior work and instead\ncharacterizes how users interact with LLMs through the course of a session. We\nidentify prototypical behaviors in how users interact with LLMs in prompts\nfollowing their original request. We refer to these as Prototypical Human-AI\nCollaboration Behaviors (PATHs) and find that a small group of PATHs explain a\nmajority of the variation seen in user-LLM interaction. These PATHs span users\nrevising intents, exploring texts, posing questions, adjusting style or\ninjecting new content. Next, we find statistically significant correlations\nbetween specific writing intents and PATHs, revealing how users' intents shape\ntheir collaboration behaviors. We conclude by discussing the implications of\nour findings on LLM alignment.",
    "pdf_url": "http://arxiv.org/pdf/2505.16023v3",
    "published": "2025-05-21T21:13:01+00:00",
    "categories": [
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16022v2",
    "title": "NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning",
    "authors": [
      "Wei Liu",
      "Siya Qi",
      "Xinyu Wang",
      "Chen Qian",
      "Yali Du",
      "Yulan He"
    ],
    "abstract": "Recent advances such as DeepSeek R1-Zero highlight the effectiveness of\nincentive training, a reinforcement learning paradigm that computes rewards\nsolely based on the final answer part of a language model's output, thereby\nencouraging the generation of intermediate reasoning steps. However, these\nmethods fundamentally rely on external verifiers, which limits their\napplicability to domains like mathematics and coding where such verifiers are\nreadily available. Although reward models can serve as verifiers, they require\nhigh-quality annotated data and are costly to train. In this work, we propose\nNOVER, NO-VERifier Reinforcement Learning, a general reinforcement learning\nframework that requires only standard supervised fine-tuning data with no need\nfor an external verifier. NOVER enables incentive training across a wide range\nof text-to-text tasks and outperforms the model of the same size distilled from\nlarge reasoning models such as DeepSeek R1 671B by 7.7 percent. Moreover, the\nflexibility of NOVER enables new possibilities for optimizing large language\nmodels, such as inverse incentive training.",
    "pdf_url": "http://arxiv.org/pdf/2505.16022v2",
    "published": "2025-05-21T21:12:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16021v1",
    "title": "Auxiliary Field Quantum Monte Carlo for Electron-Photon Correlation",
    "authors": [
      "Braden M. Weight",
      "Yu Zhang"
    ],
    "abstract": "Hybrid light-matter polaritonic states have shown great promise for altering\nalready known and enabling novel chemical reactions and controlling\nphotophysical phenomena. This field has recently become one of the most\nprominent and active areas of research that connects the communities of\nchemistry and quantum optics. The ab initio modeling of such polaritonic\nphenomena has led to updating commonly used electronic structure methods, such\nas Hartree-Fock, density functional, and coupled cluster theories, to\nexplicitly include Bosonic degrees of freedom. In this work, we explore the\nquantum electrodynamic auxiliary field quantum Monte Carlo (QED-AFQMC) method\nto accurately capture the polaritonic ground state of representative quantum\nchemical benchmark systems to explore electron-photon correlations. We analyze\nthese correlations across multiple examples and benchmark the QED-AFQMC results\nagainst other ab initio quantum electrodynamics methods, including QED-coupled\ncluster and QED-full configuration interaction, demonstrating the method's\naccuracy and its potential for scalable simulations of strongly coupled\nlight-matter systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.16021v1",
    "published": "2025-05-21T21:10:49+00:00",
    "categories": [
      "quant-ph",
      "physics.chem-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.16020v3",
    "title": "Holstein mechanism in single-site model with unitary evolution",
    "authors": [
      "Chen-Huan Wu"
    ],
    "abstract": "We investigate the Holstein mechanism in a single-electron (one-site) system,\nwhere unitary evolution intrinsically involves both fermion and boson operators\nunder nonadiabatic conditions. The resulting unitary dynamics and\nboson-frequency dependence reveal a quantum phase transition, evidenced by\ndistinct short-time (power-law decay) and long-time (exponential decay)\nbehaviors, which are manifested in the polaronic shift, bosonic energy, and\ndynamics of reduced density matrix. This observation is consistent with a\nnon-Markovian to Markovian transition.",
    "pdf_url": "http://arxiv.org/pdf/2505.16020v3",
    "published": "2025-05-21T21:08:08+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "quant-ph"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.16019v1",
    "title": "Quantile Predictions for Equity Premium using Penalized Quantile Regression with Consistent Variable Selection across Multiple Quantiles",
    "authors": [
      "Shaobo Li",
      "Ben Sherwood"
    ],
    "abstract": "This paper considers equity premium prediction, for which mean regression can\nbe problematic due to heteroscedasticity and heavy-tails of the error. We show\nadvantages of quantile predictions using a novel penalized quantile regression\nthat offers a model for a full spectrum analysis on the equity premium\ndistribution. To enhance model interpretability and address the well-known\nissue of crossing quantile predictions in quantile regression, we propose a\nmodel that enforces the selection of a common set of variables across all\nquantiles. Such a selection consistency is achieved by simultaneously\nestimating all quantiles with a group penalty that ensures sparsity pattern is\nthe same for all quantiles. Consistency results are provided that allow the\nnumber of predictors to increase with the sample size. A Huberized quantile\nloss function and an augmented data approach are implemented for computational\nefficiency. Simulation studies show the effectiveness of the proposed approach.\nEmpirical results show that the proposed method outperforms several benchmark\nmethods. Moreover, we find some important predictors reverse their relationship\nto the excess return from lower to upper quantiles, potentially offering\ninteresting insights to the domain experts. Our proposed method can be applied\nto other fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.16019v1",
    "published": "2025-05-21T21:05:08+00:00",
    "categories": [
      "stat.ME",
      "q-fin.ST",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.17125v1",
    "title": "NEXT-EVAL: Next Evaluation of Traditional and LLM Web Data Record Extraction",
    "authors": [
      "Soyeon Kim",
      "Namhee Kim",
      "Yeonwoo Jeong"
    ],
    "abstract": "Effective evaluation of web data record extraction methods is crucial, yet\nhampered by static, domain-specific benchmarks and opaque scoring practices.\nThis makes fair comparison between traditional algorithmic techniques, which\nrely on structural heuristics, and Large Language Model (LLM)-based approaches,\noffering zero-shot extraction across diverse layouts, particularly challenging.\nTo overcome these limitations, we introduce a concrete evaluation framework.\nOur framework systematically generates evaluation datasets from arbitrary MHTML\nsnapshots, annotates XPath-based supervision labels, and employs\nstructure-aware metrics for consistent scoring, specifically preventing text\nhallucination and allowing only for the assessment of positional hallucination.\nIt also incorporates preprocessing strategies to optimize input for LLMs while\npreserving DOM semantics: HTML slimming, Hierarchical JSON, and Flat JSON.\nAdditionally, we created a publicly available synthetic dataset by transforming\nDOM structures and modifying content. We benchmark deterministic heuristic\nalgorithms and off-the-shelf LLMs across these multiple input formats. Our\nbenchmarking shows that Flat JSON input enables LLMs to achieve superior\nextraction accuracy (F1 score of 0.9567) and minimal hallucination compared to\nother input formats like Slimmed HTML and Hierarchical JSON. We establish a\nstandardized foundation for rigorous benchmarking, paving the way for the next\nprincipled advancements in web data record extraction.",
    "pdf_url": "http://arxiv.org/pdf/2505.17125v1",
    "published": "2025-05-21T21:03:37+00:00",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.16018v1",
    "title": "Non-equilibrium steady state for a three-mode energy cascade model",
    "authors": [
      "Zaher Hani",
      "Yao Li",
      "Andrea Nahmod",
      "Gigliola Staffilani"
    ],
    "abstract": "Motivated by the central phenomenon of energy cascades in wave turbulence\ntheory, we construct non-equilibrium statistical steady states (NESS), or\ninvariant measures, for a simplified model derived from the nonlinear\nSchr\\\"odinger (NLS) equation with external forcing and dissipation. This new\nperspective to studying energy cascades, distinct from traditional analyses\nbased on kinetic equations and their cascade spectra, focuses on the underlying\nstatistical steady state that is expected to hold when the cascade spectra of\nwave turbulence manifest.\n  In the full generality of the (infinite dimensional) nonlinear Schr\\\"odinger\nequation, constructing such invariant measures is more involved than the\nrigorous justification of the Kolmogorov-Zakharov (KZ) spectra, which itself\nremains an outstanding open question despite the recent progress on\nmathematical wave turbulence. Since such complexity remains far beyond the\ncurrent knowledge (even for much simpler chain models), we confine our analysis\nto a three-mode reduced system that captures the resonant dynamics of the NLS\nequation, offering a tractable framework for constructing the NESS. For this,\nwe introduce a novel approach based on solving an elliptic Feynman-Kac equation\nto construct the needed Lyapunov function.",
    "pdf_url": "http://arxiv.org/pdf/2505.16018v1",
    "published": "2025-05-21T21:01:54+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.DS",
      "math.MP",
      "60H10, 35Q55, 82C05"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16017v1",
    "title": "GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection",
    "authors": [
      "Mariia Seleznova",
      "Hung-Hsu Chou",
      "Claudio Mayrink Verdun",
      "Gitta Kutyniok"
    ],
    "abstract": "We introduce GradPCA, an Out-of-Distribution (OOD) detection method that\nexploits the low-rank structure of neural network gradients induced by Neural\nTangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis\n(PCA) to gradient class-means, achieving more consistent performance than\nexisting methods across standard image classification benchmarks. We provide a\ntheoretical perspective on spectral OOD detection in neural networks to support\nGradPCA, highlighting feature-space properties that enable effective detection\nand naturally emerge from NTK alignment. Our analysis further reveals that\nfeature quality -- particularly the use of pretrained versus non-pretrained\nrepresentations -- plays a crucial role in determining which detectors will\nsucceed. Extensive experiments validate the strong performance of GradPCA, and\nour theoretical framework offers guidance for designing more principled\nspectral OOD detectors.",
    "pdf_url": "http://arxiv.org/pdf/2505.16017v1",
    "published": "2025-05-21T21:00:39+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16016v2",
    "title": "Electronic mobility, doping, and defects in epitaxial $\\mathrm{BaZrS_3}$ chalcogenide perovskite thin films",
    "authors": [
      "Jack Van Sambeek",
      "Jessica Dong",
      "Anton V. Ievlev",
      "Tao Cai",
      "Ida Sadeghi",
      "Rafael Jaramillo"
    ],
    "abstract": "We present the electronic transport properties of $\\mathrm{BaZrS_3}$ (BZS)\nthin films grown epitaxially by gas-source molecular beam epitaxy (MBE). We\nobserve n-type behavior in all samples, with carrier concentration ranging from\n$4 \\times 10^{18}$ to $4 \\times 10^{20} \\mathrm{cm^{-3}}$ at room temperature\n(RT). We observe a champion RT Hall mobility of 11.1\n$\\mathrm{cm^2V^{-1}s^{-1}}$, which is competitive with established thin-film\nphotovoltaic (PV) absorbers. Temperature-dependent Hall mobility data show that\nphonon scattering dominates at room temperature, in agreement with\ncomputational predictions. X-ray diffraction data illustrate a correlation\nbetween mobility and stacking fault concentration, illustrating how\nmicrostructure can affect transport. Despite the well-established environmental\nstability of chalcogenide perovskites, we observe significant changes to\nelectronic properties as a function of storage time in ambient conditions. With\nthe help of secondary-ion mass-spectrometry (SIMS) measurements, we propose and\nsupport a defect mechanism that explains this behavior: as-grown films have a\nhigh concentration of sulfur vacancies that are shallow donors\n($\\mathrm{V_S^\\bullet}$ or $\\mathrm{V_S^{\\bullet \\bullet}}$), which are\nconverted into neutral oxygen defects ($\\mathrm{O_S^\\times}$) upon air\nexposure. We discuss the relevance of this defect mechanism within the larger\ncontext of chalcogenide perovskite research, and we identify means to stabilize\nthe electronic properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.16016v2",
    "published": "2025-05-21T21:00:23+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.16015v1",
    "title": "Generalized algebraic connectivity of graphs in Euclidean spaces: extremal properties and bounds",
    "authors": [
      "Juan F. Presenza",
      "Ignacio Mas",
      "Juan I. Giribet",
      "J. Ignacio Alvarez-Hamelin"
    ],
    "abstract": "Graph rigidity, the study of vertex realizations in $\\mathbb{R}^d$ and the\nmotions that preserve the induced edge lengths, has been the focus of extensive\nresearch for decades. Its equivalency to graph connectivity for $d=1$ is well\nknown; thus it can be viewed as a generalization that incorporates geometric\nconstraints. Graph connectivity is commonly quantified by the algebraic\nconnectivity, the second-smallest eigenvalue of the Laplacian matrix. Recently,\na graph invariant for quantifying graph rigidity in $\\mathbb{R}^d$, termed the\ngeneralized algebraic connectivity, was introduced. Recognizing the intrinsic\nrelationship between rigidity and connectivity, this article presents new\ncontributions. In particular, we introduce the d-rigidity ratio as a metric for\nexpressing the level of rigidity of a graph in $\\mathbb{R}^d$ relative to its\nconnectivity. We show that this ratio is bounded and provide extremal examples.\nAdditionally, we offer a new upper bound for the generalized algebraic\nconnectivity that depends inversely on the diameter and on the vertex\nconnectivity, thereby improving previous bounds. Moreover, we investigate the\nrelationship between graph rigidity and the diameter, a measure of the graph's\noverall extent. We provide the maximal diameter achievable by rigid graphs and\nshow that generalized path graphs serve as extremal examples. Finally, we\nderive an upper bound for the generalized algebraic connectivity of generalized\npath graphs that (asymptotically) improves upon existing ones by a factor of\nfour.",
    "pdf_url": "http://arxiv.org/pdf/2505.16015v1",
    "published": "2025-05-21T20:58:52+00:00",
    "categories": [
      "math.CO",
      "math.OC"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.16014v3",
    "title": "Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains",
    "authors": [
      "Yash Saxena",
      "Ankur Padia",
      "Mandar S Chaudhary",
      "Kalpa Gunaratna",
      "Srinivasan Parthasarathy",
      "Manas Gaur"
    ],
    "abstract": "Traditional Retrieval-Augmented Generation (RAG) pipelines rely on\nsimilarity-based retrieval and re-ranking, which depend on heuristics such as\ntop-k, and lack explainability, interpretability, and robustness against\nadversarial content. To address this gap, we propose a novel method METEORA\nthat replaces re-ranking in RAG with a rationale-driven selection approach.\nMETEORA operates in two stages. First, a general-purpose LLM is\npreference-tuned to generate rationales conditioned on the input query using\ndirect preference optimization. These rationales guide the evidence chunk\nselection engine, which selects relevant chunks in three stages: pairing\nindividual rationales with corresponding retrieved chunks for local relevance,\nglobal selection with elbow detection for adaptive cutoff, and context\nexpansion via neighboring chunks. This process eliminates the need for top-k\nheuristics. The rationales are also used for consistency check using a Verifier\nLLM to detect and filter poisoned or misleading content for safe generation.\nThe framework provides explainable and interpretable evidence flow by using\nrationales consistently across both selection and verification. Our evaluation\nacross six datasets spanning legal, financial, and academic research domains\nshows that METEORA improves generation accuracy by 33.34% while using\napproximately 50% fewer chunks than state-of-the-art re-ranking methods. In\nadversarial settings, METEORA significantly improves the F1 score from 0.10 to\n0.44 over the state-of-the-art perplexity-based defense baseline, demonstrating\nstrong resilience to poisoning attacks. Code available at:\nhttps://anonymous.4open.science/r/METEORA-DC46/README.md",
    "pdf_url": "http://arxiv.org/pdf/2505.16014v3",
    "published": "2025-05-21T20:57:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16013v1",
    "title": "Towards improved pest management of the soybean aphid",
    "authors": [
      "Urvashi Verma",
      "Margaret Lewis",
      "Jordan Lehman",
      "Rana D. Parshad"
    ],
    "abstract": "The soybean aphid (\\emph{Aphis glycines}) is an invasive insect pest that\ncontinues to cause large-scale damage to soybean crops in the North Central\nUnited States. The current manuscript proposes several mathematical models for\nthe top-down bio-control of the aphid, as well as control via pesticides and\nneonicotinoids. The models are motivated empirically, and constructed based on\nlaboratory experiments conducted to test control of aphids by Lacewing larvae,\nas well as by a parasitic wasp (\\emph{Aphidius colemani}). The effectiveness of\nthese models is compared by taking into account factors such as economic injury\nlevels for soybeans, life history traits such as cannibalism amongst the\npredator, and intraguild predation between competing bio-control agents such as\npredators and parasitoids. The models predict multiple population peaks and\ntransient chaotic dynamics when a predator and/or insecticides are used. It is\nobserved that parasitoids, in conjunction with predators, are more efficient at\nstabilizing the population dynamics than insecticide use. They also suggest a\ncombination of predators, parasitoids, and insecticides would be more efficient\nat suppressing aphid populations than using only predators or parasitoids. The\nmodels also qualitatively capture the features seen in long-time field data\nfrom 2000-2013. We discuss applications of our results to pest management\nstrategies for soybean aphids in the context of a changing climate, as well as\nregime shifts.",
    "pdf_url": "http://arxiv.org/pdf/2505.16013v1",
    "published": "2025-05-21T20:56:43+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.16012v2",
    "title": "Decision DNNFs with imbalanced conjunction cannot efficiently represent CNFs of bounded width",
    "authors": [
      "Igor Razgon"
    ],
    "abstract": "Decomposable Negation Normal Forms \\textsc{dnnf} [Darwiche, 'Decomposable\nNegation Normal Form', JACM, 2001] is a landmark Knowledge Compilation\n(\\textsc{kc}) model, highly important both in \\textsc{ai} and Theoretical\nComputer Science. Numerous restrictions of the model have been studied. In this\npaper we consider the restriction where all the gates are $\\alpha$-imbalanced\nthat is, at most one input of each gate depends on more than $n^{\\alpha}$\nvariables (where $n$ is the number if variables of the function being\nrepresented).\n  The concept of imbalanced gates has been first considered in [Lai, Liu, Yin\n'New canonical representations by augmenting OBDDs with conjunctive\ndecomposition', JAIR, 2017]. We consider the idea in the context of\nrepresentation of \\textsc{cnf}s of bounded primal treewidth. We pose an open\nquestion as to whether \\textsc{cnf}s of bounded primal treewidth can be\nrepresented as \\textsc{fpt}-sized \\textsc{dnnf} with $\\alpha$-imbalanced gates.\n  We answer the question negatively for Decision \\textsc{dnnf} with\n$\\alpha$-imbalanced conjunction gates. In particular, we establish a lower\nbound of $n^{\\Omega((1-\\alpha) \\cdot k)}$ for the representation size (where\n$k$ is the primal treewidth of the input \\textsc{cnf}). The main engine for the\nabove lower bound is a combinatorial result that may be of an independent\ninterest in the area of parameterized complexity as it introduces a novel\nconcept of bidimensionality.",
    "pdf_url": "http://arxiv.org/pdf/2505.16012v2",
    "published": "2025-05-21T20:55:50+00:00",
    "categories": [
      "cs.CC"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16011v1",
    "title": "Exploring Perception-Based Techniques for Redirected Walking in VR: A Comprehensive Survey",
    "authors": [
      "Bradley Coles",
      "Yahya Hmaiti",
      "Joseph J. LaViola Jr"
    ],
    "abstract": "We present a comprehensive survey of perception-based redirected walking\n(RDW) techniques in virtual reality (VR), presenting a taxonomy that serves as\na framework for understanding and designing RDW algorithms. RDW enables users\nto explore virtual environments (VEs) larger than their physical space,\naddressing the constraints of real walking in limited home VR setups. Our\nreview spans 232 papers, with 165 included in the final analysis. We categorize\nperception-based RDW techniques based on gains, gain application, target\norientation calculation, and optional general enhancements, identifying key\npatterns and relationships. We present data on how current work aligns within\nthis classification system and suggest how this data can guide future work into\nareas that are relatively under explored. This taxonomy clarifies\nperception-based RDW techniques, guiding the design and application of RDW\nsystems, and suggests future research directions to enhance VR user experience.",
    "pdf_url": "http://arxiv.org/pdf/2505.16011v1",
    "published": "2025-05-21T20:55:05+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16010v1",
    "title": "Electric field effects on the collision efficiency of uncharged water droplets in a linear flow",
    "authors": [
      "Pijush Patra",
      "Anubhab Roy",
      "J. S. Wettlaufer"
    ],
    "abstract": "We study the dynamics of collisions between a pair of uncharged conducting\ndroplets under the influence of a uniaxial compressional flow and an external\nelectric field. The near-field asymptotic expression for the\nelectric-field-induced attractive force demonstrate that surface-to-surface\ncontact in finite time is facilitated by overcoming lubrication resistance. We\ndemonstrate the significant role of the external electric field on the relative\ntrajectories of two droplets in a compressional flow and provide estimates of\nthe correlation between collision efficiency and the forces induced by the\nelectric field. For droplet collisions in clouds, continuum lubrication\napproximations become inadequate to capture collision dynamics, and thus we\nincorporate non-continuum lubrication interactions into our analysis to address\nthis complexity. Our findings reveal the dependence of collision efficiency on\nthe strength of the electric field, geometry of the two interacting droplets,\nnon-continuum effects, and van der Waals forces.",
    "pdf_url": "http://arxiv.org/pdf/2505.16010v1",
    "published": "2025-05-21T20:53:32+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.ao-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.16009v1",
    "title": "On the full automorphism groups of $2$-designs constructed from finite fields ${\\mathbb F}_{2^n}$",
    "authors": [
      "Tung Le",
      "B. G. Rodrigues"
    ],
    "abstract": "In this manuscript, for $q:=2^n$ with $n\\geq2$, we study two primitive\nmaximal subgroups of the alternating group ${\\sf A}_{q-1}$. These subgroups are\nthe full automorphism groups of $2$-designs which are constructed from\nalgebraic curves over the finite field ${\\mathbb F}_q$.",
    "pdf_url": "http://arxiv.org/pdf/2505.16009v1",
    "published": "2025-05-21T20:49:31+00:00",
    "categories": [
      "math.GR",
      "math.CO",
      "05B05, 12E05, 20B15, 20B25, 20B35, 20D06"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.16008v1",
    "title": "LAGO: Few-shot Crosslingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization",
    "authors": [
      "Wenrui Yu",
      "Yiyi Chen",
      "Johannes Bjerva",
      "Sokol Kosta",
      "Qiongxiu Li"
    ],
    "abstract": "We propose LAGO - Language Similarity-Aware Graph Optimization - a novel\napproach for few-shot cross-lingual embedding inversion attacks, addressing\ncritical privacy vulnerabilities in multilingual NLP systems. Unlike prior work\nin embedding inversion attacks that treat languages independently, LAGO\nexplicitly models linguistic relationships through a graph-based constrained\ndistributed optimization framework. By integrating syntactic and lexical\nsimilarity as edge constraints, our method enables collaborative parameter\nlearning across related languages. Theoretically, we show this formulation\ngeneralizes prior approaches, such as ALGEN, which emerges as a special case\nwhen similarity constraints are relaxed. Our framework uniquely combines\nFrobenius-norm regularization with linear inequality or total variation\nconstraints, ensuring robust alignment of cross-lingual embedding spaces even\nwith extremely limited data (as few as 10 samples per language). Extensive\nexperiments across multiple languages and embedding models demonstrate that\nLAGO substantially improves the transferability of attacks with 10-20% increase\nin Rouge-L score over baselines. This work establishes language similarity as a\ncritical factor in inversion attack transferability, urging renewed focus on\nlanguage-aware privacy-preserving multilingual embeddings.",
    "pdf_url": "http://arxiv.org/pdf/2505.16008v1",
    "published": "2025-05-21T20:48:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16007v1",
    "title": "Position: Agentic Systems Constitute a Key Component of Next-Generation Intelligent Image Processing",
    "authors": [
      "Jinjin Gu"
    ],
    "abstract": "This position paper argues that the image processing community should broaden\nits focus from purely model-centric development to include agentic system\ndesign as an essential complementary paradigm. While deep learning has\nsignificantly advanced capabilities for specific image processing tasks,\ncurrent approaches face critical limitations in generalization, adaptability,\nand real-world problem-solving flexibility. We propose that developing\nintelligent agentic systems, capable of dynamically selecting, combining, and\noptimizing existing image processing tools, represents the next evolutionary\nstep for the field. Such systems would emulate human experts' ability to\nstrategically orchestrate different tools to solve complex problems, overcoming\nthe brittleness of monolithic models. The paper analyzes key limitations of\nmodel-centric paradigms, establishes design principles for agentic image\nprocessing systems, and outlines different capability levels for such agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.16007v1",
    "published": "2025-05-21T20:47:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16006v2",
    "title": "The Peekaboo galaxy: new SALT spectroscopy and implications of archive HST data",
    "authors": [
      "Alexei Kniazev",
      "Simon Pustilnik"
    ],
    "abstract": "The dwarf galaxy Peekaboo was recently identified as a Local Volume (LV)\ngas-rich and 'eXtremely Metal-Poor' (XMP) dIrr. Its gas metallicity is\nZ~Zsun/50, with +/-1$\\sigma$ uncertainty range of [Zsun/72-Zsun/35]). Its the\n\"Tip of Red Giant Stars\" (TRGB)-based distance is of 6.8$\\pm$0.7 Mpc. HST data\nfor its individual stars reveal that its older RGB stars comprise a smaller\npart, while the majority of visible stars have ages of less than one to a few\nGyr. Thus, Peekaboo dwarf can be considered as the nearest record-low-Z dwarf.\nAs such, the galaxy deserves a deeper multi-method study, including properties\nof both, young massive stars and the fainter older population, and its ionised\ngas and the dominant baryonic component of HI gas. We use the direct (Te)\nmethod for the east HII region, in which the [OIII]4363A line is well detected,\nto estimate its parameter 12+log(O/H). Since in the west HII region the line\n[OIII]4363A is not detected, its O/H is estimated via the empirical\n\"strong-line\" method. The resulting value of O/H is very close to that in the\neast HII region. The new spectroscopy of Peekaboo dwarf allows us to improve\nsubstantially the accuracy of its direct O/H estimate, which appears of\n12+log(O/H) = 6.99$\\pm$0.06. The new data reveal that emission lines in the E\nregion consist of two components with the velocity difference of ~65 km/s. The\nfainter, approaching, component can be related to a fast-moving WR star thrown\nfrom a cluster or a binary system. Using the HST $V$ magnitudes and colour\n$V-I$, we identify tentative O-type and very hot candidate WO stars, which are\nlikely the ionising stars of the studied HII regions. With the new optical\nspectra, the Peekaboo galaxy is confirmed as the lowest-metallicity dwarf in\nthe Local Volume and the valuable object for indeep multi-method studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.16006v2",
    "published": "2025-05-21T20:47:01+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16005v1",
    "title": "Distance estimation of the high-velocity cloud Anti-Center Shell",
    "authors": [
      "Yu-Ting Wang",
      "Chao Liu",
      "Zhi-Yu Zhang"
    ],
    "abstract": "High-velocity clouds (HVCs) are interstellar gas clouds whose velocities are\nincompatible with Galactic rotation. Since the first discovery of HVCs in 1963,\ntheir origins have been debated for decades but are still not settled down,\nbecause of the lack of vital parameters of HVCs, e.g., the distance. In this\nwork, we determined the distance to the high-velocity cloud, namely the\nAnti-Center Shell (ACS). We trace the ACS with extinction derived from K-giant\nstars with known distances and with the diffuse interstellar band (DIB) feature\nat 5780 $\\text{{\\AA}}$ fitted on spectra of O- and B-type stars with distance.\nAs a result, we provide a lower limit distance of ACS as $\\sim$8 kpc, which\nextends the lower limit outward by approximately 4 kpc compared to previous\nwork. A byproduct of the DIB method is that we detected a bar-shaped structure\nwith a unusually high positive line-of-sight velocity. Its shape extends along\nthe (l,b)=(155,-5)$^{\\circ}$ sight-line and shows a slightly increasing trend\nin equivalent width and velocity as the distance increases.",
    "pdf_url": "http://arxiv.org/pdf/2505.16005v1",
    "published": "2025-05-21T20:42:21+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.16004v1",
    "title": "Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations",
    "authors": [
      "Aaron J. Li",
      "Suraj Srinivas",
      "Usha Bhalla",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Sparse autoencoders (SAEs) are commonly used to interpret the internal\nactivations of large language models (LLMs) by mapping them to\nhuman-interpretable concept representations. While existing evaluations of SAEs\nfocus on metrics such as the reconstruction-sparsity tradeoff, human\n(auto-)interpretability, and feature disentanglement, they overlook a critical\naspect: the robustness of concept representations to input perturbations. We\nargue that robustness must be a fundamental consideration for concept\nrepresentations, reflecting the fidelity of concept labeling. To this end, we\nformulate robustness quantification as input-space optimization problems and\ndevelop a comprehensive evaluation framework featuring realistic scenarios in\nwhich adversarial perturbations are crafted to manipulate SAE representations.\nEmpirically, we find that tiny adversarial input perturbations can effectively\nmanipulate concept-based interpretations in most scenarios without notably\naffecting the outputs of the base LLMs themselves. Overall, our results suggest\nthat SAE concept representations are fragile and may be ill-suited for\napplications in model monitoring and oversight.",
    "pdf_url": "http://arxiv.org/pdf/2505.16004v1",
    "published": "2025-05-21T20:42:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.16003v1",
    "title": "SLMEval: Entropy-Based Calibration for Human-Aligned Evaluation of Large Language Models",
    "authors": [
      "Roland Daynauth",
      "Christopher Clarke",
      "Krisztian Flautner",
      "Lingjia Tang",
      "Jason Mars"
    ],
    "abstract": "The LLM-as-a-Judge paradigm offers a scalable, reference-free approach for\nevaluating language models. Although several calibration techniques have been\nproposed to better align these evaluators with human judgment, prior studies\nfocus primarily on narrow, well-structured benchmarks. As a result, it remains\nunclear whether such calibrations generalize to real-world, open-ended tasks.\n  In this work, we show that SOTA calibrated evaluators often fail in these\nsettings, exhibiting weak or even negative correlation with human judgments. To\naddress this, we propose SLMEval, a novel and efficient calibration method\nbased on entropy maximization over a small amount of human preference data. By\nestimating a latent distribution over model quality and reweighting evaluator\nscores accordingly, SLMEval achieves strong correlation with human evaluations\nacross two real-world production use cases and the public benchmark. For\nexample, on one such task, SLMEval achieves a Spearman correlation of 0.57 with\nhuman judgments, while G-Eval yields a negative correlation. In addition,\nSLMEval reduces evaluation costs by 5-30x compared to GPT-4-based calibrated\nevaluators such as G-eval.",
    "pdf_url": "http://arxiv.org/pdf/2505.16003v1",
    "published": "2025-05-21T20:40:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16002v1",
    "title": "Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions",
    "authors": [
      "Sasha Boguraev",
      "Christopher Potts",
      "Kyle Mahowald"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful sources of evidence for\nlinguists seeking to develop theories of syntax. In this paper, we argue that\ncausal interpretability methods, applied to LLMs, can greatly enhance the value\nof such evidence by helping us characterize the abstract mechanisms that LLMs\nlearn to use. Our empirical focus is a set of English filler-gap dependency\nconstructions (e.g., questions, relative clauses). Linguistic theories largely\nagree that these constructions share many properties. Using experiments based\nin Distributed Interchange Interventions, we show that LLMs converge on similar\nabstract analyses of these constructions. These analyses also reveal previously\noverlooked factors -- relating to frequency, filler type, and surrounding\ncontext -- that could motivate changes to standard linguistic theory. Overall,\nthese results suggest that mechanistic, internal analyses of LLMs can push\nlinguistic theory forward.",
    "pdf_url": "http://arxiv.org/pdf/2505.16002v1",
    "published": "2025-05-21T20:37:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.16001v1",
    "title": "Image-to-Image Translation with Diffusion Transformers and CLIP-Based Image Conditioning",
    "authors": [
      "Qiang Zhu",
      "Kuan Lu",
      "Menghao Huo",
      "Yuxiao Li"
    ],
    "abstract": "Image-to-image translation aims to learn a mapping between a source and a\ntarget domain, enabling tasks such as style transfer, appearance\ntransformation, and domain adaptation. In this work, we explore a\ndiffusion-based framework for image-to-image translation by adapting Diffusion\nTransformers (DiT), which combine the denoising capabilities of diffusion\nmodels with the global modeling power of transformers. To guide the translation\nprocess, we condition the model on image embeddings extracted from a\npre-trained CLIP encoder, allowing for fine-grained and structurally consistent\ntranslations without relying on text or class labels. We incorporate both a\nCLIP similarity loss to enforce semantic consistency and an LPIPS perceptual\nloss to enhance visual fidelity during training. We validate our approach on\ntwo benchmark datasets: face2comics, which translates real human faces to\ncomic-style illustrations, and edges2shoes, which translates edge maps to\nrealistic shoe images. Experimental results demonstrate that DiT, combined with\nCLIP-based conditioning and perceptual similarity objectives, achieves\nhigh-quality, semantically faithful translations, offering a promising\nalternative to GAN-based models for paired image-to-image translation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.16001v1",
    "published": "2025-05-21T20:37:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.16000v2",
    "title": "Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model",
    "authors": [
      "Mehrdad Ghassabi",
      "Pedram Rostami",
      "Hamidreza Baradaran Kashani",
      "Amirhossein Poursina",
      "Zahra Kazemi",
      "Milad Tavakoli"
    ],
    "abstract": "The rapid advancement of language models has demonstrated the potential of\nartificial intelligence in the healthcare industry. However, small language\nmodels struggle with specialized domains in low-resource languages like\nPersian. While numerous medical-domain websites exist in Persian, no curated\ndataset or corpus has been available making ours the first of its kind. This\nstudy explores the enhancement of medical knowledge in a small language model\nby leveraging accessible online data, including a crawled corpus from medical\nmagazines and a dataset of real doctor-patient QA pairs. We fine-tuned a\nbaseline model using our curated data to improve its medical knowledge.\nBenchmark evaluations demonstrate that the fine-tuned model achieves improved\naccuracy in medical question answering and provides better responses compared\nto its baseline. This work highlights the potential of leveraging open-access\nonline data to enrich small language models in medical fields, providing a\nnovel solution for Persian medical AI applications suitable for\nresource-constrained environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.16000v2",
    "published": "2025-05-21T20:30:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15999v1",
    "title": "Application of Quaternions to Obtain Analytic Solutions to Systems of Polarization Components",
    "authors": [
      "Michael G. Taylor"
    ],
    "abstract": "The usual way to describe mathematically a beam of coherent light passing\nthrough a system of waveplates is via the Jones vector and Jones matrix. This\npaper will show that a quaternion can be used to represent both the optical\nsignal and the waveplate component it passes through, replacing the Jones\nvector and the Jones matrix. The quaternion description is easier to manipulate\nthan the matrix-vector description; for example it can be inverted. As well as\nthe Jones vector, the state of polarization (SOP) of an optical signal is often\ndescribed as a three-dimensional vector on the Poincar\\'e sphere, or as a\npolarization ellipse, and it will be shown how these three forms are closely\nrelated to the quaternion representation. Similarly, the action of a waveplate\nmay be represented as a rotation about an axis on the Poincar\\'e sphere, and\nthat rotation is shown to have a logarithm-exponential relationship to the\nwaveplate's quaternion. The paper presents rules to decide if two optical\nsignals are aligned or orthogonal in phase or in polarization from their\nquaternions, and presents the quaternion operations to change the phase or\nchange the SOP. Light passing through a system of waveplates is written as a\nproduct of quaternions, and it can be hard to simplify or manipulate that\nexpression because quaternion multiplication does not commute. The paper brings\ntogether several mathematical tools that allow such a quaternion product to be\nrearranged, including the new idea of partial conjugation. Finally, a worked\nexample is included of the quaternion mathematics applied to a waveplate\nproblem that has not been solved before. It is shown that an endless optical\nphase shifter can be built using three rotatable waveplates, and equations for\nthe angles of rotation are derived to produce the desired phase shift for given\ninput and output SOPs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15999v1",
    "published": "2025-05-21T20:29:50+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15998v2",
    "title": "Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics",
    "authors": [
      "Thomas Michel",
      "Marko Cvjetko",
      "Gautier Hamon",
      "Pierre-Yves Oudeyer",
      "Cl√©ment Moulin-Frier"
    ],
    "abstract": "We present a method for the automated discovery of system-level dynamics in\nFlow-Lenia--a continuous cellular automaton (CA) with mass conservation and\nparameter localization-using a curiosity--driven AI scientist. This method aims\nto uncover processes leading to self-organization of evolutionary and\necosystemic dynamics in CAs. We build on previous work which uses diversity\nsearch algorithms in Lenia to find self-organized individual patterns, and\nextend it to large environments that support distinct interacting patterns. We\nadapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive\nexploration of diverse Flow-Lenia environments using simulation-wide metrics,\nsuch as evolutionary activity, compression-based complexity, and multi-scale\nentropy. We test our method in two experiments, showcasing its ability to\nilluminate significantly more diverse dynamics compared to random search. We\nshow qualitative results illustrating how ecosystemic simulations enable\nself-organization of complex collective behaviors not captured by previous\nindividual pattern search and analysis. We complement automated discovery with\nan interactive exploration tool, creating an effective human-AI collaborative\nworkflow for scientific investigation. Though demonstrated specifically with\nFlow-Lenia, this methodology provides a framework potentially applicable to\nother parameterizable complex systems where understanding emergent collective\nproperties is of interest.",
    "pdf_url": "http://arxiv.org/pdf/2505.15998v2",
    "published": "2025-05-21T20:28:58+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15997v1",
    "title": "Domain Adaptive Skin Lesion Classification via Conformal Ensemble of Vision Transformers",
    "authors": [
      "Mehran Zoravar",
      "Shadi Alijani",
      "Homayoun Najjaran"
    ],
    "abstract": "Exploring the trustworthiness of deep learning models is crucial, especially\nin critical domains such as medical imaging decision support systems. Conformal\nprediction has emerged as a rigorous means of providing deep learning models\nwith reliable uncertainty estimates and safety guarantees. However, conformal\nprediction results face challenges due to the backbone model's struggles in\ndomain-shifted scenarios, such as variations in different sources. To aim this\nchallenge, this paper proposes a novel framework termed Conformal Ensemble of\nVision Transformers (CE-ViTs) designed to enhance image classification\nperformance by prioritizing domain adaptation and model robustness, while\naccounting for uncertainty. The proposed method leverages an ensemble of vision\ntransformer models in the backbone, trained on diverse datasets including\nHAM10000, Dermofit, and Skin Cancer ISIC datasets. This ensemble learning\napproach, calibrated through the combined mentioned datasets, aims to enhance\ndomain adaptation through conformal learning. Experimental results underscore\nthat the framework achieves a high coverage rate of 90.38\\%, representing an\nimprovement of 9.95\\% compared to the HAM10000 model. This indicates a strong\nlikelihood that the prediction set includes the true label compared to singular\nmodels. Ensemble learning in CE-ViTs significantly improves conformal\nprediction performance, increasing the average prediction set size for\nchallenging misclassified samples from 1.86 to 3.075.",
    "pdf_url": "http://arxiv.org/pdf/2505.15997v1",
    "published": "2025-05-21T20:28:43+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15996v1",
    "title": "A broken-FEEC framework for structure-preserving discretizations of polar domains with tensor-product splines",
    "authors": [
      "Yaman G√º√ßl√º",
      "Francesco Patrizi",
      "Martin Campos Pinto"
    ],
    "abstract": "We propose a novel projection-based approach to derive structure-preserving\nFinite Element Exterior Calculus (FEEC) discretizations using standard\ntensor-product splines on domains with a polar singularity. This approach\nfollows the main lines of broken-FEEC schemes which define stable and\nstructure-preserving operators in non-conforming discretizations of the de Rham\nsequence. Here, we devise a polar broken-FEEC framework that enables the use of\nstandard tensor-product spline spaces while ensuring stability and smoothness\nfor the solutions, as well as the preservation of the de Rham structure: A\nbenefit of this approach is the ability to reuse codes that implement standard\nsplines on smooth parametric domains, and efficient solvers such as\nKronecker-product spline interpolation. Our construction is based on two\npillars: the first one is an explicit characterization of smooth polar spline\nspaces within the tensor-product splines ones, which are either discontinuous\nor non square-integrable as a result of the singular polar pushforward\noperators. The second pillar consists of local, explicit and matrix-free\nconforming projection operators that map general tensor-product splines onto\nsmooth polar splines, and that commute with the differential operators of the\nde Rham sequence.",
    "pdf_url": "http://arxiv.org/pdf/2505.15996v1",
    "published": "2025-05-21T20:25:41+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.comp-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15995v1",
    "title": "NIRCam yells at cloud: JWST MIRI imaging can directly detect exoplanets of the same temperature, mass, age, and orbital separation as Saturn and Jupiter",
    "authors": [
      "Rachel Bowens-Rubin",
      "James Mang",
      "Mary Anne Limbach",
      "Aarynn L. Carter",
      "Kevin B. Stevenson",
      "Kevin Wagner",
      "Giovanni Strampelli",
      "Caroline V. Morley",
      "Grant Kennedy",
      "Elisabeth Matthews",
      "Andrew Vanderburg",
      "Ma√Øssa Salama"
    ],
    "abstract": "NIRCam and MIRI coronagraphy have successfully demonstrated the ability to\ndirectly image young sub-Jupiter mass and mature gas-giant exoplanets. However,\nthese modes struggle to reach the sensitivities needed to find the population\nof cold giant planets that are similar to our own Solar System's giant planets\n($T_{\\rm eff} = 60 - 125$ K; $a=5 - 30$ AU). For the first time, we explore the\nhigh-contrast imaging capabilities of MIRI imaging rather than coronagraphy.\nUsing data from the JWST GO 6122: Cool Kids on the Block program which targets\nnearby ($<6$ pc) M-dwarfs with NIRCam coronagraphy and MIRI imaging, we\ndemonstrate that 21$\\mu$m MIRI imaging can detect planets with the same\ntemperature, mass, age, and orbital separations as Saturn and Jupiter. For\nsystems within 3pc, 21$\\mu$m MIRI imaging reaches the sensitivity needed to\ndetect planets colder than Saturn ($<95$ K). NIRCam coronagraphy can achieve\nsimilar results only in the unlikely case that a cold giant planet is\ncloud-free. Motivated by these compelling findings, we extend our analysis to\nevaluate the measured performance of MIRI F2100W imaging versus NIRCam F444W\ncoronagraphy to 70 pc and conclude that MIRI imaging offers the advantage for\nsystems within 20pc. Microlensing surveys predict an occurrence rate as high as\n1 - 2 low-mass giant exoplanets per star, suggesting that JWST MIRI imaging\nsurveys of nearby systems may be poised to uncover a substantial population.\nThis breakthrough enables a path towards the first direct characterization of\ncold giant exoplanets that are analogous to the solar system giant planets.",
    "pdf_url": "http://arxiv.org/pdf/2505.15995v1",
    "published": "2025-05-21T20:25:21+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15994v1",
    "title": "Fourier inequalities and sign uncertainty",
    "authors": [
      "Roni Edwin"
    ],
    "abstract": "Motivated by inequalities in Fourier analysis, we present an improvement on\nthe lower bound for the sign uncertainty principle of Bourgain, Clozel and\nKahane in high dimensions. Additionally, our methods can be used to match the\nexisting Torquato-Stillinger lower bounds for the Cohn-Elkies linear program\nfor sphere packing.",
    "pdf_url": "http://arxiv.org/pdf/2505.15994v1",
    "published": "2025-05-21T20:24:18+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15993v1",
    "title": "Explaining Puzzle Solutions in Natural Language: An Exploratory Study on 6x6 Sudoku",
    "authors": [
      "Anirudh Maiya",
      "Razan Alghamdi",
      "Maria Leonor Pacheco",
      "Ashutosh Trivedi",
      "Fabio Somenzi"
    ],
    "abstract": "The success of Large Language Models (LLMs) in human-AI collaborative\ndecision-making hinges on their ability to provide trustworthy, gradual, and\ntailored explanations. Solving complex puzzles, such as Sudoku, offers a\ncanonical example of this collaboration, where clear and customized\nexplanations often hold greater importance than the final solution. In this\nstudy, we evaluate the performance of five LLMs in solving and explaining\n\\sixsix{} Sudoku puzzles. While one LLM demonstrates limited success in solving\npuzzles, none can explain the solution process in a manner that reflects\nstrategic reasoning or intuitive problem-solving. These findings underscore\nsignificant challenges that must be addressed before LLMs can become effective\npartners in human-AI collaborative decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2505.15993v1",
    "published": "2025-05-21T20:22:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15992v2",
    "title": "On the Complexity of Finding Approximate LCS of Multiple Strings",
    "authors": [
      "Hamed Hasibi",
      "Neerja Mhaskar",
      "W. F. Smyth"
    ],
    "abstract": "Finding an Approximate Longest Common Substring (ALCS) within a given set\n$S=\\{s_1,s_2,\\ldots,s_m\\}$ of $m \\ge 2$ strings is a problem of particular\nimportance in computational biology (e.g., identifying related mutations across\nmultiple genetic sequences). In this paper, we study several ALCS problems\nthat, for given integers $k$ and $t \\le m$, require finding a longest string\n$u$ -- or a longest substring $u$ of any string in $S$ -- that lies within\ndistance $k$ of at least one substring in $t$ distinct strings of $S$. Although\ntwo of these problems, denoted $k$-LCS and \\textit{k-t} LCS, are NP-hard,\nnevertheless restricted variations of them under Hamming and edit distance can\nbe solved in $O(N^2)$ and $O(k\\ell N^2)$ time, respectively, where $\\ell$ is\nthe length of each string and $N=m\\ell$. Further, we show that using the\n$k$-errata tree data structure, a restricted variation of the ALCS problem\nunder both Hamming and edit distance can be computed in $O(mN\\log^k \\ell)$\ntime. We also establish an $O(N^2)$ conditional lower bound for a variation of\nthe ALCS problem under the Strong Exponential Time Hypothesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.15992v2",
    "published": "2025-05-21T20:20:16+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15991v2",
    "title": "Integral equation formulation of run-and-tumble particles in a harmonic trap: the special status of a system in two-dimensions",
    "authors": [
      "Derek Frydel"
    ],
    "abstract": "Statistical-mechanical models often exhibit a dimension-dependent\nsolvability: in 1D, exact solutions are straightforward; in 2D, solutions are\nexact but require nontrivial derivations; and in 3D, closed-form solutions are\ntypically unavailable. This logic is repeated for a simple model of\nself-propelled particles, run-and-tumble particles (RTP) in a harmonic trap,\nconfirming the claim that the system in 2D enjoys special status. This study\nrevisits the RTP-harmonic-trap model using an integral-equation formulation\nrecently proposed in Ref. \\cite{POF-Frydel-2024}. The formulation is based on\nreinterpreting RTP motion as a jump process. The key quantity of the\nformulation is a transition operator $G(x,x')$, representing the probability\ndistribution of the jumps of an auxiliary system. The stationary distribution\nis then obtained from the integral equation $\\rho(x) = \\int dx' \\, \\rho(x')\nG(x,x')$. In 2D, we find that $G(x,x')$ is reversible. This implies the\n$\\rho(x)$ satisfied the detailed balance condition, $\\rho(x') G(x,x') = \\rho(x)\nG(x',x)$, from which $\\rho(x)$ can be obtained without need of an integral\nequation. The reversibility of $G(x,x')$ does not mean that RTP particles are\nin equilibrium. It only means that our specific interpretation of the RTP\nmotion leads to an auxiliary system that is in equilibrium. The reversibility\nof the system in 2D is lost if the probability distribution of the waiting\ntimes (the times that determine the duration on the \"run\" stage of the RTP\nmotion) deviates from an exponential distribution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15991v2",
    "published": "2025-05-21T20:19:26+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.15990v1",
    "title": "Free five-valued Nelson Algebras",
    "authors": [
      "Juan Manuel Cornejo",
      "Andr√©s Gallardo",
      "Luiz F. Monteiro",
      "Ignacio Viglizzo"
    ],
    "abstract": "Five-valued Nelson algebras are those satisfying the condition: $((x\\to z)\\to\ny)\\to(((y \\to x)\\to y)\\to y)=1$. We give alternative equations defining these\nalgebras, and determine the structure and number of elements of the free\nfive-valued Nelson algebra with a finite number of free generators.",
    "pdf_url": "http://arxiv.org/pdf/2505.15990v1",
    "published": "2025-05-21T20:12:58+00:00",
    "categories": [
      "math.LO",
      "03G25"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15989v1",
    "title": "AI-Assisted NLOS Sensing for RIS-Based Indoor Localization in Smart Factories",
    "authors": [
      "Taofeek A. O. Yusuf",
      "Sigurd S. Petersen",
      "Puchu Li",
      "Jian Ren",
      "Placido Mursia",
      "Vincenzo Sciancalepore",
      "Xavier Costa P√©rez",
      "Gilberto Berardinelli",
      "Ming Shen"
    ],
    "abstract": "In the era of Industry 4.0, precise indoor localization is vital for\nautomation and efficiency in smart factories. Reconfigurable Intelligent\nSurfaces (RIS) are emerging as key enablers in 6G networks for joint sensing\nand communication. However, RIS faces significant challenges in\nNon-Line-of-Sight (NLOS) and multipath propagation, particularly in\nlocalization scenarios, where detecting NLOS conditions is crucial for ensuring\nnot only reliable results and increased connectivity but also the safety of\nsmart factory personnel. This study introduces an AI-assisted framework\nemploying a Convolutional Neural Network (CNN) customized for accurate\nLine-of-Sight (LOS) and Non-Line-of-Sight (NLOS) classification to enhance\nRIS-based localization using measured, synthetic, mixed-measured, and\nmixed-synthetic experimental data, that is, original, augmented, slightly\nnoisy, and highly noisy data, respectively. Validated through such data from\nthree different environments, the proposed customized-CNN (cCNN) model achieves\n{95.0\\%-99.0\\%} accuracy, outperforming standard pre-trained models like Visual\nGeometry Group 16 (VGG-16) with an accuracy of {85.5\\%-88.0\\%}. By addressing\nRIS limitations in NLOS scenarios, this framework offers scalable and\nhigh-precision localization solutions for 6G-enabled smart factories.",
    "pdf_url": "http://arxiv.org/pdf/2505.15989v1",
    "published": "2025-05-21T20:12:30+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15988v1",
    "title": "An Ecosystem of Services for FAIR Computational Workflows",
    "authors": [
      "Sean R. Wilkinson",
      "Johan Gustafsson",
      "Finn Bacall",
      "Khalid Belhajjame",
      "Salvador Capella",
      "Jose Maria Fernandez Gonzalez",
      "Jacob Fosso Tande",
      "Luiz Gadelha",
      "Daniel Garijo",
      "Patricia Grubel",
      "Bjorn Gr√ºning",
      "Farah Zaib Khan",
      "Sehrish Kanwal",
      "Simone Leo",
      "Stuart Owen",
      "Luca Pireddu",
      "Line Pouchard",
      "Laura Rodr√≠guez-Navas",
      "Beatriz Serrano-Solano",
      "Stian Soiland-Reyes",
      "Baiba Vilne",
      "Alan Williams",
      "Merridee Ann Wouters",
      "Frederik Coppens",
      "Carole Goble"
    ],
    "abstract": "Computational workflows, regardless of their portability or maturity,\nrepresent major investments of both effort and expertise. They are first class,\npublishable research objects in their own right. They are key to sharing\nmethodological know-how for reuse, reproducibility, and transparency.\nConsequently, the application of the FAIR principles to workflows is inevitable\nto enable them to be Findable, Accessible, Interoperable, and Reusable. Making\nworkflows FAIR would reduce duplication of effort, assist in the reuse of best\npractice approaches and community-supported standards, and ensure that\nworkflows as digital objects can support reproducible and robust science. FAIR\nworkflows also encourage interdisciplinary collaboration, enabling workflows\ndeveloped in one field to be repurposed and adapted for use in other research\ndomains. FAIR workflows draw from both FAIR data and software principles.\nWorkflows propose explicit method abstractions and tight bindings to data,\nhence making many of the data principles apply. Meanwhile, as executable\npipelines with a strong emphasis on code composition and data flow between\nsteps, the software principles apply, too. As workflows are chiefly concerned\nwith the processing and creation of data, they also have an important role to\nplay in ensuring and supporting data FAIRification.\n  The FAIR Principles for software and data mandate the use of persistent\nidentifiers (PID) and machine actionable metadata associated with workflows to\nenable findability, reusability, interoperability and reusability. To implement\nthe principles requires a PID and metadata framework with appropriate\nprogrammatic protocols, an accompanying ecosystem of services, tools,\nguidelines, policies, and best practices, as well the buy-in of existing\nworkflow systems such that they adapt in order to adopt. The European EOSC-Life\nWorkflow Collaboratory is an example of such a ...",
    "pdf_url": "http://arxiv.org/pdf/2505.15988v1",
    "published": "2025-05-21T20:11:58+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15987v2",
    "title": "Towards Identifiability of Interventional Stochastic Differential Equations",
    "authors": [
      "Aaron Zweig",
      "Zaikang Lin",
      "Elham Azizi",
      "David Knowles"
    ],
    "abstract": "We study identifiability of stochastic differential equation (SDE) models\nunder multiple interventions. Our results give the first provable bounds for\nunique recovery of SDE parameters given samples from their stationary\ndistributions. We give tight bounds on the number of necessary interventions\nfor linear SDEs, and upper bounds for nonlinear SDEs in the small noise regime.\nWe experimentally validate the recovery of true parameters in synthetic data,\nand motivated by our theoretical results, demonstrate the advantage of\nparameterizations with learnable activation functions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15987v2",
    "published": "2025-05-21T20:10:54+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15986v1",
    "title": "Generalized Rosenfeld-Tarazona scaling and high-density specific heat of simple liquids",
    "authors": [
      "S. Khrapak",
      "A. Khrapak"
    ],
    "abstract": "The original Rosenfeld-Tarazona (RT) scaling of the excess energy in simple\ndense fluids predicts a $\\propto T^{3/5}$ thermal correction to the fluid\nMadelung energy. This implies that the excess isochoric heat capacity scales as\n$C_{\\rm v}^{\\rm ex}\\propto T^{-2/5}$. Careful examination performed in this\npaper demonstrates that the exponent $-2/5$ is not always optimal. For\ninstance, in the Lennard-Jones fluid in some vicinity of the triple point, the\nexponent $-1/3$ turns out to be more appropriate. The analysis of the specific\nheat data in neon, argon, krypton, xenon, and liquid mercury reveals that no\nsingle value of the exponent exists, describing all the data simultaneously.\nTherefore we propose a generalized RT scaling in the form $C_{\\rm v}^{\\rm\nex}\\propto T^{-\\alpha}$, where $\\alpha$ is a density- and material-dependent\nadjustable parameter. The question concerning which material properties and\nparameters affect the exponent $\\alpha$ and whether it can be predicted from\ngeneral physical arguments requires further investigation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15986v1",
    "published": "2025-05-21T20:08:41+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2506.11048v1",
    "title": "I Can't Believe It's Not Real: CV-MuSeNet: Complex-Valued Multi-Signal Segmentation",
    "authors": [
      "Sangwon Shin",
      "Mehmet C. Vuran"
    ],
    "abstract": "The increasing congestion of the radio frequency spectrum presents challenges\nfor efficient spectrum utilization. Cognitive radio systems enable dynamic\nspectrum access with the aid of recent innovations in neural networks. However,\ntraditional real-valued neural networks (RVNNs) face difficulties in low\nsignal-to-noise ratio (SNR) environments, as they were not specifically\ndeveloped to capture essential wireless signal properties such as phase and\namplitude. This work presents CMuSeNet, a complex-valued multi-signal\nsegmentation network for wideband spectrum sensing, to address these\nlimitations. Extensive hyperparameter analysis shows that a naive conversion of\nexisting RVNNs into their complex-valued counterparts is ineffective. Built on\ncomplex-valued neural networks (CVNNs) with a residual architecture, CMuSeNet\nintroduces a complexvalued Fourier spectrum focal loss (CFL) and a complex\nplane intersection over union (CIoU) similarity metric to enhance training\nperformance. Extensive evaluations on synthetic, indoor overthe-air, and\nreal-world datasets show that CMuSeNet achieves an average accuracy of\n98.98%-99.90%, improving by up to 9.2 percentage points over its real-valued\ncounterpart and consistently outperforms state of the art. Strikingly, CMuSeNet\nachieves the accuracy level of its RVNN counterpart in just two epochs,\ncompared to the 27 epochs required for RVNN, while reducing training time by up\nto a 92.2% over the state of the art. The results highlight the effectiveness\nof complex-valued architectures in improving weak signal detection and training\nefficiency for spectrum sensing in challenging low-SNR environments. The\ndataset is available at: https://dx.doi.org/10.21227/hcc1-6p22",
    "pdf_url": "http://arxiv.org/pdf/2506.11048v1",
    "published": "2025-05-21T20:08:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15985v1",
    "title": "Fast-wave slow-wave spectral deferred correction methods applied to the compressible Euler equations",
    "authors": [
      "Alex Brown",
      "Joscha Fregin",
      "Thomas Bendall",
      "Thomas Melvin",
      "Daniel Ruprecht",
      "Jemma Shipton"
    ],
    "abstract": "This paper investigates the application of a fast-wave slow-wave spectral\ndeferred correction time-stepping method (FWSW-SDC) to the compressible Euler\nequations. The resulting model achieves arbitrary order accuracy in time,\ndemonstrating robust performance in standard benchmark idealised test cases for\ndynamical cores used for numerical weather prediction. The model uses a\ncompatible finite element spatial discretisation, achieving good linear wave\ndispersion properties without spurious computational modes. A convergence test\nconfirms the model's high temporal accuracy. Arbitrarily high spatial-temporal\nconvergence is demonstrated using a gravity wave test case. The model is\nfurther extended to include the parametrisation of a simple physics process by\nadding two phases of moisture and its validity is demonstrated for a rising\nthermal problem. Finally, a baroclinic wave in simulated in a Cartesian domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.15985v1",
    "published": "2025-05-21T20:07:04+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.ao-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15984v1",
    "title": "Diffusion Probabilistic Generative Models for Accelerated, in-NICU Permanent Magnet Neonatal MRI",
    "authors": [
      "Yamin Arefeen",
      "Brett Levac",
      "Bhairav Patel",
      "Chang Ho",
      "Jonathan I. Tamir"
    ],
    "abstract": "Purpose: Magnetic Resonance Imaging (MRI) enables non-invasive assessment of\nbrain abnormalities during early life development. Permanent magnet scanners\noperating in the neonatal intensive care unit (NICU) facilitate MRI of sick\ninfants, but have long scan times due to lower signal-to-noise ratios (SNR) and\nlimited receive coils. This work accelerates in-NICU MRI with diffusion\nprobabilistic generative models by developing a training pipeline accounting\nfor these challenges.\n  Methods: We establish a novel training dataset of clinical, 1 Tesla neonatal\nMR images in collaboration with Aspect Imaging and Sha'are Zedek Medical\nCenter. We propose a pipeline to handle the low quantity and SNR of our\nreal-world dataset (1) modifying existing network architectures to support\nvarying resolutions; (2) training a single model on all data with learned class\nembedding vectors; (3) applying self-supervised denoising before training; and\n(4) reconstructing by averaging posterior samples. Retrospective under-sampling\nexperiments, accounting for signal decay, evaluated each item of our proposed\nmethodology. A clinical reader study with practicing pediatric\nneuroradiologists evaluated our proposed images reconstructed from 1.5x\nunder-sampled data.\n  Results: Combining all data, denoising pre-training, and averaging posterior\nsamples yields quantitative improvements in reconstruction. The generative\nmodel decouples the learned prior from the measurement model and functions at\ntwo acceleration rates without re-training. The reader study suggests that\nproposed images reconstructed from approximately 1.5x under-sampled data are\nadequate for clinical use.\n  Conclusion: Diffusion probabilistic generative models applied with the\nproposed pipeline to handle challenging real-world datasets could reduce scan\ntime of in-NICU neonatal MRI.",
    "pdf_url": "http://arxiv.org/pdf/2505.15984v1",
    "published": "2025-05-21T20:05:45+00:00",
    "categories": [
      "eess.IV",
      "cs.LG",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15983v1",
    "title": "MeerKAT Discovery of an Infalling Cold Gas Tail onto the Nearby Barred Spiral Galaxy, NGC 5643",
    "authors": [
      "K. C. Santana",
      "F. M. Maccagni",
      "R. Deane",
      "J. Healy"
    ],
    "abstract": "The detailed study of gas flows in local Active Galactic Nuclei (AGN) is\nessential for understanding the regulation of star formation and black hole\ngrowth, which are fundamental to galaxy evolution. One such AGN case study is\nNGC 5643, a nearby ($D_{L}\\sim17.3$ Mpc) star-forming, late-type, Seyfert\ngalaxy, where inflows and outflows have been observed in detail. NGC 5643 has\nbeen studied at multiple wavelengths, however, a key missing component is\nsensitive, high-resolution neutral hydrogen ($\\mathrm{H\\,I}$) observations. We\npresent 21-cm observations of NGC 5643 with MeerKAT, revealing six\nlow-$\\mathrm{H\\,I}$ mass ($M_{\\text{$\\mathrm{H\\,I}$}}\\sim10^{7} M_\\odot$)\nsources surrounding NGC 5643 and $\\mathrm{H\\,I}$ in IC 4444, $\\sim230$ kpc\nnorth of NGC 5643. In NGC 5643, $\\mathrm{H\\,I}$ extends beyond the stellar disk\nwith several morphological and kinematical asymmetries. North of the disk is an\nextended 30 kpc tail with counter-rotating velocities. This is $\\mathrm{H\\,I}$\ngas accreting onto the regularly rotating disk of NGC 5643 from the\nenvironment. Within the spiral arms of the disk, we identify extraplanar gas\ncomponents, tracing galactic fountains driven by star formation regions. These\nfountains have a molecular gas component and show an increased\n$\\mathrm{H}_2$/$\\mathrm{H\\,I}$ ratio. In the circum-nuclear region, we observe\nspatially unresolved $\\mathrm{H\\,I}$ absorption that is slightly blue-shifted\n($\\sim72$ \\kms) with an $\\mathrm{H\\,I}$ emission counterpart at redshifted\nvelocities. These MeerKAT observations provide a complete census of the\n$\\mathrm{H\\,I}$ in and around this nearby Seyfert galaxy, providing missing\ninformation on the cold gas flows fuelling the star formation and nuclear\nactivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15983v1",
    "published": "2025-05-21T20:03:30+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15982v1",
    "title": "Using covariance of node states to design early warning signals for network dynamics",
    "authors": [
      "Shilong Yu",
      "Neil G. MacLaren",
      "Naoki Masuda"
    ],
    "abstract": "Real-life systems often experience regime shifts. An early warning signal\n(EWS) is a quantity that attempts to anticipate such a regime shift. Because\ncomplex systems of practical interest showing regime shifts are often dynamics\non networks, a research interest is to design EWSs for networks, including\ndetermining sentinel nodes that are useful for constructing high-quality EWSs.\nPrevious work has shown that the sample variance is a viable EWS including in\nthe case of networks. We explore the use of the sample covariance of two nodes,\nor sentinel node pairs, for improving EWSs for networks. We perform analytical\ncalculations in four-node networks and numerical simulations in larger networks\nto find that the sample covariance and its combination over node pairs is\ninferior to the sample variance and its combination over nodes; the latter are\npreviously proposed EWSs based on sentinel node selection. The present results\nsupport the predominant use of diagonal entries of the covariance matrix (i.e.,\nvariance) as opposed to off-diagonal entries in EWS construction.",
    "pdf_url": "http://arxiv.org/pdf/2505.15982v1",
    "published": "2025-05-21T20:03:27+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15981v1",
    "title": "Thermodynamic Analysis for Harmonic Oscillator with Position-Dependent Mass",
    "authors": [
      "Daniel Sabi Takou",
      "Assimiou Yarou Mora",
      "Gabriel Y. H. Avossevou"
    ],
    "abstract": "In this paper, we examine the thermodynamic behavior of a quantum harmonic\noscillator with a position-dependent mass (PDM), where spatial inhomogeneity is\nmodeled through a deformation parameter {\\alpha}. Based on the exact energy\nspectrum, we explore the resulting thermodynamic quantities and\nsuperstatistics. Our findings reveal that increasing {\\alpha} leads to a\ndecrease in entropy and specific heat, reflecting a confinement-induced\nreduction in the number of accessible states. The partition function and free\nenergy exhibit smooth behavior across all parameter regimes, indicating the\nabsence of critical phase transitions. This study underscores the influence of\nmass deformation on quantum thermal responses and demonstrates that, while the\noverall thermodynamic trends are consistent with those reported in the\nliterature, certain distinctive features emerge due to the specific form of the\ndeformation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15981v1",
    "published": "2025-05-21T20:00:44+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15980v1",
    "title": "Entanglement Entropy of a Scalar Field in Anti-de Sitter Space",
    "authors": [
      "Konstantinos Boutivas",
      "Dimitrios Katsinis",
      "Ioannis Papadimitriou",
      "Georgios Pastras",
      "Nikolaos Tetradis"
    ],
    "abstract": "We study the entanglement entropy of a free massive scalar field at its\nground state in (3+1)-dimensional AdS space in global coordinates. We consider\nspherical entangling surfaces centered at the origin of AdS. We determine the\nstructure of the UV-divergent terms in the entanglement entropy and compute the\nnumerical values of the respective coefficients. We confirm the connection\nbetween the coefficient of the logarithmic term and the conformal anomaly.",
    "pdf_url": "http://arxiv.org/pdf/2505.15980v1",
    "published": "2025-05-21T19:59:13+00:00",
    "categories": [
      "hep-th",
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15979v2",
    "title": "On a computation of the skein tree depth of knots and links",
    "authors": [
      "Michal Jablonowski"
    ],
    "abstract": "The maximum length of the shortest path from a leaf to the root of a skein\ntree for knots and links gives a measure of the complexity of computing link\npolynomials by the skein relation (the Jones polynomial, the Alexander-Conway\npolynomial, and more generally HOMFLY-PT polynomial). In this paper, we prove\nthe new upper bound on the skein tree depth of a link and give examples of\nlinks where the new bound is stronger than the known bound. We also give the\nnew lower bound. Moreover, we derive tables of knots and links with their skein\ntree depth that were up to now undetermined (for some of them, we give their\nrange of possible values).",
    "pdf_url": "http://arxiv.org/pdf/2505.15979v2",
    "published": "2025-05-21T19:58:40+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.03159v2",
    "title": "Bayes Error Rate Estimation in Difficult Situations",
    "authors": [
      "Lesley Wheat",
      "Martin v. Mohrenschildt",
      "Saeid Habibi"
    ],
    "abstract": "The Bayes Error Rate (BER) is the fundamental limit on the achievable\ngeneralizable classification accuracy of any machine learning model due to\ninherent uncertainty within the data. BER estimators offer insight into the\ndifficulty of any classification problem and set expectations for optimal\nclassification performance. In order to be useful, the estimators must also be\naccurate with a limited number of samples on multivariate problems with unknown\nclass distributions. To determine which estimators meet the minimum\nrequirements for \"usefulness\", an in-depth examination of their accuracy is\nconducted using Monte Carlo simulations with synthetic data in order to obtain\ntheir confidence bounds for binary classification. To examine the usability of\nthe estimators for real-world applications, new non-linear multi-modal test\nscenarios are introduced. In each scenario, 2500 Monte Carlo simulations per\nscenario are run over a wide range of BER values. In a comparison of k-Nearest\nNeighbor (kNN), Generalized Henze-Penrose (GHP) divergence and Kernel Density\nEstimation (KDE) techniques, results show that kNN is overwhelmingly the more\naccurate non-parametric estimator. In order to reach the target of an under 5%\nrange for the 95% confidence bounds, the minimum number of required samples per\nclass is 1000. As more features are added, more samples are needed, so that\n2500 samples per class are required at only 4 features. Other estimators do\nbecome more accurate than kNN as more features are added, but continuously fail\nto meet the target range.",
    "pdf_url": "http://arxiv.org/pdf/2506.03159v2",
    "published": "2025-05-21T19:58:20+00:00",
    "categories": [
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15978v2",
    "title": "Quantum-Enhanced Power Flow and Optimal Power Flow based on Combinatorial Reformulation",
    "authors": [
      "Zeynab Kaseb",
      "Matthias Moller",
      "Peter Palensky",
      "Pedro P. Vergara"
    ],
    "abstract": "This study introduces the Adiabatic Quantum Power Flow (AQPF) and Adiabatic\nQuantum Optimal Power Flow (AQOPF) algorithms to solve power flow (PF) and\noptimal power flow (OPF) problems, respectively. These algorithms utilize a\nnovel combinatorial optimization reformulation of classical PF and OPF\nproblems, and hence, enable their implementation on Ising machines, e.g.,\nquantum and quantum-inspired hardware. The experiments are conducted on\nstandard test cases ranging from 4-bus to 1354-bus systems, using D-Wave's\nAdvantage system (QA), its hybrid quantum-classical solver (HA), as well as the\nthird-generation Digital Annealer (DAv3) and Quantum-Inspired Integrated\nOptimization software (QIIO) developed by Fujitsu. The annealers are\nsystematically evaluated based on: (i) full and partitioned formulations, (ii)\nability to handle ill-conditioned cases, and (iii) scalability. The results are\nbenchmarked against the Newton-Raphson numerical method (NR) and suggest that\nAQPF and AQOPF can serve as effective solvers or complementary tools to\nclassical methods to address unsolved challenges in large-scale modern power\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15978v2",
    "published": "2025-05-21T19:57:01+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15977v1",
    "title": "A Hierarchical Optimization Framework Using Deep Reinforcement Learning for Task-Driven Bandwidth Allocation in 5G Teleoperation",
    "authors": [
      "Narges Golmohammadi",
      "Madan Mohan Rayguru",
      "Sabur Baidya"
    ],
    "abstract": "The evolution of 5G wireless technology has revolutionized connectivity,\nenabling a diverse range of applications. Among these are critical use cases\nsuch as real time teleoperation, which demands ultra reliable low latency\ncommunications (URLLC) to ensure precise and uninterrupted control, and\nenhanced mobile broadband (eMBB) services, which cater to data-intensive\napplications requiring high throughput and bandwidth. In our scenario, there\nare two queues, one for eMBB users and one for URLLC users. In teleoperation\ntasks, control commands are received in the URLLC queue, where communication\ndelays occur. The dynamic index (DI) controls the service rate, affecting the\ntelerobotic (URLLC) queue. A separate queue models eMBB data traffic. Both\nqueues are managed through network slicing and application delay constraints,\nleading to a unified Lagrangian-based Lyapunov optimization for efficient\nresource allocation. We propose a DRL based hierarchical optimization framework\nthat consists of two levels. At the first level, network optimization\ndynamically allocates resources for eMBB and URLLC users using a Lagrangian\nfunctional and an actor critic network to balance competing objectives. At the\nsecond level, control optimization finetunes the best gains for robots,\nensuring stability and responsiveness in network conditions. This hierarchical\napproach enhances both communication and control processes, ensuring efficient\nresource utilization and optimized performance across the network.",
    "pdf_url": "http://arxiv.org/pdf/2505.15977v1",
    "published": "2025-05-21T19:53:20+00:00",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15976v2",
    "title": "A Lee-Huang-Yang type expansion for the thermodynamic energy density of a dilute mixture of Bose gases",
    "authors": [
      "Marco Olivieri"
    ],
    "abstract": "We consider a dilute gas in 3D composed of two species of bosons interacting\nthrough positive inter-species and intra-species pairwise potentials. We prove\na second order expansion for the energy density in the thermodynamic limit. For\nthe case of compactly supported, integrable potentials, we derive the correct\nsecond order of the expansion. If we make the further assumption of having soft\npotentials, we also derive the correct coefficient of the second order and the\nresulting formula is coherent with the physics literature. If we let the\ndensity and scattering length of one of the species go to zero, we obtain the\nLee-Huang-Yang formula for one species of bosons. The paper also contains a\nproof of BEC for a mixture of bosons in a box with length scale larger than the\nGross-Pitaevskii one.",
    "pdf_url": "http://arxiv.org/pdf/2505.15976v2",
    "published": "2025-05-21T19:52:16+00:00",
    "categories": [
      "math-ph",
      "math.AP",
      "math.MP",
      "math.SP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15975v1",
    "title": "Geometric formulation of $k$-essence and late-time acceleration",
    "authors": [
      "Lehel Csillag",
      "Erik Jensko"
    ],
    "abstract": "We study a class of geometries in which nonmetricity is fully determined by a\nvectorial degree of freedom and three independent coefficients. Formulating the\nsimplest linear action in this geometry, implemented through Lagrange\nmultipliers, naturally leads to an equivalence with the purely kinetic\n$k$-essence models with quadratic kinetic terms. A detailed dynamical systems\nanalysis reveals that the $\\Lambda$CDM phenomenology is embedded within the\nmodel. Crucially, we find that if stability conditions such as a positive sound\nspeed squared and non-negative energy density are not enforced, the model\ngenerically exhibits instabilities and divergent behaviour in the phase space.\nThese physical viability criteria allow us to isolate stable regions of the\nparameter space and derive well-motivated priors for parameter inference. Using\nMarkov Chain Monte Carlo methods and late-time observational data, including\ncosmic chronometers, Pantheon$^{+}$ Type Ia supernovae, and DESI baryon\nacoustic oscillations, we constrain the degrees of freedom associated with\nnonmetricity and demonstrate the viability of the model. Remarkably, the model\nis found to be statistically indistinguishable from $\\Lambda$CDM at late times.\nWe discuss the implications of these results in light of the recent cosmic\ntensions, and give a possible explanation as to why the equivalent $k$-essence\nmodels have been missed as serious competitors to $\\Lambda$CDM in the past.\nFinally, we review the geometric foundations of the theory and show that the\nintegrable Weyl, Schr\\\"{o}dinger and completely symmetric geometries are\nembedded within our framework as special cases.",
    "pdf_url": "http://arxiv.org/pdf/2505.15975v1",
    "published": "2025-05-21T19:51:14+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15974v2",
    "title": "Real-Time Stress Monitoring, Detection, and Management in College Students: A Wearable Technology and Machine-Learning Approach",
    "authors": [
      "Alan Ta",
      "Nilsu Salgin",
      "Mustafa Demir",
      "Kala Phillips Reindel",
      "Ranjana K. Mehta",
      "Anthony McDonald",
      "Carly McCord",
      "Farzan Sasangohar"
    ],
    "abstract": "College students are increasingly affected by stress, anxiety, and\ndepression, yet face barriers to traditional mental health care. This study\nevaluated the efficacy of a mobile health (mHealth) intervention, Mental Health\nEvaluation and Lookout Program (mHELP), which integrates a smartwatch sensor\nand machine learning (ML) algorithms for real-time stress detection and\nself-management. In a 12-week randomized controlled trial (n = 117),\nparticipants were assigned to a treatment group using mHELP's full suite of\ninterventions or a control group using the app solely for real-time stress\nlogging and weekly psychological assessments. The primary outcome, \"Moments of\nStress\" (MS), was assessed via physiological and self-reported indicators and\nanalyzed using Generalized Linear Mixed Models (GLMM) approaches. Similarly,\nsecondary outcomes of psychological assessments, including the Generalized\nAnxiety Disorder-7 (GAD-7) for anxiety, the Patient Health Questionnaire\n(PHQ-8) for depression, and the Perceived Stress Scale (PSS), were also\nanalyzed via GLMM. The finding of the objective measure, MS, indicates a\nsubstantial decrease in MS among the treatment group compared to the control\ngroup, while no notable between-group differences were observed in subjective\nscores of anxiety (GAD-7), depression (PHQ-8), or stress (PSS). However, the\ntreatment group exhibited a clinically meaningful decline in GAD-7 and PSS\nscores. These findings underscore the potential of wearable-enabled mHealth\ntools to reduce acute stress in college populations and highlight the need for\nextended interventions and tailored features to address chronic symptoms like\ndepression.",
    "pdf_url": "http://arxiv.org/pdf/2505.15974v2",
    "published": "2025-05-21T19:45:42+00:00",
    "categories": [
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15973v1",
    "title": "An Exploratory Study on Multi-modal Generative AI in AR Storytelling",
    "authors": [
      "Hyungjun Doh",
      "Jingyu Shi",
      "Rahul Jain",
      "Heesoo Kim",
      "Karthik Ramani"
    ],
    "abstract": "Storytelling in AR has gained attention due to its multi-modality and\ninteractivity. However, generating multi-modal content for AR storytelling\nrequires expertise and efforts for high-quality conveyance of the narrator's\nintention. Recently, Generative-AI (GenAI) has shown promising applications in\nmulti-modal content generation. Despite the potential benefit, current research\ncalls for validating the effect of AI-generated content (AIGC) in AR\nStorytelling. Therefore, we conducted an exploratory study to investigate the\nutilization of GenAI. Analyzing 223 AR videos, we identified a design space for\nmulti-modal AR Storytelling. Based on the design space, we developed a testbed\nfacilitating multi-modal content generation and atomic elements in AR\nStorytelling. Through two studies with N=30 experienced storytellers and live\npresenters, we 1. revealed participants' preferences for modalities, 2.\nevaluated the interactions with AI to generate content, and 3. assessed the\nquality of the AIGC for AR Storytelling. We further discussed design\nconsiderations for future AR Storytelling with GenAI.",
    "pdf_url": "http://arxiv.org/pdf/2505.15973v1",
    "published": "2025-05-21T19:44:58+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15972v1",
    "title": "Extremum Seeking for PDE Systems using Physics-Informed Neural Networks",
    "authors": [
      "Haojin Guo",
      "Zongyi Guo",
      "Jianguo Guo",
      "Tiago Roux Oliveira"
    ],
    "abstract": "Extremum Seeking (ES) is an effective real-time optimization method for PDE\nsystems in cascade with nonlinear quadratic maps. To address PDEs in the\nfeedback loop, a boundary control law and a re-design of the additive probing\nsignal are mandatory. The latter, commonly called \"trajectory generation\" or\n\"motion planning,\" involves designing perturbation signals that anticipate\ntheir propagation through PDEs. Specifically, this requires solving motion\nplanning problems for systems governed by parabolic and hyperbolic PDEs.\nPhysics-Informed Neural Networks (PINN) is a powerful tool for solving PDEs by\nembedding physical laws as constraints in the neural network's loss function,\nenabling efficient solutions for high-dimensional, nonlinear, and complex\nproblems. This paper proposes a novel construction integrating PINN and ES,\nautomating the motion planning process for specific PDE systems and eliminating\nthe need for case-by-case analytical derivations. The proposed strategy\nefficiently extracts perturbation signals, optimizing the PDE system.",
    "pdf_url": "http://arxiv.org/pdf/2505.15972v1",
    "published": "2025-05-21T19:44:27+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15971v2",
    "title": "A Paradigm for Creative Ownership",
    "authors": [
      "Tejaswi Polimetla",
      "Katy Ilonka Gero",
      "Elena Leah Glassman"
    ],
    "abstract": "As generative AI tools become embedded in creative practice, questions of\nownership in co-creative contexts are pressing. Yet studies of human-AI\ncollaboration often invoke \"ownership\" without definition: sometimes conflating\nit with other concepts, and other times leaving interpretation to participants.\nThis inconsistency makes findings difficult to compare across or even within\nstudies. We introduce a framework of creative ownership comprising three\ndimensions - Person, Process, and System - each with three subdimensions,\noffering a shared language for both system design and HCI research. In\nsemi-structured interviews with 21 creative professionals, we found that\nparticipants' initial references to ownership (e.g., embodiment, control,\nconcept) were fully encompassed by the framework, demonstrating its coverage.\nOnce introduced, however, they also articulated and prioritized the remaining\nsubdimensions, underscoring how the framework expands reflection and enables\nricher insights. Our contributions include 1) the framework, 2) a web-based\nvisualization tool, and 3) empirical findings on its utility.",
    "pdf_url": "http://arxiv.org/pdf/2505.15971v2",
    "published": "2025-05-21T19:44:22+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15970v1",
    "title": "Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders",
    "authors": [
      "Matthew Lyle Olson",
      "Musashi Hinck",
      "Neale Ratzlaff",
      "Changbai Li",
      "Phillip Howard",
      "Vasudev Lal",
      "Shao-Yen Tseng"
    ],
    "abstract": "The ImageNet hierarchy provides a structured taxonomy of object categories,\noffering a valuable lens through which to analyze the representations learned\nby deep vision models. In this work, we conduct a comprehensive analysis of how\nvision models encode the ImageNet hierarchy, leveraging Sparse Autoencoders\n(SAEs) to probe their internal representations. SAEs have been widely used as\nan explanation tool for large language models (LLMs), where they enable the\ndiscovery of semantically meaningful features. Here, we extend their use to\nvision models to investigate whether learned representations align with the\nontological structure defined by the ImageNet taxonomy. Our results show that\nSAEs uncover hierarchical relationships in model activations, revealing an\nimplicit encoding of taxonomic structure. We analyze the consistency of these\nrepresentations across different layers of the popular vision foundation model\nDINOv2 and provide insights into how deep vision models internalize\nhierarchical category information by increasing information in the class token\nthrough each layer. Our study establishes a framework for systematic\nhierarchical analysis of vision model representations and highlights the\npotential of SAEs as a tool for probing semantic structure in deep networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15970v1",
    "published": "2025-05-21T19:38:48+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15969v1",
    "title": "Grassmann and Flag Varieties in Linear Algebra, Optimization, and Statistics: An Algebraic Perspective",
    "authors": [
      "Hannah Friedman",
      "Serkan Ho≈üten"
    ],
    "abstract": "Grassmann and flag varieties lead many lives in pure and applied mathematics.\nHere we focus on the algebraic complexity of solving various problems in linear\nalgebra and statistics as optimization problems over these varieties. The\nmeasure of the algebraic complexity is the amount of complex critical points of\nthe corresponding optimization problem. After an exposition of different\nrealizations of these manifolds as algebraic varieties we present a sample of\noptimization problems over them and we compute their algebraic complexity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15969v1",
    "published": "2025-05-21T19:37:56+00:00",
    "categories": [
      "math.OC",
      "math.AG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15968v1",
    "title": "The invisible threat: assessing the collisional hazard posed by the undiscovered Venus co-orbital asteroids",
    "authors": [
      "V. Carruba",
      "R. Sfair",
      "R. A. Araujo",
      "O. C. Winter",
      "D. C. Mour√£o",
      "S. Di Ruzza",
      "S. Aljbaae",
      "G. Carit√°",
      "R. C. Domingos",
      "A. A. Alves"
    ],
    "abstract": "Currently, 20 co-orbital asteroids of Venus are known, with only one with an\neccentricity below 0.38. This is most likely caused by observational biases\nsince asteroids with larger eccentricities may approach the Earth and are\neasier to detect. We aim to assess the possible threat that the yet undetected\npopulation of Venus co-orbitals may pose to Earth, and investigate their\ndetectability from Earth and space observatories. We used semi-analytical\nmodels of the 1:1 mean-motion resonance with Venus and numerical simulations to\nmonitor close encounters with Earth on several co-orbital cycles. We analyzed\nobservability windows and brightness variations for potential Venus co-orbitals\nas viewed from ground-based telescopes to assess their future detection\nfeasibility with next-generation survey capabilities. There is a range of\norbits with e < 0.38, larger at lower inclinations, for which Venus'\nco-orbitals can pose a collisional hazard to Earth. Current ground-based\nobservations are constrained by periodic observing windows and solar elongation\nlimitations, though the Rubin Observatory may detect some of these objects\nduring favorable configurations. Space missions based on Venus' orbits may be\ninstrumental in detecting Venus' co-orbitals at low eccentricities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15968v1",
    "published": "2025-05-21T19:37:30+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15967v1",
    "title": "On the existence of stationary solutions for certain systems of integro-differential equations with the double scale anomalous diffusion",
    "authors": [
      "Vitali Vougalter",
      "Vitaly Volpert"
    ],
    "abstract": "The work deals with establishing the solvability of a system of\nintegro-differential equations in the situation of the double scale anomalous\ndiffusion. Each equation of such system involves the sum of the two negative\nLaplace operators raised to two distinct fractional powers in the space of\nthree dimensions. The proof of the existence of solutions is based on a fixed\npoint technique. We use the solvability conditions for the non-Fredholm\nelliptic operators in unbounded domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.15967v1",
    "published": "2025-05-21T19:35:24+00:00",
    "categories": [
      "math.AP",
      "35R11, 35P30, 45K05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15966v2",
    "title": "Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning",
    "authors": [
      "Alex Su",
      "Haozhe Wang",
      "Weiming Ren",
      "Fangzhen Lin",
      "Wenhu Chen"
    ],
    "abstract": "Chain-of-thought reasoning has significantly improved the performance of\nLarge Language Models (LLMs) across various domains. However, this reasoning\nprocess has been confined exclusively to textual space, limiting its\neffectiveness in visually intensive tasks. To address this limitation, we\nintroduce the concept of reasoning in the pixel-space. Within this novel\nframework, Vision-Language Models (VLMs) are equipped with a suite of visual\nreasoning operations, such as zoom-in and select-frame. These operations enable\nVLMs to directly inspect, interrogate, and infer from visual evidences, thereby\nenhancing reasoning fidelity for visual tasks. Cultivating such pixel-space\nreasoning capabilities in VLMs presents notable challenges, including the\nmodel's initially imbalanced competence and its reluctance to adopt the newly\nintroduced pixel-space operations. We address these challenges through a\ntwo-phase training approach. The first phase employs instruction tuning on\nsynthesized reasoning traces to familiarize the model with the novel visual\noperations. Following this, a reinforcement learning (RL) phase leverages a\ncuriosity-driven reward scheme to balance exploration between pixel-space\nreasoning and textual reasoning. With these visual operations, VLMs can\ninteract with complex visual inputs, such as information-rich images or videos\nto proactively gather necessary information. We demonstrate that this approach\nsignificantly improves VLM performance across diverse visual reasoning\nbenchmarks. Our 7B model, \\model, achieves 84\\% on V* bench, 74\\% on\nTallyQA-Complex, and 84\\% on InfographicsVQA, marking the highest accuracy\nachieved by any open-source model to date. These results highlight the\nimportance of pixel-space reasoning and the effectiveness of our framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.15966v2",
    "published": "2025-05-21T19:35:08+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15965v2",
    "title": "Analyzing the Impact of Accent on English Speech: Acoustic and Articulatory Perspectives",
    "authors": [
      "Gowtham Premananth",
      "Vinith Kugathasan",
      "Carol Espy-Wilson"
    ],
    "abstract": "Advancements in AI-driven speech-based applications have transformed diverse\nindustries ranging from healthcare to customer service. However, the increasing\nprevalence of non-native accented speech in global interactions poses\nsignificant challenges for speech-processing systems, which are often trained\non datasets dominated by native speech. This study investigates accented\nEnglish speech through articulatory and acoustic analysis, identifying simpler\ncoordination patterns and higher average pitch than native speech. Using\neigenspectra and Vocal Tract Variable-based coordination features, we establish\nan efficient method for quantifying accent strength without relying on\nresource-intensive phonetic transcriptions. Our findings provide a new avenue\nfor research on the impacts of accents on speech intelligibility and offer\ninsights for developing inclusive, robust speech processing systems that\naccommodate diverse linguistic communities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15965v2",
    "published": "2025-05-21T19:31:40+00:00",
    "categories": [
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15964v1",
    "title": "Bad approximability, bounded ratios and Diophantine exponents",
    "authors": [
      "Antoine Marnat",
      "Nikolay Moshchevitin",
      "Johannes Schleischitz"
    ],
    "abstract": "For a real $m\\times n$ matrix $\\pmb{\\xi}$, we consider its sequence of best\nDiophantine approximation vectors $ \\pmb{x}_i \\in \\mathbb{Z}^n, \\, i =1,2,3,\n... $, the sequences of its norms $X_i = \\|\\pmb{x}_i\\|$ and the norms of\nremainders $L_i = \\|\\pmb{\\xi}\\pmb{x}_i\\|$. It is known that, in the cases\n$m=1$, bad approximability of $\\pmb{\\xi}$ is equivalent to the boundedness of\nratios $\\frac{X_{i+1}}{X_i}$, while for $n=1$ bad approximability of\n$\\pmb{\\xi}$ is equivalent to the boundedness of ratios $ \\frac{L_i}{L_{i+1}}$.\nMoreover, carefully constructed example show that in the cases $m=1$ and $n=1$\nboundedness of ratios $ \\frac{L_i}{L_{i+1}}$ and $\\frac{X_{i+1}}{X_i}$\nrespectively (the order of ratios changed), does not imply bad approximability\nof $\\pmb{\\xi}$. In the present paper, we study the impact of the boundedness of\nratios on Diophantine properties of $\\pmb{\\xi}$, in particular, what\nrestrictions it gives for Diophantine exponents $\\omega(\\pmb{\\xi})$ and\n$\\hat{\\omega}(\\pmb{\\xi})$. One of our particular results deals with the case\n$m=n=2$. We prove that for $2\\times 2 $ matrices $\\pmb{\\xi}$ boundedness of\nboth ratios $ \\frac{X_{i+1}}{X_i}, \\frac{L_i}{L_{i+1}} $ implies inequality\n$\\hat{\\omega}(\\pmb{\\xi})\\le \\frac{4}{3}$ and that this result is optimal. Our\nmethods combine parametric geometry of numbers as well as more classical tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.15964v1",
    "published": "2025-05-21T19:31:25+00:00",
    "categories": [
      "math.NT",
      "11J13"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15963v1",
    "title": "OViP: Online Vision-Language Preference Learning",
    "authors": [
      "Shujun Liu",
      "Siyuan Wang",
      "Zejun Li",
      "Jianxiang Wang",
      "Cheng Zeng",
      "Zhongyu Wei"
    ],
    "abstract": "Large vision-language models (LVLMs) remain vulnerable to hallucination,\noften generating content misaligned with visual inputs. While recent approaches\nadvance multi-modal Direct Preference Optimization (DPO) to mitigate\nhallucination, they typically rely on predefined or randomly edited negative\nsamples that fail to reflect actual model errors, limiting training efficacy.\nIn this work, we propose an Online Vision-language Preference Learning (OViP)\nframework that dynamically constructs contrastive training data based on the\nmodel's own hallucinated outputs. By identifying semantic differences between\nsampled response pairs and synthesizing negative images using a diffusion\nmodel, OViP generates more relevant supervision signals in real time. This\nfailure-driven training enables adaptive alignment of both textual and visual\npreferences. Moreover, we refine existing evaluation protocols to better\ncapture the trade-off between hallucination suppression and expressiveness.\nExperiments on hallucination and general benchmarks demonstrate that OViP\neffectively reduces hallucinations while preserving core multi-modal\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15963v1",
    "published": "2025-05-21T19:26:09+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15962v2",
    "title": "Pre-training Large Memory Language Models with Internal and External Knowledge",
    "authors": [
      "Linxi Zhao",
      "Sofian Zalouk",
      "Christian K. Belardi",
      "Justin Lovelace",
      "Jin Peng Zhou",
      "Kilian Q. Weinberger",
      "Yoav Artzi",
      "Jennifer J. Sun"
    ],
    "abstract": "Neural language models are black-boxes -- both linguistic patterns and\nfactual knowledge are distributed across billions of opaque parameters. This\nentangled encoding makes it difficult to reliably inspect, verify, or update\nspecific facts. We propose a new class of language models, Large Memory\nLanguage Models (LMLM) with a pre-training recipe that stores factual knowledge\nin both internal weights and an external database. Our approach strategically\nmasks externally retrieved factual values from the training loss, thereby\nteaching the model to perform targeted lookups rather than relying on\nmemorization in model weights. Our experiments demonstrate that LMLMs achieve\ncompetitive performance compared to significantly larger, knowledge-dense LLMs\non standard benchmarks, while offering the advantages of explicit, editable,\nand verifiable knowledge bases. This work represents a fundamental shift in how\nlanguage models interact with and manage factual knowledge.",
    "pdf_url": "http://arxiv.org/pdf/2505.15962v2",
    "published": "2025-05-21T19:26:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15961v2",
    "title": "Super-Resolution with Structured Motion",
    "authors": [
      "Gabby Litterio",
      "Juan-David Lizarazo-Ferro",
      "Pedro Felzenszwalb",
      "Rashid Zia"
    ],
    "abstract": "We consider the limits of super-resolution using imaging constraints. Due to\nvarious theoretical and practical limitations, reconstruction-based methods\nhave been largely restricted to small increases in resolution. In addition,\nmotion-blur is usually seen as a nuisance that impedes super-resolution. We\nshow that by using high-precision motion information, sparse image priors, and\nconvex optimization, it is possible to increase resolution by large factors. A\nkey operation in super-resolution is deconvolution with a box. In general,\nconvolution with a box is not invertible. However, we obtain perfect\nreconstructions of sparse signals using convex optimization. We also show that\nmotion blur can be helpful for super-resolution. We demonstrate that using\npseudo-random motion it is possible to reconstruct a high-resolution target\nusing a single low-resolution image. We present numerical experiments with\nsimulated data and results with real data captured by a camera mounted on a\ncomputer controlled stage.",
    "pdf_url": "http://arxiv.org/pdf/2505.15961v2",
    "published": "2025-05-21T19:25:28+00:00",
    "categories": [
      "cs.CV",
      "I.4.1; I.4.3"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15960v1",
    "title": "Training Step-Level Reasoning Verifiers with Formal Verification Tools",
    "authors": [
      "Ryo Kamoi",
      "Yusen Zhang",
      "Nan Zhang",
      "Sarkar Snigdha Sarathi Das",
      "Rui Zhang"
    ],
    "abstract": "Process Reward Models (PRMs), which provide step-by-step feedback on the\nreasoning generated by Large Language Models (LLMs), are receiving increasing\nattention. However, two key research gaps remain: collecting accurate\nstep-level error labels for training typically requires costly human\nannotation, and existing PRMs are limited to math reasoning problems. In\nresponse to these gaps, this paper aims to address the challenges of automatic\ndataset creation and the generalization of PRMs to diverse reasoning tasks. To\nachieve this goal, we propose FoVer, an approach for training PRMs on\nstep-level error labels automatically annotated by formal verification tools,\nsuch as Z3 for formal logic and Isabelle for theorem proof, which provide\nautomatic and accurate verification for symbolic tasks. Using this approach, we\nsynthesize a training dataset with error labels on LLM responses for formal\nlogic and theorem proof tasks without human annotation. Although this data\nsynthesis is feasible only for tasks compatible with formal verification, we\nobserve that LLM-based PRMs trained on our dataset exhibit cross-task\ngeneralization, improving verification across diverse reasoning tasks.\nSpecifically, PRMs trained with FoVer significantly outperform baseline PRMs\nbased on the original LLMs and achieve competitive or superior results compared\nto state-of-the-art PRMs trained on labels annotated by humans or stronger\nmodels, as measured by step-level verification on ProcessBench and Best-of-K\nperformance across 12 reasoning benchmarks, including MATH, AIME, ANLI, MMLU,\nand BBH. The datasets, models, and code are provided at\nhttps://github.com/psunlpgroup/FoVer.",
    "pdf_url": "http://arxiv.org/pdf/2505.15960v1",
    "published": "2025-05-21T19:23:45+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15959v2",
    "title": "HornStr: Invariant Synthesis for Regular Model Checking as Constrained Horn Clauses(Technical Report)",
    "authors": [
      "Hongjian Jiang",
      "Anthony W. Lin",
      "Oliver Markgraf",
      "Philipp R√ºmmer",
      "Daniel Stan"
    ],
    "abstract": "We present HornStr, the first solver for invariant synthesis for Regular\nModel Checking (RMC) with the specification provided in the SMT-LIB 2.6 theory\nof strings. It is well-known that invariant synthesis for RMC subsumes various\nimportant verification problems, including safety verification for\nparameterized systems. To achieve a simple and standardized file format, we\ntreat the invariant synthesis problem as a problem of solving Constrained Horn\nClauses (CHCs) over strings. Two strategies for synthesizing invariants in\nterms of regular constraints are supported: (1) L* automata learning, and (2)\nSAT-based automata learning. HornStr implements these strategies with the help\nof existing SMT solvers for strings, which are interfaced through SMT-LIB.\nHornStr provides an easy-to-use interface for string solver developers to apply\ntheir techniques to verification. At the same time, it allows verification\nresearchers to painlessly tap into the wealth of modern string solving\ntechniques. To assess the effectiveness of HornStr, we conducted a\ncomprehensive evaluation using benchmarks derived from applications including\nparameterized verification and string rewriting tasks. Our experiments\nhighlight HornStr's capacity to effectively handle these benchmarks, e.g., as\nthe first solver to verify the challenging MU puzzle automatically. Finally,\nHornStr can be used to automatically generate a new class of interesting\nSMT-LIB 2.6 string constraint benchmarks, which might in the future be used in\nthe SMT-COMP strings track. In particular, our experiments on the above\ninvariant synthesis benchmarks produce more than 30000 new QF_S constraints. We\nalso detail the performance of various integrated string solvers, providing\ninsights into their effectiveness on our new benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15959v2",
    "published": "2025-05-21T19:22:16+00:00",
    "categories": [
      "cs.LO",
      "cs.FL"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15958v1",
    "title": "Data-driven Verification of Procedural Programs with Integer Arrays",
    "authors": [
      "Ahmed Bouajjani",
      "Wael-Amine Boutglay",
      "Peter Habermehl"
    ],
    "abstract": "We address the problem of verifying automatically procedural programs\nmanipulating parametric-size arrays of integers, encoded as a constrained Horn\nclauses solving problem. We propose a new algorithmic method for synthesizing\nloop invariants and procedure pre/post-conditions represented as universally\nquantified first-order formulas constraining the array elements and program\nvariables. We adopt a data-driven approach that extends the decision tree\nHorn-ICE framework to handle arrays. We provide a powerful learning technique\nbased on reducing a complex classification problem of vectors of integer arrays\nto a simpler classification problem of vectors of integers. The obtained\nclassifier is generalized to get universally quantified invariants and\nprocedure pre/post-conditions. We have implemented our method and shown its\nefficiency and competitiveness w.r.t. state-of-the-art tools on a significant\nbenchmark.",
    "pdf_url": "http://arxiv.org/pdf/2505.15958v1",
    "published": "2025-05-21T19:19:21+00:00",
    "categories": [
      "cs.PL",
      "cs.LG"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15957v2",
    "title": "Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey",
    "authors": [
      "Chih-Kai Yang",
      "Neo S. Ho",
      "Hung-yi Lee"
    ],
    "abstract": "With advancements in large audio-language models (LALMs), which enhance large\nlanguage models (LLMs) with auditory capabilities, these models are expected to\ndemonstrate universal proficiency across various auditory tasks. While numerous\nbenchmarks have emerged to assess LALMs' performance, they remain fragmented\nand lack a structured taxonomy. To bridge this gap, we conduct a comprehensive\nsurvey and propose a systematic taxonomy for LALM evaluations, categorizing\nthem into four dimensions based on their objectives: (1) General Auditory\nAwareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented\nAbility, and (4) Fairness, Safety, and Trustworthiness. We provide detailed\noverviews within each category and highlight challenges in this field, offering\ninsights into promising future directions. To the best of our knowledge, this\nis the first survey specifically focused on the evaluations of LALMs, providing\nclear guidelines for the community. We will release the collection of the\nsurveyed papers and actively maintain it to support ongoing advancements in the\nfield.",
    "pdf_url": "http://arxiv.org/pdf/2505.15957v2",
    "published": "2025-05-21T19:17:29+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15956v1",
    "title": "Fast quantum interferometry at the nanometer and attosecond scales with energy-entangled photons",
    "authors": [
      "Colin P. Lualdi",
      "Spencer J. Johnson",
      "Michael Vayninger",
      "Kristina A. Meier",
      "Swetapadma Sahoo",
      "Simeon I. Bogdanov",
      "Paul G. Kwiat"
    ],
    "abstract": "In classical optical interferometry, loss and background complicate achieving\nfast nanometer-resolution measurements with illumination at low light levels.\nConversely, quantum two-photon interference is unaffected by loss and\nbackground, but nanometer-scale resolution is physically difficult to realize.\nAs a solution, we enhance two-photon interference with highly non-degenerate\nenergy entanglement featuring photon frequencies separated by 177 THz. We\nobserve measurement resolution at the nanometer (attosecond) scale with only\n$O(10^4)$ photon pairs, despite the presence of background and loss. Our\nnon-destructive thickness measurement of a metallic thin film agrees with\natomic force microscopy, which often achieves better resolution via destructive\nmeans. With contactless, non-destructive measurements in seconds or faster, our\ninstrument enables metrological studies in optically challenging contexts where\nbackground, loss, or photosensitivity are factors.",
    "pdf_url": "http://arxiv.org/pdf/2505.15956v1",
    "published": "2025-05-21T19:16:19+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15955v2",
    "title": "Comparison of Oracles",
    "authors": [
      "David Lagziel",
      "Ehud Lehrer",
      "Tao Wang"
    ],
    "abstract": "We analyze incomplete-information games where an oracle publicly shares\ninformation with players. One oracle dominates another if, in every game, it\ncan match the set of equilibrium outcomes induced by the latter. Distinct\ncharacterizations are provided for deterministic and stochastic signaling\nfunctions, based on simultaneous posterior matching, partition refinements, and\ncommon knowledge components. This study extends the work of Blackwell (1951) to\ngames, and expands the study of Aumann (1976) on common knowledge by developing\na theory of information loops.",
    "pdf_url": "http://arxiv.org/pdf/2505.15955v2",
    "published": "2025-05-21T19:16:03+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.15954v1",
    "title": "Integrating Robotic Navigation with Blockchain: A Novel PoS-Based Approach for Heterogeneous Robotic Teams",
    "authors": [
      "Nasim Paykari",
      "Ali Alfatemi",
      "Damian M. Lyons",
      "Mohamed Rahouti"
    ],
    "abstract": "This work explores a novel integration of blockchain methodologies with Wide\nArea Visual Navigation (WAVN) to address challenges in visual navigation for a\nheterogeneous team of mobile robots deployed for unstructured applications in\nagriculture, forestry, etc. Focusing on overcoming challenges such as GPS\nindependence, environmental changes, and computational limitations, the study\nintroduces the Proof of Stake (PoS) mechanism, commonly used in blockchain\nsystems, into the WAVN framework \\cite{Lyons_2022}. This integration aims to\nenhance the cooperative navigation capabilities of robotic teams by\nprioritizing robot contributions based on their navigation reliability. The\nmethodology involves a stake weight function, consensus score with PoS, and a\nnavigability function, addressing the computational complexities of robotic\ncooperation and data validation. This innovative approach promises to optimize\nrobotic teamwork by leveraging blockchain principles, offering insights into\nthe scalability, efficiency, and overall system performance. The project\nanticipates significant advancements in autonomous navigation and the broader\napplication of blockchain technology beyond its traditional financial context.",
    "pdf_url": "http://arxiv.org/pdf/2505.15954v1",
    "published": "2025-05-21T19:11:36+00:00",
    "categories": [
      "cs.RO",
      "cs.CR"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15953v1",
    "title": "Modular Fault-Tolerant DBMS",
    "authors": [
      "Nikolay Fot",
      "Alexander Vinarsky"
    ],
    "abstract": "The article addresses the problem of storing data in extreme environmental\nconditions with limited computing resources and memory. There is a requirement\nto create portable, fault-tolerant, modular database management systems (DBMS)\nthat are optimized for use in embedded systems. Existing databases, such as\nLittleDB, LMDB, and Berkeley DB, are reviewed, and their limitations are\nidentified. A variant of a portable DBMS is introduced to efficiently manage\ndata in environments where computational resource usage must be minimized,\nwhile meeting specific requirements for fault tolerance and noise immunity.\nCommon solutions for optimizing of insertion, storage and management of data\nare reviewed. Algorithms for fault-tolerant data encoding in RAM are\nimplemented. An architectural solution to data storage and minimizing the\nimpact of bit errors is proposed. Software that manages relational data in\nextreme conditions is developed, that allows testing and comparing results with\nexisting solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15953v1",
    "published": "2025-05-21T19:10:12+00:00",
    "categories": [
      "cs.DB",
      "68P15",
      "H.2.4"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.15952v1",
    "title": "VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance",
    "authors": [
      "Mohammad Reza Taesiri",
      "Abhijay Ghildyal",
      "Saman Zadtootaghaj",
      "Nabajeet Barman",
      "Cor-Paul Bezemer"
    ],
    "abstract": "With video games now generating the highest revenues in the entertainment\nindustry, optimizing game development workflows has become essential for the\nsector's sustained growth. Recent advancements in Vision-Language Models (VLMs)\noffer considerable potential to automate and enhance various aspects of game\ndevelopment, particularly Quality Assurance (QA), which remains one of the\nindustry's most labor-intensive processes with limited automation options. To\naccurately evaluate the performance of VLMs in video game QA tasks and\ndetermine their effectiveness in handling real-world scenarios, there is a\nclear need for standardized benchmarks, as existing benchmarks are insufficient\nto address the specific requirements of this domain. To bridge this gap, we\nintroduce VideoGameQA-Bench, a comprehensive benchmark that covers a wide array\nof game QA activities, including visual unit testing, visual regression\ntesting, needle-in-a-haystack tasks, glitch detection, and bug report\ngeneration for both images and videos of various games. Code and data are\navailable at: https://asgaardlab.github.io/videogameqa-bench/",
    "pdf_url": "http://arxiv.org/pdf/2505.15952v1",
    "published": "2025-05-21T19:08:38+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15951v3",
    "title": "TriggerCalib: a turnkey package for estimating LHCb trigger efficiencies",
    "authors": [
      "Johannes Albrecht",
      "James Andrew Gooding",
      "Maxim Lysenko",
      "Abhijit Mathad",
      "Alessandro Scarabotto"
    ],
    "abstract": "Data-driven estimations of trigger efficiencies are essential to LHCb physics\nanalyses. A software package, TriggerCalib, has been developed to provide a\ncentralised framework of trigger efficiency calculations. In this paper, a\ndata-driven method of estimating trigger efficiencies is presented, within the\ncontext of the TriggerCalib package, and its functionalities validated on\ncandidate $B^+\\to J/\\psi\\left(\\mu^+\\mu^-\\right) K^+$ decays in LHCb simulated\ndata. A detailed overview of the trigger efficiency calculations is given,\ndiscussing different background mitigation methods and the computation of\nstatistical and systematic uncertainties.",
    "pdf_url": "http://arxiv.org/pdf/2505.15951v3",
    "published": "2025-05-21T19:08:19+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.15950v2",
    "title": "Gaussian Processes in Power Systems: Techniques, Applications, and Future Works",
    "authors": [
      "Bendong Tan",
      "Tong Su",
      "Yu Weng",
      "Ketian Ye",
      "Parikshit Pareek",
      "Petr Vorobev",
      "Hung Nguyen",
      "Junbo Zhao",
      "Deepjyoti Deka"
    ],
    "abstract": "The increasing integration of renewable energy sources (RESs) and distributed\nenergy resources (DERs) has significantly heightened operational complexity and\nuncertainty in modern power systems. Concurrently, the widespread deployment of\nsmart meters, phasor measurement units (PMUs) and other sensors has generated\nvast spatiotemporal data streams, enabling advanced data-driven analytics and\ndecision-making in grid operations. In this context, Gaussian processes (GPs)\nhave emerged as a powerful probabilistic framework, offering uncertainty\nquantification, non-parametric modeling, and predictive capabilities to enhance\npower system analysis and control. This paper presents a comprehensive review\nof GP techniques and their applications in power system operation and control.\nGP applications are reviewed across three key domains: GP-based modeling, risk\nassessment, and optimization and control. These areas serve as representative\nexamples of how GP can be utilized in power systems. Furthermore, critical\nchallenges in GP applications are discussed, and potential research directions\nare outlined to facilitate future power system operations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15950v2",
    "published": "2025-05-21T19:06:59+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15949v1",
    "title": "Partial Domination in Some Geometric Intersection Graphs and Some Complexity Results",
    "authors": [
      "Madhura Dutta",
      "Anil Maheshwari",
      "Subhas C. Nandy",
      "Bodhayan Roy"
    ],
    "abstract": "{\\em Partial domination problem} is a generalization of the {\\em minimum\ndominating set problem} on graphs. Here, instead of dominating all the nodes,\none asks to dominate at least a fraction of the nodes of the given graph by\nchoosing a minimum number of nodes. For any real number $\\alpha\\in(0,1]$,\n$\\alpha$-partial domination problem can be proved to be NP-complete for general\ngraphs. In this paper, we define the {\\em maximum dominating $k$-set} of a\ngraph, which is polynomially transformable to the partial domination problem.\nThe existence of a graph class for which the minimum dominating set problem is\npolynomial-time solvable, whereas the partial dominating set problem is\nNP-hard, is shown. We also propose polynomial-time algorithms for the maximum\ndominating $k$-set problem for the unit and arbitrary interval graphs. The\nproblem can also be solved in polynomial time for the intersection graphs of a\nset of 2D objects intersected by a straight line, where each object is an\naxis-parallel unit square, as well as in the case where each object is a unit\ndisk. Our technique also works for axis-parallel unit-height rectangle\nintersection graphs, where a straight line intersects all the rectangles.\nFinally, a parametrized algorithm for the maximum dominating $k$-set problem in\na disk graph where the input disks are intersected by a straight line is\nproposed; here the parameter is the ratio of the diameters of the largest and\nsmallest input disks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15949v1",
    "published": "2025-05-21T19:06:56+00:00",
    "categories": [
      "cs.CG"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15948v1",
    "title": "Citation Parsing and Analysis with Language Models",
    "authors": [
      "Parth Sarin",
      "Juan Pablo Alperin"
    ],
    "abstract": "A key type of resource needed to address global inequalities in knowledge\nproduction and dissemination is a tool that can support journals in\nunderstanding how knowledge circulates. The absence of such a tool has resulted\nin comparatively less information about networks of knowledge sharing in the\nGlobal South. In turn, this gap authorizes the exclusion of researchers and\nscholars from the South in indexing services, reinforcing colonial arrangements\nthat de-center and minoritize those scholars. In order to support citation\nnetwork tracking on a global scale, we investigate the capacity of open-weight\nlanguage models to mark up manuscript citations in an indexable format. We\nassembled a dataset of matched plaintext and annotated citations from preprints\nand published research papers. Then, we evaluated a number of open-weight\nlanguage models on the annotation task. We find that, even out of the box,\ntoday's language models achieve high levels of accuracy on identifying the\nconstituent components of each citation, outperforming state-of-the-art\nmethods. Moreover, the smallest model we evaluated, Qwen3-0.6B, can parse all\nfields with high accuracy in $2^5$ passes, suggesting that post-training is\nlikely to be effective in producing small, robust citation parsing models. Such\na tool could greatly improve the fidelity of citation networks and thus\nmeaningfully improve research indexing and discovery, as well as further\nmetascientific research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15948v1",
    "published": "2025-05-21T19:06:17+00:00",
    "categories": [
      "cs.CL",
      "cs.DL",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15947v1",
    "title": "Directional Sparsity Based Statistical Channel Estimation for 6D Movable Antenna Communications",
    "authors": [
      "Xiaodan Shao",
      "Rui Zhang",
      "Jihong Park",
      "Tony Q. S. Quek",
      "Robert Schober",
      "Xuemin Shen"
    ],
    "abstract": "Six-dimensional movable antenna (6DMA) is an innovative and transformative\ntechnology to improve wireless network capacity by adjusting the 3D positions\nand 3D rotations of antennas/surfaces (sub-arrays) based on the channel spatial\ndistribution. For optimization of the antenna positions and rotations, the\nacquisition of statistical channel state information (CSI) is essential for\n6DMA systems. In this paper, we unveil for the first time a new\n\\textbf{\\textit{directional sparsity}} property of the 6DMA channels between\nthe base station (BS) and the distributed users, where each user has\nsignificant channel gains only with a (small) subset of 6DMA position-rotation\npairs, which can receive direct/reflected signals from the user. By exploiting\nthis property, a covariance-based algorithm is proposed for estimating the\nstatistical CSI in terms of the average channel power at a small number of 6DMA\npositions and rotations. Based on such limited channel power estimation, the\naverage channel powers for all possible 6DMA positions and rotations in the BS\nmovement region are reconstructed by further estimating the multi-path average\npower and direction-of-arrival (DOA) vectors of all users. Simulation results\nshow that the proposed directional sparsity-based algorithm can achieve higher\nchannel power estimation accuracy than existing benchmark schemes, while\nrequiring a lower pilot overhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.15947v1",
    "published": "2025-05-21T19:05:01+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15946v2",
    "title": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding",
    "authors": [
      "Yuxiang Wei",
      "Yanteng Zhang",
      "Xi Xiao",
      "Tianyang Wang",
      "Xiao Wang",
      "Vince D. Calhoun"
    ],
    "abstract": "Decoding visual experiences from fMRI offers a powerful avenue to understand\nhuman perception and develop advanced brain-computer interfaces. However,\ncurrent progress often prioritizes maximizing reconstruction fidelity while\noverlooking interpretability, an essential aspect for deriving neuroscientific\ninsight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework\ndesigned for high-fidelity, adaptable, and interpretable visual reconstruction.\nMoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture\nwhere distinct experts process fMRI signals from functionally related voxel\ngroups, mimicking specialized brain networks. The experts are first trained to\nencode fMRI into the frozen CLIP space. A finetuned diffusion model then\nsynthesizes images, guided by expert outputs through a novel dual-stage routing\nmechanism that dynamically weighs expert contributions across the diffusion\nprocess. MoRE-Brain offers three main advancements: First, it introduces a\nnovel Mixture-of-Experts architecture grounded in brain network principles for\nneuro-decoding. Second, it achieves efficient cross-subject generalization by\nsharing core expert networks while adapting only subject-specific routers.\nThird, it provides enhanced mechanistic insight, as the explicit routing\nreveals precisely how different modeled brain regions shape the semantic and\nspatial attributes of the reconstructed image. Extensive experiments validate\nMoRE-Brain's high reconstruction fidelity, with bottleneck analyses further\ndemonstrating its effective utilization of fMRI signals, distinguishing genuine\nneural decoding from over-reliance on generative priors. Consequently,\nMoRE-Brain marks a substantial advance towards more generalizable and\ninterpretable fMRI-based visual decoding. Code will be publicly available soon:\nhttps://github.com/yuxiangwei0808/MoRE-Brain.",
    "pdf_url": "http://arxiv.org/pdf/2505.15946v2",
    "published": "2025-05-21T19:02:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15945v2",
    "title": "Bloch oscillation with a diatomic tight-binding model on quantum computers",
    "authors": [
      "Peng Guo",
      "Jaime Park",
      "Frank X. Lee"
    ],
    "abstract": "We aim to explore a more efficient way to simulate few-body dynamics on\nquantum computers. Instead of mapping the second quantization of the system\nHamiltonian to qubit Pauli gates representation via the Jordan-Wigner\ntransform, we propose to use the few-body Hamiltonian matrix under the\nstatevector basis representation which is more economical on the required\nnumber of quantum registers. For a single-particle excitation state on a\none-dimensional chain, $\\Gamma$ qubits can simulate $N=2^\\Gamma$ number of\nsites, in comparison to $N$ qubits for $N$ sites via the Jordan-Wigner\napproach. A two-band diatomic tight-binding model is used to demonstrate the\neffectiveness of the statevector basis representation. Both one-particle and\ntwo-particle quantum circuits are constructed and some numerical tests on IBM\nhardware are presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.15945v2",
    "published": "2025-05-21T19:02:16+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall",
      "cond-mat.other",
      "hep-lat",
      "nucl-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17124v1",
    "title": "On the Tameness of Power Series Space Pairs",
    "authors": [
      "Buket Can Bahadƒ±r"
    ],
    "abstract": "In this paper, it is shown that the tameness of the K\\\"othe space pair\n$(\\lambda^p(A),\\lambda^q(B))$ is determined solely by the tameness of the\nfamily of quasi-diagonal operators defined between the pair of spaces. We use\nthis tool to fill the gaps in characterization of pairs of power series spaces,\nadding to the previously established results of Dubinsky, Vogt, Nyberg and\netc., and summarize this complete characterization in Table 1. As a result, we\nalso show that the range of every continuous tame operator defined between\npower series spaces of infinite type has a basis.",
    "pdf_url": "http://arxiv.org/pdf/2505.17124v1",
    "published": "2025-05-21T19:01:11+00:00",
    "categories": [
      "math.FA",
      "46A04, 46A45, 46A61"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15944v1",
    "title": "Optimal Treatment Allocations Accounting for Population Differences",
    "authors": [
      "Wei Zhang",
      "Zhiwei Zhang",
      "Aiyi Liu"
    ],
    "abstract": "The treatment allocation mechanism in a randomized clinical trial can be\noptimized by maximizing the nonparametric efficiency bound for a specific\nmeasure of treatment effect. Optimal treatment allocations which may or may not\ndepend on baseline covariates have been derived for a variety of effect\nmeasures focusing on the trial population, the patient population represented\nby the trial participants. Frequently, clinical trial data are used to estimate\ntreatment effects in a target population that is related to but different from\nthe trial population. This article provides optimal treatment allocations that\naccount for the impact of such population differences. We consider three cases\nwith different data configurations: transportation, generalization, and\npost-stratification. Our results indicate that, for general effect measures,\noptimal treatment allocations may depend on the covariate distribution in the\ntarget population but not on the configuration of data or information that\ndescribes the target covariate distribution. For estimating average treatment\neffects, there is a unique covariate-dependent allocation that achieves maximal\nefficiency regardless of the target covariate distribution and the associated\ndata configuration.",
    "pdf_url": "http://arxiv.org/pdf/2505.15944v1",
    "published": "2025-05-21T19:00:46+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15943v3",
    "title": "Asymptotics of the spectral data of perturbed Stark operators in the half-line with mixed boundary conditions",
    "authors": [
      "Julio H. Toloza",
      "Alfredo Uribe"
    ],
    "abstract": "We obtain sharp asymptotic formulas for the eigenvalues and norming constants\nof Sturm-Liouville operators associated with the differential expression \\[\n-\\frac{d^2}{dx^2} + x + q(x), \\quad x\\in [0,\\infty), \\] together with the\nboundary condition $\\varphi'(0) - b\\varphi(0) =0$, $b\\in\\mathbb{R}$, where \\[\nq\\in \\left\\{ p\\in L^2_{\\mathbb{R}}(\\mathbb{R}_+,(1+x)^r dx) : p'\\in\nL^2_{\\mathbb{R}}(\\mathbb{R}_+,(1+x)^r dx)\\right\\} \\] with $r>1$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15943v3",
    "published": "2025-05-21T18:57:10+00:00",
    "categories": [
      "math.SP",
      "math-ph",
      "math.MP",
      "34E10, 34L15, 81Q05, 81Q10"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15942v1",
    "title": "Effects of symmetry and hydrodynamics on the cohesion of groups of swimmers",
    "authors": [
      "Mohamed Niged Mabrouk",
      "Daniel Floryan"
    ],
    "abstract": "When groups of inertial swimmers move together, hydrodynamic interactions\nplay a key role in shaping their collective dynamics, including the cohesion of\nthe group. To explore how these interactions influence group cohesion, we\ndevelop a three-dimensional, inviscid, far-field model of a swimmer. Focusing\non symmetric triangular, diamond, and circular group arrangements, we\ninvestigate whether passive hydrodynamics alone can promote cohesive behavior,\nand what role symmetry of the group plays. While small symmetric (and even\nasymmetric) groups can be cohesive, larger groups typically are not, instead\nbreaking apart into smaller, self-organized subgroups that are cohesive.\nNotably, we discover circular arrangements of swimmers that chase each other\naround a circle, resembling the milling behavior of natural fish schools; we\ncall this hydrodynamic milling. Hydrodynamic milling is cohesive in the sense\nthat it is a fixed point of a particular Poincar\\'e map, but it is unstable,\nespecially to asymmetric perturbations. Our findings suggest that while passive\nhydrodynamics alone cannot sustain large-scale cohesion indefinitely,\ncontrolling interactions between subgroups, or controlling the behavior of only\nthe periphery of a large group, could potentially enable stable collective\nbehavior with minimal active input.",
    "pdf_url": "http://arxiv.org/pdf/2505.15942v1",
    "published": "2025-05-21T18:55:53+00:00",
    "categories": [
      "physics.flu-dyn",
      "cond-mat.soft"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.15941v1",
    "title": "The Hydrodynamic Approach to Quantum Gravity",
    "authors": [
      "T. Banks"
    ],
    "abstract": "Several papers from the mid to late 1990s suggest that Einstein's equations\nshould be thought of as the hydrodynamic equations of a special class of\nquantum systems. A classical solution defines subsystems by dividing space-time\nup into CAUSAL DIAMONDS and Einstein's equations are the hydrodynamics of a\nsystem that assigns a density matrix to each diamond whose modular Hamiltonian\nK has expectation value and fluctuation both given by A/4G. A is the maximal\nd-2 volume on the boundary of the diamond and G is Newton's constant. These\nproperties define the EMPTY DIAMOND STATE, the analog of the quantum field\ntheory (QFT) vacuum, in the background geometry. The assignment of density\nmatrices to each diamond enables one to define the analog of half sided modular\nflow along geodesics in the background manifold, as a unitary embedding of the\nHilbert space of a given diamond into the next one in a nesting with Planck\nscale time steps. We conjecture that this can be enhanced to a full set of\ncompatible unitary evolutions on a Hilbert bundle of the space of time-like\ngeodesics, using a QUANTUM PRINCIPLE OF EQUIVALENCE defined in the text. The\ncompatibility of this formalism with the experimental success of QFT is\ndiscussed, as well as the theoretical mechanism by which QFT emerges from this\nversion of quantum gravity. This is a slightly expanded version of an essay\nthat won Honorable Mention in the Gravitation Research Essay Contest for 2025.",
    "pdf_url": "http://arxiv.org/pdf/2505.15941v1",
    "published": "2025-05-21T18:52:45+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15940v1",
    "title": "Degrees of Freedom for Critical Random 2-SAT",
    "authors": [
      "Andreas Basse-O'Connor",
      "Mette Skj√∏tt"
    ],
    "abstract": "The random $k$-SAT problem serves as a model that represents the 'typical'\n$k$-SAT instances. This model is thought to undergo a phase transition as the\nclause density changes, and it is believed that the random $k$-SAT problem is\nprimarily difficult to solve near this critical phase. In this paper, we\nintroduce a weak formulation of degrees of freedom for random $k$-SAT problems\nand demonstrate that the critical random $2$-SAT problem has $\\sqrt[3]{n}$\ndegrees of freedom. This quantity represents the maximum number of variables\nthat can be assigned truth values without affecting the formula's\nsatisfiability. Notably, the value of $\\sqrt[3]{n}$ differs significantly from\nthe degrees of freedom in random $2$-SAT problems sampled below the\nsatisfiability threshold, where the corresponding value equals $\\sqrt{n}$.\nThus, our result underscores the significant shift in structural properties and\nvariable dependency as satisfiability problems approach criticality.",
    "pdf_url": "http://arxiv.org/pdf/2505.15940v1",
    "published": "2025-05-21T18:51:57+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15939v1",
    "title": "Human Workload Prediction: Lag Horizon Selection",
    "authors": [
      "Mark-Robin Giolando",
      "Julie A. Adams"
    ],
    "abstract": "Human-robot teams must be aware of human workload when operating in\nuncertain, dynamic environments. Prior work employed physiological response\nmetrics from wearable sensors to estimate the current human workload; however,\nthese estimates only enable robots to respond to under- or overload conditions\nreactively. Current human workload prediction approaches are limited to short\nprediction horizons and fail to investigate variable lag horizons' impact on\npredictions. This letter investigates the impact of lag horizons on both\nunivariate and multivariate time series forecasting models for human workload\nprediction. A key finding is that univariate predictions required longer lag\nhorizons of 240 seconds (s), whereas multivariate workload predictions sufficed\nwith shorter lag horizons with diminishing returns around 120s.",
    "pdf_url": "http://arxiv.org/pdf/2505.15939v1",
    "published": "2025-05-21T18:51:38+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.03158v1",
    "title": "DUAL: Dynamic Uncertainty-Aware Learning",
    "authors": [
      "Jiahao Qin",
      "Bei Peng",
      "Feng Liu",
      "Guangliang Cheng",
      "Lu Zong"
    ],
    "abstract": "Deep learning models frequently encounter feature uncertainty in diverse\nlearning scenarios, significantly impacting their performance and reliability.\nThis challenge is particularly complex in multi-modal scenarios, where models\nmust integrate information from different sources with inherent uncertainties.\nWe propose Dynamic Uncertainty-Aware Learning (DUAL), a unified framework that\neffectively handles feature uncertainty in both single-modal and multi-modal\nscenarios. DUAL introduces three key innovations: Dynamic Feature Uncertainty\nModeling, which continuously refines uncertainty estimates through joint\nconsideration of feature characteristics and learning dynamics; Adaptive\nDistribution-Aware Modulation, which maintains balanced feature distributions\nthrough dynamic sample influence adjustment; and Uncertainty-aware Cross-Modal\nRelationship Learning, which explicitly models uncertainties in cross-modal\ninteractions. Through extensive experiments, we demonstrate DUAL's\neffectiveness across multiple domains: in computer vision tasks, it achieves\nsubstantial improvements of 7.1% accuracy on CIFAR-10, 6.5% accuracy on\nCIFAR-100, and 2.3% accuracy on Tiny-ImageNet; in multi-modal learning, it\ndemonstrates consistent gains of 4.1% accuracy on CMU-MOSEI and 2.8% accuracy\non CMU-MOSI for sentiment analysis, while achieving 1.4% accuracy improvements\non MISR. The code will be available on GitHub soon.",
    "pdf_url": "http://arxiv.org/pdf/2506.03158v1",
    "published": "2025-05-21T18:50:15+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15938v1",
    "title": "The Batalin-Vilkovisky formalism in noncommutative effective field theory",
    "authors": [
      "Alastair Hamilton"
    ],
    "abstract": "We address the treatment of gauge theories within the framework that is\nformed from combining the machinery of noncommutative symplectic geometry, as\nintroduced by Kontsevich, with Costello's approach to effective gauge field\ntheories within the Batalin-Vilkovisky formalism; discussing the problem of\nquantization in this context, and identifying the relevant cohomology theory\ncontrolling this process. We explain how the resulting noncommutative effective\ngauge field theories produce classes in a compactification of the moduli space\nof Riemann surfaces, when we pass to the large length scale limit. Within this\nsetting, the large $N$ correspondence of 't Hooft -- describing a connection\nbetween open string theories and gauge theories -- appears as a relation\nbetween the noncommutative and commutative geometries. We use this\ncorrespondence to investigate and ultimately quantize a noncommutative analogue\nof Chern-Simons theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.15938v1",
    "published": "2025-05-21T18:49:45+00:00",
    "categories": [
      "math.QA",
      "hep-th",
      "81T12, 81T13, 81T15, 81T30, 81T35, 81T70, 81T75"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15937v2",
    "title": "A generic threshold phenomena in weighted $\\ell^2$",
    "authors": [
      "Adem Limani"
    ],
    "abstract": "We consider threshold phenomenons in the context of weighted $\\ell^2$-spaces.\nOur main result is a summable Baire category version of K\\\"orner's topological\nIvashev-Musatov Theorem, which is proved to be optimal from several aspects.",
    "pdf_url": "http://arxiv.org/pdf/2505.15937v2",
    "published": "2025-05-21T18:47:50+00:00",
    "categories": [
      "math.FA",
      "math.CA",
      "42A16, 42A55"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15936v2",
    "title": "Self-heating electrochemical memory for high-precision analog computing",
    "authors": [
      "Adam L. Gross",
      "Sangheon Oh",
      "Fran√ßois L√©onard",
      "Wyatt Hodges",
      "T. Patrick Xiao",
      "Joshua D. Sugar",
      "Jacklyn Zhu",
      "Sritharini Radhakrishnan",
      "Sangyong Lee",
      "Jolie Wang",
      "Adam Christensen",
      "Sam Lilak",
      "Patrick S. Finnegan",
      "Patrick Crandall",
      "Christopher H. Bennett",
      "William Wahby",
      "Robin Jacobs-Gedrim",
      "Matthew J. Marinella",
      "Suhas Kumar",
      "Sapan Agarwal",
      "Yiyang Li",
      "A. Alec Talin",
      "Elliot J. Fuller"
    ],
    "abstract": "Analog computers hold promise to significantly reduce the energy consumption\nof artificial intelligence algorithms, but commercialization has been hampered\nby a fundamental scientific challenge - how to reliably store and process\nanalog information with high precision. We present an approach based upon metal\noxide memory cells that undergo controlled self-heating during programming with\na newly developed, electro-thermo-chemical gate. The gate uniformly spreads\nheat and electrochemical reactions to enable wide, bulk-vacancy modulation\nwhich yields nine orders of magnitude in tunable analog resistance - three\norders greater than other devices reported, with thousands of states. The\ngating profoundly reduces noise and drift to enable precision programming to\ntargeted states within a few operations, lowering conductance errors by two\norders of magnitude relative to other devices reported. Simulations show\nimprovement in computational energy efficiency by at least 10x over other\ndevices due to far greater scalability at higher precision. The results\noverturn long-held assumptions about the poor reliability and precision of\nanalog resistance devices and opens the door to manufacturable, bulk\nmetal-oxide devices and new applications that leverage high precision.",
    "pdf_url": "http://arxiv.org/pdf/2505.15936v2",
    "published": "2025-05-21T18:44:10+00:00",
    "categories": [
      "cs.ET",
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.15935v2",
    "title": "MAPS: A Multilingual Benchmark for Global Agent Performance and Security",
    "authors": [
      "Omer Hofman",
      "Jonathan Brokman",
      "Oren Rachmil",
      "Shamik Bose",
      "Vikas Pahuja",
      "Toshiya Shimizu",
      "Trisha Starostina",
      "Kelly Marchisio",
      "Seraphina Goldfarb-Tarrant",
      "Roman Vainshtein"
    ],
    "abstract": "Agentic AI systems, which build on Large Language Models (LLMs) and interact\nwith tools and memory, have rapidly advanced in capability and scope. Yet,\nsince LLMs have been shown to struggle in multilingual settings, typically\nresulting in lower performance and reduced safety, agentic systems risk\ninheriting these limitations. This raises concerns about the accessibility of\nsuch systems, as users interacting in languages other than English may\nencounter unreliable or security-critical agent behavior. Despite growing\ninterest in evaluating agentic AI, existing benchmarks focus exclusively on\nEnglish, leaving multilingual settings unexplored. To address this gap, we\npropose MAPS, a multilingual benchmark suite designed to evaluate agentic AI\nsystems across diverse languages and tasks. MAPS builds on four widely used\nagentic benchmarks - GAIA (real-world tasks), SWE-bench (code generation), MATH\n(mathematical reasoning), and the Agent Security Benchmark (security). We\ntranslate each dataset into eleven diverse languages, resulting in 805 unique\ntasks and 9,660 total language-specific instances - enabling a systematic\nanalysis of the multilingual effect on AI agents' performance and robustness.\nEmpirically, we observe degradation in both performance and security when\ntransitioning from English to other languages, with severity varying by task\nand correlating with the amount of translated input. Building on these\nfindings, we provide actionable recommendations to guide agentic AI systems\ndevelopment and assessment under multilingual settings. This work establishes\nthe first standardized evaluation framework for multilingual agentic AI,\nencouraging future research towards equitable, reliable, and accessible agentic\nAI. MAPS benchmark suite is publicly available at\nhttps://huggingface.co/datasets/Fujitsu-FRE/MAPS",
    "pdf_url": "http://arxiv.org/pdf/2505.15935v2",
    "published": "2025-05-21T18:42:00+00:00",
    "categories": [
      "cs.DB",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.15934v1",
    "title": "Improving the Predictability of the Madden-Julian Oscillation at Subseasonal Scales with Gaussian Process Models",
    "authors": [
      "Haoyuan Chen",
      "Emil Constantinescu",
      "Vishwas Rao",
      "Cristiana Stan"
    ],
    "abstract": "The Madden--Julian Oscillation (MJO) is an influential climate phenomenon\nthat plays a vital role in modulating global weather patterns. In spite of the\nimprovement in MJO predictions made by machine learning algorithms, such as\nneural networks, most of them cannot provide the uncertainty levels in the MJO\nforecasts directly. To address this problem, we develop a nonparametric\nstrategy based on Gaussian process (GP) models. We calibrate GPs using\nempirical correlations and we propose a posteriori covariance correction.\nNumerical experiments demonstrate that our model has better prediction skills\nthan the ANN models for the first five lead days. Additionally, our posteriori\ncovariance correction extends the probabilistic coverage by more than three\nweeks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15934v1",
    "published": "2025-05-21T18:40:40+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.ao-ph",
      "stat.ML"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15933v1",
    "title": "Phonon, Infrared and Raman Spectra of LiGa5O8 from Density Functional Perturbation Theory",
    "authors": [
      "Sarker Md. Sadman",
      "Walter R. L. Lambrecht"
    ],
    "abstract": "LiGa$_5$O$_8$ with a cubic spinel type structure was recently reported to be\na ultra-wide-band-gap semiconductor with unintentional p-type conduction. While\nthe origin of p-type doping is still unclear, the fundamental properties of\nthis material are of interest. Here we present a first-principles study of the\nphonons using density functional perturbation theory. The phonon band\nstructures show no unstable modes verifying the stability of the structure. We\nfocus mainly on the phonons at the Brillouin zone center for which a full\nsymmetry analysis is presented. We present the dielectric function\ncontributions from the infrared active modes as well as the Raman spectra and\ntheir polarization dependence. The phonon density of states integrated over the\nBrillouin zone is also presented as this may related to disordered Raman\nspectra.",
    "pdf_url": "http://arxiv.org/pdf/2505.15933v1",
    "published": "2025-05-21T18:38:55+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15932v1",
    "title": "Constant-Sum High-Order Barrier Functions for Safety Between Parallel Boundaries",
    "authors": [
      "Kwang Hak Kim",
      "Mamadou Diagne",
      "Miroslav Krstiƒá"
    ],
    "abstract": "This paper takes a step towards addressing the difficulty of constructing\nControl Barrier Functions (CBFs) for parallel safety boundaries. A single CBF\nfor both boundaries has been reported to be difficult to validate for safety,\nand we identify why this challenge is inherent. To overcome this, the proposed\nmethod constructs separate CBFs for each boundary. We begin by presenting\nresults for the relative degree one case and then extend these to higher\nrelative degrees using the CBF backstepping technique, establishing conditions\nthat guarantee safety. Finally, we showcase our method by applying it to a\nunicycle system, deriving a simple, verifiable condition to validate the target\nCBFs for direct implementation of our results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15932v1",
    "published": "2025-05-21T18:36:44+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15931v1",
    "title": "AllMetrics: A Unified Python Library for Standardized Metric Evaluation and Robust Data Validation in Machine Learning",
    "authors": [
      "Morteza Alizadeh",
      "Mehrdad Oveisi",
      "Sonya Falahati",
      "Ghazal Mousavi",
      "Mohsen Alambardar Meybodi",
      "Somayeh Sadat Mehrnia",
      "Ilker Hacihaliloglu",
      "Arman Rahmim",
      "Mohammad R. Salmanpour"
    ],
    "abstract": "Machine learning (ML) models rely heavily on consistent and accurate\nperformance metrics to evaluate and compare their effectiveness. However,\nexisting libraries often suffer from fragmentation, inconsistent\nimplementations, and insufficient data validation protocols, leading to\nunreliable results. Existing libraries have often been developed independently\nand without adherence to a unified standard, particularly concerning the\nspecific tasks they aim to support. As a result, each library tends to adopt\nits conventions for metric computation, input/output formatting, error\nhandling, and data validation protocols. This lack of standardization leads to\nboth implementation differences (ID) and reporting differences (RD), making it\ndifficult to compare results across frameworks or ensure reliable evaluations.\nTo address these issues, we introduce AllMetrics, an open-source unified Python\nlibrary designed to standardize metric evaluation across diverse ML tasks,\nincluding regression, classification, clustering, segmentation, and\nimage-to-image translation. The library implements class-specific reporting for\nmulti-class tasks through configurable parameters to cover all use cases, while\nincorporating task-specific parameters to resolve metric computation\ndiscrepancies across implementations. Various datasets from domains like\nhealthcare, finance, and real estate were applied to our library and compared\nwith Python, Matlab, and R components to identify which yield similar results.\nAllMetrics combines a modular Application Programming Interface (API) with\nrobust input validation mechanisms to ensure reproducibility and reliability in\nmodel evaluation. This paper presents the design principles, architectural\ncomponents, and empirical analyses demonstrating the ability to mitigate\nevaluation errors and to enhance the trustworthiness of ML workflows.",
    "pdf_url": "http://arxiv.org/pdf/2505.15931v1",
    "published": "2025-05-21T18:36:05+00:00",
    "categories": [
      "cs.LG",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15930v1",
    "title": "Simulating random variates from the Pearson IV and betaized Meixner-Morris distributions",
    "authors": [
      "Luc Devroye",
      "Joe R. Hill"
    ],
    "abstract": "We develop uniformly fast random variate generators for the Pearson IV\ndistribution that can be used over the entire range of both shape parameters.\nAdditionally, we derive an efficient algorithm for sampling from the betaized\nMeixner-Morris density, which is proportional to the product of two generalized\nhyperbolic secant densities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15930v1",
    "published": "2025-05-21T18:35:45+00:00",
    "categories": [
      "stat.CO",
      "G3, I6"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15929v2",
    "title": "PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?",
    "authors": [
      "Hui Shen",
      "Taiqiang Wu",
      "Qi Han",
      "Yunta Hsieh",
      "Jizhou Wang",
      "Yuyue Zhang",
      "Yuxin Cheng",
      "Zijian Hao",
      "Yuansheng Ni",
      "Xin Wang",
      "Zhongwei Wan",
      "Kai Zhang",
      "Wendong Xu",
      "Jing Xiong",
      "Ping Luo",
      "Wenhu Chen",
      "Chaofan Tao",
      "Zhuoqing Mao",
      "Ngai Wong"
    ],
    "abstract": "Existing benchmarks fail to capture a crucial aspect of intelligence:\nphysical reasoning, the integrated ability to combine domain knowledge,\nsymbolic reasoning, and understanding of real-world constraints. To address\nthis gap, we introduce PhyX: the first large-scale benchmark designed to assess\nmodels capacity for physics-grounded reasoning in visual scenarios. PhyX\nincludes 3K meticulously curated multimodal questions spanning 6 reasoning\ntypes across 25 sub-domains and 6 core physics domains: thermodynamics,\nelectromagnetism, mechanics, modern physics, optics, and wave\\&acoustics. In\nour comprehensive evaluation, even state-of-the-art models struggle\nsignificantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and\nGPT-o4-mini achieve only 32.5%, 42.2%, and 45.8% accuracy\nrespectively-performance gaps exceeding 29% compared to human experts. Our\nanalysis exposes critical limitations in current models: over-reliance on\nmemorized disciplinary knowledge, excessive dependence on mathematical\nformulations, and surface-level visual pattern matching rather than genuine\nphysical understanding. We provide in-depth analysis through fine-grained\nstatistics, detailed case studies, and multiple evaluation paradigms to\nthoroughly examine physical reasoning capabilities. To ensure reproducibility,\nwe implement a compatible evaluation protocol based on widely-used toolkits\nsuch as VLMEvalKit, enabling one-click evaluation. More details are available\non our project page: https://phyx-bench.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.15929v2",
    "published": "2025-05-21T18:33:50+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15928v1",
    "title": "ViQAgent: Zero-Shot Video Question Answering via Agent with Open-Vocabulary Grounding Validation",
    "authors": [
      "Tony Montes",
      "Fernando Lozano"
    ],
    "abstract": "Recent advancements in Video Question Answering (VideoQA) have introduced\nLLM-based agents, modular frameworks, and procedural solutions, yielding\npromising results. These systems use dynamic agents and memory-based mechanisms\nto break down complex tasks and refine answers. However, significant\nimprovements remain in tracking objects for grounding over time and\ndecision-making based on reasoning to better align object references with\nlanguage model outputs, as newer models get better at both tasks. This work\npresents an LLM-brained agent for zero-shot Video Question Answering (VideoQA)\nthat combines a Chain-of-Thought framework with grounding reasoning alongside\nYOLO-World to enhance object tracking and alignment. This approach establishes\na new state-of-the-art in VideoQA and Video Understanding, showing enhanced\nperformance on NExT-QA, iVQA, and ActivityNet-QA benchmarks. Our framework also\nenables cross-checking of grounding timeframes, improving accuracy and\nproviding valuable support for verification and increased output reliability\nacross multiple video domains. The code is available at\nhttps://github.com/t-montes/viqagent.",
    "pdf_url": "http://arxiv.org/pdf/2505.15928v1",
    "published": "2025-05-21T18:32:43+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "I.4.8"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.13994v1",
    "title": "Detection, attribution, and modeling of climate change: key open issues",
    "authors": [
      "Nicola Scafetta"
    ],
    "abstract": "The CMIP global climate models (GCMs) assess that nearly 100% of global\nsurface warming observed between 1850-1900 and 2011-2020 is attributable to\nanthropogenic drivers like greenhouse gas emissions. These models also generate\nfuture climate projections based on shared socioeconomic pathways (SSPs),\naiding in risk assessment and the development of costly Net-Zero climate\nmitigation strategies. Yet, the CMIP GCMs face significant scientific\nchallenges in attributing and modeling climate change, particularly in\ncapturing natural climate variability over multiple timescales throughout the\nHolocene. Other key concerns include the reliability of global surface\ntemperature records, the accuracy of solar irradiance models, and the\nrobustness of climate sensitivity estimates. Global warming estimates may be\noverstated due to uncorrected non-climatic biases, and the GCMs may\nsignificantly underestimate solar and astronomical influences on climate\nvariations. The equilibrium climate sensitivity (ECS) to radiative forcing\ncould be lower than commonly assumed; empirical findings suggest ECS values\nlower than 3 K and possibly even closer to 1.1 +/- 0.4 K. Empirical models\nincorporating natural variability suggest that the 21st-century global warming\nmay remain moderate, even under SSP scenarios that do not necessitate Net-Zero\nemission policies. These findings raise important questions regarding the\nnecessity and urgency of implementing aggressive climate mitigation strategies.\nWhile GCMs remain essential tools for climate research and policymaking, their\nscientific limitations underscore the need for more refined modeling approaches\nto ensure accurate future climate assessments. Addressing uncertainties related\nto climate change detection, natural variability, solar influences, and climate\nsensitivity to radiative forcing will enhance predictions and better inform\nsustainable climate strategies.",
    "pdf_url": "http://arxiv.org/pdf/2506.13994v1",
    "published": "2025-05-21T18:31:14+00:00",
    "categories": [
      "physics.soc-ph",
      "physics.ao-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15927v1",
    "title": "CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision",
    "authors": [
      "Awni Altabaa",
      "Omar Montasser",
      "John Lafferty"
    ],
    "abstract": "Learning complex functions that involve multi-step reasoning poses a\nsignificant challenge for standard supervised learning from input-output\nexamples. Chain-of-thought (CoT) supervision, which provides intermediate\nreasoning steps together with the final output, has emerged as a powerful\nempirical technique, underpinning much of the recent progress in the reasoning\ncapabilities of large language models. This paper develops a statistical theory\nof learning under CoT supervision. A key characteristic of the CoT setting, in\ncontrast to standard supervision, is the mismatch between the training\nobjective (CoT risk) and the test objective (end-to-end risk). A central part\nof our analysis, distinguished from prior work, is explicitly linking those two\ntypes of risk to achieve sharper sample complexity bounds. This is achieved via\nthe *CoT information measure* $\\mathcal{I}_{\\mathcal{D},\nh_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, which quantifies the additional\ndiscriminative power gained from observing the reasoning process. The main\ntheoretical results demonstrate how CoT supervision can yield significantly\nfaster learning rates compared to standard E2E supervision. Specifically, it is\nshown that the sample complexity required to achieve a target E2E error\n$\\epsilon$ scales as $d/\\mathcal{I}_{\\mathcal{D},\nh_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, where $d$ is a measure of hypothesis\nclass complexity, which can be much faster than standard $d/\\epsilon$ rates.\nInformation-theoretic lower bounds in terms of the CoT information are also\nobtained. Together, these results suggest that CoT information is a fundamental\nmeasure of statistical complexity for learning under chain-of-thought\nsupervision.",
    "pdf_url": "http://arxiv.org/pdf/2505.15927v1",
    "published": "2025-05-21T18:28:54+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15926v2",
    "title": "Ideal Gas Law for a Quantum Particle",
    "authors": [
      "Alejandro M. F Rivas",
      "Eduardo G. Vergini",
      "Leonardo Ermann",
      "Gabriel G. Carlo"
    ],
    "abstract": "The question of how classical thermodynamic laws emerge from the underlying\nquantum substrate lies at the foundations of physics. Here, we examine the\nvalidity of the ideal gas law (IGL) for a single quantum particle confined\nwithin a two-dimensional cavity. By interpreting the quantum wave function as a\nprobability density analogous to that of an ideal gas, we employ the energy\nequipartition principle to define the temperature of the quantum state. For the\nmean pressure we take two definitions, one straightforwardly based on the\nradiation pressure concept and the other taking advantage of a\nquasi-orthogonality relation valid for billiard eigenstates. We analyze systems\nwith regular dynamics-the circular and rectangular billiards-and compare them\nwith the classically chaotic Bunimovich stadium. We find that the IGL for the\nfirst definition of pressure holds exactly in isotropic systems (as the\ncircular case), while for anisotropic geometries, quantum eigenfunctions\ngenerally conform to the IGL only on average, exhibiting meaningful deviations.\nThese deviations are diminished in the presence of chaotic dynamics and for\ncoherent states. This observation is consistent with the Eigenstate\nThermalization Hypothesis (ETH). Notably, the second definition of pressure\nallows for a good matching with the IGL.",
    "pdf_url": "http://arxiv.org/pdf/2505.15926v2",
    "published": "2025-05-21T18:25:35+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15925v2",
    "title": "VERDI: VLM-Embedded Reasoning for Autonomous Driving",
    "authors": [
      "Bowen Feng",
      "Zhiting Mei",
      "Baiang Li",
      "Julian Ost",
      "Roger Girgis",
      "Anirudha Majumdar",
      "Felix Heide"
    ],
    "abstract": "While autonomous driving (AD) stacks struggle with decision making under\npartial observability and real-world complexity, human drivers are capable of\ncommonsense reasoning to make near-optimal decisions with limited information.\nRecent work has attempted to leverage finetuned Vision-Language Models (VLMs)\nfor trajectory planning at inference time to emulate human behavior. Despite\ntheir success in benchmark evaluations, these methods are often impractical to\ndeploy (a 70B parameter VLM inference at merely 8 tokens per second requires\nmore than 160G of memory), and their monolithic network structure prohibits\nsafety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for\nautonomous Driving (VERDI), a training-time framework that distills the\nreasoning process and commonsense knowledge of VLMs into the AD stack. VERDI\naugments modular differentiable end-to-end (e2e) AD models by aligning\nintermediate module outputs at the perception, prediction, and planning stages\nwith text features explaining the driving reasoning process produced by VLMs.\nBy encouraging alignment in latent space, VERDI enables the modular AD stack to\ninternalize structured reasoning, without incurring the inference-time costs of\nlarge VLMs. We demonstrate the effectiveness of our method on the NuScenes\ndataset and find that VERDI outperforms existing e2e methods that do not embed\nreasoning by 10% in $\\ell_{2}$ distance, while maintaining high inference\nspeed.",
    "pdf_url": "http://arxiv.org/pdf/2505.15925v2",
    "published": "2025-05-21T18:24:36+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15924v1",
    "title": "Chemical Abundances in the Milky Way's Nuclear Stellar Disc",
    "authors": [
      "N. Ryde",
      "G. Nandakumar",
      "R. Albarracin",
      "M. Schultheis",
      "A. Rojas-Arriagada",
      "M. Zoccali"
    ],
    "abstract": "The Nuclear Stellar Disc (NSD) is a rotating, disc-like structure in the\nGalactic Center, believed to have a distinct star formation. However, its\nformation history and evolutionary links to other structures in the Galactic\nCenter remain uncertain. This study aims to present the first comprehensive\nchemical census of the NSD by deriving abundance trends for 18 elements in 9 M\ngiants in the metallicity range of -1.0 <[Fe/H]< 0.5. By comparing these trends\nwith those of other Galactic populations we seek to understand the chemical\nrelationships between these structures. We obtained high-resolution H- and\nK-band spectra of NSD stars using the IGRINS spectrometer mounted on the Gemini\nSouth telescope. The giants were analyzed consistently with stars from a\ncomparison populations to minimize systematic uncertainties. The abundance\ntrends of NSD stars exhibit similarities with those of the inner-bulge and\nNuclear Star Cluster (NSC) populations across a broad range of elements with\ndifferent chemical evolution histories. The trends for 17 elements align\nclosely with the local thick-disc behaviour at subsolar metallicities. At\nsuper-solar metallicities, most elements follow the NSC and inner-bulge trends.\nSodium is the only element exhibiting a distinct trend, with enhanced\nabundances in the NSD and NSC compared to both thin-disc and inner-bulge stars.\nThe chemical similarity suggests that the NSD likely shares an evolutionary\nhistory with the NSC and possibly the inner-disc sequence. Further studies are\nrequired to determine potential evolutionary links to Liller 1 and metal-rich\nglobular clusters. We find no evidence of typical globular cluster abundance\nsignatures in our NSD stars with subsolar metallicities. Our study demonstrates\nthe feasibility of obtaining high-quality abundance data even in highly\ndust-obscured regions of the Milky Way, paving the way for future surveys.",
    "pdf_url": "http://arxiv.org/pdf/2505.15924v1",
    "published": "2025-05-21T18:24:30+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15923v1",
    "title": "Discovery and characterization of 25 new quasars at 4.6 < z < 6.9 from wide-field multi-band surveys",
    "authors": [
      "Silvia Belladitta",
      "Eduardo Ba√±ados",
      "Zhang-Liang Xie",
      "Roberto Decarli",
      "Silvia Onorato",
      "Jinyi Yang",
      "Manuela Bischetti",
      "Masafusa Onoue",
      "Federica Loiacono",
      "Laura N. Mart√≠nez-Ram√≠rez",
      "Chiara Mazzucchelli",
      "Frederick B. Davies",
      "Julien Wolf",
      "Jan-Torge Schindler",
      "Xiaohui Fan",
      "Feige Wang",
      "Fabian Walter",
      "Tatevik Mkrtchyan",
      "Daniel Stern",
      "Emanuele P. Farina",
      "Bram P. Venemans"
    ],
    "abstract": "Luminous quasars at $z>4$ provide key insights into the early Universe. Their\nrarity necessitates wide-field multi-band surveys to efficiently separate them\nfrom the main astrophysical contaminants (i.e., ultracool dwarfs). To expand\nthe sample of high-$z$ quasars, we conducted targeted selections using optical,\ninfrared, and radio surveys, complemented by literature-based quasar candidate\ncatalogs. In this paper, we report the discovery of \\nqsos\\ new quasars at\n$4.6<z<6.9$ (six at $z\\geq6.5$), with $M_{1450}$ between $-$25.4 and $-$27.0.\nWe also present new spectra of six $z>6.5$ quasars we selected, but whose\nindependent discovery has already been published in the literature. Three of\nthe newly discovered quasars are strong radio emitters (L$_{1.4~\\rm\nGHz}$$=0.09-1.0\\times$10$^{34}$erg s$^{-1}$ Hz$^{-1}$). Among them, one source\nat $z=4.71$ exhibits typical blazar-like properties, including a flat radio\nspectrum, radio-loudness $\\sim$1000, and multi-frequency variability. It is\nalso detected by SRG/eROSITA X-ray telescope (f$_{\\rm 0.2-2.3keV} \\sim\n1.3\\times10^{-13}$erg s$^{-1}$ cm$^{-2}$). In addition, for seven $6.3<z<6.9$\nquasars we present near-infrared spectroscopy and estimate the central black\nhole mass from their C$\\rm IV$ and Mg$\\rm II$ broad emission lines.Their masses\n(log[M$_{\\rm BH,MgII}$]$=8.58-9.14~\\rm M_{\\odot}$) and Eddington ratios\n($\\lambda_{\\rm Edd,MgII}=0.74-2.2$) are consistent with other $z>6$ quasars\nreported in the literature. A $z = 6.3$ quasar exhibits a velocity difference\nof approximately $9000$ km s$^{-1}$ between the C$\\rm IV$ and Mg$\\rm II$\nemission lines, making it one of the most extreme C$\\rm IV$ outflows currently\nknown. Additionally, the sample includes three high-ionization broad absorption\nline quasars. One of these quasars shows potential evidence of an extremely\nfast outflow feature, reaching $48000$ km s$^{-1}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15923v1",
    "published": "2025-05-21T18:20:06+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15922v1",
    "title": "Aligning Dialogue Agents with Global Feedback via Large Language Model Reward Decomposition",
    "authors": [
      "Dong Won Lee",
      "Hae Won Park",
      "Cynthia Breazeal",
      "Louis-Philippe Morency"
    ],
    "abstract": "We propose a large language model based reward decomposition framework for\naligning dialogue agents using only a single session-level feedback signal. We\nleverage the reasoning capabilities of a frozen, pretrained large language\nmodel (LLM) to infer fine-grained local implicit rewards by decomposing global,\nsession-level feedback. Our first text-only variant prompts the LLM to perform\nreward decomposition using only the dialogue transcript. The second multimodal\nvariant incorporates additional behavioral cues, such as pitch, gaze, and\nfacial affect, expressed as natural language descriptions. These inferred\nturn-level rewards are distilled into a lightweight reward model, which we\nutilize for RL-based fine-tuning for dialogue generation. We evaluate both\ntext-only and multimodal variants against state-of-the-art reward decomposition\nmethods and demonstrate notable improvements in human evaluations of\nconversation quality, suggesting that LLMs are strong reward decomposers that\nobviate the need for manual reward shaping and granular human feedback.",
    "pdf_url": "http://arxiv.org/pdf/2505.15922v1",
    "published": "2025-05-21T18:19:45+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15921v1",
    "title": "Defining Atomicity (and Integrity) for Snapshots of Storage in Forensic Computing",
    "authors": [
      "Jenny Ottmann",
      "Frank Breitinger",
      "Felix Freiling"
    ],
    "abstract": "The acquisition of data from main memory or from hard disk storage is usually\none of the first steps in a forensic investigation. We revisit the discussion\non quality criteria for \"forensically sound\" acquisition of such storage and\npropose a new way to capture the intent to acquire an instantaneous snapshot\nfrom a single target system. The idea of our definition is to allow a certain\nflexibility into when individual portions of memory are acquired, but at the\nsame time require being consistent with causality (i.e., cause/effect\nrelations). Our concept is much stronger than the original notion of atomicity\ndefined by Vomel and Freiling (2012) but still attainable using copy-on-write\nmechanisms. As a minor result, we also fix a conceptual problem within the\noriginal definition of integrity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15921v1",
    "published": "2025-05-21T18:19:24+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15920v1",
    "title": "Quantum Calabi-Yau Black Holes and Non-Perturbative D0-brane Effects",
    "authors": [
      "Alberto Castellano",
      "Dieter L√ºst",
      "Carmine Montella",
      "Matteo Zatti"
    ],
    "abstract": "We compute the supersymmetric entropy of the most general BPS black hole in\n4d $\\mathcal{N}=2$ supergravity coupled to $n_V$ vector multiplets obtained\nfrom Type IIA string theory compactified on a Calabi-Yau threefold at large\nvolume, including the all-genera leading-order $\\alpha'$-corrections. These can\nbe equivalently seen as D0-brane quantum effects from a dual five-dimensional\nM-theory perspective. We find that these corrections generically lead to both\nperturbative and non-perturbative contributions to the black hole entropy. We\nargue that the exception occurs for certain specific configurations where the\ngauge background, seen through the lens of D0-brane probes, behaves as purely\nelectric or purely magnetic, thereby accounting for the absence of such\nnon-perturbative effects. To explore this further, we perform a semiclassical\nanalysis of the (non-)BPS particle dynamics in the near-horizon geometry of the\nunderlying black hole, which is described by a maximally supersymmetric\nAdS$_2\\times \\mathbf{S}^2$ solution. As a byproduct, this study provides\nadditional insights into the (non-perturbative) stability of supersymmetric\nblack hole solutions and suggests an interpretation in terms of complex saddles\ncontributing to the worldline path integral.",
    "pdf_url": "http://arxiv.org/pdf/2505.15920v1",
    "published": "2025-05-21T18:18:42+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15919v1",
    "title": "Mitigating cosmic ray-like correlated events with a modular quantum processor",
    "authors": [
      "Xuntao Wu",
      "Yash J. Joshi",
      "Haoxiong Yan",
      "Gustav Andersson",
      "Alexander Anferov",
      "Christopher R. Conner",
      "Bayan Karimi",
      "Amber M. King",
      "Shiheng Li",
      "Howard L. Malc",
      "Jacob M. Miller",
      "Harsh Mishra",
      "Hong Qiao",
      "Minseok Ryu",
      "Siyuan Xing",
      "Jian Shi",
      "Andrew N. Cleland"
    ],
    "abstract": "Quantum processors based on superconducting qubits are being scaled to larger\nqubit numbers, enabling the implementation of small-scale quantum error\ncorrection codes. However, catastrophic chip-scale correlated errors have been\nobserved in these processors, attributed to e.g. cosmic ray impacts, which\nchallenge conventional error-correction codes such as the surface code. These\nevents are characterized by a temporary but pronounced suppression of the qubit\nenergy relaxation times. Here, we explore the potential for modular quantum\ncomputing architectures to mitigate such correlated energy decay events. We\nmeasure cosmic ray-like events in a quantum processor comprising a motherboard\nand two flip-chip bonded daughterboard modules, each module containing two\nsuperconducting qubits. We monitor the appearance of correlated qubit decay\nevents within a single module and across the physically separated modules. We\nfind that while decay events within one module are strongly correlated (over\n$85\\%$), events in separate modules only display $\\sim 2\\%$ correlations. We\nalso report coincident decay events in the motherboard and in either of the two\ndaughterboard modules, providing further insight into the nature of these decay\nevents. These results suggest that modular architectures, combined with bespoke\nerror correction codes, offer a promising approach for protecting future\nquantum processors from chip-scale correlated errors.",
    "pdf_url": "http://arxiv.org/pdf/2505.15919v1",
    "published": "2025-05-21T18:16:06+00:00",
    "categories": [
      "quant-ph",
      "hep-ex"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15918v2",
    "title": "Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization",
    "authors": [
      "Aliakbar Nafar",
      "Kristen Brent Venable",
      "Zijun Cui",
      "Parisa Kordjamshidi"
    ],
    "abstract": "In this work, we evaluate the potential of Large Language Models (LLMs) in\nbuilding Bayesian Networks (BNs) by approximating domain expert priors. LLMs\nhave demonstrated potential as factual knowledge bases; however, their\ncapability to generate probabilistic knowledge about real-world events remains\nunderstudied. We explore utilizing the probabilistic knowledge inherent in LLMs\nto derive probability estimates for statements regarding events and their\nrelationships within a BN. Using LLMs in this context allows for the\nparameterization of BNs, enabling probabilistic modeling within specific\ndomains. Our experiments on eighty publicly available Bayesian Networks, from\nhealthcare to finance, demonstrate that querying LLMs about the conditional\nprobabilities of events provides meaningful results when compared to baselines,\nincluding random and uniform distributions, as well as approaches based on\nnext-token generation probabilities. We explore how these LLM-derived\ndistributions can serve as expert priors to refine distributions extracted from\ndata, especially when data is scarce. Overall, this work introduces a promising\nstrategy for automatically constructing Bayesian Networks by combining\nprobabilistic knowledge extracted from LLMs with real-world data. Additionally,\nwe establish the first comprehensive baseline for assessing LLM performance in\nextracting probabilistic knowledge.",
    "pdf_url": "http://arxiv.org/pdf/2505.15918v2",
    "published": "2025-05-21T18:15:05+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15917v1",
    "title": "How to factor 2048 bit RSA integers with less than a million noisy qubits",
    "authors": [
      "Craig Gidney"
    ],
    "abstract": "Planning the transition to quantum-safe cryptosystems requires understanding\nthe cost of quantum attacks on vulnerable cryptosystems. In Gidney+Eker{\\aa}\n2019, I co-published an estimate stating that 2048 bit RSA integers could be\nfactored in eight hours by a quantum computer with 20 million noisy qubits. In\nthis paper, I substantially reduce the number of qubits required. I estimate\nthat a 2048 bit RSA integer could be factored in less than a week by a quantum\ncomputer with less than a million noisy qubits. I make the same assumptions as\nin 2019: a square grid of qubits with nearest neighbor connections, a uniform\ngate error rate of $0.1\\%$, a surface code cycle time of 1 microsecond, and a\ncontrol system reaction time of $10$ microseconds.\n  The qubit count reduction comes mainly from using approximate residue\narithmetic (Chevignard+Fouque+Schrottenloher 2024), from storing idle logical\nqubits with yoked surface codes (Gidney+Newman+Brooks+Jones 2023), and from\nallocating less space to magic state distillation by using magic state\ncultivation (Gidney+Shutty+Jones 2024). The longer runtime is mainly due to\nperforming more Toffoli gates and using fewer magic state factories compared to\nGidney+Eker{\\aa} 2019. That said, I reduce the Toffoli count by over 100x\ncompared to Chevignard+Fouque+Schrottenloher 2024.",
    "pdf_url": "http://arxiv.org/pdf/2505.15917v1",
    "published": "2025-05-21T18:11:44+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15916v1",
    "title": "BR-TaxQA-R: A Dataset for Question Answering with References for Brazilian Personal Income Tax Law, including case law",
    "authors": [
      "Juvenal Domingos J√∫nior",
      "Augusto Faria",
      "E. Seiti de Oliveira",
      "Erick de Brito",
      "Matheus Teotonio",
      "Andre Assump√ß√£o",
      "Diedre Carmo",
      "Roberto Lotufo",
      "Jayr Pereira"
    ],
    "abstract": "This paper presents BR-TaxQA-R, a novel dataset designed to support question\nanswering with references in the context of Brazilian personal income tax law.\nThe dataset contains 715 questions from the 2024 official Q\\&A document\npublished by Brazil's Internal Revenue Service, enriched with statutory norms\nand administrative rulings from the Conselho Administrativo de Recursos Fiscais\n(CARF). We implement a Retrieval-Augmented Generation (RAG) pipeline using\nOpenAI embeddings for searching and GPT-4o-mini for answer generation. We\ncompare different text segmentation strategies and benchmark our system against\ncommercial tools such as ChatGPT and Perplexity.ai using RAGAS-based metrics.\nResults show that our custom RAG pipeline outperforms commercial systems in\nResponse Relevancy, indicating stronger alignment with user queries, while\ncommercial models achieve higher scores in Factual Correctness and fluency.\nThese findings highlight a trade-off between legally grounded generation and\nlinguistic fluency. Crucially, we argue that human expert evaluation remains\nessential to ensure the legal validity of AI-generated answers in high-stakes\ndomains such as taxation. BR-TaxQA-R is publicly available at\nhttps://huggingface.co/datasets/unicamp-dl/BR-TaxQA-R.",
    "pdf_url": "http://arxiv.org/pdf/2505.15916v1",
    "published": "2025-05-21T18:11:41+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15915v3",
    "title": "On spatial decay for coherent states of the Benjamin-Ono equation",
    "authors": [
      "Gavin Stewart"
    ],
    "abstract": "We consider solutions to the Benjamin-Ono equation\n  $$\\partial_t u - H \\partial_x^2 u = -\\partial_x(u^2)$$\n  that are localized in a reference frame moving to the right with constant\nspeed. We show that any such solution that decays at least like $\\langle\nx\\rangle^{-1-\\epsilon}$ for some $\\epsilon > 0$ in a comoving coordinate frame\nmust in fact decay like $\\langle x\\rangle^{-2}$. In view of the explicit\nsoliton solutions, this decay rate is sharp. Our proof has two main\ningredients. The first is microlocal dispersive estimates for the Benjamin-Ono\nequation in a moving frame, which allow us to prove spatial decay of the\nsolution provided the nonlinearity has sufficient decay. The second is a\ncareful normal form analysis, which allows us to obtain rapid decay of the\nnonlinearity for a transformed equation assuming only modest decay of the\nsolution. Our arguments are entirely time dependent, and do not require the\nsolution to be an exact traveling wave.",
    "pdf_url": "http://arxiv.org/pdf/2505.15915v3",
    "published": "2025-05-21T18:09:21+00:00",
    "categories": [
      "math.AP",
      "76B15 (Primary) 70K45 35C07 (Secondary)"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15914v2",
    "title": "A Novel Deep Learning Framework for Efficient Multichannel Acoustic Feedback Control",
    "authors": [
      "Yuan-Kuei Wu",
      "Juan Azcarreta",
      "Kashyap Patel",
      "Buye Xu",
      "Jung-Suk Lee",
      "Sanha Lee",
      "Ashutosh Pandey"
    ],
    "abstract": "This study presents a deep-learning framework for controlling multichannel\nacoustic feedback in audio devices. Traditional digital signal processing\nmethods struggle with convergence when dealing with highly correlated noise\nsuch as feedback. We introduce a Convolutional Recurrent Network that\nefficiently combines spatial and temporal processing, significantly enhancing\nspeech enhancement capabilities with lower computational demands. Our approach\nutilizes three training methods: In-a-Loop Training, Teacher Forcing, and a\nHybrid strategy with a Multichannel Wiener Filter, optimizing performance in\ncomplex acoustic environments. This scalable framework offers a robust solution\nfor real-world applications, making significant advances in Acoustic Feedback\nControl technology.",
    "pdf_url": "http://arxiv.org/pdf/2505.15914v2",
    "published": "2025-05-21T18:07:48+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15913v1",
    "title": "In the shadow of the Hadamard test: Using the garbage state for good and further modifications",
    "authors": [
      "Paul K. Faehrmann",
      "Jens Eisert",
      "Richard Kueng"
    ],
    "abstract": "The Hadamard test is naturally suited for the intermediate regime between the\ncurrent era of noisy quantum devices and complete fault tolerance. Its\napplications use measurements of the auxiliary qubit to extract information,\nbut disregard the system register completely. Separate advances in classical\nrepresentations of quantum states via classical shadows allow the\nimplementation of even global classical shadows with shallow circuits. This\nwork combines the Hadamard test on a single auxiliary readout qubit with\nclassical shadows on the remaining $n$-qubit work register. We argue that this\ncombination inherits the best of both worlds and discuss statistical phase\nestimation as a vignette application. There, we can use the Hadamard test to\nestimate eigenvalues on the auxiliary qubit, while classical shadows on the\nremaining $n$ qubits provide access to additional features such as, (i)\nfidelity with certain pure quantum states, (ii) the initial state's energy and\n(iii) how pure and how close the initial state is to an eigenstate of the\nHamiltonian. Finally, we also discuss how anti-controlled unitaries can further\naugment this framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.15913v1",
    "published": "2025-05-21T18:06:58+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15912v1",
    "title": "BHaHAHA: A Fast, Robust Apparent Horizon Finder Library for Numerical Relativity",
    "authors": [
      "Zachariah B. Etienne",
      "Thiago Assump√ß√£o",
      "Leonardo Rosa Werneck",
      "Samuel D. Tootle"
    ],
    "abstract": "Apparent horizon (AH) finders are essential for characterizing black holes\nand excising their interiors in numerical relativity (NR) simulations. However,\nopen-source AH finders to date are tightly coupled to individual NR codes. We\nintroduce BHaHAHA, the BlackHoles@Home Apparent Horizon Algorithm, the first\nopen-source, infrastructure-agnostic library for AH finding in NR. BHaHAHA\nimplements the first-ever hyperbolic flow-based approach, recasting the\nelliptic partial differential equation for a marginally outer trapped surface\nas a damped nonlinear wave equation. To enhance performance, BHaHAHA\nincorporates a multigrid-inspired refinement strategy, an over-relaxation\ntechnique, and OpenMP parallelization. When compared to a na\\\"ive hyperbolic\nrelaxation implementation, these enhancements result in 64x speedups for\ndifficult common-horizon finds on a single spacetime slice, enabling BHaHAHA to\nachieve runtimes within 10% of the widely used (single-core) AHFinderDirect and\noutperform it on multiple cores. For dynamic horizon tracking with typical core\ncounts on a high-performance-computing cluster, BHaHAHA is approximately 2.1\ntimes faster than AHFinderDirect at accuracies limited by interpolation of\nmetric data from the host NR code. Implemented and tested in both the Einstein\nToolkit and BlackHoles@Home, BHaHAHA demonstrates that hyperbolic relaxation\ncan be a robust, versatile, and performant approach for AH finding.",
    "pdf_url": "http://arxiv.org/pdf/2505.15912v1",
    "published": "2025-05-21T18:05:47+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.IM"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15911v2",
    "title": "ASVspoof2019 vs. ASVspoof5: Assessment and Comparison",
    "authors": [
      "Avishai Weizman",
      "Yehuda Ben-Shimol",
      "Itshak Lapidot"
    ],
    "abstract": "ASVspoof challenges are designed to advance the understanding of spoofing\nspeech attacks and encourage the development of robust countermeasure systems.\nThese challenges provide a standardized database for assessing and comparing\nspoofing-robust automatic speaker verification solutions. The ASVspoof5\nchallenge introduces a shift in database conditions compared to ASVspoof2019.\nWhile ASVspoof2019 has mismatched conditions only in spoofing attacks in the\nevaluation set, ASVspoof5 incorporates mismatches in both bona fide and spoofed\nspeech statistics. This paper examines the impact of these mismatches,\npresenting qualitative and quantitative comparisons within and between the two\ndatabases. We show the increased difficulty for genuine and spoofed speech and\ndemonstrate that in ASVspoof5, not only are the attacks more challenging, but\nthe genuine speech also shifts toward spoofed speech compared to ASVspoof2019.",
    "pdf_url": "http://arxiv.org/pdf/2505.15911v2",
    "published": "2025-05-21T18:04:44+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15910v1",
    "title": "GAMA 526784: the progenitor of a globular cluster-rich ultra-diffuse galaxy? I. Star clusters, stellar body and ionised gas properties",
    "authors": [
      "Maria Luisa Buzzo",
      "Michael Hilker",
      "Anita Zanella",
      "Katja Fahrion",
      "Richard M. McDermid",
      "Remco van der Burg",
      "Marco Mirabile"
    ],
    "abstract": "Context. Ultra-diffuse galaxies (UDGs) are an intriguing population of\ngalaxies. Despite their dwarf-like stellar masses and low surface brightness,\nthey have large half-light radii and exhibit a diverse range of globular\ncluster (GC) populations. Some UDGs host many GCs while others have none,\nraising questions about the conditions under which star clusters (SC) form in\ndwarfs. GAMA526784, an isolated UDG with both an old stellar body and an\nextended star-forming (SF) front, including many young SCs, provides an\nexceptional case to explore the link between UDG evolution and star cluster\nformation. Aims. This study investigates the stellar populations, SCs, ionised\ngas, and kinematics of GAMA526784, focusing on its potential to form massive\nGCs and its connection to broader UDG formation scenarios. Methods. Imaging\nfrom HST and Subaru/HSC, alongside MUSE spectroscopy, were used to analyse the\ngalaxy's morphology, chemical composition, and kinematics. A combination of SED\nfitting and full spectral fitting was applied. Results. GAMA526784's central\nstellar body exhibits a low-metallicity ([M/H] ~ -1.0 dex) and an old age (~9.9\nGyr). The outskirts are much younger (~0.9 Gyr), but slightly more metal-poor\n([M/H] ~ -1.2 dex). The stellar kinematics show low velocity dispersions (~10\nkm/s) and a coherent rotational field, while the ionised gas exhibits higher\ndispersions (~50 km/s), a misaligned rotation axis (~20 deg) and localised SF,\nwhat could be suggestive of a recent interaction. The young SCs span ages of\n8-11 Myr and masses of log(M*/Mo)~5.0, while the old GCs have ~9 Gyr and\nstellar masses of log(M*/Mo)~5.5. Conclusions. GAMA526784's properties point to\ninteractions that triggered localised SF, leading to the formation of young\nSCs. Future observations of its molecular and neutral gas will help assess its\nenvironment, and the trigger of this SF episode.",
    "pdf_url": "http://arxiv.org/pdf/2505.15910v1",
    "published": "2025-05-21T18:03:48+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15909v1",
    "title": "Is (Selective) Round-To-Nearest Quantization All You Need?",
    "authors": [
      "Alex Kogan"
    ],
    "abstract": "Quantization became a necessary tool for serving ever-increasing Large\nLanguage Models (LLMs). RTN (Round-to-Nearest) is perhaps the simplest\nquantization technique that has been around well before LLMs surged to the\nforefront of machine learning (ML) research. Yet, it has been largely dismissed\nby recent and more advanced quantization methods that claim superiority over\nRTN in nearly every aspect of performance. This work aims to dispel this\nestablished point of view, showing that RTN is not only much cheaper to apply,\nbut also its token generation throughput can be better than and accuracy can be\nsimilar to more advanced alternatives. In particular, we discuss our\nimplementation of RTN based on the recent Marlin kernels and demonstrate how\nthe accuracy of RTN can be gradually improved by selectively increasing the\ndata precision format of certain model layers and modules. Based on our\nresults, we argue that RTN presents a viable and practical choice for\nquantizing LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15909v1",
    "published": "2025-05-21T18:01:32+00:00",
    "categories": [
      "cs.LG",
      "I.2.7; D.4.8; G.4"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15908v1",
    "title": "NonHermitian Topological Phases in a Hermitian Modified Bosonic Kitaev Chain",
    "authors": [
      "Raditya Weda Bomantara",
      "Ibsal Assi",
      "J. P. F. LeBlanc",
      "Michael Vogl"
    ],
    "abstract": "We present a modification to the bosonic Kitaev chain that, despite being\nHermitian, supports both nonHermitian skin effect and nontrivial topological\nedge modes in its excitation Hamiltonian. We establish an exact mapping between\nthe excitation Hamiltonian of our system and a nonHermitian\nSu-Schrieffer-Heeger (SSH) model, which allows for a completely analytical\ncharacterization of its topology. In particular, topological phase transition\npoints separating a topologically trivial and nontrivial regime were identified\nanalytically by the appropriate winding number invariant and the presence of\nzero energy modes. Similarly to the regular bosonic Kitaev chain, the\nnonHermitian skin effect and some (but not all) topological edge modes are\nquickly destroyed at nonzero bosonic onsite potential (harmonic oscillator\nfrequency). Remarkably, however, disorder partially recovers some of these\nfeatures. This work thus demonstrates the potential of a modified bosonic\nKitaev chain as a platform to generate rich nonHermitian topological phenomena\nfrom a completely Hermitian system's perspective. Lastly, we suggest a possible\nexperimental realization of the model, which could allow for total control over\nthe parameter space.",
    "pdf_url": "http://arxiv.org/pdf/2505.15908v1",
    "published": "2025-05-21T18:01:08+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15907v1",
    "title": "Resource Analysis of Low-Overhead Transversal Architectures for Reconfigurable Atom Arrays",
    "authors": [
      "Hengyun Zhou",
      "Casey Duckering",
      "Chen Zhao",
      "Dolev Bluvstein",
      "Madelyn Cain",
      "Aleksander Kubica",
      "Sheng-Tao Wang",
      "Mikhail D. Lukin"
    ],
    "abstract": "Neutral atom arrays have recently emerged as a promising platform for\nfault-tolerant quantum computing. Based on these advances, including\ndynamically-reconfigurable connectivity and fast transversal operations, we\npresent a low-overhead architecture that supports the layout and resource\nestimation of large-scale fault-tolerant quantum algorithms. Utilizing recent\nadvances in fault tolerance with transversal gate operations, this architecture\nachieves a run time speed-up on the order of the code distance $d$, which we\nfind directly translates to run time improvements of large-scale quantum\nalgorithms. Our architecture consists of functional building blocks of key\nalgorithmic subroutines, including magic state factories, quantum arithmetic\nunits, and quantum look-up tables. These building blocks are implemented using\nefficient transversal operations, and we design space-time efficient versions\nof them that minimize interaction distance, thereby reducing atom move times\nand minimizing the volume for correlated decoding. We further propose models to\nestimate their logical error performance. We perform resource estimation for a\nlarge-scale implementation of Shor's factoring algorithm, one of the\nprototypical benchmarks for large-scale quantum algorithms, finding that\n2048-bit RSA factoring can be executed with 19 million qubits in 5.6 days, for\n1 ms QEC cycle times. This represents close to 50$\\times$ speed-up of the\nrun-time compared to existing estimates with similar assumptions, with no\nincrease in space footprint.",
    "pdf_url": "http://arxiv.org/pdf/2505.15907v1",
    "published": "2025-05-21T18:00:18+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15906v1",
    "title": "Pairing mechanism and superconductivity in pressurized La$_5$Ni$_3$O$_{11}$",
    "authors": [
      "Ming Zhang",
      "Cui-Qun Chen",
      "Dao-Xin Yao",
      "Fan Yang"
    ],
    "abstract": "The discovery of superconductivity (SC) with critical temperature $T_c$ above\nthe boiling point of liquid nitrogen in pressurized La$_3$Ni$_2$O$_{7}$ has\nsparked a surge of exploration of high-$T_c$ superconductors in the\nRuddlesden-Popper (RP) phase nickelates. More recently, the RP phase nicklate\nLa$_5$Ni$_3$O$_{11}$, which hosts layered structure with alternating bilayer\nand single-layer NiO$_2$ planes, is reported to accommodate SC under pressure,\nexhibiting a dome-shaped pressure dependence with highest $T_c\\approx 64$ K,\ncapturing a lot of interests. Here, using density functional theory (DFT) and\nrandom phase approximation (RPA) calculations, we systematically study the\nelectronic properties and superconducting mechanism of this material. Our DFT\ncalculations yield a band structure including two nearly decoupled sets of\nsub-band structures, with one set originating from the bilayer subsystem and\nthe other from the single-layer one. RPA-based analysis demonstrates that SC in\nthis material occurs primarily within the bilayer subsystem exhibiting an\n$s^\\pm$ wave pairing symmetry similar to that observed in pressurized\nLa$_3$Ni$_2$O$_{7}$, while the single-layer subsystem mainly serves as a bridge\nfacilitating the inter-bilayer phase coherence through the interlayer Josephson\ncoupling (IJC). Since the IJC thus attained is extremely weak, it experiences a\nprominent enhancement under pressure, leading to the increase of the bulk $T_c$\nwith pressure initially. When the pressure is high enough, the $T_c$ gradually\ndecreases due to the reduced density of states on the $\\gamma$-pocket. In this\nway, the dome-shaped pressure dependence of $T_c$ observed experimentally is\nnaturally understood.",
    "pdf_url": "http://arxiv.org/pdf/2505.15906v1",
    "published": "2025-05-21T18:00:15+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.15905v1",
    "title": "Capacitated Fair-Range Clustering: Hardness and Approximation Algorithms",
    "authors": [
      "Ameet Gadekar",
      "Suhas Thejaswi"
    ],
    "abstract": "Capacitated fair-range $k$-clustering generalizes classical $k$-clustering by\nincorporating both capacity constraints and demographic fairness. In this\nsetting, each facility has a capacity limit and may belong to one or more\ndemographic groups. The task is to select $k$ facilities as centers and assign\neach client to a center such that: ($a$) no center exceeds its capacity, ($b$)\nthe number of centers selected from each group lies within specified lower and\nupper bounds (fair-range constraints), and ($c$) the clustering cost (e.g.,\n$k$-median or $k$-means) is minimized.\n  Prior work by Thejaswi et al. (KDD 2022) showed that satisfying fair-range\nconstraints is NP-hard, making the problem inapproximable to any polynomial\nfactor. We strengthen this result by showing that inapproximability persists\neven when the fair-range constraints are trivially satisfiable, highlighting\nthe intrinsic computational complexity of the clustering task itself. Assuming\nstandard complexity conjectures, we show that no non-trivial approximation is\npossible without exhaustively enumerating all $k$-subsets of the facility set.\nNotably, our inapproximability results hold even on tree metrics and when the\nnumber of groups is logarithmic in the size of the facility set.\n  In light of these strong inapproximability results, we focus on a more\npractical setting where the number of groups is constant. In this regime, we\ndesign two approximation algorithms: ($i$) a polynomial-time $O(\\log k)$- and\n$O(\\log^2 k)$-approximation algorithm for the $k$-median and $k$-means\nobjectives, and ($ii$) a fixed-parameter tractable algorithm parameterized by\n$k$, achieving $(3+\\epsilon)$- and $(9 + \\epsilon)$-approximation,\nrespectively. These results match the best-known approximation guarantees for\ncapacitated clustering without fair-range constraints and resolves an open\nquestion posed by Zang et al. (NeurIPS 2024).",
    "pdf_url": "http://arxiv.org/pdf/2505.15905v1",
    "published": "2025-05-21T18:00:06+00:00",
    "categories": [
      "cs.DS",
      "cs.CC"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15904v2",
    "title": "The Bearable Inhomogeneity of the Baryon Asymmetry",
    "authors": [
      "Hengameh Bagherian",
      "Majid Ekhterachian",
      "Stefan Stelzl"
    ],
    "abstract": "We study the implications of precision measurements of light-element\nabundances, in combination with the Cosmic Microwave Background, for scenarios\nof physics beyond the Standard Model that generate large inhomogeneities in the\nbaryon-to-photon ratio. We show that precision Big Bang Nucleosynthesis (BBN)\nplaces strong constraints on any mechanism that produces large-scale\ninhomogeneities at temperatures around or below the TeV scale. In particular,\nwe find that fluctuations of order $25\\%$ on comoving length scales larger than\nthe horizon at $T \\simeq 3~\\mathrm{TeV}$ are incompatible with the observed\nlight-element abundances. This sensitivity to early-universe physics arises\nbecause baryon-number inhomogeneities homogenize primarily through diffusion, a\nslow process. As a result, BBN serves as a novel probe of baryogenesis below\nthe TeV scale, readily ruling out some proposed scenarios in the literature. We\ndiscuss the implications for electroweak baryogenesis, and further show that\nprecision BBN provides a new probe of first-order phase transitions that\ngenerate gravitational waves in the pHz-mHz frequency range. This yields\nconstraints on the electroweak phase transition, as well as first-order phase\ntransitions that have been suggested as an explanation of the pulsar timing\narray signal. Finally, we comment on the future prospects for improving this\nprobe.",
    "pdf_url": "http://arxiv.org/pdf/2505.15904v2",
    "published": "2025-05-21T18:00:05+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15903v1",
    "title": "Core Collapse Beyond the Fluid Approximation: The Late Evolution of Self-Interacting Dark Matter Halos",
    "authors": [
      "James Gurian",
      "Simon May"
    ],
    "abstract": "We show that the gravothermal collapse of self-interacting dark matter (SIDM)\nhalos can deviate from local thermodynamic equilibrium. As a consequence, the\nself-similar evolution predicted by the commonly adopted conducting fluid model\ncan be altered or broken. Our results are obtained using a novel, efficient\nkinetic solver called KiSS-SIDM for tracing the gravothermal evolution based on\nthe Direct Simulation Monte Carlo (DSMC) framework. In the long mean free path\nstage, the code is a viable alternative to the fluid model, yet requires no\ncalibration parameters. Further, this method enables a fully kinetic treatment\nwell into the late, short mean free path, stage of the collapse. We apply the\nmethod to a canonical case with isotropic, velocity independent scattering. We\nfind that although a fluid treatment is appropriate deep in the short mean free\npath core, departures from local thermodynamic equilibrium develop in the\nintermediate mean free path region bounding the core, which modify the\nlate-time evolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15903v1",
    "published": "2025-05-21T18:00:04+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15901v1",
    "title": "Strong-gravity precession resonances for binary systems orbiting a Schwarzschild black hole",
    "authors": [
      "Marta Cocco",
      "Gianluca Grignani",
      "Troels Harmark",
      "Marta Orselli",
      "Daniele Pica"
    ],
    "abstract": "Binary systems of compact objects in close orbit around a supermassive black\nhole (SMBH) may form in galactic nuclei, providing a unique environment to\nprobe strong-gravity tidal effects on the binary's dynamics. In this work, we\ninvestigate precession resonances arising between the periastron precession\nfrequency of a binary system and its orbital frequencies around the SMBH. By\nmodeling the SMBH as a Schwarzschild black hole, we find that relativistic\neffects in the tidal field give rise to a significantly richer resonance\nspectrum compared to the Newtonian case. This result is supported by both\nperturbative and numerical analyses of the quadrupolar tidal interaction in the\nstrong-gravity regime. Our results reveal new signatures for strong-gravity\neffects in such triple systems, with potential implications for\ngravitational-wave astronomy.",
    "pdf_url": "http://arxiv.org/pdf/2505.15901v1",
    "published": "2025-05-21T18:00:03+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.GA",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15902v2",
    "title": "On Dequantization of Supervised Quantum Machine Learning via Random Fourier Features",
    "authors": [
      "Mehrad Sahebi",
      "Alice Barthe",
      "Yudai Suzuki",
      "Zo√´ Holmes",
      "Michele Grossi"
    ],
    "abstract": "In the quest for quantum advantage, a central question is under what\nconditions can classical algorithms achieve a performance comparable to quantum\nalgorithms--a concept known as dequantization. Random Fourier features (RFFs)\nhave demonstrated potential for dequantizing certain quantum neural networks\n(QNNs) applied to regression tasks, but their applicability to other learning\nproblems and architectures remains unexplored. In this work, we derive bounds\non the generalization performance gap between classical RFF models and quantum\nmodels for regression and classification tasks with both QNN and quantum kernel\narchitectures. We support our findings with numerical experiments that\nillustrate the practical dequantization of existing quantum kernel-based\nmethods. Our findings not only broaden the applicability of RFF-based\ndequantization but also enhance the understanding of potential quantum\nadvantages in practical machine-learning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15902v2",
    "published": "2025-05-21T18:00:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15898v1",
    "title": "Heuristic ansatz design for trainable ion-native digital-analog quantum circuits",
    "authors": [
      "Georgii Paradezhenko",
      "Daniil Rabinovich",
      "Ernesto Campos",
      "Kirill Lakhmanskiy"
    ],
    "abstract": "Variational quantum algorithms have become a standard approach for solving a\nwide range of problems on near-term quantum computers. Identifying an\nappropriate ansatz configuration for variational algorithms, however, remains a\nchallenging task, especially when taking into account restrictions imposed by\nreal quantum platforms. This motivated the development of digital-analog\nquantum circuits, where sequences of quantum gates are alternated with natural\nHamiltonian evolutions. A prominent example is the use of the controllable\nlong-range Ising interaction induced in ion-based quantum computers. This\ninteraction has recently been applied to develop an algorithm similar to the\nquantum approximate optimization algorithm (QAOA), but native to the ion\nhardware. The performance of this algorithm has demonstrated a strong\ndependence on the strengths of the individual ion-ion interactions, which serve\nas ansatz hyperparameters. In this work, we propose a heuristic for identifying\na problem-specific ansatz configuration, which enhances the trainability of the\nion native digital-analog circuit. The proposed approach is systematically\napplied to random instances of the Sherrington-Kirkpatrick Hamiltonian for up\nto 15 qubits, providing favorable cost landscapes. As the result, the developed\napproach identifies a well-trainable ion native ansatz, which requires a lower\ncircuit depth to solve specific problems as compared to standard QAOA. This\nbrings the algorithm one step closer to its large scale practical\nimplementation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15898v1",
    "published": "2025-05-21T18:00:02+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15899v1",
    "title": "The CMB optical depth constrains the duration of reionization",
    "authors": [
      "Christopher Cain",
      "Alexander Van Engelen",
      "Kevin S. Croker",
      "Darby Kramer",
      "Anson D'Aloisio",
      "Garett Lopez"
    ],
    "abstract": "Recently, it was pointed out that invoking a large value of the CMB optical\ndepth, $\\tau_{\\rm CMB} = 0.09$, could help resolve tensions between DESI DR2\nBAO data and the CMB. This is larger than the value of $\\tau_{\\rm CMB} = 0.058$\nmeasured from the Planck low-$\\ell$ polarization data. Traditionally,\n$\\tau_{\\rm CMB}$ is thought of as a constraint on reionization's midpoint.\nHowever, recent observations and modeling of the Ly$\\alpha$ forest of high-$z$\nquasars at $5 < z < 6$ have tightly constrained the timing of the last\n$10-20\\%$ of reionization, adding nuance to this interpretation. Here, we point\nout that fixing reionization's endpoint, in accordance with the latest\nLy$\\alpha$ forest constraints, renders $\\tau_{\\rm CMB}$ a sensitive probe of\nthe duration of reionization, as well as its midpoint. We compare low and high\nvalues of $\\tau_{\\rm CMB}$ to upper limits on the patchy kinematic\nSunyaev-Zeldovich (pkSZ) effect, another CMB observable that constrains\nreionization's duration, and find that a value of $\\tau_{\\rm CMB} = 0.09$ is in\n$\\approx 2\\sigma$ tension with existing limits on the pkSZ from the South Pole\nTelescope.",
    "pdf_url": "http://arxiv.org/pdf/2505.15899v1",
    "published": "2025-05-21T18:00:02+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15900v1",
    "title": "The alternating 'changing-look' blazar OQ 334 (B2 1420+32): New observational clues to the blazar state transitions",
    "authors": [
      "Krishan Chand",
      "Gopal-Krishna"
    ],
    "abstract": "The high-luminosity blazar OQ 334 is a leading exponent of the intriguing\nrare phenomenon of alternating between a flat-spectrum radio quasar (FSRQ) and\na BL Lac (BLL) states. Its two optical continuum outbursts observed during the\n$\\sim$ 1.5-year long time span, starting Jan 2018, had been shown to coincide\nwith transition from the FSRQ to BLL state, manifested by a sharp drop in the\nequivalent width of MgII broad emission-line. Recently, a continuous monitoring\nof its blazar state, over a much longer duration (past $\\sim$ 5 years) has\nbecome possible by deploying the observed $\\gamma-ray$ spectral slope\n($\\Gamma_{\\gamma}$) as a diagnostic. This opens prospects of making a much less\nbiased and statistically more robust check on the association of optical\nflaring with FSRQ $\\rightarrow$ BLL transition. We find that all 4 such\ntransitions ($\\Gamma_{\\gamma}$ becoming < 2.0), observed during the past $\\sim$\n5 years, were accompanied by an optical flare. While this appears consistent\nwith the transition to BL Lac state happening purely due to an enhanced optical\ncontinuum (flaring) swamping out the broad emission-lines, this simple scheme\nmay need additional ingredients, considering the hint found for a day-like\noffset between the flaring and the state transition.",
    "pdf_url": "http://arxiv.org/pdf/2505.15900v1",
    "published": "2025-05-21T18:00:02+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15891v1",
    "title": "Gaplessness from disorder and quantum geometry in gapped superconductors",
    "authors": [
      "Omri Lesser",
      "Sagnik Banerjee",
      "Xuepeng Wang",
      "Jaewon Kim",
      "Ehud Altman",
      "Debanjan Chowdhury"
    ],
    "abstract": "It is well known that disorder can induce low-energy Andreev bound states in\na sign-changing, but fully gapped, superconductor at $\\pi-$junctions.\nGenerically, these excitations are localized. Starting from a superconductor\nwith a sign-changing and nodeless order parameter in the clean limit, here we\ndemonstrate a mechanism for increasing the localization length associated with\nthe low-energy Andreev bound states at a fixed disorder strength. We find that\nthe Fubini-Study metric associated with the electronic Bloch wavefunctions\ncontrols the localization length and the hybridization between bound states\nlocalized at distinct $\\pi-$junctions. We present results for the inverse\nparticipation ratio, superfluid stiffness, site-resolved and disorder-averaged\nspectral functions as a function of increasing Fubini-Study metric, which\nindicate an increased tendency towards delocalization. The low-energy\nproperties resemble those of a dirty nodal superconductor with gapless\nBogoliubov excitations. We place these results in the context of recent\nexperiments in moire graphene superconductors.",
    "pdf_url": "http://arxiv.org/pdf/2505.15891v1",
    "published": "2025-05-21T18:00:01+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.dis-nn",
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.15892v2",
    "title": "Observers seeing gravitational Hilbert spaces: abstract sources for an abstract path integral",
    "authors": [
      "Hong Zhe Chen"
    ],
    "abstract": "The gravitational path integral suggests a striking result: the Hilbert space\nof closed universes in each superselection sector, a so-called $\\alpha$-sector,\nis one-dimensional. We develop an abstract formalism encapsulating recent\nproposals that modify the gravitational path integral in the presence of\nobservers and allow larger Hilbert spaces to be associated with closed\nuniverses. Our formalism regards the gravitational path integral as a map from\nabstract objects called sources to complex numbers, and introduces additional\nobjects called partial sources, which form sources when glued together. We\napply this formalism to treat, on equal footing, universes with spatial\nboundaries, closed universes with prescribed observer worldlines, and closed\nuniverses containing observers entangled with external systems. In these\ncontexts, the relevant gravitational Hilbert spaces contain states prepared by\npartial sources and can consequently have nontrivial $\\alpha$-sectors\nsupporting noncommuting operators. Within our general framework, the positivity\nof the gravitational inner product implies a bound on the Hilbert space trace\nof certain positive operators over each $\\alpha$-sector. The trace of such\noperators, in turn, quantifies the effective size of this Hilbert space.",
    "pdf_url": "http://arxiv.org/pdf/2505.15892v2",
    "published": "2025-05-21T18:00:01+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15893v1",
    "title": "Calibration of Binary Population Synthesis Models Using White Dwarf Binaries from APOGEE, GALEX and Gaia",
    "authors": [
      "A. C. Rubio",
      "K. Breivik",
      "C. Badenes",
      "K. El-Badry",
      "B. Anguiano",
      "E. Linck",
      "S. Majewski",
      "K. Stassun"
    ],
    "abstract": "The effectiveness and stability of mass transfer in binaries system are\ncrucial in determining its final product. Rapid binary population synthesis\n(BPS) codes simplify the complex physics of mass transfer by adopting\nparameterized prescriptions for the stability of mass transfer, accretion\nefficiency in stable mass transfer, and the efficiency of common-envelope\nejection. We calibrate these uncertain parameters by comparing BPS models with\nobservational data. White dwarf and main sequence binaries are an ideal\npopulation to study binary interaction, as they can be formed through stable or\nunstable mass transfer, or without interaction, which affect the orbital period\nand masses of the present-day population. The APOGEE-GALEX-Gaia catalog\nprovides a homogeneous sample of over 500 systems with well measured radial\nvelocities that can be used as a comparison baseline for BPS simulations of\nsuch binaries. We compare the distribution of observed maximum radial velocity\nvariation ($\\Delta RV_{\\rm max}$) and estimated masses to BPS models simulated\nwith COSMIC, varying the mass transfer and common-envelope ejection efficiency,\nand the criteria for mass transfer stability at key evolutionary stages. The\n$\\Delta RV_{\\rm max}$ comparison shows clear preference for a higher fraction\nof stable mass transfer during the first ascent giant branch, and for highly\neffective envelope ejection. For the systems with WD masses, there is a slight\npreference for non-conservative mass transfer. In COSMIC and similar codes, the\nenvelope ejection efficiency and the envelope binding energy are degenerate\nparameters. Our result of high ejection efficiency may indicate that either\nadditional sources of energy are required to eject the envelope, or that its\nbinding energy is lower than traditionally assumed. Future comparisons to BPS\nsimulations can be drawn for other datasets as they become available.",
    "pdf_url": "http://arxiv.org/pdf/2505.15893v1",
    "published": "2025-05-21T18:00:01+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15894v1",
    "title": "Activation of anomalous Hall effect and orbital magnetization by domain walls in altermagnets",
    "authors": [
      "Sopheak Sorn",
      "Yuriy Mokrousov"
    ],
    "abstract": "Altermagnets are an emerging class of unconventional antiferromagnets,\ncharacterized by a N\\'eel ordering that does not break the translation symmetry\nof the underlying lattice. Depending on the orientation of the N\\'eel vector,\nthe anomalous Hall effect (AHE) may or may not exist. In the so-called pure\naltermagnets, AHE is forbidden by the magnetic symmetry. Here, we demonstrate\nthat in pure altermagnets, the domain walls can lift the symmetry constraints,\nthereby activating the AHE and orbital magnetization. Taking a representative\nexample of a rutile-lattice tight-binding minimal model in slab geometry, we\nuse the linear response theory to demonstrate the emergence of the domain wall\nAHE, finding that it is closely related with the orbital magnetization, while\nthe spin magnetization does not play a significant role. Using Landau theory,\nwe argue that while for a random arrangement of $\\pi$ domain walls, the\ncontributions from the individual domain walls will cancel one another, an\nexternal magnetic field will favor domain-wall arrangements with specific\nchirality giving rise to a net AHE signal. Using group theory, we discuss how\nthese findings can be generalized straightforwardly to certain other classes of\naltermagnets. Our work reveals a crucial role of the domain walls in the\nunderstanding of the Hall transport and orbital magnetism of altermagnets.",
    "pdf_url": "http://arxiv.org/pdf/2505.15894v1",
    "published": "2025-05-21T18:00:01+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.15895v1",
    "title": "A magnitude-limited catalogue of unresolved white dwarf-main sequence binaries from Gaia DR3",
    "authors": [
      "Alberto Rebassa-Mansergas",
      "Enrique Solano",
      "Alex J. Brown",
      "Steven G. Parsons",
      "Raquel Murillo-Ojeda",
      "Roberto Raddi",
      "Maria Camisassa",
      "Santiago Torres",
      "Jan van Roestel"
    ],
    "abstract": "Binary stars containing a white dwarf and a main-sequence star, WDMS\nbinaries, can be used to study a wide range of aspects of stellar astrophysics.\nWe build a magnitude-limited sample of unresolved WDMS binaries from Gaia DR3\nto enlarge these studies. We look for WDMS with available spectra whose\nlocation in the Gaia colour-magnitude diagram bridges between the evolutionary\nsequences of single white dwarfs and the main-sequence. To exclude spurious\nsources we apply quality cuts on the Gaia photometry and astrometry and we fit\nthe SED (spectral energy distribution) of the objects with VOSA (Virtual\nObservatory SED Analyser) to exclude single sources. We further clean the\nsample via visual inspection of the Gaia spectra and publicly available images\nof the objects. We re-fit the SEDs of the finally selected WDMS with VOSA using\ncomposite models to measure their stellar parameters and we search for\neclipsing systems by inspecting available ZTF and CRTS light curves. The\ncatalogue consists of 1312 WDMS and we manage to derive stellar parameters for\n435. This is because most WDMS are dominated by the main-sequence companions,\nmaking it hard to derive parameters for the white dwarfs. We also identify 67\neclipsing systems and estimate a lower limit to the completeness of the sample\nto be ~50% (~5% if we consider that not all WDMS in the studied region have\nGaia spectra). Our catalogue increases by one order of magnitude the\nvolume-limited sample we presented in our previous work. Despite the fact that\nthe sample is incomplete and suffers from heavy observational biases, it is\nwell characterised and can therefore be used to further constrain binary\nevolution by comparing the observed properties to those from synthetic samples\nobtained modeling the WDMS population in the Galaxy, taking into account all\nselection effects.",
    "pdf_url": "http://arxiv.org/pdf/2505.15895v1",
    "published": "2025-05-21T18:00:01+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15896v1",
    "title": "A pulsar-helium star compact binary system formed by common envelope evolution",
    "authors": [
      "Z. L. Yang",
      "J. L. Han",
      "D. J. Zhou",
      "W. C. Jing",
      "W. C. Chen",
      "T. Wang",
      "X. D. Li",
      "S. Wang",
      "B. Wang",
      "H. W. Ge",
      "Y. L. Guo",
      "L. H. Li",
      "Y. Shao",
      "J. F. Liu",
      "W. Q. Su",
      "L. G. Hou",
      "W. J. Huang",
      "J. C. Jiang",
      "P. Jiang",
      "J. H. Sun",
      "B. J. Wang",
      "C. Wang",
      "H. G. Wang",
      "J. B. Wang",
      "N. Wang",
      "P. F. Wang",
      "S. Q. Wang",
      "H. Xu",
      "J. Xu",
      "R. X. Xu",
      "W. M. Yan",
      "Y. Yan",
      "X. P. You",
      "D. J. Yu",
      "Z. S. Yuan",
      "C. F. Zhang"
    ],
    "abstract": "A stellar common envelope occurs in a binary system when the atmosphere of an\nevolving star expands to encompass an orbiting companion object. Such systems\nare predicted to evolve rapidly, ejecting the stellar envelope and leaving the\ncompanion in a tighter orbit around a stripped star. We used radio timing to\nidentify a pulsar, PSR J1928+1815, with a spin period of 10.55 ms in a compact\nbinary system with an orbital period of 3.60 hours. The companion star has 1.0\nto 1.6 solar masses, eclipses the pulsar for about 17% of the orbit, and is\nundetected at other wavelengths, so it is most likely a stripped helium star.\nWe interpret this system as having recently undergone a common envelope phase,\nproducing a compact binary.",
    "pdf_url": "http://arxiv.org/pdf/2505.15896v1",
    "published": "2025-05-21T18:00:01+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15897v1",
    "title": "Dark Matter Nuclear Magnetic Resonance is Sensitive to Dark Photons and the Axion-Photon Coupling",
    "authors": [
      "Carl Beadle",
      "Sebastian A. R. Ellis",
      "Jacob M. Leedom",
      "Nicholas L. Rodd"
    ],
    "abstract": "We demonstrate that nuclear magnetic resonance based searches for dark matter\n(DM) have intrinsic and powerful sensitivity to dark photons and the\naxion-photon coupling. The reason is conceptually straightforward. An\ninstrument such as CASPEr-Gradient begins with a large sample of nuclear spins\npolarised in a background magnetic field. In the presence of axion DM coupled\nto nucleons, the spin ensemble feels an effective magnetic field $\\mathbf{B}\n\\propto \\nabla a$ that tilts the spins, generating a potentially observable\nprecession. If the magnetic field is real rather than effective, the system\nresponds identically. A real field can be generated by a kinetically mixed dark\nphoton within the shielded region the sample is placed or an axion coupled to\nphotons through its interaction with the background magnetic field. We show\nthat all three signals are detectable and distinguishable. If CASPEr-Gradient\nwere to reach the QCD axion prediction of the axion-nucleon coupling, it would\nsimultaneously be sensitive to kinetic mixings of $\\epsilon \\simeq 3 \\times\n10^{-16}$ and axion-photon couplings of $g_{a\\gamma\\gamma} \\simeq 2 \\times\n10^{-16}\\,{\\rm GeV}^{-1}$ for $m \\simeq 1\\,\\mu{\\rm eV}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15897v1",
    "published": "2025-05-21T18:00:01+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15881v1",
    "title": "The Lyman-alpha Halos of Galaxies at z=2-3 in the Keck Baryonic Structure Survey",
    "authors": [
      "Ryan F. Trainor",
      "Noah R. Lamb",
      "Charles C. Steidel",
      "Yuguang Chen",
      "Dawn K. Erb",
      "Elizabeth Trenholm",
      "Rebecca L. McClain",
      "Io Kovach"
    ],
    "abstract": "We present the large-scale spatial Lya profiles of galaxies from the Keck\nBaryonic Structure Survey (KBSS) at 2<z<3. This work also describes the Lya\nimaging for the KBSS-Lya survey for the first time. Our sample includes 734\nLya-selected galaxies and 119 continuum-selected galaxies with Lya narrow-band\nimaging, and we measure the spatial morphology of Lya and continuum emission\nfor stacked subsamples of these two populations. These samples allow us to\nstudy the variation in Lya emission profiles over a broad range of UV continuum\nluminosities and Lya equivalent widths (EW_Lya), including systems with net Lya\nabsorption in slit spectroscopy. We characterize the spatial profiles using two\ntechniques: directly fitting an exponential function to the stacked profile,\nand a multi-component forward-modeling technique using the empirical\nlarge-scale PSF. We find that both methods yield similar results and that the\nforward-modeling technique self-consistently fits profiles exhibiting central\nLya emission or Lya absorption, with the spatial scale of central Lya\napproximately matching that of the continuum emission. We also find extended\nLya emission such that all our subsamples -- including central Lya absorbers --\nare net Lya emitters on scales comparable to the circumgalactic medium (R > 50\nkpc, theta > 6''). We find that the scale length of the Lya halo is not\nstrongly dependent on the properties of the central galaxy, including its net\ncontinuum luminosity or EW_Lya, although we find a possible weak tendency of\ncontinuum-faint, high-EW_Lya galaxies to exhibit larger Lya halos in contrast\nwith previous work.",
    "pdf_url": "http://arxiv.org/pdf/2505.15881v1",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15882v1",
    "title": "Fully non-linear simulations of galaxy intrinsic alignments for weak lensing with the MillenniumTNG lightcone",
    "authors": [
      "Fulvio Ferlito",
      "Volker Springel",
      "Christopher T. Davies",
      "Toshiki Kurita",
      "Ana Maria Delgado",
      "Sownak Bose",
      "Lars Hernquist"
    ],
    "abstract": "We present a complete forward model of a realistic weak lensing galaxy\ncatalogue based on the 740 Mpc hydrodynamical MillenniumTNG (MTNG) simulation.\nStarting with a complete particle and cell lightcone covering one octant of the\nsky with redshift range 0 < $z$ < 1.5, we apply a group and subhalo finder to\ngenerate the corresponding galaxy catalogue for a fiducial observer. For all\ngalaxies, we compute both their intrinsic and lensing-induced shear. The\nintrinsic component is derived from the luminosity-weighted inertia tensor of\nstellar particles, while the extrinsic (gravitational) shear is obtained\nthrough full-sky ray-tracing on the same lightcone. This allows us to directly\npredict the impact of intrinsic alignment (IA) of galaxies on the shear\ncorrelation function and popular convergence statistics in a fully non-linear\nforward model. We find that IA modifies the convergence power spectrum at all\nangular scales by up to 20%, it significantly impacts the PDF, altering its\ntails by 10-20%, and distorts peak and minimum counts up to 30%, depending on\nredshift and scale. We also evaluate the impact of the IA signal on the shear\ncorrelation function finding that, along with a redshift dependence, the signal\nstrongly increases for higher galaxy stellar mass cuts applied to the\ncatalogue. Notably, with the highest stellar mass cut we apply, the intrinsic\nshear autocorrelation can become comparable to the gravitational shear\ncomponent on small angular scales. Our results highlight the importance of\naccurately modeling IA for precision weak lensing cosmology with upcoming Stage\nIV surveys.",
    "pdf_url": "http://arxiv.org/pdf/2505.15882v1",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15883v2",
    "title": "$G_2$-manifolds from Diophantine equations",
    "authors": [
      "Jakob Moritz"
    ],
    "abstract": "We argue that \\emph{perturbatively flat vacua} (PFVs) introduced in\n\\cite{Demirtas:2019sip} are dual to M-theory compactifications on\n$G_2$-manifolds, enabling the enumeration of novel $G_2$-manifolds via\nsolutions to Diophantine equations in type IIB flux quanta. Independently, we\nshow that warping corrections to the effective action of type IIB flux vacua\ngrow parametrically at large complex structure, and we demonstrate that these\ncorrections can nonetheless be captured by a classical geometric computation in\nM-theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.15883v2",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15884v1",
    "title": "String Theory and Grand Unification Suggest a Sub-Microelectronvolt QCD Axion",
    "authors": [
      "Joshua N. Benabou",
      "Katherine Fraser",
      "Mario Reig",
      "Benjamin R. Safdi"
    ],
    "abstract": "Axions, grand unification, and string theory are each compelling extensions\nof the Standard Model. We show that combining these frameworks imposes strong\nconstraints on the QCD axion mass. Using unitarity arguments and explicit\nstring compactifications - such as those from the Kreuzer-Skarke (KS) type IIB\nensemble - we find that the axion mass is favored to lie within the range\n$10^{-11}$ eV $\\lesssim m_a \\lesssim$ $10^{-8}$ eV. This range is directly\nrelevant for near-future axion dark matter searches, including\nABRACADABRA/DMRadio and CASPEr. We argue that grand unification and the absence\nof proton decay suggest a compactification volume that keeps the string scale\nabove the unification scale ($\\sim$$10^{16}$ GeV), which in turn limits how\nheavy the axion can be. The same requirements limit the KS axiverse to have at\nmost $\\sim$47 axions. As an additional application of our methodology, we\nsearch for axions in the KS axiverse that could explain the recent Dark Energy\nSpectroscopic Instrument (DESI) hints of evolving dark energy but find none\nwith high enough decay constant ($f_a \\gtrsim 2.5 \\times 10^{17}$ GeV); we\ncomment on why such high decay constants and low axion masses are difficult to\nobtain in string compactifications more broadly.",
    "pdf_url": "http://arxiv.org/pdf/2505.15884v1",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15885v2",
    "title": "Cobordism Utopia: U-Dualities, Bordisms, and the Swampland",
    "authors": [
      "Noah Braeger",
      "Arun Debray",
      "Markus Dierigl",
      "Jonathan J. Heckman",
      "Miguel Montero"
    ],
    "abstract": "The U-dualities of maximally supersymmetric supergravity theories lead to\ncelebrated non-perturbative constraints on the structure of quantum gravity.\nThey can also lead to the presence of global symmetries since manifolds\nequipped with non-trivial duality bundles can carry topological charges\ncaptured by non-trivial elements of bordism groups. The recently proposed\nSwampland Cobordism Conjecture thus predicts the existence of new singular\nobjects absent in the low-energy supergravity theory, which break these global\nsymmetries.\n  We investigate this expectation in two directions, involving the different\nchoices of U-duality groups $G_U$, as well as $k$, the dimension of the closed\nmanifold carrying the topological charge. First, we compute for all\nsupergravity theories in dimension $3 \\leq D \\leq 11$ the bordism groups\n$\\Omega_1^{\\text{Spin}}(BG_U)$. Second, we treat in detail the case of $D = 8$,\ncomputing all relevant bordism groups $\\Omega_k^{\\text{Spin}}(BG_U)$ for $1\n\\leq k \\leq 7$. In all cases, we identify corresponding string, M-, or F-theory\nbackgrounds which implement the required U-duality defects. In particular, we\nfind that in some cases there is no purely geometric background available which\nimplements the required symmetry-breaking defect. This includes non-geometric\ntwists as well as non-geometric strings and instantons.\n  This computation involves several novel computations of the bordism groups\nfor $G_U = \\mathrm{SL}(2,\\mathbb{Z}) \\times \\mathrm{SL}(3,\\mathbb{Z})$, which\nlocalizes at primes $p=2,3$. Whereas an amalgamated product structure greatly\nsimplifies the calculation of purely $\\mathrm{SL}(2,\\mathbb{Z})$ bundles, this\ndoes not extend to $\\mathrm{SL}(3,\\mathbb{Z})$. Rather, we leverage the\nappearance of product / ring structures induced from cyclic subgroups of $G_U$\nwhich naturally act on the relevant bordism groups.",
    "pdf_url": "http://arxiv.org/pdf/2505.15885v2",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "hep-th",
      "math.AT"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15886v2",
    "title": "Fundamental Complement of a Gravitating Region",
    "authors": [
      "Raphael Bousso",
      "Sami Kaya"
    ],
    "abstract": "Any gravitating region $a$ in any spacetime gives rise to a generalized\nentanglement wedge, the hologram $e(a)$. Holograms exhibit properties expected\nof fundamental operator algebras, such as strong subadditivity, nesting, and\nno-cloning. But the entanglement wedge EW of an AdS boundary region $B$ with\ncommutant $\\bar B$ satisfies an additional condition, complementarity: EW$(B)$\nis the spacelike complement of EW$(\\bar B)$ in the bulk.\n  Here we identify an analogue of the boundary commutant $\\bar B$ in general\nspacetimes: given a gravitating region $a$, its \\emph{fundamental complement}\n$\\tilde{a}$ is the smallest wedge that contains all infinite world lines\ncontained in the spacelike complement $a'$ of $a$. We refine the definition of\n$e(a)$ by requiring that it be spacelike to $\\tilde a$. We prove that $e(a)$ is\nthe spacelike complement of $e(\\tilde a)$ when the latter is computed in $a'$.\n  We exhibit many examples of $\\tilde{a}$ and of $e(a)$ in de Sitter, flat, and\ncosmological spacetimes. We find that a Big Bang cosmology (spatially closed or\nnot) is trivially reconstructible: the whole universe is the entanglement wedge\nof any wedge inside it. But de Sitter space is not trivially reconstructible,\ndespite being closed. We recover the AdS/CFT prescription by proving that\nEW$(B)=e($causal wedge of $B$).",
    "pdf_url": "http://arxiv.org/pdf/2505.15886v2",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "hep-th",
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15887v2",
    "title": "A Temperature Change can Solve the Deutsch-Jozsa Problem : An Exploration of Thermodynamic Query Complexity",
    "authors": [
      "Jake Xuereb"
    ],
    "abstract": "We demonstrate how a single heat exchange between a probe thermal qubit and\nmulti-qubit thermal machine encoding a Boolean function, can determine whether\nthe function is balanced or constant, thus providing a novel thermodynamic\nsolution to the Deutsch-Jozsa problem. We introduce a thermodynamic model of\nquantum query complexity, showing how qubit thermal machines can act as\noracles, queried via heat exchange with a probe. While the Deutsch-Jozsa\nproblem requires an exponential encoding in the number of oracle bits, we also\nexplore the Bernstein-Vazirani problem, which admits a linear thermal oracle\nand a single thermal query solution. We establish bounds on the number of\nsamples needed to determine the probe temperature encoding the solution for the\nDeutsch-Jozsa problem, showing that it remains constant with problem size.\nAdditionally, we propose a proof-of-principle experimental implementation to\nsolve the 3-bit Bernstein-Vazirani problem via thermal kickback. This work\nbridges thermodynamics and complexity theory, suggesting a new test bed for\nquantum thermodynamic computing.",
    "pdf_url": "http://arxiv.org/pdf/2505.15887v2",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15888v1",
    "title": "Last Layer Empirical Bayes",
    "authors": [
      "Valentin Villecroze",
      "Yixin Wang",
      "Gabriel Loaiza-Ganem"
    ],
    "abstract": "The task of quantifying the inherent uncertainty associated with neural\nnetwork predictions is a key challenge in artificial intelligence. Bayesian\nneural networks (BNNs) and deep ensembles are among the most prominent\napproaches to tackle this task. Both approaches produce predictions by\ncomputing an expectation of neural network outputs over some distribution on\nthe corresponding weights; this distribution is given by the posterior in the\ncase of BNNs, and by a mixture of point masses for ensembles. Inspired by\nrecent work showing that the distribution used by ensembles can be understood\nas a posterior corresponding to a learned data-dependent prior, we propose last\nlayer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a\nnormalizing flow, which is then trained to maximize the evidence lower bound;\nto retain tractability we use the flow only on the last layer. We show why LLEB\nis well motivated, and how it interpolates between standard BNNs and ensembles\nin terms of the strength of the prior that they use. LLEB performs on par with\nexisting approaches, highlighting that empirical Bayes is a promising direction\nfor future research in uncertainty quantification.",
    "pdf_url": "http://arxiv.org/pdf/2505.15888v1",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15889v1",
    "title": "Strong Hilbert space fragmentation and fractons from subsystem and higher-form symmetries",
    "authors": [
      "Charles Stahl",
      "Oliver Hart",
      "Alexey Khudorozhkov",
      "Rahul Nandkishore"
    ],
    "abstract": "We introduce a new route to Hilbert space fragmentation in high dimensions\nleveraging the group-word formalism. We show that taking strongly fragmented\nmodels in one dimension and \"lifting\" to higher dimensions using subsystem\nsymmetries can yield strongly fragmented dynamics in higher dimensions, with\nsubdimensional (e.g., lineonic) excitations. This provides a new route to\nhigher-dimensional strong fragmentation, and also a new route to fractonic\nbehavior. Meanwhile, lifting one-dimensional strongly fragmented models to\nhigher dimensions using higher-form symmetries yields models with topologically\nrobust weak fragmentation. In three or more spatial dimensions, one can also\n\"mix and match\" subsystem and higher-form symmetries, leading to canonical\nfracton models such as X-cube. We speculate that this approach could also yield\na new route to non-Abelian fractons. These constructions unify a number of\nphenomena that have been discussed in the literature, as well as furnishing\nmodels with novel properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.15889v1",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.15890v2",
    "title": "Hydrogen 21 cm Constraints on the Photon's Spin Scale",
    "authors": [
      "Aidan Reilly",
      "Alessandro Russo",
      "Philip Schuster",
      "Natalia Toro"
    ],
    "abstract": "We explore the fundamental but untested possibility that the photon is a\ncontinuous spin particle (CSP) with a small but non-zero spin Casimir $\\rho$.\nWhen $\\rho\\neq 0$, the familiar polarization modes of the photon transform\nnon-trivially under Lorentz boosts, leading to deviations from familiar QED.\nSurprisingly, these deviations are strongest at low energy, but smoothly vanish\nin the $\\rho\\rightarrow 0$ limit. In this letter, we compute corrections to the\nhydrogen 21cm transition rate, which is expected to be particularly sensitive\ngiven the small hyperfine energy splitting $\\omega$. We find deviations from\nQED $\\propto \\rho^2 \\alpha^2/\\omega^2$ at leading order, suggesting\nexperimental constraints $\\rho\\lesssim 1$ meV. Building on this work, we expect\nthat a range of other atomic, molecular, or condensed matter systems could be\nused to provide even more stringent tests of $\\rho$ in electromagnetic\ninteractions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15890v2",
    "published": "2025-05-21T18:00:00+00:00",
    "categories": [
      "hep-ph",
      "physics.atom-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15819v1",
    "title": "Selection of optically variable active galactic nuclei via a random forest algorithm",
    "authors": [
      "Demetra De Cicco",
      "Gaetano Zazzaro",
      "Stefano Cavuoti",
      "Maurizio Paolillo",
      "Giuseppe Longo",
      "Vincenzo Petrecca",
      "Ivano Saccheo",
      "Paula S√°nchez-S√°ez"
    ],
    "abstract": "Context. A defining characteristic of active galactic nuclei (AGN) that\ndistinguishes them from other astronomical sources is their stochastic\nvariability, which is observable across the entire electromagnetic spectrum.\nUpcoming optical wide-field surveys, such as the Vera C. Rubin Observatory's\nLegacy Survey of Space and Time, are set to transform astronomy by delivering\nunprecedented volumes of data for time domain studies. This data influx will\nrequire the development of the expertise and methodologies necessary to manage\nand analyze it effectively. Aims. This project focuses on optimizing AGN\nselection through optical variability in wide-field surveys and aims to reduce\nthe bias against obscured AGN. We tested a random forest (RF) algorithm trained\non various feature sets to select AGN. The initial dataset consisted of 54\nobservations in the r-band and 25 in the g-band of the COSMOS field, captured\nwith the VLT Survey Telescope over a 3.3-year baseline. Methods. Our analysis\nrelies on feature sets derived separately from either band plus a set of\nfeatures combining data from both bands, mostly characterizing AGN on the basis\nof their variability properties and obtained from their light curves. We\ntrained multiple RF classifiers using different subsets of selected features\nand assessed their performance via targeted metrics. Results. Our tests provide\nvaluable insights into the use of multiband and multivisit data for AGN\nidentification. We compared our findings with previous studies and dedicated\npart of the analysis to potential enhancements in selecting obscured AGN. The\nexpertise gained and the methodologies developed here are readily applicable to\ndatasets from other ground- and space-based missions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15819v1",
    "published": "2025-05-21T17:59:58+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15818v1",
    "title": "InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition",
    "authors": [
      "Yijie Zheng",
      "Weijie Wu",
      "Qingyun Li",
      "Xuehui Wang",
      "Xu Zhou",
      "Aiai Ren",
      "Jun Shen",
      "Long Zhao",
      "Guoqing Li",
      "Xue Yang"
    ],
    "abstract": "Language-Guided object recognition in remote sensing imagery is crucial for\nlarge-scale mapping and automated data annotation. However, existing\nopen-vocabulary and visual grounding methods rely on explicit category cues,\nlimiting their ability to handle complex or implicit queries that require\nadvanced reasoning. To address this issue, we introduce a new suite of tasks,\nincluding Instruction-Oriented Object Counting, Detection, and Segmentation\n(InstructCDS), covering open-vocabulary, open-ended, and open-subclass\nscenarios. We further present EarthInstruct, the first InstructCDS benchmark\nfor earth observation. It is constructed from two diverse remote sensing\ndatasets with varying spatial resolutions and annotation rules across 20\ncategories, necessitating models to interpret dataset-specific instructions.\nGiven the scarcity of semantically rich labeled data in remote sensing, we\npropose InstructSAM, a training-free framework for instruction-driven object\nrecognition. InstructSAM leverages large vision-language models to interpret\nuser instructions and estimate object counts, employs SAM2 for mask proposal,\nand formulates mask-label assignment as a binary integer programming problem.\nBy integrating semantic similarity with counting constraints, InstructSAM\nefficiently assigns categories to predicted masks without relying on confidence\nthresholds. Experiments demonstrate that InstructSAM matches or surpasses\nspecialized baselines across multiple tasks while maintaining near-constant\ninference time regardless of object count, reducing output tokens by 89% and\noverall runtime by over 32% compared to direct generation approaches. We\nbelieve the contributions of the proposed tasks, benchmark, and effective\napproach will advance future research in developing versatile object\nrecognition systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15818v1",
    "published": "2025-05-21T17:59:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15880v2",
    "title": "Challenger: Affordable Adversarial Driving Video Generation",
    "authors": [
      "Zhiyuan Xu",
      "Bohan Li",
      "Huan-ang Gao",
      "Mingju Gao",
      "Yong Chen",
      "Ming Liu",
      "Chenxu Yan",
      "Hang Zhao",
      "Shuo Feng",
      "Hao Zhao"
    ],
    "abstract": "Generating photorealistic driving videos has seen significant progress\nrecently, but current methods largely focus on ordinary, non-adversarial\nscenarios. Meanwhile, efforts to generate adversarial driving scenarios often\noperate on abstract trajectory or BEV representations, falling short of\ndelivering realistic sensor data that can truly stress-test autonomous driving\n(AD) systems. In this work, we introduce Challenger, a framework that produces\nphysically plausible yet photorealistic adversarial driving videos. Generating\nsuch videos poses a fundamental challenge: it requires jointly optimizing over\nthe space of traffic interactions and high-fidelity sensor observations.\nChallenger makes this affordable through two techniques: (1) a physics-aware\nmulti-round trajectory refinement process that narrows down candidate\nadversarial maneuvers, and (2) a tailored trajectory scoring function that\nencourages realistic yet adversarial behavior while maintaining compatibility\nwith downstream video synthesis. As tested on the nuScenes dataset, Challenger\ngenerates a diverse range of aggressive driving scenarios-including cut-ins,\nsudden lane changes, tailgating, and blind spot intrusions-and renders them\ninto multiview photorealistic videos. Extensive evaluations show that these\nscenarios significantly increase the collision rate of state-of-the-art\nend-to-end AD models (UniAD, VAD, SparseDrive, and DiffusionDrive), and\nimportantly, adversarial behaviors discovered for one model often transfer to\nothers.",
    "pdf_url": "http://arxiv.org/pdf/2505.15880v2",
    "published": "2025-05-21T17:59:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15817v2",
    "title": "Learning to Reason via Mixture-of-Thought for Logical Reasoning",
    "authors": [
      "Tong Zheng",
      "Lichang Chen",
      "Simeng Han",
      "R. Thomas McCoy",
      "Heng Huang"
    ],
    "abstract": "Human beings naturally utilize multiple reasoning modalities to learn and\nsolve logical problems, i.e., different representational formats such as\nnatural language, code, and symbolic logic. In contrast, most existing\nLLM-based approaches operate with a single reasoning modality during training,\ntypically natural language. Although some methods explored modality selection\nor augmentation at inference time, the training process remains modality-blind,\nlimiting synergy among modalities. To fill in this gap, we propose\nMixture-of-Thought (MoT), a framework that enables LLMs to reason across three\ncomplementary modalities: natural language, code, and a newly introduced\nsymbolic modality, truth-table, which systematically enumerates logical cases\nand partially mitigates key failure modes in natural language reasoning. MoT\nadopts a two-phase design: (1) self-evolving MoT training, which jointly learns\nfrom filtered, self-generated rationales across modalities; and (2) MoT\ninference, which fully leverages the synergy of three modalities to produce\nbetter predictions. Experiments on logical reasoning benchmarks including FOLIO\nand ProofWriter demonstrate that our MoT framework consistently and\nsignificantly outperforms strong LLM baselines with single-modality\nchain-of-thought approaches, achieving up to +11.7pp average accuracy gain.\nFurther analyses show that our MoT framework benefits both training and\ninference stages; that it is particularly effective on harder logical reasoning\nproblems; and that different modalities contribute complementary strengths,\nwith truth-table reasoning helping to overcome key bottlenecks in natural\nlanguage inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.15817v2",
    "published": "2025-05-21T17:59:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15816v1",
    "title": "Streamline Without Sacrifice -- Squeeze out Computation Redundancy in LMM",
    "authors": [
      "Penghao Wu",
      "Lewei Lu",
      "Ziwei Liu"
    ],
    "abstract": "Large multimodal models excel in multimodal tasks but face significant\ncomputational challenges due to excessive computation on visual tokens. Unlike\ntoken reduction methods that focus on token-level redundancy, we identify and\nstudy the computation-level redundancy on vision tokens to ensure no\ninformation loss. Our key insight is that vision tokens from the pretrained\nvision encoder do not necessarily require all the heavy operations (e.g.,\nself-attention, FFNs) in decoder-only LMMs and could be processed more lightly\nwith proper designs. We designed a series of experiments to discover and\nprogressively squeeze out the vision-related computation redundancy. Based on\nour findings, we propose ProxyV, a novel approach that utilizes proxy vision\ntokens to alleviate the computational burden on original vision tokens. ProxyV\nenhances efficiency without compromising performance and can even yield notable\nperformance gains in scenarios with more moderate efficiency improvements.\nFurthermore, the flexibility of ProxyV is demonstrated through its combination\nwith token reduction methods to boost efficiency further. The code will be made\npublic at this https://github.com/penghao-wu/ProxyV URL.",
    "pdf_url": "http://arxiv.org/pdf/2505.15816v1",
    "published": "2025-05-21T17:59:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15815v1",
    "title": "On an Euler-Schr√∂dinger system appearing in laser-plasma interaction",
    "authors": [
      "Kuntal Bhandari",
      "Bernard Ducomet",
      "≈†arka Neƒçasov√°",
      "John Sebastian H. Simon"
    ],
    "abstract": "We consider the Cauchy problem for the barotropic Euler system coupled to a\nvector Schr\\\"{o}dinger equation in the whole space. Assuming that the initial\ndensity and vector potential are small enough, and that the initial velocity is\nclose to some reference vector field $u_0$ such that the spectrum of $Du_0$ is\nbounded away from zero, we prove the existence of a global-in-time unique\nsolution with (fractional) Sobolev regularity. Moreover, we obtain some\nalgebraic time decay estimates of the solution. Our work extends the papers by\nD. Serre and M. Grassin [11, 13, 19] and previous works by B. Ducomet and\nco-authors [4, 8] dedicated to the compressible Euler-Poisson system.",
    "pdf_url": "http://arxiv.org/pdf/2505.15815v1",
    "published": "2025-05-21T17:59:51+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15814v1",
    "title": "A Taxonomy of Structure from Motion Methods",
    "authors": [
      "Federica Arrigoni"
    ],
    "abstract": "Structure from Motion (SfM) refers to the problem of recovering both\nstructure (i.e., 3D coordinates of points in the scene) and motion (i.e.,\ncamera matrices) starting from point correspondences in multiple images. It has\nattracted significant attention over the years, counting practical\nreconstruction pipelines as well as theoretical results. This paper is\nconceived as a conceptual review of SfM methods, which are grouped into three\nmain categories, according to which part of the problem - between motion and\nstructure - they focus on. The proposed taxonomy brings a new perspective on\nexisting SfM approaches as well as insights into open problems and possible\nfuture research directions. Particular emphasis is given on identifying the\ntheoretical conditions that make SfM well posed, which depend on the problem\nformulation that is being considered.",
    "pdf_url": "http://arxiv.org/pdf/2505.15814v1",
    "published": "2025-05-21T17:59:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15813v1",
    "title": "Meta-Learning an In-Context Transformer Model of Human Higher Visual Cortex",
    "authors": [
      "Muquan Yu",
      "Mu Nan",
      "Hossein Adeli",
      "Jacob S. Prince",
      "John A. Pyles",
      "Leila Wehbe",
      "Margaret M. Henderson",
      "Michael J. Tarr",
      "Andrew F. Luo"
    ],
    "abstract": "Understanding functional representations within higher visual cortex is a\nfundamental question in computational neuroscience. While artificial neural\nnetworks pretrained on large-scale datasets exhibit striking representational\nalignment with human neural responses, learning image-computable models of\nvisual cortex relies on individual-level, large-scale fMRI datasets. The\nnecessity for expensive, time-intensive, and often impractical data acquisition\nlimits the generalizability of encoders to new subjects and stimuli. BraInCoRL\nuses in-context learning to predict voxelwise neural responses from few-shot\nexamples without any additional finetuning for novel subjects and stimuli. We\nleverage a transformer architecture that can flexibly condition on a variable\nnumber of in-context image stimuli, learning an inductive bias over multiple\nsubjects. During training, we explicitly optimize the model for in-context\nlearning. By jointly conditioning on image features and voxel activations, our\nmodel learns to directly generate better performing voxelwise models of higher\nvisual cortex. We demonstrate that BraInCoRL consistently outperforms existing\nvoxelwise encoder designs in a low-data regime when evaluated on entirely novel\nimages, while also exhibiting strong test-time scaling behavior. The model also\ngeneralizes to an entirely new visual fMRI dataset, which uses different\nsubjects and fMRI data acquisition parameters. Further, BraInCoRL facilitates\nbetter interpretability of neural signals in higher visual cortex by attending\nto semantically relevant stimuli. Finally, we show that our framework enables\ninterpretable mappings from natural language queries to voxel selectivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15813v1",
    "published": "2025-05-21T17:59:41+00:00",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15812v1",
    "title": "Leveraging the Powerful Attention of a Pre-trained Diffusion Model for Exemplar-based Image Colorization",
    "authors": [
      "Satoshi Kosugi"
    ],
    "abstract": "Exemplar-based image colorization aims to colorize a grayscale image using a\nreference color image, ensuring that reference colors are applied to\ncorresponding input regions based on their semantic similarity. To achieve\naccurate semantic matching between regions, we leverage the self-attention\nmodule of a pre-trained diffusion model, which is trained on a large dataset\nand exhibits powerful attention capabilities. To harness this power, we propose\na novel, fine-tuning-free approach based on a pre-trained diffusion model,\nmaking two key contributions. First, we introduce dual attention-guided color\ntransfer. We utilize the self-attention module to compute an attention map\nbetween the input and reference images, effectively capturing semantic\ncorrespondences. The color features from the reference image is then\ntransferred to the semantically matching regions of the input image, guided by\nthis attention map, and finally, the grayscale features are replaced with the\ncorresponding color features. Notably, we utilize dual attention to calculate\nattention maps separately for the grayscale and color images, achieving more\nprecise semantic alignment. Second, we propose classifier-free colorization\nguidance, which enhances the transferred colors by combining color-transferred\nand non-color-transferred outputs. This process improves the quality of\ncolorization. Our experimental results demonstrate that our method outperforms\nexisting techniques in terms of image quality and fidelity to the reference.\nSpecifically, we use 335 input-reference pairs from previous research,\nachieving an FID of 95.27 (image quality) and an SI-FID of 5.51 (fidelity to\nthe reference). Our source code is available at\nhttps://github.com/satoshi-kosugi/powerful-attention.",
    "pdf_url": "http://arxiv.org/pdf/2505.15812v1",
    "published": "2025-05-21T17:59:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15811v1",
    "title": "On the creation of narrow AI: hierarchy and nonlocality of neural network skills",
    "authors": [
      "Eric J. Michaud",
      "Asher Parker-Sartori",
      "Max Tegmark"
    ],
    "abstract": "We study the problem of creating strong, yet narrow, AI systems. While recent\nAI progress has been driven by the training of large general-purpose foundation\nmodels, the creation of smaller models specialized for narrow domains could be\nvaluable for both efficiency and safety. In this work, we explore two\nchallenges involved in creating such systems, having to do with basic\nproperties of how neural networks learn and structure their representations.\nThe first challenge regards when it is possible to train narrow models from\nscratch. Through experiments on a synthetic task, we find that it is sometimes\nnecessary to train networks on a wide distribution of data to learn certain\nnarrow skills within that distribution. This effect arises when skills depend\non each other hierarchically, and training on a broad distribution introduces a\ncurriculum which substantially accelerates learning. The second challenge\nregards how to transfer particular skills from large general models into small\nspecialized models. We find that model skills are often not perfectly localized\nto a particular set of prunable components. However, we find that methods based\non pruning can still outperform distillation. We investigate the use of a\nregularization objective to align desired skills with prunable components while\nunlearning unnecessary skills.",
    "pdf_url": "http://arxiv.org/pdf/2505.15811v1",
    "published": "2025-05-21T17:59:21+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17123v2",
    "title": "MTR-Bench: A Comprehensive Benchmark for Multi-Turn Reasoning Evaluation",
    "authors": [
      "Xiaoyuan Li",
      "Keqin Bao",
      "Yubo Ma",
      "Moxin Li",
      "Wenjie Wang",
      "Rui Men",
      "Yichang Zhang",
      "Fuli Feng",
      "Dayiheng Liu",
      "Junyang Lin"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have shown promising results\nin complex reasoning tasks. However, current evaluations predominantly focus on\nsingle-turn reasoning scenarios, leaving interactive tasks largely unexplored.\nWe attribute it to the absence of comprehensive datasets and scalable automatic\nevaluation protocols. To fill these gaps, we present MTR-Bench for LLMs'\nMulti-Turn Reasoning evaluation. Comprising 4 classes, 40 tasks, and 3600\ninstances, MTR-Bench covers diverse reasoning capabilities, fine-grained\ndifficulty granularity, and necessitates multi-turn interactions with the\nenvironments. Moreover, MTR-Bench features fully-automated framework spanning\nboth dataset constructions and model evaluations, which enables scalable\nassessment without human interventions. Extensive experiments reveal that even\nthe cutting-edge reasoning models fall short of multi-turn, interactive\nreasoning tasks. And the further analysis upon these results brings valuable\ninsights for future research in interactive AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17123v2",
    "published": "2025-05-21T17:59:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15810v2",
    "title": "GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents",
    "authors": [
      "Yuqi Zhou",
      "Sunhao Dai",
      "Shuai Wang",
      "Kaiwen Zhou",
      "Qinglin Jia",
      "Jun Xu"
    ],
    "abstract": "Recent Graphical User Interface (GUI) agents replicate the R1-Zero paradigm,\ncoupling online Reinforcement Learning (RL) with explicit chain-of-thought\nreasoning prior to object grounding and thereby achieving substantial\nperformance gains. In this paper, we first conduct extensive analysis\nexperiments of three key components of that training pipeline: input design,\noutput evaluation, and policy update-each revealing distinct challenges arising\nfrom blindly applying general-purpose RL without adapting to GUI grounding\ntasks. Input design: Current templates encourage the model to generate\nchain-of-thought reasoning, but longer chains unexpectedly lead to worse\ngrounding performance. Output evaluation: Reward functions based on hit signals\nor box area allow models to exploit box size, leading to reward hacking and\npoor localization quality. Policy update: Online RL tends to overfit easy\nexamples due to biases in length and sample difficulty, leading to\nunder-optimization on harder cases. To address these issues, we propose three\ntargeted solutions. First, we adopt a Fast Thinking Template that encourages\ndirect answer generation, reducing excessive reasoning during training. Second,\nwe incorporate a box size constraint into the reward function to mitigate\nreward hacking. Third, we revise the RL objective by adjusting length\nnormalization and adding a difficulty-aware scaling factor, enabling better\noptimization on hard samples. Our GUI-G1-3B, trained on 17K public samples with\nQwen2.5-VL-3B-Instruct, achieves 90.3% accuracy on ScreenSpot and 37.1% on\nScreenSpot-Pro. This surpasses all prior models of similar size and even\noutperforms the larger UI-TARS-7B, establishing a new state-of-the-art in GUI\nagent grounding. The project repository is available at\nhttps://github.com/Yuqi-Zhou/GUI-G1.",
    "pdf_url": "http://arxiv.org/pdf/2505.15810v2",
    "published": "2025-05-21T17:59:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15809v1",
    "title": "MMaDA: Multimodal Large Diffusion Language Models",
    "authors": [
      "Ling Yang",
      "Ye Tian",
      "Bowen Li",
      "Xinchen Zhang",
      "Ke Shen",
      "Yunhai Tong",
      "Mengdi Wang"
    ],
    "abstract": "We introduce MMaDA, a novel class of multimodal diffusion foundation models\ndesigned to achieve superior performance across diverse domains such as textual\nreasoning, multimodal understanding, and text-to-image generation. The approach\nis distinguished by three key innovations: (i) MMaDA adopts a unified diffusion\narchitecture with a shared probabilistic formulation and a modality-agnostic\ndesign, eliminating the need for modality-specific components. This\narchitecture ensures seamless integration and processing across different data\ntypes. (ii) We implement a mixed long chain-of-thought (CoT) fine-tuning\nstrategy that curates a unified CoT format across modalities. By aligning\nreasoning processes between textual and visual domains, this strategy\nfacilitates cold-start training for the final reinforcement learning (RL)\nstage, thereby enhancing the model's ability to handle complex tasks from the\noutset. (iii) We propose UniGRPO, a unified policy-gradient-based RL algorithm\nspecifically tailored for diffusion foundation models. Utilizing diversified\nreward modeling, UniGRPO unifies post-training across both reasoning and\ngeneration tasks, ensuring consistent performance improvements. Experimental\nresults demonstrate that MMaDA-8B exhibits strong generalization capabilities\nas a unified multimodal foundation model. It surpasses powerful models like\nLLaMA-3-7B and Qwen2-7B in textual reasoning, outperforms Show-o and SEED-X in\nmultimodal understanding, and excels over SDXL and Janus in text-to-image\ngeneration. These achievements highlight MMaDA's effectiveness in bridging the\ngap between pretraining and post-training within unified diffusion\narchitectures, providing a comprehensive framework for future research and\ndevelopment. We open-source our code and trained models at:\nhttps://github.com/Gen-Verse/MMaDA",
    "pdf_url": "http://arxiv.org/pdf/2505.15809v1",
    "published": "2025-05-21T17:59:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15808v1",
    "title": "Neural Conditional Transport Maps",
    "authors": [
      "Carlos Rodriguez-Pardo",
      "Leonardo Chiani",
      "Emanuele Borgonovo",
      "Massimo Tavoni"
    ],
    "abstract": "We present a neural framework for learning conditional optimal transport (OT)\nmaps between probability distributions. Our approach introduces a conditioning\nmechanism capable of processing both categorical and continuous conditioning\nvariables simultaneously. At the core of our method lies a hypernetwork that\ngenerates transport layer parameters based on these inputs, creating adaptive\nmappings that outperform simpler conditioning methods. Comprehensive ablation\nstudies demonstrate the superior performance of our method over baseline\nconfigurations. Furthermore, we showcase an application to global sensitivity\nanalysis, offering high performance in computing OT-based sensitivity indices.\nThis work advances the state-of-the-art in conditional optimal transport,\nenabling broader application of optimal transport principles to complex,\nhigh-dimensional domains such as generative modeling and black-box model\nexplainability.",
    "pdf_url": "http://arxiv.org/pdf/2505.15808v1",
    "published": "2025-05-21T17:59:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.PR",
      "stat.AP",
      "stat.ML",
      "49Q22 (Primary) 68T07 (Secondary)",
      "I.5.1; I.2.0; G.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17122v1",
    "title": "Shallow Preference Signals: Large Language Model Aligns Even Better with Truncated Data?",
    "authors": [
      "Xuan Qi",
      "Jiahao Qiu",
      "Xinzhe Juan",
      "Yue Wu",
      "Mengdi Wang"
    ],
    "abstract": "Aligning large language models (LLMs) with human preferences remains a key\nchallenge in AI. Preference-based optimization methods, such as Reinforcement\nLearning with Human Feedback (RLHF) and Direct Preference Optimization (DPO),\nrely on human-annotated datasets to improve alignment. In this work, we\nidentify a crucial property of the existing learning method: the distinguishing\nsignal obtained in preferred responses is often concentrated in the early\ntokens. We refer to this as shallow preference signals.\n  To explore this property, we systematically truncate preference datasets at\nvarious points and train both reward models and DPO models on the truncated\ndata. Surprisingly, models trained on truncated datasets, retaining only the\nfirst half or fewer tokens, achieve comparable or even superior performance to\nthose trained on full datasets. For example, a reward model trained on the\nSkywork-Reward-Preference-80K-v0.2 dataset outperforms the full dataset when\ntrained on a 40\\% truncated dataset. This pattern is consistent across multiple\ndatasets, suggesting the widespread presence of shallow preference signals.\n  We further investigate the distribution of the reward signal through decoding\nstrategies. We consider two simple decoding strategies motivated by the shallow\nreward signal observation, namely Length Control Decoding and KL Threshold\nControl Decoding, which leverage shallow preference signals to optimize the\ntrade-off between alignment and computational efficiency. The performance is\neven better, which again validates our hypothesis.\n  The phenomenon of shallow preference signals highlights potential issues in\nLLM alignment: existing alignment methods often focus on aligning only the\ninitial tokens of responses, rather than considering the full response. This\ncould lead to discrepancies with real-world human preferences, resulting in\nsuboptimal alignment performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.17122v1",
    "published": "2025-05-21T17:59:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15807v1",
    "title": "The Atlas of In-Context Learning: How Attention Heads Shape In-Context Retrieval Augmentation",
    "authors": [
      "Patrick Kahardipraja",
      "Reduan Achtibat",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "abstract": "Large language models are able to exploit in-context learning to access\nexternal knowledge beyond their training data through retrieval-augmentation.\nWhile promising, its inner workings remain unclear. In this work, we shed light\non the mechanism of in-context retrieval augmentation for question answering by\nviewing a prompt as a composition of informational components. We propose an\nattribution-based method to identify specialized attention heads, revealing\nin-context heads that comprehend instructions and retrieve relevant contextual\ninformation, and parametric heads that store entities' relational knowledge. To\nbetter understand their roles, we extract function vectors and modify their\nattention weights to show how they can influence the answer generation process.\nFinally, we leverage the gained insights to trace the sources of knowledge used\nduring inference, paving the way towards more safe and transparent language\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.15807v1",
    "published": "2025-05-21T17:59:01+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15806v1",
    "title": "Discovery of a dwarf planet candidate in an extremely wide orbit: 2017 OF201",
    "authors": [
      "Sihao Cheng",
      "Jiaxuan Li",
      "Eritas Yang"
    ],
    "abstract": "We report the discovery of a dwarf planet candidate, 2017 OF201, currently\nlocated at a distance of 90.5 au. Its orbit is extremely wide and extends to\nthe inner Oort cloud, with a semi-major axis of 838 au and a perihelion of 44.9\nau precisely determined from 19 observations over seven years. Assuming a\ntypical albedo of 0.15, we estimate a diameter about 700 km, making it the\nsecond-largest known object in this dynamical population and a likely dwarf\nplanet. Its high eccentricity suggests that it is part of a broader, unseen\npopulation of similar objects totaling about 1 % of Earth's mass. Notably, the\norbit of 2017 OF201 lies well outside the clustering of longitude of perihelion\nobserved in extreme trans-Neptunian objects, which has been proposed as\ndynamical evidence for a distant, undetected planet.",
    "pdf_url": "http://arxiv.org/pdf/2505.15806v1",
    "published": "2025-05-21T17:58:16+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15805v1",
    "title": "Keep Security! Benchmarking Security Policy Preservation in Large Language Model Contexts Against Indirect Attacks in Question Answering",
    "authors": [
      "Hwan Chang",
      "Yumin Kim",
      "Yonghyun Jun",
      "Hwanhee Lee"
    ],
    "abstract": "As Large Language Models (LLMs) are increasingly deployed in sensitive\ndomains such as enterprise and government, ensuring that they adhere to\nuser-defined security policies within context is critical-especially with\nrespect to information non-disclosure. While prior LLM studies have focused on\ngeneral safety and socially sensitive data, large-scale benchmarks for\ncontextual security preservation against attacks remain lacking. To address\nthis, we introduce a novel large-scale benchmark dataset, CoPriva, evaluating\nLLM adherence to contextual non-disclosure policies in question answering.\nDerived from realistic contexts, our dataset includes explicit policies and\nqueries designed as direct and challenging indirect attacks seeking prohibited\ninformation. We evaluate 10 LLMs on our benchmark and reveal a significant\nvulnerability: many models violate user-defined policies and leak sensitive\ninformation. This failure is particularly severe against indirect attacks,\nhighlighting a critical gap in current LLM safety alignment for sensitive\napplications. Our analysis reveals that while models can often identify the\ncorrect answer to a query, they struggle to incorporate policy constraints\nduring generation. In contrast, they exhibit a partial ability to revise\noutputs when explicitly prompted. Our findings underscore the urgent need for\nmore robust methods to guarantee contextual security.",
    "pdf_url": "http://arxiv.org/pdf/2505.15805v1",
    "published": "2025-05-21T17:58:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15804v3",
    "title": "STAR-R1: Spatial TrAnsformation Reasoning by Reinforcing Multimodal LLMs",
    "authors": [
      "Zongzhao Li",
      "Zongyang Ma",
      "Mingze Li",
      "Songyou Li",
      "Yu Rong",
      "Tingyang Xu",
      "Ziqi Zhang",
      "Deli Zhao",
      "Wenbing Huang"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities across diverse tasks, yet they lag significantly behind humans in\nspatial reasoning. We investigate this gap through Transformation-Driven Visual\nReasoning (TVR), a challenging task requiring identification of object\ntransformations across images under varying viewpoints. While traditional\nSupervised Fine-Tuning (SFT) fails to generate coherent reasoning paths in\ncross-view settings, sparse-reward Reinforcement Learning (RL) suffers from\ninefficient exploration and slow convergence. To address these limitations, we\npropose STAR-R1, a novel framework that integrates a single-stage RL paradigm\nwith a fine-grained reward mechanism tailored for TVR. Specifically, STAR-R1\nrewards partial correctness while penalizing excessive enumeration and passive\ninaction, enabling efficient exploration and precise reasoning. Comprehensive\nevaluations demonstrate that STAR-R1 achieves state-of-the-art performance\nacross all 11 metrics, outperforming SFT by 23% in cross-view scenarios.\nFurther analysis reveals STAR-R1's anthropomorphic behavior and highlights its\nunique ability to compare all objects for improving spatial reasoning. Our work\nprovides critical insights in advancing the research of MLLMs and reasoning\nmodels. The codes, model weights, and data will be publicly available at\nhttps://github.com/zongzhao23/STAR-R1.",
    "pdf_url": "http://arxiv.org/pdf/2505.15804v3",
    "published": "2025-05-21T17:57:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15803v1",
    "title": "Adaptive Estimation and Learning under Temporal Distribution Shift",
    "authors": [
      "Dheeraj Baby",
      "Yifei Tang",
      "Hieu Duy Nguyen",
      "Yu-Xiang Wang",
      "Rohit Pyati"
    ],
    "abstract": "In this paper, we study the problem of estimation and learning under temporal\ndistribution shift. Consider an observation sequence of length $n$, which is a\nnoisy realization of a time-varying groundtruth sequence. Our focus is to\ndevelop methods to estimate the groundtruth at the final time-step while\nproviding sharp point-wise estimation error rates. We show that, without prior\nknowledge on the level of temporal shift, a wavelet soft-thresholding estimator\nprovides an optimal estimation error bound for the groundtruth. Our proposed\nestimation method generalizes existing researches Mazzetto and Upfal (2023) by\nestablishing a connection between the sequence's non-stationarity level and the\nsparsity in the wavelet-transformed domain. Our theoretical findings are\nvalidated by numerical experiments. Additionally, we applied the estimator to\nderive sparsity-aware excess risk bounds for binary classification under\ndistribution shift and to develop computationally efficient training\nobjectives. As a final contribution, we draw parallels between our results and\nthe classical signal processing problem of total-variation denoising (Mammen\nand van de Geer,1997; Tibshirani, 2014), uncovering novel optimal algorithms\nfor such task.",
    "pdf_url": "http://arxiv.org/pdf/2505.15803v1",
    "published": "2025-05-21T17:56:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15802v2",
    "title": "A Deep Learning Framework for Two-Dimensional, Multi-Frequency Propagation Factor Estimation",
    "authors": [
      "Sarah E. Wessinger",
      "Leslie N. Smith",
      "Jacob Gull",
      "Jonathan Gehman",
      "Zachary Beever",
      "Andrew J. Kammerer"
    ],
    "abstract": "Accurately estimating the refractive environment over multiple frequencies\nwithin the marine atmospheric boundary layer is crucial for the effective\ndeployment of radar technologies. Traditional parabolic equation simulations,\nwhile effective, can be computationally expensive and time-intensive, limiting\ntheir practical application. This communication explores a novel approach using\ndeep neural networks to estimate the pattern propagation factor, a critical\nparameter for characterizing environmental impacts on signal propagation.\nImage-to-image translation generators designed to ingest modified refractivity\ndata and generate predictions of pattern propagation factors over the same\ndomain were developed. Findings demonstrate that deep neural networks can be\ntrained to analyze multiple frequencies and reasonably predict the pattern\npropagation factor, offering an alternative to traditional methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15802v2",
    "published": "2025-05-21T17:56:02+00:00",
    "categories": [
      "cs.LG",
      "eess.SP",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15879v1",
    "title": "GRIT: Teaching MLLMs to Think with Images",
    "authors": [
      "Yue Fan",
      "Xuehai He",
      "Diji Yang",
      "Kaizhi Zheng",
      "Ching-Chen Kuo",
      "Yuting Zheng",
      "Sravana Jyothi Narayanaraju",
      "Xinze Guan",
      "Xin Eric Wang"
    ],
    "abstract": "Recent studies have demonstrated the efficacy of using Reinforcement Learning\n(RL) in building reasoning models that articulate chains of thoughts prior to\nproducing final answers. However, despite ongoing advances that aim at enabling\nreasoning for vision-language tasks, existing open-source visual reasoning\nmodels typically generate reasoning content with pure natural language, lacking\nexplicit integration of visual information. This limits their ability to\nproduce clearly articulated and visually grounded reasoning chains. To this\nend, we propose Grounded Reasoning with Images and Texts (GRIT), a novel method\nfor training MLLMs to think with images. GRIT introduces a grounded reasoning\nparadigm, in which models generate reasoning chains that interleave natural\nlanguage and explicit bounding box coordinates. These coordinates point to\nregions of the input image that the model consults during its reasoning\nprocess. Additionally, GRIT is equipped with a reinforcement learning approach,\nGRPO-GR, built upon the GRPO algorithm. GRPO-GR employs robust rewards focused\non the final answer accuracy and format of the grounded reasoning output, which\neliminates the need for data with reasoning chain annotations or explicit\nbounding box labels. As a result, GRIT achieves exceptional data efficiency,\nrequiring as few as 20 image-question-answer triplets from existing datasets.\nComprehensive evaluations demonstrate that GRIT effectively trains MLLMs to\nproduce coherent and visually grounded reasoning chains, showing a successful\nunification of reasoning and grounding abilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15879v1",
    "published": "2025-05-21T17:54:49+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15878v1",
    "title": "Readout sweet spots for spin qubits with strong spin-orbit interaction",
    "authors": [
      "Domonkos Svastits",
      "Bence Het√©nyi",
      "G√°bor Sz√©chenyi",
      "James Wootton",
      "Daniel Loss",
      "Stefano Bosco",
      "Andr√°s P√°lyi"
    ],
    "abstract": "Qubit readout schemes often deviate from ideal projective measurements,\nintroducing critical issues that limit quantum computing performance. In this\nwork, we model charge-sensing-based readout for semiconductor spin qubits in\ndouble quantum dots, and identify key error mechanisms caused by the\nback-action of the charge sensor. We quantify how the charge noise of the\nsensor, residual tunneling, and $g$-tensor modulation degrade readout fidelity,\ninduce a mixed post-measurement state, and cause leakage from the computational\nsubspace. For state-of-the-art systems with strong spin-orbit interaction and\nelectrically tunable $g$-tensors, we identify a readout sweet spot, that is, a\nspecial device configuration where readout is closest to projective. Our\nframework provides a foundation for developing effective readout error\nmitigation strategies, with broad applications for optimizing readout\nperformance for a variety of charge-sensing techniques, advancing quantum\nprotocols, and improving adaptive circuits for error correction.",
    "pdf_url": "http://arxiv.org/pdf/2505.15878v1",
    "published": "2025-05-21T17:54:48+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15801v2",
    "title": "VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models",
    "authors": [
      "Yuchen Yan",
      "Jin Jiang",
      "Zhenbang Ren",
      "Yijun Li",
      "Xudong Cai",
      "Yang Liu",
      "Xin Xu",
      "Mengdi Zhang",
      "Jian Shao",
      "Yongliang Shen",
      "Jun Xiao",
      "Yueting Zhuang"
    ],
    "abstract": "Large reasoning models such as OpenAI o1 and DeepSeek-R1 have achieved\nremarkable performance in the domain of reasoning. A key component of their\ntraining is the incorporation of verifiable rewards within reinforcement\nlearning (RL). However, existing reward benchmarks do not evaluate\nreference-based reward systems, leaving researchers with limited understanding\nof the accuracy of verifiers used in RL. In this paper, we introduce two\nbenchmarks, VerifyBench and VerifyBench-Hard, designed to assess the\nperformance of reference-based reward systems. These benchmarks are constructed\nthrough meticulous data collection and curation, followed by careful human\nannotation to ensure high quality. Current models still show considerable room\nfor improvement on both VerifyBench and VerifyBench-Hard, especially\nsmaller-scale models. Furthermore, we conduct a thorough and comprehensive\nanalysis of evaluation results, offering insights for understanding and\ndeveloping reference-based reward systems. Our proposed benchmarks serve as\neffective tools for guiding the development of verifier accuracy and the\nreasoning capabilities of models trained via RL in reasoning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15801v2",
    "published": "2025-05-21T17:54:43+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15800v2",
    "title": "Interspatial Attention for Efficient 4D Human Video Generation",
    "authors": [
      "Ruizhi Shao",
      "Yinghao Xu",
      "Yujun Shen",
      "Ceyuan Yang",
      "Yang Zheng",
      "Changan Chen",
      "Yebin Liu",
      "Gordon Wetzstein"
    ],
    "abstract": "Generating photorealistic videos of digital humans in a controllable manner\nis crucial for a plethora of applications. Existing approaches either build on\nmethods that employ template-based 3D representations or emerging video\ngeneration models but suffer from poor quality or limited consistency and\nidentity preservation when generating individual or multiple digital humans. In\nthis paper, we introduce a new interspatial attention (ISA) mechanism as a\nscalable building block for modern diffusion transformer (DiT)--based video\ngeneration models. ISA is a new type of cross attention that uses relative\npositional encodings tailored for the generation of human videos. Leveraging a\ncustom-developed video variation autoencoder, we train a latent ISA-based\ndiffusion model on a large corpus of video data. Our model achieves\nstate-of-the-art performance for 4D human video synthesis, demonstrating\nremarkable motion consistency and identity preservation while providing precise\ncontrol of the camera and body poses. Our code and model are publicly released\nat https://dsaurus.github.io/isa4d/.",
    "pdf_url": "http://arxiv.org/pdf/2505.15800v2",
    "published": "2025-05-21T17:53:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15799v2",
    "title": "The Agentic Economy",
    "authors": [
      "David M. Rothschild",
      "Markus Mobius",
      "Jake M. Hofman",
      "Eleanor W. Dillon",
      "Daniel G. Goldstein",
      "Nicole Immorlica",
      "Sonia Jaffe",
      "Brendan Lucier",
      "Aleksandrs Slivkins",
      "Matthew Vogel"
    ],
    "abstract": "Generative AI has transformed human-computer interaction by enabling natural\nlanguage interfaces and the emergence of autonomous agents capable of acting on\nusers' behalf. While early applications have improved individual productivity,\nthese gains have largely been confined to predefined tasks within existing\nworkflows. We argue that the more profound economic impact lies in reducing\ncommunication frictions between consumers and businesses. This shift could\nreorganize markets, redistribute power, and catalyze the creation of new\nproducts and services. We explore the implications of an agentic economy, where\nassistant agents act on behalf of consumers and service agents represent\nbusinesses, interacting programmatically to facilitate transactions. A key\ndistinction we draw is between unscripted interactions -- enabled by technical\nadvances in natural language and protocol design -- and unrestricted\ninteractions, which depend on market structures and governance. We examine the\ncurrent limitations of siloed and end-to-end agents, and explore future\nscenarios shaped by technical standards and market dynamics. These include the\npotential tension between agentic walled gardens and an open web of agents,\nimplications for advertising and discovery, the evolution of\nmicro-transactions, and the unbundling and rebundling of digital goods.\nUltimately, we argue that the architecture of agentic communication will\ndetermine the extent to which generative AI democratizes access to economic\nopportunity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15799v2",
    "published": "2025-05-21T17:51:36+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15798v1",
    "title": "Model Merging is Secretly Certifiable: Non-Vacuous Generalisation Bounds for Low-Shot Learning",
    "authors": [
      "Taehoon Kim",
      "Henry Gouk",
      "Minyoung Kim",
      "Timothy Hospedales"
    ],
    "abstract": "Certifying the IID generalisation ability of deep networks is the first of\nmany requirements for trusting AI in high-stakes applications from medicine to\nsecurity. However, when instantiating generalisation bounds for deep networks\nit remains challenging to obtain non-vacuous guarantees, especially when\napplying contemporary large models on the small scale data prevalent in such\nhigh-stakes fields. In this paper, we draw a novel connection between a family\nof learning methods based on model fusion and generalisation certificates, and\nsurprisingly show that with minor adjustment several existing learning\nstrategies already provide non-trivial generalisation guarantees. Essentially,\nby focusing on data-driven learning of downstream tasks by fusion rather than\nfine-tuning, the certified generalisation gap becomes tiny and independent of\nthe base network size, facilitating its certification. Our results show for the\nfirst time non-trivial generalisation guarantees for learning with as low as\n100 examples, while using vision models such as VIT-B and language models such\nas mistral-7B. This observation is significant as it has immediate implications\nfor facilitating the certification of existing systems as trustworthy, and\nopens up new directions for research at the intersection of practice and\ntheory.",
    "pdf_url": "http://arxiv.org/pdf/2505.15798v1",
    "published": "2025-05-21T17:51:05+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15797v1",
    "title": "VoteMate: A Decentralized Application for Scalable Electronic Voting on EVM-Based Blockchain",
    "authors": [
      "Ivan Homoliak",
      "Tom√°≈° ≈†vondr"
    ],
    "abstract": "Voting is a cornerstone of democracy, allowing citizens to express their will\nand make collective decisions. With advancing technology, online voting is\ngaining popularity as it enables voting from anywhere with Internet access,\neliminating the need for printed ballots or polling stations. However, despite\nits benefits, online voting carries significant risks. A single vulnerability\ncould be exploited to manipulate elections on a large scale. Centralized\nsystems can be secure but may lack transparency and confidentiality, especially\nif those in power manipulate them. Blockchain-based voting offers a\ntransparent, tamper-resistant alternative with end-to-end verifiability and\nstrong security. Adding cryptographic layers can also ensure voter\nconfidentiality.",
    "pdf_url": "http://arxiv.org/pdf/2505.15797v1",
    "published": "2025-05-21T17:50:18+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15796v1",
    "title": "Lean-SMT: An SMT tactic for discharging proof goals in Lean",
    "authors": [
      "Abdalrhman Mohamed",
      "Tomaz Mascarenhas",
      "Harun Khan",
      "Haniel Barbosa",
      "Andrew Reynolds",
      "Yicheng Qian",
      "Cesare Tinelli",
      "Clark Barrett"
    ],
    "abstract": "Lean is an increasingly popular proof assistant based on dependent type\ntheory. Despite its success, it still lacks important automation features\npresent in more seasoned proof assistants, such as the Sledgehammer tactic in\nIsabelle/HOL. A key aspect of Sledgehammer is the use of proof-producing SMT\nsolvers to prove a translated proof goal and the reconstruction of the\nresulting proof into valid justifications for the original goal. We present\nLean-SMT, a tactic providing this functionality in Lean. We detail how the\ntactic converts Lean goals into SMT problems and, more importantly, how it\nreconstructs SMT proofs into native Lean proofs. We evaluate the tactic on\nestablished benchmarks used to evaluate Sledgehammer's SMT integration, with\npromising results. We also evaluate Lean-SMT as a standalone proof checker for\nproofs of SMT-LIB problems. We show that Lean-SMT offers a smaller trusted core\nwithout sacrificing too much performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15796v1",
    "published": "2025-05-21T17:49:43+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15795v1",
    "title": "Reverse Engineering Human Preferences with Reinforcement Learning",
    "authors": [
      "Lisa Alazraki",
      "Tan Yi-Chern",
      "Jon Ander Campos",
      "Maximilian Mozes",
      "Marek Rei",
      "Max Bartolo"
    ],
    "abstract": "The capabilities of Large Language Models (LLMs) are routinely evaluated by\nother LLMs trained to predict human preferences. This framework--known as\nLLM-as-a-judge--is highly scalable and relatively low cost. However, it is also\nvulnerable to malicious exploitation, as LLM responses can be tuned to overfit\nthe preferences of the judge. Previous work shows that the answers generated by\na candidate-LLM can be edited post hoc to maximise the score assigned to them\nby a judge-LLM. In this study, we adopt a different approach and use the signal\nprovided by judge-LLMs as a reward to adversarially tune models that generate\ntext preambles designed to boost downstream performance. We find that frozen\nLLMs pipelined with these models attain higher LLM-evaluation scores than\nexisting frameworks. Crucially, unlike other frameworks which intervene\ndirectly on the model's response, our method is virtually undetectable. We also\ndemonstrate that the effectiveness of the tuned preamble generator transfers\nwhen the candidate-LLM and the judge-LLM are replaced with models that are not\nused during training. These findings raise important questions about the design\nof more reliable LLM-as-a-judge evaluation settings. They also demonstrate that\nhuman preferences can be reverse engineered effectively, by pipelining LLMs to\noptimise upstream preambles via reinforcement learning--an approach that could\nfind future applications in diverse tasks and domains beyond adversarial\nattacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15795v1",
    "published": "2025-05-21T17:48:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15794v1",
    "title": "One-sample location tests based on center-outward signs and ranks",
    "authors": [
      "Daniel Hlubinka",
      "≈†√°rka Hudecov√°"
    ],
    "abstract": "A multivariate one-sample location test based on the center-outward ranks and\nsigns is considered, and two different testing procedures are proposed for\ncentrally symmetric distributions. The first test is based on a random division\nof the data into two samples, while the second one uses a symmetrized sample.\nThe asymptotic distributions of the proposed tests are provided. For univariate\ndata, two variants of the symmetrized test statistic are shown to be equivalent\nto the standard sign and Wilcoxon test respectively. The small sample behavior\nof the proposed techniques is illustrated by a simulation study that also\nprovides a power comparison for various transportation grids.",
    "pdf_url": "http://arxiv.org/pdf/2505.15794v1",
    "published": "2025-05-21T17:47:51+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.15793v2",
    "title": "HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving",
    "authors": [
      "Zhiwen Chen",
      "Bo Leng",
      "Zhuoren Li",
      "Hanming Deng",
      "Guizhe Jin",
      "Ran Yu",
      "Huanxi Wen"
    ],
    "abstract": "Integrating Large Language Models (LLMs) with Reinforcement Learning (RL) can\nenhance autonomous driving (AD) performance in complex scenarios. However,\ncurrent LLM-Dominated RL methods over-rely on LLM outputs, which are prone to\nhallucinations. Evaluations show that state-of-the-art LLM indicates a\nnon-hallucination rate of only approximately 57.95% when assessed on essential\ndriving-related tasks. Thus, in these methods, hallucinations from the LLM can\ndirectly jeopardize the performance of driving policies. This paper argues that\nmaintaining relative independence between the LLM and the RL is vital for\nsolving the hallucinations problem. Consequently, this paper is devoted to\npropose a novel LLM-Hinted RL paradigm. The LLM is used to generate semantic\nhints for state augmentation and policy optimization to assist RL agent in\nmotion planning, while the RL agent counteracts potential erroneous semantic\nindications through policy learning to achieve excellent driving performance.\nBased on this paradigm, we propose the HCRMP (LLM-Hinted Contextual\nReinforcement Learning Motion Planner) architecture, which is designed that\nincludes Augmented Semantic Representation Module to extend state space.\nContextual Stability Anchor Module enhances the reliability of multi-critic\nweight hints by utilizing information from the knowledge base. Semantic Cache\nModule is employed to seamlessly integrate LLM low-frequency guidance with RL\nhigh-frequency control. Extensive experiments in CARLA validate HCRMP's strong\noverall driving performance. HCRMP achieves a task success rate of up to 80.3%\nunder diverse driving conditions with different traffic densities. Under\nsafety-critical driving conditions, HCRMP significantly reduces the collision\nrate by 11.4%, which effectively improves the driving performance in complex\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.15793v2",
    "published": "2025-05-21T17:47:24+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15792v1",
    "title": "Long-Form Information Alignment Evaluation Beyond Atomic Facts",
    "authors": [
      "Danna Zheng",
      "Mirella Lapata",
      "Jeff Z. Pan"
    ],
    "abstract": "Information alignment evaluators are vital for various NLG evaluation tasks\nand trustworthy LLM deployment, reducing hallucinations and enhancing user\ntrust. Current fine-grained methods, like FactScore, verify facts individually\nbut neglect inter-fact dependencies, enabling subtle vulnerabilities. In this\nwork, we introduce MontageLie, a challenging benchmark that constructs\ndeceptive narratives by \"montaging\" truthful statements without introducing\nexplicit hallucinations. We demonstrate that both coarse-grained LLM-based\nevaluators and current fine-grained frameworks are susceptible to this attack,\nwith AUC-ROC scores falling below 65%. To enable more robust fine-grained\nevaluation, we propose DoveScore, a novel framework that jointly verifies\nfactual accuracy and event-order consistency. By modeling inter-fact\nrelationships, DoveScore outperforms existing fine-grained methods by over 8%,\nproviding a more robust solution for long-form text alignment evaluation. Our\ncode and datasets are available at https://github.com/dannalily/DoveScore.",
    "pdf_url": "http://arxiv.org/pdf/2505.15792v1",
    "published": "2025-05-21T17:46:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15791v2",
    "title": "VARD: Efficient and Dense Fine-Tuning for Diffusion Models with Value-based RL",
    "authors": [
      "Fengyuan Dai",
      "Zifeng Zhuang",
      "Yufei Huang",
      "Siteng Huang",
      "Bangyan Liao",
      "Donglin Wang",
      "Fajie Yuan"
    ],
    "abstract": "Diffusion models have emerged as powerful generative tools across various\ndomains, yet tailoring pre-trained models to exhibit specific desirable\nproperties remains challenging. While reinforcement learning (RL) offers a\npromising solution,current methods struggle to simultaneously achieve stable,\nefficient fine-tuning and support non-differentiable rewards. Furthermore,\ntheir reliance on sparse rewards provides inadequate supervision during\nintermediate steps, often resulting in suboptimal generation quality. To\naddress these limitations, dense and differentiable signals are required\nthroughout the diffusion process. Hence, we propose VAlue-based Reinforced\nDiffusion (VARD): a novel approach that first learns a value function\npredicting expection of rewards from intermediate states, and subsequently uses\nthis value function with KL regularization to provide dense supervision\nthroughout the generation process. Our method maintains proximity to the\npretrained model while enabling effective and stable training via\nbackpropagation. Experimental results demonstrate that our approach facilitates\nbetter trajectory guidance, improves training efficiency and extends the\napplicability of RL to diffusion models optimized for complex,\nnon-differentiable reward functions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15791v2",
    "published": "2025-05-21T17:44:37+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15790v1",
    "title": "Exploring the Innovation Opportunities for Pre-trained Models",
    "authors": [
      "Minjung Park",
      "Jodi Forlizzi",
      "John Zimmerman"
    ],
    "abstract": "Innovators transform the world by understanding where services are\nsuccessfully meeting customers' needs and then using this knowledge to identify\nfailsafe opportunities for innovation. Pre-trained models have changed the AI\ninnovation landscape, making it faster and easier to create new AI products and\nservices. Understanding where pre-trained models are successful is critical for\nsupporting AI innovation. Unfortunately, the hype cycle surrounding pre-trained\nmodels makes it hard to know where AI can really be successful. To address\nthis, we investigated pre-trained model applications developed by HCI\nresearchers as a proxy for commercially successful applications. The research\napplications demonstrate technical capabilities, address real user needs, and\navoid ethical challenges. Using an artifact analysis approach, we categorized\ncapabilities, opportunity domains, data types, and emerging interaction design\npatterns, uncovering some of the opportunity space for innovation with\npre-trained models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15790v1",
    "published": "2025-05-21T17:43:46+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15789v1",
    "title": "CMB Lensing Trispectrum as a Probe of Parity Violation in LSS",
    "authors": [
      "Alessandro Greco",
      "Zachary Slepian",
      "Jiamin Hou",
      "Alex Krolewski"
    ],
    "abstract": "We show that the Cosmic Microwave Background (CMB) lensing trispectrum is\nsensitive to parity violation in Large-Scale Structure (LSS). We obtain a\ncompact expression for the reduced lensing trispectrum that is general for any\ninput matter trispectrum. We then present as an example a simple\nparity-violating toy model for the latter, and explicitly compute the\nparity-odd lensing trispectrum, including an estimate of the Signal-to-Noise\nRatio (SNR). This work serves as a proof of principle, demonstrating how future\nstudies of more physically motivated models can be conducted. It also provides\nan intuitive physical explanation of why CMB lensing is sensitive to parity.\nOur work is the first to point out that secondary CMB anisotropies can be used\nto probe parity in LSS, and will be important in enabling upcoming experiments\nsuch as Simons Observatory and CMB-S4 to contribute maximal power on parity\nviolation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15789v1",
    "published": "2025-05-21T17:42:36+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21516v2",
    "title": "A mix of long-duration hydrogen and thermal storage enables large-scale electrified heating in a renewable European energy system",
    "authors": [
      "Felix Schmidt",
      "Alexander Roth",
      "Wolf-Peter Schill"
    ],
    "abstract": "Hydrogen-based long-duration electricity storage (LDES) is a key component of\nrenewable energy systems to deal with seasonality and prolonged periods of low\nwind and solar energy availability. In this paper, we investigate how\nelectrified heating with heat pumps impacts LDES requirements in a fully\nrenewable European energy system, and which role thermal storage can play.\nUsing a large weather dataset of 78 weather years, we find that electrified\nheating significantly increases LDES needs, as optimal average energy\ncapacities more than quadruple across all weather years compared to a scenario\nwithout electrified heating. We attribute 75% of this increase to a leverage\neffect, as additional electric load amplifies storage needs during times of low\nrenewable availability. The remaining 25% are the result of a compound effect,\nwhere exceptional cold spells coincide with periods of renewable scarcity.\nFurthermore, heat pumps increase the variance in optimal storage capacities\nbetween weather years substantially because of demand-side weather variability.\nLong-duration thermal storage attached to district heating networks can reduce\nLDES needs by on average 36%. To support and safeguard wide-spread heating\nelectrification, policymakers should expedite the creation of adequate\nregulatory frameworks for both long-duration storage types to de-risk\ninvestments in light of high weather variability.",
    "pdf_url": "http://arxiv.org/pdf/2505.21516v2",
    "published": "2025-05-21T17:41:13+00:00",
    "categories": [
      "physics.soc-ph",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15788v1",
    "title": "Fair Supervised Learning Through Constraints on Smooth Nonconvex Unfairness-Measure Surrogates",
    "authors": [
      "Zahra Khatti",
      "Daniel P. Robinson",
      "Frank E. Curtis"
    ],
    "abstract": "A new strategy for fair supervised machine learning is proposed. The main\nadvantages of the proposed strategy as compared to others in the literature are\nas follows. (a) We introduce a new smooth nonconvex surrogate to approximate\nthe Heaviside functions involved in discontinuous unfairness measures. The\nsurrogate is based on smoothing methods from the optimization literature, and\nis new for the fair supervised learning literature. The surrogate is a tight\napproximation which ensures the trained prediction models are fair, as opposed\nto other (e.g., convex) surrogates that can fail to lead to a fair prediction\nmodel in practice. (b) Rather than rely on regularizers (that lead to\noptimization problems that are difficult to solve) and corresponding\nregularization parameters (that can be expensive to tune), we propose a\nstrategy that employs hard constraints so that specific tolerances for\nunfairness can be enforced without the complications associated with the use of\nregularization. (c)~Our proposed strategy readily allows for constraints on\nmultiple (potentially conflicting) unfairness measures at the same time.\nMultiple measures can be considered with a regularization approach, but at the\ncost of having even more difficult optimization problems to solve and further\nexpense for tuning. By contrast, through hard constraints, our strategy leads\nto optimization models that can be solved tractably with minimal tuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15788v1",
    "published": "2025-05-21T17:41:06+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15787v2",
    "title": "Flavour hierarchies, extended groups and composites",
    "authors": [
      "Javier M. Lizana"
    ],
    "abstract": "In these proceedings, I present a composite Higgs model in which the flavour\nhierarchies between the third and light families emerge naturally. In\nparticular, CKM mixing angles turn out to be suppressed while PMNS matrix\nremains anarchic. This flavour structure arises as a consequence of the\nextended non-universal gauge symmetry of the model and the electroweak charges\nof the fundamental fermions of the new composite sector that realises the Higgs\nboson as a pseudo Nambu-Goldstone boson. The model is described in detail in\narXiv:2412.14243.",
    "pdf_url": "http://arxiv.org/pdf/2505.15787v2",
    "published": "2025-05-21T17:39:52+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15786v1",
    "title": "Cohen's theorem in tensor triangular geometry",
    "authors": [
      "Tobias Barthel"
    ],
    "abstract": "A theorem of Cohen from 1950 states that a commutative ring is Noetherian if\nand only if every prime ideal is finitely generated. In this note, we establish\nanalogues of this result in tensor triangular geometry. In particular, for an\nessentially small tensor triangulated category $\\mathscr{K}$ with weakly\nNoetherian spectrum, we show that every prime ideal in $\\mathscr{K}$ can be\ngenerated by finitely many objects if and only if the set of prime ideals of\n$\\mathscr{K}$ is finite.",
    "pdf_url": "http://arxiv.org/pdf/2505.15786v1",
    "published": "2025-05-21T17:39:34+00:00",
    "categories": [
      "math.CT",
      "math.AT",
      "math.RT"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15877v1",
    "title": "Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval",
    "authors": [
      "Siting Li",
      "Xiang Gao",
      "Simon Shaolei Du"
    ],
    "abstract": "While an image is worth more than a thousand words, only a few provide\ncrucial information for a given task and thus should be focused on. In light of\nthis, ideal text-to-image (T2I) retrievers should prioritize specific visual\nattributes relevant to queries. To evaluate current retrievers on handling\nattribute-focused queries, we build COCO-Facet, a COCO-based benchmark with\n9,112 queries about diverse attributes of interest. We find that CLIP-like\nretrievers, which are widely adopted due to their efficiency and zero-shot\nability, have poor and imbalanced performance, possibly because their image\nembeddings focus on global semantics and subjects while leaving out other\ndetails. Notably, we reveal that even recent Multimodal Large Language Model\n(MLLM)-based, stronger retrievers with a larger output dimension struggle with\nthis limitation. Hence, we hypothesize that retrieving with general image\nembeddings is suboptimal for performing such queries. As a solution, we propose\nto use promptable image embeddings enabled by these multimodal retrievers,\nwhich boost performance by highlighting required attributes. Our pipeline for\nderiving such embeddings generalizes across query types, image pools, and base\nretriever architectures. To enhance real-world applicability, we offer two\nacceleration strategies: Pre-processing promptable embeddings and using linear\napproximations. We show that the former yields a 15% improvement in Recall@5\nwhen prompts are predefined, while the latter achieves an 8% improvement when\nprompts are only available during inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.15877v1",
    "published": "2025-05-21T17:38:06+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15785v2",
    "title": "Rescuing 331 bileptons from the Landau pole",
    "authors": [
      "Stefano Morisi",
      "Giovanna Paola Perdon√†",
      "Giulia Ricciardi"
    ],
    "abstract": "Among the particles being searched for at the LHC beyond the Standard Model\nare bileptons, which are doubly charged gauge bosons. Bileptons are predicted\nby several Standard Model extensions, including the so-called 331 models with\n$\\beta = \\sqrt 3$. The minimal formulation of these models is generally plagued\nby a \"low energy\" Landau pole, which can undermine current predictions for\nTeV-scale bileptons. We analyze this issue and investigate the possibility to\nshift the Landau pole at higher energy scales by extending the troublesome\nminimal 331 models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15785v2",
    "published": "2025-05-21T17:37:44+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15784v1",
    "title": "Large Language Models as Computable Approximations to Solomonoff Induction",
    "authors": [
      "Jun Wan",
      "Lingrui Mei"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) calls for a rigorous\ntheoretical framework to explain their empirical success. While significant\nprogress has been made in understanding LLM behaviors, existing theoretical\nframeworks remain fragmented in explaining emergent phenomena through a unified\nmathematical lens. We establish the first formal connection between LLM\narchitectures and Algorithmic Information Theory (AIT) by proving two\nfundamental results: (1) the training process computationally approximates\nSolomonoff prior through loss minimization interpreted as program length\noptimization, and (2) next-token prediction implements approximate Solomonoff\ninduction. We leverage AIT to provide a unified theoretical explanation for\nin-context learning, few-shot learning, and scaling laws. Furthermore, our\ntheoretical insights lead to a principled method for few-shot example selection\nthat prioritizes samples where models exhibit lower predictive confidence. We\ndemonstrate through experiments on diverse text classification benchmarks that\nthis strategy yields significant performance improvements, particularly for\nsmaller model architectures, when compared to selecting high-confidence\nexamples. Our framework bridges the gap between theoretical foundations and\npractical LLM behaviors, providing both explanatory power and actionable\ninsights for future model development.",
    "pdf_url": "http://arxiv.org/pdf/2505.15784v1",
    "published": "2025-05-21T17:35:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15783v1",
    "title": "Rapid phase ordering for Ising and Potts dynamics on random regular graphs",
    "authors": [
      "Reza Gheissari",
      "Allan Sly",
      "Youngtak Sohn"
    ],
    "abstract": "We consider the Ising, and more generally, $q$-state Potts Glauber dynamics\non random $d$-regular graphs on $n$ vertices at low temperatures $\\beta \\gtrsim\n\\frac{\\log d}{d}$. The mixing time is exponential in $n$ due to a bottleneck\nbetween $q$ dominant phases consisting of configurations in which the majority\nof vertices are in the same state. We prove that for any $d\\ge 7$, from biased\ninitializations with $\\epsilon_d n$ more vertices in state-$1$ than in other\nstates, the Glauber dynamics quasi-equilibrates to the stationary distribution\nconditioned on having plurality in state-$1$ in optimal $O(\\log n)$ time.\nMoreover, the requisite initial bias $\\epsilon_d$ can be taken to zero as $d\n\\to \\infty$. Even for the $q=2$ Ising case, where the states are naturally\nidentified with $\\pm 1$, proving such a result requires a new approach in order\nto control negative information spread in spacetime despite the model being in\nlow temperature and exhibiting strong local correlations. For this purpose, we\nintroduce a coupled non-Markovian rigid dynamics for which a delicate temporal\nrecursion on probability mass functions of minus spacetime cluster sizes\nestablishes their subcriticality.",
    "pdf_url": "http://arxiv.org/pdf/2505.15783v1",
    "published": "2025-05-21T17:34:39+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15782v1",
    "title": "Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning",
    "authors": [
      "Pedro P. Santos",
      "Alberto Sardinha",
      "Francisco S. Melo"
    ],
    "abstract": "In this work, we contribute the first approach to solve infinite-horizon\ndiscounted general-utility Markov decision processes (GUMDPs) in the\nsingle-trial regime, i.e., when the agent's performance is evaluated based on a\nsingle trajectory. First, we provide some fundamental results regarding policy\noptimization in the single-trial regime, investigating which class of policies\nsuffices for optimality, casting our problem as a particular MDP that is\nequivalent to our original problem, as well as studying the computational\nhardness of policy optimization in the single-trial regime. Second, we show how\nwe can leverage online planning techniques, in particular a Monte-Carlo tree\nsearch algorithm, to solve GUMDPs in the single-trial regime. Third, we provide\nexperimental results showcasing the superior performance of our approach in\ncomparison to relevant baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.15782v1",
    "published": "2025-05-21T17:32:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15781v1",
    "title": "dKV-Cache: The Cache for Diffusion Language Models",
    "authors": [
      "Xinyin Ma",
      "Runpeng Yu",
      "Gongfan Fang",
      "Xinchao Wang"
    ],
    "abstract": "Diffusion Language Models (DLMs) have been seen as a promising competitor for\nautoregressive language models. However, diffusion language models have long\nbeen constrained by slow inference. A core challenge is that their\nnon-autoregressive architecture and bidirectional attention preclude the\nkey-value cache that accelerates decoding. We address this bottleneck by\nproposing a KV-cache-like mechanism, delayed KV-Cache, for the denoising\nprocess of DLMs. Our approach is motivated by the observation that different\ntokens have distinct representation dynamics throughout the diffusion process.\nAccordingly, we propose a delayed and conditioned caching strategy for key and\nvalue states. We design two complementary variants to cache key and value\nstep-by-step: (1) dKV-Cache-Decode, which provides almost lossless\nacceleration, and even improves performance on long sequences, suggesting that\nexisting DLMs may under-utilise contextual information during inference. (2)\ndKV-Cache-Greedy, which has aggressive caching with reduced lifespan, achieving\nhigher speed-ups with quadratic time complexity at the cost of some performance\ndegradation. dKV-Cache, in final, achieves from 2-10x speedup in inference,\nlargely narrowing the gap between ARs and DLMs. We evaluate our dKV-Cache on\nseveral benchmarks, delivering acceleration across general language\nunderstanding, mathematical, and code-generation benchmarks. Experiments\ndemonstrate that cache can also be used in DLMs, even in a training-free manner\nfrom current DLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15781v1",
    "published": "2025-05-21T17:32:10+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15780v1",
    "title": "A Hermitian metric on hyperbolic complex manifolds",
    "authors": [
      "Debraj Chakrabarti",
      "Prachi Mahajan"
    ],
    "abstract": "We describe a method of defining a Hermitian metric on Kobayashi hyperbolic\nmanifolds. The metric is distance decreasing under holomorphic mappings, up to\na multiplicative constant. This method is distinct from the classical\nconstruction of Wu, and yields a metric which is expected to have superior\nregularity properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.15780v1",
    "published": "2025-05-21T17:31:53+00:00",
    "categories": [
      "math.CV",
      "32F45"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15779v1",
    "title": "IA-T2I: Internet-Augmented Text-to-Image Generation",
    "authors": [
      "Chuanhao Li",
      "Jianwen Sun",
      "Yukang Feng",
      "Mingliang Zhai",
      "Yifan Chang",
      "Kaipeng Zhang"
    ],
    "abstract": "Current text-to-image (T2I) generation models achieve promising results, but\nthey fail on the scenarios where the knowledge implied in the text prompt is\nuncertain. For example, a T2I model released in February would struggle to\ngenerate a suitable poster for a movie premiering in April, because the\ncharacter designs and styles are uncertain to the model. To solve this problem,\nwe propose an Internet-Augmented text-to-image generation (IA-T2I) framework to\ncompel T2I models clear about such uncertain knowledge by providing them with\nreference images. Specifically, an active retrieval module is designed to\ndetermine whether a reference image is needed based on the given text prompt; a\nhierarchical image selection module is introduced to find the most suitable\nimage returned by an image search engine to enhance the T2I model; a\nself-reflection mechanism is presented to continuously evaluate and refine the\ngenerated image to ensure faithful alignment with the text prompt. To evaluate\nthe proposed framework's performance, we collect a dataset named Img-Ref-T2I,\nwhere text prompts include three types of uncertain knowledge: (1) known but\nrare. (2) unknown. (3) ambiguous. Moreover, we carefully craft a complex prompt\nto guide GPT-4o in making preference evaluation, which has been shown to have\nan evaluation accuracy similar to that of human preference evaluation.\nExperimental results demonstrate the effectiveness of our framework,\noutperforming GPT-4o by about 30% in human evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15779v1",
    "published": "2025-05-21T17:31:49+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15778v1",
    "title": "Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space",
    "authors": [
      "Zhen Zhang",
      "Xuehai He",
      "Weixiang Yan",
      "Ao Shen",
      "Chenyang Zhao",
      "Shuohang Wang",
      "Yelong Shen",
      "Xin Eric Wang"
    ],
    "abstract": "Human cognition typically involves thinking through abstract, fluid concepts\nrather than strictly using discrete linguistic tokens. Current reasoning\nmodels, however, are constrained to reasoning within the boundaries of human\nlanguage, processing discrete token embeddings that represent fixed points in\nthe semantic space. This discrete constraint restricts the expressive power and\nupper potential of such reasoning models, often causing incomplete exploration\nof reasoning paths, as standard Chain-of-Thought (CoT) methods rely on sampling\none token per step. In this work, we introduce Soft Thinking, a training-free\nmethod that emulates human-like \"soft\" reasoning by generating soft, abstract\nconcept tokens in a continuous concept space. These concept tokens are created\nby the probability-weighted mixture of token embeddings, which form the\ncontinuous concept space, enabling smooth transitions and richer\nrepresentations that transcend traditional discrete boundaries. In essence,\neach generated concept token encapsulates multiple meanings from related\ndiscrete tokens, implicitly exploring various reasoning paths to converge\neffectively toward the correct answer. Empirical evaluations on diverse\nmathematical and coding benchmarks consistently demonstrate the effectiveness\nand efficiency of Soft Thinking, improving pass@1 accuracy by up to 2.48 points\nwhile simultaneously reducing token usage by up to 22.4% compared to standard\nCoT. Qualitative analysis further reveals that Soft Thinking outputs remain\nhighly interpretable and readable, highlighting the potential of Soft Thinking\nto break the inherent bottleneck of discrete language-based reasoning. Code is\navailable at https://github.com/eric-ai-lab/Soft-Thinking.",
    "pdf_url": "http://arxiv.org/pdf/2505.15778v1",
    "published": "2025-05-21T17:29:15+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15777v1",
    "title": "Projection-Based Correction for Enhancing Deep Inverse Networks",
    "authors": [
      "Jorge Bacca"
    ],
    "abstract": "Deep learning-based models have demonstrated remarkable success in solving\nillposed inverse problems; however, many fail to strictly adhere to the\nphysical constraints imposed by the measurement process. In this work, we\nintroduce a projection-based correction method to enhance the inference of deep\ninverse networks by ensuring consistency with the forward model. Specifically,\ngiven an initial estimate from a learned reconstruction network, we apply a\nprojection step that constrains the solution to lie within the valid solution\nspace of the inverse problem. We theoretically demonstrate that if the recovery\nmodel is a well-trained deep inverse network, the solution can be decomposed\ninto range-space and null-space components, where the projection-based\ncorrection reduces to an identity transformation. Extensive simulations and\nexperiments validate the proposed method, demonstrating improved reconstruction\naccuracy across diverse inverse problems and deep network architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.15777v1",
    "published": "2025-05-21T17:28:14+00:00",
    "categories": [
      "cs.LG",
      "cs.CV",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15776v1",
    "title": "ConvSearch-R1: Enhancing Query Reformulation for Conversational Search with Reasoning via Reinforcement Learning",
    "authors": [
      "Changtai Zhu",
      "Siyin Wang",
      "Ruijun Feng",
      "Kai Song",
      "Xipeng Qiu"
    ],
    "abstract": "Conversational search systems require effective handling of context-dependent\nqueries that often contain ambiguity, omission, and coreference. Conversational\nQuery Reformulation (CQR) addresses this challenge by transforming these\nqueries into self-contained forms suitable for off-the-shelf retrievers.\nHowever, existing CQR approaches suffer from two critical constraints: high\ndependency on costly external supervision from human annotations or large\nlanguage models, and insufficient alignment between the rewriting model and\ndownstream retrievers. We present ConvSearch-R1, the first self-driven\nframework that completely eliminates dependency on external rewrite supervision\nby leveraging reinforcement learning to optimize reformulation directly through\nretrieval signals. Our novel two-stage approach combines Self-Driven Policy\nWarm-Up to address the cold-start problem through retrieval-guided\nself-distillation, followed by Retrieval-Guided Reinforcement Learning with a\nspecially designed rank-incentive reward shaping mechanism that addresses the\nsparsity issue in conventional retrieval metrics. Extensive experiments on\nTopiOCQA and QReCC datasets demonstrate that ConvSearch-R1 significantly\noutperforms previous state-of-the-art methods, achieving over 10% improvement\non the challenging TopiOCQA dataset while using smaller 3B parameter models\nwithout any external supervision.",
    "pdf_url": "http://arxiv.org/pdf/2505.15776v1",
    "published": "2025-05-21T17:27:42+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15775v1",
    "title": "New Understandings and Computation on Augmented Lagrangian Methods for Low-Rank Semidefinite Programming",
    "authors": [
      "Lijun Ding",
      "Haihao Lu",
      "Jinwen Yang"
    ],
    "abstract": "Augmented Lagrangian Method (ALM) combined with Burer-Monteiro (BM)\nfactorization, dubbed ALM-BM, offers a powerful approach for solving\nlarge-scale low-rank semidefinite programs (SDPs). Despite its empirical\nsuccess, the theoretical understandings of the resulting non-convex ALM-BM\nsubproblems, particularly concerning their structural properties and efficient\nsubproblem solvability by first-order methods, still remain limited. This work\naddresses these notable gaps by providing a rigorous theoretical analysis. We\ndemonstrate that, under appropriate regularity of the original SDP, termed as\nprimal simplicity, ALM subproblems inherit crucial properties such as\nlow-rankness and strict complementarity when the dual variable is localized.\nFurthermore, ALM subproblems are shown to enjoy a quadratic growth condition,\nbuilding on which we prove that the non-convex ALM-BM subproblems can be solved\nto global optimality by gradient descent, achieving linear convergence under\nconditions of local initialization and dual variable proximity. Through\nillustrative examples, we further establish the necessity of these local\nassumptions, revealing them as inherent characteristics of the problem\nstructure. Motivated by these theoretical insights, we propose ALORA, a\nrank-adaptive augmented Lagrangian method that builds upon the ALM-BM\nframework, which dynamically adjusts the rank using spectral information and\nexplores negative curvature directions to navigate the nonconvex landscape.\nExploiting modern GPU computing architectures, ALORA exhibits strong numerical\nperformance, solving SDPs with tens of millions of dimensions in hundreds of\nseconds.",
    "pdf_url": "http://arxiv.org/pdf/2505.15775v1",
    "published": "2025-05-21T17:27:04+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15774v1",
    "title": "Beyond Hard and Soft: Hybrid Context Compression for Balancing Local and Global Information Retention",
    "authors": [
      "Huanxuan Liao",
      "Wen Hu",
      "Yao Xu",
      "Shizhu He",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Large Language Models (LLMs) encounter significant challenges in\nlong-sequence inference due to computational inefficiency and redundant\nprocessing, driving interest in context compression techniques. Existing\nmethods often rely on token importance to perform hard local compression or\nencode context into latent representations for soft global compression.\nHowever, the uneven distribution of textual content relevance and the diversity\nof demands for user instructions mean these approaches frequently lead to the\nloss of potentially valuable information. To address this, we propose\n$\\textbf{Hy}$brid $\\textbf{Co}$ntext $\\textbf{Co}$mpression (HyCo$_2$) for\nLLMs, which integrates both global and local perspectives to guide context\ncompression while retaining both the essential semantics and critical details\nfor task completion. Specifically, we employ a hybrid adapter to refine global\nsemantics with the global view, based on the observation that different\nadapters excel at different tasks. Then we incorporate a classification layer\nthat assigns a retention probability to each context token based on the local\nview, determining whether it should be retained or discarded. To foster a\nbalanced integration of global and local compression, we introduce auxiliary\nparaphrasing and completion pretraining before instruction tuning. This\npromotes a synergistic integration that emphasizes instruction-relevant\ninformation while preserving essential local details, ultimately balancing\nlocal and global information retention in context compression. Experiments show\nthat our HyCo$_2$ method significantly enhances long-text reasoning while\nreducing token usage. It improves the performance of various LLM series by an\naverage of 13.1\\% across seven knowledge-intensive QA benchmarks. Moreover,\nHyCo$_2$ matches the performance of uncompressed methods while reducing token\nconsumption by 88.8\\%.",
    "pdf_url": "http://arxiv.org/pdf/2505.15774v1",
    "published": "2025-05-21T17:26:11+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15773v1",
    "title": "ToxicTone: A Mandarin Audio Dataset Annotated for Toxicity and Toxic Utterance Tonality",
    "authors": [
      "Yu-Xiang Luo",
      "Yi-Cheng Lin",
      "Ming-To Chuang",
      "Jia-Hung Chen",
      "I-Ning Tsai",
      "Pei Xing Kiew",
      "Yueh-Hsuan Huang",
      "Chien-Feng Liu",
      "Yu-Chen Chen",
      "Bo-Han Feng",
      "Wenze Ren",
      "Hung-yi Lee"
    ],
    "abstract": "Despite extensive research on toxic speech detection in text, a critical gap\nremains in handling spoken Mandarin audio. The lack of annotated datasets that\ncapture the unique prosodic cues and culturally specific expressions in\nMandarin leaves spoken toxicity underexplored. To address this, we introduce\nToxicTone -- the largest public dataset of its kind -- featuring detailed\nannotations that distinguish both forms of toxicity (e.g., profanity, bullying)\nand sources of toxicity (e.g., anger, sarcasm, dismissiveness). Our data,\nsourced from diverse real-world audio and organized into 13 topical categories,\nmirrors authentic communication scenarios. We also propose a multimodal\ndetection framework that integrates acoustic, linguistic, and emotional\nfeatures using state-of-the-art speech and emotion encoders. Extensive\nexperiments show our approach outperforms text-only and baseline models,\nunderscoring the essential role of speech-specific cues in revealing hidden\ntoxic expressions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15773v1",
    "published": "2025-05-21T17:25:27+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15772v1",
    "title": "MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech Paralinguistic and Affect Labeling",
    "authors": [
      "Yifan Cheng",
      "Ruoyi Zhang",
      "Jiatong Shi"
    ],
    "abstract": "Acquiring large-scale emotional speech data with strong consistency remains a\nchallenge for speech synthesis. This paper presents MIKU-PAL, a fully automated\nmultimodal pipeline for extracting high-consistency emotional speech from\nunlabeled video data. Leveraging face detection and tracking algorithms, we\ndeveloped an automatic emotion analysis system using a multimodal large\nlanguage model (MLLM). Our results demonstrate that MIKU-PAL can achieve\nhuman-level accuracy (68.5% on MELD) and superior consistency (0.93 Fleiss\nkappa score) while being much cheaper and faster than human annotation. With\nthe high-quality, flexible, and consistent annotation from MIKU-PAL, we can\nannotate fine-grained speech emotion categories of up to 26 types, validated by\nhuman annotators with 83% rationality ratings. Based on our proposed system, we\nfurther released a fine-grained emotional speech dataset MIKU-EmoBench(131.2\nhours) as a new benchmark for emotional text-to-speech and visual voice\ncloning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15772v1",
    "published": "2025-05-21T17:23:12+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15771v1",
    "title": "Elasto-acoustic wave propagation in geophysical media using hybrid high-order methods on general meshes",
    "authors": [
      "Romain Mottier",
      "Alexandre Ern",
      "Laurent Guillot"
    ],
    "abstract": "Hybrid high-order (HHO) methods are numerical methods characterized by\nseveral interesting properties such as local conservativity, geometric\nflexibility and high-order accuracy. Here, HHO schemes are studied for the\nspace semi-discretization of coupled elasto-acoustic waves in the time domain\nusing a first-order formulation. Explicit and singly diagonal implicit\nRunge--Kutta (ERK & SDIRK) schemes are used for the time discretization. We\nshow that an efficient implementation of explicit (resp. implicit) time schemes\ncalls for a static condensation of the face (resp. cell) unknowns. Crucially,\nboth static condensation procedures only involve block-diagonal matrices. Then,\nwe provide numerical estimates for the CFL stability limit of ERK schemes and\npresent a comparative study on the efficiency of explicit versus implicit\nschemes. Our findings indicate that implicit time schemes remain competitive in\nmany situations. Finally, simulations in a 2D realistic geophysical\nconfiguration are performed, illustrating the geometrical flexibility of the\nHHO method: both hybrid (triangular and quadrangular) and nonconforming (with\nhanging nodes) meshes are easily handled, delivering results of comparable\naccuracy to a reference spectral element software based on tensorized elements.",
    "pdf_url": "http://arxiv.org/pdf/2505.15771v1",
    "published": "2025-05-21T17:22:45+00:00",
    "categories": [
      "math.NA",
      "cs.CE",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15770v2",
    "title": "The abelian state hidden subgroup problem: Learning stabilizer groups and beyond",
    "authors": [
      "Marcel Hinsche",
      "Jens Eisert",
      "Jose Carrasco"
    ],
    "abstract": "Identifying the symmetry properties of quantum states is a central theme in\nquantum information theory and quantum many-body physics. In this work, we\ninvestigate quantum learning problems in which the goal is to identify a hidden\nsymmetry of an unknown quantum state. Building on the recent formulation of the\nstate hidden subgroup problem (StateHSP), we focus on abelian groups and\ndevelop an efficient quantum algorithm that learns any hidden symmetry subgroup\nusing a generalized form of Fourier sampling. We showcase the versatility of\nthe approach in three concrete applications: These are learning (i) qubit and\nqudit stabilizer groups, (ii) cuts along which a state is unentangled, and\n(iii) hidden translation symmetries. Through these applications, we reveal that\nwell-known quantum learning primitives, such as Bell sampling and Bell\ndifference sampling, are in fact special cases of Fourier sampling. Our results\nhighlight the broad potential of the StateHSP framework for symmetry-based\nquantum learning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15770v2",
    "published": "2025-05-21T17:21:51+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15769v1",
    "title": "Transfer of Structural Knowledge from Synthetic Languages",
    "authors": [
      "Mikhail Budnikov",
      "Ivan Yamshchikov"
    ],
    "abstract": "This work explores transfer learning from several synthetic languages to\nEnglish. We investigate the structure of the embeddings in the fine-tuned\nmodels, the information they contain, and the capabilities of the fine-tuned\nmodels on simple linguistic tasks. We also introduce a new synthetic language\nthat leads to better transfer to English than the languages used in previous\nresearch. Finally, we introduce Tiny-Cloze Benchmark - a new synthetic\nbenchmark for natural language understanding that is more informative for less\npowerful models. We use Tiny-Cloze Benchmark to evaluate fine-tuned models in\nseveral domains demonstrating that fine-tuning on a new synthetic language\nallows for better performance on a variety of tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15769v1",
    "published": "2025-05-21T17:18:51+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15768v1",
    "title": "Current constraints on the minimally extended varying speed of light model through the cosmic distance duality relation",
    "authors": [
      "Jaiane Santos",
      "Carlos Bengaly",
      "Rodrigo S. Gon√ßalves"
    ],
    "abstract": "One of the most crucial tests of the standard cosmological model consists on\ntesting possible variations on fundamental physical constants. In frameworks\nsuch as the minimally extended varying speed of light model (meVSL), the\nrelationship between the luminosity distance ($D_{\\text{L}}$) and the angular\ndiameter distance ($D_{\\text{A}}$), namely the cosmic distance duality relation\n(CDDR), is expected to deviate from $\\eta(z) \\equiv\nD_{\\text{L}}(z)/D_{\\text{A}}(z) = (1+z)^{2}$, making it a powerful probe of a\npotential variation of such a fundamental constant. Hence, we test the\nviability of the meVSL model through the CDDR by comparing $D_{\\text{A}}$\nmeasurements, provided by the transverse (2D) and anisotropic (3D) baryon\nacoustic oscillations (BAO) observations from different surveys, like SDSS, DES\nand DESI, in combination with $D_{\\text{L}}$ measurements from Pantheon+ type\nIa Supernova (SNe) compilation. The Gaussian Process reconstruction is employed\non the SN data to match $D_{\\text{A}}$ with $D_{\\text{L}}$ at the same\nredshift. We find no deviation of the standard CDDR relation within 1-2$\\sigma$\nconfidence level when considering SNe with 2D and 3D BAO samples combined\ntogether, as well as when considering SNe with 3D BAO only. However, when SNe\nand 2D BAO only are considered, the standard CDDR is only recovered at $\\sim\n4\\sigma$ confidence level. However, such a result might be due to some recently\ndiscussed tensions between SN and BAO datasets, especially at low redshifts, in\naddition to possible inconsistencies between the BAO datasets individually.\nTherefore, our results show no significant evidence in favour of the meVSL\nmodel, once these potential systematics are taken into account.",
    "pdf_url": "http://arxiv.org/pdf/2505.15768v1",
    "published": "2025-05-21T17:18:07+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15767v1",
    "title": "Free monoids and Riguet congruences",
    "authors": [
      "Juan Climent Vidal",
      "Enric Cosme Ll√≥pez",
      "Ra√∫l Ruiz Mora"
    ],
    "abstract": "For a set $A$, after recalling the notion of free monoid on $A$, denoted by\n$\\mathbf{A}^{\\star}$, we associate to $\\mathbf{A}^{\\star}$ a category\n$\\mathsf{C}(\\mathbf{A}^{\\star})$, which, in general, is not skeletal, and prove\nthat it is equivalent to $\\mathsf{Set}^{A}_{\\mathrm{f}}$, the category of\nfinite $A$-sorted sets. Following this, after recalling and completing the\nnotion of Riguet congruence on a category, we obtain, for a suitable Riguet\ncongruence on $\\mathsf{C}(\\mathbf{A}^{\\star})$, a skeletal quotient category\n$\\mathsf{Q}(\\mathbf{A}^{\\star})$ of $\\mathsf{C}(\\mathbf{A}^{\\star})$ and prove\nthat it is also equivalent to $\\mathsf{Set}^{A}_{\\mathrm{f}}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15767v1",
    "published": "2025-05-21T17:13:54+00:00",
    "categories": [
      "math.CT",
      "08B20, 18A32, 18B05 (Primary) 18A05, 18A40, 18B99 (Secondary)"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15766v1",
    "title": "Quasar radiation transforms the gas in a merging companion galaxy",
    "authors": [
      "Sergei Balashev",
      "Pasquier Noterdaeme",
      "Neeraj Gupta",
      "Jens-Kristian Krogager",
      "Francoise Combes",
      "Sebastian Lopez",
      "Patrick Petitjean",
      "Alain Omont",
      "Raghunathan Srianand",
      "Rodrigo Cuellar"
    ],
    "abstract": "Quasars, powered by gas accretion onto supermassive black holes, rank among\nthe most energetic objects of the Universe. While they are thought to be\nignited by galaxy mergers and affect the surrounding gas, observational\nconstraints on both processes remain scarce. Here we unveil a major merging\nsystem at redshift $z \\approx 2.7$, and demonstrate that radiation from the\nquasar in one galaxy directly alters the gas properties in the other galaxy.\nOur findings reveal that the galaxies, with centroids separated by only a few\nkiloparsecs and approaching each other at speed $\\approx550\\,$km$\\,$s$^{-1}$,\nare massive, form stars, and contain a substantial molecular mass. Yet, dusty\nmolecular gas seen in absorption against the quasar nucleus is highly excited\nand confined within cloudlets with densities $\\sim 10^5$ - $10^6$ cm$^{-3}$ and\nsizes $<$0.02 pc, several orders of magnitude more compact than those observed\nin intervening (non-quasar) environments. This is also approximately 10$^5$\ntimes smaller than currently resolvable through molecular-line emission at high\nredshifts. We infer that, wherever exposed to the quasar radiation, molecular\ngas is disrupted, leaving behind surviving dense clouds too small to give birth\nto new stars. Our results not only underscore the role of major galaxy mergers\nin triggering quasar activity, but also reveal localized negative feedback as a\nprofound alteration of internal gas structure which likely hampers star\nformation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15766v1",
    "published": "2025-05-21T17:13:09+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.18206v1",
    "title": "Quantum-Resilient Blockchain for Secure Transactions in UAV-Assisted Smart Agriculture Networks",
    "authors": [
      "Taimoor Ahmad"
    ],
    "abstract": "The integration of unmanned aerial vehicles (UAVs) into smart agriculture has\nenabled real-time monitoring, data collection, and automated farming\noperations. However, the high mobility, decentralized nature, and low-power\ncommunication of UAVs pose significant security challenges, particularly in\nensuring transaction integrity and trust. This paper presents a\nquantum-resilient blockchain framework designed to secure data and resource\ntransactions in UAV-assisted smart agriculture networks. The proposed solution\nincorporates post-quantum cryptographic primitives-specifically lattice-based\ndigital signatures and key encapsulation mechanisms to achieve tamper-proof,\nlow-latency consensus without relying on traditional computationally intensive\nproof-of-work schemes. A lightweight consensus protocol tailored for UAV\ncommunication constraints is developed, and transaction validation is handled\nthrough a trust-ranked, multi-layer ledger maintained by edge nodes.\nExperimental results from simulations using NS-3 and custom blockchain testbeds\nshow that the framework outperforms existing schemes in terms of transaction\nthroughput, energy efficiency, and resistance to quantum attacks. The proposed\nsystem provides a scalable, secure, and sustainable solution for precision\nagriculture, enabling trusted automation and resilient data sharing in\npost-quantum eras.",
    "pdf_url": "http://arxiv.org/pdf/2505.18206v1",
    "published": "2025-05-21T17:12:39+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15765v1",
    "title": "Constructing a 3D Town from a Single Image",
    "authors": [
      "Kaizhi Zheng",
      "Ruijian Zhang",
      "Jing Gu",
      "Jie Yang",
      "Xin Eric Wang"
    ],
    "abstract": "Acquiring detailed 3D scenes typically demands costly equipment, multi-view\ndata, or labor-intensive modeling. Therefore, a lightweight alternative,\ngenerating complex 3D scenes from a single top-down image, plays an essential\nrole in real-world applications. While recent 3D generative models have\nachieved remarkable results at the object level, their extension to full-scene\ngeneration often leads to inconsistent geometry, layout hallucinations, and\nlow-quality meshes. In this work, we introduce 3DTown, a training-free\nframework designed to synthesize realistic and coherent 3D scenes from a single\ntop-down view. Our method is grounded in two principles: region-based\ngeneration to improve image-to-3D alignment and resolution, and spatial-aware\n3D inpainting to ensure global scene coherence and high-quality geometry\ngeneration. Specifically, we decompose the input image into overlapping regions\nand generate each using a pretrained 3D object generator, followed by a masked\nrectified flow inpainting process that fills in missing geometry while\nmaintaining structural continuity. This modular design allows us to overcome\nresolution bottlenecks and preserve spatial structure without requiring 3D\nsupervision or fine-tuning. Extensive experiments across diverse scenes show\nthat 3DTown outperforms state-of-the-art baselines, including Trellis,\nHunyuan3D-2, and TripoSG, in terms of geometry quality, spatial coherence, and\ntexture fidelity. Our results demonstrate that high-quality 3D town generation\nis achievable from a single image using a principled, training-free approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.15765v1",
    "published": "2025-05-21T17:10:47+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15764v1",
    "title": "Direct Detection of Cosmic Walls with Paleo Detectors",
    "authors": [
      "Wen Yin"
    ],
    "abstract": "Paleo detectors are emerging dark matter detection technology that exploits\nancient minerals as passive, time-integrated detectors. Unlike conventional\nreal-time experiments, they search for permanent damage tracks-typically tens\nof nanometers to micrometers long-left in crystal lattices by rare particle\ninteractions, most notably dark matter induced nuclear recoils accumulated over\nmillions to billions of years. In this paper I propose a direct detection\nstrategy for cosmic walls-either bubble walls produced by a late-time\nfirst-order phase transition or domain walls in a scaling regime-using paleo\ndetectors as the target medium. Because the cosmic wall is expected to traverse\nEarth at most $\\mathcal{O}(1)$ time(s) in cosmic history, an ancient,\ncontinuously exposed detector is the only feasible way to observe it directly.\nBy calculating the target recoils, I find that the smoking-gun signature would\nbe parallel damage tracks found worldwide in minerals older than the\nwall-crossing epoch. I derive the limit on the wall-target coupling by assuming\nthat a wall passed through the Earth within the last 0.5 Gyr. I also mention a\nnovel indirect detection of ultra-relativistic cosmic walls by noting the\ninduced cosmic rays.",
    "pdf_url": "http://arxiv.org/pdf/2505.15764v1",
    "published": "2025-05-21T17:10:19+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15763v1",
    "title": "Analysis of Distributional Dynamics for Repeated Cross-Sectional and Intra-Period Observations",
    "authors": [
      "Bo Hu",
      "Joon Y. Park",
      "Junhui Qian"
    ],
    "abstract": "This paper introduces a novel approach to investigate the dynamics of state\ndistributions, which accommodate both cross-sectional distributions of repeated\npanels and intra-period distributions of a time series observed at high\nfrequency. In our approach, densities of the state distributions are regarded\nas functional elements in a Hilbert space, and are assumed to follow a\nfunctional autoregressive model. We propose an estimator for the autoregressive\noperator, establish its consistency, and provide tools and asymptotics to\nanalyze the forecast of state density and the moment dynamics of state\ndistributions. We apply our methodology to study the time series of\ndistributions of the GBP/USD exchange rate intra-month returns and the time\nseries of cross-sectional distributions of the NYSE stocks monthly returns.\nFinally, we conduct simulations to evaluate the density forecasts based on our\nmodel.",
    "pdf_url": "http://arxiv.org/pdf/2505.15763v1",
    "published": "2025-05-21T17:09:39+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2506.11047v1",
    "title": "Perception-Driven Bias Detection in Machine Learning via Crowdsourced Visual Judgment",
    "authors": [
      "Chirudeep Tupakula",
      "Rittika Shamsuddin"
    ],
    "abstract": "Machine learning systems are increasingly deployed in high-stakes domains,\nyet they remain vulnerable to bias systematic disparities that\ndisproportionately impact specific demographic groups. Traditional bias\ndetection methods often depend on access to sensitive labels or rely on rigid\nfairness metrics, limiting their applicability in real-world settings. This\npaper introduces a novel, perception-driven framework for bias detection that\nleverages crowdsourced human judgment. Inspired by reCAPTCHA and other\ncrowd-powered systems, we present a lightweight web platform that displays\nstripped-down visualizations of numeric data (for example-salary distributions\nacross demographic clusters) and collects binary judgments on group similarity.\nWe explore how users' visual perception-shaped by layout, spacing, and question\nphrasing can signal potential disparities. User feedback is aggregated to flag\ndata segments as biased, which are then validated through statistical tests and\nmachine learning cross-evaluations. Our findings show that perceptual signals\nfrom non-expert users reliably correlate with known bias cases, suggesting that\nvisual intuition can serve as a powerful, scalable proxy for fairness auditing.\nThis approach offers a label-efficient, interpretable alternative to\nconventional fairness diagnostics, paving the way toward human-aligned,\ncrowdsourced bias detection pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2506.11047v1",
    "published": "2025-05-21T17:09:18+00:00",
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15876v1",
    "title": "Polarizing 3He via Metastability Exchange Optical Pumping Using a 1.2 mbar Sealed Cell at Magnetic Fields up to 5 T",
    "authors": [
      "Pushpa Pandey",
      "Hao Lu",
      "James Maxwell",
      "James Brock",
      "Christopher Keith",
      "Xiaqing Li",
      "Richard Milner",
      "Dien Nguyen"
    ],
    "abstract": "We report high nuclear polarization of 1.2 mbar 3He gas in a sealed cell in\nmagnetic fields up to 5 T using Metastability Exchange Optical Pumping (MEOP).\nThe creation of a highly polarized 3He gas target for use in the 5 T field of\nJefferson Lab's CLAS12 spectrometer would enable new studies of spin-dependent\nasymmetries on the neutron. A systematic study was conducted to evaluate the\neffects of discharge intensity, pump laser power, and optical pumping\ntransition schemes on nuclear polarization and pumping rates. Steady-state\npolarizations up to 86 % in magnetic fields between 2 and 5 T were achieved,\nwith a discharge-on relaxation time of 898 s at 5 T. These results underscore\nthe potential of MEOP for high-field applications in nuclear physics\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15876v1",
    "published": "2025-05-21T17:08:53+00:00",
    "categories": [
      "physics.ins-det",
      "nucl-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.15762v1",
    "title": "Discretization Theorems for Entire Functions of Exponential Type",
    "authors": [
      "Michael I. Ganzburg"
    ],
    "abstract": "We prove $L_q(\\R^m)$--discretization inequalities\n  for entire functions $f$ of exponential type\n  in the form\n  \\ba\n  C_2\\|f\\|_{L_q(\\R^m)}\n  \\le \\left(\\sum_{\\nu=1}^\\iy \\left\\vert f\\left(X_\\nu\\right)\n  \\right\\vert^q\\right)^{1/q}\n  \\le C_1\\|f\\|_{L_q(\\R^m)},\\qquad q\\in[1,\\iy],\n  \\ea\n  with estimates for $C_1$ and $C_2$.\n  We find a necessary and sufficient condition on\n  $\\Omega=\\left\\{X_\\nu\\right\\}_{\\nu=1}^\\iy\\subset\\R^m$\n  for the right inequality to be valid and a\n  sufficient condition on $\\Omega$ for the left one to\n  hold true.\n  In addition, $L_\\iy(Q^m_b)$-discretization\n  inequalities on an $m$-dimensional cube are proved for\n  entire functions of exponential type\n  and exponential polynomials.",
    "pdf_url": "http://arxiv.org/pdf/2505.15762v1",
    "published": "2025-05-21T17:07:54+00:00",
    "categories": [
      "math.CA",
      "Primary 26D07, 26D15, Secondary 41A10, 41A63"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15761v2",
    "title": "Simple groups with strong fixed-point properties",
    "authors": [
      "Nansen Petrosyan"
    ],
    "abstract": "We exhibit finitely generated torsion-free groups for which any action on any\nfinite-dimensional CW-complex with finite Betti numbers has a global fixed\npoint.",
    "pdf_url": "http://arxiv.org/pdf/2505.15761v2",
    "published": "2025-05-21T17:06:35+00:00",
    "categories": [
      "math.GR",
      "math.AT",
      "math.GT"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00022v3",
    "title": "Scaling Physical Reasoning with the PHYSICS Dataset",
    "authors": [
      "Shenghe Zheng",
      "Qianjia Cheng",
      "Junchi Yao",
      "Mengsong Wu",
      "Haonan He",
      "Ning Ding",
      "Yu Cheng",
      "Shuyue Hu",
      "Lei Bai",
      "Dongzhan Zhou",
      "Ganqu Cui",
      "Peng Ye"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable progress on advanced\nreasoning tasks such as mathematics and coding competitions. Meanwhile,\nphysics, despite being both reasoning-intensive and essential to real-world\nunderstanding, received limited academic and industrial attention. This paper\nintroduces PHYSICS, a dataset containing 16,568 high-quality physics problems\nspanning subjects and difficulty levels, to facilitate this issue.\nSpecifically, PHYSICS is curated with exercises from over 100 textbooks through\na carefully designed pipeline for quality control. It covers five major physics\ndomains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern\nPhysics. It also spans a wide range of difficulty levels, from high school to\ngraduate-level physics courses. To utilize the data for improving and\nevaluating the model's physical reasoning capabilities, we split the dataset\ninto training and test sets, and provide reasoning paths generated by powerful\nreasoning models for the training data to facilitate model training. In\naddition, for the evaluation part, we find that existing evaluation frameworks\nexhibit biases in aspects such as units, simplification, and precision in\nphysics domain. To balance efficiency and accuracy, we introduce a Rule+Model\nevaluation framework tailored to physics problems. Our evaluations on current\nstate-of-the-art open-source and proprietary models highlight the limitations\nof current models in handling physics-related tasks. We hope that our dataset\nand evaluation methodology will jointly advance the development of LLMs in the\nfield of physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00022v3",
    "published": "2025-05-21T17:06:28+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "physics.ed-ph"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.05356v1",
    "title": "AI-Driven Dynamic Firewall Optimization Using Reinforcement Learning for Anomaly Detection and Prevention",
    "authors": [
      "Taimoor Ahmad"
    ],
    "abstract": "The growing complexity of cyber threats has rendered static firewalls\nincreasingly ineffective for dynamic, real-time intrusion prevention. This\npaper proposes a novel AI-driven dynamic firewall optimization framework that\nleverages deep reinforcement learning (DRL) to autonomously adapt and update\nfirewall rules in response to evolving network threats. Our system employs a\nMarkov Decision Process (MDP) formulation, where the RL agent observes network\nstates, detects anomalies using a hybrid LSTM-CNN model, and dynamically\nmodifies firewall configurations to mitigate risks. We train and evaluate our\nframework on the NSL-KDD and CIC-IDS2017 datasets using a simulated\nsoftware-defined network environment. Results demonstrate significant\nimprovements in detection accuracy, false positive reduction, and rule update\nlatency when compared to traditional signature- and behavior-based firewalls.\nThe proposed method provides a scalable, autonomous solution for enhancing\nnetwork resilience against complex attack vectors in both enterprise and\ncritical infrastructure settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.05356v1",
    "published": "2025-05-21T17:05:33+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15760v1",
    "title": "Variable Calder√≥n-Hardy spaces on the Heisenberg group",
    "authors": [
      "Pablo Rocha"
    ],
    "abstract": "Let $\\mathbb{H}^{n}$ be the Heisenberg group and $Q = 2n+2$. For $1 < q <\n\\infty$, $\\gamma > 0$ and an exponent function $p(\\cdot)$ on $\\mathbb{H}^n$,\nwhich satisfy log-H\\\"older conditions, with $0 < p_{-} \\leq p_{+} < \\infty$, we\nintroduce the variable Calder\\'on-Hardy spaces $\\mathcal{H}^{p(\\cdot)}_{q,\n\\gamma}(\\mathbb{H}^{n})$, and show for every $f \\in\nH^{p(\\cdot)}(\\mathbb{H}^{n})$ that the equation \\[ \\mathcal{L} F = f \\] has a\nunique solution $F$ in $\\mathcal{H}^{p(\\cdot)}_{q, 2}(\\mathbb{H}^{n})$, where\n$\\mathcal{L}$ is the sublaplacian on $\\mathbb{H}^{n}$, $1 < q < \\frac{n+1}{n}$\nand $Q (2 + \\frac{Q}{q})^{-1} < \\underline{p}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15760v1",
    "published": "2025-05-21T17:03:49+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2506.05355v1",
    "title": "Zero-Trust Mobility-Aware Authentication Framework for Secure Vehicular Fog Computing Networks",
    "authors": [
      "Taimoor Ahmad"
    ],
    "abstract": "Vehicular Fog Computing (VFC) is a promising paradigm to meet the low-latency\nand high-bandwidth demands of Intelligent Transportation Systems (ITS).\nHowever, dynamic vehicle mobility and diverse trust boundaries introduce\ncritical security challenges. This paper presents a novel Zero-Trust\nMobility-Aware Authentication Framework (ZTMAF) for secure communication in VFC\nnetworks. The framework employs context-aware authentication with lightweight\ncryptographic primitives, a decentralized trust evaluation system, and fog\nnode-assisted session validation to combat spoofing, replay, and impersonation\nattacks. Simulation results on NS-3 and SUMO demonstrate improved\nauthentication latency, reduced computational overhead, and better scalability\ncompared to traditional PKI and blockchain-based models. Our findings suggest\nthat ZTMAF is effective for secure, real-time V2X interactions under\nadversarial and mobility-variant scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.05355v1",
    "published": "2025-05-21T17:03:39+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15759v1",
    "title": "Estimating Associations Between Cumulative Exposure and Health via Generalized Distributed Lag Non-Linear Models using Penalized Splines",
    "authors": [
      "Tianyi Pan",
      "Hwashin Hyun Shin",
      "Glen McGee",
      "Alex Stringer"
    ],
    "abstract": "Quantifying associations between short-term exposure to ambient air pollution\nand health outcomes is an important public health priority. Many studies have\ninvestigated the association considering delayed effects within the past few\ndays. Adaptive cumulative exposure distributed lag non-linear models\n(ACE-DLNMs) quantify associations between health outcomes and cumulative\nexposure that is specified in a data-adaptive way. While the ACE-DLNM framework\nis highly interpretable, it is limited to continuous outcomes and does not\nscale well to large datasets. Motivated by a large analysis of daily pollution\nand respiratory hospitalization counts in Canada between 2001 and 2018, we\npropose a generalized ACE-DLNM incorporating penalized splines, improving upon\nexisting ACE-DLNM methods to accommodate general response types. We then\ndevelop a computationally efficient estimation strategy based on profile\nlikelihood and Laplace approximate marginal likelihood with Newton-type\nmethods. We demonstrate the performance and practical advantages of the\nproposed method through simulations. In application to the motivating analysis,\nthe proposed method yields more stable inferences compared to generalized\nadditive models with fixed exposures, while retaining interpretability.",
    "pdf_url": "http://arxiv.org/pdf/2505.15759v1",
    "published": "2025-05-21T17:03:34+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15758v2",
    "title": "A partition function framework for estimating logical error curves in stabilizer codes",
    "authors": [
      "Leon Wichette",
      "Hans Hohenfeld",
      "Elie Mounzer",
      "Linnea Grans-Samuelsson"
    ],
    "abstract": "Based on the mapping between stabilizer quantum error correcting codes and\ndisordered statistical mechanics models, we define a ratio of partition\nfunctions that measures the success probability for maximum partition function\ndecoding, which at the Nishimori temperature corresponds to maximum likelihood\n(ML) decoding. We show that this ratio differs from the similarly defined order\nprobability and describe the decoding strategy whose success rate is described\nby the order probability. We refer to the latter as a probabilistic partition\nfunction decoding and show that it is the strategy that at zero temperature\ncorresponds to maximum probability (MP) decoding. Based on the difference\nbetween the two decoders, we discuss the possibility of a maximum partition\nfunction decodability boundary outside the order-disorder phase boundary. At\nzero temperature, the difference between the two ratios measures to what degree\nMP decoding can be improved by accounting for degeneracy among maximum\nprobability errors, through methods such as ensembling. We consider in detail\nthe example of the toric code under bitflip noise, which maps to the Random\nBond Ising Model. We demonstrate that estimation of logical performance through\ndecoding probability and order probability is more sample efficient than\nestimation by counting failures of the corresponding decoders. We consider both\nuniform noise and noise where qubits are given individual error rates. The\nlatter noise model lifts the degeneracy among maximum probability errors, but\nwe show that ensembling remains useful as long as it also samples less probable\nerrors.",
    "pdf_url": "http://arxiv.org/pdf/2505.15758v2",
    "published": "2025-05-21T17:03:15+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15757v1",
    "title": "State Characterisation of Self-Directed Channel Memristive Devices",
    "authors": [
      "D√°niel Hajt√≥",
      "Waleed El-Geresy",
      "Deniz G√ºnd√ºz",
      "Gy√∂rgy Cserey"
    ],
    "abstract": "Knowing how to reliably use memristors as information storage devices is\ncrucial not only to their role as emerging memories, but also for their\napplication in neural network acceleration and as components of novel\nneuromorphic systems. In order to better understand the dynamics of information\nstorage on memristors, it is essential to be able to characterise and measure\ntheir state. To this end, in this paper we propose a general, physics-inspired\nmodelling approach for characterising the state of self-directed channel (SDC)\nmemristors. Additionally, to enable the identification of the proposed state\nfrom device data, we introduce a noise-aware approach to the minimum-variance\nestimation of the state from voltage and current pairs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15757v1",
    "published": "2025-05-21T17:02:42+00:00",
    "categories": [
      "cs.ET",
      "physics.app-ph"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2506.06304v1",
    "title": "Trigonometric Ratios Can Prove the Pythagorean Theorem",
    "authors": [
      "Shoya Kise",
      "Takesa Uehara",
      "Takashi Shinzato"
    ],
    "abstract": "Recent interest in noncircular trigonometric proofs has underscored the need\nfor alternative methodologies. Jackson and Johnson's 2024 study addresses a\nlongstanding gap in the foundations of trigonometric proofs. Inspired by the\nwork of Jackson and Johnson [JJ24], we present three noncircular proofs of the\nPythagorean theorem based on trigonometric identities. First, we establish the\nPythagorean theorem via an isosceles triangle construction and the tangent\ndouble-angle formula. Second, we present an alternative proof utilizing an\nisosceles-triangle and the angle-bisector theorem. Third, we derive a novel\ntrigonometric relation from the angle-bisector theorem, thereby unifying and\nextending the two preceding approaches. These approaches collectively\ndemonstrate that the principal contribution of Jackson and Johnson lies in\ntheir strategic use of the double-angle formula. These proofs clarify the role\nof trigonometric identities independent of infinite series.",
    "pdf_url": "http://arxiv.org/pdf/2506.06304v1",
    "published": "2025-05-21T17:01:41+00:00",
    "categories": [
      "math.HO",
      "math.AG"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15756v1",
    "title": "An Empirical Analysis of Vulnerability Detection Tools for Solidity Smart Contracts Using Line Level Manually Annotated Vulnerabilities",
    "authors": [
      "Francesco Salzano",
      "Cosmo Kevin Antenucci",
      "Simone Scalabrino",
      "Giovanni Rosa",
      "Rocco Oliveto",
      "Remo Pareschi"
    ],
    "abstract": "The rapid adoption of blockchain technology highlighted the importance of\nensuring the security of smart contracts due to their critical role in\nautomated business logic execution on blockchain platforms. This paper provides\nan empirical evaluation of automated vulnerability analysis tools specifically\ndesigned for Solidity smart contracts. Leveraging the extensive SmartBugs 2.0\nframework, which includes 20 analysis tools, we conducted a comprehensive\nassessment using an annotated dataset of 2,182 instances we manually annotated\nwith line-level vulnerability labels. Our evaluation highlights the detection\neffectiveness of these tools in detecting various types of vulnerabilities, as\ncategorized by the DASP TOP 10 taxonomy. We evaluated the effectiveness of a\nLarge Language Model-based detection method on two popular datasets. In this\ncase, we obtained inconsistent results with the two datasets, showing\nunreliable detection when analyzing real-world smart contracts. Our study\nidentifies significant variations in the accuracy and reliability of different\ntools and demonstrates the advantages of combining multiple detection methods\nto improve vulnerability identification. We identified a set of 3 tools that,\ncombined, achieve up to 76.78\\% found vulnerabilities taking less than one\nminute to run, on average. This study contributes to the field by releasing the\nlargest dataset of manually analyzed smart contracts with line-level\nvulnerability annotations and the empirical evaluation of the greatest number\nof tools to date.",
    "pdf_url": "http://arxiv.org/pdf/2505.15756v1",
    "published": "2025-05-21T17:01:18+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15755v1",
    "title": "Exploring The Visual Feature Space for Multimodal Neural Decoding",
    "authors": [
      "Weihao Xia",
      "Cengiz Oztireli"
    ],
    "abstract": "The intrication of brain signals drives research that leverages multimodal AI\nto align brain modalities with visual and textual data for explainable\ndescriptions. However, most existing studies are limited to coarse\ninterpretations, lacking essential details on object descriptions, locations,\nattributes, and their relationships. This leads to imprecise and ambiguous\nreconstructions when using such cues for visual decoding. To address this, we\nanalyze different choices of vision feature spaces from pre-trained visual\ncomponents within Multimodal Large Language Models (MLLMs) and introduce a\nzero-shot multimodal brain decoding method that interacts with these models to\ndecode across multiple levels of granularities. % To assess a model's ability\nto decode fine details from brain signals, we propose the Multi-Granularity\nBrain Detail Understanding Benchmark (MG-BrainDub). This benchmark includes two\nkey tasks: detailed descriptions and salient question-answering, with metrics\nhighlighting key visual elements like objects, attributes, and relationships.\nOur approach enhances neural decoding precision and supports more accurate\nneuro-decoding applications. Code will be available at\nhttps://github.com/weihaox/VINDEX.",
    "pdf_url": "http://arxiv.org/pdf/2505.15755v1",
    "published": "2025-05-21T17:01:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15754v1",
    "title": "Improving planning and MBRL with temporally-extended actions",
    "authors": [
      "Palash Chatterjee",
      "Roni Khardon"
    ],
    "abstract": "Continuous time systems are often modeled using discrete time dynamics but\nthis requires a small simulation step to maintain accuracy. In turn, this\nrequires a large planning horizon which leads to computationally demanding\nplanning problems and reduced performance. Previous work in model free\nreinforcement learning has partially addressed this issue using action repeats\nwhere a policy is learned to determine a discrete action duration. Instead we\npropose to control the continuous decision timescale directly by using\ntemporally-extended actions and letting the planner treat the duration of the\naction as an additional optimization variable along with the standard action\nvariables. This additional structure has multiple advantages. It speeds up\nsimulation time of trajectories and, importantly, it allows for deep horizon\nsearch in terms of primitive actions while using a shallow search depth in the\nplanner. In addition, in the model based reinforcement learning (MBRL) setting,\nit reduces compounding errors from model learning and improves training time\nfor models. We show that this idea is effective and that the range for action\ndurations can be automatically selected using a multi-armed bandit formulation\nand integrated into the MBRL framework. An extensive experimental evaluation\nboth in planning and in MBRL, shows that our approach yields faster planning,\nbetter solutions, and that it enables solutions to problems that are not solved\nin the standard formulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15754v1",
    "published": "2025-05-21T16:59:32+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15753v1",
    "title": "Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval",
    "authors": [
      "Taiye Chen",
      "Zeming Wei",
      "Ang Li",
      "Yisen Wang"
    ],
    "abstract": "Large Language Models (LLMs) are known to be vulnerable to jailbreaking\nattacks, wherein adversaries exploit carefully engineered prompts to induce\nharmful or unethical responses. Such threats have raised critical concerns\nabout the safety and reliability of LLMs in real-world deployment. While\nexisting defense mechanisms partially mitigate such risks, subsequent\nadvancements in adversarial techniques have enabled novel jailbreaking methods\nto circumvent these protections, exposing the limitations of static defense\nframeworks. In this work, we explore defending against evolving jailbreaking\nthreats through the lens of context retrieval. First, we conduct a preliminary\nstudy demonstrating that even a minimal set of safety-aligned examples against\na particular jailbreak can significantly enhance robustness against this attack\npattern. Building on this insight, we further leverage the retrieval-augmented\ngeneration (RAG) techniques and propose Safety Context Retrieval (SCR), a\nscalable and robust safeguarding paradigm for LLMs against jailbreaking. Our\ncomprehensive experiments demonstrate how SCR achieves superior defensive\nperformance against both established and emerging jailbreaking tactics,\ncontributing a new paradigm to LLM safety. Our code will be available upon\npublication.",
    "pdf_url": "http://arxiv.org/pdf/2505.15753v1",
    "published": "2025-05-21T16:58:14+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15752v2",
    "title": "Energy transfer between localized emitters in photonic cavities from first principles",
    "authors": [
      "Swarnabha Chattaraj",
      "Giulia Galli"
    ],
    "abstract": "Radiative and nonradiative resonant couplings between defects are ubiquitous\nphenomena in photonic devices used in classical and quantum information\ntechnology applications. In this work we present a first principles approach to\nenable quantitative predictions of the energy transfer between defects in\nphotonic cavities, beyond the dipole-dipole approximation and including the\nmany-body nature of the electronic states. As an example, we discuss the energy\ntransfer from a dipole like emitter to an F center in MgO in a spherical\ncavity. We show that the cavity can be used to controllably enhance or suppress\nspecific spin flip and spin conserving transitions. Specifically, we predict\nthat a ~10 to 100 enhancement in the resonant energy transfer rate can be\ngained in the case of the F center in MgO at ~10nm distances from a dipolar\nsource, using rather moderate cavity with quality factor Q~400. We also show\nthat a similar suppression in the transfer rate can be achieved by off-tuning\nthe cavity resonance relative to the emitter transition energy. The framework\npresented here is general and readily applicable to a wide range of devices\nwhere localized emitters are embedded in micro-spheres, core-shell\nnanoparticles, and dielectric Mie resonators. Hence, our approach paves the way\nto predict how to control energy transfer in quantum memories and in ultra-high\ndensity optical memories, and in a variety of quantum information platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15752v2",
    "published": "2025-05-21T16:57:55+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mtrl-sci",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.15751v1",
    "title": "Metasurface-mediated quantum entanglement via bound states in the continuum",
    "authors": [
      "Hannah Riley",
      "Emmanuel Lassalle",
      "Diego Romero Abujetas",
      "Adam Stokes",
      "Ramon Paniagua-Dominguez",
      "Ahsan Nazir"
    ],
    "abstract": "Scalable quantum technologies demand entanglement between many distant\nquantum emitters (QEs), for which we propose using high-$Q$, spatially extended\nbound states in the continuum (BICs) in all-dielectric metasurfaces. We show\nthat QE-BIC coupling efficiencies ($\\beta$-factors) can exceed $80\\%$,\ncomparable to waveguides even without further mode engineering, but within a 2D\ngeometry that naturally accommodates large QE arrays and relaxes strict emitter\nplacement. Inter-QE entanglement is generated faster than in free space, is\nsignificantly amplified, and persists over several resonant wavelengths.\nOptimality requires large $\\beta$-factors but moderately small Purcell factors.\nOur results establish all-dielectric metasurfaces as a practical, scalable\nplatform for leading-edge quantum photonics.",
    "pdf_url": "http://arxiv.org/pdf/2505.15751v1",
    "published": "2025-05-21T16:57:47+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15750v2",
    "title": "Localising invariants in derived bornological geometry",
    "authors": [
      "Jack Kelly",
      "Devarshi Mukherjee"
    ],
    "abstract": "We study several categories of analytic stacks relative to the category of\nbornological modules over a Banach ring. When the underlying Banach ring is a\nnonarchimedean valued field, this category contains derived rigid analytic\nspaces as a full subcategory. When the underlying field is the complex numbers,\nit contains the category of derived complex analytic spaces. In the second part\nof the paper, we consider localising invariants of rigid categories associated\nto bornological algebras. The main results in this part include Nisnevich\ndescent for derived analytic spaces and a version of the\nGrothendieck-Riemann-Roch Theorem for derived dagger analytic spaces over an\narbitrary Banach ring.",
    "pdf_url": "http://arxiv.org/pdf/2505.15750v2",
    "published": "2025-05-21T16:57:37+00:00",
    "categories": [
      "math.KT",
      "math.AG",
      "math.AT"
    ],
    "primary_category": "math.KT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15749v1",
    "title": "A note on the Brill-Noether loci of small codimension in moduli space of stable bundles",
    "authors": [
      "Pritthijit Biswas",
      "Jaya NN Iyer"
    ],
    "abstract": "Let $X$ be a smooth projective curve of genus $g$ over the field\n$\\mathbb{C}$. Let $M_{X}(2,L)$ denote the moduli space of stable rank $2$\nvector bundles on $X$ with fixed determinant $L$ of degree $2g-1$. Consider the\nBrill-Noether subvariety $W^{1}_{X}(2,L)$ of $M_{X}(2,L)$ which parametrises\nstable vector bundles having at least two linearly independent global sections.\nIn this article, for generic $X$ and $L$, we show that $W^{1}_{X}(2,L)$ is\nstably-rational when $g=3$, unirational when $g=4$, and rationally chain\nconnected by Hecke curves, when $g\\geq 5$. We also show triviality of low\ndimensional rational Chow groups of an associated Brill-Noether hypersurface.",
    "pdf_url": "http://arxiv.org/pdf/2505.15749v1",
    "published": "2025-05-21T16:55:19+00:00",
    "categories": [
      "math.AG",
      "14D20"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15748v3",
    "title": "Characterization of bi-parametric potentials and rate of convergence of truncated hypersingular integrals in the Dunkl setting",
    "authors": [
      "Sandeep Kumar Verma",
      "Athulya P"
    ],
    "abstract": "In this work, we introduce the $\\beta$-semigroup for $\\beta > 0$, which\nunifies and extends the classical Poisson (for $\\beta=1$) and heat (for\n$\\beta=2$) semigroups within the Dunkl analysis framework. Leveraging this\nsemigroup, we derive an explicit representation for the inverse of the\nDunkl-Riesz potential and characterize the image of the function space\n$L_k^p(\\mathbb{R}^n)$ for $1 \\leq p < \\frac{n + 2\\gamma}{\\alpha}$. We further\ndefine the bi-parametric potential of order $\\alpha$ by\n$$\\mathfrak{S}_k^{(\\alpha,\\beta)} = \\left(I +\n(-\\Delta_k)^{\\beta/2}\\right)^{-\\alpha/\\beta}$$ and establish its inverse along\nwith a detailed description of the associated range space. Our approach employs\na wavelet-based method that represents the inverse as the limit of truncated\nhypersingular integrals parameterized by $\\epsilon > 0$. To analyze the\nconvergence of these approximations, we introduce the concept of\n$\\eta$-smoothness at a point $x_0$ in the Dunkl setting. We show that if a\nfunction $f \\in L_k^p(\\mathbb{R}^n) \\cap L_k^2(\\mathbb{R}^n)$, for $1 \\leq p\n\\leq \\infty$, possesses $\\eta$-smoothness at $x_0$, then the truncated\nhypersingular approximations converge to $f(x_0)$ as $\\epsilon \\to 0^+$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15748v3",
    "published": "2025-05-21T16:53:43+00:00",
    "categories": [
      "math.FA",
      "41A35, 42A38, 44A35, 47G20",
      "G.0"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15747v2",
    "title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs",
    "authors": [
      "Kanan Kiguchi",
      "Yunhao Tu",
      "Katsuhiro Ajito",
      "Fady Alnajjar",
      "Kazuyuki Murase"
    ],
    "abstract": "We propose a novel framework for integrating fragmented multi-modal data in\nAlzheimer's disease (AD) research using large language models (LLMs) and\nknowledge graphs. While traditional multimodal analysis requires matched\npatient IDs across datasets, our approach demonstrates population-level\nintegration of MRI, gene expression, biomarkers, EEG, and clinical indicators\nfrom independent cohorts. Statistical analysis identified significant features\nin each modality, which were connected as nodes in a knowledge graph. LLMs then\nanalyzed the graph to extract potential correlations and generate hypotheses in\nnatural language. This approach revealed several novel relationships, including\na potential pathway linking metabolic risk factors to tau protein abnormalities\nvia neuroinflammation (r>0.6, p<0.001), and unexpected correlations between\nfrontal EEG channels and specific gene expression profiles (r=0.42-0.58,\np<0.01). Cross-validation with independent datasets confirmed the robustness of\nmajor findings, with consistent effect sizes across cohorts (variance <15%).\nThe reproducibility of these findings was further supported by expert review\n(Cohen's k=0.82) and computational validation. Our framework enables cross\nmodal integration at a conceptual level without requiring patient ID matching,\noffering new possibilities for understanding AD pathology through fragmented\ndata reuse and generating testable hypotheses for future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15747v2",
    "published": "2025-05-21T16:51:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.1; H.3.1; J.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15746v1",
    "title": "Higher-order Structure Boosts Link Prediction on Temporal Graphs",
    "authors": [
      "Jingzhe Liu",
      "Zhigang Hua",
      "Yan Xie",
      "Bingheng Li",
      "Harry Shomer",
      "Yu Song",
      "Kaveh Hassani",
      "Jiliang Tang"
    ],
    "abstract": "Temporal Graph Neural Networks (TGNNs) have gained growing attention for\nmodeling and predicting structures in temporal graphs. However, existing TGNNs\nprimarily focus on pairwise interactions while overlooking higher-order\nstructures that are integral to link formation and evolution in real-world\ntemporal graphs. Meanwhile, these models often suffer from efficiency\nbottlenecks, further limiting their expressive power. To tackle these\nchallenges, we propose a Higher-order structure Temporal Graph Neural Network,\nwhich incorporates hypergraph representations into temporal graph learning. In\nparticular, we develop an algorithm to identify the underlying higher-order\nstructures, enhancing the model's ability to capture the group interactions.\nFurthermore, by aggregating multiple edge features into hyperedge\nrepresentations, HTGN effectively reduces memory cost during training. We\ntheoretically demonstrate the enhanced expressiveness of our approach and\nvalidate its effectiveness and efficiency through extensive experiments on\nvarious real-world temporal graphs. Experimental results show that HTGN\nachieves superior performance on dynamic link prediction while reducing memory\ncosts by up to 50\\% compared to existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15746v1",
    "published": "2025-05-21T16:51:44+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15745v1",
    "title": "Majorana Zero Modes in a Heterogenous Structure of Topological and Trivial Domains in FeSe$_{1-x}$Te$_x$",
    "authors": [
      "Prashant Gupta",
      "Jasmin Bedow",
      "Eric Mascot",
      "Dirk K. Morr"
    ],
    "abstract": "We propose that the existence of vortices in FeSe$_{1-x}$Te$_x$ with and\nwithout Majoarana zero modes (MZMs) can be explained by a heterogeneous mixture\nof strong topological and trivial superconducting domains, with only vortices\nin the former exhibiting MZMs. We identify the spectroscopic signatures of\ntopological and trivial vortices and show that they are necessarily separated\nby a domain wall harboring Majorana edge modes. We demonstrate that when a\nvortex is moved from a trivial to a topological domain in real time, a domain\nwall Majorana edge mode is transferred to the vortex as an MZM.",
    "pdf_url": "http://arxiv.org/pdf/2505.15745v1",
    "published": "2025-05-21T16:51:20+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.15744v1",
    "title": "Some questions in Diophantine approximation: real and p-adics",
    "authors": [
      "Dipendra Prasad"
    ],
    "abstract": "The Weak approximation theorem describes the closure of $G(Q)$ inside\n$G(Q_p)$ as well as inside\n  $G(R)$ for $G$ an algebraic group over $Q$; the closure is always an open\nnormal subgroup with finite abelian quotient, and is well understood in a\ncertain sense even if precise\n  results are not always available (such as for tori!). In this paper,\n  for a finitely generated subgroup $ L \\subset G(Q)$ we consider the\ntopological closure of $ L$ inside $G(Q_p)$\n  and $G(R)$. The paper is written mostly for $G$ a torus or an abelian\nvariety, but eventually considers a variant of the question for\n  $G$ a semisimple group. The paper is written with the wishful thinking\n  that when dealing with questions on topological closure of algebraic points\nin an algebraic group defined over a number field,\n  the simplest answers hold, a well-known\n  principle known as ``Occum's razor''.",
    "pdf_url": "http://arxiv.org/pdf/2505.15744v1",
    "published": "2025-05-21T16:50:21+00:00",
    "categories": [
      "math.NT",
      "11J95, 11J13"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15743v1",
    "title": "Who \"Controls\" Where Work Shall be Done? State-of-Practice in Post-Pandemic Remote Work Regulation",
    "authors": [
      "Darja Smite",
      "Nils Brede Moe",
      "Maria Teresa Baldassarre",
      "Fabio Calefato",
      "Guilherme Horta Travassos",
      "Marcin Floryan",
      "Marcos Kalinowski",
      "Daniel Mendez",
      "Graziela Basilio Pereira",
      "Margaret-Anne Storey",
      "Rafael Prikladnicki"
    ],
    "abstract": "The COVID-19 pandemic has permanently altered workplace structures, making\nremote work a widespread practice. While many employees advocate for\nflexibility, many employers reconsider their attitude toward remote work and\nopt for structured return-to-office mandates. Media headlines repeatedly\nemphasize that the corporate world is returning to full-time office work. This\nstudy examines how companies employing software engineers and supporting roles\nregulate work location, whether corporate policies have evolved in the last\nfive years, and, if so, how, and why. We collected data on remote work\nregulation from corporate HR and/or management representatives from 68\ncorporate entities that vary in size, location, and orientation towards remote\nor office work. Our findings reveal that although many companies prioritize\noffice-centred working (50%), most companies in our sample permit hybrid\nworking to varying degrees (85%). Remote work regulation does not reveal any\nparticular new \"best practice\" as policies differ greatly, but the single most\npopular arrangement was the three in-office days per week. More than half of\nthe companies (51%) encourage or mandate office days, and more than quarter\n(28%) have changed regulations, gradually increasing the mandatory office\npresence or implementing differentiated conditions. Although no companies have\nincreased flexibility, only four companies are returning to full-time office\nwork. Our key recommendation for office-oriented companies is to consider a\ntrust-based alternative to strict office presence mandates, while for companies\noriented toward remote working, we warn about the points of no (or hard)\nreturn. Finally, the current state of policies is clearly not final, as\ncompanies continue to experiment and adjust their work regulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15743v1",
    "published": "2025-05-21T16:50:09+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15742v1",
    "title": "Neuro-Argumentative Learning with Case-Based Reasoning",
    "authors": [
      "Adam Gould",
      "Francesca Toni"
    ],
    "abstract": "We introduce Gradual Abstract Argumentation for Case-Based Reasoning (Gradual\nAA-CBR), a data-driven, neurosymbolic classification model in which the outcome\nis determined by an argumentation debate structure that is learned\nsimultaneously with neural-based feature extractors. Each argument in the\ndebate is an observed case from the training data, favouring their labelling.\nCases attack or support those with opposing or agreeing labellings, with the\nstrength of each argument and relationship learned through gradient-based\nmethods. This argumentation debate structure provides human-aligned reasoning,\nimproving model interpretability compared to traditional neural networks (NNs).\nUnlike the existing purely symbolic variant, Abstract Argumentation for\nCase-Based Reasoning (AA-CBR), Gradual AA-CBR is capable of multi-class\nclassification, automatic learning of feature and data point importance,\nassigning uncertainty values to outcomes, using all available data points, and\ndoes not require binary features. We show that Gradual AA-CBR performs\ncomparably to NNs whilst significantly outperforming existing AA-CBR\nformulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15742v1",
    "published": "2025-05-21T16:49:47+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15741v1",
    "title": "Evolutionary Computation and Large Language Models: A Survey of Methods, Synergies, and Applications",
    "authors": [
      "Dikshit Chauhan",
      "Bapi Dutta",
      "Indu Bala",
      "Niki van Stein",
      "Thomas B√§ck",
      "Anupam Yadav"
    ],
    "abstract": "Integrating Large Language Models (LLMs) and Evolutionary Computation (EC)\nrepresents a promising avenue for advancing artificial intelligence by\ncombining powerful natural language understanding with optimization and search\ncapabilities. This manuscript explores the synergistic potential of LLMs and\nEC, reviewing their intersections, complementary strengths, and emerging\napplications. We identify key opportunities where EC can enhance LLM training,\nfine-tuning, prompt engineering, and architecture search, while LLMs can, in\nturn, aid in automating the design, analysis, and interpretation of ECs. The\nmanuscript explores the synergistic integration of EC and LLMs, highlighting\ntheir bidirectional contributions to advancing artificial intelligence. It\nfirst examines how EC techniques enhance LLMs by optimizing key components such\nas prompt engineering, hyperparameter tuning, and architecture search,\ndemonstrating how evolutionary methods automate and refine these processes.\nSecondly, the survey investigates how LLMs improve EC by automating\nmetaheuristic design, tuning evolutionary algorithms, and generating adaptive\nheuristics, thereby increasing efficiency and scalability. Emerging\nco-evolutionary frameworks are discussed, showcasing applications across\ndiverse fields while acknowledging challenges like computational costs,\ninterpretability, and algorithmic convergence. The survey concludes by\nidentifying open research questions and advocating for hybrid approaches that\ncombine the strengths of EC and LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15741v1",
    "published": "2025-05-21T16:48:28+00:00",
    "categories": [
      "cs.NE",
      "cs.CL",
      "cs.MA",
      "I.2.7; I.2.11"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.17121v1",
    "title": "NeSyGeo: A Neuro-Symbolic Framework for Multimodal Geometric Reasoning Data Generation",
    "authors": [
      "Weiming Wu",
      "Zi-kang Wang",
      "Jin Ye",
      "Zhi Zhou",
      "Yu-Feng Li",
      "Lan-Zhe Guo"
    ],
    "abstract": "Obtaining large-scale, high-quality data with reasoning paths is crucial for\nimproving the geometric reasoning capabilities of multi-modal large language\nmodels (MLLMs). However, existing data generation methods, whether based on\npredefined templates or constrained symbolic provers, inevitably face diversity\nand numerical generalization limitations. To address these limitations, we\npropose NeSyGeo, a novel neuro-symbolic framework for generating geometric\nreasoning data. First, we propose a domain-specific language grounded in the\nentity-relation-constraint paradigm to comprehensively represent all components\nof plane geometry, along with generative actions defined within this symbolic\nspace. We then design a symbolic-visual-text pipeline that synthesizes symbolic\nsequences, maps them to corresponding visual and textual representations, and\ngenerates diverse question-answer (Q&A) pairs using large language models\n(LLMs). To the best of our knowledge, we are the first to propose a\nneuro-symbolic approach in generating multimodal reasoning data. Based on this\nframework, we construct NeSyGeo-CoT and NeSyGeo-Caption datasets, containing\n100k samples, and release a new benchmark NeSyGeo-Test for evaluating geometric\nreasoning abilities in MLLMs. Experiments demonstrate that the proposal\nsignificantly and consistently improves the performance of multiple MLLMs under\nboth reinforcement and supervised fine-tuning. With only 4k samples and two\nepochs of reinforcement fine-tuning, base models achieve improvements of up to\n+15.8% on MathVision, +8.4% on MathVerse, and +7.3% on GeoQA. Notably, a 4B\nmodel can be improved to outperform an 8B model from the same series on\ngeometric reasoning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.17121v1",
    "published": "2025-05-21T16:45:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15740v1",
    "title": "HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement",
    "authors": [
      "Jilin Hu",
      "Jianyu Zhang",
      "Yongwang Zhao",
      "Talia Ringer"
    ],
    "abstract": "Formal methods is pivotal for verifying the reliability of critical systems\nthrough rigorous mathematical proofs. However, its adoption is hindered by\nlabor-intensive manual proofs and the expertise required to use theorem\nprovers. Recent advancements in large language models (LLMs) offer new\nopportunities for automated theorem proving. Two promising approaches are\ngenerating tactics step by step and generating a whole proof directly with an\nLLM. However, existing work makes no attempt to combine the two approaches. In\nthis work, we introduce HybridProver, a dual-model proof synthesis framework\nthat combines tactic-based generation and whole-proof synthesis to harness the\nbenefits of both approaches. HybridProver generates whole proof candidates for\nevaluation directly, then extracts proof sketches from those candidates. It\nthen uses a tactic-based generation model that integrates automated tools to\ncomplete the sketches via stepwise refinement. We implement HybridProver for\nthe Isabelle theorem prover and fine-tune LLMs on our optimized Isabelle\ndatasets. Evaluation on the miniF2F dataset illustrates HybridProver's\neffectiveness. We achieve a 59.4% success rate on miniF2F, where the previous\nSOTA is 56.1%. Our ablation studies show that this SOTA result is attributable\nto combining whole-proof and tactic-based generation. Additionally, we show how\nthe dataset quality, training parameters, and sampling diversity affect the\nfinal result during automated theorem proving with LLMs. All of our code,\ndatasets, and LLMs are open source.",
    "pdf_url": "http://arxiv.org/pdf/2505.15740v1",
    "published": "2025-05-21T16:45:43+00:00",
    "categories": [
      "cs.FL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15739v1",
    "title": "On a Simplex Contained in a Ball",
    "authors": [
      "Mikhail Nevskii"
    ],
    "abstract": "Let $B_n$ be the $n$-dimensional unit ball given by the inequality $\\|x\\|\\leq\n1$, where $\\|x\\|$ is the standard Euclid norm in ${\\mathbb R}^n$. For an\n$n$-dimensional nondegenerate simplex $S$, we denote by $E$ the ellipsoid of\nminimum volume which contains $S$. Suppose $S\\subset B_n$, $0\\leq m\\leq n-1$.\nLet $G$ be any $m$-dimensional face of $S$ and let $H$ be the opposite\n$(n-m-1)$-dimensional face. Denote by $g$ and $h$ the centers of gravity of $G$\nand $H$ respectively. Define $y$ as the intersection point of the line passing\nfrom $g$ to $h$ with the boundary of $E$. Let us call the face $G$ suitable if\n$y\\in B_n.$ Earlier it was proved that each simplex $S\\subset B_n$ has a\nsuitable face of any dimension $\\leq n-1$. We show the following. If some\nvertex of $S$ is suitable, then there exists a suitable face of any dimension\n$\\leq n-1$ which contains this vertex.",
    "pdf_url": "http://arxiv.org/pdf/2505.15739v1",
    "published": "2025-05-21T16:43:51+00:00",
    "categories": [
      "math.MG",
      "41A05, 52B55, 52C07"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15738v1",
    "title": "Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses",
    "authors": [
      "Xiaoxue Yang",
      "Bozhidar Stevanoski",
      "Matthieu Meeus",
      "Yves-Alexandre de Montjoye"
    ],
    "abstract": "Large language models (LLMs) are rapidly deployed in real-world applications\nranging from chatbots to agentic systems. Alignment is one of the main\napproaches used to defend against attacks such as prompt injection and\njailbreaks. Recent defenses report near-zero Attack Success Rates (ASR) even\nagainst Greedy Coordinate Gradient (GCG), a white-box attack that generates\nadversarial suffixes to induce attacker-desired outputs. However, this search\nspace over discrete tokens is extremely large, making the task of finding\nsuccessful attacks difficult. GCG has, for instance, been shown to converge to\nlocal minima, making it sensitive to initialization choices. In this paper, we\nassess the future-proof robustness of these defenses using a more informed\nthreat model: attackers who have access to some information about the alignment\nprocess. Specifically, we propose an informed white-box attack leveraging the\nintermediate model checkpoints to initialize GCG, with each checkpoint acting\nas a stepping stone for the next one. We show this approach to be highly\neffective across state-of-the-art (SOTA) defenses and models. We further show\nour informed initialization to outperform other initialization methods and show\na gradient-informed checkpoint selection strategy to greatly improve attack\nperformance and efficiency. Importantly, we also show our method to\nsuccessfully find universal adversarial suffixes -- single suffixes effective\nacross diverse inputs. Our results show that, contrary to previous beliefs,\neffective adversarial suffixes do exist against SOTA alignment-based defenses,\nthat these can be found by existing attack methods when adversaries exploit\nalignment knowledge, and that even universal suffixes exist. Taken together,\nour results highlight the brittleness of current alignment-based methods and\nthe need to consider stronger threat models when testing the safety of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15738v1",
    "published": "2025-05-21T16:43:17+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15737v2",
    "title": "RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction",
    "authors": [
      "Zhuodong Jiang",
      "Haoran Wang",
      "Guoxi Huang",
      "Brett Seymour",
      "Nantheera Anantrasirichai"
    ],
    "abstract": "Reconstructing high-fidelity underwater scenes remains a challenging task due\nto light absorption, scattering, and limited visibility inherent in aquatic\nenvironments. This paper presents an enhanced Gaussian Splatting-based\nframework that improves both the visual quality and geometric accuracy of deep\nunderwater rendering. We propose decoupled learning for RGB channels, guided by\nthe physics of underwater attenuation, to enable more accurate colour\nrestoration. To address sparse-view limitations and improve view consistency,\nwe introduce a frame interpolation strategy with a novel adaptive weighting\nscheme. Additionally, we introduce a new loss function aimed at reducing noise\nwhile preserving edges, which is essential for deep-sea content. We also\nrelease a newly collected dataset, Submerged3D, captured specifically in\ndeep-sea environments. Experimental results demonstrate that our framework\nconsistently outperforms state-of-the-art methods with PSNR gains up to 1.90dB,\ndelivering superior perceptual quality and robustness, and offering promising\ndirections for marine robotics and underwater visual analytics. The code of\nRUSplatting is available at https://github.com/theflash987/RUSplatting and the\ndataset Submerged3D can be downloaded at https://zenodo.org/records/15482420.",
    "pdf_url": "http://arxiv.org/pdf/2505.15737v2",
    "published": "2025-05-21T16:42:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15736v1",
    "title": "AstroSat/UVIT far and near UV deep field around IC 4329A",
    "authors": [
      "Piyali Ganguly",
      "Priyanka Rani",
      "Gulab C. Dewangan"
    ],
    "abstract": "We present high-resolution near-ultraviolet (NUV) and far-ultraviolet (FUV)\ndeep imaging of the field around the Seyfert galaxy IC~4329A based on five\nobservations performed with the Ultra-Violet Imaging Telescope (UVIT), onboard\nAstroSat. The long exposures of 82.9 ks in NUV (N245M;\n$\\lambda_{mean}=2447$\\r{A} ; $\\Delta\\lambda = 270$\\r{A}) and 92.2~ks in FUV\n(F154W; $\\lambda_{mean} = 1541$\\r{A}; $\\Delta\\lambda=380$\\r{A}) bands\nconstitute the deepest observations with $5\\sigma$ detection limits of AB\nmagnitudes $m_{NUV}= 26.2$ and $m_{FUV} = 25.7$. Leveraging UVIT's excellent\nangular resolution (FWHM $\\sim 1.2-1.8^{\\prime \\prime}$), we performed a\ndetailed analysis of the IC~4329A field and detected (above 5$\\sigma$\nsignificance level) a total of 4437 and 456 sources in the NUV and FUV bands,\nrespectively. A large number of these detected sources were unknown previously.\nWe performed astrometry and photometry on all detected sources. By\ncross-matching our catalogue with Gaia-DR3 and XMM-Newton DR12 catalogues, we\nfound 651 optical and 97 X-ray counterparts of our sources. Additionally, we\nexplored UV variability of point sources, identifying 28 NUV sources as\nvariable with a significance above the $2.5\\sigma$ level. Of these, only three\nsources exhibited variability in the FUV band. Utilising the NUV and Gaia\nfluxes, we determined that two previously catalogued white dwarf candidates are\nmisclassified. Furthermore, we highlight galaxies with atypical morphology,\nincluding ring-like structures, multiple compact central sources, bifurcating\nspiral arms, etc. Follow-up optical spectroscopy and multi-wavelength\nobservations are imperative to further investigate the nature of the sources\nwithin this field.",
    "pdf_url": "http://arxiv.org/pdf/2505.15736v1",
    "published": "2025-05-21T16:41:08+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15735v1",
    "title": "A systematic review of sample size determination in Bayesian randomized clinical trials: full Bayesian methods are rarely used",
    "authors": [
      "Yanara Marks",
      "Jessie Cunningham",
      "Arlene Jiang",
      "Linke Li",
      "Yi-Shu Lin",
      "Abigail McGrory",
      "Yongdong Ouyang",
      "Nam-Anh Tran",
      "Yuning Wang",
      "Anna Heath"
    ],
    "abstract": "Utilizing Bayesian methods in clinical trials has become increasingly\npopular, as they can incorporate historical data and expert opinions into the\ndesign and allow for smaller sample sizes to reduce costs while providing\nreliable and robust statistical results. Sample size determination (SSD) is a\nkey aspect of clinical trial design and various methods for Bayesian sample\nsize determination are available. However, it is unclear how these methods are\nbeing used in practice. A systematic literature review was conducted to\nunderstand how sample sizes for Bayesian randomized clinical trials (RCTs) are\ndetermined and inform the design of future Bayesian trials. We searched five\ndatabases in May 2023, and updated in January 2025, including efficacy RCTs in\nhumans which utilized a Bayesian framework for the primary data analysis,\npublished in English, and enrolled participants between 2009 and 2024. The\nliterature search produced 19,182 records, of which 105 studies were selected\nfor data extraction. Results show that the most common method for SSD in\nBayesian RCTs was a hybrid approach in which elements of Bayesian and\nfrequentist theory are combined. Many RCTs did not provide a justification for\nSSD, while fully Bayesian methods were rarely used in practice, despite\nsignificant theoretical development. Our review also revealed a lack of\nstandardized reporting, making it challenging to review the SSD. The CONSORT\nstatement for reporting RCTs states that sample size calculations must be\nreported, which was poorly adhered to. Among RCTs that reported SSD, relevant\ninformation was frequently omitted from the reports and discussed in poorly\nstructured supplementary materials. Thus, there is a critical need for greater\ntransparency, standardization and translation of relevant methodology in\nBayesian RCTs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15735v1",
    "published": "2025-05-21T16:40:40+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15734v1",
    "title": "DEBATE, TRAIN, EVOLVE: Self Evolution of Language Model Reasoning",
    "authors": [
      "Gaurav Srivastava",
      "Zhenyu Bi",
      "Meng Lu",
      "Xuan Wang"
    ],
    "abstract": "Large language models (LLMs) have improved significantly in their reasoning\nthrough extensive training on massive datasets. However, relying solely on\nadditional data for improvement is becoming increasingly impractical,\nhighlighting the need for models to autonomously enhance their reasoning\nwithout external supervision. In this paper, we propose Debate, Train, Evolve\n(DTE), a novel ground truth-free training framework that uses multi-agent\ndebate traces to evolve a single language model. We also introduce a new\nprompting strategy Reflect-Critique-Refine, to improve debate quality by\nexplicitly instructing agents to critique and refine their reasoning. Extensive\nevaluations on five reasoning benchmarks with six open-weight models show that\nour DTE framework achieve substantial improvements, with an average accuracy\ngain of 8.92% on the challenging GSM-PLUS dataset. Furthermore, we observe\nstrong cross-domain generalization, with an average accuracy gain of 5.8% on\nall other benchmarks, suggesting that our method captures general reasoning\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15734v1",
    "published": "2025-05-21T16:40:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15733v1",
    "title": "Distributionally Robust Planning of Hydrogen-Electrical Microgrids for Sea Islands",
    "authors": [
      "Yuchen Dong",
      "Zhengsong Lu",
      "Xiaoyu Cao",
      "Zhengwen He",
      "Tanveer Hossain Bhuiyan",
      "Bo Zeng"
    ],
    "abstract": "This paper presents a distributionally robust planning method for\nhydrogen-electrical microgrids over islands, where the cross-island energy\nexchange is supported by a maritime hydrogen transport network. This planning\nproblem is complicated due to heterogeneous off-shore wind-driven uncertainties\n(i.e., renewable power, transport availability, demand fluctuations, and grid\nfaulting), a subset of which exhibit endogenous uncertainty, as they can be\naffected by proactive measures (e.g., grid hardening) or infrastructure\ninvestment. To capture these features, a two-stage distributionally robust\noptimization (DRO) model is developed considering decision-dependent\nuncertainty (DDU), which encompasses variation of the underlying distributional\nambiguity due to the change of the first stage decisions. Notably, the complete\nrecourse property is missing, which is often neglected in existing DRO studies.\nNevertheless, different from the case for land-based microgrids, this issue is\ncritical and fundamental for sea island systems due to their particular\nphysical and logistical requirements. To address these issues, we develop a\nC&CG algorithm that is customized with strong cutting planes to handle DRO with\na varying DDU ambiguity set and feasibility requirements. Numerical results\ndemonstrate the cost-effectiveness and resilience of the proposed planning\nframework, along with the nontrivial improvements of the algorithm in both\nsolution accuracy and computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.15733v1",
    "published": "2025-05-21T16:39:36+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15732v1",
    "title": "Designing a Potential NASA Fermi Orbit Change",
    "authors": [
      "Wayne Yu",
      "Trevor Williams",
      "Russell Carpenter"
    ],
    "abstract": "The Fermi Gamma ray Space Telescope, launched in 2008, has over 16 years of\noperations providing gamma ray (8 keV to 300 Gev) spectra science observations\nof cosmic phenomena. It continues to provide invaluable research for the\nastrophysics community which include the study of pulsars, cosmic rays, gamma\nray bursts, and coordination with gravity wave observations for neutron star\nmergers. The Fermi Earth orbit at a 500 x 512 km altitude is subject to\ncollision warnings due to new constellations deployed near Fermi: currently\nover 7,000 satellites and growing. This paper presents analysis concerning\nchanging Fermi's orbit and associated operational flight dynamics\nconsiderations. The cadence of burns and expected fuel use for a proposed orbit\nraise scenario is examined, ensuring that Fermi should have sufficient fuel for\nend of life operations. In addition, a Monte Carlo design is presented to\ncapture single maneuver model uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2505.15732v1",
    "published": "2025-05-21T16:38:15+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15731v1",
    "title": "Active Protothrusts and Fluid Highways: Seismic Noise Reveals Hidden Subduction Dynamics in Cascadia",
    "authors": [
      "Maleen Kidiwela",
      "Marine A. Denolle",
      "William S. D. Wilcock",
      "Kuan-Fu Feng"
    ],
    "abstract": "Complex interactions between strain accumulation, fault slip, and fluid\nmigration influence shallow subduction zone dynamics. Using a decade of\ncontinuous ambient seismic data from Cascadia seafloor observatories, we\nidentified distinct regional variations in subduction dynamics. Northern\nCascadia exhibits a fully locked megathrust with persistent strain\naccumulation, while central Cascadia displays a slow slip event on protothrusts\nand rapid fluid migration along fault systems in the overriding plate.\nEffective fluid transport through the decollement and the Alvin Canyon Fault\nlikely modulates the earthquake behavior but does not cause slow slip events on\nthe megathrust and likely stabilizes large earthquakes, promoting rupture\narrest.",
    "pdf_url": "http://arxiv.org/pdf/2505.15731v1",
    "published": "2025-05-21T16:36:52+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15730v1",
    "title": "iBitter-Stack: A Multi-Representation Ensemble Learning Model for Accurate Bitter Peptide Identification",
    "authors": [
      "Sarfraz Ahmad",
      "Momina Ahsan",
      "Muhammad Nabeel Asim",
      "Andreas Dengel",
      "Muhammad Imran Malik"
    ],
    "abstract": "The identification of bitter peptides is crucial in various domains,\nincluding food science, drug discovery, and biochemical research. These\npeptides not only contribute to the undesirable taste of hydrolyzed proteins\nbut also play key roles in physiological and pharmacological processes.\nHowever, experimental methods for identifying bitter peptides are\ntime-consuming and expensive. With the rapid expansion of peptide sequence\ndatabases in the post-genomic era, the demand for efficient computational\napproaches to distinguish bitter from non-bitter peptides has become\nincreasingly significant. In this study, we propose a novel stacking-based\nensemble learning framework aimed at enhancing the accuracy and reliability of\nbitter peptide classification. Our method integrates diverse sequence-based\nfeature representations and leverages a broad set of machine learning\nclassifiers. The first stacking layer comprises multiple base classifiers, each\ntrained on distinct feature encoding schemes, while the second layer employs\nlogistic regression to refine predictions using an eight-dimensional\nprobability vector. Extensive evaluations on a carefully curated dataset\ndemonstrate that our model significantly outperforms existing predictive\nmethods, providing a robust and reliable computational tool for bitter peptide\nidentification. Our approach achieves an accuracy of 96.09\\% and a Matthews\nCorrelation Coefficient (MCC) of 0.9220 on the independent test set,\nunderscoring its effectiveness and generalizability. To facilitate real-time\nusage and broader accessibility, we have also developed a user-friendly web\nserver based on the proposed method, which is freely accessible at\nhttps://ibitter-stack-webserver.streamlit.app/. This tool enables researchers\nand practitioners to conveniently screen peptide sequences for bitterness in\nreal-time applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15730v1",
    "published": "2025-05-21T16:35:29+00:00",
    "categories": [
      "q-bio.QM",
      "J.3"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.17120v1",
    "title": "Self-Interpretability: LLMs Can Describe Complex Internal Processes that Drive Their Decisions, and Improve with Training",
    "authors": [
      "Dillon Plunkett",
      "Adam Morris",
      "Keerthi Reddy",
      "Jorge Morales"
    ],
    "abstract": "We have only limited understanding of how and why large language models\n(LLMs) respond in the ways that they do. Their neural networks have proven\nchallenging to interpret, and we are only beginning to tease out the function\nof individual neurons and circuits within them. However, another path to\nunderstanding these systems is to investigate and develop their capacity to\nintrospect and explain their own functioning. Here, we show that i)\ncontemporary LLMs are capable of providing accurate, quantitative descriptions\nof their own internal processes during certain kinds of decision-making, ii)\nthat it is possible to improve these capabilities through training, and iii)\nthat this training generalizes to at least some degree. To do so, we fine-tuned\nGPT-4o and GPT-4o-mini to make decisions in a wide variety of complex contexts\n(e.g., choosing between condos, loans, vacations, etc.) according to\nrandomly-generated, quantitative preferences about how to weigh different\nattributes during decision-making (e.g., the relative importance of natural\nlight versus quiet surroundings for condos). We demonstrate that the LLMs can\naccurately report these preferences (i.e., the weights that they learned to\ngive to different attributes during decision-making). Next, we demonstrate that\nthese LLMs can be fine-tuned to explain their decision-making even more\naccurately. Finally, we demonstrate that this training generalizes: It improves\nthe ability of the models to accurately explain what they are doing as they\nmake other complex decisions, not just decisions they have learned to make via\nfine-tuning. This work is a step towards training LLMs to accurately and\nbroadly report on their own internal processes -- a possibility that would\nyield substantial benefits for interpretability, control, and safety.",
    "pdf_url": "http://arxiv.org/pdf/2505.17120v1",
    "published": "2025-05-21T16:35:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15729v1",
    "title": "Properties of Building Blocks Comprising Strongly Interacting Posts and Their Consideration in Advanced Coaxial Filter Designs",
    "authors": [
      "Smain Amari",
      "Mustafa Bakr",
      "Uwe Rosenberg"
    ],
    "abstract": "Building blocks containing strongly coupled posts offer new possibilities for\nadvanced coaxial (comb-line) filter designs. Equivalent circuits based on the\nindividual resonances of the posts cannot be used to reliably describe the\nbehavior of these structures because of the strong coupling between the posts.\nInstead, sets of electromagnetic (EM) resonances that satisfy the boundary\nconditions are used. The resulting equivalent circuit is either a fully\ntransversal circuit or contains locally transversal sub-circuits depending on\nthe strength of the coupling between the cascaded blocks. The validity of\nsimilarity transformations that result in topologies with unusual strong\ncoupling coefficients is questionable despite the fact that they yield the\ncorrect frequency response. Such coupling matrices obscure the physics of the\nproblem and fail to predict the correct behavior of filtering structures.\nHowever, topologies that match the layout of the posts can be used to optimize\nthe filter in connection with a full-wave solver or measurement. Examples of\ndual-post and triple-post units are used to illustrate the key findings. The\nbasic knowledge of the real functionality of these special resonator\nconfigurations allows their consideration in advanced filter implementations by\nwell-established classic design methods, without limitation by the design\napproach. This is demonstrated by an example of a 2-order in-line filter\nimplementation providing one transmission zero by using the combination of\nsingle and transverse dual-post resonators. This fundamental understanding of\nthe special properties provides the pre-requisite for a variety of novel filter\nsolutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15729v1",
    "published": "2025-05-21T16:34:44+00:00",
    "categories": [
      "physics.class-ph"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15875v1",
    "title": "Decouple and Orthogonalize: A Data-Free Framework for LoRA Merging",
    "authors": [
      "Shenghe Zheng",
      "Hongzhi Wang",
      "Chenyu Huang",
      "Xiaohui Wang",
      "Tao Chen",
      "Jiayuan Fan",
      "Shuyue Hu",
      "Peng Ye"
    ],
    "abstract": "With more open-source models available for diverse tasks, model merging has\ngained attention by combining models into one, reducing training, storage, and\ninference costs. Current research mainly focuses on model merging for full\nfine-tuning, overlooking the popular LoRA. However, our empirical analysis\nreveals that: a) existing merging methods designed for full fine-tuning perform\npoorly on LoRA; b) LoRA modules show much larger parameter magnitude variance\nthan full fine-tuned weights; c) greater parameter magnitude variance\ncorrelates with worse merging performance. Considering that large magnitude\nvariances cause deviations in the distribution of the merged parameters,\nresulting in information loss and performance degradation, we propose a\nDecoupled and Orthogonal merging approach(DO-Merging). By separating parameters\ninto magnitude and direction components and merging them independently, we\nreduce the impact of magnitude differences on the directional alignment of the\nmerged models, thereby preserving task information. Furthermore, we introduce a\ndata-free, layer-wise gradient descent method with orthogonal constraints to\nmitigate interference during the merging of direction components. We provide\ntheoretical guarantees for both the decoupling and orthogonal components. And\nwe validate through extensive experiments across vision, language, and\nmulti-modal domains that our proposed DO-Merging can achieve significantly\nhigher performance than existing merging methods at a minimal cost. Notably,\neach component can be flexibly integrated with existing methods, offering near\nfree-lunch improvements across tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15875v1",
    "published": "2025-05-21T16:34:37+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15728v1",
    "title": "Are machine learning interpretations reliable? A stability study on global interpretations",
    "authors": [
      "Luqin Gan",
      "Tarek M. Zikry",
      "Genevera I. Allen"
    ],
    "abstract": "As machine learning systems are increasingly used in high-stakes domains,\nthere is a growing emphasis placed on making them interpretable to improve\ntrust in these systems. In response, a range of interpretable machine learning\n(IML) methods have been developed to generate human-understandable insights\ninto otherwise black box models. With these methods, a fundamental question\narises: Are these interpretations reliable? Unlike with prediction accuracy or\nother evaluation metrics for supervised models, the proximity to the true\ninterpretation is difficult to define. Instead, we ask a closely related\nquestion that we argue is a prerequisite for reliability: Are these\ninterpretations stable? We define stability as findings that are consistent or\nreliable under small random perturbations to the data or algorithms. In this\nstudy, we conduct the first systematic, large-scale empirical stability study\non popular machine learning global interpretations for both supervised and\nunsupervised tasks on tabular data. Our findings reveal that popular\ninterpretation methods are frequently unstable, notably less stable than the\npredictions themselves, and that there is no association between the accuracy\nof machine learning predictions and the stability of their associated\ninterpretations. Moreover, we show that no single method consistently provides\nthe most stable interpretations across a range of benchmark datasets. Overall,\nthese results suggest that interpretability alone does not warrant trust, and\nunderscores the need for rigorous evaluation of interpretation stability in\nfuture work. To support these principles, we have developed and released an\nopen source IML dashboard and Python package to enable researchers to assess\nthe stability and reliability of their own data-driven interpretations and\ndiscoveries.",
    "pdf_url": "http://arxiv.org/pdf/2505.15728v1",
    "published": "2025-05-21T16:34:11+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15727v2",
    "title": "VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models",
    "authors": [
      "Heyang Liu",
      "Yuhao Wang",
      "Ziyang Cheng",
      "Ronghua Wu",
      "Qunshan Gu",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has accelerated the\ndevelopment of multimodal models capable of speech communications. Unlike text\ninteractions, speech conveys diverse information, including acoustic\nvariations, paralanguage cues, and environmental context. However, existing\nevaluations of speech interaction models lack instances mimicking real\nscenarios and predominantly focus on the quality of their textual responses,\noverlooking critical aspects of vocal performance. To address this gap, we\npropose VocalBench, a comprehensive benchmark to assess the speech\nconversational abilities, comprising 9,400 carefully curated instances across\nfour key dimensions: semantic quality, acoustic performance, conversational\nabilities, and robustness. It covers a broad range of fundamental skills\nessential for effective vocal interactions. For the evaluation scheme, we\npropose several objective evaluation indicators and incorporate an additional\nLLM-as-a-judge approach to score open-ended questions. Experimental results on\n15 mainstream systems reveal significant variability, each exhibiting distinct\nstrengths and weaknesses, and provide valuable insights to guide future\nresearch in speech interaction systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15727v2",
    "published": "2025-05-21T16:34:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15726v2",
    "title": "Fluctuations of Young diagrams for symplectic groups and semiclassical orthogonal polynomials",
    "authors": [
      "Anton Nazarov",
      "Anton Selemenchuk"
    ],
    "abstract": "Consider an $n\\times k$ matrix of i.i.d. Bernoulli random numbers with\n$p=1/2$. Dual RSK algorithm gives a bijection of this matrix to a pair of Young\ntableaux of conjugate shape, which is manifestation of skew Howe $GL_{n}\\times\nGL_{k}$-duality. Thus the probability measure on zero-ones matrix leads to the\nprobability measure on Young diagrams proportional to the ratio of the\ndimension of $GL_{n}\\times GL_{k}$-representation and the dimension of the\nexterior algebra $\\bigwedge\\left(\\mathbb{C}^{n}\\otimes\\mathbb{C}^{k}\\right)$.\n  Similarly, by applying Proctor's algorithm based on Berele's modification of\nthe Schensted insertion, we get skew Howe duality for the pairs of groups\n$Sp_{2n}\\times Sp_{2k}$. In the limit when $n,k\\to\\infty$ $GL$-case is\nrelatively easily studied by use of free-fermionic representation for the\ncorrelation kernel. But for the symplectic groups there is no convenient\nfree-fermionic representation. We use Christoffel transformation to obtain the\nsemiclassical orthogonal polynomials for $Sp_{2n}\\times Sp_{2k}$ from\nKrawtchouk polynomials that describe $GL_{2n}\\times GL_{2k}$ case. We derive an\nintegral representation for semiclassical polynomials. The study of the\nasymptotic of this integral representation gives us the description of the\nlimit shapes and fluctuations of the random Young diagrams for symplectic\ngroups.",
    "pdf_url": "http://arxiv.org/pdf/2505.15726v2",
    "published": "2025-05-21T16:33:12+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP",
      "math.RT",
      "33C45, 60G55, 22E46, 60B10",
      "G.3"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15725v2",
    "title": "UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning",
    "authors": [
      "Xiangyu Wang",
      "Donglin Yang",
      "Yue Liao",
      "Wenhao Zheng",
      "wenjun wu",
      "Bin Dai",
      "Hongsheng Li",
      "Si Liu"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) are evolving into language-interactive\nplatforms, enabling more intuitive forms of human-drone interaction. While\nprior works have primarily focused on high-level planning and long-horizon\nnavigation, we shift attention to language-guided fine-grained trajectory\ncontrol, where UAVs execute short-range, reactive flight behaviors in response\nto language instructions. We formalize this problem as the Flying-on-a-Word\n(Flow) task and introduce UAV imitation learning as an effective approach. In\nthis framework, UAVs learn fine-grained control policies by mimicking expert\npilot trajectories paired with atomic language instructions. To support this\nparadigm, we present UAV-Flow, the first real-world benchmark for\nlanguage-conditioned, fine-grained UAV control. It includes a task formulation,\na large-scale dataset collected in diverse environments, a deployable control\nframework, and a simulation suite for systematic evaluation. Our design enables\nUAVs to closely imitate the precise, expert-level flight trajectories of human\npilots and supports direct deployment without sim-to-real gap. We conduct\nextensive experiments on UAV-Flow, benchmarking VLN and VLA paradigms. Results\nshow that VLA models are superior to VLN baselines and highlight the critical\nrole of spatial grounding in the fine-grained Flow setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.15725v2",
    "published": "2025-05-21T16:31:28+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15724v2",
    "title": "Gravitational Bremsstrahlung in Black-Hole Scattering at $\\mathcal{O}(G^3)$: Quadratic-in-Spin Effects",
    "authors": [
      "Lara Bohnenblust",
      "Harald Ita",
      "Manfred Kraus",
      "Johannes Schlenk"
    ],
    "abstract": "We are employing a supersymmetric variant of the worldline quantum field\ntheory (WQFT) formalism to compute the far-field momentum-space gravitational\nwaveform emitted during the scattering of two spinning black holes at\nnext-to-leading order (NLO) in the post-Minkowskian expansion. Our results are\naccurate up to quadratic-in-spin contributions, which means we report for the\nvery first time the waveform observable at the order\n$\\mathcal{O}(G^3\\mathcal{S}^2)$. Our computation is based on mapping $n$-body\ntree-level amplitudes in such a way that we can obtain the $(n-2)$-loop\ntwo-body waveform integrand. We discuss in detail this procedure and highlight\nthe similarity of the resulting structures with those obtained in the\nscattering-amplitude approach. As a by product of our computational approach,\nwe also obtain, for the first time, the leading-order waveform for three-body\nscattering of spinning black holes. We validated our results in various ways\nbut most notably, we find exact agreement for the NLO waveform integrand\nobtained from the WQFT and the classical limit of scattering amplitudes in QFT.",
    "pdf_url": "http://arxiv.org/pdf/2505.15724v2",
    "published": "2025-05-21T16:31:25+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15723v1",
    "title": "Propulsion of a flexible foil in a wavy flow: resonance, antiresonance, and destructive self-interference",
    "authors": [
      "Abdur Rehman",
      "Daniel Floryan"
    ],
    "abstract": "Swimming and flying animals demonstrate remarkable adaptations to diverse\nflow conditions in their environments. In this study, we aim to advance the\nfundamental understanding of the interaction between flexible bodies and\nheterogeneous flow conditions. We develop a linear inviscid model of an\nelastically mounted foil that passively pitches in response to a prescribed\nheaving motion and an incoming flow that consists of a traveling wave\ndisturbance superposed on a uniform flow. In addition to the well-known\nresonant response, the wavy flow induces an antiresonant response for\nnon-dimensional phase velocities near unity due to the emergence of\nnon-circulatory forces that oppose circulatory forces. We also find that the\nwavy flow destructively interferes with itself, effectively rendering the foil\na low-pass filter. The net result is that the waviness of the flow always\nimproves thrust and efficiency when the wavy flow is of a different frequency\nthan the prescribed heaving motion. Such a simple statement cannot be made when\nthe wavy flow and heaving motion have the same frequency. Depending on the\nwavenumber and relative phase, the two may work in concert or in opposition,\nbut they do open the possibility of simultaneous propulsion and net energy\nextraction from the flow, which is impossible in a uniform flow.",
    "pdf_url": "http://arxiv.org/pdf/2505.15723v1",
    "published": "2025-05-21T16:31:16+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.17119v1",
    "title": "Systematic Evaluation of Machine-Generated Reasoning and PHQ-9 Labeling for Depression Detection Using Large Language Models",
    "authors": [
      "Zongru Shao",
      "Xin Wang",
      "Zhanyang Liu",
      "Chenhan Wang",
      "K. P. Subbalakshmi"
    ],
    "abstract": "Recent research leverages large language models (LLMs) for early mental\nhealth detection, such as depression, often optimized with machine-generated\ndata. However, their detection may be subject to unknown weaknesses. Meanwhile,\nquality control has not been applied to these generated corpora besides limited\nhuman verifications. Our goal is to systematically evaluate LLM reasoning and\nreveal potential weaknesses. To this end, we first provide a systematic\nevaluation of the reasoning over machine-generated detection and\ninterpretation. Then we use the models' reasoning abilities to explore\nmitigation strategies for enhanced performance. Specifically, we do the\nfollowing: A. Design an LLM instruction strategy that allows for systematic\nanalysis of the detection by breaking down the task into several subtasks. B.\nDesign contrastive few-shot and chain-of-thought prompts by selecting typical\npositive and negative examples of detection reasoning. C. Perform human\nannotation for the subtasks identified in the first step and evaluate the\nperformance. D. Identify human-preferred detection with desired logical\nreasoning from the few-shot generation and use them to explore different\noptimization strategies. We conducted extensive comparisons on the DepTweet\ndataset across the following subtasks: 1. identifying whether the speaker is\ndescribing their own depression; 2. accurately detecting the presence of PHQ-9\nsymptoms, and 3. finally, detecting depression. Human verification of\nstatistical outliers shows that LLMs demonstrate greater accuracy in analyzing\nand detecting explicit language of depression as opposed to implicit\nexpressions of depression. Two optimization methods are used for performance\nenhancement and reduction of the statistic bias: supervised fine-tuning (SFT)\nand direct preference optimization (DPO). Notably, the DPO approach achieves\nsignificant performance improvement.",
    "pdf_url": "http://arxiv.org/pdf/2505.17119v1",
    "published": "2025-05-21T16:30:50+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15722v1",
    "title": "Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities",
    "authors": [
      "Xiaoyu Luo",
      "Yiyi Chen",
      "Johannes Bjerva",
      "Qiongxiu Li"
    ],
    "abstract": "We present the first comprehensive study of Memorization in Multilingual\nLarge Language Models (MLLMs), analyzing 95 languages using models across\ndiverse model scales, architectures, and memorization definitions. As MLLMs are\nincreasingly deployed, understanding their memorization behavior has become\ncritical. Yet prior work has focused primarily on monolingual models, leaving\nmultilingual memorization underexplored, despite the inherently long-tailed\nnature of training corpora. We find that the prevailing assumption, that\nmemorization is highly correlated with training data availability, fails to\nfully explain memorization patterns in MLLMs. We hypothesize that treating\nlanguages in isolation - ignoring their similarities - obscures the true\npatterns of memorization. To address this, we propose a novel graph-based\ncorrelation metric that incorporates language similarity to analyze\ncross-lingual memorization. Our analysis reveals that among similar languages,\nthose with fewer training tokens tend to exhibit higher memorization, a trend\nthat only emerges when cross-lingual relationships are explicitly modeled.\nThese findings underscore the importance of a language-aware perspective in\nevaluating and mitigating memorization vulnerabilities in MLLMs. This also\nconstitutes empirical evidence that language similarity both explains\nMemorization in MLLMs and underpins Cross-lingual Transferability, with broad\nimplications for multilingual NLP.",
    "pdf_url": "http://arxiv.org/pdf/2505.15722v1",
    "published": "2025-05-21T16:30:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15721v1",
    "title": "Privacy-Preserving Conformal Prediction Under Local Differential Privacy",
    "authors": [
      "Coby Penso",
      "Bar Mahpud",
      "Jacob Goldberger",
      "Or Sheffet"
    ],
    "abstract": "Conformal prediction (CP) provides sets of candidate classes with a\nguaranteed probability of containing the true class. However, it typically\nrelies on a calibration set with clean labels. We address privacy-sensitive\nscenarios where the aggregator is untrusted and can only access a perturbed\nversion of the true labels. We propose two complementary approaches under local\ndifferential privacy (LDP). In the first approach, users do not access the\nmodel but instead provide their input features and a perturbed label using a\nk-ary randomized response. In the second approach, which enforces stricter\nprivacy constraints, users add noise to their conformity score by binary search\nresponse. This method requires access to the classification model but preserves\nboth data and label privacy. Both approaches compute the conformal threshold\ndirectly from noisy data without accessing the true labels. We prove\nfinite-sample coverage guarantees and demonstrate robust coverage even under\nsevere randomization. This approach unifies strong local privacy with\npredictive uncertainty control, making it well-suited for sensitive\napplications such as medical imaging or large language model queries,\nregardless of whether users can (or are willing to) compute their own scores.",
    "pdf_url": "http://arxiv.org/pdf/2505.15721v1",
    "published": "2025-05-21T16:29:44+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17118v1",
    "title": "After Retrieval, Before Generation: Enhancing the Trustworthiness of Large Language Models in RAG",
    "authors": [
      "Xinbang Dai",
      "Huikang Hu",
      "Yuncheng Hua",
      "Jiaqi Li",
      "Yongrui Chen",
      "Rihui Jin",
      "Nan Hu",
      "Guilin Qi"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems face critical challenges in\nbalancing internal (parametric) and external (retrieved) knowledge, especially\nwhen these sources conflict or are unreliable. To analyze these scenarios\ncomprehensively, we construct the Trustworthiness Response Dataset (TRD) with\n36,266 questions spanning four RAG settings. We reveal that existing approaches\naddress isolated scenarios-prioritizing one knowledge source, naively merging\nboth, or refusing answers-but lack a unified framework to handle different\nreal-world conditions simultaneously. Therefore, we propose the BRIDGE\nframework, which dynamically determines a comprehensive response strategy of\nlarge language models (LLMs). BRIDGE leverages an adaptive weighting mechanism\nnamed soft bias to guide knowledge collection, followed by a Maximum Soft-bias\nDecision Tree to evaluate knowledge and select optimal response strategies\n(trust internal/external knowledge, or refuse). Experiments show BRIDGE\noutperforms baselines by 5-15% in accuracy while maintaining balanced\nperformance across all scenarios. Our work provides an effective solution for\nLLMs' trustworthy responses in real-world RAG applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.17118v1",
    "published": "2025-05-21T16:29:19+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15720v1",
    "title": "Linearized Polynomial Chinese remainder codes",
    "authors": [
      "Philippe Gaborit",
      "Camille Garnier",
      "Olivier Ruatta"
    ],
    "abstract": "In this paper, we introduce a new family of codes relevent for rank and\nsum-rank metrics. These codes are based on an effective Chinese remainders\ntheorem for linearized polynomials over finite fields. We propose a decoding\nalgorithm for some instances of these codes.",
    "pdf_url": "http://arxiv.org/pdf/2505.15720v1",
    "published": "2025-05-21T16:29:11+00:00",
    "categories": [
      "math.RA",
      "cs.IT",
      "cs.SC",
      "math.IT",
      "94B05, 94B35, 94B70, 11T71, 11T55",
      "G.2; H.1.1; E.4"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15719v1",
    "title": "Linear scaling relation between two-dimensional massless Dirac fermion Fermi velocity and Fe-As bond length in iron arsenide superconductor systems",
    "authors": [
      "Chengpu Lv",
      "Jianzhou Zhao",
      "Yueshan Xu",
      "Yu Song",
      "Chenglin Zhang",
      "Mykhaylo Ozerov",
      "Pengcheng Dai",
      "Nan-Lin Wang",
      "Zhi-Guo Chen"
    ],
    "abstract": "Two-dimensional (2D) massless Dirac fermions (MDF), which represent a type of\nquasi-particles with linear energy-momentum dispersions only in 2D momentum\nspace, provide a fertile ground for realizing novel quantum phenomena. However,\n2D MDF were seldom observed in the superconducting bulk states of 3D materials.\nFurthermore, as a cornerstone for accurately tuning the quantum phenomena based\non 2D MDF, a quantitative relationship between 2D MDF and a structural\nparameter has rarely been revealed so far. Here, we report magneto-infrared\nspectroscopy studies of the iron-arsenide-superconductor systems NaFeAs and\n$A\\mathrm{Fe_2As_2} (A = \\mathrm{Ca, Ba})$ at temperature $T \\sim 4.2 $ K and\nat magnetic fields ($B$) up to 17.5 T. Our results demonstrate the existence of\n2D MDF in the superconducting bulk state of NaFeAs. Moreover, the 2D-MDF Fermi\nvelocities in NaFeAs and $A\\mathrm{Fe_2As_2} (A = \\mathrm{Ca, Ba})$, which are\nextracted from the slopes of the linear $\\sqrt{B}$ dependences of the\nLandau-level transition energies, scale linearly with the Fe-As bond lengths.\nThe linear scaling between the 2D-MDF Fermi velocities and the Fe-As bond\nlengths is supported by (i) the linear relationship between the square root of\nthe effective mass of the $d_{xy}$ electrons and the Fe-As bond length and (ii)\nthe linear dependence of the square root of the calculated tight-binding\nhopping energy on the Fe-As bond length. Our results open up new avenues for\nexploring and tuning novel quantum phenomena based on 2D MDF in the\nsuperconducting bulk states of 3D materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.15719v1",
    "published": "2025-05-21T16:29:02+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.17117v4",
    "title": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning",
    "authors": [
      "Chen Shani",
      "Liron Soffer",
      "Dan Jurafsky",
      "Yann LeCun",
      "Ravid Shwartz-Ziv"
    ],
    "abstract": "Humans organize knowledge into compact categories through semantic\ncompression by mapping diverse instances to abstract representations while\npreserving meaning (e.g., robin and blue jay are both birds; most birds can\nfly). These concepts reflect a trade-off between expressive fidelity and\nrepresentational simplicity. Large Language Models (LLMs) demonstrate\nremarkable linguistic abilities, yet whether their internal representations\nstrike a human-like trade-off between compression and semantic fidelity is\nunclear. We introduce a novel information-theoretic framework, drawing from\nRate-Distortion Theory and the Information Bottleneck principle, to\nquantitatively compare these strategies. Analyzing token embeddings from a\ndiverse suite of LLMs against seminal human categorization benchmarks, we\nuncover key divergences. While LLMs form broad conceptual categories that align\nwith human judgment, they struggle to capture the fine-grained semantic\ndistinctions crucial for human understanding. More fundamentally, LLMs\ndemonstrate a strong bias towards aggressive statistical compression, whereas\nhuman conceptual systems appear to prioritize adaptive nuance and contextual\nrichness, even if this results in lower compressional efficiency by our\nmeasures. These findings illuminate critical differences between current AI and\nhuman cognitive architectures, guiding pathways toward LLMs with more\nhuman-aligned conceptual representations.",
    "pdf_url": "http://arxiv.org/pdf/2505.17117v4",
    "published": "2025-05-21T16:29:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17116v1",
    "title": "Comparative Evaluation of Prompting and Fine-Tuning for Applying Large Language Models to Grid-Structured Geospatial Data",
    "authors": [
      "Akash Dhruv",
      "Yangxinyu Xie",
      "Jordan Branham",
      "Tanwi Mallick"
    ],
    "abstract": "This paper presents a comparative study of large language models (LLMs) in\ninterpreting grid-structured geospatial data. We evaluate the performance of a\nbase model through structured prompting and contrast it with a fine-tuned\nvariant trained on a dataset of user-assistant interactions. Our results\nhighlight the strengths and limitations of zero-shot prompting and demonstrate\nthe benefits of fine-tuning for structured geospatial and temporal reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.17116v1",
    "published": "2025-05-21T16:27:51+00:00",
    "categories": [
      "cs.CL",
      "cs.ET"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.18205v2",
    "title": "Source identification via pathwise gradient estimation",
    "authors": [
      "Richard B. Lehoucq",
      "Scott A. McKinley",
      "Petr Plech√°ƒç"
    ],
    "abstract": "In the context of PDE-constrained optimization theory, source identification\nproblems traditionally entail particles emerging from an unknown source\ndistribution inside a domain, moving according to a prescribed stochastic\nprocess, e.g.~Brownian motion, and then exiting through the boundary of a\ncompact domain. Given information about the flux of particles through the\nboundary of the domain, the challenge is to infer as much as possible about the\nsource.\n  In the PDE setting, it is usually assumed that the flux can be observed\nwithout error and at all points on the boundary. Here we consider a different,\nmore statistical presentation of the problem, in which the data has the form of\ndiscrete counts of particles arriving at a set of disjoint detectors whose\nunion is a strict subset of the boundary. In keeping with the primacy of the\nstochastic processes in the generation of the model, we present a stochastic\ngradient descent algorithm in which exit rates and parameter sensitivities are\ncomputed by simulations of particle paths. We present examples for both It\\^o\ndiffusion and piecewise-deterministic Markov processes, noting that the form of\nthe sensitivities depends only on the parameterization of the source\ndistribution and is universal among a large class of Markov processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.18205v2",
    "published": "2025-05-21T16:27:09+00:00",
    "categories": [
      "math.OC",
      "math.PR",
      "62M99"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15718v1",
    "title": "Safe Control for Pursuit-Evasion with Density Functions",
    "authors": [
      "Mustafa Bozdag",
      "Arya Honarpisheh",
      "Mario Sznaier"
    ],
    "abstract": "This letter presents a density function based safe control synthesis\nframework for the pursuit-evasion problem. We extend safety analysis to dynamic\nunsafe sets by formulating a reach-avoid type pursuit-evasion differential game\nas a robust safe control problem. Using density functions and semi-algebraic\nset definitions, we derive sufficient conditions for weak eventuality and\nevasion, reformulating the problem into a convex sum-of-squares program\nsolvable via standard semidefinite programming solvers. This approach avoids\nthe computational complexity of solving the Hamilton-Jacobi-Isaacs partial\ndifferential equation, offering a scalable and efficient framework. Numerical\nsimulations demonstrate the efficacy of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.15718v1",
    "published": "2025-05-21T16:25:52+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15717v1",
    "title": "On the fixed locus of the antisymplectic involution of an EPW cube",
    "authors": [
      "Francesca Rizzo"
    ],
    "abstract": "EPW cubes are polarized hyper-K\\\"ahler varieties of K$3^{[3]}$-type that\ncarry an anti-symplectic involution. We study the geometry of the fixed locus\n$\\sW_A$ of this involution and prove that it is a \\emph{rigid} atomic\nLagrangian submanifold. Our proof is based on a detailed description of certain\nsingular degenerations of EPW cubes and the degeneration methods of\nFlappan--Macr\\`i--O'Grady--Sacc\\`a.",
    "pdf_url": "http://arxiv.org/pdf/2505.15717v1",
    "published": "2025-05-21T16:25:22+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15716v1",
    "title": "Detector Based Evaluation of Extractable Entanglement in Flat spacetime",
    "authors": [
      "Hiromasa Tajima",
      "Riku Yoshimoto",
      "Ryo Nemoto",
      "Yuki Osawa"
    ],
    "abstract": "Entanglement entropy (EE) is widely used to quantify quantum correlations in\nfield theory, with the well-known result in two-dimensional conformal field\ntheory (CFT) predicting a logarithmic divergence with the ultraviolet (UV)\ncutoff. However, this expression lacks operational meaning: it remains unclear\nhow much of the entanglement is physically extractable via local measurements.\nIn this work, we investigate the operationally accessible entanglement by\nemploying a pair of Unruh-DeWitt detectors, each interacting with complementary\nregions of a quantum field. We derive an upper bound on the entanglement that\ncan be harvested by such detectors and show that it scales as a double\nlogarithm with respect to the UV cutoff-significantly weaker than the\nsingle-logarithmic divergence of the standard CFT result. This work provides an\noperational perspective on field-theoretic entanglement and sets fundamental\nlimits on its extractability.",
    "pdf_url": "http://arxiv.org/pdf/2505.15716v1",
    "published": "2025-05-21T16:25:14+00:00",
    "categories": [
      "hep-th",
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15715v1",
    "title": "Beyond Empathy: Integrating Diagnostic and Therapeutic Reasoning with Large Language Models for Mental Health Counseling",
    "authors": [
      "He Hu",
      "Yucheng Zhou",
      "Juzheng Si",
      "Qianning Wang",
      "Hengheng Zhang",
      "Fuji Ren",
      "Fei Ma",
      "Laizhong Cui"
    ],
    "abstract": "Large language models (LLMs) hold significant potential for mental health\nsupport, capable of generating empathetic responses and simulating therapeutic\nconversations. However, existing LLM-based approaches often lack the clinical\ngrounding necessary for real-world psychological counseling, particularly in\nexplicit diagnostic reasoning aligned with standards like the DSM/ICD and\nincorporating diverse therapeutic modalities beyond basic empathy or single\nstrategies. To address these critical limitations, we propose PsyLLM, the first\nlarge language model designed to systematically integrate both diagnostic and\ntherapeutic reasoning for mental health counseling. To develop the PsyLLM, we\npropose a novel automated data synthesis pipeline. This pipeline processes\nreal-world mental health posts, generates multi-turn dialogue structures, and\nleverages LLMs guided by international diagnostic standards (e.g., DSM/ICD) and\nmultiple therapeutic frameworks (e.g., CBT, ACT, psychodynamic) to simulate\ndetailed clinical reasoning processes. Rigorous multi-dimensional filtering\nensures the generation of high-quality, clinically aligned dialogue data. In\naddition, we introduce a new benchmark and evaluation protocol, assessing\ncounseling quality across four key dimensions: comprehensiveness,\nprofessionalism, authenticity, and safety. Our experiments demonstrate that\nPsyLLM significantly outperforms state-of-the-art baseline models on this\nbenchmark.",
    "pdf_url": "http://arxiv.org/pdf/2505.15715v1",
    "published": "2025-05-21T16:24:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15714v1",
    "title": "Splay Stiffening and Twist Softening in a Ferroelectric Nematic Liquid Crystal",
    "authors": [
      "Evangelia E. Zavvou",
      "Alexander Jarosik",
      "Hajnalka N√°dasi",
      "Christoforos A. Krontiras",
      "Panagiota K. Karahaliou",
      "Rachel Tuffin",
      "Melanie Klasen-Memmer",
      "Alexey Eremin"
    ],
    "abstract": "The recent discovery of ferroelectric nematics-genuine 3D ferroelectric\nfluids-has underscored the importance of electrostatic interactions in shaping\nthe physical behaviour of soft matter systems. In this paper, we investigate\nthe mechanical properties of ferroelectric nematics by directly comparing the\nsplay and twist elastic constants in a liquid crystal system that exhibits both\nnonpolar and ferroelectric nematic phases. Our results reveal that polar\nordering results in increased splay rigidity and a concomitant reduction in\ntwist elasticity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15714v1",
    "published": "2025-05-21T16:24:22+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.15713v1",
    "title": "Electro-Fenton treatment of benzophenone-4 solutions: A sustainable approach for its removal using an air-diffusion cathode",
    "authors": [
      "Caio Machado Fernandes",
      "Enric Brillas",
      "Mauro C. Santos",
      "Sergi Garcia-Segura"
    ],
    "abstract": "This work reports the efficient degradation and mineralization of\nbenzophenone-4 (BP-4), a widely used UV filter associated with\nendocrine-disrupting effects, via the electro-Fenton process. Key operating\nparameters including pH, current density, Fe2+ dosage, and initial pollutant\nconcentration were optimized. At pH = 3.0, the best performance was obtained.\nUnder optimum conditions of 20 mA cm-2 and 0.75 mM Fe2+, complete BP-4\ndegradation was achieved in remarkably short times: 2 min for 1-2.5 mg L-1, 3\nmin for 5 mg L-1, 4 min for 10 mg L-1, 5 min for 20 mg L-1, and 7 min for 40 mg\nL-1. Total mineralization was reached for low concentration of 1 mg L-1,\nvarying between 77 and 90% for higher loads up to 40 mg L-1. The reaction\nfollowed pseudo-first-order kinetics, with high apparent rate constant of 0.641\nmin-1 for 40 mg L-1 and lower energy consumption of 0.261 kWh (g TOC)-1.\nRadical quenching experiments with TBA confirmed that physisorbed BDD(.OH) and\nhomogeneous .OH were the predominant oxidants. Persistent carboxylic acid\nby-products, in the form of Fe3+ complexes, were the only residues after 180\nmin of treatment, readily being biodegradable. The process demonstrates high\nefficiency across a broad range of BP-4 concentrations, offering a viable\nsolution for its removal from contaminated waters.",
    "pdf_url": "http://arxiv.org/pdf/2505.15713v1",
    "published": "2025-05-21T16:23:45+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15712v1",
    "title": "TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games",
    "authors": [
      "Yuan Yuan",
      "Muyu He",
      "Muhammad Adil Shahid",
      "Jiani Huang",
      "Ziyang Li",
      "Li Zhang"
    ],
    "abstract": "This paper introduces TurnaboutLLM, a novel framework and dataset for\nevaluating the deductive reasoning abilities of Large Language Models (LLMs) by\nleveraging the interactive gameplay of detective games Ace Attorney and\nDanganronpa. The framework tasks LLMs with identifying contradictions between\ntestimonies and evidences within long narrative contexts, a challenging task\ndue to the large answer space and diverse reasoning types presented by its\nquestions. We evaluate twelve state-of-the-art LLMs on the dataset, hinting at\nlimitations of popular strategies for enhancing deductive reasoning such as\nextensive thinking and Chain-of-Thought prompting. The results also suggest\nvarying effects of context size, the number of reasoning step and answer space\nsize on model performance. Overall, TurnaboutLLM presents a substantial\nchallenge for LLMs' deductive reasoning abilities in complex, narrative-rich\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15712v1",
    "published": "2025-05-21T16:22:32+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15711v1",
    "title": "Dissipative phase transition of interacting non-reciprocal fermions",
    "authors": [
      "Rafael D. Soares",
      "Matteo Brunelli",
      "Marco Schir√≤"
    ],
    "abstract": "We study an interacting fermionic chain in the presence of non-reciprocal\ngain and loss processes obtained via reservoir engineering. The interplay\nbetween unitary evolution and the two dissipative processes leads to distinct\nnon-reciprocal signatures in the transient dynamics and the steady state. These\ninclude a transition from exponential to power-law relaxation towards a\nfinite-density steady-state, a nonzero particle current from breaking inversion\nsymmetry, and dynamics under open boundary conditions showing directionality\nand charge accumulation. Weak interactions preserve the main signatures of\nnon-reciprocity, enriching the interacting many-body non-reciprocal phase with\nvolume law entanglement of quantum trajectories. Upon increasing the\ninteraction above a critical value, we find a dissipative phase transition\nwhere reciprocity is dynamically restored.",
    "pdf_url": "http://arxiv.org/pdf/2505.15711v1",
    "published": "2025-05-21T16:21:51+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15710v1",
    "title": "Advancing LLM Safe Alignment with Safety Representation Ranking",
    "authors": [
      "Tianqi Du",
      "Zeming Wei",
      "Quan Chen",
      "Chenheng Zhang",
      "Yisen Wang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has demonstrated\nmilestone success in a variety of tasks, yet their potential for generating\nharmful content has raised significant safety concerns. Existing safety\nevaluation approaches typically operate directly on textual responses,\noverlooking the rich information embedded in the model's internal\nrepresentations. In this paper, we propose Safety Representation Ranking (SRR),\na listwise ranking framework that selects safe responses using hidden states\nfrom the LLM itself. SRR encodes both instructions and candidate completions\nusing intermediate transformer representations and ranks candidates via a\nlightweight similarity-based scorer. Our approach directly leverages internal\nmodel states and supervision at the list level to capture subtle safety\nsignals. Experiments across multiple benchmarks show that SRR significantly\nimproves robustness to adversarial prompts. Our code will be available upon\npublication.",
    "pdf_url": "http://arxiv.org/pdf/2505.15710v1",
    "published": "2025-05-21T16:21:29+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15709v2",
    "title": "Composing $Œ±$-Gauss and logistic maps: Gradual and sudden transitions to chaos",
    "authors": [
      "Marcelo A. Pires",
      "Constantino Tsallis",
      "Evaldo M. F. Curado"
    ],
    "abstract": "We introduce the $\\alpha$-Gauss-Logistic map, a new nonlinear dynamics\nconstructed by composing the logistic and $\\alpha$-Gauss maps. Explicitly, our\nmodel is given by $x_{t+1} = f_L(x_t)x_t^{-\\alpha} - \\lfloor\nf_L(x_t)x_t^{-\\alpha} \\rfloor $ where $f_L(x_t) = r x_t (1-x_t)$ is the\nlogistic map and $ \\lfloor \\ldots \\rfloor $ is the integer part function. Our\ninvestigation reveals a rich phenomenology depending solely on two parameters,\n$r$ and $\\alpha$. For $\\alpha < 1$, the system exhibits multiple\nperiod-doubling cascades to chaos as the parameter $r$ is increased,\ninterspersed with stability windows within the chaotic attractor. In contrast,\nfor $1 \\leq \\alpha < 2$, the onset of chaos is abrupt, occurring without any\nprior bifurcations, and the resulting chaotic attractors emerge without\nstability windows. For $\\alpha \\geq 2$, the regular behavior is absent. The\nspecial case of $\\alpha = 1$ allows an analytical treatment, yielding a\nclosed-form formula for the Lyapunov exponent and conditions for an exact\nuniform invariant density, using the Perron-Frobenius equation. Chaotic regimes\nfor $\\alpha = 1$ can exhibit gaps or be gapless. Surprisingly, the golden ratio\n$\\Phi$ marks the threshold for the disappearance of the largest gap in the\nregime diagram. Additionally, at the edge of chaos in the abrupt transition\nregime, the invariant density approaches a $q$-Gaussian with $q=2$, which\ncorresponds to a Cauchy distribution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15709v2",
    "published": "2025-05-21T16:20:33+00:00",
    "categories": [
      "nlin.CD",
      "math-ph",
      "math.MP",
      "physics.comp-ph",
      "physics.soc-ph",
      "q-bio.PE"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15708v1",
    "title": "In Silico Trials for Sex-Specific patient Inclusion Criteria in Cardiac Resynchronization Therapy: Advancing Precision in Heart Failure Treatment",
    "authors": [
      "Shuang Qian",
      "Devran Ugurlu",
      "Elliot Fairweather",
      "Richard E Jones",
      "Hassan Zaidi",
      "Sanjay Prasad",
      "Brian P Halliday",
      "Daniel J Hammersley",
      "Gernot Plank",
      "Edward Vigmond",
      "Christopher A Rinaldi",
      "Alistair Young",
      "Pablo Lamata",
      "Martin Bishop",
      "Steven Niederer"
    ],
    "abstract": "Cardiac resynchronization therapy (CRT) guidelines are based on clinical\ntrials with limited female representation and inconsistent left bundle branch\nblock (LBBB) definitions. Conventional QRS duration (QRSd) criteria show\nvariable diagnostic accuracy between sexes, partly due to differences in heart\nsize and remodeling. We evaluated the influence of sex, heart size, LBBB, and\nconduction delay on QRSd and assessed the diagnostic performance of\nconventional and indexed QRSd criteria using a population-based modelling\napproach. Simulated QRSd were derived from electrophysiological simulations\nconducted in 2627 UK Biobank healthy participants and 359 patients with\nischemic heart disease, by modelling LBBB and normal activation combined\nwith/without conduction delay. QRSd criteria under-selected LBBB females and\nover-selected non-LBBB patients. Indexing by LVEDV and LV mass reduced sex\ndisparities but increased the over-selection in non-LBBB patients.\nHeight-indexed QRSd effectively resolved sex differences and maintained low\nnon-LBBB selection rates, demonstrating superior performance and potential for\nmore equitable CRT selection.",
    "pdf_url": "http://arxiv.org/pdf/2505.15708v1",
    "published": "2025-05-21T16:19:56+00:00",
    "categories": [
      "physics.med-ph",
      "q-bio.PE"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15707v2",
    "title": "When are syzygies of the residue field self-dual?",
    "authors": [
      "Souvik Dey"
    ],
    "abstract": "Finitely generated reflexive modules over commutative Noetherian rings form a\nkey component of Auslander and Bridger's stable module theory and are likewise\nessential in the study of Cohen--Macaulay representations. Recently, H. Dao\ncharacterized Arf local rings as exactly those one-dimensional Cohen--Macaulay\nlocal rings over which every finitely generated reflexive module is self-dual,\nand raised the general question of characterizing rings over which every\nfinitely generated reflexive module is self-dual. Motivated by this, in this\narticle, we study the question of self-duality of syzygies of the residue field\nof a local ring when they are known to be reflexive. We show that for local\nrings of depth at least 2, the answer is given by hypersurface or regular local\nrings in most cases.",
    "pdf_url": "http://arxiv.org/pdf/2505.15707v2",
    "published": "2025-05-21T16:19:54+00:00",
    "categories": [
      "math.AC",
      "13D02, 13H10"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15706v1",
    "title": "Extensions of categoricity relative to a degree",
    "authors": [
      "Java Darleen Villano"
    ],
    "abstract": "In this paper, we apply the machinery developed in arXiv:2401.06641(2) to\nstudy the behavior of computable categoricity relativized to non-c.e. degrees.\nIn particular, we show that we can build a computable structure which is not\ncomputably categorical but is computably categorical relative to a $1$-generic\ndegree. Additionally, we show that other classes of structures besides directed\ngraphs admit a computable example which can change its computable categorical\nbehavior relative to different degrees.",
    "pdf_url": "http://arxiv.org/pdf/2505.15706v1",
    "published": "2025-05-21T16:19:50+00:00",
    "categories": [
      "math.LO",
      "03C57, 03D25"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15705v1",
    "title": "Quantum Dots as Functional Nanosystems for Enhanced Biomedical Applications",
    "authors": [
      "Pronama Biswas",
      "Asmita Saha",
      "Bhoomika Sridhar",
      "Anwesha Patel",
      "Belaguppa Manjunath Ashwin Desai"
    ],
    "abstract": "Quantum dots (QDs) have emerged as promising nanomaterials with unique\noptical and physical properties, making them highly attractive for various\napplications in biomedicine. This review provides a comprehensive overview of\nthe types, modes of synthesis, characterization, applications, and recent\nadvances of QDs in the field of biomedicine, with a primary focus on\nbioimaging, drug delivery, and biosensors. The unique properties of QDs, such\nas tunable emission spectra, long-term photostability, high quantum yield, and\ntargeted drug delivery, hold tremendous promise for advancing diagnostics,\ntherapeutics, and imaging techniques in biomedical research. However, several\nsignificant hurdles remain before their full potential in the biomedical field,\nlike bioaccumulation, toxicity, and short-term stability. Addressing these\nhurdles is essential to effectively incorporate QDs into clinical use and\nenhance their influence on healthcare outcomes. Furthermore, the review\nconducts a critical analysis of potential QD toxicity and explores recent\nprogress in strategies and methods to mitigate these adverse effects, such as\nsurface modification, surface coatings, and encapsulation. By thoroughly\nexamining current research and recent advancements, this comprehensive review\noffers invaluable insights into both the future possibilities and the\nchallenges that lie ahead in fully harnessing the potential of QDs in the field\nof biomedicine, promising a revolution in the landscape of medical diagnostics,\ntherapies, and imaging technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.15705v1",
    "published": "2025-05-21T16:18:39+00:00",
    "categories": [
      "physics.bio-ph",
      "physics.med-ph",
      "q-bio.BM",
      "J.3"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15704v3",
    "title": "Hidden-Strangeness Tetraquarks in the Dynamical Diquark Model",
    "authors": [
      "Shahriyar Jafarzade",
      "Richard F. Lebed"
    ],
    "abstract": "The dynamical diquark model describes multiquark exotic hadrons in terms of\ndiquark components nucleated by heavy quarks, and successfully explains\nmultiple features of hidden-charm and -bottom exotics. Here we apply the model\nto the marginally heavy case of hidden-strange states to probe whether mesons\nnear 2 GeV with peculiar properties, such as $\\phi(2170)$, $f_2(2340)$, and\nX(2370), are possible tetraquark candidates. We calculate spin-multiplet\naverage masses using potentials obtained through lattice simulations and quark\nmodels, and we also describe the detailed spectra of the expected multiplets as\na diagnostic to discern the nature of future hadrons likely to be discovered in\nthis mass region by experiments at facilities such as BESIII, JLab, and the\nEIC.",
    "pdf_url": "http://arxiv.org/pdf/2505.15704v3",
    "published": "2025-05-21T16:17:43+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15703v1",
    "title": "HAMF: A Hybrid Attention-Mamba Framework for Joint Scene Context Understanding and Future Motion Representation Learning",
    "authors": [
      "Xiaodong Mei",
      "Sheng Wang",
      "Jie Cheng",
      "Yingbing Chen",
      "Dan Xu"
    ],
    "abstract": "Motion forecasting represents a critical challenge in autonomous driving\nsystems, requiring accurate prediction of surrounding agents' future\ntrajectories. While existing approaches predict future motion states with the\nextracted scene context feature from historical agent trajectories and road\nlayouts, they suffer from the information degradation during the scene feature\nencoding. To address the limitation, we propose HAMF, a novel motion\nforecasting framework that learns future motion representations with the scene\ncontext encoding jointly, to coherently combine the scene understanding and\nfuture motion state prediction. We first embed the observed agent states and\nmap information into 1D token sequences, together with the target multi-modal\nfuture motion features as a set of learnable tokens. Then we design a unified\nAttention-based encoder, which synergistically combines self-attention and\ncross-attention mechanisms to model the scene context information and aggregate\nfuture motion features jointly. Complementing the encoder, we implement the\nMamba module in the decoding stage to further preserve the consistency and\ncorrelations among the learned future motion representations, to generate the\naccurate and diverse final trajectories. Extensive experiments on Argoverse 2\nbenchmark demonstrate that our hybrid Attention-Mamba model achieves\nstate-of-the-art motion forecasting performance with the simple and lightweight\narchitecture.",
    "pdf_url": "http://arxiv.org/pdf/2505.15703v1",
    "published": "2025-05-21T16:16:52+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15702v1",
    "title": "LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing",
    "authors": [
      "Peng Wang",
      "Biyu Zhou",
      "Xuehai Tang",
      "Jizhong Han",
      "Songlin Hu"
    ],
    "abstract": "Large Language Models often contain factually incorrect or outdated\nknowledge, giving rise to model editing methods for precise knowledge updates.\nHowever, current mainstream locate-then-edit approaches exhibit a progressive\nperformance decline during sequential editing, due to inadequate mechanisms for\nlong-term knowledge preservation. To tackle this, we model the sequential\nediting as a constrained stochastic programming. Given the challenges posed by\nthe cumulative preservation error constraint and the gradually revealed editing\ntasks, \\textbf{LyapLock} is proposed. It integrates queuing theory and Lyapunov\noptimization to decompose the long-term constrained programming into tractable\nstepwise subproblems for efficient solving. This is the first model editing\nframework with rigorous theoretical guarantees, achieving asymptotic optimal\nediting performance while meeting the constraints of long-term knowledge\npreservation. Experimental results show that our framework scales sequential\nediting capacity to over 10,000 edits while stabilizing general capabilities\nand boosting average editing efficacy by 11.89\\% over SOTA baselines.\nFurthermore, it can be leveraged to enhance the performance of baseline\nmethods. Our code is released on https://github.com/caskcsg/LyapLock.",
    "pdf_url": "http://arxiv.org/pdf/2505.15702v1",
    "published": "2025-05-21T16:16:33+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.06303v1",
    "title": "Reward Is Enough: LLMs Are In-Context Reinforcement Learners",
    "authors": [
      "Kefan Song",
      "Amir Moeini",
      "Peng Wang",
      "Lei Gong",
      "Rohan Chandra",
      "Yanjun Qi",
      "Shangtong Zhang"
    ],
    "abstract": "Reinforcement learning (RL) is a human-designed framework for solving\nsequential decision making problems. In this work, we demonstrate that,\nsurprisingly, RL emerges in LLM's (Large Language Model) inference time -- a\nphenomenon known as in-context RL (ICRL). Specifically, we propose a novel\nmulti-round prompting framework called ICRL prompting. The goal is to prompt\nthe LLM to complete a task. After the LLM generates a response at the current\nround, we give numerical scalar feedbacks for the response, called the rewards.\nAt the next round, we prompt the LLM again with the same task and a context\nconsisting of all previous responses and rewards. We observe that the quality\nof the LLM's response increases as the context grows. In other words, the LLM\nis able to maximize the scalar reward signal in the inference time, just like\nan RL algorithm. We evaluate ICRL prompting in three benchmarks (Game of 24,\ncreative writing, and ScienceWorld) and demonstrate significant performance\nimprovements over baseline methods such as Self-Refine and Reflexion.\nSurprisingly, in some experiments the reward signals are generated by the LLM\nitself, yet performance improvements are still observed from ICRL prompting,\noffering a promising paradigm for scaling test-time compute.",
    "pdf_url": "http://arxiv.org/pdf/2506.06303v1",
    "published": "2025-05-21T16:15:01+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15701v1",
    "title": "HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases",
    "authors": [
      "Pingqing Zheng",
      "Jiayin Qin",
      "Fuqi Zhang",
      "Shang Wu",
      "Yu Cao",
      "Caiwen Ding",
      "Yang",
      "Zhao"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated their potential in hardware\ndesign tasks, such as Hardware Description Language (HDL) generation and\ndebugging. Yet, their performance in real-world, repository-level HDL projects\nwith thousands or even tens of thousands of code lines is hindered. To this\nend, we propose HDLxGraph, a novel framework that integrates Graph Retrieval\nAugmented Generation (Graph RAG) with LLMs, introducing HDL-specific graph\nrepresentations by incorporating Abstract Syntax Trees (ASTs) and Data Flow\nGraphs (DFGs) to capture both code graph view and hardware graph view.\nHDLxGraph utilizes a dual-retrieval mechanism that not only mitigates the\nlimited recall issues inherent in similarity-based semantic retrieval by\nincorporating structural information, but also enhances its extensibility to\nvarious real-world tasks by a task-specific retrieval finetuning. Additionally,\nto address the lack of comprehensive HDL search benchmarks, we introduce\nHDLSearch, a multi-granularity evaluation dataset derived from real-world\nrepository-level projects. Experimental results demonstrate that HDLxGraph\nsignificantly improves average search accuracy, debugging efficiency and\ncompletion quality by 12.04%, 12.22% and 5.04% compared to similarity-based\nRAG, respectively. The code of HDLxGraph and collected HDLSearch benchmark are\navailable at https://github.com/Nick-Zheng-Q/HDLxGraph.",
    "pdf_url": "http://arxiv.org/pdf/2505.15701v1",
    "published": "2025-05-21T16:14:10+00:00",
    "categories": [
      "cs.AR",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15700v2",
    "title": "\"Alexa, can you forget me?\" Machine Unlearning Benchmark in Spoken Language Understanding",
    "authors": [
      "Alkis Koudounas",
      "Claudio Savelli",
      "Flavio Giobergia",
      "Elena Baralis"
    ],
    "abstract": "Machine unlearning, the process of efficiently removing specific information\nfrom machine learning models, is a growing area of interest for responsible AI.\nHowever, few studies have explored the effectiveness of unlearning methods on\ncomplex tasks, particularly speech-related ones. This paper introduces\nUnSLU-BENCH, the first benchmark for machine unlearning in spoken language\nunderstanding (SLU), focusing on four datasets spanning four languages. We\naddress the unlearning of data from specific speakers as a way to evaluate the\nquality of potential \"right to be forgotten\" requests. We assess eight\nunlearning techniques and propose a novel metric to simultaneously better\ncapture their efficacy, utility, and efficiency. UnSLU-BENCH sets a foundation\nfor unlearning in SLU and reveals significant differences in the effectiveness\nand computational feasibility of various techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.15700v2",
    "published": "2025-05-21T16:13:57+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15699v1",
    "title": "Families of tractable problems with respect to vertex-interval-membership width and its generalisations",
    "authors": [
      "Jessica Enright",
      "Samuel D. Hand",
      "Laura Larios-Jones",
      "Kitty Meeks"
    ],
    "abstract": "Temporal graphs are graphs whose edges are labelled with times at which they\nare active. Their time-sensitivity provides a useful model of real networks,\nbut renders many problems studied on temporal graphs more computationally\ncomplex than their static counterparts. To contend with this, there has been\nrecent work devising parameters for which temporal problems become tractable.\nOne such parameter is vertex-interval-membership width. Broadly, this gives a\nbound on the number of vertices we need to keep track of at any time in order\nto solve any of a family of problems. Our contributions are two-fold. Firstly,\nwe introduce a new parameter, tree-interval-membership-width, that generalises\nboth vertex-interval-membership-width and several existing generalisations.\nSecondly, we provide meta-algorithms for both parameters which can be used to\nprove fixed-parameter-tractability for large families of problems, bypassing\nthe need to give involved dynamic programming arguments for every problem. We\napply these algorithms to temporal versions of Hamiltonian path, matching, edge\ndeletion to limit maximum reachability, and firefighting.",
    "pdf_url": "http://arxiv.org/pdf/2505.15699v1",
    "published": "2025-05-21T16:12:39+00:00",
    "categories": [
      "cs.DM",
      "math.CO"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15698v1",
    "title": "An Efficient Data Structure and Algorithm for Long-Match Query in Run-Length Compressed BWT",
    "authors": [
      "Ahsan Sanaullah",
      "Degui Zhi",
      "Shaojie Zhang"
    ],
    "abstract": "In this paper, we describe a new type of match between a pattern and a text\nthat aren't necessarily maximal in the query, but still contain useful matching\ninformation: locally maximal exact matches (LEMs). There are usually a large\namount of LEMs, so we only consider those above some length threshold\n$\\mathcal{L}$. These are referred to as long LEMs. The purpose of long LEMs is\nto capture substring matches between a query and a text that are not\nnecessarily maximal in the pattern but still long enough to be important.\nTherefore efficient long LEMs finding algorithms are desired for these\ndatasets. However, these datasets are too large to query on traditional string\nindexes. Fortunately, these datasets are very repetitive. Recently, compressed\nstring indexes that take advantage of the redundancy in the data but retain\nefficient querying capability have been proposed as a solution. We therefore\ngive an efficient algorithm for computing all the long LEMs of a query and a\ntext in a BWT runs compressed string index. We describe an $O(m+occ)$ expected\ntime algorithm that relies on an $O(r)$ words space string index for outputting\nall long LEMs of a pattern with respect to a text given the matching statistics\nof the pattern with respect to the text. Here $m$ is the length of the query,\n$occ$ is the number of long LEMs outputted, and $r$ is the number of runs in\nthe BWT of the text. The $O(r)$ space string index we describe relies on an\nadaptation of the move data structure by Nishimoto and Tabei. We are able to\nsupport $LCP[i]$ queries in constant time given $SA[i]$. In other words, we\nanswer $PLCP[i]$ queries in constant time. Long LEMs may provide useful\nsimilarity information between a pattern and a text that MEMs may ignore. This\ninformation is particularly useful in pangenome and biobank scale haplotype\npanel contexts.",
    "pdf_url": "http://arxiv.org/pdf/2505.15698v1",
    "published": "2025-05-21T16:11:31+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15697v1",
    "title": "SENSE -- Sensor-Enhanced Neural Shear Stress Estimation for Quantitative Oilfilm Visualizations",
    "authors": [
      "Lennart Rohlfs",
      "Julien Weiss"
    ],
    "abstract": "Wall shear stress quantification is fundamental in fluid dynamics but remains\nchallenging in wind-tunnel experiments. Sensor-based methods offer high\naccuracy but lack spatial resolution for capturing complex three-dimensional\neffects. Conversely, oil-film visualization is a simple method to obtain\nhigh-resolution surface flow topology by processing a sequence of images using\noptical flow (OF) techniques. However, leveraging this approach for\nquantitative analysis suffers from noise and systematic biases. This study\nintroduces SENSE (Sensor-Enhanced Neural Shear Stress Estimation), a\ndata-driven approach that leverages a neural network to enhance OF-based shear\nstress estimation through the integration of sparse, high-fidelity sensor\nmeasurements via a multi-objective loss function. SENSE processes oil-film\nimage sequences directly, inherently mitigating temporal noise without explicit\naveraging. The method is validated in a turbulent separated flow on a one-sided\ndiffuser. Results demonstrate SENSE's robustness to sequence length and spatial\nresolution compared to classical optical flow algorithms. Crucially,\nincorporating sparse sensor data significantly improves quantitative accuracy,\nachieving over 30% reduction in root-mean-squared error on validation sensors\nwith only 8 strategically distributed sensors. The sensor data provides a\nglobal regularization effect, improving estimates far from sensor locations.\nSENSE offers a promising approach to elevate oil-film visualization to a\nreliable quantitative measurement technique by combining image sequences and\nsparse sensor data.",
    "pdf_url": "http://arxiv.org/pdf/2505.15697v1",
    "published": "2025-05-21T16:10:47+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.15696v1",
    "title": "MaxPoolBERT: Enhancing BERT Classification via Layer- and Token-Wise Aggregation",
    "authors": [
      "Maike Behrendt",
      "Stefan Sylvius Wagner",
      "Stefan Harmeling"
    ],
    "abstract": "The [CLS] token in BERT is commonly used as a fixed-length representation for\nclassification tasks, yet prior work has shown that both other tokens and\nintermediate layers encode valuable contextual information. In this work, we\npropose MaxPoolBERT, a lightweight extension to BERT that refines the [CLS]\nrepresentation by aggregating information across layers and tokens.\nSpecifically, we explore three modifications: (i) max-pooling the [CLS] token\nacross multiple layers, (ii) enabling the [CLS] token to attend over the entire\nfinal layer using an additional multi-head attention (MHA) layer, and (iii)\ncombining max-pooling across the full sequence with MHA. Our approach enhances\nBERT's classification accuracy (especially on low-resource tasks) without\nrequiring pre-training or significantly increasing model size. Experiments on\nthe GLUE benchmark show that MaxPoolBERT consistently achieves a better\nperformance on the standard BERT-base model.",
    "pdf_url": "http://arxiv.org/pdf/2505.15696v1",
    "published": "2025-05-21T16:10:02+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15695v2",
    "title": "Can Large Language Models be Effective Online Opinion Miners?",
    "authors": [
      "Ryang Heo",
      "Yongsik Seo",
      "Junseong Lee",
      "Dongha Lee"
    ],
    "abstract": "The surge of user-generated online content presents a wealth of insights into\ncustomer preferences and market trends. However, the highly diverse, complex,\nand context-rich nature of such contents poses significant challenges to\ntraditional opinion mining approaches. To address this, we introduce Online\nOpinion Mining Benchmark (OOMB), a novel dataset and evaluation protocol\ndesigned to assess the ability of large language models (LLMs) to mine opinions\neffectively from diverse and intricate online environments. OOMB provides\nextensive (entity, feature, opinion) tuple annotations and a comprehensive\nopinion-centric summary that highlights key opinion topics within each content,\nthereby enabling the evaluation of both the extractive and abstractive\ncapabilities of models. Through our proposed benchmark, we conduct a\ncomprehensive analysis of which aspects remain challenging and where LLMs\nexhibit adaptability, to explore whether they can effectively serve as opinion\nminers in realistic online scenarios. This study lays the foundation for\nLLM-based opinion mining and discusses directions for future research in this\nfield.",
    "pdf_url": "http://arxiv.org/pdf/2505.15695v2",
    "published": "2025-05-21T16:09:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15694v1",
    "title": "A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO",
    "authors": [
      "Xingyu Zhou",
      "Yulian Wu",
      "Francesco Orabona"
    ],
    "abstract": "In this paper, we theoretically investigate the effects of noisy labels in\noffline alignment, with a focus on the interplay between privacy and robustness\nagainst adversarial corruption. Specifically, under linear modeling\nassumptions, we present a unified analysis covering both reinforcement learning\nfrom human feedback (RLHF) and direct preference optimization (DPO) under\ndifferent privacy-corruption scenarios, such as Local differential\nprivacy-then-Corruption (LTC), where human preference labels are privatized\nbefore being corrupted by an adversary, and Corruption-then-Local differential\nprivacy (CTL), where labels are corrupted before privacy protection. Our\nanalysis leverages a reduction framework that reduces the offline alignment\nproblem under linear modeling assumptions to parameter estimation in logistic\nregression. This framework allows us to establish an interesting separation\nresult between LTC and CTL, demonstrating that LTC presents a greater challenge\nthan CTL in offline alignment, even under linear models. As important\nby-products, our findings also advance the state-of-the-art theoretical results\nin offline alignment under privacy-only or corruption-only scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.15694v1",
    "published": "2025-05-21T16:07:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15693v1",
    "title": "Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives",
    "authors": [
      "Milad Kazemi",
      "Mateo Perez",
      "Fabio Somenzi",
      "Sadegh Soudjani",
      "Ashutosh Trivedi",
      "Alvaro Velasquez"
    ],
    "abstract": "Recent advances in reinforcement learning (RL) have renewed focus on the\ndesign of reward functions that shape agent behavior. Manually designing reward\nfunctions is tedious and error-prone. A principled alternative is to specify\nbehaviors in a formal language that can be automatically translated into\nrewards. Omega-regular languages are a natural choice for this purpose, given\ntheir established role in formal verification and synthesis. However, existing\nmethods using omega-regular specifications typically rely on discounted reward\nRL in episodic settings, with periodic resets. This setup misaligns with the\nsemantics of omega-regular specifications, which describe properties over\ninfinite behavior traces. In such cases, the average reward criterion and the\ncontinuing setting -- where the agent interacts with the environment over a\nsingle, uninterrupted lifetime -- are more appropriate.\n  To address the challenges of infinite-horizon, continuing tasks, we focus on\nabsolute liveness specifications -- a subclass of omega-regular languages that\ncannot be violated by any finite behavior prefix, making them well-suited to\nthe continuing setting. We present the first model-free RL framework that\ntranslates absolute liveness specifications to average-reward objectives. Our\napproach enables learning in communicating MDPs without episodic resetting. We\nalso introduce a reward structure for lexicographic multi-objective\noptimization, aiming to maximize an external average-reward objective among the\npolicies that also maximize the satisfaction probability of a given\nomega-regular specification. Our method guarantees convergence in unknown\ncommunicating MDPs and supports on-the-fly reductions that do not require full\nknowledge of the environment, thus enabling model-free RL. Empirical results\nshow our average-reward approach in continuing setting outperforms\ndiscount-based methods across benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15693v1",
    "published": "2025-05-21T16:06:51+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15692v2",
    "title": "Thought-Augmented Policy Optimization: Bridging External Guidance and Internal Capabilities",
    "authors": [
      "Jinyang Wu",
      "Chonghua Liao",
      "Mingkuan Feng",
      "Shuai Zhang",
      "Zhengqi Wen",
      "Pengpeng Shao",
      "Huazhe Xu",
      "Jianhua Tao"
    ],
    "abstract": "Reinforcement learning (RL) has emerged as an effective method for training\nreasoning models. However, existing RL approaches typically bias the model's\noutput distribution toward reward-maximizing paths without introducing external\nknowledge. This limits their exploration capacity and results in a narrower\nreasoning capability boundary compared to base models. To address this\nlimitation, we propose TAPO (Thought-Augmented Policy Optimization), a novel\nframework that augments RL by incorporating external high-level guidance\n(\"thought patterns\"). By adaptively integrating structured thoughts during\ntraining, TAPO effectively balances model-internal exploration and external\nguidance exploitation. Extensive experiments show that our approach\nsignificantly outperforms GRPO by 99% on AIME, 41% on AMC, and 17% on Minerva\nMath. Notably, these high-level thought patterns, abstracted from only 500\nprior samples, generalize effectively across various tasks and models. This\nhighlights TAPO's potential for broader applications across multiple tasks and\ndomains. Our further analysis reveals that introducing external guidance\nproduces powerful reasoning models with superior explainability of inference\nbehavior and enhanced output readability.",
    "pdf_url": "http://arxiv.org/pdf/2505.15692v2",
    "published": "2025-05-21T16:06:10+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15691v1",
    "title": "Stellar population modelling of neutron stars and black holes: spatially-resolved graveyards in MaNGA/SDSS-IV galaxies",
    "authors": [
      "Claudia Maraston",
      "Marco Limongi",
      "Justus Neumann",
      "Lorenzo Roberti",
      "Alessandro Chieffi",
      "Daniel Thomas",
      "Jianhui Lian"
    ],
    "abstract": "We update our stellar population models for the time evolution of the number\nand mass of massive remnants - neutron stars and black holes - with a new\ninitial mass-remnant mass relation for core collapse supernovae. The\ncalculations are based on hydrodynamical simulations and induced explosions of\na subset of previously published pre-supernovae models spanning a wide range of\nstellar mass, metallicity and different values for rotation velocity. The\nresulting stellar population models predict lower numbers of neutron stars (by\nup to 0.3 dex) and higher numbers of black holes (by up to 0.8 dex), especially\nwhen stellar rotation is considered. The mass fraction locked in neutron stars\nand black holes is lowest in high-metallicity populations, with the largest\nnumber of remnants found at about half-solar metallicity. This mirrors the\namount of available gas, ranging from 35 per cent to 45 per cent. We then apply\nour new models to IFU spectra for ~10,000 galaxies from the SDSS-IV/MaNGA\nsurvey for which we previously published spatially-resolved star formation\nhistories. This allows us to probe spatially-resolved graveyards in galaxies of\ndifferent types. The number and radial distribution of remnants depend on a\ngalaxy's mass, star formation history and metal content. More massive and hence\nmore metal-rich galaxies are found to host fewer remnants. Radial gradients in\nthe number of remnants depend on galaxy mass mostly because of the\nmass-dependent profiles in mass density: the gradients are flat in low-mass\ngalaxies, and negative in high-mass galaxies, particularly in Milky Way\nanalogues.",
    "pdf_url": "http://arxiv.org/pdf/2505.15691v1",
    "published": "2025-05-21T16:05:34+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15690v2",
    "title": "Toward Open Earth Science as Fast and Accessible as Natural Language",
    "authors": [
      "Marquita Ellis",
      "Iksha Gurung",
      "Muthukumaran Ramasubramanian",
      "Rahul Ramachandran"
    ],
    "abstract": "Is natural-language-driven earth observation data analysis now feasible with\nthe assistance of Large Language Models (LLMs)? For open science in service of\npublic interest, feasibility requires reliably high accuracy, interactive\nlatencies, low (sustainable) costs, open LLMs, and openly maintainable software\n-- hence, the challenge. What are the techniques and programming system\nrequirements necessary for satisfying these constraints, and what is the\ncorresponding development and maintenance burden in practice? This study lays\nthe groundwork for exploring these questions, introducing an impactful earth\nscience use-case, and providing a software framework with evaluation data and\nmetrics, along with initial results from employing model scaling,\nprompt-optimization, and inference-time scaling optimization techniques. While\nwe attain high accuracy (near 100%) across 10 of 11 metrics, the analysis\nfurther considers cost (token-spend), latency, and maintainability across this\nspace of techniques. Finally, we enumerate opportunities for further research,\ngeneral programming and evaluation framework development, and ongoing work for\na comprehensive, deployable solution. This is a call for collaboration and\ncontribution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15690v2",
    "published": "2025-05-21T16:05:29+00:00",
    "categories": [
      "cs.CE",
      "J.2; H.5.2; H.3.3"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15689v1",
    "title": "Weighted Multiplier Method for Source-Independent Waveform Inversion",
    "authors": [
      "Ali Gholami",
      "Kamal Aghazade"
    ],
    "abstract": "The Lagrangian multiplier method has proven highly effective in addressing\nthe ill-conditioning of full waveform inversion (FWI). It enables the\ndevelopment of robust and computationally efficient algorithms capable of\nconverging to accurate velocity models, even from poor initial estimates.\nTraditionally, these methods optimize an Augmented Lagrangian (AL) function,\nusing a scalar penalty parameter to weight the quadratic penalty term for\nwave-equation constraint violations. This penalty balances relaxation of the\nwave equation to improve data fit. However, it imposes uniform relaxation\nacross the model, regardless of source location and the natural decay of\nseismic amplitudes. To overcome this, we propose a variable penalty strategy\nthat introduces greater flexibility by assigning distance-dependent penalties\nto the wave-equation constraints. These nonstationary weights apply minimal\npenalties near the source and larger penalties with increasing distance. This\ncompensates for amplitude decay and allows the wave equation to be satisfied\nmore uniformly across the model. This eliminates the need for explicit source\nsignature estimation and relaxes the requirement for source alignment with grid\npoints, making the method more practical for real applications. The strategy is\nimplemented in the dual formulation of the multiplier method, where model\nparameters are eliminated, reducing the problem to a fixed-point iteration for\nsource multipliers. Once obtained, model parameters are recovered as a\nbyproduct. Numerical experiments show that this method eliminates explicit\nsource estimation and enhances convexity, improving robustness, convergence,\nand computational efficiency of FWI.",
    "pdf_url": "http://arxiv.org/pdf/2505.15689v1",
    "published": "2025-05-21T16:04:56+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15688v1",
    "title": "A packing lemma for VCN${}_k$-dimension and learning high-dimensional data",
    "authors": [
      "Leonardo N. Coregliano",
      "Maryanthe Malliaris"
    ],
    "abstract": "Recently, the authors introduced the theory of high-arity PAC learning, which\nis well-suited for learning graphs, hypergraphs and relational structures. In\nthe same initial work, the authors proved a high-arity analogue of the\nFundamental Theorem of Statistical Learning that almost completely\ncharacterizes all notions of high-arity PAC learning in terms of a\ncombinatorial dimension, called the Vapnik--Chervonenkis--Natarajan (VCN${}_k$)\n$k$-dimension, leaving as an open problem only the characterization of\nnon-partite, non-agnostic high-arity PAC learnability.\n  In this work, we complete this characterization by proving that non-partite\nnon-agnostic high-arity PAC learnability implies a high-arity version of the\nHaussler packing property, which in turn implies finiteness of\nVCN${}_k$-dimension. This is done by obtaining direct proofs that classic PAC\nlearnability implies classic Haussler packing property, which in turn implies\nfinite Natarajan dimension and noticing that these direct proofs nicely lift to\nhigh-arity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15688v1",
    "published": "2025-05-21T16:03:12+00:00",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.TH",
      "Primary: 68Q32. Secondary: 68T05"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15687v1",
    "title": "Discovering Pathology Rationale and Token Allocation for Efficient Multimodal Pathology Reasoning",
    "authors": [
      "Zhe Xu",
      "Cheng Jin",
      "Yihui Wang",
      "Ziyi Liu",
      "Hao Chen"
    ],
    "abstract": "Multimodal pathological image understanding has garnered widespread interest\ndue to its potential to improve diagnostic accuracy and enable personalized\ntreatment through integrated visual and textual data. However, existing methods\nexhibit limited reasoning capabilities, which hamper their ability to handle\ncomplex diagnostic scenarios. Additionally, the enormous size of pathological\nimages leads to severe computational burdens, further restricting their\npractical deployment. To address these limitations, we introduce a novel\nbilateral reinforcement learning framework comprising two synergistic branches.\nOne reinforcement branch enhances the reasoning capability by enabling the\nmodel to learn task-specific decision processes, i.e., pathology rationales,\ndirectly from labels without explicit reasoning supervision. While the other\nbranch dynamically allocates a tailored number of tokens to different images\nbased on both their visual content and task context, thereby optimizing\ncomputational efficiency. We apply our method to various pathological tasks\nsuch as visual question answering, cancer subtyping, and lesion detection.\nExtensive experiments show an average +41.7 absolute performance improvement\nwith 70.3% lower inference costs over the base models, achieving both reasoning\naccuracy and computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.15687v1",
    "published": "2025-05-21T16:03:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15686v1",
    "title": "Path Planning Algorithm Comparison Analysis for Wireless AUVs Energy Sharing System",
    "authors": [
      "Zhengji Feng",
      "Hengxiang Chen",
      "Liqun Chen",
      "Heyan Li",
      "Xiaolin Mou"
    ],
    "abstract": "Autonomous underwater vehicles (AUVs) are increasingly used in marine\nresearch, military applications, and undersea exploration. However, their\noperational range is significantly affected by battery performance. In this\npaper, a framework for a wireless energy sharing system among AUVs is proposed,\nenabling rapid energy replenishment. Path planning plays a crucial role in the\nenergy-sharing process and autonomous navigation, as it must generate feasible\ntrajectories toward designated goals. This article focuses on efficient\nobstacle avoidance in complex underwater environments, including irregularly\nshaped obstacles and narrow passages. The proposed method combines\nRapidly-exploring Random Trees Star (RRT*) with Particle Swarm Optimization\n(PSO) to improve path planning efficiency. Comparative analysis of the two\nalgorithms is presented through simulation results in both random and irregular\nobstacle environments. Index Terms: Wireless charging, autonomous underwater\nvehicles (AUVs), path planning, irregular obstacles, narrow passages, RRT*,\nparticle swarm optimization (PSO).",
    "pdf_url": "http://arxiv.org/pdf/2505.15686v1",
    "published": "2025-05-21T16:02:13+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15685v1",
    "title": "From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems",
    "authors": [
      "Xiuchao Sui",
      "Daiying Tian",
      "Qi Sun",
      "Ruirui Chen",
      "Dongkyu Choi",
      "Kenneth Kwok",
      "Soujanya Poria"
    ],
    "abstract": "Foundation models (FMs) are increasingly used to bridge language and action\nin embodied agents, yet the operational characteristics of different FM\nintegration strategies remain under-explored -- particularly for complex\ninstruction following and versatile action generation in changing environments.\nThis paper examines three paradigms for building robotic systems: end-to-end\nvision-language-action (VLA) models that implicitly integrate perception and\nplanning, and modular pipelines incorporating either vision-language models\n(VLMs) or multimodal large language models (LLMs). We evaluate these paradigms\nthrough two focused case studies: a complex instruction grounding task\nassessing fine-grained instruction understanding and cross-modal\ndisambiguation, and an object manipulation task targeting skill transfer via\nVLA finetuning. Our experiments in zero-shot and few-shot settings reveal\ntrade-offs in generalization and data efficiency. By exploring performance\nlimits, we distill design implications for developing language-driven physical\nagents and outline emerging challenges and opportunities for FM-powered\nrobotics in real-world conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15685v1",
    "published": "2025-05-21T16:01:11+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15684v2",
    "title": "ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy",
    "authors": [
      "Gengyang Li",
      "Yifeng Gao",
      "Yuming Li",
      "Yunfang Wu"
    ],
    "abstract": "While Chain-of-Thought (CoT) prompting improves reasoning in large language\nmodels (LLMs), the excessive length of reasoning tokens increases latency and\nKV cache memory usage, and may even truncate final answers under context\nlimits. We propose ThinkLess, an inference-efficient framework that terminates\nreasoning generation early and maintains output quality without modifying the\nmodel. Atttention analysis reveals that answer tokens focus minimally on\nearlier reasoning steps and primarily attend to the reasoning terminator token,\ndue to information migration under causal masking. Building on this insight,\nThinkLess inserts the terminator token at earlier positions to skip redundant\nreasoning while preserving the underlying knowledge transfer. To prevent format\ndiscruption casued by early termination, ThinkLess employs a lightweight\npost-regulation mechanism, relying on the model's natural instruction-following\nability to produce well-structured answers. Without fine-tuning or auxiliary\ndata, ThinkLess achieves comparable accuracy to full-length CoT decoding while\ngreatly reducing decoding time and memory consumption.",
    "pdf_url": "http://arxiv.org/pdf/2505.15684v2",
    "published": "2025-05-21T15:58:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15683v2",
    "title": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models",
    "authors": [
      "Zishuai Zhang",
      "Hainan zhang",
      "Weihua Li",
      "Qinnan zhang",
      "jin Dong",
      "Yongxin Tong",
      "Zhiming Zheng"
    ],
    "abstract": "Private data holds promise for improving LLMs due to its high quality, but\nits scattered distribution across data silos and the high computational demands\nof LLMs limit their deployment in federated environments. To address this, the\ntransformer-based federated split models are proposed, which offload most model\nparameters to the server (or distributed clients) while retaining only a small\nportion on the client to ensure data privacy. Despite this design, they still\nface three challenges: 1) Peer-to-peer key encryption struggles to secure\ntransmitted vectors effectively; 2) The auto-regressive nature of LLMs means\nthat federated split learning can only train and infer sequentially, causing\nhigh communication overhead; 3) Fixed partition points lack adaptability to\ndownstream tasks. In this paper, we introduce FedSEA-LLaMA, a Secure,\nEfficient, and Adaptive Federated splitting framework based on LLaMA2. First,\nwe inject Gaussian noise into forward-pass hidden states to enable secure\nend-to-end vector transmission. Second, we employ attention-mask compression\nand KV cache collaboration to reduce communication costs, accelerating training\nand inference. Third, we allow users to dynamically adjust the partition points\nfor input/output blocks based on specific task requirements. Experiments on\nnatural language understanding, summarization, and conversational QA tasks show\nthat FedSEA-LLaMA maintains performance comparable to centralized LLaMA2 and\nachieves up to 8x speedups in training and inference. Further analysis of\nprivacy attacks and different partition points also demonstrates the\neffectiveness of FedSEA-LLaMA in security and adaptability.",
    "pdf_url": "http://arxiv.org/pdf/2505.15683v2",
    "published": "2025-05-21T15:58:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15682v1",
    "title": "The Representational Alignment between Humans and Language Models is implicitly driven by a Concreteness Effect",
    "authors": [
      "Cosimo Iaia",
      "Bhavin Choksi",
      "Emily Wiebers",
      "Gemma Roig",
      "Christian J. Fiebach"
    ],
    "abstract": "The nouns of our language refer to either concrete entities (like a table) or\nabstract concepts (like justice or love), and cognitive psychology has\nestablished that concreteness influences how words are processed. Accordingly,\nunderstanding how concreteness is represented in our mind and brain is a\ncentral question in psychology, neuroscience, and computational linguistics.\nWhile the advent of powerful language models has allowed for quantitative\ninquiries into the nature of semantic representations, it remains largely\nunderexplored how they represent concreteness. Here, we used behavioral\njudgments to estimate semantic distances implicitly used by humans, for a set\nof carefully selected abstract and concrete nouns. Using Representational\nSimilarity Analysis, we find that the implicit representational space of\nparticipants and the semantic representations of language models are\nsignificantly aligned. We also find that both representational spaces are\nimplicitly aligned to an explicit representation of concreteness, which was\nobtained from our participants using an additional concreteness rating task.\nImportantly, using ablation experiments, we demonstrate that the human-to-model\nalignment is substantially driven by concreteness, but not by other important\nword characteristics established in psycholinguistics. These results indicate\nthat humans and language models converge on the concreteness dimension, but not\non other dimensions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15682v1",
    "published": "2025-05-21T15:57:58+00:00",
    "categories": [
      "cs.CL",
      "I.2.7; J.4"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15681v1",
    "title": "Spectroscopic Study of Blue Straggler Stars in the Globular Cluster NGC 3201",
    "authors": [
      "Gourav Kumawat",
      "Arvind K. Dattatrey",
      "R. K. S Yadav"
    ],
    "abstract": "We conducted a spectroscopic study of 39 blue straggler stars in the globular\ncluster NGC 3201. The spectra of these stars were collected from the\nliterature. We determined the radial velocity, atmospheric parameters (Teff,\nlog g), and the abundance of Mg, as well as the metallicity ([Fe/H]) of the\nblue straggler population. The mean radial velocity and [Fe/H] are determined\nto be 498.0 $\\pm$ 5.3 km/s and -1.42 $\\pm$ 0.27, respectively, for the blue\nstraggler stars. The derived [Fe/H] is consistent, within uncertainties, with\nthe cluster's [Fe/H] of -1.59 dex. The mean [Mg/Fe] for the blue straggler\nstars is estimated to be 0.36 $\\pm$ 0.73. Importantly, this study first\nestimates [Mg/Fe] for the blue straggler stars in the cluster NGC 3201.",
    "pdf_url": "http://arxiv.org/pdf/2505.15681v1",
    "published": "2025-05-21T15:57:50+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15680v2",
    "title": "Radiative decays of the second shell $Œõ_b$ and $Œû_b$ bottom baryons",
    "authors": [
      "Ailier Rivero-Acosta",
      "H. Garc√≠a-Tecocoatzi",
      "A. Ramirez-Morales",
      "E. Santopinto",
      "Carlos Alberto Vaquera-Araujo"
    ],
    "abstract": "In this work, we investigate the radiative decays of the $\\Lambda_b$ and\n$\\Xi_b$ bottom baryons, which belong to the flavor anti-triplet\n($\\mathbf{\\bar{3}}_{\\rm F}$), within the constituent quark model formalism. The\nelectromagnetic transitions are calculated from the second-shell states to both\nthe ground and $P$-wave final states. These decays play a crucial role in\nconfirming the existence of certain resonances. When strong decays are not\nallowed, the reconstruction of states relies on their electromagnetic decay\nchannels. Moreover, electromagnetic decay widths are particularly useful for\nthe identification of resonances when states have the same mass and total decay\nwidth. This study presents, for the first time, the calculation of\nelectromagnetic decays for $D_\\rho$-wave states, $\\rho-\\lambda$ mixed states,\nand $\\rho$-mode radially excited states. Throughout our calculations, we\naccount for uncertainties arising from both experimental and model-dependent\nerrors.",
    "pdf_url": "http://arxiv.org/pdf/2505.15680v2",
    "published": "2025-05-21T15:57:08+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15679v1",
    "title": "SwarmDiff: Swarm Robotic Trajectory Planning in Cluttered Environments via Diffusion Transformer",
    "authors": [
      "Kang Ding",
      "Chunxuan Jiao",
      "Yunze Hu",
      "Kangjie Zhou",
      "Pengying Wu",
      "Yao Mu",
      "Chang Liu"
    ],
    "abstract": "Swarm robotic trajectory planning faces challenges in computational\nefficiency, scalability, and safety, particularly in complex, obstacle-dense\nenvironments. To address these issues, we propose SwarmDiff, a hierarchical and\nscalable generative framework for swarm robots. We model the swarm's\nmacroscopic state using Probability Density Functions (PDFs) and leverage\nconditional diffusion models to generate risk-aware macroscopic trajectory\ndistributions, which then guide the generation of individual robot trajectories\nat the microscopic level. To ensure a balance between the swarm's optimal\ntransportation and risk awareness, we integrate Wasserstein metrics and\nConditional Value at Risk (CVaR). Additionally, we introduce a Diffusion\nTransformer (DiT) to improve sampling efficiency and generation quality by\ncapturing long-range dependencies. Extensive simulations and real-world\nexperiments demonstrate that SwarmDiff outperforms existing methods in\ncomputational efficiency, trajectory validity, and scalability, making it a\nreliable solution for swarm robotic trajectory planning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15679v1",
    "published": "2025-05-21T15:56:55+00:00",
    "categories": [
      "cs.RO",
      "cs.MA"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15678v1",
    "title": "Optimization of fipronil removal via electro-Fenton using a carbon cloth air-diffusion electrode",
    "authors": [
      "Caio Machado Fernandes",
      "Gabriel A. Cerron-Calle",
      "Enric Brillas",
      "Mauro C. Santos",
      "Sergi Garcia-Segura"
    ],
    "abstract": "The electro-Fenton (EF) process using a boron-doped diamond (BDD) anode and a\ncarbon cloth air-diffusion cathode was optimized for efficient fipronil\ndegradation. The system achieved high H2O2 electrogeneration with close to 80%\ncurrent efficiency operating between 10 and 50 mA cm-2, with hydroxil radicals\nformed from BDD oxidation and Fenton's reaction that drive pollutant decay.\nOptimum conditions were found with 0.50 mM Fe2+ catalyst at pH = 3.0 and 30 mA\ncm-2, yielding almost complete removal for 20 mg L-1 fipronil in 60 min, 85%\nremoval for 10 mg L-1, and a robust performance down to 1 mg L-1, thus\nreflecting real-world applicability. The system demonstrated excellent\nreusability and stability over seven consecutive runs. The evolution of final\nshot-chain linear carboxylic acids like acetic, fumaric, formic, oxalic, and\noxamic, and inorganic ions like F-, Cl-, NH4+, was determined. This study\nhighlights the EF process as a highly efficient, energy-balanced, and stable\nsolution for fipronil degradation in water treatment.",
    "pdf_url": "http://arxiv.org/pdf/2505.15678v1",
    "published": "2025-05-21T15:56:29+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15677v1",
    "title": "Coupling quantum spin ice to matter on the centered pyrochlore lattice",
    "authors": [
      "Rajah P. Nutakki",
      "Sylvain Capponi",
      "Ludovic D. C. Jaubert",
      "Lode Pollet"
    ],
    "abstract": "The low-energy physics of quantum spin ice is known to support an emergent\nform of quantum electrodynamics (QED), where magnetic monopoles exist and the\nfine structure constant is material dependent. In this article, we show how\nthis QED is modified via a coupling to dynamical matter on the centered\npyrochlore lattice, a structure which has recently been synthesized using\nmetal-organic frameworks. Specifically, we study the low-energy properties of\nthe S = 1/2 quantum XXZ model on the centered pyrochlore lattice. At fourth\norder in degenerate perturbation theory, this model hosts a quantum spin liquid\ndistinct from the well-known U(1) quantum spin ice on the pyrochlore due to the\npresence of dynamical matter in the ground state. Exact diagonalization results\nare consistent with this quantum spin liquid over an extended region of the\nground state phase diagram although potential quantum critical points within\nthis region could indicate a richer phase structure. Our work thus expands the\nphysics of quantum spin ice in an experimentally motivated geometry, providing\nthe framework for understanding how the emergent QED behaves in the presence of\ndynamical matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.15677v1",
    "published": "2025-05-21T15:55:27+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.15676v1",
    "title": "Distillation of multipartite entangled states for arbitrary subsets of parties in noisy quantum networks of increasing size",
    "authors": [
      "Aitor Balmaseda",
      "Julio I. de Vicente"
    ],
    "abstract": "Quantum network states are multipartite states built from distributing\npairwise entanglement among parties and underpin the paradigm of quantum\nnetworks for quantum information processing. In this work we introduce the\nproblem of partial distillability in noisy quantum networks. This corresponds\nto the possibility of creating locally starting from a single copy of a quantum\nnetwork state with mixed entangled links supporting a constant amount of noise\nan arbitrary pure state for an arbitrary subset of parties with fidelity as\nclose to 1 as desired as the size of the network increases. While we prove an\nobstruction to multipartite distillation protocols after teleportation with\nchannels with constant noise, we show that partial distillability is indeed\npossible if certain well-established graph-theoretic parameters that measure\nthe connectivity in the network grow fast enough with its size. We give\nnecessary as well as sufficient conditions for partial distillability in terms\nof these parameters and we moreover provide explicit constructions of networks\nwith partial distillability and a relatively slow connectivity growth.",
    "pdf_url": "http://arxiv.org/pdf/2505.15676v1",
    "published": "2025-05-21T15:54:38+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15675v1",
    "title": "Borg-type theorem for a class of higher-order differential operators",
    "authors": [
      "Ai-Wei Guan",
      "Dong-Jie Wu",
      "Chuan-Fu Yang",
      "Natalia P. Bondarenko"
    ],
    "abstract": "In this paper, we study an inverse spectral operator for the higher-order\ndifferential equation $(-1)^my^{(2m)}+ q y = \\lambda y$, where $q \\in\nL^2(0,\\pi)$. We prove that if $\\|q\\|_2$ is sufficiently small, the two spectra\ncorresponding to the both Dirichlet boundary conditions and to the\nDirichlet-Neumann ones uniquely determine the potential $q$. The result extends\nthe Borg theorem from the second order to all even higher orders.",
    "pdf_url": "http://arxiv.org/pdf/2505.15675v1",
    "published": "2025-05-21T15:54:20+00:00",
    "categories": [
      "math.SP"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15674v1",
    "title": "UniErase: Unlearning Token as a Universal Erasure Primitive for Language Models",
    "authors": [
      "Miao Yu",
      "Liang Lin",
      "Guibin Zhang",
      "Xinfeng Li",
      "Junfeng Fang",
      "Ningyu Zhang",
      "Kun Wang",
      "Yang Wang"
    ],
    "abstract": "Large language models require iterative updates to address challenges such as\nknowledge conflicts and outdated information (e.g., incorrect, private, or\nillegal contents). Machine unlearning provides a systematic methodology for\ntargeted knowledge removal from trained models, enabling elimination of\nsensitive information influences. However, mainstream fine-tuning-based\nunlearning methods often fail to balance unlearning efficacy and model ability,\nfrequently resulting in catastrophic model collapse under extensive knowledge\nremoval. Meanwhile, in-context unlearning, which relies solely on contextual\nprompting without modifying the model's intrinsic mechanisms, suffers from\nlimited generalizability and struggles to achieve true unlearning. In this\nwork, we introduce UniErase, a novel unlearning paradigm that employs learnable\nparametric suffix (unlearning token) to steer language models toward targeted\nforgetting behaviors. UniErase operates through two key phases: (I) an\noptimization stage that binds desired unlearning outputs to the model's\nautoregressive probability distribution via token optimization, followed by\n(II) a lightweight model editing phase that activates the learned token to\nprobabilistically induce specified forgetting objective. Serving as a new\nresearch direction for token learning to induce unlearning target, UniErase\nachieves state-of-the-art (SOTA) performance across batch, sequential, and\nprecise unlearning under fictitious and real-world knowledge settings.\nRemarkably, in terms of TOFU benchmark, UniErase, modifying only around 3.66%\nof the LLM parameters, outperforms previous forgetting SOTA baseline by around\n4.01 times for model ability with even better unlearning efficacy. Similarly,\nUniErase, maintaining more ability, also surpasses previous retaining SOTA by\n35.96% for unlearning efficacy, showing dual top-tier performances in current\nunlearing domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.15674v1",
    "published": "2025-05-21T15:53:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15673v1",
    "title": "High-$Œ≤$* Optics Calculus at IP2 for Forward Physics in LHC Runs 3 and 4",
    "authors": [
      "Sorina Popescu"
    ],
    "abstract": "We present a study of high-$\\beta$* optics configurations at Interaction\nPoint 2 (IP2) of the Large Hadron Collider (LHC), developed to enable forward\nand diffractive physics measurements with the ALICE experiment during Runs 3\nand 4. Using MAD-X, we designed a $\\beta$* = 30 m optics scheme that satisfies\nbeam stability and aperture requirements, while offering improved sensitivity\nto small-angle scattering. The configuration follows the Achromatic Telescopic\nSqueeze (ATS) optics scheme, originally developed for IP1 and IP5, which\nprovides enhanced control over phase advance and chromaticity. The resulting\noptics layout enables a forward physics program with continuous data-taking. We\nalso outline possible extensions toward even higher $\\beta$* values and discuss\nthe implementation roadmap.",
    "pdf_url": "http://arxiv.org/pdf/2505.15673v1",
    "published": "2025-05-21T15:51:48+00:00",
    "categories": [
      "hep-ex",
      "physics.acc-ph"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.15672v2",
    "title": "Explicit isomorphisms for the symmetry algebras of continuous and discrete isotropic oscillators",
    "authors": [
      "Pavel Drozdov",
      "Giorgio Gubbiotti",
      "Danilo Latini"
    ],
    "abstract": "We present a detailed study of a parametric Lie algebra encompassing the\nsymmetry algebras of various models, both continuous and discrete. This\nalgebraic structure characterizes the isotropic oscillator (with positive,\npurely imaginary, and zero frequency) and one of its possible nonlinear\ndeformations. We demonstrate a novel occurrence of this Lie algebra in the\nframework of maximally superintegrable discretizations of the isotropic\nharmonic oscillator. In particular, we also show that the continuous model and\none of its discretizations admit a Nambu-Hamiltonian structure. Through an\nin-depth analysis of the properties characterizing the Lie algebra in the\nabstract setting, for different values of the parameter, we find explicit\nexpressions of the Killing forms and construct explicit isomorphism maps to\n$\\mathfrak{u}_N$, $\\mathfrak{gl}_N(\\mathbb{R})$, and a semidirect sum of\n$\\mathfrak{so}_N(\\mathbb{R})$ with $\\mathbb{R}^{N(N+1)/2}$. Notably, due to the\nabove isomorphisms, our formulas hold true for $\\mathfrak{su}_N$ and\n$\\mathfrak{sl}_N(\\mathbb{R})$ and are valid for arbitrary $N$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15672v2",
    "published": "2025-05-21T15:50:05+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15671v1",
    "title": "Enhancing Monte Carlo Dropout Performance for Uncertainty Quantification",
    "authors": [
      "Hamzeh Asgharnezhad",
      "Afshar Shamsi",
      "Roohallah Alizadehsani",
      "Arash Mohammadi",
      "Hamid Alinejad-Rokny"
    ],
    "abstract": "Knowing the uncertainty associated with the output of a deep neural network\nis of paramount importance in making trustworthy decisions, particularly in\nhigh-stakes fields like medical diagnosis and autonomous systems. Monte Carlo\nDropout (MCD) is a widely used method for uncertainty quantification, as it can\nbe easily integrated into various deep architectures. However, conventional MCD\noften struggles with providing well-calibrated uncertainty estimates. To\naddress this, we introduce innovative frameworks that enhances MCD by\nintegrating different search solutions namely Grey Wolf Optimizer (GWO),\nBayesian Optimization (BO), and Particle Swarm Optimization (PSO) as well as an\nuncertainty-aware loss function, thereby improving the reliability of\nuncertainty quantification. We conduct comprehensive experiments using\ndifferent backbones, namely DenseNet121, ResNet50, and VGG16, on various\ndatasets, including Cats vs. Dogs, Myocarditis, Wisconsin, and a synthetic\ndataset (Circles). Our proposed algorithm outperforms the MCD baseline by 2-3%\non average in terms of both conventional accuracy and uncertainty accuracy\nwhile achieving significantly better calibration. These results highlight the\npotential of our approach to enhance the trustworthiness of deep learning\nmodels in safety-critical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15671v1",
    "published": "2025-05-21T15:50:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15670v4",
    "title": "SALM-Duplex: Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model",
    "authors": [
      "Ke Hu",
      "Ehsan Hosseini-Asl",
      "Chen Chen",
      "Edresson Casanova",
      "Subhankar Ghosh",
      "Piotr ≈ªelasko",
      "Zhehuai Chen",
      "Jason Li",
      "Jagadeesh Balam",
      "Boris Ginsburg"
    ],
    "abstract": "Spoken dialogue is an intuitive form of human-computer interaction, yet\ncurrent speech language models often remain constrained to turn-based\nexchanges, lacking real-time adaptability such as user barge-in. We propose a\nnovel duplex speech to speech (S2S) architecture featuring continuous user\ninputs and codec agent outputs with channel fusion that directly models\nsimultaneous user and agent streams. Using a pretrained streaming encoder for\nuser input enables the first duplex S2S model without requiring speech\npretrain. Separate architectures for agent and user modeling facilitate codec\nfine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared\nto previous works. Experimental results show that the proposed model\noutperforms previous duplex models in reasoning, turn-taking, and barge-in\nabilities. The model requires significantly less speech data, as speech\npretrain is skipped, which markedly simplifies the process of building a duplex\nS2S model from any LLMs. Finally, it is the first openly available duplex S2S\nmodel with training and inference code to foster reproducibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.15670v4",
    "published": "2025-05-21T15:48:30+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17115v2",
    "title": "Swarm Intelligence Enhanced Reasoning: A Density-Driven Framework for LLM-Based Multi-Agent Optimization",
    "authors": [
      "Ying Zhu",
      "Heng Zhou",
      "Rui Su",
      "Peiqin Zhuang",
      "Lei Bai"
    ],
    "abstract": "Recently, many approaches, such as Chain-of-Thought (CoT) prompting and\nMulti-Agent Debate (MAD), have been proposed to further enrich Large Language\nModels' (LLMs) complex problem-solving capacities in reasoning scenarios.\nHowever, these methods may fail to solve complex problems due to the lack of\nability to find optimal solutions. Swarm Intelligence has been serving as a\npowerful tool for finding optima in the field of traditional optimization\nproblems. To this end, we propose integrating swarm intelligence into the\nreasoning process by introducing a novel Agent-based Swarm Intelligence (ASI)\nparadigm. In this paradigm, we formulate LLM reasoning as an optimization\nproblem and use a swarm intelligence scheme to guide a group of LLM-based\nagents in collaboratively searching for optimal solutions. To avoid swarm\nintelligence getting trapped in local optima, we further develop a Swarm\nIntelligence Enhancing Reasoning (SIER) framework, which develops a\ndensity-driven strategy to enhance the reasoning ability. To be specific, we\npropose to perform kernel density estimation and non-dominated sorting to\noptimize both solution quality and diversity simultaneously. In this case, SIER\nefficiently enhances solution space exploration through expanding the diversity\nof the reasoning path. Besides, a step-level quality evaluation is used to help\nagents improve solution quality by correcting low-quality intermediate steps.\nThen, we use quality thresholds to dynamically control the termination of\nexploration and the selection of candidate steps, enabling a more flexible and\nefficient reasoning process. Extensive experiments are ...",
    "pdf_url": "http://arxiv.org/pdf/2505.17115v2",
    "published": "2025-05-21T15:48:13+00:00",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15669v1",
    "title": "Measurement-free quantum error correction optimized for biased noise",
    "authors": [
      "Katharina Brechtelsbauer",
      "Friederike Butt",
      "David F. Locher",
      "Santiago Higuera Quintero",
      "Sebastian Weber",
      "Markus M√ºller",
      "Hans Peter B√ºchler"
    ],
    "abstract": "In this paper, we derive optimized measurement-free protocols for quantum\nerror correction and the implementation of a universal gate set optimized for\nan error model that is noise biased . The noise bias is adapted for neutral\natom platforms, where two- and multi-qubit gates are realized with Rydberg\ninteractions and are thus expected to be the dominating source of noise.\nCareful design of the gates allows to further reduce the noise model to Pauli-Z\nerrors. In addition, the presented circuits are robust to arbitrary\nsingle-qubit gate errors, and we demonstrate that the break-even point can be\nsignificantly improved compared to fully fault-tolerant measurement-free\nschemes. The obtained logical qubits with their suppressed error rates on\nlogical gate operations can then be used as building blocks in a first step of\nerror correction in order to push the effective error rates below the threshold\nof a fully fault-tolerant and scalable quantum error correction scheme.",
    "pdf_url": "http://arxiv.org/pdf/2505.15669v1",
    "published": "2025-05-21T15:46:13+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15668v1",
    "title": "Graph Conditional Flow Matching for Relational Data Generation",
    "authors": [
      "Davide Scassola",
      "Sebastiano Saccani",
      "Luca Bortolussi"
    ],
    "abstract": "Data synthesis is gaining momentum as a privacy-enhancing technology. While\nsingle-table tabular data generation has seen considerable progress, current\nmethods for multi-table data often lack the flexibility and expressiveness\nneeded to capture complex relational structures. In particular, they struggle\nwith long-range dependencies and complex foreign-key relationships, such as\ntables with multiple parent tables or multiple types of links between the same\npair of tables. We propose a generative model for relational data that\ngenerates the content of a relational dataset given the graph formed by the\nforeign-key relationships. We do this by learning a deep generative model of\nthe content of the whole relational database by flow matching, where the neural\nnetwork trained to denoise records leverages a graph neural network to obtain\ninformation from connected records. Our method is flexible, as it can support\nrelational datasets with complex structures, and expressive, as the generation\nof each record can be influenced by any other record within the same connected\ncomponent. We evaluate our method on several benchmark datasets and show that\nit achieves state-of-the-art performance in terms of synthetic data fidelity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15668v1",
    "published": "2025-05-21T15:45:15+00:00",
    "categories": [
      "cs.LG",
      "68T07"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15667v1",
    "title": "Segmentation-Variant Codebooks for Preservation of Paralinguistic and Prosodic Information",
    "authors": [
      "Nicholas Sanders",
      "Yuanchao Li",
      "Korin Richmond",
      "Simon King"
    ],
    "abstract": "Quantization in SSL speech models (e.g., HuBERT) improves compression and\nperformance in tasks like language modeling, resynthesis, and text-to-speech\nbut often discards prosodic and paralinguistic information (e.g., emotion,\nprominence). While increasing codebook size mitigates some loss, it\ninefficiently raises bitrates. We propose Segmentation-Variant Codebooks\n(SVCs), which quantize speech at distinct linguistic units (frame, phone, word,\nutterance), factorizing it into multiple streams of segment-specific discrete\nfeatures. Our results show that SVCs are significantly more effective at\npreserving prosodic and paralinguistic information across probing tasks.\nAdditionally, we find that pooling before rather than after discretization\nbetter retains segment-level information. Resynthesis experiments further\nconfirm improved style realization and slightly improved quality while\npreserving intelligibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.15667v1",
    "published": "2025-05-21T15:44:32+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15666v2",
    "title": "Shubnikov-de Haas Oscillations in 2D $\\text{PtSe}_2$: A fermiological Charge Carrier Investigation",
    "authors": [
      "Julian Max Salchegger",
      "Rajdeep Adhikari",
      "Bogdan Faina",
      "Alberta Bonanni"
    ],
    "abstract": "High magnetic field and low temperature transport is carried out in order to\ncharacterize the charge carriers of $\\text{PtSe}_2$. In particular, the\nShubnikov-de Haas oscillations arising at applied magnetic field strengths\n$\\gtrsim 4.5\\,\\text{T}$ are found to occur exclusively in plane and emerge at a\nlayer thickness of $\\approx 18\\,\\text{nm}$, increasing in amplitude and\ndecreasing in frequency for thinner $\\text{PtSe}_2$ flakes. Moreover, the\nquantum transport time, Berry phase, Dingle temperature and cyclotron mass of\nthe charge carriers are ascertained. The emergence of weak antilocalization\n(WAL) lies in contrast to the presence of magnetic moments from Pt vacancies.\nAn explanation is provided on how WAL and the Kondo effect can be observed\nwithin the same material. Detailed information about the charge carriers and\ntransport phenomena in $\\text{PtSe}_2$ is obtained, which is relevant for the\ndesign of prospective spintronic and orbitronic devices and for the realization\nof orbital Hall effect-based architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.15666v2",
    "published": "2025-05-21T15:43:00+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15665v1",
    "title": "Analysis and Simulation of Generalized Langevin Equations with Non-Gaussian Orthogonal Forces",
    "authors": [
      "Henrik Kiefer",
      "Benjamin J. A. H√©ry",
      "Lucas Tepper",
      "Benjamin A. Dalton",
      "Cihan Ayaz",
      "Roland R. Netz"
    ],
    "abstract": "The generalized Langevin equation (GLE) is a useful framework for analyzing\nand modeling the dynamics of many-body systems in terms of low-dimensional\nreaction coordinates, with its specific form determined by the choice of\nprojection formalism. We compare parameters derived from different GLE\nformulations using molecular dynamics simulations of butane's dihedral angle\ndynamics. Our analysis reveals non-Gaussian contributions of the orthogonal\nforce in different GLEs, being most enhanced for the Mori-GLE, where all\nnon-linearities are relegated to the orthogonal force. We establish a\nsimulation technique that correctly accounts for non-Gaussian orthogonal\nforces, which is critical for accurately predicting dihedral-angle mean\nfirst-passage times. We find that the accuracy of GLE simulations depends\nsignificantly on the chosen GLE formalism; the Mori-GLE offers the most\nnumerically robust framework for capturing the statistical observables of the\ndihedral angle dynamics, provided the correct non-Gaussian orthogonal force\ndistribution is used.",
    "pdf_url": "http://arxiv.org/pdf/2505.15665v1",
    "published": "2025-05-21T15:41:07+00:00",
    "categories": [
      "physics.comp-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15874v1",
    "title": "Text-to-Pipeline: Bridging Natural Language and Data Preparation Pipelines",
    "authors": [
      "Yuhang Ge",
      "Yachuan Liu",
      "Yuren Mao",
      "Yunjun Gao"
    ],
    "abstract": "Data preparation (DP) transforms raw data into a form suitable for downstream\napplications, typically by composing operations into executable pipelines.\nBuilding such pipelines is time-consuming and requires sophisticated\nprogramming skills. If we can build the pipelines with natural language (NL),\nthe technical barrier of DP will be significantly reduced. However,\nconstructing DP pipelines from NL instructions remains underexplored. To fill\nthe gap, we introduce Text-to-Pipeline, a new task that translates NL data\npreparation instructions into DP pipelines. Furthermore, we develop a benchmark\nnamed PARROT to support systematic evaluation. To simulate realistic DP\nscenarios, we mined transformation patterns from production pipelines and\ninstantiated them on 23,009 real-world tables collected from six public\nsources. The resulting benchmark comprises ~18,000 pipelines covering 16 core\nDP operators. We evaluated cutting-edge large language models on PARROTand\nobserved that they only solved 72.86% of the cases, revealing notable\nlimitations in instruction understanding and multi-step reasoning. To address\nthis, we propose Pipeline-Agent, a stronger baseline that iteratively predicts\nand executes operations with intermediate table feedback, achieving the best\nperformance of 76.17%. Despite this improvement, there remains substantial room\nfor progress on Text-to-Pipeline. Our data, codes, and evaluation tools are\navailable at https://anonymous.4open.science/r/Text-to-Pipeline.",
    "pdf_url": "http://arxiv.org/pdf/2505.15874v1",
    "published": "2025-05-21T15:40:53+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15664v1",
    "title": "$q$-analogues of Fisher's inequality and oddtown theorem",
    "authors": [
      "Hiranya Kishore Dey"
    ],
    "abstract": "A classical result in design theory, known as Fisher's inequality, states\nthat if every pair of clubs in a town shares the same number of members, then\nthe number of clubs cannot exceed the number of inhabitants in the town. In\nthis short note, we establish a $q$-analogue of Fisher's inequality.\nAdditionally, we present a $q$-analogue of the oddtown theorem for the case\nwhen $q$ is an odd prime power.",
    "pdf_url": "http://arxiv.org/pdf/2505.15664v1",
    "published": "2025-05-21T15:40:37+00:00",
    "categories": [
      "math.CO",
      "05D05, 05A30"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15663v1",
    "title": "Lithium Intercalation in the Anisotropic van der Waals Magnetic Semiconductor CrSBr",
    "authors": [
      "Kseniia Mosina",
      "Aljoscha S√∂ll",
      "Jiri Sturala",
      "Martin Vesel√Ω",
      "Petr Levinsk√Ω",
      "Florian Dirnberger",
      "Giuliana Materzanini",
      "Nicola Marzari",
      "Gian-Marco Rignanese",
      "Borna Radatoviƒá",
      "David Sedmidubsky",
      "Zdenƒõk Sofer"
    ],
    "abstract": "Alkali metal intercalation is an important strategy for doping van der Waals\nmaterials. Lithium, in particular, was shown to achieve exceptional charge\ncarrier densities, reaching levels at which fundamental electrical, optical,\nand magnetic material properties begin to be strongly modified. While lithium\nis known to be highly volatile, its migration dynamics in anisotropic layered\ncrystals remain poorly understood. In this work, we investigate the\nintercalation of lithium in-between layers of the anisotropic magnetic\nsemiconductor CrSBr. Using exfoliated crystals, we are able to monitor the\ndynamics of the intercalation process in real time through optical and\nelectrical characterization methods. Our measurements reveal highly anisotropic\nmigration of Lithium characterized by diffusion coefficients that differ by\nmore than one order of magnitude along a- and b-directions. This finding is in\ngood agreement with our molecular dynamics simulations which show trajectories\nof lithium atoms primarily follow the Br-chains in the a-direction. Beyond\nthat, we find that partially covering CrSBr crystals by thin hexagonal boron\nnitride (hBN) flakes has a significant impact on the intercalation process, and\nthat lithium strongly enhances the electrical conductivity along the a-axis.\nOur method offers a new platform for lithium diffusion studies and encourages\nfurther research to pursue the fabrication of lithium-doped devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15663v1",
    "published": "2025-05-21T15:39:35+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15662v1",
    "title": "Neural Quantum Digital Twins for Optimizing Quantum Annealing",
    "authors": [
      "Jianlong Lu",
      "Hanqiu Peng",
      "Ying Chen"
    ],
    "abstract": "Quantum annealers have shown potential in addressing certain combinatorial\noptimization problems, though their performance is often limited by scalability\nand errors rates. In this work, we propose a Neural Quantum Digital Twin (NQDT)\nframework that reconstructs the energy landscape of quantum many-body systems\nrelevant to quantum annealing. The digital twin models both ground and excited\nstate dynamics, enabling detailed simulation of the adiabatic evolution\nprocess. We benchmark NQDT on systems with known analytical solutions and\ndemonstrate that it accurately captures key quantum phenomena, including\nquantum criticality and phase transitions. Leveraging this framework, one can\nidentify optimal annealing schedules that minimize excitation-related errors.\nThese findings highlight the utility of neural network-based digital twins as a\ndiagnostic and optimization tool for improving the performance of quantum\nannealers.",
    "pdf_url": "http://arxiv.org/pdf/2505.15662v1",
    "published": "2025-05-21T15:38:55+00:00",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15661v1",
    "title": "Deep greedy unfolding: Sorting out argsorting in greedy sparse recovery algorithms",
    "authors": [
      "Sina Mohammad-Taheri",
      "Matthew J. Colbrook",
      "Simone Brugiapaglia"
    ],
    "abstract": "Gradient-based learning imposes (deep) neural networks to be differentiable\nat all steps. This includes model-based architectures constructed by unrolling\niterations of an iterative algorithm onto layers of a neural network, known as\nalgorithm unrolling. However, greedy sparse recovery algorithms depend on the\nnon-differentiable argsort operator, which hinders their integration into\nneural networks. In this paper, we address this challenge in Orthogonal\nMatching Pursuit (OMP) and Iterative Hard Thresholding (IHT), two popular\nrepresentative algorithms in this class. We propose permutation-based variants\nof these algorithms and approximate permutation matrices using \"soft\"\npermutation matrices derived from softsort, a continuous relaxation of argsort.\nWe demonstrate -- both theoretically and numerically -- that Soft-OMP and\nSoft-IHT, as differentiable counterparts of OMP and IHT and fully compatible\nwith neural network training, effectively approximate these algorithms with a\ncontrollable degree of accuracy. This leads to the development of OMP- and\nIHT-Net, fully trainable network architectures based on Soft-OMP and Soft-IHT,\nrespectively. Finally, by choosing weights as \"structure-aware\" trainable\nparameters, we connect our approach to structured sparse recovery and\ndemonstrate its ability to extract latent sparsity patterns from data.",
    "pdf_url": "http://arxiv.org/pdf/2505.15661v1",
    "published": "2025-05-21T15:36:38+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "cs.NE",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15660v2",
    "title": "Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization",
    "authors": [
      "Jiaming Zhou",
      "Ke Ye",
      "Jiayi Liu",
      "Teli Ma",
      "Zifan Wang",
      "Ronghe Qiu",
      "Kun-Yu Lin",
      "Zhilin Zhao",
      "Junwei Liang"
    ],
    "abstract": "The generalization capabilities of vision-language-action (VLA) models to\nunseen tasks are crucial to achieving general-purpose robotic manipulation in\nopen-world settings. However, the cross-task generalization capabilities of\nexisting VLA models remain significantly underexplored. To address this gap, we\nintroduce AGNOSTOS, a novel simulation benchmark designed to rigorously\nevaluate cross-task zero-shot generalization in manipulation. AGNOSTOS\ncomprises 23 unseen manipulation tasks for testing, distinct from common\ntraining task distributions, and incorporates two levels of generalization\ndifficulty to assess robustness. Our systematic evaluation reveals that current\nVLA models, despite being trained on diverse datasets, struggle to generalize\neffectively to these unseen tasks. To overcome this limitation, we propose\nCross-Task In-Context Manipulation (X-ICM), a method that conditions large\nlanguage models (LLMs) on in-context demonstrations from seen tasks to predict\naction sequences for unseen tasks. Additionally, we introduce a dynamics-guided\nsample selection strategy that identifies relevant demonstrations by capturing\ncross-task dynamics. On AGNOSTOS, X-ICM significantly improves cross-task\nzero-shot generalization performance over leading VLAs. We believe AGNOSTOS and\nX-ICM will serve as valuable tools for advancing general-purpose robotic\nmanipulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15660v2",
    "published": "2025-05-21T15:35:57+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15873v2",
    "title": "Abstractions-of-Thought: Intermediate Representations for LLM Reasoning in Hardware Design",
    "authors": [
      "Matthew DeLorenzo",
      "Kevin Tieu",
      "Prithwish Jana",
      "Piyush Jha",
      "Dileep Kalathil",
      "Vijay Ganesh",
      "Jeyavijayan Rajendran"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive proficiency on logic\nand programming tasks, often rivaling expert-level performance. However,\ngenerating functionally correct hardware description language (HDL) code from\nnatural language specifications remains challenging, primarily in data-scarce\ndomains.\n  Therefore, we present Abstractions-of-Thought (AoT) - a training-free,\ninference-only prompting framework to mitigate misinterpretations and reasoning\npitfalls of LLMs through a series of task-based abstractions within the\nprompting procedure, assisting in the transition from high-level to low-level\nrepresentations of hardware. Furthermore, AoT consists of the following stages:\n(1) an LLM-based classification of hardware design patterns, (2) a structured\nintermediate representation (IR) to separate functional decomposition from code\nsyntax, and (3) a line-by-line pseudocode solution enabling a more direct\nmapping to the final Verilog implementation. Experimental results on the\nVerilogEval benchmark depict that AoT demonstrates improvements in\nfunctionality when applied to large non-reasoning models (such as GPT-4o,\noutperforming all baseline techniques (including 1-shot, Chain-of-Thought, and\nTree-of-Thought) while significantly reducing the generated tokens by 1.8-5.2x\ncompared to popular Tree-of-Thought prompting.",
    "pdf_url": "http://arxiv.org/pdf/2505.15873v2",
    "published": "2025-05-21T15:34:00+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15659v1",
    "title": "FLARE: Robot Learning with Implicit World Modeling",
    "authors": [
      "Ruijie Zheng",
      "Jing Wang",
      "Scott Reed",
      "Johan Bjorck",
      "Yu Fang",
      "Fengyuan Hu",
      "Joel Jang",
      "Kaushil Kundalia",
      "Zongyu Lin",
      "Loic Magne",
      "Avnish Narayan",
      "You Liang Tan",
      "Guanzhi Wang",
      "Qi Wang",
      "Jiannan Xiang",
      "Yinzhen Xu",
      "Seonghyeon Ye",
      "Jan Kautz",
      "Furong Huang",
      "Yuke Zhu",
      "Linxi Fan"
    ],
    "abstract": "We introduce $\\textbf{F}$uture $\\textbf{LA}$tent $\\textbf{RE}$presentation\nAlignment ($\\textbf{FLARE}$), a novel framework that integrates predictive\nlatent world modeling into robot policy learning. By aligning features from a\ndiffusion transformer with latent embeddings of future observations,\n$\\textbf{FLARE}$ enables a diffusion transformer policy to anticipate latent\nrepresentations of future observations, allowing it to reason about long-term\nconsequences while generating actions. Remarkably lightweight, $\\textbf{FLARE}$\nrequires only minimal architectural modifications -- adding a few tokens to\nstandard vision-language-action (VLA) models -- yet delivers substantial\nperformance gains. Across two challenging multitask simulation imitation\nlearning benchmarks spanning single-arm and humanoid tabletop manipulation,\n$\\textbf{FLARE}$ achieves state-of-the-art performance, outperforming prior\npolicy learning baselines by up to 26%. Moreover, $\\textbf{FLARE}$ unlocks the\nability to co-train with human egocentric video demonstrations without action\nlabels, significantly boosting policy generalization to a novel object with\nunseen geometry with as few as a single robot demonstration. Our results\nestablish $\\textbf{FLARE}$ as a general and scalable approach for combining\nimplicit world modeling with high-frequency robotic control.",
    "pdf_url": "http://arxiv.org/pdf/2505.15659v1",
    "published": "2025-05-21T15:33:27+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15658v1",
    "title": "Energy Conservation and Vanishing Viscosity Limit for the Primitive Equations",
    "authors": [
      "≈†√°rka Neƒçasov√°",
      "Tong Tang",
      "Emil Wiedemann",
      "Lu Zhu"
    ],
    "abstract": "In this paper, we consider the problem of energy conservation for weak\nsolutions of the inviscid Primitive Equations (PE) in a bounded domain. Based\non the work [Bardos et al., Onsager's conjecture with physical boundaries and\nan application to the vanishing viscosity limit, Comm. Math. Phys., 2019,\n291-310], we prove the energy conservation for PE with boundary condition under\nsuitable Onsager-type assumptions. But due to the special structure of PE\nsystem and its domain, some new challenging difficulties arise: the lack of\ninformation about the vertical velocity, and existing corner points in the\ndomain. We introduce some new ideas to overcome the above obstacles. As a\nbyproduct, we give a sufficient condition for absence of anomalous energy\ndissipation in the vanishing viscosity limit.",
    "pdf_url": "http://arxiv.org/pdf/2505.15658v1",
    "published": "2025-05-21T15:33:02+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15657v1",
    "title": "LCDB 1.1: A Database Illustrating Learning Curves Are More Ill-Behaved Than Previously Thought",
    "authors": [
      "Cheng Yan",
      "Felix Mohr",
      "Tom Viering"
    ],
    "abstract": "Sample-wise learning curves plot performance versus training set size. They\nare useful for studying scaling laws and speeding up hyperparameter tuning and\nmodel selection. Learning curves are often assumed to be well-behaved: monotone\n(i.e. improving with more data) and convex. By constructing the Learning Curves\nDatabase 1.1 (LCDB 1.1), a large-scale database with high-resolution learning\ncurves, we show that learning curves are less often well-behaved than\npreviously thought. Using statistically rigorous methods, we observe\nsignificant ill-behavior in approximately 14% of the learning curves, almost\ntwice as much as in previous estimates. We also identify which learners are to\nblame and show that specific learners are more ill-behaved than others.\nAdditionally, we demonstrate that different feature scalings rarely resolve\nill-behavior. We evaluate the impact of ill-behavior on downstream tasks, such\nas learning curve fitting and model selection, and find it poses significant\nchallenges, underscoring the relevance and potential of LCDB 1.1 as a\nchallenging benchmark for future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15657v1",
    "published": "2025-05-21T15:32:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15656v1",
    "title": "Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!",
    "authors": [
      "Zhexin Zhang",
      "Yuhao Sun",
      "Junxiao Yang",
      "Shiyao Cui",
      "Hongning Wang",
      "Minlie Huang"
    ],
    "abstract": "Fine-tuning on open-source Large Language Models (LLMs) with proprietary data\nis now a standard practice for downstream developers to obtain task-specific\nLLMs. Surprisingly, we reveal a new and concerning risk along with the\npractice: the creator of the open-source LLMs can later extract the private\ndownstream fine-tuning data through simple backdoor training, only requiring\nblack-box access to the fine-tuned downstream model. Our comprehensive\nexperiments, across 4 popularly used open-source models with 3B to 32B\nparameters and 2 downstream datasets, suggest that the extraction performance\ncan be strikingly high: in practical settings, as much as 76.3% downstream\nfine-tuning data (queries) out of a total 5,000 samples can be perfectly\nextracted, and the success rate can increase to 94.9% in more ideal settings.\nWe also explore a detection-based defense strategy but find it can be bypassed\nwith improved attack. Overall, we highlight the emergency of this newly\nidentified data breaching risk in fine-tuning, and we hope that more follow-up\nresearch could push the progress of addressing this concerning risk. The code\nand data used in our experiments are released at\nhttps://github.com/thu-coai/Backdoor-Data-Extraction.",
    "pdf_url": "http://arxiv.org/pdf/2505.15656v1",
    "published": "2025-05-21T15:32:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15655v1",
    "title": "First-order transducibility among classes of sparse graphs",
    "authors": [
      "Jakub Gajarsk√Ω",
      "Jeremi G≈Çadkowski",
      "Jan Jedelsk√Ω",
      "Micha≈Ç Pilipczuk",
      "Szymon Toru≈Ñczyk"
    ],
    "abstract": "We prove several negative results about first-order transducibility for\nclasses of sparse graphs:\n  - for every $t \\in \\mathbb{N}$, the class of graphs of treewidth at most\n$t+1$ is not transducible from the class of graphs of treewidth at most $t$;\n  - for every $t \\in \\mathbb{N}$, the class of graphs with Hadwiger number at\nmost $t+2$ is not transducible from the class of graphs with Hadwiger number at\nmost $t$; and\n  - the class of graphs of treewidth at most $4$ is not transducible from the\nclass of planar graphs.\n  These results are obtained by combining the known upper and lower bounds on\nthe weak coloring numbers of the considered graph classes with the following\ntwo new observations:\n  - If a weakly sparse graph class $\\mathscr D$ is transducible from a class\n$\\mathscr C$ of bounded expansion, then for some $k \\in \\mathbb{N}$, every\ngraph $G \\in \\mathscr D$ is a $k$-congested depth-$k$ minor of a graph\n$H^\\circ$ obtained from some $H\\in \\mathscr C$ by adding a universal vertex.\n  - The operations of adding a universal vertex and of taking $k$-congested\ndepth-$k$ minors, for a fixed $k$, preserve the degree of the distance-$d$ weak\ncoloring number of a graph class, understood as a polynomial in $d$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15655v1",
    "published": "2025-05-21T15:31:33+00:00",
    "categories": [
      "cs.LO",
      "cs.DM",
      "math.CO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15654v1",
    "title": "Round Elimination via Self-Reduction: Closing Gaps for Distributed Maximal Matching",
    "authors": [
      "Seri Khoury",
      "Aaron Schild"
    ],
    "abstract": "In this work, we present an $\\Omega\\left(\\min\\{\\log \\Delta, \\sqrt{\\log\nn}\\}\\right)$ lower bound for Maximal Matching (MM) in $\\Delta$-ary trees\nagainst randomized algorithms. By a folklore reduction, the same lower bound\napplies to Maximal Independent Set (MIS), albeit not in trees. As a function of\n$n$, this is the first advancement in our understanding of the randomized\ncomplexity of the two problems in more than two decades. As a function of\n$\\Delta$, this shows that the current upper bounds are optimal for a wide range\nof $\\Delta \\in 2^{O(\\sqrt{\\log n})}$, answering an open question by Balliu,\nBrandt, Hirvonen, Olivetti, Rabie, and Suomela [FOCS'19, JACM'21].\n  Moreover, our result implies a surprising and counterintuitive separation\nbetween MIS and MM in trees, as it was very recently shown that MIS in trees\ncan be solved in $o(\\sqrt{\\log n})$ rounds. While MIS can be used to find an MM\nin general graphs, the reduction does not preserve the tree structure when\napplied to trees. Our separation shows that this is not an artifact of the\nreduction, but a fundamental difference between the two problems in trees. This\nalso implies that MIS is strictly harder in general graphs compared to trees.",
    "pdf_url": "http://arxiv.org/pdf/2505.15654v1",
    "published": "2025-05-21T15:31:32+00:00",
    "categories": [
      "cs.DC",
      "cs.DS"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15653v2",
    "title": "Quantifying structural uncertainty in chemical reaction network inference",
    "authors": [
      "Yong See Foo",
      "Adriana Zanca",
      "Jennifer A. Flegg",
      "Ivo Siekmann"
    ],
    "abstract": "Dynamical systems in chemistry and biology are complex, and one often does\nnot have comprehensive knowledge about the interactions involved. Chemical\nreaction network (CRN) inference aims to identify, from observing species\nconcentrations over time, the unknown reactions between the species. Existing\napproaches largely focus on identifying a single, most likely CRN, without\naddressing uncertainty about the network structure. However, it is important to\nquantify structural uncertainty to have confidence in our inference and\npredictions. In this work, we do so by inferring an approximate posterior\ndistribution over CRN structures. This is done by keeping a large set of\nsuboptimal solutions found through sparse optimisation, in contrast to existing\noptimisation approaches which discard suboptimal solutions. We find that\ninducing reaction sparsity with nonconvex penalty functions results in more\nparsimonious CRNs compared to the popular lasso regularisation. In a real-data\nexample where multiple CRNs have been previously suggested, our method\nsimultaneously recovers reactions proposed from different literature. Our\nemphasis on network-level probabilities enables a novel, hierarchical\nrepresentation of structural ambiguities in the space of CRNs. This readily\ntranslates into alternative reaction pathways suggested by the available data,\nthus guiding the efforts of future experimental design.",
    "pdf_url": "http://arxiv.org/pdf/2505.15653v2",
    "published": "2025-05-21T15:31:00+00:00",
    "categories": [
      "stat.ME",
      "q-bio.QM",
      "34A55, 62F07, 62F15",
      "G.3"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15652v1",
    "title": "Breaking Barriers for Distributed MIS by Faster Degree Reduction",
    "authors": [
      "Seri Khoury",
      "Aaron Schild"
    ],
    "abstract": "We study the problem of finding a maximal independent set (MIS) in the\nstandard LOCAL model of distributed computing. Classical algorithms by Luby\n[JACM'86] and Alon, Babai, and Itai [JALG'86] find an MIS in $O(\\log n)$ rounds\nin $n$-node graphs with high probability. Despite decades of research, the\nexistence of any $o(\\log n)$-round algorithm for general graphs remains one of\nthe major open problems in the field.\n  Interestingly, the hard instances for this problem must contain\nconstant-length cycles. This is because there exists a sublogarithmic-round\nalgorithm for graphs with super-constant girth; i.e., graphs where the length\nof the shortest cycle is $\\omega(1)$, as shown by Ghaffari~[SODA'16]. Thus,\nresolving this $\\approx 40$-year-old open problem requires understanding the\nfamily of graphs that contain $k$-cycles for some constant $k$.\n  In this work, we come very close to resolving this $\\approx 40$-year-old open\nproblem by presenting a sublogarithmic-round algorithm for graphs that can\ncontain $k$-cycles for all $k > 6$. Specifically, our algorithm finds an MIS in\n$O\\left(\\frac{\\log \\Delta}{\\log(\\log^* \\Delta)} + \\mathrm{poly}(\\log\\log\nn)\\right)$ rounds, as long as the graph does not contain cycles of length $\\leq\n6$, where $\\Delta$ is the maximum degree of the graph. As a result, we push the\nlimit on the girth of graphs that admit sublogarithmic-round algorithms from $k\n= \\omega(1)$ all the way down to a small constant $k=7$. This also implies a\n$o(\\sqrt{\\log n})$ round algorithm for MIS in trees, refuting a conjecture from\nthe book by Barrenboim and Elkin.",
    "pdf_url": "http://arxiv.org/pdf/2505.15652v1",
    "published": "2025-05-21T15:29:13+00:00",
    "categories": [
      "cs.DC",
      "cs.DS"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15651v1",
    "title": "Probing Scalar-Photon Coupling in the Early Universe: Implications for CMB Temperature and Anisotropies",
    "authors": [
      "Yousef Bisabr"
    ],
    "abstract": "The Hubble tension, as a persistent discrepancy between early-time and\nlate-time measurements of the Hubble constant, motivates explorations of new\nphysics in the early Universe. In a recent early dark energy (EDE) model, we\nintroduced a scalar field interacting with the radiation sector at early-time\nbefore recombination. We showed that such a scalar-photon coupling can lead to\nan accelerated expansion phase in which the energy density of scalar component\ndilutes faster than\n  radiation does, a crucial feature for a successful EDE model. In the present\nwork, we extend our analysis to investigate how this scalar-photon coupling\naffects the CMB temperature-redshift law and CMB anisotropies. We demonstrate\nthat the temperature-redshift law deviates from the standard relation\n$T(z)\\propto (1+z)$ due to the scalar-photon coupling. This deviation is\ncontrolled by a model parameter $\\epsilon$, which quantifies the rate of energy\ntransfer between the scalar field and radiation. We also argue that a positive\nvalue of $\\epsilon$ shifts the acoustic peaks to larger scales, which\npotentially alleviates the Hubble tension. These findings suggest that\nscalar-photon coupling is a testable mechanism for reconciling different\ncosmological observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15651v1",
    "published": "2025-05-21T15:29:08+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15650v1",
    "title": "Testing the nature of the $Œ£^*(1430)$",
    "authors": [
      "Jia-Xin Lin",
      "Jing Song",
      "Miguel Albaladejo",
      "Albert Feijoo",
      "Eulogio Oset"
    ],
    "abstract": "We study the feasibility of having the $\\Sigma^*(1430)$ state, predicted\nwithin the chiral unitary approach and recently reported by the Belle\nCollaboration, as corresponding to a state of non-molecular nature. Starting\nfrom this assumption, since the state is observed in the $\\pi \\Lambda$ channel,\nwe allow the coupling to this state and relate the coupling to $\\bar K N$ and\n$\\pi \\Sigma$ using $SU(3)$ symmetry arguments. We find that it is possible to\nhave such a state with negligible coupling to the molecular components with a\nbare mass of the state very close to the physical mass of the $\\Sigma^*(1430)$.\nYet, this has consequences on other observables, since the width obtained is\nextremely small and incompatible with the Belle observations, and it leads to\nabnormally large values of the $\\bar K N$ effective range. Conversely, such\nmismatches do not appear for large values of the bare mass of the state, but in\nthis case we observe that the state develops large molecular components. While\none can rule out a largely non-molecular nature for this state, its properties\nand detailed nature will need further experimental developments which one can\nanticipate will be coming in the near future.",
    "pdf_url": "http://arxiv.org/pdf/2505.15650v1",
    "published": "2025-05-21T15:28:21+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15649v1",
    "title": "The Devil is in Fine-tuning and Long-tailed Problems:A New Benchmark for Scene Text Detection",
    "authors": [
      "Tianjiao Cao",
      "Jiahao Lyu",
      "Weichao Zeng",
      "Weimin Mu",
      "Yu Zhou"
    ],
    "abstract": "Scene text detection has seen the emergence of high-performing methods that\nexcel on academic benchmarks. However, these detectors often fail to replicate\nsuch success in real-world scenarios. We uncover two key factors contributing\nto this discrepancy through extensive experiments. First, a \\textit{Fine-tuning\nGap}, where models leverage \\textit{Dataset-Specific Optimization} (DSO)\nparadigm for one domain at the cost of reduced effectiveness in others, leads\nto inflated performances on academic benchmarks. Second, the suboptimal\nperformance in practical settings is primarily attributed to the long-tailed\ndistribution of texts, where detectors struggle with rare and complex\ncategories as artistic or overlapped text. Given that the DSO paradigm might\nundermine the generalization ability of models, we advocate for a\n\\textit{Joint-Dataset Learning} (JDL) protocol to alleviate the Fine-tuning\nGap. Additionally, an error analysis is conducted to identify three major\ncategories and 13 subcategories of challenges in long-tailed scene text, upon\nwhich we propose a Long-Tailed Benchmark (LTB). LTB facilitates a comprehensive\nevaluation of ability to handle a diverse range of long-tailed challenges. We\nfurther introduce MAEDet, a self-supervised learning-based method, as a strong\nbaseline for LTB. The code is available at https://github.com/pd162/LTB.",
    "pdf_url": "http://arxiv.org/pdf/2505.15649v1",
    "published": "2025-05-21T15:26:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15648v1",
    "title": "Learning Small Decision Trees with Few Outliers: A Parameterized Perspective",
    "authors": [
      "Harmender Gahlawat",
      "Meirav Zehavi"
    ],
    "abstract": "Decision trees are a fundamental tool in machine learning for representing,\nclassifying, and generalizing data. It is desirable to construct ``small''\ndecision trees, by minimizing either the \\textit{size} ($s$) or the\n\\textit{depth} $(d)$ of the \\textit{decision tree} (\\textsc{DT}). Recently, the\nparameterized complexity of \\textsc{Decision Tree Learning} has attracted a lot\nof attention. We consider a generalization of \\textsc{Decision Tree Learning}\nwhere given a \\textit{classification instance} $E$ and an integer $t$, the task\nis to find a ``small'' \\textsc{DT} that disagrees with $E$ in at most $t$\nexamples. We consider two problems: \\textsc{DTSO} and \\textsc{DTDO}, where the\ngoal is to construct a \\textsc{DT} minimizing $s$ and $d$, respectively. We\nfirst establish that both \\textsc{DTSO} and \\textsc{DTDO} are W[1]-hard when\nparameterized by $s+\\delta_{max}$ and $d+\\delta_{max}$, respectively, where\n$\\delta_{max}$ is the maximum number of features in which two differently\nlabeled examples can differ. We complement this result by showing that these\nproblems become \\textsc{FPT} if we include the parameter $t$. We also consider\nthe kernelization complexity of these problems and establish several positive\nand negative results for both \\textsc{DTSO} and \\textsc{DTDO}.",
    "pdf_url": "http://arxiv.org/pdf/2505.15648v1",
    "published": "2025-05-21T15:25:57+00:00",
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15647v1",
    "title": "Second-Order Convergence in Private Stochastic Non-Convex Optimization",
    "authors": [
      "Youming Tao",
      "Zuyuan Zhang",
      "Dongxiao Yu",
      "Xiuzhen Cheng",
      "Falko Dressler",
      "Di Wang"
    ],
    "abstract": "We investigate the problem of finding second-order stationary points (SOSP)\nin differentially private (DP) stochastic non-convex optimization. Existing\nmethods suffer from two key limitations: (i) inaccurate convergence error rate\ndue to overlooking gradient variance in the saddle point escape analysis, and\n(ii) dependence on auxiliary private model selection procedures for identifying\nDP-SOSP, which can significantly impair utility, particularly in distributed\nsettings. To address these issues, we propose a generic perturbed stochastic\ngradient descent (PSGD) framework built upon Gaussian noise injection and\ngeneral gradient oracles. A core innovation of our framework is using model\ndrift distance to determine whether PSGD escapes saddle points, ensuring\nconvergence to approximate local minima without relying on second-order\ninformation or additional DP-SOSP identification. By leveraging the adaptive\nDP-SPIDER estimator as a specific gradient oracle, we develop a new DP\nalgorithm that rectifies the convergence error rates reported in prior work. We\nfurther extend this algorithm to distributed learning with arbitrarily\nheterogeneous data, providing the first formal guarantees for finding DP-SOSP\nin such settings. Our analysis also highlights the detrimental impacts of\nprivate selection procedures in distributed learning under high-dimensional\nmodels, underscoring the practical benefits of our design. Numerical\nexperiments on real-world datasets validate the efficacy of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.15647v1",
    "published": "2025-05-21T15:25:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15646v1",
    "title": "Word Level Timestamp Generation for Automatic Speech Recognition and Translation",
    "authors": [
      "Ke Hu",
      "Krishna Puvvada",
      "Elena Rastorgueva",
      "Zhehuai Chen",
      "He Huang",
      "Shuoyang Ding",
      "Kunal Dhawan",
      "Hainan Xu",
      "Jagadeesh Balam",
      "Boris Ginsburg"
    ],
    "abstract": "We introduce a data-driven approach for enabling word-level timestamp\nprediction in the Canary model. Accurate timestamp information is crucial for a\nvariety of downstream tasks such as speech content retrieval and timed\nsubtitles. While traditional hybrid systems and end-to-end (E2E) models may\nemploy external modules for timestamp prediction, our approach eliminates the\nneed for separate alignment mechanisms. By leveraging the NeMo Forced Aligner\n(NFA) as a teacher model, we generate word-level timestamps and train the\nCanary model to predict timestamps directly. We introduce a new <|timestamp|>\ntoken, enabling the Canary model to predict start and end timestamps for each\nword. Our method demonstrates precision and recall rates between 80% and 90%,\nwith timestamp prediction errors ranging from 20 to 120 ms across four\nlanguages, with minimal WER degradation. Additionally, we extend our system to\nautomatic speech translation (AST) tasks, achieving timestamp prediction errors\naround 200 milliseconds.",
    "pdf_url": "http://arxiv.org/pdf/2505.15646v1",
    "published": "2025-05-21T15:24:29+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15645v1",
    "title": "Exploring future synergies for large-scale structure between gravitational waves and radio sources",
    "authors": [
      "Stefano Zazzera",
      "Jos√© Fonseca",
      "Tessa Baker",
      "Chris Clarkson"
    ],
    "abstract": "Future third-generation gravitational wave detectors like the Einstein\nTelescope (ET) and Cosmic Explorer (CE) are expected to detect millions of\nbinary black hole (BBH) mergers. Alongside these advances, upcoming radio\nsurveys, such as the Square Kilometer Array Observatory (SKAO) will provide new\nsets of cosmological tracers. These include mapping the large-scale\ndistribution of neutral hydrogen (HI) using intensity mapping (IM), HI galaxies\nand radio continuum galaxies. In this work, we will investigate synergies\nbetween gravitational waves (GW) and radio tracers through a multi-tracer\napproach. We first forecast the precision on the clustering bias of GWs by\ncross-correlating data from an ET-like detector with an SKAO IM survey. Our\nresults indicate that this approach can constrain the GW clustering bias to\nwithin $2\\%$ up to $z = 2.5$. Additionally, we explore the potential of a\ntriple cross-correlation using GWs, IM, and photometric galaxies from a survey\nlike LSST. This multi-tracer method enhances constraints on the magnification\nlensing effect, achieving percent-level precision, and allows for a measurement\nof the Doppler effect with approximately $15\\%$ uncertainty. Furthermore we\nshow for the first time that this method could achieve the precision required\nto measure subdominant gravitational potential contributions to the\nrelativistic corrections, which had thought to be below cosmic variance. Our\nanalysis highlights the potential of cross-correlations between GWs and radio\ntracers to improve constraints on astrophysical properties of BBHs, measure\nrelativistic effects, and perform null tests of GR in cosmological scales.",
    "pdf_url": "http://arxiv.org/pdf/2505.15645v1",
    "published": "2025-05-21T15:23:54+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.12026v1",
    "title": "LURK-T: Limited Use of Remote Keys With Added Trust in TLS 1.3",
    "authors": [
      "Behnam Shobiri",
      "Sajjad Pourali",
      "Daniel Migault",
      "Ioana Boureanu",
      "Stere Preda",
      "Mohammad Mannan",
      "Amr Youssef"
    ],
    "abstract": "In many web applications, such as Content Delivery Networks (CDNs), TLS\ncredentials are shared, e.g., between the website's TLS origin server and the\nCDN's edge servers, which can be distributed around the globe. To enhance the\nsecurity and trust for TLS 1.3 in such scenarios, we propose LURK-T, a provably\nsecure framework which allows for limited use of remote keys with added trust\nin TLS 1.3. We efficiently decouple the server side of TLS 1.3 into a LURK-T\nCrypto Service (CS) and a LURK-T Engine (E). CS executes all cryptographic\noperations in a Trusted Execution Environment (TEE), upon E's requests. CS and\nE together provide the whole TLS-server functionality. A major benefit of our\nconstruction is that it is application agnostic; the LURK-T Crypto Service\ncould be collocated with the LURK-T Engine, or it could run on different\nmachines. Thus, our design allows for in situ attestation and protection of the\ncryptographic side of the TLS server, as well as for all setups of CDNs over\nTLS. To support such a generic decoupling, we provide a full Application\nProgramming Interface (API) for LURK-T. To this end, we implement our LURK-T\nCrypto Service using Intel SGX and integrate it with OpenSSL. We also test\nLURK-T's efficiency and show that, from a TLS-client's perspective, HTTPS\nservers using LURK-T instead a traditional TLS-server have no noticeable\noverhead when serving files greater than 1MB. In addition, we provide\ncryptographic proofs and formal security verification using ProVerif.",
    "pdf_url": "http://arxiv.org/pdf/2506.12026v1",
    "published": "2025-05-21T15:23:17+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15644v1",
    "title": "FragFake: A Dataset for Fine-Grained Detection of Edited Images with Vision Language Models",
    "authors": [
      "Zhen Sun",
      "Ziyi Zhang",
      "Zeren Luo",
      "Zeyang Sha",
      "Tianshuo Cong",
      "Zheng Li",
      "Shiwen Cui",
      "Weiqiang Wang",
      "Jiaheng Wei",
      "Xinlei He",
      "Qi Li",
      "Qian Wang"
    ],
    "abstract": "Fine-grained edited image detection of localized edits in images is crucial\nfor assessing content authenticity, especially given that modern diffusion\nmodels and image editing methods can produce highly realistic manipulations.\nHowever, this domain faces three challenges: (1) Binary classifiers yield only\na global real-or-fake label without providing localization; (2) Traditional\ncomputer vision methods often rely on costly pixel-level annotations; and (3)\nNo large-scale, high-quality dataset exists for modern image-editing detection\ntechniques. To address these gaps, we develop an automated data-generation\npipeline to create FragFake, the first dedicated benchmark dataset for edited\nimage detection, which includes high-quality images from diverse editing models\nand a wide variety of edited objects. Based on FragFake, we utilize Vision\nLanguage Models (VLMs) for the first time in the task of edited image\nclassification and edited region localization. Experimental results show that\nfine-tuned VLMs achieve higher average Object Precision across all datasets,\nsignificantly outperforming pretrained models. We further conduct ablation and\ntransferability analyses to evaluate the detectors across various\nconfigurations and editing scenarios. To the best of our knowledge, this work\nis the first to reformulate localized image edit detection as a vision-language\nunderstanding task, establishing a new paradigm for the field. We anticipate\nthat this work will establish a solid foundation to facilitate and inspire\nsubsequent research endeavors in the domain of multimodal content authenticity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15644v1",
    "published": "2025-05-21T15:22:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15643v1",
    "title": "Optimal Best-Arm Identification under Fixed Confidence with Multiple Optima",
    "authors": [
      "Lan V. Truong"
    ],
    "abstract": "We study the problem of best-arm identification in stochastic multi-armed\nbandits under the fixed-confidence setting, with a particular focus on\ninstances that admit multiple optimal arms. While the Track-and-Stop algorithm\nof Garivier and Kaufmann (2016) is widely conjectured to be instance-optimal,\nits performance in the presence of multiple optima has remained insufficiently\nunderstood. In this work, we revisit the Track-and-Stop strategy and propose a\nmodified stopping rule that ensures instance-optimality even when the set of\noptimal arms is not a singleton. Our analysis introduces a new\ninformation-theoretic lower bound that explicitly accounts for multiple optimal\narms, and we demonstrate that our stopping rule tightly matches this bound.",
    "pdf_url": "http://arxiv.org/pdf/2505.15643v1",
    "published": "2025-05-21T15:22:37+00:00",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15642v1",
    "title": "Thermodynamically Admissible Diffuse Interface Model for Nanoscale Transport of Dense Fluids",
    "authors": [
      "Rahul Bhattacharjee",
      "Henning Struchtrup",
      "Anirudh Singh Rana"
    ],
    "abstract": "We investigate interfacial fluid dynamics and heat transfer at nanoscales\nusing an improved diffuse interface approach for liquid-vapor interfaces in\nnon-equilibrium. Conventional Navier-Stokes-Korteweg (NSK) formulations often\nfail to accurately capture transport phenomena across extremely thin interfaces\ndue to underestimation of interface resistances. In this work, we improve the\nNSK model by adding a production term in the momentum equation based on\nhigher-order corrections. To enhance interface resistances, viscosity and\nthermal conductivity are made dependent on the density gradient, increasing\nresistance only within the interface region. The gradient-based coefficients\nare determined by fitting to solutions of the Enskog-Vlasov equation for\nCouette flow (see Struchtrup and Frezzotti, 2022). Applying these fitted\nequations to pure heat conduction and planar evaporation problems shows that\nthe model accurately captures interfacial transport, making it a useful tool\nfor studying nanoscale evaporation, thermal management, and droplet dynamics on\nsolid surfaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.15642v1",
    "published": "2025-05-21T15:22:32+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.15641v1",
    "title": "A Simple Approximation Algorithm for Optimal Decision Tree",
    "authors": [
      "Zhengjia Zhuo",
      "Viswanath Nagarajan"
    ],
    "abstract": "Optimal decision tree (\\odt) is a fundamental problem arising in applications\nsuch as active learning, entity identification, and medical diagnosis. An\ninstance of \\odt is given by $m$ hypotheses, out of which an unknown ``true''\nhypothesis is drawn according to some probability distribution. An algorithm\nneeds to identify the true hypothesis by making queries: each query incurs a\ncost and has a known response for each hypothesis. The goal is to minimize the\nexpected query cost to identify the true hypothesis. We consider the most\ngeneral setting with arbitrary costs, probabilities and responses. \\odt is\nNP-hard to approximate better than $\\ln m$ and there are $O(\\ln m)$\napproximation algorithms known for it. However, these algorithms and/or their\nanalyses are quite complex. Moreover, the leading constant factors are large.\nWe provide a simple algorithm and analysis for \\odt, proving an approximation\nratio of $8 \\ln m$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15641v1",
    "published": "2025-05-21T15:21:56+00:00",
    "categories": [
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15640v1",
    "title": "Damping optimization of discrete mechanical systems -- rod/string model",
    "authors": [
      "Ninoslav Truhar",
      "Kre≈°imir Veseliƒá"
    ],
    "abstract": "This paper investigates two optimization criteria for damping optimization in\na multi-body oscillator system with arbitrary degrees of freedom ($n$),\nresembling string/rod free vibrations. The total average energy over all\npossible initial data and the total average displacement over all possible\ninitial data. Our first result shows that both criteria are equivalent to the\ntrace minimization of the solution of the Lyapunov equation with different\nright-hand sides. As the second result, we prove that in the case of damping\nwith one damper, for the discrete system, the minimal trace for each criterion\ncan be expressed as a linear or cubic function of the dimension $n$.\nConsequently, the optimal damping position is determined solely by the number\nof dominant eigenfrequencies and the optimal viscosity, independent of the\ndimension $n$, offering efficient damping optimization in discrete systems. The\npaper concludes with numerical examples illustrating the presented theoretical\nframework and results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15640v1",
    "published": "2025-05-21T15:19:59+00:00",
    "categories": [
      "math.OC",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15639v1",
    "title": "Time reversal of Brownian motion with Poissonian resetting",
    "authors": [
      "Fausto Colantoni",
      "Mirko D'Ovidio",
      "Gianni Pagnini"
    ],
    "abstract": "In this paper, we study reflecting Brownian motion with Poissonian resetting.\nAfter providing a probabilistic description of the phenomenon using jump\ndiffusions and semigroups, we analyze the time-reversed process starting from\nthe stationary measure. We prove that the time-reversed process is a Brownian\nmotion with a negative drift and non-local boundary conditions at zero.\nMoreover, we further study the time-reversed process between two consecutive\nresetting points and show that, within this time window, it behaves as the same\nreflecting Brownian motion with a negative drift, where both the jump sizes and\nthe time spent at zero coincide with those of the process obtained under the\nstationary measure. We characterize the dynamics of both processes, their local\ntimes, and finally investigate elliptic problems on positive half-spaces,\nshowing that the two processes leave the same traces at the boundary.",
    "pdf_url": "http://arxiv.org/pdf/2505.15639v1",
    "published": "2025-05-21T15:19:17+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15638v1",
    "title": "Bayesian Ensembling: Insights from Online Optimization and Empirical Bayes",
    "authors": [
      "Daniel Waxman",
      "Fernando Llorente",
      "Petar M. Djuriƒá"
    ],
    "abstract": "We revisit the classical problem of Bayesian ensembles and address the\nchallenge of learning optimal combinations of Bayesian models in an online,\ncontinual learning setting. To this end, we reinterpret existing approaches\nsuch as Bayesian model averaging (BMA) and Bayesian stacking through a novel\nempirical Bayes lens, shedding new light on the limitations and pathologies of\nBMA. Further motivated by insights from online optimization, we propose Online\nBayesian Stacking (OBS), a method that optimizes the log-score over predictive\ndistributions to adaptively combine Bayesian models. A key contribution of our\nwork is establishing a novel connection between OBS and portfolio selection,\nbridging Bayesian ensemble learning with a rich, well-studied theoretical\nframework that offers efficient algorithms and extensive regret analysis. We\nfurther clarify the relationship between OBS and online BMA, showing that they\noptimize related but distinct cost functions. Through theoretical analysis and\nempirical evaluation, we identify scenarios where OBS outperforms online BMA\nand provide principled guidance on when practitioners should prefer one\napproach over the other.",
    "pdf_url": "http://arxiv.org/pdf/2505.15638v1",
    "published": "2025-05-21T15:19:08+00:00",
    "categories": [
      "cs.LG",
      "stat.CO",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15637v1",
    "title": "Oral Imaging for Malocclusion Issues Assessments: OMNI Dataset, Deep Learning Baselines and Benchmarking",
    "authors": [
      "Pujun Xue",
      "Junyi Ge",
      "Xiaotong Jiang",
      "Siyang Song",
      "Zijian Wu",
      "Yupeng Huo",
      "Weicheng Xie",
      "Linlin Shen",
      "Xiaoqin Zhou",
      "Xiaofeng Liu",
      "Min Gu"
    ],
    "abstract": "Malocclusion is a major challenge in orthodontics, and its complex\npresentation and diverse clinical manifestations make accurate localization and\ndiagnosis particularly important. Currently, one of the major shortcomings\nfacing the field of dental image analysis is the lack of large-scale,\naccurately labeled datasets dedicated to malocclusion issues, which limits the\ndevelopment of automated diagnostics in the field of dentistry and leads to a\nlack of diagnostic accuracy and efficiency in clinical practice. Therefore, in\nthis study, we propose the Oral and Maxillofacial Natural Images (OMNI)\ndataset, a novel and comprehensive dental image dataset aimed at advancing the\nstudy of analyzing dental images for issues of malocclusion. Specifically, the\ndataset contains 4166 multi-view images with 384 participants in data\ncollection and annotated by professional dentists. In addition, we performed a\ncomprehensive validation of the created OMNI dataset, including three CNN-based\nmethods, two Transformer-based methods, and one GNN-based method, and conducted\nautomated diagnostic experiments for malocclusion issues. The experimental\nresults show that the OMNI dataset can facilitate the automated diagnosis\nresearch of malocclusion issues and provide a new benchmark for the research in\nthis field. Our OMNI dataset and baseline code are publicly available at\nhttps://github.com/RoundFaceJ/OMNI.",
    "pdf_url": "http://arxiv.org/pdf/2505.15637v1",
    "published": "2025-05-21T15:18:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15636v1",
    "title": "Distance Adaptive Beam Search for Provably Accurate Graph-Based Nearest Neighbor Search",
    "authors": [
      "Yousef Al-Jazzazi",
      "Haya Diwan",
      "Jinrui Gou",
      "Cameron Musco",
      "Christopher Musco",
      "Torsten Suel"
    ],
    "abstract": "Nearest neighbor search is central in machine learning, information\nretrieval, and databases. For high-dimensional datasets, graph-based methods\nsuch as HNSW, DiskANN, and NSG have become popular thanks to their empirical\naccuracy and efficiency. These methods construct a directed graph over the\ndataset and perform beam search on the graph to find nodes close to a given\nquery. While significant work has focused on practical refinements and\ntheoretical understanding of graph-based methods, many questions remain. We\npropose a new distance-based termination condition for beam search to replace\nthe commonly used condition based on beam width. We prove that, as long as the\nsearch graph is navigable, our resulting Adaptive Beam Search method is\nguaranteed to approximately solve the nearest-neighbor problem, establishing a\nconnection between navigability and the performance of graph-based search. We\nalso provide extensive experiments on our new termination condition for both\nnavigable graphs and approximately navigable graphs used in practice, such as\nHNSW and Vamana graphs. We find that Adaptive Beam Search outperforms standard\nbeam search over a range of recall values, data sets, graph constructions, and\ntarget number of nearest neighbors. It thus provides a simple and practical way\nto improve the performance of popular methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15636v1",
    "published": "2025-05-21T15:18:53+00:00",
    "categories": [
      "cs.IR",
      "cs.DB",
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15635v1",
    "title": "Relative phase and dynamical phase sensing in a Hamiltonian model of the optical SU(1,1) interferometer",
    "authors": [
      "T. J. Volkoff"
    ],
    "abstract": "The SU(1,1) interferometer introduced by Yurke, McCall, Klauder is\nreformulated starting from the Hamiltonian of two identical optical\ndownconversion processes with opposite pump phases. From the four optical\nmodes, two are singled out up to a relative phase by the assumption of exact\nalignment of the interferometer (i.e., mode indistinguishability). The state of\nthe two resulting modes is parametrized by the nonlinearity $g$, the relative\nphase $\\phi$, and a dynamical phase $\\theta$ resulting from the interaction\ntime. The optimal operating point for sensing the relative phase (dynamical\nphase) is found to be $\\phi = \\pi$ ($\\theta=0$) with quantum Fisher information\nexhibiting Heisenberg scaling $E^{2}$ (logarithmically modified Heisenberg\nscaling $\\left({E\\over \\ln E}\\right)^{2}$). Compared to the predictions of the\ncircuit-based model, we find in that in the Hamiltonian model: 1. the optimal\noperating points occur for a non-vacuum state inside the interferometer, and 2.\nmeasurement of the total photon number operator does not provide an estimate of\nthe relative or dynamical phase with precision that saturates the quantum\nCramer-Rao bound, whereas an observable based on weighted shift operators\nbecomes optimal as $g$ increases. The results indicate a first-principles\napproach for describing general optical quantum sensors containing multiple\noptical downconversion processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.15635v1",
    "published": "2025-05-21T15:18:18+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15634v4",
    "title": "Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models",
    "authors": [
      "Zihao Li",
      "Xu Wang",
      "Yuzhe Yang",
      "Ziyu Yao",
      "Haoyi Xiong",
      "Mengnan Du"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate the ability to solve reasoning and\nmathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT\nlength, as seen in models such as DeepSeek-R1, significantly enhances this\nreasoning for complex problems, but requires costly and high-quality long CoT\ndata and fine-tuning. This work, inspired by the deep thinking paradigm of\nDeepSeek-R1, utilizes a steering technique to enhance the reasoning ability of\nan LLM without external datasets. Our method first employs Sparse Autoencoders\n(SAEs) to extract interpretable features from vanilla CoT. These features are\nthen used to steer the LLM's internal states during generation. Recognizing\nthat many LLMs do not have corresponding pre-trained SAEs, we further introduce\na novel SAE-free steering algorithm, which directly computes steering\ndirections from the residual activations of an LLM, obviating the need for an\nexplicit SAE. Experimental results demonstrate that both our SAE-based and\nsubsequent SAE-free steering algorithms significantly enhance the reasoning\ncapabilities of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15634v4",
    "published": "2025-05-21T15:17:59+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15633v1",
    "title": "Listen to the Context: Towards Faithful Large Language Models for Retrieval Augmented Generation on Climate Questions",
    "authors": [
      "David Thulke",
      "Jakob Kemmler",
      "Christian Dugast",
      "Hermann Ney"
    ],
    "abstract": "Large language models that use retrieval augmented generation have the\npotential to unlock valuable knowledge for researchers, policymakers, and the\npublic by making long and technical climate-related documents more accessible.\nWhile this approach can help alleviate factual hallucinations by relying on\nretrieved passages as additional context, its effectiveness depends on whether\nthe model's output remains faithful to these passages. To address this, we\nexplore the automatic assessment of faithfulness of different models in this\nsetting. We then focus on ClimateGPT, a large language model specialised in\nclimate science, to examine which factors in its instruction fine-tuning impact\nthe model's faithfulness. By excluding unfaithful subsets of the model's\ntraining data, we develop ClimateGPT Faithful+, which achieves an improvement\nin faithfulness from 30% to 57% in supported atomic claims according to our\nautomatic metric.",
    "pdf_url": "http://arxiv.org/pdf/2505.15633v1",
    "published": "2025-05-21T15:17:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15632v1",
    "title": "Combining Progressive Image Compression and Random Access in DNA Data Storage",
    "authors": [
      "Xavier Pic",
      "Raja Appuswamy"
    ],
    "abstract": "The exponential increase in storage demand and low lifespan of data storage\ndevices has resulted in long-term archival and preservation emerging as a\ncritical bottlenecks in data storage. In order to meet this demand, researchers\nare now investigating novel forms of data storage media. The high density, long\nlifespan and low energy needs of synthetic DNA make it a promising candidate\nfor long-term data archival. However, current DNA data storage technologies are\nfacing challenges with respect to cost (writing data to DNA is expensive) and\nreliability (reading and writing data is error prone). Thus, data compression\nand error correction are crucial to scale DNA storage. Additionally, the DNA\nmolecules encoding several files are very often stored in the same place,\ncalled an oligo pool. For this reason, without random access solutions, it is\nrelatively impractical to decode a specific file from the pool, because all the\noligos from all the files need to first be sequenced, which greatly\ndeteriorates the read cost. This paper introduces PIC-DNA - a novel\nJPEG2000-based progressive image coder adapted to DNA data storage. This coder\ndirectly includes a random access process in its coding system, allowing for\nthe retrieval of a specific image from a pool of oligos encoding several\nimages. The progressive decoder can dynamically adapt the read cost according\nto the user's cost and quality constraints at decoding time. Both the random\naccess and progressive decoding greatly improve on the read-cost of image\ncoders adapted to DNA.",
    "pdf_url": "http://arxiv.org/pdf/2505.15632v1",
    "published": "2025-05-21T15:17:06+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15631v1",
    "title": "Guidelines for the Quality Assessment of Energy-Aware NAS Benchmarks",
    "authors": [
      "Nick Kocher",
      "Christian Wassermann",
      "Leona Hennig",
      "Jonas Seng",
      "Holger Hoos",
      "Kristian Kersting",
      "Marius Lindauer",
      "Matthias M√ºller"
    ],
    "abstract": "Neural Architecture Search (NAS) accelerates progress in deep learning\nthrough systematic refinement of model architectures. The downside is\nincreasingly large energy consumption during the search process.\nSurrogate-based benchmarking mitigates the cost of full training by querying a\npre-trained surrogate to obtain an estimate for the quality of the model.\nSpecifically, energy-aware benchmarking aims to make it possible for NAS to\nfavourably trade off model energy consumption against accuracy. Towards this\nend, we propose three design principles for such energy-aware benchmarks: (i)\nreliable power measurements, (ii) a wide range of GPU usage, and (iii) holistic\ncost reporting. We analyse EA-HAS-Bench based on these principles and find that\nthe choice of GPU measurement API has a large impact on the quality of results.\nUsing the Nvidia System Management Interface (SMI) on top of its underlying\nlibrary influences the sampling rate during the initial data collection,\nreturning faulty low-power estimations. This results in poor correlation with\naccurate measurements obtained from an external power meter. With this study,\nwe bring to attention several key considerations when performing energy-aware\nsurrogate-based benchmarking and derive first guidelines that can help design\nnovel benchmarks. We show a narrow usage range of the four GPUs attached to our\ndevice, ranging from 146 W to 305 W in a single-GPU setting, and narrowing down\neven further when using all four GPUs. To improve holistic energy reporting, we\npropose calibration experiments over assumptions made in popular tools, such as\nCode Carbon, thus achieving reductions in the maximum inaccuracy from 10.3 % to\n8.9 % without and to 6.6 % with prior estimation of the expected load on the\ndevice.",
    "pdf_url": "http://arxiv.org/pdf/2505.15631v1",
    "published": "2025-05-21T15:16:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15630v1",
    "title": "Permutons from Demazure Products",
    "authors": [
      "Colin Defant"
    ],
    "abstract": "We construct and analyze several new families of permutons arising from\nrandom processes involving the Demazure product on the symmetric group. First,\nwe consider Demazure products associated to random pipe dreams, generalizing\nthe Grothendieck permutons introduced by Morales, Panova, Petrov, and\nYeliussizov by replacing staircase shapes with arbitrary order-convex shapes.\nUsing the totally asymmetric simple exclusion process (TASEP) with geometric\njumps, we prove precise scaling limit and fluctuation results for the\nassociated height functions, showing that these models belong to the\nKardar--Parisi--Zhang (KPZ) universality class. We then consider permutons\nobtained by applying deterministic sequences of bubble-sort operators to random\ninitial permutations. We again provide precise descriptions of the limiting\npermutons. In a special case, we deduce the exact forms of the standard\nbubble-sort permutons, the supports of which were computed by DiFranco.\n  A crucial tool in our analysis is a formulation, due to Chan and Pflueger, of\nthe Demazure product as matrix multiplication in the min-plus tropical\nsemiring. This allows us to define a Demazure product on the set of permutons.\nWe discuss further applications of this product. For instance, we show that the\nnumber of inversions of the Demazure product of two independent uniformly\nrandom permutations of size $n$ is $\\binom{n}{2}(1-o(1))$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15630v1",
    "published": "2025-05-21T15:16:29+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.CO",
      "math.MP",
      "60C05, 05A05, 60K35"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15629v1",
    "title": "Relationship Analysis of Image-Text Pair in SNS Posts",
    "authors": [
      "Takuto Nabeoka",
      "Yijun Duan",
      "Qiang Ma"
    ],
    "abstract": "Social networking services (SNS) contain vast amounts of image-text posts,\nnecessitating effective analysis of their relationships for improved\ninformation retrieval. This study addresses the classification of image-text\npairs in SNS, overcoming prior limitations in distinguishing relationships\nbeyond similarity. We propose a graph-based method to classify image-text pairs\ninto similar and complementary relationships. Our approach first embeds images\nand text using CLIP, followed by clustering. Next, we construct an Image-Text\nRelationship Clustering Line Graph (ITRC-Line Graph), where clusters serve as\nnodes. Finally, edges and nodes are swapped in a pseudo-graph representation. A\nGraph Convolutional Network (GCN) then learns node and edge representations,\nwhich are fused with the original embeddings for final classification.\nExperimental results on a publicly available dataset demonstrate the\neffectiveness of our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.15629v1",
    "published": "2025-05-21T15:15:04+00:00",
    "categories": [
      "cs.MM"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15628v1",
    "title": "SNAP: A Benchmark for Testing the Effects of Capture Conditions on Fundamental Vision Tasks",
    "authors": [
      "Iuliia Kotseruba",
      "John K. Tsotsos"
    ],
    "abstract": "Generalization of deep-learning-based (DL) computer vision algorithms to\nvarious image perturbations is hard to establish and remains an active area of\nresearch. The majority of past analyses focused on the images already captured,\nwhereas effects of the image formation pipeline and environment are less\nstudied. In this paper, we address this issue by analyzing the impact of\ncapture conditions, such as camera parameters and lighting, on DL model\nperformance on 3 vision tasks -- image classification, object detection, and\nvisual question answering (VQA). To this end, we assess capture bias in common\nvision datasets and create a new benchmark, SNAP (for $\\textbf{S}$hutter speed,\nISO se$\\textbf{N}$sitivity, and $\\textbf{AP}$erture), consisting of images of\nobjects taken under controlled lighting conditions and with densely sampled\ncamera settings. We then evaluate a large number of DL vision models and show\nthe effects of capture conditions on each selected vision task. Lastly, we\nconduct an experiment to establish a human baseline for the VQA task. Our\nresults show that computer vision datasets are significantly biased, the models\ntrained on this data do not reach human accuracy even on the well-exposed\nimages, and are susceptible to both major exposure changes and minute\nvariations of camera settings. Code and data can be found at\nhttps://github.com/ykotseruba/SNAP",
    "pdf_url": "http://arxiv.org/pdf/2505.15628v1",
    "published": "2025-05-21T15:14:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15627v1",
    "title": "Non-individuality and experience",
    "authors": [
      "Raoni Arroyo"
    ],
    "abstract": "This chapter acknowledges a gap between the ``non-individuals''\ninterpretation of quantum mechanics and our world of experience, and begins to\nbridge it. Section 1 states the problem with Abner Shimony's ``Phenomenological\nprinciple''; section 2 briefly presents the interpretation with connection to\nstandard quantum mechanics; section 3 presents the measurement problem in\nconnection with the Phenomenological principle, the standard way out of it, and\nwhy the ``non-individuals'' interpretation of quantum mechanics should not\nfollow it; section 4 finally shows two closed venues for such an interpretation\n(Bohmian mechanics and the Modal-Hamiltonian Interpretation), and two\nalternatives for such it (Everettian quantum mechanics and spontaneous collapse\ntheories).",
    "pdf_url": "http://arxiv.org/pdf/2505.15627v1",
    "published": "2025-05-21T15:14:17+00:00",
    "categories": [
      "physics.hist-ph",
      "quant-ph"
    ],
    "primary_category": "physics.hist-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15626v1",
    "title": "Aligning Explanations with Human Communication",
    "authors": [
      "Jacopo Teneggi",
      "Zhenzhen Wang",
      "Paul H. Yi",
      "Tianmin Shu",
      "Jeremias Sulam"
    ],
    "abstract": "Machine learning explainability aims to make the decision-making process of\nblack-box models more transparent by finding the most important input features\nfor a given prediction task. Recent works have proposed composing explanations\nfrom semantic concepts (e.g., colors, patterns, shapes) that are inherently\ninterpretable to the user of a model. However, these methods generally ignore\nthe communicative context of explanation-the ability of the user to understand\nthe prediction of the model from the explanation. For example, while a medical\ndoctor might understand an explanation in terms of clinical markers, a patient\nmay need a more accessible explanation to make sense of the same diagnosis. In\nthis paper, we address this gap with listener-adaptive explanations. We propose\nan iterative procedure grounded in principles of pragmatic reasoning and the\nrational speech act to generate explanations that maximize communicative\nutility. Our procedure only needs access to pairwise preferences between\ncandidate explanations, relevant in real-world scenarios where a listener model\nmay not be available. We evaluate our method in image classification tasks,\ndemonstrating improved alignment between explanations and listener preferences\nacross three datasets. Furthermore, we perform a user study that demonstrates\nour explanations increase communicative utility.",
    "pdf_url": "http://arxiv.org/pdf/2505.15626v1",
    "published": "2025-05-21T15:14:05+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21515v1",
    "title": "Edge Games: Cooperative Partner Selection in Network Cooperation Evolution",
    "authors": [
      "Hongqian Wu",
      "Hongzhong Deng",
      "Jichao Li",
      "Chengxing Wu",
      "Zhuoting Yu",
      "Haidong Zhang",
      "Gaoxin Qi"
    ],
    "abstract": "The phenomenon of group cooperation constitutes a fundamental mechanism\nunderlying various social and biological systems. Complex networks provide a\nstructural framework for group interactions, where individuals can not only\nobtain information from their neighbors but also choose neighbors as\ncooperative partners. However, traditional evolutionary game theory models,\nwhere nodes are the game players, are not convenient for directly choosing\ncooperative partners. Here, we exchange the roles of nodes and edges and\ninnovatively propose the \"edge game\" model, using edges in complex networks as\nvirtual game players for group games. Theoretical analysis and simulation\nexperiments show that by configuring a synergy factor (r) that satisfies the\n\"moderate cooperation\" condition, a stable cooperative structure can be\nachieved for any network at the evolutionary equilibrium. Specifically, when\nthere is no constraint on the number of cooperators per node, the condition for\nthe evolution of cooperation in the network is r > kmax, where kmax is the\nmaximum degree of the nodes. When there is a threshold constraint, in\nnearest-neighbor coupled networks (with degree k), the condition for \"moderate\ncooperation\" is k < r < 2k. In heterogeneous networks, a variable synergy\nfactor scheme is adopted, where the synergy factor for each game group (rx) is\ndefined to be proportional to the degree of the central node (kx) in the group\n(rx = n-fold*kx), \"moderate cooperation\" can be achieved when 1 < n-fold < 2.\nIf the value of r exceeds the range, it may lead to \"excessive cooperation\"\nwith node overload. Comparing algorithm performance and time complexity, edge\ngames demonstrate advantages over other optimization algorithms. Simple and\nuniversal, the edge game provides a new approach to addressing multi-agent\ncooperation problems in the era of machine intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2505.21515v1",
    "published": "2025-05-21T15:14:02+00:00",
    "categories": [
      "physics.soc-ph",
      "nlin.AO"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15625v2",
    "title": "Probing the quantum phase transition around $N\\approx60$ via mass measurements of technetium isotopes",
    "authors": [
      "J. Ruotsalainen",
      "A. Jaries",
      "M. Stryjczyk",
      "A. Kankainen",
      "B. Andel",
      "M. Araszkiewicz",
      "O. Beliuskina",
      "A. Bruce",
      "S. Cannarozzo",
      "S. Chinthakayala",
      "S. Doshi",
      "T. Eronen",
      "A. Fija≈Çkowska",
      "L. M. Fraile",
      "P. Garczy≈Ñski",
      "Z. Ge",
      "D. Grigorova",
      "G. Jaworski",
      "A. Korgul",
      "T. Krakowski",
      "J. Kurpeta",
      "S. Lalkovski",
      "M. Llanos Exp√≥sito",
      "I. D. Moore",
      "L. M. Motilla",
      "M. Mougeot",
      "H. Penttil√§",
      "A. Raggio",
      "W. Rattanasakuldilok",
      "J. Saren",
      "K. Solak"
    ],
    "abstract": "The masses of neutron-rich $^{104-106}$Tc isotopes were measured using the\nJYFLTRAP double Penning trap and found to deviate from the Atomic Mass\nEvaluation 2020 by $-79(25)$, $40(12)$ and $94(41)$ keV, respectively. In the\ncase of $^{105,106}$Tc, the updated $Q_\\beta$ values are in agreement with a\nprevious JYFLTRAP measurement, disagreeing with the values from the mass\nevaluation. The new mass values result in a more linear trend in two-neutron\nseparation energies indicating that technetium ($Z=43$) isotopes around $N\n\\approx 60$ are not a part of the island of shape coexistence around\n$^{100}$Zr$_{60}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15625v2",
    "published": "2025-05-21T15:13:32+00:00",
    "categories": [
      "nucl-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.15624v1",
    "title": "Mechanistic Insights into Grokking from the Embedding Layer",
    "authors": [
      "H. V. AlquBoj",
      "Hilal AlQuabeh",
      "Velibor Bojkovic",
      "Munachiso Nwadike",
      "Kentaro Inui"
    ],
    "abstract": "Grokking, a delayed generalization in neural networks after perfect training\nperformance, has been observed in Transformers and MLPs, but the components\ndriving it remain underexplored. We show that embeddings are central to\ngrokking: introducing them into MLPs induces delayed generalization in modular\narithmetic tasks, whereas MLPs without embeddings can generalize immediately.\nOur analysis identifies two key mechanisms: (1) Embedding update dynamics,\nwhere rare tokens stagnate due to sparse gradient updates and weight decay, and\n(2) Bilinear coupling, where the interaction between embeddings and downstream\nweights introduces saddle points and increases sensitivity to initialization.\nTo confirm these mechanisms, we investigate frequency-aware sampling, which\nbalances token updates by minimizing gradient variance, and embedding-specific\nlearning rates, derived from the asymmetric curvature of the bilinear loss\nlandscape. We prove that an adaptive learning rate ratio,\n\\(\\frac{\\eta_E}{\\eta_W} \\propto \\frac{\\sigma_{\\max}(E)}{\\sigma_{\\max}(W)} \\cdot\n\\frac{f_W}{f_E}\\), mitigates bilinear coupling effects, accelerating\nconvergence. Our methods not only improve grokking dynamics but also extend to\nbroader challenges in Transformer optimization, where bilinear interactions\nhinder efficient training.",
    "pdf_url": "http://arxiv.org/pdf/2505.15624v1",
    "published": "2025-05-21T15:12:34+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15623v1",
    "title": "Can LLMs $\\textit{understand}$ Math? -- Exploring the Pitfalls in Mathematical Reasoning",
    "authors": [
      "Tiasa Singha Roy",
      "Aditeya Baral",
      "Ayush Rajesh Jhaveri",
      "Yusuf Baig"
    ],
    "abstract": "Large language models (LLMs) demonstrate considerable potential in various\nnatural language tasks but face significant challenges in mathematical\nreasoning, particularly in executing precise, multi-step logic. However,\ncurrent evaluation frameworks judge their performance solely based on accuracy,\nwhich only accounts for the final answer. This study explores these pitfalls by\nemploying a novel evaluation framework. We propose an evaluation metric called\nthe MAPLE score, which holistically quantifies reasoning misalignment by\nintegrating error rates, redundancy, and validity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15623v1",
    "published": "2025-05-21T15:12:20+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15622v1",
    "title": "Benchmarking Energy and Latency in TinyML: A Novel Method for Resource-Constrained AI",
    "authors": [
      "Pietro Bartoli",
      "Christian Veronesi",
      "Andrea Giudici",
      "David Siorpaes",
      "Diana Trojaniello",
      "Franco Zappa"
    ],
    "abstract": "The rise of IoT has increased the need for on-edge machine learning, with\nTinyML emerging as a promising solution for resource-constrained devices such\nas MCU. However, evaluating their performance remains challenging due to\ndiverse architectures and application scenarios. Current solutions have many\nnon-negligible limitations. This work introduces an alternative benchmarking\nmethodology that integrates energy and latency measurements while\ndistinguishing three execution phases pre-inference, inference, and\npost-inference. Additionally, the setup ensures that the device operates\nwithout being powered by an external measurement unit, while automated testing\ncan be leveraged to enhance statistical significance. To evaluate our setup, we\ntested the STM32N6 MCU, which includes a NPU for executing neural networks. Two\nconfigurations were considered: high-performance and Low-power. The variation\nof the EDP was analyzed separately for each phase, providing insights into the\nimpact of hardware configurations on energy efficiency. Each model was tested\n1000 times to ensure statistically relevant results. Our findings demonstrate\nthat reducing the core voltage and clock frequency improve the efficiency of\npre- and post-processing without significantly affecting network execution\nperformance. This approach can also be used for cross-platform comparisons to\ndetermine the most efficient inference platform and to quantify how pre- and\npost-processing overhead varies across different hardware implementations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15622v1",
    "published": "2025-05-21T15:12:14+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15621v2",
    "title": "DSCodeBench: A Realistic Benchmark for Data Science Code Generation",
    "authors": [
      "Shuyin Ouyang",
      "Dong Huang",
      "Jingwen Guo",
      "Zeyu Sun",
      "Qihao Zhu",
      "Jie M. Zhang"
    ],
    "abstract": "We introduce DSCodeBench, a new benchmark designed to evaluate large language\nmodels (LLMs) on complicated and realistic data science code generation tasks.\nDSCodeBench consists of 1,000 carefully constructed problems sourced from\nrealistic problems from GitHub across ten widely used Python data science\nlibraries. Compared to the current state-of-the-art benchmark DS-1000,\nDSCodeBench offers a more challenging and representative testbed, longer code\nsolutions, more comprehensive data science libraries, clearer and better\nstructured problem descriptions, and stronger test suites. To construct the\nDSCodeBench, we develop a robust pipeline that combines task scope selection,\ncode construction, test case generation, and problem description synthesis. The\nprocess is paired with rigorous manual editing to ensure alignment and enhance\nevaluation reliability. Experimental result shows that DSCodeBench exhibits\nrobust scaling behavior, where larger models systematically outperform smaller\nones, validating its ability to distinguish model capabilities. The best LLM we\ntest, GPT-4o, has a pass@1 of 0.202, indicating that LLMs still have a large\nroom to improve for realistic data science code generation tasks. We believe\nDSCodeBench will serve as a rigorous and trustworthy foundation for advancing\nLLM-based data science programming.",
    "pdf_url": "http://arxiv.org/pdf/2505.15621v2",
    "published": "2025-05-21T15:11:26+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15620v1",
    "title": "Observation of $œá_{cJ}\\to 3K_S^0K^\\pmœÄ^\\mp$",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "Y. Ban",
      "H. -R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "M. H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "X. Y. Chai",
      "J. F. Chang",
      "G. R. Che",
      "Y. Z. Che",
      "G. Chelkov",
      "C. Chen",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "Z. K. Chen",
      "S. K. Choi",
      "X. Chu",
      "G. Cibinetto",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "Y. X. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "Z. H. Duan",
      "P. Egorov",
      "G. F. Fan",
      "J. J. Fan",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "X. B. Gao",
      "Y. N. Gao",
      "Y. N. Gao",
      "Y. Y. Gao",
      "Yang Gao",
      "S. Garbolino",
      "I. Garzia",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "A. Gilman",
      "K. Goetzen",
      "J. D. Gong",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "Y. T. Gu",
      "C. Y. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "J. Gutierrez",
      "K. L. Han",
      "T. T. Han",
      "F. Hanisch",
      "K. D. Hao",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. H. Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "T. Holtmann",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "B. Y. Hu",
      "H. M. Hu",
      "J. F. Hu",
      "Q. P. Hu",
      "S. L. Hu",
      "T. Hu",
      "Y. Hu",
      "Z. M. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "P. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "Y. S. Huang",
      "T. Hussain",
      "N. H√ºsken",
      "N. in der Wiesche",
      "J. Jackson",
      "S. Janchiv",
      "Q. Ji",
      "Q. P. Ji",
      "W. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "Z. K. Jia",
      "D. Jiang",
      "H. B. Jiang",
      "P. C. Jiang",
      "S. J. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "J. K. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "X. M. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "M. Kavatsyuk",
      "B. C. Ke",
      "V. Khachatryan",
      "A. Khoukaz",
      "R. Kiuchi",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "N. Kumar",
      "A. Kupsc",
      "W. K√ºhn",
      "Q. Lan",
      "W. N. Lan",
      "T. T. Lei",
      "Z. H. Lei",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "C. K. Li",
      "Cheng Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "K. Li",
      "K. L. Li",
      "K. L. Li",
      "L. J. Li",
      "Lei Li",
      "M. H. Li",
      "M. R. Li",
      "P. L. Li",
      "P. R. Li",
      "Q. M. Li",
      "Q. X. Li",
      "R. Li",
      "T. Li",
      "T. Y. Li",
      "W. D. Li",
      "W. G. Li",
      "X. Li",
      "X. H. Li",
      "X. L. Li",
      "X. Y. Li",
      "X. Z. Li",
      "Y. Li",
      "Y. G. Li",
      "Y. P. Li",
      "Z. J. Li",
      "Z. Y. Li",
      "C. Liang",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "L. B. Liao",
      "M. H. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "C. C. Lin",
      "C. X. Lin",
      "D. X. Lin",
      "L. Q. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. Liu",
      "F. H. Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. B. Liu",
      "H. H. Liu",
      "H. M. Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. J. Liu",
      "K. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. Liu",
      "L. C. Liu",
      "Lu Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "W. T. Liu",
      "X. Liu",
      "X. Liu",
      "X. Y. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. D. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "Y. Lu",
      "Y. H. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "J. R. Luo",
      "J. S. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "Z. Y. Lv",
      "X. R. Lyu",
      "Y. F. Lyu",
      "Y. H. Lyu",
      "F. C. Ma",
      "H. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "L. R. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "R. Y. Ma",
      "T. Ma",
      "X. T. Ma",
      "X. Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "I. MacKay",
      "M. Maggiora",
      "S. Malde",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "Y. H. Meng",
      "Z. X. Meng",
      "J. G. Messchendorp",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "B. Moses",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "L. S. Nie",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Q. L. Niu",
      "W. D. Niu",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "Y. Y. Peng",
      "K. Peters",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "V. Prasad",
      "F. Z. Qi",
      "H. R. Qi",
      "M. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "J. H. Qiao",
      "J. J. Qin",
      "J. L. Qin",
      "L. Q. Qin",
      "L. Y. Qin",
      "P. B. Qin",
      "X. P. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "Z. H. Qu",
      "C. F. Redmer",
      "A. Rivetti",
      "M. Rolo",
      "G. Rong",
      "S. S. Rong",
      "Ch. Rosner",
      "M. Q. Ruan",
      "S. N. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Schoenning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "Z. J. Shang",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "S. Y. Shi",
      "X. Shi",
      "H. L. Song",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "S. S Su",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "Y. C. Sun",
      "Y. H. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. Q. Sun",
      "Z. T. Sun",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "L. F. Tang",
      "M. Tang",
      "Y. A. Tang",
      "L. Y. Tao",
      "M. Tat",
      "J. X. Teng",
      "V. Thoren",
      "J. Y. Tian",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "B. Wang",
      "B. Wang",
      "Bo Wang",
      "C. Wang",
      "Cong Wang",
      "D. Y. Wang",
      "H. J. Wang",
      "J. J. Wang",
      "K. Wang",
      "L. L. Wang",
      "L. W. Wang",
      "M. Wang",
      "M. Wang",
      "N. Y. Wang",
      "S. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "X. N. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. H. Wang",
      "Y. L. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "Yaqian Wang",
      "Yi Wang",
      "Yuan Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. Q. Wang",
      "Z. Y. Wang",
      "D. H. Wei",
      "H. R. Wei",
      "F. Weidner",
      "S. P. Wen",
      "Y. R. Wen",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "Lianjie Wu",
      "S. G. Wu",
      "S. M. Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "B. H. Xiang",
      "T. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "H. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "K. J. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "M. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. Xu",
      "Y. Xu",
      "Y. C. Xu",
      "Z. S. Xu",
      "H. Y. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "W. P. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "J. H. Yang",
      "R. J. Yang",
      "T. Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. H. Yang",
      "Y. Q. Yang",
      "Y. X. Yang",
      "Y. Z. Yang",
      "M. Ye",
      "M. H. Ye",
      "Junhao Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "M. C. Yu",
      "T. Yu",
      "X. D. Yu",
      "Y. C. Yu",
      "C. Z. Yuan",
      "H. Yuan",
      "J. Yuan",
      "J. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "Ying Yue",
      "A. A. Zafar",
      "S. H. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. Zhang",
      "H. C. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. R. Zhang",
      "H. Y. Zhang",
      "J. Zhang",
      "J. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. S. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "L. M. Zhang",
      "Lei Zhang",
      "N. Zhang",
      "P. Zhang",
      "Q. Zhang",
      "Q. Y. Zhang",
      "R. Y. Zhang",
      "S. H. Zhang",
      "Shulei Zhang",
      "X. M. Zhang",
      "X. Y Zhang",
      "X. Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Y. M. Zhang",
      "Z. D. Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. L. Zhang",
      "Z. X. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "Z. Z. Zhang",
      "Zh. Zh. Zhang",
      "G. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "L. Zhao",
      "Lei Zhao",
      "M. G. Zhao",
      "N. Zhao",
      "R. P. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. L. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "B. M. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "X. R. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "X. Zhong",
      "H. Zhou",
      "J. Q. Zhou",
      "J. Y. Zhou",
      "S. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. Z. Zhou",
      "Z. C. Zhou",
      "A. N. Zhu",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "K. S. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "T. J. Zhu",
      "W. D. Zhu",
      "W. D. Zhu",
      "W. J. Zhu",
      "W. Z. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "X. Y. Zhuang",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "By analyzing $(2712.4\\pm14.3)\\times10^6$ $\\psi(3686)$ events collected with\nthe BESIII detector operating at the BEPCII collider, the decays $\\chi_{c0,1,2}\n\\to 3K_S^0K^\\pm\\pi^\\mp$ are observed for the first time with statistical\nsignificances greater than $10\\sigma$. The branching fractions of these decays\nare determined to be $\\mathcal{B}(\\chi_{c0}\\to 3K_S^0K^\\pm\\pi^\\mp\n)=(7.95\\pm0.50\\pm0.65)\\times10^{-5},$ $\\mathcal{B}(\\chi_{c1}\\to\n3K_S^0K^\\pm\\pi^\\mp)=(2.62\\pm0.08\\pm0.19)\\times10^{-4},$ and\n$\\mathcal{B}(\\chi_{c2}\\to\n3K_S^0K^\\pm\\pi^\\mp)=(1.72\\pm0.07\\pm0.15)\\times10^{-4},$ where the first\nuncertainties are statistical and the second systematic.",
    "pdf_url": "http://arxiv.org/pdf/2505.15620v1",
    "published": "2025-05-21T15:10:46+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.15619v1",
    "title": "Search for Dark Photon Dark Matter of a Mass around $36.1\\text{ }\\mathrmŒº\\mathrm{eV}$ Using a Frequency-tunable Cavity Controlled through a Coupled Superconducting Qubit",
    "authors": [
      "K. Nakazono",
      "S. Chen",
      "H. Fukuda",
      "Y. Iiyama",
      "T. Inada",
      "T. Moroi",
      "T. Nitta",
      "A. Noguchi",
      "R. Sawada",
      "S. Shirai",
      "T. Sichanugrist",
      "K. Terashi",
      "K. Watanabe"
    ],
    "abstract": "We report the results of a search for dark photon dark matter using a cavity\nthat employs a transmon qubit as a frequency tuning component. The tuning\nmechanism utilizes the energy level shift (Lamb shift) arising from the mode\nmixing between the qubit and the cavity mode. This method offers several\nadvantages: (i) it does not introduce physical thermal noise from the tuning\nmechanism itself, (ii) it avoids electromagnetic leakage typically associated\nwith cavity seams, and (iii) its implementation is straightforward. We excluded\nthe dark photon parameter region for a dark photon mass around $36.1 \\\n\\mathrm{\\mu eV} $with a peak sensitivity of $\\chi \\sim 10^{-12}$ over the mass\nrange $[36.0791, 36.1765] \\ \\mathrm{\\mu eV}$, surpassing the existing\ncosmological bounds.",
    "pdf_url": "http://arxiv.org/pdf/2505.15619v1",
    "published": "2025-05-21T15:09:12+00:00",
    "categories": [
      "hep-ex",
      "quant-ph"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.15618v1",
    "title": "Lecture notes on large deviations in non-equilibrium diffusive systems",
    "authors": [
      "Bernard Derrida"
    ],
    "abstract": "These notes are a written version of lectures given in the 2024 Les Houches\nSummer School on {\\it Large deviations and applications}. They are are based on\na series of works published over the last 25 years on steady properties of\nnon-equilibrium systems in contact with several heat baths at different\ntemperatures or several reservoirs of particles at different densities. After\nrecalling some classical tools to study non-equilibrium steady states, such as\nthe use of tilted matrices, the Fluctuation theorem, the determination of\ntransport coefficients, the Einstein relations or fluctuating hydrodynamics,\nthey describe some of the basic ideas of the macroscopic fluctuation theory\nallowing to determine the large deviation functions of the density and of the\ncurrent of diffusive systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15618v1",
    "published": "2025-05-21T15:08:28+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15617v2",
    "title": "Functional Central Limit Theorem and SPDE for epidemic model with memory of the last infection and waning immunity",
    "authors": [
      "Arsene Brice Zotsa-Ngoufack"
    ],
    "abstract": "We study the fluctuations of a stochastic epidemic model with memory of the\nlast infections, varying infectivity, and waning immunity, as introduced in\nGuerin and Zotsa-Ngoufack:arXiv preprint arXiv:2505.00601. The dynamics of the\nepidemic model are described by a measure-valued process with respect to\ninfection age and individual traits. The Functional Law of Large Numbers (FLLN)\nis formulated as an integral equation, which is solved by a deterministic\nmeasure. In this article, we establish the Functional Central Limit Theorem\n(FCLT), capturing the fluctuations of the stochastic model around its\ndeterministic limit. The limit of the FCLT is given by a nonlinear stochastic\nintegral equation which is solved by a random signed-measure. We further derive\nthe weak solution in the form of a stochastic partial differential equation\n(SPDE) and propose an alternative representation of the FCLT, as fluctuations\nin the average total force of infection and average susceptibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.15617v2",
    "published": "2025-05-21T15:07:07+00:00",
    "categories": [
      "math.PR",
      "60F05, 60F17, 60K35, 60G55"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15616v1",
    "title": "LENS: Multi-level Evaluation of Multimodal Reasoning with Large Language Models",
    "authors": [
      "Ruilin Yao",
      "Bo Zhang",
      "Jirui Huang",
      "Xinwei Long",
      "Yifang Zhang",
      "Tianyu Zou",
      "Yufei Wu",
      "Shichao Su",
      "Yifan Xu",
      "Wenxi Zeng",
      "Zhaoyu Yang",
      "Guoyou Li",
      "Shilan Zhang",
      "Zichan Li",
      "Yaxiong Chen",
      "Shengwu Xiong",
      "Peng Xu",
      "Jiajun Zhang",
      "Bowen Zhou",
      "David Clifton",
      "Luc Van Gool"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have achieved significant advances\nin integrating visual and linguistic information, yet their ability to reason\nabout complex and real-world scenarios remains limited. The existing benchmarks\nare usually constructed in the task-oriented manner without guarantee that\ndifferent task samples come from the same data distribution, thus they often\nfall short in evaluating the synergistic effects of lower-level perceptual\ncapabilities on higher-order reasoning. To lift this limitation, we contribute\nLens, a multi-level benchmark with 3.4K contemporary images and 60K+\nhuman-authored questions covering eight tasks and 12 daily scenarios, forming\nthree progressive task tiers, i.e., perception, understanding, and reasoning.\nOne feature is that each image is equipped with rich annotations for all tasks.\nThus, this dataset intrinsically supports to evaluate MLLMs to handle\nimage-invariable prompts, from basic perception to compositional reasoning. In\naddition, our images are manully collected from the social media, in which 53%\nwere published later than Jan. 2025. We evaluate 15+ frontier MLLMs such as\nQwen2.5-VL-72B, InternVL3-78B, GPT-4o and two reasoning models QVQ-72B-preview\nand Kimi-VL. These models are released later than Dec. 2024, and none of them\nachieve an accuracy greater than 60% in the reasoning tasks. Project page:\nhttps://github.com/Lens4MLLMs/lens. ICCV 2025 workshop page:\nhttps://lens4mllms.github.io/mars2-workshop-iccv2025/",
    "pdf_url": "http://arxiv.org/pdf/2505.15616v1",
    "published": "2025-05-21T15:06:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15615v2",
    "title": "Simple Sufficient Criteria for Optimality of Entanglement Witnesses",
    "authors": [
      "Frederik vom Ende",
      "Simon Cichy"
    ],
    "abstract": "If one wants to establish optimality of a given bipartite entanglement\nwitness, the current standard approach is to check whether it has the spanning\nproperty. Although this is not necessary for optimality, it is most often\nsatisfied in practice, and for small enough dimensions or sufficiently\nstructured witnesses this criterion can be checked by hand. In this work we\nintroduce a novel characterization of the spanning property via\nentanglement-breaking channels, which in turn leads to a new sufficient\ncriterion for optimality. This criterion amounts to just checking the kernel of\nsome bipartite state. It is slightly weaker than the spanning property, but it\nis a lot easier to test for -- by hand as well as numerically -- and it applies\nto almost all witnesses which are known to have the spanning property. A second\ncriterion is derived from this, where one can simply compute the expectation\nvalue of the given witness on a maximally entangled state. Finally, this\napproach implies new spectral constraints on witnesses as well as on positive\nmaps.",
    "pdf_url": "http://arxiv.org/pdf/2505.15615v2",
    "published": "2025-05-21T15:05:16+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15614v1",
    "title": "Implementation of CR Energy SPectrum (CRESP) algorithm in PIERNIK MHD code. II. Propagation of Primary and Secondary nuclei in a magneto-hydrodynamical environment",
    "authors": [
      "Antoine Baldacchino-Jordan",
      "Michal Hanasz",
      "Mateusz Ogrodnik",
      "Dominik W√≥lta≈Ñski",
      "Artur Gawryszczak",
      "Andrew W. Strong",
      "Philipp Girichidis"
    ],
    "abstract": "We developed a new model for the production and propagation of spectrally\nresolved primary and secondary Cosmic Ray (CR) nuclei elements within the\nframework of the Cosmic Ray Energy Spectrum (CRESP) module of the PIERNIK MHD\ncode. We extend the algorithm to several CR nuclei and demonstrate our code's\ncapability to model primary and secondary CR species simultaneously. Primary C,\nN, and O are accelerated in supernova (SN) remnants. In contrast, the\nspallation collisions of the primary nuclei against the thermal ISM protons\nlead to secondary Li, Be, and B products. All the CR species evolve according\nto the momentum-dependent Fokker-Planck equations that are dynamically coupled\nto the MHD system of equations governing the evolution of the ISM. We\ndemonstrate the operation of this system in the gravity-stratified box,\nreproducing the Milky Way conditions in the Sun's local environment. We perform\na parameter study by investigating the impact of the SN rate, CR parallel\ndiffusion coefficient $D_\\parallel$, and the rigidity-dependent diffusion\ncoefficient power index $\\delta$. A novel result of our investigation is that\nthe Secondary to Primary flux ratio \\BtoC grows when the diffusion coefficient\ngrows, due to the weaker vertical magnetic field resulting from CR buoyancy\neffects. Moreover, a higher SN rate leads to lower values of \\BtoC because of\nstronger winds and the shorter residence of primary CR particles in dense disk\nregions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15614v1",
    "published": "2025-05-21T15:05:07+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15613v1",
    "title": "Congestion and extreme events in urban street networks",
    "authors": [
      "Ajay Agarwal",
      "M. S. Santhanam"
    ],
    "abstract": "Congestion and extreme events in transportation networks are emergent\nphenomena with significant socio-economic implications. In this work, we study\ncongestion and extreme event properties on real urban street (planar) networks\ndrawn from four cities and compare it with that on a regular square grid. For\ndynamics, we employ three variants of random walk with additional realistic\ntransport features. In all the four urban street networks and 2D square grid\nand with all dynamical models, phase transitions are observed from a free flow\nto congested phase as a function of birth rate of vehicles. These transitions\ncan be modified by traffic-aware routing protocols, but congestion cannot be\nentirely mitigated. In organically evolved street networks, we observe a\nsemi-congested regime which has both congested and free-flow components. In the\nfree-flow regime, the extreme event occurrence probability is larger for small\ndegree nodes than for hubs, a feature originally observed in non-planar\nscale-free networks. In general, with respect to congestion and extreme events,\nthe urban street networks and regular square grid display similar properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.15613v1",
    "published": "2025-05-21T15:04:37+00:00",
    "categories": [
      "physics.soc-ph",
      "cond-mat.dis-nn",
      "physics.data-an"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15612v1",
    "title": "Learn to Reason Efficiently with Adaptive Length-based Reward Shaping",
    "authors": [
      "Wei Liu",
      "Ruochen Zhou",
      "Yiyun Deng",
      "Yuzhen Huang",
      "Junteng Liu",
      "Yuntian Deng",
      "Yizhe Zhang",
      "Junxian He"
    ],
    "abstract": "Large Reasoning Models (LRMs) have shown remarkable capabilities in solving\ncomplex problems through reinforcement learning (RL), particularly by\ngenerating long reasoning traces. However, these extended outputs often exhibit\nsubstantial redundancy, which limits the efficiency of LRMs. In this paper, we\ninvestigate RL-based approaches to promote reasoning efficiency. Specifically,\nwe first present a unified framework that formulates various efficient\nreasoning methods through the lens of length-based reward shaping. Building on\nthis perspective, we propose a novel Length-bAsed StEp Reward shaping method\n(LASER), which employs a step function as the reward, controlled by a target\nlength. LASER surpasses previous methods, achieving a superior Pareto-optimal\nbalance between performance and efficiency. Next, we further extend LASER based\non two key intuitions: (1) The reasoning behavior of the model evolves during\ntraining, necessitating reward specifications that are also adaptive and\ndynamic; (2) Rather than uniformly encouraging shorter or longer chains of\nthought (CoT), we posit that length-based reward shaping should be\ndifficulty-aware i.e., it should penalize lengthy CoTs more for easy queries.\nThis approach is expected to facilitate a combination of fast and slow\nthinking, leading to a better overall tradeoff. The resulting method is termed\nLASER-D (Dynamic and Difficulty-aware). Experiments on\nDeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, and\nDeepSeek-R1-Distill-Qwen-32B show that our approach significantly enhances both\nreasoning performance and response length efficiency. For instance, LASER-D and\nits variant achieve a +6.1 improvement on AIME2024 while reducing token usage\nby 63%. Further analysis reveals our RL-based compression produces more concise\nreasoning patterns with less redundant \"self-reflections\". Resources are at\nhttps://github.com/hkust-nlp/Laser.",
    "pdf_url": "http://arxiv.org/pdf/2505.15612v1",
    "published": "2025-05-21T15:03:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15611v1",
    "title": "Shortermism and excessive risk taking in optimal execution with a target performance",
    "authors": [
      "Emilio Barucci",
      "Yuheng Lan"
    ],
    "abstract": "We deal with the optimal execution problem when the broker's goal is to reach\na performance barrier avoiding a downside barrier. The performance is provided\nby the wealth accumulated by trading in the market, the shares detained by the\nbroker evaluated at the market price plus a slippage cost yielding a quadratic\ninventory cost. Over a short horizon, this type of remuneration leads, at the\nsame time, to a more aggressive and less risky strategy compared to the\nclassical one, and over a long horizon the performance turns to be poorer and\nmore dispersed.",
    "pdf_url": "http://arxiv.org/pdf/2505.15611v1",
    "published": "2025-05-21T15:02:07+00:00",
    "categories": [
      "q-fin.MF",
      "q-fin.TR"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2505.15610v2",
    "title": "Entanglement of Inhomogeneous Free Bosons and Orthogonal Polynomials",
    "authors": [
      "Pierre-Antoine Bernard",
      "Rafael I. Nepomechie",
      "Gilles Parez",
      "Eric Ragoucy",
      "David Raveh",
      "Luc Vinet"
    ],
    "abstract": "In this paper, we investigate the ground-state entanglement entropy in\ninhomogeneous free-boson models in one spatial dimension. We develop a powerful\nmethod to extract the leading term in the entanglement scaling, based on the\nanalytic properties of the inhomogeneous potential. This method is applicable\nto a broad class of models with smooth spatial inhomogeneities. As a case\nstudy, we apply this approach for a family of exactly-solvable models\ncharacterized by orthogonal polynomials of the Askey scheme, finding a perfect\nmatch between the numerical and analytical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15610v2",
    "published": "2025-05-21T15:01:57+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "hep-th",
      "math-ph",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.15609v2",
    "title": "Uhlmann and scalar Wilczek-Zee phases of degenerate quantum systems",
    "authors": [
      "Xin Wang",
      "Hao Guo",
      "Chih-Chun Chien"
    ],
    "abstract": "The Wilczek-Zee (WZ) holonomy arises in degenerate states while the Uhlmann\nholonomy characterizes finite-temperature topology. We investigate possible\nrelationships between the Uhlmann phase and the scalar WZ phase, which reflects\nthe Uhlmann and WZ holonomy respectively, in an exemplary four-level model with\ntwo doubly degenerate subspaces. Through exact solutions, we contrast the\nbehavior of the Uhlmann and WZ connections and their associated phases. In the\nzero-temperature limit, the Uhlmann phase may or may not agree with the scalar\nWZ phase of the degenerate ground states due to obstructions from the\nHamiltonian manifested as Dirac points. This is in stark contrast to\nnon-degenerate systems where the correspondence between the Uhlmann and Berry\nphases in general holds. Our analyses further show that for the example studied\nhere, the Uhlmann phase catches the singular behavior at the Dirac points while\nthe WZ connection and scalar WZ phase vanish along a zero-field axis. We also\nbriefly discuss possible experimental implications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15609v2",
    "published": "2025-05-21T15:01:52+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15608v1",
    "title": "Comparison of stability indices of powers of graded ideals",
    "authors": [
      "Antonino Ficarra",
      "Emanuele Sgroi"
    ],
    "abstract": "In this paper, we compare the index of ass-stability $\\text{astab}(I)$ and\nthe index of $\\text{v}$-stability $\\text{vstab}(I)$ of powers of a graded ideal\n$I$. We prove that $\\text{astab}(I)=1\\le\\text{vstab}(I)$ for any graded ideal\n$I$ in a 2-dimensional polynomial ring, and that $\\text{vstab}(I)$ can be any\npositive integer in this situation. Moreover, given any integers $a,b\\ge1$, we\nconstruct a graded ideal $I$ in a $3(a+1)$-dimensional polynomial ring such\nthat $(\\text{astab}(I),\\text{vstab}(I))=(a,b)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15608v1",
    "published": "2025-05-21T15:00:57+00:00",
    "categories": [
      "math.AC",
      "math.CO"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15607v1",
    "title": "From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning",
    "authors": [
      "David Dinucu-Jianu",
      "Jakub Macina",
      "Nico Daheim",
      "Ido Hakimi",
      "Iryna Gurevych",
      "Mrinmaya Sachan"
    ],
    "abstract": "Large language models (LLMs) can transform education, but their optimization\nfor direct question-answering often undermines effective pedagogy which\nrequires strategically withholding answers. To mitigate this, we propose an\nonline reinforcement learning (RL)-based alignment framework that can quickly\nadapt LLMs into effective tutors using simulated student-tutor interactions by\nemphasizing pedagogical quality and guided problem-solving over simply giving\naway answers. We use our method to train a 7B parameter tutor model without\nhuman annotations which reaches similar performance to larger proprietary\nmodels like LearnLM. We introduce a controllable reward weighting to balance\npedagogical support and student solving accuracy, allowing us to trace the\nPareto frontier between these two objectives. Our models better preserve\nreasoning capabilities than single-turn SFT baselines and can optionally\nenhance interpretability through thinking tags that expose the model's\ninstructional planning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15607v1",
    "published": "2025-05-21T15:00:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15606v3",
    "title": "Five-Term Relations for wreath Macdonald polynomials and tableau formulas for Pieri coefficients",
    "authors": [
      "Marino Romero",
      "Joshua Jeishing Wen"
    ],
    "abstract": "We present a variety of new identities involving operators in the theory of\nwreath Macdonald polynomials. One such family of identities gives five-term\nrelations, analogous to the one given by Garsia and Mellit for the modified\nMacdonald polynomials. As a consequence, we generate tableau formulas for\nwreath Macdonald Pieri coefficients, which give an incredibly quick way of\ncomputing their monomial expansions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15606v3",
    "published": "2025-05-21T14:59:46+00:00",
    "categories": [
      "math.CO",
      "math.QA",
      "math.RT",
      "Primary: 05E05, 05E10, 33D52 Secondary: 81R10"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15605v1",
    "title": "A General Information Extraction Framework Based on Formal Languages",
    "authors": [
      "Markus L. Schmid"
    ],
    "abstract": "For a terminal alphabet $\\Sigma$ and an attribute alphabet $\\Gamma$, a\n$(\\Sigma, \\Gamma)$-extractor is a function that maps every string over $\\Sigma$\nto a table with a column per attribute and with sets of positions of $w$ as\ncell entries. This rather general information extraction framework extends the\nwell-known document spanner framework, which has intensively been investigated\nin the database theory community over the last decade. Moreover, our framework\nis based on formal language theory in a particularly clean and simple way. In\naddition to this conceptual contribution, we investigate closure properties,\ndifferent representation formalisms and the complexity of natural decision\nproblems for extractors.",
    "pdf_url": "http://arxiv.org/pdf/2505.15605v1",
    "published": "2025-05-21T14:59:34+00:00",
    "categories": [
      "cs.FL"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15604v2",
    "title": "Group actions and automorphisms of evolution algebras associated to finite graphs",
    "authors": [
      "Mary Luz Rodi√±o Montoya",
      "Natalia A. Viana Bedoya",
      "Carlos Henao"
    ],
    "abstract": "Given an evolution algebra associated to a connected finite graph $\\Gamma$,\nwe exhibit a free action of the group of symmetries of $\\Gamma$ on the set of\nautomorphisms of the algebra. This allows us to explicitly describe this set\nand we prove that a sufficient condition for it to be finite is that every\nautomorphism is induced by a graph symmetry. Consequently, we extend a known\nresult about perfect evolution algebras to other families.",
    "pdf_url": "http://arxiv.org/pdf/2505.15604v2",
    "published": "2025-05-21T14:58:54+00:00",
    "categories": [
      "math.RA",
      "17A36, 05E18 (Primary) 05C25, 05C81 (Secondary)"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15603v2",
    "title": "Triplet Excitons Reconcile Charge Generation and Recombination in Low-Offset Organic Solar Cells: Efficiency Limits from a 5-State Model",
    "authors": [
      "Jonathan L. Langentepe-Kong",
      "Manasi Pranav",
      "Safa Shoaee",
      "Dieter Neher"
    ],
    "abstract": "The power conversion efficiency of organic solar cells has recently improved\nbeyond 20%. The active layers of these devices comprise of at least two organic\nsemiconductors, forming a type II heterojunction. Hereby, the device\nperformance is determined by the kinetic interplay of various species,\nincluding localized excitons, charge transfer states as well as\ncharge-separated states. However, a model which describes all relevant\nphotovoltaic measures has yet to be developed. Herein, we present a\ncomprehensive 5-state rate model which includes both singlet and triplet charge\ntransfer states and takes into account the formation, re-splitting and decay of\nthe local triplet state, parametric in the respective energy offset. We show\nthat this model not only describes key device properties such as charge\ngeneration efficiency, photoluminescence, electroluminescence and Langevin\nreduction factor simultaneously but also elucidate how these vary across\nmaterial combinations based on the D:A interfacial energy offset alone. We find\nthat the electroluminescence and Langevin reduction factor depend strongly on\nthe triplet properties and that the triplet decay becomes the dominant charge\nrecombination pathway for systems with moderate offset, in full agreement to\nprevious experimental results. Validation against literature data demonstrates\nthe model's ability to predict the device efficiency accurately. Subsequently,\nwe identify material combinations with singlet exciton to charge transfer state\nenergetic offset of roughly 150meV as particularly promising. Our model\nexplains further why recent certified efficiency records for binary blends\nremain at ca. 20% if no further means to improve photon and charge carrier\nharvesting are taken.",
    "pdf_url": "http://arxiv.org/pdf/2505.15603v2",
    "published": "2025-05-21T14:58:40+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15602v1",
    "title": "Deep Learning for Continuous-time Stochastic Control with Jumps",
    "authors": [
      "Patrick Cheridito",
      "Jean-Loup Dupret",
      "Donatien Hainaut"
    ],
    "abstract": "In this paper, we introduce a model-based deep-learning approach to solve\nfinite-horizon continuous-time stochastic control problems with jumps. We\niteratively train two neural networks: one to represent the optimal policy and\nthe other to approximate the value function. Leveraging a continuous-time\nversion of the dynamic programming principle, we derive two different training\nobjectives based on the Hamilton-Jacobi-Bellman equation, ensuring that the\nnetworks capture the underlying stochastic dynamics. Empirical evaluations on\ndifferent problems illustrate the accuracy and scalability of our approach,\ndemonstrating its effectiveness in solving complex, high-dimensional stochastic\ncontrol tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15602v1",
    "published": "2025-05-21T14:57:39+00:00",
    "categories": [
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "math.OC",
      "q-fin.PM",
      "I.2.8; I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15601v1",
    "title": "Finite temperature hadronic spectral properties",
    "authors": [
      "Ryan Bignell",
      "Gert Aarts",
      "Chris Allton",
      "M. Naeem Anwar",
      "Timothy J. Burns",
      "Rachel Horohan D'arcy",
      "Benjamin J√§ger",
      "Seyong Kim",
      "Maria Paola Lombardo",
      "Sin√©ad Ryan",
      "Jon-Ivar Skullerud",
      "Antonio Smecca"
    ],
    "abstract": "The FASTSUM collaboration has a long-standing project examining hadronic\nproperties using anisotropic lattice QCD. We determine the spectral properties\nof bottomonia at finite temperature using lattice NRQCD and describe how our\nnewer simulations improve our control over systematic errors. Motivated by\nthese efforts, the temperature dependence of charm hadron masses is determined\nwhere it is found that temperature effects can extend into the confining phase\nand that some species remain stable deep past the pseudo-critical temperature.",
    "pdf_url": "http://arxiv.org/pdf/2505.15601v1",
    "published": "2025-05-21T14:56:36+00:00",
    "categories": [
      "hep-lat"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.15600v1",
    "title": "Qiskit Variational Quantum Classifier on the Pulsar Classification Problem",
    "authors": [
      "Anna B. M. Souza",
      "Clebson Cruz",
      "Marcelo A. Moret"
    ],
    "abstract": "Quantum Machine Learning is a new computational tool that combines the\nquantum properties from quantum computing with the pattern recognition from\nmachine learning. In this paper, we apply the Variational Quantum Classifier\nalgorithm to the problem of pulsar classification of candidates from the High\nTime Resolution Universe 2 dataset. We use Qiskit Machine Learning circuits to\ncompare the performance of the model using different feature selection methods,\nvarious number of features and training data size. Comparisons on the model\nfrom changing the data encoding and ansatz options are also reported. Keywords:\nQuantum Computing, Quantum Machine Learning, Astrophysics, Pulsars",
    "pdf_url": "http://arxiv.org/pdf/2505.15600v1",
    "published": "2025-05-21T14:53:29+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15599v3",
    "title": "A Fully Device-Independent Ternary Quantum Key Distribution Protocol Based on the Impossible Colouring Game",
    "authors": [
      "Aniket Basak",
      "Rajeet Ghosh",
      "Rohit Sarma Sarkar",
      "Chandan Goswami",
      "Avishek Adhikari"
    ],
    "abstract": "We propose a Ternary Fully Device-Independent Quantum Key Distribution\n(TFDIQKD) protocol based on the two-party Impossible Colouring pseudo-telepathy\ngame, utilizing maximally entangled qutrit states to enable secure key\ngeneration between distant parties. The protocol harnesses Bell inequality\nviolations that arise from contextuality in the Kochen-Specker theorem, thereby\noffering a quantum advantage in a task that is classically impossible and\neliminating reliance on assumptions about the internal functioning of quantum\ndevices. A specially designed qutrit quantum circuit is used for state\npreparation. Security and device independence are rigorously analyzed within a\ncomposable framework, employing Bell-inequality violations, smooth min-entropy,\nvon Neumann entropy, and Shannon entropy. The protocol achieves optimal key\nrates in the ideal case and maintains security under significant noise, with a\nfinite-key analysis that supports its practical viability. Overall, the\nprotocol operates within an adequate security framework and demonstrates an\nimproved key generation rate compared to standard quantum key distribution\nschemes, highlighting the potential of high-dimensional quantum systems for\nsecure communication.",
    "pdf_url": "http://arxiv.org/pdf/2505.15599v3",
    "published": "2025-05-21T14:52:31+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15598v1",
    "title": "Limits of $(\\infty, 1)$-categories with structure and their lax morphisms",
    "authors": [
      "Joanna Ko"
    ],
    "abstract": "Riehl and Verity have established that for a quasi-category $A$ that admits\nlimits, and a homotopy coherent monad on $A$ which does not preserve limits,\nthe Eilenberg-Moore object still admits limits; this can be interpreted as a\ncompleteness result involving lax morphisms. We generalise their result to\ndifferent models for $(\\infty, 1)$-categories, with an abundant variety of\nstructures. For instance, $(\\infty, 1)$-categories with limits, Cartesian\nfibrations between $(\\infty, 1)$-categories, and adjunctions between $(\\infty,\n1)$-categories. In addition, we show that these $(\\infty, 1)$-categories with\nstructure in fact possess an important class of limits of lax morphisms,\nincluding $\\infty$-categorical versions of inserters and equifiers, when only\none morphism in the diagram is required to be structure-preserving. Our\napproach provides a minimal requirement and a transparent explanation for\nseveral kinds of limits of $(\\infty, 1)$-categories and their lax morphisms to\nexist.",
    "pdf_url": "http://arxiv.org/pdf/2505.15598v1",
    "published": "2025-05-21T14:52:03+00:00",
    "categories": [
      "math.CT",
      "math.AT",
      "18N60"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15597v1",
    "title": "Trial and Return Option Strategy in Omnichannel Retailing",
    "authors": [
      "Yasuyuki Kusuda"
    ],
    "abstract": "This study examines the dynamics of customer behavior with trial and return\noptions in omnichannel retailing, where retailers face challenges in\nintegrating physical and online stores. Recently, major retailers have begun\noffering customers the option of trying eligible items for a set period and\nreturning unwanted products free of charge. However, existing research has not\nfully explored the temporal dynamics of customer return behaviors. This study\ninvestigates how temporal dynamics affect customer return behaviors and\ndecision-making during trial periods. Using a theoretical game structure\nframework, this study explores customer decision patterns regarding store\nvisits, product trials, and returns, while examining the strategic role of\nstore clerks in encouraging product trials. The findings suggest that retailers\ncan maximize profit through trial and return options when product fit\nprobability is low, emphasizing the importance of maintaining complementary\nphysical and online channels. We also found that store clerks play a critical\nrole in encouraging customers to try misfit products. The results further\nreveal that return cost coverage policies may not significantly impact customer\nbehavior or retailer profit.",
    "pdf_url": "http://arxiv.org/pdf/2505.15597v1",
    "published": "2025-05-21T14:51:53+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.15596v1",
    "title": "Exploring LLM-Generated Feedback for Economics Essays: How Teaching Assistants Evaluate and Envision Its Use",
    "authors": [
      "Xinyi Lu",
      "Aditya Mahesh",
      "Zejia Shen",
      "Mitchell Dudley",
      "Larissa Sano",
      "Xu Wang"
    ],
    "abstract": "This project examines the prospect of using AI-generated feedback as\nsuggestions to expedite and enhance human instructors' feedback provision. In\nparticular, we focus on understanding the teaching assistants' perspectives on\nthe quality of AI-generated feedback and how they may or may not utilize AI\nfeedback in their own workflows. We situate our work in a foundational college\nEconomics class, which has frequent short essay assignments. We developed an\nLLM-powered feedback engine that generates feedback on students' essays based\non grading rubrics used by the teaching assistants (TAs). To ensure that TAs\ncan meaningfully critique and engage with the AI feedback, we had them complete\ntheir regular grading jobs. For a randomly selected set of essays that they had\ngraded, we used our feedback engine to generate feedback and displayed the\nfeedback as in-text comments in a Word document. We then performed think-aloud\nstudies with 5 TAs over 20 1-hour sessions to have them evaluate the AI\nfeedback, contrast the AI feedback with their handwritten feedback, and share\nhow they envision using the AI feedback if they were offered as suggestions.\nThe study highlights the importance of providing detailed rubrics for AI to\ngenerate high-quality feedback for knowledge-intensive essays. TAs considered\nthat using AI feedback as suggestions during their grading could expedite\ngrading, enhance consistency, and improve overall feedback quality. We discuss\nthe importance of decomposing the feedback generation task into steps and\npresenting intermediate results, in order for TAs to use the AI feedback.",
    "pdf_url": "http://arxiv.org/pdf/2505.15596v1",
    "published": "2025-05-21T14:50:30+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15595v1",
    "title": "A Methodology to Evaluate Strategies Predicting Rankings on Unseen Domains",
    "authors": [
      "S√©bastien Pi√©rard",
      "Adrien Deli√®ge",
      "Ana√Øs Halin",
      "Marc Van Droogenbroeck"
    ],
    "abstract": "Frequently, multiple entities (methods, algorithms, procedures, solutions,\netc.) can be developed for a common task and applied across various domains\nthat differ in the distribution of scenarios encountered. For example, in\ncomputer vision, the input data provided to image analysis methods depend on\nthe type of sensor used, its location, and the scene content. However, a\ncrucial difficulty remains: can we predict which entities will perform best in\na new domain based on assessments on known domains, without having to carry out\nnew and costly evaluations? This paper presents an original methodology to\naddress this question, in a leave-one-domain-out fashion, for various\napplication-specific preferences. We illustrate its use with 30 strategies to\npredict the rankings of 40 entities (unsupervised background subtraction\nmethods) on 53 domains (videos).",
    "pdf_url": "http://arxiv.org/pdf/2505.15595v1",
    "published": "2025-05-21T14:50:09+00:00",
    "categories": [
      "cs.PF",
      "cs.CV"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2505.15594v1",
    "title": "Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off",
    "authors": [
      "Yury Belousov",
      "Brian Pulfer",
      "Vitaliy Kinakh",
      "Slava Voloshynovskiy"
    ],
    "abstract": "While foundation models demonstrate impressive performance across various\ntasks, they remain vulnerable to adversarial inputs. Current research explores\nvarious approaches to enhance model robustness, with Diffusion Denoised\nSmoothing emerging as a particularly promising technique. This method employs a\npretrained diffusion model to preprocess inputs before model inference. Yet,\nits effectiveness remains largely unexplored beyond classification. We aim to\naddress this gap by analyzing three datasets with four distinct downstream\ntasks under three different adversarial attack algorithms. Our findings reveal\nthat while foundation models maintain resilience against conventional\ntransformations, applying high-noise diffusion denoising to clean images\nwithout any distortions significantly degrades performance by as high as 57%.\nLow-noise diffusion settings preserve performance but fail to provide adequate\nprotection across all attack types. Moreover, we introduce a novel attack\nstrategy specifically targeting the diffusion process itself, capable of\ncircumventing defenses in the low-noise regime. Our results suggest that the\ntrade-off between adversarial robustness and performance remains a challenge to\nbe addressed.",
    "pdf_url": "http://arxiv.org/pdf/2505.15594v1",
    "published": "2025-05-21T14:49:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15593v1",
    "title": "Self-powered smart contact lenses: a multidisciplinary approach to micro-scale energy and 900 MHz - 1.1 GHz bandwidth microfabricated loop antennas communication systems",
    "authors": [
      "Patrice Salzenstein",
      "Blandine Guichardaz",
      "Aya Maroua Bessou",
      "Ekaterina Pavlyuchenko",
      "Martine Comte",
      "Maxim V. Pogumirsky"
    ],
    "abstract": "Smart contact lenses are at the forefront of integrating microelectronics,\nbiomedical engineering, and optics into wearable technologies. This work\naddresses a key obstacle in their development: achieving autonomous power\nwithout compromising safety or miniaturization. We examine energy harvesting\nstrategies using intrinsic ocular sources-particularly tear salinity and eyelid\nmotion-to enable sustainable operation without external batteries. The study\nemphasizes compact loop antennas operating between 900 MHz and 1.1 GHz as\ncritical for wireless data transmission and power management. Material choices,\nsignal integrity, and biocompatibility are also discussed. By presenting recent\nadvances in 3D-printed optics, antenna integration, and energy systems, we\npropose a conceptual framework for the next generation of smart lenses,\nenabling real-time health monitoring and vision enhancement through\nself-powered, compact devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15593v1",
    "published": "2025-05-21T14:47:07+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "physics.app-ph"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15592v1",
    "title": "VP Lab: a PEFT-Enabled Visual Prompting Laboratory for Semantic Segmentation",
    "authors": [
      "Niccolo Avogaro",
      "Thomas Frick",
      "Yagmur G. Cinar",
      "Daniel Caraballo",
      "Cezary Skura",
      "Filip M. Janicki",
      "Piotr Kluska",
      "Brown Ebouky",
      "Nicola Farronato",
      "Florian Scheidegger",
      "Cristiano Malossi",
      "Konrad Schindler",
      "Andrea Bartezzaghi",
      "Roy Assaf",
      "Mattia Rigotti"
    ],
    "abstract": "Large-scale pretrained vision backbones have transformed computer vision by\nproviding powerful feature extractors that enable various downstream tasks,\nincluding training-free approaches like visual prompting for semantic\nsegmentation. Despite their success in generic scenarios, these models often\nfall short when applied to specialized technical domains where the visual\nfeatures differ significantly from their training distribution. To bridge this\ngap, we introduce VP Lab, a comprehensive iterative framework that enhances\nvisual prompting for robust segmentation model development. At the core of VP\nLab lies E-PEFT, a novel ensemble of parameter-efficient fine-tuning techniques\nspecifically designed to adapt our visual prompting pipeline to specific\ndomains in a manner that is both parameter- and data-efficient. Our approach\nnot only surpasses the state-of-the-art in parameter-efficient fine-tuning for\nthe Segment Anything Model (SAM), but also facilitates an interactive,\nnear-real-time loop, allowing users to observe progressively improving results\nas they experiment within the framework. By integrating E-PEFT with visual\nprompting, we demonstrate a remarkable 50\\% increase in semantic segmentation\nmIoU performance across various technical datasets using only 5 validated\nimages, establishing a new paradigm for fast, efficient, and interactive model\ndeployment in new, challenging domains. This work comes in the form of a\ndemonstration.",
    "pdf_url": "http://arxiv.org/pdf/2505.15592v1",
    "published": "2025-05-21T14:46:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15591v2",
    "title": "Fiber-coupled external cavity DFB-laser",
    "authors": [
      "David C. Nak",
      "Jasper Riebesehl",
      "Andreas Hemmerich"
    ],
    "abstract": "Narrow-linewidth, compact and robust laser systems are of high interest,\nespecially with prospects for portable quantum metrological applications. We\nrealized an external cavity DFB-laser incorporating an intra-cavity EOM in a\nfully fiber-coupled manner. Additional active feedback on the EOM, by\nreferencing a high finesse cavity, enabled us to reach low kHz-linewidths. We\nanalyzed the laser spectrum by means of delayed self-heterodyne measurements to\nreconstruct the power spectral density. This is achieved by utilizing a\ndata-driven power spectrum equalization approach. The presented laser setup is\nsuccessfully used to create an ultracold gas by laser cooling on a narrow\natomic transition of ${}^{40}$Ca at 1978 nm.",
    "pdf_url": "http://arxiv.org/pdf/2505.15591v2",
    "published": "2025-05-21T14:46:45+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.15589v1",
    "title": "World Models as Reference Trajectories for Rapid Motor Adaptation",
    "authors": [
      "Carlos Stein Brito",
      "Daniel McNamee"
    ],
    "abstract": "Deploying learned control policies in real-world environments poses a\nfundamental challenge. When system dynamics change unexpectedly, performance\ndegrades until models are retrained on new data. We introduce Reflexive World\nModels (RWM), a dual control framework that uses world model predictions as\nimplicit reference trajectories for rapid adaptation. Our method separates the\ncontrol problem into long-term reward maximization through reinforcement\nlearning and robust motor execution through rapid latent control. This dual\narchitecture achieves significantly faster adaptation with low online\ncomputational cost compared to model-based RL baselines, while maintaining\nnear-optimal performance. The approach combines the benefits of flexible policy\nlearning through reinforcement learning with rapid error correction\ncapabilities, providing a principled approach to maintaining performance in\nhigh-dimensional continuous control tasks under varying dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.15589v1",
    "published": "2025-05-21T14:46:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15590v1",
    "title": "Bridging the Gap: Physical PCI Device Integration Into SystemC-TLM Virtual Platforms",
    "authors": [
      "Nils Bosbach",
      "Rebecca Pelke",
      "Niko Zurstra√üen",
      "Jan Henrik Weinstock",
      "Lukas J√ºnger",
      "Rainer Leupers"
    ],
    "abstract": "In today's technology-driven world, early-stage software development and\ntesting are crucial. Virtual Platforms (VPs) have become indispensable tools\nfor this purpose as they serve as a platform to execute and debug the\nunmodified target software at an early design stage. With the increasing\ncomplexity of software, especially in areas like Artificial Intelligence (AI)\napplications, VPs need to provide high simulation speed to ensure the target\nsoftware executes within a reasonable time. Hybrid simulation, which combines\nvirtual models with real hardware, can improve the performance of VPs. This\npaper introduces a novel approach for integrating real Peripheral Component\nInterconnect (PCI) devices into SystemC-TLM-2.0-based VPs. The embedded PCI\ndevices enable high performance, easy integration, and allow introspection for\nanalysis and optimization. To illustrate the practical application of our\napproach, we present a case study where we integrate Google Coral's Edge Tensor\nProcessing Unit (TPU) into an ARM-based VP. The integration allows efficient\nexecution of AI workloads, accelerating simulation speeds by up to 480x while\neliminating the need for complex virtual device models. Beyond accelerating\nAI-workload execution, our framework enables driver development, regression\ntesting across architectures, and device communication analysis. Our findings\ndemonstrate that embedding PCI devices into SystemC simulations significantly\nenhances",
    "pdf_url": "http://arxiv.org/pdf/2505.15590v1",
    "published": "2025-05-21T14:46:41+00:00",
    "categories": [
      "cs.SE",
      "cs.AR",
      "cs.PF"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15588v4",
    "title": "EPBench: A Benchmark for Short-term Earthquake Prediction with Neural Networks",
    "authors": [
      "Zhiyu Xu",
      "Qingliang Chen"
    ],
    "abstract": "Since the beginning of this century, the significant advancements in\nartificial intelligence and neural networks have offered the potential to bring\nnew transformations to short-term earthquake prediction research. However,\ncurrently, there is no widely used benchmark for this task. To address this, we\nhave built a new benchmark (EPBench), which is, to our knowledge, the first\nglobal regional-scale short-term earthquake prediction benchmark. Our benchmark\ncomprises 924,472 earthquake records and 2959 multimodal earthquake records\ncollected from seismic networks around the world. Each record includes basic\ninformation such as time, longitude and latitude, magnitude, while each\nmultimodal record includes waveform and moment tensor information additionally,\ncovering a time span from 1970 to 2021. To evaluate performance of models on\nthis task, we have established a series of data partitions and evaluation\nmethods tailored to the short-term earthquake prediction task. We also provide\na variety of tools to assist future researchers in partitioning the data\naccording to their geographical understanding. Our benchmark includes a variety\nof neural network models widely used for time series forecasting, as well as a\nstatistical-based model currently employed by seismological bureaus in several\ncountries. We hope this benchmark will serve as a guide to attract more\nresearchers to explore new methods for addressing this task, which holds great\nsignificance for human existence. Code is available at\nhttps://github.com/CoderZY-X/EPBench",
    "pdf_url": "http://arxiv.org/pdf/2505.15588v4",
    "published": "2025-05-21T14:45:53+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15872v2",
    "title": "InfoDeepSeek: Benchmarking Agentic Information Seeking for Retrieval-Augmented Generation",
    "authors": [
      "Yunjia Xi",
      "Jianghao Lin",
      "Menghui Zhu",
      "Yongzhao Xiao",
      "Zhuoying Ou",
      "Jiaqi Liu",
      "Tong Wan",
      "Bo Chen",
      "Weiwen Liu",
      "Yasheng Wang",
      "Ruiming Tang",
      "Weinan Zhang",
      "Yong Yu"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\ngrounding responses with retrieved information. As an emerging paradigm,\nAgentic RAG further enhances this process by introducing autonomous LLM agents\ninto the information seeking process. However, existing benchmarks fall short\nin evaluating such systems, as they are confined to a static retrieval\nenvironment with a fixed, limited corpus} and simple queries that fail to\nelicit agentic behavior. Moreover, their evaluation protocols assess\ninformation seeking effectiveness by pre-defined gold sets of documents, making\nthem unsuitable for the open-ended and dynamic nature of real-world web\nenvironments. To bridge this gap, we present InfoDeepSeek, a new benchmark with\nchallenging questions designed for assessing agentic information seeking in\nreal-world, dynamic web environments. We propose a systematic methodology for\nconstructing challenging queries satisfying the criteria of determinacy,\ndifficulty, and diversity. Based on this, we develop the first evaluation\nframework tailored to dynamic agentic information seeking, including\nfine-grained metrics about the accuracy, utility, and compactness of\ninformation seeking outcomes. Through extensive experiments across LLMs, search\nengines, and question types, InfoDeepSeek reveals nuanced agent behaviors and\noffers actionable insights for future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15872v2",
    "published": "2025-05-21T14:44:40+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15587v2",
    "title": "Approximate Probabilistic Bisimulation for Continuous-Time Markov Chains",
    "authors": [
      "Timm Spork",
      "Christel Baier",
      "Joost-Pieter Katoen",
      "Sascha Kl√ºppelholz",
      "Jakob Piribauer"
    ],
    "abstract": "We introduce $(\\varepsilon, \\delta)$-bisimulation, a novel type of\napproximate probabilistic bisimulation for continuous-time Markov chains. In\ncontrast to related notions, $(\\varepsilon, \\delta)$-bisimulation allows the\nuse of different tolerances for the transition probabilities ($\\varepsilon$,\nadditive) and total exit rates ($\\delta$, multiplicative) of states.\nFundamental properties of the notion, as well as bounds on the absolute\ndifference of time- and reward-bounded reachability probabilities for\n$(\\varepsilon,\\delta)$-bisimilar states, are established.",
    "pdf_url": "http://arxiv.org/pdf/2505.15587v2",
    "published": "2025-05-21T14:44:13+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15586v1",
    "title": "A De Giorgi conjecture on the regularity of minimizers of Cartesian area in 1D",
    "authors": [
      "Giovanni Bellettini",
      "Shokhrukh Yu. Kholmatov"
    ],
    "abstract": "We prove a $C^{1,1}$-regularity of minimizers of the functional $$ \\int_I\n\\sqrt{1+|Du|^2} + \\int_I |u-g|ds,\\quad u\\in BV(I), $$ provided\n$I\\subset\\mathbb{R}$ is a bounded open interval and $\\|g\\|_\\infty$ is\nsufficiently small, thus partially establishing a De Giorgi conjecture in\ndimension one and codimension one. We also extend our result to a suitable\nanisotropic setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.15586v1",
    "published": "2025-05-21T14:41:43+00:00",
    "categories": [
      "math.AP",
      "math.CA",
      "49Q15, 49Q20, 26A06, 26A45"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15585v1",
    "title": "MIRB: Mathematical Information Retrieval Benchmark",
    "authors": [
      "Haocheng Ju",
      "Bin Dong"
    ],
    "abstract": "Mathematical Information Retrieval (MIR) is the task of retrieving\ninformation from mathematical documents and plays a key role in various\napplications, including theorem search in mathematical libraries, answer\nretrieval on math forums, and premise selection in automated theorem proving.\nHowever, a unified benchmark for evaluating these diverse retrieval tasks has\nbeen lacking. In this paper, we introduce MIRB (Mathematical Information\nRetrieval Benchmark) to assess the MIR capabilities of retrieval models. MIRB\nincludes four tasks: semantic statement retrieval, question-answer retrieval,\npremise retrieval, and formula retrieval, spanning a total of 12 datasets. We\nevaluate 13 retrieval models on this benchmark and analyze the challenges\ninherent to MIR. We hope that MIRB provides a comprehensive framework for\nevaluating MIR systems and helps advance the development of more effective\nretrieval models tailored to the mathematical domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.15585v1",
    "published": "2025-05-21T14:40:27+00:00",
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15584v1",
    "title": "Improved power methods for computing eigenvalues of dual quaternion Hermitian matrices",
    "authors": [
      "Yongjun Chen",
      "Liping Zhang"
    ],
    "abstract": "This paper investigates the eigenvalue computation problem of the dual\nquaternion Hermitian matrix closely related to multi-agent group control.\nRecently, power method was proposed by Cui and Qi in Journal of Scientific\nComputing, 100 (2024) to solve such problem. Recognizing that the convergence\nrate of power method is slow due to its dependence on the eigenvalue\ndistribution, we propose two improved versions of power method based on dual\ncomplex adjoint matrices and Aitken extrapolation, named DCAM-PM and ADCAM-PM.\nThey achieve notable efficiency improvements and demonstrate significantly\nfaster convergence. However, power method may be invalid for dual quaternion\nHermitian matrices with eigenvalues having identical standard parts but\ndistinct dual parts. To overcome this disadvantage, utilizing the\neigen-decomposition properties of dual complex adjoint matrix, we propose a\nnovel algorithm EDDCAM-EA which surpasses the power method in both accuracy and\nspeed. Application to eigenvalue computations of dual quaternion Hermitian\nmatrices in multi-agent formation control and numerical experiments highlight\nthe remarkable accuracy and speed of our proposed algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15584v1",
    "published": "2025-05-21T14:40:16+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15583v1",
    "title": "Special cycles in compact locally Hermitian symmetric spaces of type III associated with the Lie group $SO_0(2,m)$",
    "authors": [
      "Ankita Pal",
      "Pampa Paul"
    ],
    "abstract": "Let $G = SO_0(2,m),$ the connected component of the Lie group $SO(2,m);\\ K =\nSO(2) \\times SO(m),$ a maximal compact subgroup of $G;$ and $\\theta$ be the\nassociated Cartan involution of $G.$ Let $X = G/K,\\ \\frak{g}_0$ be the Lie\nalgebra of $G$ and $\\frak{g} = \\frak{g}_0^\\mathbb{C}.$ In this article, we have\nconsidered the special cycles associated with all possible involutions of $G$\ncommuting with $\\theta.$ We have determined the special cycles which give\nnon-zero cohomology classes in $H^*(\\Gamma \\backslash X; \\mathbb{C})$ for some\n$\\theta$-stable torsion-free arithmetic uniform lattice $\\Gamma$ in $G,$ by a\nresult of Millson and Raghunathan. For each cohomologically induced\nrepresentation $A_\\frak{q}$ with trivial infinitesimal character, we have\ndetermined the special cycles for which the non-zero cohomology class has no\n$A_\\frak{q}$-component, via Matsushima's isomorphism.",
    "pdf_url": "http://arxiv.org/pdf/2505.15583v1",
    "published": "2025-05-21T14:39:08+00:00",
    "categories": [
      "math.RT",
      "22E40, 22E46, 17B20, 17B40, 57S15"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15582v1",
    "title": "Measurement of the Z-boson mass",
    "authors": [
      "LHCb collaboration",
      "R. Aaij",
      "A. S. W. Abdelmotteleb",
      "C. Abellan Beteta",
      "F. Abudin√©n",
      "T. Ackernley",
      "A. A. Adefisoye",
      "B. Adeva",
      "M. Adinolfi",
      "P. Adlarson",
      "C. Agapopoulou",
      "C. A. Aidala",
      "Z. Ajaltouni",
      "S. Akar",
      "K. Akiba",
      "P. Albicocco",
      "J. Albrecht",
      "F. Alessio",
      "Z. Aliouche",
      "P. Alvarez Cartelle",
      "R. Amalric",
      "S. Amato",
      "J. L. Amey",
      "Y. Amhis",
      "L. An",
      "L. Anderlini",
      "M. Andersson",
      "P. Andreola",
      "M. Andreotti",
      "A. Anelli",
      "D. Ao",
      "F. Archilli",
      "Z Areg",
      "M. Argenton",
      "S. Arguedas Cuendis",
      "A. Artamonov",
      "M. Artuso",
      "E. Aslanides",
      "R. Ata√≠de Da Silva",
      "M. Atzeni",
      "B. Audurier",
      "D. Bacher",
      "I. Bachiller Perea",
      "S. Bachmann",
      "M. Bachmayer",
      "J. J. Back",
      "P. Baladron Rodriguez",
      "V. Balagura",
      "A. Balboni",
      "W. Baldini",
      "L. Balzani",
      "H. Bao",
      "J. Baptista de Souza Leite",
      "C. Barbero Pretel",
      "M. Barbetti",
      "I. R. Barbosa",
      "R. J. Barlow",
      "M. Barnyakov",
      "S. Barsuk",
      "W. Barter",
      "J. Bartz",
      "S. Bashir",
      "B. Batsukh",
      "P. B. Battista",
      "A. Bay",
      "A. Beck",
      "M. Becker",
      "F. Bedeschi",
      "I. B. Bediaga",
      "N. A. Behling",
      "S. Belin",
      "K. Belous",
      "I. Belov",
      "I. Belyaev",
      "G. Benane",
      "G. Bencivenni",
      "E. Ben-Haim",
      "A. Berezhnoy",
      "R. Bernet",
      "S. Bernet Andres",
      "A. Bertolin",
      "C. Betancourt",
      "F. Betti",
      "J. Bex",
      "Ia. Bezshyiko",
      "O. Bezshyyko",
      "J. Bhom",
      "M. S. Bieker",
      "N. V. Biesuz",
      "P. Billoir",
      "A. Biolchini",
      "M. Birch",
      "F. C. R. Bishop",
      "A. Bitadze",
      "A. Bizzeti",
      "T. Blake",
      "F. Blanc",
      "J. E. Blank",
      "S. Blusk",
      "V. Bocharnikov",
      "J. A. Boelhauve",
      "O. Boente Garcia",
      "T. Boettcher",
      "A. Bohare",
      "A. Boldyrev",
      "C. S. Bolognani",
      "R. Bolzonella",
      "R. B. Bonacci",
      "N. Bondar",
      "A. Bordelius",
      "F. Borgato",
      "S. Borghi",
      "M. Borsato",
      "J. T. Borsuk",
      "E. Bottalico",
      "S. A. Bouchiba",
      "M. Bovill",
      "T. J. V. Bowcock",
      "A. Boyer",
      "C. Bozzi",
      "J. D. Brandenburg",
      "A. Brea Rodriguez",
      "N. Breer",
      "J. Brodzicka",
      "A. Brossa Gonzalo",
      "J. Brown",
      "D. Brundu",
      "E. Buchanan",
      "L. Buonincontri",
      "M. Burgos Marcos",
      "A. T. Burke",
      "C. Burr",
      "J. S. Butter",
      "J. Buytaert",
      "W. Byczynski",
      "S. Cadeddu",
      "H. Cai",
      "A. Caillet",
      "R. Calabrese",
      "S. Calderon Ramirez",
      "L. Calefice",
      "S. Cali",
      "M. Calvi",
      "M. Calvo Gomez",
      "P. Camargo Magalhaes",
      "J. I. Cambon Bouzas",
      "P. Campana",
      "D. H. Campora Perez",
      "A. F. Campoverde Quezada",
      "S. Capelli",
      "L. Capriotti",
      "R. Caravaca-Mora",
      "A. Carbone",
      "L. Carcedo Salgado",
      "R. Cardinale",
      "A. Cardini",
      "P. Carniti",
      "L. Carus",
      "A. Casais Vidal",
      "R. Caspary",
      "G. Casse",
      "M. Cattaneo",
      "G. Cavallero",
      "V. Cavallini",
      "S. Celani",
      "S. Cesare",
      "A. J. Chadwick",
      "I. Chahrour",
      "H. Chang",
      "M. Charles",
      "Ph. Charpentier",
      "E. Chatzianagnostou",
      "M. Chefdeville",
      "C. Chen",
      "S. Chen",
      "Z. Chen",
      "A. Chernov",
      "S. Chernyshenko",
      "X. Chiotopoulos",
      "V. Chobanova",
      "M. Chrzaszcz",
      "A. Chubykin",
      "V. Chulikov",
      "P. Ciambrone",
      "X. Cid Vidal",
      "G. Ciezarek",
      "P. Cifra",
      "P. E. L. Clarke",
      "M. Clemencic",
      "H. V. Cliff",
      "J. Closier",
      "C. Cocha Toapaxi",
      "V. Coco",
      "J. Cogan",
      "E. Cogneras",
      "L. Cojocariu",
      "S. Collaviti",
      "P. Collins",
      "T. Colombo",
      "M. Colonna",
      "A. Comerma-Montells",
      "L. Congedo",
      "A. Contu",
      "N. Cooke",
      "C. Coronel",
      "I. Corredoira",
      "A. Correia",
      "G. Corti",
      "J. Cottee Meldrum",
      "B. Couturier",
      "D. C. Craik",
      "M. Cruz Torres",
      "E. Curras Rivera",
      "R. Currie",
      "C. L. Da Silva",
      "S. Dadabaev",
      "L. Dai",
      "X. Dai",
      "E. Dall'Occo",
      "J. Dalseno",
      "C. D'Ambrosio",
      "J. Daniel",
      "P. d'Argent",
      "G. Darze",
      "A. Davidson",
      "J. E. Davies",
      "O. De Aguiar Francisco",
      "C. De Angelis",
      "F. De Benedetti",
      "J. de Boer",
      "K. De Bruyn",
      "S. De Capua",
      "M. De Cian",
      "U. De Freitas Carneiro Da Graca",
      "E. De Lucia",
      "J. M. De Miranda",
      "L. De Paula",
      "M. De Serio",
      "P. De Simone",
      "F. De Vellis",
      "J. A. de Vries",
      "F. Debernardis",
      "D. Decamp",
      "S. Dekkers",
      "L. Del Buono",
      "B. Delaney",
      "H. -P. Dembinski",
      "J. Deng",
      "V. Denysenko",
      "O. Deschamps",
      "F. Dettori",
      "B. Dey",
      "P. Di Nezza",
      "I. Diachkov",
      "S. Didenko",
      "S. Ding",
      "Y. Ding",
      "L. Dittmann",
      "V. Dobishuk",
      "A. D. Docheva",
      "C. Dong",
      "A. M. Donohoe",
      "F. Dordei",
      "A. C. dos Reis",
      "A. D. Dowling",
      "W. Duan",
      "P. Duda",
      "M. W. Dudek",
      "L. Dufour",
      "V. Duk",
      "P. Durante",
      "M. M. Duras",
      "J. M. Durham",
      "O. D. Durmus",
      "A. Dziurda",
      "A. Dzyuba",
      "S. Easo",
      "E. Eckstein",
      "U. Egede",
      "A. Egorychev",
      "V. Egorychev",
      "S. Eisenhardt",
      "E. Ejopu",
      "L. Eklund",
      "M. Elashri",
      "J. Ellbracht",
      "S. Ely",
      "A. Ene",
      "J. Eschle",
      "S. Esen",
      "T. Evans",
      "F. Fabiano",
      "S. Faghih",
      "L. N. Falcao",
      "B. Fang",
      "R. Fantechi",
      "L. Fantini",
      "M. Faria",
      "K. Farmer",
      "D. Fazzini",
      "L. Felkowski",
      "M. Feng",
      "M. Feo",
      "A. Fernandez Casani",
      "M. Fernandez Gomez",
      "A. D. Fernez",
      "F. Ferrari",
      "F. Ferreira Rodrigues",
      "M. Ferrillo",
      "M. Ferro-Luzzi",
      "S. Filippov",
      "R. A. Fini",
      "M. Fiorini",
      "M. Firlej",
      "K. L. Fischer",
      "D. S. Fitzgerald",
      "C. Fitzpatrick",
      "T. Fiutowski",
      "F. Fleuret",
      "A. Fomin",
      "M. Fontana",
      "L. F. Foreman",
      "R. Forty",
      "D. Foulds-Holt",
      "V. Franco Lima",
      "M. Franco Sevilla",
      "M. Frank",
      "E. Franzoso",
      "G. Frau",
      "C. Frei",
      "D. A. Friday",
      "J. Fu",
      "Q. F√ºhring",
      "Y. Fujii",
      "T. Fulghesu",
      "E. Gabriel",
      "G. Galati",
      "M. D. Galati",
      "A. Gallas Torreira",
      "D. Galli",
      "S. Gambetta",
      "M. Gandelman",
      "P. Gandini",
      "B. Ganie",
      "H. Gao",
      "R. Gao",
      "T. Q. Gao",
      "Y. Gao",
      "Y. Gao",
      "Y. Gao",
      "L. M. Garcia Martin",
      "P. Garcia Moreno",
      "J. Garc√≠a Pardi√±as",
      "P. Gardner",
      "K. G. Garg",
      "L. Garrido",
      "C. Gaspar",
      "A. Gavrikov",
      "L. L. Gerken",
      "E. Gersabeck",
      "M. Gersabeck",
      "T. Gershon",
      "S. Ghizzo",
      "Z. Ghorbanimoghaddam",
      "L. Giambastiani",
      "F. I. Giasemis",
      "V. Gibson",
      "H. K. Giemza",
      "A. L. Gilman",
      "M. Giovannetti",
      "A. Giovent√π",
      "L. Girardey",
      "M. A. Giza",
      "F. C. Glaser",
      "V. V. Gligorov",
      "C. G√∂bel",
      "L. Golinka-Bezshyyko",
      "E. Golobardes",
      "D. Golubkov",
      "A. Golutvin",
      "S. Gomez Fernandez",
      "W. Gomulka",
      "F. Goncalves Abrantes",
      "M. Goncerz",
      "G. Gong",
      "J. A. Gooding",
      "I. V. Gorelov",
      "C. Gotti",
      "E. Govorkova",
      "J. P. Grabowski",
      "L. A. Granado Cardoso",
      "E. Graug√©s",
      "E. Graverini",
      "L. Grazette",
      "G. Graziani",
      "A. T. Grecu",
      "L. M. Greeven",
      "N. A. Grieser",
      "L. Grillo",
      "S. Gromov",
      "C. Gu",
      "M. Guarise",
      "L. Guerry",
      "V. Guliaeva",
      "P. A. G√ºnther",
      "A. -K. Guseinov",
      "E. Gushchin",
      "Y. Guz",
      "T. Gys",
      "K. Habermann",
      "T. Hadavizadeh",
      "C. Hadjivasiliou",
      "G. Haefeli",
      "C. Haen",
      "G. Hallett",
      "P. M. Hamilton",
      "J. Hammerich",
      "Q. Han",
      "X. Han",
      "S. Hansmann-Menzemer",
      "L. Hao",
      "N. Harnew",
      "T. H. Harris",
      "M. Hartmann",
      "S. Hashmi",
      "J. He",
      "F. Hemmer",
      "C. Henderson",
      "R. D. L. Henderson",
      "A. M. Hennequin",
      "K. Hennessy",
      "L. Henry",
      "J. Herd",
      "P. Herrero Gascon",
      "J. Heuel",
      "A. Hicheur",
      "G. Hijano Mendizabal",
      "J. Horswill",
      "R. Hou",
      "Y. Hou",
      "N. Howarth",
      "J. Hu",
      "W. Hu",
      "X. Hu",
      "W. Hulsbergen",
      "R. J. Hunter",
      "M. Hushchyn",
      "D. Hutchcroft",
      "M. Idzik",
      "D. Ilin",
      "P. Ilten",
      "A. Iniukhin",
      "A. Ishteev",
      "K. Ivshin",
      "H. Jage",
      "S. J. Jaimes Elles",
      "S. Jakobsen",
      "E. Jans",
      "B. K. Jashal",
      "A. Jawahery",
      "V. Jevtic",
      "E. Jiang",
      "X. Jiang",
      "Y. Jiang",
      "Y. J. Jiang",
      "M. John",
      "A. John Rubesh Rajan",
      "D. Johnson",
      "C. R. Jones",
      "T. P. Jones",
      "S. Joshi",
      "B. Jost",
      "J. Juan Castella",
      "N. Jurik",
      "I. Juszczak",
      "D. Kaminaris",
      "S. Kandybei",
      "M. Kane",
      "Y. Kang",
      "C. Kar",
      "M. Karacson",
      "D. Karpenkov",
      "A. Kauniskangas",
      "J. W. Kautz",
      "M. K. Kazanecki",
      "F. Keizer",
      "M. Kenzie",
      "T. Ketel",
      "B. Khanji",
      "A. Kharisova",
      "S. Kholodenko",
      "G. Khreich",
      "T. Kirn",
      "V. S. Kirsebom",
      "O. Kitouni",
      "S. Klaver",
      "N. Kleijne",
      "K. Klimaszewski",
      "M. R. Kmiec",
      "S. Koliiev",
      "L. Kolk",
      "A. Konoplyannikov",
      "P. Kopciewicz",
      "P. Koppenburg",
      "A. Korchin",
      "M. Korolev",
      "I. Kostiuk",
      "O. Kot",
      "S. Kotriakhova",
      "E. Kowalczyk",
      "A. Kozachuk",
      "P. Kravchenko",
      "L. Kravchuk",
      "M. Kreps",
      "P. Krokovny",
      "W. Krupa",
      "W. Krzemien",
      "O. Kshyvanskyi",
      "S. Kubis",
      "M. Kucharczyk",
      "V. Kudryavtsev",
      "E. Kulikova",
      "A. Kupsc",
      "V. Kushnir",
      "B. Kutsenko",
      "I. Kyryllin",
      "D. Lacarrere",
      "P. Laguarta Gonzalez",
      "A. Lai",
      "A. Lampis",
      "D. Lancierini",
      "C. Landesa Gomez",
      "J. J. Lane",
      "G. Lanfranchi",
      "C. Langenbruch",
      "J. Langer",
      "O. Lantwin",
      "T. Latham",
      "F. Lazzari",
      "C. Lazzeroni",
      "R. Le Gac",
      "H. Lee",
      "R. Lef√®vre",
      "A. Leflat",
      "S. Legotin",
      "M. Lehuraux",
      "E. Lemos Cid",
      "O. Leroy",
      "T. Lesiak",
      "E. D. Lesser",
      "B. Leverington",
      "A. Li",
      "C. Li",
      "C. Li",
      "H. Li",
      "J. Li",
      "K. Li",
      "L. Li",
      "M. Li",
      "P. Li",
      "P. -R. Li",
      "Q. Li",
      "S. Li",
      "T. Li",
      "T. Li",
      "Y. Li",
      "Y. Li",
      "Z. Lian",
      "X. Liang",
      "S. Libralon",
      "C. Lin",
      "T. Lin",
      "R. Lindner",
      "H. Linton",
      "R. Litvinov",
      "D. Liu",
      "F. L. Liu",
      "G. Liu",
      "K. Liu",
      "S. Liu",
      "W. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. L. Liu",
      "G. Loachamin Ordonez",
      "A. Lobo Salvia",
      "A. Loi",
      "T. Long",
      "J. H. Lopes",
      "A. Lopez Huertas",
      "S. L√≥pez Soli√±o",
      "Q. Lu",
      "C. Lucarelli",
      "D. Lucchesi",
      "M. Lucio Martinez",
      "Y. Luo",
      "A. Lupato",
      "E. Luppi",
      "K. Lynch",
      "X. -R. Lyu",
      "G. M. Ma",
      "S. Maccolini",
      "F. Machefert",
      "F. Maciuc",
      "B. Mack",
      "I. Mackay",
      "L. M. Mackey",
      "L. R. Madhan Mohan",
      "M. J. Madurai",
      "D. Magdalinski",
      "D. Maisuzenko",
      "J. J. Malczewski",
      "S. Malde",
      "L. Malentacca",
      "A. Malinin",
      "T. Maltsev",
      "G. Manca",
      "G. Mancinelli",
      "C. Mancuso",
      "R. Manera Escalero",
      "F. M. Manganella",
      "D. Manuzzi",
      "D. Marangotto",
      "J. F. Marchand",
      "R. Marchevski",
      "U. Marconi",
      "E. Mariani",
      "S. Mariani",
      "C. Marin Benito",
      "J. Marks",
      "A. M. Marshall",
      "L. Martel",
      "G. Martelli",
      "G. Martellotti",
      "L. Martinazzoli",
      "M. Martinelli",
      "D. Martinez Gomez",
      "D. Martinez Santos",
      "F. Martinez Vidal",
      "A. Martorell i Granollers",
      "A. Massafferri",
      "R. Matev",
      "A. Mathad",
      "V. Matiunin",
      "C. Matteuzzi",
      "K. R. Mattioli",
      "A. Mauri",
      "E. Maurice",
      "J. Mauricio",
      "P. Mayencourt",
      "J. Mazorra de Cos",
      "M. Mazurek",
      "M. McCann",
      "T. H. McGrath",
      "N. T. McHugh",
      "A. McNab",
      "R. McNulty",
      "B. Meadows",
      "G. Meier",
      "D. Melnychuk",
      "F. M. Meng",
      "M. Merk",
      "A. Merli",
      "L. Meyer Garcia",
      "D. Miao",
      "H. Miao",
      "M. Mikhasenko",
      "D. A. Milanes",
      "A. Minotti",
      "E. Minucci",
      "T. Miralles",
      "B. Mitreska",
      "D. S. Mitzel",
      "A. Modak",
      "L. Moeser",
      "R. A. Mohammed",
      "R. D. Moise",
      "E. F. Molina Cardenas",
      "T. Momb√§cher",
      "M. Monk",
      "S. Monteil",
      "A. Morcillo Gomez",
      "G. Morello",
      "M. J. Morello",
      "M. P. Morgenthaler",
      "J. Moron",
      "W. Morren",
      "A. B. Morris",
      "A. G. Morris",
      "R. Mountain",
      "H. Mu",
      "Z. M. Mu",
      "E. Muhammad",
      "F. Muheim",
      "M. Mulder",
      "K. M√ºller",
      "F. Mu√±oz-Rojas",
      "R. Murta",
      "V. Mytrochenko",
      "P. Naik",
      "T. Nakada",
      "R. Nandakumar",
      "T. Nanut",
      "I. Nasteva",
      "M. Needham",
      "E. Nekrasova",
      "N. Neri",
      "S. Neubert",
      "N. Neufeld",
      "P. Neustroev",
      "J. Nicolini",
      "D. Nicotra",
      "E. M. Niel",
      "N. Nikitin",
      "Q. Niu",
      "P. Nogarolli",
      "P. Nogga",
      "C. Normand",
      "J. Novoa Fernandez",
      "G. Nowak",
      "C. Nunez",
      "H. N. Nur",
      "A. Oblakowska-Mucha",
      "V. Obraztsov",
      "T. Oeser",
      "S. Okamura",
      "A. Okhotnikov",
      "O. Okhrimenko",
      "R. Oldeman",
      "F. Oliva",
      "M. Olocco",
      "C. J. G. Onderwater",
      "R. H. O'Neil",
      "D. Osthues",
      "J. M. Otalora Goicochea",
      "P. Owen",
      "A. Oyanguren",
      "O. Ozcelik",
      "F. Paciolla",
      "A. Padee",
      "K. O. Padeken",
      "B. Pagare",
      "T. Pajero",
      "A. Palano",
      "M. Palutan",
      "X. Pan",
      "S. Panebianco",
      "G. Panshin",
      "L. Paolucci",
      "A. Papanestis",
      "M. Pappagallo",
      "L. L. Pappalardo",
      "C. Pappenheimer",
      "C. Parkes",
      "D. Parmar",
      "B. Passalacqua",
      "G. Passaleva",
      "D. Passaro",
      "A. Pastore",
      "M. Patel",
      "J. Patoc",
      "C. Patrignani",
      "A. Paul",
      "C. J. Pawley",
      "A. Pellegrino",
      "J. Peng",
      "M. Pepe Altarelli",
      "S. Perazzini",
      "D. Pereima",
      "H. Pereira Da Costa",
      "A. Pereiro Castro",
      "P. Perret",
      "A. Perrevoort",
      "A. Perro",
      "M. J. Peters",
      "K. Petridis",
      "A. Petrolini",
      "J. P. Pfaller",
      "H. Pham",
      "L. Pica",
      "M. Piccini",
      "L. Piccolo",
      "B. Pietrzyk",
      "G. Pietrzyk",
      "R. N. Pilato",
      "D. Pinci",
      "F. Pisani",
      "M. Pizzichemi",
      "V. M. Placinta",
      "M. Plo Casasus",
      "T. Poeschl",
      "F. Polci",
      "M. Poli Lener",
      "A. Poluektov",
      "N. Polukhina",
      "I. Polyakov",
      "E. Polycarpo",
      "S. Ponce",
      "D. Popov",
      "S. Poslavskii",
      "K. Prasanth",
      "C. Prouve",
      "D. Provenzano",
      "V. Pugatch",
      "G. Punzi",
      "S. Qasim",
      "Q. Q. Qian",
      "W. Qian",
      "N. Qin",
      "S. Qu",
      "R. Quagliani",
      "R. I. Rabadan Trejo",
      "J. H. Rademacker",
      "M. Rama",
      "M. Ram√≠rez Garc√≠a",
      "V. Ramos De Oliveira",
      "M. Ramos Pernas",
      "M. S. Rangel",
      "F. Ratnikov",
      "G. Raven",
      "M. Rebollo De Miguel",
      "F. Redi",
      "J. Reich",
      "F. Reiss",
      "Z. Ren",
      "P. K. Resmi",
      "M. Ribalda Galvez",
      "R. Ribatti",
      "G. Ricart",
      "D. Riccardi",
      "S. Ricciardi",
      "K. Richardson",
      "M. Richardson-Slipper",
      "K. Rinnert",
      "P. Robbe",
      "G. Robertson",
      "E. Rodrigues",
      "A. Rodriguez Alvarez",
      "E. Rodriguez Fernandez",
      "J. A. Rodriguez Lopez",
      "E. Rodriguez Rodriguez",
      "J. Roensch",
      "A. Rogachev",
      "A. Rogovskiy",
      "D. L. Rolf",
      "P. Roloff",
      "V. Romanovskiy",
      "A. Romero Vidal",
      "G. Romolini",
      "F. Ronchetti",
      "T. Rong",
      "M. Rotondo",
      "S. R. Roy",
      "M. S. Rudolph",
      "M. Ruiz Diaz",
      "R. A. Ruiz Fernandez",
      "J. Ruiz Vidal",
      "J. J. Saavedra-Arias",
      "J. J. Saborido Silva",
      "R. Sadek",
      "N. Sagidova",
      "D. Sahoo",
      "N. Sahoo",
      "B. Saitta",
      "M. Salomoni",
      "I. Sanderswood",
      "R. Santacesaria",
      "C. Santamarina Rios",
      "M. Santimaria",
      "L. Santoro",
      "E. Santovetti",
      "A. Saputi",
      "D. Saranin",
      "A. Sarnatskiy",
      "G. Sarpis",
      "M. Sarpis",
      "C. Satriano",
      "M. Saur",
      "D. Savrina",
      "H. Sazak",
      "F. Sborzacchi",
      "A. Scarabotto",
      "S. Schael",
      "S. Scherl",
      "M. Schiller",
      "H. Schindler",
      "M. Schmelling",
      "B. Schmidt",
      "S. Schmitt",
      "H. Schmitz",
      "O. Schneider",
      "A. Schopper",
      "N. Schulte",
      "S. Schulte",
      "M. H. Schune",
      "G. Schwering",
      "B. Sciascia",
      "A. Sciuccati",
      "I. Segal",
      "S. Sellam",
      "A. Semennikov",
      "T. Senger",
      "M. Senghi Soares",
      "A. Sergi",
      "N. Serra",
      "L. Sestini",
      "A. Seuthe",
      "B. Sevilla Sanjuan",
      "Y. Shang",
      "D. M. Shangase",
      "M. Shapkin",
      "R. S. Sharma",
      "I. Shchemerov",
      "L. Shchutska",
      "T. Shears",
      "L. Shekhtman",
      "Z. Shen",
      "S. Sheng",
      "V. Shevchenko",
      "B. Shi",
      "Q. Shi",
      "Y. Shimizu",
      "E. Shmanin",
      "R. Shorkin",
      "J. D. Shupperd",
      "R. Silva Coutinho",
      "G. Simi",
      "S. Simone",
      "M. Singha",
      "N. Skidmore",
      "T. Skwarnicki",
      "M. W. Slater",
      "E. Smith",
      "K. Smith",
      "M. Smith",
      "L. Soares Lavra",
      "M. D. Sokoloff",
      "F. J. P. Soler",
      "A. Solomin",
      "A. Solovev",
      "N. S. Sommerfeld",
      "R. Song",
      "Y. Song",
      "Y. Song",
      "Y. S. Song",
      "F. L. Souza De Almeida",
      "B. Souza De Paula",
      "E. Spadaro Norella",
      "E. Spedicato",
      "J. G. Speer",
      "E. Spiridenkov",
      "P. Spradlin",
      "V. Sriskaran",
      "F. Stagni",
      "M. Stahl",
      "S. Stahl",
      "S. Stanislaus",
      "M. Stefaniak",
      "E. N. Stein",
      "O. Steinkamp",
      "O. Stenyakin",
      "H. Stevens",
      "D. Strekalina",
      "Y. Su",
      "F. Suljik",
      "J. Sun",
      "L. Sun",
      "D. Sundfeld",
      "W. Sutcliffe",
      "K. Swientek",
      "F. Swystun",
      "A. Szabelski",
      "T. Szumlak",
      "Y. Tan",
      "Y. Tang",
      "Y. T. Tang",
      "M. D. Tat",
      "A. Terentev",
      "F. Terzuoli",
      "F. Teubert",
      "U. Thoma",
      "E. Thomas",
      "D. J. D. Thompson",
      "H. Tilquin",
      "V. Tisserand",
      "S. T'Jampens",
      "M. Tobin",
      "L. Tomassetti",
      "G. Tonani",
      "X. Tong",
      "T. Tork",
      "D. Torres Machado",
      "L. Toscano",
      "D. Y. Tou",
      "C. Trippl",
      "G. Tuci",
      "N. Tuning",
      "L. H. Uecker",
      "A. Ukleja",
      "D. J. Unverzagt",
      "A. Upadhyay",
      "B. Urbach",
      "A. Usachov",
      "A. Ustyuzhanin",
      "U. Uwer",
      "V. Vagnoni",
      "V. Valcarce Cadenas",
      "G. Valenti",
      "N. Valls Canudas",
      "J. van Eldik",
      "H. Van Hecke",
      "E. van Herwijnen",
      "C. B. Van Hulse",
      "R. Van Laak",
      "M. van Veghel",
      "G. Vasquez",
      "R. Vazquez Gomez",
      "P. Vazquez Regueiro",
      "C. V√°zquez Sierra",
      "S. Vecchi",
      "J. J. Velthuis",
      "M. Veltri",
      "A. Venkateswaran",
      "M. Verdoglia",
      "M. Vesterinen",
      "D. Vico Benet",
      "P. Vidrier Villalba",
      "M. Vieites Diaz",
      "X. Vilasis-Cardona",
      "E. Vilella Figueras",
      "A. Villa",
      "P. Vincent",
      "B. Vivacqua",
      "F. C. Volle",
      "D. vom Bruch",
      "N. Voropaev",
      "K. Vos",
      "C. Vrahas",
      "J. Wagner",
      "J. Walsh",
      "E. J. Walton",
      "G. Wan",
      "A. Wang",
      "C. Wang",
      "G. Wang",
      "H. Wang",
      "J. Wang",
      "J. Wang",
      "J. Wang",
      "J. Wang",
      "M. Wang",
      "N. W. Wang",
      "R. Wang",
      "X. Wang",
      "X. Wang",
      "X. W. Wang",
      "Y. Wang",
      "Y. Wang",
      "Y. W. Wang",
      "Z. Wang",
      "Z. Wang",
      "Z. Wang",
      "J. A. Ward",
      "M. Waterlaat",
      "N. K. Watson",
      "D. Websdale",
      "Y. Wei",
      "J. Wendel",
      "B. D. C. Westhenry",
      "C. White",
      "M. Whitehead",
      "E. Whiter",
      "A. R. Wiederhold",
      "D. Wiedner",
      "G. Wilkinson",
      "M. K. Wilkinson",
      "M. Williams",
      "M. J. Williams",
      "M. R. J. Williams",
      "R. Williams",
      "Z. Williams",
      "F. F. Wilson",
      "M. Winn",
      "W. Wislicki",
      "M. Witek",
      "L. Witola",
      "G. Wormser",
      "S. A. Wotton",
      "H. Wu",
      "J. Wu",
      "X. Wu",
      "Y. Wu",
      "Z. Wu",
      "K. Wyllie",
      "S. Xian",
      "Z. Xiang",
      "Y. Xie",
      "T. X. Xing",
      "A. Xu",
      "L. Xu",
      "L. Xu",
      "M. Xu",
      "Z. Xu",
      "Z. Xu",
      "Z. Xu",
      "K. Yang",
      "X. Yang",
      "Y. Yang",
      "Z. Yang",
      "V. Yeroshenko",
      "H. Yeung",
      "H. Yin",
      "X. Yin",
      "C. Y. Yu",
      "J. Yu",
      "X. Yuan",
      "Y Yuan",
      "E. Zaffaroni",
      "M. Zavertyaev",
      "M. Zdybal",
      "F. Zenesini",
      "C. Zeng",
      "M. Zeng",
      "C. Zhang",
      "D. Zhang",
      "J. Zhang",
      "L. Zhang",
      "R. Zhang",
      "S. Zhang",
      "S. Zhang",
      "Y. Zhang",
      "Y. Z. Zhang",
      "Z. Zhang",
      "Y. Zhao",
      "A. Zhelezov",
      "S. Z. Zheng",
      "X. Z. Zheng",
      "Y. Zheng",
      "T. Zhou",
      "X. Zhou",
      "Y. Zhou",
      "V. Zhovkovska",
      "L. Z. Zhu",
      "X. Zhu",
      "X. Zhu",
      "Y. Zhu",
      "V. Zhukov",
      "J. Zhuo",
      "Q. Zou",
      "D. Zuliani",
      "G. Zunica"
    ],
    "abstract": "The first dedicated $Z$-boson mass measurement at the LHC with $Z \\to\n\\mu^+\\mu^-$ decays is reported. The dataset uses proton-proton collisions at a\ncentre-of-mass energy of $13$ TeV, recorded in 2016 by the LHCb experiment, and\ncorresponds to an integrated luminosity of $1.7$ fb$^{-1}$. A template fit to\nthe $\\mu^+\\mu^-$ mass distribution yields the following result for the\n$Z$-boson mass, \\begin{equation*}\n  m_{Z} = 91184.2 \\pm 8.5 \\pm 3.8 \\rm{MeV}, \\end{equation*} where the first\nuncertainty is statistical and the second systematic. This result is consistent\nwith previous measurements and predictions from global electroweak fits.",
    "pdf_url": "http://arxiv.org/pdf/2505.15582v1",
    "published": "2025-05-21T14:38:31+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.15581v3",
    "title": "Advancing Marine Research: UWSAM Framework and UIIS10K Dataset for Precise Underwater Instance Segmentation",
    "authors": [
      "Hua Li",
      "Shijie Lian",
      "Zhiyuan Li",
      "Runmin Cong",
      "Chongyi Li",
      "Laurence T. Yang",
      "Weidong Zhang",
      "Sam Kwong"
    ],
    "abstract": "With recent breakthroughs in large-scale modeling, the Segment Anything Model\n(SAM) has demonstrated significant potential in a variety of visual\napplications. However, due to the lack of underwater domain expertise, SAM and\nits variants face performance limitations in end-to-end underwater instance\nsegmentation tasks, while their higher computational requirements further\nhinder their application in underwater scenarios. To address this challenge, we\npropose a large-scale underwater instance segmentation dataset, UIIS10K, which\nincludes 10,048 images with pixel-level annotations for 10 categories. Then, we\nintroduce UWSAM, an efficient model designed for automatic and accurate\nsegmentation of underwater instances. UWSAM efficiently distills knowledge from\nthe SAM ViT-Huge image encoder into the smaller ViT-Small image encoder via the\nMask GAT-based Underwater Knowledge Distillation (MG-UKD) method for effective\nvisual representation learning. Furthermore, we design an End-to-end Underwater\nPrompt Generator (EUPG) for UWSAM, which automatically generates underwater\nprompts instead of explicitly providing foreground points or boxes as prompts,\nthus enabling the network to locate underwater instances accurately for\nefficient segmentation. Comprehensive experimental results show that our model\nis effective, achieving significant performance improvements over\nstate-of-the-art methods on multiple underwater instance datasets. Datasets and\ncodes are available at https://github.com/LiamLian0727/UIIS10K.",
    "pdf_url": "http://arxiv.org/pdf/2505.15581v3",
    "published": "2025-05-21T14:36:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15580v1",
    "title": "Eclipsing white dwarf from the Zwicky Transient Facility: II. Seven eclipsing double white dwarfs",
    "authors": [
      "J. van Roestel",
      "K. Burdge",
      "I. Caiazzo",
      "T. Kupfer",
      "P. Mr√≥z",
      "T. A. Prince",
      "A. C. Rodriguez",
      "S. Toonen",
      "Z. Vanderbosch",
      "E. C. Bellm",
      "A. J. Drake",
      "M. J. Graham",
      "S. L. Groom",
      "G. Helou",
      "S. R. Kulkarni",
      "A. A. Mahabal",
      "R. L. Riddle",
      "B. Rushome"
    ],
    "abstract": "In a systematic search for eclipsing white dwarfs using Zwicky transient\nfacility (ZTF) data, we found seven eclipsing double white dwarfs with orbital\nperiods ranging from 45 minutes to 3 hours. We collected high-speed light\ncurves, archival multi-wavelength data, and optical spectra for all systems and\ndetermined the binary parameters for each of them. We show that six of the\nsystems are low-mass, double helium-core white dwarf binaries, with the last\none a carbon-oxygen -- helium core white dwarf binary. These binaries slowly\nspiral inwards due to gravitational wave energy losses and are expected to\nmerge within 36Myr--1.2Gyr, and we predict that the shortest orbital period\nbinary will show a measurable eclipse arrival time delay within a decade. The\ntwo longest systems show a delay in the arrival time of the secondary eclipse,\nwhich we attribute to a small eccentricity of $\\approx 2\\times10^{-3}$. This is\nthe first time that a non-zero eccentricity is measured in a compact double\nwhite dwarf binary. We suggest that these systems emerged from the common\nenvelope with this small eccentricity, and because of the relatively long\norbital period, gravitational wave emission has not yet circularised the\nbinaries. Finally, we predict that relativistic apsidal precession will result\nin a change in the delay of the secondary eclipse that is measurable within a\ndecade.",
    "pdf_url": "http://arxiv.org/pdf/2505.15580v1",
    "published": "2025-05-21T14:35:39+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.11046v1",
    "title": "The Effects of Data Augmentation on Confidence Estimation for LLMs",
    "authors": [
      "Rui Wang",
      "Renyu Zhu",
      "Minmin Lin",
      "Runze Wu",
      "Tangjie Lv",
      "Changjie Fan",
      "Haobo Wang"
    ],
    "abstract": "Confidence estimation is crucial for reflecting the reliability of large\nlanguage models (LLMs), particularly in the widely used closed-source models.\nUtilizing data augmentation for confidence estimation is viable, but\ndiscussions focus on specific augmentation techniques, limiting its potential.\nWe study the impact of different data augmentation methods on confidence\nestimation. Our findings indicate that data augmentation strategies can achieve\nbetter performance and mitigate the impact of overconfidence. We investigate\nthe influential factors related to this and discover that, while preserving\nsemantic information, greater data diversity enhances the effectiveness of\naugmentation. Furthermore, the impact of different augmentation strategies\nvaries across different range of application. Considering parameter\ntransferability and usability, the random combination of augmentations is a\npromising choice.",
    "pdf_url": "http://arxiv.org/pdf/2506.11046v1",
    "published": "2025-05-21T14:35:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17114v3",
    "title": "RAVEN: Query-Guided Representation Alignment for Question Answering over Audio, Video, Embedded Sensors, and Natural Language",
    "authors": [
      "Subrata Biswas",
      "Mohammad Nur Hossain Khan",
      "Bashima Islam"
    ],
    "abstract": "Multimodal question answering (QA) often requires identifying which video,\naudio, or sensor tokens are relevant to the question. Yet modality\ndisagreements are common: off-camera speech, background noise, or motion\noutside the field of view often mislead fusion models that weight all streams\nequally. We present RAVEN, a unified QA architecture whose core is QuART, a\nquery-conditioned cross-modal gating module that assigns scalar relevance\nscores to each token across modalities, enabling the model to amplify\ninformative signals and suppress distractors before fusion. RAVEN is trained\nthrough a three-stage pipeline comprising unimodal pretraining, query-aligned\nfusion, and disagreement-oriented fine-tuning -- each stage targeting a\ndistinct challenge in multi-modal reasoning: representation quality,\ncross-modal relevance, and robustness to modality mismatch. To support training\nand evaluation, we release AVS-QA, a dataset of 300K synchronized\nAudio--Video-Sensor streams paired with automatically generated question-answer\npairs. Experimental results on seven multi-modal QA benchmarks -- including\negocentric and exocentric tasks -- show that RAVEN achieves up to 14.5\\% and\n8.0\\% gains in accuracy compared to state-of-the-art multi-modal large language\nmodels, respectively. Incorporating sensor data provides an additional 16.4\\%\nboost, and the model remains robust under modality corruption, outperforming\nSOTA baselines by 50.23\\%. Our code and dataset are available at\nhttps://github.com/BASHLab/RAVEN.",
    "pdf_url": "http://arxiv.org/pdf/2505.17114v3",
    "published": "2025-05-21T14:33:36+00:00",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15871v2",
    "title": "The strong hull property for affine irreducible Coxeter groups of rank 3",
    "authors": [
      "Ziming Liu"
    ],
    "abstract": "The conjecture proposed by Gaetz and Gao asserts that the Cayley graph of any\nCoxeter group possesses the strong hull property. This conjecture has been\nproved for symmetric groups, hyperoctahedral groups, all right-angled Coxeter\ngroups, and computationally verified for finite Coxeter groups of types $D_4$,\n$F_4$, $G_2$, and $H_3$. This paper investigates all affine irreducible Coxeter\ngroups of rank 3, specifically those of affine types $\\widetilde{A}_2$,\n$\\widetilde{C}_2$, and $\\widetilde{G}_2$. By employing key concepts from\nbuilding theory, we develop novel techniques: first reducing and classifying\nthe convex hull in their Cayley graphs into finitely many cases, then proving\nthe strong hull conjecture for these cases through combinatorial computations.\nNotably, for the case of affine type $\\widetilde{G}_2$, we streamline the proof\nstrategy by reducing it to a corollary of results established for affine type\n$\\widetilde{A}_2$. The reduction techniques developed in this study demonstrate\npotential for generalization. Their possible algebraic reformulation may not\nonly provide new perspectives for further investigation of this conjecture but\nalso offer methodological insights for algebraic combinatorics and geometric\ngroup theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.15871v2",
    "published": "2025-05-21T14:31:20+00:00",
    "categories": [
      "math.CO",
      "math.GR",
      "20F05, 20F55"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15579v1",
    "title": "Federated Learning with Unlabeled Clients: Personalization Can Happen in Low Dimensions",
    "authors": [
      "Hossein Zakerinia",
      "Jonathan Scott",
      "Christoph H. Lampert"
    ],
    "abstract": "Personalized federated learning has emerged as a popular approach to training\non devices holding statistically heterogeneous data, known as clients. However,\nmost existing approaches require a client to have labeled data for training or\nfinetuning in order to obtain their own personalized model. In this paper we\naddress this by proposing FLowDUP, a novel method that is able to generate a\npersonalized model using only a forward pass with unlabeled data. The generated\nmodel parameters reside in a low-dimensional subspace, enabling efficient\ncommunication and computation. FLowDUP's learning objective is theoretically\nmotivated by our new transductive multi-task PAC-Bayesian generalization bound,\nthat provides performance guarantees for unlabeled clients. The objective is\nstructured in such a way that it allows both clients with labeled data and\nclients with only unlabeled data to contribute to the training process. To\nsupplement our theoretical results we carry out a thorough experimental\nevaluation of FLowDUP, demonstrating strong empirical performance on a range of\ndatasets with differing sorts of statistically heterogeneous clients. Through\nnumerous ablation studies, we test the efficacy of the individual components of\nthe method.",
    "pdf_url": "http://arxiv.org/pdf/2505.15579v1",
    "published": "2025-05-21T14:30:59+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15578v1",
    "title": "The equilibrium price of bubble assets",
    "authors": [
      "Charles Bertucci",
      "Jean-Michel Lasry",
      "Pierre Louis Lions"
    ],
    "abstract": "Considering a simple economy, we derive a new Hamilton-Jacobi equation which\nis satisfied by the value of a ''bubble'' asset. We then show, by providing a\nrigorous mathematical analysis of this equation, that a unique non-zero stable\nsolution exists under certain assumptions. The economic interpretation of this\nresult is that, if the bubble asset can produce more stable returns than fiat\nmoney, agents protect themselves from hazardous situations through the bubble\nasset, thus forming a bubble's consensus value. Our mathematical analysis uses\ndifferent ideas coming from the study of semi-linear elliptic equations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15578v1",
    "published": "2025-05-21T14:30:50+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15577v1",
    "title": "Quantum Field Theory Between Rigor and Pragmatism",
    "authors": [
      "Johannes Branahl"
    ],
    "abstract": "Quantum Field Theory (QFT), the foundational framework of particle physics,\nhas long existed in a state of tension between empirical success and\nmathematical rigor. Conventional QFT (CQFT), which underpins the Standard\nModel, offers unparalleled predictive accuracy but relies on inconsistent and\nad hoc methods. In contrast, axiomatic QFT (AxQFT) aspires to a consistent,\nmathematically rigorous foundation, yet lacks empirical applicability. This\npaper introduces the heuristic vehicle of a realism quotient to model and\nnavigate this tension, framing it as a dynamic balance between realism and\ninstrumentalism in the mathematical structures of physical theories. By\nreconstructing the historical development of QFT and extrapolating its\ntrajectory, the paper offers both a descriptive account of theoretical progress\nand a normative proposal: that CQFT and AxQFT must converge to address selected\nchallenges of physics beyond the Standard Model. The model also contributes to\nbroader debates in scientific realism, offering a structured framework for\nunderstanding the interplay between empirical adequacy and conceptual\nrobustness and mathematical rigour in foundational physics.",
    "pdf_url": "http://arxiv.org/pdf/2505.15577v1",
    "published": "2025-05-21T14:30:47+00:00",
    "categories": [
      "physics.hist-ph"
    ],
    "primary_category": "physics.hist-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15576v2",
    "title": "Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models",
    "authors": [
      "Xin Huang",
      "Ruibin Li",
      "Tong Jia",
      "Wei Zheng",
      "Ya Wang"
    ],
    "abstract": "Vision-Language Models (VLMs) are essential for multimodal tasks, especially\ncompositional reasoning (CR) tasks, which require distinguishing fine-grained\nsemantic differences between visual and textual embeddings. However, existing\nmethods primarily fine-tune the model by generating text-based hard negative\nsamples, neglecting the importance of image-based negative samples, which\nresults in insufficient training of the visual encoder and ultimately impacts\nthe overall performance of the model. Moreover, negative samples are typically\ntreated uniformly, without considering their difficulty levels, and the\nalignment of positive samples is insufficient, which leads to challenges in\naligning difficult sample pairs. To address these issues, we propose Adaptive\nHard Negative Perturbation Learning (AHNPL). AHNPL translates text-based hard\nnegatives into the visual domain to generate semantically disturbed image-based\nnegatives for training the model, thereby enhancing its overall performance.\nAHNPL also introduces a contrastive learning approach using a multimodal hard\nnegative loss to improve the model's discrimination of hard negatives within\neach modality and a dynamic margin loss that adjusts the contrastive margin\naccording to sample difficulty to enhance the distinction of challenging sample\npairs. Experiments on three public datasets demonstrate that our method\neffectively boosts VLMs' performance on complex CR tasks. The source code is\navailable at https://github.com/nynu-BDAI/AHNPL.",
    "pdf_url": "http://arxiv.org/pdf/2505.15576v2",
    "published": "2025-05-21T14:28:43+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15575v1",
    "title": "Regularity and Convergence Properties of Finite Free Convolutions",
    "authors": [
      "Katsunori Fujie"
    ],
    "abstract": "Finite free convolutions, $\\boxplus_d$ and $\\boxtimes_d$, are binary\noperations on polynomials of degree $d$ that are central to finite free\nprobability, a developing field at the intersection of free probability and the\ngeometry of polynomials. Motivated by established regularities in free\nprobability, this paper investigates analogous regularities for finite free\nconvolutions. Key findings include triangle inequalities for these convolutions\nand necessary and sufficient conditions regarding atoms of probability\nmeasures. Applications of these results include proving the weak convergence of\n$\\boxplus_d$ and $\\boxtimes_d$ to their infinite counterparts $\\boxplus$ and\n$\\boxtimes$ as $d \\to \\infty$, without compactness assumptions. Furthermore,\nthis weak convergence is strengthened to convergence in Kolmogorov distance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15575v1",
    "published": "2025-05-21T14:28:18+00:00",
    "categories": [
      "math.PR",
      "math.OA",
      "46L54, 30C15 (Primary) 60B10 (Secondary)"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15574v1",
    "title": "Model-theoretic characterizations of large cardinals (Re)${}^2$visited",
    "authors": [
      "Will Boney",
      "Jonathan Osinski"
    ],
    "abstract": "We characterize several large cardinal notions by model-theoretic properties\nof extensions of first-order logic. We show that $\\Pi_n$-strong cardinals, and,\nas a corollary, ``Ord is Woodin\" and weak Vop\\v{e}nka's Principle, are\ncharacterized by compactness properties involving Henkin models for sort logic.\nThis provides a model-theoretic analogy between Vop\\v{e}nka's Principle and\nweak Vop\\v{e}nka's Principle. We also characterize huge cardinals by\ncompactness for type omission properties of the well-foundedness logic $\\mathbb\nL(Q^{\\text{WF}})$, and show that the compactness number of the H\\\"artig\nquantifier logic $\\mathbb L(I)$ can consistently be larger than the first\nsupercompact cardinal. Finally, we show that the upward\nL\\\"owenheim-Skolem-Tarski number of second-order logic $\\mathbb L^2$ and the\nsort logic $\\mathbb L^{s,n}$ are given by the first extendible and\n$C^{(n)}$-extendible cardinal, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.15574v1",
    "published": "2025-05-21T14:27:20+00:00",
    "categories": [
      "math.LO",
      "03E55, 03C85, 03C95"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15573v3",
    "title": "Looking for stabilizers in NSOP$\\_1$",
    "authors": [
      "Yvon Bossut"
    ],
    "abstract": "In this work we study some examples of groups definable and type-definable in\nNSOP1 theories. We exhibit some behaviors of these groups that differ from the\nones of simple groups. We take interest in the notions of generics and\nstabilizers, and define the Kim-stabilizer. We apply the notion of\nKim-stabilizer and the stabilizer from Hrushovsky to the context of a group G\ndefinable in an NSOP1 field F satisfying some assumptions to show that there is\na finite to one embedding of a type definable subgroup of G of bounded index\ninto an algebraic group over F. We then show that definable groups in\nomega-free PAC fields satisfy these conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15573v3",
    "published": "2025-05-21T14:26:37+00:00",
    "categories": [
      "math.LO"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15572v1",
    "title": "Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback",
    "authors": [
      "Wangyang Ying",
      "Haoyue Bai",
      "Nanxu Gong",
      "Xinyuan Wang",
      "Sixun Dong",
      "Haifeng Chen",
      "Yanjie Fu"
    ],
    "abstract": "The data-to-equation (Data2Eqn) task aims to discover interpretable\nmathematical equations that map observed values to labels, offering physical\ninsights and broad applicability across academic and industrial domains.\nGenetic programming and traditional deep learning-based approaches suffer from\nsearch inefficiency and poor generalization on small task-specific datasets.\nFoundation models showed promise in this area, but existing approaches suffer\nfrom: 1) They are pretrained on general-purpose data distributions, making them\nless effective for domain-specific tasks; and 2) their training objectives\nfocus on token-level alignment, overlooking mathematical semantics, which can\nlead to inaccurate equations. To address these issues, we aim to enhance the\ndomain adaptability of foundation models for Data2Eqn tasks. In this work, we\npropose a reinforcement learning-based finetuning framework that directly\noptimizes the generation policy of a pretrained model through reward signals\nderived from downstream numerical fitness. Our method allows the model to adapt\nto specific and complex data distributions and generate mathematically\nmeaningful equations. Extensive experiments demonstrate that our approach\nimproves both the accuracy and robustness of equation generation under complex\ndistributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15572v1",
    "published": "2025-05-21T14:25:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15571v1",
    "title": "Temporal Spectrum Cartography in Low-Altitude Economy Networks: A Generative AI Framework with Multi-Agent Learning",
    "authors": [
      "Changyuan Zhao",
      "Ruichen Zhang",
      "Jiacheng Wang",
      "Dusit Niyato",
      "Geng Sun",
      "Hongyang Du",
      "Zan Li",
      "Abbas Jamalipour",
      "Dong In Kim"
    ],
    "abstract": "This paper introduces a two-stage generative AI (GenAI) framework tailored\nfor temporal spectrum cartography in low-altitude economy networks (LAENets).\nLAENets, characterized by diverse aerial devices such as UAVs, rely heavily on\nwireless communication technologies while facing challenges, including spectrum\ncongestion and dynamic environmental interference. Traditional spectrum\ncartography methods have limitations in handling the temporal and spatial\ncomplexities inherent to these networks. Addressing these challenges, the\nproposed framework first employs a Reconstructive Masked Autoencoder (RecMAE)\ncapable of accurately reconstructing spectrum maps from sparse and temporally\nvarying sensor data using a novel dual-mask mechanism. This approach\nsignificantly enhances the precision of reconstructed radio frequency (RF)\npower maps. In the second stage, the Multi-agent Diffusion Policy (MADP) method\nintegrates diffusion-based reinforcement learning to optimize the trajectories\nof dynamic UAV sensors. By leveraging temporal-attention encoding, this method\neffectively manages spatial exploration and exploitation to minimize cumulative\nreconstruction errors. Extensive numerical experiments validate that this\nintegrated GenAI framework outperforms traditional interpolation methods and\ndeep learning baselines by achieving 57.35% and 88.68% reconstruction error\nreduction, respectively. The proposed trajectory planner substantially improves\nspectrum map accuracy, reconstruction stability, and sensor deployment\nefficiency in dynamically evolving low-altitude environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15571v1",
    "published": "2025-05-21T14:25:31+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17113v1",
    "title": "Schwinger instability, modular flow, and holographic entropy for near-extremal charged BTZ black hole",
    "authors": [
      "Mendrit Latifi",
      "Kimet Jusufi"
    ],
    "abstract": "We investigate the quantum dynamics of a charged scalar field in the\nnear-horizon region of a near-extremal charged BTZ black hole. A controlled\nexpansion of the Einstein-Maxwell equations reveals an emergent warped AdS$_2\n\\times S^1$ throat geometry threaded by a constant electric field--an ideal\nsetting for studying Schwinger pair production, Hawking radiation, and entropy\nflow. By solving the Klein-Gordon equation using both tunneling and\nfield-theoretic methods, we compute the pair production rate and identify an\neffective Unruh-like temperature. In particular, we apply the WKB approximation\nfor Hawking tunneling, justified by the infinite blueshift experienced by\noutgoing modes near the horizon. Instability arises when local acceleration\nexceeds the AdS curvature scale, linking near-horizon dynamics to thermal\nemission. Through the generalized uncertainty principle, which implies the\nexistence of a minimal length, we argue that quantum gravity effects can drive\nthe Hawking and Schwinger-like temperatures to zero. To connect quantum\nradiation to geometry, we analyze the flux of the modular Hamiltonian across\nthe horizon and show that its variation matches the entropic contribution of\nthe produced pairs. Using Tomita-Takesaki theory and the type II\\_\\infty von\nNeumann algebra of horizon observables, we derive a semiclassical gravitational\nconstraint involving the second variation of the stress tensor, recovering the\nnull-null component of the Einstein equations from entropy extremization. The\nintersection point of inward and outward RT geodesics marks both the peak of\npair production and the vanishing of entropy variation, revealing a geometric\nalignment between entanglement, quantum matter, and backreaction. The\nnear-horizon geometry does not merely support quantum effects--it organizes\nthem.",
    "pdf_url": "http://arxiv.org/pdf/2505.17113v1",
    "published": "2025-05-21T14:24:37+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15570v1",
    "title": "Refining Neural Activation Patterns for Layer-Level Concept Discovery in Neural Network-Based Receivers",
    "authors": [
      "Marko Tuononen",
      "Duy Vu",
      "Dani Korpi",
      "Vesa Starck",
      "Ville Hautam√§ki"
    ],
    "abstract": "Concept discovery in neural networks often targets individual neurons or\nhuman-interpretable features, overlooking distributed layer-wide patterns. We\nstudy the Neural Activation Pattern (NAP) methodology, which clusters\nfull-layer activation distributions to identify such layer-level concepts.\nApplied to visual object recognition and radio receiver models, we propose\nimproved normalization, distribution estimation, distance metrics, and varied\ncluster selection. In the radio receiver model, distinct concepts did not\nemerge; instead, a continuous activation manifold shaped by Signal-to-Noise\nRatio (SNR) was observed -- highlighting SNR as a key learned factor,\nconsistent with classical receiver behavior and supporting physical\nplausibility. Our enhancements to NAP improved in-distribution vs.\nout-of-distribution separation, suggesting better generalization and indirectly\nvalidating clustering quality. These results underscore the importance of\nclustering design and activation manifolds in interpreting and troubleshooting\nneural network behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.15570v1",
    "published": "2025-05-21T14:23:38+00:00",
    "categories": [
      "cs.LG",
      "eess.SP",
      "68T07 (Primary) 62H30, 94A05 (Secondary)",
      "I.2.6; I.5.3; C.2.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15569v2",
    "title": "On braided Hopf structures on exterior algebras",
    "authors": [
      "Rinat Kashaev",
      "Vladimir Mangazeev"
    ],
    "abstract": "We show that the exterior algebra of a vector space $V$ of dimension greater\nthan one admits a one-parameter family of braided Hopf algebra structures,\narising from its identification with a Nichols algebra. We explicitly compute\nthe structure constants with respect to a natural set-theoretic basis.\n  A one-parameter family of diagonal automorphisms exists, which we use to\nconstruct solutions to the (constant) Yang--Baxter equation. These solutions\nare conjectured to give rise to the two-variable Links--Gould polynomial\ninvariants associated with the super-quantum group $U_q(\\mathfrak{gl}(N|1))$,\nwhere $N = \\dim(V)$. We support this conjecture through computations for small\nvalues of $N$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15569v2",
    "published": "2025-05-21T14:23:37+00:00",
    "categories": [
      "math.QA",
      "math-ph",
      "math.GT",
      "math.MP",
      "math.RA",
      "16T05 (Primary) 16T25, 16T30, 57K10, 57K14 (Secondary)"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15568v1",
    "title": "Model Checking the Security of the Lightning Network",
    "authors": [
      "Matthias Grundmann",
      "Hannes Hartenstein"
    ],
    "abstract": "Payment channel networks are an approach to improve the scalability of\nblockchain-based cryptocurrencies. The Lightning Network is a payment channel\nnetwork built for Bitcoin that is already used in practice. Because the\nLightning Network is used for transfer of financial value, its security in the\npresence of adversarial participants should be verified. The Lightning\nprotocol's complexity makes it hard to assess whether the protocol is secure.\nTo enable computer-aided security verification of Lightning, we formalize the\nprotocol in TLA+ and formally specify the security property that honest users\nare guaranteed to retrieve their correct balance. While model checking provides\na fully automated verification of the security property, the state space of the\nprotocol's specification is so large that model checking becomes unfeasible. We\nmake model checking the Lightning Network possible using two refinement steps\nthat we verify using proofs. In a first step, we prove that the model of time\nused in the protocol can be abstracted using ideas from the research of timed\nautomata. In a second step, we prove that it suffices to model check the\nprotocol for single payment channels and the protocol for multi-hop payments\nseparately. These refinements reduce the state space sufficiently to allow for\nmodel checking Lightning with models with payments over up to four hops and two\nconcurrent payments. These results indicate that the current specification of\nLightning is secure.",
    "pdf_url": "http://arxiv.org/pdf/2505.15568v1",
    "published": "2025-05-21T14:22:34+00:00",
    "categories": [
      "cs.CR",
      "cs.LO"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15567v1",
    "title": "Plasma-state metasurfaces for ultra-intensive field manipulation",
    "authors": [
      "Zi-Yu Chen",
      "Hao Xu",
      "Jiao Jia",
      "Yanjie Chen",
      "Siyu Chen",
      "Yan Zhang",
      "Mingxuan Wei",
      "Minghao Ma",
      "Runze Li",
      "Fan Yang",
      "Mo Li",
      "Guangwei Lu",
      "Weijun Zhou",
      "Hanmi Mou",
      "Zhuofan Zhang",
      "Zhida Yang",
      "Jian Gao",
      "Feng liu",
      "Boyuan Li",
      "Min Chen",
      "Liming Chen",
      "Yongtian Wang",
      "Lingling Huang",
      "Wenchao Yan",
      "Shuang Zhang",
      "Jie Zhang"
    ],
    "abstract": "High-power lasers offer ultrahigh intensities for plasma interactions, but\nthey lack advanced techniques to control the properties of the fields, because\nno optical elements could withstand their high intensities. The vibrant field\nof metasurfaces has transformed modern optics by enabling unprecedented control\nover light at subwavelength through deliberate design. However, metasurfaces\nhave traditionally been limited to solid-state materials and low light\nintensities. Extending the sophisticated capabilities of metasurfaces from\nsolids into the plasma realm would open new horizons for high-field science.\nHere, we experimentally demonstrate plasma-state metasurfaces (PSMs) through\nthe photonic spin Hall effect and stable-propagating vortex beam generation\nirradiated by intense light. Time-resolved pump-probe measurements reveal that\nthe functionality of PSMs can persist for several picoseconds, making them\nsuitable for controlling ultra-intense femtosecond lasers, even in\nstate-of-the-art multi-petawatt systems. Harnessing the powerful toolkit of\nmetasurfaces, this approach holds the promise to revolutionize our ability to\nmanipulate the amplitude, phase, polarization, and wavefront of high-power\nlasers during their pulse duration. It also opens new possibilities for\ninnovative applications in laser-plasma interactions such as compact particle\nacceleration and novel radiation sources.",
    "pdf_url": "http://arxiv.org/pdf/2505.15567v1",
    "published": "2025-05-21T14:21:06+00:00",
    "categories": [
      "physics.plasm-ph",
      "physics.optics"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15566v1",
    "title": "Hyperscaling of Fidelity and Operator Estimations in the Critical Manifold",
    "authors": [
      "Matheus Henrique Martins Costa",
      "Flavio de Souza Nogueira",
      "Jeroen van den Brink"
    ],
    "abstract": "By formulating the renormalization group as a quantum channel acting on\ndensity matrices in Quantum Field Theories (QFTs), we show that ground-state\nexpectation values of observables supported on slow momentum modes can be\napproximated by their averages on the fixed-point theories to which the QFTs\nflow. This is done by studying the fidelity between ground states of different\nQFTs and arriving at certain hyperscaling relations satisfied at criticality.\nOur results allow for a clear identification of cases in which one can replace\na QFT by its scale-invariant limit in the calculation of expectation values,\nopening the way for the application of numerical and analytical methods to as\nof yet difficult computer simulation of critical models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15566v1",
    "published": "2025-05-21T14:20:54+00:00",
    "categories": [
      "hep-th",
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15565v1",
    "title": "Exciton Bohr radius of lead halide perovskites for photovoltaic and light-emitting applications",
    "authors": [
      "Hyun Myung Jang",
      "Kyung Yeon Jang",
      "Song Hee Lee",
      "Jinwoo Park",
      "Tae-Woo Lee"
    ],
    "abstract": "Exciton Bohr radius (a_B) and exciton binding energy (E_b) of metal halide\nperovskites are two prime quantities in their applications to both\nlight-emitting diode displays and photovoltaic devices. We develop a reliable\ntheoretical method of simultaneously finding a_B and {\\epsilon}_r^c (dielectric\nconstant) based on the net exciton energy above the bulk band gap. It is\nestimated that a_B under the dielectric confinement is substantially smaller\nthan a_B in the absence of dielectric confinement: 4.36 nm vs. 5.61 nm in the\ncase of CH3NH3PbBr3. We attribute the enhanced a_B to variations of\n{\\epsilon}_r^c and the electron-hole correlation energy. We also develop a\nsimple method of finding E_b based on the same net exciton energy. Using this,\nwe attribute the well-known difference in E_b between organic bromide\nperovskites and iodide counterparts to {\\epsilon}_r^c and explain that iodide\nperovskites are more suited than bromide counterparts in photovoltaic\napplications, which require smaller E_b for efficient charge-carriers\ntransport.",
    "pdf_url": "http://arxiv.org/pdf/2505.15565v1",
    "published": "2025-05-21T14:19:39+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15564v1",
    "title": "TinyDrive: Multiscale Visual Question Answering with Selective Token Routing for Autonomous Driving",
    "authors": [
      "Hossein Hassani",
      "Soodeh Nikan",
      "Abdallah Shami"
    ],
    "abstract": "Vision Language Models (VLMs) employed for visual question-answering (VQA) in\nautonomous driving often require substantial computational resources that pose\na challenge for their deployment in resource-constrained vehicles. To address\nthis challenge, we introduce TinyDrive, a lightweight yet effective VLM for\nmulti-view VQA in driving scenarios. Our model comprises two key components\nincluding a multiscale vision encoder and a dual-level prioritization mechanism\nfor tokens and sequences. The multiscale encoder facilitates the processing of\nmulti-view images at diverse resolutions through scale injection and\ncross-scale gating to generate enhanced visual representations. At the token\nlevel, we design a token routing mechanism that dynamically selects and process\nthe most informative tokens based on learned importance scores. At the sequence\nlevel, we propose integrating normalized loss, uncertainty estimates, and a\ndiversity metric to formulate sequence scores that rank and preserve samples\nwithin a sequence priority buffer. Samples with higher scores are more\nfrequently selected for training. TinyDrive is first evaluated on our\ncustom-curated VQA dataset, and it is subsequently tested on the public DriveLM\nbenchmark, where it achieves state-of-the-art language understanding\nperformance. Notably, it achieves relative improvements of 11.1% and 35.4% in\nBLEU-4 and METEOR scores, respectively, despite having a significantly smaller\nparameter count.",
    "pdf_url": "http://arxiv.org/pdf/2505.15564v1",
    "published": "2025-05-21T14:19:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15563v1",
    "title": "Semantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis",
    "authors": [
      "Mohammad Ali",
      "Naeemul Hassan"
    ],
    "abstract": "This research presents a novel approach to computational framing analysis,\ncalled Semantic Relations-based Unsupervised Framing Analysis (SUFA). SUFA\nleverages semantic relations and dependency parsing algorithms to identify and\nassess entity-centric emphasis frames in news media reports. This innovative\nmethod is derived from two studies -- qualitative and computational -- using a\ndataset related to gun violence, demonstrating its potential for analyzing\nentity-centric emphasis frames. This article discusses SUFA's strengths,\nlimitations, and application procedures. Overall, the SUFA approach offers a\nsignificant methodological advancement in computational framing analysis, with\nits broad applicability across both the social sciences and computational\ndomains.",
    "pdf_url": "http://arxiv.org/pdf/2505.15563v1",
    "published": "2025-05-21T14:19:22+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15562v2",
    "title": "On Triangular Forms for x-Flat Control-Affine Systems With Two Inputs",
    "authors": [
      "Georg Hartl",
      "Conrad Gst√∂ttner",
      "Markus Sch√∂berl"
    ],
    "abstract": "This paper examines a broadly applicable triangular normal form for two-input\nx-flat control-affine systems. First, we show that this triangular form\nencompasses a wide range of established normal forms. Next, we prove that any\nx-flat system can be transformed into this triangular structure after a finite\nnumber of prolongations of each input. Finally, we introduce a refined\nalgorithm for identifying candidates for x-flat outputs. Through illustrative\nexamples, we demonstrate the usefulness of our results. In particular, we show\nthat the refined algorithm exceeds the capabilities of existing methods for\ncomputing flat outputs based on triangular forms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15562v2",
    "published": "2025-05-21T14:18:36+00:00",
    "categories": [
      "math.DS",
      "math.OC"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15561v1",
    "title": "Do RAG Systems Suffer From Positional Bias?",
    "authors": [
      "Florin Cuconasu",
      "Simone Filice",
      "Guy Horowitz",
      "Yoelle Maarek",
      "Fabrizio Silvestri"
    ],
    "abstract": "Retrieval Augmented Generation enhances LLM accuracy by adding passages\nretrieved from an external corpus to the LLM prompt. This paper investigates\nhow positional bias - the tendency of LLMs to weight information differently\nbased on its position in the prompt - affects not only the LLM's capability to\ncapitalize on relevant passages, but also its susceptibility to distracting\npassages. Through extensive experiments on three benchmarks, we show how\nstate-of-the-art retrieval pipelines, while attempting to retrieve relevant\npassages, systematically bring highly distracting ones to the top ranks, with\nover 60% of queries containing at least one highly distracting passage among\nthe top-10 retrieved passages. As a result, the impact of the LLM positional\nbias, which in controlled settings is often reported as very prominent by\nrelated works, is actually marginal in real scenarios since both relevant and\ndistracting passages are, in turn, penalized. Indeed, our findings reveal that\nsophisticated strategies that attempt to rearrange the passages based on LLM\npositional preferences do not perform better than random shuffling.",
    "pdf_url": "http://arxiv.org/pdf/2505.15561v1",
    "published": "2025-05-21T14:18:01+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15560v1",
    "title": "Impact of Data Sparsity on Machine Learning for Fault Detection in Power System Protection",
    "authors": [
      "Julian Oelhaf",
      "Georg Kordowich",
      "Changhun Kim",
      "Paula Andrea Perez-Toro",
      "Andreas Maier",
      "Johann Jager",
      "Siming Bayer"
    ],
    "abstract": "Germany's transition to a renewable energy-based power system is reshaping\ngrid operations, requiring advanced monitoring and control to manage\ndecentralized generation. Machine learning (ML) has emerged as a powerful tool\nfor power system protection, particularly for fault detection (FD) and fault\nline identification (FLI) in transmission grids. However, ML model reliability\ndepends on data quality and availability. Data sparsity resulting from sensor\nfailures, communication disruptions, or reduced sampling rates poses a\nchallenge to ML-based FD and FLI. Yet, its impact has not been systematically\nvalidated prior to this work. In response, we propose a framework to assess the\nimpact of data sparsity on ML-based FD and FLI performance. We simulate\nrealistic data sparsity scenarios, evaluate their impact, derive quantitative\ninsights, and demonstrate the effectiveness of this evaluation strategy by\napplying it to an existing ML-based framework. Results show the ML model\nremains robust for FD, maintaining an F1-score of 0.999 $\\pm$ 0.000 even after\na 50x data reduction. In contrast, FLI is more sensitive, with performance\ndecreasing by 55.61% for missing voltage measurements and 9.73% due to\ncommunication failures at critical network points. These findings offer\nactionable insights for optimizing ML models for real-world grid protection.\nThis enables more efficient FD and supports targeted improvements in FLI.",
    "pdf_url": "http://arxiv.org/pdf/2505.15560v1",
    "published": "2025-05-21T14:17:58+00:00",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15559v1",
    "title": "Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes",
    "authors": [
      "Zixun Guo",
      "Simon Dixon"
    ],
    "abstract": "Moonbeam is a transformer-based foundation model for symbolic music,\npretrained on a large and diverse collection of MIDI data totaling 81.6K hours\nof music and 18 billion tokens. Moonbeam incorporates music-domain inductive\nbiases by capturing both absolute and relative musical attributes through the\nintroduction of a novel domain-knowledge-inspired tokenization method and\nMultidimensional Relative Attention (MRA), which captures relative music\ninformation without additional trainable parameters. Leveraging the pretrained\nMoonbeam, we propose 2 finetuning architectures with full anticipatory\ncapabilities, targeting 2 categories of downstream tasks: symbolic music\nunderstanding and conditional music generation (including music infilling). Our\nmodel outperforms other large-scale pretrained music models in most cases in\nterms of accuracy and F1 score across 3 downstream music classification tasks\non 4 datasets. Moreover, our finetuned conditional music generation model\noutperforms a strong transformer baseline with a REMI-like tokenizer. We\nopen-source the code, pretrained model, and generated samples on Github.",
    "pdf_url": "http://arxiv.org/pdf/2505.15559v1",
    "published": "2025-05-21T14:17:25+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15558v1",
    "title": "Robo-DM: Data Management For Large Robot Datasets",
    "authors": [
      "Kaiyuan Chen",
      "Letian Fu",
      "David Huang",
      "Yanxiang Zhang",
      "Lawrence Yunliang Chen",
      "Huang Huang",
      "Kush Hari",
      "Ashwin Balakrishna",
      "Ted Xiao",
      "Pannag R Sanketi",
      "John Kubiatowicz",
      "Ken Goldberg"
    ],
    "abstract": "Recent results suggest that very large datasets of teleoperated robot\ndemonstrations can be used to train transformer-based models that have the\npotential to generalize to new scenes, robots, and tasks. However, curating,\ndistributing, and loading large datasets of robot trajectories, which typically\nconsist of video, textual, and numerical modalities - including streams from\nmultiple cameras - remains challenging. We propose Robo-DM, an efficient\nopen-source cloud-based data management toolkit for collecting, sharing, and\nlearning with robot data. With Robo-DM, robot datasets are stored in a\nself-contained format with Extensible Binary Meta Language (EBML). Robo-DM can\nsignificantly reduce the size of robot trajectory data, transfer costs, and\ndata load time during training. Compared to the RLDS format used in OXE\ndatasets, Robo-DM's compression saves space by up to 70x (lossy) and 3.5x\n(lossless). Robo-DM also accelerates data retrieval by load-balancing video\ndecoding with memory-mapped decoding caches. Compared to LeRobot, a framework\nthat also uses lossy video compression, Robo-DM is up to 50x faster when\ndecoding sequentially. We physically evaluate a model trained by Robo-DM with\nlossy compression, a pick-and-place task, and In-Context Robot Transformer.\nRobo-DM uses 75x compression of the original dataset and does not suffer\nreduction in downstream task accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.15558v1",
    "published": "2025-05-21T14:17:06+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15557v2",
    "title": "Modular Jump Gaussian Processes",
    "authors": [
      "Anna R. Flowers",
      "Christopher T. Franck",
      "Micka√´l Binois",
      "Chiwoo Park",
      "Robert B. Gramacy"
    ],
    "abstract": "Gaussian processes (GPs) furnish accurate nonlinear predictions with\nwell-calibrated uncertainty. However, the typical GP setup has a built-in\nstationarity assumption, making it ill-suited for modeling data from processes\nwith sudden changes, or \"jumps\" in the output variable. The \"jump GP\" (JGP) was\ndeveloped for modeling data from such processes, combining local GPs and latent\n\"level\" variables under a joint inferential framework. But joint modeling can\nbe fraught with difficulty. We aim to simplify by suggesting a more modular\nsetup, eschewing joint inference but retaining the main JGP themes: (a)\nlearning optimal neighborhood sizes that locally respect manifolds of\ndiscontinuity; and (b) a new cluster-based (latent) feature to capture regions\nof distinct output levels on both sides of the manifold. We show that each of\n(a) and (b) separately leads to dramatic improvements when modeling processes\nwith jumps. In tandem (but without requiring joint inference) that benefit is\ncompounded, as illustrated on real and synthetic benchmark examples from the\nrecent literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.15557v2",
    "published": "2025-05-21T14:16:56+00:00",
    "categories": [
      "stat.ME",
      "cs.LG"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15556v1",
    "title": "A Survey on Multilingual Mental Disorders Detection from Social Media Data",
    "authors": [
      "Ana-Maria Bucur",
      "Marcos Zampieri",
      "Tharindu Ranasinghe",
      "Fabio Crestani"
    ],
    "abstract": "The increasing prevalence of mental health disorders globally highlights the\nurgent need for effective digital screening methods that can be used in\nmultilingual contexts. Most existing studies, however, focus on English data,\noverlooking critical mental health signals that may be present in non-English\ntexts. To address this important gap, we present the first survey on the\ndetection of mental health disorders using multilingual social media data. We\ninvestigate the cultural nuances that influence online language patterns and\nself-disclosure behaviors, and how these factors can impact the performance of\nNLP tools. Additionally, we provide a comprehensive list of multilingual data\ncollections that can be used for developing NLP models for mental health\nscreening. Our findings can inform the design of effective multilingual mental\nhealth screening tools that can meet the needs of diverse populations,\nultimately improving mental health outcomes on a global scale.",
    "pdf_url": "http://arxiv.org/pdf/2505.15556v1",
    "published": "2025-05-21T14:15:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15555v1",
    "title": "Robust Activity Detection for Massive Random Access",
    "authors": [
      "Xinjue Wang",
      "Esa Ollila",
      "Sergiy A. Vorobyov"
    ],
    "abstract": "Massive machine-type communications (mMTC) are fundamental to the Internet of\nThings (IoT) framework in future wireless networks, involving the connection of\na vast number of devices with sporadic transmission patterns. Traditional\ndevice activity detection (AD) methods are typically developed for Gaussian\nnoise, but their performance may deteriorate when these conditions are not met,\nparticularly in the presence of heavy-tailed impulsive noise. In this paper, we\npropose robust statistical techniques for AD that do not rely on the Gaussian\nassumption and replace the Gaussian loss function with robust loss functions\nthat can effectively mitigate the impact of heavy-tailed noise and outliers.\nFirst, we prove that the coordinate-wise (conditional) objective function is\ngeodesically convex and derive a fixed-point (FP) algorithm for minimizing it,\nalong with convergence guarantees. Building on the FP algorithm, we propose two\nrobust algorithms for solving the full (unconditional) objective function: a\ncoordinate-wise optimization algorithm (RCWO) and a greedy covariance\nlearning-based matching pursuit algorithm (RCL-MP). Numerical experiments\ndemonstrate that the proposed methods significantly outperform existing\nalgorithms in scenarios with non-Gaussian noise, achieving higher detection\naccuracy and robustness.",
    "pdf_url": "http://arxiv.org/pdf/2505.15555v1",
    "published": "2025-05-21T14:15:51+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15554v1",
    "title": "DayDreamer at CQs-Gen 2025: Generating Critical Questions through Argument Scheme Completion",
    "authors": [
      "Wendi Zhou",
      "Ameer Saadat-Yazdi",
      "Nadin K√∂kciyan"
    ],
    "abstract": "Critical questions are essential resources to provoke critical thinking when\nencountering an argumentative text. We present our system for the Critical\nQuestions Generation (CQs-Gen) Shared Task at ArgMining 2025. Our approach\nleverages large language models (LLMs) with chain-of-thought prompting to\ngenerate critical questions guided by Walton's argumentation schemes. For each\ninput intervention, we conversationally prompt LLMs to instantiate the\ncorresponding argument scheme template to first obtain structured arguments,\nand then generate relevant critical questions. Following this, we rank all the\navailable critical questions by prompting LLMs to select the top 3 most helpful\nquestions based on the original intervention text. This combination of\nstructured argumentation theory and step-by-step reasoning enables the\ngeneration of contextually relevant and diverse critical questions. Our\npipeline achieves competitive performance in the final test set, showing its\npotential to foster critical thinking given argumentative text and detect\nmissing or uninformed claims. Code available at\n\\href{https://git.ecdf.ed.ac.uk/s2236454/DayDreamer-CQs-Gen}{DayDreamer}.",
    "pdf_url": "http://arxiv.org/pdf/2505.15554v1",
    "published": "2025-05-21T14:15:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15553v2",
    "title": "Social Bias in Popular Question-Answering Benchmarks",
    "authors": [
      "Angelie Kraft",
      "Judith Simon",
      "Sonja Schimmler"
    ],
    "abstract": "Question-answering (QA) and reading comprehension (RC) benchmarks are\nessential for assessing the capabilities of large language models (LLMs) in\nretrieving and reproducing knowledge. However, we demonstrate that popular QA\nand RC benchmarks are biased and do not cover questions about different\ndemographics or regions in a representative way, potentially due to a lack of\ndiversity of those involved in their creation. We perform a qualitative content\nanalysis of 30 benchmark papers and a quantitative analysis of 20 respective\nbenchmark datasets to learn (1) who is involved in the benchmark creation, (2)\nhow social bias is addressed or prevented, and (3) whether the demographics of\nthe creators and annotators correspond to particular biases in the content.\nMost analyzed benchmark papers provided insufficient information regarding the\nstakeholders involved in benchmark creation, particularly the annotators.\nNotably, just one of the benchmark papers explicitly reported measures taken to\naddress social representation issues. Moreover, the data analysis revealed\ngender, religion, and geographic biases across a wide range of encyclopedic,\ncommonsense, and scholarly benchmarks. More transparent and bias-aware QA and\nRC benchmark creation practices are needed to facilitate better scrutiny and\nincentivize the development of fairer LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15553v2",
    "published": "2025-05-21T14:14:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15552v4",
    "title": "Robust Atom Interferometry with Super-Gaussian Pulses against Thermal Velocity Spread",
    "authors": [
      "Yujuan Liu",
      "Ziwen Song",
      "Tingting Lin",
      "Biao Tang",
      "Aoxing Hao"
    ],
    "abstract": "Laser frequency fluctuation and atomic thermal motion can lead to errors in\npulse duration and detuning in cold atom interferometry, thereby reducing\nmeasurement stability and fringe contrast. To address this issue, we\ninvestigate the use of super-Gaussian pulses, which are characterized by smooth\ntemporal profiles and centralized energy distribution, in the beam-splitting\nand reflection stages of an atom interferometer. Through numerical simulations,\nwe compare the performance of rectangular, Gaussian, and 2nd- to 10th-order\nsuper-Gaussian pulses subject to deviations in pulse duration and detuning. Our\nresults show that both Gaussian and super-Gaussian pulses offer a significant\nadvantage over traditional rectangular pulses, particularly under thermal\nconditions where velocity spread is prominent. We find that 4th-order pulses\nachieving up to a 90\\% improvement in contrast over rectangular pulses under\nrealistic conditions, and while their peak performance at very low temperatures\nis comparable to that of Gaussian pulses, they demonstrate enhanced robustness\nagainst combined detuning and pulse-length errors. These findings demonstrate\nthat super-Gaussian pulse shaping is an effective method for enhancing the\nrobustness of atom interferometers against errors induced by thermal motion.",
    "pdf_url": "http://arxiv.org/pdf/2505.15552v4",
    "published": "2025-05-21T14:14:14+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15551v1",
    "title": "The Landau-Feynman transiently open quantum system: entanglement and density operators",
    "authors": [
      "Alain Deville",
      "Yannick Deville"
    ],
    "abstract": "Users of quantum mechanics, both in physics and in the field of quantum\ninformation, are familiar with the concept of a statistical mixture as\nintroduced by von Neumann, and with the use of a density operator in that\ncontext. A density operator may also be used in another situation, introduced\nby Landau, with a transient coupling between the two parts of a quantum\nbipartite system. But more than fifty years after a clarifying work by Feynman\non the subject, a confusion still persists about what we call the\nLandau-Feynman situation. This is specifically testified by the development of\ncontroversies around that subject. The aim of this paper is to stress that,\nwhen facing the Landau-Feynman situation, the right concept to be used is not\nthe one of a mixed state (or statistical mixture) - be it qualified as proper\nor improper -, but the one of entanglement.",
    "pdf_url": "http://arxiv.org/pdf/2505.15551v1",
    "published": "2025-05-21T14:13:36+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15550v1",
    "title": "The Sagittarius stellar stream embedded in a fermionic dark matter halo",
    "authors": [
      "Santiago Collazo",
      "Mart√≠n F. Mestre",
      "Carlos R. Arg√ºelles"
    ],
    "abstract": "Stellar streams are essential tracers of the gravitational potential of the\nMilky Way, with key implications to the problem of dark matter (DM) model\ndistributions, either within or beyond phenomenological $\\Lambda$CDM halos. For\nthe first time in the literature, a DM halo model based on first physical\nprinciples such as quantum statistical mechanics and thermodynamics is used to\ntry to reproduce the 6D observations of the Sagittarius (Sgr) stream. We model\nboth DM haloes, the one of Sgr dwarf and the one of its host with a spherical\nself-gravitating system of neutral fermions which accounts for the effects of\nparticles escape and fermion degeneracy, the latter causing a high-density core\nat the center of the halo. Full baryonic components for each galaxy are also\nconsidered. We use a spray algorithm with $\\sim 10^{5}$ particles to generate\nthe Sgr tidal debris, which evolves in the gravitational potential of the\nhost-progenitor system, to compare with the full phase-space data of the\nstream. We repeat this kind of simulations for different parameter setups of\nthe fermionic model including the particle mass, with special attention to test\ndifferent DM halo morphologies allowed by the physics. We find that across the\ndifferent families of fermionic halo models, they can only reproduce the\ntrailing arm of the Sgr stream. Within the observationally allowed span of\nenclosed masses where the stream moves, neither the power-law like, nor the\npolytropic behaviour of the fermionic halo models can answer for the observed\ntrend of the leading tail. A conclusion which is shared by former analysis\nusing other type of spherically symmetric haloes. We conclude that further\nmodel sophistications such as abandoning spherical symmetry and including the\nLarge Magellanic Cloud perturber are needed for a proper modelisation of the\noverall Milky Way potential within this kind of first principle halo models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15550v1",
    "published": "2025-05-21T14:12:42+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15549v1",
    "title": "Pointwise convergence of polynomial multiple ergodic averages along the primes",
    "authors": [
      "Renhui Wan"
    ],
    "abstract": "We establish pointwise almost everywhere convergence for the polynomial\nmultiple ergodic averages $$\\frac{1}{N} \\sum_{n=1}^N \\La(n) f_1(T^{P_1(n)}\nx)\\cdots f_k(T^{P_k(n)} x)$$ as $N\\to \\infty$, where $\\La$ is the von Mangoldt\nfunction, $T \\colon X \\to X$ is an invertible measure-preserving transformation\nof a probability space $(X,\\nu)$, $P_1,\\ldots, P_k$ are polynomials with\ninteger coefficients and distinct degrees, and $f_1,\\ldots,f_k\\in L^\\infty(X)$.\nThis pointwise almost everywhere convergence result can be seen as a refinement\nof the norm convergence result obtained in Wooley--Ziegler (Amer. J. Math,\n2012) in the case of polynomials with distinct degrees.\n  Building on the foundational work of Krause--Mirek--Tao (Ann. of Math.,\n2022), Kosz--Mirek--Peluse--Wright (arXiv: 2411.09478, 2024), and\nKrause--Mousavi--Tao--Ter\\\"{a}v\\\"{a}inen (arXiv: 2409.10510, 2024), we develop\na multilinear circle method for\n  von Mangoldt-weighted (equivalently, prime-weighted) averages. This method\ncombines harmonic analysis techniques across multiple groups with the newest\ninverse theorem from additive combinatorics. In particular, the principal\ninnovations of this framework include:\n  (i) an inverse theorem and a Weyl-type inequality for multilinear\nCram\\'{e}r-weighted averages; (ii) a multilinear Rademacher-Menshov inequality;\nand (iii) an arithmetic multilinear estimate.",
    "pdf_url": "http://arxiv.org/pdf/2505.15549v1",
    "published": "2025-05-21T14:12:38+00:00",
    "categories": [
      "math.DS",
      "math.CA",
      "math.NT"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15548v1",
    "title": "Short-Range Dependency Effects on Transformer Instability and a Decomposed Attention Solution",
    "authors": [
      "Suvadeep Hajra"
    ],
    "abstract": "Transformer language models have driven significant progress across various\nfields, including natural language processing and computer vision. A central\ncomponent of these models is the self-attention (SA) mechanism, which learns\nrich vector representations of tokens by modeling their relationships with\nothers in a sequence. However, despite extensive research, transformers\ncontinue to suffer from training instability -- often manifesting as spikes or\ndivergence in the training loss during a run.\n  In this work, we identify one source of this instability: SA's limited\nability to capture short-range dependencies, especially in tasks like language\nmodeling, where almost every token heavily relies on its nearby neighbors. This\nlimitation causes the pre-softmax logits of SA to grow rapidly, destabilizing\ntraining. To address this, we propose decomposing the SA into local\n(short-range) and global (long-range) attention heads. This decomposed\nattention, referred to as Long Short-attention (LS-attention), mitigates logit\nexplosion and results in more stable training compared to an equivalent\nmulti-head self-attention (MHSA). Empirical comparisons with two alternative\ntraining stabilization methods show that LS-attention reduces the validation\nperplexity to nearly 2/5 of that achieved by one method and reaches a similar\nperplexity as the other method using only 1/20 of the GPU hours. Additionally,\nour experiments demonstrate that LS-attention reduces inference latency by up\nto 36% compared to a state-of-the-art implementation of equivalent MHSA.",
    "pdf_url": "http://arxiv.org/pdf/2505.15548v1",
    "published": "2025-05-21T14:12:30+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15547v2",
    "title": "Oversmoothing, Oversquashing, Heterophily, Long-Range, and more: Demystifying Common Beliefs in Graph Machine Learning",
    "authors": [
      "Adrian Arnaiz-Rodriguez",
      "Federico Errica"
    ],
    "abstract": "After a renaissance phase in which researchers revisited the message-passing\nparadigm through the lens of deep learning, the graph machine learning\ncommunity shifted its attention towards a deeper and practical understanding of\nmessage-passing's benefits and limitations. In this position paper, we notice\nhow the fast pace of progress around the topics of oversmoothing and\noversquashing, the homophily-heterophily dichotomy, and long-range tasks, came\nwith the consolidation of commonly accepted beliefs and assumptions that are\nnot always true nor easy to distinguish from each other. We argue that this has\nled to ambiguities around the investigated problems, preventing researchers\nfrom focusing on and addressing precise research questions while causing a good\namount of misunderstandings. Our contribution wants to make such common beliefs\nexplicit and encourage critical thinking around these topics, supported by\nsimple but noteworthy counterexamples. The hope is to clarify the distinction\nbetween the different issues and promote separate but intertwined research\ndirections to address them.",
    "pdf_url": "http://arxiv.org/pdf/2505.15547v2",
    "published": "2025-05-21T14:11:59+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18204v1",
    "title": "Brownian Bridge Augmented Surrogate Simulation and Injection Planning for Geological CO$_2$ Storage",
    "authors": [
      "Haoyue Bai",
      "Guodong Chen",
      "Wangyang Ying",
      "Xinyuan Wang",
      "Nanxu Gong",
      "Sixun Dong",
      "Giulia Pedrielli",
      "Haoyu Wang",
      "Haifeng Chen",
      "Yanjie Fu"
    ],
    "abstract": "Geological CO2 storage (GCS) involves injecting captured CO2 into deep\nsubsurface formations to support climate goals. The effective management of GCS\nrelies on adaptive injection planning to dynamically control injection rates\nand well pressures to balance both storage safety and efficiency. Prior\nliterature, including numerical optimization methods and surrogate-optimization\nmethods, is limited by real-world GCS requirements of smooth state transitions\nand goal-directed planning within limited time. To address these limitations,\nwe propose a Brownian Bridge-augmented framework for surrogate simulation and\ninjection planning in GCS and develop two insights: (i) Brownian bridge as a\nsmooth state regularizer for better surrogate simulation; (ii) Brownian bridge\nas goal-time-conditioned planning guidance for improved injection planning. Our\nmethod has three stages: (i) learning deep Brownian bridge representations with\ncontrastive and reconstructive losses from historical reservoir and utility\ntrajectories, (ii) incorporating Brownian bridge-based next state interpolation\nfor simulator regularization, and (iii) guiding injection planning with\nBrownian utility-conditioned trajectories to generate high-quality injection\nplans. Experimental results across multiple datasets collected from diverse GCS\nsettings demonstrate that our framework consistently improves simulation\nfidelity and planning effectiveness while maintaining low computational\noverhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.18204v1",
    "published": "2025-05-21T14:11:46+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.11045v1",
    "title": "Procedural Environment Generation for Tool-Use Agents",
    "authors": [
      "Michael Sullivan",
      "Mareike Hartmann",
      "Alexander Koller"
    ],
    "abstract": "Although the power of LLM tool-use agents has ignited a flurry of recent\nresearch in this area, the curation of tool-use training data remains an open\nproblem$-$especially for online RL training. Existing approaches to synthetic\ntool-use data generation tend to be non-interactive, and/or non-compositional.\nWe introduce RandomWorld, a pipeline for the procedural generation of\ninteractive tools and compositional tool-use data. We show that models tuned\nvia SFT and RL on synthetic RandomWorld data improve on a range of tool-use\nbenchmarks, and set the new SoTA for two metrics on the NESTFUL dataset.\nFurther experiments show that downstream performance scales with the amount of\nRandomWorld-generated training data, opening up the possibility of further\nimprovement through the use of entirely synthetic data.",
    "pdf_url": "http://arxiv.org/pdf/2506.11045v1",
    "published": "2025-05-21T14:10:06+00:00",
    "categories": [
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15546v1",
    "title": "Decreasing Utilization of Systems with Multi-Rate Cause-Effect Chains While Reducing End-to-End Latencies",
    "authors": [
      "Luiz Maia",
      "Gerhard Fohler"
    ],
    "abstract": "The Logical Execution Time (LET) model has deterministic properties which\ndramatically reduce the complexity of analyzing temporal requirements of\nmulti-rate cause-effect chains. The configuration (length and position) of\ntask's communication intervals directly define which task instances propagate\ndata through the chain and affect end-to-end latencies. Since not all task\ninstances propagate data through the chain, the execution of these instances\nwastes processing resources. By manipulating the configuration of communication\nintervals, it is possible to control which task instances are relevant for data\npropagation and end-to-end latencies. However, since tasks can belong to more\nthan one cause-effect chain, the problem of configuring communication intervals\nbecomes non-trivial given the large number of possible configurations. In this\npaper, we present a method to decrease the waste of processing resources while\nreducing end-to-end latencies. We use a search algorithm to analyze different\ncommunication interval configurations and find the combination that best\ndecrease system utilization while reducing end-to-end latencies. By controlling\ndata propagation by means of precedence constraints, our method modifies\ncommunication intervals and controls which task instances affect end-to-end\nlatencies. Despite the sporadic release time of some task instances during the\nanalysis, our method transforms those instances into periodic tasks. We\nevaluate our work using synthetic task sets and the automotive benchmark\nproposed by BOSCH for the WATERS industrial challenge.",
    "pdf_url": "http://arxiv.org/pdf/2505.15546v1",
    "published": "2025-05-21T14:09:47+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15545v1",
    "title": "seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation",
    "authors": [
      "Andrew Caunes",
      "Thierry Chateau",
      "Vincent Fremont"
    ],
    "abstract": "3D semantic segmentation plays a pivotal role in autonomous driving and road\ninfrastructure analysis, yet state-of-the-art 3D models are prone to severe\ndomain shift when deployed across different datasets. We propose a novel\nmulti-view projection framework that excels in both domain generalization (DG)\nand unsupervised domain adaptation (UDA). Our approach first aligns Lidar scans\ninto coherent 3D scenes and renders them from multiple virtual camera poses to\ncreate a large-scale synthetic 2D dataset (PC2D). We then use it to train a 2D\nsegmentation model in-domain. During inference, the model processes hundreds of\nviews per scene; the resulting logits are back-projected to 3D with an\nocclusion-aware voting scheme to generate final point-wise labels. Our\nframework is modular and enables extensive exploration of key design\nparameters, such as view generation optimization (VGO), visualization modality\noptimization (MODO), and 2D model choice. We evaluate on the nuScenes and\nSemanticKITTI datasets under both the DG and UDA settings. We achieve\nstate-of-the-art results in UDA and close to state-of-the-art in DG, with\nparticularly large gains on large, static classes. Our code and dataset\ngeneration tools will be publicly available at\nhttps://github.com/andrewcaunes/ia4markings",
    "pdf_url": "http://arxiv.org/pdf/2505.15545v1",
    "published": "2025-05-21T14:08:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15544v3",
    "title": "A Temporal Difference Method for Stochastic Continuous Dynamics",
    "authors": [
      "Haruki Settai",
      "Naoya Takeishi",
      "Takehisa Yairi"
    ],
    "abstract": "For continuous systems modeled by dynamical equations such as ODEs and SDEs,\nBellman's principle of optimality takes the form of the Hamilton-Jacobi-Bellman\n(HJB) equation, which provides the theoretical target of reinforcement learning\n(RL). Although recent advances in RL successfully leverage this formulation,\nthe existing methods typically assume the underlying dynamics are known a\npriori because they need explicit access to the coefficient functions of\ndynamical equations to update the value function following the HJB equation. We\naddress this inherent limitation of HJB-based RL; we propose a model-free\napproach still targeting the HJB equation and propose the corresponding\ntemporal difference method. We demonstrate its potential advantages over\ntransition kernel-based formulations, both qualitatively and empirically. The\nproposed formulation paves the way toward bridging stochastic optimal control\nand model-free reinforcement learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15544v3",
    "published": "2025-05-21T14:08:34+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.11044v2",
    "title": "Boost Post-Training Quantization via Null Space Optimization for Large Language Models",
    "authors": [
      "Jiaqi Zhao",
      "Weili Guan",
      "Ming Li",
      "Miao Zhang"
    ],
    "abstract": "Existing post-training quantization methods for large language models (LLMs)\noffer remarkable success. However, the increasingly marginal performance gains\nsuggest that existing quantization strategies are insufficient to support the\ndevelopment of more compressed models. To inspire new directions for future\nresearch, this paper introduces the concept of null space into LLMs\nquantization. We argue that the quantization error can be effectively\nalleviated by constraining the post-quantization weight perturbation to lie\nwithin the null space of input activations. To prove this idea, we propose a\nplug-and-play null space projection module for existing milestone PTQ baselines\nnamed Q2N. Specifically, we first design an efficient and accurate null space\nprojection approximation method tailored to the characteristics of LLMs.\nSubsequently, we theoretically derive a closed-form solution for an equivalent\nvector of the obtained projection matrix, which satisfies practical inference\ncondition while avoiding additional memory overhead. Extensive experiments are\nconducted on various state-of-the-art LLMs (LLaMA3, DeepSeek, Qwen3) and\nbaselines, demonstrating the effectiveness of both our Q2N and the perspective\nof null space optimization for LLMs quantization. We view this paper the first\nstep to further alleviate the quantization error based on the insights of null\nspace, hoping it inspiring future researchers to design more advanced\nquantization methods. Codes are available at https://github.com/zjq0455/q2n.",
    "pdf_url": "http://arxiv.org/pdf/2506.11044v2",
    "published": "2025-05-21T14:07:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15543v1",
    "title": "Heavy-tailed and Horseshoe priors for regression and sparse Besov rates",
    "authors": [
      "Sergios Agapiou",
      "Isma√´l Castillo",
      "Paul Egels"
    ],
    "abstract": "The large variety of functions encountered in nonparametric statistics, calls\nfor methods that are flexible enough to achieve optimal or near-optimal\nperformance over a wide variety of functional classes, such as Besov balls, as\nwell as over a large array of loss functions. In this work, we show that a\nclass of heavy-tailed prior distributions on basis function coefficients\nintroduced in \\cite{AC} and called Oversmoothed heavy-Tailed (OT) priors, leads\nto Bayesian posterior distributions that satisfy these requirements; the case\nof horseshoe distributions is also investigated, for the first time in the\ncontext of nonparametrics, and we show that they fit into this framework.\nPosterior contraction rates are derived in two settings. The case of\nSobolev--smooth signals and $L_2$--risk is considered first, along with a lower\nbound result showing that the imposed form of the scalings on prior\ncoefficients by the OT prior is necessary to get full adaptation to smoothness.\nSecond, the broader case of Besov-smooth signals with $L_{p'}$--risks, $p' \\geq\n1$, is considered, and minimax posterior contraction rates, adaptive to the\nunderlying smoothness, and including rates in the so-called {\\em sparse} zone,\nare derived. We provide an implementation of the proposed method and illustrate\nour results through a simulation study.",
    "pdf_url": "http://arxiv.org/pdf/2505.15543v1",
    "published": "2025-05-21T14:05:33+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.15542v1",
    "title": "Hardware-Level QoS Enforcement Features: Technologies, Use Cases, and Research Challenges",
    "authors": [
      "Oliver Larsson",
      "Thijs Metsch",
      "Cristian Klein",
      "Erik Elmroth"
    ],
    "abstract": "Recent advancements in commodity server processors have enabled dynamic\nhardware-based quality-of-service (QoS) enforcement. These features have\ngathered increasing interest in research communities due to their versatility\nand wide range of applications. Thus, there exists a need to understand how\nscholars leverage hardware QoS enforcement in research, understand strengths\nand shortcomings, and identify gaps in current state-of-the-art research. This\npaper observes relevant publications, presents a novel taxonomy, discusses the\napproaches used, and identifies trends. Furthermore, an opportunity is\nrecognized for QoS enforcement utilization in service-based cloud computing\nenvironments, and open challenges are presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.15542v1",
    "published": "2025-05-21T14:04:55+00:00",
    "categories": [
      "cs.DC",
      "C.m; B.3.0"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15541v1",
    "title": "Some exact results on the Belinski-Khalatnikov-Lifshitz scenario",
    "authors": [
      "Piotr P. Goldstein"
    ],
    "abstract": "The well-known Bielinski-Khalatnikov-Lifshitz (BKL) scenario for the universe\nnear the cosmological singularity is supplemented with a few exact results\nfollowing from the BKL asymptotic of the Einstein equations: (1) The\ncosmological singularity is proved to be an inevitable beginning or end of the\nuniverse as described by these equations. (2) Attaining the singularity from\nshrinking initial conditions requires infinite time parameter $\\tau$; no\nsingularity of any kind may occur in a finite $\\tau$. (3) The previously found\nexact solution [P.G. and W. Piechocki, Eur. Phys. J. C 82:216 (2022)] is the\nonly asymptotic with well-defined proportions between the directional scale\nfactors which have been appropriately compensated against indefinite growth of\nanisotropy. In all other cases, the universe undergoes oscillations of Kasner\ntype, which reduce the length scales to nearly zero in some directions, while\nlargely extending it in the others. Together with instability of the exact\nsolution [op. cit.], it makes the approach to the singularity inevitably\nchaotic. (4) Reduced equations are proposed and explicitly solved to describe\nthese oscillations near their turning points. In logarithmic variables, the\noscillations are found to have sawtooth shapes. A by-product is a quadric of\nkinetic energy, a simple geometric tool for all this analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.15541v1",
    "published": "2025-05-21T14:04:43+00:00",
    "categories": [
      "gr-qc",
      "math-ph",
      "math.MP",
      "nlin.PS",
      "83F05 34D05 34E10"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15540v1",
    "title": "Quasinormal Modes of Schwarzschild Black Holes in the Dehnen-(1, 4, 5/2) Type Dark Matter Halos",
    "authors": [
      "Qi-Qi Liang",
      "Dong Liu",
      "Zheng-Wen Long"
    ],
    "abstract": "The Dehnen - type dark matter density distribution model is mainly used for\ndwarf galaxies. In recent years, researchers have speculated that black holes\nmay exist in this dark matter model and have given the black hole metric\nsolutions. On this basis, this paper conducts a systematic study on the\nquasinormal modes of a Schwarzschild black hole in a Dehnen - (1,4, 5/2) dark\nmatter halo, revealing the influences of dark matter distribution and\nperturbation field types on the black hole's quasinormal modes.The research\nuses the shadow radius data of the M87$^{\\ast}$ black hole. Through the\ngeodesic equation, two sets of dark matter halo parameter values of $\\rho_{\\rm\ns}$ and $r_{\\rm s}$ are determined, and the specific numerical values of the\nblack hole's event horizon radius, photon sphere radius, and shadow radius\nunder the corresponding conditions are obtained. The wave equations and\neffective potentials of the black hole under the perturbations of the scalar\nfield, electromagnetic field, and axial gravitational were analyzed. It was\nfound that the larger the values of $\\rho_{\\rm s}$ or $r_{\\rm s}$, the smaller\nthe peak value of the effective potential, and the wave function oscillation\nslows down with a lower frequency. The black hole remains stable under\nperturbations. These studies provide relevant data for the quasinormal modes of\nthe Schwarzschild black hole in the Dehnen-(1,4, 5/2) type dark matter halo.\nThey also offer crucial evidence for understanding the interaction mechanism\nbetween the black hole and the dark matter halo.",
    "pdf_url": "http://arxiv.org/pdf/2505.15540v1",
    "published": "2025-05-21T14:03:30+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17112v1",
    "title": "Cultural Value Alignment in Large Language Models: A Prompt-based Analysis of Schwartz Values in Gemini, ChatGPT, and DeepSeek",
    "authors": [
      "Robin Segerer"
    ],
    "abstract": "This study examines cultural value alignment in large language models (LLMs)\nby analyzing how Gemini, ChatGPT, and DeepSeek prioritize values from\nSchwartz's value framework. Using the 40-item Portrait Values Questionnaire, we\nassessed whether DeepSeek, trained on Chinese-language data, exhibits distinct\nvalue preferences compared to Western models. Results of a Bayesian ordinal\nregression model show that self-transcendence values (e.g., benevolence,\nuniversalism) were highly prioritized across all models, reflecting a general\nLLM tendency to emphasize prosocial values. However, DeepSeek uniquely\ndownplayed self-enhancement values (e.g., power, achievement) compared to\nChatGPT and Gemini, aligning with collectivist cultural tendencies. These\nfindings suggest that LLMs reflect culturally situated biases rather than a\nuniversal ethical framework. To address value asymmetries in LLMs, we propose\nmulti-perspective reasoning, self-reflective feedback, and dynamic\ncontextualization. This study contributes to discussions on AI fairness,\ncultural neutrality, and the need for pluralistic AI alignment frameworks that\nintegrate diverse moral perspectives.",
    "pdf_url": "http://arxiv.org/pdf/2505.17112v1",
    "published": "2025-05-21T14:03:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2508.00829v1",
    "title": "Open Science, Open Innovation? The Role of Open Access in Patenting Activity",
    "authors": [
      "Abdelghani Maddi",
      "Ahmad Yaman Abdin",
      "Francesco Fdp de Pretis"
    ],
    "abstract": "Scientific knowledge is a key driver of technological innovation, shaping\nindustrial development and policy decisions worldwide. Understanding how\npatents incorporate scientific research is essential for assessing the role of\nacademic discoveries in technological progress. Non-Patent References (NPRs)\nprovide a useful indicator of this relationship by revealing the extent to\nwhich patents draw upon scientific literature. Here, we show that reliance on\nscientific research in patents varies significantly across regions. Oceania and\nEurope display stronger engagement with scientific knowledge, while the\nAmericas exhibit lower reliance. Moreover, NPRs are more likely to be open\naccess than the average scientific publication, a trend that intensifies when\nSci-Hub availability is considered. These results highlight the transformative\nimpact of Open Science on global innovation dynamics. By facilitating broader\naccess to research, Open Science strengthens the link between academia and\nindustry, underscoring the need for policies that promote equitable and\nscience-based innovation, particularly in developing regions.",
    "pdf_url": "http://arxiv.org/pdf/2508.00829v1",
    "published": "2025-05-21T14:02:44+00:00",
    "categories": [
      "cs.DL"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15539v2",
    "title": "Tailoring the Electronic Configurations of YPc$_2$ on Cu(111): Decoupling Strategies for Molecular Spin Qubits Platforms",
    "authors": [
      "Soyoung Oh",
      "Franklin. H. Cho",
      "We-hyo Soe",
      "Jisoo Yu",
      "Hong Bui",
      "Lukas Spree",
      "Caroline Hommel",
      "Wonjun Jang",
      "Soo-hyon Phark",
      "Luciano Colazzo",
      "Christoph Wolf",
      "Fabio Donati"
    ],
    "abstract": "Among the potential spin qubit candidates, yttrium phthalocyanine\ndouble-decker (YPc$_2$) features a diamagnetic metal ion core that stabilizes\nthe molecular structure, while its magnetic properties arise primarily from an\nunpaired electron (S=1/2) delocalized over the two phthalocyanine (Pc) ligands.\nUnderstanding its properties in the proximity of metal electrodes is crucial to\nassess its potential use in molecular spin qubits architectures. Here, we\ninvestigated the morphology and electronic structure of this molecule adsorbed\non Cu(111) surface using scanning tunneling microscopy (STM). On Cu(111),\nYPc$_2$ adsorbs flat, with isolated molecules showing a preferred orientation\nalong the <111> crystal axes. Moreover, we observed two different types of\nself-assembly molecular packing when growing molecular patches. For YPc$_2$ in\ndirect contact with Cu(111), STM revealed a widely separated highest occupied\nand lowest unoccupied molecular orbitals (HOMO/LUMO), suggesting the quenching\nof the unpaired spin. Conversely, when YPc$_2$ is separated from the metal\nsubstrate by a few-layer thick diamagnetic zinc phthalocyanine (ZnPc) layer, we\nfound the HOMO to split into singly occupied and singly unoccupied molecular\norbitals (SOMO/SUMO). We observed that more than 2 layers of ZnPc are needed to\navoid intermixing between the two molecules and spin quenching in YPc2. Density\nfunctional theory (DFT) reveals the spin quenching is due to the hybridization\nbetween YPc$_2$ and Cu(111) states, confirming the importance of using suitable\ndecoupling layers to preserve the unpaired molecular spin. Our results suggest\nthe potential of YPc$_2$/ZnPc heterostructures as a stable and effective\nmolecular spin qubit platform and validate the possibility of integrating this\nmolecular spin qubit candidate in future quantum logic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15539v2",
    "published": "2025-05-21T14:00:29+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.15538v1",
    "title": "Machine learning-based parameter optimization for M√ºntz spectral methods",
    "authors": [
      "Wei Zeng",
      "Chuanju Xu",
      "Yiming Lu",
      "Qian Wang"
    ],
    "abstract": "Spectral methods employing non-standard polynomial bases, such as M\\\"untz\npolynomials, have proven effective for accurately solving problems with\nsolutions exhibiting low regularity, notably including sub-diffusion equations.\nHowever, due to the absence of theoretical guidance, the key parameters\ncontrolling the exponents of M\\\"untz polynomials are usually determined\nempirically through extensive numerical experiments, leading to a\ntime-consuming tuning process. To address this issue, we propose a novel\nmachine learning-based optimization framework for the M\\\"untz spectral method.\nAs an illustrative example, we optimize the parameter selection for solving\ntime-fractional partial differential equations (PDEs). Specifically, an\nartificial neural network (ANN) is employed to predict optimal parameter values\nbased solely on the time-fractional order as input. The ANN is trained by\nminimizing solution errors on a one-dimensional time-fractional\nconvection-diffusion equation featuring manufactured exact solutions that\nmanifest singularities of varying intensity, covering a comprehensive range of\nsampled fractional orders. Numerical results for time-fractional PDEs in both\none and two dimensions demonstrate that the ANN-based parameter prediction\nsignificantly improves the accuracy of the M\\\"untz spectral method. Moreover,\nthe trained ANN generalizes effectively from one-dimensional to two-dimensional\ncases, highlighting its robustness across spatial dimensions. Additionally, we\nverify that the ANN substantially outperforms traditional function\napproximators, such as spline interpolation, in both prediction accuracy and\ntraining efficiency. The proposed optimization framework can be extended beyond\nfractional PDEs, offering a versatile and powerful approach for spectral\nmethods applied to various low-regularity problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15538v1",
    "published": "2025-05-21T13:58:24+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15536v2",
    "title": "DeepCEE: Efficient Cross-Region Model Distributed Training System under Heterogeneous GPUs and Networks",
    "authors": [
      "Jinquan Wang",
      "Xiaojian Liao",
      "Xuzhao Liu",
      "Jiashun Suo",
      "Zhisheng Huo",
      "Chenhao Zhang",
      "Xiangrong Xu",
      "Runnan Shen",
      "Xilong Xie",
      "Limin Xiao"
    ],
    "abstract": "Most existing training systems focus on a single region. In contrast, we\nenvision that cross-region training offers more flexible GPU resource\nallocation and yields significant potential. However, the hierarchical cluster\ntopology and unstable networks in the cloud-edge-end (CEE) environment, a\ntypical cross-region scenario, pose substantial challenges to building an\nefficient and autonomous model training system. We propose DeepCEE, a\ngeo-distributed model training system tailored for heterogeneous GPUs and\nnetworks in CEE environments. DeepCEE adopts a communication-centric design\nphilosophy to tackle challenges arising from slow and unstable inter-region\nnetworks. It begins with a heterogeneous device profiler that identifies and\ngroups devices based on both network and compute characteristics. Leveraging\ndevice groups, DeepCEE implements compact, zero-bubble pipeline parallelism,\nautomatically deriving optimal parallel strategies. To further adapt to runtime\nvariability, DeepCEE integrates a dynamic environment adapter that reacts to\nnetwork fluctuations. Extensive evaluations demonstrate that DeepCEE achieves\n1.3-2.8x higher training throughput compared to widely used and SOTA training\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15536v2",
    "published": "2025-05-21T13:58:13+00:00",
    "categories": [
      "eess.SY",
      "cs.DC",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15537v1",
    "title": "Riemannian EXTRA: Communication-efficient decentralized optimization over compact submanifolds with data heterogeneity",
    "authors": [
      "Jiayuan Wu",
      "Zhanwang Deng",
      "Jiang Hu",
      "Weijie Su",
      "Zaiwen Wen"
    ],
    "abstract": "We consider decentralized optimization over a compact Riemannian submanifold\nin a network of $n$ agents, where each agent holds a smooth, nonconvex local\nobjective defined by its private data. The goal is to collaboratively minimize\nthe sum of these local objective functions. In the presence of data\nheterogeneity across nodes, existing algorithms typically require communicating\nboth local gradients and iterates to ensure exact convergence with constant\nstep sizes. In this work, we propose REXTRA, a Riemannian extension of the\nEXTRA algorithm [Shi et al., SIOPT, 2015], to address this limitation. On the\ntheoretical side, we leverage proximal smoothness to overcome the challenges of\nmanifold nonconvexity and establish a global sublinear convergence rate of\n$\\mathcal{O}(1/k)$, matching the best-known results. To our knowledge, REXTRA\nis the first algorithm to achieve a global sublinear convergence rate under a\nconstant step size while requiring only a single round of local iterate\ncommunication per iteration. Numerical experiments show that REXTRA achieves\nsuperior performance compared to state-of-the-art methods, while supporting\nlarger step sizes and reducing total communication by over 50\\%.",
    "pdf_url": "http://arxiv.org/pdf/2505.15537v1",
    "published": "2025-05-21T13:58:13+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15535v1",
    "title": "Matrix-Free Methods for Finite-Strain Elasticity: Automatic Code Generation with No Performance Overhead",
    "authors": [
      "Micha≈Ç Wichrowski",
      "Mohsen Rezaee-Hajidehi",
      "Jo≈æe Korelc",
      "Martin Kronbichler",
      "Stanis≈Çaw Stupkiewicz"
    ],
    "abstract": "This study explores matrix-free tangent evaluations in finite-strain\nelasticity with the use of automatically-generated code for the\nquadrature-point level calculations. The code generation is done via automatic\ndifferentiation (AD) with AceGen. We compare hand-written and AD-generated\ncodes under two computing strategies: on-the-fly evaluation and caching\nintermediate results. The comparison reveals that the AD-generated code\nachieves superior performance in matrix-free computations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15535v1",
    "published": "2025-05-21T13:56:16+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65M60, 74B20, 74S05"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15534v1",
    "title": "An enhanced extriangulated subquotient",
    "authors": [
      "Nao Mochizuki",
      "Yasuaki Ogawa"
    ],
    "abstract": "Bondal-Kapranov's enhanced triangulated categories perform nicely in the\ncontext of the localization theory, that is, the Verdier quotient is lifted to\nthe Drinfeld dg quotient of pretriangulated dg categories. In this article, we\nprovide a development of such an enhancement for Nakaoka-Palu's notion of\nextriangulated categories which contains exact and triangulated categories. The\nenhancement of them was recently initiated by Xiaofa Chen under the name of\nexact dg categories. In addition, it is known that a certain ideal quotient of\nan extriangulated category is still extriangulated, and such an extriangulated\nideal quotient was enhanced by the dg quotient of the associated connective\nexact dg category there. Motivated by Chen's enhanced extriangulated theory, we\nintroduce the notion of cohomological envelope of an exact dg category and\ngeneralize his enhanced ideal quotient. We indeed show that the dg quotient of\nexact dg categories passing to the cohomological envelope and substructures,\nwhere we call it the exact dg subquotient, enjoys compatibility with a wide\nclass of extriangulated quotients in the sense of Nakaoka-Ogawa-Sakai. To\nutilize and clarify the range of our approach, we formulate the extriangulated\nsubquotient which permits us to localize any extriangulated category by\nextension-closed subcategories. It includes not only both the ideal quotient\nand the Verdier quotient, but the quotient of an exact category by biresolving\nsubcategories. Notably the extriangulated subquotient is lifted to the exact dg\nsubquotient.",
    "pdf_url": "http://arxiv.org/pdf/2505.15534v1",
    "published": "2025-05-21T13:55:05+00:00",
    "categories": [
      "math.CT",
      "math.RT",
      "Primary 18G35, Secondary 18G80, 18E35, 16E30"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15533v1",
    "title": "Convolutional Long Short-Term Memory Neural Networks Based Numerical Simulation of Flow Field",
    "authors": [
      "Chang Liu"
    ],
    "abstract": "Computational Fluid Dynamics (CFD) is the main approach to analyzing flow\nfield. However, the convergence and accuracy depend largely on mathematical\nmodels of flow, numerical methods, and time consumption. Deep learning-based\nanalysis of flow filed provides an alternative. For the task of flow field\nprediction, an improved Convolutional Long Short-Term Memory (Con-vLSTM) Neural\nNetwork is proposed as the baseline network in consideration of the temporal\nand spatial characteristics of flow field. Combining dynamic mesh technology\nand User-Defined Function (UDF), numerical simulations of flow around a\ncircular cylinder were conducted. Flow field snapshots were used to sample data\nfrom the cylinder's wake region at different time instants, constructing a flow\nfield dataset with sufficient volume and rich flow state var-iations. Residual\nnetworks and attention mechanisms are combined with the standard ConvLSTM\nmodel. Compared with the standard ConvLSTM model, the results demonstrate that\nthe improved ConvLSTM model can extract more temporal and spatial features\nwhile having fewer parameters and shorter train-ing time.",
    "pdf_url": "http://arxiv.org/pdf/2505.15533v1",
    "published": "2025-05-21T13:54:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15532v1",
    "title": "Global well-posedness of 2D incompressible MHD equations without magnetic diffusion",
    "authors": [
      "Shijin Ding",
      "Ronghua Pan",
      "Yi Zhu"
    ],
    "abstract": "In recent years, the global existence of classical solutions to the Cauchy\nproblem for 2D incompressible viscous MHD equations without magnetic diffusion\nhas been proved in \\cite{Ren,TZhang}, under the assumption that initial data is\nclose to equilibrium states with nontrivial magnetic field, and the\nperturbation is small in some suitable spaces, say for instance, the Sobolev\nspaces with negative exponents. It leads to an interesting open question: Can\none establish the global existence of classical solutions without the extra\nhelp from Sobolev spaces with negative exponents like its counterparts of ideal\nMHD ( i.e. without viscosity and magnetic diffusion), and fully dissipative MHD\n(i.e. with both viscosity and magnetic diffusion)? This paper offers an\naffirmative answer to this question. In fact, we will establish the existence\nof a global unique solution for initial perturbations being small in\n$H^2(\\mathbb{R}^2)$. The key idea is further exploring the structure of system,\nusing dispersive effects of Alfv\\'{e}n waves in the direction which is\ntransversal to the dissipation favorable direction. This motivates our key\nstrategy to treat the wildest nonlinear terms as an artificial linear term.\nThese observations help us to construct some interesting quantities which\nimproves the nonlinearity order for the wildest terms, and to control them by\nterms with better properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.15532v1",
    "published": "2025-05-21T13:54:36+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15531v1",
    "title": "Modeling and Optimizing Latency for Delayed Hit Caching with Stochastic Miss Latency",
    "authors": [
      "Bowen Jiang",
      "Chaofan Ma"
    ],
    "abstract": "Caching is crucial for system performance, but the delayed hit phenomenon,\nwhere requests queue during lengthy fetches after a cache miss, significantly\ndegrades user-perceived latency in modern high-throughput systems. While prior\nworks address delayed hits by estimating aggregate delay, they universally\nassume deterministic fetch latencies. This paper tackles the more realistic,\nyet unexplored, scenario where fetch latencies are stochastic. We present, to\nour knowledge, the first theoretical analysis of delayed hits under this\ncondition, deriving analytical expressions for both the mean and variance of\nthe aggregate delay assuming exponentially distributed fetch latency.\nLeveraging these insights, we develop a novel variance-aware ranking function\ntailored for this stochastic setting to guide cache eviction decisions more\neffectively. The simulations on synthetic and real-world datasets demonstrate\nthat our proposed algorithm significantly reduces overall latency compared to\nstate-of-the-art delayed-hit strategies, achieving a $3\\%-30\\%$ reduction on\nsynthetic datasets and approximately $1\\%-7\\%$ reduction on real-world traces.",
    "pdf_url": "http://arxiv.org/pdf/2505.15531v1",
    "published": "2025-05-21T13:52:45+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15530v1",
    "title": "A fast deep-learning approach to probing primordial black hole populations in gravitational wave events",
    "authors": [
      "Jun-Qian Jiang",
      "Hai-Long Huang",
      "Jibin He",
      "Yu-Tong Wang",
      "Yun-Song Piao"
    ],
    "abstract": "Primordial black holes (PBHs), envisioned as a compelling dark matter\ncandidate and a window onto early-Universe physics, may contribute to the part\nof the gravitational-wave (GW) signals detected by the LIGO-Virgo-KAGRA\nnetwork. Traditional hierarchical Bayesian analysis, which relies on precise\nGW-event posterior estimates, for extracting the information of potential PBH\npopulation from GW events become computationally prohibitive for catalogs of\nhundreds of events. Here, we present a fast deep-learning framework, leveraging\nTransformer and normalizing flows, that maps GW-event posterior samples to\njoint posterior distributions over the hyperparameters of the PBH population.\nOur approach yields accurate credible intervals while reducing end-to-end\ninference time to $\\mathcal{O}(1)$ s on a single GPU. These results underscore\nthe potential of deep learning for fast, high-accurately PBH population studies\nin the era of next-generation GW detectors.",
    "pdf_url": "http://arxiv.org/pdf/2505.15530v1",
    "published": "2025-05-21T13:52:42+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "astro-ph.IM",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15529v1",
    "title": "Clapper: Compact Learning and Video Representation in VLMs",
    "authors": [
      "Lingyu Kong",
      "Hongzhi Zhang",
      "Jingyuan Zhang",
      "Jianzhao Huang",
      "Kunze Li",
      "Qi Wang",
      "Fuzheng Zhang"
    ],
    "abstract": "Current vision-language models (VLMs) have demonstrated remarkable\ncapabilities across diverse video understanding applications. Designing VLMs\nfor video inputs requires effectively modeling the temporal dimension (i.e.\ncapturing dependencies across frames) and balancing the processing of short and\nlong videos. Specifically, short videos demand preservation of fine-grained\ndetails, whereas long videos require strategic compression of visual\ninformation to handle extensive temporal contexts efficiently. However, our\nempirical analysis reveals a critical limitation: most existing VLMs suffer\nsevere performance degradation in long video understanding tasks when\ncompressing visual tokens below a quarter of their original visual tokens. To\nenable more effective modeling of both short and long video inputs, we propose\nClapper, a method that utilizes a slow-fast strategy for video representation\nand introduces a novel module named TimePerceiver for efficient\ntemporal-spatial encoding within existing VLM backbones. By using our method,\nwe achieves 13x compression of visual tokens per frame (averaging 61\ntokens/frame) without compromising QA accuracy. In our experiments, Clapper\nachieves 62.0% on VideoMME, 69.8% on MLVU, and 67.4% on TempCompass, all with\nfewer than 6,000 visual tokens per video. The code will be publicly available\non the homepage.",
    "pdf_url": "http://arxiv.org/pdf/2505.15529v1",
    "published": "2025-05-21T13:52:17+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15528v1",
    "title": "PlantDreamer: Achieving Realistic 3D Plant Models with Diffusion-Guided Gaussian Splatting",
    "authors": [
      "Zane K J Hartley",
      "Lewis A G Stuart",
      "Andrew P French",
      "Michael P Pound"
    ],
    "abstract": "Recent years have seen substantial improvements in the ability to generate\nsynthetic 3D objects using AI. However, generating complex 3D objects, such as\nplants, remains a considerable challenge. Current generative 3D models struggle\nwith plant generation compared to general objects, limiting their usability in\nplant analysis tools, which require fine detail and accurate geometry. We\nintroduce PlantDreamer, a novel approach to 3D synthetic plant generation,\nwhich can achieve greater levels of realism for complex plant geometry and\ntextures than available text-to-3D models. To achieve this, our new generation\npipeline leverages a depth ControlNet, fine-tuned Low-Rank Adaptation and an\nadaptable Gaussian culling algorithm, which directly improve textural realism\nand geometric integrity of generated 3D plant models. Additionally,\nPlantDreamer enables both purely synthetic plant generation, by leveraging\nL-System-generated meshes, and the enhancement of real-world plant point clouds\nby converting them into 3D Gaussian Splats. We evaluate our approach by\ncomparing its outputs with state-of-the-art text-to-3D models, demonstrating\nthat PlantDreamer outperforms existing methods in producing high-fidelity\nsynthetic plants. Our results indicate that our approach not only advances\nsynthetic plant generation, but also facilitates the upgrading of legacy point\ncloud datasets, making it a valuable tool for 3D phenotyping applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15528v1",
    "published": "2025-05-21T13:51:57+00:00",
    "categories": [
      "cs.CV",
      "cs.GR",
      "I.2.10; I.3.0; I.4.5"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15527v1",
    "title": "The effects of expansion and turbulence on the interplanetary evolution of a magnetic cloud",
    "authors": [
      "Mattia Sangalli",
      "Andrea Verdini",
      "Simone Landi",
      "Emanuele Papini"
    ],
    "abstract": "Coronal mass ejections (CMEs) represent the most extreme solar products,\nshowing complex and dynamic structures when detected in situ. They are often\npreceded by a shock and carry a magnetic cloud organised as a flux rope,\nsurrounded and permeated by turbulent fluctuations, and whose radial size\nexpands during propagation. We investigate the internal dynamics of the 2D\nsection of a cylindrical flux rope propagating at constant velocity in the\nspherically expanding solar wind, employing the expanding box model, which\nallows for high spatial resolution. Our setting is simplified, with uniform and\nnon-magnetised solar wind, to which we superpose turbulent fluctuations. We\nfind that the spherically expanding geometry alone perturbs the flux rope\nequilibrium, producing a radial head-tail velocity profile and a radial size\nincrease. The ratio between the expansion and Alfv\\'en timescales, associated\nrespectively to propagation and internal crossing time, controls the resistance\nto transverse stretching and the increase of the flux rope radial extent; the\nplasma beta controls the overall size of the structure. Turbulent fluctuations\nmainly affect the flux rope transverse structure, spreading its axial field at\ndistances comparable to its size; on the contrary, dynamics along the radial\ndirection remains coherent and the increase in radial size is still\nconsistently observed. We validate our results by comparison with statistical\nobservations and dimensionless estimates, such as the expansion parameter and\nthe radial size scaling exponent, suggesting that the ratio between internal\nand propagation timescales might help in better classifying different kinds of\nradial expansions for flux ropes.",
    "pdf_url": "http://arxiv.org/pdf/2505.15527v1",
    "published": "2025-05-21T13:51:33+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15525v1",
    "title": "Continuous-time iterative linear-quadratic regulator",
    "authors": [
      "Juraj Lieskovsk√Ω",
      "Jaroslav Bu≈°ek",
      "Tom√°≈° Vyhl√≠dal"
    ],
    "abstract": "We present a continuous-time equivalent to the well-known iterative\nlinear-quadratic algorithm including an implementation of a backtracking\nline-search policy and a novel regularization approach based on the necessary\nconditions in the Riccati pass of the linear-quadratic regulator. This allows\nthe algorithm to effectively solve trajectory optimization problems with\nnon-convex cost functions, which is demonstrated on the cart-pole swing-up\nproblem. The algorithm compatibility with state-of-the-art suites of numerical\nintegration solvers allows for the use of high-order adaptive-step methods.\nTheir use results in a variable number of time steps both between passes of the\nalgorithm and across iterations, maintaining a balance between the number of\nfunction evaluations and the discretization error.",
    "pdf_url": "http://arxiv.org/pdf/2505.15525v1",
    "published": "2025-05-21T13:51:27+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC",
      "93D15",
      "I.6.4; I.6.5"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15526v1",
    "title": "Measuring inequality in society-oriented Lotka--Volterra-type kinetic equations",
    "authors": [
      "Marco Menale",
      "Giuseppe Toscani"
    ],
    "abstract": "We present a possible approach to measuring inequality in a system of coupled\nFokker-Planck-type equations that describe the evolution of distribution\ndensities for two populations interacting pairwise due to social and/or\neconomic factors. The macroscopic dynamics of their mean values follow a\nLotka-Volterra system of ordinary differential equations. Unlike classical\nmodels of wealth and opinion formation, which tend to converge toward a\nsteady-state profile, the oscillatory behavior of these densities only leads to\nthe formation of local equilibria within the Fokker-Planck system. This makes\ntracking the evolution of most inequality measures challenging. However, an\ninsightful perspective on the problem is obtained by using the coefficient of\nvariation, a simple inequality measure closely linked to the Gini index.\nNumerical experiments confirm that, despite the system's oscillatory nature,\ninequality initially tends to decrease.",
    "pdf_url": "http://arxiv.org/pdf/2505.15526v1",
    "published": "2025-05-21T13:51:27+00:00",
    "categories": [
      "q-fin.GN",
      "math-ph",
      "math.MP",
      "physics.soc-ph",
      "35Q20 35Q84 91B80"
    ],
    "primary_category": "q-fin.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.15524v1",
    "title": "Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs",
    "authors": [
      "Lang Gao",
      "Kaiyang Wan",
      "Wei Liu",
      "Chenxi Wang",
      "Zirui Song",
      "Zixiang Xu",
      "Yanbo Wang",
      "Veselin Stoyanov",
      "Xiuying Chen"
    ],
    "abstract": "Bias in Large Language Models (LLMs) significantly undermines their\nreliability and fairness. We focus on a common form of bias: when two reference\nconcepts in the model's concept space, such as sentiment polarities (e.g.,\n\"positive\" and \"negative\"), are asymmetrically correlated with a third, target\nconcept, such as a reviewing aspect, the model exhibits unintended bias. For\ninstance, the understanding of \"food\" should not skew toward any particular\nsentiment. Existing bias evaluation methods assess behavioral differences of\nLLMs by constructing labeled data for different social groups and measuring\nmodel responses across them, a process that requires substantial human effort\nand captures only a limited set of social concepts. To overcome these\nlimitations, we propose BiasLens, a test-set-free bias analysis framework based\non the structure of the model's vector space. BiasLens combines Concept\nActivation Vectors (CAVs) with Sparse Autoencoders (SAEs) to extract\ninterpretable concept representations, and quantifies bias by measuring the\nvariation in representational similarity between the target concept and each of\nthe reference concepts. Even without labeled data, BiasLens shows strong\nagreement with traditional bias evaluation metrics (Spearman correlation r >\n0.85). Moreover, BiasLens reveals forms of bias that are difficult to detect\nusing existing methods. For example, in simulated clinical scenarios, a\npatient's insurance status can cause the LLM to produce biased diagnostic\nassessments. Overall, BiasLens offers a scalable, interpretable, and efficient\nparadigm for bias discovery, paving the way for improving fairness and\ntransparency in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15524v1",
    "published": "2025-05-21T13:50:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15523v1",
    "title": "Exciton-defect interaction and optical properties from a first-principles T-matrix approach",
    "authors": [
      "Yang-hao Chan",
      "Jonah B. Haber",
      "Mit H. Naik",
      "Diana Y. Qiu",
      "Felipe H. da Jornada"
    ],
    "abstract": "Understanding exciton-defect interactions is critical for optimizing\noptoelectronic and quantum information applications in many materials. However,\nab initio simulations of material properties with defects are often limited to\nhigh defect density. Here, we study effects of exciton-defect interactions on\noptical absorption and photoluminescence spectra in monolayer MoS2 using a\nfirst-principles T-matrix approach. We demonstrate that exciton-defect bound\nstates can be captured by the disorder-averaged Green's function with the\nT-matrix approximation and further analyze their optical properties. Our\napproach yields photoluminescence spectra in good agreement with experiments\nand provides a new, computationally efficient framework for simulating optical\nproperties of disordered 2D materials from first-principles.",
    "pdf_url": "http://arxiv.org/pdf/2505.15523v1",
    "published": "2025-05-21T13:49:03+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15522v1",
    "title": "First-principles calculations of transport coefficients in Weyl semimetal TaAs",
    "authors": [
      "Guillaume E. Allemand",
      "Matteo Giantomassi",
      "Matthieu J. Verstraete"
    ],
    "abstract": "We study charge and heat transport from first-principles in the topological\nWeyl semimetal TaAs. Electron-phonon coupling matrix elements are calculated\nusing density functional perturbation theory and used to derive the\nthermo-electric transport coefficients, including the electrical conductivity,\nSeebeck coefficient, electronic thermal conductivity and the Peltier\ncoefficient. We compare the self-energy and momentum relaxation time\napproximations to the iterative solution of the Boltzmann Transport Equation,\nfinding they give similar results for TaAs provided the chemical potential is\ntreated accurately. For the iterative method, we derive an additional equation,\nwhich is needed to fully solve for transport under both thermal and an\nelectrical potential gradients. Interestingly, the Onsager reciprocity between\n$S$ and $\\Pi$ is no longer imposed, and we can deal with systems breaking\ntime-reversal symmetry, in particular magnetic materials. We compare our\nresults with the available experimental data for TaAs: the agreement is\nexcellent for $\\sigma_{xx}$, while $\\sigma_{zz}$ is overestimated, probably due\nto differences in experimental carrier concentrations. The Seebeck coefficient\nis of the same order of magnitude in theory and experiments, and we find that\nits low-T behavior also strongly depends on the doping level.",
    "pdf_url": "http://arxiv.org/pdf/2505.15522v1",
    "published": "2025-05-21T13:47:54+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15521v1",
    "title": "Prethermalization, shadowing breakdown, and the absence of Trotterization transition in quantum circuits",
    "authors": [
      "Marko Znidaric"
    ],
    "abstract": "One of premier utilities of present day noisy quantum computers is simulation\nof many-body quantum systems. We study how long in time is such a discrete-time\nsimulation representative of a continuous time Hamiltonian evolution, namely, a\nfinite time-step introduces so-called Trotterization errors. We show that the\ntruncated operator propagator (Ruelle-Pollicott resonances) is a powerful tool\nto that end, as well as to study prethermalization and discrete time crystals,\nincluding finding those phenomena at large gate duration, and can be used to\ncalculate diffusion constant. We show that the effective energy is more stable\nthan suggested by Trotter errors -- a manifestation of prethermalization --\nwhile all other observables are not. Even such the most stable observable\nthough deteriorates in the thermodynamic limit. Different than in classical\nsystems with the strongest chaos, where the faithfulness time (the shadowing\ntime) can be infinite, in quantum many-body chaotic systems it is finite. A\ncorollary of our results is also that, opposite to previous claims, there is no\nTrotterization transition in non-integrable many-body quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15521v1",
    "published": "2025-05-21T13:46:39+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15520v2",
    "title": "A Multi-Tiered Bayesian Network Coastal Compound Flood Analysis Framework",
    "authors": [
      "Ziyue Liu",
      "Meredith L. Carr",
      "Norberto C. Nadal-Caraballo",
      "Luke A. Aucoin",
      "Madison C. Yawn",
      "Michelle T. Bensi"
    ],
    "abstract": "Coastal compound floods (CCFs) are triggered by the interaction of multiple\nmechanisms, such as storm surges, storm rainfall, tides, and river flow. These\nevents can bring significant damage to communities, and there is an increasing\ndemand for accurate and efficient probabilistic analyses of CCFs to support\nrisk assessments and decision-making. In this study, a multi-tiered Bayesian\nnetwork (BN) CCF analysis framework is established. In this framework,\nconceptual designs of multiple tiers of BN models with varying complexities are\ndeveloped for application with varying levels of data availability and\nresources. A case study is conducted in New Orleans, LA, with three tiers of BN\nmodels constructed to demonstrate this framework. In the Tier-1 BN model, storm\nsurges and river flow are incorporated based on hydrodynamic simulations. A\nseasonality node is used to capture the dependence between concurrent river\nflow and tropical cyclone (TC) parameters. In the Tier-2 BN model, joint\ndistribution models of TC parameters are built for separate TC intensity\ncategories. TC-induced rainfall is modeled as input to hydraulic simulations.\nIn the Tier-3 BN model, potential variations of meteorological conditions are\nincorporated by quantifying their effects on TC activity and coastal water\nlevel. Flood antecedent conditions are also incorporated to more completely\nrepresent the conditions contributing to flood severity. In this case study, a\nseries of joint distribution, numerical, machine learning, and experimental\nmodels are used to compute conditional probability tables needed for the BNs. A\nseries of probabilistic analyses is performed based on these BN models,\nincluding CCF hazard curve construction and CCF deaggregation. The results of\nthe analysis demonstrate the promise of this framework in performing CCF hazard\nanalysis under varying levels of resource availability and project needs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15520v2",
    "published": "2025-05-21T13:44:40+00:00",
    "categories": [
      "physics.ao-ph",
      "stat.AP"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15519v1",
    "title": "Exploiting Age of Information in Network Digital Twins for AI-driven Real-Time Link Blockage Detection",
    "authors": [
      "Michele Zhu",
      "Francesco Linsalata",
      "Silvia Mura",
      "Lorenzo Cazzella",
      "Damiano Badini",
      "Umberto Spagnolini"
    ],
    "abstract": "The Line-of-Sight (LoS) identification is crucial to ensure reliable\nhigh-frequency communication links, especially those vulnerable to blockages.\nNetwork Digital Twins and Artificial Intelligence are key technologies enabling\nblockage detection (LoS identification) for high-frequency wireless systems,\ne.g., 6>GHz. In this work, we enhance Network Digital Twins by incorporating\nAge of Information (AoI) metrics, a quantification of status update freshness,\nenabling reliable real-time blockage detection (LoS identification) in dynamic\nwireless environments. By integrating raytracing techniques, we automate\nlarge-scale collection and labeling of channel data, specifically tailored to\nthe evolving conditions of the environment. The introduced AoI is integrated\nwith the loss function to prioritize more recent information to fine-tune deep\nlearning models in case of performance degradation (model drift). The\neffectiveness of the proposed solution is demonstrated in realistic urban\nsimulations, highlighting the trade-off between input resolution, computational\ncost, and model performance. A resolution reduction of 4x8 from an original\nchannel sample size of (32, 1024) along the angle and subcarrier dimension\nresults in a computational speedup of 32 times. The proposed fine-tuning\nsuccessfully mitigates performance degradation while requiring only 1% of the\navailable data samples, enabling automated and fast mitigation of model drifts.",
    "pdf_url": "http://arxiv.org/pdf/2505.15519v1",
    "published": "2025-05-21T13:43:47+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15518v1",
    "title": "Detection of Underwater Multi-Targets Based on Self-Supervised Learning and Deformable Path Aggregation Feature Pyramid Network",
    "authors": [
      "Chang Liu"
    ],
    "abstract": "To overcome the constraints of the underwater environment and improve the\naccuracy and robustness of underwater target detection models, this paper\ndevelops a specialized dataset for underwater target detection and proposes an\nefficient algorithm for underwater multi-target detection. A self-supervised\nlearning based on the SimSiam structure is employed for the pre-training of\nunderwater target detection network. To address the problems of low detection\naccuracy caused by low contrast, mutual occlusion and dense distribution of\nunderwater targets in underwater object detection, a detection model suitable\nfor underwater target detection is proposed by introducing deformable\nconvolution and dilated convolution. The proposed detection model can obtain\nmore effective information by increasing the receptive field. In addition, the\nregression loss function EIoU is introduced, which improves model performance\nby separately calculating the width and height losses of the predicted box.\nExperiment results show that the accuracy of the underwater target detection\nhas been improved by the proposed detector.",
    "pdf_url": "http://arxiv.org/pdf/2505.15518v1",
    "published": "2025-05-21T13:43:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15517v2",
    "title": "Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets",
    "authors": [
      "Kaiyuan Chen",
      "Shuangyu Xie",
      "Zehan Ma",
      "Pannag R Sanketi",
      "Ken Goldberg"
    ],
    "abstract": "Vision-Language Models (VLMs) acquire real-world knowledge and general\nreasoning ability through Internet-scale image-text corpora. They can augment\nrobotic systems with scene understanding and task planning, and assist\nvisuomotor policies that are trained on robot trajectory data. We explore the\nreverse paradigm - using rich, real, multi-modal robot trajectory data to\nenhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual\nQuestion Answering (VQA) dataset generation framework for VLMs. Given a human\ntele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual\nand non-descriptive sensory modalities, such as end-effector pose, gripper\naperture, and force sensing. Based on these modalities, it segments the robot\ntrajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses\nscene and interaction understanding to identify 3D properties of the robot,\ntask goal, and the target object. The properties are used to generate\nrepresentative VQA queries - images with textural multiple-choice questions -\nbased on spatial, goal-conditioned, and interaction reasoning question\ntemplates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710\nquestions covering 463 distinct scenes and 3,396 robotic manipulation tasks\nfrom 176k real robot trajectories. Results suggest that Robo2VLM-1 can\nbenchmark and improve VLM capabilities in spatial and interaction reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15517v2",
    "published": "2025-05-21T13:42:52+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15516v1",
    "title": "Explainable embeddings with Distance Explainer",
    "authors": [
      "Christiaan Meijer",
      "E. G. Patrick Bos"
    ],
    "abstract": "While eXplainable AI (XAI) has advanced significantly, few methods address\ninterpretability in embedded vector spaces where dimensions represent complex\nabstractions. We introduce Distance Explainer, a novel method for generating\nlocal, post-hoc explanations of embedded spaces in machine learning models. Our\napproach adapts saliency-based techniques from RISE to explain the distance\nbetween two embedded data points by assigning attribution values through\nselective masking and distance-ranked mask filtering. We evaluate Distance\nExplainer on cross-modal embeddings (image-image and image-caption pairs) using\nestablished XAI metrics including Faithfulness, Sensitivity/Robustness, and\nRandomization. Experiments with ImageNet and CLIP models demonstrate that our\nmethod effectively identifies features contributing to similarity or\ndissimilarity between embedded data points while maintaining high robustness\nand consistency. We also explore how parameter tuning, particularly mask\nquantity and selection strategy, affects explanation quality. This work\naddresses a critical gap in XAI research and enhances transparency and\ntrustworthiness in deep learning applications utilizing embedded spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.15516v1",
    "published": "2025-05-21T13:42:28+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "68T99",
      "I.2.m"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15515v1",
    "title": "From learning to safety: A Direct Data-Driven Framework for Constrained Control",
    "authors": [
      "Kanghui He",
      "Shengling Shi",
      "Ton van den Boom",
      "Bart De Schutter"
    ],
    "abstract": "Ensuring safety in the sense of constraint satisfaction for learning-based\ncontrol is a critical challenge, especially in the model-free case. While\nsafety filters address this challenge in the model-based setting by modifying\nunsafe control inputs, they typically rely on predictive models derived from\nphysics or data. This reliance limits their applicability for advanced\nmodel-free learning control methods. To address this gap, we propose a new\noptimization-based control framework that determines safe control inputs\ndirectly from data. The benefit of the framework is that it can be updated\nthrough arbitrary model-free learning algorithms to pursue optimal performance.\nAs a key component, the concept of direct data-driven safety filters (3DSF) is\nfirst proposed. The framework employs a novel safety certificate, called the\nstate-action control barrier function (SACBF). We present three different\nschemes to learn the SACBF. Furthermore, based on input-to-state safety\nanalysis, we present the error-to-state safety analysis framework, which\nprovides formal guarantees on safety and recursive feasibility even in the\npresence of learning inaccuracies. The proposed control framework bridges the\ngap between model-free learning-based control and constrained control, by\ndecoupling performance optimization from safety enforcement. Simulations on\nvehicle control illustrate the superior performance regarding constraint\nsatisfaction and task achievement compared to model-based methods and reward\nshaping.",
    "pdf_url": "http://arxiv.org/pdf/2505.15515v1",
    "published": "2025-05-21T13:39:45+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15514v1",
    "title": "AM-PPO: (Advantage) Alpha-Modulation with Proximal Policy Optimization",
    "authors": [
      "Soham Sane"
    ],
    "abstract": "Proximal Policy Optimization (PPO) is a widely used reinforcement learning\nalgorithm that heavily relies on accurate advantage estimates for stable and\nefficient training. However, raw advantage signals can exhibit significant\nvariance, noise, and scale-related issues, impeding optimal learning\nperformance. To address this challenge, we introduce Advantage Modulation PPO\n(AM-PPO), a novel enhancement of PPO that adaptively modulates advantage\nestimates using a dynamic, non-linear scaling mechanism. This adaptive\nmodulation employs an alpha controller that dynamically adjusts the scaling\nfactor based on evolving statistical properties of the advantage signals, such\nas their norm, variance, and a predefined target saturation level. By\nincorporating a tanh-based gating function driven by these adaptively scaled\nadvantages, AM-PPO reshapes the advantage signals to stabilize gradient updates\nand improve the conditioning of the policy gradient landscape. Crucially, this\nmodulation also influences value function training by providing consistent and\nadaptively conditioned learning targets. Empirical evaluations across standard\ncontinuous control benchmarks demonstrate that AM-PPO achieves superior reward\ntrajectories, exhibits sustained learning progression, and significantly\nreduces the clipping required by adaptive optimizers. These findings underscore\nthe potential of advantage modulation as a broadly applicable technique for\nenhancing reinforcement learning optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.15514v1",
    "published": "2025-05-21T13:38:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15513v1",
    "title": "Hybridization theory for plasmon resonance in metallic nanostructures",
    "authors": [
      "Qi Lei",
      "Hongyu Liu",
      "Zhi-Qiang Miao",
      "Guang-Hui Zheng"
    ],
    "abstract": "In this paper, we investigate the hybridization theory of plasmon resonance\nin metallic nanostructures, which has been validated by the authors in [31]\nthrough a series of experiments. In an electrostatic field, we establish a\nmathematical framework for the Neumann-Poincar\\'{e}(NP) type operators for\nmetallic nanoparticles with general geometries related to core and shell\nscales. We calculate the plasmon resonance frequency of concentric disk metal\nnanoshells with normal perturbations at the interfaces by the asymptotic\nanalysis and perturbation theory to reveal the intrinsic hybridization between\nsolid and cavity plasmon modes. The theoretical finding are convincingly\nsupported by extensive numerical experiments. Our theory corroborates and\nstrengthens that by properly enriching the materials structures as well as the\nunderlying geometries, one can induce much richer plasmon resonance phenomena\nof practical significance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15513v1",
    "published": "2025-05-21T13:36:01+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15512v1",
    "title": "Deterministic Quantum Search for Arbitrary Initial Success Probabilities",
    "authors": [
      "Harishankar Mishra",
      "Asvija Balasubramanyam",
      "Gudapati Naresh Raghava"
    ],
    "abstract": "Unstructured search remains as one of the significant challenges in computer\nscience, as classical search algorithms become increasingly impractical for\nlarge-scale systems due to their linear time complexity. Quantum algorithms,\nnotably Grover's algorithm, leverages quantum parallelism to achieve quadratic\nspeedup over classical approaches. Its generalization, the amplitude\namplification algorithm, extends this advantage to a broader class of search\nproblems. However, both algorithms are inherently probabilistic and fail to\nguarantee success with certainty, also they offer no quantum advantage when the\ninitial success probability exceeds 0.5. This work presents a deterministic\nquantum search algorithm that operates effectively for arbitrary initial\nsuccess probabilities, providing guaranteed success in searching target states.\nThe proposed approach introduces at most one additional iteration beyond the\noptimal count required by probabilistic quantum search algorithms. The\nalgorithm preserves the quadratic speedup characteristic of quantum search\nmethods. Additionally, an approach is proposed for the exact search of multiple\ntarget states within a bounded number of steps. A complete circuit-level\nimplementation of the proposed algorithm is also presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.15512v1",
    "published": "2025-05-21T13:35:42+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15511v1",
    "title": "NOMAD Projection",
    "authors": [
      "Brandon Duderstadt",
      "Zach Nussbaum",
      "Laurens van der Maaten"
    ],
    "abstract": "The rapid adoption of generative AI has driven an explosion in the size of\ndatasets consumed and produced by AI models. Traditional methods for\nunstructured data visualization, such as t-SNE and UMAP, have not kept up with\nthe pace of dataset scaling. This presents a significant challenge for AI\nexplainability, which relies on methods such as t-SNE and UMAP for exploratory\ndata analysis. In this paper, we introduce Negative Or Mean Affinity\nDiscrimination (NOMAD) Projection, the first method for unstructured data\nvisualization via nonlinear dimensionality reduction that can run on multiple\nGPUs at train time. We provide theory that situates NOMAD Projection as an\napproximate upper bound on the InfoNC-t-SNE loss, and empirical results that\ndemonstrate NOMAD Projection's superior performance and speed profile compared\nto existing state-of-the-art methods. We demonstrate the scalability of NOMAD\nProjection by computing the first complete data map of Multilingual Wikipedia.",
    "pdf_url": "http://arxiv.org/pdf/2505.15511v1",
    "published": "2025-05-21T13:35:13+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18203v1",
    "title": "Stationary Solution of p-Order Cloud Model via Stochastic Recurrence Equation",
    "authors": [
      "Biao Hu",
      "Minyue Wang"
    ],
    "abstract": "This paper investigates the generative mechanism of the p-order cloud model,\nwhich is a mathematical framework for representing uncertainty with\napplications in image processing, evaluation, and decision-making systems. By\nemploying a reparameterization technique, we reformulate the cloud model as a\nstochastic recurrence equation (SRE) with a nonlinear transformation involving\nan absolute value. Under standard assumptions of stationarity, ergodicity, and\nan appropriate integrability condition, we establish the existence and\nuniqueness of a stationary solution. In particular, we demonstrate that the\nlogarithmic moment of the model's coefficient, modeled as a standard normal\nrandom variable, is negative, thereby ensuring almost sure convergence. These\nresults provide new insights into the stochastic stability of cloud models and\noffer a rigorous foundation for further theoretical and practical developments\nin uncertainty quantification.",
    "pdf_url": "http://arxiv.org/pdf/2505.18203v1",
    "published": "2025-05-21T13:30:08+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15510v1",
    "title": "Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought",
    "authors": [
      "Zihui Cheng",
      "Qiguang Chen",
      "Xiao Xu",
      "Jiaqi Wang",
      "Weiyun Wang",
      "Hao Fei",
      "Yidong Wang",
      "Alex Jinpeng Wang",
      "Zhi Chen",
      "Wanxiang Che",
      "Libo Qin"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in\nmultimodal tasks, with multimodal chain-of-thought (MCoT) further enhancing\nperformance and interpretability. Recent MCoT methods fall into two categories:\n(i) Textual-MCoT (T-MCoT), which takes multimodal input and produces textual\noutput; and (ii) Interleaved-MCoT (I-MCoT), which generates interleaved\nimage-text outputs. Despite advances in both approaches, the mechanisms driving\nthese improvements are not fully understood. To fill this gap, we first reveal\nthat MCoT boosts LVLMs by incorporating visual thoughts, which convey image\ninformation to the reasoning process regardless of the MCoT format, depending\nonly on clarity and conciseness of expression. Furthermore, to explore visual\nthoughts systematically, we define four distinct forms of visual thought\nexpressions and analyze them comprehensively. Our findings demonstrate that\nthese forms differ in clarity and conciseness, yielding varying levels of MCoT\nimprovement. Additionally, we explore the internal nature of visual thoughts,\nfinding that visual thoughts serve as intermediaries between the input image\nand reasoning to deeper transformer layers, enabling more advanced visual\ninformation transmission. We hope that the visual thoughts can inspire further\nbreakthroughs for future MCoT research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15510v1",
    "published": "2025-05-21T13:29:58+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15509v1",
    "title": "Milstein-type methods for strong approximation of systems of SDEs with a discontinuous drift coefficient",
    "authors": [
      "Christopher Rauh√∂gger"
    ],
    "abstract": "We study strong approximation of $d$-dimensional stochastic differential\nequations (SDEs) with a discontinuous drift coefficient driven by a\n$d$-dimensional\n  Brownian motion $W$.\n  More precisely, we essentially assume that the drift coefficient $\\mu$ is\npiecewise Lipschitz continuous with an exceptional set $\\Theta\\subset\n\\mathbb{R}^d$\n  that is an orientable $C^5$-hypersurface of positive reach, the diffusion\ncoefficient $\\sigma$ is assumed to be\n  Lipschitz continuous and, in a neighborhood of $\\Theta$, both coefficients\nare bounded and $\\sigma$ is non-degenerate.\n  Furthermore, both $\\mu$ and $\\sigma$ are assumed to be $C^{1}$ with intrinsic\nLipschitz continuous derivative on $\\mathbb{R}^{d}\\setminus \\Theta$.\n  We introduce, for the first time in literature, a Milstein-type method which\ncan be used to approximate SDEs of this type for general $d \\in \\mathbb{N}$ and\nprove\n  that this Milstein-type scheme achieves an $L_{p}$-error rate of order at\nleast $3/4-$ in terms of the number of steps. This method depends, in addition\nto evaluations of $W$ on a fixed grid, also on iterated integrals w.r.t.\ncomponents of $W$, which can in general not be represented as functionals of\n$W$ evaluated at finitely many time points. We additionally prove that our\nsuggested Milstein-type method is only dependent on evaluations of $W$ on a\nfinite, fixed grid if $\\sigma$ is additionally commutative.\n  To obtain our main result we prove that a quasi-Milstein scheme achieves an\n$L_{p}$-error rate of order at least $3/4-$ in our setting if $\\mu$ is\nadditionally continuous, which is of interest in itself.",
    "pdf_url": "http://arxiv.org/pdf/2505.15509v1",
    "published": "2025-05-21T13:28:30+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15508v1",
    "title": "Multilingual Test-Time Scaling via Initial Thought Transfer",
    "authors": [
      "Prasoon Bajpai",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Test-time scaling has emerged as a widely adopted inference-time strategy for\nboosting reasoning performance. However, its effectiveness has been studied\nalmost exclusively in English, leaving its behavior in other languages largely\nunexplored. We present the first systematic study of test-time scaling in\nmultilingual settings, evaluating DeepSeek-R1-Distill-LLama-8B and\nDeepSeek-R1-Distill-Qwen-7B across both high- and low-resource Latin-script\nlanguages. Our findings reveal that the relative gains from test-time scaling\nvary significantly across languages. Additionally, models frequently switch to\nEnglish mid-reasoning, even when operating under strictly monolingual prompts.\nWe further show that low-resource languages not only produce initial reasoning\nthoughts that differ significantly from English but also have lower internal\nconsistency across generations in their early reasoning. Building on our\nfindings, we introduce MITT (Multilingual Initial Thought Transfer), an\nunsupervised and lightweight reasoning prefix-tuning approach that transfers\nhigh-resource reasoning prefixes to enhance test-time scaling across all\nlanguages, addressing inconsistencies in multilingual reasoning performance.\nMITT significantly boosts DeepSeek-R1-Distill-Qwen-7B's reasoning performance,\nespecially for underrepresented languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.15508v1",
    "published": "2025-05-21T13:27:38+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15507v1",
    "title": "Directional Non-Commutative Monoidal Structures for Compositional Embeddings in Machine Learning",
    "authors": [
      "Mahesh Godavarti"
    ],
    "abstract": "We introduce a new algebraic structure for multi-dimensional compositional\nembeddings, built on directional non-commutative monoidal operators. The core\ncontribution of this work is this novel framework, which exhibits appealing\ntheoretical properties (associativity along each dimension and an interchange\nlaw ensuring global consistency) while remaining compatible with modern machine\nlearning architectures. Our construction defines a distinct composition\noperator circ_i for each axis i, ensuring associative combination along each\naxis without imposing global commutativity. Importantly, all axis-specific\noperators commute with one another, enforcing a global interchange law that\nenables consistent crossaxis compositions. This is, to our knowledge, the first\napproach that provides a common foundation that generalizes classical\nsequence-modeling paradigms (e.g., structured state-space models (SSMs) and\ntransformer self-attention) to a unified multi-dimensional framework. For\nexample, specific one-dimensional instances of our framework can recover the\nfamiliar affine transformation algebra, vanilla self-attention, and the\nSSM-style recurrence. The higher-dimensional generalizations naturally support\nrecursive, structure-aware operations in embedding spaces. We outline several\npotential applications unlocked by this structure-including structured\npositional encodings in Transformers, directional image embeddings, and\nsymbolic modeling of sequences or grids-indicating that it could inform future\ndeep learning model designs. We formally establish the algebraic properties of\nour framework and discuss efficient implementations. Finally, as our focus is\ntheoretical, we include no experiments here and defer empirical validation to\nfuture work, which we plan to undertake.",
    "pdf_url": "http://arxiv.org/pdf/2505.15507v1",
    "published": "2025-05-21T13:27:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "20-XX, 08A02",
      "F.4.1; I.2"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15506v1",
    "title": "Prompt Tuning Vision Language Models with Margin Regularizer for Few-Shot Learning under Distribution Shifts",
    "authors": [
      "Debarshi Brahma",
      "Anuska Roy",
      "Soma Biswas"
    ],
    "abstract": "Recently, Vision-Language foundation models like CLIP and ALIGN, which are\npre-trained on large-scale data have shown remarkable zero-shot generalization\nto diverse datasets with different classes and even domains. In this work, we\ntake a step further and analyze whether these models can be adapted to target\ndatasets having very different distributions and classes compared to what these\nmodels have been trained on, using only a few labeled examples from the target\ndataset. In such scenarios, finetuning large pretrained models is challenging\ndue to problems of overfitting as well as loss of generalization, and has not\nbeen well explored in prior literature. Since, the pre-training data of such\nmodels are unavailable, it is difficult to comprehend the performance on\nvarious downstream datasets. First, we try to answer the question: Given a\ntarget dataset with a few labelled examples, can we estimate whether further\nfine-tuning can enhance the performance compared to zero-shot evaluation? by\nanalyzing the common vision-language embedding space. Based on the analysis, we\npropose a novel prompt-tuning method, PromptMargin for adapting such\nlarge-scale VLMs directly on the few target samples. PromptMargin effectively\ntunes the text as well as visual prompts for this task, and has two main\nmodules: 1) Firstly, we use a selective augmentation strategy to complement the\nfew training samples in each task; 2) Additionally, to ensure robust training\nin the presence of unfamiliar class names, we increase the inter-class margin\nfor improved class discrimination using a novel Multimodal Margin Regularizer.\nExtensive experiments and analysis across fifteen target benchmark datasets,\nwith varying degrees of distribution shifts from natural images, shows the\neffectiveness of the proposed framework over the existing state-of-the-art\napproaches applied to this setting. github.com/debarshigit/PromptMargin.",
    "pdf_url": "http://arxiv.org/pdf/2505.15506v1",
    "published": "2025-05-21T13:26:56+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15505v1",
    "title": "Deep Learning Enabled Segmentation, Classification and Risk Assessment of Cervical Cancer",
    "authors": [
      "Abdul Samad Shaik",
      "Shashaank Mattur Aswatha",
      "Rahul Jashvantbhai Pandya"
    ],
    "abstract": "Cervical cancer, the fourth leading cause of cancer in women globally,\nrequires early detection through Pap smear tests to identify precancerous\nchanges and prevent disease progression. In this study, we performed a focused\nanalysis by segmenting the cellular boundaries and drawing bounding boxes to\nisolate the cancer cells. A novel Deep Learning (DL) architecture, the\n``Multi-Resolution Fusion Deep Convolutional Network\", was proposed to\neffectively handle images with varying resolutions and aspect ratios, with its\nefficacy showcased using the SIPaKMeD dataset. The performance of this DL model\nwas observed to be similar to the state-of-the-art models, with accuracy\nvariations of a mere 2\\% to 3\\%, achieved using just 1.7 million learnable\nparameters, which is approximately 85 times less than the VGG-19 model.\nFurthermore, we introduced a multi-task learning technique that simultaneously\nperforms segmentation and classification tasks and begets an Intersection over\nUnion score of 0.83 and a classification accuracy of 90\\%. The final stage of\nthe workflow employs a probabilistic approach for risk assessment, extracting\nfeature vectors to predict the likelihood of normal cells progressing to\nmalignant states, which can be utilized for the prognosis of cervical cancer.",
    "pdf_url": "http://arxiv.org/pdf/2505.15505v1",
    "published": "2025-05-21T13:25:27+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15504v1",
    "title": "Beyond Linearity: Squeeze-and-Recalibrate Blocks for Few-Shot Whole Slide Image Classification",
    "authors": [
      "Conghao Xiong",
      "Zhengrui Guo",
      "Zhe Xu",
      "Yifei Zhang",
      "Raymond Kai-Yu Tong",
      "Si Yong Yeo",
      "Hao Chen",
      "Joseph J. Y. Sung",
      "Irwin King"
    ],
    "abstract": "Deep learning has advanced computational pathology but expert annotations\nremain scarce. Few-shot learning mitigates annotation burdens yet suffers from\noverfitting and discriminative feature mischaracterization. In addition, the\ncurrent few-shot multiple instance learning (MIL) approaches leverage\npretrained vision-language models to alleviate these issues, but at the cost of\ncomplex preprocessing and high computational cost. We propose a\nSqueeze-and-Recalibrate (SR) block, a drop-in replacement for linear layers in\nMIL models to address these challenges. The SR block comprises two core\ncomponents: a pair of low-rank trainable matrices (squeeze pathway, SP) that\nreduces parameter count and imposes a bottleneck to prevent spurious feature\nlearning, and a frozen random recalibration matrix that preserves geometric\nstructure, diversifies feature directions, and redefines the optimization\nobjective for the SP. We provide theoretical guarantees that the SR block can\napproximate any linear mapping to arbitrary precision, thereby ensuring that\nthe performance of a standard MIL model serves as a lower bound for its\nSR-enhanced counterpart. Extensive experiments demonstrate that our SR-MIL\nmodels consistently outperform prior methods while requiring significantly\nfewer parameters and no architectural changes.",
    "pdf_url": "http://arxiv.org/pdf/2505.15504v1",
    "published": "2025-05-21T13:24:47+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15503v1",
    "title": "Coloring Between the Lines: Personalization in the Null Space of Planning Constraints",
    "authors": [
      "Tom Silver",
      "Rajat Kumar Jenamani",
      "Ziang Liu",
      "Ben Dodson",
      "Tapomayukh Bhattacharjee"
    ],
    "abstract": "Generalist robots must personalize in-the-wild to meet the diverse needs and\npreferences of long-term users. How can we enable flexible personalization\nwithout sacrificing safety or competency? This paper proposes Coloring Between\nthe Lines (CBTL), a method for personalization that exploits the null space of\nconstraint satisfaction problems (CSPs) used in robot planning. CBTL begins\nwith a CSP generator that ensures safe and competent behavior, then\nincrementally personalizes behavior by learning parameterized constraints from\nonline interaction. By quantifying uncertainty and leveraging the\ncompositionality of planning constraints, CBTL achieves sample-efficient\nadaptation without environment resets. We evaluate CBTL in (1) three diverse\nsimulation environments; (2) a web-based user study; and (3) a real-robot\nassisted feeding system, finding that CBTL consistently achieves more effective\npersonalization with fewer interactions than baselines. Our results demonstrate\nthat CBTL provides a unified and practical approach for continual, flexible,\nactive, and safe robot personalization. Website:\nhttps://emprise.cs.cornell.edu/cbtl/",
    "pdf_url": "http://arxiv.org/pdf/2505.15503v1",
    "published": "2025-05-21T13:24:05+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15502v1",
    "title": "Meta-analytic-predictive priors based on a single study",
    "authors": [
      "Christian R√∂ver",
      "Tim Friede"
    ],
    "abstract": "Meta-analytic-predictive (MAP) priors have been proposed as a generic\napproach to deriving informative prior distributions, where external empirical\ndata are processed to learn about certain parameter distributions. The use of\nMAP priors is also closely related to shrinkage estimation (also sometimes\nreferred to as dynamic borrowing). A potentially odd situation arises when the\nexternal data consist only of a single study. Conceptually this is not a\nproblem, it only implies that certain prior assumptions gain in importance and\nneed to be specified with particular care. We outline this important, not\nuncommon special case and demonstrate its implementation and interpretation\nbased on the normal-normal hierarchical model. The approach is illustrated\nusing example applications in clinical medicine.",
    "pdf_url": "http://arxiv.org/pdf/2505.15502v1",
    "published": "2025-05-21T13:23:48+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15501v1",
    "title": "Protoknowledge Shapes Behaviour of LLMs in Downstream Tasks: Memorization and Generalization with Knowledge Graphs",
    "authors": [
      "Federico Ranaldi",
      "Andrea Zugarini",
      "Leonardo Ranaldi",
      "Fabio Massimo Zanzotto"
    ],
    "abstract": "We introduce the concept of protoknowledge to formalize and measure how\nsequences of tokens encoding Knowledge Graphs are internalized during\npretraining and utilized at inference time by Large Language Models (LLMs).\nIndeed, LLMs have demonstrated the ability to memorize vast amounts of token\nsequences during pretraining, and a central open question is how they leverage\nthis memorization as reusable knowledge through generalization. We then\ncategorize protoknowledge into lexical, hierarchical, and topological forms,\nvarying on the type of knowledge that needs to be activated. We measure\nprotoknowledge through Knowledge Activation Tasks (KATs), analyzing its general\nproperties such as semantic bias. We then investigate the impact of\nprotoknowledge on Text-to-SPARQL performance by varying prompting strategies\ndepending on input conditions. To this end, we adopt a novel analysis framework\nthat assesses whether model predictions align with the successful activation of\nthe relevant protoknowledge for each query. This methodology provides a\npractical tool to explore Semantic-Level Data Contamination and serves as an\neffective strategy for Closed-Pretraining models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15501v1",
    "published": "2025-05-21T13:22:34+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15500v2",
    "title": "Interference Fringe Mitigation in Short-Delay Self-Heterodyne Laser Phase Noise Measurements",
    "authors": [
      "Jasper Riebesehl",
      "David C. Nak",
      "Darko Zibar"
    ],
    "abstract": "Self-heterodyne techniques are widely used for laser phase noise\ncharacterization due to their simple experimental setup and the removed need\nfor a reference laser. However, when investigating low-noise lasers, optical\ndelay paths shorter than the laser coherence length become necessary. This\nintroduces interference patterns that distort the measured phase noise\nspectrum. To compensate for this distortion, we introduce a robust data-driven\ndigital signal processing routine that integrates a kernel-based regression\nmodel into a phase noise power spectral density (PN-PSD) equalization\nframework. Unlike conventional compensation methods that rely on simplified\nphase noise models, our approach automatically adapts to arbitrary laser\nlineshapes by using Kernel Ridge Regression with automatic hyperparameter\noptimization. This approach effectively removes the interference artifacts and\nprovides accurate PN-PSD estimates. We demonstrate the method's accuracy and\neffectiveness through simulations and via experimental measurements of two\ndistinct low-noise lasers. The method's applicability to a broad range of\nlasers, minimal hardware requirements, and improved accuracy make this approach\nideal for improving routine phase noise characterizations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15500v2",
    "published": "2025-05-21T13:22:27+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.15499v1",
    "title": "Creation of fixed points in block-parallel Boolean automata networks",
    "authors": [
      "K√©vin Perrot",
      "Sylvain Sen√©",
      "L√©ah Tapin"
    ],
    "abstract": "In the context of discrete dynamical systems and their applications, fixed\npoints often have a clear interpretation. This is indeed a central topic of\ngene regulatory mechanisms modeled by Boolean automata networks (BANs), where a\ncollection of Boolean entities (the automata) update their state depending on\nthe states of others. Fixed points represent phenotypes such as differentiated\ncell types. The interaction graph of a BAN captures the architecture of\ndependencies among its automata. A first seminal result is that cycles of\ninteractions (so called feedbacks) are the engines of dynamical complexity. A\nsecond seminal result is that fixed points are invariant under block-sequential\nupdate schedules, which update the automata following an ordered partition of\nthe set of automata. In this article we study the ability of block-parallel\nupdate schedules (dual to the latter) to break this fixed point invariance\nproperty, with a focus on the simplest feedback mechanism: the canonical\npositive cycle. We quantify numerically the creation of new fixed points, and\nprovide families of block-parallel update schedules generating exponentially\nmany fixed points on this elementary structure of interaction.",
    "pdf_url": "http://arxiv.org/pdf/2505.15499v1",
    "published": "2025-05-21T13:22:25+00:00",
    "categories": [
      "cs.DM"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15498v1",
    "title": "Mott transition and correlation effects on strictly localized states in an octagonal quasicrystal",
    "authors": [
      "Efe Yelesti",
      "Onur Erten",
      "M. O. Oktel"
    ],
    "abstract": "Flat-band systems have attracted significant attention as platforms for\nstudying strongly correlated electron physics, where the dominance of\nelectron-electron interactions over kinetic energy gives rise to a variety of\nemergent phenomena. Quasicrystals are compelling systems for studying these\nphenomena as they host degenerate strictly localized states at zero energy due\nto perfect destructive interference patterns. In this study, we use the\nslave-rotor mean-field approach to investigate the effects of electron\ninteractions within the Hubbard model on the Ammann-Beenker quasicrystal. The\nphase diagram characterizing metallic and Mott insulator regions indicates a\nfirst-order phase transition. Our analysis shows that the local coordination\nnumber affects the local quasiparticle weight, displaying varying metallicity\nacross the sites. Furthermore, we focus on the strictly localized states that\narise in the non-interacting limit. We find that interactions and deviation\nfrom particle-hole symmetry induce spectral splitting, broadening, and partial\ndelocalization of the localized states, depending on the local environment. In\nparticular, certain localized states with higher coordination numbers remain\nmore robust compared to others. Our results highlight the critical role of\nlocal geometry in shaping correlation effects in flat-band quasicrystals.",
    "pdf_url": "http://arxiv.org/pdf/2505.15498v1",
    "published": "2025-05-21T13:22:23+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.15497v1",
    "title": "Certified Neural Approximations of Nonlinear Dynamics",
    "authors": [
      "Frederik Baymler Mathiesen",
      "Nikolaus Vertovec",
      "Francesco Fabiano",
      "Luca Laurenti",
      "Alessandro Abate"
    ],
    "abstract": "Neural networks hold great potential to act as approximate models of\nnonlinear dynamical systems, with the resulting neural approximations enabling\nverification and control of such systems. However, in safety-critical contexts,\nthe use of neural approximations requires formal bounds on their closeness to\nthe underlying system. To address this fundamental challenge, we propose a\nnovel, adaptive, and parallelizable verification method based on certified\nfirst-order models. Our approach provides formal error bounds on the neural\napproximations of dynamical systems, allowing them to be safely employed as\nsurrogates by interpreting the error bound as bounded disturbances acting on\nthe approximated dynamics. We demonstrate the effectiveness and scalability of\nour method on a range of established benchmarks from the literature, showing\nthat it outperforms the state-of-the-art. Furthermore, we highlight the\nflexibility of our framework by applying it to two novel scenarios not\npreviously explored in this context: neural network compression and an\nautoencoder-based deep learning architecture for learning Koopman operators,\nboth yielding compelling results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15497v1",
    "published": "2025-05-21T13:22:20+00:00",
    "categories": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15496v1",
    "title": "Fast Rate Bounds for Multi-Task and Meta-Learning with Different Sample Sizes",
    "authors": [
      "Hossein Zakerinia",
      "Christoph H. Lampert"
    ],
    "abstract": "We present new fast-rate generalization bounds for multi-task and\nmeta-learning in the unbalanced setting, i.e. when the tasks have training sets\nof different sizes, as is typically the case in real-world scenarios.\nPreviously, only standard-rate bounds were known for this situation, while\nfast-rate bounds were limited to the setting where all training sets are of\nequal size. Our new bounds are numerically computable as well as interpretable,\nand we demonstrate their flexibility in handling a number of cases where they\ngive stronger guarantees than previous bounds. Besides the bounds themselves,\nwe also make conceptual contributions: we demonstrate that the unbalanced\nmulti-task setting has different statistical properties than the balanced\nsituation, specifically that proofs from the balanced situation do not carry\nover to the unbalanced setting. Additionally, we shed light on the fact that\nthe unbalanced situation allows two meaningful definitions of multi-task risk,\ndepending on whether if all tasks should be considered equally important or if\nsample-rich tasks should receive more weight than sample-poor ones.",
    "pdf_url": "http://arxiv.org/pdf/2505.15496v1",
    "published": "2025-05-21T13:22:07+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15495v1",
    "title": "Life after death: Europa in the evolving Habitable Zone of a Red Sun",
    "authors": [
      "Elijah Mullens",
      "Britney Schmidt",
      "Lisa Kaltenegger",
      "Nikole K. Lewis"
    ],
    "abstract": "Most stars end their main-sequence (MS) lives by evolving through the\nred-giant and asymptotic-giant branches before ending as a quiescent, stable\nwhite dwarf. Therefore, it is imperative to model the post-MS as it relates to\nlong-term stability of environments potentially suitable for life. Recent work\nhas shown that gas giants can exist in the habitable zone (HZ) during the red\ngiant phase and around a white dwarf remnant. Icy moons represent large\nreservoirs of water and will evolve through sublimation and melting when\nexposed to higher instellation, where the relatively lower surface gravity\ncould lead to the rapid loss of all surface water. We model the surface\nevolution of Europa when initially exposed to habitable zone instellation in\nthe red giant branch. Modeling the diurnal and yearly flux variations on a 2D\nmap we show that, due to Jupiter's increased albedo, the sub-Jovian hemisphere\nof Europa largely sublimates while only the anti-Jovian equatorial band\nsublimates. With the increasing instellation of the red giant branch, both\nhemispheres sublimate substantially. We then model the evolution of a tenuous\nwater-vapor atmosphere and show it is stable against atmospheric loss for at\nleast 0.2 Gyr in the red giant branch habitable zone. We then present three\nways to observe a sublimating Europan-like exomoon and potential spectra.\nExtending the results of this work to different planets and moons could open up\na new pathway by which life could persist beyond the death of a star.",
    "pdf_url": "http://arxiv.org/pdf/2505.15495v1",
    "published": "2025-05-21T13:22:05+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15494v1",
    "title": "Laminar boundary layer separation over a fully porous bump",
    "authors": [
      "Grace Bridge",
      "Wen Wu"
    ],
    "abstract": "This study investigates laminar boundary layer separation over a fully porous\nGaussian bump using pore-resolved direct numerical simulations. The bump is\nformed by randomly packed spheres. Compared to a solid bump, the porous surface\nsignificantly alters the flow by enabling cross-bump mass flux. Near-wall fluid\nis drawn into the bump by favorable pressure gradients on the windward side and\nexits near the crest and leeward side due to adverse pressure gradients. This\npore flow weakens the reverse flow and reduces mean shear in the separated\nregion, delaying reattachment and extending the separation zone. The findings\nhighlight the role of porous structures in modulating boundary layer\nseparation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15494v1",
    "published": "2025-05-21T13:21:55+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.15493v1",
    "title": "SINR Maximizing Distributionally Robust Adaptive Beamforming",
    "authors": [
      "Kiarash Hassas Irani",
      "Yongwei Huang",
      "Sergiy A. Vorobyov"
    ],
    "abstract": "This paper addresses the robust adaptive beamforming (RAB) problem via the\nworst-case signal-to-interference-plus-noise ratio (SINR) maximization over\ndistributional uncertainty sets for the random interference-plus-noise\ncovariance (INC) matrix and desired signal steering vector. Our study explores\ntwo distinct uncertainty sets for the INC matrix and three for the steering\nvector. The uncertainty sets of the INC matrix account for the support and the\npositive semidefinite (PSD) mean of the distribution, as well as a similarity\nconstraint on the mean. The uncertainty sets for the steering vector consist of\nthe constraints on the first- and second-order moments of its associated\nprobability distribution. The RAB problem is formulated as the minimization of\nthe worst-case expected value of the SINR denominator over any distribution\nwithin the uncertainty set of the INC matrix, subject to the condition that the\nexpected value of the numerator is greater than or equal to one for every\ndistribution within the uncertainty set of the steering vector. By leveraging\nthe strong duality of linear conic programming, this RAB problem is\nreformulated as a quadratic matrix inequality problem. Subsequently, it is\naddressed by iteratively solving a sequence of linear matrix inequality\nrelaxation problems, incorporating a penalty term for the rank-one PSD matrix\nconstraint. We further analyze the convergence of the iterative algorithm. The\nproposed robust beamforming approach is validated through simulation examples,\nwhich illustrate improved performance in terms of the array output SINR.",
    "pdf_url": "http://arxiv.org/pdf/2505.15493v1",
    "published": "2025-05-21T13:20:58+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15492v2",
    "title": "Damping oscillatory Integrals of convex analytic functions",
    "authors": [
      "Sanghyuk Lee",
      "Sewook Oh"
    ],
    "abstract": "Let $H\\subset \\R^{d+1}$ be a compact, convex, analytic hypersurface of finite\ntype with a smooth measure $\\sigma $ on $H$. Let $\\kappa$ denote the Gaussian\ncurvature on $H$. We consider the oscillatory integral $(\\kappa^{1/2}\n\\sigma)^\\wedge$ with the damping factor $\\kappa^{1/2}$ and prove the optimal\ndecay estimate\n  \\[ |(\\kappa^{1/2} \\sigma )^\\wedge(\\xi)|\\le C|\\xi|^{-d/2}\\]\n  for $d=2,3,$ and with an extra logarithmic factor for $d=4$. Our result\nprovides an essentially complete answer, since such decay estimates generally\nfail for $d \\ge 5$, even for convex analytic hypersurfaces, as shown by\nCowling--Disney--Mauceri--M\\\"uller. Furthermore, we prove the same estimates\nfor $(\\kappa^{1/2+it} \\sigma )^\\wedge$ with $C$ growing polynomially in $|t|$.\nAs consequences, we obtain the best possible estimates for the convolution,\nmaximal, and adjoint restriction operators associated with $H$, incorporating\nthe mitigating factors of optimal orders. In particular, for $d=2, 3$, we prove\nthe $L^2$--$L^{2(d+2)/(d+4)}$ restriction estimate with respect to the affine\nsurface measure $\\kappa^{1/(d+2)} \\sigma$. This work was inspired by the\nstationary set method due to Basu--Guo--Zhang--Zorin-Kranich.",
    "pdf_url": "http://arxiv.org/pdf/2505.15492v2",
    "published": "2025-05-21T13:19:18+00:00",
    "categories": [
      "math.CA",
      "Primary 42B20, Secondary 42B10"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15491v1",
    "title": "Spectral-Aware Global Fusion for RGB-Thermal Semantic Segmentation",
    "authors": [
      "Ce Zhang",
      "Zifu Wan",
      "Simon Stepputtis",
      "Katia Sycara",
      "Yaqi Xie"
    ],
    "abstract": "Semantic segmentation relying solely on RGB data often struggles in\nchallenging conditions such as low illumination and obscured views, limiting\nits reliability in critical applications like autonomous driving. To address\nthis, integrating additional thermal radiation data with RGB images\ndemonstrates enhanced performance and robustness. However, how to effectively\nreconcile the modality discrepancies and fuse the RGB and thermal features\nremains a well-known challenge. In this work, we address this challenge from a\nnovel spectral perspective. We observe that the multi-modal features can be\ncategorized into two spectral components: low-frequency features that provide\nbroad scene context, including color variations and smooth areas, and\nhigh-frequency features that capture modality-specific details such as edges\nand textures. Inspired by this, we propose the Spectral-aware Global Fusion\nNetwork (SGFNet) to effectively enhance and fuse the multi-modal features by\nexplicitly modeling the interactions between the high-frequency,\nmodality-specific features. Our experimental results demonstrate that SGFNet\noutperforms the state-of-the-art methods on the MFNet and PST900 datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.15491v1",
    "published": "2025-05-21T13:17:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15870v1",
    "title": "Satellites Reveal Mobility: A Commuting Origin-destination Flow Generator for Global Cities",
    "authors": [
      "Can Rong",
      "Xin Zhang",
      "Yanxin Xi",
      "Hongjie Sui",
      "Jingtao Ding",
      "Yong Li"
    ],
    "abstract": "Commuting Origin-destination~(OD) flows, capturing daily population mobility\nof citizens, are vital for sustainable development across cities around the\nworld. However, it is challenging to obtain the data due to the high cost of\ntravel surveys and privacy concerns. Surprisingly, we find that satellite\nimagery, publicly available across the globe, contains rich urban semantic\nsignals to support high-quality OD flow generation, with over 98\\%\nexpressiveness of traditional multisource hard-to-collect urban\nsociodemographic, economics, land use, and point of interest data. This\ninspires us to design a novel data generator, GlODGen, which can generate OD\nflow data for any cities of interest around the world. Specifically, GlODGen\nfirst leverages Vision-Language Geo-Foundation Models to extract urban semantic\nsignals related to human mobility from satellite imagery. These features are\nthen combined with population data to form region-level representations, which\nare used to generate OD flows via graph diffusion models. Extensive experiments\non 4 continents and 6 representative cities show that GlODGen has great\ngeneralizability across diverse urban environments on different continents and\ncan generate OD flow data for global cities highly consistent with real-world\nmobility data. We implement GlODGen as an automated tool, seamlessly\nintegrating data acquisition and curation, urban semantic feature extraction,\nand OD flow generation together. It has been released at\nhttps://github.com/tsinghua-fib-lab/generate-od-pubtools.",
    "pdf_url": "http://arxiv.org/pdf/2505.15870v1",
    "published": "2025-05-21T13:17:34+00:00",
    "categories": [
      "cs.CV",
      "cs.CY",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15490v1",
    "title": "Collaborative Problem-Solving in an Optimization Game",
    "authors": [
      "Isidora Jeknic",
      "Alex Duchnowski",
      "Alexander Koller"
    ],
    "abstract": "Dialogue agents that support human users in solving complex tasks have\nreceived much attention recently. Many such tasks are NP-hard optimization\nproblems that require careful collaborative exploration of the solution space.\nWe introduce a novel dialogue game in which the agents collaboratively solve a\ntwo-player Traveling Salesman problem, along with an agent that combines LLM\nprompting with symbolic mechanisms for state tracking and grounding. Our best\nagent solves 45% of games optimally in self-play. It also demonstrates an\nability to collaborate successfully with human users and generalize to\nunfamiliar graphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15490v1",
    "published": "2025-05-21T13:15:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15489v2",
    "title": "Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models",
    "authors": [
      "Jiaying Wu",
      "Fanxiao Li",
      "Min-Yen Kan",
      "Bryan Hooi"
    ],
    "abstract": "The real-world impact of misinformation stems from the underlying misleading\nnarratives that creators seek to convey. As such, interpreting misleading\ncreator intent is essential for multimodal misinformation detection (MMD)\nsystems aimed at effective information governance. In this paper, we introduce\nan automated framework that simulates real-world multimodal news creation by\nexplicitly modeling creator intent through two components: the desired\ninfluence and the execution plan. Using this framework, we construct\nDeceptionDecoded, a large-scale benchmark comprising 12,000 image-caption pairs\naligned with trustworthy reference articles. The dataset captures both\nmisleading and non-misleading intents and spans manipulations across visual and\ntextual modalities. We conduct a comprehensive evaluation of 14\nstate-of-the-art vision-language models (VLMs) on three intent-centric tasks:\n(1) misleading intent detection, (2) misleading source attribution, and (3)\ncreator desire inference. Despite recent advances, we observe that current VLMs\nfall short in recognizing misleading intent, often relying on spurious cues\nsuch as superficial cross-modal consistency, stylistic signals, and heuristic\nauthenticity hints. Our findings highlight the pressing need for intent-aware\nmodeling in MMD and open new directions for developing systems capable of\ndeeper reasoning about multimodal misinformation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15489v2",
    "published": "2025-05-21T13:14:32+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15488v1",
    "title": "Machine Learning Derived Blood Input for Dynamic PET Images of Rat Heart",
    "authors": [
      "Shubhrangshu Debsarkar",
      "Bijoy Kundu"
    ],
    "abstract": "Dynamic FDG PET imaging study of n = 52 rats including 26 control\nWistar-Kyoto (WKY) rats and 26 experimental spontaneously hypertensive rats\n(SHR) were performed using a Siemens microPET and Albira trimodal scanner\nlongitudinally at 1, 2, 3, 5, 9, 12 and 18 months of age. A 15-parameter dual\noutput model correcting for spill over contamination and partial volume effects\nwith peak fitting cost functions was developed for simultaneous estimation of\nmodel corrected blood input function (MCIF) and kinetic rate constants for\ndynamic FDG PET images of rat heart in vivo. Major drawbacks of this model are\nits dependence on manual annotations for the Image Derived Input Function\n(IDIF) and manual determination of crucial model parameters to compute MCIF. To\novercome these limitations, we performed semi-automated segmentation and then\nformulated a Long-Short-Term Memory (LSTM) cell network to train and predict\nMCIF in test data using a concatenation of IDIFs and myocardial inputs and\ncompared them with reference-modeled MCIF. Thresholding along 2D plane slices\nwith two thresholds, with T1 representing high-intensity myocardium, and T2\nrepresenting lower-intensity rings, was used to segment the area of the LV\nblood pool. The resultant IDIF and myocardial TACs were used to compute the\ncorresponding reference (model) MCIF for all data sets. The segmented IDIF and\nthe myocardium formed the input for the LSTM network. A k-fold cross validation\nstructure with a 33:8:11 split and 5 folds was utilized to create the model and\nevaluate the performance of the LSTM network for all datasets. To overcome the\nsparseness of data as time steps increase, midpoint interpolation was utilized\nto increase the density of datapoints beyond time = 10 minutes. The model\nutilizing midpoint interpolation was able to achieve a 56.4% improvement over\nprevious Mean Squared Error (MSE).",
    "pdf_url": "http://arxiv.org/pdf/2505.15488v1",
    "published": "2025-05-21T13:10:44+00:00",
    "categories": [
      "eess.IV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15487v1",
    "title": "Strong Coupling Expansion of Gluodynamics on a Lattice under Rotation",
    "authors": [
      "Sheng Wang",
      "Jun-Xia Chen",
      "Defu Hou",
      "Hai-Cang Ren"
    ],
    "abstract": "The analytic strong coupling expansion of the gluodynamics under a rotation\nwith an angular velocity $\\omega$ is reported. While the expansion is\nsystematic, free from additional assumptions, the deconfinement temperature\ndetermined by the onset of the Polyakov loop expectation value decreases with\nthe angular velocity up to $\\omega^2$, opposite to the tendency found in\nnumerical simulations. As a by-product, a simple formula is obtained for the\n$\\omega^2$ coefficient of the deconfinement temperature shift in terms of the\nlatent heat and the discontinuity of the moment of inertia at the transition\nwithout rotation. This formula is independent of the strong coupling and may\nbenefit further investigation of the subject.",
    "pdf_url": "http://arxiv.org/pdf/2505.15487v1",
    "published": "2025-05-21T13:09:32+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.18202v1",
    "title": "Departure time choice user equilibrium for public transport demand management",
    "authors": [
      "Xia Zhou",
      "Zhenliang Ma",
      "Mark Wallace",
      "Daniel D. Harabor"
    ],
    "abstract": "Departure time management is an efficient way in addressing the peak-hour\ncrowding in public transport by reducing the temporal imbalance between service\nsupply and travel demand. From the demand management perspective, the problem\nis to determine an equilibrium distribution of departure times for which no\nuser can reduce their generalized cost by changing their departure times\nunilaterally. This study introduces the departure time choice user equilibrium\nproblem in public transport (DTUE-PT) for multi-line, schedule-based networks\nwith hard train capacity constraints. We model the DTUE-PT problem as a\nNon-linear Mathematical Program problem (NMP) (minimizing the system gap) with\na simulation model describing the complex system dynamics and passenger\ninteractions. We develop an efficient, adaptive gap-based descent direction\n(AdaGDD) solution algorithm to solve the NMP problem. We validate the\nmethodology on a multi-line public transport network with transfers by\ncomparing with classical public transport assignment benchmark models,\nincluding Method of Successive Average (MSA) and day-to-day learning methods.\nThe results show that the model can achieve a system gap ratio (the solution\ngap relative to the ideal least cost of an origin-destination option) of\n0.1926, which significantly improves the solution performance from day-to-day\nlearning (85%) and MSA (76%) algorithms. The sensitivity analysis highlights\nthe solution stability of AdaGDD method over initial solution settings. The\npotential use of DTUE-PT model is demonstrated for evaluating the network\ndesign of Hong Kong mass transit railway network and can be easily extended to\nincorporate the route choice.",
    "pdf_url": "http://arxiv.org/pdf/2505.18202v1",
    "published": "2025-05-21T13:07:13+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15486v1",
    "title": "Eu-doped CsSrCl$_3$ Large Nanocrystal Clusters with Self-Reduction Effect and Near-Unity Quantum Yield",
    "authors": [
      "Chuangchang Lei",
      "Xiang Wu",
      "Yaohua Li",
      "Xu Xu",
      "Guangzheng Zuo",
      "Qiongrong Ou",
      "Shuyu Zhang"
    ],
    "abstract": "Europium halide perovskites have emerged as promising candidates for\nenvironmental-friendly blue-emitting materials. However, their development is\nhindered by relative low photoluminescence quantum yields (PLQY, e.g. ~2-5% for\nintrinsic CsEuCl3) and poor stability against air. Here, we introduce a\none-step-procedure for synthesizing Eu$^{2+}$-doped CsSrCl$_3$ large\nnanocrystal clusters (LNCs) with the effect of self-reduction, therefore\neliminating the use of conventional reductant oleylamine (OAm) and ensuring\nphase purity. The CsSrCl$_3$:Eu LNCs shows photoluminescence emission centered\nat 430 nm with a full width at half-maximum (FWHM) of 25 nm and a PLQY of ~40%,\nwhich can be further enhanced to ~97% after passivating the surface defects by\nadding trioctylphosphine (TOP), the highest among all reported lead-free\nblue-emitting perovskite nanocrystals. The stability of CsSrCl$_3$:Eu can also\nbe improved significantly by epitaxially growing ZnS shell on the surface. This\nwork will shed more light on lanthanide and alkaline-earth metal (AEM)-based\nperovskites for nontoxic light-emitting materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.15486v1",
    "published": "2025-05-21T13:06:22+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15485v2",
    "title": "$œÜ^3$ theory at six loops",
    "authors": [
      "Oliver Schnetz"
    ],
    "abstract": "We present the renormalization functions of dimensionally regularized\n$\\phi^3$ theory in six dimensions up to loop order six in the minimal\nsubtraction scheme.",
    "pdf_url": "http://arxiv.org/pdf/2505.15485v2",
    "published": "2025-05-21T13:02:09+00:00",
    "categories": [
      "hep-th",
      "hep-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15484v1",
    "title": "Chemical design of monolayer altermagnets",
    "authors": [
      "Runzhang Xu",
      "Yifan Gao",
      "Junwei Liu"
    ],
    "abstract": "The crystal-symmetry-paired spin-momentum locking (CSML) arisen from the\nintrinsic crystal symmetry connecting different magnetic sublattices in\naltermagnets enables many exotic spintronics properties such as unconventional\npiezomagnetism and noncollinear spin current. However, the shortage of\nmonolayer altermagnets restricts further exploration of dimensionally confined\nphenomena and applications of nanostructured devices. Here, we propose general\nchemical design principles inspired by sublattice symmetry of layered\naltermagnet V$_2$(Se,Te)$_2$O through symmetry-preserving structural\nmodification and valence-adaptive chemical substitutions. In total, we\nconstruct 2600 candidates across four structural frameworks,\nM$_2$A$_2$B$_{1,0}$ and their Janus derivatives. High-throughput calculations\nidentify 670 potential altermagnets with N\\'eel-ordered ground states, among\nwhich 91 ones exhibiting CSML Dirac cones that enable spin-polarized ultra-fast\ntransport. These materials also feature different ground-state magnetic\norderings and demonstrate diverse electronic behaviors, ranging from\nsemiconductors, metals, half-metals, to Dirac semimetals. This work not only\nreveals abundant monolayer altermagnets, but also establishes a rational\nprinciple for their design, opening gates for exploration of confined magnetism\nand spintronics in atomically thin systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15484v1",
    "published": "2025-05-21T13:01:45+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15483v2",
    "title": "Optimal Piecewise-based Mechanism for Collecting Bounded Numerical Data under Local Differential Privacy",
    "authors": [
      "Ye Zheng",
      "Sumita Mishra",
      "Yidan Hu"
    ],
    "abstract": "Numerical data with bounded domains is a common data type in personal\ndevices, such as wearable sensors. While the collection of such data is\nessential for third-party platforms, it raises significant privacy concerns.\nLocal differential privacy (LDP) has been shown as a framework providing\nprovable individual privacy, even when the third-party platform is untrusted.\nFor numerical data with bounded domains, existing state-of-the-art LDP\nmechanisms are piecewise-based mechanisms, which are not optimal, leading to\nreduced data utility.\n  This paper investigates the optimal design of piecewise-based mechanisms to\nmaximize data utility under LDP. We demonstrate that existing piecewise-based\nmechanisms are heuristic forms of the $3$-piecewise mechanism, which is far\nfrom enough to study optimality. We generalize the $3$-piecewise mechanism to\nits most general form, i.e. $m$-piecewise mechanism with no pre-defined form of\neach piece. Under this form, we derive the closed-form optimal mechanism by\ncombining analytical proofs and off-the-shelf optimization solvers. Next, we\nextend the generalized piecewise-based mechanism to the circular domain (along\nwith the classical domain), defined on a cyclic range where the distance\nbetween the two endpoints is zero. By incorporating this property, we design\nthe optimal mechanism for the circular domain, achieving significantly improved\ndata utility compared with existing mechanisms.\n  Our proposed mechanisms guarantee optimal data utility under LDP among all\ngeneralized piecewise-based mechanisms. We show that they also achieve optimal\ndata utility in two common applications of LDP: distribution estimation and\nmean estimation. Theoretical analyses and experimental evaluations prove and\nvalidate the data utility advantages of our proposed mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15483v2",
    "published": "2025-05-21T13:01:41+00:00",
    "categories": [
      "cs.CR",
      "E.3"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15482v1",
    "title": "LET-modifying joint optimization for mixed-modality photon-proton treatment planning",
    "authors": [
      "Lisa Seckler",
      "Amit Ben Antony Bennan",
      "Niklas Wahl"
    ],
    "abstract": "As depth increases, linear energy transfer (LET) rises toward the distal edge\nof the Bragg peak, boosting the radiobiological effectiveness (RBE). To manage\nthe biological variation and limit normal-tissue damage, LET-modifying\nobjective functions on, e.g., dose-weighted LET or dirty dose and/or usage of\nvariable RBE models were introduced. Because shaping LET by proton irradiation\nalone has its limits, this work proposes to jointly optimize mixed-modality\nproton-photon treatments based on directly LET-modifying objective functions.\nThe investigated objective functions rely on either dose-weighted LET or dirty\ndose concepts. To formulate a consistent combined optimization problem, the\ncontribution of secondary electron LET in photon treatments is considered (and\ndiscussed) as well. Combined dose/LET calculation and optimization are realized\nin the open source toolkit matRad. Phantom plans as well as a patient plans are\noptimized for analysis on the method, combining five proton fractions with 25\nphoton fractions. Dose-optimized combined plans are used as a reference. The\nreference plan shows that protons are, in general, dosimetrically superior and\nthus preferred, with photons aiding in achieving conformity. The introduction\nof LET modified objectives locally modifies the proton contribution in the\ntargeted regions of interest. Especially at the distal edge, the photon\ncontribution increases to move high-LET/dirty dose out of the OARs. Dirty dose\nobjectives seem to allow a more comprehensive steering of the high-LET regions\ncompared to LETxDose. Incorporating LET-based objectives into a jointly\noptimized proton-photon system allows for improved dose conformity and reduced\nhigh-LET exposure in critical regions in proximity to the distal proton edge.\nThis approach enables the utilization of modality-specific strengths and can\ncontribute to safer, more effective treatment plans.",
    "pdf_url": "http://arxiv.org/pdf/2505.15482v1",
    "published": "2025-05-21T13:01:22+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15869v1",
    "title": "Quantum steganography using catalytic and entanglement-assisted quantum codes",
    "authors": [
      "Sanjoy Dutta",
      "Nihar Ranjan Dash",
      "Subhashish Banerjee",
      "R. Srikanth"
    ],
    "abstract": "Steganography is the technique for transmitting a secret message by employing\nsubterfuge to conceal it in innocent-looking data, rather than by overt\nsecurity measures as in cryptography. Typically, non-degenerate quantum\nerror-correcting codes (QECCs) are used as the cover medium, with the stego\nmessage disguised as noise. As in cryptography, a large number of bits or ebits\nare pre-shared, in this case mainly in order to ensure the innocence effect. In\nthis work we develop three steganographic protocols: first, a scheme based on\ncatalytic quantum codes to minimize initial pre-shared resources; second, a\nscheme incorporating prior entanglement into QECCs in the form of possibly\ndegenerate entanglement-assisted QECCs; third, a scheme that uses the phase bit\nof a pre-shared ebit, combined with QECCs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15869v1",
    "published": "2025-05-21T12:58:57+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15481v1",
    "title": "A conditional coalescent for diploid exchangeable population models given the pedigree",
    "authors": [
      "Frederic Alberti",
      "Matthias Birkner",
      "Wai-Tong Louis Fan",
      "John Wakeley"
    ],
    "abstract": "We study coalescent processes conditional on the population pedigree under\nthe exchangeable diploid bi-parental population model of\n\\citet{BirknerEtAl2018}. While classical coalescent models average over all\nreproductive histories, thereby marginalizing the pedigree, our work analyzes\nthe genealogical structure embedded within a fixed pedigree generated by the\ndiploid Cannings model. In the large-population limit, we show that these\nconditional coalescent processes differ significantly from their marginal\ncounterparts when the marginal coalescent process includes multiple mergers. We\ncharacterize the limiting process as an inhomogeneous $(\\Psi,c)$-coalescent,\nwhere $\\Psi$ encodes the timing and scale of multiple mergers caused by\ngenerations with large individual progeny (GLIPs), and $c$ is a constant rate\ngoverning binary mergers.\n  Our results reveal fundamental distinctions between quenched (conditional)\nand annealed (classical) genealogical models, demonstrate how the fixed\npedigree structure impacts multi-locus statistics such as the site-frequency\nspectrum, and have implications for interpreting patterns of genetic variation\namong unlinked loci in the genomes of sampled individuals. They significantly\nextend the results of \\citet{DiamantidisEtAl2024}, which considered a sample of\nsize two under a specific Wright-Fisher model with a highly reproductive\ncouple, and those of \\citet{TyukinThesis2015}, where Kingman coalescent was the\nlimiting process. Our proofs adapt coupling techniques from the theory of\nrandom walks in random environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15481v1",
    "published": "2025-05-21T12:57:35+00:00",
    "categories": [
      "math.PR",
      "Primary 60J90, 92D10, Secondary 60K37, 60J95"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17111v1",
    "title": "A Global Commuting Origin-Destination Flow Dataset for Urban Sustainable Development",
    "authors": [
      "Can Rong",
      "Jingtao Ding",
      "Meng Li",
      "Yong Li"
    ],
    "abstract": "Commuting Origin-Destination (OD) flows capture movements of people from\nresidences to workplaces, representing the predominant form of intra-city\nmobility and serving as a critical reference for understanding urban dynamics\nand supporting sustainable policies. However, acquiring such data requires\ncostly, time-consuming censuses. In this study, we introduce a commuting OD\nflow dataset for cities around the world, spanning 6 continents, 179 countries,\nand 1,625 cities, providing unprecedented coverage of dynamics under diverse\nurban environments. Specifically, we collected fine-grained demographic data,\nsatellite imagery, and points of interest~(POIs) for each city as foundational\ninputs to characterize the functional roles of urban regions. Leveraging these,\na deep generative model is employed to capture the complex relationships\nbetween urban geospatial features and human mobility, enabling the generation\nof commuting OD flows between urban regions. Comprehensively, validation shows\nthat the spatial distributions of the generated flows closely align with\nreal-world observations. We believe this dataset offers a valuable resource for\nadvancing sustainable urban development research in urban science, data\nscience, transportation engineering, and related fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.17111v1",
    "published": "2025-05-21T12:56:40+00:00",
    "categories": [
      "cs.OH"
    ],
    "primary_category": "cs.OH"
  },
  {
    "id": "http://arxiv.org/abs/2505.15480v2",
    "title": "KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance",
    "authors": [
      "Qihuang Zhong",
      "Liang Ding",
      "Xiantao Cai",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "abstract": "Supervised fine-tuning (SFT) is a common approach to improve the\ndomain-specific question-answering (QA) performance of large language models\n(LLMs). However, recent literature reveals that due to the conflicts between\nLLMs' internal knowledge and the context knowledge of training data, vanilla\nSFT using the full QA training set is usually suboptimal. In this paper, we\nfirst design a query diversification strategy for robust conflict detection and\nthen conduct a series of experiments to analyze the impact of knowledge\nconflict. We find that 1) training samples with varied conflicts contribute\ndifferently, where SFT on the data with large conflicts leads to catastrophic\nperformance drops; 2) compared to directly filtering out the conflict data,\nappropriately applying the conflict data would be more beneficial. Motivated by\nthis, we propose a simple-yet-effective Knowledge-aware Fine-tuning (namely\nKaFT) approach to effectively boost LLMs' performance. The core of KaFT is to\nadapt the training weight by assigning different rewards for different training\nsamples according to conflict level. Extensive experiments show that KaFT\nbrings consistent and significant improvements across four LLMs. More analyses\nprove that KaFT effectively improves the model generalization and alleviates\nthe hallucination.",
    "pdf_url": "http://arxiv.org/pdf/2505.15480v2",
    "published": "2025-05-21T12:55:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.04233v1",
    "title": "polyBART: A Chemical Linguist for Polymer Property Prediction and Generative Design",
    "authors": [
      "Anagha Savit",
      "Harikrishna Sahu",
      "Shivank Shukla",
      "Wei Xiong",
      "Rampi Ramprasad"
    ],
    "abstract": "Designing polymers for targeted applications and accurately predicting their\nproperties is a key challenge in materials science owing to the vast and\ncomplex polymer chemical space. While molecular language models have proven\neffective in solving analogous problems for molecular discovery, similar\nadvancements for polymers are limited. To address this gap, we propose\npolyBART, a language model-driven polymer discovery capability that enables\nrapid and accurate exploration of the polymer design space. Central to our\napproach is Pseudo-polymer SELFIES (PSELFIES), a novel representation that\nallows for the transfer of molecular language models to the polymer space.\npolyBART is, to the best of our knowledge, the first language model capable of\nbidirectional translation between polymer structures and properties, achieving\nstate-of-the-art results in property prediction and design of novel polymers\nfor electrostatic energy storage. Further, polyBART is validated through a\ncombination of both computational and laboratory experiments. We report what we\nbelieve is the first successful synthesis and validation of a polymer designed\nby a language model, predicted to exhibit high thermal degradation temperature\nand confirmed by our laboratory measurements. Our work presents a generalizable\nstrategy for adapting molecular language models to the polymer space and\nintroduces a polymer foundation model, advancing generative polymer design that\nmay be adapted for a variety of applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.04233v1",
    "published": "2025-05-21T12:55:21+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.15479v1",
    "title": "An efficient integrator for stellar dynamics in effective gravity fields based on the isochrone potential",
    "authors": [
      "Alexandre Bougakov",
      "Melaine Saillenfest",
      "Marc Fouchard"
    ],
    "abstract": "Context. Integrating the motion of stars in a smoothed potential is necessary\nin many stellar and galactic studies. Previous works have often used numerical\nintegrators that alternate between linear drifts and velocity kicks (such as\nthe Leapfrog scheme). This approach contrasts with the sophisticated methods\ndeveloped in planetary dynamics, for which integrators alternate between\nKeplerian drifts and velocity kicks.\n  Aims. Inspired by the splitting methods used in planetary dynamics, we aim to\nbuild an integration scheme dedicated to stellar and galactic dynamics.\n  Methods. We took advantage of the properties of H\\'enon's isochrone potential\nto design a symplectic splitting scheme that can be used to integrate the\nmotion of stars in any gravitational potential. This scheme alternates between\nisochrone drifts and velocity kicks. As a first application, we consider the\nmotion of a star in a Plummer potential -- an essential constituent of galactic\npotentials -- and determine integration parameters that provide the best\nefficiency (i.e. best conservation of energy for lowest computational cost).\n  Results. We derive the analytical solution for all kinds of orbits in\nH\\'enon's isochrone potential (bound and unbound trajectories) as needed in our\nintegration scheme. Our experiments for stars in a Plummer potential show\nexcellent performances in the inner and outer parts of the gravity field, that\nis, where the motion of stars is well approximated by isochrone trajectories\n(with perturbations of order $10^{-3}$ or less). For highly elongated orbits\nthat cross the characteristic length of the Plummer potential, the performance\nis equivalent to that of previous methods.\n  Conclusions. The splitting scheme presented here is a good alternative to\nprevious methods: it performs at least as well, and up to orders of magnitude\nbetter, depending on the dynamical regime of the star.",
    "pdf_url": "http://arxiv.org/pdf/2505.15479v1",
    "published": "2025-05-21T12:54:52+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15478v1",
    "title": "AI-empowered Real-Time Line-of-Sight Identification via Network Digital Twins",
    "authors": [
      "Michele Zhu",
      "Silvia Mura",
      "Francesco Linsalata",
      "Lorenzo Cazzella",
      "Damiano Badini",
      "Umberto Spagnolini"
    ],
    "abstract": "The identification of Line-of-Sight (LoS) conditions is critical for ensuring\nreliable high-frequency communication links, which are particularly vulnerable\nto blockages and rapid channel variations. Network Digital Twins (NDTs) and\nRay-Tracing (RT) techniques can significantly automate the large-scale\ncollection and labeling of channel data, tailored to specific wireless\nenvironments. This paper examines the quality of Artificial Intelligence (AI)\nmodels trained on data generated by Network Digital Twins. We propose and\nevaluate training strategies for a general-purpose Deep Learning model,\ndemonstrating superior performance compared to the current state-of-the-art. In\nterms of classification accuracy, our approach outperforms the state-of-the-art\nDeep Learning model by 5% in very low SNR conditions and by approximately 10%\nin medium-to-high SNR scenarios. Additionally, the proposed strategies\neffectively reduce the input size to the Deep Learning model while preserving\nits performance. The computational cost, measured in floating-point operations\nper second (FLOPs) during inference, is reduced by 98.55% relative to\nstate-of-the-art solutions, making it ideal for real-time applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15478v1",
    "published": "2025-05-21T12:54:00+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15477v1",
    "title": "Brain volume predicts survival of colliding-spreading messages on mammal brain networks",
    "authors": [
      "Yan Hao",
      "Tate Tower",
      "Hannah Lax",
      "Marc-Thorsten H√ºtt",
      "Daniel J. Graham"
    ],
    "abstract": "White matter in mammal brains forms a densely interconnected communication\nnetwork. Due to high edge density, along with continuous generation and spread\nof messages, brain networks must contend with congestion, which may limit\npolysynaptic message survival in complex ways. Here we study congestion with a\ncolliding-spreading model, a synchronous Markovian process where messages\narriving coincidentally at a node are deleted, while surviving messages spread\nto all nearest neighbors. Numerical simulations on a large sample of mammal\nconnectomes demonstrate that message survival follows a positively skewed\nlognormal-like distribution for all connectomes tested. This distribution\nmirrors empirical distributions of interareal distances and edge weights.\nHowever, the distribution of message survival is an emergent property of system\ndynamics and graph topology alone; it does not require interareal distances or\nedge weights. We then show that message survival is well predicted by log brain\nvolume (r = -0.64) across species. Thus, messages survive longer in small\ncompared to large mammals, in accordance with the notion that larger brains\nbecome more modular. Chimpanzee showed the lowest message survival among the\nanimals tested. We describe structural properties that may play a role in\ngenerating these dynamics and we discuss implications of our results for brain\nfunction and evolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15477v1",
    "published": "2025-05-21T12:53:49+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15476v1",
    "title": "Pura: An Efficient Privacy-Preserving Solution for Face Recognition",
    "authors": [
      "Guotao Xu",
      "Bowen Zhao",
      "Yang Xiao",
      "Yantao Zhong",
      "Liang Zhai",
      "Qingqi Pei"
    ],
    "abstract": "Face recognition is an effective technology for identifying a target person\nby facial images. However, sensitive facial images raises privacy concerns.\nAlthough privacy-preserving face recognition is one of potential solutions,\nthis solution neither fully addresses the privacy concerns nor is efficient\nenough. To this end, we propose an efficient privacy-preserving solution for\nface recognition, named Pura, which sufficiently protects facial privacy and\nsupports face recognition over encrypted data efficiently. Specifically, we\npropose a privacy-preserving and non-interactive architecture for face\nrecognition through the threshold Paillier cryptosystem. Additionally, we\ncarefully design a suite of underlying secure computing protocols to enable\nefficient operations of face recognition over encrypted data directly.\nFurthermore, we introduce a parallel computing mechanism to enhance the\nperformance of the proposed secure computing protocols. Privacy analysis\ndemonstrates that Pura fully safeguards personal facial privacy. Experimental\nevaluations demonstrate that Pura achieves recognition speeds up to 16 times\nfaster than the state-of-the-art.",
    "pdf_url": "http://arxiv.org/pdf/2505.15476v1",
    "published": "2025-05-21T12:50:25+00:00",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15475v1",
    "title": "LFTF: Locating First and Then Fine-Tuning for Mitigating Gender Bias in Large Language Models",
    "authors": [
      "Zhanyue Qin",
      "Yue Ding",
      "Deyuan Liu",
      "Qingbin Liu",
      "Junxian Cai",
      "Xi Chen",
      "Zhiying Tu",
      "Dianhui Chu",
      "Cuiyun Gao",
      "Dianbo Sui"
    ],
    "abstract": "Nowadays, Large Language Models (LLMs) have attracted widespread attention\ndue to their powerful performance. However, due to the unavoidable exposure to\nsocially biased data during training, LLMs tend to exhibit social biases,\nparticularly gender bias. To better explore and quantifying the degree of\ngender bias in LLMs, we propose a pair of datasets named GenBiasEval and\nGenHintEval, respectively. The GenBiasEval is responsible for evaluating the\ndegree of gender bias in LLMs, accompanied by an evaluation metric named\nAFGB-Score (Absolutely Fair Gender Bias Score). Meanwhile, the GenHintEval is\nused to assess whether LLMs can provide responses consistent with prompts that\ncontain gender hints, along with the accompanying evaluation metric UB-Score\n(UnBias Score). Besides, in order to mitigate gender bias in LLMs more\neffectively, we present the LFTF (Locating First and Then Fine-Tuning)\nalgorithm.The algorithm first ranks specific LLM blocks by their relevance to\ngender bias in descending order using a metric called BMI (Block Mitigating\nImportance Score). Based on this ranking, the block most strongly associated\nwith gender bias is then fine-tuned using a carefully designed loss function.\nNumerous experiments have shown that our proposed LFTF algorithm can\nsignificantly mitigate gender bias in LLMs while maintaining their general\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15475v1",
    "published": "2025-05-21T12:49:37+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15474v1",
    "title": "Entropy exchange in an inter-correlating binary quasi-classical system: Concept of entropy-bath accelerated molecular dynamics",
    "authors": [
      "Projesh Kumar Roy"
    ],
    "abstract": "This letter highlights the entropy exchange phenomenon in a coupled binary\ninter-correlating system following Haldane's non-linear statistical\ncorrelation. A unique coupling between a classical and a quantum-like system at\nthe marginal distribution is observed. It is shown that the quantum nature of a\nsystem can arise without any self-correlation. Extending this idea, an enhanced\nsampling method in molecular dynamics simulation is postulated where a\nclassical system is forced to show quantum-like behavior with the help of an\nentropy-bath. An entropy-bath exchanges entropy with the system to scale the\npotential energy distribution of the system, so that a probability upper bound\nat each energy level is maintained. An algorithm to implement the entropy-bath\naccelerated molecular dynamics simulation is discussed. Using low temperature\nvitreous silica as an example, the capability of such an algorithm to greatly\nimprove sampling of the potential energy landscape under equilibrium conditions\nfor kinetically arrested systems is highlighted.",
    "pdf_url": "http://arxiv.org/pdf/2505.15474v1",
    "published": "2025-05-21T12:49:25+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.15473v1",
    "title": "Fast and robust detection of single Rydberg excitations in mesoscopic ensembles",
    "authors": [
      "Sven Schmidt",
      "Aaron Thielmann",
      "Thomas Niederpr√ºm",
      "Herwig Ott"
    ],
    "abstract": "We propose a novel non-destructive method for the detection of single Rydberg\nexcitations in a mesoscopic ensemble. The protocol achieves high fidelities on\na microsecond timescale and is robust against changes in the probe laser\nfrequency. The technique relies on optical pumping in Autler Townes\nconfiguration, whose efficiency is controlled by the presence/absence of a\nRydberg excitation. Taking rubidium atoms as an example, we give realistic\nestimates for the achievable fidelities and parameters. However, our protocol\ncan be transferred to any other atomic species which features multiple stable\nstates. Our protocol is applicable in quantum simulation and quantum\ninformation processing with mesoscopic ensembles requiring fast and high\nfidelity Rydberg state detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.15473v1",
    "published": "2025-05-21T12:49:08+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15472v2",
    "title": "PhysicsArena: The First Multimodal Physics Reasoning Benchmark Exploring Variable, Process, and Solution Dimensions",
    "authors": [
      "Song Dai",
      "Yibo Yan",
      "Jiamin Su",
      "Dongfang Zihao",
      "Yubo Gao",
      "Yonghua Hei",
      "Jungang Li",
      "Junyan Zhang",
      "Sicheng Tao",
      "Zhuoran Gao",
      "Xuming Hu"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in diverse reasoning tasks, yet their application to complex\nphysics reasoning remains underexplored. Physics reasoning presents unique\nchallenges, requiring grounding in physical conditions and the interpretation\nof multimodal information. Current physics benchmarks are limited, often\nfocusing on text-only inputs or solely on problem-solving, thereby overlooking\nthe critical intermediate steps of variable identification and process\nformulation. To address these limitations, we introduce PhysicsArena, the first\nmultimodal physics reasoning benchmark designed to holistically evaluate MLLMs\nacross three critical dimensions: variable identification, physical process\nformulation, and solution derivation. PhysicsArena aims to provide a\ncomprehensive platform for assessing and advancing the multimodal physics\nreasoning abilities of MLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15472v2",
    "published": "2025-05-21T12:48:16+00:00",
    "categories": [
      "cs.CL",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15471v1",
    "title": "CoLA: Collaborative Low-Rank Adaptation",
    "authors": [
      "Yiyun Zhou",
      "Chang Yao",
      "Jingyuan Chen"
    ],
    "abstract": "The scaling law of Large Language Models (LLMs) reveals a power-law\nrelationship, showing diminishing return on performance as model scale\nincreases. While training LLMs from scratch is resource-intensive, fine-tuning\na pre-trained model for specific tasks has become a practical alternative. Full\nfine-tuning (FFT) achieves strong performance; however, it is computationally\nexpensive and inefficient. Parameter-efficient fine-tuning (PEFT) methods, like\nLoRA, have been proposed to address these challenges by freezing the\npre-trained model and adding lightweight task-specific modules. LoRA, in\nparticular, has proven effective, but its application to multi-task scenarios\nis limited by interference between tasks. Recent approaches, such as\nMixture-of-Experts (MOE) and asymmetric LoRA, have aimed to mitigate these\nissues but still struggle with sample scarcity and noise interference due to\ntheir fixed structure. In response, we propose CoLA, a more flexible LoRA\narchitecture with an efficient initialization scheme, and introduces three\ncollaborative strategies to enhance performance by better utilizing the\nquantitative relationships between matrices $A$ and $B$. Our experiments\ndemonstrate the effectiveness and robustness of CoLA, outperforming existing\nPEFT methods, especially in low-sample scenarios. Our data and code are fully\npublicly available at https://github.com/zyy-2001/CoLA.",
    "pdf_url": "http://arxiv.org/pdf/2505.15471v1",
    "published": "2025-05-21T12:46:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15470v2",
    "title": "The PAU Survey: Measuring intrinsic galaxy alignments in deep wide fields as a function of colour, luminosity, stellar mass and redshift",
    "authors": [
      "D. Navarro-Giron√©s",
      "M. Crocce",
      "E. Gazta√±aga",
      "A. Wittje",
      "M. Siudek",
      "H. Hoekstra",
      "H. Hildebrandt",
      "B. Joachimi",
      "R. Paviot",
      "C. M. Baugh",
      "J. Carretero",
      "R. Casas",
      "F. J. Castander",
      "M. Eriksen",
      "E. Fernandez",
      "P. Fosalba",
      "J. Garc√≠a-Bellido",
      "R. Miquel",
      "C. Padilla",
      "P. Renard",
      "E. S√°nchez",
      "S. Serrano",
      "I. Sevilla-Noarbe",
      "P. Tallada-Cresp√≠"
    ],
    "abstract": "We present the measurements and constraints of intrinsic alignments (IA) in\nthe Physics of the Accelerating Universe Survey (PAUS) deep wide fields, which\ninclude the W1 and W3 fields from the Canada-France-Hawaii Telescope Legacy\nSurvey (CFHTLS) and the G09 field from the Kilo-Degree Survey (KiDS). Our\nanalyses cover 51deg$^{2}$, in the photometric redshift (photo-$z$) range $0.1\n< z_{\\mathrm{b}} < 1$ and a magnitude limit $i_{\\mathrm{AB}}<22$. The precise\nphoto-$z$s and the luminosity coverage of PAUS enable robust IA measurements,\nwhich are key for setting informative priors for upcoming stage-IV surveys. For\nred galaxies, we detect an increase in IA amplitude with both luminosity and\nstellar mass, extending previous results towards fainter and less massive\nregimes. As a function of redshift, we observe strong IA signals at\nintermediate ($z_{\\mathrm{b}}\\sim0.55$) and high ($z_{\\mathrm{b}}\\sim0.75$)\nredshift bins. However, we find no significant trend of IA evolution with\nredshift after accounting for the varying luminosities across redshift bins,\nconsistent with the literature. For blue galaxies, no significant IA signal is\ndetected, with $A_{1}=0.68_{-0.51}^{+0.53}$ when splitting only by galaxy\ncolour, yielding some of the tightest constraints to date for the blue\npopulation and constraining a regime of very faint and low-mass galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2505.15470v2",
    "published": "2025-05-21T12:46:20+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15469v1",
    "title": "A Qualitative Investigation into LLM-Generated Multilingual Code Comments and Automatic Evaluation Metrics",
    "authors": [
      "Jonathan Katzy",
      "Yongcheng Huang",
      "Gopal-Raj Panchu",
      "Maksym Ziemlewski",
      "Paris Loizides",
      "Sander Vermeulen",
      "Arie van Deursen",
      "Maliheh Izadi"
    ],
    "abstract": "Large Language Models are essential coding assistants, yet their training is\npredominantly English-centric. In this study, we evaluate the performance of\ncode language models in non-English contexts, identifying challenges in their\nadoption and integration into multilingual workflows. We conduct an open-coding\nstudy to analyze errors in code comments generated by five state-of-the-art\ncode models, CodeGemma, CodeLlama, CodeQwen1.5, GraniteCode, and StarCoder2\nacross five natural languages: Chinese, Dutch, English, Greek, and Polish. Our\nstudy yields a dataset of 12,500 labeled generations, which we publicly\nrelease. We then assess the reliability of standard metrics in capturing\ncomment \\textit{correctness} across languages and evaluate their\ntrustworthiness as judgment criteria. Through our open-coding investigation, we\nidentified a taxonomy of 26 distinct error categories in model-generated code\ncomments. They highlight variations in language cohesion, informativeness, and\nsyntax adherence across different natural languages. Our analysis shows that,\nwhile these models frequently produce partially correct comments, modern neural\nmetrics fail to reliably differentiate meaningful completions from random\nnoise. Notably, the significant score overlap between expert-rated correct and\nincorrect comments calls into question the effectiveness of these metrics in\nassessing generated comments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15469v1",
    "published": "2025-05-21T12:45:49+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15468v1",
    "title": "Fourier Dimension in $C^{1+Œ±}$ Parabolic Dynamics",
    "authors": [
      "Ga√©tan Leclerc",
      "Sampo Paukkonen",
      "Tuomas Sahlsten"
    ],
    "abstract": "We introduce a non-smooth non-linearity condition for $C^{1+\\alpha}$ Markov\niterated function systems motivated by the proof of power Fourier decay of\nnonlinear 2D Axiom A equilibrium states, which was inspired by recent advances\nin exponential mixing for 3D Anosov flows. We verify this condition for a class\nof $C^{1+\\alpha}$ systems using fixed point theory in space of Cantor\nfunctions, which gives first examples of truly $C^{1+\\alpha}$ IFSs with\npositive Fourier dimension for their attractors. Moreover, the proof method\nalso applies in smoother parabolic Markov systems including Young tower codings\nleading also to power Fourier decay for conformal measures for\nManneville-Pommeau maps, Lorenz maps arising from the Lorenz system, and\nPatterson-Sullivan measures for cusped hyperbolic surfaces, generalising the\nwork of Bourgain and Dyatlov to geometrically finite groups with parabolic\nelements. The lack of smoothness preventing the traditional use of spectral\ngaps for transfer operators is replaced with multiscale oscillations of the\nderivatives on Cantor sets allowing us to reduce to exponential sums of\nproducts of random variables with finite exponential moments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15468v1",
    "published": "2025-05-21T12:45:45+00:00",
    "categories": [
      "math.DS",
      "math.CA",
      "math.SP",
      "37A46 (Primary) 37D35, 37D45 (Secondary)"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15467v1",
    "title": "Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning",
    "authors": [
      "Yukun Zhao",
      "Lingyong Yan",
      "Zhenyang Li",
      "Shuaiqiang Wang",
      "Zhumin Chen",
      "Zhaochun Ren",
      "Dawei Yin"
    ],
    "abstract": "Large language models have achieved remarkable success in various tasks.\nHowever, it is challenging for them to learn new tasks incrementally due to\ncatastrophic forgetting. Existing approaches rely on experience replay,\noptimization constraints, or task differentiation, which encounter strict\nlimitations in real-world scenarios. To address these issues, we propose Joint\nFlashback Adaptation. We first introduce flashbacks -- a limited number of\nprompts from old tasks -- when adapting to new tasks and constrain the\ndeviations of the model outputs compared to the original one. We then\ninterpolate latent tasks between flashbacks and new tasks to enable jointly\nlearning relevant latent tasks, new tasks, and flashbacks, alleviating data\nsparsity in flashbacks and facilitating knowledge sharing for smooth\nadaptation. Our method requires only a limited number of flashbacks without\naccess to the replay data and is task-agnostic. We conduct extensive\nexperiments on state-of-the-art large language models across 1000+\ninstruction-following tasks, arithmetic reasoning tasks, and general reasoning\ntasks. The results demonstrate the superior performance of our method in\nimproving generalization on new tasks and reducing forgetting in old tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15467v1",
    "published": "2025-05-21T12:45:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15466v1",
    "title": "A Participatory Strategy for AI Ethics in Education and Rehabilitation grounded in the Capability Approach",
    "authors": [
      "Valeria Cesaroni",
      "Eleonora Pasqua",
      "Piercosma Bisconti",
      "Martina Galletti"
    ],
    "abstract": "AI-based technologies have significant potential to enhance inclusive\neducation and clinical-rehabilitative contexts for children with Special\nEducational Needs and Disabilities. AI can enhance learning experiences,\nempower students, and support both teachers and rehabilitators. However, their\nusage presents challenges that require a systemic-ecological vision, ethical\nconsiderations, and participatory research. Therefore, research and\ntechnological development must be rooted in a strong ethical-theoretical\nframework. The Capability Approach - a theoretical model of disability, human\nvulnerability, and inclusion - offers a more relevant perspective on\nfunctionality, effectiveness, and technological adequacy in inclusive learning\nenvironments. In this paper, we propose a participatory research strategy with\ndifferent stakeholders through a case study on the ARTIS Project, which\ndevelops an AI-enriched interface to support children with text comprehension\ndifficulties. Our research strategy integrates ethical, educational, clinical,\nand technological expertise in designing and implementing AI-based technologies\nfor children's learning environments through focus groups and collaborative\ndesign sessions. We believe that this holistic approach to AI adoption in\neducation can help bridge the gap between technological innovation and ethical\nresponsibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.15466v1",
    "published": "2025-05-21T12:45:01+00:00",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15465v1",
    "title": "Synthetic Enclosed Echoes: A New Dataset to Mitigate the Gap Between Simulated and Real-World Sonar Data",
    "authors": [
      "Guilherme de Oliveira",
      "Matheus M. dos Santos",
      "Paulo L. J. Drews-Jr"
    ],
    "abstract": "This paper introduces Synthetic Enclosed Echoes (SEE), a novel dataset\ndesigned to enhance robot perception and 3D reconstruction capabilities in\nunderwater environments. SEE comprises high-fidelity synthetic sonar data,\ncomplemented by a smaller subset of real-world sonar data. To facilitate\nflexible data acquisition, a simulated environment has been developed, enabling\nthe generation of additional data through modifications such as the inclusion\nof new structures or imaging sonar configurations. This hybrid approach\nleverages the advantages of synthetic data, including readily available ground\ntruth and the ability to generate diverse datasets, while bridging the\nsimulation-to-reality gap with real-world data acquired in a similar\nenvironment. The SEE dataset comprehensively evaluates acoustic data-based\nmethods, including mathematics-based sonar approaches and deep learning\nalgorithms. These techniques were employed to validate the dataset, confirming\nits suitability for underwater 3D reconstruction. Furthermore, this paper\nproposes a novel modification to a state-of-the-art algorithm, demonstrating\nimproved performance compared to existing methods. The SEE dataset enables the\nevaluation of acoustic data-based methods in realistic scenarios, thereby\nimproving their feasibility for real-world underwater applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15465v1",
    "published": "2025-05-21T12:44:14+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15464v1",
    "title": "A Bayesian Approach for Inference on Mixed Graphical Models",
    "authors": [
      "Mauro Florez",
      "Anna Gottard",
      "Carrie McAdams",
      "Michele Guindani",
      "Marina Vannucci"
    ],
    "abstract": "Mixed data refers to a type of data in which variables can be of multiple\ntypes, such as continuous, discrete, or categorical. This data is routinely\ncollected in various fields, including healthcare and social sciences. A common\ngoal in the analysis of such data is to identify dependence relationships\nbetween variables, for an understanding of their associations. In this paper,\nwe propose a Bayesian pairwise graphical model that estimates conditional\nindependencies between any type of data. We implement a flexible modeling\nconstruction, that includes zero-inflated count data and can also handle\nmissing data. We show that the model maintains both global and local Markov\nproperties. We employ a spike-and-slab prior for the estimation of the graph\nand implement an MCMC algorithm for posterior inference based on conditional\nlikelihoods. We assess performances on four simulation scenarios with distinct\ndependence structures, that also include cases with data missing at random, and\ncompare results with existing methods. Finally, we present an analysis of real\ndata from adolescents diagnosed with an eating disorder. Estimated graphs show\ndifferences in the associations estimated at intake and discharge, suggesting\npossible effects of the treatment on cognitive and behavioral measures in the\nadolescents.",
    "pdf_url": "http://arxiv.org/pdf/2505.15464v1",
    "published": "2025-05-21T12:41:09+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15463v2",
    "title": "Scale-by-scale kinetic energy flux calculations in simulations of rotating convection",
    "authors": [
      "Youri H. Lemm",
      "Xander M. de Wit",
      "Rudie P. J. Kunnen"
    ],
    "abstract": "Turbulence is an out-of-equilibrium flow state that is characterised by\nnonzero net fluxes of kinetic energy between different scales of the flow.\nThese fluxes play a crucial role in the formation of characteristic flow\nstructures in many turbulent flows encountered in nature. However, measuring\nthese energy fluxes in practical settings can be challenging as soon as one\nmoves away from unrestricted turbulence in an idealised periodic box. Here, we\nfocus on rotating Rayleigh-B\\'enard convection, being the canonical model\nsystem to study geophysical and astrophysical flows. Owing to the effect of\nrotation, this flow can yield a split cascade, where part of the energy is\ntransported to smaller scales (direct cascade), while another fraction is\ntransported to larger scales (inverse cascade). We compare two different\ntechniques for measuring these energy fluxes throughout the domain: one based\non a spatial filtering approach and an adapted Fourier-based method. We show\nhow one can use these methods to measure the energy flux adequately in the\nanisotropic, aperiodic domains encountered in rotating convection, even in\ndomains with spatial confinement. Our measurements reveal that in the studied\nregime, the bulk flow is dominated by the direct cascade, while significant\ninverse cascading action is observed most strongly near the top and bottom\nplates, due to the vortex merging of Ekman plumes into larger flow structures.",
    "pdf_url": "http://arxiv.org/pdf/2505.15463v2",
    "published": "2025-05-21T12:41:02+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.15462v1",
    "title": "AI-based Decision Support System for Heritage Aircraft Corrosion Prevention",
    "authors": [
      "Michal Kucha≈ô",
      "Jarom√≠r Fi≈°er",
      "Cyril Oswald",
      "Tom√°≈° Vyhl√≠dal"
    ],
    "abstract": "The paper presents a decision support system for the long-term preservation\nof aeronautical heritage exhibited/stored in sheltered sites. The aeronautical\nheritage is characterized by diverse materials of which this heritage is\nconstituted. Heritage aircraft are made of ancient aluminum alloys, (ply)wood,\nand particularly fabrics. The decision support system (DSS) designed, starting\nfrom a conceptual model, is knowledge-based on degradation/corrosion mechanisms\nof prevailing materials of aeronautical heritage. In the case of historical\naircraft wooden parts, this knowledge base is filled in by the damage function\nmodels developed within former European projects. Model-based corrosion\nprediction is implemented within the new DSS for ancient aluminum alloys. The\nnovelty of this DSS consists of supporting multi-material heritage protection\nand tailoring to peculiarities of aircraft exhibition/storage hangars and the\nneeds of aviation museums. The novel DSS is tested on WWII aircraft heritage\nexhibited in the Aviation Museum Kbely, Military History Institute Prague,\nCzech Republic.",
    "pdf_url": "http://arxiv.org/pdf/2505.15462v1",
    "published": "2025-05-21T12:40:51+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY",
      "62C25",
      "H.4.2; I.6.5"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15461v3",
    "title": "Direct Estimation of Earthquake Source Properties from a Single CCTV Camera",
    "authors": [
      "Soumaya Latour",
      "Mathias Lebihain",
      "Harsha S. Bhat",
      "C√©dric Twardzik",
      "Quentin Bletery",
      "Kenneth W. Hudnut",
      "Fran√ßois Passel√®gue"
    ],
    "abstract": "We present a direct measurement of the slip-rate function from a natural\ncoseismic rupture, recorded on March 28, 2025, during the $M_w$ 7.7 Mandalay\nearthquake (Myanmar). This measurement was made on video footage of the surface\nrupture captured by a security camera located only meters away from the fault\ntrace. Using direct image analysis, we measured the relative slip at each time\nstep and deduced the slip rate. Our results show a local slip duration of 1.4 s\nand cumulative slip of $\\sim$3 m, during which surface slip velocity peaked at\n$\\sim$3.5 m/s with passage of the rupture front. These findings demonstrate the\npulse-like nature of the seismic rupture, at the location of the recording.\nUsing slip-pulse elastodynamic rupture models, we obtain the complete\nmechanical properties of this pulse, including the energy release rate.",
    "pdf_url": "http://arxiv.org/pdf/2505.15461v3",
    "published": "2025-05-21T12:40:29+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15460v1",
    "title": "Atomic oxygen densities in He/O$_2$ micro-scaled atmospheric pressure plasma jets: a systematic model validation study",
    "authors": [
      "Youfan He",
      "Ralf Peter Brinkmann",
      "Efe Kemaneci",
      "Andrew R. Gibson"
    ],
    "abstract": "Reactive species produced by atmospheric pressure plasma jets have high\napplication potential in the fields of biomedicine and surface processing. An\nextensive validation between the simulation results in this work and\nmeasurement data from various research groups is carried out in order to\nreliably understand the complicated chemical kinetics defining the reactive\nspecies densities. Atomic oxygen densities in parallel plate radio frequency\ndriven He/O$_2$ micro-scaled atmospheric pressure plasma jets ($\\mu$APPJs) have\nbeen measured in the literature by several research groups with different\nmethods including: two-photon absorption laser induced fluorescence (TALIF)\nspectroscopy and optical emission spectroscopy (OES)-based methods. These\nmeasurement data with a variation of the absorbed power, the He gas flow rate\nand the O$_2$ mixture ratio are simulated in this paper with a zero-dimensional\n(0-D) plasma-chemical plug-flow model coupled with a two-term Boltzmann\nequation solver. The simulated atomic oxygen densities agree well with most of\nthe measured ones. Specifically, good agreement is achieved between the\nsimulations and most of the TALIF measurements over a range of operating\nconditions. Our model prediction accuracy relative to these TALIF measurements\nis quantified by the percentage error between the measured and simulated atomic\noxygen densities. An approximate normal distribution is observed in the\nhistogram plot of the percentage error, and the mean is close to zero. The mean\nis shifted positively and negatively in the case of removing a dominant atomic\noxygen gain and loss reaction channel, which implies the underestimation and\noverestimation of the simulation results relative to the measurement data,\nrespectively. This indicates that proper incorporation of the dominant reaction\nchannels in the simulations plays a key role in the model prediction accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.15460v1",
    "published": "2025-05-21T12:40:24+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17110v1",
    "title": "Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling",
    "authors": [
      "Junlin Li",
      "Guodong DU",
      "Jing Li",
      "Sim Kuan Goh",
      "Wenya Wang",
      "Yequan Wang",
      "Fangming Liu",
      "Ho-Kin Tang",
      "Saleh Alharbi",
      "Daojing He",
      "Min Zhang"
    ],
    "abstract": "Fine-tuning Large Language Models (LLMs) with multimodal encoders on\nmodality-specific data expands the modalities that LLMs can handle, leading to\nthe formation of Multimodal LLMs (MLLMs). However, this paradigm heavily relies\non resource-intensive and inflexible fine-tuning from scratch with new\nmultimodal data. In this paper, we propose MMER (Multi-modality Expansion and\nRetention), a training-free approach that integrates existing MLLMs for\neffective multimodal expansion while retaining their original performance.\nSpecifically, MMER reuses MLLMs' multimodal encoders while merging their LLM\nparameters. By comparing original and merged LLM parameters, MMER generates\nbinary masks to approximately separate LLM parameters for each modality. These\ndecoupled parameters can independently process modality-specific inputs,\nreducing parameter conflicts and preserving original MLLMs' fidelity. MMER can\nalso mitigate catastrophic forgetting by applying a similar process to MLLMs\nfine-tuned on new tasks. Extensive experiments show significant improvements\nover baselines, proving that MMER effectively expands LLMs' multimodal\ncapabilities while retaining 99% of the original performance, and also markedly\nmitigates catastrophic forgetting.",
    "pdf_url": "http://arxiv.org/pdf/2505.17110v1",
    "published": "2025-05-21T12:40:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15459v1",
    "title": "Developing clinical informatics to support direct care and population health management: the VIEWER story",
    "authors": [
      "Robert Harland",
      "Tao Wang",
      "David Codling",
      "Catherine Polling",
      "Matthew Broadbent",
      "Holly Newton",
      "Yamiko Joseph Msosa",
      "Daisy Kornblum",
      "Claire Delaney-Pope",
      "Barbara Arroyo",
      "Stuart MacLellan",
      "Zoe Keddie",
      "Mary Docherty",
      "Angus Roberts",
      "Derek Tracy",
      "Philip McGuire",
      "Richard Dobson",
      "Robert Stewart"
    ],
    "abstract": "Electronic health records (EHRs) provide comprehensive patient data which\ncould be better used to enhance informed decision-making, resource allocation,\nand coordinated care, thereby optimising healthcare delivery. However, in\nmental healthcare, critical information, such as on risk factors, precipitants,\nand treatment responses, is often embedded in unstructured text, limiting the\nability to automate at scale measures to identify and prioritise local\npopulations and patients, which potentially hinders timely prevention and\nintervention. We describe the development and proof-of-concept implementation\nof VIEWER, a clinical informatics platform designed to enhance direct patient\ncare and population health management by improving the accessibility and\nusability of EHR data. We further outline strategies that were employed in this\nwork to foster informatics innovation through interdisciplinary and\ncross-organisational collaboration to support integrated, personalised care,\nand detail how these advancements were piloted and implemented within a large\nUK mental health National Health Service Foundation Trust to improve patient\noutcomes at an individual patient, clinician, clinical team, and organisational\nlevel.",
    "pdf_url": "http://arxiv.org/pdf/2505.15459v1",
    "published": "2025-05-21T12:39:58+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15458v1",
    "title": "Infinite linear patterns in sets of positive density",
    "authors": [
      "Felipe Hern√°ndez"
    ],
    "abstract": "In this article we describe all possible infinite linear configurations that\ncan be found in a shift of any set of positive upper Banach density. This\nsimultaneously generalizes Szemer\\'edi's theorem on arithmetic progressions and\nthe recent density finite sums theorem of Kra, Moreira, Richter, and Robertson.",
    "pdf_url": "http://arxiv.org/pdf/2505.15458v1",
    "published": "2025-05-21T12:39:26+00:00",
    "categories": [
      "math.DS",
      "math.CO",
      "math.NT",
      "37A44 37B20 05D10"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15457v1",
    "title": "All-electrical near-field injection of excitons in a van der Waals antiferromagnet",
    "authors": [
      "Jonas D. Ziegler",
      "Sotirios Papadopoulos",
      "Antti J. Moilanen",
      "Marcelo M. Valenzuela",
      "Qia Lin",
      "Kseniia Mosina",
      "Takashi Taniguchi",
      "Kenji Watanabe",
      "Zdenek Sofer",
      "Florian Dirnberger",
      "Lukas Novotny"
    ],
    "abstract": "Van der Waals materials have become a promising building block for future\nelectronics and photonics. The two-dimensional magnet CrSBr came into the\nspotlight of solid state research due to its intriguing combination of\nantiferromagnetic order, strong light-matter coupling and unusual quasi-1D\nelectronic bandstructure. This study reports the electrical excitation of\nexcitons in CrSBr layers from cryogenic temperatures up to room temperature. By\nexploiting the energy transfer via tunneling electrons in a graphene tunnel\njunction strongly bound excitons are excited in proximate CrSBr layers. This\nfacilitates electrically-excited emission from CrSBr crystals ranging in\nthickness from a bilayer up to 250 nm, in which the strong linear polarization\nof the electroluminescence confirms the excitonic origin. For thicker layers,\nclear evidence for the electrically excited emission from self-hybridized\nexciton polaritons is observed, highlighting the strong coupling between\noptical excitations and confined photon modes in CrSBr. These results pave the\nway for future applications in spintronic and optical readout of magnetic\nproperties.",
    "pdf_url": "http://arxiv.org/pdf/2505.15457v1",
    "published": "2025-05-21T12:38:41+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.15456v1",
    "title": "Teaching Language Models to Evolve with Users: Dynamic Profile Modeling for Personalized Alignment",
    "authors": [
      "Weixiang Zhao",
      "Xingyu Sui",
      "Yulin Hu",
      "Jiahe Guo",
      "Haixiao Liu",
      "Biye Li",
      "Yanyan Zhao",
      "Bing Qin",
      "Ting Liu"
    ],
    "abstract": "Personalized alignment is essential for enabling large language models (LLMs)\nto engage effectively in user-centric dialogue. While recent prompt-based and\noffline optimization methods offer preliminary solutions, they fall short in\ncold-start scenarios and long-term personalization due to their inherently\nstatic and shallow designs. In this work, we introduce the Reinforcement\nLearning for Personalized Alignment (RLPA) framework, in which an LLM interacts\nwith a simulated user model to iteratively infer and refine user profiles\nthrough dialogue. The training process is guided by a dual-level reward\nstructure: the Profile Reward encourages accurate construction of user\nrepresentations, while the Response Reward incentivizes generation of responses\nconsistent with the inferred profile. We instantiate RLPA by fine-tuning\nQwen-2.5-3B-Instruct, resulting in Qwen-RLPA, which achieves state-of-the-art\nperformance in personalized dialogue. Empirical evaluations demonstrate that\nQwen-RLPA consistently outperforms prompting and offline fine-tuning baselines,\nand even surpasses advanced commercial models such as Claude-3.5 and GPT-4o.\nFurther analysis highlights Qwen-RLPA's robustness in reconciling conflicting\nuser preferences, sustaining long-term personalization and delivering more\nefficient inference compared to recent reasoning-focused LLMs. These results\nemphasize the potential of dynamic profile inference as a more effective\nparadigm for building personalized dialogue systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15456v1",
    "published": "2025-05-21T12:38:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15455v2",
    "title": "Magnetohydrodynamic turbulence and the associated spatial diffusion tensor of cosmic rays in dynamical galactic halos",
    "authors": [
      "J. Kleimann",
      "H. Fichtner",
      "M. Stein",
      "R. -J. Dettmar",
      "D. J. Bomans",
      "S. Oughton"
    ],
    "abstract": "A detailed understanding of cosmic-ray transport in galactic halos is\nessential for explaining various observations, such as the radio continuum\nmeasurements of synchrotron radiation from energetic electrons. Of central\nimportance is the spatial diffusion tensor of cosmic rays, which can be\ncomputed in an ab~initio manner if the turbulence in the background medium is\nknown. The study aimed to establish a suitable framework to compute the\nevolution of magnetohydrodynamic (MHD) turbulence and, hence, the diffusion\ntensor in the dynamical halos of galaxies. The Reynolds-averaged single-fluid\nMHD equations were solved numerically on a cylindrical grid, assuming axial\nsymmetry and fixed boundary conditions on a central ellipsoid representing the\ngalaxy. The physical properties of both large-scale MHD and small-scale\nturbulent quantities, including the coefficients of parallel and perpendicular\ndiffusion, were extracted from the resulting steady state. Hydrodynamic\nvalidation revealed a persistent instability of the near-axis flow, which could\nbe traced to the galaxy's gravitating mass. The results for the evolution of\nMHD turbulence in a galactic halo -- using parameters approximating those of\nNGC4631 -- enabled an ab initio computation of the spatial diffusion tensor of\ncosmic rays through the application of a state-of-the-art nonlinear theory. The\nsimulation results reveal variation in turbulence quantities, (i.e.,\nfluctuation energy, correlation scale, and cross helicity) in a dynamical halo.\nFurthermore, the corresponding diffusion tensor of cosmic rays exhibits\nsignificant variation throughout such a halo.",
    "pdf_url": "http://arxiv.org/pdf/2505.15455v2",
    "published": "2025-05-21T12:38:26+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15454v1",
    "title": "Pointwise Convergence in Games with Conflicting Interest",
    "authors": [
      "Nanxiang Zhou",
      "Jing Dong",
      "Baoxiang Wang"
    ],
    "abstract": "In this work, we introduce the concept of non-negative weighted regret, an\nextension of non-negative regret \\cite{anagnostides2022last} in games.\nInvestigating games with non-negative weighted regret helps us to understand\ngames with conflicting interests, including harmonic games and important\nclasses of zero-sum games.We show that optimistic variants of classical\nno-regret learning algorithms, namely optimistic mirror descent (OMD) and\noptimistic follow the regularized leader (OFTRL), converge to an\n$\\epsilon$-approximate Nash equilibrium at a rate of\n$O(1/\\epsilon^2)$.Consequently, they guarantee pointwise convergence to a Nash\nequilibrium if there are only finitely many Nash equilibria in the game. These\nalgorithms are robust in the sense the convergence holds even if the players\ndeviate Our theoretical findings are supported by empirical evaluations of OMD\nand OFTRL on the game of matching pennies and harmonic game instances.",
    "pdf_url": "http://arxiv.org/pdf/2505.15454v1",
    "published": "2025-05-21T12:37:16+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15453v1",
    "title": "A dynamical memory with only one spiking neuron",
    "authors": [
      "Damien Depannemaecker",
      "Adrien d'Hollande",
      "Jiaming Wu",
      "Marcelo J. Rozenberg"
    ],
    "abstract": "Common wisdom indicates that to implement a Dynamical Memory with spiking\nneurons two ingredients are necessary: recurrence and a neuron population. Here\nwe shall show that the second requirement is not needed. We shall demonstrate\nthat under very general assumptions a single recursive spiking neuron can\nrealize a robust model of a dynamical memory. We demonstrate the implementation\nof a dynamical memory in both, software and hardware. In the former case, we\nintroduce trivial extensions of the popular aQIF and AdEx models. In the\nlatter, we show traces obtained in a circuit model with a recently proposed\nmemristive spiking neuron. We show that the bistability of the theoretical\nmodels can be understood in terms of a self-consistent problem that can be\nrepresented geometrically. Our minimal dynamical memory model provides a\nsimplest implementation of an important neuro-computational primitive, which\ncan be useful in navigation system models based on purely spiking dynamics. A\none neuron dynamical memory may also provides a natural explanation to the\nsurprising recent observation that the excitation bump in Drosophila's\nellipsoidal body is made by just a handful of neurons.",
    "pdf_url": "http://arxiv.org/pdf/2505.15453v1",
    "published": "2025-05-21T12:35:44+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15452v1",
    "title": "Equilibration and convected limit in 2D-1D corotational Oldroyd's fluid-structure interaction",
    "authors": [
      "Prince Romeo Mensah"
    ],
    "abstract": "We consider a solute-solvent-structure mutually coupled system of equations\ngiven by an Oldroyd-type model for a two-dimensional dilute corotational\npolymer fluid with solute diffusion and damping that is interacting with a\none-dimensional viscoelastic shell. Firstly, we give the rate at which its\nsolution decays exponentially in time to the equilibrium solution, independent\nof the choice of the initial datum. Secondly, as the polymer relaxation time\ngoes to infinity (or, equivalently, the center-of mass diffusion goes to zero),\nwe show that any family of strong solutions of the system described above, that\nis parametrized by the relaxation time, converges to an essentially bounded\nweak solution of a corotational polymer fluid-structure interaction system\nwhose solute evolves according to the convected time derivative of its extra\nstress tensor. A consequence of this is a weak-strong uniqueness result.",
    "pdf_url": "http://arxiv.org/pdf/2505.15452v1",
    "published": "2025-05-21T12:34:22+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15451v1",
    "title": "Exploring short-term stellar activity in M dwarfs: A volume-limited perspective",
    "authors": [
      "G. Galletta",
      "S. Colombo",
      "L. Prisinzano",
      "G. Micela"
    ],
    "abstract": "Flares are short-lived but energetic manifestations of stellar activity.\nStudying them is crucial, as they emit intense high-energy radiation that can\nimpact the circumstellar environment, especially the atmospheres of orbiting\nplanets. This is particularly relevant for M dwarfs, which frequently flare and\noften host planets within their habitable zones. Flare-driven photoevaporation\nand photochemical processes may significantly affect planetary evolution. In\nthis work, we analyzed the flaring properties of a volume-limited, unbiased\nsample of nearby M dwarfs using data from the Transiting Exoplanet Survey\nSatellite (TESS). We selected stars within 10 pc from Gaia DR3 and used an\niterative Gaussian process to remove long-term stellar variability from the\nlight curves, isolating impulsive flare events. For each flare, we measured\namplitude, duration, and total emitted energy. Our sample includes 173 stars\nand 17,229 detected flares, ranging from 0 to 76 flares per TESS sector. We\nfocused on three representative stars to highlight the diversity in flare\nactivity. Detected flares had energies above 10^29 erg and durations from 2 to\n8000 seconds. We modeled cumulative energy distributions with one- and\ntwo-slope power-law fits, finding average slopes of -0.79 +/- 0.64 and -1.23\n+/- 1.32, respectively. We introduced the Flare Energy Index (GF.01) to\ndescribe flare frequency, identifying two populations: fainter stars tend to\nproduce fewer high-energy flares, while brighter stars exhibit more frequent\nlow-energy flares. Finally, we investigated two highly active stars, G 227-22\nand G 258-33, observed across many sectors, to study long-term flare behavior\nand energy trends.",
    "pdf_url": "http://arxiv.org/pdf/2505.15451v1",
    "published": "2025-05-21T12:33:33+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15450v1",
    "title": "Comprehensive Evaluation and Analysis for NSFW Concept Erasure in Text-to-Image Diffusion Models",
    "authors": [
      "Die Chen",
      "Zhiwen Li",
      "Cen Chen",
      "Yuexiang Xie",
      "Xiaodan Li",
      "Jinyan Ye",
      "Yingda Chen",
      "Yaliang Li"
    ],
    "abstract": "Text-to-image diffusion models have gained widespread application across\nvarious domains, demonstrating remarkable creative potential. However, the\nstrong generalization capabilities of diffusion models can inadvertently lead\nto the generation of not-safe-for-work (NSFW) content, posing significant risks\nto their safe deployment. While several concept erasure methods have been\nproposed to mitigate the issue associated with NSFW content, a comprehensive\nevaluation of their effectiveness across various scenarios remains absent. To\nbridge this gap, we introduce a full-pipeline toolkit specifically designed for\nconcept erasure and conduct the first systematic study of NSFW concept erasure\nmethods. By examining the interplay between the underlying mechanisms and\nempirical observations, we provide in-depth insights and practical guidance for\nthe effective application of concept erasure methods in various real-world\nscenarios, with the aim of advancing the understanding of content safety in\ndiffusion models and establishing a solid foundation for future research and\ndevelopment in this critical area.",
    "pdf_url": "http://arxiv.org/pdf/2505.15450v1",
    "published": "2025-05-21T12:31:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15449v1",
    "title": "Controlling quantum phases with electric fields in one-dimensional Hubbard systems",
    "authors": [
      "D. Arisa",
      "R. M. Dos Santos",
      "Isaac M. Carvalho",
      "Vivian V. Fran√ßa"
    ],
    "abstract": "Quantum systems under electric fields provide a powerful framework for\nuncovering and controlling novel quantum phases, especially in low-dimensional\nsystems with strong correlations. In this work, we investigate quantum phase\ntransitions induced by an electric potential difference in a one-dimensional\nhalf-filled Hubbard chain. By analyzing (i) tunneling and pairing mechanisms,\n(ii) charge and spin gaps, and (iii) entanglement between the chain halves, we\nidentify three distinct phases: Mott insulator, metal and band-like insulator.\nThe metallic regime, characterized by the closing of both charge and spin gaps,\nis accompanied by a field-dependent kinetic energy and a quasi-periodic\noscillatory behavior of pairing response and entanglement. Although the\nmetallic phase persists for different magnetizations, its extent in the phase\ndiagram shrinks as spin polarization increases.",
    "pdf_url": "http://arxiv.org/pdf/2505.15449v1",
    "published": "2025-05-21T12:31:00+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.15448v1",
    "title": "Constraining scalar-tensor theories from higher harmonics with GW230529",
    "authors": [
      "Baoxiang Wang",
      "Tao Yang"
    ],
    "abstract": "The Advanced LIGO and Virgo collaborations recently detected a gravitational\nwave event, GW230529\\_181500, during the fourth observing run, which is most\nplausibly attributed to the merger of a neutron star and a black hole. This\nobservation provides an opportunity to test a class of gravitational theories\nthat deviate from general relativity. In such theories, additional terms\ncontribute to the gravitational wave signal only in cases of asymmetric\nbinaries. This study focuses on two scalar-tensor models within this class of\ntheories: the Screened Modified Gravity and Brans-Dicke theory. These models\nhave potential applications in areas such as dark matter, dark energy, cosmic\ninflation, and primordial nucleosynthesis. With the GW230529\\_181500 and\nBayesian Markov-chain Monte Carlo analyses, we derive a 90\\% credible lower\nbound as $ \\frac{\\varphi_{\\rm_{VEV}}}{M_{\\rm Pl}}<1.7\\times10^{-2}$ and\n$\\omega_{\\rm BD}>25.12$ by using dominant-mode correction. Asymmetric binary\nsystems usually have a significant mass ratio, in such cases, higher harmonic\nmodes cannot be neglected. Our work considers higher harmonic corrections from\nscalar-tensor theories and provides a tighter constraint of $\n\\frac{\\varphi_{\\rm_{VEV}}}{M_{\\rm Pl}}<1.5\\times10^{-2}$ and $\\omega_{\\rm\nBD}>32.68$, with a 13.3\\% and 30.1\\% improvement respectively. Combining\nGW230529\\_181500, GW200115 and GW190814 and including higher modes, the\nconstraint is improved to $\\frac{\\varphi_{\\rm_{VEV}}}{M_{\\rm\nPl}}<7.84\\times10^{-3}$ and $\\omega_{\\rm BD}>123.75$. This is currently the\nstrongest constraint from GWs, contingent upon GW190814 being an NSBH event.",
    "pdf_url": "http://arxiv.org/pdf/2505.15448v1",
    "published": "2025-05-21T12:30:44+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15447v1",
    "title": "ViaRL: Adaptive Temporal Grounding via Visual Iterated Amplification Reinforcement Learning",
    "authors": [
      "Ziqiang Xu",
      "Qi Dai",
      "Tian Xie",
      "Yifan Yang",
      "Kai Qiu",
      "DongDong Chen",
      "Zuxuan Wu",
      "Chong Luo"
    ],
    "abstract": "Video understanding is inherently intention-driven-humans naturally focus on\nrelevant frames based on their goals. Recent advancements in multimodal large\nlanguage models (MLLMs) have enabled flexible query-driven reasoning; however,\nvideo-based frameworks like Video Chain-of-Thought lack direct training signals\nto effectively identify relevant frames. Current approaches often rely on\nheuristic methods or pseudo-label supervised annotations, which are both costly\nand limited in scalability across diverse scenarios. To overcome these\nchallenges, we introduce ViaRL, the first framework to leverage rule-based\nreinforcement learning (RL) for optimizing frame selection in intention-driven\nvideo understanding. An iterated amplification strategy is adopted to perform\nalternating cyclic training in the video CoT system, where each component\nundergoes iterative cycles of refinement to improve its capabilities. ViaRL\nutilizes the answer accuracy of a downstream model as a reward signal to train\na frame selector through trial-and-error, eliminating the need for expensive\nannotations while closely aligning with human-like learning processes.\nComprehensive experiments across multiple benchmarks, including VideoMME,\nLVBench, and MLVU, demonstrate that ViaRL consistently delivers superior\ntemporal grounding performance and robust generalization across diverse video\nunderstanding tasks, highlighting its effectiveness and scalability. Notably,\nViaRL achieves a nearly 15\\% improvement on Needle QA, a subset of MLVU, which\nis required to search a specific needle within a long video and regarded as one\nof the most suitable benchmarks for evaluating temporal grounding.",
    "pdf_url": "http://arxiv.org/pdf/2505.15447v1",
    "published": "2025-05-21T12:29:40+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15446v1",
    "title": "Subdivisions of Six-Blocks Cycles C(k,1,1,1,1,1) in Strong Digraphs",
    "authors": [
      "Hiba Ayoub",
      "Soukaina Zayat",
      "Darine Al-Mniny"
    ],
    "abstract": "A cycle C(k1,k2,...,kn) is the oriented cycle formed of n blocks of lengths\nk1,k2,...,kn-1 and kn respectively. In 2018 Cohen et al. conjectured that for\nevery positive integers k1,k2,...,kn there exists a constant g(k1,k2,...,kn)\nsuch that every strongly connected digraph containing no subdivisions of\nC(k1,k2,...,kn) has a chromatic number at most g(k1,k2,...,kn). In their paper,\nCohen et al. confirmed the conjecture for cycles with two blocks and for cycles\nwith four blocks having all its blocks of length 1. Recently, the conjecture\nwas proved for special types of four-blocks cycles. In this paper, we confirm\nCohen et al.'s conjecture for all six-blocks cycles C(k,1,1,1,1,1). Precisely,\nfor any integer k, we prove that every strongly connected digraph containing no\nsubdivisions of C(k,1,1,1,1,1) has a chromatic number at most O(k), and we\nsignificantly reduce the chromatic number in case k=1.",
    "pdf_url": "http://arxiv.org/pdf/2505.15446v1",
    "published": "2025-05-21T12:29:08+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.18201v1",
    "title": "Reinforcement Twinning for Hybrid Control of Flapping-Wing Drones",
    "authors": [
      "Romain Poletti",
      "Lorenzo Schena",
      "Lilla Koloszar",
      "Joris Degroote",
      "Miguel Alfonso Mendez"
    ],
    "abstract": "Controlling the flight of flapping-wing drones requires versatile controllers\nthat handle their time-varying, nonlinear, and underactuated dynamics from\nincomplete and noisy sensor data. Model-based methods struggle with accurate\nmodeling, while model-free approaches falter in efficiently navigating very\nhigh-dimensional and nonlinear control objective landscapes. This article\npresents a novel hybrid model-free/model-based approach to flight control based\non the recently proposed reinforcement twinning algorithm. The model-based (MB)\napproach relies on an adjoint formulation using an adaptive digital twin,\ncontinuously identified from live trajectories, while the model-free (MF)\napproach relies on reinforcement learning. The two agents collaborate through\ntransfer learning, imitation learning, and experience sharing using the real\nenvironment, the digital twin and a referee. The latter selects the best agent\nto interact with the real environment based on performance within the digital\ntwin and a real-to-virtual environment consistency ratio. The algorithm is\nevaluated for controlling the longitudinal dynamics of a flapping-wing drone,\nwith the environment simulated as a nonlinear, time-varying dynamical system\nunder the influence of quasi-steady aerodynamic forces. The hybrid control\nlearning approach is tested with three types of initialization of the adaptive\nmodel: (1) offline identification using previously available data, (2) random\ninitialization with full online identification, and (3) offline pre-training\nwith an estimation bias, followed by online adaptation. In all three scenarios,\nthe proposed hybrid learning approach demonstrates superior performance\ncompared to purely model-free and model-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.18201v1",
    "published": "2025-05-21T12:27:09+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15445v1",
    "title": "On Optimizing Time-, Space- and Power-Domain Energy-Saving Techniques for Sub-6 GHz Base Stations",
    "authors": [
      "Emanuele Peschiera",
      "Youssef Agram",
      "Fran√ßois Quitin",
      "Liesbet Van der Perre",
      "Fran√ßois Rottenberg"
    ],
    "abstract": "What is the optimal base station (BS) resource allocation strategy given a\nmeasurement-based power consumption model and a fixed target user rate?\nRush-to-sleep in time, rush-to-mute in space, awake-but-whisper in power, or a\ncombination of them? We propose in this paper an efficient solution to the\nproblem of finding the optimal number of active time slots, active antennas,\nand transmit power at active antennas in a multiple-input multiple-output\n(MIMO) orthogonal frequency-division multiplexing (OFDM) system under per-user\nrate and per-antenna transmit power constraints. The use of a parametric power\nconsumption model validated on operator measurements of 4G and 5G BSs enhances\nthe interpretation of the results. We discuss the optimal energy-saving\nstrategy at different network loads for three BS configurations. Using as few\nBS antennas as possible is close to optimal in BSs not implementing time-domain\npower savings such as micro-discontinuous transmission ({\\mu}DTX).\nEnergy-saving schemes that jointly operate in the three domains are instead\noptimal when the BS hardware can enter time-domain power-saving modes, with a\ntendency for rush-to-mute in massive MIMO and for rush-to-sleep in BS with\nfewer antennas. Median energy savings up to $30\\%$ are achieved at low network\nloads.",
    "pdf_url": "http://arxiv.org/pdf/2505.15445v1",
    "published": "2025-05-21T12:25:26+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15444v1",
    "title": "Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization",
    "authors": [
      "Yutao Zhu",
      "Jiajie Jin",
      "Hongjin Qian",
      "Zheng Liu",
      "Zhicheng Dou",
      "Ji-Rong Wen"
    ],
    "abstract": "Existing studies have optimized retrieval-augmented generation (RAG) across\nvarious sub-tasks, such as query understanding and retrieval refinement, but\nintegrating these optimizations into a unified framework remains challenging.\nTo tackle this problem, this work proposes RoleRAG, a unified RAG framework\nthat achieves efficient multi-task processing through role-specific token\noptimization. RoleRAG comprises six modules, each handling a specific sub-task\nwithin the RAG process. Additionally, we introduce a query graph to represent\nthe decomposition of the query, which can be dynamically resolved according to\nthe decomposing state. All modules are driven by the same underlying LLM,\ndistinguished by task-specific role tokens that are individually optimized.\nThis design allows RoleRAG to dynamically activate different modules within a\nsingle LLM instance, thereby streamlining deployment and reducing resource\nconsumption. Experimental results on five open-domain question-answering\ndatasets demonstrate the effectiveness, generalizability, and flexibility of\nour framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.15444v1",
    "published": "2025-05-21T12:25:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15443v1",
    "title": "AdUE: Improving uncertainty estimation head for LoRA adapters in LLMs",
    "authors": [
      "Artem Zabolotnyi",
      "Roman Makarov",
      "Mile Mitrovic",
      "Polina Proskura",
      "Oleg Travkin",
      "Roman Alferov",
      "Alexey Zaytsev"
    ],
    "abstract": "Uncertainty estimation remains a critical challenge in adapting pre-trained\nlanguage models to classification tasks, particularly under parameter-efficient\nfine-tuning approaches such as adapters. We introduce AdUE1, an efficient\npost-hoc uncertainty estimation (UE) method, to enhance softmax-based\nestimates. Our approach (1) uses a differentiable approximation of the maximum\nfunction and (2) applies additional regularization through L2-SP, anchoring the\nfine-tuned head weights and regularizing the model. Evaluations on five NLP\nclassification datasets across four language models (RoBERTa, ELECTRA, LLaMA-2,\nQwen) demonstrate that our method consistently outperforms established\nbaselines such as Mahalanobis distance and softmax response. Our approach is\nlightweight (no base-model changes) and produces better-calibrated confidence.",
    "pdf_url": "http://arxiv.org/pdf/2505.15443v1",
    "published": "2025-05-21T12:23:40+00:00",
    "categories": [
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15442v2",
    "title": "On the Generalization vs Fidelity Paradox in Knowledge Distillation",
    "authors": [
      "Suhas Kamasetty Ramesh",
      "Ayan Sengupta",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Knowledge distillation (KD) is a key technique for compressing large language\nmodels into smaller ones while preserving performance. Despite the recent\ntraction of KD research, its effectiveness for smaller language models (LMs)\nand the mechanisms driving knowledge transfer remain underexplored. In this\nwork, we present the first large-scale empirical and statistical analysis of KD\nacross models ranging from 0.5B to 7B parameters on 14 complex reasoning tasks\nin a zero-shot setting. Our findings reveal that KD can improve the average\nperformance of smaller models by up to $10\\%$, with a peak task specific gain\nof $22\\%$, while providing only marginal benefits ($\\sim 1.3\\%$) for larger\nmodels. Surprisingly, teacher performance has a minimal impact on student\noutcomes, while teacher task expertise impacts KD effectiveness. A correlation\nstudy indicates that smaller LMs benefit more from KD, whereas larger LMs show\ndiminished gains. Additionally, we uncover a misalignment between improvements\nin student performance and reasoning fidelity, suggesting that while KD\nenhances accuracy, it does not always maintain the structured decision-making\nprocesses of the teacher. Our ablation study further highlights the importance\nof teacher signals and logit smoothing in influencing students' performance\nafter distillation. Overall, our study offers a comprehensive empirical and\nstatistical assessment of KD, highlighting both its benefits and trade-offs\nwhen distilling knowledge from larger to smaller LMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15442v2",
    "published": "2025-05-21T12:23:32+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15441v2",
    "title": "Stronger ViTs With Octic Equivariance",
    "authors": [
      "David Nordstr√∂m",
      "Johan Edstedt",
      "Fredrik Kahl",
      "Georg B√∂kman"
    ],
    "abstract": "Recent efforts at scaling computer vision models have established Vision\nTransformers (ViTs) as the leading architecture. ViTs incorporate weight\nsharing over image patches as an important inductive bias. In this work, we\nshow that ViTs benefit from incorporating equivariance under the octic group,\ni.e., reflections and 90-degree rotations, as a further inductive bias. We\ndevelop new architectures, octic ViTs, that use octic-equivariant layers and\nput them to the test on both supervised and self-supervised learning. Through\nextensive experiments on DeiT-III and DINOv2 training on ImageNet-1K, we show\nthat octic ViTs yield more computationally efficient networks while also\nimproving performance. In particular, we achieve approximately 40% reduction in\nFLOPs for ViT-H while simultaneously improving both classification and\nsegmentation results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15441v2",
    "published": "2025-05-21T12:22:53+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15440v1",
    "title": "What Is Serendipity? An Interview Study to Conceptualize Experienced Serendipity in Recommender Systems",
    "authors": [
      "Brett Binst",
      "Lien Michiels",
      "Annelien Smets"
    ],
    "abstract": "Serendipity has been associated with numerous benefits in the context of\nrecommender systems, e.g., increased user satisfaction and consumption of\nlong-tail items. Despite this, serendipity in the context of recommender\nsystems has thus far remained conceptually ambiguous. This conceptual ambiguity\nhas led to inconsistent operationalizations between studies, making it\ndifficult to compare and synthesize findings. In this paper, we conceptualize\nthe user's experience of serendipity. To this effect, we interviewed 17\nparticipants and analyzed the data following the grounded theory paradigm.\nBased on these interviews, we conceptualize experienced serendipity as \"a user\nexperience in which a user unintentionally encounters content that feels\nfortuitous, refreshing, and enriching\". We find that all three components --\nfortuitous, refreshing and enriching -- are necessary and together are\nsufficient to classify a user's experience as serendipitous. However, these\ncomponents can be satisfied through a variety of conditions. Our\nconceptualization unifies previous definitions of serendipity within a single\nframework, resolving inconsistencies by identifying distinct flavors of\nserendipity. It highlights underexposed flavors, offering new insights into how\nusers experience serendipity in the context of recommender systems. By\nclarifying the components and conditions of experienced serendipity in\nrecommender systems, this work can guide the design of recommender systems that\nstimulate experienced serendipity in their users, and lays the groundwork for\ndeveloping a standardized operationalization of experienced serendipity in its\nmany flavors, enabling more consistent and comparable evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15440v1",
    "published": "2025-05-21T12:22:24+00:00",
    "categories": [
      "cs.HC",
      "H.1.2; H.3.3; H.5.2"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15439v1",
    "title": "FRN: Fractal-Based Recursive Spectral Reconstruction Network",
    "authors": [
      "Ge Meng",
      "Zhongnan Cai",
      "Ruizhe Chen",
      "Jingyan Tu",
      "Yingying Wang",
      "Yue Huang",
      "Xinghao Ding"
    ],
    "abstract": "Generating hyperspectral images (HSIs) from RGB images through spectral\nreconstruction can significantly reduce the cost of HSI acquisition. In this\npaper, we propose a Fractal-Based Recursive Spectral Reconstruction Network\n(FRN), which differs from existing paradigms that attempt to directly integrate\nthe full-spectrum information from the R, G, and B channels in a one-shot\nmanner. Instead, it treats spectral reconstruction as a progressive process,\npredicting from broad to narrow bands or employing a coarse-to-fine approach\nfor predicting the next wavelength. Inspired by fractals in mathematics, FRN\nestablishes a novel spectral reconstruction paradigm by recursively invoking an\natomic reconstruction module. In each invocation, only the spectral information\nfrom neighboring bands is used to provide clues for the generation of the image\nat the next wavelength, which follows the low-rank property of spectral data.\nMoreover, we design a band-aware state space model that employs a\npixel-differentiated scanning strategy at different stages of the generation\nprocess, further suppressing interference from low-correlation regions caused\nby reflectance differences. Through extensive experimentation across different\ndatasets, FRN achieves superior reconstruction performance compared to\nstate-of-the-art methods in both quantitative and qualitative evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15439v1",
    "published": "2025-05-21T12:20:59+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.18200v1",
    "title": "CrossRF: A Domain-Invariant Deep Learning Approach for RF Fingerprinting",
    "authors": [
      "Fahrettin Emin Tiras",
      "Hayriye Serra Altinoluk"
    ],
    "abstract": "Radio Frequency (RF) fingerprinting offers a promising approach for drone\nidentification and security, although it suffers from significant performance\ndegradation when operating on different transmission channels. This paper\npresents CrossRF, a domain-invariant deep learning approach that addresses the\nproblem of cross-channel RF fingerprinting for Unmanned Aerial Vehicle (UAV)\nidentification. Our approach aims to minimize the domain gap between different\nRF channels by using adversarial learning to train a more robust model that\nmaintains consistent identification performance despite channel variations. We\nvalidate our approach using the UAVSig dataset, comprising real-world\nover-the-air RF signals from identical drone models operating across several\nfrequency channels, ensuring that the findings correspond to real-world\nscenarios. The experimental results show CrossRF's efficiency, achieving up to\n99.03% accuracy when adapting from Channel 3 to Channel 4, compared to only\n26.39% using conventional methods. The model maintains robust performance in\nmore difficult multi-channel scenarios (87.57% accuracy adapting from Channels\n1,3 to 2,4) and achieves 89.45% accuracy with 0.9 precision for controller\nclassification. These results confirm CrossRF's ability to significantly reduce\nperformance degradation due to cross-channel variations while maintaining high\nidentification accuracy with minimal training data requirements, making it\nparticularly suitable for practical drone security applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.18200v1",
    "published": "2025-05-21T12:20:10+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15438v1",
    "title": "Bridging Sign and Spoken Languages: Pseudo Gloss Generation for Sign Language Translation",
    "authors": [
      "Jianyuan Guo",
      "Peike Li",
      "Trevor Cohn"
    ],
    "abstract": "Sign Language Translation (SLT) aims to map sign language videos to spoken\nlanguage text. A common approach relies on gloss annotations as an intermediate\nrepresentation, decomposing SLT into two sub-tasks: video-to-gloss recognition\nand gloss-to-text translation. While effective, this paradigm depends on\nexpert-annotated gloss labels, which are costly and rarely available in\nexisting datasets, limiting its scalability. To address this challenge, we\npropose a gloss-free pseudo gloss generation framework that eliminates the need\nfor human-annotated glosses while preserving the structured intermediate\nrepresentation. Specifically, we prompt a Large Language Model (LLM) with a few\nexample text-gloss pairs using in-context learning to produce draft sign\nglosses from spoken language text. To enhance the correspondence between\nLLM-generated pseudo glosses and the sign sequences in video, we correct the\nordering in the pseudo glosses for better alignment via a weakly supervised\nlearning process. This reordering facilitates the incorporation of auxiliary\nalignment objectives, and allows for the use of efficient supervision via a\nConnectionist Temporal Classification (CTC) loss. We train our SLT mode, which\nconsists of a vision encoder and a translator, through a three-stage pipeline,\nwhich progressively narrows the modality gap between sign language and spoken\nlanguage. Despite its simplicity, our approach outperforms previous\nstate-of-the-art gloss-free frameworks on two SLT benchmarks and achieves\ncompetitive results compared to gloss-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15438v1",
    "published": "2025-05-21T12:19:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15436v1",
    "title": "Chain-of-Focus: Adaptive Visual Search and Zooming for Multimodal Reasoning via RL",
    "authors": [
      "Xintong Zhang",
      "Zhi Gao",
      "Bofei Zhang",
      "Pengxiang Li",
      "Xiaowen Zhang",
      "Yang Liu",
      "Tao Yuan",
      "Yuwei Wu",
      "Yunde Jia",
      "Song-Chun Zhu",
      "Qing Li"
    ],
    "abstract": "Vision language models (VLMs) have achieved impressive performance across a\nvariety of computer vision tasks. However, the multimodal reasoning capability\nhas not been fully explored in existing models. In this paper, we propose a\nChain-of-Focus (CoF) method that allows VLMs to perform adaptive focusing and\nzooming in on key image regions based on obtained visual cues and the given\nquestions, achieving efficient multimodal reasoning. To enable this CoF\ncapability, we present a two-stage training pipeline, including supervised\nfine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we\nconstruct the MM-CoF dataset, comprising 3K samples derived from a visual agent\ndesigned to adaptively identify key regions to solve visual tasks with\ndifferent image resolutions and questions. We use MM-CoF to fine-tune the\nQwen2.5-VL model for cold start. In the RL stage, we leverage the outcome\naccuracies and formats as rewards to update the Qwen2.5-VL model, enabling\nfurther refining the search and reasoning strategy of models without human\npriors. Our model achieves significant improvements on multiple benchmarks. On\nthe V* benchmark that requires strong visual reasoning capability, our model\noutperforms existing VLMs by 5% among 8 image resolutions ranging from 224 to\n4K, demonstrating the effectiveness of the proposed CoF method and facilitating\nthe more efficient deployment of VLMs in practical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15436v1",
    "published": "2025-05-21T12:18:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15437v1",
    "title": "Adaptive Temperature Scaling with Conformal Prediction",
    "authors": [
      "Nikita Kotelevskii",
      "Mohsen Guizani",
      "Eric Moulines",
      "Maxim Panov"
    ],
    "abstract": "Conformal prediction enables the construction of high-coverage prediction\nsets for any pre-trained model, guaranteeing that the true label lies within\nthe set with a specified probability. However, these sets do not provide\nprobability estimates for individual labels, limiting their practical use. In\nthis paper, we propose, to the best of our knowledge, the first method for\nassigning calibrated probabilities to elements of a conformal prediction set.\nOur approach frames this as an adaptive calibration problem, selecting an\ninput-specific temperature parameter to match the desired coverage level.\nExperiments on several challenging image classification datasets demonstrate\nthat our method maintains coverage guarantees while significantly reducing\nexpected calibration error.",
    "pdf_url": "http://arxiv.org/pdf/2505.15437v1",
    "published": "2025-05-21T12:18:15+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15435v1",
    "title": "TimeCausality: Evaluating the Causal Ability in Time Dimension for Vision Language Models",
    "authors": [
      "Zeqing Wang",
      "Shiyuan Zhang",
      "Chengpei Tang",
      "Keze Wang"
    ],
    "abstract": "Reasoning about temporal causality, particularly irreversible transformations\nof objects governed by real-world knowledge (e.g., fruit decay and human\naging), is a fundamental aspect of human visual understanding. Unlike temporal\nperception based on simple event sequences, this form of reasoning requires a\ndeeper comprehension of how object states change over time. Although the\ncurrent powerful Vision-Language Models (VLMs) have demonstrated impressive\nperformance on a wide range of downstream tasks, their capacity to reason about\ntemporal causality remains underexplored. To address this gap, we introduce\n\\textbf{TimeCausality}, a novel benchmark specifically designed to evaluate the\ncausal reasoning ability of VLMs in the temporal dimension. Based on our\nTimeCausality, we find that while the current SOTA open-source VLMs have\nachieved performance levels comparable to closed-source models like GPT-4o on\nvarious standard visual question answering tasks, they fall significantly\nbehind on our benchmark compared with their closed-source competitors.\nFurthermore, even GPT-4o exhibits a marked drop in performance on TimeCausality\ncompared to its results on other tasks. These findings underscore the critical\nneed to incorporate temporal causality into the evaluation and development of\nVLMs, and they highlight an important challenge for the open-source VLM\ncommunity moving forward. Code and Data are available at\n\\href{https://github.com/Zeqing-Wang/TimeCausality }{TimeCausality}.",
    "pdf_url": "http://arxiv.org/pdf/2505.15435v1",
    "published": "2025-05-21T12:18:02+00:00",
    "categories": [
      "cs.CV",
      "I.4.9"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15434v1",
    "title": "A Faster Algorithm for Independent Cut",
    "authors": [
      "Vsevolod Chernyshev",
      "Johannes Rauch",
      "Dieter Rautenbach",
      "Liliia Redina"
    ],
    "abstract": "The previously fastest algorithm for deciding the existence of an independent\ncut had a runtime of $\\mathcal{O}^*(1.4423^n)$, where $n$ is the order of the\ninput graph. We improve this to $\\mathcal{O}^*(1.4143^n)$. In fact, we prove a\nruntime of $\\mathcal{O}^*\\left( 2^{(\\frac{1}{2}-\\alpha_\\Delta)n} \\right)$ on\ngraphs of order $n$ and maximum degree at most $\\Delta$, where\n$\\alpha_\\Delta=\\frac{1}{2+4\\lfloor \\frac{\\Delta}{2} \\rfloor}$. Furthermore, we\nshow that the problem is fixed-parameter tractable on graphs of order $n$ and\nminimum degree at least $\\beta n$ for some $\\beta > \\frac{1}{2}$, where $\\beta$\nis the parameter.",
    "pdf_url": "http://arxiv.org/pdf/2505.15434v1",
    "published": "2025-05-21T12:15:43+00:00",
    "categories": [
      "cs.DS",
      "68R10",
      "G.2.2"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15433v1",
    "title": "Set-LLM: A Permutation-Invariant LLM",
    "authors": [
      "Beni Egressy",
      "Jan St√ºhmer"
    ],
    "abstract": "While large language models (LLMs) demonstrate impressive capabilities across\nnumerous applications, their robustness remains a critical concern. This paper\nis motivated by a specific vulnerability: the order sensitivity of LLMs. This\nvulnerability manifests itself as the order bias observed when LLMs decide\nbetween possible options (for example, a preference for the first option) and\nthe tendency of LLMs to provide different answers when options are reordered.\nThe use cases for this scenario extend beyond the classical case of\nmultiple-choice question answering to the use of LLMs as automated evaluators\nin AI pipelines, comparing output generated by different models. We introduce\nSet-LLM, a novel architectural adaptation for pretrained LLMs that enables the\nprocessing of mixed set-text inputs with permutation invariance guarantees. The\nadaptations involve a new attention mask and new positional encodings\nspecifically designed for sets. We provide a theoretical proof of invariance\nand demonstrate through experiments that Set-LLM can be trained effectively,\nachieving comparable or improved performance and maintaining the runtime of the\noriginal model, while eliminating order sensitivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15433v1",
    "published": "2025-05-21T12:14:26+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15432v1",
    "title": "Affine standard Lyndon words",
    "authors": [
      "Corbet Elkins",
      "Alexander Tsymbaliuk"
    ],
    "abstract": "In this note, we establish the convexity and monotonicity for affine standard\nLyndon words in all types, generalizing the $A$-type results of\narXiv:2305.16299. We also derive partial results on the structure of imaginary\nstandard Lyndon words and present a conjecture for their general form.\nAdditionally, we provide computer code in Appendix which, in particular, allows\nto efficiently compute affine standard Lyndon words in exceptional types for\nall orders.",
    "pdf_url": "http://arxiv.org/pdf/2505.15432v1",
    "published": "2025-05-21T12:13:32+00:00",
    "categories": [
      "math.RT",
      "math.CO",
      "math.QA"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15431v3",
    "title": "Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought",
    "authors": [
      "Tencent Hunyuan Team",
      "Ao Liu",
      "Botong Zhou",
      "Can Xu",
      "Chayse Zhou",
      "ChenChen Zhang",
      "Chengcheng Xu",
      "Chenhao Wang",
      "Decheng Wu",
      "Dengpeng Wu",
      "Dian Jiao",
      "Dong Du",
      "Dong Wang",
      "Feng Zhang",
      "Fengzong Lian",
      "Guanghui Xu",
      "Guanwei Zhang",
      "Hai Wang",
      "Haipeng Luo",
      "Han Hu",
      "Huilin Xu",
      "Jiajia Wu",
      "Jianchen Zhu",
      "Jianfeng Yan",
      "Jiaqi Zhu",
      "Jihong Zhang",
      "Jinbao Xue",
      "Jun Xia",
      "Junqiang Zheng",
      "Kai Liu",
      "Kai Zhang",
      "Kai Zheng",
      "Kejiao Li",
      "Keyao Wang",
      "Lan Jiang",
      "Lixin Liu",
      "Lulu Wu",
      "Mengyuan Huang",
      "Peijie Yu",
      "Peiqi Wang",
      "Qian Wang",
      "Qianbiao Xiang",
      "Qibin Liu",
      "Qingfeng Sun",
      "Richard Guo",
      "Ruobing Xie",
      "Saiyong Yang",
      "Shaohua Chen",
      "Shihui Hu",
      "Shuai Li",
      "Shuaipeng Li",
      "Shuang Chen",
      "Suncong Zheng",
      "Tao Yang",
      "Tian Zhang",
      "Tinghao Yu",
      "Weidong Han",
      "Weijie Liu",
      "Weijin Zhou",
      "Weikang Wang",
      "Wesleye Chen",
      "Xiao Feng",
      "Xiaoqin Ren",
      "Xingwu Sun",
      "Xiong Kuang",
      "Xuemeng Huang",
      "Xun Cao",
      "Yanfeng Chen",
      "Yang Du",
      "Zhen Yang",
      "Yangyu Tao",
      "Yaping Deng",
      "Yi Shen",
      "Yigeng Hong",
      "Yiqi Chen",
      "Yiqing Huang",
      "Yuchi Deng",
      "Yue Mao",
      "Yulong Wang",
      "Yuyuan Zeng",
      "Zenan Xu",
      "Zhanhui Kang",
      "Zhe Zhao",
      "ZhenXiang Yan",
      "Zheng Fang",
      "Zhichao Hu",
      "Zhongzhi Chen",
      "Zhuoyu Li",
      "Zongwei Li",
      "Alex Yan",
      "Ande Liang",
      "Baitong Liu",
      "Beiping Pan",
      "Bin Xing",
      "Binghong Wu",
      "Bingxin Qu",
      "Bolin Ni",
      "Boyu Wu",
      "Chen Li",
      "Cheng Jiang",
      "Cheng Zhang",
      "Chengjun Liu",
      "Chengxu Yang",
      "Chengzhong Xu",
      "Chiyu Wang",
      "Chong Zha",
      "Daisy Yi",
      "Di Wang",
      "Fanyang Lu",
      "Fei Chen",
      "Feifei Liu",
      "Feng Zheng",
      "Guanghua Yu",
      "Guiyang Li",
      "Guohua Wang",
      "Haisheng Lin",
      "Han Liu",
      "Han Wang",
      "Hao Fei",
      "Hao Lu",
      "Haoqing Jiang",
      "Haoran Sun",
      "Haotian Zhu",
      "Huangjin Dai",
      "Huankui Chen",
      "Huawen Feng",
      "Huihui Cai",
      "Huxin Peng",
      "Jackson Lv",
      "Jiacheng Shi",
      "Jiahao Bu",
      "Jianbo Li",
      "Jianglu Hu",
      "Jiangtao Guan",
      "Jianing Xu",
      "Jianwei Cai",
      "Jiarong Zhang",
      "Jiawei Song",
      "Jie Jiang",
      "Jie Liu",
      "Jieneng Yang",
      "Jihong Zhang",
      "Jin lv",
      "Jing Zhao",
      "Jinjian Li",
      "Jinxing Liu",
      "Jun Zhao",
      "Juntao Guo",
      "Kai Wang",
      "Kan Wu",
      "Lei Fu",
      "Lei He",
      "Lei Wang",
      "Li Liu",
      "Liang Dong",
      "Liya Zhan",
      "Long Cheng",
      "Long Xu",
      "Mao Zheng",
      "Meng Liu",
      "Mengkang Hu",
      "Nanli Chen",
      "Peirui Chen",
      "Peng He",
      "Pengju Pan",
      "Pengzhi Wei",
      "Qi Yang",
      "Qi Yi",
      "Roberts Wang",
      "Rongpeng Chen",
      "Rui Sun",
      "Rui Yang",
      "Ruibin Chen",
      "Ruixu Zhou",
      "Shaofeng Zhang",
      "Sheng Zhang",
      "Shihao Xu",
      "Shuaishuai Chang",
      "Shulin Liu",
      "SiQi Wang",
      "Songjia Feng",
      "Songling Yuan",
      "Tao Zhang",
      "Tianjiao Lang",
      "Tongkai Li",
      "Wei Deng",
      "Wei Li",
      "Weichao Wang",
      "Weigang Zhang",
      "Weixuan Sun",
      "Wen Ouyang",
      "Wenxiang Jiao",
      "Wenzhi Sun",
      "Wenzhuo Jia",
      "Xiang Zhang",
      "Xiangyu He",
      "Xianshun Ren",
      "XiaoYing Zhu",
      "Xiaolong Guo",
      "Xiaoxue Li",
      "Xiaoyu Ma",
      "Xican Lu",
      "Xinhua Feng",
      "Xinting Huang",
      "Xinyu Guan",
      "Xirui Li",
      "Xu Zhang",
      "Xudong Gao",
      "Xun Luo",
      "Xuxiang Qi",
      "Yangkun Chen",
      "Yangyu Tao",
      "Yanling Xiao",
      "Yantao Mai",
      "Yanze Chen",
      "Yao Ding",
      "Yeting Yang",
      "YiFan Song",
      "Yifan Yang",
      "Yijiao Zhu",
      "Yinhe Wu",
      "Yixian Liu",
      "Yong Yang",
      "Yuanjun Cai",
      "Yuanlin Tu",
      "Yue Zhang",
      "Yufei Huang",
      "Yuhang Zhou",
      "Yuhao Jiang",
      "Yuhong Liu",
      "Yuhui Hu",
      "Yujin Lin",
      "Yun Yang",
      "Yunhao Wang",
      "Yusong Zhang",
      "Zekun Wu",
      "Zelong Zhang",
      "Zhan Yu",
      "Zhaoliang Yang",
      "Zhe Zhao",
      "Zheng Li",
      "Zhenyu Huang",
      "Zhiguang Liu",
      "Zhijiang Xu",
      "Zhiqing Kui",
      "Zhiyin Zeng",
      "Zhiyuan Xiong",
      "Zhuo Han",
      "Zifan Wu",
      "Zigang Geng",
      "Zilong Zhao",
      "Ziyan Tang",
      "Ziyuan Zhu",
      "Zonglei Zhu",
      "Zhijiang Xu"
    ],
    "abstract": "As Large Language Models (LLMs) rapidly advance, we introduce Hunyuan-TurboS,\na novel large hybrid Transformer-Mamba Mixture of Experts (MoE) model. It\nsynergistically combines Mamba's long-sequence processing efficiency with\nTransformer's superior contextual understanding. Hunyuan-TurboS features an\nadaptive long-short chain-of-thought (CoT) mechanism, dynamically switching\nbetween rapid responses for simple queries and deep \"thinking\" modes for\ncomplex problems, optimizing computational resources. Architecturally, this 56B\nactivated (560B total) parameter model employs 128 layers (Mamba2, Attention,\nFFN) with an innovative AMF/MF block pattern. Faster Mamba2 ensures linear\ncomplexity, Grouped-Query Attention minimizes KV cache, and FFNs use an MoE\nstructure. Pre-trained on 16T high-quality tokens, it supports a 256K context\nlength and is the first industry-deployed large-scale Mamba model. Our\ncomprehensive post-training strategy enhances capabilities via Supervised\nFine-Tuning (3M instructions), a novel Adaptive Long-short CoT Fusion method,\nMulti-round Deliberation Learning for iterative improvement, and a two-stage\nLarge-scale Reinforcement Learning process targeting STEM and general\ninstruction-following. Evaluations show strong performance: overall top 7 rank\non LMSYS Chatbot Arena with a score of 1356, outperforming leading models like\nGemini-2.0-Flash-001 (1352) and o4-mini-2025-04-16 (1345). TurboS also achieves\nan average of 77.9% across 23 automated benchmarks. Hunyuan-TurboS balances\nhigh performance and efficiency, offering substantial capabilities at lower\ninference costs than many reasoning models, establishing a new paradigm for\nefficient large-scale pre-trained models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15431v3",
    "published": "2025-05-21T12:11:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15430v1",
    "title": "Wireless Sensing via Pinching-Antenna Systems",
    "authors": [
      "Zhaolin Wang",
      "Chongjun Ouyang",
      "Yuanwei Liu",
      "Arumugam Nallanathan"
    ],
    "abstract": "A wireless sensing architecture via pinching antenna systems is proposed.\nCompared to conventional wireless systems, PASS offers flexible antenna\ndeployment and improved probing performance for wireless sensing by leveraging\ndielectric waveguides and pinching antennas (PAs). To enhance signal reception,\nleaky coaxial (LCX) cables are used to uniformly collect echo signals over a\nwide area. The Cram\\'er-Rao bound (CRB) for multi-target sensing is derived and\nthen minimized through the joint optimization of the transmit waveform and the\npositions of PAs. To solve the resulting highly coupled, non-convex problem, a\ntwo-stage particle swarm optimization (PSO)-based algorithm is proposed.\nNumerical results demonstrate significant gains in sensing accuracy and\nrobustness over conventional sensing systems, highlighting the benefits of\nintegrating LCX-based reception with optimized PASS configurations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15430v1",
    "published": "2025-05-21T12:11:17+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15429v1",
    "title": "Uncertainty Quantification in SVM prediction",
    "authors": [
      "Pritam Anand"
    ],
    "abstract": "This paper explores Uncertainty Quantification (UQ) in SVM predictions,\nparticularly for regression and forecasting tasks. Unlike the Neural Network,\nthe SVM solutions are typically more stable, sparse, optimal and interpretable.\nHowever, there are only few literature which addresses the UQ in SVM\nprediction. At first, we provide a comprehensive summary of existing Prediction\nInterval (PI) estimation and probabilistic forecasting methods developed in the\nSVM framework and evaluate them against the key properties expected from an\nideal PI model. We find that none of the existing SVM PI models achieves a\nsparse solution. To introduce sparsity in SVM model, we propose the Sparse\nSupport Vector Quantile Regression (SSVQR) model, which constructs PIs and\nprobabilistic forecasts by solving a pair of linear programs. Further, we\ndevelop a feature selection algorithm for PI estimation using SSVQR that\neffectively eliminates a significant number of features while improving PI\nquality in case of high-dimensional dataset. Finally we extend the SVM models\nin Conformal Regression setting for obtaining more stable prediction set with\nfinite test set guarantees. Extensive experiments on artificial, real-world\nbenchmark datasets compare the different characteristics of both existing and\nproposed SVM-based PI estimation methods and also highlight the advantages of\nthe feature selection in PI estimation. Furthermore, we compare both, the\nexisting and proposed SVM-based PI estimation models, with modern deep learning\nmodels for probabilistic forecasting tasks on benchmark datasets. Furthermore,\nSVM models show comparable or superior performance to modern complex deep\nlearning models for probabilistic forecasting task in our experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15429v1",
    "published": "2025-05-21T12:11:07+00:00",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15428v1",
    "title": "Likelihood Variance as Text Importance for Resampling Texts to Map Language Models",
    "authors": [
      "Momose Oyama",
      "Ryo Kishino",
      "Hiroaki Yamagiwa",
      "Hidetoshi Shimodaira"
    ],
    "abstract": "We address the computational cost of constructing a model map, which embeds\ndiverse language models into a common space for comparison via KL divergence.\nThe map relies on log-likelihoods over a large text set, making the cost\nproportional to the number of texts. To reduce this cost, we propose a\nresampling method that selects important texts with weights proportional to the\nvariance of log-likelihoods across models for each text. Our method\nsignificantly reduces the number of required texts while preserving the\naccuracy of KL divergence estimates. Experiments show that it achieves\ncomparable performance to uniform sampling with about half as many texts, and\nalso facilitates efficient incorporation of new models into an existing map.\nThese results enable scalable and efficient construction of language model\nmaps.",
    "pdf_url": "http://arxiv.org/pdf/2505.15428v1",
    "published": "2025-05-21T12:10:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15427v1",
    "title": "Responsible Diffusion Models via Constraining Text Embeddings within Safe Regions",
    "authors": [
      "Zhiwen Li",
      "Die Chen",
      "Mingyuan Fan",
      "Cen Chen",
      "Yaliang Li",
      "Yanhao Wang",
      "Wenmeng Zhou"
    ],
    "abstract": "The remarkable ability of diffusion models to generate high-fidelity images\nhas led to their widespread adoption. However, concerns have also arisen\nregarding their potential to produce Not Safe for Work (NSFW) content and\nexhibit social biases, hindering their practical use in real-world\napplications. In response to this challenge, prior work has focused on\nemploying security filters to identify and exclude toxic text, or\nalternatively, fine-tuning pre-trained diffusion models to erase sensitive\nconcepts. Unfortunately, existing methods struggle to achieve satisfactory\nperformance in the sense that they can have a significant impact on the normal\nmodel output while still failing to prevent the generation of harmful content\nin some cases. In this paper, we propose a novel self-discovery approach to\nidentifying a semantic direction vector in the embedding space to restrict text\nembedding within a safe region. Our method circumvents the need for correcting\nindividual words within the input text and steers the entire text prompt\ntowards a safe region in the embedding space, thereby enhancing model\nrobustness against all possibly unsafe prompts. In addition, we employ Low-Rank\nAdaptation (LoRA) for semantic direction vector initialization to reduce the\nimpact on the model performance for other semantics. Furthermore, our method\ncan also be integrated with existing methods to improve their social\nresponsibility. Extensive experiments on benchmark datasets demonstrate that\nour method can effectively reduce NSFW content and mitigate social bias\ngenerated by diffusion models compared to several state-of-the-art baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.15427v1",
    "published": "2025-05-21T12:10:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15426v1",
    "title": "NeoN: A Tool for Automated Detection, Linguistic and LLM-Driven Analysis of Neologisms in Polish",
    "authors": [
      "Aleksandra Tomaszewska",
      "Dariusz Czerski",
      "Bartosz ≈ªuk",
      "Maciej Ogrodniczuk"
    ],
    "abstract": "NeoN, a tool for detecting and analyzing Polish neologisms. Unlike\ntraditional dictionary-based methods requiring extensive manual review, NeoN\ncombines reference corpora, Polish-specific linguistic filters, an LLM-driven\nprecision-boosting filter, and daily RSS monitoring in a multi-layered\npipeline. The system uses context-aware lemmatization, frequency analysis, and\northographic normalization to extract candidate neologisms while consolidating\ninflectional variants. Researchers can verify candidates through an intuitive\ninterface with visualizations and filtering controls. An integrated LLM module\nautomatically generates definitions and categorizes neologisms by domain and\nsentiment. Evaluations show NeoN maintains high accuracy while significantly\nreducing manual effort, providing an accessible solution for tracking lexical\ninnovation in Polish.",
    "pdf_url": "http://arxiv.org/pdf/2505.15426v1",
    "published": "2025-05-21T12:09:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15425v2",
    "title": "On the Robustness of Medical Vision-Language Models: Are they Truly Generalizable?",
    "authors": [
      "Raza Imam",
      "Rufael Marew",
      "Mohammad Yaqub"
    ],
    "abstract": "Medical Vision-Language Models (MVLMs) have achieved par excellence\ngeneralization in medical image analysis, yet their performance under noisy,\ncorrupted conditions remains largely untested. Clinical imaging is inherently\nsusceptible to acquisition artifacts and noise; however, existing evaluations\npredominantly assess generally clean datasets, overlooking robustness -- i.e.,\nthe model's ability to perform under real-world distortions. To address this\ngap, we first introduce MediMeta-C, a corruption benchmark that systematically\napplies several perturbations across multiple medical imaging datasets.\nCombined with MedMNIST-C, this establishes a comprehensive robustness\nevaluation framework for MVLMs. We further propose RobustMedCLIP, a visual\nencoder adaptation of a pretrained MVLM that incorporates few-shot tuning to\nenhance resilience against corruptions. Through extensive experiments, we\nbenchmark 5 major MVLMs across 5 medical imaging modalities, revealing that\nexisting models exhibit severe degradation under corruption and struggle with\ndomain-modality tradeoffs. Our findings highlight the necessity of diverse\ntraining and robust adaptation strategies, demonstrating that efficient\nlow-rank adaptation when paired with few-shot tuning, improves robustness while\npreserving generalization across modalities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15425v2",
    "published": "2025-05-21T12:08:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15424v1",
    "title": "Gated Integration of Low-Rank Adaptation for Continual Learning of Language Models",
    "authors": [
      "Yan-Shuo Liang",
      "Wu-Jun Li"
    ],
    "abstract": "Continual learning (CL), which requires the model to learn multiple tasks\nsequentially, is crucial for language models (LMs). Recently, low-rank\nadaptation (LoRA), one of the most representative parameter-efficient\nfine-tuning (PEFT) methods, has gained increasing attention in CL of LMs.\nHowever, most existing CL methods based on LoRA typically expand a new LoRA\nbranch to learn each new task and force the new and old LoRA branches to\ncontribute equally to old tasks, potentially leading to forgetting. In this\nwork, we propose a new method, called gated integration of low-rank adaptation\n(GainLoRA), for CL of LMs. GainLoRA expands a new LoRA branch for each new task\nand introduces gating modules to integrate the new and old LoRA branches.\nFurthermore, GainLoRA leverages the new gating module to minimize the\ncontribution from the new LoRA branch to old tasks, effectively mitigating\nforgetting and improving the model's overall performance. Experimental results\non CL benchmarks demonstrate that GainLoRA outperforms existing\nstate-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15424v1",
    "published": "2025-05-21T12:08:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15423v1",
    "title": "SplitWise Regression: Stepwise Modeling with Adaptive Dummy Encoding",
    "authors": [
      "Marcell T. Kurbucz",
      "Nikolaos Tzivanakis",
      "Nilufer Sari Aslam",
      "Adam M. Sykulski"
    ],
    "abstract": "Capturing nonlinear relationships without sacrificing interpretability\nremains a persistent challenge in regression modeling. We introduce SplitWise,\na novel framework that enhances stepwise regression. It adaptively transforms\nnumeric predictors into threshold-based binary features using shallow decision\ntrees, but only when such transformations improve model fit, as assessed by the\nAkaike Information Criterion (AIC) or Bayesian Information Criterion (BIC).\nThis approach preserves the transparency of linear models while flexibly\ncapturing nonlinear effects. Implemented as a user-friendly R package,\nSplitWise is evaluated on both synthetic and real-world datasets. The results\nshow that it consistently produces more parsimonious and generalizable models\nthan traditional stepwise and penalized regression techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.15423v1",
    "published": "2025-05-21T12:06:43+00:00",
    "categories": [
      "cs.LG",
      "econ.EM",
      "stat.AP",
      "stat.ME",
      "stat.ML",
      "62H20, 62J05, 68T05",
      "G.3; I.2.6; I.5.1; I.5.2"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15422v1",
    "title": "Trends and Challenges in Authorship Analysis: A Review of ML, DL, and LLM Approaches",
    "authors": [
      "Nudrat Habib",
      "Tosin Adewumi",
      "Marcus Liwicki",
      "Elisa Barney"
    ],
    "abstract": "Authorship analysis plays an important role in diverse domains, including\nforensic linguistics, academia, cybersecurity, and digital content\nauthentication. This paper presents a systematic literature review on two key\nsub-tasks of authorship analysis; Author Attribution and Author Verification.\nThe review explores SOTA methodologies, ranging from traditional ML approaches\nto DL models and LLMs, highlighting their evolution, strengths, and\nlimitations, based on studies conducted from 2015 to 2024. Key contributions\ninclude a comprehensive analysis of methods, techniques, their corresponding\nfeature extraction techniques, datasets used, and emerging challenges in\nauthorship analysis. The study highlights critical research gaps, particularly\nin low-resource language processing, multilingual adaptation, cross-domain\ngeneralization, and AI-generated text detection. This review aims to help\nresearchers by giving an overview of the latest trends and challenges in\nauthorship analysis. It also points out possible areas for future study. The\ngoal is to support the development of better, more reliable, and accurate\nauthorship analysis system in diverse textual domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.15422v1",
    "published": "2025-05-21T12:06:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15421v1",
    "title": "On various Carleson-type geometric lemmas and uniform rectifiability in metric spaces: Part 2",
    "authors": [
      "Katrin F√§ssler",
      "Ivan Yuri Violo"
    ],
    "abstract": "We characterize uniform $k$-rectifiability in Euclidean spaces in terms of a\nCarleson-type geometric lemma for a new notion of flatness coefficients, which\nwe call $\\iota$-numbers. The characterization follows from an abstract\nstatement about approximation by generalized planes in metric spaces, which\nalso applies to the study of low-dimensional sets in Heisenberg groups. A key\naspect is that the $\\iota$-coefficients are in general not pointwise comparable\nto the usual squared $\\beta$-numbers for dyadic cubes on $k$-regular sets in\n$\\mathbb{R}^n$, however our result implies that they are still equivalent in\nterms of a Carleson-type geometric lemma.",
    "pdf_url": "http://arxiv.org/pdf/2505.15421v1",
    "published": "2025-05-21T12:05:28+00:00",
    "categories": [
      "math.MG",
      "49Q15, 43A80, 43A85"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15420v1",
    "title": "Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries",
    "authors": [
      "Yuhao Wang",
      "Wenjie Qu",
      "Yanze Jiang",
      "Zichen Liu",
      "Yue Liu",
      "Shengfang Zhai",
      "Yinpeng Dong",
      "Jiaheng Zhang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems enhance large language models\n(LLMs) by incorporating external knowledge bases, but they are vulnerable to\nprivacy risks from data extraction attacks. Existing extraction methods\ntypically rely on malicious inputs such as prompt injection or jailbreaking,\nmaking them easily detectable via input- or output-level detection. In this\npaper, we introduce Implicit Knowledge Extraction Attack (IKEA), which conducts\nknowledge extraction on RAG systems through benign queries. IKEA first\nleverages anchor concepts to generate queries with the natural appearance, and\nthen designs two mechanisms to lead to anchor concept thoroughly 'explore' the\nRAG's privacy knowledge: (1) Experience Reflection Sampling, which samples\nanchor concepts based on past query-response patterns to ensure the queries'\nrelevance to RAG documents; (2) Trust Region Directed Mutation, which\niteratively mutates anchor concepts under similarity constraints to further\nexploit the embedding space. Extensive experiments demonstrate IKEA's\neffectiveness under various defenses, surpassing baselines by over 80% in\nextraction efficiency and 90% in attack success rate. Moreover, the substitute\nRAG system built from IKEA's extractions consistently outperforms those based\non baseline methods across multiple evaluation tasks, underscoring the\nsignificant privacy risk in RAG systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15420v1",
    "published": "2025-05-21T12:04:42+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15868v1",
    "title": "An Inclusive Foundation Model for Generalizable Cytogenetics in Precision Oncology",
    "authors": [
      "Changchun Yang",
      "Weiqian Dai",
      "Yilan Zhang",
      "Siyuan Chen",
      "Jingdong Hu",
      "Junkai Su",
      "Yuxuan Chen",
      "Ao Xu",
      "Na Li",
      "Xin Gao",
      "Yongguo Yu"
    ],
    "abstract": "Chromosome analysis is vital for diagnosing genetic disorders and guiding\ncancer therapy decisions through the identification of somatic clonal\naberrations. However, developing an AI model are hindered by the overwhelming\ncomplexity and diversity of chromosomal abnormalities, requiring extensive\nannotation efforts, while automated methods remain task-specific and lack\ngeneralizability due to the scarcity of comprehensive datasets spanning diverse\nresource conditions. Here, we introduce CHROMA, a foundation model for\ncytogenomics, designed to overcome these challenges by learning generalizable\nrepresentations of chromosomal abnormalities. Pre-trained on over 84,000\nspecimens (~4 million chromosomal images) via self-supervised learning, CHROMA\noutperforms other methods across all types of abnormalities, even when trained\non fewer labelled data and more imbalanced datasets. By facilitating\ncomprehensive mapping of instability and clonal leisons across various\naberration types, CHROMA offers a scalable and generalizable solution for\nreliable and automated clinical analysis, reducing the annotation workload for\nexperts and advancing precision oncology through the early detection of rare\ngenomic abnormalities, enabling broad clinical AI applications and making\nadvanced genomic analysis more accessible.",
    "pdf_url": "http://arxiv.org/pdf/2505.15868v1",
    "published": "2025-05-21T12:03:37+00:00",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15419v1",
    "title": "Impact of general relativistic accretion on primordial black holes",
    "authors": [
      "Santabrata Das",
      "Md Riajul Haque",
      "Jitumani Kalita",
      "Rajesh Karmakar",
      "Debaprasad Maity"
    ],
    "abstract": "We demonstrate that general relativistic corrections to the accretion of\nrelativistic matter onto primordial black holes (PBHs) can significantly\nenhance their mass growth during the early Universe. Contrary to previous\nNewtonian treatments, our analysis reveals that PBH masses can increase by an\norder of magnitude before evaporation, leading to substantial modifications of\ntheir lifetime and cosmological imprints. We quantify the resulting shifts in\nthe minimum PBH mass constrained by Big Bang Nucleosynthesis (BBN), the revised\nlower bound for PBHs surviving today, and the dark matter parameter space\nallowed by PBH evaporation. Furthermore, we show that the enhanced accretion\nalters the high-frequency gravitational wave spectrum from PBH evaporation,\npotentially within the reach of future detectors. Our results provide a\ncomprehensive, relativistically consistent framework to delineate the role of\nPBHs in early-universe cosmology and dark matter phenomenology.",
    "pdf_url": "http://arxiv.org/pdf/2505.15419v1",
    "published": "2025-05-21T12:02:28+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15418v1",
    "title": "Guided Policy Optimization under Partial Observability",
    "authors": [
      "Yueheng Li",
      "Guangming Xie",
      "Zongqing Lu"
    ],
    "abstract": "Reinforcement Learning (RL) in partially observable environments poses\nsignificant challenges due to the complexity of learning under uncertainty.\nWhile additional information, such as that available in simulations, can\nenhance training, effectively leveraging it remains an open problem. To address\nthis, we introduce Guided Policy Optimization (GPO), a framework that co-trains\na guider and a learner. The guider takes advantage of privileged information\nwhile ensuring alignment with the learner's policy that is primarily trained\nvia imitation learning. We theoretically demonstrate that this learning scheme\nachieves optimality comparable to direct RL, thereby overcoming key limitations\ninherent in existing approaches. Empirical evaluations show strong performance\nof GPO across various tasks, including continuous control with partial\nobservability and noise, and memory-based challenges, significantly\noutperforming existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15418v1",
    "published": "2025-05-21T12:01:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15417v1",
    "title": "Robust Multimodal Learning via Entropy-Gated Contrastive Fusion",
    "authors": [
      "Leon Chlon",
      "Maggie Chlon",
      "MarcAntonio M. Awada"
    ],
    "abstract": "Real-world multimodal systems routinely face missing-input scenarios, and in\nreality, robots lose audio in a factory or a clinical record omits lab tests at\ninference time. Standard fusion layers either preserve robustness or\ncalibration but never both. We introduce Adaptive Entropy-Gated Contrastive\nFusion (AECF), a single light-weight layer that (i) adapts its entropy\ncoefficient per instance, (ii) enforces monotone calibration across all\nmodality subsets, and (iii) drives a curriculum mask directly from\ntraining-time entropy. On AV-MNIST and MS-COCO, AECF improves masked-input mAP\nby +18 pp at a 50% drop rate while reducing ECE by up to 200%, yet adds 1%\nrun-time. All back-bones remain frozen, making AECF an easy drop-in layer for\nrobust, calibrated multimodal inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.15417v1",
    "published": "2025-05-21T12:00:37+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15416v1",
    "title": "$4K_1$-free graph with the cop number $3$",
    "authors": [
      "Arnab Char",
      "Paras Vinubhai Maniya",
      "Dinabandhu Pradhan"
    ],
    "abstract": "The game of cops and robber is a two-player turn-based game played on a graph\nwhere the cops try to capture the robber. The cop number of a graph $G$,\ndenoted by $c(G)$ is the minimum number of cops required to capture the robber.\nFor a given class of graphs ${\\cal F}$, let $c({\\cal F}):=\\sup\\{c(F)|F\\in {\\cal\nF}\\}$, and let Forb$({\\cal F})$ denote the class of ${\\cal F}$-free graphs. We\nshow that the complement of the Shrikhande graph is $(4K_1,C_{\\ell}$)-free for\nany $\\ell \\geq 6$ and has the cop number~$3$. This provides a counterexample\nfor the conjecture proposed by Sivaraman (arxiv, 2019) which states that if $G$\nis $C_{\\ell}$-free for all $\\ell\\ge 6$, then $c(G)\\le 2$. This also gives a\nnegative answer to the question posed by Turcotte (Discrete Math. 345:112660\n(2022)) 112660. to check whether $c($Forb$(pK_1))=p-2$. Turcotte also posed the\nquestion to check whether $c($Forb$(pK_1+K_2))\\leq p+1$, for $p\\geq 3$. We\nprove that this result indeed holds. We also generalize this result for\nForb$(pK_1+qK_2)$. Motivated by the results of Baird et al. (Contrib. Discrete\nMath. 9:70--84 (2014)) and Turcotte and Yvon (Discrete Appl. Math. 301:74--98\n(2021)), we define the upper threshold degree and lower threshold degree for a\nparticular class of graphs and show some computational advantage to find the\ncop number using these.",
    "pdf_url": "http://arxiv.org/pdf/2505.15416v1",
    "published": "2025-05-21T12:00:32+00:00",
    "categories": [
      "cs.DM",
      "math.CO",
      "05C57"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15415v1",
    "title": "Conformal extremal metrics and constant scalar curvature",
    "authors": [
      "Xiaokui Yang",
      "Kaijie Zhang"
    ],
    "abstract": "Let $M$ be a compact complex manifold of dimension $n\\geq 2$. We prove that\nfor any Hermitian metric $\\omega$ on $M$, there exists a unique smooth function\n$f$ (up to additive constants) such that the conformal metric $\\omega_g =e^f\n\\omega$ solves the fourth-order nonlinear PDE\n  $$\\square_g^*(s_g|s_g|^{n-2})=0,$$\n  where $s_g$ is the Chern scalar curvature of $\\omega_g$, and $\\square_g^*$\ndenotes the formal adjoint of the complex Laplacian\n$\\square_g=\\mathrm{tr}_{\\omega_g}\\sqrt{-1}\\partial\\bar\\partial$ with respect to\n$\\omega_g$. This equation arises as the Euler-Lagrange equation of the\n$n$-Calabi functional\n  $$C_{n}(\\omega_g)=\\int |s_g|^n\\frac{\\omega_g^n}{n!}$$ within the conformal\nclass of $\\omega_g$. Moreover, we show that the critical metric $\\omega_g$\nminimizes the $n$-Calabi functional within the conformal class $[\\omega]$. In\nparticular,\n  if $\\omega_g$ is a Gauduchon metric, then $\\omega_g$ has constant Chern\nscalar curvature.",
    "pdf_url": "http://arxiv.org/pdf/2505.15415v1",
    "published": "2025-05-21T11:57:46+00:00",
    "categories": [
      "math.DG",
      "53C55"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15867v1",
    "title": "SCENIR: Visual Semantic Clarity through Unsupervised Scene Graph Retrieval",
    "authors": [
      "Nikolaos Chaidos",
      "Angeliki Dimitriou",
      "Maria Lymperaiou",
      "Giorgos Stamou"
    ],
    "abstract": "Despite the dominance of convolutional and transformer-based architectures in\nimage-to-image retrieval, these models are prone to biases arising from\nlow-level visual features, such as color. Recognizing the lack of semantic\nunderstanding as a key limitation, we propose a novel scene graph-based\nretrieval framework that emphasizes semantic content over superficial image\ncharacteristics. Prior approaches to scene graph retrieval predominantly rely\non supervised Graph Neural Networks (GNNs), which require ground truth graph\npairs driven from image captions. However, the inconsistency of caption-based\nsupervision stemming from variable text encodings undermine retrieval\nreliability. To address these, we present SCENIR, a Graph Autoencoder-based\nunsupervised retrieval framework, which eliminates the dependence on labeled\ntraining data. Our model demonstrates superior performance across metrics and\nruntime efficiency, outperforming existing vision-based, multimodal, and\nsupervised GNN approaches. We further advocate for Graph Edit Distance (GED) as\na deterministic and robust ground truth measure for scene graph similarity,\nreplacing the inconsistent caption-based alternatives for the first time in\nimage-to-image retrieval evaluation. Finally, we validate the generalizability\nof our method by applying it to unannotated datasets via automated scene graph\ngeneration, while substantially contributing in advancing state-of-the-art in\ncounterfactual image retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2505.15867v1",
    "published": "2025-05-21T11:56:09+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15414v1",
    "title": "Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks",
    "authors": [
      "Uranik Berisha",
      "Jens Mehnert",
      "Alexandru Paul Condurache"
    ],
    "abstract": "Vision Transformers have emerged as the state-of-the-art models in various\nComputer Vision tasks, but their high computational and resource demands pose\nsignificant challenges. While Mixture-of-Experts (MoE) can make these models\nmore efficient, they often require costly retraining or even training from\nscratch. Recent developments aim to reduce these computational costs by\nleveraging pretrained networks. These have been shown to produce sparse\nactivation patterns in the Multi-Layer Perceptrons (MLPs) of the encoder\nblocks, allowing for conditional activation of only relevant subnetworks for\neach sample. Building on this idea, we propose a new method to construct MoE\nvariants from pretrained models. Our approach extracts expert subnetworks from\nthe model's MLP layers post-training in two phases. First, we cluster output\nactivations to identify distinct activation patterns. In the second phase, we\nuse these clusters to extract the corresponding subnetworks responsible for\nproducing them. On ImageNet-1k recognition tasks, we demonstrate that these\nextracted experts can perform surprisingly well out of the box and require only\nminimal fine-tuning to regain 98% of the original performance, all while\nreducing MACs and model size, by up to 36% and 32% respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.15414v1",
    "published": "2025-05-21T11:55:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15413v1",
    "title": "Depth-Efficient Quantum Circuit Synthesis for Deterministic Dicke State Preparation",
    "authors": [
      "Pei Yuan",
      "Shengyu Zhang"
    ],
    "abstract": "The $n$-qubit $k$-weight Dicke states $|D^n_k\\rangle$, defined as the uniform\nsuperposition of all computational basis states with exactly $k$ qubits in\nstate $|1\\rangle$, form a basis of the symmetric subspace and represent an\nimportant class of entangled quantum states with broad applications in quantum\ncomputing. We propose deterministic quantum circuits for Dicke state\npreparation under two commonly seen qubit connectivity constraints: 1.\nAll-to-all qubit connectivity: our circuit has depth $O(\\log(k)\\log(n/k)+k)$,\nwhich improves the previous best bound of $O(k\\log(n/k))$. 2. Grid qubit\nconnectivity ($(n_1\\times n_2)$-grid, $n_1\\le n_2$): (a) For $k\\ge n_2/n_1$, we\ndesign a circuit with depth $O(k\\log(n/k)+n_2)$, surpassing the prior\n$O(\\sqrt{nk})$ bound. (b) For $k< n_2/n_1$, we design an optimal-depth circuit\nwith depth $O(n_2)$. Furthermore, we establish the depth lower bounds of\n$\\Omega(\\log(n))$ for all-to-all qubit connectivity and $\\Omega(n_2)$ for\n$(n_1\\times n_2)$-grid connectivity constraints, demonstrating the\nnear-optimality of our constructions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15413v1",
    "published": "2025-05-21T11:55:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15412v1",
    "title": "Evaluation of Mobile Environment for Vehicular Visible Light Communication Using Multiple LEDs and Event Cameras",
    "authors": [
      "Ryota Soga",
      "Shintaro Shiba",
      "Quan Kong",
      "Norimasa Kobori",
      "Tsukasa Shimizu",
      "Shan Lu",
      "Takaya Yamazato"
    ],
    "abstract": "In the fields of Advanced Driver Assistance Systems (ADAS) and Autonomous\nDriving (AD), sensors that serve as the ``eyes'' for sensing the vehicle's\nsurrounding environment are essential. Traditionally, image sensors and LiDAR\nhave played this role. However, a new type of vision sensor, event cameras, has\nrecently attracted attention. Event cameras respond to changes in the\nsurrounding environment (e.g., motion), exhibit strong robustness against\nmotion blur, and perform well in high dynamic range environments, which are\ndesirable in robotics applications. Furthermore, the asynchronous and\nlow-latency principles of data acquisition make event cameras suitable for\noptical communication. By adding communication functionality to event cameras,\nit becomes possible to utilize I2V communication to immediately share\ninformation about forward collisions, sudden braking, and road conditions,\nthereby contributing to hazard avoidance. Additionally, receiving information\nsuch as signal timing and traffic volume enables speed adjustment and optimal\nroute selection, facilitating more efficient driving. In this study, we\nconstruct a vehicle visible light communication system where event cameras are\nreceivers, and multiple LEDs are transmitters. In driving scenes, the system\ntracks the transmitter positions and separates densely packed LED light sources\nusing pilot sequences based on Walsh-Hadamard codes. As a result, outdoor\nvehicle experiments demonstrate error-free communication under conditions where\nthe transmitter-receiver distance was within 40 meters and the vehicle's\ndriving speed was 30 km/h (8.3 m/s).",
    "pdf_url": "http://arxiv.org/pdf/2505.15412v1",
    "published": "2025-05-21T11:54:56+00:00",
    "categories": [
      "cs.RO",
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15411v1",
    "title": "Novel constraints on $Œõ\\barŒõ$ and $p\\barŒõ$ interactions using correlation data",
    "authors": [
      "Valentina Mantovani Sarti"
    ],
    "abstract": "The interaction between baryons and antibaryons remains a fundamental topic\nin hadronic physics, particularly due to its potential to reveal exotic bound\nstates such as baryonia. While the proton-antiproton system has been\nextensively studied, mainly via scattering experiments, interactions involving\nantihyperons, such as proton-antilambda and lambda-antilambda, are still poorly\nconstrained due to limited experimental data. High-precision measurements of\nthese systems, especially at low relative momentum, have recently become\navailable through femtoscopic analyses in proton-proton collisions at the LHC.\n  In this work, we extract for the first time the scattering parameters for the\nlambda-antilambda and proton-antilambda systems using correlation data measured\nby the ALICE experiment. Our aim is to investigate potential differences\nbetween the elastic and annihilation components of the interaction potential.\nWe employ a novel analysis framework, iCATS (imaginary CATS), which solves the\nSchr\\\"odinger equation with complex optical potentials to model the strong\nfinal-state interactions in systems dominated by inelastic processes.\n  Our results indicate distinct annihilation characteristics between the two\nsystems, challenging the assumption of universal baryon-antibaryon dynamics.\nThe extracted scattering amplitudes are compared with available production\ncross sections and invariant mass spectra. The consistency between femtoscopic\nconstraints and other observables supports the use of this approach for future\nexplorations of the baryon-antibaryon sector.",
    "pdf_url": "http://arxiv.org/pdf/2505.15411v1",
    "published": "2025-05-21T11:53:25+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15410v1",
    "title": "ClickSight: Interpreting Student Clickstreams to Reveal Insights on Learning Strategies via LLMs",
    "authors": [
      "Bahar Radmehr",
      "Ekaterina Shved",
      "Fatma Bet√ºl G√ºre≈ü",
      "Adish Singla",
      "Tanja K√§ser"
    ],
    "abstract": "Clickstream data from digital learning environments offer valuable insights\ninto students' learning behaviors, but are challenging to interpret due to\ntheir high dimensionality and granularity. Prior approaches have relied mainly\non handcrafted features, expert labeling, clustering, or supervised models,\ntherefore often lacking generalizability and scalability. In this work, we\nintroduce ClickSight, an in-context Large Language Model (LLM)-based pipeline\nthat interprets student clickstreams to reveal their learning strategies.\nClickSight takes raw clickstreams and a list of learning strategies as input\nand generates textual interpretations of students' behaviors during\ninteraction. We evaluate four different prompting strategies and investigate\nthe impact of self-refinement on interpretation quality. Our evaluation spans\ntwo open-ended learning environments and uses a rubric-based domain-expert\nevaluation. Results show that while LLMs can reasonably interpret learning\nstrategies from clickstreams, interpretation quality varies by prompting\nstrategy, and self-refinement offers limited improvement. ClickSight\ndemonstrates the potential of LLMs to generate theory-driven insights from\neducational interaction data.",
    "pdf_url": "http://arxiv.org/pdf/2505.15410v1",
    "published": "2025-05-21T11:52:57+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15866v1",
    "title": "Multi-omic Causal Discovery using Genotypes and Gene Expression",
    "authors": [
      "Stephen Asiedu",
      "David Watson"
    ],
    "abstract": "Causal discovery in multi-omic datasets is crucial for understanding the\nbigger picture of gene regulatory mechanisms, but remains challenging due to\nhigh dimensionality, differentiation of direct from indirect relationships, and\nhidden confounders. We introduce GENESIS (GEne Network inference from\nExpression SIgnals and SNPs), a constraint-based algorithm that leverages the\nnatural causal precedence of genotypes to infer ancestral relationships in\ntranscriptomic data. Unlike traditional causal discovery methods that start\nwith a fully connected graph, GENESIS initialises an empty ancestrality matrix\nand iteratively populates it with direct, indirect or non-causal relationships\nusing a series of provably sound marginal and conditional independence tests.\nBy integrating genotypes as fixed causal anchors, GENESIS provides a principled\n``head start'' to classical causal discovery algorithms, restricting the search\nspace to biologically plausible edges. We test GENESIS on synthetic and\nreal-world genomic datasets. This framework offers a powerful avenue for\nuncovering causal pathways in complex traits, with promising applications to\nfunctional genomics, drug discovery, and precision medicine.",
    "pdf_url": "http://arxiv.org/pdf/2505.15866v1",
    "published": "2025-05-21T11:52:23+00:00",
    "categories": [
      "q-bio.GN",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.15409v1",
    "title": "Object-centric Processes with Structured Data and Exact Synchronization (Extended Version)",
    "authors": [
      "Alessandro Gianola",
      "Marco Montali",
      "Sarah Winkler"
    ],
    "abstract": "Real-world processes often involve interdependent objects that also carry\ndata values, such as integers, reals, or strings. However, existing process\nformalisms fall short to combine key modeling features, such as tracking object\nidentities, supporting complex datatypes, handling dependencies among them, and\nobject-aware synchronization. Object-centric Petri nets with identifiers\n(OPIDs) partially address these needs but treat objects as unstructured\nidentifiers (e.g., order and item IDs), overlooking the rich semantics of\ncomplex data values (e.g., item prices or other attributes). To overcome these\nlimitations, we introduce data-aware OPIDs (DOPIDs), a framework that strictly\nextends OPIDs by incorporating structured data manipulation capabilities, and\nfull synchronization mechanisms. In spite of the expressiveness of the model,\nwe show that it can be made operational: Specifically, we define a novel\nconformance checking approach leveraging satisfiability modulo theories (SMT)\nto compute data-aware object-centric alignments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15409v1",
    "published": "2025-05-21T11:52:11+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15408v3",
    "title": "Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes",
    "authors": [
      "Patrik Reiske",
      "Marcus N. Boon",
      "Niek Andresen",
      "Sole Traverso",
      "Katharina Hohlbaum",
      "Lars Lewejohann",
      "Christa Th√∂ne-Reineke",
      "Olaf Hellwich",
      "Henning Sprekeler"
    ],
    "abstract": "Machine learning and computer vision methods have a major impact on the study\nof natural animal behavior, as they enable the (semi-)automatic analysis of\nvast amounts of video data. Mice are the standard mammalian model system in\nmost research fields, but the datasets available today to refine such methods\nfocus either on simple or social behaviors. In this work, we present a video\ndataset of individual mice solving complex mechanical puzzles, so-called\nlockboxes. The more than 110 hours of total playtime show their behavior\nrecorded from three different perspectives. As a benchmark for frame-level\naction classification methods, we provide human-annotated labels for all videos\nof two different mice, that equal 13% of our dataset. Our keypoint (pose)\ntracking-based action classification framework illustrates the challenges of\nautomated labeling of fine-grained behaviors, such as the manipulation of\nobjects. We hope that our work will help accelerate the advancement of\nautomated action and behavior classification in the computational neuroscience\ncommunity. Our dataset is publicly available at\nhttps://doi.org/10.14279/depositonce-23850",
    "pdf_url": "http://arxiv.org/pdf/2505.15408v3",
    "published": "2025-05-21T11:51:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15407v1",
    "title": "Efficient Differentiable Approximation of Generalized Low-rank Regularization",
    "authors": [
      "Naiqi Li",
      "Yuqiu Xie",
      "Peiyuan Liu",
      "Tao Dai",
      "Yong Jiang",
      "Shu-Tao Xia"
    ],
    "abstract": "Low-rank regularization (LRR) has been widely applied in various machine\nlearning tasks, but the associated optimization is challenging. Directly\noptimizing the rank function under constraints is NP-hard in general. To\novercome this difficulty, various relaxations of the rank function were\nstudied. However, optimization of these relaxed LRRs typically depends on\nsingular value decomposition, which is a time-consuming and nondifferentiable\noperator that cannot be optimized with gradient-based techniques. To address\nthese challenges, in this paper we propose an efficient differentiable\napproximation of the generalized LRR. The considered LRR form subsumes many\npopular choices like the nuclear norm, the Schatten-$p$ norm, and various\nnonconvex relaxations. Our method enables LRR terms to be appended to loss\nfunctions in a plug-and-play fashion, and the GPU-friendly operations enable\nefficient and convenient implementation. Furthermore, convergence analysis is\npresented, which rigorously shows that both the bias and the variance of our\nrank estimator rapidly reduce with increased sample size and iteration steps.\nIn the experimental study, the proposed method is applied to various tasks,\nwhich demonstrates its versatility and efficiency. Code is available at\nhttps://github.com/naiqili/EDLRR.",
    "pdf_url": "http://arxiv.org/pdf/2505.15407v1",
    "published": "2025-05-21T11:49:17+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15406v1",
    "title": "Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models",
    "authors": [
      "Zirui Song",
      "Qian Jiang",
      "Mingxuan Cui",
      "Mingzhe Li",
      "Lang Gao",
      "Zeyu Zhang",
      "Zixiang Xu",
      "Yanbo Wang",
      "Chenxi Wang",
      "Guangxian Ouyang",
      "Zhenhao Chen",
      "Xiuying Chen"
    ],
    "abstract": "The rise of Large Audio Language Models (LAMs) brings both potential and\nrisks, as their audio outputs may contain harmful or unethical content.\nHowever, current research lacks a systematic, quantitative evaluation of LAM\nsafety especially against jailbreak attacks, which are challenging due to the\ntemporal and semantic nature of speech. To bridge this gap, we introduce\nAJailBench, the first benchmark specifically designed to evaluate jailbreak\nvulnerabilities in LAMs. We begin by constructing AJailBench-Base, a dataset of\n1,495 adversarial audio prompts spanning 10 policy-violating categories,\nconverted from textual jailbreak attacks using realistic text to speech\nsynthesis. Using this dataset, we evaluate several state-of-the-art LAMs and\nreveal that none exhibit consistent robustness across attacks. To further\nstrengthen jailbreak testing and simulate more realistic attack conditions, we\npropose a method to generate dynamic adversarial variants. Our Audio\nPerturbation Toolkit (APT) applies targeted distortions across time, frequency,\nand amplitude domains. To preserve the original jailbreak intent, we enforce a\nsemantic consistency constraint and employ Bayesian optimization to efficiently\nsearch for perturbations that are both subtle and highly effective. This\nresults in AJailBench-APT, an extended dataset of optimized adversarial audio\nsamples. Our findings demonstrate that even small, semantically preserved\nperturbations can significantly reduce the safety performance of leading LAMs,\nunderscoring the need for more robust and semantically aware defense\nmechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15406v1",
    "published": "2025-05-21T11:47:47+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15405v1",
    "title": "HOPSE: Scalable Higher-Order Positional and Structural Encoder for Combinatorial Representations",
    "authors": [
      "Martin Carrasco",
      "Guillermo Bernardez",
      "Marco Montagna",
      "Nina Miolane",
      "Lev Telyatnikov"
    ],
    "abstract": "While Graph Neural Networks (GNNs) have proven highly effective at modeling\nrelational data, pairwise connections cannot fully capture multi-way\nrelationships naturally present in complex real-world systems. In response to\nthis, Topological Deep Learning (TDL) leverages more general combinatorial\nrepresentations -- such as simplicial or cellular complexes -- to accommodate\nhigher-order interactions. Existing TDL methods often extend GNNs through\nHigher-Order Message Passing (HOMP), but face critical \\emph{scalability\nchallenges} due to \\textit{(i)} a combinatorial explosion of message-passing\nroutes, and \\textit{(ii)} significant complexity overhead from the propagation\nmechanism. To overcome these limitations, we propose HOPSE (Higher-Order\nPositional and Structural Encoder) -- a \\emph{message passing-free} framework\nthat uses Hasse graph decompositions to derive efficient and expressive\nencodings over \\emph{arbitrary higher-order domains}. Notably, HOPSE scales\nlinearly with dataset size while preserving expressive power and permutation\nequivariance. Experiments on molecular, expressivity and topological benchmarks\nshow that HOPSE matches or surpasses state-of-the-art performance while\nachieving up to 7 $times$ speedups over HOMP-based models, opening a new path\nfor scalable TDL.",
    "pdf_url": "http://arxiv.org/pdf/2505.15405v1",
    "published": "2025-05-21T11:47:40+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15404v1",
    "title": "How Should We Enhance the Safety of Large Reasoning Models: An Empirical Study",
    "authors": [
      "Zhexin Zhang",
      "Xian Qi Loye",
      "Victor Shea-Jay Huang",
      "Junxiao Yang",
      "Qi Zhu",
      "Shiyao Cui",
      "Fei Mi",
      "Lifeng Shang",
      "Yingkang Wang",
      "Hongning Wang",
      "Minlie Huang"
    ],
    "abstract": "Large Reasoning Models (LRMs) have achieved remarkable success on\nreasoning-intensive tasks such as mathematics and programming. However, their\nenhanced reasoning capabilities do not necessarily translate to improved safety\nperformance-and in some cases, may even degrade it. This raises an important\nresearch question: how can we enhance the safety of LRMs? In this paper, we\npresent a comprehensive empirical study on how to enhance the safety of LRMs\nthrough Supervised Fine-Tuning (SFT). Our investigation begins with an\nunexpected observation: directly distilling safe responses from DeepSeek-R1\nfails to significantly enhance safety. We analyze this phenomenon and identify\nthree key failure patterns that contribute to it. We then demonstrate that\nexplicitly addressing these issues during the data distillation process can\nlead to substantial safety improvements. Next, we explore whether a long and\ncomplex reasoning process is necessary for achieving safety. Interestingly, we\nfind that simply using short or template-based reasoning process can attain\ncomparable safety performance-and are significantly easier for models to learn\nthan more intricate reasoning chains. These findings prompt a deeper reflection\non the role of reasoning in ensuring safety. Finally, we find that mixing math\nreasoning data during safety fine-tuning is helpful to balance safety and\nover-refusal. Overall, we hope our empirical study could provide a more\nholistic picture on enhancing the safety of LRMs. The code and data used in our\nexperiments are released in https://github.com/thu-coai/LRM-Safety-Study.",
    "pdf_url": "http://arxiv.org/pdf/2505.15404v1",
    "published": "2025-05-21T11:45:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15403v1",
    "title": "RIS Beam Calibration for ISAC Systems: Modeling and Performance Analysis",
    "authors": [
      "Mengting Li",
      "Hui Chen",
      "Sigurd Sandor Petersen",
      "Huiping Huang",
      "Alireza Pourafzal",
      "Yu Ge",
      "Ming Shen",
      "Henk Wymeersch"
    ],
    "abstract": "High-accuracy localization is a key enabler for integrated sensing and\ncommunication (ISAC), playing an essential role in various applications such as\nautonomous driving. Antenna arrays and reconfigurable intelligent surface (RIS)\nare incorporated into these systems to achieve high angular resolution,\nassisting in the localization process. However, array and RIS beam patterns in\npractice often deviate from the idealized models used for algorithm design,\nleading to significant degradation in positioning accuracy. This mismatch\nhighlights the need for beam calibration to bridge the gap between theoretical\nmodels and real-world hardware behavior. In this paper, we present and analyze\nthree beam models considering several key non-idealities such as mutual\ncoupling, non-ideal codebook, and measurement uncertainties. Based on the\nmodels, we then develop calibration algorithms to estimate the model parameters\nthat can be used for future localization tasks. This work evaluates the\neffectiveness of the beam models and the calibration algorithms using both\ntheoretical bounds and real-world beam pattern data from an RIS prototype. The\nsimulation results show that the model incorporating combined impacts can\naccurately reconstruct measured beam patterns. This highlights the necessity of\nrealistic beam modeling and calibration to achieve high-accuracy localization.",
    "pdf_url": "http://arxiv.org/pdf/2505.15403v1",
    "published": "2025-05-21T11:45:22+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15402v1",
    "title": "Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via In-Context Learning",
    "authors": [
      "Junchuan Zhao",
      "Xintong Wang",
      "Ye Wang"
    ],
    "abstract": "Recent advances in discrete audio codecs have significantly improved speech\nrepresentation modeling, while codec language models have enabled in-context\nlearning for zero-shot speech synthesis. Inspired by this, we propose a voice\nconversion (VC) model within the VALLE-X framework, leveraging its strong\nin-context learning capabilities for speaker adaptation. To enhance prosody\ncontrol, we introduce a prosody-aware audio codec encoder (PACE) module, which\nisolates and refines prosody from other sources, improving expressiveness and\ncontrol. By integrating PACE into our VC model, we achieve greater flexibility\nin prosody manipulation while preserving speaker timbre. Experimental\nevaluation results demonstrate that our approach outperforms baseline VC\nsystems in prosody preservation, timbre consistency, and overall naturalness,\nsurpassing baseline VC systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15402v1",
    "published": "2025-05-21T11:42:49+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15401v1",
    "title": "Visual Question Answering on Multiple Remote Sensing Image Modalities",
    "authors": [
      "Hichem Boussaid",
      "Lucrezia Tosato",
      "Flora Weissgerber",
      "Camille Kurtz",
      "Laurent Wendling",
      "Sylvain Lobry"
    ],
    "abstract": "The extraction of visual features is an essential step in Visual Question\nAnswering (VQA). Building a good visual representation of the analyzed scene is\nindeed one of the essential keys for the system to be able to correctly\nunderstand the latter in order to answer complex questions. In many fields such\nas remote sensing, the visual feature extraction step could benefit\nsignificantly from leveraging different image modalities carrying complementary\nspectral, spatial and contextual information. In this work, we propose to add\nmultiple image modalities to VQA in the particular context of remote sensing,\nleading to a novel task for the computer vision community. To this end, we\nintroduce a new VQA dataset, named TAMMI (Text and Multi-Modal Imagery) with\ndiverse questions on scenes described by three different modalities (very high\nresolution RGB, multi-spectral imaging data and synthetic aperture radar).\nThanks to an automated pipeline, this dataset can be easily extended according\nto experimental needs. We also propose the MM-RSVQA (Multi-modal\nMulti-resolution Remote Sensing Visual Question Answering) model, based on\nVisualBERT, a vision-language transformer, to effectively combine the multiple\nimage modalities and text through a trainable fusion process. A preliminary\nexperimental study shows promising results of our methodology on this\nchallenging dataset, with an accuracy of 65.56% on the targeted VQA task. This\npioneering work paves the way for the community to a new multi-modal\nmulti-resolution VQA task that can be applied in other imaging domains (such as\nmedical imaging) where multi-modality can enrich the visual representation of a\nscene. The dataset and code are available at https://tammi.sylvainlobry.com/.",
    "pdf_url": "http://arxiv.org/pdf/2505.15401v1",
    "published": "2025-05-21T11:42:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15400v2",
    "title": "When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning",
    "authors": [
      "Xiaoyun Zhang",
      "Jingqing Ruan",
      "Xing Ma",
      "Yawen Zhu",
      "Haodong Zhao",
      "Hao Li",
      "Jiansong Chen",
      "Ke Zeng",
      "Xunliang Cai"
    ],
    "abstract": "Large reasoning models (LRMs) achieve remarkable performance via long\nreasoning chains, but often incur excessive computational overhead due to\nredundant reasoning, especially on simple tasks. In this work, we\nsystematically quantify the upper bounds of LRMs under both Long-Thinking and\nNo-Thinking modes, and uncover the phenomenon of \"Internal Self-Recovery\nMechanism\" where models implicitly supplement reasoning during answer\ngeneration. Building on this insight, we propose Adaptive Self-Recovery\nReasoning (ASRR), a framework that suppresses unnecessary reasoning and enables\nimplicit recovery. By introducing accuracy-aware length reward regulation, ASRR\nadaptively allocates reasoning effort according to problem difficulty,\nachieving high efficiency with negligible performance sacrifice. Experiments\nacross multiple benchmarks and models show that, compared with GRPO, ASRR\nreduces reasoning budget by up to 32.5% (1.5B) and 25.7% (7B) with minimal\naccuracy loss (1.2% and 0.6% pass@1), and significantly boosts harmless rates\non safety benchmarks (up to +21.7%). Our results highlight the potential of\nASRR for enabling efficient, adaptive, and safer reasoning in LRMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15400v2",
    "published": "2025-05-21T11:41:39+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15399v1",
    "title": "A Falsifiable Alternative to General Relativity",
    "authors": [
      "Daniel Coumbe",
      "Aria Rahmaty"
    ],
    "abstract": "Asymptotically Weyl-invariant gravity (AWIG) is further developed within the\nPalatini formalism as a power-counting renormalizable alternative to general\nrelativity (GR). An expression for the dimensionless exponent n(R) is derived\nbased on dynamical dimensional reduction. We show that this version of AWIG\nnaturally resolves several theoretical issues normally associated with the\nPalatini formalism. A falsifiable prediction regarding the frequency of\ngravitational waves from binary black hole mergers is made. A preliminary\nanalysis of gravitational wave GW150914 yields a maximum tension of 0.9{\\sigma}\nwith GR and marginally favours AWIG. A similar analysis of gravitational wave\nGW151226 yields a maximum tension of 2.7{\\sigma} with GR and favours AWIG more\nsignificantly.",
    "pdf_url": "http://arxiv.org/pdf/2505.15399v1",
    "published": "2025-05-21T11:38:56+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15398v2",
    "title": "Expanding Zero-Shot Object Counting with Rich Prompts",
    "authors": [
      "Huilin Zhu",
      "Senyao Li",
      "Jingling Yuan",
      "Zhengwei Yang",
      "Yu Guo",
      "Wenxuan Liu",
      "Xian Zhong",
      "Shengfeng He"
    ],
    "abstract": "Expanding pre-trained zero-shot counting models to handle unseen categories\nrequires more than simply adding new prompts, as this approach does not achieve\nthe necessary alignment between text and visual features for accurate counting.\nWe introduce RichCount, the first framework to address these limitations,\nemploying a two-stage training strategy that enhances text encoding and\nstrengthens the model's association with objects in images. RichCount improves\nzero-shot counting for unseen categories through two key objectives: (1)\nenriching text features with a feed-forward network and adapter trained on\ntext-image similarity, thereby creating robust, aligned representations; and\n(2) applying this refined encoder to counting tasks, enabling effective\ngeneralization across diverse prompts and complex images. In this manner,\nRichCount goes beyond simple prompt expansion to establish meaningful feature\nalignment that supports accurate counting across novel categories. Extensive\nexperiments on three benchmark datasets demonstrate the effectiveness of\nRichCount, achieving state-of-the-art performance in zero-shot counting and\nsignificantly enhancing generalization to unseen categories in open-world\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.15398v2",
    "published": "2025-05-21T11:38:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15397v1",
    "title": "Observation of Body-Centered Cubic Iron above 200 Gigapascals",
    "authors": [
      "Zuzana Konopkova",
      "Eric Edmund",
      "Orianna B Ball",
      "Agnes Dewaele",
      "Helene Ginestet",
      "Rachel J Husband",
      "Nicolas Jaisle",
      "Cornelius Strohm",
      "Madden S Anae",
      "Daniele Antonangeli",
      "Karen Appel",
      "Marzena Baron",
      "Silvia Boccato",
      "Khachiwan Buakor",
      "Julien Chantel",
      "Hyunchae Cynn",
      "Anand P Dwivedi",
      "Lars Ehm",
      "Konstantin Glazyrin",
      "Heinz Graafsma",
      "Egor Koemets",
      "Torsten Laurus",
      "Hauke Marquardt",
      "Bernhard Massani",
      "James D McHardy",
      "Malcolm I McMahon",
      "Vitali Prakapenka",
      "Jolanta Sztuk-Dambietz",
      "Minxue Tang",
      "Tianqi Xie",
      "Zena Younes",
      "Ulf Zastrau",
      "Alexander F Goncharov",
      "Clemens Prescher",
      "Ryan S McWilliams",
      "Guillaume Morard",
      "Sebastien Merkel"
    ],
    "abstract": "The crystallographic structure of iron under extreme conditions is a key\nbenchmark for cutting-edge experimental and numerical methods. Moreover, it\nplays a crucial role in understanding planetary cores, as it significantly\ninfluences the interpretation of observational data and, consequently, insights\ninto their internal structure and dynamics. However, even the structure of pure\nsolid iron under the Earth's core conditions remains uncertain, with the\ncommonly expected hexagonal close-packed structure energetically competitive\nwith various cubic lattices. In this study, iron was compressed in a diamond\nanvil cell to above 200 GPa, and dynamically probed near the melting point\nusing MHz frequency X-ray pulses from the European X-ray Free Electron Laser.\nThe emergence of an additional diffraction line at high temperatures suggests\nthe formation of an entropically stabilized bcc structure. Rapid heating and\ncooling cycles captured intermediate phases, offering new insights into iron's\nphase transformation paths. The appearance of the bcc phase near melting at\nextreme pressures challenges current understanding of the iron phase diagram\nunder Earth's core conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15397v1",
    "published": "2025-05-21T11:37:39+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15396v1",
    "title": "Density modulations in active colloidal systems through orthogonal propulsion control and sensory delays",
    "authors": [
      "Ueli T√∂pfer",
      "Maximilian R. Bailey",
      "Sanjay Schreiber",
      "Federico Paratore",
      "Lucio Isa"
    ],
    "abstract": "Recent advancements in active colloidal systems aim to mimic key\ncharacteristics of biological microswimmers, particularly their adaptive\nmotility in response to environmental changes. While many approaches rely on\nexternally imposing a propulsive force, achieving true autonomous and\nself-regulating adaptation to the environment remains limited. In this study,\nwe develop and analyze Janus microswimmers driven by electrohydrodynamic flows\nthat autonomously adjust their propulsion dynamics in response to varying\nillumination conditions. Our Janus particles are silica colloids partially\ncoated with titania, which self-propel via induced-charge electrophoresis\n(ICEP) under uniform AC electric fields. Since titania is photoconductive, it\nincreases its conductivity under UV illumination, which thereby regulates the\npropulsion velocity independently of and orthogonally to the applied electric\nfield. Crucially, the velocity adaptation requires a finite time. This sensory\ndelay, which we systematically characterize, leads to enhanced microswimmer\nlocalization in response to spatiotemporal light modulations compared to the\ntypical case of instantaneous response considered for synthetic microswimmers.\nBy harnessing these dynamics, akin to those of biological microswimmers, we\nexert precise control over both local and global particle behavior, presenting\nnovel opportunities for adaptive active matter systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15396v1",
    "published": "2025-05-21T11:37:03+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.15395v1",
    "title": "Piecewise-linear Ricci curvature flows on weighted graphs",
    "authors": [
      "Jicheng Ma",
      "Yunyan Yang"
    ],
    "abstract": "Community detection is an important problem in graph neural networks.\nRecently, algorithms based on Ricci curvature flows have gained significant\nattention. It was suggested by Ollivier (2009), and applied to community\ndetection by Ni et al (2019) and Lai et al (2022). Its mathematical theory was\ndue to Bai et al (2024) and Li-M\\\"unch (2025). In particular, solutions to some\nof these flows have existence, uniqueness and convergence. However, a unified\ntheoretical framework has not yet been established in this field.\n  In the current study, we propose several unified piecewise-linear Ricci\ncurvature flows with respect to arbitrarily selected Ricci curvatures. First,\nwe prove that the flows have global existence and uniqueness. Second, we show\nthat if the Ricci curvature being used is homogeneous, then after undergoing\nmultiple surgeries, the evolving graph has a constant Ricci curvature on each\nconnected component. Note that five commonly used Ricci curvatures, which were\nrespectively defined by Ollivier, Lin-Lu-Yau, Forman, Menger and Haantjes, are\nall homogeneous, and that the proof of all these results is independent of the\nchoice of the specific Ricci curvature. Third, as an application, we apply the\ndiscrete piecewise-linear Ricci curvature flow with surgeries to the problem of\ncommunity detection. On three real-world datasets, the flow consistently\noutperforms baseline models and existing methods. Complementary experiments on\nsynthetic graphs further confirm its scalability and robustness. Compared with\nexisting algorithms, our algorithm has two advantages: it does not require\ncurvature calculations at each iteration, and the iterative process converges.",
    "pdf_url": "http://arxiv.org/pdf/2505.15395v1",
    "published": "2025-05-21T11:36:27+00:00",
    "categories": [
      "math.AP",
      "math.DG"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17109v1",
    "title": "Mitigating Cyber Risk in the Age of Open-Weight LLMs: Policy Gaps and Technical Realities",
    "authors": [
      "Alfonso de Gregorio"
    ],
    "abstract": "Open-weight general-purpose AI (GPAI) models offer significant benefits but\nalso introduce substantial cybersecurity risks, as demonstrated by the\noffensive capabilities of models like DeepSeek-R1 in evaluations such as\nMITRE's OCCULT. These publicly available models empower a wider range of actors\nto automate and scale cyberattacks, challenging traditional defence paradigms\nand regulatory approaches. This paper analyzes the specific threats --\nincluding accelerated malware development and enhanced social engineering --\nmagnified by open-weight AI release. We critically assess current regulations,\nnotably the EU AI Act and the GPAI Code of Practice, identifying significant\ngaps stemming from the loss of control inherent in open distribution, which\nrenders many standard security mitigations ineffective. We propose a path\nforward focusing on evaluating and controlling specific high-risk capabilities\nrather than entire models, advocating for pragmatic policy interpretations for\nopen-weight systems, promoting defensive AI innovation, and fostering\ninternational collaboration on standards and cyber threat intelligence (CTI)\nsharing to ensure security without unduly stifling open technological progress.",
    "pdf_url": "http://arxiv.org/pdf/2505.17109v1",
    "published": "2025-05-21T11:35:52+00:00",
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15394v1",
    "title": "Reranking with Compressed Document Representation",
    "authors": [
      "Herv√© D√©jean",
      "St√©phane Clinchant"
    ],
    "abstract": "Reranking, the process of refining the output of a first-stage retriever, is\noften considered computationally expensive, especially with Large Language\nModels. Borrowing from recent advances in document compression for RAG, we\nreduce the input size by compressing documents into fixed-size embedding\nrepresentations. We then teach a reranker to use compressed inputs by\ndistillation. Although based on a billion-size model, our trained reranker\nusing this compressed input can challenge smaller rerankers in terms of both\neffectiveness and efficiency, especially for long documents. Given that text\ncompressors are still in their early development stages, we view this approach\nas promising.",
    "pdf_url": "http://arxiv.org/pdf/2505.15394v1",
    "published": "2025-05-21T11:35:11+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15393v1",
    "title": "FAV-NSS: An HIL Framework for Accelerating Validation of Automotive Network Security Strategies",
    "authors": [
      "Changhong Li",
      "Shashwat Khandelwal",
      "Shreejith Shanker"
    ],
    "abstract": "Complex electronic control unit (ECU) architectures, software models and\nin-vehicle networks are consistently improving safety and comfort functions in\nmodern vehicles. However, the extended functionality and increased connectivity\nintroduce new security risks and vulnerabilities that can be exploited on\nlegacy automotive networks such as the controller area network (CAN). With the\nrising complexity of vehicular systems and attack vectors, the need for a\nflexible hardware-in-the-loop (HIL) test fixture that can inject attacks and\nvalidate the performance of countermeasures in near-real-world conditions in\nreal time is vital. This paper presents an FPGA-based HIL framework tailored\ntowards validating network security approaches (IDS, IPS) and smart integration\nstrategies of such capabilities for an automotive CAN bus. FAV-NSS replicates\nan actual vehicular system environment with functional ECUs and network\ninfrastructure on an FPGA, allowing functional validation of IDS/IPS\nalgorithms, accelerator designs and integration schemes (software task on ECU,\ndedicated accelerator). To show the efficacy of FAV-NSS, we evaluate an IDS\naccelerator integration problem, both as a traditional coupled accelerator (to\nthe ECU), and secondly close to the CAN controller (mimicking an extended CAN\ncontroller). We show that the latter strategy can be fully validated by our\nframework, which would otherwise require integration of specialised CAN modules\ninto otherwise standard HIL fixtures with ability to instrument internal\nsignals for characterising timing performance. The tests demonstrate a\npromising latency reduction of 6.3x when compared to the traditional coupled\naccelerator. Our case study demonstrates the potential of FAV-NSS for\naccelerating the optimisation, integration and verification of smart ECUs and\ncommunication controllers in current and future vehicular systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15393v1",
    "published": "2025-05-21T11:34:48+00:00",
    "categories": [
      "cs.AR",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15392v1",
    "title": "An Empirical Study of the Anchoring Effect in LLMs: Existence, Mechanism, and Potential Mitigations",
    "authors": [
      "Yiming Huang",
      "Biquan Bie",
      "Zuqiu Na",
      "Weilin Ruan",
      "Songxin Lei",
      "Yutao Yue",
      "Xinlei He"
    ],
    "abstract": "The rise of Large Language Models (LLMs) like ChatGPT has advanced natural\nlanguage processing, yet concerns about cognitive biases are growing. In this\npaper, we investigate the anchoring effect, a cognitive bias where the mind\nrelies heavily on the first information as anchors to make affected judgments.\nWe explore whether LLMs are affected by anchoring, the underlying mechanisms,\nand potential mitigation strategies. To facilitate studies at scale on the\nanchoring effect, we introduce a new dataset, SynAnchors. Combining refined\nevaluation metrics, we benchmark current widely used LLMs. Our findings show\nthat LLMs' anchoring bias exists commonly with shallow-layer acting and is not\neliminated by conventional strategies, while reasoning can offer some\nmitigation. This recontextualization via cognitive psychology urges that LLM\nevaluations focus not on standard benchmarks or over-optimized robustness\ntests, but on cognitive-bias-aware trustworthy evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15392v1",
    "published": "2025-05-21T11:33:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15391v1",
    "title": "InTreeger: An End-to-End Framework for Integer-Only Decision Tree Inference",
    "authors": [
      "Duncan Bart",
      "Bruno Endres Forlin",
      "Ana-Lucia Varbanescu",
      "Marco Ottavi",
      "Kuan-Hsun Chen"
    ],
    "abstract": "Integer quantization has emerged as a critical technique to facilitate\ndeployment on resource-constrained devices. Although they do reduce the\ncomplexity of the learning models, their inference performance is often prone\nto quantization-induced errors. To this end, we introduce InTreeger: an\nend-to-end framework that takes a training dataset as input, and outputs an\narchitecture-agnostic integer-only C implementation of tree-based machine\nlearning model, without loss of precision. This framework enables anyone, even\nthose without prior experience in machine learning, to generate a highly\noptimized integer-only classification model that can run on any hardware simply\nby providing an input dataset and target variable. We evaluated our generated\nimplementations across three different architectures (ARM, x86, and RISC-V),\nresulting in significant improvements in inference latency. In addition, we\nshow the energy efficiency compared to typical decision tree implementations\nthat rely on floating-point arithmetic. The results underscore the advantages\nof integer-only inference, making it particularly suitable for energy- and\narea-constrained devices such as embedded systems and edge computing platforms,\nwhile also enabling the execution of decision trees on existing ultra-low power\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15391v1",
    "published": "2025-05-21T11:28:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15390v1",
    "title": "Enhancing the creation of elements in laser-assisted heavy-ion fusion reactions",
    "authors": [
      "Nicholas Thomson",
      "Laura Moschini",
      "Alexis Diaz-Torres"
    ],
    "abstract": "Low-energy fusion of heavy ions is a fascinating coupling-assisted quantum\ntunnelling problem, whose understanding is crucial for advancing the synthesis\nof new elements and isotopes. Quantum dynamical coupled-channels calculations\nof laser-assisted $^{16}$O + $^{238}$U fusion are presented for both a central\ncollision and the total fusion cross-sections, suggesting that laser-nucleus\ninteraction can enhance the average $^{16}$O + $^{238}$U fusion probability by\n$6-60 \\%$ at subbarrier energies using quasi-static laser fields of intensity\n$10^{27}-10^{29}$ Wcm$^{-2}$ and photon's energy of $1$ eV. Femtosecond laser\npulses are shown to reduce this enhancement by many orders of magnitude.",
    "pdf_url": "http://arxiv.org/pdf/2505.15390v1",
    "published": "2025-05-21T11:28:24+00:00",
    "categories": [
      "nucl-th",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15389v1",
    "title": "Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study",
    "authors": [
      "DongGeon Lee",
      "Joonwon Jang",
      "Jihae Jeong",
      "Hwanjo Yu"
    ],
    "abstract": "Rapid deployment of vision-language models (VLMs) magnifies safety risks, yet\nmost evaluations rely on artificial images. This study asks: How safe are\ncurrent VLMs when confronted with meme images that ordinary users share? To\ninvestigate this question, we introduce MemeSafetyBench, a 50,430-instance\nbenchmark pairing real meme images with both harmful and benign instructions.\nUsing a comprehensive safety taxonomy and LLM-based instruction generation, we\nassess multiple VLMs across single and multi-turn interactions. We investigate\nhow real-world memes influence harmful outputs, the mitigating effects of\nconversational context, and the relationship between model scale and safety\nmetrics. Our findings demonstrate that VLMs show greater vulnerability to\nmeme-based harmful prompts than to synthetic or typographic images. Memes\nsignificantly increase harmful responses and decrease refusals compared to\ntext-only inputs. Though multi-turn interactions provide partial mitigation,\nelevated vulnerability persists. These results highlight the need for\necologically valid evaluations and stronger safety mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15389v1",
    "published": "2025-05-21T11:26:40+00:00",
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15388v1",
    "title": "Impact of Wind Generation on Risk-based Security Assessment of Power System",
    "authors": [
      "Umair Shahzad"
    ],
    "abstract": "The electric power system is one of the largest and most intricate\ninfrastructures. Therefore, it is critical to assess and maintain its security.\nA power system security assessment is indispensable for identifying\npost-contingency issues, taking corrective measures, and protecting the system\nfrom blackouts. This paper examined the impact of wind generation on the\nrisk-based security assessment of a power transmission network in the context\nof planning. DIgSILENT PowerFactory software was used to conduct the analysis\nusing a combination of the brute force technique and the nonsequential Monte\nCarlo (MC) simulation method on the IEEE 39-bus transmission test system.\nOptimal power flow (OPF) was used to quantify security, considering (N-1),\n(N-2), and (N-3) line outages and an (N-1) bus outage. Moreover, the average\ncost deviation from the mean optimal system operating cost was proposed as a\nnovel security indicator. The results obtianed accurately depicted the effects\nof changing wind generation levels on system security in terms of risk. The\nmost and least critical line(s) and bus in the system, for different wind\ngeneration levels, were also determined. Moreover, the worst-case\nwind-generation threshold level using two different cost functions for wind was\nidentified.",
    "pdf_url": "http://arxiv.org/pdf/2505.15388v1",
    "published": "2025-05-21T11:24:28+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15387v1",
    "title": "Generalized digroups, di-skew braces, and solutions of the set-theoretic Yang-Baxter equation",
    "authors": [
      "Andrea Albano",
      "Paola Stefanelli"
    ],
    "abstract": "We introduce a novel algebraic structure called di-skew brace by which we\nshow that generalized digroups systematically yield bijective, non-degenerate\nsolutions to the set-theoretic Yang-Baxter equation. We study the structural\nproperties of these solutions with a particular focus on their left derived\nshelves, which belong to the class of conjugation racks. Consistently, we show\nthat these solutions belong to a broader class that includes skew brace\nsolutions. In particular, we prove that each such solution can be decomposed as\na hemi-semidirect product of a skew brace solution endowed with a certain\ncompatible action on the idempotents of the associated di-skew brace structure.\nFinally, we provide concrete instances of these solutions through a suitable\nnotion of averaging operators on groups.",
    "pdf_url": "http://arxiv.org/pdf/2505.15387v1",
    "published": "2025-05-21T11:24:20+00:00",
    "categories": [
      "math.QA",
      "16T25, 81R50, 16Y99, 20N99, 20M99, 17B38"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15386v2",
    "title": "RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection",
    "authors": [
      "Yiming Huang",
      "Junyan Zhang",
      "Zihao Wang",
      "Biquan Bie",
      "Yunzhong Qiu",
      "Yi R. Fung",
      "Xinlei He"
    ],
    "abstract": "Large Language Models (LLMs) have become powerful, but hallucinations remain\na vital obstacle to their trustworthy use. While previous works improved the\ncapability of hallucination detection by measuring uncertainty, they all lack\nthe ability to explain the provenance behind why hallucinations occur, i.e.,\nwhich part of the inputs tends to trigger hallucinations. Recent works on the\nprompt attack indicate that uncertainty exists in semantic propagation, where\nattention mechanisms gradually fuse local token information into high-level\nsemantics across layers. Meanwhile, uncertainty also emerges in language\ngeneration, due to its probability-based selection of high-level semantics for\nsampled generations. Based on that, we propose RePPL to recalibrate uncertainty\nmeasurement by these two aspects, which dispatches explainable uncertainty\nscores to each token and aggregates in Perplexity-style Log-Average form as\ntotal score. Experiments show that our method achieves the best comprehensive\ndetection performance across various QA datasets on advanced models (average\nAUC of 0.833), and our method is capable of producing token-level uncertainty\nscores as explanations for the hallucination. Leveraging these scores, we\npreliminarily find the chaotic pattern of hallucination and showcase its\npromising usage.",
    "pdf_url": "http://arxiv.org/pdf/2505.15386v2",
    "published": "2025-05-21T11:23:05+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15385v1",
    "title": "EVA: Expressive Virtual Avatars from Multi-view Videos",
    "authors": [
      "Hendrik Junkawitsch",
      "Guoxing Sun",
      "Heming Zhu",
      "Christian Theobalt",
      "Marc Habermann"
    ],
    "abstract": "With recent advancements in neural rendering and motion capture algorithms,\nremarkable progress has been made in photorealistic human avatar modeling,\nunlocking immense potential for applications in virtual reality, augmented\nreality, remote communication, and industries such as gaming, film, and\nmedicine. However, existing methods fail to provide complete, faithful, and\nexpressive control over human avatars due to their entangled representation of\nfacial expressions and body movements. In this work, we introduce Expressive\nVirtual Avatars (EVA), an actor-specific, fully controllable, and expressive\nhuman avatar framework that achieves high-fidelity, lifelike renderings in real\ntime while enabling independent control of facial expressions, body movements,\nand hand gestures. Specifically, our approach designs the human avatar as a\ntwo-layer model: an expressive template geometry layer and a 3D Gaussian\nappearance layer. First, we present an expressive template tracking algorithm\nthat leverages coarse-to-fine optimization to accurately recover body motions,\nfacial expressions, and non-rigid deformation parameters from multi-view\nvideos. Next, we propose a novel decoupled 3D Gaussian appearance model\ndesigned to effectively disentangle body and facial appearance. Unlike unified\nGaussian estimation approaches, our method employs two specialized and\nindependent modules to model the body and face separately. Experimental results\ndemonstrate that EVA surpasses state-of-the-art methods in terms of rendering\nquality and expressiveness, validating its effectiveness in creating full-body\navatars. This work represents a significant advancement towards fully drivable\ndigital human models, enabling the creation of lifelike digital avatars that\nfaithfully replicate human geometry and appearance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15385v1",
    "published": "2025-05-21T11:22:52+00:00",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15384v1",
    "title": "A two-stage model for factors influencing citation counts",
    "authors": [
      "Pablo Dorta-Gonz√°lez",
      "Emilio G√≥mez-D√©niz"
    ],
    "abstract": "This work aims to study a count response random variable, the number of\ncitations of a research paper, affected by some explanatory variables through a\nsuitable regression model. Due to the fact that the count variable exhibits\nsubstantial variation since the sample variance is larger than the sample mean,\nthe classical Poisson regression model seems not to be appropriate. We\nconcentrate attention on the negative binomial regression model, which allows\nthe variance of each measurement to be a function of its predicted value.\nNevertheless, the process of citations of papers may be divided into two parts.\nIn the first stage, the paper has no citations, and the second part provides\nthe intensity of the citations. A hurdle model for separating the documents\nwith citations and those without citations is considered. The dataset for the\nempirical application consisted of 43,190 research papers in the field of\nEconomics and Business from 2014-2021, obtained from The Lens database.\nCitation counts and social attention scores for each article were gathered from\nAltmetric database. The main findings indicate that both collaboration and\nfunding have a positive impact on citation counts and reduce the likelihood of\nreceiving zero citations. Higher journal impact factors lead to higher citation\ncounts, while lower peer review ratings lead to fewer citations and a higher\nprobability of zero citations. Mentions in news, blogs, and social media have\nvarying but generally limited effects on citation counts. Open access via\nrepositories (green OA) correlates with higher citation counts and a lower\nprobability of zero citations. In contrast, OA via the publisher's website\nwithout an explicit open license (bronze OA) is associated with higher citation\ncounts but also with a higher probability of zero citations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15384v1",
    "published": "2025-05-21T11:22:03+00:00",
    "categories": [
      "cs.DL",
      "stat.AP",
      "62J12, 62P25"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17108v1",
    "title": "REMS: a unified solution representation, problem modeling and metaheuristic algorithm design for general combinatorial optimization problems",
    "authors": [
      "Aijuan Song",
      "Guohua Wu"
    ],
    "abstract": "Combinatorial optimization problems (COPs) with discrete variables and finite\nsearch space are critical across numerous fields, and solving them in\nmetaheuristic algorithms is popular. However, addressing a specific COP\ntypically requires developing a tailored and handcrafted algorithm. Even minor\nadjustments, such as constraint changes, may necessitate algorithm\nredevelopment. Therefore, establishing a framework for formulating diverse COPs\ninto a unified paradigm and designing reusable metaheuristic algorithms is\nvaluable. A COP can be typically viewed as the process of giving resources to\nperform specific tasks, subjecting to given constraints. Motivated by this, a\nresource-centered modeling and solving framework (REMS) is introduced for the\nfirst time. We first extract and define resources and tasks from a COP.\nSubsequently, given predetermined resources, the solution structure is unified\nas assigning tasks to resources, from which variables, objectives, and\nconstraints can be derived and a problem model is constructed. To solve the\nmodeled COPs, several fundamental operators are designed based on the unified\nsolution structure, including the initial solution, neighborhood structure,\ndestruction and repair, crossover, and ranking. These operators enable the\ndevelopment of various metaheuristic algorithms. Specially, 4\nsingle-point-based algorithms and 1 population-based algorithm are configured\nherein. Experiments on 10 COPs, covering routing, location, loading,\nassignment, scheduling, and graph coloring problems, show that REMS can model\nthese COPs within the unified paradigm and effectively solve them with the\ndesigned metaheuristic algorithms. Furthermore, REMS is more competitive than\nGUROBI and SCIP in tackling large-scale instances and complex COPs, and\noutperforms OR-TOOLS on several challenging COPs.",
    "pdf_url": "http://arxiv.org/pdf/2505.17108v1",
    "published": "2025-05-21T11:21:58+00:00",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15383v1",
    "title": "Real-Time Detection of Insider Threats Using Behavioral Analytics and Deep Evidential Clustering",
    "authors": [
      "Anas Ali",
      "Mubashar Husain",
      "Peter Hans"
    ],
    "abstract": "Insider threats represent one of the most critical challenges in modern\ncybersecurity. These threats arise from individuals within an organization who\nmisuse their legitimate access to harm the organization's assets, data, or\noperations. Traditional security mechanisms, primarily designed for external\nattackers, fall short in identifying these subtle and context-aware threats. In\nthis paper, we propose a novel framework for real-time detection of insider\nthreats using behavioral analytics combined with deep evidential clustering.\nOur system captures and analyzes user activities, applies context-rich\nbehavioral features, and classifies potential threats using a deep evidential\nclustering model that estimates both cluster assignment and epistemic\nuncertainty. The proposed model dynamically adapts to behavioral changes and\nsignificantly reduces false positives. We evaluate our framework on benchmark\ninsider threat datasets such as CERT and TWOS, achieving an average detection\naccuracy of 94.7% and a 38% reduction in false positives compared to\ntraditional clustering methods. Our results demonstrate the effectiveness of\nintegrating uncertainty modeling in threat detection pipelines. This research\nprovides actionable insights for deploying intelligent, adaptive, and robust\ninsider threat detection systems across various enterprise environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15383v1",
    "published": "2025-05-21T11:21:33+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15382v2",
    "title": "An eigenvalue result for Hammerstein integral equations with sign changing nonlinearities and functional terms",
    "authors": [
      "Gennaro Infante",
      "Giuseppe Antonio Veltri"
    ],
    "abstract": "We discuss, via a version of the Birkhoff-Kellogg theorem, the existence of\npositive and negative eigenvalues of Hammerstein integral equations with\nsign-changing nonlinearities and functional terms. The corresponding\neigenfunctions have a given norm that, in turn, provides a location for the\neigenvalues. As an application, we study the solvability of parameter-dependent\nboundary value problems for nonlocal ordinary differential equations. Two\nexamples illustrate the applicability of the theory in the case of mixed and\nDirichlet boundary conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15382v2",
    "published": "2025-05-21T11:20:41+00:00",
    "categories": [
      "math.CA",
      "Primary 45C05, secondary 34B08, 47H10"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15381v1",
    "title": "Inter-Subject Variance Transfer Learning for EMG Pattern Classification Based on Bayesian Inference",
    "authors": [
      "Seitaro Yoneda",
      "Akira Furui"
    ],
    "abstract": "In electromyogram (EMG)-based motion recognition, a subject-specific\nclassifier is typically trained with sufficient labeled data. However, this\nprocess demands extensive data collection over extended periods, burdening the\nsubject. To address this, utilizing information from pre-training on multiple\nsubjects for the training of the target subject could be beneficial. This paper\nproposes an inter-subject variance transfer learning method based on a Bayesian\napproach. This method is founded on the simple hypothesis that while the means\nof EMG features vary greatly across subjects, their variances may exhibit\nsimilar patterns. Our approach transfers variance information, acquired through\npre-training on multiple source subjects, to a target subject within a Bayesian\nupdating framework, thereby allowing accurate classification using limited\ntarget calibration data. A coefficient was also introduced to adjust the amount\nof information transferred for efficient transfer learning. Experimental\nevaluations using two EMG datasets demonstrated the effectiveness of our\nvariance transfer strategy and its superiority compared to existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15381v1",
    "published": "2025-05-21T11:18:39+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15380v2",
    "title": "Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding",
    "authors": [
      "Zijian Lin",
      "Yang Zhang",
      "Yougen Yuan",
      "Yuming Yan",
      "Jinjiang Liu",
      "Zhiyong Wu",
      "Pengfei Hu",
      "Qun Yu"
    ],
    "abstract": "Modern autoregressive speech synthesis models leveraging language models have\ndemonstrated remarkable performance. However, the sequential nature of next\ntoken prediction in these models leads to significant latency, hindering their\ndeployment in scenarios where inference speed is critical. In this work, we\npropose Speech Speculative Decoding (SSD), a novel framework for autoregressive\nspeech synthesis acceleration. Specifically, our method employs a lightweight\ndraft model to generate candidate token sequences, which are subsequently\nverified in parallel by the target model using the proposed SSD framework.\nExperimental results demonstrate that SSD achieves a significant speedup of\n1.4x compared with conventional autoregressive decoding, while maintaining high\nfidelity and naturalness. Subjective evaluations further validate the\neffectiveness of SSD in preserving the perceptual quality of the target model\nwhile accelerating inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.15380v2",
    "published": "2025-05-21T11:17:04+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15379v1",
    "title": "The P$^3$ dataset: Pixels, Points and Polygons for Multimodal Building Vectorization",
    "authors": [
      "Raphael Sulzer",
      "Liuyun Duan",
      "Nicolas Girard",
      "Florent Lafarge"
    ],
    "abstract": "We present the P$^3$ dataset, a large-scale multimodal benchmark for building\nvectorization, constructed from aerial LiDAR point clouds, high-resolution\naerial imagery, and vectorized 2D building outlines, collected across three\ncontinents. The dataset contains over 10 billion LiDAR points with\ndecimeter-level accuracy and RGB images at a ground sampling distance of 25\ncentimeter. While many existing datasets primarily focus on the image modality,\nP$^3$ offers a complementary perspective by also incorporating dense 3D\ninformation. We demonstrate that LiDAR point clouds serve as a robust modality\nfor predicting building polygons, both in hybrid and end-to-end learning\nframeworks. Moreover, fusing aerial LiDAR and imagery further improves accuracy\nand geometric quality of predicted polygons. The P$^3$ dataset is publicly\navailable, along with code and pretrained weights of three state-of-the-art\nmodels for building polygon prediction at\nhttps://github.com/raphaelsulzer/PixelsPointsPolygons .",
    "pdf_url": "http://arxiv.org/pdf/2505.15379v1",
    "published": "2025-05-21T11:16:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15378v2",
    "title": "On the Relevance of Clinical Assessment Tasks for the Automatic Detection of Parkinson's Disease Medication State from Speech",
    "authors": [
      "David Gimeno-G√≥mez",
      "Rub√©n Solera-Ure√±a",
      "Anna Pompili",
      "Carlos-D. Mart√≠nez-Hinarejos",
      "Rita Cardoso",
      "Isabel Guimar√£es",
      "Joaquim J. Ferreira",
      "Alberto Abad"
    ],
    "abstract": "The automatic identification of medication states of Parkinson's disease (PD)\npatients can assist clinicians in monitoring and scheduling personalized\ntreatments, as well as studying the effects of medication in alleviating the\nmotor symptoms that characterize the disease. This paper explores speech as a\nnon-invasive and accessible biomarker for identifying PD medication states,\nintroducing a novel approach that addresses this task from a\nspeaker-independent perspective. While traditional machine learning models\nachieve competitive results, self-supervised speech representations prove\nessential for optimal performance, significantly surpassing knowledge-based\nacoustic descriptors. Experiments across diverse speech assessment tasks\nhighlight the relevance of prosody and continuous speech in distinguishing\nmedication states, reaching an F1-score of 88.2%. These findings may streamline\nclinicians' work and reduce patient effort in voice recordings.",
    "pdf_url": "http://arxiv.org/pdf/2505.15378v2",
    "published": "2025-05-21T11:15:26+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15377v1",
    "title": "Stress Bytes: Decoding the Associations between Internet Use and Perceived Stress",
    "authors": [
      "Mohammad Belal",
      "Nguyen Luong",
      "Talayeh Aledavood",
      "Juhi Kulshrestha"
    ],
    "abstract": "In today's digital era, internet plays a pervasive role in our lives,\ninfluencing everyday activities such as communication, work, and leisure. This\nonline engagement intertwines with offline experiences, shaping individuals'\noverall well-being. Despite its significance, existing research often falls\nshort in capturing the relationship between internet use and well-being,\nrelying primarily on isolated studies and self-reported data. One of the major\ncontributors to deteriorated well-being - both physical and mental - is stress.\nWhile some research has examined the relationship between internet use and\nstress, both positive and negative associations have been reported. Our primary\ngoal in this work is to identify the associations between an individual's\ninternet use and their stress. For achieving our goal, we conducted a\nlongitudinal multimodal study that spanned seven months. We combined\nfine-grained URL-level web browsing traces of 1490 German internet users with\ntheir sociodemographics and monthly measures of stress. Further, we developed a\nconceptual framework that allows us to simultaneously explore different\ncontextual dimensions, including how, where, when, and by whom the internet is\nused. Our analysis revealed several associations between internet use and\nstress that vary by context. Social media, entertainment, online shopping, and\ngaming were positively associated with stress, while productivity, news, and\nadult content use were negatively associated. In the future, the behavioral\nmarkers we identified can pave the way for designing individualized tools for\npeople to self-monitor and self-moderate their online behaviors to enhance\ntheir well-being, reducing the burden on already overburdened mental health\nservices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15377v1",
    "published": "2025-05-21T11:12:18+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15376v1",
    "title": "Federated Learning-Enhanced Blockchain Framework for Privacy-Preserving Intrusion Detection in Industrial IoT",
    "authors": [
      "Anas Ali",
      "Mubashar Husain",
      "Peter Hans"
    ],
    "abstract": "Industrial Internet of Things (IIoT) systems have become integral to smart\nmanufacturing, yet their growing connectivity has also exposed them to\nsignificant cybersecurity threats. Traditional intrusion detection systems\n(IDS) often rely on centralized architectures that raise concerns over data\nprivacy, latency, and single points of failure. In this work, we propose a\nnovel Federated Learning-Enhanced Blockchain Framework (FL-BCID) for\nprivacy-preserving intrusion detection tailored for IIoT environments. Our\narchitecture combines federated learning (FL) to ensure decentralized model\ntraining with blockchain technology to guarantee data integrity, trust, and\ntamper resistance across IIoT nodes. We design a lightweight intrusion\ndetection model collaboratively trained using FL across edge devices without\nexposing sensitive data. A smart contract-enabled blockchain system records\nmodel updates and anomaly scores to establish accountability. Experimental\nevaluations using the ToN-IoT and N-BaIoT datasets demonstrate the superior\nperformance of our framework, achieving 97.3% accuracy while reducing\ncommunication overhead by 41% compared to baseline centralized methods. Our\napproach ensures privacy, scalability, and robustness-critical for secure\nindustrial operations. The proposed FL-BCID system provides a promising\nsolution for enhancing trust and privacy in modern IIoT security architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.15376v1",
    "published": "2025-05-21T11:11:44+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15375v1",
    "title": "Quadrupole Strength in Isobaric Triplets",
    "authors": [
      "B. C. Backes",
      "J. Dobaczewski",
      "D. Muir",
      "W. Nazarewicz",
      "P. -G. Reinhard",
      "M. A. Bentley",
      "R. Wadsworth"
    ],
    "abstract": "The dependence of the $E2$ matrix elements on isospin projection $T_z$ is\nlinked to the conservation of the isospin symmetry. To study this conjecture,\nwe calculated the ${B(E2: 2^+ \\rightarrow 0^+)}$ rates for the even-even $T=1$\nmirror nuclei with $42$ $\\leq$ $A$ $\\leq$ $98$ within nuclear density\nfunctional theory, employing the generalized Bohr Hamiltonian, and carrying out\nangular momentum projection. We demonstrated that collective effects are\ncrucial for describing experimental data near the $N=Z$ line without invoking\nexplicit beyond-Coulomb isospin symmetry-breaking corrections. We also\ndetermined the $B(E2\\downarrow)$ values for odd-odd $T_z=0$ nuclei $^{70}Br$\nand $^{78}Y$ in doubly-blocked configurations. We discussed the requirements\nfor accurately describing isobaric analog states and emphasized how current\ntheoretical results should be interpreted within the study of isospin symmetry\nacross isospin triplets.",
    "pdf_url": "http://arxiv.org/pdf/2505.15375v1",
    "published": "2025-05-21T11:09:41+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15374v1",
    "title": "A Risk-Based Probabilistic Transient Stability Approach for Ranking of Circuit Breakers in a Power System",
    "authors": [
      "Umair Shahzad"
    ],
    "abstract": "Power systems are getting more complex than ever and are consequently\noperating close to their limit of stability. Moreover, with the increasing\ndemand of renewable wind generation, and the requirement to maintain a secure\npower system, the importance of transient stability cannot be overestimated.\nCurrent deterministic industry practices of transient stability assessment\nignore the probability of variables involved. With increasing system\nuncertainties and widespread electricity market deregulation, there is a strong\ninevitability to incorporate probabilistic transient stability analysis.\nCircuit breakers play a critical role in fault clearing and consequently in\ndetermining the system transient stability. It is important that they undergo\ntimely and appropriate maintenance procedures based on some criterion.\nConsidering the need of incorporating risk in modern power systems, this paper\nproposes a risk-based probabilistic transient stability approach for ranking of\ncircuit breakers in a power system. A novel priority index was proposed to rank\nthe circuit breakers based on the system transient stability risk. DIgSILENT\nPowerFactory software was used to conduct the required simulations on IEEE 14\nbus system. The proposed risk-based framework was deemed to be efficient in\nidentification of the circuit breakers based on their priority rank index which\ncan aid in power system planning process.",
    "pdf_url": "http://arxiv.org/pdf/2505.15374v1",
    "published": "2025-05-21T11:08:44+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15373v1",
    "title": "RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction with Spatio-Temporal Aggregation",
    "authors": [
      "Naman Patel",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami"
    ],
    "abstract": "Mapping and understanding complex 3D environments is fundamental to how\nautonomous systems perceive and interact with the physical world, requiring\nboth precise geometric reconstruction and rich semantic comprehension. While\nexisting 3D semantic mapping systems excel at reconstructing and identifying\npredefined object instances, they lack the flexibility to efficiently build\nsemantic maps with open-vocabulary during online operation. Although recent\nvision-language models have enabled open-vocabulary object recognition in 2D\nimages, they haven't yet bridged the gap to 3D spatial understanding. The\ncritical challenge lies in developing a training-free unified system that can\nsimultaneously construct accurate 3D maps while maintaining semantic\nconsistency and supporting natural language interactions in real time. In this\npaper, we develop a zero-shot framework that seamlessly integrates\nGPU-accelerated geometric reconstruction with open-vocabulary vision-language\nmodels through online instance-level semantic embedding fusion, guided by\nhierarchical object association with spatial indexing. Our training-free system\nachieves superior performance through incremental processing and unified\ngeometric-semantic updates, while robustly handling 2D segmentation\ninconsistencies. The proposed general-purpose 3D scene understanding framework\ncan be used for various tasks including zero-shot 3D instance retrieval,\nsegmentation, and object detection to reason about previously unseen objects\nand interpret natural language queries. The project page is available at\nhttps://razer-3d.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2505.15373v1",
    "published": "2025-05-21T11:07:25+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15372v1",
    "title": "X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System",
    "authors": [
      "Peng Wang",
      "Ruihan Tao",
      "Qiguang Chen",
      "Mengkang Hu",
      "Libo Qin"
    ],
    "abstract": "Recently, large language model (LLM)-based agents have achieved significant\nsuccess in interactive environments, attracting significant academic and\nindustrial attention. Despite these advancements, current research\npredominantly focuses on English scenarios. In reality, there are over 7,000\nlanguages worldwide, all of which demand access to comparable agentic services.\nNevertheless, the development of language agents remains inadequate for meeting\nthe diverse requirements of multilingual agentic applications. To fill this\ngap, we introduce X-WebAgentBench, a novel multilingual agent benchmark in an\ninteractive web environment, which evaluates the planning and interaction\nperformance of language agents across multiple languages, thereby contributing\nto the advancement of global agent intelligence. Additionally, we assess the\nperformance of various LLMs and cross-lingual alignment methods, examining\ntheir effectiveness in enhancing agents. Our findings reveal that even advanced\nmodels like GPT-4o, when combined with cross-lingual techniques, fail to\nachieve satisfactory results. We hope that X-WebAgentBench can serve as a\nvaluable benchmark for multilingual agent scenario in real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15372v1",
    "published": "2025-05-21T11:07:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15371v1",
    "title": "Distributionally Robust Federated Learning with Client Drift Minimization",
    "authors": [
      "Mounssif Krouka",
      "Chaouki Ben Issaid",
      "Mehdi Bennis"
    ],
    "abstract": "Federated learning (FL) faces critical challenges, particularly in\nheterogeneous environments where non-independent and identically distributed\ndata across clients can lead to unfair and inefficient model performance. In\nthis work, we introduce \\textit{DRDM}, a novel algorithm that addresses these\nissues by combining a distributionally robust optimization (DRO) framework with\ndynamic regularization to mitigate client drift. \\textit{DRDM} frames the\ntraining as a min-max optimization problem aimed at maximizing performance for\nthe worst-case client, thereby promoting robustness and fairness. This robust\nobjective is optimized through an algorithm leveraging dynamic regularization\nand efficient local updates, which significantly reduces the required number of\ncommunication rounds. Moreover, we provide a theoretical convergence analysis\nfor convex smooth objectives under partial participation. Extensive experiments\non three benchmark datasets, covering various model architectures and data\nheterogeneity levels, demonstrate that \\textit{DRDM} significantly improves\nworst-case test accuracy while requiring fewer communication rounds than\nexisting state-of-the-art baselines. Furthermore, we analyze the impact of\nsignal-to-noise ratio (SNR) and bandwidth on the energy consumption of\nparticipating clients, demonstrating that the number of local update steps can\nbe adaptively selected to achieve a target worst-case test accuracy with\nminimal total energy cost across diverse communication environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15371v1",
    "published": "2025-05-21T11:05:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15370v2",
    "title": "Prediction of Reposting on X",
    "authors": [
      "Ziming Xu",
      "Shi Zhou",
      "Vasileios Lampos",
      "Ingemar J. Cox"
    ],
    "abstract": "There have been considerable efforts to predict a user's reposting behaviour\non X (formerly Twitter) using machine learning models. The problem is\npreviously cast as a supervised classification task, where Tweets are randomly\nassigned to a test or training set. The random assignment helps to ensure that\nthe test and training sets are drawn from the same distribution. In practice,\nwe would like to predict users' reposting behaviour for a set of messages\nrelated to a new, previously unseen, topic (defined by a hashtag). In this\ncase, the problem becomes an out-of-distribution generalisation classification\ntask.\n  Experimental results reveal that while existing algorithms, which\npredominantly use features derived from the content of Tweet messages, perform\nwell when the training and test distributions are the same, these algorithms\nperform much worse when the test set is out of distribution. We then show that\nif the message features are supplemented or replaced with features derived from\nusers' profile and past behaviour, the out-of-distribution prediction is\ngreatly improved, with the F1 score increasing from 0.24 to 0.70. Our\nexperimental results suggest that a significant component of reposting\nbehaviour can be predicted based on users' profile and past behaviour, and is\nindependent of the content of messages.",
    "pdf_url": "http://arxiv.org/pdf/2505.15370v2",
    "published": "2025-05-21T11:04:50+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.17107v1",
    "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution",
    "authors": [
      "Minghao Shao",
      "Haoran Xi",
      "Nanda Rani",
      "Meet Udeshi",
      "Venkata Sai Charan Putrevu",
      "Kimberly Milner",
      "Brendan Dolan-Gavitt",
      "Sandeep Kumar Shukla",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami",
      "Ramesh Karri",
      "Muhammad Shafique"
    ],
    "abstract": "Large Language Model (LLM) agents can automate cybersecurity tasks and can\nadapt to the evolving cybersecurity landscape without re-engineering. While LLM\nagents have demonstrated cybersecurity capabilities on Capture-The-Flag (CTF)\ncompetitions, they have two key limitations: accessing latest cybersecurity\nexpertise beyond training data, and integrating new knowledge into complex task\nplanning. Knowledge-based approaches that incorporate technical understanding\ninto the task-solving automation can tackle these limitations. We present\nCRAKEN, a knowledge-based LLM agent framework that improves cybersecurity\ncapability through three core mechanisms: contextual decomposition of\ntask-critical information, iterative self-reflected knowledge retrieval, and\nknowledge-hint injection that transforms insights into adaptive attack\nstrategies. Comprehensive evaluations with different configurations show\nCRAKEN's effectiveness in multi-stage vulnerability detection and exploitation\ncompared to previous approaches. Our extensible architecture establishes new\nmethodologies for embedding new security knowledge into LLM-driven\ncybersecurity agentic systems. With a knowledge database of CTF writeups,\nCRAKEN obtained an accuracy of 22% on NYU CTF Bench, outperforming prior works\nby 3% and achieving state-of-the-art results. On evaluation of MITRE ATT&CK\ntechniques, CRAKEN solves 25-30% more techniques than prior work, demonstrating\nimproved cybersecurity capabilities via knowledge-based execution. We make our\nframework open source to public\nhttps://github.com/NYU-LLM-CTF/nyuctf_agents_craken.",
    "pdf_url": "http://arxiv.org/pdf/2505.17107v1",
    "published": "2025-05-21T11:01:11+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15369v1",
    "title": "An adaptive proximal safeguarded augmented Lagrangian method for nonsmooth DC problems with convex constraints",
    "authors": [
      "Christian Kanzow",
      "Tanja Neder"
    ],
    "abstract": "A proximal safeguarded augmented Lagrangian method for minimizing the\ndifference of convex (DC) functions over a nonempty, closed and convex set with\nadditional linear equality as well as convex inequality constraints is\npresented. Thereby, all functions involved may be nonsmooth. Iterates (of the\nprimal variable) are obtained by solving convex optimization problems as the\nconcave part of the objective function gets approximated by an affine\nlinearization. Under the assumption of a modified Slater constraint\nqualification, both convergence of the primal and dual variables to a\ngeneralized Karush-Kuhn-Tucker (KKT) point is proven, at least on a\nsubsequence. Numerical experiments and comparison with existing solution\nmethods are presented using some classes of constrained and nonsmooth DC\nproblems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15369v1",
    "published": "2025-05-21T10:58:14+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15368v4",
    "title": "Neurodyne: Neural Pitch Manipulation with Representation Learning and Cycle-Consistency GAN",
    "authors": [
      "Yicheng Gu",
      "Chaoren Wang",
      "Zhizheng Wu",
      "Lauri Juvela"
    ],
    "abstract": "Pitch manipulation is the process of producers adjusting the pitch of an\naudio segment to a specific key and intonation, which is essential in music\nproduction. Neural-network-based pitch-manipulation systems have been popular\nin recent years due to their superior synthesis quality compared to classical\nDSP methods. However, their performance is still limited due to their\ninaccurate feature disentanglement using source-filter models and the lack of\npaired in- and out-of-tune training data. This work proposes Neurodyne to\naddress these issues. Specifically, Neurodyne uses adversarial representation\nlearning to learn a pitch-independent latent representation to avoid inaccurate\ndisentanglement and cycle-consistency training to create paired training data\nimplicitly. Experimental results on global-key and template-based pitch\nmanipulation demonstrate the effectiveness of the proposed system, marking\nimproved synthesis quality while maintaining the original singer identity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15368v4",
    "published": "2025-05-21T10:58:10+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15367v2",
    "title": "Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition",
    "authors": [
      "Dasol Choi",
      "Seunghyun Lee",
      "Youngsook Song"
    ],
    "abstract": "Vision-Language Models (VLMs) have shown capabilities in interpreting visual\ncontent, but their reliability in safety-critical everyday life scenarios\nremains insufficiently explored. We introduce VERI (Visual Emergency\nRecognition Dataset), a diagnostic benchmark comprising 200 images organized\ninto 100 contrastive pairs. Each emergency scene is paired with a visually\nsimilar but safe counterpart through human verification and refinement. Using a\ntwo-stage evaluation protocol - risk identification and emergency response - we\nassess 14 VLMs (2B to 124B parameters) across medical emergencies, accidents,\nand natural disasters. Our analysis reveals an \"overreaction problem\", where\nmodels accurately identify genuine emergencies (70-100 percent success rate)\nbut produce high false-positive rates, misclassifying 31-96 percent of safe\nsituations as dangerous. Ten safe scenarios were universally misclassified by\nall models regardless of scale. This \"better-safe-than-sorry\" bias primarily\nresults from contextual overinterpretation (88-93 percent of errors),\nchallenging VLM reliability in safety-critical applications. These findings\nhighlight fundamental limitations in current VLM architectures, which persist\ndespite increased model scale. Our results demonstrate an urgent need for\nstrategies specifically improving contextual reasoning in ambiguous visual\nsituations. The consistently low performance of the model indicates that these\ndata serve effectively as a diagnostic dataset.",
    "pdf_url": "http://arxiv.org/pdf/2505.15367v2",
    "published": "2025-05-21T10:57:40+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15366v1",
    "title": "Erd≈ës-Szekeres Maker-Breaker Games",
    "authors": [
      "A. D≈æuklevski",
      "D. P√°lv√∂gyi",
      "A. Pokrovskiy",
      "C. D. T√≥th",
      "T. Valla",
      "L. Verlinde"
    ],
    "abstract": "We present new results on Maker-Breaker games arising from the\nErd\\H{o}s-Szekeres problem in planar geometry. This classical problem asks how\nlarge a set in general position has to be to ensure the existence of $n$ points\nthat are the vertices of a convex $n$-gon. Moreover, Erd\\H{o}s further extended\nthis problem by asking what happens if we also require that this $n$-gon has an\nempty interior. In a 2-player Maker-Breaker setting, this problem inspires two\nmain games. In both games, Maker tries to obtain an empty convex $k$-gon, while\nBreaker tries to prevent her from doing so. The games differ only in which\npoints can comprise the winning $k$-gons: in the monochromatic version the\npoints of both players can make up a $k$-gon, while in the bichromatic version\nonly Maker's points contribute to such a polygon. Both settings are studied in\nthis paper. We show that in the monochromatic game, Maker always wins. Even in\na biased game where Breaker is allowed to place $s$ points per round, for any\nconstant $s \\geq 1$, Maker has a winning strategy. In the bichromatic setting,\nMaker still wins whenever Breaker is allowed to place $s$ points per round for\nany constant $s<2$. This settles an open problem posed by Aichholzer et al.\n(2019). Furthermore, we show that there are games that are not a lost cause for\nBreaker. Whenever $k\\ge 8$ and Breaker is allowed to play 12 or more points per\nround, she has a winning strategy. We also consider the one-round bichromatic\ngame (a.k.a.\\ the offline version). In this setting, we show that Breaker wins\nif she can place twice as many points as Maker but if the bias is less than\n$2$, then Maker wins for large enough set of points.",
    "pdf_url": "http://arxiv.org/pdf/2505.15366v1",
    "published": "2025-05-21T10:56:37+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15365v1",
    "title": "AI vs. Human Judgment of Content Moderation: LLM-as-a-Judge and Ethics-Based Response Refusals",
    "authors": [
      "Stefan Pasch"
    ],
    "abstract": "As large language models (LLMs) are increasingly deployed in high-stakes\nsettings, their ability to refuse ethically sensitive prompts-such as those\ninvolving hate speech or illegal activities-has become central to content\nmoderation and responsible AI practices. While refusal responses can be viewed\nas evidence of ethical alignment and safety-conscious behavior, recent research\nsuggests that users may perceive them negatively. At the same time, automated\nassessments of model outputs are playing a growing role in both evaluation and\ntraining. In particular, LLM-as-a-Judge frameworks-in which one model is used\nto evaluate the output of another-are now widely adopted to guide benchmarking\nand fine-tuning. This paper examines whether such model-based evaluators assess\nrefusal responses differently than human users. Drawing on data from Chatbot\nArena and judgments from two AI judges (GPT-4o and Llama 3 70B), we compare how\ndifferent types of refusals are rated. We distinguish ethical refusals, which\nexplicitly cite safety or normative concerns (e.g., \"I can't help with that\nbecause it may be harmful\"), and technical refusals, which reflect system\nlimitations (e.g., \"I can't answer because I lack real-time data\"). We find\nthat LLM-as-a-Judge systems evaluate ethical refusals significantly more\nfavorably than human users, a divergence not observed for technical refusals.\nWe refer to this divergence as a moderation bias-a systematic tendency for\nmodel-based evaluators to reward refusal behaviors more than human users do.\nThis raises broader questions about transparency, value alignment, and the\nnormative assumptions embedded in automated evaluation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15365v1",
    "published": "2025-05-21T10:56:16+00:00",
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15364v1",
    "title": "MHANet: Multi-scale Hybrid Attention Network for Auditory Attention Detection",
    "authors": [
      "Lu Li",
      "Cunhang Fan",
      "Hongyu Zhang",
      "Jingjing Zhang",
      "Xiaoke Yang",
      "Jian Zhou",
      "Zhao Lv"
    ],
    "abstract": "Auditory attention detection (AAD) aims to detect the target speaker in a\nmulti-talker environment from brain signals, such as electroencephalography\n(EEG), which has made great progress. However, most AAD methods solely utilize\nattention mechanisms sequentially and overlook valuable multi-scale contextual\ninformation within EEG signals, limiting their ability to capture long-short\nrange spatiotemporal dependencies simultaneously. To address these issues, this\npaper proposes a multi-scale hybrid attention network (MHANet) for AAD, which\nconsists of the multi-scale hybrid attention (MHA) module and the\nspatiotemporal convolution (STC) module. Specifically, MHA combines channel\nattention and multi-scale temporal and global attention mechanisms. This\neffectively extracts multi-scale temporal patterns within EEG signals and\ncaptures long-short range spatiotemporal dependencies simultaneously. To\nfurther improve the performance of AAD, STC utilizes temporal and spatial\nconvolutions to aggregate expressive spatiotemporal representations.\nExperimental results show that the proposed MHANet achieves state-of-the-art\nperformance with fewer trainable parameters across three datasets, 3 times\nlower than that of the most advanced model. Code is available at:\nhttps://github.com/fchest/MHANet.",
    "pdf_url": "http://arxiv.org/pdf/2505.15364v1",
    "published": "2025-05-21T10:55:56+00:00",
    "categories": [
      "cs.HC",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15865v1",
    "title": "How Do Large Vision-Language Models See Text in Image? Unveiling the Distinctive Role of OCR Heads",
    "authors": [
      "Ingeol Baek",
      "Hwan Chang",
      "Sunghyun Ryu",
      "Hwanhee Lee"
    ],
    "abstract": "Despite significant advancements in Large Vision Language Models (LVLMs), a\ngap remains, particularly regarding their interpretability and how they locate\nand interpret textual information within images. In this paper, we explore\nvarious LVLMs to identify the specific heads responsible for recognizing text\nfrom images, which we term the Optical Character Recognition Head (OCR Head).\nOur findings regarding these heads are as follows: (1) Less Sparse: Unlike\nprevious retrieval heads, a large number of heads are activated to extract\ntextual information from images. (2) Qualitatively Distinct: OCR heads possess\nproperties that differ significantly from general retrieval heads, exhibiting\nlow similarity in their characteristics. (3) Statically Activated: The\nfrequency of activation for these heads closely aligns with their OCR scores.\nWe validate our findings in downstream tasks by applying Chain-of-Thought (CoT)\nto both OCR and conventional retrieval heads and by masking these heads. We\nalso demonstrate that redistributing sink-token values within the OCR heads\nimproves performance. These insights provide a deeper understanding of the\ninternal mechanisms LVLMs employ in processing embedded textual information in\nimages.",
    "pdf_url": "http://arxiv.org/pdf/2505.15865v1",
    "published": "2025-05-21T10:53:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2507.13354v2",
    "title": "Physical models realizing the transformer architecture of large language models",
    "authors": [
      "Zeqian Chen"
    ],
    "abstract": "The introduction of the transformer architecture in 2017 marked the most\nstriking advancement in natural language processing. The transformer is a model\narchitecture relying entirely on an attention mechanism to draw global\ndependencies between input and output. However, we believe there is a gap in\nour theoretical understanding of what the transformer is, and how it works\nphysically. From a physical perspective on modern chips, such as those chips\nunder 28nm, modern intelligent machines should be regarded as open quantum\nsystems beyond conventional statistical systems. Thereby, in this paper, we\nconstruct physical models realizing large language models based on a\ntransformer architecture as open quantum systems in the Fock space over the\nHilbert space of tokens. Our physical models underlie the transformer\narchitecture for large language models.",
    "pdf_url": "http://arxiv.org/pdf/2507.13354v2",
    "published": "2025-05-21T10:53:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15363v2",
    "title": "Robust extrapolation using physics-related activation functions in neural networks for nuclear masses",
    "authors": [
      "C. H. Kim",
      "K. Y. Chae",
      "M. S. Smith"
    ],
    "abstract": "Given the importance of nuclear mass predictions, numerous models have been\ndeveloped to extrapolate the measured data into unknown regions. While neural\nnetworks -- the core of modern artificial intelligence -- have been recently\nsuggested as powerful methods, showcasing high predictive power in the measured\nregion, their ability to extrapolate remains questionable. This limitation\nstems from their `black box' nature and large number of parameters entangled\nwith nonlinear functions designed in the context of computer science. In this\nstudy, we demonstrate that replacing such nonlinear functions with\nphysics-related functions significantly improves extrapolation performance and\nprovides enhanced understanding of the model mechanism. Using only the\ninformation about neutron (N) and proton (Z) numbers without any existing\nglobal mass models or knowledge of magic numbers, we developed a highly\naccurate model that covers light nuclei (N, Z > 0) up to the drip lines. The\nextrapolation performance was rigorously evaluated using the outermost nuclei\nin the measurement landscape, and only the data in the inner region was used\nfor training. We present details of the method and model, along with\nopportunities for future improvements.",
    "pdf_url": "http://arxiv.org/pdf/2505.15363v2",
    "published": "2025-05-21T10:50:02+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15362v2",
    "title": "Minimum blocking sets for families of partitions",
    "authors": [
      "Guillermo Gamboa Quintero",
      "Ida Kantor"
    ],
    "abstract": "A $3$-partition of an $n$-element set $V$ is a triple of pairwise disjoint\nnonempty subsets $X,Y,Z$ such that $V=X\\cup Y\\cup Z$. We determine the minimum\nsize $\\varphi_3(n)$ of a set $\\mathcal{E}$ of triples such that for every\n3-partition $X,Y,Z$ of the set $\\{1,\\dots,n\\}$, there is some $\\{x,y,z\\}\\in\n\\mathcal{E}$ with $x\\in X$, $y\\in Y$, and $z\\in Z$. In particular,\n$$\\varphi_3(n)=\\left\\lceil{\\frac{n(n-2)}{3}}\\right\\rceil.$$ For $d>3$, one may\ndefine an analogous number $\\varphi_d(n)$. We determine the order of magnitude\nof $\\varphi_d(n)$, and prove the following upper and lower bounds, for $d>3$:\n$$\\frac{2 n^{d-1}}{d!} -o(n^{d-1}) \\leq \\varphi_d(n) \\leq\n\\frac{0.86}{(d-1)!}n^{d-1}+o(n^{d-1}).$$",
    "pdf_url": "http://arxiv.org/pdf/2505.15362v2",
    "published": "2025-05-21T10:47:46+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "05D15"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15361v1",
    "title": "Silicon photonics LMA amplifiers: High power, high gain, low noise and tunable polarization sensitivity",
    "authors": [
      "Jan Lorenzen",
      "Neetesh Singh",
      "Kai Wang",
      "Sonia M. Garcia-Blanco",
      "Franz X. K√§rtner"
    ],
    "abstract": "High-power amplifiers are of great importance in many optical systems\ndeployed in optical sensing, ranging, medical surgery, material processing and\nmore. Likewise, high-gain, low-noise amplifiers with low polarization\ndependence are critical components of long-range optical communication systems.\nIntegrated photonic solutions show great potential in challenging application\nfields thanks to their drastic reduction in size, weight and cost, but this\ncomes at the expense of low optical power due to reduced energy storage\ncapacity in small devices. Recently, the large mode area (LMA) technology,\nwhich is well known for dramatically increasing the output power of fiber\namplifiers by orders of magnitude, has been brought to the chip-level. With a\nlarge optical mode in the gain medium, the energy storage capacity and\nsaturation power are increased significantly, allowing for high-power\namplification with watt-level output power directly from the chip. In this work\nwe demonstrate that a single integrated LMA amplifier is capable of both\nhigh-power amplification up to 800 mW with output saturation powers > 115 mW as\nwell as high small-signal net gain up to 30 dB and low-noise amplification with\nnoise figures < 4 dB. The LMA design further allows for a tuning of the\npolarization dependent gain (PDG) by adjusting the pump power and pump\npolarization, making it possible to completely nullify the\npolarization-sensitivity for any given signal power from the {\\mu}W to\nmW-level. The power and noise performance achieved surpasses the performance\nlevel of many integrated amplifiers and fiber-based amplifiers. We believe that\nthe tunability of the PDG combined with high gain and low noise figure can play\na disruptive role for next-generation integrated amplifiers in\ntelecommunication networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15361v1",
    "published": "2025-05-21T10:47:40+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.15360v1",
    "title": "Numerical simulations on First-order phase transition through thermal fluctuation",
    "authors": [
      "Ligong Bian",
      "Yuefeng Di",
      "Yongtao Jia",
      "Yang Li",
      "Kehao Zeng"
    ],
    "abstract": "In this Letter, we numerically present the possibility of the first-order\nphase transition occurring through the thermal fluctuation in the early\nuniverse. We find that when the temperature is slightly higher than the mass\nscale of the background field, the bubble-like field configurations appear\nproceeded by oscillons, which expand and collide to finish the phase\ntransition. We provide the false vacuum decay rate and the accompanied\ngravitational waves. We also present the vacuum phase transition comparison of\nthe quantum tunneling case and thermal fluctuation case.",
    "pdf_url": "http://arxiv.org/pdf/2505.15360v1",
    "published": "2025-05-21T10:45:14+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15359v1",
    "title": "Group Order Logic",
    "authors": [
      "Anatole Dahan"
    ],
    "abstract": "We introduce an extension of fixed-point logic ($\\mathsf{FP}$) with a\ngroup-order operator ($\\mathsf{ord}$), that computes the size of a group\ngenerated by a definable set of permutations. This operation is a\ngeneralization of the rank operator ($\\mathsf{rk}$). We show that $\\mathsf{FP}\n+ \\mathsf{ord}$ constitutes a new candidate logic for the class of\npolynomial-time computable queries ($\\mathsf{P}$). As was the case for\n$\\mathsf{FP} + \\mathsf{rk}$, the model-checking of $\\mathsf{FP} + \\mathsf{ord}$\nformulae is polynomial-time computable. Moreover, the query separating\n$\\mathsf{FP} + \\mathsf{rk}$ from $\\mathsf{P}$ exhibited by Lichter in his\nrecent breakthrough is definable in $\\mathsf{FP} + \\mathsf{ord}$. Precisely, we\nshow that $\\mathsf{FP} + \\mathsf{ord}$ canonizes structures with Abelian\ncolors, a class of structures which contains Lichter's counter-example. This\nproof involves expressing a fragment of the group-theoretic approach to graph\ncanonization in the logic $\\mathsf{FP}+ \\mathsf{ord}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15359v1",
    "published": "2025-05-21T10:44:04+00:00",
    "categories": [
      "cs.LO",
      "cs.CC",
      "cs.DS",
      "math.GR",
      "68Q19",
      "F.4.1; G.2.2"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.18199v3",
    "title": "Closed Bounded Rational Framing Motions",
    "authors": [
      "Hans-Peter Schr√∂cker",
      "Zbynƒõk ≈†√≠r"
    ],
    "abstract": "We present a method for constructing all bounded rational motions that frame\na space curve $\\mathbf{r}(t)$. This means that the motion guides an orthogonal\nframe along the curve such that one frame axis is in direction of the curve\ntangent. Existence of (bounded) framing motions is equivalent to\n$\\mathbf{r}(t)$ being a (bounded) rational Pythagorean Hodograph curve. In\ncontrast to previous constructions that rely on polynomial curves with smooth\nself-intersection, our motions and curves are infinitely differentiable. To\nthis end, we develop the theory of Pythagorean hodograph curves parameterized\nover the projective line. We also provide a simple geometric necessary and\nsufficient condition on the spherical part of the motion, given by the\nhomogeneous quaternionic preimage of the Pythagorean hodograph curve, that\nensures the existence of a corresponding bounded, rational, and even regular\nframing motion. The translation part comes from the speed distribution, which\nmust be a special positive rational function. This can in practice be ensured\nby semidefinite optimization methods. We illustrate our findings with a number\nof examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.18199v3",
    "published": "2025-05-21T10:42:49+00:00",
    "categories": [
      "math.OC",
      "65D17, 53A04, 70B10"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15358v2",
    "title": "Objective Bicycle Occlusion Level Classification using a Deformable Parts-Based Model",
    "authors": [
      "Angelique Mangubat",
      "Shane Gilroy"
    ],
    "abstract": "Road safety is a critical challenge, particularly for cyclists, who are among\nthe most vulnerable road users. This study aims to enhance road safety by\nproposing a novel benchmark for bicycle occlusion level classification using\nadvanced computer vision techniques. Utilizing a parts-based detection model,\nimages are annotated and processed through a custom image detection pipeline. A\nnovel method of bicycle occlusion level is proposed to objectively quantify the\nvisibility and occlusion level of bicycle semantic parts. The findings indicate\nthat the model robustly quantifies the visibility and occlusion level of\nbicycles, a significant improvement over the subjective methods used by the\ncurrent state of the art. Widespread use of the proposed methodology will\nfacilitate accurate performance reporting of cyclist detection algorithms for\noccluded cyclists, informing the development of more robust vulnerable road\nuser detection methods for autonomous vehicles.",
    "pdf_url": "http://arxiv.org/pdf/2505.15358v2",
    "published": "2025-05-21T10:42:41+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15357v3",
    "title": "Comparative study of the butterfly velocity in holographic QCD models at finite temperature and chemical potential",
    "authors": [
      "Nikesh Lilani",
      "Dilpreet Sandhu",
      "Subhash Mahapatra"
    ],
    "abstract": "In this work, we study quantum chaos in a variety of holographic QCD models\nat finite temperature and chemical potentials. This includes the 1 R-Charge\nblack hole (1RCBH) model, the 2 R-Charge black hole (2RCBH) model, a potential\nreconstruction-based analytic bottom-up model, and a numerical bottom-up model.\nAll these models are different avatars of the Einstein-Maxwell-dilaton gravity\naction, distinguished by their specific choices of dilaton potentials and\ngauge-kinetic coupling functions. We focus on computing the chaos parameter,\nthe butterfly velocity, using three distinct methods: entanglement wedge\nreconstruction, out-of-time-ordered correlators (OTOCs), and pole-skipping. We\nshow that all three methods yield identical results for the butterfly velocity\nacross all the holographic QCD models considered, further establishing the\nequivalence between the three approaches. Furthermore, we analyze in detail the\nbehavior of the butterfly velocity as a function of chemical potential and\ntemperature. Interestingly, a universal trend emerges across all models: the\nbutterfly velocity increases/decreases with temperature/chemical potential for\nthermodynamically stable phases. Additionally, in the high-temperature limit,\nthe butterfly velocity in all models approaches that of the chargeless plasma.",
    "pdf_url": "http://arxiv.org/pdf/2505.15357v3",
    "published": "2025-05-21T10:40:11+00:00",
    "categories": [
      "hep-th",
      "hep-lat",
      "hep-ph",
      "nlin.CD",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15356v1",
    "title": "NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging",
    "authors": [
      "Weiming Zhang",
      "Qingyao Li",
      "Xinyi Dai",
      "Jizheng Chen",
      "Kounianhua Du",
      "Weinan Zhang",
      "Weiwen Liu",
      "Yasheng Wang",
      "Ruiming Tang",
      "Yong Yu"
    ],
    "abstract": "Debugging is a critical aspect of LLM's coding ability. Early debugging\nefforts primarily focused on code-level analysis, which often falls short when\naddressing complex programming errors that require a deeper understanding of\nalgorithmic logic. Recent advancements in large language models (LLMs) have\nshifted attention toward leveraging natural language reasoning to enhance\ncode-related tasks. However, two fundamental questions remain unanswered: What\ntype of natural language format is most effective for debugging tasks? And what\nspecific benefits does natural language reasoning bring to the debugging\nprocess? In this paper, we introduce NL-DEBUGGING, a novel framework that\nemploys natural language as an intermediate representation to improve code\ndebugging. By debugging at a natural language level, we demonstrate that\nNL-DEBUGGING outperforms traditional debugging methods and enables a broader\nmodification space through direct refinement guided by execution feedback. Our\nfindings highlight the potential of natural language reasoning to advance\nautomated code debugging and address complex programming challenges.",
    "pdf_url": "http://arxiv.org/pdf/2505.15356v1",
    "published": "2025-05-21T10:38:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.11043v1",
    "title": "A Framework for Non-Linear Attention via Modern Hopfield Networks",
    "authors": [
      "Ahmed Farooq"
    ],
    "abstract": "In this work we propose an energy functional along the lines of Modern\nHopfield Networks (MNH), the stationary points of which correspond to the\nattention due to Vaswani et al. [12], thus unifying both frameworks. The minima\nof this landscape form \"context wells\" - stable configurations that encapsulate\nthe contextual relationships among tokens. A compelling picture emerges: across\n$n$ token embeddings an energy landscape is defined whose gradient corresponds\nto the attention computation. Non-linear attention mechanisms offer a means to\nenhance the capabilities of transformer models for various sequence modeling\ntasks by improving the model's understanding of complex relationships, learning\nof representations, and overall efficiency and performance. A rough analogy can\nbe seen via cubic splines which offer a richer representation of non-linear\ndata where a simpler linear model may be inadequate. This approach can be used\nfor the introduction of non-linear heads in transformer based models such as\nBERT, [6], etc.",
    "pdf_url": "http://arxiv.org/pdf/2506.11043v1",
    "published": "2025-05-21T10:33:01+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15355v1",
    "title": "Decoding Phone Pairs from MEG Signals Across Speech Modalities",
    "authors": [
      "Xabier de Zuazo",
      "Eva Navas",
      "Ibon Saratxaga",
      "Mathieu Bourguignon",
      "Nicola Molinaro"
    ],
    "abstract": "Understanding the neural mechanisms underlying speech production is essential\nfor both advancing cognitive neuroscience theory and developing practical\ncommunication technologies. In this study, we investigated\nmagnetoencephalography signals to decode phones from brain activity during\nspeech production and perception (passive listening and voice playback) tasks.\nUsing a dataset comprising 17 participants, we performed pairwise phone\nclassification, extending our analysis to 15 phonetic pairs. Multiple machine\nlearning approaches, including regularized linear models and neural network\narchitectures, were compared to determine their effectiveness in decoding\nphonetic information. Our results demonstrate significantly higher decoding\naccuracy during speech production (76.6%) compared to passive listening and\nplayback modalities (~51%), emphasizing the richer neural information available\nduring overt speech. Among the models, the Elastic Net classifier consistently\noutperformed more complex neural networks, highlighting the effectiveness of\ntraditional regularization techniques when applied to limited and\nhigh-dimensional MEG datasets. Besides, analysis of specific brain frequency\nbands revealed that low-frequency oscillations, particularly Delta (0.2-3 Hz)\nand Theta (4-7 Hz), contributed the most substantially to decoding accuracy,\nsuggesting that these bands encode critical speech production-related neural\nprocesses. Despite using advanced denoising methods, it remains unclear whether\ndecoding solely reflects neural activity or if residual muscular or movement\nartifacts also contributed, indicating the need for further methodological\nrefinement. Overall, our findings underline the critical importance of\nexamining overt speech production paradigms, which, despite their complexity,\noffer opportunities to improve brain-computer interfaces to help individuals\nwith severe speech impairments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15355v1",
    "published": "2025-05-21T10:31:34+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.NE",
      "cs.SD",
      "eess.AS",
      "I.2.6; I.5.1"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15354v1",
    "title": "Human in the Loop Adaptive Optimization for Improved Time Series Forecasting",
    "authors": [
      "Malik Tiomoko",
      "Hamza Cherkaoui",
      "Giuseppe Paolo",
      "Zhang Yili",
      "Yu Meng",
      "Zhang Keli",
      "Hafiz Tiomoko Ali"
    ],
    "abstract": "Time series forecasting models often produce systematic, predictable errors\neven in critical domains such as energy, finance, and healthcare. We introduce\na novel post training adaptive optimization framework that improves forecast\naccuracy without retraining or architectural changes. Our method automatically\napplies expressive transformations optimized via reinforcement learning,\ncontextual bandits, or genetic algorithms to correct model outputs in a\nlightweight and model agnostic way. Theoretically, we prove that affine\ncorrections always reduce the mean squared error; practically, we extend this\nidea with dynamic action based optimization. The framework also supports an\noptional human in the loop component: domain experts can guide corrections\nusing natural language, which is parsed into actions by a language model.\nAcross multiple benchmarks (e.g., electricity, weather, traffic), we observe\nconsistent accuracy gains with minimal computational overhead. Our interactive\ndemo shows the framework's real time usability. By combining automated post hoc\nrefinement with interpretable and extensible mechanisms, our approach offers a\npowerful new direction for practical forecasting systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15354v1",
    "published": "2025-05-21T10:30:02+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15353v1",
    "title": "Revealing Language Model Trajectories via Kullback-Leibler Divergence",
    "authors": [
      "Ryo Kishino",
      "Yusuke Takase",
      "Momose Oyama",
      "Hiroaki Yamagiwa",
      "Hidetoshi Shimodaira"
    ],
    "abstract": "A recently proposed method enables efficient estimation of the KL divergence\nbetween language models, including models with different architectures, by\nassigning coordinates based on log-likelihood vectors. To better understand the\nbehavior of this metric, we systematically evaluate KL divergence across a wide\nrange of conditions using publicly available language models. Our analysis\ncovers comparisons between pretraining checkpoints, fine-tuned and base models,\nand layers via the logit lens. We find that trajectories of language models, as\nmeasured by KL divergence, exhibit a spiral structure during pretraining and\nthread-like progressions across layers. Furthermore, we show that, in terms of\ndiffusion exponents, model trajectories in the log-likelihood space are more\nconstrained than those in weight space.",
    "pdf_url": "http://arxiv.org/pdf/2505.15353v1",
    "published": "2025-05-21T10:27:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15352v1",
    "title": "Every nonflat conformal minimal surface is homotopic to a proper one",
    "authors": [
      "Tjasa Vrhovnik"
    ],
    "abstract": "Given an open Riemann surface $M$, we prove that every nonflat conformal\nminimal immersion $M\\to\\mathbb{R}^n$ ($n\\geq 3$) is homotopic through nonflat\nconformal minimal immersions $M\\to\\mathbb{R}^n$ to a proper one. If $n\\geq 5$,\nit may be chosen in addition injective, hence a proper conformal minimal\nembedding. Prescribing its flux, as a consequence, every nonflat conformal\nminimal immersion $M\\to\\mathbb{R}^n$ is homotopic to the real part of a proper\nholomorphic null embedding $M\\to\\mathbb{C}^n$. We also obtain a result for a\nmore general family of holomorphic immersions from an open Riemann surface into\n$\\mathbb{C}^n$ directed by Oka cones in $\\mathbb{C}^n$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15352v1",
    "published": "2025-05-21T10:24:40+00:00",
    "categories": [
      "math.DG",
      "math.CV"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15351v1",
    "title": "Phasebook: A Survey of Selected Open Problems in Phase Retrieval",
    "authors": [
      "Marc Allain",
      "Selin Aslan",
      "Wim Coene",
      "Sjoerd Dirksen",
      "Jonathan Dong",
      "Julien Flamant",
      "Mark Iwen",
      "Felix Krahmer",
      "Tristan van Leeuwen",
      "Oleh Melnyk",
      "Andreas Menzel",
      "Allard P. Mosk",
      "Viktor Nikitin",
      "Gerlind Plonka",
      "Palina Salanevich",
      "Matthias Wellershoff"
    ],
    "abstract": "Phase retrieval is an inverse problem that, on one hand, is crucial in many\napplications across imaging and physics, and, on the other hand, leads to deep\nresearch questions in theoretical signal processing and applied harmonic\nanalysis. This survey paper is an outcome of the recent workshop Phase\nRetrieval in Mathematics and Applications (PRiMA) (held on August 5--9 2024 at\nthe Lorentz Center in Leiden, The Netherlands) that brought together experts\nworking on theoretical and practical aspects of the phase retrieval problem\nwith the purpose to formulate and explore essential open problems in the field.",
    "pdf_url": "http://arxiv.org/pdf/2505.15351v1",
    "published": "2025-05-21T10:22:55+00:00",
    "categories": [
      "cs.IT",
      "math.IT",
      "math.OC"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15350v1",
    "title": "Multiplexed holographic molecular binding assays with internal calibration standards",
    "authors": [
      "Kaitlynn Snyder",
      "Andrew D. Hollingsworth",
      "Fook Chiong Cheong",
      "Rushna Quddus",
      "David G. Grier"
    ],
    "abstract": "Holographic molecular binding assays detect macromolecules binding to\ncolloidal probe beads by monitoring nanometer-scale changes in the beads'\ndiameters with holographic microscopy. Measured changes are interpreted with\nMaxwell Garnett effective-medium theory to infer the surface coverage of\nanalyte molecules and therefore to measure the analyte concentration in\nsolution. The precision and accuracy of those measurements can be degraded by\nrun-to-run instrumental variations, which introduce systematic errors in the\nholographic characterization measurements. We detect and mitigate these errors\nby introducing a class of inert reference beads whose polymer brush coating\nresists macromolecular binding. The holographically measured diameter and\nrefractive index of those beads serve as internal standards for THC\nmeasurements. To characterize the reference beads, we introduce a general\nall-optical method to measure the grafting density of the polymer brush that\ncombines holographic characterization of the bead diameter with a refractometry\nmeasurement of the polymer's specific volume. The latter technique shows the\nspecific volume of poly(ethylene oxide) to be 1.308(4) cubic nanometers per\nkilodalton. We use this suite of techniques to demonstrate a multiplexed\nimmunoassay for immunoglobulin G (IgG) whose success validates the\neffective-medium analysis of holographic characterization measurements.\nInternal negative controls provided by the reference beads are validated by\nnegative control measurements on alcohol dehydrogenase (ADH), which has a\nsimilar molecular weight to IgG but does not bind to the probe beads' binding\nsites.",
    "pdf_url": "http://arxiv.org/pdf/2505.15350v1",
    "published": "2025-05-21T10:22:40+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.optics"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.15349v2",
    "title": "A note on the calculation of the Komar integral in the Lorentzian Taub-NUT spacetime",
    "authors": [
      "Gabriele Barbagallo",
      "Jos√© Luis V. Cerdeira",
      "Carmen G√≥mez-Fayr√©n",
      "Tom√°s Ort√≠n"
    ],
    "abstract": "It has recently been shown that one can derive consistent thermodynamical\nexpressions in the Lorentzian Taub--NUT spacetime keeping the Misner-string\nsingularities and taking into account their contributions in the Komar\nintegrals. We show how the same results are obtained when the Mister-string\nsingularities are removed by using Misner's procedure because, even though the\ncomplete spacetime has no such singularities anymore, they are unavoidable in\nall spacelike hypersurfaces which are used in the Komar integrals. Different\nchoices of hypersurfaces may contain different strings and lead to different\nphysics, though.",
    "pdf_url": "http://arxiv.org/pdf/2505.15349v2",
    "published": "2025-05-21T10:21:52+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17106v1",
    "title": "RRTL: Red Teaming Reasoning Large Language Models in Tool Learning",
    "authors": [
      "Yifei Liu",
      "Yu Cui",
      "Haibin Zhang"
    ],
    "abstract": "While tool learning significantly enhances the capabilities of large language\nmodels (LLMs), it also introduces substantial security risks. Prior research\nhas revealed various vulnerabilities in traditional LLMs during tool learning.\nHowever, the safety of newly emerging reasoning LLMs (RLLMs), such as\nDeepSeek-R1, in the context of tool learning remains underexplored. To bridge\nthis gap, we propose RRTL, a red teaming approach specifically designed to\nevaluate RLLMs in tool learning. It integrates two novel strategies: (1) the\nidentification of deceptive threats, which evaluates the model's behavior in\nconcealing the usage of unsafe tools and their potential risks; and (2) the use\nof Chain-of-Thought (CoT) prompting to force tool invocation. Our approach also\nincludes a benchmark for traditional LLMs. We conduct a comprehensive\nevaluation on seven mainstream RLLMs and uncover three key findings: (1) RLLMs\ngenerally achieve stronger safety performance than traditional LLMs, yet\nsubstantial safety disparities persist across models; (2) RLLMs can pose\nserious deceptive risks by frequently failing to disclose tool usage and to\nwarn users of potential tool output risks; (3) CoT prompting reveals\nmulti-lingual safety vulnerabilities in RLLMs. Our work provides important\ninsights into enhancing the security of RLLMs in tool learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.17106v1",
    "published": "2025-05-21T10:21:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15348v1",
    "title": "The Super Emotion Dataset",
    "authors": [
      "Enric Junqu√© de Fortuny"
    ],
    "abstract": "Despite the wide-scale usage and development of emotion classification\ndatasets in NLP, the field lacks a standardized, large-scale resource that\nfollows a psychologically grounded taxonomy. Existing datasets either use\ninconsistent emotion categories, suffer from limited sample size, or focus on\nspecific domains. The Super Emotion Dataset addresses this gap by harmonizing\ndiverse text sources into a unified framework based on Shaver's empirically\nvalidated emotion taxonomy, enabling more consistent cross-domain emotion\nrecognition research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15348v1",
    "published": "2025-05-21T10:21:00+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15347v1",
    "title": "FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management",
    "authors": [
      "Xiang Liu",
      "Hong Chen",
      "Xuming Hu",
      "Xiaowen Chu"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed in multi-turn\nconversational applications, where the management of the Key-Value (KV) Cache\npresents a significant bottleneck. The linear growth of the KV Cache with\ndialogue history imposes substantial computational costs, and existing eviction\nstrategies often degrade performance by repeatedly compressing early\nconversational context, leading to information loss and context forgetting.\nThis paper introduces FlowKV, a novel \\textbf{multi-turn isolation mechanism}\nfor KV Cache management, which can be applied to any KV Cache compression\nmethod without training. FlowKV's core innovation is a multi-turn isolation\nmechanism that preserves the accumulated compressed KV cache from past turns.\nCompression is then strategically applied only to the newly generated KV pairs\nof the latest completed turn, effectively preventing the re-compression of\nolder context and thereby mitigating catastrophic forgetting. Our results\ndemonstrate that FlowKV consistently and significantly outperforms baseline\nstrategies in maintaining instruction-following accuracy and user preference\nretention from 10.90\\% to 75.40\\%, particularly in later conversational turns.",
    "pdf_url": "http://arxiv.org/pdf/2505.15347v1",
    "published": "2025-05-21T10:20:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15346v1",
    "title": "More on the Concept of Anti-integrability for H√©non Maps",
    "authors": [
      "Zin Arai",
      "Yi-Chiuan Chen"
    ],
    "abstract": "For the family of H\\'{e}non maps $(x,y)\\mapsto (\\sqrt{a}(1-x^2)-b y,x)$ of\n$\\mathbb{R}^2$, the so-called anti-integrable (AI) limit concerns the limit\n$a\\to\\infty$ with fixed Jacobian $b$. At the AI limit, the dynamics reduces to\na subshift of finite type. There is a one-to-one correspondence between\nsequences allowed by the subshift and the AI orbits. The theory of\nanti-integrability says that each AI orbit can be continued to becoming a\ngenuine orbit of the H\\'{e}non map for $a$ sufficiently large (and fixed\nJacobian).\n  In this paper, we assume $b$ is a smooth function of $a$ and show that the\ntheory can be extended to investigating the limit $\\lim_{a\\to\\infty}\nb/\\sqrt{a}=\\hat{r}$ for any $\\hat{r}>0$ provided that the one dimensional\nquadratic map $x\\mapsto \\displaystyle\\frac{1}{\\hat{r}}(1-x^2)$ is hyperbolic.",
    "pdf_url": "http://arxiv.org/pdf/2505.15346v1",
    "published": "2025-05-21T10:20:18+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15345v2",
    "title": "Hadamax Encoding: Elevating Performance in Model-Free Atari",
    "authors": [
      "Jacob E. Kooi",
      "Zhao Yang",
      "Vincent Fran√ßois-Lavet"
    ],
    "abstract": "Neural network architectures have a large impact in machine learning. In\nreinforcement learning, network architectures have remained notably simple, as\nchanges often lead to small gains in performance. This work introduces a novel\nencoder architecture for pixel-based model-free reinforcement learning. The\nHadamax (\\textbf{Hada}mard \\textbf{max}-pooling) encoder achieves\nstate-of-the-art performance by max-pooling Hadamard products between\nGELU-activated parallel hidden layers. Based on the recent PQN algorithm, the\nHadamax encoder achieves state-of-the-art model-free performance in the\nAtari-57 benchmark. Specifically, without applying any algorithmic\nhyperparameter modifications, Hadamax-PQN achieves an 80\\% performance gain\nover vanilla PQN and significantly surpasses Rainbow-DQN. For reproducibility,\nthe full code is available on\n\\href{https://github.com/Jacobkooi/Hadamax}{GitHub}.",
    "pdf_url": "http://arxiv.org/pdf/2505.15345v2",
    "published": "2025-05-21T10:19:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15344v1",
    "title": "Alpay Algebra: A Universal Structural Foundation",
    "authors": [
      "Faruk Alpay"
    ],
    "abstract": "Alpay Algebra is introduced as a universal, category-theoretic framework that\nunifies classical algebraic structures with modern needs in symbolic recursion\nand explainable AI. Starting from a minimal list of axioms, we model each\nalgebra as an object in a small cartesian closed category $\\mathcal{A}$ and\ndefine a transfinite evolution functor $\\phi\\colon\\mathcal{A}\\to\\mathcal{A}$.\nWe prove that the fixed point $\\phi^{\\infty}$ exists for every initial object\nand satisfies an internal universal property that recovers familiar constructs\n-- limits, colimits, adjunctions -- while extending them to ordinal-indexed\nfolds. A sequence of theorems establishes (i) soundness and conservativity over\nstandard universal algebra, (ii) convergence of $\\phi$-iterates under regular\ncardinals, and (iii) an explanatory correspondence between $\\phi^{\\infty}$ and\nminimal sufficient statistics in information-theoretic AI models. We conclude\nby outlining computational applications: type-safe functional languages,\ncategorical model checking, and signal-level reasoning engines that leverage\nAlpay Algebra's structural invariants. All proofs are self-contained; no\nexternal set-theoretic axioms beyond ZFC are required. This exposition\npositions Alpay Algebra as a bridge between foundational mathematics and\nhigh-impact AI systems, and provides a reference for further work in category\ntheory, transfinite fixed-point analysis, and symbolic computation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15344v1",
    "published": "2025-05-21T10:18:49+00:00",
    "categories": [
      "math.GM",
      "18B99, 68T27",
      "F.4.1; I.2.3"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15343v1",
    "title": "Subgap pumping of antiferromagnetic Mott insulators: photoexcitation mechanisms and applications",
    "authors": [
      "Radu Andrei",
      "Mingyao Guo",
      "Mustafa Ali",
      "Hoon Kim",
      "Richard D. Averitt",
      "David Hsieh",
      "Eugene Demler"
    ],
    "abstract": "We study the behavior of the 2D repulsive Hubbard model on a square lattice\nat half filling, under strong driving with ac electric fields, by employing a\ntime-dependent Gaussian variational approach. Within the same theoretical\nframework, we analytically obtain the conventional Keldysh crossover between\nmultiphoton and tunneling photoexcitation mechanisms, as well as two new\nregimes beyond the Keldysh paradigm. We discuss how dynamical renormalization\nof the Mott-Hubbard gap feeds back into the photoexcitation process, modulating\nthe carrier generation rate in real time. The momentum distribution of\nquasiparticle excitations immediately after the drive is calculated, and shown\nto contain valuable information about the generation mechanism. Finally, we\ndiscuss experimental probing of the pump-induced nonequilibrium electronic\nstate.",
    "pdf_url": "http://arxiv.org/pdf/2505.15343v1",
    "published": "2025-05-21T10:16:21+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.15342v1",
    "title": "Policy Testing in Markov Decision Processes",
    "authors": [
      "Kaito Ariu",
      "Po-An Wang",
      "Alexandre Proutiere",
      "Kenshi Abe"
    ],
    "abstract": "We study the policy testing problem in discounted Markov decision processes\n(MDPs) under the fixed-confidence setting. The goal is to determine whether the\nvalue of a given policy exceeds a specified threshold while minimizing the\nnumber of observations. We begin by deriving an instance-specific lower bound\nthat any algorithm must satisfy. This lower bound is characterized as the\nsolution to an optimization problem with non-convex constraints. We propose a\npolicy testing algorithm inspired by this optimization problem--a common\napproach in pure exploration problems such as best-arm identification, where\nasymptotically optimal algorithms often stem from such optimization-based\ncharacterizations. As for other pure exploration tasks in MDPs, however, the\nnon-convex constraints in the lower-bound problem present significant\nchallenges, raising doubts about whether statistically optimal and\ncomputationally tractable algorithms can be designed. To address this, we\nreformulate the lower-bound problem by interchanging the roles of the objective\nand the constraints, yielding an alternative problem with a non-convex\nobjective but convex constraints. Strikingly, this reformulated problem admits\nan interpretation as a policy optimization task in a newly constructed reversed\nMDP. Leveraging recent advances in policy gradient methods, we efficiently\nsolve this problem and use it to design a policy testing algorithm that is\nstatistically optimal--matching the instance-specific lower bound on sample\ncomplexity--while remaining computationally tractable. We validate our approach\nwith numerical experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15342v1",
    "published": "2025-05-21T10:13:54+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15341v1",
    "title": "High-Throughput Mechanical Characterization of Giant Unilamellar Vesicles by Real-Time Deformability Cytometry",
    "authors": [
      "Maximilian Kloppe",
      "Stefan J. Maurer",
      "Tobias Abele",
      "Kerstin G√∂pfrich",
      "Sebastian Aland"
    ],
    "abstract": "Real-time deformability cytometry (RT-DC) enables high-throughput,\ncontact-free mechanical characterization of giant unilamellar vesicles (GUVs).\nHowever, the interpretation of vesicle deformation under flow has been hindered\nby the absence of a suitable theoretical or computational framework. Here, we\npresent a simulation-based model that describes GUV deformation in RT-DC,\ntaking into account the surface dilational elastic modulus as the dominant\nmechanical parameter. Using phase-field simulations over a wide parameter\nspace, we find GUV deformation to depend linearly on GUV area.\n  Based on these results, we derive two complementary fitting strategies for\nextracting the surface dilational modulus K from RT-DC data: a direct\nmodel-based fit for single-vesicle characterization and a noise-resistant\ncollective approach that enables robust population-level estimates.\nFurthermore, we introduce a combined fitting method that integrates both\napproaches to filter outliers and improve accuracy in heterogeneous or noisy\ndatasets. All methods scale across varying flow rates, channel geometries and\nbuffer viscosities, and produce predictions of K consistent with literature\nvalues for different lipid compositions. Compared to traditional techniques\nsuch as micropipette aspiration, our approach offers orders of magnitude higher\nthroughput without mechanical contact, making it particularly suitable for GUV\npopulation studies. Beyond mechanical phenotyping, this framework opens new\navenues for sorting vesicle populations based on membrane mechanics, a\ncapability of growing interest in synthetic biology and soft matter research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15341v1",
    "published": "2025-05-21T10:13:53+00:00",
    "categories": [
      "physics.bio-ph",
      "cond-mat.soft"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15340v1",
    "title": "SSR: Speculative Parallel Scaling Reasoning in Test-time",
    "authors": [
      "Yuanlin Chu",
      "Bo Wang",
      "Xiang Liu",
      "Hong Chen",
      "Aiwei Liu",
      "Xuming Hu"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive results on multi-step\nmathematical reasoning, yet at the cost of high computational overhead. This\nchallenge is particularly acute for test-time scaling methods such as parallel\ndecoding, which increase answer diversity but scale poorly in efficiency. To\naddress this efficiency-accuracy trade-off, we propose SSR (Speculative\nParallel Scaling Reasoning), a training-free framework that leverages a key\ninsight: by introducing speculative decoding at the step level, we can\naccelerate reasoning without sacrificing correctness. SSR integrates two\ncomponents: a Selective Parallel Module (SPM) that identifies a small set of\npromising reasoning strategies via model-internal scoring, and Step-level\nSpeculative Decoding (SSD), which enables efficient draft-target collaboration\nfor fine-grained reasoning acceleration. Experiments on three mathematical\nbenchmarks-AIME 2024, MATH-500, and LiveMathBench - demonstrate that SSR\nachieves strong gains over baselines. For instance, on LiveMathBench, SSR\nimproves pass@1 accuracy by 13.84% while reducing computation to 80.5% of the\nbaseline FLOPs. On MATH-500, SSR reduces compute to only 30% with no loss in\naccuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.15340v1",
    "published": "2025-05-21T10:12:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15339v1",
    "title": "Evolution of broad emission lines from double-peaked to single-peaked to support a central tidal disruption event",
    "authors": [
      "Zhang XueGuang"
    ],
    "abstract": "In this manuscript, considering evolution of fallback accreting debris in a\ncentral Tidal Disruption Event (TDE), the outer boundary increased with time of\nthe disk-like broad emission line regions (BLRs) lying into central accretion\ndisk will lead expected broad emission lines changed from double-peaked to\nsingle-peaked. Considering common elliptical orbitals for the accreting\nfallback TDEs debris, based on simulated results through the preferred standard\nelliptical accretion disk model, a probability about 3.95\\% can be estimated\nfor cases with double-peaked profile changed to single-peaked profile in\nmulti-epoch broad emission lines, indicating such unique profile variability\ncould be indicator for BLRs related to TDE debris. Meanwhile, among the\nreported optical TDE candidates with apparent broad lines, such profile changes\nin broad H$\\alpha$ can be found in the AT 2018hyz. After accepted the outer\nboundaries of the disk-like BLRs increased with time, the observed multi-epoch\nbroad H$\\alpha$ can be described in AT 2018hyz. Moreover, the elliptical\naccretion disk model determined time dependent ratios of the outer boundaries\nof the disk-like BLRs are well consistent with the TDE model expected ratios of\nthe outer boundaries of the fallback TDE debris. Furthermore, the evolution\nproperties of disk-like BLRs can be applied to estimate the locations of the\ndisk-like BLRs of which outer boundary could be about one sixth of the outer\nboundary of the fallback TDE debris in AT 2018hyz. Such unique profile changes\nfrom double-peaked to single-peaked could be applied as further clues to\nsupport a central TDE.",
    "pdf_url": "http://arxiv.org/pdf/2505.15339v1",
    "published": "2025-05-21T10:12:27+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15338v1",
    "title": "Liquidity provision with $œÑ$-reset strategies: a dynamic historical liquidity approach",
    "authors": [
      "Andrey Urusov",
      "Rostislav Berezovskiy",
      "Anatoly Krestenko",
      "Andrei Kornilov"
    ],
    "abstract": "Since the launch of Uniswap and other AMM protocols, the DeFi industry has\nevolved from simple constant product functions with uniform liquidity\ndistribution across the entire price axis to more advanced mechanisms that\nallow Liquidity Providers (LPs) to concentrate capital within selected price\nranges. This evolution has introduced new research challenges focused on\noptimizing capital allocation in Decentralized Exchanges (DEXs) under dynamic\nmarket conditions. In this paper, we present a methodology for finding optimal\nliquidity provision strategies in DEXs within a specific family of $\\tau$-reset\nstrategies. The approach is detailed step by step and includes an original\nmethod for approximating historical liquidity within active pool ranges using a\nparametric model that does not rely on historical liquidity data. We find\noptimal LP strategies using a machine learning approach, evaluate performance\nover an out-of-time period, and compare the resulting strategies against a\nuniform benchmark. All experiments were conducted using a custom backtesting\nframework specifically developed for Concentrated Liquidity Market Makers\n(CLMMs). The effectiveness and flexibility of the proposed methodology are\ndemonstrated across various Uniswap v3 trading pairs, and also benchmarked\nagainst an alternative backtesting and strategy development tool.",
    "pdf_url": "http://arxiv.org/pdf/2505.15338v1",
    "published": "2025-05-21T10:09:29+00:00",
    "categories": [
      "q-fin.MF"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2505.15337v3",
    "title": "Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors",
    "authors": [
      "Hao Fang",
      "Jiawei Kong",
      "Tianqu Zhuang",
      "Yixiang Qiu",
      "Kuofeng Gao",
      "Bin Chen",
      "Shu-Tao Xia",
      "Yaowei Wang",
      "Min Zhang"
    ],
    "abstract": "The misuse of large language models (LLMs), such as academic plagiarism, has\ndriven the development of detectors to identify LLM-generated texts. To bypass\nthese detectors, paraphrase attacks have emerged to purposely rewrite these\ntexts to evade detection. Despite the success, existing methods require\nsubstantial data and computational budgets to train a specialized paraphraser,\nand their attack efficacy greatly reduces when faced with advanced detection\nalgorithms. To address this, we propose \\textbf{Co}ntrastive\n\\textbf{P}araphrase \\textbf{A}ttack (CoPA), a training-free method that\neffectively deceives text detectors using off-the-shelf LLMs. The first step is\nto carefully craft instructions that encourage LLMs to produce more human-like\ntexts. Nonetheless, we observe that the inherent statistical biases of LLMs can\nstill result in some generated texts carrying certain machine-like attributes\nthat can be captured by detectors. To overcome this, CoPA constructs an\nauxiliary machine-like word distribution as a contrast to the human-like\ndistribution generated by the LLM. By subtracting the machine-like patterns\nfrom the human-like distribution during the decoding process, CoPA is able to\nproduce sentences that are less discernible by text detectors. Our theoretical\nanalysis suggests the superiority of the proposed attack. Extensive experiments\nvalidate the effectiveness of CoPA in fooling text detectors across various\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.15337v3",
    "published": "2025-05-21T10:08:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15336v1",
    "title": "My Face Is Mine, Not Yours: Facial Protection Against Diffusion Model Face Swapping",
    "authors": [
      "Hon Ming Yam",
      "Zhongliang Guo",
      "Chun Pong Lau"
    ],
    "abstract": "The proliferation of diffusion-based deepfake technologies poses significant\nrisks for unauthorized and unethical facial image manipulation. While\ntraditional countermeasures have primarily focused on passive detection\nmethods, this paper introduces a novel proactive defense strategy through\nadversarial attacks that preemptively protect facial images from being\nexploited by diffusion-based deepfake systems. Existing adversarial protection\nmethods predominantly target conventional generative architectures (GANs, AEs,\nVAEs) and fail to address the unique challenges presented by diffusion models,\nwhich have become the predominant framework for high-quality facial deepfakes.\nCurrent diffusion-specific adversarial approaches are limited by their reliance\non specific model architectures and weights, rendering them ineffective against\nthe diverse landscape of diffusion-based deepfake implementations.\nAdditionally, they typically employ global perturbation strategies that\ninadequately address the region-specific nature of facial manipulation in\ndeepfakes.",
    "pdf_url": "http://arxiv.org/pdf/2505.15336v1",
    "published": "2025-05-21T10:07:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15335v1",
    "title": "A Note on Spinning Billiards and Chaos",
    "authors": [
      "Jacob S. Lund",
      "Jeff Murugan",
      "Jonathan P. Shock"
    ],
    "abstract": "We investigate the impact of internal degrees of freedom - specifically spin\n- on the classical dynamics of billiard systems. While traditional studies\nmodel billiards as point particles undergoing specular reflection, we extend\nthe paradigm by incorporating finite-size effects and angular momentum,\nintroducing a dimensionless spin parameter $\\alpha$ that characterizes the\nmoment of inertia. Using numerical simulations across circular, rectangular,\nstadium, and Sinai geometries, we analyze the resulting trajectories and\nquantify chaos via the leading Lyapunov exponent. Strikingly, we find that spin\nregularizes the dynamics even in geometries that are classically chaotic: for a\nwide range of $\\alpha$, the Lyapunov exponent vanishes at late times in the\nstadium and Sinai tables, signaling suppression of chaos. This effect is\ncorroborated by phase space analysis showing non-exponential divergence of\nnearby trajectories. Our results suggest that internal structure can\nqualitatively alter the dynamical landscape of a system, potentially serving as\na mechanism for chaos suppression in broader contexts.",
    "pdf_url": "http://arxiv.org/pdf/2505.15335v1",
    "published": "2025-05-21T10:06:00+00:00",
    "categories": [
      "nlin.CD",
      "hep-th"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15334v1",
    "title": "Parameter-Efficient Fine-Tuning of Multispectral Foundation Models for Hyperspectral Image Classification",
    "authors": [
      "Bernardin Ligan",
      "Khalide Jbilou",
      "Fahd Kalloubi",
      "Ahmed Ratnani"
    ],
    "abstract": "Foundation models have achieved great success across diverse domains,\nincluding remote sensing (RS), thanks to their versatility and strong\ngeneralization abilities. However, most RS foundation models are designed for\nmultispectral data, while hyperspectral imagery (HSI) - with its hundreds of\nspectral bands - remains less explored. Fine-tuning such models for downstream\ntasks is also challenging, often demanding considerable memory and storage. In\nthis paper, we propose an efficient framework to fine-tune SpectralGPT, a\nmultispectral foundation model, for hyperspectral image classification (HSIC).\nWe explore several Parameter-Efficient Fine-Tuning (PEFT) methods, including\nLow-Rank Adaptation (LoRA), Kronecker-based adaptation (KronA), Low-Rank\nKronecker (LoKr), and the recent LoRA+, which uses distinct learning rates for\nlow-rank adapters scaled by a factor lambda. Inspired by LoRA+, we introduce\nKronA+, which applies a similar mechanism to the Kronecker matrices. We\nevaluate our approach on five datasets from different sensors, showing\ncompetitive performance with state-of-the-art HSI models. Our full fine-tuning\n(FFT) setup for SpectralGPT even outperforms a dedicated hyperspectral\nfoundation model on some datasets while requiring only a quarter of the\ntraining epochs. Under the same number of epochs, KronA+ reaches similar\nperformance with far fewer trainable parameters - just 0.056 percent - and adds\nonly approximately 0.2 megabytes of storage, making it the most effective PEFT\nmethod tested.",
    "pdf_url": "http://arxiv.org/pdf/2505.15334v1",
    "published": "2025-05-21T10:05:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15333v1",
    "title": "Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation",
    "authors": [
      "Yuhao Zhang",
      "Xiangnan Ma",
      "Kaiqi Kou",
      "Peizhuo Liu",
      "Weiqiao Shan",
      "Benyou Wang",
      "Tong Xiao",
      "Yuxin Huang",
      "Zhengtao Yu",
      "Jingbo Zhu"
    ],
    "abstract": "The success of building textless speech-to-speech translation (S2ST) models\nhas attracted much attention. However, S2ST still faces two main challenges: 1)\nextracting linguistic features for various speech signals, called cross-modal\n(CM), and 2) learning alignment of difference languages in long sequences,\ncalled cross-lingual (CL). We propose the unit language to overcome the two\nmodeling challenges. The unit language can be considered a text-like\nrepresentation format, constructed using $n$-gram language modeling. We\nimplement multi-task learning to utilize the unit language in guiding the\nspeech modeling process. Our initial results reveal a conflict when applying\nsource and target unit languages simultaneously. We propose task prompt\nmodeling to mitigate this conflict. We conduct experiments on four languages of\nthe Voxpupil dataset. Our method demonstrates significant improvements over a\nstrong baseline and achieves performance comparable to models trained with\ntext.",
    "pdf_url": "http://arxiv.org/pdf/2505.15333v1",
    "published": "2025-05-21T10:05:25+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15332v1",
    "title": "Towards Zero-Shot Differential Morphing Attack Detection with Multimodal Large Language Models",
    "authors": [
      "Ria Shekhawat",
      "Hailin Li",
      "Raghavendra Ramachandra",
      "Sushma Venkatesh"
    ],
    "abstract": "Leveraging the power of multimodal large language models (LLMs) offers a\npromising approach to enhancing the accuracy and interpretability of morphing\nattack detection (MAD), especially in real-world biometric applications. This\nwork introduces the use of LLMs for differential morphing attack detection\n(D-MAD). To the best of our knowledge, this is the first study to employ\nmultimodal LLMs to D-MAD using real biometric data. To effectively utilize\nthese models, we design Chain-of-Thought (CoT)-based prompts to reduce\nfailure-to-answer rates and enhance the reasoning behind decisions. Our\ncontributions include: (1) the first application of multimodal LLMs for D-MAD\nusing real data subjects, (2) CoT-based prompt engineering to improve response\nreliability and explainability, (3) comprehensive qualitative and quantitative\nbenchmarking of LLM performance using data from 54 individuals captured in\npassport enrollment scenarios, and (4) comparative analysis of two multimodal\nLLMs: ChatGPT-4o and Gemini providing insights into their morphing attack\ndetection accuracy and decision transparency. Experimental results show that\nChatGPT-4o outperforms Gemini in detection accuracy, especially against\nGAN-based morphs, though both models struggle under challenging conditions.\nWhile Gemini offers more consistent explanations, ChatGPT-4o is more resilient\nbut prone to a higher failure-to-answer rate.",
    "pdf_url": "http://arxiv.org/pdf/2505.15332v1",
    "published": "2025-05-21T10:05:19+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15331v1",
    "title": "Impact of Distance on Epidemiological Dynamics in Human Connection Network with Mobility",
    "authors": [
      "Md. Arquam",
      "Suchi Kumari",
      "Utkarsh Tiwari",
      "Mohammad Al-saffar"
    ],
    "abstract": "The spread of infectious diseases is often influenced by human mobility\nacross different geographical regions. Although numerous studies have\ninvestigated how diseases like SARS and COVID-19 spread from China to various\nglobal locations, there remains a gap in understanding how the movement of\nindividuals contributes to disease transmission on a more personal or\nhuman-to-human level. Typically, researchers have employed the concept of\nmetapopulation movement to analyze how diseases move from one location to\nanother. This paper shifts focus to the dynamics of disease transmission,\nincorporating the critical factor of distance between an infected person and a\nhealthy individual during human movement. The study delves into the impact of\ndistance on various parameters of epidemiological dynamics throughout human\nmobility. Mathematical expressions for important epidemiological metrics, such\nas the basic reproduction number ($R_0$) and the critical infection rate\n($\\beta_{critical}$), are derived in relation to the distance between\nindividuals. The results indicate that the proposed model closely aligns with\nobserved patterns of COVID-19 spread based on the analysis done on the\navailable datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.15331v1",
    "published": "2025-05-21T10:04:38+00:00",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15330v1",
    "title": "Zeros of linear combinations of Hermite polynomials",
    "authors": [
      "Antonio J. Dur√°n"
    ],
    "abstract": "We study the number of real zeros of finite combinations of $K+1$ consecutive\nnormalized Hermite polynomials of the form $$ q_n(x)=\\sum_{j=0}^K\\gamma_j\\tilde\nH_{n-j}(x),\\quad n\\ge K, $$ where $\\gamma_j$, $j=0,\\dots ,K$, are real numbers\nwith $\\gamma_0=1$, $\\gamma_K\\not =0$. We consider two different normalizations\nof Hermite polynomials: the standard one (i.e. $\\tilde H_n=H_n$), and $\\tilde\nH_n=H_n/(2^nn!)$ (so that $q_n$ are Appell polynomials: $q_n'=q_{n-1}$). In\nboth cases, we show the key role played by the polynomial\n$P(x)=\\sum_{j=0}^K\\gamma_jx^{K-j}$ to solve this problem. In particular, if all\nthe zeros of $P$ are real then all the zeros of $q_n$, $n\\ge K$, are also real.",
    "pdf_url": "http://arxiv.org/pdf/2505.15330v1",
    "published": "2025-05-21T10:04:08+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15329v2",
    "title": "Fourier-Invertible Neural Encoder (FINE) for Homogeneous Flows",
    "authors": [
      "Anqiao Ouyang",
      "Hongyi Ke",
      "Qi Wang"
    ],
    "abstract": "Invertible neural architectures have recently attracted attention for their\ncompactness, interpretability, and information-preserving properties. In this\nwork, we propose the Fourier-Invertible Neural Encoder (FINE), which combines\ninvertible monotonic activation functions with reversible filter structures,\nand could be extended using Invertible ResNets. This architecture is examined\nin learning low-dimensional representations of one-dimensional nonlinear wave\ninteractions and exact circular translation symmetry. Dimensionality is\npreserved across layers, except for a Fourier truncation step in the latent\nspace, which enables dimensionality reduction while maintaining shift\nequivariance and interpretability. Our results demonstrate that FINE\nsignificantly outperforms classical linear methods such as Discrete Fourier\nTransformation (DFT) and Proper Orthogonal Decomposition (POD), and achieves\nreconstruction accuracy better than conventional deep autoencoders with\nconvolutional layers (CNN) - while using substantially smaller models and\noffering superior physical interpretability. These findings suggest that\ninvertible single-neuron networks, when combined with spectral truncation,\noffer a promising framework for learning compact and interpretable\nrepresentations of physics datasets, and symmetry-aware representation learning\nin physics-informed machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15329v2",
    "published": "2025-05-21T10:02:59+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15328v3",
    "title": "A covariate-adaptive test for replicability across multiple studies with false discovery rate control",
    "authors": [
      "Ninh Tran",
      "Dennis Leung"
    ],
    "abstract": "Replicability is a lynchpin for credible discoveries. The partial conjunction\n(PC) p-value, which combines individual base p-values from multiple similar\nstudies, can gauge whether a feature of interest exhibits replicated signals\nacross studies. However, when a large set of features are examined as in\nhigh-throughput experiments, testing for their replicated signals\nsimultaneously can pose a very underpowered problem, due to both the\nmultiplicity burden and inherent limitations of PC $p$-values. This power\ndeficiency is markedly severe when replication is demanded for all studies\nunder consideration, which is nonetheless the most natural and appealing\nbenchmark for scientific generalizability a practitioner may request.\n  We propose ParFilter, a general framework that marries the ideas of filtering\nand covariate-adaptiveness to power up large-scale testing for replicated\nsignals as described above. It reduces the multiplicity burden by partitioning\nstudies into smaller groups and borrowing the cross-group information to filter\nout unpromising features. Moreover, harnessing side information offered by\nauxiliary covariates whenever they are available, it can train informative\nhypothesis weights to encourage rejections of features more likely to exhibit\nreplicated signals. We prove its finite-sample control on the false discovery\nrate, under both independence and arbitrary dependence among the base\n$p$-values across features. In simulations as well as a real case study on\nautoimmunity based on RNA-Seq data obtained from thymic cells, the ParFilter\nhas demonstrated competitive performance against other existing methods for\nsuch replicability analyses.",
    "pdf_url": "http://arxiv.org/pdf/2505.15328v3",
    "published": "2025-05-21T10:02:35+00:00",
    "categories": [
      "stat.ME",
      "62F03"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15327v2",
    "title": "Let's Take Esoteric Programming Languages Seriously",
    "authors": [
      "Jeremy Singer",
      "Steve Draper"
    ],
    "abstract": "Esoteric programming languages are challenging to learn, but their unusual\nfeatures and constraints may serve to improve programming ability. From\nlanguages designed to be intentionally obtuse (e.g. INTERCAL) to others\ntargeting artistic expression (e.g. Piet) or exploring the nature of\ncomputation (e.g. Fractan), there is rich variety in the realm of esoteric\nprogramming languages. This essay examines the counterintuitive appeal of\nesoteric languages and seeks to analyse reasons for this popularity. We will\nexplore why people are attracted to esoteric languages in terms of (a) program\ncomprehension and construction, as well as (b) language design and\nimplementation. Our assertion is that esoteric languages can improve general PL\nawareness, at the same time as enabling the esoteric programmer to impress\ntheir peers with obscure knowledge. We will also consider pedagogic principles\nand the use of AI, in relation to esoteric languages. Emerging from the\nspecific discussion, we identify a general set of 'good' reasons for designing\nnew programming languages. It may not be possible to be exhaustive on this\ntopic, and it is certain we have not achieved that goal here. However we\nbelieve our most important contribution is to draw attention to the varied and\noften implicit motivations involved in programming language design.",
    "pdf_url": "http://arxiv.org/pdf/2505.15327v2",
    "published": "2025-05-21T10:02:07+00:00",
    "categories": [
      "cs.PL",
      "D.3.0"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15326v1",
    "title": "Extreme Fluctuations in the Sun's Activity over the Modern Maximum: Understanding the Enigmatic Solar Cycles 19-20",
    "authors": [
      "Shaonwita Pal",
      "Dibyendu Nandy"
    ],
    "abstract": "Over the past century, the Sun's activity -- which exhibits significant\nvariations -- went through a phase known as the Modern Maximum. Notably, the\nstrongest sunspot cycle on record during this period, and indeed since direct\nsunspot observations began, was cycle 19; this was followed by a significantly\nweaker cycle 20. Understanding and reconstructing this extreme variability has\nremained elusive. Utilizing data-driven, coupled models of magnetic field\nevolution on the Sun's surface and within its convection zone, here we show\nthat random deviations in the tilt angle and polarity orientation of bipolar\nsunspot pairs is sufficient to explain these observed, extreme fluctuations\nduring the modern maximum in solar activity. Our results support the theory\nthat perturbation in the poloidal field source of the dynamo mechanism --\nmediated via the emergence of anomalously tilted solar active regions - is the\nprimary driver of extreme variations in the Sun's activity. This study has\nimplications for understanding how the Sun may switch from a phase of extreme\nactivity to quiescent, low activity phases -- such as the Maunder Minimum.",
    "pdf_url": "http://arxiv.org/pdf/2505.15326v1",
    "published": "2025-05-21T10:01:57+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15325v2",
    "title": "SoftHGNN: Soft Hypergraph Neural Networks for General Visual Recognition",
    "authors": [
      "Mengqi Lei",
      "Yihong Wu",
      "Siqi Li",
      "Xinhu Zheng",
      "Juan Wang",
      "Yue Gao",
      "Shaoyi Du"
    ],
    "abstract": "Visual recognition relies on understanding both the semantics of image tokens\nand the complex interactions among them. Mainstream self-attention methods,\nwhile effective at modeling global pair-wise relations, fail to capture\nhigh-order associations inherent in real-world scenes and often suffer from\nredundant computation. Hypergraphs extend conventional graphs by modeling\nhigh-order interactions and offer a promising framework for addressing these\nlimitations. However, existing hypergraph neural networks typically rely on\nstatic and hard hyperedge assignments, leading to excessive and redundant\nhyperedges with hard binary vertex memberships that overlook the continuity of\nvisual semantics. To overcome these issues, we present Soft Hypergraph Neural\nNetworks (SoftHGNNs), which extend the methodology of hypergraph computation,\nto make it truly efficient and versatile in visual recognition tasks. Our\nframework introduces the concept of soft hyperedges, where each vertex is\nassociated with hyperedges via continuous participation weights rather than\nhard binary assignments. This dynamic and differentiable association is\nachieved by using the learnable hyperedge prototype. Through similarity\nmeasurements between token features and the prototype, the model generates\nsemantically rich soft hyperedges. SoftHGNN then aggregates messages over soft\nhyperedges to capture high-order semantics. To further enhance efficiency when\nscaling up the number of soft hyperedges, we incorporate a sparse hyperedge\nselection mechanism that activates only the top-k important hyperedges, along\nwith a load-balancing regularizer to ensure balanced hyperedge utilization.\nExperimental results across three tasks on five datasets demonstrate that\nSoftHGNN efficiently captures high-order associations in visual scenes,\nachieving significant performance improvements.",
    "pdf_url": "http://arxiv.org/pdf/2505.15325v2",
    "published": "2025-05-21T10:01:30+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15324v1",
    "title": "Improved Approximation Algorithms for Path and Forest Augmentation via a Novel Relaxation",
    "authors": [
      "Felix Hommelsheim"
    ],
    "abstract": "The Forest Augmentation Problem (FAP) asks for a minimum set of additional\nedges (links) that make a given forest 2-edge-connected while spanning all\nvertices. A key special case is the Path Augmentation Problem (PAP), where the\ninput forest consists of vertex-disjoint paths. Grandoni, Jabal Ameli, and\nTraub [STOC'22] recently broke the long-standing 2-approximation barrier for\nFAP, achieving a 1.9973-approximation. A crucial component of this result was\ntheir 1.9913-approximation for PAP; the first better-than-2 approximation for\nPAP. In this work, we improve these results and provide a 1.9412-approximation\nfor PAP, which implies a 1.9955-approximation for FAP. One of our key\ninnovations is a $(\\frac{7}{4} + \\varepsilon)$-approximation preserving\nreduction to so-called structured instances, which simplifies the problem and\nenables our improved approximation. Additionally, we introduce a new relaxation\ninspired by 2-edge covers and analyze it via a corresponding packing problem,\nwhere the relationship between the two problems is similar to the relationship\nbetween 2-edge covers and 2-matchings. Using a factor-revealing LP, we bound\nthe cost of our solution to the packing problem w.r.t. the relaxation and\nderive a strong initial solution. We then transform this solution into a\nfeasible PAP solution, combining techniques from FAP and related connectivity\naugmentation problems, along with new insights. A key aspect of our approach is\nleveraging the properties of structured PAP instances to achieve our final\napproximation guarantee. Our reduction framework and relaxation may be of\nindependent interest in future work on connectivity augmentation problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15324v1",
    "published": "2025-05-21T10:00:02+00:00",
    "categories": [
      "cs.DS",
      "68W25 (Primary), 68W40, 68R10, 05C40, 05C85 (Secondary)",
      "F.2.2"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15864v1",
    "title": "Ambient-pressure superconductivity onset at 10 K and robust Tc under high pressure in TiNbTaN3 medium-entropy nitride",
    "authors": [
      "Lingyong Zeng",
      "Jie Wang",
      "Hongyu Liu",
      "Longfu Li",
      "Jinjun Qin",
      "Yucheng Li",
      "Rui Chen",
      "Jing Song",
      "Yusheng Hou",
      "Huixia Luo"
    ],
    "abstract": "Superconductivity has been one of the focal points in medium and high-entropy\nalloys (MEAs-HEAs) since the first discovery of the HEA superconductor in 2014.\nUntil now, most HEAs' superconducting transition temperature (Tc) has not\nexceeded 10 K. Here we report the first observation of superconductivity in a\nbulk medium-entropy nitride (MEN), TiNbTaN3, which shows a Tc of 10 K at\nambient pressure. Notably, the electronic specific heat coefficient {\\gamma}(H)\nexhibits nonlinear H-dependence behavior, which is similar to other\nwell-studied multigap superconductors. Furthermore, TiNbTaN3 exhibits\nextraordinary pressure resilience, maintaining robust superconductivity under\nhigh-pressure conditions. Density functional theory (DFT) calculations indicate\nthat pressure exerts a negligible impact on the electronic structures of\nTiNbTaN3, thereby corroborating the experimental observations. These findings\nnot only advance our understanding of emergent phenomena in entropy-stabilized\nnitrides but also establish a new material platform for finding more high-Tc\nsuperconductors with combinations of 4d/5d transition metal elements and light\nelements, motivating further investigations into high-entropy functional\nceramics for extreme environment applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15864v1",
    "published": "2025-05-21T09:59:10+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.15323v1",
    "title": "Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack",
    "authors": [
      "Silvia Cappelletti",
      "Tobia Poppi",
      "Samuele Poppi",
      "Zheng-Xin Yong",
      "Diego Garcia-Olano",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly evaluated on multiple-choice\nquestion answering (MCQA) tasks using *first-token probability* (FTP), which\nselects the answer option whose initial token has the highest likelihood. While\nefficient, FTP can be fragile: models may assign high probability to unrelated\ntokens (*misalignment*) or use a valid token merely as part of a generic\npreamble rather than as a clear answer choice (*misinterpretation*),\nundermining the reliability of symbolic evaluation. We propose a simple\nsolution: the *prefilling attack*, a structured natural-language prefix (e.g.,\n\"*The correct option is:*\") prepended to the model output. Originally explored\nin AI safety, we repurpose prefilling to steer the model to respond with a\nclean, valid option, without modifying its parameters. Empirically, the FTP\nwith prefilling strategy substantially improves accuracy, calibration, and\noutput consistency across a broad set of LLMs and MCQA benchmarks. It\noutperforms standard FTP and often matches the performance of open-ended\ngeneration approaches that require full decoding and external classifiers,\nwhile being significantly more efficient. Our findings suggest that prefilling\nis a simple, robust, and low-cost method to enhance the reliability of\nFTP-based evaluation in multiple-choice settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.15323v1",
    "published": "2025-05-21T09:58:38+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15322v1",
    "title": "CEBSNet: Change-Excited and Background-Suppressed Network with Temporal Dependency Modeling for Bitemporal Change Detection",
    "authors": [
      "Qi'ao Xu",
      "Yan Xing",
      "Jiali Hu",
      "Yunan Jia",
      "Rui Huang"
    ],
    "abstract": "Change detection, a critical task in remote sensing and computer vision, aims\nto identify pixel-level differences between image pairs captured at the same\ngeographic area but different times. It faces numerous challenges such as\nillumination variation, seasonal changes, background interference, and shooting\nangles, especially with a large time gap between images. While current methods\nhave advanced, they often overlook temporal dependencies and overemphasize\nprominent changes while ignoring subtle but equally important changes. To\naddress these limitations, we introduce \\textbf{CEBSNet}, a novel\nchange-excited and background-suppressed network with temporal dependency\nmodeling for change detection. During the feature extraction, we utilize a\nsimple Channel Swap Module (CSM) to model temporal dependency, reducing\ndifferences and noise. The Feature Excitation and Suppression Module (FESM) is\ndeveloped to capture both obvious and subtle changes, maintaining the integrity\nof change regions. Additionally, we design a Pyramid-Aware Spatial-Channel\nAttention module (PASCA) to enhance the ability to detect change regions at\ndifferent sizes and focus on critical regions. We conduct extensive experiments\non three common street view datasets and two remote sensing datasets, and our\nmethod achieves the state-of-the-art performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15322v1",
    "published": "2025-05-21T09:57:30+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15321v1",
    "title": "Hereditarily and nonhereditarily complete systems of vectors in a Hilbert space",
    "authors": [
      "Mikhail Prokofyev"
    ],
    "abstract": "In this paper, we study the property of hereditary completeness of vector\nsystems $\\{x_k\\}_{k=1}^\\infty$ in a Hilbert space. A criterion of hereditary\ncompleteness is obtained in terms of projectors on closed linear spans of\nsystems of the form $\\{x_k\\}_{k \\in N}$, $N \\subset \\mathbb{N}$. Developed\ntechnique has been used to prove that mixed systems of a hereditarily complete\nsystem are also hereditarily complete. In conclusion, the problem of possible\ndefects in a nonhereditarily complete system is considered.",
    "pdf_url": "http://arxiv.org/pdf/2505.15321v1",
    "published": "2025-05-21T09:52:32+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15320v1",
    "title": "Analysis of ABC Frontend Audio Systems for the NIST-SRE24",
    "authors": [
      "Sara Barahona",
      "Anna Silnova",
      "Ladislav Mo≈°ner",
      "Junyi Peng",
      "Old≈ôich Plchot",
      "Johan Rohdin",
      "Lin Zhang",
      "Jiangyu Han",
      "Petr Palka",
      "Federico Landini",
      "Luk√°≈° Burget",
      "Themos Stafylakis",
      "Sandro Cumani",
      "Dominik Bobo≈°",
      "Miroslav Hlavaƒçek",
      "Martin Kodovsky",
      "Tom√°≈° Pavl√≠ƒçek"
    ],
    "abstract": "We present a comprehensive analysis of the embedding extractors (frontends)\ndeveloped by the ABC team for the audio track of NIST SRE 2024. We follow the\ntwo scenarios imposed by NIST: using only a provided set of telephone\nrecordings for training (fixed) or adding publicly available data (open\ncondition). Under these constraints, we develop the best possible speaker\nembedding extractors for the pre-dominant conversational telephone speech (CTS)\ndomain. We explored architectures based on ResNet with different pooling\nmechanisms, recently introduced ReDimNet architecture, as well as a system\nbased on the XLS-R model, which represents the family of large pre-trained\nself-supervised models. In open condition, we train on VoxBlink2 dataset,\ncontaining 110 thousand speakers across multiple languages. We observed a good\nperformance and robustness of VoxBlink-trained models, and our experiments show\npractical recipes for developing state-of-the-art frontends for speaker\nrecognition.",
    "pdf_url": "http://arxiv.org/pdf/2505.15320v1",
    "published": "2025-05-21T09:52:27+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15319v1",
    "title": "Thermal emission effect on Chandrasekhar's $H(Œº)$-function for isotropic scattering in semi-infinite atmosphere problem",
    "authors": [
      "Soumya Sengupta",
      "Manika Singla",
      "Fikret Anli"
    ],
    "abstract": "Chandrasekhars $H(\\mu)$-function has long been a cornerstone of radiative\ntransfer theory in semi-infinite, isotropically scattering atmospheres\nsubjected to external illumination. However, this classical formulation does\nnot account for thermal emission arising from internal heat sources, which is\ncritical in a variety of astrophysical contexts such as hot Jupiters, brown\ndwarfs, and irradiated exoplanets, where the re-radiation of absorbed stellar\nenergy significantly alters the emergent intensity. To address this limitation,\nwe extend the diffuse reflection framework to incorporate both isotropic\nscattering and intrinsic thermal emission, leading to a generalized function\nknown as the $M(\\mu)$-function. Building on the formalism of Chandrashekhar\n(1960) combined with the recent work by Sengupta(2021), we derive the governing\nintegral equations for the $M$-function and express it in terms of three key\nphysical parameters: the radiation direction cosine $\\mu$, the thermal emission\ncoefficient $U(T) = B(T)/F$, and the single scattering albedo\n$\\tilde{\\omega}_0$. We implement a numerically stable iterative scheme, using\nGaussian quadrature method to compute high-precision values of $M(\\mu, U,\n\\tilde{\\omega}_0)$ across a broad parameter space. In the zero-emission limit,\nour results recover the classical $H$-function, thus validating the method.We\nprovide comprehensive values of $M$-function for $\\mu \\in [0, 1]$, $U < 0.7$,\nand $\\tilde{\\omega}_0 < 1$, enabling direct application to modeling diffusely\nreflected intensities from thermally emitting atmospheres.As a case study, we\napply this formalism to exoplanet K2-137b and identify the wavelength range\n(0.85 -2.5 $\\mu$m) where the model is most applicable, highlighting its\nrelevance to the observation range of the telescopes JWST, HST, ARIEL.",
    "pdf_url": "http://arxiv.org/pdf/2505.15319v1",
    "published": "2025-05-21T09:49:36+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15318v1",
    "title": "Linear Convergence of Plug-and-Play Algorithms with Kernel Denoisers",
    "authors": [
      "Arghya Sinha",
      "Bhartendu Kumar",
      "Chirayu D. Athalye",
      "Kunal N. Chaudhury"
    ],
    "abstract": "The use of denoisers for image reconstruction has shown significant\npotential, especially for the Plug-and-Play (PnP) framework. In PnP, a powerful\ndenoiser is used as an implicit regularizer in proximal algorithms such as ISTA\nand ADMM. The focus of this work is on the convergence of PnP iterates for\nlinear inverse problems using kernel denoisers. It was shown in prior work that\nthe update operator in standard PnP is contractive for symmetric kernel\ndenoisers under appropriate conditions on the denoiser and the linear forward\noperator. Consequently, we could establish global linear convergence of the\niterates using the contraction mapping theorem. In this work, we develop a\nunified framework to establish global linear convergence for symmetric and\nnonsymmetric kernel denoisers. Additionally, we derive quantitative bounds on\nthe contraction factor (convergence rate) for inpainting, deblurring, and\nsuperresolution. We present numerical results to validate our theoretical\nfindings.",
    "pdf_url": "http://arxiv.org/pdf/2505.15318v1",
    "published": "2025-05-21T09:49:11+00:00",
    "categories": [
      "eess.IV",
      "math.OC",
      "94A08, 41A25, 65F10"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15317v1",
    "title": "Procedure of tuning up a three-site artificial Kitaev chain based on transmon measurements",
    "authors": [
      "Xiaozhou Yang",
      "Zhaozheng Lyu",
      "Xiang Wang",
      "Enna Zhuo",
      "Yunxiao Zhang",
      "Duolin Wang",
      "Yukun Shi",
      "Yuyang Huang",
      "Bing Li",
      "Xiaohui Song",
      "Peiling Li",
      "Bingbing Tong",
      "Ziwei Dou",
      "Jie Shen",
      "Guangtong Liu",
      "Fanming Qu",
      "Li Lu"
    ],
    "abstract": "Artificial Kitaev chains (AKCs), formed of quantum dot-superconductor linear\narrays, provide a promising platform for hosting Majorana bound states (MBSs)\nand implementing topological quantum computing. The main challenges along this\nresearch direction would include the tuning up of AKCs for hosting MBSs and the\nreadout of the parity of the chains. In this work, we present a step-by-step\nprocedure for tuning up a three-site AKC to its sweet spots based on the\nspectra of a transmon circuit which is integrated with the chain for the\npurpose of reading out the parity of the chain. The signatures of the\ntransmon's plasma modes in each step, particular those related to the\nappearance of MBSs in the chain, will be given. We find that the sweet spots in\na three-site AKC can be classified into three types based on the relative\nstrengths of elastic cotunneling (ECT) and crossed Andreev reflection (CAR):\nECT-dominated sweet spots, genuine sweet spots and CAR-dominated sweet spots.\nWe show that the ECT-dominated and CAR-dominated sweet spots can be more\nconveniently accessed and utilized in transmon-based measurements.",
    "pdf_url": "http://arxiv.org/pdf/2505.15317v1",
    "published": "2025-05-21T09:48:05+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.15316v1",
    "title": "Emotional Supporters often Use Multiple Strategies in a Single Turn",
    "authors": [
      "Xin Bai",
      "Guanyi Chen",
      "Tingting He",
      "Chenlian Zhou",
      "Yu Liu"
    ],
    "abstract": "Emotional Support Conversations (ESC) are crucial for providing empathy,\nvalidation, and actionable guidance to individuals in distress. However,\nexisting definitions of the ESC task oversimplify the structure of supportive\nresponses, typically modelling them as single strategy-utterance pairs. Through\na detailed corpus analysis of the ESConv dataset, we identify a common yet\npreviously overlooked phenomenon: emotional supporters often employ multiple\nstrategies consecutively within a single turn. We formally redefine the ESC\ntask to account for this, proposing a revised formulation that requires\ngenerating the full sequence of strategy-utterance pairs given a dialogue\nhistory. To facilitate this refined task, we introduce several modelling\napproaches, including supervised deep learning models and large language\nmodels. Our experiments show that, under this redefined task, state-of-the-art\nLLMs outperform both supervised models and human supporters. Notably, contrary\nto some earlier findings, we observe that LLMs frequently ask questions and\nprovide suggestions, demonstrating more holistic support capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15316v1",
    "published": "2025-05-21T09:46:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15315v1",
    "title": "Local-Global Associative Frames for Symmetry-Preserving Crystal Structure Modeling",
    "authors": [
      "Haowei Hua",
      "Wanyu Lin"
    ],
    "abstract": "Crystal structures are defined by the periodic arrangement of atoms in 3D\nspace, inherently making them equivariant to SO(3) group. A fundamental\nrequirement for crystal property prediction is that the model's output should\nremain invariant to arbitrary rotational transformations of the input\nstructure. One promising strategy to achieve this invariance is to align the\ngiven crystal structure into a canonical orientation with appropriately\ncomputed rotations, or called frames. However, existing work either only\nconsiders a global frame or solely relies on more advanced local frames based\non atoms' local structure. A global frame is too coarse to capture the local\nstructure heterogeneity of the crystal, while local frames may inadvertently\ndisrupt crystal symmetry, limiting their expressivity. In this work, we revisit\nthe frame design problem for crystalline materials and propose a novel approach\nto construct expressive Symmetry-Preserving Frames, dubbed as SPFrame, for\nmodeling crystal structures. Specifically, this local-global associative frame\nconstructs invariant local frames rather than equivariant ones, thereby\npreserving the symmetry of the crystal. In parallel, it integrates global\nstructural information to construct an equivariant global frame to enforce\nSO(3) invariance. Extensive experimental results demonstrate that SPFrame\nconsistently outperforms traditional frame construction techniques and existing\ncrystal property prediction baselines across multiple benchmark tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15315v1",
    "published": "2025-05-21T09:45:32+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15314v1",
    "title": "A Deep Dive into classical and Topological CFT Thermodynamics in Lifshitz and Hyperscaling Violating Black Holes",
    "authors": [
      "Mohammad Ali S. Afshar",
      "Mohammad Reza Alipour",
      "Saeed Noori Gashti",
      "Jafar Sadeghi"
    ],
    "abstract": "To effectively utilize the AdS/CFT correspondence, a precise set of rules\nmust be established to guide the translation of computed quantities in the\ngravitational sector into their CFT counterparts, and vice versa. This\nframework is commonly referred to as the holographic dictionary. The\nformulation of such dictionaries opens a two-way gateway, allowing researchers\nto extend theoretical principles and findings from one domain into the other\nfor further exploration and study. The development of a holographic dictionary\nfor Lifshitz black holes and hyperscaling violation (HSV) models \\cite{6} has\nprovided an essential foundation for studying CFT thermodynamics and phase\nbehavior of these black holes. Based on this framework, we will investigate\ntheir thermodynamic properties using two distinct approaches. In the first\nstep, we adopt the classical and traditional method, identifying critical\npoints to examine the behavior of the free energy function as a function of\ntemperature near the critical boundary. By analyzing its behavior, we will\nstudy phase transitions and then proceed to evaluate the stability of the\nmodels. In the next step, to compare both methodologies and highlight their\nequivalence, particularly demonstrating the accessibility of the topological\nmethod compared to the classical approach, we will analyze phase behavior\nthrough the lens of topological charges.",
    "pdf_url": "http://arxiv.org/pdf/2505.15314v1",
    "published": "2025-05-21T09:44:43+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15313v2",
    "title": "FaceCrafter: Identity-Conditional Diffusion with Disentangled Control over Facial Pose, Expression, and Emotion",
    "authors": [
      "Kazuaki Mishima",
      "Antoni Bigata Casademunt",
      "Stavros Petridis",
      "Maja Pantic",
      "Kenji Suzuki"
    ],
    "abstract": "Human facial images encode a rich spectrum of information, encompassing both\nstable identity-related traits and mutable attributes such as pose, expression,\nand emotion. While recent advances in image generation have enabled\nhigh-quality identity-conditional face synthesis, precise control over\nnon-identity attributes remains challenging, and disentangling identity from\nthese mutable factors is particularly difficult. To address these limitations,\nwe propose a novel identity-conditional diffusion model that introduces two\nlightweight control modules designed to independently manipulate facial pose,\nexpression, and emotion without compromising identity preservation. These\nmodules are embedded within the cross-attention layers of the base diffusion\nmodel, enabling precise attribute control with minimal parameter overhead.\nFurthermore, our tailored training strategy, which leverages cross-attention\nbetween the identity feature and each non-identity control feature, encourages\nidentity features to remain orthogonal to control signals, enhancing\ncontrollability and diversity. Quantitative and qualitative evaluations, along\nwith perceptual user studies, demonstrate that our method surpasses existing\napproaches in terms of control accuracy over pose, expression, and emotion,\nwhile also improving generative diversity under identity-only conditioning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15313v2",
    "published": "2025-05-21T09:43:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15312v1",
    "title": "Sonnet: Spectral Operator Neural Network for Multivariable Time Series Forecasting",
    "authors": [
      "Yuxuan Shu",
      "Vasileios Lampos"
    ],
    "abstract": "Multivariable time series forecasting methods can integrate information from\nexogenous variables, leading to significant prediction accuracy gains.\nTransformer architecture has been widely applied in various time series\nforecasting models due to its ability to capture long-range sequential\ndependencies. However, a na\\\"ive application of transformers often struggles to\neffectively model complex relationships among variables over time. To mitigate\nagainst this, we propose a novel architecture, namely the Spectral Operator\nNeural Network (Sonnet). Sonnet applies learnable wavelet transformations to\nthe input and incorporates spectral analysis using the Koopman operator. Its\npredictive skill relies on the Multivariable Coherence Attention (MVCA), an\noperation that leverages spectral coherence to model variable dependencies. Our\nempirical analysis shows that Sonnet yields the best performance on $34$ out of\n$47$ forecasting tasks with an average mean absolute error (MAE) reduction of\n$1.1\\%$ against the most competitive baseline (different per task). We further\nshow that MVCA -- when put in place of the na\\\"ive attention used in various\ndeep learning models -- can remedy its deficiencies, reducing MAE by $10.7\\%$\non average in the most challenging forecasting tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15312v1",
    "published": "2025-05-21T09:43:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15311v1",
    "title": "Trajectory Bellman Residual Minimization: A Simple Value-Based Method for LLM Reasoning",
    "authors": [
      "Yurun Yuan",
      "Fan Chen",
      "Zeyu Jia",
      "Alexander Rakhlin",
      "Tengyang Xie"
    ],
    "abstract": "Policy-based methods currently dominate reinforcement learning (RL) pipelines\nfor large language model (LLM) reasoning, leaving value-based approaches\nlargely unexplored. We revisit the classical paradigm of Bellman Residual\nMinimization and introduce Trajectory Bellman Residual Minimization (TBRM), an\nalgorithm that naturally adapts this idea to LLMs, yielding a simple yet\neffective off-policy algorithm that optimizes a single trajectory-level Bellman\nobjective using the model's own logits as $Q$-values. TBRM removes the need for\ncritics, importance-sampling ratios, or clipping, and operates with only one\nrollout per prompt. We prove convergence to the near-optimal KL-regularized\npolicy from arbitrary off-policy data via an improved\nchange-of-trajectory-measure analysis. Experiments on standard\nmathematical-reasoning benchmarks show that TBRM consistently outperforms\npolicy-based baselines, like PPO and GRPO, with comparable or lower\ncomputational and memory overhead. Our results indicate that value-based RL\nmight be a principled and efficient alternative for enhancing reasoning\ncapabilities in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15311v1",
    "published": "2025-05-21T09:41:53+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15310v1",
    "title": "Transcendental meromorphic solutions and the complex Schr√∂dinger equation with delay",
    "authors": [
      "Tingbin Cao",
      "Risto Korhonen",
      "Wenlong Liu"
    ],
    "abstract": "In this article, we focus on studying the differential-difference equation\n  \\[ f'(z) = a(z)f(z+1) + R(z, f(z)), \\quad R(z, f(z)) = \\frac{P(z, f(z))}{Q(z,\nf(z))}, \\]\n  where the two nonzero polynomials \\( P(z, f(z)) \\) and \\( Q(z, f(z)) \\) in \\(\nf(z) \\), with small meromorphic coefficients, are coprime, and \\( a(z) \\) is a\nnonzero small meromorphic function of \\( f(z) \\). This equation includes the\ncomplex Schrodinger equation with delay as a special case.\n  If \\( f(z) \\) is a transcendental meromorphic solution of the equation with\nsubnormal growth, then we derive all possible forms of the equation.\nAdditionally, under these assumptions, we classify these specific forms based\non the degrees of \\( P(z, f(z)) \\) and \\( Q(z, f(z)) \\) to establish necessary\nconditions for the existence of transcendental meromorphic solutions. In\nparticular, when the degree of \\( P \\) minus the degree of \\( Q \\) is 2, we\ndemonstrate that the equation reduces to a Riccati differential equation.\nFinally, examples are provided to support our results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15310v1",
    "published": "2025-05-21T09:40:40+00:00",
    "categories": [
      "math.CV"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15309v1",
    "title": "$œÜ\\to 3œÄ$ and $œÜœÄ^{0}$ transition form factor from Khuri-Treiman equations",
    "authors": [
      "A. Garcia-Lorenzo",
      "M. Albaladejo",
      "S. Gonzlez-Solis",
      "N. Hammoud",
      "V. Mathieu",
      "G. Montana",
      "A. Pilloni",
      "D. Winney",
      "A. P. Szczepaniak"
    ],
    "abstract": "This work studies the $\\phi \\to 3\\pi$ decay and the $\\phi \\to \\pi^0\n\\gamma^\\ast$ transition form factor, utilizing the Khuri-Treiman formalism to\naccount for analyticity, crossing, and unitarity. Using once-subtracted\ndispersion relations, we perform a simultaneous fit to the $\\phi \\to 3\\pi$\nDalitz plot distribution and the $\\phi \\to \\pi^0 \\gamma^\\ast$ measurements from\nthe KLOE collaboration, finding good agreement with these experimental data.\nThese results reaffirm the applicability of the Khuri-Treiman approach in the\nanalysis of three-body decays. An interesting result is that the subtraction\nconstant appearing in the equations is similar to a sum rule expectation, in\ncontrast to analogous studies of $\\omega \\to 3\\pi$ decays and $\\omega \\to \\pi^0\n\\gamma^\\ast$, which shows significant deviations. Our results also provide a\nreasonable description of the trend of the transition form factor data from\nBaBar in the $e^{+}e^{-}\\to\\phi\\pi^{0}$ scattering region. These intriguing\ntheoretical differences between the decays of $\\phi$ and $\\omega$ could\nencourage further experimental measurements to assess the discrepancies and\nrefine the theoretical predictions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15309v1",
    "published": "2025-05-21T09:38:48+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15308v1",
    "title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution",
    "authors": [
      "Ji Guo",
      "Xiaolei Wen",
      "Wenbo Jiang",
      "Cheng Huang",
      "Jinjin Li",
      "Hongwei Li"
    ],
    "abstract": "With the widespread application of super-resolution (SR) in various fields,\nresearchers have begun to investigate its security. Previous studies have\ndemonstrated that SR models can also be subjected to backdoor attacks through\ndata poisoning, affecting downstream tasks. A backdoor SR model generates an\nattacker-predefined target image when given a triggered image while producing a\nnormal high-resolution (HR) output for clean images. However, prior backdoor\nattacks on SR models have primarily focused on the stealthiness of poisoned\nlow-resolution (LR) images while ignoring the stealthiness of poisoned HR\nimages, making it easy for users to detect anomalous data. To address this\nproblem, we propose BadSR, which improves the stealthiness of poisoned HR\nimages. The key idea of BadSR is to approximate the clean HR image and the\npre-defined target image in the feature space while ensuring that modifications\nto the clean HR image remain within a constrained range. The poisoned HR images\ngenerated by BadSR can be integrated with existing triggers. To further improve\nthe effectiveness of BadSR, we design an adversarially optimized trigger and a\nbackdoor gradient-driven poisoned sample selection method based on a genetic\nalgorithm. The experimental results show that BadSR achieves a high attack\nsuccess rate in various models and data sets, significantly affecting\ndownstream tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15308v1",
    "published": "2025-05-21T09:36:35+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15307v1",
    "title": "Towards Pre-training an Effective Respiratory Audio Foundation Model",
    "authors": [
      "Daisuke Niizumi",
      "Daiki Takeuchi",
      "Masahiro Yasuda",
      "Binh Thien Nguyen",
      "Yasunori Ohishi",
      "Noboru Harada"
    ],
    "abstract": "Recent advancements in foundation models have sparked interest in respiratory\naudio foundation models. However, the effectiveness of applying conventional\npre-training schemes to datasets that are small-sized and lack diversity has\nnot been sufficiently verified. This study aims to explore better pre-training\npractices for respiratory sounds by comparing numerous pre-trained audio\nmodels. Our investigation reveals that models pre-trained on AudioSet, a\ngeneral audio dataset, are more effective than the models specifically\npre-trained on respiratory sounds. Moreover, combining AudioSet and respiratory\nsound datasets for further pre-training enhances performance, and preserving\nthe frequency-wise information when aggregating features is vital. Along with\nmore insights found in the experiments, we establish a new state-of-the-art for\nthe OPERA benchmark, contributing to advancing respiratory audio foundation\nmodels. Our code is available online at\nhttps://github.com/nttcslab/eval-audio-repr/tree/main/plugin/OPERA.",
    "pdf_url": "http://arxiv.org/pdf/2505.15307v1",
    "published": "2025-05-21T09:36:11+00:00",
    "categories": [
      "eess.AS",
      "cs.SD",
      "68T07",
      "J.3"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15306v1",
    "title": "Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One",
    "authors": [
      "Yiwen Song",
      "Qianyue Hao",
      "Qingmin Liao",
      "Jian Yuan",
      "Yong Li"
    ],
    "abstract": "Model ensemble is a useful approach in reinforcement learning (RL) for\ntraining effective agents. Despite wide success of RL, training effective\nagents remains difficult due to the multitude of factors requiring careful\ntuning, such as algorithm selection, hyperparameter settings, and even random\nseed choices, all of which can significantly influence an agent's performance.\nModel ensemble helps overcome this challenge by combining multiple weak agents\ninto a single, more powerful one, enhancing overall performance. However,\nexisting ensemble methods, such as majority voting and Boltzmann addition, are\ndesigned as fixed strategies and lack a semantic understanding of specific\ntasks, limiting their adaptability and effectiveness. To address this, we\npropose LLM-Ens, a novel approach that enhances RL model ensemble with\ntask-specific semantic understandings driven by large language models (LLMs).\nGiven a task, we first design an LLM to categorize states in this task into\ndistinct 'situations', incorporating high-level descriptions of the task\nconditions. Then, we statistically analyze the strengths and weaknesses of each\nindividual agent to be used in the ensemble in each situation. During the\ninference time, LLM-Ens dynamically identifies the changing task situation and\nswitches to the agent that performs best in the current situation, ensuring\ndynamic model selection in the evolving task condition. Our approach is\ndesigned to be compatible with agents trained with different random seeds,\nhyperparameter settings, and various RL algorithms. Extensive experiments on\nthe Atari benchmark show that LLM-Ens significantly improves the RL model\nensemble, surpassing well-known baselines by up to 20.9%. For reproducibility,\nour code is open-source at\nhttps://anonymous.4open.science/r/LLM4RLensemble-F7EE.",
    "pdf_url": "http://arxiv.org/pdf/2505.15306v1",
    "published": "2025-05-21T09:35:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15305v2",
    "title": "Vacuum Tunneling from Conifold Transitions in IIB",
    "authors": [
      "Xin Gao",
      "Qinjian Lou",
      "Yi-Nan Wang"
    ],
    "abstract": "We investigate the quantum tunneling process through a topology transition\nnear a conifold singularity, in the setup of IIB CY3 orientifold\ncompactification. We propose a novel method to do moduli stabilization in an\nextended moduli space, parametrized by both the geometric moduli and the light\nD3-brane wrapping modes arisen from the brane quantization. Assuming the\nabsence of flux through the vanishing exceptional 3-cycle, we find two types of\nvacuum solutions, one corresponds to the resolved conifold and the other one is\ninterpreted as a novel non-geometric phase. We compute the quantum tunneling\nrate between these two solutions and find that it is difficult to achieve a\nsignificantly large tunneling rate in the controllable regime.",
    "pdf_url": "http://arxiv.org/pdf/2505.15305v2",
    "published": "2025-05-21T09:35:39+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15304v2",
    "title": "Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control",
    "authors": [
      "Seongmin Park",
      "Hyungmin Kim",
      "Sangwoo Kim",
      "Wonseok Jeon",
      "Juyoung Yang",
      "Byeongwook Jeon",
      "Yoonseon Oh",
      "Jungwook Choi"
    ],
    "abstract": "Deep neural network (DNN)-based policy models, such as vision-language-action\n(VLA) models, excel at automating complex decision-making from multi-modal\ninputs. However, scaling these models greatly increases computational overhead,\ncomplicating deployment in resource-constrained settings like robot\nmanipulation and autonomous driving. To address this, we propose Saliency-Aware\nQuantized Imitation Learning (SQIL), which combines quantization-aware training\nwith a selective loss-weighting strategy for mission-critical states. By\nidentifying these states via saliency scores and emphasizing them in the\ntraining loss, SQIL preserves decision fidelity under low-bit precision. We\nvalidate SQIL's generalization capability across extensive simulation\nbenchmarks with environment variations, real-world tasks, and cross-domain\ntasks (self-driving, physics simulation), consistently recovering\nfull-precision performance. Notably, a 4-bit weight-quantized VLA model for\nrobotic manipulation achieves up to 2.5x speedup and 2.5x energy savings on an\nedge GPU with minimal accuracy loss. These results underline SQIL's potential\nfor efficiently deploying large IL-based policy models on resource-limited\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15304v2",
    "published": "2025-05-21T09:35:12+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15303v1",
    "title": "Laplace Sample Information: Data Informativeness Through a Bayesian Lens",
    "authors": [
      "Johannes Kaiser",
      "Kristian Schwethelm",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "abstract": "Accurately estimating the informativeness of individual samples in a dataset\nis an important objective in deep learning, as it can guide sample selection,\nwhich can improve model efficiency and accuracy by removing redundant or\npotentially harmful samples. We propose Laplace Sample Information (LSI)\nmeasure of sample informativeness grounded in information theory widely\napplicable across model architectures and learning settings. LSI leverages a\nBayesian approximation to the weight posterior and the KL divergence to measure\nthe change in the parameter distribution induced by a sample of interest from\nthe dataset. We experimentally show that LSI is effective in ordering the data\nwith respect to typicality, detecting mislabeled samples, measuring class-wise\ninformativeness, and assessing dataset difficulty. We demonstrate these\ncapabilities of LSI on image and text data in supervised and unsupervised\nsettings. Moreover, we show that LSI can be computed efficiently through probes\nand transfers well to the training of large models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15303v1",
    "published": "2025-05-21T09:34:27+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17105v2",
    "title": "Transparency in Healthcare AI: Testing European Regulatory Provisions against Users' Transparency Needs",
    "authors": [
      "Anna Spagnolli",
      "Cecilia Tolomini",
      "Elisa Beretta",
      "Claudio Sarra"
    ],
    "abstract": "Artificial Intelligence (AI) plays an essential role in healthcare and is\npervasively incorporated into medical software and equipment. In the European\nUnion, healthcare is a high-risk application domain for AI, and providers must\nprepare Instructions for Use (IFU) according to the European regulation\n2024/1689 (AI Act). To this regulation, the principle of transparency is\ncardinal and requires the IFU to be clear and relevant to the users. This study\ntests whether these latter requirements are satisfied by the IFU structure. A\nsurvey was administered online via the Qualtrics platform to four types of\ndirect stakeholders, i.e., managers (N = 238), healthcare professionals (N =\n115), patients (N = 229), and Information Technology experts (N = 230). The\nparticipants rated the relevance of a set of transparency needs and indicated\nthe IFU section addressing them. The results reveal differentiated priorities\nacross stakeholders and a troubled mapping of transparency needs onto the IFU\nstructure. Recommendations to build a locally meaningful IFU are derived.",
    "pdf_url": "http://arxiv.org/pdf/2505.17105v2",
    "published": "2025-05-21T09:34:05+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.1; J.3"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15302v1",
    "title": "Robust and compact single-lens crossed-beam optical dipole trap for Bose-Einstein condensation in microgravity",
    "authors": [
      "Jan Simon Haase",
      "Alexander Fieguth",
      "Igor Br√∂ckel",
      "Janina Hamann",
      "Jens Kruse",
      "Carsten Klempt"
    ],
    "abstract": "We present a novel concept for a compact and robust crossed-beam optical\ndipole trap (cODT) based on a single lens, designed for the efficient\ngeneration of Bose-Einstein condensates (BECs) under dynamic conditions. The\nsystem employs two independent two-dimensional acousto-optical deflectors\n(AODs) in combination with a single high-numerical-aperture lens to provide\nthree-dimensional control over the trap geometry, minimizing potential\nmisalignments and ensuring long-term operational stability. By leveraging\ntime-averaged potentials, rapid and efficient evaporative cooling sequences\ntoward BECs are enabled. The functionality of the cODT under microgravity\nconditions has been successfully demonstrated in the Einstein-Elevator in\nHannover, Germany, where the beam intersection was shown to remain stable\nthroughout the microgravity phase of the flight. In addition, the system has\nbeen implemented in the sensor head of the INTENTAS project to verify BEC\ngeneration. Additional realization of one- and two-dimensional control of\narrays of condensates through dynamic trap shaping was achieved. This versatile\napproach allows for advanced quantum sensing applications in mobile and\nspace-based environments based on all- optical BECs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15302v1",
    "published": "2025-05-21T09:32:46+00:00",
    "categories": [
      "quant-ph",
      "physics.ins-det",
      "physics.optics",
      "physics.space-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15301v1",
    "title": "Singularities of Magnetic Monopoles for Dirac and 't Hooft-Polyakov Theories by Pre-potential Method",
    "authors": [
      "Masakatsu Kenmoku"
    ],
    "abstract": "The magnetic monopole is one of the important problems in the early stage of\nuniverse as well as observations and experiments on Earth. We study the\nexistence or non-existence of the Dirac and the 't Hooft-Polyakov magnetic\nmonopole theories using the pre-potential $\\boldsymbol{C}$, which is defined to\nderive the vector potential by the curl operation as $\\boldsymbol{A}=\\nabla\n\\times \\boldsymbol{C}$ . We assert that the magnetic singularity exists for the\n't Hooft-Polyakov monopole in SO(3) gauge theory, as well as for the Dirac\nmonopole in U(1) gauge theory. The regularization method confirms our\nassertion.",
    "pdf_url": "http://arxiv.org/pdf/2505.15301v1",
    "published": "2025-05-21T09:31:53+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15300v1",
    "title": "Stochastic homogenization of stable-like process with divergence free drift",
    "authors": [
      "Xin Chen",
      "Kun Yin"
    ],
    "abstract": "In this paper we will study homogenization of for stable-like process with\ndivergence-free drift in ergodic environments. In particular, neither the drift\nnor the stream function are required to be bounded.",
    "pdf_url": "http://arxiv.org/pdf/2505.15300v1",
    "published": "2025-05-21T09:31:41+00:00",
    "categories": [
      "math.PR",
      "60G51, 60G52, 60J25, 60J75"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15299v2",
    "title": "Multi-Hop Question Generation via Dual-Perspective Keyword Guidance",
    "authors": [
      "Maodong Li",
      "Longyin Zhang",
      "Fang Kong"
    ],
    "abstract": "Multi-hop question generation (MQG) aims to generate questions that require\nsynthesizing multiple information snippets from documents to derive target\nanswers. The primary challenge lies in effectively pinpointing crucial\ninformation snippets related to question-answer (QA) pairs, typically relying\non keywords. However, existing works fail to fully utilize the guiding\npotential of keywords and neglect to differentiate the distinct roles of\nquestion-specific and document-specific keywords. To address this, we define\ndual-perspective keywords (i.e., question and document keywords) and propose a\nDual-Perspective Keyword-Guided (DPKG) framework, which seamlessly integrates\nkeywords into the multi-hop question generation process. We argue that question\nkeywords capture the questioner's intent, whereas document keywords reflect the\ncontent related to the QA pair. Functionally, question and document keywords\nwork together to pinpoint essential information snippets in the document, with\nquestion keywords required to appear in the generated question. The DPKG\nframework consists of an expanded transformer encoder and two answer-aware\ntransformer decoders for keyword and question generation, respectively.\nExtensive experiments demonstrate the effectiveness of our work, showcasing its\npromising performance and underscoring its significant value in the MQG task.",
    "pdf_url": "http://arxiv.org/pdf/2505.15299v2",
    "published": "2025-05-21T09:30:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.12025v3",
    "title": "Unsupervised Learning for Optimal Transport plan prediction between unbalanced graphs",
    "authors": [
      "Sonia Mazelet",
      "R√©mi Flamary",
      "Bertrand Thirion"
    ],
    "abstract": "Optimal transport between graphs, based on Gromov-Wasserstein and other\nextensions, is a powerful tool for comparing and aligning graph structures.\nHowever, solving the associated non-convex optimization problems is\ncomputationally expensive, which limits the scalability of these methods to\nlarge graphs. In this work, we present Unbalanced Learning of Optimal Transport\n(ULOT), a deep learning method that predicts optimal transport plans between\ntwo graphs. Our method is trained by minimizing the fused unbalanced\nGromov-Wasserstein (FUGW) loss. We propose a novel neural architecture with\ncross-attention that is conditioned on the FUGW tradeoff hyperparameters. We\nevaluate ULOT on synthetic stochastic block model (SBM) graphs and on real\ncortical surface data obtained from fMRI. ULOT predicts transport plans with\ncompetitive loss up to two orders of magnitude faster than classical solvers.\nFurthermore, the predicted plan can be used as a warm start for classical\nsolvers to accelerate their convergence. Finally, the predicted transport plan\nis fully differentiable with respect to the graph inputs and FUGW\nhyperparameters, enabling the optimization of functionals of the ULOT plan.",
    "pdf_url": "http://arxiv.org/pdf/2506.12025v3",
    "published": "2025-05-21T09:29:19+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15298v3",
    "title": "AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving",
    "authors": [
      "Kangan Qian",
      "Sicong Jiang",
      "Yang Zhong",
      "Ziang Luo",
      "Zilin Huang",
      "Tianze Zhu",
      "Kun Jiang",
      "Mengmeng Yang",
      "Zheng Fu",
      "Jinyu Miao",
      "Yining Shi",
      "He Zhe Lim",
      "Li Liu",
      "Tianbao Zhou",
      "Huang Yu",
      "Yifei Hu",
      "Guang Li",
      "Guang Chen",
      "Hao Ye",
      "Lijun Sun",
      "Diange Yang"
    ],
    "abstract": "Vision-Language Models (VLMs) show promise for autonomous driving, yet their\nstruggle with hallucinations, inefficient reasoning, and limited real-world\nvalidation hinders accurate perception and robust step-by-step reasoning. To\novercome this, we introduce AgentThink, a pioneering unified framework that,\nfor the first time, integrates Chain-of-Thought (CoT) reasoning with dynamic,\nagent-style tool invocation for autonomous driving tasks. AgentThink's core\ninnovations include: (i) Structured Data Generation, by establishing an\nautonomous driving tool library to automatically construct structured,\nself-verified reasoning data explicitly incorporating tool usage for diverse\ndriving scenarios; (ii) A Two-stage Training Pipeline, employing Supervised\nFine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to equip VLMs\nwith the capability for autonomous tool invocation; and (iii) Agent-style\nTool-Usage Evaluation, introducing a novel multi-tool assessment protocol to\nrigorously evaluate the model's tool invocation and utilization. Experiments on\nthe DriveLMM-o1 benchmark demonstrate AgentThink significantly boosts overall\nreasoning scores by 53.91% and enhances answer accuracy by 33.54%, while\nmarkedly improving reasoning quality and consistency. Furthermore, ablation\nstudies and robust zero-shot/few-shot generalization experiments across various\nbenchmarks underscore its powerful capabilities. These findings highlight a\npromising trajectory for developing trustworthy and tool-aware autonomous\ndriving models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15298v3",
    "published": "2025-05-21T09:27:43+00:00",
    "categories": [
      "cs.RO",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15297v1",
    "title": "Chinese Toxic Language Mitigation via Sentiment Polarity Consistent Rewrites",
    "authors": [
      "Xintong Wang",
      "Yixiao Liu",
      "Jingheng Pan",
      "Liang Ding",
      "Longyue Wang",
      "Chris Biemann"
    ],
    "abstract": "Detoxifying offensive language while preserving the speaker's original intent\nis a challenging yet critical goal for improving the quality of online\ninteractions. Although large language models (LLMs) show promise in rewriting\ntoxic content, they often default to overly polite rewrites, distorting the\nemotional tone and communicative intent. This problem is especially acute in\nChinese, where toxicity often arises implicitly through emojis, homophones, or\ndiscourse context. We present ToxiRewriteCN, the first Chinese detoxification\ndataset explicitly designed to preserve sentiment polarity. The dataset\ncomprises 1,556 carefully annotated triplets, each containing a toxic sentence,\na sentiment-aligned non-toxic rewrite, and labeled toxic spans. It covers five\nreal-world scenarios: standard expressions, emoji-induced and homophonic\ntoxicity, as well as single-turn and multi-turn dialogues. We evaluate 17 LLMs,\nincluding commercial and open-source models with variant architectures, across\nfour dimensions: detoxification accuracy, fluency, content preservation, and\nsentiment polarity. Results show that while commercial and MoE models perform\nbest overall, all models struggle to balance safety with emotional fidelity in\nmore subtle or context-heavy settings such as emoji, homophone, and\ndialogue-based inputs. We release ToxiRewriteCN to support future research on\ncontrollable, sentiment-aware detoxification for Chinese.",
    "pdf_url": "http://arxiv.org/pdf/2505.15297v1",
    "published": "2025-05-21T09:27:18+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15296v1",
    "title": "Agent-based Liquidity Risk Modelling for Financial Markets",
    "authors": [
      "Perukrishnen Vytelingum",
      "Rory Baggott",
      "Namid Stillman",
      "Jianfei Zhang",
      "Dingqiu Zhu",
      "Tao Chen",
      "Justin Lyon"
    ],
    "abstract": "In this paper, we describe a novel agent-based approach for modelling the\ntransaction cost of buying or selling an asset in financial markets, e.g., to\nliquidate a large position as a result of a margin call to meet financial\nobligations. The simple act of buying or selling in the market causes a price\nimpact and there is a cost described as liquidity risk. For example, when\nselling a large order, there is market slippage -- each successive trade will\nexecute at the same or worse price. When the market adjusts to the new\ninformation revealed by the execution of such a large order, we observe in the\ndata a permanent price impact that can be attributed to the change in the\nfundamental value as market participants reassess the value of the asset. In\nour ABM model, we introduce a novel mechanism where traders assume orderflow is\ninformed and each trade reveals some information about the value of the asset,\nand traders update their belief of the fundamental value for every trade. The\nresult is emergent, realistic price impact without oversimplifying the problem\nas most stylised models do, but within a realistic framework that models the\nexchange with its protocols, its limit orderbook and its auction mechanism and\nthat can calculate the transaction cost of any execution strategy without\nlimitation. Our stochastic ABM model calculates the costs and uncertainties of\nbuying and selling in a market by running Monte-Carlo simulations, for a better\nunderstanding of liquidity risk and can be used to optimise for optimal\nexecution under liquidity risk. We demonstrate its practical application in the\nreal world by calculating the liquidity risk for the Hang-Seng Futures Index.",
    "pdf_url": "http://arxiv.org/pdf/2505.15296v1",
    "published": "2025-05-21T09:25:32+00:00",
    "categories": [
      "q-fin.TR"
    ],
    "primary_category": "q-fin.TR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15295v1",
    "title": "Finiteness of pointed families of symplectic varieties: a geometric Shafarevich conjecture",
    "authors": [
      "Lie Fu",
      "Zhiyuan Li",
      "Teppei Takamatsu",
      "Haitao Zou"
    ],
    "abstract": "We investigate in this paper the so-called pointed Shafarevich problem for\nfamilies of primitive symplectic varieties. More precisely, for any fixed\npointed curve $(B, 0)$ and any fixed primitive symplectic variety $X$, among\nall locally trivial families of $\\mathbb{Q}$-factorial and terminal primitive\nsymplectic varieties over $B$ whose fiber over $0$ is isomorphic to $X$, we\nshow that there are only finitely many isomorphism classes of generic fibers.\nMoreover, assuming semi-ampleness of isotropic nef divisors, which holds true\nfor all hyper-K\\\"ahler manifolds of known deformation types, we show that there\nare only finitely many such projective families up to isomorphism. These\nresults are optimal since we can construct infinitely many pairwise\nnon-isomorphic (not necessarily projective) families of smooth hyper-K\\\"ahler\nvarieties over some pointed curve $(B, 0)$ such that they are all isomorphic\nover the punctured curve $B\\backslash \\{0\\}$ and have isomorphic fibers over\nthe base point $0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15295v1",
    "published": "2025-05-21T09:25:27+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15294v1",
    "title": "R3GS: Gaussian Splatting for Robust Reconstruction and Relocalization in Unconstrained Image Collections",
    "authors": [
      "Xu yan",
      "Zhaohui Wang",
      "Rong Wei",
      "Jingbo Yu",
      "Dong Li",
      "Xiangde Liu"
    ],
    "abstract": "We propose R3GS, a robust reconstruction and relocalization framework\ntailored for unconstrained datasets. Our method uses a hybrid representation\nduring training. Each anchor combines a global feature from a convolutional\nneural network (CNN) with a local feature encoded by the multiresolution hash\ngrids [2]. Subsequently, several shallow multi-layer perceptrons (MLPs) predict\nthe attributes of each Gaussians, including color, opacity, and covariance. To\nmitigate the adverse effects of transient objects on the reconstruction\nprocess, we ffne-tune a lightweight human detection network. Once ffne-tuned,\nthis network generates a visibility map that efffciently generalizes to other\ntransient objects (such as posters, banners, and cars) with minimal need for\nfurther adaptation. Additionally, to address the challenges posed by sky\nregions in outdoor scenes, we propose an effective sky-handling technique that\nincorporates a depth prior as a constraint. This allows the inffnitely distant\nsky to be represented on the surface of a large-radius sky sphere,\nsigniffcantly reducing ffoaters caused by errors in sky reconstruction.\nFurthermore, we introduce a novel relocalization method that remains robust to\nchanges in lighting conditions while estimating the camera pose of a given\nimage within the reconstructed 3DGS scene. As a result, R3GS significantly\nenhances rendering ffdelity, improves both training and rendering efffciency,\nand reduces storage requirements. Our method achieves state-of-the-art\nperformance compared to baseline methods on in-the-wild datasets. The code will\nbe made open-source following the acceptance of the paper.",
    "pdf_url": "http://arxiv.org/pdf/2505.15294v1",
    "published": "2025-05-21T09:25:22+00:00",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15293v1",
    "title": "LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models",
    "authors": [
      "Qianyue Hao",
      "Yiwen Song",
      "Qingmin Liao",
      "Jian Yuan",
      "Yong Li"
    ],
    "abstract": "Policy exploration is critical in reinforcement learning (RL), where existing\napproaches include greedy, Gaussian process, etc. However, these approaches\nutilize preset stochastic processes and are indiscriminately applied in all\nkinds of RL tasks without considering task-specific features that influence\npolicy exploration. Moreover, during RL training, the evolution of such\nstochastic processes is rigid, which typically only incorporates a decay in the\nvariance, failing to adjust flexibly according to the agent's real-time\nlearning status. Inspired by the analyzing and reasoning capability of large\nlanguage models (LLMs), we design LLM-Explorer to adaptively generate\ntask-specific exploration strategies with LLMs, enhancing the policy\nexploration in RL. In our design, we sample the learning trajectory of the\nagent during the RL training in a given task and prompt the LLM to analyze the\nagent's current policy learning status and then generate a probability\ndistribution for future policy exploration. Updating the probability\ndistribution periodically, we derive a stochastic process specialized for the\nparticular task and dynamically adjusted to adapt to the learning process. Our\ndesign is a plug-in module compatible with various widely applied RL\nalgorithms, including the DQN series, DDPG, TD3, and any possible variants\ndeveloped based on them. Through extensive experiments on the Atari and MuJoCo\nbenchmarks, we demonstrate LLM-Explorer's capability to enhance RL policy\nexploration, achieving an average performance improvement up to 37.27%. Our\ncode is open-source at https://anonymous.4open.science/r/LLM-Explorer-19BE for\nreproducibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.15293v1",
    "published": "2025-05-21T09:24:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15292v1",
    "title": "Stabilization of Martensite and Austenite Phases and Realization of Two-way Martensitic Transition in Co-Ni-Ga Ferromagnetic Shape Memory Alloy Nanoparticles",
    "authors": [
      "Debraj Mahata",
      "Ananthakrishnan Srinivasana"
    ],
    "abstract": "Three sets of Co-Ni-Ga alloy nanoparticles have been synthesized by a\ntemplate-free chemical route. Structural, morphological, shape memory, and\nmagnetic properties of room temperature martensite (M) phase, dual (M +\nsecondary $\\gamma$) phase and austenite (A) phase Co-Ni-Ga nanoparticles are\nreported. Temperature-dependent XRD analysis revealed that\n$Co_{36}Ni_{36}Ga_{28}$ nanoparticles exhibiting a single M phase at room\ntemperature, completely transform to A phase at $\\sim1000$ K. Upon cooling to\nroom temperature, the A phase transforms back to single M phase, confirming the\ntwo-way martensitic transition in Co-Ni-Ga nanoparticles. Structural analysis\nshows that the $\\gamma$-phase does not influence the martensitic transition of\nbi-phasic (M + $\\gamma$) $Co_{41}Ni_{34}Ga_{25}$ nanoparticles. These\nnanoparticles display saturation magnetization ranging from 2.9 emu/g to 15.3\nemu/g at room temperature. The $\\gamma$ phase could be introduced in A phase\n$Co_{44}Ni_{26}Ga_{30}$ nanoparticles when heated up to 1073 K. Curie\ntemperatures of A and M phases are higher than the martensitic transition\ntemperatures in all the samples, qualifying them as ferromagnetic shape memory\nalloy nanoparticles. Observation of M $\\leftrightarrow$ A phase transition,\nCo-Ni-Ga nanoparticles with tunable magnetic properties make them excellent\ncandidates for low and high temperature nanoactuators and other ferromagnetic\nshape memory applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15292v1",
    "published": "2025-05-21T09:22:21+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15291v1",
    "title": "Hallucinate at the Last in Long Response Generation: A Case Study on Long Document Summarization",
    "authors": [
      "Joonho Yang",
      "Seunghyun Yoon",
      "Hwan Chang",
      "Byeongjeong Kim",
      "Hwanhee Lee"
    ],
    "abstract": "Large Language Models (LLMs) have significantly advanced text generation\ncapabilities, including tasks like summarization, often producing coherent and\nfluent outputs. However, faithfulness to source material remains a significant\nchallenge due to the generation of hallucinations. While extensive research\nfocuses on detecting and reducing these inaccuracies, less attention has been\npaid to the positional distribution of hallucination within generated text,\nparticularly in long outputs. In this work, we investigate where hallucinations\noccur in LLM-based long response generation, using long document summarization\nas a key case study. Focusing on the challenging setting of long context-aware\nlong response generation, we find a consistent and concerning phenomenon:\nhallucinations tend to concentrate disproportionately in the latter parts of\nthe generated long response. To understand this bias, we explore potential\ncontributing factors related to the dynamics of attention and decoding over\nlong sequences. Furthermore, we investigate methods to mitigate this positional\nhallucination, aiming to improve faithfulness specifically in the concluding\nsegments of long outputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15291v1",
    "published": "2025-05-21T09:22:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15290v1",
    "title": "Robust Probabilistic Bisimilarity for Labelled Markov Chains",
    "authors": [
      "Syyeda Zainab Fatmi",
      "Stefan Kiefer",
      "David Parker",
      "Franck van Breugel"
    ],
    "abstract": "Despite its prevalence, probabilistic bisimilarity suffers from a lack of\nrobustness under minuscule perturbations of the transition probabilities. This\ncan lead to discontinuities in the probabilistic bisimilarity distance\nfunction, undermining its reliability in practical applications where\ntransition probabilities are often approximations derived from experimental\ndata. Motivated by this limitation, we introduce the notion of robust\nprobabilistic bisimilarity for labelled Markov chains, which ensures the\ncontinuity of the probabilistic bisimilarity distance function. We also propose\nan efficient algorithm for computing robust probabilistic bisimilarity and show\nthat it performs well in practice, as evidenced by our experimental results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15290v1",
    "published": "2025-05-21T09:20:46+00:00",
    "categories": [
      "cs.LO",
      "cs.FL"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15289v1",
    "title": "International Tourism and Global Biodiversity Risks",
    "authors": [
      "Yingtong Chen",
      "Fei Wu",
      "Dayong Zhang",
      "Qiang Ji"
    ],
    "abstract": "The impact of international tourism on biodiversity risks has received\nconsiderable attention, yet quantitative research in this field remains\nrelatively limited. This study constructs a biodiversity risk index for 155\ncountries and regions spanning the years 2001 to 2019, analysing how\ninternational tourism influences biodiversity risks in destination countries.\nThe results indicate that the growth of international tourism significantly\nelevates biodiversity risks, with these effects displaying both lagging and\ncumulative characteristics. Furthermore, spatial analysis shows that\ninternational tourism also intensifies biodiversity risks in neighbouring\ncountries. The extent of its impact varies according to the tourism model and\ndestination. In addition, government regulations and international financial\nassistance play a crucial role in mitigating the biodiversity risks associated\nwith international tourism.",
    "pdf_url": "http://arxiv.org/pdf/2505.15289v1",
    "published": "2025-05-21T09:20:10+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.15288v1",
    "title": "Strong odd colorings in graph classes of bounded expansion",
    "authors": [
      "Micha≈Ç Pilipczuk"
    ],
    "abstract": "We prove that for every $d\\in \\mathbb{N}$ and a graph class of bounded\nexpansion $\\mathscr{C}$, there exists some $c\\in \\mathbb{N}$ so that every\ngraph from $\\mathscr{C}$ admits a proper coloring with at most $c$ colors\nsatisfying the following condition: in every ball of radius $d$, every color\nappears either zero times or an odd number of times. For $d=1$, this provides a\npositive answer to a question raised by Goetze, Klute, Knauer, Parada, Pe\\~na,\nand Ueckerdt [ArXiv 2505.02736] about the boundedness of the strong odd\nchromatic number in graph classes of bounded expansion. The key technical\ningredient towards the result is a proof that the strong odd coloring number of\na sets system can be bounded in terms of its semi-ladder index, 2VC dimension,\nand the maximum subchromatic number among induced subsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15288v1",
    "published": "2025-05-21T09:17:10+00:00",
    "categories": [
      "math.CO",
      "cs.DM"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15287v1",
    "title": "GS2E: Gaussian Splatting is an Effective Data Generator for Event Stream Generation",
    "authors": [
      "Yuchen Li",
      "Chaoran Feng",
      "Zhenyu Tang",
      "Kaiyuan Deng",
      "Wangbo Yu",
      "Yonghong Tian",
      "Li Yuan"
    ],
    "abstract": "We introduce GS2E (Gaussian Splatting to Event), a large-scale synthetic\nevent dataset for high-fidelity event vision tasks, captured from real-world\nsparse multi-view RGB images. Existing event datasets are often synthesized\nfrom dense RGB videos, which typically lack viewpoint diversity and geometric\nconsistency, or depend on expensive, difficult-to-scale hardware setups. GS2E\novercomes these limitations by first reconstructing photorealistic static\nscenes using 3D Gaussian Splatting, and subsequently employing a novel,\nphysically-informed event simulation pipeline. This pipeline generally\nintegrates adaptive trajectory interpolation with physically-consistent event\ncontrast threshold modeling. Such an approach yields temporally dense and\ngeometrically consistent event streams under diverse motion and lighting\nconditions, while ensuring strong alignment with underlying scene structures.\nExperimental results on event-based 3D reconstruction demonstrate GS2E's\nsuperior generalization capabilities and its practical value as a benchmark for\nadvancing event vision research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15287v1",
    "published": "2025-05-21T09:15:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15286v1",
    "title": "On stronger forms of Devaney chaos",
    "authors": [
      "Shital H. Joshi",
      "Ekta Shah"
    ],
    "abstract": "We define and study stronger forms of Devaney chaos and name it as\n$\\mathscr{F}-$Devaney chaos, where $\\mathscr{F}$ is a family of subsets of\n$\\mathbb{N}$. Examples of maps which is $\\mathscr{F}_t-$Devaney chaotic but not\n$\\mathscr{F}_{cf}-$Devaney chaotic, $\\mathscr{F}_s-$Devaney chaotic but neither\n$\\mathscr{F}_t-$Devaney chaotic nor $\\mathscr{F}_{cf}-$Devaney chaotic are\ndiscussed. Further, we show that for the maps on infinite metric space without\nisolated points, $\\mathscr{F}-$sensitivity is a redundant condition in the\ndefinition $\\mathscr{F}-$Devaney chaos. Here $\\mathscr{F}=\\mathscr{F}_s, \\:\n\\mathscr{F}_t, \\: \\mathscr{F}_{ts}$ or $\\mathscr{F}_{cf}$. We also obtain\nconditions under which Devaney chaos implies $\\mathscr{F}_s-$Devaney chaos or\n$\\mathscr{F}_t-$Devaney chaos. Next, we define the concept of\n$\\left(\\mathscr{F}, \\mathscr{G}\\right)-P-$chaos and obtain conditions under\nwhich $\\left(\\mathscr{F}_1, \\mathscr{G}_1\\right)-P-$chaos implies\n$\\mathscr{F}-$Devaney chaos for different families $\\mathscr{F}_1$ and\n$\\mathscr{G}_1$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15286v1",
    "published": "2025-05-21T09:13:03+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15285v1",
    "title": "Reconsider the Template Mesh in Deep Learning-based Mesh Reconstruction",
    "authors": [
      "Fengting Zhang",
      "Boxu Liang",
      "Qinghao Liu",
      "Min Liu",
      "Xiang Chen",
      "Yaonan Wang"
    ],
    "abstract": "Mesh reconstruction is a cornerstone process across various applications,\nincluding in-silico trials, digital twins, surgical planning, and navigation.\nRecent advancements in deep learning have notably enhanced mesh reconstruction\nspeeds. Yet, traditional methods predominantly rely on deforming a standardised\ntemplate mesh for individual subjects, which overlooks the unique anatomical\nvariations between them, and may compromise the fidelity of the\nreconstructions. In this paper, we propose an adaptive-template-based mesh\nreconstruction network (ATMRN), which generates adaptive templates from the\ngiven images for the subsequent deformation, moving beyond the constraints of a\nsingular, fixed template. Our approach, validated on cortical magnetic\nresonance (MR) images from the OASIS dataset, sets a new benchmark in\nvoxel-to-cortex mesh reconstruction, achieving an average symmetric surface\ndistance of 0.267mm across four cortical structures. Our proposed method is\ngeneric and can be easily transferred to other image modalities and anatomical\nstructures.",
    "pdf_url": "http://arxiv.org/pdf/2505.15285v1",
    "published": "2025-05-21T09:10:31+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15284v1",
    "title": "Kernel PCA for Out-of-Distribution Detection: Non-Linear Kernel Selections and Approximations",
    "authors": [
      "Kun Fang",
      "Qinghua Tao",
      "Mingzhen He",
      "Kexin Lv",
      "Runze Yang",
      "Haibo Hu",
      "Xiaolin Huang",
      "Jie Yang",
      "Longbin Cao"
    ],
    "abstract": "Out-of-Distribution (OoD) detection is vital for the reliability of deep\nneural networks, the key of which lies in effectively characterizing the\ndisparities between OoD and In-Distribution (InD) data. In this work, such\ndisparities are exploited through a fresh perspective of non-linear feature\nsubspace. That is, a discriminative non-linear subspace is learned from InD\nfeatures to capture representative patterns of InD, while informative patterns\nof OoD features cannot be well captured in such a subspace due to their\ndifferent distribution. Grounded on this perspective, we exploit the deviations\nof InD and OoD features in such a non-linear subspace for effective OoD\ndetection. To be specific, we leverage the framework of Kernel Principal\nComponent Analysis (KPCA) to attain the discriminative non-linear subspace and\ndeploy the reconstruction error on such subspace to distinguish InD and OoD\ndata. Two challenges emerge: (i) the learning of an effective non-linear\nsubspace, i.e., the selection of kernel function in KPCA, and (ii) the\ncomputation of the kernel matrix with large-scale InD data. For the former, we\nreveal two vital non-linear patterns that closely relate to the InD-OoD\ndisparity, leading to the establishment of a Cosine-Gaussian kernel for\nconstructing the subspace. For the latter, we introduce two techniques to\napproximate the Cosine-Gaussian kernel with significantly cheap computations.\nIn particular, our approximation is further tailored by incorporating the InD\ndata confidence, which is demonstrated to promote the learning of\ndiscriminative subspaces for OoD data. Our study presents new insights into the\nnon-linear feature subspace for OoD detection and contributes practical\nexplorations on the associated kernel design and efficient computations,\nyielding a KPCA detection method with distinctively improved efficacy and\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.15284v1",
    "published": "2025-05-21T09:06:44+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17104v1",
    "title": "P2P: Automated Paper-to-Poster Generation and Fine-Grained Benchmark",
    "authors": [
      "Tao Sun",
      "Enhao Pan",
      "Zhengkai Yang",
      "Kaixin Sui",
      "Jiajun Shi",
      "Xianfu Cheng",
      "Tongliang Li",
      "Wenhao Huang",
      "Ge Zhang",
      "Jian Yang",
      "Zhoujun Li"
    ],
    "abstract": "Academic posters are vital for scholarly communication, yet their manual\ncreation is time-consuming. However, automated academic poster generation faces\nsignificant challenges in preserving intricate scientific details and achieving\neffective visual-textual integration. Existing approaches often struggle with\nsemantic richness and structural nuances, and lack standardized benchmarks for\nevaluating generated academic posters comprehensively. To address these\nlimitations, we introduce P2P, the first flexible, LLM-based multi-agent\nframework that generates high-quality, HTML-rendered academic posters directly\nfrom research papers, demonstrating strong potential for practical\napplications. P2P employs three specialized agents-for visual element\nprocessing, content generation, and final poster assembly-each integrated with\ndedicated checker modules to enable iterative refinement and ensure output\nquality. To foster advancements and rigorous evaluation in this domain, we\nconstruct and release P2PInstruct, the first large-scale instruction dataset\ncomprising over 30,000 high-quality examples tailored for the academic\npaper-to-poster generation task. Furthermore, we establish P2PEval, a\ncomprehensive benchmark featuring 121 paper-poster pairs and a dual evaluation\nmethodology (Universal and Fine-Grained) that leverages LLM-as-a-Judge and\ndetailed, human-annotated checklists. Our contributions aim to streamline\nresearch dissemination and provide the community with robust tools for\ndeveloping and evaluating next-generation poster generation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17104v1",
    "published": "2025-05-21T09:06:05+00:00",
    "categories": [
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15283v1",
    "title": "Quantization of Probability Distributions via Divide-and-Conquer: Convergence and Error Propagation under Distributional Arithmetic Operations",
    "authors": [
      "Bilgesu Arif Bilgin",
      "Olof Hallqvist Elias",
      "Michael Selby",
      "Phillip Stanley-Marbell"
    ],
    "abstract": "This article studies a general divide-and-conquer algorithm for approximating\ncontinuous one-dimensional probability distributions with finite mean. The\narticle presents a numerical study that compares pre-existing approximation\nschemes with a special focus on the stability of the discrete approximations\nwhen they undergo arithmetic operations. The main results are a simple upper\nbound of the approximation error in terms of the Wasserstein-1 distance that is\nvalid for all continuous distributions with finite mean. In many use-cases, the\nstudied method achieve optimal rate of convergence, and numerical experiments\nshow that the algorithm is more stable than pre-existing approximation schemes\nin the context of arithmetic operations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15283v1",
    "published": "2025-05-21T09:03:14+00:00",
    "categories": [
      "math.PR",
      "cs.CE",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15282v1",
    "title": "Exploring In-Image Machine Translation with Real-World Background",
    "authors": [
      "Yanzhi Tian",
      "Zeming Liu",
      "Zhengyang Liu",
      "Yuhang Guo"
    ],
    "abstract": "In-Image Machine Translation (IIMT) aims to translate texts within images\nfrom one language to another. Previous research on IIMT was primarily conducted\non simplified scenarios such as images of one-line text with black font in\nwhite backgrounds, which is far from reality and impractical for applications\nin the real world. To make IIMT research practically valuable, it is essential\nto consider a complex scenario where the text backgrounds are derived from\nreal-world images. To facilitate research of complex scenario IIMT, we design\nan IIMT dataset that includes subtitle text with real-world background. However\nprevious IIMT models perform inadequately in complex scenarios. To address the\nissue, we propose the DebackX model, which separates the background and\ntext-image from the source image, performs translation on text-image directly,\nand fuses the translated text-image with the background, to generate the target\nimage. Experimental results show that our model achieves improvements in both\ntranslation quality and visual effect.",
    "pdf_url": "http://arxiv.org/pdf/2505.15282v1",
    "published": "2025-05-21T09:02:53+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15281v1",
    "title": "A Unified Approach to Quantum Contraction and Correlation Coefficients",
    "authors": [
      "Ian George",
      "Marco Tomamichel"
    ],
    "abstract": "In classical information theory, the maximal correlation coefficient is used\nto establish strong limits on distributed processing. Through its relation to\nthe $\\chi^{2}$-contraction coefficient, it also establishes fundamental bounds\non sequential processing. Two distinct quantum extensions of the maximal\ncorrelation coefficient have been introduced to recover these two scenarios,\nbut they do not recover the entire classical framework. We introduce a family\nof non-commutative $L^{2}(p)$ spaces induced by operator monotone functions\nfrom which families of quantum maximal correlation coefficients and the quantum\n$\\chi^{2}$-divergences can be identified. Through this framework, we lift the\nclassical results to the quantum setting. For distributed processing, using our\nquantum maximal correlation coefficients, we establish strong limits on\nconverting quantum states under local operations. For sequential processing, we\nclarify the relation between the data processing inequality of quantum maximal\ncorrelation coefficients, $\\chi^{2}$-contraction coefficients, and\n$f$-divergences. Moreover, we establish the quantum maximal correlation\ncoefficients and $\\chi^{2}$-contraction coefficients are often computable via\nlinear algebraic methods, which in particular implies a method for obtaining\nrigorous, computable upper bounds for time-homogeneous quantum Markov chains\nwith a unique, full rank fixed point.",
    "pdf_url": "http://arxiv.org/pdf/2505.15281v1",
    "published": "2025-05-21T08:58:45+00:00",
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15280v2",
    "title": "Multisetting protocol for Bell correlated states detection with spin-$f$ systems",
    "authors": [
      "Arkadiusz Kobus",
      "Xinwei Li",
      "Mariusz Gajda",
      "Li You",
      "Emilia Witkowska"
    ],
    "abstract": "We propose a multisetting protocol for the detection of two-body Bell\ncorrelations, and apply it to spin-nematic squeezed states realized in $f$\npairs of SU(2) subsystems within spin-$f$ atomic Bose-Einstein condensates.\nExperimental data for $f=1$, alongside with numerical simulations using the\ntruncated Wigner method for $f=1,\\,2,\\,3$, demonstrate the effectiveness of the\nproposed protocol. Our findings extend the reach of multisetting Bell tests in\nultracold atomic system, paving the way for extended quantum information\nprocessing in high-spin ensemble platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15280v2",
    "published": "2025-05-21T08:58:31+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.15279v1",
    "title": "Robust Secure Communications in Near-Field ISCAP Systems with Extremely Large-Scale Antenna Array",
    "authors": [
      "Zixiang Ren",
      "Siyao Zhang",
      "Ling Qiu",
      "Derrick Wing Kwan Ng",
      "Jie Xu"
    ],
    "abstract": "This paper investigates robust secure communications in a near-field\nintegrated sensing, communication, and powering (ISCAP) system, in which the\nbase station (BS) is equipped with an extremely large-scale antenna array\n(ELAA). In this system, the BS transmits confidential messages to a single\nlegitimate communication user (CU), simultaneously providing wireless power\ntransfer to multiple energy receivers (ERs) and performing point target\nsensing. We consider a scenario in which both the ERs and the sensing target\nmay act as potential eavesdroppers attempting to intercept the confidential\nmessages. To safeguard secure communication, the BS employs a joint beamforming\ndesign by transmitting information beams combined with dedicated triple-purpose\nbeams serving as energy and sensing signals, as well as artificial noise (AN)\nfor effectively jamming potential eavesdroppers. It is assumed that only coarse\nlocation information of the ERs and sensing targets or eavesdroppers is\navailable at the BS, leading to imperfect channel state information (CSI).\nUnder this setup, we formulate a robust beamforming optimization problem with\nthe objective of maximizing the secrecy rate for the CU, while ensuring\nworst-case performance requirements on both target sensing and wireless energy\nharvesting at the ERs. To address the non-convex robust joint beamforming\nproblem and facilitate the deployment of a low-complexity algorithm, we employ\nthe S-procedure alongside an eavesdropping CSI error-bound determination method\nto acquire a high-quality solution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15279v1",
    "published": "2025-05-21T08:58:28+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15278v2",
    "title": "Analytic extensions of $A_{\\infty}$-weights on Lipschitz curves and their use in weighted Hardy spaces",
    "authors": [
      "Fernando Ballesta-Yag√ºe"
    ],
    "abstract": "An $A_{\\infty}$-weight on a Lipschitz curve $\\Lambda$ in the plane can be\nextended analytically to the graph Lipschitz domain $\\Omega$ above it. This\nproblem was studied by C. Kenig [Ken80], who introduced the class $AE$ of\nwell-behaved analytic extensions. Later, he and D. Jerison [JK82] added a\nSmirnov-type condition to the definition of this class.\n  In this note, we show that this Smirnov-type condition is equivalent to an\n$H^1$-integrability condition. As a consequence, one of the conditions in the\ndefinition of $AE$ can be dropped. We use this simplification to apply C.\nKenig's theory to prove results about weighted Hardy spaces. These are useful\nto study the Neumann problem in $\\Omega$ with boundary data in weighted spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.15278v2",
    "published": "2025-05-21T08:57:20+00:00",
    "categories": [
      "math.CA",
      "math.AP",
      "math.CV"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15277v1",
    "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents",
    "authors": [
      "Hyungjoo Chae",
      "Sunghwan Kim",
      "Junhee Cho",
      "Seungone Kim",
      "Seungjun Moon",
      "Gyeom Hwangbo",
      "Dongha Lim",
      "Minjin Kim",
      "Yeonjun Hwang",
      "Minju Gwak",
      "Dongwook Choi",
      "Minseok Kang",
      "Gwanhoon Im",
      "ByeongUng Cho",
      "Hyojun Kim",
      "Jun Hee Han",
      "Taeyoon Kwon",
      "Minju Kim",
      "Beong-woo Kwak",
      "Dongjin Kang",
      "Jinyoung Yeo"
    ],
    "abstract": "Web navigation is a unique domain that can automate many repetitive real-life\ntasks and is challenging as it requires long-horizon sequential decision making\nbeyond typical multimodal large language model (MLLM) tasks. Yet, specialized\nreward models for web navigation that can be utilized during both training and\ntest-time have been absent until now. Despite the importance of speed and\ncost-effectiveness, prior works have utilized MLLMs as reward models, which\nposes significant constraints for real-world deployment. To address this, in\nthis work, we propose the first process reward model (PRM) called Web-Shepherd\nwhich could assess web navigation trajectories in a step-level. To achieve\nthis, we first construct the WebPRM Collection, a large-scale dataset with 40K\nstep-level preference pairs and annotated checklists spanning diverse domains\nand difficulty levels. Next, we also introduce the WebRewardBench, the first\nmeta-evaluation benchmark for evaluating PRMs. In our experiments, we observe\nthat our Web-Shepherd achieves about 30 points better accuracy compared to\nusing GPT-4o on WebRewardBench. Furthermore, when testing on WebArena-lite by\nusing GPT-4o-mini as the policy and Web-Shepherd as the verifier, we achieve\n10.9 points better performance, in 10 less cost compared to using GPT-4o-mini\nas the verifier. Our model, dataset, and code are publicly available at LINK.",
    "pdf_url": "http://arxiv.org/pdf/2505.15277v1",
    "published": "2025-05-21T08:56:55+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15276v1",
    "title": "When Can Large Reasoning Models Save Thinking? Mechanistic Analysis of Behavioral Divergence in Reasoning",
    "authors": [
      "Rongzhi Zhu",
      "Yi Liu",
      "Zequn Sun",
      "Yiwei Wang",
      "Wei Hu"
    ],
    "abstract": "Large reasoning models (LRMs) have significantly advanced performance on\ncomplex tasks, yet their tendency to overthink introduces inefficiencies. This\nstudy investigates the internal mechanisms of reinforcement learning\n(RL)-trained LRMs when prompted to save thinking, revealing three distinct\nthinking modes: no thinking (NT), explicit thinking (ET), and implicit thinking\n(IT). Through comprehensive analysis of confidence in thinking termination,\nattention from thinking to generation, and attentional focus on input sections,\nwe uncover key factors influencing the reasoning behaviors. We further find\nthat NT reduces output length at the cost of accuracy, while ET and IT maintain\naccuracy with reduced response length. Our findings expose fundamental\ninconsistencies in RL-optimized LRMs, necessitating adaptive improvements for\nreliable efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.15276v1",
    "published": "2025-05-21T08:55:35+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15275v1",
    "title": "Learning-based Autonomous Oversteer Control and Collision Avoidance",
    "authors": [
      "Seokjun Lee",
      "Seung-Hyun Kong"
    ],
    "abstract": "Oversteer, wherein a vehicle's rear tires lose traction and induce\nunintentional excessive yaw, poses critical safety challenges. Failing to\ncontrol oversteer often leads to severe traffic accidents. Although recent\nautonomous driving efforts have attempted to handle oversteer through\nstabilizing maneuvers, the majority rely on expert-defined trajectories or\nassume obstacle-free environments, limiting real-world applicability. This\npaper introduces a novel end-to-end (E2E) autonomous driving approach that\ntackles oversteer control and collision avoidance simultaneously. Existing E2E\ntechniques, including Imitation Learning (IL), Reinforcement Learning (RL), and\nHybrid Learning (HL), generally require near-optimal demonstrations or\nextensive experience. Yet even skilled human drivers struggle to provide\nperfect demonstrations under oversteer, and high transition variance hinders\naccumulating sufficient data. Hence, we present Q-Compared Soft Actor-Critic\n(QC-SAC), a new HL algorithm that effectively learns from suboptimal\ndemonstration data and adapts rapidly to new conditions. To evaluate QC-SAC, we\nintroduce a benchmark inspired by real-world driver training: a vehicle\nencounters sudden oversteer on a slippery surface and must avoid randomly\nplaced obstacles ahead. Experimental results show QC-SAC attains near-optimal\ndriving policies, significantly surpassing state-of-the-art IL, RL, and HL\nbaselines. Our method demonstrates the world's first safe autonomous oversteer\ncontrol with obstacle avoidance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15275v1",
    "published": "2025-05-21T08:53:38+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17103v1",
    "title": "Forging Time Series with Language: A Large Language Model Approach to Synthetic Data Generation",
    "authors": [
      "C√©cile Rousseau",
      "Tobia Boschi",
      "Giandomenico Cornacchia",
      "Dhaval Salwala",
      "Alessandra Pascale",
      "Juan Bernabe Moreno"
    ],
    "abstract": "SDForger is a flexible and efficient framework for generating high-quality\nmultivariate time series using LLMs. Leveraging a compact data representation,\nSDForger provides synthetic time series generation from a few samples and\nlow-computation fine-tuning of any autoregressive LLM. Specifically, the\nframework transforms univariate and multivariate signals into tabular\nembeddings, which are then encoded into text and used to fine-tune the LLM. At\ninference, new textual embeddings are sampled and decoded into synthetic time\nseries that retain the original data's statistical properties and temporal\ndynamics. Across a diverse range of datasets, SDForger outperforms existing\ngenerative models in many scenarios, both in similarity-based evaluations and\ndownstream forecasting tasks. By enabling textual conditioning in the\ngeneration process, SDForger paves the way for multimodal modeling and the\nstreamlined integration of time series with textual information. SDForger\nsource code will be open-sourced soon.",
    "pdf_url": "http://arxiv.org/pdf/2505.17103v1",
    "published": "2025-05-21T08:50:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15274v2",
    "title": "Identification of Probabilities of Causation: A Complete Characterization",
    "authors": [
      "Xin Shu",
      "Shuai Wang",
      "Ang Li"
    ],
    "abstract": "Probabilities of causation are fundamental to modern decision-making. Pearl\nfirst introduced three binary probabilities of causation, and Tian and Pearl\nlater derived tight bounds for them using Balke's linear programming. The\ntheoretical characterization of probabilities of causation with multi-valued\ntreatments and outcomes has remained unresolved for decades, limiting the scope\nof causality-based decision-making. In this paper, we resolve this foundational\ngap by proposing a complete set of representative probabilities of causation\nand proving that they are sufficient to characterize all possible probabilities\nof causation within the framework of Structural Causal Models (SCMs). We then\nformally derive tight bounds for these representative quantities using formal\nmathematical proofs. Finally, we demonstrate the practical relevance of our\nresults through illustrative toy examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.15274v2",
    "published": "2025-05-21T08:50:12+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15273v1",
    "title": "Non-weight modules over gap-$p$ Virasoro algebras",
    "authors": [
      "Chengkang Xu",
      "Fulin Chen",
      "Shaobin Tan"
    ],
    "abstract": "In this paper, we study non-weight modules over gap-$p$ Virasoro algebras,\nincluding Whittaker modules, $\\mathcal{U}(\\mathbb{C} L_0)$-free modules and\ntheir tensor products. We establish necessary and sufficient conditions for\nuniversal Whittaker modules to be irreducible and study the structure of\nirreducible Whittaker modules. The $\\mathcal{U}(\\mathbb{C} L_0)$-free modules\nof rank 1 are classified and the irreducibility of such modules are determined.\nMoreover, the irreducibility of tensor products of $\\mathcal{U}(\\mathbb{C}\nL_0)$-free modules of rank 1 and irreducible restricted modules is also\ndetermined.",
    "pdf_url": "http://arxiv.org/pdf/2505.15273v1",
    "published": "2025-05-21T08:50:01+00:00",
    "categories": [
      "math.RT",
      "17B10, 17B65, 17B66, 17B68, 17B69"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15272v1",
    "title": "DiffProb: Data Pruning for Face Recognition",
    "authors": [
      "Eduarda Caldeira",
      "Jan Niklas Kolf",
      "Naser Damer",
      "Fadi Boutros"
    ],
    "abstract": "Face recognition models have made substantial progress due to advances in\ndeep learning and the availability of large-scale datasets. However, reliance\non massive annotated datasets introduces challenges related to training\ncomputational cost and data storage, as well as potential privacy concerns\nregarding managing large face datasets. This paper presents DiffProb, the first\ndata pruning approach for the application of face recognition. DiffProb\nassesses the prediction probabilities of training samples within each identity\nand prunes the ones with identical or close prediction probability values, as\nthey are likely reinforcing the same decision boundaries, and thus contribute\nminimally with new information. We further enhance this process with an\nauxiliary cleaning mechanism to eliminate mislabeled and label-flipped samples,\nboosting data quality with minimal loss. Extensive experiments on CASIA-WebFace\nwith different pruning ratios and multiple benchmarks, including LFW, CFP-FP,\nand IJB-C, demonstrate that DiffProb can prune up to 50% of the dataset while\nmaintaining or even, in some settings, improving the verification accuracies.\nAdditionally, we demonstrate DiffProb's robustness across different\narchitectures and loss functions. Our method significantly reduces training\ncost and data volume, enabling efficient face recognition training and reducing\nthe reliance on massive datasets and their demanding management.",
    "pdf_url": "http://arxiv.org/pdf/2505.15272v1",
    "published": "2025-05-21T08:49:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15271v1",
    "title": "WISP: Image Segmentation-Based Whitespace Diagnosis for Optimal Rectilinear Floorplanning",
    "authors": [
      "Xiaotian Zhao",
      "Zixuan Li",
      "Yichen Cai",
      "Xinfei Guo"
    ],
    "abstract": "The increasing number of rectilinear floorplans in modern chip designs\npresents significant challenges for traditional macro placers due to the\nadditional complexity introduced by blocked corners. Particularly, the widely\nadopted wirelength model Half-Perimeter Wirelength (HPWL) struggles to\naccurately handle rectilinear boundaries, highlighting the need for additional\nobjectives tailored to rectilinear floorplan optimization. In this paper, we\nidentify the necessity for whitespace diagnosis in rectilinear floorplanning,\nan aspect often overlooked in past research. We introduce WISP, a novel\nframework that analyzes and scores whitespace regions to guide placement\noptimization. WISP leverages image segmentation techniques for whitespace\nparsing, a lightweight probabilistic model to score whitespace regions based on\nmacro distribution, a Gaussian Mixture Model (GMM) for whitespace density\nscoring and direction-aware macro relocation to iteratively refine macro\nplacement, reduce wasted whitespace, and enhance design quality. The proposed\ndiagnostic technique also enables the reclamation of block-level unused area\nand its return to the top level, maximizing overall area utilization. When\ncompared against state-of-the-art academia placer DREAMPlace 4.1, our method\nachieves an average improvement of 5.4% in routing wirelength, with a maximum\nof 11.4% across widely-used benchmarks. This yields an average of 41.5% and\n43.7% improvement in Worst Negative Slack (WNS) and Total Negative Slack (TNS),\nrespectively. Additionally, WISP recycles an average of 16.2% area at the block\nlevel, contributing to more efficient top-level area distribution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15271v1",
    "published": "2025-05-21T08:49:04+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15270v1",
    "title": "Scaling Diffusion Transformers Efficiently via $Œº$P",
    "authors": [
      "Chenyu Zheng",
      "Xinyu Zhang",
      "Rongzhen Wang",
      "Wei Huang",
      "Zhi Tian",
      "Weilin Huang",
      "Jun Zhu",
      "Chongxuan Li"
    ],
    "abstract": "Diffusion Transformers have emerged as the foundation for vision generative\nmodels, but their scalability is limited by the high cost of hyperparameter\n(HP) tuning at large scales. Recently, Maximal Update Parametrization ($\\mu$P)\nwas proposed for vanilla Transformers, which enables stable HP transfer from\nsmall to large language models, and dramatically reduces tuning costs. However,\nit remains unclear whether $\\mu$P of vanilla Transformers extends to diffusion\nTransformers, which differ architecturally and objectively. In this work, we\ngeneralize standard $\\mu$P to diffusion Transformers and validate its\neffectiveness through large-scale experiments. First, we rigorously prove that\n$\\mu$P of mainstream diffusion Transformers, including DiT, U-ViT,\nPixArt-$\\alpha$, and MMDiT, aligns with that of the vanilla Transformer,\nenabling the direct application of existing $\\mu$P methodologies. Leveraging\nthis result, we systematically demonstrate that DiT-$\\mu$P enjoys robust HP\ntransferability. Notably, DiT-XL-2-$\\mu$P with transferred learning rate\nachieves 2.9 times faster convergence than the original DiT-XL-2. Finally, we\nvalidate the effectiveness of $\\mu$P on text-to-image generation by scaling\nPixArt-$\\alpha$ from 0.04B to 0.61B and MMDiT from 0.18B to 18B. In both cases,\nmodels under $\\mu$P outperform their respective baselines while requiring small\ntuning cost, only 5.5% of one training run for PixArt-$\\alpha$ and 3% of\nconsumption by human experts for MMDiT-18B. These results establish $\\mu$P as a\nprincipled and efficient framework for scaling diffusion Transformers.",
    "pdf_url": "http://arxiv.org/pdf/2505.15270v1",
    "published": "2025-05-21T08:49:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15269v1",
    "title": "LiveVLM: Efficient Online Video Understanding via Streaming-Oriented KV Cache and Retrieval",
    "authors": [
      "Zhenyu Ning",
      "Guangda Liu",
      "Qihao Jin",
      "Wenchao Ding",
      "Minyi Guo",
      "Jieru Zhao"
    ],
    "abstract": "Recent developments in Video Large Language Models (Video LLMs) have enabled\nmodels to process long video sequences and demonstrate remarkable performance.\nNonetheless, studies predominantly focus on offline video question answering,\nneglecting memory usage and response speed that are essential in various\nreal-world applications, such as Deepseek services, autonomous driving, and\nrobotics. To mitigate these challenges, we propose $\\textbf{LiveVLM}$, a\ntraining-free framework specifically designed for streaming, online video\nunderstanding and real-time interaction. Unlike existing works that process\nvideos only after one question is posed, LiveVLM constructs an innovative\nstreaming-oriented KV cache to process video streams in real-time, retain\nlong-term video details and eliminate redundant KVs, ensuring prompt responses\nto user queries. For continuous video streams, LiveVLM generates and compresses\nvideo key-value tensors (video KVs) to reserve visual information while\nimproving memory efficiency. Furthermore, when a new question is proposed,\nLiveVLM incorporates an online question-answering process that efficiently\nfetches both short-term and long-term visual information, while minimizing\ninterference from redundant context. Extensive experiments demonstrate that\nLiveVLM enables the foundation LLaVA-OneVision model to process 44$\\times$\nnumber of frames on the same device, and achieves up to 5$\\times$ speedup in\nresponse speed compared with SoTA online methods at an input of 256 frames,\nwhile maintaining the same or better model performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15269v1",
    "published": "2025-05-21T08:47:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15268v1",
    "title": "Fiber Nonlinearity Mitigation in Coherent Optical Systems",
    "authors": [
      "Stella Civelli",
      "Dario Cellini",
      "Enrico Forestieri",
      "Marco Secondini"
    ],
    "abstract": "Fiber nonlinearity represents a critical challenge to the capacity\nenhancement of modern optical communication systems. In recent years,\nsignificant research efforts have focused on mitigating its impact through two\ncomplementary approaches. On the one hand, researchers have investigated\npractical digital signal processing (DSP) techniques to mitigate or compensate\nfor nonlinear impairments, such as reversing fiber propagation effects through\ndigital backpropagation (DBP). However, the high computational complexity of\nthese techniques often discourages their practical implementation. On the other\nhand, information-theoretic studies have sought to establish the capacity\nlimits of the nonlinear optical fiber channel, providing a framework for\nevaluating the ultimate performance of existing optical networks and guiding\nthe design of next-generation systems. This work reviews recent advances and\nproposes future directions for nonlinearity compensation and mitigation,\nincluding constellation shaping techniques and low-complexity DBP. Furthermore,\nit highlights the potential of these innovations both in advancing the\ntheoretical understanding of fiber capacity limits and in enabling practical\nDSP implementations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15268v1",
    "published": "2025-05-21T08:47:02+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15267v2",
    "title": "Contrastive Learning-Enhanced Trajectory Matching for Small-Scale Dataset Distillation",
    "authors": [
      "Wenmin Li",
      "Shunsuke Sakai",
      "Tatsuhito Hasegawa"
    ],
    "abstract": "Deploying machine learning models in resource-constrained environments, such\nas edge devices or rapid prototyping scenarios, increasingly demands\ndistillation of large datasets into significantly smaller yet informative\nsynthetic datasets. Current dataset distillation techniques, particularly\nTrajectory Matching methods, optimize synthetic data so that the model's\ntraining trajectory on synthetic samples mirrors that on real data. While\ndemonstrating efficacy on medium-scale synthetic datasets, these methods fail\nto adequately preserve semantic richness under extreme sample scarcity. To\naddress this limitation, we propose a novel dataset distillation method\nintegrating contrastive learning during image synthesis. By explicitly\nmaximizing instance-level feature discrimination, our approach produces more\ninformative and diverse synthetic samples, even when dataset sizes are\nsignificantly constrained. Experimental results demonstrate that incorporating\ncontrastive learning substantially enhances the performance of models trained\non very small-scale synthetic datasets. This integration not only guides more\neffective feature representation but also significantly improves the visual\nfidelity of the synthesized images. Experimental results demonstrate that our\nmethod achieves notable performance improvements over existing distillation\ntechniques, especially in scenarios with extremely limited synthetic data.",
    "pdf_url": "http://arxiv.org/pdf/2505.15267v2",
    "published": "2025-05-21T08:46:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15266v1",
    "title": "Bonding relay for room-temperature oxide plasticity like metals",
    "authors": [
      "Xiangkai Chen",
      "Yuhong Li",
      "Xiaofei Zhu",
      "Yun-Long Tang",
      "Shi Liu"
    ],
    "abstract": "Oxides have long been regarded as intrinsically brittle due to their strong,\ndirectional ionic or covalent bonds, in stark contrast to the ductile behavior\nof metals, where delocalized electron sharing enables plasticity through facile\ndislocation glide. Here, we challenge this paradigm by demonstrating that\ntypical oxides, such as SrTiO3 and MgO, can exhibit room-temperature plasticity\nwith pronounced crystallographic anisotropy. Through an integrated approach\ncombining ab initio calculations, large scale molecular dynamics simulations,\nand experimental nanoindentation, we identify a universal structural criterion\nenabling room-temperature oxide plasticity: the presence of alternating\npositively and negatively charged atomic layers along specific slip directions,\nspecifically the (1-10)[110] orientation in perovskite and rocksalt oxides.\nThis charge alternating configuration enables a bonding relay mechanism, in\nwhich sequential bond breaking and reformation across the slip plane\naccompanied by interlayer persistent bonds mimics multi centered interactions\nin metals, thereby facilitating dislocation motion without catastrophic\nfailure. Our findings reveal a previously unrecognized pathway to achieving\nmetal-like plasticity in oxides and establish a structural design principle for\nengineering flexible and mechanically resilient oxide materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.15266v1",
    "published": "2025-05-21T08:46:02+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15265v2",
    "title": "Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs",
    "authors": [
      "Zihao Pan",
      "Yu Tong",
      "Weibin Wu",
      "Jingyi Wang",
      "Lifeng Chen",
      "Zhe Zhao",
      "Jiajia Wei",
      "Yitong Qiao",
      "Zibin Zheng"
    ],
    "abstract": "Adversarial attacks aim to generate malicious inputs that mislead deep\nmodels, but beyond causing model failure, they cannot provide certain\ninterpretable information such as ``\\textit{What content in inputs make models\nmore likely to fail?}'' However, this information is crucial for researchers to\nspecifically improve model robustness. Recent research suggests that models may\nbe particularly sensitive to certain semantics in visual inputs (such as\n``wet,'' ``foggy''), making them prone to errors. Inspired by this, in this\npaper we conducted the first exploration on large vision-language models\n(LVLMs) and found that LVLMs indeed are susceptible to hallucinations and\nvarious errors when facing specific semantic concepts in images. To efficiently\nsearch for these sensitive concepts, we integrated large language models (LLMs)\nand text-to-image (T2I) models to propose a novel semantic evolution framework.\nRandomly initialized semantic concepts undergo LLM-based crossover and mutation\noperations to form image descriptions, which are then converted by T2I models\ninto visual inputs for LVLMs. The task-specific performance of LVLMs on each\ninput is quantified as fitness scores for the involved semantics and serves as\nreward signals to further guide LLMs in exploring concepts that induce LVLMs.\nExtensive experiments on seven mainstream LVLMs and two multimodal tasks\ndemonstrate the effectiveness of our method. Additionally, we provide\ninteresting findings about the sensitive semantics of LVLMs, aiming to inspire\nfurther in-depth research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15265v2",
    "published": "2025-05-21T08:45:43+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15264v1",
    "title": "[Dispersion for the wave equation in the exterior of the torus]{Dispersion for the wave equation in the exterior of the torus in three dimensions}",
    "authors": [
      "Ronald Quirchmayr",
      "Alden Waters"
    ],
    "abstract": "We prove dispersive estimates for the wave equation in the exterior of a\ntorus. Because no separation of variables into a basis of eigenfunctions and\neigenvalues exists for the time harmonic problem, we introduce a related\napproximate operator for the Dirichlet Laplacian in the exterior of a torus.\nThe approximate operator coincides with the Schr\\\"odinger operator with a\nP\\\"oschl-Teller potential and agrees with the Dirichlet Laplacian to leading\norder. The operator here which we develop is related to the so-called\nMehler-Fock kernel. Using the known solution to the eigenvector and eigenvalue\nproblem of P\\\"oschl-Teller, a high-frequency analysis of the approximate\noperator for the wave equation can be made accurately. The operator for this\nproblem gives a close approximation to the $L^1\\rightarrow L^{\\infty}$\ndispersive estimate at a suitable small distance from the torus for the\ncorresponding exterior wave operator with Dirichlet Laplacian.",
    "pdf_url": "http://arxiv.org/pdf/2505.15264v1",
    "published": "2025-05-21T08:43:14+00:00",
    "categories": [
      "math.AP",
      "math.SP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15263v1",
    "title": "gen2seg: Generative Models Enable Generalizable Instance Segmentation",
    "authors": [
      "Om Khangaonkar",
      "Hamed Pirsiavash"
    ],
    "abstract": "By pretraining to synthesize coherent images from perturbed inputs,\ngenerative models inherently learn to understand object boundaries and scene\ncompositions. How can we repurpose these generative representations for\ngeneral-purpose perceptual organization? We finetune Stable Diffusion and MAE\n(encoder+decoder) for category-agnostic instance segmentation using our\ninstance coloring loss exclusively on a narrow set of object types (indoor\nfurnishings and cars). Surprisingly, our models exhibit strong zero-shot\ngeneralization, accurately segmenting objects of types and styles unseen in\nfinetuning (and in many cases, MAE's ImageNet-1K pretraining too). Our\nbest-performing models closely approach the heavily supervised SAM when\nevaluated on unseen object types and styles, and outperform it when segmenting\nfine structures and ambiguous boundaries. In contrast, existing promptable\nsegmentation architectures or discriminatively pretrained models fail to\ngeneralize. This suggests that generative models learn an inherent grouping\nmechanism that transfers across categories and domains, even without\ninternet-scale pretraining. Code, pretrained models, and demos are available on\nour website.",
    "pdf_url": "http://arxiv.org/pdf/2505.15263v1",
    "published": "2025-05-21T08:42:05+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15262v1",
    "title": "A minimum problem associated with scalar Ginzburg-Landau equation and free boundary",
    "authors": [
      "Yuwei Hu",
      "Jun Zheng",
      "Leandro S. Tavares"
    ],
    "abstract": "Let $N>2$, $p\\in \\left(\\frac{2N}{N+2},+\\infty\\right)$, and $\\Omega$ be an\nopen bounded domain in $\\mathbb{R}^N$. We consider the minimum problem\n  $$\n  \\mathcal{J} (u) := \\displaystyle\\int_{\\Omega } \\left(\\frac{1}{p}| \\nabla u|\n^p+\\lambda_1\\left(1-(u^+)^2\\right)^2+\\lambda_2u^+\\right)\\text{d}x\\rightarrow\n\\text{min}\n  $$\n  over a certain class $\\mathcal{K}$, where $\\lambda_1\\geq 0$ and $\n\\lambda_2\\in \\mathbb{R}$ are constants, and $u^+:=\\max\\{u,0\\}$.\n  The corresponding Euler-Lagrange equation is related to the Ginzburg-Landau\nequation and involves a subcritical exponent when $\\lambda_1>0$.\n  For $\\lambda_1\\geq 0$ and $ \\lambda_2\\in \\mathbb{R}$, we prove the existence,\nnon-negativity, and uniform boundedness of minimizers of $\\mathcal{J} (u) $.\nThen, we show that any minimizer is locally $C^{1,\\alpha}$-continuous with some\n$\\alpha\\in (0,1)$ and admits the optimal growth $\\frac{p}{p-1}$ near the free\nboundary. Finally, under the additional assumption that $\\lambda_2>0$, we\nestablish non-degeneracy for minimizers near the free boundary and show that\nthere exists at least one minimizer for which the corresponding free boundary\nhas finite ($N-1$)-dimensional Hausdorff measure.",
    "pdf_url": "http://arxiv.org/pdf/2505.15262v1",
    "published": "2025-05-21T08:39:43+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15261v1",
    "title": "AGENT-X: Adaptive Guideline-based Expert Network for Threshold-free AI-generated teXt detection",
    "authors": [
      "Jiatao Li",
      "Mao Ye",
      "Cheng Peng",
      "Xunjian Yin",
      "Xiaojun Wan"
    ],
    "abstract": "Existing AI-generated text detection methods heavily depend on large\nannotated datasets and external threshold tuning, restricting interpretability,\nadaptability, and zero-shot effectiveness. To address these limitations, we\npropose AGENT-X, a zero-shot multi-agent framework informed by classical\nrhetoric and systemic functional linguistics. Specifically, we organize\ndetection guidelines into semantic, stylistic, and structural dimensions, each\nindependently evaluated by specialized linguistic agents that provide explicit\nreasoning and robust calibrated confidence via semantic steering. A meta agent\nintegrates these assessments through confidence-aware aggregation, enabling\nthreshold-free, interpretable classification. Additionally, an adaptive\nMixture-of-Agent router dynamically selects guidelines based on inferred\ntextual characteristics. Experiments on diverse datasets demonstrate that\nAGENT-X substantially surpasses state-of-the-art supervised and zero-shot\napproaches in accuracy, interpretability, and generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.15261v1",
    "published": "2025-05-21T08:39:18+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15260v1",
    "title": "How thin does random interlacement have to be so that a random walk can see through it?",
    "authors": [
      "Nicolas Bouchot"
    ],
    "abstract": "The random interlacements $\\mathscr{I}(u)$ at level $u$ has been introduced\nby Sznitman, as a Poissonian collection of independent simple random walk\ntrajectories on $\\mathbb{Z}^d$, $d\\geq 3$, with intensity $u>0$. Since then,\nseveral works investigated the properties of the random interlacements\nintersected with large sets of~$\\mathbb{Z}^d$.\n  In this paper, we study the asymptotic behavior of the capacity of\n$\\mathscr{I}(u) \\cap D_N$, where $D_N$ is the blow up of a compact set $D$,\nwith typical size $N$. We determine the correct window $(u_N)_{N\\geq 1}$ of the\nintensity parameter for which the capacity $\\mathrm{cap}(\\mathscr{I}(u_N)\\cap\nD_N)$ starts to become negligible compared to $\\mathrm{cap}(D_N)$; this roughly\nmeans that a random walk starting from far away starts to see through\n$\\mathscr{I}(u_N)\\cap D_N$.\n  In the same spirit, we investigate the capacity of the simple random walk\nconditioned to stay in a large Euclidean ball up to time $t_N$, and find\nsimilar asymptotics by taking $t_N = u_N N^d$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15260v1",
    "published": "2025-05-21T08:36:38+00:00",
    "categories": [
      "math.PR",
      "60G50, 60K35"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15259v2",
    "title": "ReGUIDE: Data Efficient GUI Grounding via Spatial Reasoning and Search",
    "authors": [
      "Hyunseok Lee",
      "Jeonghoon Kim",
      "Beomjun Kim",
      "Jihoon Tack",
      "Chansong Jo",
      "Jaehong Lee",
      "Cheonbok Park",
      "Sookyo In",
      "Jinwoo Shin",
      "Kang Min Yoo"
    ],
    "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled\nautonomous agents to interact with computers via Graphical User Interfaces\n(GUIs), where accurately localizing the coordinates of interface elements\n(e.g., buttons) is often required for fine-grained actions. However, this\nremains significantly challenging, leading prior works to rely on large-scale\nweb datasets to improve the grounding accuracy. In this work, we propose\nReasoning Graphical User Interface Grounding for Data Efficiency (ReGUIDE), a\nnovel and effective framework for web grounding that enables MLLMs to learn\ndata efficiently through self-generated reasoning and spatial-aware criticism.\nMore specifically, ReGUIDE learns to (i) self-generate a language reasoning\nprocess for the localization via online reinforcement learning, and (ii)\ncriticize the prediction using spatial priors that enforce equivariance under\ninput transformations. At inference time, ReGUIDE further boosts performance\nthrough a test-time scaling strategy, which combines spatial search with\ncoordinate aggregation. Our experiments demonstrate that ReGUIDE significantly\nadvances web grounding performance across multiple benchmarks, outperforming\nbaselines with substantially fewer training data points (e.g., only 0.2%\nsamples compared to the best open-sourced baselines).",
    "pdf_url": "http://arxiv.org/pdf/2505.15259v2",
    "published": "2025-05-21T08:36:18+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15258v3",
    "title": "On the distances of an element to its conjugates",
    "authors": [
      "Josnei Novacoski"
    ],
    "abstract": "For a valued field $(K,v)$, with a fixed extension of $v$ to the algebraic\nclosure $\\overline K$ of $K$, and an element $\\theta\\in\\overline K$, we are\ninterested in the possible values of $\\theta-\\theta'$ where $\\theta'$ runs\nthrough all the $K$-conjugates of $\\theta$. The study of these values is a\nclassic problem in number theory and ramification theory. However, the classic\nresults focus on tame, and in particular defectless, extensions. In this paper\nwe focus on the study of defect extensions. We want to compare the number of\nsuch values to invariants of $\\theta$. The main invariant we have in mind is\nthe depth of $\\theta$. We present various examples that show that, in the\ndefect case, none of the equivalent of the classic results are true. We also\ndiscuss the relation between the number of such values and the number of\nramification ideals of the extension $(K(\\theta)/K,v)$. In order to do so, we\npresent some results about ramification ideals that have interest on their own.",
    "pdf_url": "http://arxiv.org/pdf/2505.15258v3",
    "published": "2025-05-21T08:35:54+00:00",
    "categories": [
      "math.AC"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15257v1",
    "title": "When Less Language is More: Language-Reasoning Disentanglement Makes LLMs Better Multilingual Reasoners",
    "authors": [
      "Weixiang Zhao",
      "Jiahe Guo",
      "Yang Deng",
      "Tongtong Wu",
      "Wenxuan Zhang",
      "Yulin Hu",
      "Xingyu Sui",
      "Yanyan Zhao",
      "Wanxiang Che",
      "Bing Qin",
      "Tat-Seng Chua",
      "Ting Liu"
    ],
    "abstract": "Multilingual reasoning remains a significant challenge for large language\nmodels (LLMs), with performance disproportionately favoring high-resource\nlanguages. Drawing inspiration from cognitive neuroscience, which suggests that\nhuman reasoning functions largely independently of language processing, we\nhypothesize that LLMs similarly encode reasoning and language as separable\ncomponents that can be disentangled to enhance multilingual reasoning. To\nevaluate this, we perform a causal intervention by ablating language-specific\nrepresentations at inference time. Experiments on 10 open-source LLMs spanning\n11 typologically diverse languages show that this language-specific ablation\nconsistently boosts multilingual reasoning performance. Layer-wise analyses\nfurther confirm that language and reasoning representations can be effectively\ndecoupled throughout the model, yielding improved multilingual reasoning\ncapabilities, while preserving top-layer language features remains essential\nfor maintaining linguistic fidelity. Compared to post-training such as\nsupervised fine-tuning or reinforcement learning, our training-free ablation\nachieves comparable or superior results with minimal computational overhead.\nThese findings shed light on the internal mechanisms underlying multilingual\nreasoning in LLMs and suggest a lightweight and interpretable strategy for\nimproving cross-lingual generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.15257v1",
    "published": "2025-05-21T08:35:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15256v2",
    "title": "Zero-Shot Gaze-based Volumetric Medical Image Segmentation",
    "authors": [
      "Tatyana Shmykova",
      "Leila Khaertdinova",
      "Ilya Pershin"
    ],
    "abstract": "Accurate segmentation of anatomical structures in volumetric medical images\nis crucial for clinical applications, including disease monitoring and cancer\ntreatment planning. Contemporary interactive segmentation models, such as\nSegment Anything Model 2 (SAM-2) and its medical variant (MedSAM-2), rely on\nmanually provided prompts like bounding boxes and mouse clicks. In this study,\nwe introduce eye gaze as a novel informational modality for interactive\nsegmentation, marking the application of eye-tracking for 3D medical image\nsegmentation. We evaluate the performance of using gaze-based prompts with\nSAM-2 and MedSAM-2 using both synthetic and real gaze data. Compared to\nbounding boxes, gaze-based prompts offer a time-efficient interaction approach\nwith slightly lower segmentation quality. Our findings highlight the potential\nof using gaze as a complementary input modality for interactive 3D medical\nimage segmentation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15256v2",
    "published": "2025-05-21T08:34:13+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15255v2",
    "title": "MentalMAC: Enhancing Large Language Models for Detecting Mental Manipulation via Multi-Task Anti-Curriculum Distillation",
    "authors": [
      "Yuansheng Gao",
      "Han Bao",
      "Tong Zhang",
      "Bin Li",
      "Zonghui Wang",
      "Wenzhi Chen"
    ],
    "abstract": "Mental manipulation is a subtle yet pervasive form of psychological abuse\nthat poses serious threats to mental health. Its covert nature and the\ncomplexity of manipulation strategies make it challenging to detect, even for\nstate-of-the-art large language models (LLMs). This concealment also hinders\nthe manual collection of large-scale, high-quality annotations essential for\ntraining effective models. Although recent efforts have sought to improve LLMs'\nperformance on this task, progress remains limited due to the scarcity of\nreal-world annotated datasets. To address these challenges, we propose\nMentalMAC, a multi-task anti-curriculum distillation method that enhances LLMs'\nability to detect mental manipulation in multi-turn dialogue. Our approach\nincludes: (i) EvoSA, an unsupervised data expansion method based on\nevolutionary operations and speech act theory; (ii) teacher model-generated\nmulti-task supervision; and (iii) progressive knowledge distillation from\ncomplex to simpler tasks. We then constructed the ReaMent dataset with 5,000\nreal-world dialogue samples, using a MentalMAC-distilled model to assist human\nannotation. Vast experiments demonstrate that our method significantly narrows\nthe gap between student and teacher models and outperforms competitive LLMs\nacross key evaluation metrics. All code, datasets, and checkpoints will be\nreleased upon paper acceptance. Warning: This paper contains content that may\nbe offensive to readers.",
    "pdf_url": "http://arxiv.org/pdf/2505.15255v2",
    "published": "2025-05-21T08:34:06+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15254v1",
    "title": "Voice-ENHANCE: Speech Restoration using a Diffusion-based Voice Conversion Framework",
    "authors": [
      "Kyungguen Byun",
      "Jason Filos",
      "Erik Visser",
      "Sunkuk Moon"
    ],
    "abstract": "We propose a speech enhancement system that combines speaker-agnostic speech\nrestoration with voice conversion (VC) to obtain a studio-level quality speech\nsignal. While voice conversion models are typically used to change speaker\ncharacteristics, they can also serve as a means of speech restoration when the\ntarget speaker is the same as the source speaker. However, since VC models are\nvulnerable to noisy conditions, we have included a generative speech\nrestoration (GSR) model at the front end of our proposed system. The GSR model\nperforms noise suppression and restores speech damage incurred during that\nprocess without knowledge about the target speaker. The VC stage then uses\nguidance from clean speaker embeddings to further restore the output speech. By\nemploying this two-stage approach, we have achieved speech quality objective\nmetric scores comparable to state-of-the-art (SOTA) methods across multiple\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.15254v1",
    "published": "2025-05-21T08:33:47+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.11042v1",
    "title": "GenFT: A Generative Parameter-Efficient Fine-Tuning Method for Pretrained Foundation Models",
    "authors": [
      "Baoquan Zhang",
      "Guangning Xu",
      "Michael. K. Ng"
    ],
    "abstract": "Pretrained Foundation Models (PFMs) have transformed numerous applications by\nenabling efficient adaptation to customized tasks. Parameter-Efficient\nFine-Tuning (PEFT) has emerged as a resource-efficient alternative to full\nfine-tuning, especially leveraging reparameterized weights $\\Delta W$ to adapt\nmodels for downstream tasks. However, a critical yet underexplored question\nremains: can we utilize well-pretrained weights $W_0$ to guide the update of\ntask-specific $\\Delta W$, avoiding inefficient training it from scratch? To end\nthis, we propose Generative Parameter-Efficient Fine-Tuning (GenFT), a novel\nmethod that extracts structured, transferable information from $W_0$ for\nefficient $\\Delta W$ training. To extract row and column structure information,\nGenFT applies row and column transformations to distill essential patterns from\n$W_0$. A tailored policy further decomposes $\\Delta W$ into layer-shared and\nlayer-specific components, balancing information reuse and individualized\nflexibility. GenFT is simple yet effective, achieving superior performance\nacross CV and NLP tasks. Extensive experiments on VTAB-1K, FGVC, and GLUE\nbenchmarks demonstrate that GenFT outperforms state-of-the-art PEFT methods,\noffering a new perspective for efficient model adaptation.",
    "pdf_url": "http://arxiv.org/pdf/2506.11042v1",
    "published": "2025-05-21T08:33:26+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15253v1",
    "title": "Exponential moments for Hawkes processes under minimal assumptions",
    "authors": [
      "Th√©o Leblanc"
    ],
    "abstract": "We prove that the number of points of a stationary linear Hawkes process\nlying in any bounded subset of the real line has exponential moments, without\nany other assumption than the one needed for existence of such stationary\nprocess, namely the spectral radius of the matrix of L1 norms of interaction\nfunctions is smaller than one. The proof relies on a mass transport principle\nargument. We also specify the dependence of the bounds with respect to the base\nrates and the matrix of L1 norms of interaction functions defining the Hawkes\nprocess and give a functional version of the result.",
    "pdf_url": "http://arxiv.org/pdf/2505.15253v1",
    "published": "2025-05-21T08:30:39+00:00",
    "categories": [
      "math.PR",
      "60G55, 60E15, 60J85"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15252v1",
    "title": "An Efficient Private GPT Never Autoregressively Decodes",
    "authors": [
      "Zhengyi Li",
      "Yue Guan",
      "Kang Yang",
      "Yu Feng",
      "Ning Liu",
      "Yu Yu",
      "Jingwen Leng",
      "Minyi Guo"
    ],
    "abstract": "The wide deployment of the generative pre-trained transformer (GPT) has\nraised privacy concerns for both clients and servers. While cryptographic\nprimitives can be employed for secure GPT inference to protect the privacy of\nboth parties, they introduce considerable performance overhead.To accelerate\nsecure inference, this study proposes a public decoding and secure verification\napproach that utilizes public GPT models, motivated by the observation that\nsecurely decoding one and multiple tokens takes a similar latency. The client\nuses the public model to generate a set of tokens, which are then securely\nverified by the private model for acceptance. The efficiency of our approach\ndepends on the acceptance ratio of tokens proposed by the public model, which\nwe improve from two aspects: (1) a private sampling protocol optimized for\ncryptographic primitives and (2) model alignment using knowledge distillation.\nOur approach improves the efficiency of secure decoding while maintaining the\nsame level of privacy and generation quality as standard secure decoding.\nExperiments demonstrate a $2.1\\times \\sim 6.0\\times$ speedup compared to\nstandard decoding across three pairs of public-private models and different\nnetwork conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15252v1",
    "published": "2025-05-21T08:28:56+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15251v1",
    "title": "Loss-Guided Auxiliary Agents for Overcoming Mode Collapse in GFlowNets",
    "authors": [
      "Idriss Malek",
      "Abhijit Sharma",
      "Salem Lahlou"
    ],
    "abstract": "Although Generative Flow Networks (GFlowNets) are designed to capture\nmultiple modes of a reward function, they often suffer from mode collapse in\npractice, getting trapped in early discovered modes and requiring prolonged\ntraining to find diverse solutions. Existing exploration techniques may rely on\nheuristic novelty signals. We propose Loss-Guided GFlowNets (LGGFN), a novel\napproach where an auxiliary GFlowNet's exploration is directly driven by the\nmain GFlowNet's training loss. By prioritizing trajectories where the main\nmodel exhibits high loss, LGGFN focuses sampling on poorly understood regions\nof the state space. This targeted exploration significantly accelerates the\ndiscovery of diverse, high-reward samples. Empirically, across various\nbenchmarks including grid environments, structured sequence generation, and\nBayesian structure learning, LGGFN consistently enhances exploration efficiency\nand sample diversity compared to baselines. For instance, on a challenging\nsequence generation task, it discovered over 40 times more unique valid modes\nwhile simultaneously reducing the exploration error metric by approximately\n99\\%.",
    "pdf_url": "http://arxiv.org/pdf/2505.15251v1",
    "published": "2025-05-21T08:27:10+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15250v1",
    "title": "Margin-aware Fuzzy Rough Feature Selection: Bridging Uncertainty Characterization and Pattern Classification",
    "authors": [
      "Suping Xu",
      "Lin Shang",
      "Keyu Liu",
      "Hengrong Ju",
      "Xibei Yang",
      "Witold Pedrycz"
    ],
    "abstract": "Fuzzy rough feature selection (FRFS) is an effective means of addressing the\ncurse of dimensionality in high-dimensional data. By removing redundant and\nirrelevant features, FRFS helps mitigate classifier overfitting, enhance\ngeneralization performance, and lessen computational overhead. However, most\nexisting FRFS algorithms primarily focus on reducing uncertainty in pattern\nclassification, neglecting that lower uncertainty does not necessarily result\nin improved classification performance, despite it commonly being regarded as a\nkey indicator of feature selection effectiveness in the FRFS literature. To\nbridge uncertainty characterization and pattern classification, we propose a\nMargin-aware Fuzzy Rough Feature Selection (MAFRFS) framework that considers\nboth the compactness and separation of label classes. MAFRFS effectively\nreduces uncertainty in pattern classification tasks, while guiding the feature\nselection towards more separable and discriminative label class structures.\nExtensive experiments on 15 public datasets demonstrate that MAFRFS is highly\nscalable and more effective than FRFS. The algorithms developed using MAFRFS\noutperform six state-of-the-art feature selection algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15250v1",
    "published": "2025-05-21T08:26:20+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15249v1",
    "title": "Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation",
    "authors": [
      "Yerin Hwang",
      "Dongryeol Lee",
      "Kyungmin Min",
      "Taegwan Kang",
      "Yong-il Kim",
      "Kyomin Jung"
    ],
    "abstract": "Recently, large vision-language models (LVLMs) have emerged as the preferred\ntools for judging text-image alignment, yet their robustness along the visual\nmodality remains underexplored. This work is the first study to address a key\nresearch question: Can adversarial visual manipulations systematically fool\nLVLM judges into assigning unfairly inflated scores? We define potential image\ninduced biases within the context of T2I evaluation and examine how these\nbiases affect the evaluations of LVLM judges. Moreover, we introduce a novel,\nfine-grained, multi-domain meta-evaluation benchmark named FRAME, which is\ndeliberately constructed to exhibit diverse score distributions. By introducing\nthe defined biases into the benchmark, we reveal that all tested LVLM judges\nexhibit vulnerability across all domains, consistently inflating scores for\nmanipulated images. Further analysis reveals that combining multiple biases\namplifies their effects, and pairwise evaluations are similarly susceptible.\nMoreover, we observe that visual biases persist under prompt-based mitigation\nstrategies, highlighting the vulnerability of current LVLM evaluation systems\nand underscoring the urgent need for more robust LVLM judges.",
    "pdf_url": "http://arxiv.org/pdf/2505.15249v1",
    "published": "2025-05-21T08:24:28+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15248v1",
    "title": "VET-DINO: Learning Anatomical Understanding Through Multi-View Distillation in Veterinary Imaging",
    "authors": [
      "Andre Dourson",
      "Kylie Taylor",
      "Xiaoli Qiao",
      "Michael Fitzke"
    ],
    "abstract": "Self-supervised learning has emerged as a powerful paradigm for training deep\nneural networks, particularly in medical imaging where labeled data is scarce.\nWhile current approaches typically rely on synthetic augmentations of single\nimages, we propose VET-DINO, a framework that leverages a unique characteristic\nof medical imaging: the availability of multiple standardized views from the\nsame study. Using a series of clinical veterinary radiographs from the same\npatient study, we enable models to learn view-invariant anatomical structures\nand develop an implied 3D understanding from 2D projections. We demonstrate our\napproach on a dataset of 5 million veterinary radiographs from 668,000 canine\nstudies. Through extensive experimentation, including view synthesis and\ndownstream task performance, we show that learning from real multi-view pairs\nleads to superior anatomical understanding compared to purely synthetic\naugmentations. VET-DINO achieves state-of-the-art performance on various\nveterinary imaging tasks. Our work establishes a new paradigm for\nself-supervised learning in medical imaging that leverages domain-specific\nproperties rather than merely adapting natural image techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.15248v1",
    "published": "2025-05-21T08:23:48+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15247v1",
    "title": "Experimental Evaluation of Multiple Active RISs for 5G MIMO Commercial Networks",
    "authors": [
      "Feng-Ji Chen",
      "Chao-Kai Wen",
      "De-Ming Chian"
    ],
    "abstract": "While numerous experimental studies have demonstrated the feasibility of\nreconfigurable intelligent surface (RIS) technology, most have primarily\nfocused on extending coverage. In contrast, this paper presents an experimental\nevaluation of multiple active RISs deployed in a 5G multiple-input\nmultiple-output (MIMO) commercial network, emphasizing enhancements in channel\nrank and throughput. We propose a low-complexity, codebook-based beamforming\nalgorithm specifically tailored for multi-RIS configurations, which diversifies\ndirectional channels and reduces reliance on explicit channel state\ninformation. Field tests using a commercial base station and user equipment\nreveal that the multi-RIS system can improve channel rank and throughput by up\nto 14% compared to single-RIS deployments, while maintaining low computational\ncomplexity. These findings underscore the practical benefits of active\nmulti-RIS systems for next-generation networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15247v1",
    "published": "2025-05-21T08:23:30+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15246v1",
    "title": "Mitigating Spurious Correlations with Causal Logit Perturbation",
    "authors": [
      "Xiaoling Zhou",
      "Wei Ye",
      "Rui Xie",
      "Shikun Zhang"
    ],
    "abstract": "Deep learning has seen widespread success in various domains such as science,\nindustry, and society. However, it is acknowledged that certain approaches\nsuffer from non-robustness, relying on spurious correlations for predictions.\nAddressing these limitations is of paramount importance, necessitating the\ndevelopment of methods that can disentangle spurious correlations. {This study\nattempts to implement causal models via logit perturbations and introduces a\nnovel Causal Logit Perturbation (CLP) framework to train classifiers with\ngenerated causal logit perturbations for individual samples, thereby mitigating\nthe spurious associations between non-causal attributes (i.e., image\nbackgrounds) and classes.} {Our framework employs a} perturbation network to\ngenerate sample-wise logit perturbations using a series of training\ncharacteristics of samples as inputs. The whole framework is optimized by an\nonline meta-learning-based learning algorithm and leverages human causal\nknowledge by augmenting metadata in both counterfactual and factual manners.\nEmpirical evaluations on four typical biased learning scenarios, including\nlong-tail learning, noisy label learning, generalized long-tail learning, and\nsubpopulation shift learning, demonstrate that CLP consistently achieves\nstate-of-the-art performance. Moreover, visualization results support the\neffectiveness of the generated causal perturbations in redirecting model\nattention towards causal image attributes and dismantling spurious\nassociations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15246v1",
    "published": "2025-05-21T08:21:02+00:00",
    "categories": [
      "cs.LG",
      "K.3.2",
      "F.4.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15245v1",
    "title": "Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework",
    "authors": [
      "Zihao Jiang",
      "Ben Liu",
      "Miao Peng",
      "Wenjie Xu",
      "Yao Xiao",
      "Zhenyan Shan",
      "Min Peng"
    ],
    "abstract": "While large language models (LLMs) show great potential in temporal\nreasoning, most existing work focuses heavily on enhancing performance, often\nneglecting the explainable reasoning processes underlying the results. To\naddress this gap, we introduce a comprehensive benchmark covering a wide range\nof temporal granularities, designed to systematically evaluate LLMs'\ncapabilities in explainable temporal reasoning. Furthermore, our findings\nreveal that LLMs struggle to deliver convincing explanations when relying\nsolely on textual information. To address challenge, we propose GETER, a novel\nstructure-aware generative framework that integrates Graph structures with text\nfor Explainable TEmporal Reasoning. Specifically, we first leverage temporal\nknowledge graphs to develop a temporal encoder that captures structural\ninformation for the query. Subsequently, we introduce a structure-text prefix\nadapter to map graph structure features into the text embedding space. Finally,\nLLMs generate explanation text by seamlessly integrating the soft graph token\nwith instruction-tuning prompt tokens. Experimental results indicate that GETER\nachieves state-of-the-art performance while also demonstrating its\neffectiveness as well as strong generalization capabilities. Our dataset and\ncode are available at https://github.com/carryTatum/GETER.",
    "pdf_url": "http://arxiv.org/pdf/2505.15245v1",
    "published": "2025-05-21T08:20:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15244v3",
    "title": "Reliable Vertical Federated Learning in 5G Core Network Architecture",
    "authors": [
      "Mohamad Mestoukirdi",
      "Mourad Khanfouci"
    ],
    "abstract": "This work proposes a new algorithm to mitigate model generalization loss in\nVertical Federated Learning (VFL) operating under client reliability\nconstraints within 5G Core Networks (CNs). Recently studied and endorsed by\n3GPP, VFL enables collaborative and load-balanced model training and inference\nacross the CN. However, the performance of VFL significantly degrades when the\nNetwork Data Analytics Functions (NWDAFs) - which serve as primary clients for\nVFL model training and inference - experience reliability issues stemming from\nresource constraints and operational overhead. Unlike edge environments, CN\nenvironments adopt fundamentally different data management strategies,\ncharacterized by more centralized data orchestration capabilities. This\npresents opportunities to implement better distributed solutions that take full\nadvantage of the CN data handling flexibility. Leveraging this flexibility, we\npropose a method that optimizes the vertical feature split among clients while\ncentrally defining their local models based on reliability metrics. Our\nempirical evaluation demonstrates the effectiveness of our proposed algorithm,\nshowing improved performance over traditional baseline methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15244v3",
    "published": "2025-05-21T08:20:16+00:00",
    "categories": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15243v1",
    "title": "Direct reconstruction of the quantum density matrix elements with classical shadow tomography",
    "authors": [
      "Yu Wang"
    ],
    "abstract": "We introduce a direct estimation framework for reconstructing multiple\ndensity matrix elements of an unknown quantum state using classical shadow\ntomography. Traditional direct measurement protocols (DMPs), while effective\nfor individual elements, suffer from poor scalability due to post-selection\nlosses and the need for element-specific measurement configurations. In\ncontrast, our method, DMP-ST, leverages random Clifford or biased mutually\nunbiased basis measurements to enable global estimation: a single dataset\nsuffices to estimate arbitrary off-diagonal entries with high accuracy. We\nprove that estimating \\(K\\) off-diagonal matrix elements up to additive error\n\\(\\epsilon\\) requires only \\(\\mathcal{O}(\\log K/\\epsilon^2)\\) samples,\nachieving exponential improvement over conventional DMPs. The number of\nrequired measurement configurations can also be exponentially reduced for large\nK. When extended to full state tomography, DMP-ST attains trace distance error\n\\(\\le \\epsilon\\) with sample complexity \\(\\mathcal{O}(d^3 \\log d/\\epsilon^2)\\),\nwhich is closed to the optimal scaling for single-copy measurements. Moreover,\nbiased MUB measurements reduce sample complexity by a constant factor than\nrandom Clifford measurements. This work provides both theoretical guarantees\nand explicit protocols for efficient, entrywise quantum state reconstruction.\nIt significantly advances the practicality of direct tomography, especially for\nhigh-dimensional systems and near-term quantum platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15243v1",
    "published": "2025-05-21T08:19:39+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15242v2",
    "title": "Adaptive Plan-Execute Framework for Smart Contract Security Auditing",
    "authors": [
      "Zhiyuan Wei",
      "Jing Sun",
      "Zijian Zhang",
      "Zhe Hou",
      "Zixiao Zhao"
    ],
    "abstract": "Large Language Models (LLMs) have shown great promise in code analysis and\nauditing; however, they still struggle with hallucinations and limited\ncontext-aware reasoning. We introduce SmartAuditFlow, a novel Plan-Execute\nframework that enhances smart contract security analysis through dynamic audit\nplanning and structured execution. Unlike conventional LLM-based auditing\napproaches that follow fixed workflows and predefined steps, SmartAuditFlow\ndynamically generates and refines audit plans based on the unique\ncharacteristics of each smart contract. It continuously adjusts its auditing\nstrategy in response to intermediate LLM outputs and newly detected\nvulnerabilities, ensuring a more adaptive and precise security assessment. The\nframework then executes these plans step by step, applying a structured\nreasoning process to enhance vulnerability detection accuracy while minimizing\nhallucinations and false positives. To further improve audit precision,\nSmartAuditFlow integrates iterative prompt optimization and external knowledge\nsources, such as static analysis tools and Retrieval-Augmented Generation\n(RAG). This ensures audit decisions are contextually informed and backed by\nreal-world security knowledge, producing comprehensive security reports.\nExtensive evaluations across multiple benchmarks demonstrate that\nSmartAuditFlow outperforms existing methods, achieving 100 percent accuracy on\ncommon and critical vulnerabilities, 41.2 percent accuracy for comprehensive\ncoverage of known smart contract weaknesses in real-world projects, and\nsuccessfully identifying all 13 tested CVEs. These results highlight\nSmartAuditFlow's scalability, cost-effectiveness, and superior adaptability\nover traditional static analysis tools and contemporary LLM-based approaches,\nestablishing it as a robust solution for automated smart contract auditing.",
    "pdf_url": "http://arxiv.org/pdf/2505.15242v2",
    "published": "2025-05-21T08:18:41+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15241v1",
    "title": "GAMA++: Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer",
    "authors": [
      "Kim Yun",
      "Hana Satou",
      "F Monkey"
    ],
    "abstract": "Despite progress in geometry-aware domain adaptation, current methods such as\nGAMA still suffer from two unresolved issues: (1) insufficient disentanglement\nof task-relevant and task-irrelevant manifold dimensions, and (2) rigid\nperturbation schemes that ignore per-class alignment asymmetries. To address\nthis, we propose GAMA++, a novel framework that introduces (i) latent space\ndisentanglement to isolate label-consistent manifold directions from nuisance\nfactors, and (ii) an adaptive contrastive perturbation strategy that tailors\nboth on- and off-manifold exploration to class-specific manifold curvature and\nalignment discrepancy. We further propose a cross-domain contrastive\nconsistency loss that encourages local semantic clusters to align while\npreserving intra-domain diversity. Our method achieves state-of-the-art results\non DomainNet, Office-Home, and VisDA benchmarks under both standard and\nfew-shot settings, with notable improvements in class-level alignment fidelity\nand boundary robustness. GAMA++ sets a new standard for semantic geometry\nalignment in transfer learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15241v1",
    "published": "2025-05-21T08:16:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15240v1",
    "title": "Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge",
    "authors": [
      "Yassir Fathullah",
      "Mark J. F. Gales"
    ],
    "abstract": "This paper explores generalised probabilistic modelling and uncertainty\nestimation in comparative LLM-as-a-judge frameworks. We show that existing\nProduct-of-Experts methods are specific cases of a broader framework, enabling\ndiverse modelling options. Furthermore, we propose improved uncertainty\nestimates for individual comparisons, enabling more efficient selection and\nachieving strong performance with fewer evaluations. We also introduce a method\nfor estimating overall ranking uncertainty. Finally, we demonstrate that\ncombining absolute and comparative scoring improves performance. Experiments\nshow that the specific expert model has a limited impact on final rankings but\nour proposed uncertainty estimates, especially the probability of reordering,\nsignificantly improve the efficiency of systems reducing the number of needed\ncomparisons by ~50%. Furthermore, ranking-level uncertainty metrics can be used\nto identify low-performing predictions, where the nature of the probabilistic\nmodel has a notable impact on the quality of the overall uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2505.15240v1",
    "published": "2025-05-21T08:16:18+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15239v1",
    "title": "Neural Collapse is Globally Optimal in Deep Regularized ResNets and Transformers",
    "authors": [
      "Peter S√∫ken√≠k",
      "Christoph H. Lampert",
      "Marco Mondelli"
    ],
    "abstract": "The empirical emergence of neural collapse -- a surprising symmetry in the\nfeature representations of the training data in the penultimate layer of deep\nneural networks -- has spurred a line of theoretical research aimed at its\nunderstanding. However, existing work focuses on data-agnostic models or, when\ndata structure is taken into account, it remains limited to multi-layer\nperceptrons. Our paper fills both these gaps by analyzing modern architectures\nin a data-aware regime: we prove that global optima of deep regularized\ntransformers and residual networks (ResNets) with LayerNorm trained with cross\nentropy or mean squared error loss are approximately collapsed, and the\napproximation gets tighter as the depth grows. More generally, we formally\nreduce any end-to-end large-depth ResNet or transformer training into an\nequivalent unconstrained features model, thus justifying its wide use in the\nliterature even beyond data-agnostic settings. Our theoretical results are\nsupported by experiments on computer vision and language datasets showing that,\nas the depth grows, neural collapse indeed becomes more prominent.",
    "pdf_url": "http://arxiv.org/pdf/2505.15239v1",
    "published": "2025-05-21T08:16:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15238v1",
    "title": "Rare-Earth Nitrides: Fundamental Advances and Applications in Cryogenic Electronics",
    "authors": [
      "W. F. Holmes-Hewett",
      "J. D. Miller",
      "H. G. Ahmad",
      "S. Granville",
      "B. J. Ruck"
    ],
    "abstract": "Driven by the pursuit of high-performance electronic devices, research into\nnovel materials with properties appropriate for cryogenic applications has\nunveiled the exceptional properties of the rare-earth nitride series of\nintrinsic ferromagnetic semiconductors. Here we report on the field focusing on\ndevelopments, since the most recent comprehensive review [1], which enable\napplications in cryogenic electronic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15238v1",
    "published": "2025-05-21T08:15:50+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15237v1",
    "title": "MINDS. Water reservoirs of compact planet-forming dust disk: A diversity of H$_2$O distributions",
    "authors": [
      "Milou Temmink",
      "Andrew D. Sellek",
      "Danny Gasman",
      "Ewine F. van Dishoeck",
      "Marissa Vlasblom",
      "Ang√®l Pranger",
      "Manuel G√ºdel",
      "Thomas Henning",
      "Pierre-Olivier Lagage",
      "Alessio Caratti O Garatti",
      "Inga Kamp",
      "G√∂ran Olofsson",
      "Aditya M. Arabhavi",
      "Sierra L. Grant",
      "Till Kaeufer",
      "Nicolas T. Kurtovic",
      "Giulia Perotti",
      "Matthias Samland",
      "Kamber Schwarz",
      "Beno√Æt Tabone"
    ],
    "abstract": "Millimetre-compact dust disks are thought to have efficient radial drift of\nicy dust pebbles, which has been hypothesised to produce an enhanced cold\n($T<$400 K) H$_2$O reservoir in their inner disks. Mid-infrared spectral\nsurveys, now with the James Webb Space Telescope (JWST), pave the way to\nexplore this hypothesis. In this work, we test this theory for 8 compact disks\n($R_\\mathrm{dust}<$60 au) with JWST-MIRI/MRS observations. We analyse the\ndifferent reservoirs that can be probed with the pure rotational lines ($>$10\n$\\mathrm{\\mu}$m) through parametric column density profiles, multiple component\nslab models, and line flux ratios. We find that not all compact disks show\nstrong enhancements of the cold H$_2$O reservoir, instead we propose three\ndifferent classes of inner disk H$_2$O distributions. Four of our disks appear\nto have similar H$_2$O distributions as many of the large and structured disks\n(Type N or ``Normal'' disks), as is indicated by the slab model fitting and the\nline flux ratios. These disks have a small cold reservoir, suggesting the\ninward drift of dust, but it is not as efficient as hypothesised before. Only\ntwo disks do show a strong enhancement of the cold H$_2$O emission (Type E or\ncold H$_2$O enhanced disks), agreeing with the original hypothesis. The two\nremaining disks are found to be very H$_2$O-poor (Type P or H$_2$O-poor disks),\nyet show emission from either the hot or immediate reservoirs (depending on the\nfit) in addition to emission from the cold one. We find that different\nparametrisations are able to provide a good description of the observed H$_2$O\nspectra, with the multiple component analysis yielding similar results.\nFinally, we also report the detection of other molecules in these disks,\nincluding a tentative detection of CH$_4$ in CY Tau.",
    "pdf_url": "http://arxiv.org/pdf/2505.15237v1",
    "published": "2025-05-21T08:14:19+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15236v2",
    "title": "A generic approach to proving Tur√°n-type inequalities for sequences that admit exact formulas, with an application to unimodal sequences",
    "authors": [
      "Koustav Banerjee",
      "Kathrin Bringmann",
      "Ben Kane"
    ],
    "abstract": "We derive an asymptotic expansion with effective error bound for $u(n)$,\ncounting the number of unimodal sequences of size $n$. We prove that $u(n)$\nsatisfies the higher order Tur\\'{a}n inequalities for $n\\geq33$ and that\ncertain second $j$-shifted difference of $u(n)$ are positive.",
    "pdf_url": "http://arxiv.org/pdf/2505.15236v2",
    "published": "2025-05-21T08:14:15+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15235v2",
    "title": "X-GRM: Large Gaussian Reconstruction Model for Sparse-view X-rays to Computed Tomography",
    "authors": [
      "Yifan Liu",
      "Wuyang Li",
      "Weihao Yu",
      "Chenxin Li",
      "Alexandre Alahi",
      "Max Meng",
      "Yixuan Yuan"
    ],
    "abstract": "Computed Tomography serves as an indispensable tool in clinical workflows,\nproviding non-invasive visualization of internal anatomical structures.\nExisting CT reconstruction works are limited to small-capacity model\narchitecture and inflexible volume representation. In this work, we present\nX-GRM (X-ray Gaussian Reconstruction Model), a large feedforward model for\nreconstructing 3D CT volumes from sparse-view 2D X-ray projections. X-GRM\nemploys a scalable transformer-based architecture to encode sparse-view X-ray\ninputs, where tokens from different views are integrated efficiently. Then,\nthese tokens are decoded into a novel volume representation, named Voxel-based\nGaussian Splatting (VoxGS), which enables efficient CT volume extraction and\ndifferentiable X-ray rendering. This combination of a high-capacity model and\nflexible volume representation, empowers our model to produce high-quality\nreconstructions from various testing inputs, including in-domain and out-domain\nX-ray projections. Our codes are available at:\nhttps://github.com/CUHK-AIM-Group/X-GRM.",
    "pdf_url": "http://arxiv.org/pdf/2505.15235v2",
    "published": "2025-05-21T08:14:10+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15234v1",
    "title": "SAMA-UNet: Enhancing Medical Image Segmentation with Self-Adaptive Mamba-Like Attention and Causal-Resonance Learning",
    "authors": [
      "Saqib Qamar",
      "Mohd Fazil",
      "Parvez Ahmad",
      "Ghulam Muhammad"
    ],
    "abstract": "Medical image segmentation plays an important role in various clinical\napplications, but existing models often struggle with the computational\ninefficiencies and challenges posed by complex medical data. State Space\nSequence Models (SSMs) have demonstrated promise in modeling long-range\ndependencies with linear computational complexity, yet their application in\nmedical image segmentation remains hindered by incompatibilities with image\ntokens and autoregressive assumptions. Moreover, it is difficult to achieve a\nbalance in capturing both local fine-grained information and global semantic\ndependencies. To address these challenges, we introduce SAMA-UNet, a novel\narchitecture for medical image segmentation. A key innovation is the\nSelf-Adaptive Mamba-like Aggregated Attention (SAMA) block, which integrates\ncontextual self-attention with dynamic weight modulation to prioritise the most\nrelevant features based on local and global contexts. This approach reduces\ncomputational complexity and improves the representation of complex image\nfeatures across multiple scales. We also suggest the Causal-Resonance\nMulti-Scale Module (CR-MSM), which enhances the flow of information between the\nencoder and decoder by using causal resonance learning. This mechanism allows\nthe model to automatically adjust feature resolution and causal dependencies\nacross scales, leading to better semantic alignment between the low-level and\nhigh-level features in U-shaped architectures. Experiments on MRI, CT, and\nendoscopy images show that SAMA-UNet performs better in segmentation accuracy\nthan current methods using CNN, Transformer, and Mamba. The implementation is\npublicly available at GitHub.",
    "pdf_url": "http://arxiv.org/pdf/2505.15234v1",
    "published": "2025-05-21T08:12:31+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15233v1",
    "title": "CAD: A General Multimodal Framework for Video Deepfake Detection via Cross-Modal Alignment and Distillation",
    "authors": [
      "Yuxuan Du",
      "Zhendong Wang",
      "Yuhao Luo",
      "Caiyong Piao",
      "Zhiyuan Yan",
      "Hao Li",
      "Li Yuan"
    ],
    "abstract": "The rapid emergence of multimodal deepfakes (visual and auditory content are\nmanipulated in concert) undermines the reliability of existing detectors that\nrely solely on modality-specific artifacts or cross-modal inconsistencies. In\nthis work, we first demonstrate that modality-specific forensic traces (e.g.,\nface-swap artifacts or spectral distortions) and modality-shared semantic\nmisalignments (e.g., lip-speech asynchrony) offer complementary evidence, and\nthat neglecting either aspect limits detection performance. Existing approaches\neither naively fuse modality-specific features without reconciling their\nconflicting characteristics or focus predominantly on semantic misalignment at\nthe expense of modality-specific fine-grained artifact cues. To address these\nshortcomings, we propose a general multimodal framework for video deepfake\ndetection via Cross-Modal Alignment and Distillation (CAD). CAD comprises two\ncore components: 1) Cross-modal alignment that identifies inconsistencies in\nhigh-level semantic synchronization (e.g., lip-speech mismatches); 2)\nCross-modal distillation that mitigates feature conflicts during fusion while\npreserving modality-specific forensic traces (e.g., spectral distortions in\nsynthetic audio). Extensive experiments on both multimodal and unimodal (e.g.,\nimage-only/video-only)deepfake benchmarks demonstrate that CAD significantly\noutperforms previous methods, validating the necessity of harmonious\nintegration of multimodal complementary information.",
    "pdf_url": "http://arxiv.org/pdf/2505.15233v1",
    "published": "2025-05-21T08:11:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15232v1",
    "title": "DC-Scene: Data-Centric Learning for 3D Scene Understanding",
    "authors": [
      "Ting Huang",
      "Zeyu Zhang",
      "Ruicheng Zhang",
      "Yang Zhao"
    ],
    "abstract": "3D scene understanding plays a fundamental role in vision applications such\nas robotics, autonomous driving, and augmented reality. However, advancing\nlearning-based 3D scene understanding remains challenging due to two key\nlimitations: (1) the large scale and complexity of 3D scenes lead to higher\ncomputational costs and slower training compared to 2D counterparts; and (2)\nhigh-quality annotated 3D datasets are significantly scarcer than those\navailable for 2D vision. These challenges underscore the need for more\nefficient learning paradigms. In this work, we propose DC-Scene, a data-centric\nframework tailored for 3D scene understanding, which emphasizes enhancing data\nquality and training efficiency. Specifically, we introduce a CLIP-driven\ndual-indicator quality (DIQ) filter, combining vision-language alignment scores\nwith caption-loss perplexity, along with a curriculum scheduler that\nprogressively expands the training pool from the top 25% to 75% of\nscene-caption pairs. This strategy filters out noisy samples and significantly\nreduces dependence on large-scale labeled 3D data. Extensive experiments on\nScanRefer and Nr3D demonstrate that DC-Scene achieves state-of-the-art\nperformance (86.1 CIDEr with the top-75% subset vs. 85.4 with the full dataset)\nwhile reducing training cost by approximately two-thirds, confirming that a\ncompact set of high-quality samples can outperform exhaustive training. Code\nwill be available at https://github.com/AIGeeksGroup/DC-Scene.",
    "pdf_url": "http://arxiv.org/pdf/2505.15232v1",
    "published": "2025-05-21T08:05:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15231v1",
    "title": "Finding separatrices of dynamical flows with Deep Koopman Eigenfunctions",
    "authors": [
      "Kabir V. Dabholkar",
      "Omri Barak"
    ],
    "abstract": "Many natural systems, including neural circuits involved in decision making,\ncan be modeled as high-dimensional dynamical systems with multiple stable\nstates. While existing analytical tools primarily describe behavior near stable\nequilibria, characterizing separatrices -- the manifolds that delineate\nboundaries between different basins of attraction -- remains challenging,\nparticularly in high-dimensional settings. Here, we introduce a numerical\nframework leveraging Koopman Theory combined with Deep Neural Networks to\neffectively characterize separatrices. Specifically, we approximate Koopman\nEigenfunctions (KEFs) associated with real positive eigenvalues, which vanish\nprecisely at the separatrices. Utilizing these scalar KEFs, optimization\nmethods efficiently locate separatrices even in complex systems. We demonstrate\nour approach on synthetic benchmarks, ecological network models, and recurrent\nneural networks trained on neuroscience-inspired tasks. Moreover, we illustrate\nthe practical utility of our method by designing optimal perturbations that can\nshift systems across separatrices, enabling predictions relevant to optogenetic\nstimulation experiments in neuroscience.",
    "pdf_url": "http://arxiv.org/pdf/2505.15231v1",
    "published": "2025-05-21T08:04:31+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15230v1",
    "title": "Categorical absorption for hereditary orders",
    "authors": [
      "Thilo Baumann"
    ],
    "abstract": "We show that Kuznetsov--Shinder's notion of deformation absorption of\nsingularities leads to a new approach for studying the bounded derived category\nof a hereditary order on a curve. The starting point is a hereditary order\nwhich can be interpreted as a smoothing of the finite-dimensional algebra\nobtained from the restriction to a ramified point. We construct a triangulated\nsubcategory inside the derived category of this finite-dimensional algebra\nwhich provides a deformation absorption of singularities. This allows us to\nobtain a semiorthogonal decomposition of the bounded derived category of the\nhereditary order, which is in addition linear over the base.",
    "pdf_url": "http://arxiv.org/pdf/2505.15230v1",
    "published": "2025-05-21T08:00:42+00:00",
    "categories": [
      "math.AG",
      "math.RT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15229v1",
    "title": "Multilingual Prompting for Improving LLM Generation Diversity",
    "authors": [
      "Qihan Wang",
      "Shidong Pan",
      "Tal Linzen",
      "Emily Black"
    ],
    "abstract": "Large Language Models (LLMs) are known to lack cultural representation and\noverall diversity in their generations, from expressing opinions to answering\nfactual questions. To mitigate this problem, we propose multilingual prompting:\na prompting method which generates several variations of a base prompt with\nadded cultural and linguistic cues from several cultures, generates responses,\nand then combines the results. Building on evidence that LLMs have\nlanguage-specific knowledge, multilingual prompting seeks to increase diversity\nby activating a broader range of cultural knowledge embedded in model training\ndata. Through experiments across multiple models (GPT-4o, GPT-4o-mini, LLaMA\n70B, and LLaMA 8B), we show that multilingual prompting consistently\noutperforms existing diversity-enhancing techniques such as high-temperature\nsampling, step-by-step recall, and personas prompting. Further analyses show\nthat the benefits of multilingual prompting vary with language resource level\nand model size, and that aligning the prompting language with the cultural cues\nreduces hallucination about culturally-specific information.",
    "pdf_url": "http://arxiv.org/pdf/2505.15229v1",
    "published": "2025-05-21T07:59:21+00:00",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15863v1",
    "title": "Generative AI for Autonomous Driving: A Review",
    "authors": [
      "Katharina Winter",
      "Abhishek Vivekanandan",
      "Rupert Polley",
      "Yinzhe Shen",
      "Christian Schlauch",
      "Mohamed-Khalil Bouzidi",
      "Bojan Derajic",
      "Natalie Grabowsky",
      "Annajoyce Mariani",
      "Dennis Rochau",
      "Giovanni Lucente",
      "Harsh Yadav",
      "Firas Mualla",
      "Adam Molin",
      "Sebastian Bernhard",
      "Christian Wirth",
      "√ñmer ≈ûahin Ta≈ü",
      "Nadja Klein",
      "Fabian B. Flohr",
      "Hanno Gottschalk"
    ],
    "abstract": "Generative AI (GenAI) is rapidly advancing the field of Autonomous Driving\n(AD), extending beyond traditional applications in text, image, and video\ngeneration. We explore how generative models can enhance automotive tasks, such\nas static map creation, dynamic scenario generation, trajectory forecasting,\nand vehicle motion planning. By examining multiple generative approaches\nranging from Variational Autoencoder (VAEs) over Generative Adversarial\nNetworks (GANs) and Invertible Neural Networks (INNs) to Generative\nTransformers (GTs) and Diffusion Models (DMs), we highlight and compare their\ncapabilities and limitations for AD-specific applications. Additionally, we\ndiscuss hybrid methods integrating conventional techniques with generative\napproaches, and emphasize their improved adaptability and robustness. We also\nidentify relevant datasets and outline open research questions to guide future\ndevelopments in GenAI. Finally, we discuss three core challenges: safety,\ninterpretability, and realtime capabilities, and present recommendations for\nimage generation, dynamic scenario generation, and planning.",
    "pdf_url": "http://arxiv.org/pdf/2505.15863v1",
    "published": "2025-05-21T07:59:18+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15228v1",
    "title": "Degree-Optimized Cumulative Polynomial Kolmogorov-Arnold Networks",
    "authors": [
      "Mathew Vanherreweghe",
      "Lirand√´ Pira",
      "Patrick Rebentrost"
    ],
    "abstract": "We introduce cumulative polynomial Kolmogorov-Arnold networks (CP-KAN), a\nneural architecture combining Chebyshev polynomial basis functions and\nquadratic unconstrained binary optimization (QUBO). Our primary contribution\ninvolves reformulating the degree selection problem as a QUBO task, reducing\nthe complexity from $O(D^N)$ to a single optimization step per layer. This\napproach enables efficient degree selection across neurons while maintaining\ncomputational tractability. The architecture performs well in regression tasks\nwith limited data, showing good robustness to input scales and natural\nregularization properties from its polynomial basis. Additionally, theoretical\nanalysis establishes connections between CP-KAN's performance and properties of\nfinancial time series. Our empirical validation across multiple domains\ndemonstrates competitive performance compared to several traditional\narchitectures tested, especially in scenarios where data efficiency and\nnumerical stability are important. Our implementation, including strategies for\nmanaging computational overhead in larger networks is available in\nRef.~\\citep{cpkan_implementation}.",
    "pdf_url": "http://arxiv.org/pdf/2505.15228v1",
    "published": "2025-05-21T07:59:12+00:00",
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15227v1",
    "title": "The CRAB facility at the TU Wien TRIGA reactor: status and related physics program",
    "authors": [
      "H. Abele",
      "P. Ajello",
      "A. Armatol",
      "B. Arnold",
      "J. Billard",
      "E. Bossio",
      "J. Burkhart",
      "F. Cappella",
      "N. Casali",
      "R. Cerulli",
      "J. Colas",
      "J-P. Crocombette",
      "G. del Castello",
      "M. del Gallo Roccagiovine",
      "S. Dorer",
      "C. Doutre",
      "A. Erhart",
      "S. Fichtinger",
      "M. Friedl",
      "P. Garin",
      "R. Gergen",
      "C. Goupy",
      "D. Hainz",
      "D. Hauff",
      "E. Jericha",
      "M. Kaznacheeva",
      "H. Kluck",
      "T. Lasserre",
      "D. Lhuillier",
      "O. Litaize",
      "P. de Marcillac",
      "S. Marnieros",
      "R. Martin",
      "E. Namuth",
      "T. Ortmann",
      "D. V. Poda",
      "L. Peters",
      "F. Reindl",
      "W. Reindl",
      "F. Rodari",
      "J. Rothe",
      "N. Schermer",
      "J. Schieck",
      "S. Sch√∂nert",
      "C. Schwertner",
      "G. Soum-Sidikov",
      "R. Strauss",
      "R. Thalmeier",
      "L. Thulliez",
      "C. Trunner",
      "M. Vignati",
      "M. Vivier",
      "P. Wasser",
      "A. Wex"
    ],
    "abstract": "The CRAB (Calibrated nuclear Recoils for Accurate Bolometry) project aims to\nprecisely characterize the response of cryogenic detectors to sub-keV nuclear\nrecoils of direct interest for coherent neutrino-nucleus scattering and dark\nmatter search experiments. The CRAB method relies on the radiative capture of\nthermal neutrons in the target detector, resulting in a nuclear recoil with a\nwell-defined energy. We present a new experimental setup installed at the TRIGA\nMark-II reactor at Atominstitut (Vienna), providing a low intensity beam of\nthermal neutrons sent to the target cryogenic detector mounted inside a wet\ndilution refrigerator Kelvinox 100. A crown of BaF$_2$ detectors installed\noutside the dewar enables coincident detection of the high-energy $\\gamma$\nescaping the target crystal after neutron capture. After the presentation of\nall components of the setup we report the analysis of first commissioning data\nwith a CaWO$_4$ detector of the \\NUCLEUS experiment. They show stable operation\nof the cryostat and detectors on a week-scale. Due to an energy resolution\ncurrently limited to 20 eV we use neutron beam induced events at high energy,\nin the 10 to 100 keV range, to demonstrate the excellent agreement between the\ndata and simulation and the accurate understanding of external background.\nThanks to these data we also propose an updated decay scheme of the low-lying\nexcited states of $^{187}$W. Finally, we present the first evidence of\nneutron-capture induced coincidences between $\\gamma$-detectors and a cryogenic\ndetector. These promising results pave the way for an extensive physics program\nwith various detector materials, like CaWO$_4$, Al$_2$O$_3$, Ge and Si.",
    "pdf_url": "http://arxiv.org/pdf/2505.15227v1",
    "published": "2025-05-21T07:57:10+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.15226v2",
    "title": "Comparison of simulations and semi-analytical model for WDM subhalo mass functions",
    "authors": [
      "Mizuki Ono",
      "Takashi Okamoto",
      "Shin'ichiro Ando",
      "Tomoaki Ishiyama"
    ],
    "abstract": "The Cold Dark Matter (CDM) model successfully explains large-scale structure\nformation, but challenges remain at smaller scales, leading to interest in Warm\nDark Matter (WDM) as an alternative. The abundance of Milky Way subhalos\ndepends on the mass of WDM particles, allowing constraints to be obtained by\ncomparing observations and theoretical models. However, high-resolution\nsimulations of heavier WDM particle masses are computationally demanding,\nmaking semi-analytical approaches valuable. In this study, we evaluate the\nability of the Semi-Analytical Sub-Halo Inference Modeling for WDM (SASHIMI-W)\nto reproduce subhalo mass functions for heavier WDM particle masses. We perform\nhigh-resolution cosmological N-body simulations for CDM and WDM with particle\nmasses of 1 keV, 3 keV, and 10 keV, and compare the ratio of the subhalo mass\nfunction between WDM and CDM cases. Our results show that SASHIMI-W\nsuccessfully reproduces the simulation results over redshifts z = 0 to z = 2.\nFurthermore, both simulations and the semi-analytical model show a slight\nredshift dependence in the subhalo suppression ratio. However, a direct\ncomparison of the differential subhalo mass functions shows discrepancies in\nthe mid- and low-mass regions, suggesting that the tidal stripping effects\nimplemented in SASHIMI-W may be too strong for WDM subhalos, or that the\nremoval of spurious subhalos in the simulations is insufficient. These results\nvalidate the use of SASHIMI-W in constraining WDM properties, and highlight the\nneed for refinements in both tidal effect modeling and spurious subhalo\nfiltering to improve subhalo abundance predictions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15226v2",
    "published": "2025-05-21T07:52:00+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15225v1",
    "title": "Hamiltonian reductions, scalings, and effective wave models in stratified fluids",
    "authors": [
      "Gregorio Falqui",
      "Eleonora Sforza"
    ],
    "abstract": "We apply Poisson reduction techniques to describe asymptotic fully nonlinear\nmodels of fluid wave motion in the Hamiltonian setting. We start by considering\nZakharov and Benjamin Hamiltonian settings for a stably stratified $2D$ Euler\nfluid. We use a Marsden-Ratiu reduction scheme for sharply stratified fluids to\nobtain a canonical formulation of the stratified effective model in one space\nvariable. The long-wave Serre-Green Naghdi (SGN) equations is then recovered by\nmeans of a suitable double scaling limit in the Hamiltonian function. We also\nconsider the opposite double-scaling limit, which leads to a local model in the\n\"large-lower layer\" regime. Furthermore, applying the previous results on the\ncanonical structure of the SGN equations, we provide the Miyata-Choi Camassa\n(CC) equations for fully non-linear waves in sharply stratified fluids with a\nnatural Hamiltonian structure. We also study the reduced Hamiltonian system\nobtained taking the natural constraints of the CC equations into account. To\nthis end, we perform a Dirac-type reduction on a suitable constrained\nsubmanifold of fluid field configurations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15225v1",
    "published": "2025-05-21T07:51:54+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "37K58 (primary) 35Q31, 35Q35, 76B70 (secondary)"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15224v1",
    "title": "Stabilization on ideal class groups in potential cyclic towers",
    "authors": [
      "Jianing Li"
    ],
    "abstract": "Let $p$ be a prime and let $F$ be a number field. Consider a Galois extension\n$K/F$ with Galois group $H\\rtimes \\Delta$ where $H\\cong \\mathbb{Z}_p$ or\n$\\mathbb{Z}/p^d\\mathbb{Z}$, and $\\Delta$ is an arbitrary Galois group. The\nsubfields fixed\n  by $H^{p^n} \\rtimes \\Delta$ $(n=0,1,\\cdots)$ form a tower which we call it a\npotential cyclic $p$-tower in this paper. A radical $p$-tower is a typical\nexample, say $\\mathbb{Z}\\subset \\mathbb{Z}(\\sqrt[p]{a})\\subset\n\\mathbb{Z}(\\sqrt[p^2]{a})\\subset \\cdots$ where $a\\in \\mathbb{Z}$.\n  We extend the stabilization result of Fukuda in Iwasawa theory on $p$-class\ngroups in cyclic $p$-towers to potential cyclic $p$-towers. We also extend\nIwasawa's class number formula in $\\mathbb{Z}_p$-extensions to potential\n$\\mathbb{Z}_p$-extensions.",
    "pdf_url": "http://arxiv.org/pdf/2505.15224v1",
    "published": "2025-05-21T07:51:29+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15223v2",
    "title": "Classifying and Tracking International Aid Contribution Towards SDGs",
    "authors": [
      "Sungwon Park",
      "Dongjoon Lee",
      "Kyeongjin Ahn",
      "Yubin Choi",
      "Junho Lee",
      "Meeyoung Cha",
      "Kyung Ryul Park"
    ],
    "abstract": "International aid is a critical mechanism for promoting economic growth and\nwell-being in developing nations, supporting progress toward the Sustainable\nDevelopment Goals (SDGs). However, tracking aid contributions remains\nchallenging due to labor-intensive data management, incomplete records, and the\nheterogeneous nature of aid data. Recognizing the urgency of this challenge, we\npartnered with government agencies to develop an AI model that complements\nmanual classification and mitigates human bias in subjective interpretation. By\nintegrating SDG-specific semantics and leveraging prior knowledge from language\nmodels, our approach enhances classification accuracy and accommodates the\ndiversity of aid projects. When applied to a comprehensive dataset spanning\nmultiple years, our model can reveal hidden trends in the temporal evolution of\ninternational development cooperation. Expert interviews further suggest how\nthese insights can empower policymakers with data-driven decision-making tools,\nultimately improving aid effectiveness and supporting progress toward SDGs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15223v2",
    "published": "2025-05-21T07:50:40+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15222v2",
    "title": "Continuous Representation Methods, Theories, and Applications: An Overview and Perspectives",
    "authors": [
      "Yisi Luo",
      "Xile Zhao",
      "Deyu Meng"
    ],
    "abstract": "Recently, continuous representation methods emerge as novel paradigms that\ncharacterize the intrinsic structures of real-world data through function\nrepresentations that map positional coordinates to their corresponding values\nin the continuous space. As compared with the traditional discrete framework,\nthe continuous framework demonstrates inherent superiority for data\nrepresentation and reconstruction (e.g., image restoration, novel view\nsynthesis, and waveform inversion) by offering inherent advantages including\nresolution flexibility, cross-modal adaptability, inherent smoothness, and\nparameter efficiency. In this review, we systematically examine recent\nadvancements in continuous representation frameworks, focusing on three\naspects: (i) Continuous representation method designs such as basis function\nrepresentation, statistical modeling, tensor function decomposition, and\nimplicit neural representation; (ii) Theoretical foundations of continuous\nrepresentations such as approximation error analysis, convergence property, and\nimplicit regularization; (iii) Real-world applications of continuous\nrepresentations derived from computer vision, graphics, bioinformatics, and\nremote sensing. Furthermore, we outline future directions and perspectives to\ninspire exploration and deepen insights to facilitate continuous representation\nmethods, theories, and applications. All referenced works are summarized in our\nopen-source repository:\nhttps://github.com/YisiLuo/Continuous-Representation-Zoo",
    "pdf_url": "http://arxiv.org/pdf/2505.15222v2",
    "published": "2025-05-21T07:50:19+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15221v1",
    "title": "RustSAT: A Library For SAT Solving in Rust",
    "authors": [
      "Christoph Jabs"
    ],
    "abstract": "State-of-the-art Boolean satisfiability (SAT) solvers constitute a practical\nand competitive approach for solving various real-world problems. To encourage\ntheir widespread adoption, the relatively high barrier of entry following from\nthe low level syntax of SAT and the expert knowledge required to achieve tight\nintegration with SAT solvers should be further reduced. We present RustSAT, a\nlibrary with the aim of making SAT solving technology readily available in the\nRust programming language. RustSAT provides functionality for helping with\ngenerating (Max)SAT instances, writing them to, or reading them from files.\nFurthermore, RustSAT includes interfaces to various state-of-the-art SAT\nsolvers available with a unified Rust API. Lastly, RustSAT implements several\nencodings for higher level constraints (at-most-one, cardinality, and\npseudo-Boolean), which are also available via a C and Python API.",
    "pdf_url": "http://arxiv.org/pdf/2505.15221v1",
    "published": "2025-05-21T07:50:10+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15220v1",
    "title": "Estimation methods of Matrix-valued AR model",
    "authors": [
      "Kamil Ko≈Çodziejski"
    ],
    "abstract": "This article proposes novel estimation methods for the Matrix Autoregressive\n(MAR) model, specifically adaptations of the Yule-Walker equations and Burg's\nmethod, addressing limitations in existing techniques. The MAR model, by\nmaintaining a matrix structure and requiring significantly fewer parameters\nthan vector autoregressive (VAR) models, offers a parsimonious, yet effective,\nalternative for high-dimensional time series. Empirical results demonstrate\nthat MAR models estimated via the proposed methods achieve a comparable fit to\nVAR models across metrics such as MAE and RMSE. These findings underscore the\nutility of Yule-Walker and Burg-type estimators in constructing efficient and\ninterpretable models for complex temporal data.",
    "pdf_url": "http://arxiv.org/pdf/2505.15220v1",
    "published": "2025-05-21T07:47:05+00:00",
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH",
      "62M10"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.15219v1",
    "title": "Versatile Reservoir Computing for Heterogeneous Complex Networks",
    "authors": [
      "Yao Du",
      "Huawei Fan",
      "Xingang Wang"
    ],
    "abstract": "A new machine learning scheme, termed versatile reservoir computing, is\nproposed for sustaining the dynamics of heterogeneous complex networks. We show\nthat a single, small-scale reservoir computer trained on time series from a\nsubset of elements is able to replicate the dynamics of any element in a\nlarge-scale complex network, though the elements are of different intrinsic\nparameters and connectivities. Furthermore, by substituting failed elements\nwith the trained machine, we demonstrate that the collective dynamics of the\nnetwork can be preserved accurately over a finite time horizon. The capability\nand effectiveness of the proposed scheme are validated on three representative\nnetwork models: a homogeneous complex network of non-identical phase\noscillators, a heterogeneous complex network of non-identical phase\noscillators, and a heterogeneous complex network of non-identical chaotic\noscillators.",
    "pdf_url": "http://arxiv.org/pdf/2505.15219v1",
    "published": "2025-05-21T07:46:49+00:00",
    "categories": [
      "nlin.CD",
      "cs.LG"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15217v1",
    "title": "Multimodal Conditional Information Bottleneck for Generalizable AI-Generated Image Detection",
    "authors": [
      "Haotian Qin",
      "Dongliang Chang",
      "Yueying Gao",
      "Bingyao Yu",
      "Lei Chen",
      "Zhanyu Ma"
    ],
    "abstract": "Although existing CLIP-based methods for detecting AI-generated images have\nachieved promising results, they are still limited by severe feature\nredundancy, which hinders their generalization ability. To address this issue,\nincorporating an information bottleneck network into the task presents a\nstraightforward solution. However, relying solely on image-corresponding\nprompts results in suboptimal performance due to the inherent diversity of\nprompts. In this paper, we propose a multimodal conditional bottleneck network\nto reduce feature redundancy while enhancing the discriminative power of\nfeatures extracted by CLIP, thereby improving the model's generalization\nability. We begin with a semantic analysis experiment, where we observe that\narbitrary text features exhibit lower cosine similarity with real image\nfeatures than with fake image features in the CLIP feature space, a phenomenon\nwe refer to as \"bias\". Therefore, we introduce InfoFD, a text-guided\nAI-generated image detection framework. InfoFD consists of two key components:\nthe Text-Guided Conditional Information Bottleneck (TGCIB) and Dynamic Text\nOrthogonalization (DTO). TGCIB improves the generalizability of learned\nrepresentations by conditioning on both text and class modalities. DTO\ndynamically updates weighted text features, preserving semantic information\nwhile leveraging the global \"bias\". Our model achieves exceptional\ngeneralization performance on the GenImage dataset and latest generative\nmodels. Our code is available at https://github.com/Ant0ny44/InfoFD.",
    "pdf_url": "http://arxiv.org/pdf/2505.15217v1",
    "published": "2025-05-21T07:46:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15218v1",
    "title": "Recognition of Unseen Combined Motions via Convex Combination-based EMG Pattern Synthesis for Myoelectric Control",
    "authors": [
      "Itsuki Yazawa",
      "Seitaro Yoneda",
      "Akira Furui"
    ],
    "abstract": "Electromyogram (EMG) signals recorded from the skin surface enable intuitive\ncontrol of assistive devices such as prosthetic limbs. However, in EMG-based\nmotion recognition, collecting comprehensive training data for all target\nmotions remains challenging, particularly for complex combined motions. This\npaper proposes a method to efficiently recognize combined motions using\nsynthetic EMG data generated through convex combinations of basic motion\npatterns. Instead of measuring all possible combined motions, the proposed\nmethod utilizes measured basic motion data along with synthetically combined\nmotion data for training. This approach expands the range of recognizable\ncombined motions while minimizing the required training data collection. We\nevaluated the effectiveness of the proposed method through an upper limb motion\nclassification experiment with eight subjects. The experimental results\ndemonstrated that the proposed method improved the classification accuracy for\nunseen combined motions by approximately 17%.",
    "pdf_url": "http://arxiv.org/pdf/2505.15218v1",
    "published": "2025-05-21T07:46:26+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15216v2",
    "title": "BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems",
    "authors": [
      "Andy K. Zhang",
      "Joey Ji",
      "Celeste Menders",
      "Riya Dulepet",
      "Thomas Qin",
      "Ron Y. Wang",
      "Junrong Wu",
      "Kyleen Liao",
      "Jiliang Li",
      "Jinghan Hu",
      "Sara Hong",
      "Nardos Demilew",
      "Shivatmica Murgai",
      "Jason Tran",
      "Nishka Kacheria",
      "Ethan Ho",
      "Denis Liu",
      "Lauren McLane",
      "Olivia Bruvik",
      "Dai-Rong Han",
      "Seungwoo Kim",
      "Akhil Vyas",
      "Cuiyuanxiu Chen",
      "Ryan Li",
      "Weiran Xu",
      "Jonathan Z. Ye",
      "Prerit Choudhary",
      "Siddharth M. Bhatia",
      "Vikram Sivashankar",
      "Yuxuan Bao",
      "Dawn Song",
      "Dan Boneh",
      "Daniel E. Ho",
      "Percy Liang"
    ],
    "abstract": "AI agents have the potential to significantly alter the cybersecurity\nlandscape. Here, we introduce the first framework to capture offensive and\ndefensive cyber-capabilities in evolving real-world systems. Instantiating this\nframework with BountyBench, we set up 25 systems with complex, real-world\ncodebases. To capture the vulnerability lifecycle, we define three task types:\nDetect (detecting a new vulnerability), Exploit (exploiting a specific\nvulnerability), and Patch (patching a specific vulnerability). For Detect, we\nconstruct a new success indicator, which is general across vulnerability types\nand provides localized evaluation. We manually set up the environment for each\nsystem, including installing packages, setting up server(s), and hydrating\ndatabase(s). We add 40 bug bounties, which are vulnerabilities with monetary\nawards of \\$10-\\$30,485, covering 9 of the OWASP Top 10 Risks. To modulate task\ndifficulty, we devise a new strategy based on information to guide detection,\ninterpolating from identifying a zero day to exploiting a specific\nvulnerability. We evaluate 8 agents: Claude Code, OpenAI Codex CLI with o3-high\nand o4-mini, and custom agents with o3-high, GPT-4.1, Gemini 2.5 Pro Preview,\nClaude 3.7 Sonnet Thinking, and DeepSeek-R1. Given up to three attempts, the\ntop-performing agents are OpenAI Codex CLI: o3-high (12.5% on Detect, mapping\nto \\$3,720; 90% on Patch, mapping to \\$14,152), Custom Agent with Claude 3.7\nSonnet Thinking (67.5% on Exploit), and OpenAI Codex CLI: o4-mini (90% on\nPatch, mapping to \\$14,422). OpenAI Codex CLI: o3-high, OpenAI Codex CLI:\no4-mini, and Claude Code are more capable at defense, achieving higher Patch\nscores of 90%, 90%, and 87.5%, compared to Exploit scores of 47.5%, 32.5%, and\n57.5% respectively; while the custom agents are relatively balanced between\noffense and defense, achieving Exploit scores of 37.5-67.5% and Patch scores of\n35-60%.",
    "pdf_url": "http://arxiv.org/pdf/2505.15216v2",
    "published": "2025-05-21T07:44:52+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15215v1",
    "title": "Clustering and Pruning in Causal Data Fusion",
    "authors": [
      "Otto Tabell",
      "Santtu Tikka",
      "Juha Karvanen"
    ],
    "abstract": "Data fusion, the process of combining observational and experimental data,\ncan enable the identification of causal effects that would otherwise remain\nnon-identifiable. Although identification algorithms have been developed for\nspecific scenarios, do-calculus remains the only general-purpose tool for\ncausal data fusion, particularly when variables are present in some data\nsources but not others. However, approaches based on do-calculus may encounter\ncomputational challenges as the number of variables increases and the causal\ngraph grows in complexity. Consequently, there exists a need to reduce the size\nof such models while preserving the essential features. For this purpose, we\npropose pruning (removing unnecessary variables) and clustering (combining\nvariables) as preprocessing operations for causal data fusion. We generalize\nearlier results on a single data source and derive conditions for applying\npruning and clustering in the case of multiple data sources. We give sufficient\nconditions for inferring the identifiability or non-identifiability of a causal\neffect in a larger graph based on a smaller graph and show how to obtain the\ncorresponding identifying functional for identifiable causal effects. Examples\nfrom epidemiology and social science demonstrate the use of the results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15215v1",
    "published": "2025-05-21T07:44:39+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15214v2",
    "title": "R-TOFU: Unlearning in Large Reasoning Models",
    "authors": [
      "Sangyeon Yoon",
      "Wonje Jeung",
      "Albert No"
    ],
    "abstract": "Large Reasoning Models (LRMs) embed private or copyrighted information not\nonly in their final answers but also throughout multi-step chain-of-thought\n(CoT) traces, making reliable unlearning far more demanding than in standard\nLLMs. We introduce Reasoning-TOFU (R-TOFU), the first benchmark tailored to\nthis setting. R-TOFU augments existing unlearning tasks with realistic CoT\nannotations and provides step-wise metrics that expose residual knowledge\ninvisible to answer-level checks. Using R-TOFU, we carry out a comprehensive\ncomparison of gradient-based and preference-optimization baselines and show\nthat conventional answer-only objectives leave substantial forget traces in\nreasoning. We further propose Reasoned IDK, a preference-optimization variant\nthat preserves coherent yet inconclusive reasoning, achieving a stronger\nbalance between forgetting efficacy and model utility than earlier refusal\nstyles. Finally, we identify a failure mode: decoding variants such as\nZeroThink and LessThink can still reveal forgotten content despite seemingly\nsuccessful unlearning, emphasizing the need to evaluate models under diverse\ndecoding settings. Together, the benchmark, analysis, and new baseline\nestablish a systematic foundation for studying and improving unlearning in LRMs\nwhile preserving their reasoning capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.15214v2",
    "published": "2025-05-21T07:44:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15213v1",
    "title": "KernelOracle: Predicting the Linux Scheduler's Next Move with Deep Learning",
    "authors": [
      "Sampanna Yashwant Kahu"
    ],
    "abstract": "Efficient task scheduling is paramount in the Linux kernel, where the\nCompletely Fair Scheduler (CFS) meticulously manages CPU resources to balance\nhigh utilization with interactive responsiveness. This research pioneers the\nuse of deep learning techniques to predict the sequence of tasks selected by\nCFS, aiming to evaluate the feasibility of a more generalized and potentially\nmore adaptive task scheduler for diverse workloads. Our core contributions are\ntwofold: first, the systematic generation and curation of a novel scheduling\ndataset from a running Linux kernel, capturing real-world CFS behavior; and\nsecond, the development, training, and evaluation of a Long Short-Term Memory\n(LSTM) network designed to accurately forecast the next task to be scheduled.\nThis paper further discusses the practical pathways and implications of\nintegrating such a predictive model into the kernel's scheduling framework. The\nfindings and methodologies presented herein open avenues for data-driven\nadvancements in kernel scheduling, with the full source code provided for\nreproducibility and further exploration.",
    "pdf_url": "http://arxiv.org/pdf/2505.15213v1",
    "published": "2025-05-21T07:43:52+00:00",
    "categories": [
      "cs.LG",
      "cs.OS",
      "D.4.1; I.2.0; I.2.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.12024v1",
    "title": "FlexQuant: A Flexible and Efficient Dynamic Precision Switching Framework for LLM Quantization",
    "authors": [
      "Fangxin Liu",
      "Zongwu Wang",
      "JinHong Xia",
      "Junping Zhao",
      "Jian Liu",
      "Haibing Guan",
      "Li Jiang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has exacerbated the\nmemory bottleneck due to the widening gap between model parameter scaling and\nhardware capabilities. While post-training quantization (PTQ) techniques\neffectively reduce memory overhead, existing methods predominantly rely on\nstatic quantization strategies, which struggle to adapt to dynamic workloads.\nTo address this, we propose FlexQuant, a dynamic precision-switching framework\nthat optimizes the trade-off between inference speed and accuracy. Leveraging\nmodel perplexity entropy and Kullback-Leibler (KL) divergence, FlexQuant\nenables fine-grained, layer-wise mixed-precision quantization and dynamically\nadjusts bit-widths during each token generation. Our work provides a\ncomprehensive analysis of quantization strategies, introduces a precision\nrequirement model for optimal switching, and implements efficient fine-grained\nprecision management. Experimental results demonstrate that FlexQuant achieves\na 1.3x end-to-end speedup across diverse language tasks with negligible\naccuracy loss introduced. This framework offers a flexible and adaptive\nsolution for efficient LLM deployment.",
    "pdf_url": "http://arxiv.org/pdf/2506.12024v1",
    "published": "2025-05-21T07:42:53+00:00",
    "categories": [
      "cs.LG",
      "I.2.1; I.2.7"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15212v1",
    "title": "Group Distributionally Robust Optimization with Flexible Sample Queries",
    "authors": [
      "Haomin Bai",
      "Dingzhi Yu",
      "Shuai Li",
      "Haipeng Luo",
      "Lijun Zhang"
    ],
    "abstract": "Group distributionally robust optimization (GDRO) aims to develop models that\nperform well across $m$ distributions simultaneously. Existing GDRO algorithms\ncan only process a fixed number of samples per iteration, either 1 or $m$, and\ntherefore can not support scenarios where the sample size varies dynamically.\nTo address this limitation, we investigate GDRO with flexible sample queries\nand cast it as a two-player game: one player solves an online convex\noptimization problem, while the other tackles a prediction with limited advice\n(PLA) problem. Within such a game, we propose a novel PLA algorithm,\nconstructing appropriate loss estimators for cases where the sample size is\neither 1 or not, and updating the decision using follow-the-regularized-leader.\nThen, we establish the first high-probability regret bound for non-oblivious\nPLA. Building upon the above approach, we develop a GDRO algorithm that allows\nan arbitrary and varying sample size per round, achieving a high-probability\noptimization error bound of $O\\left(\\frac{1}{t}\\sqrt{\\sum_{j=1}^t\n\\frac{m}{r_j}\\log m}\\right)$, where $r_t$ denotes the sample size at round $t$.\nThis result demonstrates that the optimization error decreases as the number of\nsamples increases and implies a consistent sample complexity of $O(m\\log\n(m)/\\epsilon^2)$ for any fixed sample size $r\\in[m]$, aligning with existing\nbounds for cases of $r=1$ or $m$. We validate our approach on synthetic binary\nand real-world multi-class datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.15212v1",
    "published": "2025-05-21T07:41:16+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15211v1",
    "title": "GCNT: Graph-Based Transformer Policies for Morphology-Agnostic Reinforcement Learning",
    "authors": [
      "Yingbo Luo",
      "Meibao Yao",
      "Xueming Xiao"
    ],
    "abstract": "Training a universal controller for robots with different morphologies is a\npromising research trend, since it can significantly enhance the robustness and\nresilience of the robotic system. However, diverse morphologies can yield\ndifferent dimensions of state space and action space, making it difficult to\ncomply with traditional policy networks. Existing methods address this issue by\nmodularizing the robot configuration, while do not adequately extract and\nutilize the overall morphological information, which has been proven crucial\nfor training a universal controller. To this end, we propose GCNT, a\nmorphology-agnostic policy network based on improved Graph Convolutional\nNetwork (GCN) and Transformer. It exploits the fact that GCN and Transformer\ncan handle arbitrary number of modules to achieve compatibility with diverse\nmorphologies. Our key insight is that the GCN is able to efficiently extract\nmorphology information of robots, while Transformer ensures that it is fully\nutilized by allowing each node of the robot to communicate this information\ndirectly. Experimental results show that our method can generate resilient\nlocomotion behaviors for robots with different configurations, including\nzero-shot generalization to robot morphologies not seen during training. In\nparticular, GCNT achieved the best performance on 8 tasks in the 2 standard\nbenchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15211v1",
    "published": "2025-05-21T07:40:00+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17102v1",
    "title": "BanglaByT5: Byte-Level Modelling for Bangla",
    "authors": [
      "Pramit Bhattacharyya",
      "Arnab Bhattacharya"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable success across various\nnatural language processing tasks. However, most LLM models use traditional\ntokenizers like BPE and SentencePiece, which fail to capture the finer nuances\nof a morphologically rich language like Bangla (Bengali). In this work, we\nintroduce BanglaByT5, the first byte-level encoder-decoder model explicitly\ntailored for Bangla. Built upon a small variant of Googles ByT5 architecture,\nBanglaByT5 is pre-trained on a 14GB curated corpus combining high-quality\nliterary and newspaper articles. Through zeroshot and supervised evaluations\nacross generative and classification tasks, BanglaByT5 demonstrates competitive\nperformance, surpassing several multilingual and larger models. Our findings\nhighlight the efficacy of byte-level modelling for morphologically rich\nlanguages and highlight BanglaByT5 potential as a lightweight yet powerful tool\nfor Bangla NLP, particularly in both resource-constrained and scalable\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.17102v1",
    "published": "2025-05-21T07:39:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17101v1",
    "title": "An approach to identify the most semantically informative deep representations of text and images",
    "authors": [
      "Santiago Acevedo",
      "Andrea Mascaretti",
      "Riccardo Rende",
      "Mat√©o Mahaut",
      "Marco Baroni",
      "Alessandro Laio"
    ],
    "abstract": "Deep neural networks are known to develop similar representations for\nsemantically related data, even when they belong to different domains, such as\nan image and its description, or the same text in different languages. We\npresent a method for quantitatively investigating this phenomenon by measuring\nthe relative information content of the representations of semantically related\ndata and probing how it is encoded into multiple tokens of large language\nmodels (LLMs) and vision transformers. Looking first at how LLMs process pairs\nof translated sentences, we identify inner ``semantic'' layers containing the\nmost language-transferable information. We find moreover that, on these layers,\na larger LLM (DeepSeek-V3) extracts significantly more general information than\na smaller one (Llama3.1-8B). Semantic information is spread across many tokens\nand it is characterized by long-distance correlations between tokens and by a\ncausal left-to-right (i.e., past-future) asymmetry. We also identify layers\nencoding semantic information within visual transformers. We show that caption\nrepresentations in the semantic layers of LLMs predict visual representations\nof the corresponding images. We observe significant and model-dependent\ninformation asymmetries between image and text representations.",
    "pdf_url": "http://arxiv.org/pdf/2505.17101v1",
    "published": "2025-05-21T07:38:48+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15210v1",
    "title": "Deliberation on Priors: Trustworthy Reasoning of Large Language Models on Knowledge Graphs",
    "authors": [
      "Jie Ma",
      "Ning Qu",
      "Zhitao Gao",
      "Rui Xing",
      "Jun Liu",
      "Hongbin Pei",
      "Jiang Xie",
      "Linyun Song",
      "Pinghui Wang",
      "Jing Tao",
      "Zhou Su"
    ],
    "abstract": "Knowledge graph-based retrieval-augmented generation seeks to mitigate\nhallucinations in Large Language Models (LLMs) caused by insufficient or\noutdated knowledge. However, existing methods often fail to fully exploit the\nprior knowledge embedded in knowledge graphs (KGs), particularly their\nstructural information and explicit or implicit constraints. The former can\nenhance the faithfulness of LLMs' reasoning, while the latter can improve the\nreliability of response generation. Motivated by these, we propose a\ntrustworthy reasoning framework, termed Deliberation over Priors (DP), which\nsufficiently utilizes the priors contained in KGs. Specifically, DP adopts a\nprogressive knowledge distillation strategy that integrates structural priors\ninto LLMs through a combination of supervised fine-tuning and Kahneman-Tversky\noptimization, thereby improving the faithfulness of relation path generation.\nFurthermore, our framework employs a reasoning-introspection strategy, which\nguides LLMs to perform refined reasoning verification based on extracted\nconstraint priors, ensuring the reliability of response generation. Extensive\nexperiments on three benchmark datasets demonstrate that DP achieves new\nstate-of-the-art performance, especially a Hit@1 improvement of 13% on the\nComplexWebQuestions dataset, and generates highly trustworthy responses. We\nalso conduct various analyses to verify its flexibility and practicality. The\ncode is available at https://github.com/reml-group/Deliberation-on-Priors.",
    "pdf_url": "http://arxiv.org/pdf/2505.15210v1",
    "published": "2025-05-21T07:38:45+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "I.2.4"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15209v3",
    "title": "DUSK: Do Not Unlearn Shared Knowledge",
    "authors": [
      "Wonje Jeung",
      "Sangyeon Yoon",
      "Hyesoo Hong",
      "Soeun Kim",
      "Seungju Han",
      "Youngjae Yu",
      "Albert No"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed in real-world\napplications, raising concerns about the unauthorized use of copyrighted or\nsensitive data. Machine unlearning aims to remove such 'forget' data while\npreserving utility and information from the 'retain' set. However, existing\nevaluations typically assume that forget and retain sets are fully disjoint,\noverlooking realistic scenarios where they share overlapping content. For\ninstance, a news article may need to be unlearned, even though the same event,\nsuch as an earthquake in Japan, is also described factually on Wikipedia.\nEffective unlearning should remove the specific phrasing of the news article\nwhile preserving publicly supported facts. In this paper, we introduce DUSK, a\nbenchmark designed to evaluate unlearning methods under realistic data overlap.\nDUSK constructs document sets that describe the same factual content in\ndifferent styles, with some shared information appearing across all sets and\nother content remaining unique to each. When one set is designated for\nunlearning, an ideal method should remove its unique content while preserving\nshared facts. We define seven evaluation metrics to assess whether unlearning\nmethods can achieve this selective removal. Our evaluation of nine recent\nunlearning methods reveals a key limitation: while most can remove\nsurface-level text, they often fail to erase deeper, context-specific knowledge\nwithout damaging shared content. We release DUSK as a public benchmark to\nsupport the development of more precise and reliable unlearning techniques for\nreal-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15209v3",
    "published": "2025-05-21T07:37:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15208v1",
    "title": "GT^2-GS: Geometry-aware Texture Transfer for Gaussian Splatting",
    "authors": [
      "Wenjie Liu",
      "Zhongliang Liu",
      "Junwei Shu",
      "Changbo Wang",
      "Yang Li"
    ],
    "abstract": "Transferring 2D textures to 3D modalities is of great significance for\nimproving the efficiency of multimedia content creation. Existing approaches\nhave rarely focused on transferring image textures onto 3D representations. 3D\nstyle transfer methods are capable of transferring abstract artistic styles to\n3D scenes. However, these methods often overlook the geometric information of\nthe scene, which makes it challenging to achieve high-quality 3D texture\ntransfer results. In this paper, we present GT^2-GS, a geometry-aware texture\ntransfer framework for gaussian splitting. From the perspective of matching\ntexture features with geometric information in rendered views, we identify the\nissue of insufficient texture features and propose a geometry-aware texture\naugmentation module to expand the texture feature set. Moreover, a\ngeometry-consistent texture loss is proposed to optimize texture features into\nthe scene representation. This loss function incorporates both camera pose and\n3D geometric information of the scene, enabling controllable texture-oriented\nappearance editing. Finally, a geometry preservation strategy is introduced. By\nalternating between the texture transfer and geometry correction stages over\nmultiple iterations, this strategy achieves a balance between learning texture\nfeatures and preserving geometric integrity. Extensive experiments demonstrate\nthe effectiveness and controllability of our method. Through geometric\nawareness, our approach achieves texture transfer results that better align\nwith human visual perception. Our homepage is available at\nhttps://vpx-ecnu.github.io/GT2-GS-website.",
    "pdf_url": "http://arxiv.org/pdf/2505.15208v1",
    "published": "2025-05-21T07:37:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15207v1",
    "title": "Canonical Structure and Hidden Symmetries in Scalar Field Cosmology",
    "authors": [
      "Andronikos Paliathanasis"
    ],
    "abstract": "We investigate hidden symmetries in minimally coupled scalar field cosmology\nwithin the FLRW universe, and a perfect fluid with and without interaction to\nthe scalar field. We show that for an exponential potential there exists a set\nof canonical transformations through which the cosmological field equations can\nbe recast in the form of a free particle in flat space. Based on this\nequivalence, we construct a mapping that generates cosmological solutions with\ninteraction terms, corresponding to a chameleon mechanism. Finally, we discuss\nhow this class of canonical transformations can relate the solution spaces of\ndifferent cosmological models, such as of the scalar field and of the\n$\\Lambda$-Cosmology.",
    "pdf_url": "http://arxiv.org/pdf/2505.15207v1",
    "published": "2025-05-21T07:36:35+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15206v1",
    "title": "EndoVLA: Dual-Phase Vision-Language-Action Model for Autonomous Tracking in Endoscopy",
    "authors": [
      "Chi Kit Ng",
      "Long Bai",
      "Guankun Wang",
      "Yupeng Wang",
      "Huxin Gao",
      "Kun Yuan",
      "Chenhan Jin",
      "Tieyong Zeng",
      "Hongliang Ren"
    ],
    "abstract": "In endoscopic procedures, autonomous tracking of abnormal regions and\nfollowing circumferential cutting markers can significantly reduce the\ncognitive burden on endoscopists. However, conventional model-based pipelines\nare fragile for each component (e.g., detection, motion planning) requires\nmanual tuning and struggles to incorporate high-level endoscopic intent,\nleading to poor generalization across diverse scenes. Vision-Language-Action\n(VLA) models, which integrate visual perception, language grounding, and motion\nplanning within an end-to-end framework, offer a promising alternative by\nsemantically adapting to surgeon prompts without manual recalibration. Despite\ntheir potential, applying VLA models to robotic endoscopy presents unique\nchallenges due to the complex and dynamic anatomical environments of the\ngastrointestinal (GI) tract. To address this, we introduce EndoVLA, designed\nspecifically for continuum robots in GI interventions. Given endoscopic images\nand surgeon-issued tracking prompts, EndoVLA performs three core tasks: (1)\npolyp tracking, (2) delineation and following of abnormal mucosal regions, and\n(3) adherence to circular markers during circumferential cutting. To tackle\ndata scarcity and domain shifts, we propose a dual-phase strategy comprising\nsupervised fine-tuning on our EndoVLA-Motion dataset and reinforcement\nfine-tuning with task-aware rewards. Our approach significantly improves\ntracking performance in endoscopy and enables zero-shot generalization in\ndiverse scenes and complex sequential tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15206v1",
    "published": "2025-05-21T07:35:00+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15205v2",
    "title": "Flashback: Memory-Driven Zero-shot, Real-time Video Anomaly Detection",
    "authors": [
      "Hyogun Lee",
      "Haksub Kim",
      "Ig-Jae Kim",
      "Yonghun Choi"
    ],
    "abstract": "Video Anomaly Detection (VAD) automatically identifies anomalous events from\nvideo, mitigating the need for human operators in large-scale surveillance\ndeployments. However, two fundamental obstacles hinder real-world adoption:\ndomain dependency and real-time constraints -- requiring near-instantaneous\nprocessing of incoming video. To this end, we propose Flashback, a zero-shot\nand real-time video anomaly detection paradigm. Inspired by the human cognitive\nmechanism of instantly judging anomalies and reasoning in current scenes based\non past experience, Flashback operates in two stages: Recall and Respond. In\nthe offline recall stage, an off-the-shelf LLM builds a pseudo-scene memory of\nboth normal and anomalous captions without any reliance on real anomaly data.\nIn the online respond stage, incoming video segments are embedded and matched\nagainst this memory via similarity search. By eliminating all LLM calls at\ninference time, Flashback delivers real-time VAD even on a consumer-grade GPU.\nOn two large datasets from real-world surveillance scenarios, UCF-Crime and\nXD-Violence, we achieve 87.3 AUC (+7.0 pp) and 75.1 AP (+13.1 pp),\nrespectively, outperforming prior zero-shot VAD methods by large margins.",
    "pdf_url": "http://arxiv.org/pdf/2505.15205v2",
    "published": "2025-05-21T07:32:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15204v1",
    "title": "BLINK: an End-To-End GPU High Time Resolution Imaging Pipeline for Fast Radio Burst Searches with the Murchison Widefield Array",
    "authors": [
      "Cristian Di Pietrantonio",
      "Marcin Sokolowski",
      "Christopher Harris",
      "Daniel Price",
      "Randall Wayth"
    ],
    "abstract": "Petabytes of archival high time resolution observations have been captured\nwith the Murchison Widefield Array. The search for Fast Radio Bursts within\nthese using established software has been limited by its inability to scale on\nsupercomputing infrastructure, necessary to meet the associated computational\nand memory requirements. Hence, past searches used a coarse integration time,\nin the scale of seconds, or analysed an insufficient number of hours of\nobservations. This paper introduces BLINK, a novel radio interferometry imaging\nsoftware for low-frequency FRB searches to be run on modern supercomputers. It\nis implemented as a suite of software libraries executing all computations on\nGPU, supporting both AMD and NVIDIA hardware vendors. These libraries are\ndesigned to interface with each other and to define the BLINK imaging pipeline\nas a single executable program. Expensive I/O operations between imaging stages\nare not necessary because the stages now share the same memory space and data\nrepresentation. BLINK is the first imaging pipeline implementation able to\nfully run on GPUs as a single process, further supporting AMD hardware and\nenabling Australian researchers to take advantage of Pawsey's Setonix\nsupercomputer. In the millisecond-scale time resolution imaging test case\nillustrated in this paper, representative of what is required for FRB searches,\nthe BLINK imaging pipeline achieves a 3687x speedup compared to a traditional\nMWA imaging pipeline employing WSClean.",
    "pdf_url": "http://arxiv.org/pdf/2505.15204v1",
    "published": "2025-05-21T07:31:09+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15203v1",
    "title": "EEG-Based Inter-Patient Epileptic Seizure Detection Combining Domain Adversarial Training with CNN-BiLSTM Network",
    "authors": [
      "Rina Tazaki",
      "Tomoyuki Akiyama",
      "Akira Furui"
    ],
    "abstract": "Automated epileptic seizure detection from electroencephalogram (EEG) remains\nchallenging due to significant individual differences in EEG patterns across\npatients. While existing studies achieve high accuracy with patient-specific\napproaches, they face difficulties in generalizing to new patients. To address\nthis, we propose a detection framework combining domain adversarial training\nwith a convolutional neural network (CNN) and a bidirectional long short-term\nmemory (BiLSTM). First, the CNN extracts local patient-invariant features\nthrough domain adversarial training, which optimizes seizure detection accuracy\nwhile minimizing patient-specific characteristics. Then, the BiLSTM captures\ntemporal dependencies in the extracted features to model seizure evolution\npatterns. Evaluation using EEG recordings from 20 patients with focal epilepsy\ndemonstrated superior performance over non-adversarial methods, achieving high\ndetection accuracy across different patients. The integration of adversarial\ntraining with temporal modeling enables robust cross-patient seizure detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.15203v1",
    "published": "2025-05-21T07:27:55+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15202v1",
    "title": "Reconstruction of Graph Signals on Complex Manifolds with Kernel Methods",
    "authors": [
      "Yu Zhang",
      "Linyu Peng",
      "Bing-Zhao Li"
    ],
    "abstract": "Graph signals are widely used to describe vertex attributes or features in\ngraph-structured data, with applications spanning the internet, social media,\ntransportation, sensor networks, and biomedicine. Graph signal processing (GSP)\nhas emerged to facilitate the analysis, processing, and sampling of such\nsignals. While kernel methods have been extensively studied for estimating\ngraph signals from samples provided on a subset of vertices, their application\nto complex-valued graph signals remains largely unexplored. This paper\nintroduces a novel framework for reconstructing graph signals using kernel\nmethods on complex manifolds. By embedding graph vertices into a\nhigher-dimensional complex ambient space that approximates a lower-dimensional\nmanifold, the framework extends the reproducing kernel Hilbert space to complex\nmanifolds. It leverages Hermitian metrics and geometric measures to\ncharacterize kernels and graph signals. Additionally, several traditional\nkernels and graph topology-driven kernels are proposed for reconstructing\ncomplex graph signals. Finally, experimental results on synthetic and\nreal-world datasets demonstrate the effectiveness of this framework in\naccurately reconstructing complex graph signals, outperforming conventional\nkernel-based approaches. This work lays a foundational basis for integrating\ncomplex geometry and kernel methods in GSP.",
    "pdf_url": "http://arxiv.org/pdf/2505.15202v1",
    "published": "2025-05-21T07:27:38+00:00",
    "categories": [
      "eess.SP",
      "stat.ML"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15201v1",
    "title": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems",
    "authors": [
      "Christian Walder",
      "Deep Karkhanis"
    ],
    "abstract": "Reinforcement Learning (RL) algorithms sample multiple n>1 solution attempts\nfor each problem and reward them independently. This optimizes for pass@1\nperformance and prioritizes the strength of isolated samples at the expense of\nthe diversity and collective utility of sets of samples. This under-utilizes\nthe sampling capacity, limiting exploration and eventual improvement on harder\nexamples. As a fix, we propose Pass-at-k Policy Optimization (PKPO), a\ntransformation on the final rewards which leads to direct optimization of\npass@k performance, thus optimizing for sets of samples that maximize reward\nwhen considered jointly. Our contribution is to derive novel low variance\nunbiased estimators for pass@k and its gradient, in both the binary and\ncontinuous reward settings. We show optimization with our estimators reduces to\nstandard RL with rewards that have been jointly transformed by a stable and\nefficient transformation function.\n  While previous efforts are restricted to k=n, ours is the first to enable\nrobust optimization of pass@k for any arbitrary k <= n. Moreover, instead of\ntrading off pass@1 performance for pass@k gains, our method allows annealing k\nduring training, optimizing both metrics and often achieving strong pass@1\nnumbers alongside significant pass@k gains.\n  We validate our reward transformations on toy experiments, which reveal the\nvariance reducing properties of our formulations. We also include real-world\nexamples using the open-source LLM, GEMMA-2. We find that our transformation\neffectively optimizes for the target k. Furthermore, higher k values enable\nsolving more and harder problems, while annealing k boosts both the pass@1 and\npass@k . Crucially, for challenging task sets where conventional pass@1\noptimization stalls, our pass@k approach unblocks learning, likely due to\nbetter exploration by prioritizing joint utility over the utility of individual\nsamples.",
    "pdf_url": "http://arxiv.org/pdf/2505.15201v1",
    "published": "2025-05-21T07:26:36+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15200v1",
    "title": "Performance Analysis of Fluid Antenna System under Spatially-Correlated Rician Fading Channels",
    "authors": [
      "Jiangsheng Huangfu",
      "Zhengyu Song",
      "Tianwei Hou",
      "Anna Li",
      "Yuanwei Liu",
      "Arumugam Nallanathan",
      "Kai-Kit Wong"
    ],
    "abstract": "Fluid antenna systems (FAS) are among the most promising technologies for the\nsixth generation (6G) mobile communication networks. Unlike traditional\nfixed-position multiple-input multiple-output (MIMO) systems, a FAS possesses\nposition reconfigurability to switch on-demand among $N$ predefined ports over\na prescribed space. This paper explores the performance of a single-input\nsingle-output (SISO) model with a fixed-position antenna transmitter and a\nsingle-antenna FAS receiver, referred to as the Rx-SISO-FAS model, under\nspatially-correlated Rician fading channels. Our contributions include exact\nexpressions and closed-form bounds for the outage probability of the\nRx-SISO-FAS model, as well as exact and closed-form lower bounds for the\nergodic rate. Importantly, we also analyze the performance considering both\nuniform linear array (ULA) and uniform planar array (UPA) configurations for\nthe ports of the FAS. To gain insights, we evaluate the diversity order of the\nproposed model and our analytical results indicate that with a fixed overall\nsystem size, increasing the number of ports, $N$, significantly decreases the\noutage performance of FAS under different Rician fading factors. Our numerical\nresults further demonstrate that: $i)$ the Rx-SISO-FAS model can enhance\nperformance under spatially-correlated Rician fading channels over the\nfixed-position antenna counterpart; $ii)$ the Rician factor negatively impacts\nperformance in the low signal-to-noise ratio (SNR) regime; $iii$) FAS can\noutperform an $L$ branches maximum ratio combining (MRC) system under Rician\nfading channels; and $iv)$ when the number of ports is identical, UPA\noutperforms ULA.",
    "pdf_url": "http://arxiv.org/pdf/2505.15200v1",
    "published": "2025-05-21T07:26:08+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15199v1",
    "title": "Geometric duality between effective field theories I: scattering amplitudes",
    "authors": [
      "Tomas Brauner",
      "Yang Li",
      "Diederik Roest",
      "Tianzhi Wang"
    ],
    "abstract": "We propose a novel type of duality that connects a sequence of well-known\ntheories with even-multiplicity scalar amplitudes: it relates the Yang-Mills\ntheory coupled to a specific scalar matter sector to the nonlinear sigma model\non a symmetric coset space, the (multiflavor) Dirac-Born-Infeld theory, and the\nspecial Galileon theory. The duality is manifested with the help of a covariant\nformulation of the classical equations of motion that features a contact\nquartic scalar self-coupling combined with propagation on a dynamical\nbackground of elementary or composite gauge fields. This is augmented with a\nset of constitutive relations that reflect the intrinsic or extrinsic geometry\nof the target space of the theory. The universality of the underlying geometric\nstructure allows for an unambiguous mapping between different theories.",
    "pdf_url": "http://arxiv.org/pdf/2505.15199v1",
    "published": "2025-05-21T07:25:59+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15198v1",
    "title": "Hybrid Quantum Walks Dynamics and Construction of a Quantum Cryptographic Primitive",
    "authors": [
      "Rachana Soni",
      "Navneet Pratap Singh",
      "Neelam Choudhary"
    ],
    "abstract": "In this research article, we design a quantum hash function model from hybrid\nquantum walks on finite path graph. The hybrid evolution operator consisting of\nintegrated framework of continuous time quantum walks and lackadaisical quantum\nwalks as per choice of bits in binary input message, acts on initial quantum\nstate and generate quantum hash values from probability distribution of final\nquantum state. The quantum hash values generated through the proposed method is\nshowing strong cryptographic properties in sensitivity analysis, collision\nanalysis, statistical features analysis, birthday attack and uniform analysis.\nOur proposed framework is showing successful results utilizing mathematically\nwell defined structure of hybrid quantum walks based on quantum mechanics\nphenomena.",
    "pdf_url": "http://arxiv.org/pdf/2505.15198v1",
    "published": "2025-05-21T07:25:34+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15197v1",
    "title": "Intentional Gesture: Deliver Your Intentions with Gestures for Speech",
    "authors": [
      "Pinxin Liu",
      "Haiyang Liu",
      "Luchuan Song",
      "Chenliang Xu"
    ],
    "abstract": "When humans speak, gestures help convey communicative intentions, such as\nadding emphasis or describing concepts. However, current co-speech gesture\ngeneration methods rely solely on superficial linguistic cues (\\textit{e.g.}\nspeech audio or text transcripts), neglecting to understand and leverage the\ncommunicative intention that underpins human gestures. This results in outputs\nthat are rhythmically synchronized with speech but are semantically shallow. To\naddress this gap, we introduce \\textbf{Intentional-Gesture}, a novel framework\nthat casts gesture generation as an intention-reasoning task grounded in\nhigh-level communicative functions. % First, we curate the \\textbf{InG} dataset\nby augmenting BEAT-2 with gesture-intention annotations (\\textit{i.e.}, text\nsentences summarizing intentions), which are automatically annotated using\nlarge vision-language models. Next, we introduce the \\textbf{Intentional\nGesture Motion Tokenizer} to leverage these intention annotations. It injects\nhigh-level communicative functions (\\textit{e.g.}, intentions) into tokenized\nmotion representations to enable intention-aware gesture synthesis that are\nboth temporally aligned and semantically meaningful, achieving new\nstate-of-the-art performance on the BEAT-2 benchmark. Our framework offers a\nmodular foundation for expressive gesture generation in digital humans and\nembodied AI. Project Page: https://andypinxinliu.github.io/Intentional-Gesture",
    "pdf_url": "http://arxiv.org/pdf/2505.15197v1",
    "published": "2025-05-21T07:24:51+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17100v1",
    "title": "Any Large Language Model Can Be a Reliable Judge: Debiasing with a Reasoning-based Bias Detector",
    "authors": [
      "Haoyan Yang",
      "Runxue Bao",
      "Cao Xiao",
      "Jun Ma",
      "Parminder Bhatia",
      "Shangqian Gao",
      "Taha Kass-Hout"
    ],
    "abstract": "LLM-as-a-Judge has emerged as a promising tool for automatically evaluating\ngenerated outputs, but its reliability is often undermined by potential biases\nin judgment. Existing efforts to mitigate these biases face key limitations:\nin-context learning-based methods fail to address rooted biases due to the\nevaluator's limited capacity for self-reflection, whereas fine-tuning is not\napplicable to all evaluator types, especially closed-source models. To address\nthis challenge, we introduce the Reasoning-based Bias Detector (RBD), which is\na plug-in module that identifies biased evaluations and generates structured\nreasoning to guide evaluator self-correction. Rather than modifying the\nevaluator itself, RBD operates externally and engages in an iterative process\nof bias detection and feedback-driven revision. To support its development, we\ndesign a complete pipeline consisting of biased dataset construction,\nsupervision collection, distilled reasoning-based fine-tuning of RBD, and\nintegration with LLM evaluators. We fine-tune four sizes of RBD models, ranging\nfrom 1.5B to 14B, and observe consistent performance improvements across all\nscales. Experimental results on 4 bias types--verbosity, position, bandwagon,\nand sentiment--evaluated using 8 LLM evaluators demonstrate RBD's strong\neffectiveness. For example, the RBD-8B model improves evaluation accuracy by an\naverage of 18.5% and consistency by 10.9%, and surpasses prompting-based\nbaselines and fine-tuned judges by 12.8% and 17.2%, respectively. These results\nhighlight RBD's effectiveness and scalability. Additional experiments further\ndemonstrate its strong generalization across biases and domains, as well as its\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.17100v1",
    "published": "2025-05-21T07:23:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15196v1",
    "title": "EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association",
    "authors": [
      "Weiqi Wang",
      "Limeng Cui",
      "Xin Liu",
      "Sreyashi Nag",
      "Wenju Xu",
      "Chen Luo",
      "Sheikh Muhammad Sarwar",
      "Yang Li",
      "Hansu Gu",
      "Hui Liu",
      "Changlong Yu",
      "Jiaxin Bai",
      "Yifan Gao",
      "Haiyang Zhang",
      "Qi He",
      "Shuiwang Ji",
      "Yangqiu Song"
    ],
    "abstract": "Goal-oriented script planning, or the ability to devise coherent sequences of\nactions toward specific goals, is commonly employed by humans to plan for\ntypical activities. In e-commerce, customers increasingly seek LLM-based\nassistants to generate scripts and recommend products at each step, thereby\nfacilitating convenient and efficient shopping experiences. However, this\ncapability remains underexplored due to several challenges, including the\ninability of LLMs to simultaneously conduct script planning and product\nretrieval, difficulties in matching products caused by semantic discrepancies\nbetween planned actions and search queries, and a lack of methods and benchmark\ndata for evaluation. In this paper, we step forward by formally defining the\ntask of E-commerce Script Planning (EcomScript) as three sequential subtasks.\nWe propose a novel framework that enables the scalable generation of\nproduct-enriched scripts by associating products with each step based on the\nsemantic similarity between the actions and their purchase intentions. By\napplying our framework to real-world e-commerce data, we construct the very\nfirst large-scale EcomScript dataset, EcomScriptBench, which includes 605,229\nscripts sourced from 2.4 million products. Human annotations are then conducted\nto provide gold labels for a sampled subset, forming an evaluation benchmark.\nExtensive experiments reveal that current (L)LMs face significant challenges\nwith EcomScript tasks, even after fine-tuning, while injecting product purchase\nintentions improves their performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15196v1",
    "published": "2025-05-21T07:21:38+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15195v1",
    "title": "Self-Boost via Optimal Retraining: An Analysis via Approximate Message Passing",
    "authors": [
      "Adel Javanmard",
      "Rudrajit Das",
      "Alessandro Epasto",
      "Vahab Mirrokni"
    ],
    "abstract": "Retraining a model using its own predictions together with the original,\npotentially noisy labels is a well-known strategy for improving the model\nperformance. While prior works have demonstrated the benefits of specific\nheuristic retraining schemes, the question of how to optimally combine the\nmodel's predictions and the provided labels remains largely open. This paper\naddresses this fundamental question for binary classification tasks. We develop\na principled framework based on approximate message passing (AMP) to analyze\niterative retraining procedures for two ground truth settings: Gaussian mixture\nmodel (GMM) and generalized linear model (GLM). Our main contribution is the\nderivation of the Bayes optimal aggregator function to combine the current\nmodel's predictions and the given labels, which when used to retrain the same\nmodel, minimizes its prediction error. We also quantify the performance of this\noptimal retraining strategy over multiple rounds. We complement our theoretical\nresults by proposing a practically usable version of the theoretically-optimal\naggregator function for linear probing with the cross-entropy loss, and\ndemonstrate its superiority over baseline methods in the high label noise\nregime.",
    "pdf_url": "http://arxiv.org/pdf/2505.15195v1",
    "published": "2025-05-21T07:16:44+00:00",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15194v1",
    "title": "GAMA: Geometry-Aware Manifold Alignment via Structured Adversarial Perturbations for Robust Domain Adaptation",
    "authors": [
      "Hana Satou",
      "F Monkey"
    ],
    "abstract": "Domain adaptation remains a challenge when there is significant manifold\ndiscrepancy between source and target domains. Although recent methods leverage\nmanifold-aware adversarial perturbations to perform data augmentation, they\noften neglect precise manifold alignment and systematic exploration of\nstructured perturbations. To address this, we propose GAMA (Geometry-Aware\nManifold Alignment), a structured framework that achieves explicit manifold\nalignment via adversarial perturbation guided by geometric information. GAMA\nsystematically employs tangent space exploration and manifold-constrained\nadversarial optimization, simultaneously enhancing semantic consistency,\nrobustness to off-manifold deviations, and cross-domain alignment. Theoretical\nanalysis shows that GAMA tightens the generalization bound via structured\nregularization and explicit alignment. Empirical results on DomainNet, VisDA,\nand Office-Home demonstrate that GAMA consistently outperforms existing\nadversarial and adaptation methods in both unsupervised and few-shot settings,\nexhibiting superior robustness, generalization, and manifold alignment\ncapability.",
    "pdf_url": "http://arxiv.org/pdf/2505.15194v1",
    "published": "2025-05-21T07:16:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15193v1",
    "title": "Influences of Uncertainties in Thermodynamic Models on Pareto-optimized Dividing Wall Columns for Ideal Mixtures",
    "authors": [
      "Lea Trescher",
      "David Mogalle",
      "Patrick Otto Ludl",
      "Tobias Seidel",
      "Michael Bortz",
      "Thomas Gruetzner"
    ],
    "abstract": "This article examines the effect of individual and combined uncertainties in\nthermodynamic models on the performance of simulated, steady-state\nPareto-optimized Dividing Wall Columns. It is a follow-up of the previous work\nanalogously treating deviations in process variables. Such deviations and\nuncertainties that may even be unknown during the design process can\nsignificantly influence the separation result. However, other than process\nvariables, uncertainties in thermodynamics are usually not systematically\nconsidered during design. For the first time, the effects of uncertain\nthermodynamic properties on Pareto-optimized DWCs with different numbers of\nstages and for different mixtures are presented and compared qualitatively and\nquantitatively. Depending on the number of stages and mixture characteristics,\nparticularly critical properties are identified. On the one hand, this provides\ninformation on aspects requiring special attention prior to design, and on the\nother hand, it also indicates in which section of the DWC a stage supplement\nmight be most beneficial.",
    "pdf_url": "http://arxiv.org/pdf/2505.15193v1",
    "published": "2025-05-21T07:16:06+00:00",
    "categories": [
      "physics.chem-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15192v1",
    "title": "Leveraging Foundation Models for Multimodal Graph-Based Action Recognition",
    "authors": [
      "Fatemeh Ziaeetabar",
      "Florentin W√∂rg√∂tter"
    ],
    "abstract": "Foundation models have ushered in a new era for multimodal video\nunderstanding by enabling the extraction of rich spatiotemporal and semantic\nrepresentations. In this work, we introduce a novel graph-based framework that\nintegrates a vision-language foundation, leveraging VideoMAE for dynamic visual\nencoding and BERT for contextual textual embedding, to address the challenge of\nrecognizing fine-grained bimanual manipulation actions. Departing from\nconventional static graph architectures, our approach constructs an adaptive\nmultimodal graph where nodes represent frames, objects, and textual\nannotations, and edges encode spatial, temporal, and semantic relationships.\nThese graph structures evolve dynamically based on learned interactions,\nallowing for flexible and context-aware reasoning. A task-specific attention\nmechanism within a Graph Attention Network further enhances this reasoning by\nmodulating edge importance based on action semantics. Through extensive\nevaluations on diverse benchmark datasets, we demonstrate that our method\nconsistently outperforms state-of-the-art baselines, underscoring the strength\nof combining foundation models with dynamic graph-based reasoning for robust\nand generalizable action recognition.",
    "pdf_url": "http://arxiv.org/pdf/2505.15192v1",
    "published": "2025-05-21T07:15:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15191v1",
    "title": "Geometrically Regularized Transfer Learning with On-Manifold and Off-Manifold Perturbation",
    "authors": [
      "Hana Satou",
      "Alan Mitkiy",
      "F Monkey"
    ],
    "abstract": "Transfer learning under domain shift remains a fundamental challenge due to\nthe divergence between source and target data manifolds. In this paper, we\npropose MAADA (Manifold-Aware Adversarial Data Augmentation), a novel framework\nthat decomposes adversarial perturbations into on-manifold and off-manifold\ncomponents to simultaneously capture semantic variation and model brittleness.\nWe theoretically demonstrate that enforcing on-manifold consistency reduces\nhypothesis complexity and improves generalization, while off-manifold\nregularization smooths decision boundaries in low-density regions. Moreover, we\nintroduce a geometry-aware alignment loss that minimizes geodesic discrepancy\nbetween source and target manifolds. Experiments on DomainNet, VisDA, and\nOffice-Home show that MAADA consistently outperforms existing adversarial and\nadaptation methods in both unsupervised and few-shot settings, demonstrating\nsuperior structural robustness and cross-domain generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.15191v1",
    "published": "2025-05-21T07:13:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15190v1",
    "title": "Building LOD Representation for 3D Urban Scenes",
    "authors": [
      "Shanshan Pan",
      "Runze Zhang",
      "Yilin Liu",
      "Minglun Gong",
      "Hui Huang"
    ],
    "abstract": "The advances in 3D reconstruction technology, such as photogrammetry and\nLiDAR scanning, have made it easier to reconstruct accurate and detailed 3D\nmodels for urban scenes. Nevertheless, these reconstructed models often contain\na large number of geometry primitives, making interactive manipulation and\nrendering challenging, especially on resource-constrained devices like virtual\nreality platforms. Therefore, the generation of appropriate levels-of-detail\n(LOD) representations for these models is crucial. Additionally, automatically\nreconstructed 3D models tend to suffer from noise and lack semantic\ninformation. Dealing with these issues and creating LOD representations that\nare robust against noise while capturing the semantic meaning present\nsignificant challenges. In this paper, we propose a novel algorithm to address\nthese challenges. We begin by analysing the properties of planar primitives\ndetected from the input and group these primitives into multiple level sets by\nforming meaningful 3D structures. These level sets form the nodes of our\ninnovative LOD-Tree. By selecting nodes at appropriate depths within the\nLOD-Tree, different LOD representations can be generated. Experimental results\non real and complex urban scenes demonstrate the merits of our approach in\ngenerating clean, accurate, and semantically meaningful LOD representations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15190v1",
    "published": "2025-05-21T07:13:01+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15188v2",
    "title": "A novel framework for detecting multiple change points in functional data sequences",
    "authors": [
      "Zhiqing Fang",
      "Xin Liu"
    ],
    "abstract": "Detecting multiple change points in functional data sequences has been\nincreasingly popular and critical in various scientific fields. In this\narticle, we propose a novel two-stage framework for detecting multiple change\npoints in functional data sequences, named as detection by Group Selection and\nPartial F-test (GS-PF). The detection problem is firstly transformed into a\nhigh-dimensional sparse estimation problem via functional basis expansion, and\nthe penalized group selection is applied to estimate the number and locations\nof candidate change points in the first stage. To further circumvent the issue\nof overestimating the true number of change points in practice, a partial\nF-test is applied in the second stage to filter redundant change points so that\nthe false discovery rate of the F-test for multiple change points is\ncontrolled. Additionally, in order to reduce complexity of the proposed GS-PF\nmethod, a link parameter is adopted to generate candidate sets of potential\nchange points, which greatly reduces the number of detected change points and\nimproves the efficiency. Asymptotic results are established and validated to\nguarantee detection consistency of the proposed GS-PF method, and its\nperformance is evaluated through intensive simulations and real data analysis,\ncompared with the state-of-the-art detecting methods. Our findings indicate\nthat the proposed GS-PF method exhibits detection consistency in different\nscenarios, which endows our method with the capability for efficient and robust\ndetection of multiple change points in functional data sequences.",
    "pdf_url": "http://arxiv.org/pdf/2505.15188v2",
    "published": "2025-05-21T07:09:03+00:00",
    "categories": [
      "stat.ME",
      "62R10, 62H12, 62H15, 62G05"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15189v1",
    "title": "Riemannian and Lorentzian Calder√≥n problem under Magnetic Perturbation",
    "authors": [
      "Yuchao Yi"
    ],
    "abstract": "We study both the Riemannian and Lorentzian Calder\\'on problem when a family\nof Dirichlet-to-Neumann maps are given for an open set of\nmagnetic/electromagnetic potentials. For the Riemannian version, by allowing\nsmall perturbations of the magnetic potential, we use the Runge Approximation\nTheorem to show that the metric can be uniquely determined. There is no gauge\nequivalence in this case. For the Lorentzian version, we use microlocal\nanalysis to construct the trajectory of null-geodesics via generic\nperturbations of the electromagnetic potential, hence the conformal class of\nthe metric can be constructed. Moreover, we also show, in the Lorentzian case,\nthe same result can be obtained using generic perturbations of the metric\nitself.",
    "pdf_url": "http://arxiv.org/pdf/2505.15189v1",
    "published": "2025-05-21T07:09:03+00:00",
    "categories": [
      "math.AP",
      "math.DG",
      "35R30 (Primary), 35J25, 35L20, 58J32, 53C50"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15187v1",
    "title": "Probing the low mass pseudoscalar in flipped Two Higgs Doublet Model",
    "authors": [
      "Dilip Kumar Ghosh",
      "Biswarup Mukhopadhyaya",
      "Sirshendu Samanta",
      "Ritesh K. Singh"
    ],
    "abstract": "The phenomenology of the flipped two-Higgs-doublet model (2HDM) is relatively\nless explored so far, as compared to the other, commonly discussed, types. It\nis found that this scenario, like several others, admits of a light neutral\npseudoscalar $A$ in the mass range 20 - 60 GeV, consistently with all current\nexperimental data and theoretical constraints. However, the fact that such a\npseudoscalar decays overwhelmingly into a $b\\bar{b}$ pair makes its\nidentification at the Large Hadron Collider (LHC) a challenging task. After\nidentifying the region of the flipped 2HDM parameter space yielding a light\npseudoscalar, we identify a useful search channel in the process $pp\n\\rightarrow A Z(Z^{*}) \\rightarrow b\\bar{b} \\ell^+ \\ell^-$. A cut-based\nanalysis, followed by one based on Boosted Decision Trees, shows that the\nlight-$A$ scenario in flipped 2HDM should be detectable with rather high\nstatistical significance at the high-luminosity LHC run, even after including\nsystematic uncertainties. Furthermore, part of the parameter space, especially\naround $m_A = 30 - 40$ GeV is amenable to detection at the discovery level\nwithin Run-2 itself.",
    "pdf_url": "http://arxiv.org/pdf/2505.15187v1",
    "published": "2025-05-21T07:05:28+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15186v1",
    "title": "Some Versions of Beurling's Theorem on H-type Groups",
    "authors": [
      "Aparajita Dasgupta",
      "Prerna Gulia",
      "Sanjoy Pusti",
      "Sundaram Thangavelu"
    ],
    "abstract": "We prove an analogue of Beurling's theorem on the H-type groups of certain\ndimensions after establishing the Gutzmer's formula for the H-type groups. We\nalso obtain some other versions of the theorem using the modified Radon\ntransform.",
    "pdf_url": "http://arxiv.org/pdf/2505.15186v1",
    "published": "2025-05-21T07:03:38+00:00",
    "categories": [
      "math.FA",
      "Primary 43A85, 42C05, Secondary 33C45, 35P10"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15185v1",
    "title": "MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth Foundation Models",
    "authors": [
      "Yifan Liu",
      "Keyu Fan",
      "Weihao Yu",
      "Chenxin Li",
      "Hao Lu",
      "Yixuan Yuan"
    ],
    "abstract": "Recent advances in generalizable 3D Gaussian Splatting have demonstrated\npromising results in real-time high-fidelity rendering without per-scene\noptimization, yet existing approaches still struggle to handle unfamiliar\nvisual content during inference on novel scenes due to limited\ngeneralizability. To address this challenge, we introduce MonoSplat, a novel\nframework that leverages rich visual priors from pre-trained monocular depth\nfoundation models for robust Gaussian reconstruction. Our approach consists of\ntwo key components: a Mono-Multi Feature Adapter that transforms monocular\nfeatures into multi-view representations, coupled with an Integrated Gaussian\nPrediction module that effectively fuses both feature types for precise\nGaussian generation. Through the Adapter's lightweight attention mechanism,\nfeatures are seamlessly aligned and aggregated across views while preserving\nvaluable monocular priors, enabling the Prediction module to generate Gaussian\nprimitives with accurate geometry and appearance. Through extensive experiments\non diverse real-world datasets, we convincingly demonstrate that MonoSplat\nachieves superior reconstruction quality and generalization capability compared\nto existing methods while maintaining computational efficiency with minimal\ntrainable parameters. Codes are available at\nhttps://github.com/CUHK-AIM-Group/MonoSplat.",
    "pdf_url": "http://arxiv.org/pdf/2505.15185v1",
    "published": "2025-05-21T07:03:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15184v1",
    "title": "AuxDet: Auxiliary Metadata Matters for Omni-Domain Infrared Small Target Detection",
    "authors": [
      "Yangting Shi",
      "Renjie He",
      "Le Hui",
      "Xiang Li",
      "Jian Yang",
      "Ming-Ming Cheng",
      "Yimian Dai"
    ],
    "abstract": "Omni-domain infrared small target detection (IRSTD) poses formidable\nchallenges, as a single model must seamlessly adapt to diverse imaging systems,\nvarying resolutions, and multiple spectral bands simultaneously. Current\napproaches predominantly rely on visual-only modeling paradigms that not only\nstruggle with complex background interference and inherently scarce target\nfeatures, but also exhibit limited generalization capabilities across complex\nomni-scene environments where significant domain shifts and appearance\nvariations occur. In this work, we reveal a critical oversight in existing\nparadigms: the neglect of readily available auxiliary metadata describing\nimaging parameters and acquisition conditions, such as spectral bands, sensor\nplatforms, resolution, and observation perspectives. To address this\nlimitation, we propose the Auxiliary Metadata Driven Infrared Small Target\nDetector (AuxDet), a novel multi-modal framework that fundamentally reimagines\nthe IRSTD paradigm by incorporating textual metadata for scene-aware\noptimization. Through a high-dimensional fusion module based on multi-layer\nperceptrons (MLPs), AuxDet dynamically integrates metadata semantics with\nvisual features, guiding adaptive representation learning for each individual\nsample. Additionally, we design a lightweight prior-initialized enhancement\nmodule using 1D convolutional blocks to further refine fused features and\nrecover fine-grained target cues. Extensive experiments on the challenging\nWideIRSTD-Full benchmark demonstrate that AuxDet consistently outperforms\nstate-of-the-art methods, validating the critical role of auxiliary information\nin improving robustness and accuracy in omni-domain IRSTD tasks. Code is\navailable at https://github.com/GrokCV/AuxDet.",
    "pdf_url": "http://arxiv.org/pdf/2505.15184v1",
    "published": "2025-05-21T07:02:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15183v1",
    "title": "Enabling the Reuse of Personal Data in Research: A Classification Model for Legal Compliance",
    "authors": [
      "Eduard Mata i Noguera",
      "Ruben Ortiz Uroz",
      "Ignasi Labastida i Juan"
    ],
    "abstract": "Inspired by a proposal made almost ten years ago, this paper presents a model\nfor classifying per-sonal data for research to inform researchers on how to\nmanage them. The classification is based on the principles of the European\nGeneral Data Protection Regulation and its implementation under the Spanish\nLaw. The paper also describes in which conditions personal data may be stored\nand can be accessed ensuring compliance with data protection regulations and\nsafeguarding privacy. The work has been developed collaboratively by the\nLibrary and the Data Protection Office. The outcomes of this collaboration are\na decision tree for researchers and a list of requirements for research data\nre-positories to store and grant access to personal data securely. This\nproposal is aligned with the FAIR principles and the commitment for responsible\nopen science practices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15183v1",
    "published": "2025-05-21T06:59:26+00:00",
    "categories": [
      "cs.CY",
      "cs.DB"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15182v1",
    "title": "ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection",
    "authors": [
      "Jeonghye Kim",
      "Sojeong Rhee",
      "Minbeom Kim",
      "Dohyung Kim",
      "Sangmook Lee",
      "Youngchul Sung",
      "Kyomin Jung"
    ],
    "abstract": "Recent advances in LLM agents have largely built on reasoning backbones like\nReAct, which interleave thought and action in complex environments. However,\nReAct often produces ungrounded or incoherent reasoning steps, leading to\nmisalignment between the agent's actual state and goal. Our analysis finds that\nthis stems from ReAct's inability to maintain consistent internal beliefs and\ngoal alignment, causing compounding errors and hallucinations. To address this,\nwe introduce ReflAct, a novel backbone that shifts reasoning from merely\nplanning next actions to continuously reflecting on the agent's state relative\nto its goal. By explicitly grounding decisions in states and enforcing ongoing\ngoal alignment, ReflAct dramatically improves strategic reliability. This\ndesign delivers substantial empirical gains: ReflAct surpasses ReAct by 27.7%\non average, achieving a 93.3% success rate in ALFWorld. Notably, ReflAct even\noutperforms ReAct with added enhancement modules (e.g., Reflexion, WKM),\nshowing that strengthening the core reasoning backbone is key to reliable agent\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15182v1",
    "published": "2025-05-21T06:57:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15181v1",
    "title": "Manipulating the hydrogen-induced insulator-metal transition through artificial microstructure engineering",
    "authors": [
      "Xuanchi Zhou",
      "Xiaohui Yao",
      "Wentian Lu",
      "Jinjian Guo",
      "Jiahui Ji",
      "Lili Lang",
      "Guowei Zhou",
      "Chunwei Yao",
      "Xiaomei Qiao",
      "Huihui Ji",
      "Zhe Yuan",
      "Xiaohong Xu"
    ],
    "abstract": "Hydrogen-associated filling-controlled Mottronics within electron-correlated\nsystem provides a groundbreaking paradigm to explore exotic physical\nfunctionality and phenomena. Dynamically controlling hydrogen-induced phase\ntransitions through external fields offers a promising route for designing\nprotonic devices in multidisciplinary fields, but faces high-speed bottlenecks\nowing to slow bulk diffusion of hydrogens. Here, we present a promising pathway\nto kinetically expedite hydrogen-related Mott transition in correlated VO2\nsystem by taking advantage of artificial microstructure design. Typically,\ninclined domain boundary configuration and cR-faceted preferential orientation\nsimultaneously realized in VO2/Al2O3 (102) heterostructure significantly lower\nthe diffusion barrier via creating an unobstructed conduit for hydrogen\ndiffusion. As a result, the achievable switching speed through hydrogenation\noutperforms that of counterpart grown on widely-reported c-plane Al2O3\nsubstrate by 2-3 times, with resistive switching concurrently improved by an\norder of magnitude. Of particular interest, an anomalous uphill hydrogen\ndiffusion observed for VO2 with a highway for hydrogen diffusion fundamentally\ndeviates from basic Fick's law, unveiling a deterministic role of hydrogen\nspatial distribution in tailoring electronic state evolution. The present work\nnot only provides a versatile strategy for manipulating ionic evolution,\nendowing with great potential in designing high-speed protonic devices, but\nalso deepens the understanding of hydrogen-induced Mott transitions in\nelectron-correlated system.",
    "pdf_url": "http://arxiv.org/pdf/2505.15181v1",
    "published": "2025-05-21T06:55:14+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.15180v2",
    "title": "NeuBM: Mitigating Model Bias in Graph Neural Networks through Neutral Input Calibration",
    "authors": [
      "Jiawei Gu",
      "Ziyue Qiao",
      "Xiao Luo"
    ],
    "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance across various\ndomains, yet they often struggle with model bias, particularly in the presence\nof class imbalance. This bias can lead to suboptimal performance and unfair\npredictions, especially for underrepresented classes. We introduce NeuBM\n(Neutral Bias Mitigation), a novel approach to mitigate model bias in GNNs\nthrough neutral input calibration. NeuBM leverages a dynamically updated\nneutral graph to estimate and correct the inherent biases of the model. By\nsubtracting the logits obtained from the neutral graph from those of the input\ngraph, NeuBM effectively recalibrates the model's predictions, reducing bias\nacross different classes. Our method integrates seamlessly into existing GNN\narchitectures and training procedures, requiring minimal computational\noverhead. Extensive experiments on multiple benchmark datasets demonstrate that\nNeuBM significantly improves the balanced accuracy and recall of minority\nclasses, while maintaining strong overall performance. The effectiveness of\nNeuBM is particularly pronounced in scenarios with severe class imbalance and\nlimited labeled data, where traditional methods often struggle. We provide\ntheoretical insights into how NeuBM achieves bias mitigation, relating it to\nthe concept of representation balancing. Our analysis reveals that NeuBM not\nonly adjusts the final predictions but also influences the learning of balanced\nfeature representations throughout the network.",
    "pdf_url": "http://arxiv.org/pdf/2505.15180v2",
    "published": "2025-05-21T06:52:10+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15179v1",
    "title": "RAG or Fine-tuning? A Comparative Study on LCMs-based Code Completion in Industry",
    "authors": [
      "Chaozheng Wang",
      "Zezhou Yang",
      "Shuzheng Gao",
      "Cuiyun Gao",
      "Ting Peng",
      "Hailiang Huang",
      "Yuetang Deng",
      "Michael Lyu"
    ],
    "abstract": "Code completion, a crucial practice in industrial settings, helps developers\nimprove programming efficiency by automatically suggesting code snippets during\ndevelopment. With the emergence of Large Code Models (LCMs), this field has\nwitnessed significant advancements. Due to the natural differences between\nopen-source and industrial codebases, such as coding patterns and unique\ninternal dependencies, it is a common practice for developers to conduct domain\nadaptation when adopting LCMs in industry. There exist multiple adaptation\napproaches, among which retrieval-augmented generation (RAG) and fine-tuning\nare the two most popular paradigms. However, no prior research has explored the\ntrade-off of the two approaches in industrial scenarios.\n  To mitigate the gap, we comprehensively compare the two paradigms including\nRetrieval-Augmented Generation (RAG) and Fine-tuning (FT), for industrial code\ncompletion in this paper. In collaboration with Tencent's WXG department, we\ncollect over 160,000 internal C++ files as our codebase. We then compare the\ntwo types of adaptation approaches from three dimensions that are concerned by\nindustrial practitioners, including effectiveness, efficiency, and parameter\nsensitivity, using six LCMs. Our findings reveal that RAG, when implemented\nwith appropriate embedding models that map code snippets into dense vector\nrepresentations, can achieve higher accuracy than fine-tuning alone.\nSpecifically, BM25 presents superior retrieval effectiveness and efficiency\namong studied RAG methods. Moreover, RAG and fine-tuning are orthogonal and\ntheir combination leads to further improvement. We also observe that RAG\ndemonstrates better scalability than FT, showing more sustained performance\ngains with larger scales of codebase.",
    "pdf_url": "http://arxiv.org/pdf/2505.15179v1",
    "published": "2025-05-21T06:51:25+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15178v1",
    "title": "A Unified Gradient-based Framework for Task-agnostic Continual Learning-Unlearning",
    "authors": [
      "Zhehao Huang",
      "Xinwen Cheng",
      "Jie Zhang",
      "Jinghao Zheng",
      "Haoran Wang",
      "Zhengbao He",
      "Tao Li",
      "Xiaolin Huang"
    ],
    "abstract": "Recent advancements in deep models have highlighted the need for intelligent\nsystems that combine continual learning (CL) for knowledge acquisition with\nmachine unlearning (MU) for data removal, forming the Continual\nLearning-Unlearning (CLU) paradigm. While existing work treats CL and MU as\nseparate processes, we reveal their intrinsic connection through a unified\noptimization framework based on Kullback-Leibler divergence minimization. This\nframework decomposes gradient updates for approximate CLU into four components:\nlearning new knowledge, unlearning targeted data, preserving existing\nknowledge, and modulation via weight saliency. A critical challenge lies in\nbalancing knowledge update and retention during sequential learning-unlearning\ncycles. To resolve this stability-plasticity dilemma, we introduce a\nremain-preserved manifold constraint to induce a remaining Hessian compensation\nfor CLU iterations. A fast-slow weight adaptation mechanism is designed to\nefficiently approximate the second-order optimization direction, combined with\nadaptive weighting coefficients and a balanced weight saliency mask, proposing\na unified implementation framework for gradient-based CLU. Furthermore, we\npioneer task-agnostic CLU scenarios that support fine-grained unlearning at the\ncross-task category and random sample levels beyond the traditional task-aware\nsetups. Experiments demonstrate that the proposed UG-CLU framework effectively\ncoordinates incremental learning, precise unlearning, and knowledge stability\nacross multiple datasets and model architectures, providing a theoretical\nfoundation and methodological support for dynamic, compliant intelligent\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15178v1",
    "published": "2025-05-21T06:49:05+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15177v2",
    "title": "SpectralGap: Graph-Level Out-of-Distribution Detection via Laplacian Eigenvalue Gaps",
    "authors": [
      "Jiawei Gu",
      "Ziyue Qiao",
      "Zechao Li"
    ],
    "abstract": "The task of graph-level out-of-distribution (OOD) detection is crucial for\ndeploying graph neural networks in real-world settings. In this paper, we\nobserve a significant difference in the relationship between the largest and\nsecond-largest eigenvalues of the Laplacian matrix for in-distribution (ID) and\nOOD graph samples: \\textit{OOD samples often exhibit anomalous spectral gaps\n(the difference between the largest and second-largest eigenvalues)}. This\nobservation motivates us to propose SpecGap, an effective post-hoc approach for\nOOD detection on graphs. SpecGap adjusts features by subtracting the component\nassociated with the second-largest eigenvalue, scaled by the spectral gap, from\nthe high-level features (i.e., $\\mathbf{X}-\\left(\\lambda_n-\\lambda_{n-1}\\right)\n\\mathbf{u}_{n-1} \\mathbf{v}_{n-1}^T$). SpecGap achieves state-of-the-art\nperformance across multiple benchmark datasets. We present extensive ablation\nstudies and comprehensive theoretical analyses to support our empirical\nresults. As a parameter-free post-hoc method, SpecGap can be easily integrated\ninto existing graph neural network models without requiring any additional\ntraining or model modification.",
    "pdf_url": "http://arxiv.org/pdf/2505.15177v2",
    "published": "2025-05-21T06:47:44+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15176v3",
    "title": "Exploring Generalized Gait Recognition: Reducing Redundancy and Noise within Indoor and Outdoor Datasets",
    "authors": [
      "Qian Zhou",
      "Xianda Guo",
      "Jilong Wang",
      "Chuanfu Shen",
      "Zhongyuan Wang",
      "Hua Zou",
      "Qin Zou",
      "Chao Liang",
      "Long Chen",
      "Gang Wu"
    ],
    "abstract": "Generalized gait recognition, which aims to achieve robust performance across\ndiverse domains, remains a challenging problem due to severe domain shifts in\nviewpoints, appearances, and environments. While mixed-dataset training is\nwidely used to enhance generalization, it introduces new obstacles including\ninter-dataset optimization conflicts and redundant or noisy samples, both of\nwhich hinder effective representation learning. To address these challenges, we\npropose a unified framework that systematically improves cross-domain gait\nrecognition. First, we design a disentangled triplet loss that isolates\nsupervision signals across datasets, mitigating gradient conflicts during\noptimization. Second, we introduce a targeted dataset distillation strategy\nthat filters out the least informative 20\\% of training samples based on\nfeature redundancy and prediction uncertainty, enhancing data efficiency.\nExtensive experiments on CASIA-B, OU-MVLP, Gait3D, and GREW demonstrate that\nour method significantly improves cross-dataset recognition for both GaitBase\nand DeepGaitV2 backbones, without sacrificing source-domain accuracy. Code will\nbe released at https://github.com/li1er3/Generalized_Gait.",
    "pdf_url": "http://arxiv.org/pdf/2505.15176v3",
    "published": "2025-05-21T06:46:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15175v2",
    "title": "A Linear Approach to Data Poisoning",
    "authors": [
      "Diego Granziol",
      "Donald Flynn"
    ],
    "abstract": "We investigate the theoretical foundations of data poisoning attacks in\nmachine learning models. Our analysis reveals that the Hessian with respect to\nthe input serves as a diagnostic tool for detecting poisoning, exhibiting\nspectral signatures that characterize compromised datasets. We use random\nmatrix theory (RMT) to develop a theory for the impact of poisoning proportion\nand regularisation on attack efficacy in linear regression. Through QR stepwise\nregression, we study the spectral signatures of the Hessian in multi-output\nregression. We perform experiments on deep networks to show experimentally that\nthis theory extends to modern convolutional and transformer networks under the\ncross-entropy loss. Based on these insights we develop preliminary algorithms\nto determine if a network has been poisoned and remedies which do not require\nfurther training.",
    "pdf_url": "http://arxiv.org/pdf/2505.15175v2",
    "published": "2025-05-21T06:45:06+00:00",
    "categories": [
      "stat.ML",
      "cs.CR",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15174v2",
    "title": "Enhancing Certified Robustness via Block Reflector Orthogonal Layers and Logit Annealing Loss",
    "authors": [
      "Bo-Han Lai",
      "Pin-Han Huang",
      "Bo-Han Kung",
      "Shang-Tse Chen"
    ],
    "abstract": "Lipschitz neural networks are well-known for providing certified robustness\nin deep learning. In this paper, we present a novel, efficient Block Reflector\nOrthogonal (BRO) layer that enhances the capability of orthogonal layers on\nconstructing more expressive Lipschitz neural architectures. In addition, by\ntheoretically analyzing the nature of Lipschitz neural networks, we introduce a\nnew loss function that employs an annealing mechanism to increase margin for\nmost data points. This enables Lipschitz models to provide better certified\nrobustness. By employing our BRO layer and loss function, we design BRONet - a\nsimple yet effective Lipschitz neural network that achieves state-of-the-art\ncertified robustness. Extensive experiments and empirical analysis on\nCIFAR-10/100, Tiny-ImageNet, and ImageNet validate that our method outperforms\nexisting baselines. The implementation is available at\nhttps://github.com/ntuaislab/BRONet.",
    "pdf_url": "http://arxiv.org/pdf/2505.15174v2",
    "published": "2025-05-21T06:44:51+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15173v2",
    "title": "AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection",
    "authors": [
      "Zhipei Xu",
      "Xuanyu Zhang",
      "Xing Zhou",
      "Jian Zhang"
    ],
    "abstract": "The rapid advancement of Artificial Intelligence Generated Content (AIGC)\ntechnologies, particularly in video generation, has led to unprecedented\ncreative capabilities but also increased threats to information integrity,\nidentity security, and public trust. Existing detection methods, while\neffective in general scenarios, lack robust solutions for human-centric videos,\nwhich pose greater risks due to their realism and potential for legal and\nethical misuse. Moreover, current detection approaches often suffer from poor\ngeneralization, limited scalability, and reliance on labor-intensive supervised\nfine-tuning. To address these challenges, we propose AvatarShield, the first\ninterpretable MLLM-based framework for detecting human-centric fake videos,\nenhanced via Group Relative Policy Optimization (GRPO). Through our carefully\ndesigned accuracy detection reward and temporal compensation reward, it\neffectively avoids the use of high-cost text annotation data, enabling precise\ntemporal modeling and forgery detection. Meanwhile, we design a dual-encoder\narchitecture, combining high-level semantic reasoning and low-level artifact\namplification to guide MLLMs in effective forgery detection. We further collect\nFakeHumanVid, a large-scale human-centric video benchmark that includes\nsynthesis methods guided by pose, audio, and text inputs, enabling rigorous\nevaluation of detection methods in real-world scenes. Extensive experiments\nshow that AvatarShield significantly outperforms existing approaches in both\nin-domain and cross-domain detection, setting a new standard for human-centric\nvideo forensics.",
    "pdf_url": "http://arxiv.org/pdf/2505.15173v2",
    "published": "2025-05-21T06:43:34+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15172v1",
    "title": "Harnessing Caption Detailness for Data-Efficient Text-to-Image Generation",
    "authors": [
      "Xinran Wang",
      "Muxi Diao",
      "Yuanzhi Liu",
      "Chunyu Wang",
      "Kongming Liang",
      "Zhanyu Ma",
      "Jun Guo"
    ],
    "abstract": "Training text-to-image (T2I) models with detailed captions can significantly\nimprove their generation quality. Existing methods often rely on simplistic\nmetrics like caption length to represent the detailness of the caption in the\nT2I training set. In this paper, we propose a new metric to estimate caption\ndetailness based on two aspects: image coverage rate (ICR), which evaluates\nwhether the caption covers all regions/objects in the image, and average object\ndetailness (AOD), which quantifies the detailness of each object's description.\nThrough experiments on the COCO dataset using ShareGPT4V captions, we\ndemonstrate that T2I models trained on high-ICR and -AOD captions achieve\nsuperior performance on DPG and other benchmarks. Notably, our metric enables\nmore effective data selection-training on only 20% of full data surpasses both\nfull-dataset training and length-based selection method, improving alignment\nand reconstruction ability. These findings highlight the critical role of\ndetail-aware metrics over length-based heuristics in caption selection for T2I\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15172v1",
    "published": "2025-05-21T06:42:17+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15171v1",
    "title": "Enhancing Cloud Task Scheduling Using a Hybrid Particle Swarm and Grey Wolf Optimization Approach",
    "authors": [
      "Raveena Prasad",
      "Aarush Roy",
      "Suchi Kumari"
    ],
    "abstract": "Assigning tasks efficiently in cloud computing is a challenging problem and\nis considered an NP-hard problem. Many researchers have used metaheuristic\nalgorithms to solve it, but these often struggle to handle dynamic workloads\nand explore all possible options effectively. Therefore, this paper presents a\nnew hybrid method that combines two popular algorithms, Grey Wolf Optimizer\n(GWO) and Particle Swarm Optimization (PSO). GWO offers strong global search\ncapabilities (exploration), while PSO enhances local refinement (exploitation).\nThe hybrid approach, called HybridPSOGWO, is compared with other existing\nmethods like MPSOSA, RL-GWO, CCGP, and HybridPSOMinMin, using key performance\nindicators such as makespan, throughput, and load balancing. We tested our\napproach using both a simulation tool (CloudSim Plus) and real-world data. The\nresults show that HybridPSOGWO outperforms other methods, with up to 15\\%\nimprovement in makespan and 10\\% better throughput, while also distributing\ntasks more evenly across virtual machines. Our implementation achieves\nconsistent convergence within a few iterations, highlighting its potential for\nefficient and adaptive cloud scheduling.",
    "pdf_url": "http://arxiv.org/pdf/2505.15171v1",
    "published": "2025-05-21T06:41:45+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15170v1",
    "title": "Bridging Two Dimensions: Luminescent Sensors at the Intersection of Temperature and Pressure",
    "authors": [
      "Lukasz Marciniak",
      "Maja Szymczak",
      "Przemyslaw Wozny",
      "Marcin Runowski"
    ],
    "abstract": "Luminescence thermometry and manometry are exponentially growing areas\ndealing with the optical detection of temperature and pressure, respectively,\nbeing appealing alternatives for conventional thermometers and manometers. The\nmain benefit of luminescent thermometers and manometers is a possibility of\nremote temperature and/or pressure monitoring, in contrast to conventional\ngauges. Moreover, the use of luminescent nanoparticles as temperature/pressure\nsensors allow detection in micron- and nano-sized areas, previously\ninaccessible for conventional gauges. Therefore, the combination of both\nfunctionalities in a single material is highly appealing, as has been shown in\na growing number of reports in the last years. Moreover, the bifunctional\npressure and temperature sensors, operating with multiple independent\nspectroscopic parameters, allow simultaneous and distinct pressure and\ntemperature readouts. However, the development of such truly bifunctional and\nreliable sensors is very challenging and rarely reported. This review\nsummarizes the current status in the field, focusing on the sensing strategy\nand the selection of optically active sensor materials appropriate for a given\napplication, including their sensitivity, spectral range of interest and\npressure/temperature (in)dependence.",
    "pdf_url": "http://arxiv.org/pdf/2505.15170v1",
    "published": "2025-05-21T06:40:45+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15169v1",
    "title": "Stability Analysis of the Possible Consistent Model of Parity Violations in the Symmetric Teleparallel Gravity: Generalized Background Solutions",
    "authors": [
      "Yeheng Tong"
    ],
    "abstract": "In this paper, we consider a symmetric teleparallel gravity model that\nextends the general relativity equivalent model by several parity violating\ninteractions between the gravitational field and a scalar field. We derive\nthree different families of background solutions in flat FRW universe, with\nthree classes of different connections. Through investigations on the linear\ncosmological perturbations, we show that one of the vector modes of this model\nwill evolve into a ghost field at high energy, and the ghost instability can be\ncancelled only under specific combinations of the coefficients. On two of three\nfamilies of backgrounds, such combination remains the same as the one we have\ninvestigated in our previous work; while on the other family of background, one\nadditional condition should be taken into consider.",
    "pdf_url": "http://arxiv.org/pdf/2505.15169v1",
    "published": "2025-05-21T06:37:29+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15168v1",
    "title": "Equilibrium models to analyse the impact of different coordination schemes between TSO and DSOs on market power in sequentially-cleared energy and ancillary services markets under load and renewable generation uncertainty",
    "authors": [
      "Giovanni Micheli",
      "Maria Teresa Vespucci",
      "Gianluigi Migliavacca",
      "Dario Siface"
    ],
    "abstract": "The current massive installation of distributed resources in electricity\ndistribution systems is transforming these systems into active dispatching\nsubjects. At the same time, the need to compensate for the intermittent\ngeneration of an increasing amount of renewable sources creates the need to\nacquire more ancillary services. Flexible resources in the distribution system\ncould provide these services not only within the perimeter of the distribution\nnetwork to which they are connected but also for the benefit of the\ntransmission system. However, this requires Transmission System Operators\n(TSOs) and Distribution System Operators (DSOs) to coordinate their dispatching\nactions effectively. One critical aspect of this coordination is establishing a\nmarket architecture that limits market power. This paper presents an innovative\ngame-theoretic approach to compare different TSO-DSO coordination models for\nacquiring ancillary services from distribution resources. Several schemes are\nconsidered: some with coordinated market management by TSOs and DSOs, others\nwith sequential or independent local markets. For each scheme, the dispatching\nproblem is formulated as a two-stage stochastic sequential game, where the\nfirst stage is the day-ahead market and the second stage is the balancing\nmarket. Nash equilibrium solutions are obtained by iteratively solving the\nprofit maximization problem of each market player. Numerical tests on a CIGRE\nbenchmark network show that coordination schemes enabling distribution\nresources to provide ancillary services to the transmission system can\nsignificantly increase system costs when congestion occurs in the transmission\nnetwork.",
    "pdf_url": "http://arxiv.org/pdf/2505.15168v1",
    "published": "2025-05-21T06:37:05+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15167v1",
    "title": "Multi-horizon optimization for domestic renewable energy system design under uncertainty",
    "authors": [
      "Giovanni Micheli",
      "Laureano F. Escudero",
      "Francesca Maggioni",
      "Guzin Bayraksan"
    ],
    "abstract": "In this paper we address the challenge of designing optimal domestic\nrenewable energy systems under multiple sources of uncertainty appearing at\ndifferent time scales. Long-term uncertainties, such as investment and\nmaintenance costs of different technologies, are combined with short-term\nuncertainties, including solar radiation, electricity prices, and uncontrolled\nload variations. We formulate the problem as a multistage multi-horizon\nstochastic Mixed Integer Linear Programming (MILP) model, minimizing the total\ncost of a domestic building complex's energy system. The model integrates\nlong-term investment decisions, such as the capacity of photovoltaic panels and\nbattery energy storage systems, with short-term operational decisions,\nincluding energy dispatch, grid exchanges, and load supply. To ensure robust\noperation under extreme scenarios, first- and second-order stochastic dominance\nrisk-averse measures are considered preserving the time consistency of the\nsolution. Given the computational complexity of solving the stochastic MILP for\nlarge instances, a rolling horizon-based matheuristic algorithm is developed.\nAdditionally, various lower-bound strategies are explored, including\nwait-and-see schemes, expected value approximations, multistage grouping and\nclustering schemes. Extensive computational experiments validate the\neffectiveness of the proposed methods on a case study based on a building\ncomplex in South Germany, tackling models with over 20 million constraints, 5\nmillion binary variables, and 6 million continuous variables.",
    "pdf_url": "http://arxiv.org/pdf/2505.15167v1",
    "published": "2025-05-21T06:36:21+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15166v1",
    "title": "Single-Shot Integrated Speckle Spectrometer with Ultrahigh Bandwidth-to-Resolution",
    "authors": [
      "Wenzhang Tian",
      "Hao Chen",
      "Mingyuan Zhang",
      "Zengqi Chen",
      "Yeyu Tong"
    ],
    "abstract": "Miniaturized spectrometers employing chip solutions are essential for a wide\nrange of applications, such as wearable health monitoring, biochemical sensing,\nand portable optical coherence tomography. However, the development of\nintegrated spectrometers is hampered by the inherent trade-off between\nbandwidth-to-resolution, footprint, sampling channels, and operation speed.\nHere, we demonstrate that an ultrahigh bandwidth-to-resolution reconstructive\nspectrometer can be easily implemented through a single image capture of the\nspeckle pattern diffracted from a passive silicon photonic chip. By leveraging\nthe high pixel count of an image sensor, we can instantly acquire a significant\nnumber of distinct spatial sampling channels. Those sampling channels are\nspatially decorrelated by using our passive optical network on chip including\ncascaded unbalanced Mach-Zehnder interferometers, random diffraction by an\nantenna array, and mutual interference in free space before being captured.\nHence, each speckle pattern contains wavelength-specific information across its\nspatial distribution to enhance the effectiveness of the global sampling\nstrategy. Experimentally, we achieve a spectral resolution of 10 pm and an\noperational bandwidth of 200 nm, with sampling channels up to 2730. Multiple\nunknown narrowband and broadband spectra can also be precisely obtained.",
    "pdf_url": "http://arxiv.org/pdf/2505.15166v1",
    "published": "2025-05-21T06:35:03+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.15165v1",
    "title": "How to exploit driving and dissipation to stabilize and manipulate quantum many-body states",
    "authors": [
      "Iacopo Carusotto"
    ],
    "abstract": "We review the basic concepts of quantum fluids of light and the different\ntechniques that have been developed to exploit driving and dissipation to\nstabilize and manipulate interesting many-body states. In the weakly\ninteracting regime, this approach has allowed to study, among other, superfluid\nlight, non-equilibrium Bose-Einstein condensation, photonic analogs of Hall\neffects, and is opening the way towards the realization of a new family of\nanalog models of gravity. In the strongly interacting regime, the recent\nobservations of Mott insulators and baby Laughlin fluids of light open\npromising avenues towards the study of novel strongly correlated many-body\nstates.",
    "pdf_url": "http://arxiv.org/pdf/2505.15165v1",
    "published": "2025-05-21T06:34:41+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.15164v1",
    "title": "A Stochastic Programming Model for Anticipative Planning of Integrated Electricity and Gas Systems with Bidirectional Energy Flows under Fuel and CO2 Price Uncertainty",
    "authors": [
      "Giovanni Micheli",
      "Maria Teresa Vespucci",
      "Alessia Cortazzi",
      "Cinzia Puglisi"
    ],
    "abstract": "A two-stage multi-period mixed-integer linear stochastic programming model is\nproposed to assist qualified operators in long-term generation and transmission\nexpansion planning of electricity and gas systems to meet policy objectives.\nThe first-stage decisions concern investments in new plants, new connections in\nthe electricity and gas sectors, and the decommissioning of existing thermal\npower plants; the second-stage variables represent operational decisions, with\nuncertainty about future fuel and CO2 prices represented by scenarios. The main\nfeatures of the model are: (i) the bidirectional conversion between electricity\nand gas enabled by Power-to-Gas and thermal power plants, (ii) a detailed\nrepresentation of short-term operation, crucial for addressing challenges\nassociated with integrating large shares of renewables in the energy mix, and\n(iii) an integrated planning framework to evaluate the operation of flexibility\nresources, their ability to manage non-programmable generation, and their\neconomic viability. Given the computational complexity of the proposed model,\nin this paper we also implement a solution algorithm based on Benders\ndecomposition to compute near-optimal solutions. A case study on the\ndecarbonisation of the Italian integrated energy system demonstrates the\neffectiveness of the model. The numerical results show: (i) the importance of\nincluding a detailed system representation for obtaining reliable results, and\n(ii) the need to consider price uncertainty to design adequate systems and\nreduce overall costs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15164v1",
    "published": "2025-05-21T06:33:50+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15163v1",
    "title": "A Categorical Decomposition of $\\mathbb C^{\\times}$-fibered $p$-biset Functors",
    "authors": [
      "Olcay Co≈ükun",
      "Ruslan Muslumov"
    ],
    "abstract": "We generalize Bouc's construction of orthogonal idempotents in the double\nBurnside algebra to the setting of the double $\\mathbb{C}^\\times$-fibered\nBurnside algebra. This yields a structural decomposition of the evaluations of\n$\\mathbb{C}^\\times$-fibered biset functors on finite groups. We then construct\na complete set of orthogonal idempotents in the category of\n$\\mathbb{C}^\\times$-fibered $p$-biset functors, leading to a categorical\ndecomposition of this category into subcategories indexed by isomorphism\nclasses of atoric $p$-groups. Furthermore, we introduce the notion of vertices\nfor indecomposable functors and establish that the Ext-groups between simple\nfunctors with distinct vertices vanish. As an application, we describe a set\ncontaining composition factors of the monomial Burnside functor, thereby\nproviding new insights into its structure. Additionally, we develop a technique\nfor analyzing fibered biset functors via their underlying biset structures.",
    "pdf_url": "http://arxiv.org/pdf/2505.15163v1",
    "published": "2025-05-21T06:33:43+00:00",
    "categories": [
      "math.RT",
      "math.KT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15162v1",
    "title": "AI Solutionism and Digital Self-Tracking with Wearables",
    "authors": [
      "Hannah R. Nolasco",
      "Andrew Vargo",
      "Koichi Kise"
    ],
    "abstract": "Self-tracking technologies and wearables automate the process of data\ncollection and insight generation with the support of artificial intelligence\nsystems, with many emerging studies exploring ways to evolve these features\nfurther through large-language models (LLMs). This is done with the intent to\nreduce capture burden and the cognitive stress of health-based decision making,\nbut studies neglect to consider how automation has stymied the agency and\nindependent reflection of users of self-tracking interventions. In this\nposition paper, we explore the consequences of automation in self-tracking by\nrelating it to our experiences with investigating the Oura Ring, a sleep\nwearable, and navigate potential remedies.",
    "pdf_url": "http://arxiv.org/pdf/2505.15162v1",
    "published": "2025-05-21T06:31:27+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15161v1",
    "title": "Exploring Event-by-Event $\\it{p}_{\\rm T}$ Fluctuations in pp Collisions at $\\sqrt{s} = 13$ TeV: An Insight from ALICE",
    "authors": [
      "Bushra Ali"
    ],
    "abstract": "Event-by-event fluctuations of the mean transverse momentum ($p_{\\rm T}$) of\nrelativistic charged particles are analyzed using the two-particle correlator\n$\\sqrt{C_m}/M(p_{\\rm T})_m$, which quantifies the correlations strength in\nunits of the mean $p_{\\rm T}$ in proton-proton collision at $\\sqrt{s} = 13$ TeV\nin ALICE both for minimum bias and and high-multiplicity triggered events. The\nnon-monotonic variations in $p_{\\rm T}$ correlations with changing energy could\nserve as a signature of QGP formation. A comprehensive investigation across\nsoft-, intermediate-, and hard-$p_{\\rm T}$ regions could provide crucial\ninsights into both equilibrium (e.g., thermal radial flow) and non-equilibrium\n(e.g., jet/minijet) contributions to $p_{\\rm T}$ fluctuations. The dependence\nof the correlator on particle multiplicity for different $p_{\\rm T}$ window\nwidths and positions is explored. The correlator values are found to decrease\nwith increasing charged particle density, following a power-law behavior\nsimilar to observations in both small and large systems at lower energies.\nAdditionally, the influence of $p_{\\rm T}$ range on the power-law coefficient\nis studied and results are compared with predictions from Monte Carlo models,\nsuch as PYTHIA (pQCD string model) and EPOS (core-corona model), to enhance\nunderstanding of the underlying mechanisms driving $p_{\\rm T}$ fluctuations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15161v1",
    "published": "2025-05-21T06:29:33+00:00",
    "categories": [
      "hep-ex",
      "nucl-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.15160v2",
    "title": "Lossless Token Merging Even Without Fine-Tuning in Vision Transformers",
    "authors": [
      "Jaeyeon Lee",
      "Dong-Wan Choi"
    ],
    "abstract": "Although Vision Transformers (ViTs) have become the standard architecture in\ncomputer vision, their massive sizes lead to significant computational\noverhead. Token compression techniques have attracted considerable attention to\naddress this issue, but they often suffer from severe information loss,\nrequiring extensive additional training to achieve practical performance. In\nthis paper, we propose Adaptive Token Merging (ATM), a novel method that\nensures lossless token merging, eliminating the need for fine-tuning while\nmaintaining competitive performance. ATM adaptively reduces tokens across\nlayers and batches by carefully adjusting layer-specific similarity thresholds,\nthereby preventing the undesirable merging of less similar tokens with respect\nto each layer. Furthermore, ATM introduces a novel token matching technique\nthat considers not only similarity but also merging sizes, particularly for the\nfinal layers, to minimize the information loss incurred from each merging\noperation. We empirically validate our method across a wide range of pretrained\nmodels, demonstrating that ATM not only outperforms all existing training-free\nmethods but also surpasses most training-intensive approaches, even without\nadditional training. Remarkably, training-free ATM achieves over a 30%\nreduction in FLOPs for the DeiT-T and DeiT-S models without any drop in their\noriginal accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.15160v2",
    "published": "2025-05-21T06:26:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15159v1",
    "title": "Rank jumps and Multisections of elliptic fibrations on K3 surfaces",
    "authors": [
      "Alice Garbagnati",
      "Cec√≠lia Salgado"
    ],
    "abstract": "We consider the countably many families $\\mathcal{L}_d$,\n$d\\in\\mathbb{N}_{\\geq 2}$, of K3 surfaces admitting an elliptic fibration with\npositive Mordell--Weil rank. We prove that the elliptic fibrations on the very\ngeneral member of these families have the potential Mordell--Weil rank jump\nproperty for $d\\neq 2,3$ and moreover the Mordell--Weil rank jump property for\n$d\\equiv 3\\mod 4$, $d\\neq 3$. We provide explicit examples and discuss some\nextensions to subfamilies. The result is based on the geometric interaction\nbetween the (potential) Mordell--Weil rank jump property and the presence of\nspecial multisections of the fibration.",
    "pdf_url": "http://arxiv.org/pdf/2505.15159v1",
    "published": "2025-05-21T06:24:34+00:00",
    "categories": [
      "math.AG",
      "14J26, 14J27, 14G05"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15158v1",
    "title": "ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving",
    "authors": [
      "Yunsheng Ma",
      "Burhaneddin Yaman",
      "Xin Ye",
      "Mahmut Yurt",
      "Jingru Luo",
      "Abhirup Mallik",
      "Ziran Wang",
      "Liu Ren"
    ],
    "abstract": "Recent advances have explored integrating large language models (LLMs) into\nend-to-end autonomous driving systems to enhance generalization and\ninterpretability. However, most existing approaches are limited to either\ndriving performance or vision-language reasoning, making it difficult to\nachieve both simultaneously. In this paper, we propose ALN-P3, a unified\nco-distillation framework that introduces cross-modal alignment between \"fast\"\nvision-based autonomous driving systems and \"slow\" language-driven reasoning\nmodules. ALN-P3 incorporates three novel alignment mechanisms: Perception\nAlignment (P1A), Prediction Alignment (P2A), and Planning Alignment (P3A),\nwhich explicitly align visual tokens with corresponding linguistic outputs\nacross the full perception, prediction, and planning stack. All alignment\nmodules are applied only during training and incur no additional costs during\ninference. Extensive experiments on four challenging benchmarks-nuScenes, Nu-X,\nTOD3Cap, and nuScenes QA-demonstrate that ALN-P3 significantly improves both\ndriving decisions and language reasoning, achieving state-of-the-art results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15158v1",
    "published": "2025-05-21T06:23:01+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15157v1",
    "title": "Cascaded Diffusion Models for Neural Motion Planning",
    "authors": [
      "Mohit Sharma",
      "Adam Fishman",
      "Vikash Kumar",
      "Chris Paxton",
      "Oliver Kroemer"
    ],
    "abstract": "Robots in the real world need to perceive and move to goals in complex\nenvironments without collisions. Avoiding collisions is especially difficult\nwhen relying on sensor perception and when goals are among clutter. Diffusion\npolicies and other generative models have shown strong performance in solving\nlocal planning problems, but often struggle at avoiding all of the subtle\nconstraint violations that characterize truly challenging global motion\nplanning problems. In this work, we propose an approach for learning global\nmotion planning using diffusion policies, allowing the robot to generate full\ntrajectories through complex scenes and reasoning about multiple obstacles\nalong the path. Our approach uses cascaded hierarchical models which unify\nglobal prediction and local refinement together with online plan repair to\nensure the trajectories are collision free. Our method outperforms (by ~5%) a\nwide variety of baselines on challenging tasks in multiple domains including\nnavigation and manipulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15157v1",
    "published": "2025-05-21T06:21:50+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15156v1",
    "title": "Privacy-Preserving Socialized Recommendation based on Multi-View Clustering in a Cloud Environment",
    "authors": [
      "Cheng Guo",
      "Jing Jia",
      "Peng Wang",
      "Jing Zhang"
    ],
    "abstract": "Recommendation as a service has improved the quality of our lives and plays a\nsignificant role in variant aspects. However, the preference of users may\nreveal some sensitive information, so that the protection of privacy is\nrequired. In this paper, we propose a privacy-preserving, socialized,\nrecommendation protocol that introduces information collected from online\nsocial networks to enhance the quality of the recommendation. The proposed\nscheme can calculate the similarity between users to determine their potential\nrelationships and interests, and it also can protect the users' privacy from\nleaking to an untrusted third party. The security analysis and experimental\nresults showed that our proposed scheme provides excellent performance and is\nfeasible for real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15156v1",
    "published": "2025-05-21T06:21:21+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15155v1",
    "title": "R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization",
    "authors": [
      "Yuante Li",
      "Xu Yang",
      "Xiao Yang",
      "Minrui Xu",
      "Xisen Wang",
      "Weiqing Liu",
      "Jiang Bian"
    ],
    "abstract": "Financial markets pose fundamental challenges for asset return prediction due\nto their high dimensionality, non-stationarity, and persistent volatility.\nDespite advances in large language models and multi-agent systems, current\nquantitative research pipelines suffer from limited automation, weak\ninterpretability, and fragmented coordination across key components such as\nfactor mining and model innovation. In this paper, we propose R&D-Agent for\nQuantitative Finance, in short RD-Agent(Q), the first data-centric multi-agent\nframework designed to automate the full-stack research and development of\nquantitative strategies via coordinated factor-model co-optimization.\nRD-Agent(Q) decomposes the quant process into two iterative stages: a Research\nstage that dynamically sets goal-aligned prompts, formulates hypotheses based\non domain priors, and maps them to concrete tasks, and a Development stage that\nemploys a code-generation agent, Co-STEER, to implement task-specific code,\nwhich is then executed in real-market backtests. The two stages are connected\nthrough a feedback stage that thoroughly evaluates experimental outcomes and\ninforms subsequent iterations, with a multi-armed bandit scheduler for adaptive\ndirection selection. Empirically, RD-Agent(Q) achieves up to 2X higher\nannualized returns than classical factor libraries using 70% fewer factors, and\noutperforms state-of-the-art deep time-series models on real markets. Its joint\nfactor-model optimization delivers a strong balance between predictive accuracy\nand strategy robustness. Our code is available at:\nhttps://github.com/microsoft/RD-Agent.",
    "pdf_url": "http://arxiv.org/pdf/2505.15155v1",
    "published": "2025-05-21T06:20:56+00:00",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-fin.CP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15154v1",
    "title": "Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive Routing for Efficient LLM/MLLM Reasoning",
    "authors": [
      "Jinghui Lu",
      "Haiyang Yu",
      "Siliang Xu",
      "Shiwei Ran",
      "Guozhi Tang",
      "Siqi Wang",
      "Bin Shan",
      "Teng Fu",
      "Hao Feng",
      "Jingqun Tang",
      "Han Wang",
      "Can Huang"
    ],
    "abstract": "Recent advancements in reasoning have significantly enhanced the capabilities\nof Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)\nacross diverse tasks. However, excessive reliance on chain-of-thought (CoT)\nreasoning can impair model performance and brings unnecessarily lengthened\noutputs, reducing efficiency. Our work reveals that prolonged reasoning does\nnot universally improve accuracy and even degrade performance on simpler tasks.\nTo address this, we propose Certainty-based Adaptive Reasoning (CAR), a novel\nframework that dynamically switches between short answers and long-form\nreasoning based on the model perplexity. CAR first generates a short answer and\nevaluates its perplexity, triggering reasoning only when the model exhibits low\nconfidence (i.e., high perplexity). Experiments across diverse multimodal\nVQA/KIE benchmarks and text reasoning datasets show that CAR outperforms both\nshort-answer and long-form reasoning approaches, striking an optimal balance\nbetween accuracy and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.15154v1",
    "published": "2025-05-21T06:20:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15153v1",
    "title": "Exploring the Delocalization of Dark States in a Multimode Optical Cavity",
    "authors": [
      "Kunyang Sun",
      "Matthew Du",
      "Joel Yuen-Zhou"
    ],
    "abstract": "The strong coupling between molecules and photonic modes in a Fabry-P\\'{e}rot\noptical cavity, which forms hybrid light-matter states called polaritons, has\nbeen demonstrated as a promising route to control the rates of chemical\nreactions. However, theoretical studies, which largely employ models with a\nsingle cavity mode, cannot explain the experimentally observed kinetic changes.\nWhile simplified multimode models with one spatial dimension can capture\nexperimental features involving the polariton states, it is unclear whether\nthey can also describe the dark states. Here, we study the delocalization of\ndark states for molecules in a multimode cavity, accounting for the\nthree-dimensional nature of experimental setups. Accounting for energetic and\norientational disorder, but fixing Rabi splitting and intermolecular distances\n(i.e., no positional disorder), we find that the delocalization of the dark\nstates scales linearly with the number of molecules in the plane parallel to\nthe cavity mirrors, in contrast to one-dimensional multimode models. Adding\nlayers of molecules along the axis normal to the mirrors increases the\ndelocalization much less. Similar to the one-dimensional models, the dark-state\ndelocalization is enhanced for smaller values of molecular energetic disorder,\nrelative to the light-matter coupling, and cavities with longer longitudinal\nlength. Our work indicates that for certain phenomena, understanding the dark\nstates under strong light-matter coupling might require a proper multimode\ndescription of the optical cavity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15153v1",
    "published": "2025-05-21T06:19:50+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15152v1",
    "title": "Sculpting Features from Noise: Reward-Guided Hierarchical Diffusion for Task-Optimal Feature Transformation",
    "authors": [
      "Nanxu Gong",
      "Zijun Li",
      "Sixun Dong",
      "Haoyue Bai",
      "Wangyang Ying",
      "Xinyuan Wang",
      "Yanjie Fu"
    ],
    "abstract": "Feature Transformation (FT) crafts new features from original ones via\nmathematical operations to enhance dataset expressiveness for downstream\nmodels. However, existing FT methods exhibit critical limitations: discrete\nsearch struggles with enormous combinatorial spaces, impeding practical use;\nand continuous search, being highly sensitive to initialization and step sizes,\noften becomes trapped in local optima, restricting global exploration. To\novercome these limitations, DIFFT redefines FT as a reward-guided generative\ntask. It first learns a compact and expressive latent space for feature sets\nusing a Variational Auto-Encoder (VAE). A Latent Diffusion Model (LDM) then\nnavigates this space to generate high-quality feature embeddings, its\ntrajectory guided by a performance evaluator towards task-specific optima. This\nsynthesis of global distribution learning (from LDM) and targeted optimization\n(reward guidance) produces potent embeddings, which a novel semi-autoregressive\ndecoder efficiently converts into structured, discrete features, preserving\nintra-feature dependencies while allowing parallel inter-feature generation.\nExtensive experiments on 14 benchmark datasets show DIFFT consistently\noutperforms state-of-the-art baselines in predictive accuracy and robustness,\nwith significantly lower training and inference times.",
    "pdf_url": "http://arxiv.org/pdf/2505.15152v1",
    "published": "2025-05-21T06:18:42+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15151v1",
    "title": "Time Tracker: Mixture-of-Experts-Enhanced Foundation Time Series Forecasting Model with Decoupled Training Pipelines",
    "authors": [
      "Xiaohou Shi",
      "Ke Li",
      "Aobo Liang",
      "Yan Sun"
    ],
    "abstract": "In the past few years, time series foundation models have achieved superior\npredicting accuracy. However, real-world time series often exhibit significant\ndiversity in their temporal patterns across different time spans and domains,\nmaking it challenging for a single model architecture to fit all complex\nscenarios. In addition, time series data may have multiple variables exhibiting\ncomplex correlations between each other. Recent mainstream works have focused\non modeling times series in a channel-independent manner in both pretraining\nand finetuning stages, overlooking the valuable inter-series dependencies. To\nthis end, we propose \\textbf{Time Tracker} for better predictions on\nmultivariate time series data. Firstly, we leverage sparse mixture of experts\n(MoE) within Transformers to handle the modeling of diverse time series\npatterns, thereby alleviating the learning difficulties of a single model while\nimproving its generalization. Besides, we propose Any-variate Attention,\nenabling a unified model structure to seamlessly handle both univariate and\nmultivariate time series, thereby supporting channel-independent modeling\nduring pretraining and channel-mixed modeling for finetuning. Furthermore, we\ndesign a graph learning module that constructs relations among sequences from\nfrequency-domain features, providing more precise guidance to capture\ninter-series dependencies in channel-mixed modeling. Based on these\nadvancements, Time Tracker achieves state-of-the-art performance in predicting\naccuracy, model generalization and adaptability.",
    "pdf_url": "http://arxiv.org/pdf/2505.15151v1",
    "published": "2025-05-21T06:18:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15150v1",
    "title": "$p$-Biset Functor of Monomial Burnside Rings",
    "authors": [
      "ƒ∞brahim Kaan Aslan",
      "Olcay Co≈ükun"
    ],
    "abstract": "We investigate the structure of the monomial Burnside biset functor over a\nfield of characteristic zero, with particular focus on its restriction kernels.\nFor each finite \\( p \\)-group \\( G \\), we give an explicit description of the\nrestriction kernel at \\( G \\), and determine the complete list of composition\nfactors of the functor. We prove that these composition factors have minimal\ngroups \\( H \\) isomorphic either to a cyclic \\( p \\)-group or to a direct\nproduct of such a group with a cyclic group of order \\( p \\). Furthermore, we\nidentify the simple \\( \\mathbb{C}[\\Aut(H)] \\)-modules that appear as\nevaluations of these composition factors at their minimal groups. Explicit\nclassifications of composition factors for biset functors are rare, and our\nresults provide one of the few complete examples of such classifications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15150v1",
    "published": "2025-05-21T06:11:55+00:00",
    "categories": [
      "math.RT",
      "math.GR",
      "math.KT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15862v2",
    "title": "Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems",
    "authors": [
      "Long Wang",
      "Jiongzhi Zheng",
      "Zhengda Xiong",
      "ChuMin Li",
      "Kun He"
    ],
    "abstract": "Algorithms designed for routing problems typically rely on high-quality\ncandidate edges to guide their search, aiming to reduce the search space and\nenhance the search efficiency. However, many existing algorithms, like the\nclassical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman\nProblem (TSP), often use predetermined candidate edges that remain static\nthroughout local searches. This rigidity could cause the algorithm to get\ntrapped in local optima, limiting its potential to find better solutions. To\naddress this issue, we propose expanding the candidate sets to include other\npromising edges, providing them an opportunity for selection. Specifically, we\nincorporate multi-armed bandit models to dynamically select the most suitable\ncandidate edges in each iteration, enabling LKH to make smarter choices and\nlead to improved solutions. Extensive experiments on multiple TSP benchmarks\nshow the excellent performance of our method. Moreover, we employ this\nbandit-based method to LKH-3, an extension of LKH tailored for solving various\nTSP variant problems, and our method also significantly enhances LKH-3's\nperformance across typical TSP variants.",
    "pdf_url": "http://arxiv.org/pdf/2505.15862v2",
    "published": "2025-05-21T06:11:00+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15149v1",
    "title": "Induced subgraphs of graphs with large deficiency",
    "authors": [
      "Jin Sun",
      "Xinmin Hou"
    ],
    "abstract": "The deficiency of a graph $G$, denoted by $\\kd(G)$, is the number of vertices\nnot saturated by a maximum matching. A bone $B_i$ is the tree obtained by\nattaching two pendent edges to each of the end vertices of a path $P_{i}$. The\nlocal independence number of $G$, denoted by $\\alpha_l(G)$, is defines as the\nmaximum integer $t$ such that $G$ contains an induced star $K_{1,t}$. Motivated\nby the seminal works of Scott and Seymour~(2016), Chudnovsky et al. (2017,\n2020) on finding special types of holes in graphs with large chromatic number\nand bounded clique number, we establish an analog result by finding special\ntypes of bones in graphs with large deficiency and bounded local independence\nnumber. Fujita et al. (2006) proved that $\\kd(G)\\le n-2$ if $G$ is a connected\ngraph with $\\alpha_l(G)<n$ and containing no bones. We further establish exact\nextremal deficiency bounds for connected graphs with bounded local independence\nnumber that exclude specific bone configurations. An algorithm that constructs\nlarge matchings and establishes an upper bound on the deficiency is also\nprovided.",
    "pdf_url": "http://arxiv.org/pdf/2505.15149v1",
    "published": "2025-05-21T06:07:36+00:00",
    "categories": [
      "math.CO",
      "05C75, 05C55"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15148v1",
    "title": "Dynamic Spectrum Sharing Based on the Rentable NFT Standard ERC4907",
    "authors": [
      "Litao Ye",
      "Bin Chen",
      "Shrivastava Shivanshu",
      "Chen Sun",
      "Shuo Wang",
      "Siming Feng",
      "Shengli Zhang"
    ],
    "abstract": "Centralized Dynamic Spectrum Sharing (DSS) faces challenges like data\nsecurity, high management costs, and limited scalability. To address these\nissues, a blockchain-based DSS scheme has been proposed in this paper. First,\nwe utilize the ERC4907 standard to mint Non-Fungible Spectrum Tokens (NFSTs)\nthat serve as unique identifiers for spectrum resources and facilitate renting.\nNext, we develop a smart contract for NFST auctions, ensuring secure spectrum\ntransactions through the auction process. Lastly, we create a Web3 spectrum\nauction platform where users can access idle spectrum data and participate in\nauctions for NFST leases corresponding to the available spectrum. Experimental\nresults demonstrate that our NFST, designed according to the ERC4907 standard,\neffectively meets users' secure and efficient DSS requirements, making it a\nfeasible solution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15148v1",
    "published": "2025-05-21T06:03:39+00:00",
    "categories": [
      "cs.NI",
      "cs.CR"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15147v1",
    "title": "From Pixels to Images: Deep Learning Advances in Remote Sensing Image Semantic Segmentation",
    "authors": [
      "Quanwei Liu",
      "Tao Huang",
      "Yanni Dong",
      "Jiaqi Yang",
      "Wei Xiang"
    ],
    "abstract": "Remote sensing images (RSIs) capture both natural and human-induced changes\non the Earth's surface, serving as essential data for environmental monitoring,\nurban planning, and resource management. Semantic segmentation (SS) of RSIs\nenables the fine-grained interpretation of surface features, making it a\ncritical task in remote sensing analysis. With the increasing diversity and\nvolume of RSIs collected by sensors on various platforms, traditional\nprocessing methods struggle to maintain efficiency and accuracy. In response,\ndeep learning (DL) has emerged as a transformative approach, enabling\nsubstantial advances in remote sensing image semantic segmentation (RSISS) by\nautomating feature extraction and improving segmentation accuracy across\ndiverse modalities. This paper revisits the evolution of DL-based RSISS by\ncategorizing existing approaches into four stages: the early pixel-based\nmethods, the prevailing patch-based and tile-based techniques, and the emerging\nimage-based strategies enabled by foundation models. We analyze these\ndevelopments from the perspective of feature extraction and learning\nstrategies, revealing the field's progression from pixel-level to tile-level\nand from unimodal to multimodal segmentation. Furthermore, we conduct a\ncomprehensive evaluation of nearly 40 advanced techniques on a unified dataset\nto quantitatively characterize their performance and applicability. This review\noffers a holistic view of DL-based SS for RS, highlighting key advancements,\ncomparative insights, and open challenges to guide future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15147v1",
    "published": "2025-05-21T06:02:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15146v2",
    "title": "lmgame-Bench: How Good are LLMs at Playing Games?",
    "authors": [
      "Lanxiang Hu",
      "Mingjia Huo",
      "Yuxuan Zhang",
      "Haoyang Yu",
      "Eric P. Xing",
      "Ion Stoica",
      "Tajana Rosing",
      "Haojian Jin",
      "Hao Zhang"
    ],
    "abstract": "Playing video games requires perception, memory, and planning, exactly the\nfaculties modern large language model (LLM) agents are expected to master. We\nstudy the major challenges in using popular video games to evaluate modern LLMs\nand find that directly dropping LLMs into games cannot make an effective\nevaluation, for three reasons -- brittle vision perception, prompt sensitivity,\nand potential data contamination. We introduce lmgame-Bench to turn games into\nreliable evaluations. lmgame-Bench features a suite of platformer, puzzle, and\nnarrative games delivered through a unified Gym-style API and paired with\nlightweight perception and memory scaffolds, and is designed to stabilize\nprompt variance and remove contamination. Across 13 leading models, we show\nlmgame-Bench is challenging while still separating models well. Correlation\nanalysis shows that every game probes a unique blend of capabilities often\ntested in isolation elsewhere. More interestingly, performing reinforcement\nlearning on a single game from lmgame-Bench transfers both to unseen games and\nto external planning tasks. Our evaluation code is available at\nhttps://github.com/lmgame-org/GamingAgent/lmgame-bench.",
    "pdf_url": "http://arxiv.org/pdf/2505.15146v2",
    "published": "2025-05-21T06:02:55+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15145v1",
    "title": "CineTechBench: A Benchmark for Cinematographic Technique Understanding and Generation",
    "authors": [
      "Xinran Wang",
      "Songyu Xu",
      "Xiangxuan Shan",
      "Yuxuan Zhang",
      "Muxi Diao",
      "Xueyan Duan",
      "Yanhua Huang",
      "Kongming Liang",
      "Zhanyu Ma"
    ],
    "abstract": "Cinematography is a cornerstone of film production and appreciation, shaping\nmood, emotion, and narrative through visual elements such as camera movement,\nshot composition, and lighting. Despite recent progress in multimodal large\nlanguage models (MLLMs) and video generation models, the capacity of current\nmodels to grasp and reproduce cinematographic techniques remains largely\nuncharted, hindered by the scarcity of expert-annotated data. To bridge this\ngap, we present CineTechBench, a pioneering benchmark founded on precise,\nmanual annotation by seasoned cinematography experts across key cinematography\ndimensions. Our benchmark covers seven essential aspects-shot scale, shot\nangle, composition, camera movement, lighting, color, and focal length-and\nincludes over 600 annotated movie images and 120 movie clips with clear\ncinematographic techniques. For the understanding task, we design question\nanswer pairs and annotated descriptions to assess MLLMs' ability to interpret\nand explain cinematographic techniques. For the generation task, we assess\nadvanced video generation models on their capacity to reconstruct\ncinema-quality camera movements given conditions such as textual prompts or\nkeyframes. We conduct a large-scale evaluation on 15+ MLLMs and 5+ video\ngeneration models. Our results offer insights into the limitations of current\nmodels and future directions for cinematography understanding and generation in\nautomatically film production and appreciation. The code and benchmark can be\naccessed at https://github.com/PRIS-CV/CineTechBench.",
    "pdf_url": "http://arxiv.org/pdf/2505.15145v1",
    "published": "2025-05-21T06:02:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15144v2",
    "title": "More on 8d non-supersymmetric branes and heterotic strings",
    "authors": [
      "Yuta Hamada",
      "Arata Ishige",
      "Yuichi Koga"
    ],
    "abstract": "We determine the maximal gauge groups arising in $E_8$ heterotic string\ntheory on $T^2$. Our analysis proceeds along two approaches. First, we start\nthe moduli space of the supersymmetric heterotic string theory on $T^2$\nfocusing on points of maximal gauge enhancement. At these special points, the\ncharge lattice can exhibit a $\\mathbb{Z}_2$ outer automorphism corresponding to\nthe bulk gauge symmetry. By orbifolding the worldsheet theory by it with the\nfermion parity, we obtain the maximal gauge group of the $E_8$ theory. Second,\nwe directly study the toroidal compactification of 10d $E_8$ heterotic string.\nBoth approaches agree, yielding a classification of $22$ maximal gauge groups.\nFor each case, we present the corresponding massless spectrum. In light of the\nno global symmetry/cobordism conjecture in quantum gravity, our result also\noffer a classification of non-supersymmetric branes in 8d supersymmetric\nheterotic string theories.",
    "pdf_url": "http://arxiv.org/pdf/2505.15144v2",
    "published": "2025-05-21T06:00:57+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15143v1",
    "title": "Filtering Learning Histories Enhances In-Context Reinforcement Learning",
    "authors": [
      "Weiqin Chen",
      "Xinjie Zhang",
      "Dharmashankar Subramanian",
      "Santiago Paternain"
    ],
    "abstract": "Transformer models (TMs) have exhibited remarkable in-context reinforcement\nlearning (ICRL) capabilities, allowing them to generalize to and improve in\npreviously unseen environments without re-training or fine-tuning. This is\ntypically accomplished by imitating the complete learning histories of a source\nRL algorithm over a substantial amount of pretraining environments, which,\nhowever, may transfer suboptimal behaviors inherited from the source\nalgorithm/dataset. Therefore, in this work, we address the issue of inheriting\nsuboptimality from the perspective of dataset preprocessing. Motivated by the\nsuccess of the weighted empirical risk minimization, we propose a simple yet\neffective approach, learning history filtering (LHF), to enhance ICRL by\nreweighting and filtering the learning histories based on their improvement and\nstability characteristics. To the best of our knowledge, LHF is the first\napproach to avoid source suboptimality by dataset preprocessing, and can be\ncombined with the current state-of-the-art (SOTA) ICRL algorithms. We\nsubstantiate the effectiveness of LHF through a series of experiments conducted\non the well-known ICRL benchmarks, encompassing both discrete environments and\ncontinuous robotic manipulation tasks, with three SOTA ICRL algorithms (AD,\nDPT, DICP) as the backbones. LHF exhibits robust performance across a variety\nof suboptimal scenarios, as well as under varying hyperparameters and sampling\nstrategies. Notably, the superior performance of LHF becomes more pronounced in\nthe presence of noisy data, indicating the significance of filtering learning\nhistories.",
    "pdf_url": "http://arxiv.org/pdf/2505.15143v1",
    "published": "2025-05-21T06:00:41+00:00",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15142v4",
    "title": "Strong semistability of Higgs bundles over curves",
    "authors": [
      "Bowen Liu",
      "Mao Sheng"
    ],
    "abstract": "In this paper we complete the study of the Lan-Sheng-Zuo conjecture proposed\nin arXiv:1210.8280 for the curve case. Precisely, we prove that every\nsemistable Higgs bundle is strongly semistable for curves of genus $g\\leq 1$,\nand over any curves of genus $g\\ge2$ construct explicit examples of semistable\nHiggs bundles of arbitrary big rank (the first example is $p=2,r=3$) which are\nnot strongly semistable. These results are complementary to the strongly\nsemistability theorem of Lan-Sheng-Yang-Zuo and Langer for semistable Higgs\nbundles of small rank.",
    "pdf_url": "http://arxiv.org/pdf/2505.15142v4",
    "published": "2025-05-21T05:59:45+00:00",
    "categories": [
      "math.AG",
      "14H60"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15141v1",
    "title": "BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms",
    "authors": [
      "Yunlong Hou",
      "Fengzhuo Zhang",
      "Cunxiao Du",
      "Xuan Zhang",
      "Jiachun Pan",
      "Tianyu Pang",
      "Chao Du",
      "Vincent Y. F. Tan",
      "Zhuoran Yang"
    ],
    "abstract": "Speculative decoding has emerged as a popular method to accelerate the\ninference of Large Language Models (LLMs) while retaining their superior text\ngeneration performance. Previous methods either adopt a fixed speculative\ndecoding configuration regardless of the prefix tokens, or train draft models\nin an offline or online manner to align them with the context. This paper\nproposes a training-free online learning framework to adaptively choose the\nconfiguration of the hyperparameters for speculative decoding as text is being\ngenerated. We first formulate this hyperparameter selection problem as a\nMulti-Armed Bandit problem and provide a general speculative decoding framework\nBanditSpec. Furthermore, two bandit-based hyperparameter selection algorithms,\nUCBSpec and EXP3Spec, are designed and analyzed in terms of a novel quantity,\nthe stopping time regret. We upper bound this regret under both stochastic and\nadversarial reward settings. By deriving an information-theoretic impossibility\nresult, it is shown that the regret performance of UCBSpec is optimal up to\nuniversal constants. Finally, extensive empirical experiments with LLaMA3 and\nQwen2 demonstrate that our algorithms are effective compared to existing\nmethods, and the throughput is close to the oracle best hyperparameter in\nsimulated real-life LLM serving scenarios with diverse input prompts.",
    "pdf_url": "http://arxiv.org/pdf/2505.15141v1",
    "published": "2025-05-21T05:56:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15140v1",
    "title": "EC-LDA : Label Distribution Inference Attack against Federated Graph Learning with Embedding Compression",
    "authors": [
      "Tong Cheng",
      "Fu Jie",
      "Xinpeng Ling",
      "Huifa Li",
      "Zhili Chen"
    ],
    "abstract": "Graph Neural Networks (GNNs) have been widely used for graph analysis.\nFederated Graph Learning (FGL) is an emerging learning framework to\ncollaboratively train graph data from various clients. However, since clients\nare required to upload model parameters to the server in each round, this\nprovides the server with an opportunity to infer each client's data privacy. In\nthis paper, we focus on label distribution attacks(LDAs) that aim to infer the\nlabel distributions of the clients' local data. We take the first step to\nattack client's label distributions in FGL. Firstly, we observe that the\neffectiveness of LDA is closely related to the variance of node embeddings in\nGNNs. Next, we analyze the relation between them and we propose a new attack\nnamed EC-LDA, which significantly improves the attack effectiveness by\ncompressing node embeddings. Thirdly, extensive experiments on node\nclassification and link prediction tasks across six widely used graph datasets\nshow that EC-LDA outperforms the SOTA LDAs. For example, EC-LDA attains optimal\nvalues under both Cos-sim and JS-div evaluation metrics in the CoraFull and\nLastFM datasets. Finally, we explore the robustness of EC-LDA under\ndifferential privacy protection.",
    "pdf_url": "http://arxiv.org/pdf/2505.15140v1",
    "published": "2025-05-21T05:54:37+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15139v1",
    "title": "Unified Cross-Modal Attention-Mixer Based Structural-Functional Connectomics Fusion for Neuropsychiatric Disorder Diagnosis",
    "authors": [
      "Badhan Mazumder",
      "Lei Wu",
      "Vince D. Calhoun",
      "Dong Hye Ye"
    ],
    "abstract": "Gaining insights into the structural and functional mechanisms of the brain\nhas been a longstanding focus in neuroscience research, particularly in the\ncontext of understanding and treating neuropsychiatric disorders such as\nSchizophrenia (SZ). Nevertheless, most of the traditional multimodal deep\nlearning approaches fail to fully leverage the complementary characteristics of\nstructural and functional connectomics data to enhance diagnostic performance.\nTo address this issue, we proposed ConneX, a multimodal fusion method that\nintegrates cross-attention mechanism and multilayer perceptron (MLP)-Mixer for\nrefined feature fusion. Modality-specific backbone graph neural networks (GNNs)\nwere firstly employed to obtain feature representation for each modality. A\nunified cross-modal attention network was then introduced to fuse these\nembeddings by capturing intra- and inter-modal interactions, while MLP-Mixer\nlayers refined global and local features, leveraging higher-order dependencies\nfor end-to-end classification with a multi-head joint loss. Extensive\nevaluations demonstrated improved performance on two distinct clinical\ndatasets, highlighting the robustness of our proposed framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.15139v1",
    "published": "2025-05-21T05:49:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15138v1",
    "title": "Global Convergence for Average Reward Constrained MDPs with Primal-Dual Actor Critic Algorithm",
    "authors": [
      "Yang Xu",
      "Swetha Ganesh",
      "Washim Uddin Mondal",
      "Qinbo Bai",
      "Vaneet Aggarwal"
    ],
    "abstract": "This paper investigates infinite-horizon average reward Constrained Markov\nDecision Processes (CMDPs) with general parametrization. We propose a\nPrimal-Dual Natural Actor-Critic algorithm that adeptly manages constraints\nwhile ensuring a high convergence rate. In particular, our algorithm achieves\nglobal convergence and constraint violation rates of\n$\\tilde{\\mathcal{O}}(1/\\sqrt{T})$ over a horizon of length $T$ when the mixing\ntime, $\\tau_{\\mathrm{mix}}$, is known to the learner. In absence of knowledge\nof $\\tau_{\\mathrm{mix}}$, the achievable rates change to\n$\\tilde{\\mathcal{O}}(1/T^{0.5-\\epsilon})$ provided that $T \\geq\n\\tilde{\\mathcal{O}}\\left(\\tau_{\\mathrm{mix}}^{2/\\epsilon}\\right)$. Our results\nmatch the theoretical lower bound for Markov Decision Processes and establish a\nnew benchmark in the theoretical exploration of average reward CMDPs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15138v1",
    "published": "2025-05-21T05:49:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15137v2",
    "title": "Multispectral Detection Transformer with Infrared-Centric Feature Fusion",
    "authors": [
      "Seongmin Hwang",
      "Daeyoung Han",
      "Moongu Jeon"
    ],
    "abstract": "Multispectral object detection aims to leverage complementary information\nfrom visible (RGB) and infrared (IR) modalities to enable robust performance\nunder diverse environmental conditions. Our key insight, derived from wavelet\nanalysis and empirical observations, is that IR images contain structurally\nrich high-frequency information critical for object detection, making an\ninfrared-centric approach highly effective. To capitalize on this finding, we\npropose Infrared-Centric Fusion (IC-Fusion), a lightweight and modality-aware\nsensor fusion method that prioritizes infrared features while effectively\nintegrating complementary RGB semantic context. IC-Fusion adopts a compact RGB\nbackbone and designs a novel fusion module comprising a Multi-Scale Feature\nDistillation (MSFD) block to enhance RGB features and a three-stage fusion\nblock with a Cross-Modal Channel Shuffle Gate (CCSG), a Cross-Modal Large\nKernel Gate (CLKG), and a Channel Shuffle Projection (CSP) to facilitate\neffective cross-modal interaction. Experiments on the FLIR and LLVIP benchmarks\ndemonstrate the superior effectiveness and efficiency of our IR-centric fusion\nstrategy, further validating its benefits. Our code is available at\nhttps://github.com/smin-hwang/IC-Fusion.",
    "pdf_url": "http://arxiv.org/pdf/2505.15137v2",
    "published": "2025-05-21T05:44:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15136v1",
    "title": "Hybrid Audio Detection Using Fine-Tuned Audio Spectrogram Transformers: A Dataset-Driven Evaluation of Mixed AI-Human Speech",
    "authors": [
      "Kunyang Huang",
      "Bin Hu"
    ],
    "abstract": "The rapid advancement of artificial intelligence (AI) has enabled\nsophisticated audio generation and voice cloning technologies, posing\nsignificant security risks for applications reliant on voice authentication.\nWhile existing datasets and models primarily focus on distinguishing between\nhuman and fully synthetic speech, real-world attacks often involve audio that\ncombines both genuine and cloned segments. To address this gap, we construct a\nnovel hybrid audio dataset incorporating human, AI-generated, cloned, and mixed\naudio samples. We further propose fine-tuned Audio Spectrogram Transformer\n(AST)-based models tailored for detecting these complex acoustic patterns.\nExtensive experiments demonstrate that our approach significantly outperforms\nexisting baselines in mixed-audio detection, achieving 97\\% classification\naccuracy. Our findings highlight the importance of hybrid datasets and tailored\nmodels in advancing the robustness of speech-based authentication systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15136v1",
    "published": "2025-05-21T05:43:41+00:00",
    "categories": [
      "cs.SD",
      "cs.CR",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15135v1",
    "title": "Physics-Guided Multi-View Graph Neural Network for Schizophrenia Classification via Structural-Functional Coupling",
    "authors": [
      "Badhan Mazumder",
      "Ayush Kanyal",
      "Lei Wu",
      "Vince D. Calhoun",
      "Dong Hye Ye"
    ],
    "abstract": "Clinical studies reveal disruptions in brain structural connectivity (SC) and\nfunctional connectivity (FC) in neuropsychiatric disorders such as\nschizophrenia (SZ). Traditional approaches might rely solely on SC due to\nlimited functional data availability, hindering comprehension of cognitive and\nbehavioral impairments in individuals with SZ by neglecting the intricate SC-FC\ninterrelationship. To tackle the challenge, we propose a novel physics-guided\ndeep learning framework that leverages a neural oscillation model to describe\nthe dynamics of a collection of interconnected neural oscillators, which\noperate via nerve fibers dispersed across the brain's structure. Our proposed\nframework utilizes SC to simultaneously generate FC by learning SC-FC coupling\nfrom a system dynamics perspective. Additionally, it employs a novel multi-view\ngraph neural network (GNN) with a joint loss to perform correlation-based SC-FC\nfusion and classification of individuals with SZ. Experiments conducted on a\nclinical dataset exhibited improved performance, demonstrating the robustness\nof our proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.15135v1",
    "published": "2025-05-21T05:41:48+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15134v1",
    "title": "The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning",
    "authors": [
      "Shivam Agarwal",
      "Zimin Zhang",
      "Lifan Yuan",
      "Jiawei Han",
      "Hao Peng"
    ],
    "abstract": "Entropy minimization (EM) trains the model to concentrate even more\nprobability mass on its most confident outputs. We show that this simple\nobjective alone, without any labeled data, can substantially improve large\nlanguage models' (LLMs) performance on challenging math, physics, and coding\ntasks. We explore three approaches: (1) EM-FT minimizes token-level entropy\nsimilarly to instruction finetuning, but on unlabeled outputs drawn from the\nmodel; (2) EM-RL: reinforcement learning with negative entropy as the only\nreward to maximize; (3) EM-INF: inference-time logit adjustment to reduce\nentropy without any training data or parameter updates. On Qwen-7B, EM-RL,\nwithout any labeled data, achieves comparable or better performance than strong\nRL baselines such as GRPO and RLOO that are trained on 60K labeled examples.\nFurthermore, EM-INF enables Qwen-32B to match or exceed the performance of\nproprietary models like GPT-4o, Claude 3 Opus, and Gemini 1.5 Pro on the\nchallenging SciCode benchmark, while being 3x more efficient than\nself-consistency and sequential refinement. Our findings reveal that many\npretrained LLMs possess previously underappreciated reasoning capabilities that\ncan be effectively elicited through entropy minimization alone, without any\nlabeled data or even any parameter updates.",
    "pdf_url": "http://arxiv.org/pdf/2505.15134v1",
    "published": "2025-05-21T05:39:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15133v1",
    "title": "DeepKD: A Deeply Decoupled and Denoised Knowledge Distillation Trainer",
    "authors": [
      "Haiduo Huang",
      "Jiangcheng Song",
      "Yadong Zhang",
      "Pengju Ren"
    ],
    "abstract": "Recent advances in knowledge distillation have emphasized the importance of\ndecoupling different knowledge components. While existing methods utilize\nmomentum mechanisms to separate task-oriented and distillation gradients, they\noverlook the inherent conflict between target-class and non-target-class\nknowledge flows. Furthermore, low-confidence dark knowledge in non-target\nclasses introduces noisy signals that hinder effective knowledge transfer. To\naddress these limitations, we propose DeepKD, a novel training framework that\nintegrates dual-level decoupling with adaptive denoising. First, through\ntheoretical analysis of gradient signal-to-noise ratio (GSNR) characteristics\nin task-oriented and non-task-oriented knowledge distillation, we design\nindependent momentum updaters for each component to prevent mutual\ninterference. We observe that the optimal momentum coefficients for\ntask-oriented gradient (TOG), target-class gradient (TCG), and non-target-class\ngradient (NCG) should be positively related to their GSNR. Second, we introduce\na dynamic top-k mask (DTM) mechanism that gradually increases K from a small\ninitial value to incorporate more non-target classes as training progresses,\nfollowing curriculum learning principles. The DTM jointly filters\nlow-confidence logits from both teacher and student models, effectively\npurifying dark knowledge during early training. Extensive experiments on\nCIFAR-100, ImageNet, and MS-COCO demonstrate DeepKD's effectiveness. Our code\nis available at https://github.com/haiduo/DeepKD.",
    "pdf_url": "http://arxiv.org/pdf/2505.15133v1",
    "published": "2025-05-21T05:38:57+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15132v1",
    "title": "Multicrossmodal Automated Agent for Integrating Diverse Materials Science Data",
    "authors": [
      "Adib Bazgir",
      "Rama chandra Praneeth Madugula",
      "Yuwen Zhang"
    ],
    "abstract": "We introduce a multicrossmodal LLM-agent framework motivated by the growing\nvolume and diversity of materials-science data ranging from high-resolution\nmicroscopy and dynamic simulation videos to tabular experiment logs and\nsprawling literature archives. While recent AI efforts have accelerated\nindividual tasks such as property prediction or image classification, they\ntypically treat each modality in isolation, leaving rich cross-modal\ncorrelations unexplored and forcing researchers to perform laborious manual\nintegration. Moreover, existing multimodal foundation models often require\nexpensive retraining or fine-tuning on domain data, and current multi-agent\nsystems in materials informatics address only narrow subtasks. To overcome\nthese obstacles, we design a coordinated team of specialized LLM agents, each\nequipped with domain-adapted prompts and plugins that project their outputs\ninto a shared embedding space. A dynamic gating mechanism then weights and\nmerges these insights, enabling unified reasoning over heterogeneous inputs\nwithout ever modifying the underlying LLM weights. We validate our approach on\nchallenging case studies and demonstrate substantial gains in retrieval\naccuracy (85%), captioning fidelity, and integrated coverage (35%) compared to\nsingle-modality and zero-shot baselines. Our work paves the way for AI digital\nresearchers capable of bridging data silos and accelerating the\nmaterials-discovery cycle. The code is available at\nhttps://github.com/adibgpt/Multicrossmodal-Autonomous-Materials-Science-Agent.",
    "pdf_url": "http://arxiv.org/pdf/2505.15132v1",
    "published": "2025-05-21T05:37:03+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15131v3",
    "title": "On Discounted Infinite-Time Mean Field Games",
    "authors": [
      "Zeyu Yang",
      "Yongsheng Song"
    ],
    "abstract": "In this paper, we study the infinite-time mean field games with discounting,\nestablishing an equilibrium where individual optimal strategies collectively\nregenerate the mean-field distribution. To solve this problem, we partition all\nagents into a representative player and the social equilibrium. When the\noptimal strategy of the representative player shares the same feedback form\nwith the strategy of the social equilibrium, we say the system achieves a Nash\nequilibrium.\n  We construct a Nash equilibrium using the stochastic maximum principle and\ninfinite-time forward-backward stochastic differential equations(FBSDEs). By\nemploying the elliptic master equations, a class of distribution-dependent\nelliptic PDEs , we provide a representation for the Nash equilibrium. We prove\nthe Yamada-Watanabe theorem and show the weak uniqueness for infinite-time\nFBSDEs. And we prove that the solutions to a system of infinite-time FBSDEs can\nbe employed to construct viscosity solutions for a class of\ndistribution-dependent elliptic PDEs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15131v3",
    "published": "2025-05-21T05:36:48+00:00",
    "categories": [
      "math.OC",
      "math.PR"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15861v1",
    "title": "P3Net: Progressive and Periodic Perturbation for Semi-Supervised Medical Image Segmentation",
    "authors": [
      "Zhenyan Yao",
      "Miao Zhang",
      "Lanhu Wu",
      "Yongri Piao",
      "Feng Tian",
      "Weibing Sun",
      "Huchuan Lu"
    ],
    "abstract": "Perturbation with diverse unlabeled data has proven beneficial for\nsemi-supervised medical image segmentation (SSMIS). While many works have\nsuccessfully used various perturbation techniques, a deeper understanding of\nlearning perturbations is needed. Excessive or inappropriate perturbation can\nhave negative effects, so we aim to address two challenges: how to use\nperturbation mechanisms to guide the learning of unlabeled data through labeled\ndata, and how to ensure accurate predictions in boundary regions. Inspired by\nhuman progressive and periodic learning, we propose a progressive and periodic\nperturbation mechanism (P3M) and a boundary-focused loss. P3M enables dynamic\nadjustment of perturbations, allowing the model to gradually learn them. Our\nboundary-focused loss encourages the model to concentrate on boundary regions,\nenhancing sensitivity to intricate details and ensuring accurate predictions.\nExperimental results demonstrate that our method achieves state-of-the-art\nperformance on two 2D and 3D datasets. Moreover, P3M is extendable to other\nmethods, and the proposed loss serves as a universal tool for improving\nexisting methods, highlighting the scalability and applicability of our\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2505.15861v1",
    "published": "2025-05-21T05:35:28+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15130v2",
    "title": "Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models",
    "authors": [
      "Sajjad Ghiasvand",
      "Haniyeh Ehsani Oskouie",
      "Mahnoosh Alizadeh",
      "Ramtin Pedarsani"
    ],
    "abstract": "Vision-Language Models (VLMs) such as CLIP have shown remarkable performance\nin cross-modal tasks through large-scale contrastive pre-training. To adapt\nthese large transformer-based models efficiently for downstream tasks,\nParameter-Efficient Fine-Tuning (PEFT) techniques like LoRA have emerged as\nscalable alternatives to full fine-tuning, especially in few-shot scenarios.\nHowever, like traditional deep neural networks, VLMs are highly vulnerable to\nadversarial attacks, where imperceptible perturbations can significantly\ndegrade model performance. Adversarial training remains the most effective\nstrategy for improving model robustness in PEFT. In this work, we propose\nAdvCLIP-LoRA, the first algorithm designed to enhance the adversarial\nrobustness of CLIP models fine-tuned with LoRA in few-shot settings. Our method\nformulates adversarial fine-tuning as a minimax optimization problem and\nprovides theoretical guarantees for convergence under smoothness and\nnonconvex-strong-concavity assumptions. Empirical results across eight datasets\nusing ViT-B/16 and ViT-B/32 models show that AdvCLIP-LoRA significantly\nimproves robustness against common adversarial attacks (e.g., FGSM, PGD),\nwithout sacrificing much clean accuracy. These findings highlight AdvCLIP-LoRA\nas a practical and theoretically grounded approach for robust adaptation of\nVLMs in resource-constrained settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.15130v2",
    "published": "2025-05-21T05:35:24+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15129v2",
    "title": "Approximation of biholomorphic maps between Runge domains by holomorphic automorphisms",
    "authors": [
      "Franc Forstneric"
    ],
    "abstract": "We show that biholomorphic maps between certain pairs of Runge domains in the\ncomplex affine space $\\mathbb C^n$, $n>1$, are limits of holomorphic\nautomorphisms of $\\mathbb C^n$. A similar result holds for volume preserving\nmaps and also in Stein manifolds with the density property. This generalizes\nseveral results in the literature and provides a considerably simpler proof.",
    "pdf_url": "http://arxiv.org/pdf/2505.15129v2",
    "published": "2025-05-21T05:34:46+00:00",
    "categories": [
      "math.CV",
      "Primary 32E30. Secondary 14R10, 32M17"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15128v1",
    "title": "Robust Relevance Feedback for Interactive Known-Item Video Search",
    "authors": [
      "Zhixin Ma",
      "Chong-Wah Ngo"
    ],
    "abstract": "Known-item search (KIS) involves only a single search target, making\nrelevance feedback-typically a powerful technique for efficiently identifying\nmultiple positive examples to infer user intent-inapplicable. PicHunter\naddresses this issue by asking users to select the top-k most similar examples\nto the unique search target from a displayed set. Under ideal conditions, when\nthe user's perception aligns closely with the machine's perception of\nsimilarity, consistent and precise judgments can elevate the target to the top\nposition within a few iterations. However, in practical scenarios, expecting\nusers to provide consistent judgments is often unrealistic, especially when the\nunderlying embedding features used for similarity measurements lack\ninterpretability. To enhance robustness, we first introduce a pairwise relative\njudgment feedback that improves the stability of top-k selections by mitigating\nthe impact of misaligned feedback. Then, we decompose user perception into\nmultiple sub-perceptions, each represented as an independent embedding space.\nThis approach assumes that users may not consistently align with a single\nrepresentation but are more likely to align with one or several among multiple\nrepresentations. We develop a predictive user model that estimates the\ncombination of sub-perceptions based on each user feedback instance. The\npredictive user model is then trained to filter out the misaligned\nsub-perceptions. Experimental evaluations on the large-scale open-domain\ndataset V3C indicate that the proposed model can optimize over 60% search\ntargets to the top rank when their initial ranks at the search depth between 10\nand 50. Even for targets initially ranked between 1,000 and 5,000, the model\nachieves a success rate exceeding 40% in optimizing ranks to the top,\ndemonstrating the enhanced robustness of relevance feedback in KIS despite\ninconsistent feedback.",
    "pdf_url": "http://arxiv.org/pdf/2505.15128v1",
    "published": "2025-05-21T05:31:49+00:00",
    "categories": [
      "cs.IR",
      "cs.MM"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15127v1",
    "title": "Spatial and velocity anisotropies of stellar halos across cosmic web environments: Insights from IllustrisTNG simulation",
    "authors": [
      "Amit Mondal",
      "Biswajit Pandey",
      "Anindita Nandi"
    ],
    "abstract": "The role of large-scale environment in shaping the structural and kinematic\nproperties of stellar halos remains an open question. We investigate whether\nthe cosmic web environments affect the spatial and velocity anisotropies of\nstellar halos in Milky Way-mass galaxies. Using high-resolution data from the\nTNG50 simulation, we analyze 29 stellar halos from each environment and\nquantify their spatial and kinematic anisotropies as a function of halo-centric\nradius. We find that stellar halos across all environments generally exhibit\nincreasing spatial anisotropy with radius, with fluctuations corresponding to\nbound substructures. The velocity anisotropy profiles show radially dominated\norbits on average, but also display significant local variation, including\ntangentially dominated regions. However, no statistically significant\ndifferences are observed in the mean spatial or velocity anisotropy profiles\nacross environments, for either the total stellar halo population or for the in\nsitu and ex situ components individually. The large scatter within each\nenvironment suggests that the formation of stellar halos is primarily driven by\nstochastic, small-scale processes such as satellite merger histories, rather\nthan the large-scale geometry of the cosmic web. Our results imply that, at\nfixed halo mass, the influence of cosmic web environment on the structure of\nstellar halo is weak or highly non-deterministic. Possible environmental\neffects may be more prominent at higher masses where accretion is more\nanisotropic. Exploring this regime will require simulations with both larger\nvolume and higher resolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15127v1",
    "published": "2025-05-21T05:31:06+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15860v1",
    "title": "RadarRGBD A Multi-Sensor Fusion Dataset for Perception with RGB-D and mmWave Radar",
    "authors": [
      "Tieshuai Song",
      "Jiandong Ye",
      "Ao Guo",
      "Guidong He",
      "Bin Yang"
    ],
    "abstract": "Multi-sensor fusion has significant potential in perception tasks for both\nindoor and outdoor environments. Especially under challenging conditions such\nas adverse weather and low-light environments, the combined use of\nmillimeter-wave radar and RGB-D sensors has shown distinct advantages. However,\nexisting multi-sensor datasets in the fields of autonomous driving and robotics\noften lack high-quality millimeter-wave radar data. To address this gap, we\npresent a new multi-sensor dataset:RadarRGBD. This dataset includes RGB-D data,\nmillimeter-wave radar point clouds, and raw radar matrices, covering various\nindoor and outdoor scenes, as well as low-light environments. Compared to\nexisting datasets, RadarRGBD employs higher-resolution millimeter-wave radar\nand provides raw data, offering a new research foundation for the fusion of\nmillimeter-wave radar and visual sensors. Furthermore, to tackle the noise and\ngaps in depth maps captured by Kinect V2 due to occlusions and mismatches, we\nfine-tune an open-source relative depth estimation framework, incorporating the\nabsolute depth information from the dataset for depth supervision. We also\nintroduce pseudo-relative depth scale information to further optimize the\nglobal depth scale estimation. Experimental results demonstrate that the\nproposed method effectively fills in missing regions in sensor data. Our\ndataset and related documentation will be publicly available at:\nhttps://github.com/song4399/RadarRGBD.",
    "pdf_url": "http://arxiv.org/pdf/2505.15860v1",
    "published": "2025-05-21T05:30:04+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17099v1",
    "title": "Learning Interpretable Representations Leads to Semantically Faithful EEG-to-Text Generation",
    "authors": [
      "Xiaozhao Liu",
      "Dinggang Shen",
      "Xihui Liu"
    ],
    "abstract": "Pretrained generative models have opened new frontiers in brain decoding by\nenabling the synthesis of realistic texts and images from non-invasive brain\nrecordings. However, the reliability of such outputs remains\nquestionable--whether they truly reflect semantic activation in the brain, or\nare merely hallucinated by the powerful generative models. In this paper, we\nfocus on EEG-to-text decoding and address its hallucination issue through the\nlens of posterior collapse. Acknowledging the underlying mismatch in\ninformation capacity between EEG and text, we reframe the decoding task as\nsemantic summarization of core meanings rather than previously verbatim\nreconstruction of stimulus texts. To this end, we propose the Generative\nLanguage Inspection Model (GLIM), which emphasizes learning informative and\ninterpretable EEG representations to improve semantic grounding under\nheterogeneous and small-scale data conditions. Experiments on the public ZuCo\ndataset demonstrate that GLIM consistently generates fluent, EEG-grounded\nsentences without teacher forcing. Moreover, it supports more robust evaluation\nbeyond text similarity, through EEG-text retrieval and zero-shot semantic\nclassification across sentiment categories, relation types, and corpus topics.\nTogether, our architecture and evaluation protocols lay the foundation for\nreliable and scalable benchmarking in generative brain decoding.",
    "pdf_url": "http://arxiv.org/pdf/2505.17099v1",
    "published": "2025-05-21T05:29:55+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15126v2",
    "title": "Damping Effects on Global Existence and Scattering for an Inhomogeneous NLS Equation with Inverse-Square Potential",
    "authors": [
      "Makram Hamouda",
      "Mohamed Majdoub",
      "Tarek Saanouni"
    ],
    "abstract": "This work explores the global existence and scattering behavior of solutions\nto a damped, inhomogeneous nonlinear Schrodinger equation featuring a\ntime-dependent damping term, an inverse-square potential, and an inhomogeneous\nnonlinearity. We establish global well-posedness in the energy space for\nsubcritical, mass-critical, and energy-critical regimes, using Strichartz\nestimates, Hardy inequalities, and Gagliardo-Nirenberg-type estimates. For\nsufficiently large damping, we highlight how the interplay between damping,\nsingular potentials, and inhomogeneity influences the dynamics. Our results\nextend existing studies and offer new insights into the long-time behavior of\nsolutions in this more general setting. To the best of our knowledge, this is\nthe first study to address the combined effects of inverse-square potential,\ninhomogeneous (or even homogeneous) nonlinearity, and damping in the context of\nthe NLS equation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15126v2",
    "published": "2025-05-21T05:27:43+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17098v1",
    "title": "TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration",
    "authors": [
      "Yanshu Li",
      "Tian Yun",
      "Jianjiang Yang",
      "Pinyuan Feng",
      "Jinfa Huang",
      "Ruixiang Tang"
    ],
    "abstract": "Multimodal in-context learning (ICL) has emerged as a key mechanism for\nharnessing the capabilities of large vision-language models (LVLMs). However,\nits effectiveness remains highly sensitive to the quality of input in-context\nsequences, particularly for tasks involving complex reasoning or open-ended\ngeneration. A major limitation is our limited understanding of how LVLMs\nactually exploit these sequences during inference. To bridge this gap, we\nsystematically interpret multimodal ICL through the lens of task mapping, which\nreveals how local and global relationships within and among demonstrations\nguide model reasoning. Building on this insight, we present TACO, a lightweight\ntransformer-based model equipped with task-aware attention that dynamically\nconfigures in-context sequences. By injecting task-mapping signals into the\nautoregressive decoding process, TACO creates a bidirectional synergy between\nsequence construction and task reasoning. Experiments on five LVLMs and nine\ndatasets demonstrate that TACO consistently surpasses baselines across diverse\nICL tasks. These results position task mapping as a valuable perspective for\ninterpreting and improving multimodal ICL.",
    "pdf_url": "http://arxiv.org/pdf/2505.17098v1",
    "published": "2025-05-21T05:22:21+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15125v1",
    "title": "Quasinormal Modes from EFT of Black Hole Perturbations in Vector-Tensor Gravity",
    "authors": [
      "Shogo Tomizuka",
      "Hajime Kobayashi",
      "Naritaka Oshita",
      "Kazufumi Takahashi",
      "Shinji Mukohyama"
    ],
    "abstract": "We study the dynamics of odd-parity perturbations on a static and spherically\nsymmetric black hole background with a timelike vector field based on the\neffective field theory (EFT) approach. We derive the quadratic Lagrangian\nwritten in terms of two master variables, corresponding to the tensor and\nvector gravitons, which are coupled in general, while they can be decoupled on\na stealth Schwarzschild(-de Sitter) background. For the stealth Schwarzschild\nbackground, we find that the quasinormal mode frequencies for both degrees of\nfreedom are obtained from those in general relativity by simple scaling.\nNonetheless, due to the fact that the metric perturbation is a non-trivial\nlinear combination of the two degrees of freedom with different QNM spectra,\nthe ringdown gravitational waves may exhibit characteristic modulation that can\nin principle be a signature of vector-tensor gravity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15125v1",
    "published": "2025-05-21T05:19:52+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15124v1",
    "title": "A Survey On Secure Machine Learning",
    "authors": [
      "Taobo Liao",
      "Taoran Li",
      "Prathamesh Nadkarni"
    ],
    "abstract": "In this survey, we will explore the interaction between secure multiparty\ncomputation and the area of machine learning. Recent advances in secure\nmultiparty computation (MPC) have significantly improved its applicability in\nthe realm of machine learning (ML), offering robust solutions for\nprivacy-preserving collaborative learning. This review explores key\ncontributions that leverage MPC to enable multiple parties to engage in ML\ntasks without compromising the privacy of their data. The integration of MPC\nwith ML frameworks facilitates the training and evaluation of models on\ncombined datasets from various sources, ensuring that sensitive information\nremains encrypted throughout the process. Innovations such as specialized\nsoftware frameworks and domain-specific languages streamline the adoption of\nMPC in ML, optimizing performance and broadening its usage. These frameworks\naddress both semi-honest and malicious threat models, incorporating features\nsuch as automated optimizations and cryptographic auditing to ensure compliance\nand data integrity. The collective insights from these studies highlight MPC's\npotential in fostering collaborative yet confidential data analysis, marking a\nsignificant stride towards the realization of secure and efficient\ncomputational solutions in privacy-sensitive industries. This paper\ninvestigates a spectrum of SecureML libraries that includes cryptographic\nprotocols, federated learning frameworks, and privacy-preserving algorithms. By\nsurveying the existing literature, this paper aims to examine the efficacy of\nthese libraries in preserving data privacy, ensuring model confidentiality, and\nfortifying ML systems against adversarial attacks. Additionally, the study\nexplores an innovative application domain for SecureML techniques: the\nintegration of these methodologies in gaming environments utilizing ML.",
    "pdf_url": "http://arxiv.org/pdf/2505.15124v1",
    "published": "2025-05-21T05:19:45+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15123v2",
    "title": "Seeing the Trees for the Forest: Rethinking Weakly-Supervised Medical Visual Grounding",
    "authors": [
      "Ta Duc Huy",
      "Duy Anh Huynh",
      "Yutong Xie",
      "Yuankai Qi",
      "Qi Chen",
      "Phi Le Nguyen",
      "Sen Kim Tran",
      "Son Lam Phung",
      "Anton van den Hengel",
      "Zhibin Liao",
      "Minh-Son To",
      "Johan W. Verjans",
      "Vu Minh Hieu Phan"
    ],
    "abstract": "Visual grounding (VG) is the capability to identify the specific regions in\nan image associated with a particular text description. In medical imaging, VG\nenhances interpretability by highlighting relevant pathological features\ncorresponding to textual descriptions, improving model transparency and\ntrustworthiness for wider adoption of deep learning models in clinical\npractice. Current models struggle to associate textual descriptions with\ndisease regions due to inefficient attention mechanisms and a lack of\nfine-grained token representations. In this paper, we empirically demonstrate\ntwo key observations. First, current VLMs assign high norms to background\ntokens, diverting the model's attention from regions of disease. Second, the\nglobal tokens used for cross-modal learning are not representative of local\ndisease tokens. This hampers identifying correlations between the text and\ndisease tokens. To address this, we introduce simple, yet effective\nDisease-Aware Prompting (DAP) process, which uses the explainability map of a\nVLM to identify the appropriate image features. This simple strategy amplifies\ndisease-relevant regions while suppressing background interference. Without any\nadditional pixel-level annotations, DAP improves visual grounding accuracy by\n20.74% compared to state-of-the-art methods across three major chest X-ray\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.15123v2",
    "published": "2025-05-21T05:16:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15122v2",
    "title": "Exploring Dynamic Load Balancing Algorithms for Block-Structured Mesh-and-Particle Simulations in AMReX",
    "authors": [
      "Amitash Nanda",
      "Md Kamal Hossain Chowdhury",
      "Hannah Ross",
      "Kevin Gott"
    ],
    "abstract": "Load balancing is critical for successful large-scale high-performance\ncomputing (HPC) simulations. With modern supercomputers increasing in\ncomplexity and variability, dynamic load balancing is becoming more critical to\nuse computational resources efficiently. In this study, performed during a\nsummer collaboration at Lawrence Berkeley National Laboratory, we investigate\nvarious standard dynamic load-balancing algorithms. This includes the time\nevaluation of a brute-force solve for application in algorithmic evaluation, as\nwell as quality and time evaluations of the Knapsack algorithm, an SFC\nalgorithm, and two novel algorithms: a painter's partition-based SFC algorithm\nand a combination Knapsack+SFC methodology-based on hardware topology. The\nresults suggest Knapsack and painter's partition-based algorithms should be\namong the first algorithms evaluated by HPC codes for cases with limited weight\ndeviation and will perform at least slightly better than AMReX's\npercentage-tracking partitioning strategy across most simulations, although\neffects diminish as weight variety increases.",
    "pdf_url": "http://arxiv.org/pdf/2505.15122v2",
    "published": "2025-05-21T05:15:14+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.18198v1",
    "title": "LTDA-Drive: LLMs-guided Generative Models based Long-tail Data Augmentation for Autonomous Driving",
    "authors": [
      "Mahmut Yurt",
      "Xin Ye",
      "Yunsheng Ma",
      "Jingru Luo",
      "Abhirup Mallik",
      "John Pauly",
      "Burhaneddin Yaman",
      "Liu Ren"
    ],
    "abstract": "3D perception plays an essential role for improving the safety and\nperformance of autonomous driving. Yet, existing models trained on real-world\ndatasets, which naturally exhibit long-tail distributions, tend to underperform\non rare and safety-critical, vulnerable classes, such as pedestrians and\ncyclists. Existing studies on reweighting and resampling techniques struggle\nwith the scarcity and limited diversity within tail classes. To address these\nlimitations, we introduce LTDA-Drive, a novel LLM-guided data augmentation\nframework designed to synthesize diverse, high-quality long-tail samples.\nLTDA-Drive replaces head-class objects in driving scenes with tail-class\nobjects through a three-stage process: (1) text-guided diffusion models remove\nhead-class objects, (2) generative models insert instances of the tail classes,\nand (3) an LLM agent filters out low-quality synthesized images. Experiments\nconducted on the KITTI dataset show that LTDA-Drive significantly improves\ntail-class detection, achieving 34.75\\% improvement for rare classes over\ncounterpart methods. These results further highlight the effectiveness of\nLTDA-Drive in tackling long-tail challenges by generating high-quality and\ndiverse data.",
    "pdf_url": "http://arxiv.org/pdf/2505.18198v1",
    "published": "2025-05-21T05:14:11+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15121v1",
    "title": "$\\textit{Ab initio}$ multiconfigurational calculations of experimentally significant energy levels and transition rates in Lr I $\\left( Z=103 \\right)$",
    "authors": [
      "Joseph S. Andrews",
      "Andrey I. Bondarev",
      "Per J√∂nsson",
      "Jon Grumer",
      "Sebastian Raeder",
      "Stephan Fritzsche",
      "Jacek Biero≈Ñ"
    ],
    "abstract": "Large-scale multiconfigurational calculations are conducted on experimentally\nsignificant transitions in Lr I and its lanthanide homologue Lu I, exhibiting\ngood agreement with recent theoretical and experimental results. A single\nreference calculation is performed, allowing for substitutions from the core\nwithin a sufficiently large active set to effectively capture the influence of\nthe core on the valence shells, improving upon previous multiconfigurational\ncalculations. An additional calculation utilising a multireference set is\nperformed to account for static correlation effects which contribute to the\nwavefunction. Reported energies for the two selected transitions are\n20716$\\pm$550 $\\text{cm}^{-1}$ and 28587$\\pm$650 $\\text{cm}^{-1}$ for $7\\!s^2\n8s~^{2} \\! {S}_{1\\!/\\!2}$ $\\rightarrow$ $7\\!s^2 7\\!p ~^{2} \\! {P}^{o}_{1\\!/\\!2\n}$ and $7\\!s^2 7\\!d ~^{2} \\! {D}_{3\\!/\\!2 }$ $\\rightarrow$ $7\\!s^2 7\\!p ~^{2}\n\\! {P}^{o}_{1\\!/\\!2 }$, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.15121v1",
    "published": "2025-05-21T05:13:29+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15120v1",
    "title": "Lung Nodule-SSM: Self-Supervised Lung Nodule Detection and Classification in Thoracic CT Images",
    "authors": [
      "Muniba Noreen",
      "Furqan Shaukat"
    ],
    "abstract": "Lung cancer remains among the deadliest types of cancer in recent decades,\nand early lung nodule detection is crucial for improving patient outcomes. The\nlimited availability of annotated medical imaging data remains a bottleneck in\ndeveloping accurate computer-aided diagnosis (CAD) systems. Self-supervised\nlearning can help leverage large amounts of unlabeled data to develop more\nrobust CAD systems. With the recent advent of transformer-based architecture\nand their ability to generalize to unseen tasks, there has been an effort\nwithin the healthcare community to adapt them to various medical downstream\ntasks. Thus, we propose a novel \"LungNodule-SSM\" method, which utilizes\nselfsupervised learning with DINOv2 as a backbone to enhance lung nodule\ndetection and classification without annotated data. Our methodology has two\nstages: firstly, the DINOv2 model is pre-trained on unlabeled CT scans to learn\nrobust feature representations, then secondly, these features are fine-tuned\nusing transformer-based architectures for lesionlevel detection and accurate\nlung nodule diagnosis. The proposed method has been evaluated on the\nchallenging LUNA 16 dataset, consisting of 888 CT scans, and compared with SOTA\nmethods. Our experimental results show the superiority of our proposed method\nwith an accuracy of 98.37%, explaining its effectiveness in lung nodule\ndetection. The source code, datasets, and pre-processed data can be accessed\nusing the\nlink:https://github.com/EMeRALDsNRPU/Lung-Nodule-SSM-Self-Supervised-Lung-Nodule-Detection-and-Classification/tree/main",
    "pdf_url": "http://arxiv.org/pdf/2505.15120v1",
    "published": "2025-05-21T05:13:11+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15119v3",
    "title": "Lipschitz regularity for fully nonlinear elliptic equations with $(p,q)$-growth",
    "authors": [
      "Sun-Sig Byun",
      "Hongsoo Kim"
    ],
    "abstract": "We prove the interior and global Lipschitz regularity results for a solution\nof fully nonlinear equations with $(p,q)$-growth. We prove that for a small gap\n$q-p$, a solution is locally or globally Lipschitz continuous. We also prove\nthat a given H\\\"older continuous solution is Lipschitz continuous under\nimproved bounds for the gap. These gap conditions are similar to those required\nfor the regularity of double phase problems in divergence form.",
    "pdf_url": "http://arxiv.org/pdf/2505.15119v3",
    "published": "2025-05-21T05:12:13+00:00",
    "categories": [
      "math.AP",
      "35B65, 35D40, 35J15, 35J25"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15118v1",
    "title": "Maximum Degree-Based Quasi-Clique Search via an Iterative Framework",
    "authors": [
      "Hongbo Xia",
      "Kaiqiang Yu",
      "Shengxin Liu",
      "Cheng Long",
      "Xun Zhou"
    ],
    "abstract": "Cohesive subgraph mining is a fundamental problem in graph theory with\nnumerous real-world applications, such as social network analysis and\nprotein-protein interaction modeling. Among various cohesive subgraphs, the\n$\\gamma$-quasi-clique is widely studied for its flexibility in requiring each\nvertex to connect to at least a $\\gamma$ proportion of other vertices in the\nsubgraph. However, solving the maximum $\\gamma$-quasi-clique problem is NP-hard\nand further complicated by the lack of the hereditary property, which makes\ndesigning efficient pruning strategies challenging. Existing algorithms, such\nas DDA and FastQC, either struggle with scalability or exhibit significant\nperformance declines for small values of $\\gamma$. In this paper, we propose a\nnovel algorithm, IterQC, which reformulates the maximum $\\gamma$-quasi-clique\nproblem as a series of $k$-plex problems that possess the hereditary property.\nIterQC introduces a non-trivial iterative framework and incorporates two key\noptimization techniques: (1) the pseudo lower bound (pseudo LB) technique,\nwhich leverages information across iterations to improve the efficiency of\nbranch-and-bound searches, and (2) the preprocessing technique that reduces\nproblem size and unnecessary iterations. Extensive experiments demonstrate that\nIterQC achieves up to four orders of magnitude speedup and solves significantly\nmore graph instances compared to state-of-the-art algorithms DDA and FastQC.",
    "pdf_url": "http://arxiv.org/pdf/2505.15118v1",
    "published": "2025-05-21T05:11:50+00:00",
    "categories": [
      "cs.SI",
      "cs.DB"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15117v1",
    "title": "An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents",
    "authors": [
      "Bowen Jin",
      "Jinsung Yoon",
      "Priyanka Kargupta",
      "Sercan O. Arik",
      "Jiawei Han"
    ],
    "abstract": "Reinforcement learning (RL) has demonstrated strong potential in training\nlarge language models (LLMs) capable of complex reasoning for real-world\nproblem solving. More recently, RL has been leveraged to create sophisticated\nLLM-based search agents that adeptly combine reasoning with search engine use.\nWhile the use of RL for training search agents is promising, the optimal design\nof such agents remains not fully understood. In particular, key factors -- such\nas (1) reward formulation, (2) the choice and characteristics of the underlying\nLLM, and (3) the role of the search engine in the RL process -- require further\ninvestigation. In this work, we conduct comprehensive empirical studies to\nsystematically investigate these and offer actionable insights. We highlight\nseveral key findings: format rewards are effective in improving final\nperformance, whereas intermediate retrieval rewards have limited impact; the\nscale and initialization of the LLM (general-purpose vs. reasoning-specialized)\nsignificantly influence RL outcomes; and the choice of search engine plays a\ncritical role in shaping RL training dynamics and the robustness of the trained\nagent during inference. These establish important guidelines for successfully\nbuilding and deploying LLM-based search agents in real-world applications. Code\nis available at https://github.com/PeterGriffinJin/Search-R1.",
    "pdf_url": "http://arxiv.org/pdf/2505.15117v1",
    "published": "2025-05-21T05:09:43+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15116v1",
    "title": "Graph Foundation Models: A Comprehensive Survey",
    "authors": [
      "Zehong Wang",
      "Zheyuan Liu",
      "Tianyi Ma",
      "Jiazheng Li",
      "Zheyuan Zhang",
      "Xingbo Fu",
      "Yiyang Li",
      "Zhengqing Yuan",
      "Wei Song",
      "Yijun Ma",
      "Qingkai Zeng",
      "Xiusi Chen",
      "Jianan Zhao",
      "Jundong Li",
      "Meng Jiang",
      "Pietro Lio",
      "Nitesh Chawla",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "Graph-structured data pervades domains such as social networks, biological\nsystems, knowledge graphs, and recommender systems. While foundation models\nhave transformed natural language processing, vision, and multimodal learning\nthrough large-scale pretraining and generalization, extending these\ncapabilities to graphs -- characterized by non-Euclidean structures and complex\nrelational semantics -- poses unique challenges and opens new opportunities. To\nthis end, Graph Foundation Models (GFMs) aim to bring scalable, general-purpose\nintelligence to structured data, enabling broad transfer across graph-centric\ntasks and domains. This survey provides a comprehensive overview of GFMs,\nunifying diverse efforts under a modular framework comprising three key\ncomponents: backbone architectures, pretraining strategies, and adaptation\nmechanisms. We categorize GFMs by their generalization scope -- universal,\ntask-specific, and domain-specific -- and review representative methods, key\ninnovations, and theoretical insights within each category. Beyond methodology,\nwe examine theoretical foundations including transferability and emergent\ncapabilities, and highlight key challenges such as structural alignment,\nheterogeneity, scalability, and evaluation. Positioned at the intersection of\ngraph learning and general-purpose AI, GFMs are poised to become foundational\ninfrastructure for open-ended reasoning over structured data. This survey\nconsolidates current progress and outlines future directions to guide research\nin this rapidly evolving field. Resources are available at\nhttps://github.com/Zehong-Wang/Awesome-Foundation-Models-on-Graphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15116v1",
    "published": "2025-05-21T05:08:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15115v1",
    "title": "Sarkisov program for algebraically integrable and threefold foliations",
    "authors": [
      "Yifei Chen",
      "Jihao Liu",
      "Yanze Wang"
    ],
    "abstract": "By applying the theory of the minimal model program for adjoint foliated\nstructures, we establish the Sarkisov program for algebraically integrable\nfoliations on klt varieties: any two Mori fiber spaces of such structure are\nconnected by a sequence of Sarkisov links. Combining with a result of R.\nMascharak, we establish the Sarkisov program for foliations in dimension at\nmost $3$ with mild singularities. Log version and adjoint foliated version of\nthe aformentioned Sarkisov programs are also established.",
    "pdf_url": "http://arxiv.org/pdf/2505.15115v1",
    "published": "2025-05-21T05:07:44+00:00",
    "categories": [
      "math.AG",
      "14E30, 37F75"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15114v1",
    "title": "Adaptive Inertial Method",
    "authors": [
      "Han Long",
      "Bingsheng He",
      "Yinyu Ye",
      "Jiheng Zhang"
    ],
    "abstract": "In this paper, we introduce the Adaptive Inertial Method (AIM), a novel\nframework for accelerated first-order methods through a customizable inertial\nterm. We provide a rigorous convergence analysis establishing a global\nconvergence rate of O(1/k) under mild conditions, requiring only convexity and\nlocal Lipschitz differentiability of the objective function. Our method enables\nadaptive parameter selection for the inertial term without manual tuning.\nFurthermore, we derive the particular form of the inertial term that transforms\nAIM into a new Quasi-Newton method. Notably, under specific circumstances, AIM\ncoincides with the regularized Newton method, achieving an accelerated rate of\nO(1/k^2) without Hessian inversions. Through extensive numerical experiments,\nwe demonstrate that AIM exhibits superior performance across diverse\noptimization problems, highlighting its practical effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.15114v1",
    "published": "2025-05-21T05:06:52+00:00",
    "categories": [
      "math.OC",
      "90C25, 90C30, 90C53, 65K10"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15113v1",
    "title": "Experimental realization of wide-mode-area slow light modes in valley photonic crystal heterostructure waveguides",
    "authors": [
      "Chengkun Zhang",
      "Guangtai Lu",
      "Nattujuks Pholsen",
      "Yasutomo Ota",
      "Satoshi Iwamoto"
    ],
    "abstract": "We experimentally realized wide-mode-area slow-light modes in valley photonic\ncrystals (VPhCs) heterostructure waveguides. The waveguides are fabricated on a\nsilicon slab by inserting gapless photonic graphene layers with varying widths\nand modifying the unit cell spacing near the domain walls. By reducing the\nspacing between unit cells at the domain boundaries, slow-light guided modes\nare achieved in VPhCs heterostructure waveguides. The presence of\nwide-mode-area modes is verified by observing the radiation in light\npropagation of leaky guided modes above the light line. To characterize guided\nmodes below the light line, we introduce air-slot terminations to induce\nout-of-plane scattering and measure intensity profiles. The results show that\nthe mode widths are tunable for both fast-light and slow-light modes in VPhCs\nheterostructure waveguides by adjusting the number of photonic graphene layers.\nThe ability to support wide-mode-area slow-light modes in VPhC heterostructures\noffers promising opportunities for the development of high-power, on-chip\nphotonic integrated devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15113v1",
    "published": "2025-05-21T05:06:41+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.15112v1",
    "title": "Parallel Scan on Ascend AI Accelerators",
    "authors": [
      "Bart≈Çomiej Wr√≥blewski",
      "Gioele Gottardo",
      "Anastasios Zouzias"
    ],
    "abstract": "We design and implement parallel prefix sum (scan) algorithms using Ascend AI\naccelerators. Ascend accelerators feature specialized computing units - the\ncube units for efficient matrix multiplication and the vector units for\noptimized vector operations. A key feature of the proposed scan algorithms is\ntheir extensive use of matrix multiplications and accumulations enabled by the\ncube unit. To showcase the effectiveness of these algorithms, we also implement\nand evaluate several scan-based operators commonly used in AI workloads,\nincluding sorting, tensor masking, and top-$k$ / top-$p$ sampling.\n  Our single-core results demonstrate substantial performance improvements,\nwith speedups ranging from $5\\times$ to $9.6\\times$ compared to vector-only\nimplementations for sufficiently large input lengths. Additionally, we present\na multi-core scan algorithm that fully utilizes both the cube and vector units\nof Ascend, reaching up to 37.5% of the theoretical memory bandwidth.\nFurthermore, our radix sort implementation, which utilizes matrix\nmultiplications for its parallel splits, showcases the potential of matrix\nengines to enhance complex operations, offering up to $3.3\\times$ speedup over\nthe baseline.",
    "pdf_url": "http://arxiv.org/pdf/2505.15112v1",
    "published": "2025-05-21T05:06:26+00:00",
    "categories": [
      "cs.DC",
      "cs.DS"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15111v1",
    "title": "iPad: Iterative Proposal-centric End-to-End Autonomous Driving",
    "authors": [
      "Ke Guo",
      "Haochen Liu",
      "Xiaojun Wu",
      "Jia Pan",
      "Chen Lv"
    ],
    "abstract": "End-to-end (E2E) autonomous driving systems offer a promising alternative to\ntraditional modular pipelines by reducing information loss and error\naccumulation, with significant potential to enhance both mobility and safety.\nHowever, most existing E2E approaches directly generate plans based on dense\nbird's-eye view (BEV) grid features, leading to inefficiency and limited\nplanning awareness. To address these limitations, we propose iterative\nProposal-centric autonomous driving (iPad), a novel framework that places\nproposals - a set of candidate future plans - at the center of feature\nextraction and auxiliary tasks. Central to iPad is ProFormer, a BEV encoder\nthat iteratively refines proposals and their associated features through\nproposal-anchored attention, effectively fusing multi-view image data.\nAdditionally, we introduce two lightweight, proposal-centric auxiliary tasks -\nmapping and prediction - that improve planning quality with minimal\ncomputational overhead. Extensive experiments on the NAVSIM and CARLA\nBench2Drive benchmarks demonstrate that iPad achieves state-of-the-art\nperformance while being significantly more efficient than prior leading\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15111v1",
    "published": "2025-05-21T05:05:38+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15110v1",
    "title": "RoT: Enhancing Table Reasoning with Iterative Row-Wise Traversals",
    "authors": [
      "Xuanliang Zhang",
      "Dingzirui Wang",
      "Keyan Xu",
      "Qingfu Zhu",
      "Wanxiang Che"
    ],
    "abstract": "The table reasoning task, crucial for efficient data acquisition, aims to\nanswer questions based on the given table. Recently, reasoning large language\nmodels (RLLMs) with Long Chain-of-Thought (Long CoT) significantly enhance\nreasoning capabilities, leading to brilliant performance on table reasoning.\nHowever, Long CoT suffers from high cost for training and exhibits low\nreliability due to table content hallucinations. Therefore, we propose\nRow-of-Thought (RoT), which performs iteratively row-wise table traversal,\nallowing for reasoning extension and reflection-based refinement at each\ntraversal. Scaling reasoning length by row-wise traversal and leveraging\nreflection capabilities of LLMs, RoT is training-free. The sequential traversal\nencourages greater attention to the table, thus reducing hallucinations.\nExperiments show that RoT, using non-reasoning models, outperforms RLLMs by an\naverage of 4.3%, and achieves state-of-the-art results on WikiTableQuestions\nand TableBench with comparable models, proving its effectiveness. Also, RoT\noutperforms Long CoT with fewer reasoning tokens, indicating higher efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.15110v1",
    "published": "2025-05-21T05:03:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15109v1",
    "title": "Comparing Parameterizations and Objective Functions for Maximizing the Volume of Zonotopic Invariant Sets",
    "authors": [
      "Chenliang Zhou",
      "Heejin Ahn",
      "Ian M. Mitchell"
    ],
    "abstract": "In formal safety verification, many proposed algorithms use parametric set\nrepresentations and convert the computation of the relevant sets into an\noptimization problem; consequently, the choice of parameterization and\nobjective function have a significant impact on the efficiency and accuracy of\nthe resulting computation. In particular, recent papers have explored the use\nof zonotope set representations for various types of invariant sets. In this\npaper we collect two zonotope parameterizations that are numerically\nwell-behaved and demonstrate that the volume of the corresponding zonotopes is\nlog-concave in the parameters. We then experimentally explore the use of these\ntwo parameterizations in an algorithm for computing the maximum volume zonotope\ninvariant under affine dynamics within a specified box constraint over a finite\nhorizon. The true volume of the zonotopes is used as an objective function,\nalong with two alternative heuristics that are faster to compute. We conclude\nthat the heuristics are much faster in practice, although the relative quality\nof their results declines as the dimension of the problem increases; however,\nour conclusions are only preliminary due to so-far limited availability of\ncompute resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.15109v1",
    "published": "2025-05-21T05:02:28+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15108v1",
    "title": "A Risk Taxonomy for Evaluating AI-Powered Psychotherapy Agents",
    "authors": [
      "Ian Steenstra",
      "Timothy W. Bickmore"
    ],
    "abstract": "The proliferation of Large Language Models (LLMs) and Intelligent Virtual\nAgents acting as psychotherapists presents significant opportunities for\nexpanding mental healthcare access. However, their deployment has also been\nlinked to serious adverse outcomes, including user harm and suicide,\nfacilitated by a lack of standardized evaluation methodologies capable of\ncapturing the nuanced risks of therapeutic interaction. Current evaluation\ntechniques lack the sensitivity to detect subtle changes in patient cognition\nand behavior during therapy sessions that may lead to subsequent\ndecompensation. We introduce a novel risk taxonomy specifically designed for\nthe systematic evaluation of conversational AI psychotherapists. Developed\nthrough an iterative process including review of the psychotherapy risk\nliterature, qualitative interviews with clinical and legal experts, and\nalignment with established clinical criteria (e.g., DSM-5) and existing\nassessment tools (e.g., NEQ, UE-ATR), the taxonomy aims to provide a structured\napproach to identifying and assessing user/patient harms. We provide a\nhigh-level overview of this taxonomy, detailing its grounding, and discuss\npotential use cases. We discuss two use cases in detail: monitoring cognitive\nmodel-based risk factors during a counseling conversation to detect unsafe\ndeviations, in both human-AI counseling sessions and in automated benchmarking\nof AI psychotherapists with simulated patients. The proposed taxonomy offers a\nfoundational step towards establishing safer and more responsible innovation in\nthe domain of AI-driven mental health support.",
    "pdf_url": "http://arxiv.org/pdf/2505.15108v1",
    "published": "2025-05-21T05:01:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15107v2",
    "title": "StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization",
    "authors": [
      "Ziliang Wang",
      "Xuhui Zheng",
      "Kang An",
      "Cijun Ouyang",
      "Jialu Cai",
      "Yuhang Wang",
      "Yichao Wu"
    ],
    "abstract": "Efficient multi-hop reasoning requires Large Language Models (LLMs) based\nagents to acquire high-value external knowledge iteratively. Previous work has\nexplored reinforcement learning (RL) to train LLMs to perform search-based\ndocument retrieval, achieving notable improvements in QA performance, but\nunderperform on complex, multi-hop QA resulting from the sparse rewards from\nglobal signal only. To address this gap in existing research, we introduce\nStepSearch, a framework for search LLMs that trained with step-wise proximal\npolicy optimization method. It consists of richer and more detailed\nintermediate search rewards and token-level process supervision based on\ninformation gain and redundancy penalties to better guide each search step. We\nconstructed a fine-grained question-answering dataset containing\nsub-question-level search trajectories based on open source datasets through a\nset of data pipeline method. On standard multi-hop QA benchmarks, it\nsignificantly outperforms global-reward baselines, achieving 11.2% and 4.2%\nabsolute improvements for 3B and 7B models over various search with RL\nbaselines using only 19k training data, demonstrating the effectiveness of\nfine-grained, stepwise supervision in optimizing deep search LLMs. Our code\nwill be released on https://github.com/Zillwang/StepSearch.",
    "pdf_url": "http://arxiv.org/pdf/2505.15107v2",
    "published": "2025-05-21T05:01:31+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21514v1",
    "title": "SIMCOPILOT: Evaluating Large Language Models for Copilot-Style Code Generation",
    "authors": [
      "Mingchao Jiang",
      "Abhinav Jain",
      "Sophia Zorek",
      "Chris Jermaine"
    ],
    "abstract": "We introduce SIMCOPILOT, a benchmark that simulates the role of large\nlanguage models (LLMs) as interactive, \"copilot\"-style coding assistants.\nTargeting both completion (finishing incomplete methods or code blocks) and\ninfill tasks (filling missing segments within existing code), SIMCOPILOT\nprovides a comprehensive framework for evaluating LLM coding capabilities. The\nbenchmark comprises dedicated sub-benchmarks for Java (SIMCOPILOTJ) and Python\n(SIMCOPILOTP), covering diverse codebases varying in size and complexity. Our\nkey contributions include: (a) establishing a realistic, detailed evaluation\nenvironment to assess LLM utility in practical coding scenarios, and (b)\nproviding fine-grained analyses that address critical factors frequently\noverlooked by existing benchmarks, such as task-specific performance nuances,\ncontextual understanding across code segments, and sensitivity to variable\nscope. Evaluations conducted across domains-including algorithms, databases,\ncomputer vision, and neural networks-offer insights into model strengths and\nhighlight persistent challenges in maintaining logical consistency within\ncomplex dependency structures. Beyond benchmarking, our study sheds light on\nthe current limitations of LLM-driven code generation and underscores the\nongoing transition of LLMs from merely syntax-aware generators toward reliable,\nintelligent software development partners.",
    "pdf_url": "http://arxiv.org/pdf/2505.21514v1",
    "published": "2025-05-21T04:59:44+00:00",
    "categories": [
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15106v1",
    "title": "A coupled HDG discretization for the interaction between acoustic and elastic waves",
    "authors": [
      "Fernando Artaza-Covarrubias",
      "Tonatiuh S√°nchez-Vizuet",
      "Manuel Solano"
    ],
    "abstract": "We propose and analyze an HDG scheme for the Laplace-domain interaction\nbetween a transient acoustic wave and a bounded elastic solid embedded in an\nunbounded fluid medium. Two mixed variables (the stress tensor and the velocity\nof the acoustic wave) are included while the symmetry of the stress tensor is\nimposed weakly by considering the antisymmetric part of the strain tensor (the\nspin or vorticity tensor) as an additional unknown. The optimal convergence of\nthe method is demonstrated theoretically and numerical results confirming the\ntheoretical prediction are presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.15106v1",
    "published": "2025-05-21T04:59:43+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.comp-ph",
      "74J05, 65M60, 65M15, 65M12"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.11041v1",
    "title": "ChemHGNN: A Hierarchical Hypergraph Neural Network for Reaction Virtual Screening and Discovery",
    "authors": [
      "Xiaobao Huang",
      "Yihong Ma",
      "Anjali Gurajapu",
      "Jules Schleinitz",
      "Zhichun Guo",
      "Sarah E. Reisman",
      "Nitesh V. Chawla"
    ],
    "abstract": "Reaction virtual screening and discovery are fundamental challenges in\nchemistry and materials science, where traditional graph neural networks (GNNs)\nstruggle to model multi-reactant interactions. In this work, we propose\nChemHGNN, a hypergraph neural network (HGNN) framework that effectively\ncaptures high-order relationships in reaction networks. Unlike GNNs, which\nrequire constructing complete graphs for multi-reactant reactions, ChemHGNN\nnaturally models multi-reactant reactions through hyperedges, enabling more\nexpressive reaction representations. To address key challenges, such as\ncombinatorial explosion, model collapse, and chemically invalid negative\nsamples, we introduce a reaction center-aware negative sampling strategy (RCNS)\nand a hierarchical embedding approach combining molecule, reaction and\nhypergraph level features. Experiments on the USPTO dataset demonstrate that\nChemHGNN significantly outperforms HGNN and GNN baselines, particularly in\nlarge-scale settings, while maintaining interpretability and chemical\nplausibility. Our work establishes HGNNs as a superior alternative to GNNs for\nreaction virtual screening and discovery, offering a chemically informed\nframework for accelerating reaction discovery.",
    "pdf_url": "http://arxiv.org/pdf/2506.11041v1",
    "published": "2025-05-21T04:58:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15105v2",
    "title": "Mechanistic evaluation of Transformers and state space models",
    "authors": [
      "Aryaman Arora",
      "Neil Rathi",
      "Nikil Roashan Selvam",
      "R√≥bert Csord√°s",
      "Dan Jurafsky",
      "Christopher Potts"
    ],
    "abstract": "State space models (SSMs) for language modelling promise an efficient and\nperformant alternative to quadratic-attention Transformers, yet show variable\nperformance on recalling basic information from the context. While performance\non synthetic tasks like Associative Recall (AR) can point to this deficiency,\nbehavioural metrics provide little information as to why--on a mechanistic\nlevel--certain architectures fail and others succeed. To address this, we\nconduct experiments on AR and find that only Transformers and Based SSM models\nfully succeed at AR, with Mamba a close third, whereas the other SSMs (H3,\nHyena) fail. We then use causal interventions to explain why. We find that\nTransformers and Based learn to store key-value associations in-context using\ninduction heads. By contrast, the SSMs compute these associations only at the\nlast state, with only Mamba succeeding because of its short convolution\ncomponent. To extend and deepen these findings, we introduce Associative\nTreecall (ATR), a synthetic task similar to AR based on PCFG induction. ATR\nintroduces language-like hierarchical structure into the AR setting. We find\nthat all architectures learn the same mechanism as they did for AR, and the\nsame three models succeed at the task. These results reveal that architectures\nwith similar accuracy may still have substantive differences, motivating the\nadoption of mechanistic evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15105v2",
    "published": "2025-05-21T04:56:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15104v1",
    "title": "Joint Optimization of Primary and Secondary Transforms Using Rate-Distortion Optimized Transform Design",
    "authors": [
      "Darukeesan Pakiyarajah",
      "Eduardo Pavez",
      "Antonio Ortega",
      "Debargha Mukherjee",
      "Onur Guleryuz",
      "Keng-Shih Lu",
      "Kruthika Koratti Sivakumar"
    ],
    "abstract": "Data-dependent transforms are increasingly being incorporated into\nnext-generation video coding systems such as AVM, a codec under development by\nthe Alliance for Open Media (AOM), and VVC. To circumvent the computational\ncomplexities associated with implementing non-separable data-dependent\ntransforms, combinations of separable primary transforms and non-separable\nsecondary transforms have been studied and integrated into video coding\nstandards. These codecs often utilize rate-distortion optimized transforms\n(RDOT) to ensure that the new transforms complement existing transforms like\nthe DCT and the ADST. In this work, we propose an optimization framework for\njointly designing primary and secondary transforms from data through a\nrate-distortion optimized clustering. Primary transforms are assumed to follow\na path-graph model, while secondary transforms are non-separable. We\nempirically evaluate our proposed approach using AVM residual data and\ndemonstrate that 1) the joint clustering method achieves lower total RD cost in\nthe RDOT design framework, and 2) jointly optimized separable path-graph\ntransforms (SPGT) provide better coding efficiency compared to separable KLTs\nobtained from the same data.",
    "pdf_url": "http://arxiv.org/pdf/2505.15104v1",
    "published": "2025-05-21T04:55:40+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15103v2",
    "title": "Khan-GCL: Kolmogorov-Arnold Network Based Graph Contrastive Learning with Hard Negatives",
    "authors": [
      "Zihu Wang",
      "Boxun Xu",
      "Hejia Geng",
      "Peng Li"
    ],
    "abstract": "Graph contrastive learning (GCL) has demonstrated great promise for learning\ngeneralizable graph representations from unlabeled data. However, conventional\nGCL approaches face two critical limitations: (1) the restricted expressive\ncapacity of multilayer perceptron (MLP) based encoders, and (2) suboptimal\nnegative samples that either from random augmentations-failing to provide\neffective 'hard negatives'-or generated hard negatives without addressing the\nsemantic distinctions crucial for discriminating graph data. To this end, we\npropose Khan-GCL, a novel framework that integrates the Kolmogorov-Arnold\nNetwork (KAN) into the GCL encoder architecture, substantially enhancing its\nrepresentational capacity. Furthermore, we exploit the rich information\nembedded within KAN coefficient parameters to develop two novel critical\nfeature identification techniques that enable the generation of semantically\nmeaningful hard negative samples for each graph representation. These\nstrategically constructed hard negatives guide the encoder to learn more\ndiscriminative features by emphasizing critical semantic differences between\ngraphs. Extensive experiments demonstrate that our approach achieves\nstate-of-the-art performance compared to existing GCL methods across a variety\nof datasets and tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15103v2",
    "published": "2025-05-21T04:54:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15102v1",
    "title": "Modified crossed Dragone optical design of the LiteBIRD low-frequency telescope",
    "authors": [
      "Frederick Matsuda",
      "Shugo Oguri",
      "Yutaro Sekimoto",
      "Aritoki Suzuki",
      "Hayato Takakura",
      "Shingo Kashima"
    ],
    "abstract": "LiteBIRD is a JAXA-led international project aimed at measuring the cosmic\nmicrowave background (CMB) polarization with high sensitivity to detect\npolarization $B$ modes. This detection would provide evidence of inflation.\nLiteBIRD will observe the full sky for three years at the L2 Lagrange point of\nthe Earth-Sun system across 34-448 GHz, and is expected to launch in the\nJapanese fiscal year of 2032. The Low-Frequency Telescope (LFT) will observe in\nthe 34-161 GHz range implementing a modified crossed Dragone (MCD) reflective\noptical design optimized for high optical performance across a wide $18^{\\circ}\n\\times 9^{\\circ}$ field-of-view (FOV). In this paper, we report the LFT optical\ndesign details including its optimization and optical performance assessed\nusing optical simulations. The MCD design consists of a paraboloidal primary\nand a hyperboloidal secondary reflector with polynomial correction terms up to\n7th order, achieving Strehl ratios $\\ge 0.97$ at 161 GHz across the FOV. The\nMueller QU (UQ) cross-polarization response is $\\le -26.9$ dB at 34 GHz. The\nsimulated beam sizes are $< 78^{\\prime}$ at 34 GHz. The simulated sidelobe\nresponse for the direct and diffuse triple reflection sidelobes are estimated\nto be $< -57$ dB, and for the focused triple reflection sidelobe $< -37$ dB at\n34 GHz. The LFT optical design satisfies all the optical requirements and\nspecifications for the project, and is compatible with the LiteBIRD science\ngoals.",
    "pdf_url": "http://arxiv.org/pdf/2505.15102v1",
    "published": "2025-05-21T04:49:52+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15101v1",
    "title": "Cost-aware LLM-based Online Dataset Annotation",
    "authors": [
      "Eray Can Elumar",
      "Cem Tekin",
      "Osman Yagan"
    ],
    "abstract": "Recent advances in large language models (LLMs) have enabled automated\ndataset labeling with minimal human supervision. While majority voting across\nmultiple LLMs can improve label reliability by mitigating individual model\nbiases, it incurs high computational costs due to repeated querying. In this\nwork, we propose a novel online framework, Cost-aware Majority Voting (CaMVo),\nfor efficient and accurate LLM-based dataset annotation. CaMVo adaptively\nselects a subset of LLMs for each data instance based on contextual embeddings,\nbalancing confidence and cost without requiring pre-training or ground-truth\nlabels. Leveraging a LinUCB-based selection mechanism and a Bayesian estimator\nover confidence scores, CaMVo estimates a lower bound on labeling accuracy for\neach LLM and aggregates responses through weighted majority voting. Our\nempirical evaluation on the MMLU and IMDB Movie Review datasets demonstrates\nthat CaMVo achieves comparable or superior accuracy to full majority voting\nwhile significantly reducing labeling costs. This establishes CaMVo as a\npractical and robust solution for cost-efficient annotation in dynamic labeling\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15101v1",
    "published": "2025-05-21T04:49:44+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15100v1",
    "title": "Normalized solutions of nonlinear Dirac equations on noncompact metric graphs with localized nonlinearities",
    "authors": [
      "Zhentao He",
      "Chao Ji"
    ],
    "abstract": "In this paper, we study the following nonlinear Dirac equations (NLDE) on\nnoncompact metric graph $\\mathcal{G}$ with localized nonlinearities\n\\begin{equation} \\mathcal{D} u - \\omega u= a\\chi_{\\mathcal{K}}|u|^{p-2}u,\n\\end{equation} where $\\mathcal{D}$ is the Dirac operator on $\\mathcal{G}$, $u:\n\\mathcal{G} \\to \\mathbb{C}^2$, $\\omega\\in \\mathbb{R}$, $a > 0$,\n$\\chi_{\\mathcal{K}}$ is the characteristic function of the compact core\n$\\mathcal{K}$, and $p>2$. First, for $2<p<4$, we prove the existence of\nnormalized solutions to (NLDE) using a perturbation argument. Then, for $p \\geq\n4$, we establish the assumption under which normalized solutions to (NLDE)\nexist. Finally, we extend these results to the case $a<0$ and, for all $p>2$,\nprove the existence of normalized solutions to (NLDE) when $\\lambda = -mc^2$ is\nan eigenvalue of the operator $\\mathcal{D}$. In the Appendix, we study the\ninfluence of the parameters $m, c > 0$ on the existence of normalized solutions\nto (NLDE). To the best of our knowledge, this is the first study to investigate\nthe normalized solutions to (NLDE) on metric graphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15100v1",
    "published": "2025-05-21T04:46:36+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.11040v1",
    "title": "Large Language models for Time Series Analysis: Techniques, Applications, and Challenges",
    "authors": [
      "Feifei Shi",
      "Xueyan Yin",
      "Kang Wang",
      "Wanyu Tu",
      "Qifu Sun",
      "Huansheng Ning"
    ],
    "abstract": "Time series analysis is pivotal in domains like financial forecasting and\nbiomedical monitoring, yet traditional methods are constrained by limited\nnonlinear feature representation and long-term dependency capture. The\nemergence of Large Language Models (LLMs) offers transformative potential by\nleveraging their cross-modal knowledge integration and inherent attention\nmechanisms for time series analysis. However, the development of\ngeneral-purpose LLMs for time series from scratch is still hindered by data\ndiversity, annotation scarcity, and computational requirements. This paper\npresents a systematic review of pre-trained LLM-driven time series analysis,\nfocusing on enabling techniques, potential applications, and open challenges.\nFirst, it establishes an evolutionary roadmap of AI-driven time series\nanalysis, from the early machine learning era, through the emerging LLM-driven\nparadigm, to the development of native temporal foundation models. Second, it\norganizes and systematizes the technical landscape of LLM-driven time series\nanalysis from a workflow perspective, covering LLMs' input, optimization, and\nlightweight stages. Finally, it critically examines novel real-world\napplications and highlights key open challenges that can guide future research\nand innovation. The work not only provides valuable insights into current\nadvances but also outlines promising directions for future development. It\nserves as a foundational reference for both academic and industrial\nresearchers, paving the way for the development of more efficient,\ngeneralizable, and interpretable systems of LLM-driven time series analysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.11040v1",
    "published": "2025-05-21T04:45:11+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.ET"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15099v1",
    "title": "Runge-Kutta Methods and Stiff Order Conditions for Semilinear ODEs",
    "authors": [
      "Steven B. Roberts",
      "David Shirokoff",
      "Abhijit Biswas",
      "Benjamin Seibold"
    ],
    "abstract": "Classical convergence theory of Runge-Kutta methods assumes that the time\nstep is small relative to the Lipschitz constant of the ordinary differential\nequation (ODE). For stiff problems, that assumption is often violated, and a\nproblematic degradation in accuracy, known as order reduction, can arise. High\nstage order methods can avoid order reduction, but they must be fully implicit.\nFor linear problems, weaker stiff order conditions exist and are compatible\nwith computationally efficient methods, i.e., explicit or diagonally implicit.\nThis work develops a new theory of stiff order conditions and convergence for\nsemilinear ODEs, consisting of a stiff linear term and a non-stiff nonlinear\nterm. New semilinear order conditions are formulated in terms of orthogonality\nrelations enumerated by rooted trees. Novel, optimized diagonally implicit\nmethods are constructed that satisfy these semilinear conditions. Numerical\nresults demonstrate that for a broad class of relevant nonlinear test problems,\nthese new methods successfully mitigate order reduction and yield highly\naccurate numerical approximations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15099v1",
    "published": "2025-05-21T04:40:21+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65L05, 65L06, 65L20, 65L70, 65M20"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15098v1",
    "title": "Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation",
    "authors": [
      "Yihang Li",
      "Tianle Zhang",
      "Xuelong Wei",
      "Jiayi Li",
      "Lin Zhao",
      "Dongchi Huang",
      "Zhirui Fang",
      "Minhua Zheng",
      "Wenjun Dai",
      "Xiaodong He"
    ],
    "abstract": "Robot manipulation learning from human demonstrations offers a rapid means to\nacquire skills but often lacks generalization across diverse scenes and object\nplacements. This limitation hinders real-world applications, particularly in\ncomplex tasks requiring dexterous manipulation. Vision-Language-Action (VLA)\nparadigm leverages large-scale data to enhance generalization. However, due to\ndata scarcity, VLA's performance remains limited. In this work, we introduce\nObject-Focus Actor (OFA), a novel, data-efficient approach for generalized\ndexterous manipulation. OFA exploits the consistent end trajectories observed\nin dexterous manipulation tasks, allowing for efficient policy training. Our\nmethod employs a hierarchical pipeline: object perception and pose estimation,\npre-manipulation pose arrival and OFA policy execution. This process ensures\nthat the manipulation is focused and efficient, even in varied backgrounds and\npositional layout. Comprehensive real-world experiments across seven tasks\ndemonstrate that OFA significantly outperforms baseline methods in both\npositional and background generalization tests. Notably, OFA achieves robust\nperformance with only 10 demonstrations, highlighting its data efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.15098v1",
    "published": "2025-05-21T04:37:56+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15097v1",
    "title": "Research on Core Loss of Direct-drive 75kW Tidal Current Generator Using Machine Learning and Multi-objective Optimization Algorithms",
    "authors": [
      "Shuai Zu",
      "Wanqiang Zhu",
      "Fuli Zhang",
      "Chi Xiao",
      "Xiao Zhang",
      "Yixiao Li",
      "Xinze Wen",
      "Yingying Qiao",
      "Junyi Xu"
    ],
    "abstract": "This paper presents a classification of generator excitation waveforms using\nprincipal component analysis (PCA) and machine learning models, including\nlogistic regression, random forest, and gradient boosting decision trees\n(GBDT). Building upon the traditional Steinmetz equation, a temperature\ncorrection term is introduced. Through nonlinear regression and least squares\nparameter fitting, a novel temperature correction equation is proposed, which\nsignificantly reduces the prediction error for core losses under\nhigh-temperature conditions. The average relative error is decreased to 16.03%,\nthereby markedly enhancing the accuracy. Using GBDT and random forest\nregression models, the independent and combined effects of temperature,\nexcitation waveforms, and magnetic materials on core loss are analyzed. The\nresults indicate that the excitation waveform has the most significant impact,\nfollowed by temperature, while the magnetic core material exhibits the least\ninfluence. The optimal combination for minimizing core loss is identified,\nachieving a core loss value of 35,310.9988 under the specified conditions. A\ndata-driven predictive model for core loss is developed, demonstrating\nexcellent performance with an R*R value of 0.9703 through machine learning\nregression analysis, indicating high prediction accuracy and broad\napplicability. Furthermore, a multi-objective optimization model considering\nboth core loss and transmission magnetic energy is proposed. Genetic algorithms\nare employed for optimization, resulting in an optimal design scheme that\nminimizes core loss and maximizes transmission magnetic energy. Based on this\nmodel, the magnetic core compensation structure of a direct-drive 75kW tidal\nenergy generator is optimized in practical applications, yielding satisfactory\nresults.",
    "pdf_url": "http://arxiv.org/pdf/2505.15097v1",
    "published": "2025-05-21T04:35:21+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15096v1",
    "title": "Dynamical model for black hole to white hole transitions",
    "authors": [
      "Samantha Hergott",
      "Viqar Husain",
      "Saeed Rastgoo"
    ],
    "abstract": "We present an asymptotically flat spherically symmetric non-singular metric\nthat describes gravitational collapse and matter bounce with transient black\nhole and white hole regions. The metric provides a dynamical counterpart to\nproposed static non-singular black holes, and a phenomenological model for\npossible black hole to white hole transitions in quantum gravity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15096v1",
    "published": "2025-05-21T04:34:33+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.15095v1",
    "title": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English",
    "authors": [
      "Ishmanbir Singh",
      "Dipankar Srirag",
      "Aditya Joshi"
    ],
    "abstract": "Sarcasm is a challenge to sentiment analysis because of the incongruity\nbetween stated and implied sentiment. The challenge is exacerbated when the\nimplication may be relevant to a specific country or geographical region.\nPragmatic metacognitive prompting (PMP) is a cognition-inspired technique that\nhas been used for pragmatic reasoning. In this paper, we harness PMP for\nexplainable sarcasm detection for Australian and Indian English, alongside a\nbenchmark dataset for standard English. We manually add sarcasm explanations to\nan existing sarcasm-labeled dataset for Australian and Indian English called\nBESSTIE, and compare the performance for explainable sarcasm detection for them\nwith FLUTE, a standard English dataset containing sarcasm explanations. Our\napproach utilising PMP when evaluated on two open-weight LLMs (GEMMA and LLAMA)\nachieves statistically significant performance improvement across all tasks and\ndatasets when compared with four alternative prompting strategies. We also find\nthat alternative techniques such as agentic prompting mitigate context-related\nfailures by enabling external knowledge retrieval. The focused contribution of\nour work is utilising PMP in generating sarcasm explanations for varieties of\nEnglish.",
    "pdf_url": "http://arxiv.org/pdf/2505.15095v1",
    "published": "2025-05-21T04:34:22+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15094v1",
    "title": "SciCUEval: A Comprehensive Dataset for Evaluating Scientific Context Understanding in Large Language Models",
    "authors": [
      "Jing Yu",
      "Yuqi Tang",
      "Kehua Feng",
      "Mingyang Rao",
      "Lei Liang",
      "Zhiqiang Zhang",
      "Mengshu Sun",
      "Wen Zhang",
      "Qiang Zhang",
      "Keyan Ding",
      "Huajun Chen"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive capabilities in contextual\nunderstanding and reasoning. However, evaluating their performance across\ndiverse scientific domains remains underexplored, as existing benchmarks\nprimarily focus on general domains and fail to capture the intricate complexity\nof scientific data. To bridge this gap, we construct SciCUEval, a comprehensive\nbenchmark dataset tailored to assess the scientific context understanding\ncapability of LLMs. It comprises ten domain-specific sub-datasets spanning\nbiology, chemistry, physics, biomedicine, and materials science, integrating\ndiverse data modalities including structured tables, knowledge graphs, and\nunstructured texts. SciCUEval systematically evaluates four core competencies:\nRelevant information identification, Information-absence detection,\nMulti-source information integration, and Context-aware inference, through a\nvariety of question formats. We conduct extensive evaluations of\nstate-of-the-art LLMs on SciCUEval, providing a fine-grained analysis of their\nstrengths and limitations in scientific context understanding, and offering\nvaluable insights for the future development of scientific-domain LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15094v1",
    "published": "2025-05-21T04:33:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15859v1",
    "title": "AutoData: A Multi-Agent System for Open Web Data Collection",
    "authors": [
      "Tianyi Ma",
      "Yiyue Qian",
      "Zheyuan Zhang",
      "Zehong Wang",
      "Xiaoye Qian",
      "Feifan Bai",
      "Yifan Ding",
      "Xuwei Luo",
      "Shinan Zhang",
      "Keerthiram Murugesan",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "The exponential growth of data-driven systems and AI technologies has\nintensified the demand for high-quality web-sourced datasets. While existing\ndatasets have proven valuable, conventional web data collection approaches face\nsignificant limitations in terms of human effort and scalability. Current\ndata-collecting solutions fall into two categories: wrapper-based methods that\nstruggle with adaptability and reproducibility, and large language model\n(LLM)-based approaches that incur substantial computational and financial\ncosts. To address these challenges, we propose AutoData, a novel multi-agent\nsystem for Automated web Data collection, that requires minimal human\nintervention, i.e., only necessitating a natural language instruction\nspecifying the desired dataset. In addition, AutoData is designed with a robust\nmulti-agent architecture, featuring a novel oriented message hypergraph\ncoordinated by a central task manager, to efficiently organize agents across\nresearch and development squads. Besides, we introduce a novel hypergraph cache\nsystem to advance the multi-agent collaboration process that enables efficient\nautomated data collection and mitigates the token cost issues prevalent in\nexisting LLM-based systems. Moreover, we introduce Instruct2DS, a new benchmark\ndataset supporting live data collection from web sources across three domains:\nacademic, finance, and sports. Comprehensive evaluations over Instruct2DS and\nthree existing benchmark datasets demonstrate AutoData's superior performance\ncompared to baseline methods. Case studies on challenging tasks such as picture\nbook collection and paper extraction from surveys further validate its\napplicability. Our source code and dataset are available at\nhttps://github.com/GraphResearcher/AutoData.",
    "pdf_url": "http://arxiv.org/pdf/2505.15859v1",
    "published": "2025-05-21T04:32:35+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15093v1",
    "title": "Steering Generative Models with Experimental Data for Protein Fitness Optimization",
    "authors": [
      "Jason Yang",
      "Wenda Chu",
      "Daniel Khalil",
      "Raul Astudillo",
      "Bruce J. Wittmann",
      "Frances H. Arnold",
      "Yisong Yue"
    ],
    "abstract": "Protein fitness optimization involves finding a protein sequence that\nmaximizes desired quantitative properties in a combinatorially large design\nspace of possible sequences. Recent developments in steering protein generative\nmodels (e.g diffusion models, language models) offer a promising approach.\nHowever, by and large, past studies have optimized surrogate rewards and/or\nutilized large amounts of labeled data for steering, making it unclear how well\nexisting methods perform and compare to each other in real-world optimization\ncampaigns where fitness is measured by low-throughput wet-lab assays. In this\nstudy, we explore fitness optimization using small amounts (hundreds) of\nlabeled sequence-fitness pairs and comprehensively evaluate strategies such as\nclassifier guidance and posterior sampling for guiding generation from\ndifferent discrete diffusion models of protein sequences. We also demonstrate\nhow guidance can be integrated into adaptive sequence selection akin to\nThompson sampling in Bayesian optimization, showing that plug-and-play guidance\nstrategies offer advantages compared to alternatives such as reinforcement\nlearning with protein language models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15093v1",
    "published": "2025-05-21T04:30:48+00:00",
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15092v3",
    "title": "The Robin heat kernel and its expansion via Robin eigenfunctions",
    "authors": [
      "Yifeng Meng",
      "Kui Wang"
    ],
    "abstract": "We prove the existence and uniqueness of the Robin heat kernel on compact\nRiemannian manifolds with smooth boundary for Robin parameter\n$\\alpha\\in\\mathbb{R}$, expressed as a spectral expansion in terms of Robin\neigenvalues and eigenfunctions. For the non-negative parameter regime\n($\\alpha\\ge 0$), we present a direct proof based on trace Sobolev inequalities\nand eigenfunction estimates. The case of negative parameters ($\\alpha<0$)\nrequires novel analytical techniques to handle $L^\\infty$ estimates of Robin\neigenfunctions, addressing challenges not present in the non-negative case. Our\nresult extends the the classical Dirichlet and Neumann cases to the\nless-studied negative parameter regime.",
    "pdf_url": "http://arxiv.org/pdf/2505.15092v3",
    "published": "2025-05-21T04:29:39+00:00",
    "categories": [
      "math.AP",
      "35P15, 53C21"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.18197v1",
    "title": "A Novel Benchmark and Dataset for Efficient 3D Gaussian Splatting with Gaussian Point Cloud Compression",
    "authors": [
      "Kangli Wang",
      "Shihao Li",
      "Qianxi Yi",
      "Wei Gao"
    ],
    "abstract": "Recently, immersive media and autonomous driving applications have\nsignificantly advanced through 3D Gaussian Splatting (3DGS), which offers\nhigh-fidelity rendering and computational efficiency. Despite these advantages,\n3DGS as a display-oriented representation requires substantial storage due to\nits numerous Gaussian attributes. Current compression methods have shown\npromising results but typically neglect the compression of Gaussian spatial\npositions, creating unnecessary bitstream overhead. We conceptualize Gaussian\nprimitives as point clouds and propose leveraging point cloud compression\ntechniques for more effective storage. AI-based point cloud compression\ndemonstrates superior performance and faster inference compared to MPEG\nGeometry-based Point Cloud Compression (G-PCC). However, direct application of\nexisting models to Gaussian compression may yield suboptimal results, as\nGaussian point clouds tend to exhibit globally sparse yet locally dense\ngeometric distributions that differ from conventional point cloud\ncharacteristics. To address these challenges, we introduce GausPcgc for\nGaussian point cloud geometry compression along with a specialized training\ndataset GausPcc-1K. Our work pioneers the integration of AI-based point cloud\ncompression into Gaussian compression pipelines, achieving superior compression\nratios. The framework complements existing Gaussian compression methods while\ndelivering significant performance improvements. All code, data, and\npre-trained models will be publicly released to facilitate further research\nadvances in this field.",
    "pdf_url": "http://arxiv.org/pdf/2505.18197v1",
    "published": "2025-05-21T04:28:08+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17097v2",
    "title": "CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention",
    "authors": [
      "Yanshu Li",
      "Jianjiang Yang",
      "Ziteng Yang",
      "Bozheng Li",
      "Hongyang He",
      "Zhengtao Yao",
      "Ligong Han",
      "Yingjie Victor Chen",
      "Songlin Fei",
      "Dongfang Liu",
      "Ruixiang Tang"
    ],
    "abstract": "Multimodal in-context learning (ICL) is emerging as a key capability that\nenables large vision-language models (LVLMs) to adapt to novel tasks without\nparameter updates, expanding their utility across various real-world\napplications. However, ICL remains unstable, even with well-matched in-context\ndemonstrations (ICDs), suggesting that LVLMs struggle to fully utilize the\nprovided context. While existing efforts focus on prompt engineering or\npost-hoc logit calibration, we instead investigate the underlying attention\ndynamics to overcome LVLMs' inherent limitations. We identify two critical\ndeficits in their self-attention that impair effective ICL. To bridge the gap,\nwe propose \\textbf{Context-Aware Modulated Attention} (CAMA), a plug-and-play\nand training-free method that dynamically modulates LVLM's attention logits\nbased on the input in-context sequence. CAMA employs a two-stage attention\nmodulation to address both identified deficits, enhancing the focus on\nsemantically significant tokens, particularly visual ones. Across four LVLMs\nand seven benchmarks, CAMA consistently outperforms vanilla models and\nbaselines, demonstrating great effectiveness and generalization. It can also\nactivate the desired effects of prompt engineering methods and remains robust\nunder diverse sequence configurations. Thus, CAMA paves the way for deeper\nexplorations of attention dynamics to advance multimodal reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.17097v2",
    "published": "2025-05-21T04:25:23+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15091v3",
    "title": "ThinkRec: Thinking-based recommendation via LLM",
    "authors": [
      "Qihang Yu",
      "Kairui Fu",
      "Shengyu Zhang",
      "Zheqi Lv",
      "Fan Wu",
      "Fei Wu"
    ],
    "abstract": "Recent advances in large language models (LLMs) have enabled more\nsemantic-aware recommendations through natural language generation. Existing\nLLM for recommendation (LLM4Rec) methods mostly operate in a System 1-like\nmanner, relying on superficial features to match similar items based on click\nhistory, rather than reasoning through deeper behavioral logic. This often\nleads to superficial and erroneous recommendations. Motivated by this, we\npropose ThinkRec, a thinking-based framework that shifts LLM4Rec from System 1\nto System 2 (rational system). Technically, ThinkRec introduces a thinking\nactivation mechanism that augments item metadata with keyword summarization and\ninjects synthetic reasoning traces, guiding the model to form interpretable\nreasoning chains that consist of analyzing interaction histories, identifying\nuser preferences, and making decisions based on target items. On top of this,\nwe propose an instance-wise expert fusion mechanism to reduce the reasoning\ndifficulty. By dynamically assigning weights to expert models based on users'\nlatent features, ThinkRec adapts its reasoning path to individual users,\nthereby enhancing precision and personalization. Extensive experiments on\nreal-world datasets demonstrate that ThinkRec significantly improves the\naccuracy and interpretability of recommendations. Our implementations are\navailable in anonymous Github: https://github.com/Yu-Qi-hang/ThinkRec.",
    "pdf_url": "http://arxiv.org/pdf/2505.15091v3",
    "published": "2025-05-21T04:25:18+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00021v1",
    "title": "Buoyant Choreographies: Harmonies of Light, Sound, and Human Connection",
    "authors": [
      "Dennis Hong",
      "Yusuke Tanaka"
    ],
    "abstract": "BALLU, the Buoyancy Assisted Lightweight Legged Unit, is a unique legged\nrobot with a helium balloon body and articulated legs \\fig{fig:fig1}. Since it\nis buoyant-assisted, BALLU is inherently stable, never falling over, while\nbeing able to walk, jump, and interact safely with people. The BALLU art\ninstallation builds on this playful platform to express fluidity, serendipity,\nand connection. It transforms robotic motion into an artistic visual and\nacoustic experience, merging technology and creativity into a dynamic,\ninteractive display. This exhibition intentionally does not have a physical\nboundary for the robots, emphasizing the harmony of the technologies and\nhumanity. This work significantly extends BALLU's existing permanent exhibition\nin the Seoul Robotics & Artificial Intelligence Museum, Seoul RAIM\n(https://anc.masilwide.com/2261), emphasizing the harmony of robotics and\nhumanity through visual, acoustic, and physical expression.",
    "pdf_url": "http://arxiv.org/pdf/2506.00021v1",
    "published": "2025-05-21T04:24:41+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15090v1",
    "title": "DeFTX: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer",
    "authors": [
      "Sona Elza Simon",
      "Preethi Jyothi"
    ],
    "abstract": "Effective cross-lingual transfer remains a critical challenge in scaling the\nbenefits of large language models from high-resource to low-resource languages.\nTowards this goal, prior studies have explored many approaches to combine task\nknowledge from task-specific data in a (high-resource) source language and\nlanguage knowledge from unlabeled text in a (low-resource) target language. One\nnotable approach proposed composable sparse fine-tuning (SFT) for cross-lingual\ntransfer that learns task-specific and language-specific sparse masks to select\na subset of the pretrained model's parameters that are further fine-tuned.\nThese sparse fine-tuned vectors (SFTs) are subsequently composed with the\npretrained model to facilitate zero-shot cross-lingual transfer to a task in a\ntarget language, using only task-specific data from a source language. These\nsparse masks for SFTs were identified using a simple magnitude-based pruning.\nIn our work, we introduce DeFT-X, a novel composable SFT approach that denoises\nthe weight matrices of a pretrained model before magnitude pruning using\nsingular value decomposition, thus yielding more robust SFTs. We evaluate\nDeFT-X on a diverse set of extremely low-resource languages for sentiment\nclassification (NusaX) and natural language inference (AmericasNLI) and\ndemonstrate that it performs at par or outperforms SFT and other prominent\ncross-lingual transfer baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.15090v1",
    "published": "2025-05-21T04:20:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15089v1",
    "title": "Development of Digital Twin Environment through Integration of Commercial Metaverse Platform and IoT Sensors of Smart Building",
    "authors": [
      "Yusuke Masubuchi",
      "Takefumi Hiraki",
      "Yuichi Hiroi",
      "Masanori Ibara",
      "Kazuki Matsutani",
      "Megumi Zaizen",
      "Junya Morita"
    ],
    "abstract": "The digital transformation of smart cities and workplaces requires effective\nintegration of physical and cyber spaces, yet existing digital twin solutions\nremain limited in supporting real-time, multi-user collaboration. While\nmetaverse platforms enable shared virtual experiences, they have not supported\ncomprehensive integration of IoT sensors on physical spaces, especially for\nlarge-scale smart architectural environments. This paper presents a digital\ntwin environment that integrates Kajima Corp.'s smart building facility \"The\nGEAR\" in Singapore with a commercial metaverse platform Cluster. Our system\nconsists of three key components: a standardized IoT sensor platform, a\nreal-time data relay system, and an environmental data visualization framework.\nQuantitative end-to-end latency measurements confirm the feasibility of our\napproach for real-world applications in large architectural spaces. The\nproposed framework enables new forms of collaboration that transcend spatial\nconstraints, advancing the development of next-generation interactive\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15089v1",
    "published": "2025-05-21T04:20:08+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15088v1",
    "title": "Leveraging Large Language Models for Command Injection Vulnerability Analysis in Python: An Empirical Study on Popular Open-Source Projects",
    "authors": [
      "Yuxuan Wang",
      "Jingshu Chen",
      "Qingyang Wang"
    ],
    "abstract": "Command injection vulnerabilities are a significant security threat in\ndynamic languages like Python, particularly in widely used open-source projects\nwhere security issues can have extensive impact. With the proven effectiveness\nof Large Language Models(LLMs) in code-related tasks, such as testing,\nresearchers have explored their potential for vulnerabilities analysis. This\nstudy evaluates the potential of large language models (LLMs), such as GPT-4,\nas an alternative approach for automated testing for vulnerability detection.\nIn particular, LLMs have demonstrated advanced contextual understanding and\nadaptability, making them promising candidates for identifying nuanced security\nvulnerabilities within code. To evaluate this potential, we applied LLM-based\nanalysis to six high-profile GitHub projects-Django, Flask, TensorFlow,\nScikit-learn, PyTorch, and Langchain-each with over 50,000 stars and extensive\nadoption across software development and academic research. Our analysis\nassesses both the strengths and limitations of LLMs in detecting command\ninjection vulnerabilities, evaluating factors such as detection accuracy,\nefficiency, and practical integration into development workflows. In addition,\nwe provide a comparative analysis of different LLM tools to identify those most\nsuitable for security applications. Our findings offer guidance for developers\nand security researchers on leveraging LLMs as innovative and automated\napproaches to enhance software security.",
    "pdf_url": "http://arxiv.org/pdf/2505.15088v1",
    "published": "2025-05-21T04:14:35+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15087v1",
    "title": "HopWeaver: Synthesizing Authentic Multi-Hop Questions Across Text Corpora",
    "authors": [
      "Zhiyu Shen",
      "Jiyuan Liu",
      "Yunhe Pang",
      "Yanghui Rao"
    ],
    "abstract": "Multi-Hop Question Answering (MHQA) is crucial for evaluating the model's\ncapability to integrate information from diverse sources. However, creating\nextensive and high-quality MHQA datasets is challenging: (i) manual annotation\nis expensive, and (ii) current synthesis methods often produce simplistic\nquestions or require extensive manual guidance. This paper introduces\nHopWeaver, the first automatic framework synthesizing authentic multi-hop\nquestions from unstructured text corpora without human intervention. HopWeaver\nsynthesizes two types of multi-hop questions (bridge and comparison) using an\ninnovative approach that identifies complementary documents across corpora. Its\ncoherent pipeline constructs authentic reasoning paths that integrate\ninformation across multiple documents, ensuring synthesized questions\nnecessitate authentic multi-hop reasoning. We further present a comprehensive\nsystem for evaluating synthesized multi-hop questions. Empirical evaluations\ndemonstrate that the synthesized questions achieve comparable or superior\nquality to human-annotated datasets at a lower cost. Our approach is valuable\nfor developing MHQA datasets in specialized domains with scarce annotated\nresources. The code for HopWeaver is publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.15087v1",
    "published": "2025-05-21T04:14:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15086v2",
    "title": "A Neural Network Approach to a Modified Quadratic Boost Multiport Resonant Converter for Electric Vehicle Chargers",
    "authors": [
      "V. Rajeswari",
      "Nalin Kant Mohanty"
    ],
    "abstract": "This topology can achieve a high step-up gain by utilizing a switched\ncapacitor and switched inductor-based VMC network arrangement.Furthermore, the\nproposed topology can achieve an output gain of approximately three times at a\nnominal duty ratio with reduced voltage and current stress across the switch,\nand enhance the maximum efficiency to 96.7",
    "pdf_url": "http://arxiv.org/pdf/2505.15086v2",
    "published": "2025-05-21T04:13:46+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15085v1",
    "title": "Orlicz-Schatten Factorizations for Non-Commutative Sobolev Embeddings",
    "authors": [
      "Emma Sulaver"
    ],
    "abstract": "We develop a framework for factorizing embeddings of non-commutative Sobolev\nspaces on quantum tori through newly defined Orlicz-Schatten sequence ideals.\nAfter introducing appropriate non-commutative Sobolev norms and Orlicz spectral\nconditions, we establish a summing operator characterization of the quantum\nLaplacian embedding. Our main results provide both existence and optimality of\nsuch factorization theorems, and highlight connections to operator ideal\ntheory. Applications to regularity of non-commutative PDEs and quantum\ninformation metrics are discussed, demonstrating the broad impact of these\nstructures in functional analysis and mathematical physics.",
    "pdf_url": "http://arxiv.org/pdf/2505.15085v1",
    "published": "2025-05-21T04:12:54+00:00",
    "categories": [
      "math.FA",
      "math.OA",
      "math.SP",
      "46L87, 46E35, 47B10"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15084v1",
    "title": "Imprints of Large-Scale Structures in the Anisotropies of the Cosmological Gravitational Wave Background",
    "authors": [
      "Rafael Bravo",
      "Walter Riquelme"
    ],
    "abstract": "We compute the cross-correlation between the anisotropies of the cosmological\ngravitational wave background (CGWB) and the galaxy density contrast. We show\nthat the cross-correlation is non-zero due to the {\\it late} integrated\nSachs-Wolfe (ISW) effect experienced by tensor modes. We study the detection\nprospects of the cross-correlation signal against cosmic variance (CV), and in\nthe light of incoming LSS and GW surveys, where we found that the signal under\ncertain conditions could be distinguishable from noise. In addition, by\nconsidering a CGWB sourced by scalar-induced gravitational waves, and the\ninclusion of a scale-dependent galaxy bias, we use the cross-correlation to\nforecast local primordial non-Gaussianity, where we find\n$\\sigma(f_\\text{NL}^\\text{loc})\\sim10$ for CV only and a LSST-like survey.\nMoreover, by combining the Fisher information of CGWB$\\times$LSS with LSS, we\nare able to improve the constraints by 4\\% compared to an LSS-only analysis.\nOur results imply that a cross-correlation between GW anisotropies and LSS can\nindeed come from a stochastic background of cosmological origin and could be\nused to distinguish it from an astrophysical one.",
    "pdf_url": "http://arxiv.org/pdf/2505.15084v1",
    "published": "2025-05-21T04:12:42+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15083v1",
    "title": "Robust Multi-Modal Forecasting: Integrating Static and Dynamic Features",
    "authors": [
      "Jeremy Qin"
    ],
    "abstract": "Time series forecasting plays a crucial role in various applications,\nparticularly in healthcare, where accurate predictions of future health\ntrajectories can significantly impact clinical decision-making. Ensuring\ntransparency and explainability of the models responsible for these tasks is\nessential for their adoption in critical settings. Recent work has explored a\ntop-down approach to bi-level transparency, focusing on understanding trends\nand properties of predicted time series using static features. In this work, we\nextend this framework by incorporating exogenous time series features alongside\nstatic features in a structured manner, while maintaining cohesive\ninterpretation. Our approach leverages the insights of trajectory comprehension\nto introduce an encoding mechanism for exogenous time series, where they are\ndecomposed into meaningful trends and properties, enabling the extraction of\ninterpretable patterns. Through experiments on several synthetic datasets, we\ndemonstrate that our approach remains predictive while preserving\ninterpretability and robustness. This work represents a step towards developing\nrobust, and generalized time series forecasting models. The code is available\nat https://github.com/jeremy-qin/TIMEVIEW",
    "pdf_url": "http://arxiv.org/pdf/2505.15083v1",
    "published": "2025-05-21T04:12:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15082v1",
    "title": "Shapes and orientations of massive halos in the statistically anisotropic universe",
    "authors": [
      "Shogo Masaki",
      "Yurino Mizuguchi",
      "Shohei Saga",
      "Shuichiro Yokoyama"
    ],
    "abstract": "We investigate how statistical anisotropy (SA) in matter distributions\naffects the shapes and orientations of cluster-sized halos, using cosmological\n$N$-body simulations that incorporate SA. While the three-dimensional halo\nshape parameters show little dependence on SA, we find that halo orientations\nare significantly influenced, with halos tending to align either perpendicular\nor parallel to the SA direction. This SA-induced alignment becomes more\nprominent for more massive halos. Our findings suggest that observational\nmeasurements of projected halo shapes, such as those derived from galaxy\ncluster-galaxy lensing, could provide a novel probe of SA in the universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.15082v1",
    "published": "2025-05-21T04:10:01+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.06302v1",
    "title": "Anti-interrupted sampling repeater jamming via linear canonical Wigner distribution lightweight LFM detection",
    "authors": [
      "Jia-Mian Li",
      "Bing-Zhao Li"
    ],
    "abstract": "Interrupted sampling repeater jamming (ISRJ) poses a serious threat to radar\ntarget detection. Traditional time-frequency (TF) domain anti-jamming methods\nare prone to TF aliasing in multi-component signal scenarios, and cannot\neffectively suppress ISRJ with energy close to the real target under low\nsignal-to-noise ratio (SNR) conditions. To address these challenges, this paper\nproposes an anti-jamming method based on generalized linear canonical Wigner\ndistribution (GLWD) line detection. By setting the parameters reasonably, the\nTF image of GLWD can have excellent TF resolution and energy concentration,\ngreatly improving the signal separation and SNR. Furthermore, in order to\nenhance the detection capability of the target LFM signal, the existing mobile\nline segment detection (M-LSD) is improved and the mobile long line segment\ndetection (M-LLSD) is proposed. M-LLSD can detect the target signal more easily\nand reduce the sensitivity to the jamming signal, so as to efficiently and\naccurately extract the TF position information of the target signal. Finally, a\nTF filter is constructed based on the mapping between GLWD and short-time\nFourier transform (STFT), performing filtering in the STFT domain to suppress\njamming. Simulations and experiments show that the method can effectively\nsuppress such difficult-to-distinguish jamming and is suitable for real-time\nradar anti-jamming with good robustness.",
    "pdf_url": "http://arxiv.org/pdf/2506.06302v1",
    "published": "2025-05-21T04:09:04+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15081v2",
    "title": "Meron Spin Textures in Momentum Space Spawning from Bound States in the Continuum",
    "authors": [
      "Lixi Rao",
      "Jiajun Wang",
      "Xinhao Wang",
      "Shunben Wu",
      "Xingqi Zhao",
      "Wenzhe Liu",
      "Rensheng Xie",
      "Yijie Shen",
      "Lei Shi",
      "Jian Zi"
    ],
    "abstract": "Topological spin textures, such as merons and skyrmions, have shown\nsignificance in both fundamental science and practical applications across\ndiverse physical systems. The optical skyrmionic textures in real space have\nbeen extensively explored, but which in momentum space are still rarely\nstudied. Here, we report the experimental generation of momentum-space meron\nspin textures via bound states in the continuum (BICs) in photonic crystal\nslabs. We show that under circularly polarized illumination, the momentum-space\nvortex topology of BICs can transform light with meron spin textures in\nmomentum space. These merons exhibit polarity-switchable configurations\ncontrolled by incident light polarization. We theoretically and experimentally\nverify the generation of momentum-space merons and demonstrate their\noperational flexibility across a broad spectral range. Our results establish a\nconnection between different momentum-space topologies and provide a robust and\ncompact platform for generating topological spin textures.",
    "pdf_url": "http://arxiv.org/pdf/2505.15081v2",
    "published": "2025-05-21T04:04:45+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.17096v2",
    "title": "TAGS: 3D Tumor-Adaptive Guidance for SAM",
    "authors": [
      "Sirui Li",
      "Linkai Peng",
      "Zheyuan Zhang",
      "Gorkem Durak",
      "Ulas Bagci"
    ],
    "abstract": "Foundation models (FMs) such as CLIP and SAM have recently shown great\npromise in image segmentation tasks, yet their adaptation to 3D medical\nimaging-particularly for pathology detection and segmentation-remains\nunderexplored. A critical challenge arises from the domain gap between natural\nimages and medical volumes: existing FMs, pre-trained on 2D data, struggle to\ncapture 3D anatomical context, limiting their utility in clinical applications\nlike tumor segmentation. To address this, we propose an adaptation framework\ncalled TAGS: Tumor Adaptive Guidance for SAM, which unlocks 2D FMs for 3D\nmedical tasks through multi-prompt fusion. By preserving most of the\npre-trained weights, our approach enhances SAM's spatial feature extraction\nusing CLIP's semantic insights and anatomy-specific prompts. Extensive\nexperiments on three open-source tumor segmentation datasets prove that our\nmodel surpasses the state-of-the-art medical image segmentation models (+46.88%\nover nnUNet), interactive segmentation frameworks, and other established\nmedical FMs, including SAM-Med2D, SAM-Med3D, SegVol, Universal, 3D-Adapter, and\nSAM-B (at least +13% over them). This highlights the robustness and\nadaptability of our proposed framework across diverse medical segmentation\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.17096v2",
    "published": "2025-05-21T04:02:17+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15080v2",
    "title": "SUS backprop: linear backpropagation algorithm for long inputs in transformers",
    "authors": [
      "Sergey Pankov",
      "Georges Harik"
    ],
    "abstract": "It is straightforward to design an unbiased gradient estimator that\nstochastically cuts the backpropagation flow through any part of a\ncomputational graph. By cutting the parts that have little effect on the\ncomputation, one can potentially save a significant amount of backpropagation\ncomputation in exchange for a minimal increase in the stochastic gradient\nvariance, in some situations. Such a situation occurs in the attention\nmechanism of the transformer architecture. For long sequences, attention\nbecomes the limiting factor, as its compute requirements increase quadratically\nwith sequence length $n$. At the same time, most attention weights become very\nsmall, as most attention heads tend to connect a given token with only a small\nfraction of other tokens in the sequence. These weights become promising\ntargets for cutting backpropagation. We propose a simple probabilistic rule\ncontrolled by a single parameter $c$ that cuts back-propagation through most\nattention weights, leaving at most $c$ interactions per token per attention\nhead. This brings a factor of $c/n$ reduction in the compute required for the\nattention backpropagation, turning it from quadratic $O(n^2)$ to linear\ncomplexity $O(nc)$. We have empirically verified that, for a typical\ntransformer model, cutting about $99\\%$ of the attention gradient flow (i.e.\nchoosing $c \\sim 25-30$) results in relative gradient variance increase of only\nabout $1\\%$ for $n \\sim 2000$, and it decreases with $n$. This approach is\namenable to efficient sparse matrix implementation, thus being promising for\nmaking the cost of a backward pass negligible relative to the cost of a forward\npass when training a transformer model on long sequences.",
    "pdf_url": "http://arxiv.org/pdf/2505.15080v2",
    "published": "2025-05-21T04:00:38+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15079v1",
    "title": "Carleson-type embeddings with closed range",
    "authors": [
      "Konstantin M. Dyakonov"
    ],
    "abstract": "We characterize the Carleson measures $\\mu$ on the unit disk for which the\nimage of the Hardy space $H^p$ under the corresponding embedding operator is\nclosed in $L^p(\\mu)$. In fact, a more general result involving $(p,q)$-Carleson\nmeasures is obtained. A similar problem is solved in the setting of Bergman\nspaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.15079v1",
    "published": "2025-05-21T03:59:59+00:00",
    "categories": [
      "math.CV",
      "math.CA",
      "math.FA",
      "30H10, 30H20, 47B91"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15078v1",
    "title": "Stability of Riemann Shocks for isothermal Euler by Inviscid limits of global-in-time large Navier-Stokes flows",
    "authors": [
      "Saehoon Eo",
      "Namhyun Eun",
      "Moon-Jin Kang",
      "HyeonSeop Oh"
    ],
    "abstract": "In this paper, we study the isothermal gas dynamics. We first establish the\nglobal existence of strong solutions to the one-dimensional isothermal\nNavier-Stokes system for smooth initial data without any smallness conditions,\nassuming that the initial density has strictly positive lower bound. The\nexistence result allows for possibly degenerate viscosity coefficients and\nadmits different asymptotic states at the far fields. We then prove a\ncontraction property for the strong solutions perturbed from viscous shocks,\nyielding uniform estimates with respect to the viscosity coefficients. This\ncovers any large perturbations, and consequently, we establish the inviscid\nlimits and their stability estimate. In other words, we demonstrate the\nstability of Riemann shocks to the one-dimensional isothermal Euler system in\nthe class of vanishing viscosity limits of the associated Navier-Stokes system.",
    "pdf_url": "http://arxiv.org/pdf/2505.15078v1",
    "published": "2025-05-21T03:59:22+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "35Q30, 76N10, 35B35"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15077v1",
    "title": "Data Augmentation and Resolution Enhancement using GANs and Diffusion Models for Tree Segmentation",
    "authors": [
      "Alessandro dos Santos Ferreira",
      "Ana Paula Marques Ramos",
      "Jos√© Marcato Junior",
      "Wesley Nunes Gon√ßalves"
    ],
    "abstract": "Urban forests play a key role in enhancing environmental quality and\nsupporting biodiversity in cities. Mapping and monitoring these green spaces\nare crucial for urban planning and conservation, yet accurately detecting trees\nis challenging due to complex landscapes and the variability in image\nresolution caused by different satellite sensors or UAV flight altitudes. While\ndeep learning architectures have shown promise in addressing these challenges,\ntheir effectiveness remains strongly dependent on the availability of large and\nmanually labeled datasets, which are often expensive and difficult to obtain in\nsufficient quantity. In this work, we propose a novel pipeline that integrates\ndomain adaptation with GANs and Diffusion models to enhance the quality of\nlow-resolution aerial images. Our proposed pipeline enhances low-resolution\nimagery while preserving semantic content, enabling effective tree segmentation\nwithout requiring large volumes of manually annotated data. Leveraging models\nsuch as pix2pix, Real-ESRGAN, Latent Diffusion, and Stable Diffusion, we\ngenerate realistic and structurally consistent synthetic samples that expand\nthe training dataset and unify scale across domains. This approach not only\nimproves the robustness of segmentation models across different acquisition\nconditions but also provides a scalable and replicable solution for remote\nsensing scenarios with scarce annotation resources. Experimental results\ndemonstrated an improvement of over 50% in IoU for low-resolution images,\nhighlighting the effectiveness of our method compared to traditional pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2505.15077v1",
    "published": "2025-05-21T03:57:10+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68T07 (Primary), 68U10, 68T45 (Secondary)",
      "I.4.8; I.2.10; I.5.4"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15076v1",
    "title": "Agentic Feature Augmentation: Unifying Selection and Generation with Teaming, Planning, and Memories",
    "authors": [
      "Nanxu Gong",
      "Sixun Dong",
      "Haoyue Bai",
      "Xinyuan Wang",
      "Wangyang Ying",
      "Yanjie Fu"
    ],
    "abstract": "As a widely-used and practical tool, feature engineering transforms raw data\ninto discriminative features to advance AI model performance. However, existing\nmethods usually apply feature selection and generation separately, failing to\nstrive a balance between reducing redundancy and adding meaningful dimensions.\nTo fill this gap, we propose an agentic feature augmentation concept, where the\nunification of feature generation and selection is modeled as agentic teaming\nand planning. Specifically, we develop a Multi-Agent System with Long and\nShort-Term Memory (MAGS), comprising a selector agent to eliminate redundant\nfeatures, a generator agent to produce informative new dimensions, and a router\nagent that strategically coordinates their actions. We leverage in-context\nlearning with short-term memory for immediate feedback refinement and long-term\nmemory for globally optimal guidance. Additionally, we employ offline Proximal\nPolicy Optimization (PPO) reinforcement fine-tuning to train the router agent\nfor effective decision-making to navigate a vast discrete feature space.\nExtensive experiments demonstrate that this unified agentic framework\nconsistently achieves superior task performance by intelligently orchestrating\nfeature selection and generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15076v1",
    "published": "2025-05-21T03:49:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.17095v1",
    "title": "Are LLMs reliable? An exploration of the reliability of large language models in clinical note generation",
    "authors": [
      "Kristine Ann M. Carandang",
      "Jasper Meynard P. Ara√±a",
      "Ethan Robert A. Casin",
      "Christopher P. Monterola",
      "Daniel Stanley Y. Tan",
      "Jesus Felix B. Valenzuela",
      "Christian M. Alis"
    ],
    "abstract": "Due to the legal and ethical responsibilities of healthcare providers (HCPs)\nfor accurate documentation and protection of patient data privacy, the natural\nvariability in the responses of large language models (LLMs) presents\nchallenges for incorporating clinical note generation (CNG) systems, driven by\nLLMs, into real-world clinical processes. The complexity is further amplified\nby the detailed nature of texts in CNG. To enhance the confidence of HCPs in\ntools powered by LLMs, this study evaluates the reliability of 12 open-weight\nand proprietary LLMs from Anthropic, Meta, Mistral, and OpenAI in CNG in terms\nof their ability to generate notes that are string equivalent (consistency\nrate), have the same meaning (semantic consistency) and are correct (semantic\nsimilarity), across several iterations using the same prompt. The results show\nthat (1) LLMs from all model families are stable, such that their responses are\nsemantically consistent despite being written in various ways, and (2) most of\nthe LLMs generated notes close to the corresponding notes made by experts.\nOverall, Meta's Llama 70B was the most reliable, followed by Mistral's Small\nmodel. With these findings, we recommend the local deployment of these\nrelatively smaller open-weight models for CNG to ensure compliance with data\nprivacy regulations, as well as to improve the efficiency of HCPs in clinical\ndocumentation.",
    "pdf_url": "http://arxiv.org/pdf/2505.17095v1",
    "published": "2025-05-21T03:44:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15075v5",
    "title": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs",
    "authors": [
      "Hao Wang",
      "Pinzhi Huang",
      "Jihan Yang",
      "Saining Xie",
      "Daisuke Kawahara"
    ],
    "abstract": "The rapid evolution of multimodal large language models (MLLMs) has\nsignificantly enhanced their real-world applications. However, achieving\nconsistent performance across languages, especially when integrating cultural\nknowledge, remains a significant challenge. To better assess this issue, we\nintroduce two new benchmarks: KnowRecall and VisRecall, which evaluate\ncross-lingual consistency in MLLMs. KnowRecall is a visual question answering\nbenchmark designed to measure factual knowledge consistency in 15 languages,\nfocusing on cultural and historical questions about global landmarks. VisRecall\nassesses visual memory consistency by asking models to describe landmark\nappearances in 9 languages without access to images. Experimental results\nreveal that state-of-the-art MLLMs, including proprietary ones, still struggle\nto achieve cross-lingual consistency. This underscores the need for more robust\napproaches that produce truly multilingual and culturally aware models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15075v5",
    "published": "2025-05-21T03:43:37+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15074v2",
    "title": "DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data",
    "authors": [
      "Yuhang Zhou",
      "Jing Zhu",
      "Shengyi Qian",
      "Zhuokai Zhao",
      "Xiyao Wang",
      "Xiaoyu Liu",
      "Ming Li",
      "Paiheng Xu",
      "Wei Ai",
      "Furong Huang"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly aligned with human preferences\nthrough Reinforcement Learning from Human Feedback (RLHF). Among RLHF methods,\nGroup Relative Policy Optimization (GRPO) has gained attention for its\nsimplicity and strong performance, notably eliminating the need for a learned\nvalue function. However, GRPO implicitly assumes a balanced domain distribution\nand uniform semantic alignment across groups - assumptions that rarely hold in\nreal-world datasets. When applied to multi-domain, imbalanced data, GRPO\ndisproportionately optimizes for dominant domains, neglecting underrepresented\nones and resulting in poor generalization and fairness. We propose\nDomain-Informed Self-Consistency Policy Optimization (DISCO), a principled\nextension to GRPO that addresses inter-group imbalance with two key\ninnovations. Domain-aware reward scaling counteracts frequency bias by\nreweighting optimization based on domain prevalence. Difficulty-aware reward\nscaling leverages prompt-level self-consistency to identify and prioritize\nuncertain prompts that offer greater learning value. Together, these strategies\npromote more equitable and effective policy learning across domains. Extensive\nexperiments across multiple LLMs and skewed training distributions show that\nDISCO improves generalization, outperforms existing GRPO variants by 5% on\nQwen3 models, and sets new state-of-the-art results on multi-domain alignment\nbenchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15074v2",
    "published": "2025-05-21T03:43:29+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15073v1",
    "title": "Seoul National University AGN Monitoring Project. V. Velocity-resolved H-beta Reverberation Mapping and Evidence of Kinematics Evolution",
    "authors": [
      "Shu Wang",
      "Jong-Hak Woo",
      "Aaron J. Barth",
      "Vardha N. Bennert",
      "Elena Gallo",
      "Edmund Hodges-Kluck",
      "Minjin Kim",
      "Suvendu Rakshit",
      "Tommaso Treu",
      "Hojin Cho",
      "Kyle M. Kabasares",
      "Matthew A. Malkan",
      "Amit Kumar Mandal",
      "Donghoon Son",
      "Vivian U",
      "Lizvette Villafana"
    ],
    "abstract": "We present velocity-resolved reverberation lags of H-beta for 20 active\ngalactic nuclei (AGNs) from the Seoul National University AGN Monitoring\nProject. We detect unambiguous velocity-resolved structures in 12 AGNs, among\nwhich eight objects exhibit symmetric structures, two objects show inflow-like\ncharacteristics, and two objects display outflow-like signatures. For two AGNs,\nwe successfully measure the velocity-resolved lags in different years,\nrevealing evidence of evolving broad-line region (BLR) kinematics. By combining\nour sample with the literature velocity-resolved lags, we find that the\nsymmetric velocity-resolved lags are the most common (40%) type among this\nsample. The frequency of inflow kinematics is also notable (20%), while outflow\nkinematics are less common (11%). Our sample significantly expands the previous\nvelocity-resolved reverberation mapping sample in the high-luminosity regime,\nenabling us to constrain BLR kinematics across a large dynamic range of\nluminosity.",
    "pdf_url": "http://arxiv.org/pdf/2505.15073v1",
    "published": "2025-05-21T03:41:26+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15072v2",
    "title": "MoTime: A Dataset Suite for Multimodal Time Series Forecasting",
    "authors": [
      "Xin Zhou",
      "Weiqing Wang",
      "Francisco J. Bald√°n",
      "Wray Buntine",
      "Christoph Bergmeir"
    ],
    "abstract": "While multimodal data sources are increasingly available from real-world\nforecasting, most existing research remains on unimodal time series. In this\nwork, we present MoTime, a suite of multimodal time series forecasting datasets\nthat pair temporal signals with external modalities such as text, metadata, and\nimages. Covering diverse domains, MoTime supports structured evaluation of\nmodality utility under two scenarios: 1) the common forecasting task, where\nvarying-length history is available, and 2) cold-start forecasting, where no\nhistorical data is available. Experiments show that external modalities can\nimprove forecasting performance in both scenarios, with particularly strong\nbenefits for short series in some datasets, though the impact varies depending\non data characteristics. By making datasets and findings publicly available, we\naim to support more comprehensive and realistic benchmarks in future multimodal\ntime series forecasting research.",
    "pdf_url": "http://arxiv.org/pdf/2505.15072v2",
    "published": "2025-05-21T03:39:42+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15071v1",
    "title": "Can Large Language Models Understand Internet Buzzwords Through User-Generated Content",
    "authors": [
      "Chen Huang",
      "Junkai Luo",
      "Xinzuo Wang",
      "Wenqiang Lei",
      "Jiancheng Lv"
    ],
    "abstract": "The massive user-generated content (UGC) available in Chinese social media is\ngiving rise to the possibility of studying internet buzzwords. In this paper,\nwe study if large language models (LLMs) can generate accurate definitions for\nthese buzzwords based on UGC as examples. Our work serves a threefold\ncontribution. First, we introduce CHEER, the first dataset of Chinese internet\nbuzzwords, each annotated with a definition and relevant UGC. Second, we\npropose a novel method, called RESS, to effectively steer the comprehending\nprocess of LLMs to produce more accurate buzzword definitions, mirroring the\nskills of human language learning. Third, with CHEER, we benchmark the\nstrengths and weaknesses of various off-the-shelf definition generation methods\nand our RESS. Our benchmark demonstrates the effectiveness of RESS while\nrevealing crucial shared challenges: over-reliance on prior exposure,\nunderdeveloped inferential abilities, and difficulty identifying high-quality\nUGC to facilitate comprehension. We believe our work lays the groundwork for\nfuture advancements in LLM-based definition generation. Our dataset and code\nare available at https://github.com/SCUNLP/Buzzword.",
    "pdf_url": "http://arxiv.org/pdf/2505.15071v1",
    "published": "2025-05-21T03:38:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.11039v1",
    "title": "Angle Domain Guidance: Latent Diffusion Requires Rotation Rather Than Extrapolation",
    "authors": [
      "Cheng Jin",
      "Zhenyu Xiao",
      "Chutao Liu",
      "Yuantao Gu"
    ],
    "abstract": "Classifier-free guidance (CFG) has emerged as a pivotal advancement in\ntext-to-image latent diffusion models, establishing itself as a cornerstone\ntechnique for achieving high-quality image synthesis. However, under high\nguidance weights, where text-image alignment is significantly enhanced, CFG\nalso leads to pronounced color distortions in the generated images. We identify\nthat these distortions stem from the amplification of sample norms in the\nlatent space. We present a theoretical framework that elucidates the mechanisms\nof norm amplification and anomalous diffusion phenomena induced by\nclassifier-free guidance. Leveraging our theoretical insights and the latent\nspace structure, we propose an Angle Domain Guidance (ADG) algorithm. ADG\nconstrains magnitude variations while optimizing angular alignment, thereby\nmitigating color distortions while preserving the enhanced text-image alignment\nachieved at higher guidance weights. Experimental results demonstrate that ADG\nsignificantly outperforms existing methods, generating images that not only\nmaintain superior text alignment but also exhibit improved color fidelity and\nbetter alignment with human perceptual preferences.",
    "pdf_url": "http://arxiv.org/pdf/2506.11039v1",
    "published": "2025-05-21T03:36:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15070v1",
    "title": "An Alternative to FLOPS Regularization to Effectively Productionize SPLADE-Doc",
    "authors": [
      "Aldo Porco",
      "Dhruv Mehra",
      "Igor Malioutov",
      "Karthik Radhakrishnan",
      "Moniba Keymanesh",
      "Daniel Preo≈£iuc-Pietro",
      "Sean MacAvaney",
      "Pengxiang Cheng"
    ],
    "abstract": "Learned Sparse Retrieval (LSR) models encode text as weighted term vectors,\nwhich need to be sparse to leverage inverted index structures during retrieval.\nSPLADE, the most popular LSR model, uses FLOPS regularization to encourage\nvector sparsity during training. However, FLOPS regularization does not ensure\nsparsity among terms - only within a given query or document. Terms with very\nhigh Document Frequencies (DFs) substantially increase latency in production\nretrieval engines, such as Apache Solr, due to their lengthy posting lists. To\naddress the issue of high DFs, we present a new variant of FLOPS\nregularization: DF-FLOPS. This new regularization technique penalizes the usage\nof high-DF terms, thereby shortening posting lists and reducing retrieval\nlatency. Unlike other inference-time sparsification methods, such as stopword\nremoval, DF-FLOPS regularization allows for the selective inclusion of\nhigh-frequency terms in cases where the terms are truly salient. We find that\nDF-FLOPS successfully reduces the prevalence of high-DF terms and lowers\nretrieval latency (around 10x faster) in a production-grade engine while\nmaintaining effectiveness both in-domain (only a 2.2-point drop in MRR@10) and\ncross-domain (improved performance in 12 out of 13 tasks on which we tested).\nWith retrieval latencies on par with BM25, this work provides an important step\ntowards making LSR practical for deployment in production-grade search engines.",
    "pdf_url": "http://arxiv.org/pdf/2505.15070v1",
    "published": "2025-05-21T03:35:51+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15069v1",
    "title": "In-Domain African Languages Translation Using LLMs and Multi-armed Bandits",
    "authors": [
      "Pratik Rakesh Singh",
      "Kritarth Prasad",
      "Mohammadi Zaki",
      "Pankaj Wasnik"
    ],
    "abstract": "Neural Machine Translation (NMT) systems face significant challenges when\nworking with low-resource languages, particularly in domain adaptation tasks.\nThese difficulties arise due to limited training data and suboptimal model\ngeneralization, As a result, selecting an optimal model for translation is\ncrucial for achieving strong performance on in-domain data, particularly in\nscenarios where fine-tuning is not feasible or practical. In this paper, we\ninvestigate strategies for selecting the most suitable NMT model for a given\ndomain using bandit-based algorithms, including Upper Confidence Bound, Linear\nUCB, Neural Linear Bandit, and Thompson Sampling. Our method effectively\naddresses the resource constraints by facilitating optimal model selection with\nhigh confidence. We evaluate the approach across three African languages and\ndomains, demonstrating its robustness and effectiveness in both scenarios where\ntarget data is available and where it is absent.",
    "pdf_url": "http://arxiv.org/pdf/2505.15069v1",
    "published": "2025-05-21T03:33:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15068v1",
    "title": "ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges",
    "authors": [
      "Cheng Qian",
      "Hongyi Du",
      "Hongru Wang",
      "Xiusi Chen",
      "Yuji Zhang",
      "Avirup Sil",
      "Chengxiang Zhai",
      "Kathleen McKeown",
      "Heng Ji"
    ],
    "abstract": "Recent progress in large language models (LLMs) has enabled substantial\nadvances in solving mathematical problems. However, existing benchmarks often\nfail to reflect the complexity of real-world problems, which demand open-ended,\ninterdisciplinary reasoning and integration of computational tools. To address\nthis gap, we introduce ModelingBench, a novel benchmark featuring\nreal-world-inspired, open-ended problems from math modeling competitions across\ndiverse domains, ranging from urban traffic optimization to ecosystem resource\nplanning. These tasks require translating natural language into formal\nmathematical formulations, applying appropriate tools, and producing\nstructured, defensible reports. ModelingBench also supports multiple valid\nsolutions, capturing the ambiguity and creativity of practical modeling. We\nalso present ModelingAgent, a multi-agent framework that coordinates tool use,\nsupports structured workflows, and enables iterative self-refinement to\ngenerate well-grounded, creative solutions. To evaluate outputs, we further\npropose ModelingJudge, an expert-in-the-loop system leveraging LLMs as\ndomain-specialized judges assessing solutions from multiple expert\nperspectives. Empirical results show that ModelingAgent substantially\noutperforms strong baselines and often produces solutions indistinguishable\nfrom those of human experts. Together, our work provides a comprehensive\nframework for evaluating and advancing real-world problem-solving in\nopen-ended, interdisciplinary modeling challenges.",
    "pdf_url": "http://arxiv.org/pdf/2505.15068v1",
    "published": "2025-05-21T03:33:23+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15067v1",
    "title": "Lawful but Awful: Evolving Legislative Responses to Address Online Misinformation, Disinformation, and Mal-Information in the Age of Generative AI",
    "authors": [
      "Simon Chesterman"
    ],
    "abstract": "\"Fake news\" is an old problem. In recent years, however, increasing usage of\nsocial media as a source of information, the spread of unverified medical\nadvice during the Covid-19 pandemic, and the rise of generative artificial\nintelligence have seen a rush of legislative proposals seeking to minimize or\nmitigate the impact of false information spread online. Drawing on a novel\ndataset of statutes and other instruments, this article analyses changing\nperceptions about the potential harms caused by misinformation, disinformation,\nand \"mal-information\". The turn to legislation began in countries that were\nless free, in terms of civil liberties, and poorer, as measured by GDP per\ncapita. Internet penetration does not seem to have been a driving factor. The\nfocus of such laws is most frequently on national security broadly construed,\nthough 2020 saw a spike in laws addressing public health. Unsurprisingly,\ngovernments with fewer legal constraints on government action have generally\nadopted more robust positions in dealing with false information. Despite early\nreservations, however, growth in such laws is now steepest in Western states.\nThough there are diverse views on the appropriate response to false information\nonline, the need for legislation of some kind appears now to be global. The\nquestion is no longer whether to regulate \"lawful but awful\" speech online, but\nhow.",
    "pdf_url": "http://arxiv.org/pdf/2505.15067v1",
    "published": "2025-05-21T03:33:13+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15066v2",
    "title": "Star formation at different stages of ram-pressure stripping as observed through far-ultraviolet imaging of 13 GASP galaxies",
    "authors": [
      "Koshy George",
      "B. M. Poggianti",
      "B. Vulcani",
      "M. Gullieuszik",
      "J. Postma",
      "Jacopo Fritz",
      "P. C√¥t√©",
      "Yara L. Jaffe",
      "A. Moretti",
      "Alessandro Ignesti",
      "Giorgia Peluso",
      "Neven Tomiƒáiƒá",
      "A. Subramaniam",
      "S. K. Ghosh",
      "S. N. Tandon"
    ],
    "abstract": "Galaxies undergoing ram-pressure stripping develop gaseous tails that can\nextend several kiloparsecs outside the galaxy disc. We used far-ultraviolet and\nH$\\alpha$ imaging from the GASP survey to investigate how different stages of\nstripping affect star formation properties in the tail and disc of 13 galaxies\nundergoing stripping. These galaxies have different stripping strengths, as\nidentified from the MUSE integral field spectroscopy. The star-forming knots in\nthe disc and tails show a good correspondence between the measured FUV and\nH$\\alpha$ flux. This is especially true for strong and extreme cases of\nstripping, which have developed extended ionized gaseous tails featuring clumpy\nstructures. The mechanism behind the H$\\alpha$ emission on the tails of these\nregions, which correlates well with FUV emission, is photoionization caused by\nyoung massive stars. The optical emission line ratio maps enable us to\nunderstand the emission mechanism, which can be attributed to star formation,\nLINER activity, or a combination of both phenomena and AGN. The star-forming\nregions in the emission line maps correspond well to the areas with significant\nFUV flux in these galaxies. Six galaxies exhibit minimal star formation in\ntheir tails, with two cases star formation is limited to the central regions\nand their discs are truncated. In galaxies with truncated discs, star formation\nis confined to a smaller region on the disc, as indicated by the FUV flux,\ncompared to H$\\alpha$. Galaxies with strong stripping are undergoing recent\nstar formation and are likely recent infalls. Galaxies with truncated discs\nconfine star formation to the center, likely because they have completed a\ncluster crossing that depleted most of their outer gaseous disc. Galaxies with\nminimal FUV flux along their tails exhibit unresolved H$\\alpha$ emission which\nmay be attributed to processes other than star formation.",
    "pdf_url": "http://arxiv.org/pdf/2505.15066v2",
    "published": "2025-05-21T03:33:05+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15065v1",
    "title": "The Pursuit of Empathy: Evaluating Small Language Models for PTSD Dialogue Support",
    "authors": [
      "Suhas BN",
      "Yash Mahajan",
      "Dominik Mattioli",
      "Andrew M. Sherrill",
      "Rosa I. Arriaga",
      "Chris W. Wiese",
      "Saeed Abdullah"
    ],
    "abstract": "Can small language models with 0.5B to 5B parameters meaningfully engage in\ntrauma-informed, empathetic dialogue for individuals with PTSD? We address this\nquestion by introducing TIDE, a dataset of 10,000 two-turn dialogues spanning\n500 diverse PTSD client personas and grounded in a three-factor empathy model:\nemotion recognition, distress normalization, and supportive reflection. All\nscenarios and reference responses were reviewed for realism and trauma\nsensitivity by a clinical psychologist specializing in PTSD. We evaluate eight\nsmall language models before and after fine-tuning, comparing their outputs to\na frontier model (Claude Sonnet 3.5). Our IRB-approved human evaluation and\nautomatic metrics show that fine-tuning generally improves perceived empathy,\nbut gains are highly scenario- and user-dependent, with smaller models facing\nan empathy ceiling. Demographic analysis shows older adults value distress\nvalidation and graduate-educated users prefer nuanced replies, while gender\neffects are minimal. We highlight the limitations of automatic metrics and the\nneed for context- and user-aware system design. Our findings, along with the\nplanned release of TIDE, provide a foundation for building safe,\nresource-efficient, and ethically sound empathetic AI to supplement, not\nreplace, clinical mental health care.",
    "pdf_url": "http://arxiv.org/pdf/2505.15065v1",
    "published": "2025-05-21T03:32:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "68T50, 68T05",
      "I.2.7; I.2.1; H.5.2"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15064v1",
    "title": "Generalization Through Growth: Hidden Dynamics Controls Depth Dependence",
    "authors": [
      "Sho Sonoda",
      "Yuka Hashimoto",
      "Isao Ishikawa",
      "Masahiro Ikeda"
    ],
    "abstract": "Recent theory has reduced the depth dependence of generalization bounds from\nexponential to polynomial and even depth-independent rates, yet these results\nremain tied to specific architectures and Euclidean inputs. We present a\nunified framework for arbitrary \\blue{pseudo-metric} spaces in which a\ndepth-\\(k\\) network is the composition of continuous hidden maps\n\\(f:\\mathcal{X}\\to \\mathcal{X}\\) and an output map \\(h:\\mathcal{X}\\to\n\\mathbb{R}\\). The resulting bound $O(\\sqrt{(\\alpha + \\log \\beta(k))/n})$\nisolates the sole depth contribution in \\(\\beta(k)\\), the word-ball growth of\nthe semigroup generated by the hidden layers. By Gromov's theorem polynomial\n(resp. exponential) growth corresponds to virtually nilpotent (resp. expanding)\ndynamics, revealing a geometric dichotomy behind existing $O(\\sqrt{k})$\n(sublinear depth) and $\\tilde{O}(1)$ (depth-independent) rates. We further\nprovide covering-number estimates showing that expanding dynamics yield an\nexponential parameter saving via compositional expressivity. Our results\ndecouple specification from implementation, offering architecture-agnostic and\ndynamical-systems-aware guarantees applicable to modern deep-learning paradigms\nsuch as test-time inference and diffusion models.",
    "pdf_url": "http://arxiv.org/pdf/2505.15064v1",
    "published": "2025-05-21T03:32:30+00:00",
    "categories": [
      "cs.LG",
      "math.DS",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15063v1",
    "title": "UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking",
    "authors": [
      "Sarfraz Ahmad",
      "Hasan Iqbal",
      "Momina Ahsan",
      "Numaan Naeem",
      "Muhammad Ahsan Riaz Khan",
      "Arham Riaz",
      "Muhammad Arslan Manzoor",
      "Yuxia Wang",
      "Preslav Nakov"
    ],
    "abstract": "The rapid use of large language models (LLMs) has raised critical concerns\nregarding the factual reliability of their outputs, especially in low-resource\nlanguages such as Urdu. Existing automated fact-checking solutions\noverwhelmingly focus on English, leaving a significant gap for the 200+ million\nUrdu speakers worldwide. In this work, we introduce UrduFactCheck, the first\ncomprehensive, modular fact-checking framework specifically tailored for Urdu.\nOur system features a dynamic, multi-strategy evidence retrieval pipeline that\ncombines monolingual and translation-based approaches to address the scarcity\nof high-quality Urdu evidence. We curate and release two new hand-annotated\nbenchmarks: UrduFactBench for claim verification and UrduFactQA for evaluating\nLLM factuality. Extensive experiments demonstrate that UrduFactCheck,\nparticularly its translation-augmented variants, consistently outperforms\nbaselines and open-source alternatives on multiple metrics. We further\nbenchmark twelve state-of-the-art (SOTA) LLMs on factual question answering in\nUrdu, highlighting persistent gaps between proprietary and open-source models.\nUrduFactCheck's code and datasets are open-sourced and publicly available at\nhttps://github.com/mbzuai-nlp/UrduFactCheck.",
    "pdf_url": "http://arxiv.org/pdf/2505.15063v1",
    "published": "2025-05-21T03:31:44+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15062v2",
    "title": "Self-GIVE: Associative Thinking from Limited Structured Knowledge for Enhanced Large Language Model Reasoning",
    "authors": [
      "Jiashu He",
      "Jinxuan Fan",
      "Bowen Jiang",
      "Ignacio Houine",
      "Dan Roth",
      "Alejandro Ribeiro"
    ],
    "abstract": "When addressing complex questions that require new information, people often\nassociate the question with existing knowledge to derive a sensible answer. For\ninstance, when evaluating whether melatonin aids insomnia, one might associate\n\"hormones helping mental disorders\" with \"melatonin being a hormone and\ninsomnia a mental disorder\" to complete the reasoning. Large Language Models\n(LLMs) also require such associative thinking, particularly in resolving\nscientific inquiries when retrieved knowledge is insufficient and does not\ndirectly answer the question. Graph Inspired Veracity Extrapolation (GIVE)\naddresses this by using a knowledge graph (KG) to extrapolate structured\nknowledge. However, it involves the construction and pruning of many\nhypothetical triplets, which limits efficiency and generalizability. We propose\nSelf-GIVE, a retrieve-RL framework that enhances LLMs with automatic\nassociative thinking through reinforcement learning. Self-GIVE extracts\nstructured information and entity sets to assist the model in linking to the\nqueried concepts. We address GIVE's key limitations: (1) extensive LLM calls\nand token overhead for knowledge extrapolation, (2) difficulty in deploying on\nsmaller LLMs (3B or 7B) due to complex instructions, and (3) inaccurate\nknowledge from LLM pruning. Specifically, after fine-tuning using self-GIVE\nwith a 135 node UMLS KG, it improves the performance of the Qwen2.5 3B and 7B\nmodels by up to $\\textbf{28.5%$\\rightarrow$71.4%}$ and\n$\\textbf{78.6$\\rightarrow$90.5%}$ in samples $\\textbf{unseen}$ in challenging\nbiomedical QA tasks. In particular, Self-GIVE allows the 7B model to match or\noutperform GPT3.5 turbo with GIVE, while cutting token usage by over 90\\%.\nSelf-GIVE enhances the scalable integration of structured retrieval and\nreasoning with associative thinking.",
    "pdf_url": "http://arxiv.org/pdf/2505.15062v2",
    "published": "2025-05-21T03:30:55+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15061v1",
    "title": "SHEET: A Multi-purpose Open-source Speech Human Evaluation Estimation Toolkit",
    "authors": [
      "Wen-Chin Huang",
      "Erica Cooper",
      "Tomoki Toda"
    ],
    "abstract": "We introduce SHEET, a multi-purpose open-source toolkit designed to\naccelerate subjective speech quality assessment (SSQA) research. SHEET stands\nfor the Speech Human Evaluation Estimation Toolkit, which focuses on\ndata-driven deep neural network-based models trained to predict human-labeled\nquality scores of speech samples. SHEET provides comprehensive training and\nevaluation scripts, multi-dataset and multi-model support, as well as\npre-trained models accessible via Torch Hub and HuggingFace Spaces. To\ndemonstrate its capabilities, we re-evaluated SSL-MOS, a speech self-supervised\nlearning (SSL)-based SSQA model widely used in recent scientific papers, on an\nextensive list of speech SSL models. Experiments were conducted on two\nrepresentative SSQA datasets named BVCC and NISQA, and we identified the\noptimal speech SSL model, whose performance surpassed the original SSL-MOS\nimplementation and was comparable to state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.15061v1",
    "published": "2025-05-21T03:30:23+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15060v1",
    "title": "SYMPHANY- SYnergy of Molecular PHase And Neutral hYdrogen in galaxies in A2626",
    "authors": [
      "Tirna Deb",
      "Garrett K. Keating",
      "Nikki Zabel",
      "Alessia Moretti",
      "Cecilia Bacchini",
      "Timothy A Davis",
      "Bianca M. Poggianti",
      "Marco Gullieuszik",
      "Benedetta Vulcani",
      "Yara Jeff√©",
      "Neven Tomicic",
      "Toby Brown"
    ],
    "abstract": "We present an analysis of the molecular and atomic gas properties of 10\nspatially resolved galaxies in the A2626 cluster (z = 0.055), observed as part\nof the SYMPHANY project. Using CO(2-1) observations from ALMA and SMA, together\nwith HI data from MeerKAT, we examine the interplay between gas phases and\nenvironmental influences. A joint morphological and kinematic analysis reveals\nthat while the kinematic behavior of HI and CO are often similar,\nmorphologically the atomic gas is more extended compared to centrally\nconcentrated CO distributions, making it more susceptible to environmental\nstripping. However, we also find evidence for molecular gas asymmetries,\ndisturbed velocity fields, and H2 deficiencies in some galaxies, indicating\nthat H2 reservoirs can also be disrupted in dense environments. Compared to\nVirgo-a dynamically unrelaxed, non-cool-core cluster-A2626's relaxed, cool-core\nstructure likely results in less intense ram-pressure stripping. This may allow\ngalaxies to retain more atomic gas, while local interactions or pre-processing\nmay still affect the molecular phase, causing relatively low HI deficiencies\nbut high H2 deficiencies in A2626 galaxies. This is also reflected in the\nhigher gas fractions, slightly elevated SFRs, along with shorter depletion\ntimescales (0.3-3 Gyr), implying moderately enhanced star formation efficiency\nA2626 galaxies. Moreover, the lack of correlation between H2 deficiency and\ncluster-centric distance or velocity suggests that molecular gas evolution in\nA2626 may be shaped more by early infall or local interactions than by current\ncluster location.",
    "pdf_url": "http://arxiv.org/pdf/2505.15060v1",
    "published": "2025-05-21T03:29:42+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15059v1",
    "title": "Restricted Spectral Gap Decomposition for Simulated Tempering Targeting Mixture Distributions",
    "authors": [
      "Jhanvi Garg",
      "Krishna Balasubramanian",
      "Quan Zhou"
    ],
    "abstract": "Simulated tempering is a widely used strategy for sampling from multimodal\ndistributions. In this paper, we consider simulated tempering combined with an\narbitrary local Markov chain Monte Carlo sampler and present a new\ndecomposition theorem that provides a lower bound on the restricted spectral\ngap of the algorithm for sampling from mixture distributions. By working with\nthe restricted spectral gap, the applicability of our results is extended to\nbroader settings such as when the usual spectral gap is difficult to bound or\nbecomes degenerate. We demonstrate the application of our theoretical results\nby analyzing simulated tempering combined with random walk Metropolis--Hastings\nfor sampling from mixtures of Gaussian distributions. We show that in\nfixed-dimensional settings, the algorithm's complexity scales polynomially with\nthe separation between modes and logarithmically with $1/\\varepsilon$, where\n$\\varepsilon$ is the target accuracy in total variation distance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15059v1",
    "published": "2025-05-21T03:28:55+00:00",
    "categories": [
      "math.ST",
      "math.PR",
      "stat.CO",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.15058v1",
    "title": "AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars",
    "authors": [
      "Tianbao Zhang",
      "Jian Zhao",
      "Yuer Li",
      "Zheng Zhu",
      "Ping Hu",
      "Zhaoxin Fan",
      "Wenjun Wu",
      "Xuelong Li"
    ],
    "abstract": "Whole-body audio-driven avatar pose and expression generation is a critical\ntask for creating lifelike digital humans and enhancing the capabilities of\ninteractive virtual agents, with wide-ranging applications in virtual reality,\ndigital entertainment, and remote communication. Existing approaches often\ngenerate audio-driven facial expressions and gestures independently, which\nintroduces a significant limitation: the lack of seamless coordination between\nfacial and gestural elements, resulting in less natural and cohesive\nanimations. To address this limitation, we propose AsynFusion, a novel\nframework that leverages diffusion transformers to achieve harmonious\nexpression and gesture synthesis. The proposed method is built upon a\ndual-branch DiT architecture, which enables the parallel generation of facial\nexpressions and gestures. Within the model, we introduce a Cooperative\nSynchronization Module to facilitate bidirectional feature interaction between\nthe two modalities, and an Asynchronous LCM Sampling strategy to reduce\ncomputational overhead while maintaining high-quality outputs. Extensive\nexperiments demonstrate that AsynFusion achieves state-of-the-art performance\nin generating real-time, synchronized whole-body animations, consistently\noutperforming existing methods in both quantitative and qualitative\nevaluations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15058v1",
    "published": "2025-05-21T03:28:53+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "eess.AS",
      "68T10"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.15057v3",
    "title": "Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models",
    "authors": [
      "Frederic Wang",
      "Jonathan I. Tamir"
    ],
    "abstract": "Magnetic Resonance Imaging (MRI) is highly susceptible to motion artifacts\ndue to the extended acquisition times required for k-space sampling. These\nartifacts can compromise diagnostic utility, particularly for dynamic imaging.\nWe propose a novel alternating minimization framework that leverages a bespoke\ndiffusion model to jointly reconstruct and correct non-rigid motion-corrupted\nk-space data. The diffusion model uses a coarse-to-fine denoising strategy to\ncapture large overall motion and reconstruct the lower frequencies of the image\nfirst, providing a better inductive bias for motion estimation than that of\nstandard diffusion models. We demonstrate the performance of our approach on\nboth real-world cine cardiac MRI datasets and complex simulated rigid and\nnon-rigid deformations, even when each motion state is undersampled by a factor\nof 64x. Additionally, our method is agnostic to sampling patterns, anatomical\nvariations, and MRI scanning protocols, as long as some low frequency\ncomponents are sampled during each motion state.",
    "pdf_url": "http://arxiv.org/pdf/2505.15057v3",
    "published": "2025-05-21T03:27:21+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15056v1",
    "title": "An ideal-sparse generalized moment problem reformulation for completely positive tensor decomposition exploiting maximal cliques of multi-hypergraphs",
    "authors": [
      "Pengfei Huang",
      "Minru Bai"
    ],
    "abstract": "In this paper, we consider the completely positive tensor decomposition\nproblem with ideal-sparsity. First, we propose an algorithm to generate the\nmaximal cliques of multi-hypergraphs associated with completely positive\ntensors. This also leads to a necessary condition for tensors to be completely\npositive. Then, the completely positive tensor decomposition problem is\nreformulated into an ideal-sparse generalized moment problem. It optimizes over\nseveral lower dimensional measure variables supported on the maximal cliques of\na multi-hypergraph. The moment-based relaxations are applied to solve the\nreformulation. The convergence of this ideal-sparse moment hierarchies is\nstudied. Numerical results show that the ideal-sparse problem is faster to\ncompute than the original dense formulation of completely positive tensor\ndecomposition problems. It also illustrates that the new reformulation utilizes\nsparsity structures that differs from the correlative and term sparsity for\ncompletely positive tensor decomposition problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15056v1",
    "published": "2025-05-21T03:26:08+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15055v2",
    "title": "Lost in Benchmarks? Rethinking Large Language Model Benchmarking with Item Response Theory",
    "authors": [
      "Hongli Zhou",
      "Hui Huang",
      "Ziqing Zhao",
      "Lvyuan Han",
      "Huicheng Wang",
      "Kehai Chen",
      "Muyun Yang",
      "Wei Bao",
      "Jian Dong",
      "Bing Xu",
      "Conghui Zhu",
      "Hailong Cao",
      "Tiejun Zhao"
    ],
    "abstract": "The evaluation of large language models (LLMs) via benchmarks is widespread,\nyet inconsistencies between different leaderboards and poor separability among\ntop models raise concerns about their ability to accurately reflect authentic\nmodel capabilities. This paper provides a critical analysis of benchmark\neffectiveness, examining mainstream prominent LLM benchmarks using results from\ndiverse models. We first propose Pseudo-Siamese Network for Item Response\nTheory (PSN-IRT), an enhanced Item Response Theory framework that incorporates\na rich set of item parameters within an IRT-grounded architecture. PSN-IRT can\nbe utilized for accurate and reliable estimations of item characteristics and\nmodel abilities. Based on PSN-IRT, we conduct extensive analysis on 11 LLM\nbenchmarks comprising 41,871 items, revealing significant and varied\nshortcomings in their measurement quality. Furthermore, we demonstrate that\nleveraging PSN-IRT is able to construct smaller benchmarks while maintaining\nstronger alignment with human preference.",
    "pdf_url": "http://arxiv.org/pdf/2505.15055v2",
    "published": "2025-05-21T03:24:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15054v1",
    "title": "MolLangBench: A Comprehensive Benchmark for Language-Prompted Molecular Structure Recognition, Editing, and Generation",
    "authors": [
      "Feiyang Cai",
      "Jiahui Bai",
      "Tao Tang",
      "Joshua Luo",
      "Tianyu Zhu",
      "Ling Liu",
      "Feng Luo"
    ],
    "abstract": "Precise recognition, editing, and generation of molecules are essential\nprerequisites for both chemists and AI systems tackling various chemical tasks.\nWe present MolLangBench, a comprehensive benchmark designed to evaluate\nfundamental molecule-language interface tasks: language-prompted molecular\nstructure recognition, editing, and generation. To ensure high-quality,\nunambiguous, and deterministic outputs, we construct the recognition tasks\nusing automated cheminformatics tools, and curate editing and generation tasks\nthrough rigorous expert annotation and validation. MolLangBench supports the\nevaluation of models that interface language with different molecular\nrepresentations, including linear strings, molecular images, and molecular\ngraphs. Evaluations of state-of-the-art models reveal significant limitations:\nthe strongest model (o3) achieves $79.2\\%$ and $78.5\\%$ accuracy on recognition\nand editing tasks, which are intuitively simple for humans, and performs even\nworse on the generation task, reaching only $29.0\\%$ accuracy. These results\nhighlight the shortcomings of current AI systems in handling even preliminary\nmolecular recognition and manipulation tasks. We hope MolLangBench will\ncatalyze further research toward more effective and reliable AI systems for\nchemical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15054v1",
    "published": "2025-05-21T03:22:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17094v1",
    "title": "Neuromorphic Mimicry Attacks Exploiting Brain-Inspired Computing for Covert Cyber Intrusions",
    "authors": [
      "Hemanth Ravipati"
    ],
    "abstract": "Neuromorphic computing, inspired by the human brain's neural architecture, is\nrevolutionizing artificial intelligence and edge computing with its low-power,\nadaptive, and event-driven designs. However, these unique characteristics\nintroduce novel cybersecurity risks. This paper proposes Neuromorphic Mimicry\nAttacks (NMAs), a groundbreaking class of threats that exploit the\nprobabilistic and non-deterministic nature of neuromorphic chips to execute\ncovert intrusions. By mimicking legitimate neural activity through techniques\nsuch as synaptic weight tampering and sensory input poisoning, NMAs evade\ntraditional intrusion detection systems, posing risks to applications such as\nautonomous vehicles, smart medical implants, and IoT networks. This research\ndevelops a theoretical framework for NMAs, evaluates their impact using a\nsimulated neuromorphic chip dataset, and proposes countermeasures, including\nneural-specific anomaly detection and secure synaptic learning protocols. The\nfindings underscore the critical need for tailored cybersecurity measures to\nprotect brain-inspired computing, offering a pioneering exploration of this\nemerging threat landscape.",
    "pdf_url": "http://arxiv.org/pdf/2505.17094v1",
    "published": "2025-05-21T03:21:51+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15053v5",
    "title": "Owicki--Gries Logic for Timestamp Semantics",
    "authors": [
      "Tatsuya Abe"
    ],
    "abstract": "Whereas an extension with non-interference of Hoare logic for sequential\nprograms Owicki--Gries logic ensures the correctness of concurrent programs on\nstrict consistency, it is unsound to weak memory models adopted by modern\ncomputer architectures and specifications of programming languages. This paper\nproposes a novel non-interference notion and provides concurrent program logic\nsound to timestamp semantics corresponding to a weak memory model that allows\ndelays in the effects of store instructions. This paper reports three\ntheoretically interesting techniques for modifying non-interference to support\ndelays in the effects of store instructions. The techniques contribute to a\nbetter understanding of constructing concurrent program logic.",
    "pdf_url": "http://arxiv.org/pdf/2505.15053v5",
    "published": "2025-05-21T03:20:16+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15052v1",
    "title": "Study of Brain Connectivity by Multichannel EEG Quaternion Principal Component Analysis for Alzheimer Disease Classification",
    "authors": [
      "Kevin Hung",
      "Gary Man-Tat Man",
      "Jincheng Wang"
    ],
    "abstract": "The early detection of Alzheimer's disease (AD) through widespread screening\nhas emerged as a primary strategy to mitigate the significant global impact of\nAD. EEG measurements offer a promising solution for extensive AD detection.\nHowever, the intricate and nonlinear dynamics of multichannel EEG signals pose\na considerable challenge for real-time AD diagnosis. This paper introduces a\nnovel algorithm, which is based on Quaternion Principal Component Analysis\n(QPCA) of multichannel EEG signals, for AD classification. The algorithm\nextracts high dimensional correlations among different channels to generate\nfeatures that are maximally representative with minimal information redundancy.\nThis provides a multidimensional and precise measure of brain connectivity in\ndisease assessment. Simulations have been conducted to evaluate the performance\nand to identify the most critical EEG channels or brain regions for AD\nclassification. The results reveal a significant drop of connectivity measure\nin the alpha bands. The average AD classification accuracy for all 4-channel\ncombinations reached 95%, while some particular permutations of channels\nachieved 100% accuracy rate. Furthermore, the temporal lobe emerges as one of\nthe most important regions in AD classification given that the EEG signals are\nrecorded during the presentation of an auditory stimulant. The selection of key\nparameters of the QPCA algorithm have been evaluated and some recommendations\nare proposed for further performance enhancement. This paper marks the first\napplication of the QPCA algorithm for AD classification and brain connectivity\nanalysis using multichannel EEG signals.",
    "pdf_url": "http://arxiv.org/pdf/2505.15052v1",
    "published": "2025-05-21T03:19:25+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.15051v1",
    "title": "An Empirical Analysis of EOS Blockchain: Architecture, Contract, and Security",
    "authors": [
      "Haiyang Liu",
      "Yingjie Mao",
      "Xiaoqi Li"
    ],
    "abstract": "With the rapid development of blockchain technology, various blockchain\nsystems are exhibiting vitality and potential. As a representative of\nBlockchain 3.0, the EOS blockchain has been regarded as a strong competitor to\nEthereum. Nevertheless, compared with Bitcoin and Ethereum, academic research\nand in-depth analyses of EOS remain scarce. To address this gap, this study\nconducts a comprehensive investigation of the EOS blockchain from five key\ndimensions: system architecture, decentralization, performance, smart\ncontracts, and behavioral security. The architectural analysis focuses on six\ncore components of the EOS system, detailing their functionalities and\noperational workflows. The decentralization and performance evaluations, based\non data from the XBlock data-sharing platform, reveal several critical issues:\nlow account activity, limited participation in the supernode election process,\nminimal variation in the set of block producers, and a substantial gap between\nactual throughput and the claimed million-level performance. Five types of\ncontract vulnerabilities are identified in the smart contract dimension, and\nfour mainstream vulnerability detection platforms are introduced and\ncomparatively analyzed. In terms of behavioral security, four real-world\nattacks targeting the structural characteristics of EOS are summarized. This\nstudy contributes to the ongoing development of the EOS blockchain and provides\nvaluable insights for enhancing the security and regulatory mechanisms of\nblockchain ecosystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15051v1",
    "published": "2025-05-21T03:16:07+00:00",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15050v2",
    "title": "Improving the fact-checking performance of language models by relying on their entailment ability",
    "authors": [
      "Gaurav Kumar",
      "Debajyoti Mazumder",
      "Ayush Garg",
      "Jasabanta Patro"
    ],
    "abstract": "Automated fact-checking is a crucial task in this digital age. The NLP\ncommunity has been trying various strategies to build robust fact-checking\nsystems. However, we have not been very successful yet. One main reason behind\nthis is that fact verification is a complex process. Language models have to\nparse through multiple pieces of evidence, often contradicting each other, to\npredict a claim's veracity. In this paper, we proposed a simple yet effective\nstrategy, where we relied on the entailment ability of language models to\nimprove the fact-checking performance. Apart from that, we did a comparison of\ndifferent prompting and fine-tuning strategies, as it is currently lacking in\nthe literature. Some of our observations are: (i) training language models with\nraw evidence sentences (TBE-1) and overall claim-evidence understanding (TBE-2)\nresulted in an improvement up to 8.20% and 16.39% in macro-F1 for RAW-FC\ndataset, and (ii) training language models with entailed justifications (TBE-3)\noutperformed the baselines by a huge margin (up to 28.57% and 44.26% for\nLIAR-RAW and RAW-FC, respectively). We have shared our code repository to\nreproduce the results.",
    "pdf_url": "http://arxiv.org/pdf/2505.15050v2",
    "published": "2025-05-21T03:15:06+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15049v1",
    "title": "Towards a Working Definition of Designing Generative User Interfaces",
    "authors": [
      "Kyungho Lee"
    ],
    "abstract": "Generative UI is transforming interface design by facilitating AI-driven\ncollaborative workflows between designers and computational systems. This study\nestablishes a working definition of Generative UI through a multi-method\nqualitative approach, integrating insights from a systematic literature review\nof 127 publications, expert interviews with 18 participants, and analyses of 12\ncase studies. Our findings identify five core themes that position Generative\nUI as an iterative and co-creative process. We highlight emerging design\nmodels, including hybrid creation, curation-based workflows, and AI-assisted\nrefinement strategies. Additionally, we examine ethical challenges, evaluation\ncriteria, and interaction models that shape the field. By proposing a\nconceptual foundation, this study advances both theoretical discourse and\npractical implementation, guiding future HCI research toward responsible and\neffective generative UI design practices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15049v1",
    "published": "2025-05-21T03:14:09+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.2; D.2.2; H.1.2; I.3.6"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15048v1",
    "title": "Numerical modeling the mass feeding rates onto accretion-modified stars embedded within AGN disks",
    "authors": [
      "Yang Luo",
      "Jian-Min Wang"
    ],
    "abstract": "Accretion disks surrounding supermassive black holes can potentially form\nstars within the self-gravitating region. These stars undergo high accretion\nrates because of the dense environment of the active galactic nuclei (AGN)\naccretion disk. The vorticity of the AGN disk may influence the ultimate mass\nfeeding rate toward the star. In our study, we simulate mass feeding rates onto\nstars at different AGN disk thicknesses through 3D numerical models to explore\nthe relationship between feeding rates and the thermal mass of the star\n($q_{\\rm th}$), defined as the ratio of the star's Bondi radius to the AGN disk\nthickness. Our findings indicate that disk shearing with angular momentum can\nnotably decrease the feeding rate, and we provide an approximate formula that\nlinks the feeding rate based on the angular momentum of the surrounding gas and\nthe thermal mass $q_{\\rm th}$. Lastly, we examine the potential feedback of the\nrapidly accreting stars on the AGN disk and their subsequent evolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.15048v1",
    "published": "2025-05-21T03:09:53+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15047v1",
    "title": "PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration",
    "authors": [
      "Yingming Pu",
      "Tao Lin",
      "Hongyu Chen"
    ],
    "abstract": "Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate\nremarkable potential for scientific discovery. Existing approaches, however,\noften automate scientific discovery using predefined workflows that lack\nrationality constraints. This often leads to aimless hypothesizing and a\nfailure to consistently link hypotheses with evidence, thereby hindering\nsystematic uncertainty reduction. Overcoming these limitations fundamentally\nrequires systematic uncertainty reduction. We introduce \\texttt{PiFlow}, an\ninformation-theoretical framework, treating automated scientific discovery as a\nstructured uncertainty reduction problem guided by principles (e.g., scientific\nlaws). In evaluations across three distinct scientific domains -- discovering\nnanomaterial structures, bio-molecules, and superconductor candidates with\ntargeted properties -- our method significantly improves discovery efficiency,\nreflected by a 73.55\\% increase in the Area Under the Curve (AUC) of property\nvalues versus exploration steps, and enhances solution quality by 94.06\\%\ncompared to a vanilla agent system. Overall, \\texttt{PiFlow} serves as a\nPlug-and-Play method, establishing a novel paradigm shift in highly efficient\nautomated scientific discovery, paving the way for more robust and accelerated\nAI-driven research. Code is publicly available at our\n\\href{https://github.com/amair-lab/PiFlow}{GitHub}.",
    "pdf_url": "http://arxiv.org/pdf/2505.15047v1",
    "published": "2025-05-21T03:09:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15046v2",
    "title": "ChartCards: A Chart-Metadata Generation Framework for Multi-Task Chart Understanding",
    "authors": [
      "Yifan Wu",
      "Lutao Yan",
      "Leixian Shen",
      "Yinan Mei",
      "Jiannan Wang",
      "Yuyu Luo"
    ],
    "abstract": "The emergence of Multi-modal Large Language Models (MLLMs) presents new\nopportunities for chart understanding. However, due to the fine-grained nature\nof these tasks, applying MLLMs typically requires large, high-quality datasets\nfor task-specific fine-tuning, leading to high data collection and training\ncosts. To address this, we propose ChartCards, a unified chart-metadata\ngeneration framework for multi-task chart understanding. ChartCards\nsystematically synthesizes various chart information, including data tables,\nvisualization code, visual elements, and multi-dimensional semantic captions.\nBy structuring this information into organized metadata, ChartCards enables a\nsingle chart to support multiple downstream tasks, such as text-to-chart\nretrieval, chart summarization, chart-to-table conversion, chart description,\nand chart question answering. Using ChartCards, we further construct MetaChart,\na large-scale high-quality dataset containing 10,862 data tables, 85K charts,\nand 170 K high-quality chart captions. We validate the dataset through\nqualitative crowdsourcing evaluations and quantitative fine-tuning experiments\nacross various chart understanding tasks. Fine-tuning six different models on\nMetaChart resulted in an average performance improvement of 5% across all\ntasks. The most notable improvements are seen in text-to-chart retrieval and\nchart-to-table tasks, with Long-CLIP and Llama 3.2-11B achieving improvements\nof 17% and 28%, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.15046v2",
    "published": "2025-05-21T03:07:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.11038v1",
    "title": "MoTE: Mixture of Task-specific Experts for Pre-Trained ModelBased Class-incremental Learning",
    "authors": [
      "Linjie Li",
      "Zhenyu Wu",
      "Yang Ji"
    ],
    "abstract": "Class-incremental learning (CIL) requires deep learning models to\ncontinuously acquire new knowledge from streaming data while preserving\npreviously learned information. Recently, CIL based on pre-trained models\n(PTMs) has achieved remarkable success. However, prompt-based approaches suffer\nfrom prompt overwriting, while adapter-based methods face challenges such as\ndimensional misalignment between tasks. While the idea of expert fusion in\nMixture of Experts (MoE) can help address dimensional inconsistency, both\nexpert and routing parameters are prone to being overwritten in dynamic\nenvironments, making MoE challenging to apply directly in CIL. To tackle these\nissues, we propose a mixture of task-specific experts (MoTE) framework that\neffectively mitigates the miscalibration caused by inconsistent output\ndimensions across tasks. Inspired by the weighted feature fusion and sparse\nactivation mechanisms in MoE, we introduce task-aware expert filtering and\nreliable expert joint inference during the inference phase, mimicking the\nbehavior of routing layers without inducing catastrophic forgetting. Extensive\nexperiments demonstrate the superiority of our method without requiring an\nexemplar set. Furthermore, the number of tasks in MoTE scales linearly with the\nnumber of adapters. Building on this, we further explore the trade-off between\nadapter expansion and model performance and propose the Adapter-Limited MoTE.\nThe code is available at https://github.com/Franklilinjie/MoTE.",
    "pdf_url": "http://arxiv.org/pdf/2506.11038v1",
    "published": "2025-05-21T03:06:10+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15045v1",
    "title": "Diffusion vs. Autoregressive Language Models: A Text Embedding Perspective",
    "authors": [
      "Siyue Zhang",
      "Yilun Zhao",
      "Liyuan Geng",
      "Arman Cohan",
      "Anh Tuan Luu",
      "Chen Zhao"
    ],
    "abstract": "Large language model (LLM)-based embedding models, benefiting from large\nscale pre-training and post-training, have begun to surpass BERT and T5-based\nmodels on general-purpose text embedding tasks such as document retrieval.\nHowever, a fundamental limitation of LLM embeddings lies in the unidirectional\nattention used during autoregressive pre-training, which misaligns with the\nbidirectional nature of text embedding tasks. To this end, We propose adopting\ndiffusion language models for text embeddings, motivated by their inherent\nbidirectional architecture and recent success in matching or surpassing LLMs\nespecially on reasoning tasks. We present the first systematic study of the\ndiffusion language embedding model, which outperforms the LLM-based embedding\nmodel by 20% on long-document retrieval, 8% on reasoning-intensive retrieval,\n2% on instruction-following retrieval, and achieve competitive performance on\ntraditional text embedding benchmarks. Our analysis verifies that bidirectional\nattention is crucial for encoding global context in long and complex text.",
    "pdf_url": "http://arxiv.org/pdf/2505.15045v1",
    "published": "2025-05-21T02:59:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15044v1",
    "title": "Learning-based Airflow Inertial Odometry for MAVs using Thermal Anemometers in a GPS and vision denied environment",
    "authors": [
      "Ze Wang",
      "Jingang Qu",
      "Zhenyu Gao",
      "Pascal Morin"
    ],
    "abstract": "This work demonstrates an airflow inertial based odometry system with\nmulti-sensor data fusion, including thermal anemometer, IMU, ESC, and\nbarometer. This goal is challenging because low-cost IMUs and barometers have\nsignificant bias, and anemometer measurements are very susceptible to\ninterference from spinning propellers and ground effects. We employ a GRU-based\ndeep neural network to estimate relative air speed from noisy and disturbed\nanemometer measurements, and an observer with bias model to fuse the sensor\ndata and thus estimate the state of aerial vehicle. A complete flight data,\nincluding takeoff and landing on the ground, shows that the approach is able to\ndecouple the downwash induced wind speed caused by propellers and the ground\neffect, and accurately estimate the flight speed in a wind-free indoor\nenvironment. IMU, and barometer bias are effectively estimated, which\nsignificantly reduces the position integration drift, which is only 5.7m for\n203s manual random flight. The open source is available on\nhttps://github.com/SyRoCo-ISIR/Flight-Speed-Estimation-Airflow.",
    "pdf_url": "http://arxiv.org/pdf/2505.15044v1",
    "published": "2025-05-21T02:53:49+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15043v1",
    "title": "Histo-Planner: A Real-time Local Planner for MAVs Teleoperation based on Histogram of Obstacle Distribution",
    "authors": [
      "Ze Wang",
      "Zhenyu Gao",
      "Jingang Qu",
      "Pascal Morin"
    ],
    "abstract": "This paper concerns real-time obstacle avoidance for micro aerial vehicles\n(MAVs). Motivated by teleoperation applications in cluttered environments with\nlimited computational power, we propose a local planner that does not require\nthe knowledge or construction of a global map of the obstacles. The proposed\nsolution consists of a real-time trajectory planning algorithm that relies on\nthe histogram of obstacle distribution and a planner manager that triggers\ndifferent planning modes depending on obstacles location around the MAV. The\nproposed solution is validated, for a teleoperation application, with both\nsimulations and indoor experiments. Benchmark comparisons based on a designed\nsimulation platform are also provided.",
    "pdf_url": "http://arxiv.org/pdf/2505.15043v1",
    "published": "2025-05-21T02:53:12+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15042v1",
    "title": "GitHub Repository Complexity Leads to Diminished Web Archive Availability",
    "authors": [
      "David Calano",
      "Michele C. Weigle",
      "Michael L. Nelson"
    ],
    "abstract": "Software is often developed using versioned controlled software, such as Git,\nand hosted on centralized Web hosts, such as GitHub and GitLab. These Web\nhosted software repositories are made available to users in the form of\ntraditional HTML Web pages for each source file and directory, as well as a\npresentational home page and various descriptive pages. We examined more than\n12,000 Web hosted Git repository project home pages, primarily from GitHub, to\nmeasure how well their presentational components are preserved in the Internet\nArchive, as well as the source trees of the collected GitHub repositories to\nassess the extent to which their source code has been preserved. We found that\nmore than 31% of the archived repository home pages examined exhibited some\nform of minor page damage and 1.6% exhibited major page damage. We also found\nthat of the source trees analyzed, less than 5% of their source files were\narchived, on average, with the majority of repositories not having source files\nsaved in the Internet Archive at all. The highest concentration of archived\nsource files available were those linked directly from repositories' home pages\nat a rate of 14.89% across all available repositories and sharply dropping off\nat deeper levels of a repository's directory tree.",
    "pdf_url": "http://arxiv.org/pdf/2505.15042v1",
    "published": "2025-05-21T02:51:30+00:00",
    "categories": [
      "cs.DL",
      "cs.IR",
      "cs.SE"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15041v1",
    "title": "Co-optimize condenser water temperature and cooling tower fan using high-fidelity synthetic data",
    "authors": [
      "Gulai Shen",
      "Gurpreet Singh",
      "Ali Mehmani"
    ],
    "abstract": "This paper introduces a novel method for optimizing HVAC systems in buildings\nby integrating a high-fidelity physics-based simulation model with machine\nlearning and measured data. The method enables a real-time building advisory\nsystem that provides optimized settings for condenser water loop operation,\nassisting building operators in decision-making. The building and its HVAC\nsystem are first modeled using eQuest. Synthetic data are then generated by\nrunning the simulation multiple times. The data are then processed, cleaned,\nand used to train the machine learning model. The machine learning model\nenables real-time optimization of the condenser water loop using particle swarm\noptimization. The results deliver both a real-time online optimizer and an\noffline operation look-up table, providing optimized condenser water\ntemperature settings and the optimal number of cooling tower fans at a given\ncooling load. Potential savings are calculated by comparing measured data from\ntwo summer months with the energy costs the building would have experienced\nunder optimized settings. Adaptive model refinement is applied to further\nimprove accuracy and effectiveness by utilizing available measured data. The\nmethod bridges the gap between simulation and real-time control. It has the\npotential to be applied to other building systems, including the chilled water\nloop, heating systems, ventilation systems, and other related processes.\nCombining physics models, data models, and measured data also enables\nperformance analysis, tracking, and retrofit recommendations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15041v1",
    "published": "2025-05-21T02:50:54+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.15040v1",
    "title": "RLBenchNet: The Right Network for the Right Reinforcement Learning Task",
    "authors": [
      "Ivan Smirnov",
      "Shangding Gu"
    ],
    "abstract": "Reinforcement learning (RL) has seen significant advancements through the\napplication of various neural network architectures. In this study, we\nsystematically investigate the performance of several neural networks in RL\ntasks, including Long Short-Term Memory (LSTM), Multi-Layer Perceptron (MLP),\nMamba/Mamba-2, Transformer-XL, Gated Transformer-XL, and Gated Recurrent Unit\n(GRU). Through comprehensive evaluation across continuous control, discrete\ndecision-making, and memory-based environments, we identify\narchitecture-specific strengths and limitations. Our results reveal that: (1)\nMLPs excel in fully observable continuous control tasks, providing an optimal\nbalance of performance and efficiency; (2) recurrent architectures like LSTM\nand GRU offer robust performance in partially observable environments with\nmoderate memory requirements; (3) Mamba models achieve a 4.5x higher throughput\ncompared to LSTM and a 3.9x increase over GRU, all while maintaining comparable\nperformance; and (4) only Transformer-XL, Gated Transformer-XL, and Mamba-2\nsuccessfully solve the most challenging memory-intensive tasks, with Mamba-2\nrequiring 8x less memory than Transformer-XL. These findings provide insights\nfor researchers and practitioners, enabling more informed architecture\nselection based on specific task characteristics and computational constraints.\nCode is available at: https://github.com/SafeRL-Lab/RLBenchNet",
    "pdf_url": "http://arxiv.org/pdf/2505.15040v1",
    "published": "2025-05-21T02:49:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15039v1",
    "title": "LogiCase: Effective Test Case Generation from Logical Description in Competitive Programming",
    "authors": [
      "Sicheol Sung",
      "Aditi",
      "Dogyu kim",
      "Yo-Sub Han",
      "Sang-Ki Ko"
    ],
    "abstract": "Automated Test Case Generation (ATCG) is crucial for evaluating software\nreliability, particularly in competitive programming where robust algorithm\nassessments depend on diverse and accurate test cases. However, existing ATCG\nmethods often fail to meet complex specifications or generate effective corner\ncases, limiting their utility. In this work, we introduce Context-Free Grammars\nwith Counters (CCFGs), a formalism that captures both syntactic and semantic\nstructures in input specifications. Using a fine-tuned CodeT5 model, we\ntranslate natural language input specifications into CCFGs, enabling the\nsystematic generation of high-quality test cases. Experiments on the\nCodeContests dataset demonstrate that CCFG-based test cases outperform baseline\nmethods in identifying incorrect algorithms, achieving significant gains in\nvalidity and effectiveness. Our approach provides a scalable and reliable\ngrammar-driven framework for enhancing automated competitive programming\nevaluations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15039v1",
    "published": "2025-05-21T02:48:01+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15038v2",
    "title": "Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering",
    "authors": [
      "Haiyan Zhao",
      "Xuansheng Wu",
      "Fan Yang",
      "Bo Shen",
      "Ninghao Liu",
      "Mengnan Du"
    ],
    "abstract": "Linear concept vectors effectively steer LLMs, but existing methods suffer\nfrom noisy features in diverse datasets that undermine steering robustness. We\npropose Sparse Autoencoder-Denoised Concept Vectors (SDCV), which selectively\nkeep the most discriminative SAE latents while reconstructing hidden\nrepresentations. Our key insight is that concept-relevant signals can be\nexplicitly separated from dataset noise by scaling up activations of top-k\nlatents that best differentiate positive and negative samples. Applied to\nlinear probing and difference-in-mean, SDCV consistently improves steering\nsuccess rates by 4-16\\% across six challenging concepts, while maintaining\ntopic relevance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15038v2",
    "published": "2025-05-21T02:45:11+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15037v2",
    "title": "Spectral dimensions for one-dimensional critical long-range percolation",
    "authors": [
      "Zherui Fan",
      "Lu-Jing Huang"
    ],
    "abstract": "Consider the critical long-range percolation on $\\mathbb{Z}$, where an edge\nconnects $i$ and $j$ independently with probability\n$1-\\exp\\{-\\beta\\int_i^{i+1}\\int_j^{j+1}|u-v|^{-2}d ud v\\}$ for $|i-j|>1$ for\nsome fixed $\\beta>0$ and with probability 1 for $|i-j|=1$. We prove that both\nthe quenched and annealed spectral dimensions of the associated simple random\nwalk are $2/(1+\\delta)$, where $\\delta\\in (0,1)$ is the exponent of the\neffective resistance in the LRP model, as derived in [10, Theorem 1.1]. Our\nwork addresses an open question from [7, Section 5].",
    "pdf_url": "http://arxiv.org/pdf/2505.15037v2",
    "published": "2025-05-21T02:44:35+00:00",
    "categories": [
      "math.PR",
      "60K35, 82B27, 82B43"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15036v1",
    "title": "Fault-Tolerant Multi-Robot Coordination with Limited Sensing within Confined Environments",
    "authors": [
      "Kehinde O. Aina",
      "Hosain Bagheri",
      "Daniel I. Goldman"
    ],
    "abstract": "As robots are increasingly deployed to collaborate on tasks within shared\nworkspaces and resources, the failure of an individual robot can critically\naffect the group's performance. This issue is particularly challenging when\nrobots lack global information or direct communication, relying instead on\nsocial interaction for coordination and to complete their tasks. In this study,\nwe propose a novel fault-tolerance technique leveraging physical contact\ninteractions in multi-robot systems, specifically under conditions of limited\nsensing and spatial confinement. We introduce the \"Active Contact Response\"\n(ACR) method, where each robot modulates its behavior based on the likelihood\nof encountering an inoperative (faulty) robot. Active robots are capable of\ncollectively repositioning stationary and faulty peers to reduce obstructions\nand maintain optimal group functionality. We implement our algorithm in a team\nof autonomous robots, equipped with contact-sensing and collision-tolerance\ncapabilities, tasked with collectively excavating cohesive model pellets.\nExperimental results indicate that the ACR method significantly improves the\nsystem's recovery time from robot failures, enabling continued collective\nexcavation with minimal performance degradation. Thus, this work demonstrates\nthe potential of leveraging local, social, and physical interactions to enhance\nfault tolerance and coordination in multi-robot systems operating in\nconstrained and extreme environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.15036v1",
    "published": "2025-05-21T02:43:36+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15035v1",
    "title": "Selective profiling of non-canonical nucleic acid structures via size-discriminative supramolecular probes",
    "authors": [
      "Runyu Shi",
      "Dan Huang",
      "Yanxi Wang",
      "Qiuju Zhou",
      "Zhenzhen Zhao",
      "Binwu Ying",
      "Qianfan Yang",
      "Feng Li"
    ],
    "abstract": "Nucleic acids can form diverse non-canonical structures, such as\nG-quadruplexes (G4s) and i-motifs (iMs), which are critical in biological\nprocesses and disease pathways. This study presents an innovative probe design\nstrategy based on groove size differences, leading to the development of\nBT-Cy-1, a supramolecular cyanine probe optimized by fine-tuning dimer\n\"thickness\". BT-Cy-1 demonstrated high sensitivity in detecting structural\ntransitions and variations in G4s and iMs, even in complex environments with\nexcess dsDNA. Applied to clinical blood samples, it revealed significant\ndifferences in RNA G4 and iM levels between liver cancer patients and healthy\nindividuals, marking the first report of altered iM levels in clinical samples.\nThis work highlights a novel approach for precise nucleic acid structural\nprofiling, offering insights into their biological significance and potential\nin disease diagnostics.",
    "pdf_url": "http://arxiv.org/pdf/2505.15035v1",
    "published": "2025-05-21T02:43:18+00:00",
    "categories": [
      "q-bio.BM"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2505.15034v1",
    "title": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning",
    "authors": [
      "Kaiwen Zha",
      "Zhengqi Gao",
      "Maohao Shen",
      "Zhang-Wei Hong",
      "Duane S. Boning",
      "Dina Katabi"
    ],
    "abstract": "Reinforcement learning (RL) has recently emerged as a compelling approach for\nenhancing the reasoning capabilities of large language models (LLMs), where an\nLLM generator serves as a policy guided by a verifier (reward model). However,\ncurrent RL post-training methods for LLMs typically use verifiers that are\nfixed (rule-based or frozen pretrained) or trained discriminatively via\nsupervised fine-tuning (SFT). Such designs are susceptible to reward hacking\nand generalize poorly beyond their training distributions. To overcome these\nlimitations, we propose Tango, a novel framework that uses RL to concurrently\ntrain both an LLM generator and a verifier in an interleaved manner. A central\ninnovation of Tango is its generative, process-level LLM verifier, which is\ntrained via RL and co-evolves with the generator. Importantly, the verifier is\ntrained solely based on outcome-level verification correctness rewards without\nrequiring explicit process-level annotations. This generative RL-trained\nverifier exhibits improved robustness and superior generalization compared to\ndeterministic or SFT-trained verifiers, fostering effective mutual\nreinforcement with the generator. Extensive experiments demonstrate that both\ncomponents of Tango achieve state-of-the-art results among 7B/8B-scale models:\nthe generator attains best-in-class performance across five competition-level\nmath benchmarks and four challenging out-of-domain reasoning tasks, while the\nverifier leads on the ProcessBench dataset. Remarkably, both components exhibit\nparticularly substantial improvements on the most difficult mathematical\nreasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango.",
    "pdf_url": "http://arxiv.org/pdf/2505.15034v1",
    "published": "2025-05-21T02:43:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15033v1",
    "title": "Toward Task Capable Active Matter: Learning to Avoid Clogging in Confined Collectives via Collisions",
    "authors": [
      "Kehinde O. Aina",
      "Ram Avinery",
      "Hui-Shun Kuan",
      "Meredith D. Betterton",
      "Michael A. D. Goodisman",
      "Daniel I. Goldman"
    ],
    "abstract": "Social organisms which construct nests consisting of tunnels and chambers\nnecessarily navigate confined and crowded conditions. Unlike low-density\ncollectives like bird flocks and insect swarms, in which hydrodynamic and\nstatistical phenomena dominate, the physics of glasses and supercooled fluids\nis important to understand clogging behaviors in high-density collectives. Our\nprevious work revealed that fire ants flowing in confined tunnels utilize\ndiverse behaviors like unequal workload distributions, spontaneous direction\nreversals, and limited interaction times to mitigate clogging and jamming and\nthus maintain functional flow; implementation of similar rules in a small\nrobophysical swarm led to high performance through spontaneous dissolution of\nclogs and clusters. However, how the insects learn such behaviors, and how we\ncan develop \"task capable\" active matter in such regimes, remains a challenge\nin part because interaction dynamics are dominated by local, time-consuming\ncollisions and no single agent can guide the entire collective. Here, we\nhypothesized that effective flow and clog mitigation could emerge purely\nthrough local learning. We tasked small groups of robots with pellet excavation\nin a narrow tunnel, allowing them to modify reversal probabilities over time.\nInitially, robots had equal probabilities and clogs were common. Reversals\nimproved flow. When reversal probabilities adapted via collisions and noisy\ntunnel length estimates, workload inequality and performance improved. Our\nrobophysical study of an excavating swarm shows that, despite the seeming\ncomplexity and difficulty of the task, simple learning rules can mitigate or\nleverage unavoidable features in task-capable dense active matter, leading to\nhypotheses for dense biological and robotic swarms.",
    "pdf_url": "http://arxiv.org/pdf/2505.15033v1",
    "published": "2025-05-21T02:42:32+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15032v2",
    "title": "Orthogonal Arrays: A Review",
    "authors": [
      "C. Devon Lin",
      "John Stufken"
    ],
    "abstract": "Orthogonal arrays are arguably one of the most fascinating and important\nstatistical tools for efficient data collection. They have a simple, natural\ndefinition, desirable properties when used as fractional factorials, and a rich\nand beautiful mathematical theory. Their connections with combinatorics, finite\nfields, geometry, and error-correcting codes are profound. Orthogonal arrays\nhave been widely used in agriculture, engineering, manufacturing, and\nhigh-technology industries for quality and productivity improvement\nexperiments. In recent years, they have drawn rapidly growing interest from\nvarious fields such as computer experiments, integration, visualization,\noptimization, big data, machine learning/artificial intelligence through\nsuccessful applications in those fields. We review the fundamental concepts and\nstatistical properties and report recent developments. Discussions of recent\napplications and connections with various fields are presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.15032v2",
    "published": "2025-05-21T02:30:28+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.11037v3",
    "title": "Mini-Game Lifetime Value Prediction in WeChat",
    "authors": [
      "Aochuan Chen",
      "Yifan Niu",
      "Ziqi Gao",
      "Yujie Sun",
      "Shoujun Liu",
      "Gong Chen",
      "Yang Liu",
      "Jia Li"
    ],
    "abstract": "The LifeTime Value (LTV) prediction, which endeavors to forecast the\ncumulative purchase contribution of a user to a particular item, remains a\nvital challenge that advertisers are keen to resolve. A precise LTV prediction\nsystem enhances the alignment of user interests with meticulously designed\nadvertisements, thereby generating substantial profits for advertisers.\nNonetheless, this issue is complicated by the paucity of data typically\nobserved in real-world advertising scenarios. The purchase rate among\nregistered users is often as critically low as 0.1%, resulting in a dataset\nwhere the majority of users make only several purchases. Consequently, there is\ninsufficient supervisory signal for effectively training the LTV prediction\nmodel. An additional challenge emerges from the interdependencies among tasks\nwith high correlation. It is a common practice to estimate a user's\ncontribution to a game over a specified temporal interval. Varying the lengths\nof these intervals corresponds to distinct predictive tasks, which are highly\ncorrelated. For instance, predictions over a 7-day period are heavily reliant\non forecasts made over a 3-day period, where exceptional cases can adversely\naffect the accuracy of both tasks. In order to comprehensively address the\naforementioned challenges, we introduce an innovative framework denoted as\nGraph-Represented Pareto-Optimal LifeTime Value prediction (GRePO-LTV). Graph\nrepresentation learning is initially employed to address the issue of data\nscarcity. Subsequently, Pareto-Optimization is utilized to manage the\ninterdependence of prediction tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.11037v3",
    "published": "2025-05-21T02:28:26+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15031v1",
    "title": "Are the confidence scores of reviewers consistent with the review content? Evidence from top conference proceedings in AI",
    "authors": [
      "Wenqing Wu",
      "Haixu Xi",
      "Chengzhi Zhang"
    ],
    "abstract": "Peer review is vital in academia for evaluating research quality. Top AI\nconferences use reviewer confidence scores to ensure review reliability, but\nexisting studies lack fine-grained analysis of text-score consistency,\npotentially missing key details. This work assesses consistency at word,\nsentence, and aspect levels using deep learning and NLP conference review data.\nWe employ deep learning to detect hedge sentences and aspects, then analyze\nreport length, hedge word/sentence frequency, aspect mentions, and sentiment to\nevaluate text-score alignment. Correlation, significance, and regression tests\nexamine confidence scores' impact on paper outcomes. Results show high\ntext-score consistency across all levels, with regression revealing higher\nconfidence scores correlate with paper rejection, validating expert assessments\nand peer review fairness.",
    "pdf_url": "http://arxiv.org/pdf/2505.15031v1",
    "published": "2025-05-21T02:26:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.11036v1",
    "title": "Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification",
    "authors": [
      "Yang Qin",
      "Chao Chen",
      "Zhihang Fu",
      "Dezhong Peng",
      "Xi Peng",
      "Peng Hu"
    ],
    "abstract": "Despite remarkable advancements in text-to-image person re-identification\n(TIReID) facilitated by the breakthrough of cross-modal embedding models,\nexisting methods often struggle to distinguish challenging candidate images due\nto intrinsic limitations, such as network architecture and data quality. To\naddress these issues, we propose an Interactive Cross-modal Learning framework\n(ICL), which leverages human-centered interaction to enhance the\ndiscriminability of text queries through external multimodal knowledge. To\nachieve this, we propose a plug-and-play Test-time Humane-centered Interaction\n(THI) module, which performs visual question answering focused on human\ncharacteristics, facilitating multi-round interactions with a multimodal large\nlanguage model (MLLM) to align query intent with latent target images.\nSpecifically, THI refines user queries based on the MLLM responses to reduce\nthe gap to the best-matching images, thereby boosting ranking accuracy.\nAdditionally, to address the limitation of low-quality training texts, we\nintroduce a novel Reorganization Data Augmentation (RDA) strategy based on\ninformation enrichment and diversity enhancement to enhance query\ndiscriminability by enriching, decomposing, and reorganizing person\ndescriptions. Extensive experiments on four TIReID benchmarks, i.e.,\nCUHK-PEDES, ICFG-PEDES, RSTPReid, and UFine6926, demonstrate that our method\nachieves remarkable performance with substantial improvement.",
    "pdf_url": "http://arxiv.org/pdf/2506.11036v1",
    "published": "2025-05-21T02:26:17+00:00",
    "categories": [
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15030v3",
    "title": "Harnessing On-Device Large Language Model: Empirical Results and Implications for AI PC",
    "authors": [
      "Qingyu Song",
      "Peiyu Liao",
      "Wenqian Zhao",
      "Yiwen Wang",
      "Shoubo Hu",
      "Hui-Ling Zhen",
      "Ning Jiang",
      "Mingxuan Yuan"
    ],
    "abstract": "The increasing deployment of Large Language Models (LLMs) on edge devices,\ndriven by model advancements and hardware improvements, offers significant\nprivacy benefits. However, these on-device LLMs inherently face performance\nlimitations due to reduced model capacity and necessary compression techniques.\nTo address this, we introduce a systematic methodology -- encompassing model\ncapability, development efficiency, and system resources -- for evaluating\non-device LLMs. Our comprehensive evaluation, encompassing models from 0.5B to\n14B parameters and seven post-training quantization (PTQ) methods on commodity\nlaptops, yields several critical insights: 1) System-level metrics exhibit\nnear-linear scaling with effective bits-per-weight (BPW). 2) A practical\nthreshold exists around $\\sim$3.5 effective BPW, larger models subjected to\nlow-bit quantization consistently outperform smaller models utilizing higher\nbit-precision. 3) Quantization with low BPW incurs marginal accuracy loss but\nsignificant memory savings. 4) Determined by low-level implementation specifics\npower consumption on CPU, where computation-intensive operations spend more\npower than memory-intensive ones. These findings offer crucial insights and\npractical guidelines for the efficient deployment and optimized configuration\nof LLMs on resource-constrained edge devices. Our codebase is available at\nhttps://github.com/simmonssong/LLMOnDevice.",
    "pdf_url": "http://arxiv.org/pdf/2505.15030v3",
    "published": "2025-05-21T02:23:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15029v1",
    "title": "Improving Beam Granularity Performance of Reconfigurable Refelctarray Radars via Spatial Quantization and Phase Quantization Approach",
    "authors": [
      "Xiaocun Zong",
      "Fan Yang",
      "Shenheng Xu",
      "Maokun Li"
    ],
    "abstract": "In this paper, the impacts of spatial quantization and phase quantization on\nthe beam granularity characteristic of reconfigurable reflectarray (RRA) radars\nare systematically investigated. From the perspective of the difference beam, a\ntheoretical analysis is conducted to derive the factors influencing beam\ngranularity. To validate the theoretical findings, simulations are performed\nunder various quantization scenarios: specifically, 1-bit, 2-bit, and 3-bit\nspatial quantization with 1-bit phase quantization, as well as 1-bit, 2-bit,\nand 3-bit phase quantization with 1-bit spatial quantization. The experimental\nresults demonstrate that both spatial quantization and phase quantization\neffectively reduce beam granularity in reconfigurable reflectarray radars,\nthereby enhancing the angular resolution of the beam. These findings offer\nvaluable insights and practical reference for beam-tracking applications in\nradar and communications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15029v1",
    "published": "2025-05-21T02:22:00+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15028v1",
    "title": "Analyzing Stellar and Interstellar Contributions to Polarization: Modeling Approaches for Hot Stars",
    "authors": [
      "R Ignace",
      "A G Fullard",
      "G V Panopoulou",
      "D J Hillier",
      "C Erba",
      "P A Scowen"
    ],
    "abstract": "Linear polarimetry of unresolved stars is a powerful method for discerning or\nconstraining the geometry of a source and its environment, since spherical\nsources produce no net polarization. However, a general challenge to\ninterpreting intrinsic stellar polarization is the contribution to the signal\nby interstellar polarization (ISP). Here, we review methodologies for\ndistinguishing the stellar signal from the interstellar contribution in the\ncontext of massive stars. We first characterize ISP with distance using a\nrecent compilation of starlight polarization catalogs. Several scenarios\ninvolving Thomson scattering, rapidly rotating stars, optically thick winds,\nand interacting binaries are considered specifically to contrast the\nwavelength-dependent effects of ISP in the ultraviolet versus optical bands.\nISP is recognizable in the stellar polarization from Thomson scattering in the\npolarization position angle rotations. For hot stars with near-critical\nrotation rates, the ISP declines whereas the stellar continuum polarization\nsharply increases. In the case of quite dense winds, strong ultraviolet lines\ntrace the ISP, which is not always the case in the optical. In the binary case,\ntemporal and chromatic effects illustrate how the ISP displaces variable\npolarization with wavelength. This study clarifies the impacts of ISP in\nrelation to new ultraviolet spectropolarimetry efforts such as Polstar and\nPollux.",
    "pdf_url": "http://arxiv.org/pdf/2505.15028v1",
    "published": "2025-05-21T02:20:54+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15027v1",
    "title": "Rethinking Habitability using Biogenic Precursors: Formaldehyde in Millimeter Molecular Clouds of the Inner Galaxy",
    "authors": [
      "Nursyazela Badrina Baharin",
      "Affan Adly Nazri",
      "Zulfazli Rosli",
      "Zamri Zainal Abidin",
      "Hairul Anuar Tajuddin",
      "Jarken Esimbek",
      "Dalei Li",
      "Xiaoke Tang"
    ],
    "abstract": "We present a comprehensive study of formaldehyde (H2CO) absorption and radio\nrecombination line (H110a) emission in 215 molecular clouds from the Bolocam\nGalactic Plane Survey (BGPS), observed using the Nanshan 25-m radio telescope.\nH2CO was detected in 88 sources (40.93 percent) with 59 being new detections,\nwhile H110a emission was found in only 11 sources (5.12 percent), all\ncoincident with H2CO absorption. There exists a correlation of H2CO fluxes with\nmillimeter fluxes below a 3 Jy threshold and an increased dispersion above it,\nsuggesting the sub-CMB cooling of H2CO. Cross-matching with kinematic distance\ncatalogs revealed H2CO spanning galactocentric distances from 0.216 to 10.769\nkpc, with column densities ranging from 7.82 x 10^11 to 6.69 x 10^14 cm-2. A\nsignificant inverse correlation was observed between H2CO detection fraction\nand galactocentric distance, suggesting enhanced star forming activity closer\nto the Galactic Center. These findings challenge traditional Galactic Habitable\nZone (GHZ) models by demonstrating the presence of biogenic precursors in the\ninner Galaxy, shielded within dense molecular clouds. Our results underscore\nthe importance of incorporating chemical tracers like H2CO, alongside physical\nconstraints, to refine the boundaries of the GHZ and advance the research of\nprebiotic chemistry in the Milky Way.",
    "pdf_url": "http://arxiv.org/pdf/2505.15027v1",
    "published": "2025-05-21T02:20:02+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.15026v1",
    "title": "Enhanced Tunable Photon Pair Generation from Nonlinear Metasurface with Guided-Mode Cavity",
    "authors": [
      "Tongmiao Fan",
      "Jihua Zhang",
      "Andrey A. Sukhorukov"
    ],
    "abstract": "The ability to generate quantum entangled photon pairs through spontaneous\nparametric down conversion (SPDC) is playing a pivotal role in many\napplications in quantum technologies, including quantum communications, quantum\ncomputation, and quantum imaging. Metasurfaces, two-dimensional arrays of\nnanostructures with subwavelength thickness, have recently shown extraordinary\ncapability in manipulating classical and quantum states of light and realizing\nminiaturized SPDC sources. Whereas previous studies have primarily focused on\nperiodic metasurfaces, we uncover the potential of spatially modulated\nnanopatterns for further SPDC enhancement and state engineering. Specifically,\nwe propose a nonlinear metasurface featuring a lateral guided-mode cavity\nformed by two distributed Bragg reflectors. With the quasi-normal mode theory,\nwe predict an SPDC rate up to 157 Hz/mW, which represents about 30 times rate\nenhancement when compared to the metasurface without a cavity. Furthermore, the\ncavity supports a continuous set of high-Q resonances across a broad bandwidth,\nallowing the all-optical tuning of the photon-pair emission directions\ntransverse to the cavity by controlling the pump wavelength, which can find\napplications in quantum imaging.",
    "pdf_url": "http://arxiv.org/pdf/2505.15026v1",
    "published": "2025-05-21T02:19:04+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.15025v1",
    "title": "Inverse Optimization via Learning Feasible Regions",
    "authors": [
      "Ke Ren",
      "Peyman Mohajerin Esfahani",
      "Angelos Georghiou"
    ],
    "abstract": "We study inverse optimization (IO), where the goal is to use a parametric\noptimization program as the hypothesis class to infer relationships between\ninput-decision pairs. Most of the literature focuses on learning only the\nobjective function, as learning the constraint function (i.e., feasible\nregions) leads to nonconvex training programs. Motivated by this, we focus on\nlearning feasible regions for known linear objectives and introduce two\ntraining losses along with a hypothesis class to parameterize the constraint\nfunction. Our hypothesis class surpasses the previous objective-only method by\nnaturally capturing discontinuous behaviors in input-decision pairs. We\nintroduce a customized block coordinate descent algorithm with a smoothing\ntechnique to solve the training problems, while for further restricted\nhypothesis classes, we reformulate the training optimization as a tractable\nconvex program or mixed integer linear program. Synthetic experiments and two\npower system applications, including comparisons with state-of-the-art\napproaches, showcase and validate the proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.15025v1",
    "published": "2025-05-21T02:17:03+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.18196v1",
    "title": "Comment on \"Politicizing science funding undermines public trust in science, academic freedom, and the unbiased generation of knowledge\"",
    "authors": [
      "John M. Herbert"
    ],
    "abstract": "In a commentary published in mid-2024 (to which the present work is a direct\nresponse), a number of scientists argue that U.S. funding agencies have\n\"politicized\" the process by which grants are awarded, in service of\ndiversifying the scientific workforce. The commentary in question, however,\nmakes numerous unfounded assertions while recycling citations to a fusillade of\nopinion essays written by the same cabal of authors, in an effort to resemble a\nwork of serious scholarship. Basic fact-checking is provided here,\ndemonstrating numerous claims that are unsupported by the source material and\nreadily debunked. The present work also serves to document the reality of\ninclusion and diversity plans for scientific grant proposals to U.S. funding\nagencies, as they existed at the end of 2024. It is intended as a bulwark\nagainst retroactive false narratives, as the U.S. moves into a period of\nintense antagonism towards diversity, equity, and inclusion activities.",
    "pdf_url": "http://arxiv.org/pdf/2505.18196v1",
    "published": "2025-05-21T02:13:56+00:00",
    "categories": [
      "cs.DL",
      "physics.chem-ph",
      "physics.soc-ph"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15024v2",
    "title": "Diagnosing our datasets: How does my language model learn clinical information?",
    "authors": [
      "Furong Jia",
      "David Sontag",
      "Monica Agrawal"
    ],
    "abstract": "Large language models (LLMs) have performed well across various clinical\nnatural language processing tasks, despite not being directly trained on\nelectronic health record (EHR) data. In this work, we examine how popular\nopen-source LLMs learn clinical information from large mined corpora through\ntwo crucial but understudied lenses: (1) their interpretation of clinical\njargon, a foundational ability for understanding real-world clinical notes, and\n(2) their responses to unsupported medical claims. For both use cases, we\ninvestigate the frequency of relevant clinical information in their\ncorresponding pretraining corpora, the relationship between pretraining data\ncomposition and model outputs, and the sources underlying this data. To isolate\nclinical jargon understanding, we evaluate LLMs on a new dataset MedLingo.\nUnsurprisingly, we find that the frequency of clinical jargon mentions across\nmajor pretraining corpora correlates with model performance. However, jargon\nfrequently appearing in clinical notes often rarely appears in pretraining\ncorpora, revealing a mismatch between available data and real-world usage.\nSimilarly, we find that a non-negligible portion of documents support disputed\nclaims that can then be parroted by models. Finally, we classified and analyzed\nthe types of online sources in which clinical jargon and unsupported medical\nclaims appear, with implications for future dataset composition.",
    "pdf_url": "http://arxiv.org/pdf/2505.15024v2",
    "published": "2025-05-21T02:13:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15023v1",
    "title": "Towards a Science of Causal Interpretability in Deep Learning for Software Engineering",
    "authors": [
      "David N. Palacio"
    ],
    "abstract": "This dissertation addresses achieving causal interpretability in Deep\nLearning for Software Engineering (DL4SE). While Neural Code Models (NCMs) show\nstrong performance in automating software tasks, their lack of transparency in\ncausal relationships between inputs and outputs limits full understanding of\ntheir capabilities. To build trust in NCMs, researchers and practitioners must\nexplain code predictions. Associational interpretability, which identifies\ncorrelations, is often insufficient for tasks requiring intervention and change\nanalysis. To address this, the dissertation introduces DoCode, a novel post hoc\ninterpretability method for NCMs. DoCode uses causal inference to provide\nprogramming language-oriented explanations of model predictions. It follows a\nfour-step pipeline: modeling causal problems using Structural Causal Models\n(SCMs), identifying the causal estimand, estimating effects with metrics like\nAverage Treatment Effect (ATE), and refuting effect estimates. Its framework is\nextensible, with an example that reduces spurious correlations by grounding\nexplanations in programming language properties. A case study on deep code\ngeneration across interpretability scenarios and various deep learning\narchitectures demonstrates DoCode's benefits. Results show NCMs' sensitivity to\ncode syntax changes and their ability to learn certain programming concepts\nwhile minimizing confounding bias. The dissertation also examines associational\ninterpretability as a foundation, analyzing software information's causal\nnature using tools like COMET and TraceXplainer for traceability. It highlights\nthe need to identify code confounders and offers practical guidelines for\napplying causal interpretability to NCMs, contributing to more trustworthy AI\nin software engineering.",
    "pdf_url": "http://arxiv.org/pdf/2505.15023v1",
    "published": "2025-05-21T02:13:11+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15022v1",
    "title": "Infinite hierarchical contrastive clustering for personal digital envirotyping",
    "authors": [
      "Ya-Yun Huang",
      "Joseph McClernon",
      "Jason A. Oliver",
      "Matthew M. Engelhard"
    ],
    "abstract": "Daily environments have profound influence on our health and behavior. Recent\nwork has shown that digital envirotyping, where computer vision is applied to\nimages of daily environments taken during ecological momentary assessment\n(EMA), can be used to identify meaningful relationships between environmental\nfeatures and health outcomes of interest. To systematically study such effects\non an individual level, it is helpful to group images into distinct\nenvironments encountered in an individual's daily life; these may then be\nanalyzed, further grouped into related environments with similar features, and\nlinked to health outcomes. Here we introduce infinite hierarchical contrastive\nclustering to address this challenge. Building on the established contrastive\nclustering framework, our method a) allows an arbitrary number of clusters\nwithout requiring the full Dirichlet Process machinery by placing a\nstick-breaking prior on predicted cluster probabilities; and b) encourages\ndistinct environments to form well-defined sub-clusters within each cluster of\nrelated environments by incorporating a participant-specific prediction loss.\nOur experiments show that our model effectively identifies distinct personal\nenvironments and groups these environments into meaningful environment types.\nWe then illustrate how the resulting clusters can be linked to various health\noutcomes, highlighting the potential of our approach to advance the\nenvirotyping paradigm.",
    "pdf_url": "http://arxiv.org/pdf/2505.15022v1",
    "published": "2025-05-21T02:11:23+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15021v1",
    "title": "Characterizing errors in parameter estimation by local measurements",
    "authors": [
      "Riddhi Ghosh",
      "Alexei Gilchrist",
      "Daniel Burgarth"
    ],
    "abstract": "The indirect estimation of couplings in quantum dynamics relies on the\nmeasurement of the spectrum and the overlap of eigenvectors with some reference\nstates. This data can be obtained by local measurements on some sites and\neliminates the need for full Hamiltonian tomography. For a 1D chain, access to\nonly one edge site is sufficient to compute all the couplings between the\nadjacent sites, and consequently to reconstruct the full Hamiltonian. However,\nits robustness in the presence of perturbations remains a critical question,\nparticularly when sites interact with other lattice sites beyond nearest\nneighbors.\n  Our work studies the applicability of schemes designed for 1D chains to\ntopologies with interactions beyond nearest-neighbour. We treat interactions\nbetween the next-nearest sites as perturbation of strength $\\varepsilon$ and\nshow that the error in estimation of couplings scales linearly with\n$\\varepsilon$ in the presence of such interactions. Further, we show that on\naverage, the existence of couplings between sites beyond the next-nearest\nneighbour results in higher error. We also study the length of the chain that\ncan be estimated (up to a fixed precision) as a function of $\\varepsilon$, in\nthe presence of next-nearest neighbour interactions. Typically, for weak\ninteractions, chains of 40 sites can be estimated within reasonable error.\nThus, we study the robustness of estimation scheme designed for a 1D chain when\nexposed to such multi-site perturbations, offering valuable insights into its\napplicability and limitations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15021v1",
    "published": "2025-05-21T02:02:23+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15020v1",
    "title": "COSMIC: Enabling Full-Stack Co-Design and Optimization of Distributed Machine Learning Systems",
    "authors": [
      "Aditi Raju",
      "Jared Ni",
      "William Won",
      "Changhai Man",
      "Srivatsan Krishnan",
      "Srinivas Sridharan",
      "Amir Yazdanbakhsh",
      "Tushar Krishna",
      "Vijay Janapa Reddi"
    ],
    "abstract": "Large-scale machine learning models necessitate distributed systems, posing\nsignificant design challenges due to the large parameter space across distinct\ndesign stacks. Existing studies often focus on optimizing individual system\naspects in isolation. This work challenges this limitation and introduces\nCOSMIC, a full-stack distributed machine learning systems environment enabling\nend-to-end simulation and agent-based design space exploration. To facilitate\nefficient exploration and optimization across the entire stack, we introduce\nParameter Set Architecture-an abstraction concept analogous to the instruction\nset architecture-abstracting away configuration complexities of agent-based\nsearch methods. Case studies demonstrate COSMIC's ability to consolidate\nparameters across multiple layers of design abstraction, discovering eight\nnon-obvious high-performance system configurations across four\ntransformer-based models with up to 175 billion parameters. By optimizing\nacross the stack, COSMIC full-stack optimization delivers 1.50-48.41x higher\nperformance compared to the isolated single-stack optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.15020v1",
    "published": "2025-05-21T01:57:22+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15019v1",
    "title": "Sensitivity of the Hyper-Kamiokande experiment to neutrino oscillation parameters using acceleration neutrinos",
    "authors": [
      "Hyper-Kamiokande Collaboration"
    ],
    "abstract": "This paper describes the analysis to estimate the sensitivity of the\nHyper-Kamiokande experiment to long-baseline neutrino oscillation parameters\nusing accelerator (anti)neutrinos. Results are presented for the CPV discovery\nsensitivity and precision measurements of the oscillation parameters\n$\\delta_{CP}$, $\\sin^2\\theta_{23}$, $\\Delta m^2_{32}$ and $\\sin^2\\theta_{13}$.\nWith the assumed Hyper-Kamiokande running plan, a $5\\sigma$ CPV discovery is\npossible in less than three years in the case of maximal CPV and known MO.In\nthe absence of external constraints on the MO, considering the MO sensitivity\nof the Hyper-Kamiokande measurement using atmospheric neutrinos, the time for a\nCPV discovery could be estimated to be around six years. Using the nominal\nfinal exposure of $27 \\times 10^{21}$ protons on target, corresponding to 10\nyears, with a ratio of 1:3 in neutrino to antineutrino beam mode, we expect to\nselect approximately 10000 charged current, quasi-elastic-like, muon neutrino\nevents, and a similar number of muon anti-neutrino events. In the electron\n(anti)neutrino appearance channels, we expect approximately 2000 charged\ncurrent, quasi-elastic-like electron neutrino events and 800 electron\nantineutrino events. These larges event samples will allow Hyper-Kamiokande to\nexclude CP conservation at the $5\\sigma$significance level for over 60% of the\npossible true values of $\\delta_{CP}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.15019v1",
    "published": "2025-05-21T01:56:34+00:00",
    "categories": [
      "hep-ex",
      "physics.ins-det"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.15018v1",
    "title": "Non-Factorizing Interface in the Two-Dimensional Long-Range Ising Model",
    "authors": [
      "Dongsheng Ge",
      "Yu Nakayama"
    ],
    "abstract": "The factorization proposal claims that the co-dimension one \"pinning defect\",\non which a local relevant operator is integrated, factorizes the space into two\nhalves in general conformal field theories in the infrared limit. In this\nletter, we study a two-dimensional long-range Ising model at criticality with a\nline defect or an interface, which physically corresponds to changing the local\ntemperature on it. We show that in the perturbative regime, it is not\nfactorizing even in the infrared limit. An intuitive explanation of the\nnon-factorization is that the long-range Ising model is equivalent to a local\nconformal field theory in higher dimensions. In this picture, the space is\nstill connected through the \"extra dimension\" across the defect line.",
    "pdf_url": "http://arxiv.org/pdf/2505.15018v1",
    "published": "2025-05-21T01:55:47+00:00",
    "categories": [
      "hep-th",
      "cond-mat.stat-mech"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.15017v1",
    "title": "PsyScam: A Benchmark for Psychological Techniques in Real-World Scams",
    "authors": [
      "Shang Ma",
      "Tianyi Ma",
      "Jiahao Liu",
      "Wei Song",
      "Zhenkai Liang",
      "Xusheng Xiao",
      "Yanfang Ye"
    ],
    "abstract": "Online scams have become increasingly prevalent, with scammers using\npsychological techniques (PTs) to manipulate victims. While existing research\nhas developed benchmarks to study scammer behaviors, these benchmarks do not\nadequately reflect the PTs observed in real-world scams. To fill this gap, we\nintroduce PsyScam, a benchmark designed to systematically capture and evaluate\nPTs embedded in real-world scam reports. In particular, PsyScam bridges\npsychology and real-world cyber security analysis through collecting a wide\nrange of scam reports from six public platforms and grounding its annotations\nin well-established cognitive and psychological theories. We further\ndemonstrate PsyScam's utility through three downstream tasks: PT\nclassification, scam completion, and scam augmentation. Experimental results\nshow that PsyScam presents significant challenges to existing models in both\ndetecting and generating scam content based on the PTs used by real-world\nscammers. Our code and dataset are available at:\nhttps://anonymous.4open.science/r/PsyScam-66E4.",
    "pdf_url": "http://arxiv.org/pdf/2505.15017v1",
    "published": "2025-05-21T01:55:04+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.15016v1",
    "title": "Two-Terminal Electrical Detection of the N√©el Vector via Longitudinal Antiferromagnetic Nonreciprocal Transport",
    "authors": [
      "Guozhi Long",
      "Hui Zeng",
      "Mingxiang Pan",
      "Wenhui Duan",
      "Huaqing Huang"
    ],
    "abstract": "We propose a robust two-terminal electrical readout scheme for detecting the\nN\\'eel vector orientation in antiferromagnetic (AFM) materials by leveraging\nlongitudinal nonreciprocal transport driven by quantum metric dipoles. Unlike\nconventional readout mechanisms, our approach does not require spin-polarized\nelectrodes, tunneling junctions, or multi-terminal geometries, offering a\nuniversal and scalable solution for AFM spintronics. As examples, we\ndemonstrate pronounced second-order longitudinal nonlinear conductivity (LNC)\nin two-dimensional (2D) MnS and 3D CuMnAs, both of which exhibit clear sign\nreversal of LNC under 180$^\\circ$ N\\'eel vector reorientation. We show that\nthis LNC is predominantly governed by the intrinsic,\nrelaxation-time-independent quantum metric mechanism rather than the extrinsic\nnonlinear Drude effect. Our findings provide a practical and material-general\npathway for electrically reading AFM memory states, with promising implications\nfor next-generation AFM spintronic technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.15016v1",
    "published": "2025-05-21T01:54:56+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.15015v1",
    "title": "Beyond Node Attention: Multi-Scale Harmonic Encoding for Feature-Wise Graph Message Passing",
    "authors": [
      "Longlong Li",
      "Cunquan Qu",
      "Guanghui Wang"
    ],
    "abstract": "Conventional Graph Neural Networks (GNNs) aggregate neighbor embeddings as\nholistic vectors, lacking the ability to identify fine-grained,\ndirection-specific feature relevance. We propose MSH-GNN (Multi-Scale Harmonic\nGraph Neural Network), a novel architecture that performs feature-wise adaptive\nmessage passing through node-specific harmonic projections. For each node,\nMSH-GNN dynamically projects neighbor features onto frequency-sensitive\ndirections determined by the target node's own representation. These\nprojections are further modulated using learnable sinusoidal encodings at\nmultiple frequencies, enabling the model to capture both smooth and oscillatory\nstructural patterns across scales. A frequency-aware attention pooling\nmechanism is introduced to emphasize spectrally and structurally salient nodes\nduring readout. Theoretically, we prove that MSH-GNN approximates\nshift-invariant kernels and matches the expressive power of the\n1-Weisfeiler-Lehman (1-WL) test. Empirically, MSH-GNN consistently outperforms\nstate-of-the-art models on a wide range of graph and node classification tasks.\nFurthermore, in challenging classification settings involving joint variations\nin graph topology and spectral frequency, MSH-GNN excels at capturing\nstructural asymmetries and high-frequency modulations, enabling more accurate\ngraph discrimination.",
    "pdf_url": "http://arxiv.org/pdf/2505.15015v1",
    "published": "2025-05-21T01:35:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15014v1",
    "title": "Status of $D_s^+\\toœÜ\\ell^+ŒΩ_\\ell$ decay with chiral-odd $œÜ$-meson LCDA",
    "authors": [
      "Ya-Xiong Wang",
      "Dan-Dan Hu",
      "Wan-Bing Luo",
      "Tao Zhong",
      "Hai-Bing Fu"
    ],
    "abstract": "The twist-2 distribution amplitude of the $\\phi$-meson has attracted\nconsiderable interest due to its unique properties. In this work, we construct\nthe transverse leading-twist light-cone distribution amplitude (LCDA)\n$\\phi_{2;\\phi}^\\bot(x,\\mu_0)$ of the $\\phi$-meson using the light-cone harmonic\noscillator (LCHO) model, in which a parameter $B_{2;\\phi}^\\bot$ dominantly\ncontrol its longitudinal distribution. To explicitly isolate different twist\ncontributions, we employ the right-handed chiral correlator for the QCD\nlight-cone sum rules (LCSR) calculation of $D_s^+\\to\\phi$ decays, and further,\nwe get the branching fraction, $\\mathcal{B}(D_s^+ \\to \\phi e^+\\nu_e )=\n(2.271_{-0.243}^{+0.291})\\times 10^{-2}$ and $\\mathcal{B}(D_s^+ \\to \\phi\n\\mu^+\\nu_\\mu )=(2.250_{-0.240}^{+0.287})\\times 10^{-2}$, where errors are\nsquared average of the mentioned error sources. Furthermore, we have extracted\nthe Cabbibo-Kobayashi-Maskawa (CKM) matrix element\n$|V_{cs}|=0.975_{-0.066}^{+0.067}$ with improved precision through the\nanalysis. Finally, we calculated the polarization parameter and asymmetry\nparameter for the $D_s^+\\to\\phi$ decays.",
    "pdf_url": "http://arxiv.org/pdf/2505.15014v1",
    "published": "2025-05-21T01:35:45+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15013v1",
    "title": "Convergence of Adam in Deep ReLU Networks via Directional Complexity and Kakeya Bounds",
    "authors": [
      "Anupama Sridhar",
      "Alexander Johansen"
    ],
    "abstract": "First-order adaptive optimization methods like Adam are the default choices\nfor training modern deep neural networks. Despite their empirical success, the\ntheoretical understanding of these methods in non-smooth settings, particularly\nin Deep ReLU networks, remains limited. ReLU activations create exponentially\nmany region boundaries where standard smoothness assumptions break down.\n\\textbf{We derive the first\n\\(\\tilde{O}\\!\\bigl(\\sqrt{d_{\\mathrm{eff}}/n}\\bigr)\\) generalization bound for\nAdam in Deep ReLU networks and the first global-optimal convergence for Adam in\nthe non smooth, non convex relu landscape without a global PL or convexity\nassumption.} Our analysis is based on stratified Morse theory and novel results\nin Kakeya sets. We develop a multi-layer refinement framework that\nprogressively tightens bounds on region crossings. We prove that the number of\nregion crossings collapses from exponential to near-linear in the effective\ndimension. Using a Kakeya based method, we give a tighter generalization bound\nthan PAC-Bayes approaches and showcase convergence using a mild uniform low\nbarrier assumption.",
    "pdf_url": "http://arxiv.org/pdf/2505.15013v1",
    "published": "2025-05-21T01:34:16+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.15012v2",
    "title": "Observation of Topological Hall Effect in Synthetic Antiferromagnetic Skyrmion System",
    "authors": [
      "Xinbao Geng",
      "Guanqi Li",
      "Zhongxiang Zhang",
      "Wenjing Hu",
      "Wenjing Zhong",
      "Xiaoming Xiong",
      "Yongbing Xu",
      "Zhendong Chen",
      "Junlin Wang",
      "Xiangyu Zheng",
      "Jing Wu"
    ],
    "abstract": "Synthetic antiferromagnetic (SAF) skyrmions have emerged as promising\ncandidates for next-generation high-speed and highly integrated spintronic\ndevices, owing to their exceptional properties such as high driving velocity,\nnanoscale dimensions, and the absence of the skyrmion Hall effect. In this\nwork, we report the observation of the topological Hall effect in both\ncompensated and non-compensated synthetic antiferromagnetic skyrmion systems\nbased on [Pt/Co/Ru]2 bilayers. The antiferromagnetic skyrmions are demonstrated\nto be robust in these synthetic antiferromagnets under zero-field. Our first\nprincipal calculations and micromagnetic simulations demonstrate that the\nformation of the antiferromagnetic skyrmions are due to nonuniformity of RKKY\ncoupling associated with the proximity effect induced magnetic moments in the\nPt and Ru layers. The skyrmions in the Pt and Ru layers adjacent to the Co\nlayers lead to the observed topological Hall effect. This work not only\nprovides insight into the effect of the magnetic proximity effect and RKKY\ncoupling to the SAF skyrmions, but also an effective detection method for the\nSAF skyrmion systems, thereby laying a foundation for the practical application\nof antiferromagnetic skyrmions in spintronic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.15012v2",
    "published": "2025-05-21T01:33:33+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.15011v1",
    "title": "HAVA: Hybrid Approach to Value-Alignment through Reward Weighing for Reinforcement Learning",
    "authors": [
      "Kryspin Varys",
      "Federico Cerutti",
      "Adam Sobey",
      "Timothy J. Norman"
    ],
    "abstract": "Our society is governed by a set of norms which together bring about the\nvalues we cherish such as safety, fairness or trustworthiness. The goal of\nvalue-alignment is to create agents that not only do their tasks but through\ntheir behaviours also promote these values. Many of the norms are written as\nlaws or rules (legal / safety norms) but even more remain unwritten (social\nnorms). Furthermore, the techniques used to represent these norms also differ.\nSafety / legal norms are often represented explicitly, for example, in some\nlogical language while social norms are typically learned and remain hidden in\nthe parameter space of a neural network. There is a lack of approaches in the\nliterature that could combine these various norm representations into a single\nalgorithm. We propose a novel method that integrates these norms into the\nreinforcement learning process. Our method monitors the agent's compliance with\nthe given norms and summarizes it in a quantity we call the agent's reputation.\nThis quantity is used to weigh the received rewards to motivate the agent to\nbecome value-aligned. We carry out a series of experiments including a\ncontinuous state space traffic problem to demonstrate the importance of the\nwritten and unwritten norms and show how our method can find the value-aligned\npolicies. Furthermore, we carry out ablations to demonstrate why it is better\nto combine these two groups of norms rather than using either separately.",
    "pdf_url": "http://arxiv.org/pdf/2505.15011v1",
    "published": "2025-05-21T01:32:54+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15010v1",
    "title": "Shape-Adaptive Planning and Control for a Deformable Quadrotor",
    "authors": [
      "Yuze Wu",
      "Zhichao Han",
      "Xuankang Wu",
      "Yuan Zhou",
      "Junjie Wang",
      "Zheng Fang",
      "Fei Gao"
    ],
    "abstract": "Drones have become essential in various applications, but conventional\nquadrotors face limitations in confined spaces and complex tasks. Deformable\ndrones, which can adapt their shape in real-time, offer a promising solution to\novercome these challenges, while also enhancing maneuverability and enabling\nnovel tasks like object grasping. This paper presents a novel approach to\nautonomous motion planning and control for deformable quadrotors. We introduce\na shape-adaptive trajectory planner that incorporates deformation dynamics into\npath generation, using a scalable kinodynamic A* search to handle deformation\nparameters in complex environments. The backend spatio-temporal optimization is\ncapable of generating optimally smooth trajectories that incorporate shape\ndeformation. Additionally, we propose an enhanced control strategy that\ncompensates for external forces and torque disturbances, achieving a 37.3\\%\nreduction in trajectory tracking error compared to our previous work. Our\napproach is validated through simulations and real-world experiments,\ndemonstrating its effectiveness in narrow-gap traversal and multi-modal\ndeformable tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15010v1",
    "published": "2025-05-21T01:29:29+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17093v1",
    "title": "Voicing Personas: Rewriting Persona Descriptions into Style Prompts for Controllable Text-to-Speech",
    "authors": [
      "Yejin Lee",
      "Jaehoon Kang",
      "Kyuhong Shim"
    ],
    "abstract": "In this paper, we propose a novel framework to control voice style in\nprompt-based, controllable text-to-speech systems by leveraging textual\npersonas as voice style prompts. We present two persona rewriting strategies to\ntransform generic persona descriptions into speech-oriented prompts, enabling\nfine-grained manipulation of prosodic attributes such as pitch, emotion, and\nspeaking rate. Experimental results demonstrate that our methods enhance the\nnaturalness, clarity, and consistency of synthesized speech. Finally, we\nanalyze implicit social biases introduced by LLM-based rewriting, with a focus\non gender. We underscore voice style as a crucial factor for persona-driven AI\ndialogue systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17093v1",
    "published": "2025-05-21T01:28:56+00:00",
    "categories": [
      "eess.AS",
      "cs.CL"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15009v2",
    "title": "One-Layer Transformers are Provably Optimal for In-context Reasoning and Distributional Association Learning in Next-Token Prediction Tasks",
    "authors": [
      "Quan Nguyen",
      "Thanh Nguyen-Tang"
    ],
    "abstract": "We study the approximation capabilities and on-convergence behaviors of\none-layer transformers on the noiseless and noisy in-context reasoning of\nnext-token prediction. Existing theoretical results focus on understanding the\nin-context reasoning behaviors for either the first gradient step or when the\nnumber of samples is infinite. Furthermore, no convergence rates nor\ngeneralization abilities were known. Our work addresses these gaps by showing\nthat there exists a class of one-layer transformers that are provably\nBayes-optimal with both linear and ReLU attention. When being trained with\ngradient descent, we show via a finite-sample analysis that the expected loss\nof these transformers converges at linear rate to the Bayes risk. Moreover, we\nprove that the trained models generalize to unseen samples as well as exhibit\nlearning behaviors that were empirically observed in previous works. Our\ntheoretical findings are further supported by extensive empirical validations.",
    "pdf_url": "http://arxiv.org/pdf/2505.15009v2",
    "published": "2025-05-21T01:26:44+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15858v2",
    "title": "Large Language Model-Powered Agent for C to Rust Code Translation",
    "authors": [
      "HoHyun Sim",
      "Hyeonjoong Cho",
      "Yeonghyeon Go",
      "Zhoulai Fu",
      "Ali Shokri",
      "Binoy Ravindran"
    ],
    "abstract": "The C programming language has been foundational in building system-level\nsoftware. However, its manual memory management model frequently leads to\nmemory safety issues. In response, a modern system programming language, Rust,\nhas emerged as a memory-safe alternative. Moreover, automating the C-to-Rust\ntranslation empowered by the rapid advancements of the generative capabilities\nof LLMs is gaining growing interest for large volumes of legacy C code. Despite\nsome success, existing LLM-based approaches have constrained the role of LLMs\nto static prompt-response behavior and have not explored their agentic\nproblem-solving capability. Applying the LLM agentic capability for the\nC-to-Rust translation introduces distinct challenges, as this task differs from\nthe traditional LLM agent applications, such as math or commonsense QA domains.\nFirst, the scarcity of parallel C-to-Rust datasets hinders the retrieval of\nsuitable code translation exemplars for in-context learning. Second, unlike\nmath or commonsense QA, the intermediate steps required for C-to-Rust are not\nwell-defined. Third, it remains unclear how to organize and cascade these\nintermediate steps to construct a correct translation trajectory. To address\nthese challenges in the C-to-Rust translation, we propose a novel intermediate\nstep, the Virtual Fuzzing-based equivalence Test (VFT), and an agentic planning\nframework, the LLM-powered Agent for C-to-Rust code translation (LAC2R). The\nVFT guides LLMs to identify input arguments that induce divergent behaviors\nbetween an original C function and its Rust counterpart and to generate\ninformative diagnoses to refine the unsafe Rust code. LAC2R uses the MCTS to\nsystematically organize the LLM-induced intermediate steps for correct\ntranslation. We experimentally demonstrated that LAC2R effectively conducts\nC-to-Rust translation on large-scale, real-world benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.15858v2",
    "published": "2025-05-21T01:26:23+00:00",
    "categories": [
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15008v1",
    "title": "Know When to Abstain: Optimal Selective Classification with Likelihood Ratios",
    "authors": [
      "Alvin Heng",
      "Harold Soh"
    ],
    "abstract": "Selective classification enhances the reliability of predictive models by\nallowing them to abstain from making uncertain predictions. In this work, we\nrevisit the design of optimal selection functions through the lens of the\nNeyman--Pearson lemma, a classical result in statistics that characterizes the\noptimal rejection rule as a likelihood ratio test. We show that this\nperspective not only unifies the behavior of several post-hoc selection\nbaselines, but also motivates new approaches to selective classification which\nwe propose here. A central focus of our work is the setting of covariate shift,\nwhere the input distribution at test time differs from that at training. This\nrealistic and challenging scenario remains relatively underexplored in the\ncontext of selective classification. We evaluate our proposed methods across a\nrange of vision and language tasks, including both supervised learning and\nvision-language models. Our experiments demonstrate that our\nNeyman--Pearson-informed methods consistently outperform existing baselines,\nindicating that likelihood ratio-based selection offers a robust mechanism for\nimproving selective classification under covariate shifts. Our code is publicly\navailable at https://github.com/clear-nus/sc-likelihood-ratios.",
    "pdf_url": "http://arxiv.org/pdf/2505.15008v1",
    "published": "2025-05-21T01:26:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.15007v1",
    "title": "Gap modes in Arnold tongues and their topological origins",
    "authors": [
      "Andrew Brown",
      "Hong Qin"
    ],
    "abstract": "Gap modes in a modified Mathieu equation, perturbed by a Dirac delta\npotential, are investigated. It is proved that the modified Mathieu equation\nadmits stable isolated gap modes with topological origins in the unstable\nregions of the Mathieu equation, which are known as Arnold tongues. The modes\nmay be identified as localized electron wavefunctions in a 1D chain or as\ntoroidal Alfv\\'en eigenmodes. A generalization of this argument shows that gap\nmodes can be induced in regimes of instability by localized potential\nperturbations for a large class of periodic Hamiltonians.",
    "pdf_url": "http://arxiv.org/pdf/2505.15007v1",
    "published": "2025-05-21T01:25:31+00:00",
    "categories": [
      "math-ph",
      "cond-mat.other",
      "math.MP",
      "physics.plasm-ph"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15006v1",
    "title": "On the Equilibria Computation of Set-Valued Lur'e Dynamical Systems",
    "authors": [
      "Phan Quoc Khanh",
      "Le Ba Khiet"
    ],
    "abstract": "In this article, we propose an efficient way to compute equilibria of a\ngeneral class of set-valued Lur'e dynamical systems, which plays an important\nrole in the asymptotical analysis of the systems. Besides the equilibria\ncomputation, our study can be also used to solve a class of quasi-variational\ninequalities. Some examples of finding Nash quasi-equilibria in game theory are\ngiven.",
    "pdf_url": "http://arxiv.org/pdf/2505.15006v1",
    "published": "2025-05-21T01:24:14+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.15005v1",
    "title": "UniSTPA: A Safety Analysis Framework for End-to-End Autonomous Driving",
    "authors": [
      "Hongrui Kou",
      "Zhouhang Lyu",
      "Ziyu Wang",
      "Cheng Wang",
      "Yuxin Zhang"
    ],
    "abstract": "As autonomous driving technology continues to advance, end-to-end models have\nattracted considerable attention owing to their superior generalisation\ncapability. Nevertheless, such learning-based systems entail numerous safety\nrisks throughout development and on-road deployment, and existing\nsafety-analysis methods struggle to identify these risks comprehensively. To\naddress this gap, we propose the Unified System Theoretic Process Analysis\n(UniSTPA) framework, which extends the scope of STPA from the operational phase\nto the entire lifecycle of an end-to-end autonomous driving system, including\ninformation gathering, data preparation, closed loop training, verification,\nand deployment. UniSTPA performs hazard analysis not only at the component\nlevel but also within the model's internal layers, thereby enabling\nfine-grained assessment of inter and intra module interactions. Using a highway\nNavigate on Autopilot function as a case study, UniSTPA uncovers multi-stage\nhazards overlooked by conventional approaches including scene design defects,\nsensor fusion biases, and internal model flaws, through multi-level causal\nanalysis, traces these hazards to deeper issues such as data quality, network\narchitecture, and optimisation objectives. The analysis result are used to\nconstruct a safety monitoring and safety response mechanism that supports\ncontinuous improvement from hazard identification to system optimisation. The\nproposed framework thus offers both theoretical and practical guidance for the\nsafe development and deployment of end-to-end autonomous driving systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.15005v1",
    "published": "2025-05-21T01:23:31+00:00",
    "categories": [
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.15004v2",
    "title": "EASY: Emotion-aware Speaker Anonymization via Factorized Distillation",
    "authors": [
      "Jixun Yao",
      "Hexin Liu",
      "Eng Siong Chng",
      "Lei Xie"
    ],
    "abstract": "Emotion plays a significant role in speech interaction, conveyed through\ntone, pitch, and rhythm, enabling the expression of feelings and intentions\nbeyond words to create a more personalized experience. However, most existing\nspeaker anonymization systems employ parallel disentanglement methods, which\nonly separate speech into linguistic content and speaker identity, often\nneglecting the preservation of the original emotional state. In this study, we\nintroduce EASY, an emotion-aware speaker anonymization framework. EASY employs\na novel sequential disentanglement process to disentangle speaker identity,\nlinguistic content, and emotional representation, modeling each speech\nattribute in distinct subspaces through a factorized distillation approach. By\nindependently constraining speaker identity and emotional representation, EASY\nminimizes information leakage, enhancing privacy protection while preserving\noriginal linguistic content and emotional state. Experimental results on the\nVoicePrivacy Challenge official datasets demonstrate that our proposed approach\noutperforms all baseline systems, effectively protecting speaker privacy while\nmaintaining linguistic content and emotional state.",
    "pdf_url": "http://arxiv.org/pdf/2505.15004v2",
    "published": "2025-05-21T01:17:09+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.15003v1",
    "title": "Rate-Distortion Optimization with Non-Reference Metrics for UGC Compression",
    "authors": [
      "Samuel Fern√°ndez-Mendui√±a",
      "Xin Xiong",
      "Eduardo Pavez",
      "Antonio Ortega",
      "Neil Birkbeck",
      "Balu Adsumilli"
    ],
    "abstract": "Service providers must encode a large volume of noisy videos to meet the\ndemand for user-generated content (UGC) in online video-sharing platforms.\nHowever, low-quality UGC challenges conventional codecs based on\nrate-distortion optimization (RDO) with full-reference metrics (FRMs). While\neffective for pristine videos, FRMs drive codecs to preserve artifacts when the\ninput is degraded, resulting in suboptimal compression. A more suitable\napproach used to assess UGC quality is based on non-reference metrics (NRMs).\nHowever, RDO with NRMs as a measure of distortion requires an iterative\nworkflow of encoding, decoding, and metric evaluation, which is computationally\nimpractical. This paper overcomes this limitation by linearizing the NRM around\nthe uncompressed video. The resulting cost function enables block-wise bit\nallocation in the transform domain by estimating the alignment of the\nquantization error with the gradient of the NRM. To avoid large deviations from\nthe input, we add sum of squared errors (SSE) regularization. We derive\nexpressions for both the SSE regularization parameter and the Lagrangian, akin\nto the relationship used for SSE-RDO. Experiments with images and videos show\nbitrate savings of more than 30\\% over SSE-RDO using the target NRM, with no\ndecoder complexity overhead and minimal encoder complexity increase.",
    "pdf_url": "http://arxiv.org/pdf/2505.15003v1",
    "published": "2025-05-21T01:15:32+00:00",
    "categories": [
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15002v2",
    "title": "Unraveling the iterative CHAD",
    "authors": [
      "Fernando Lucatelli Nunes",
      "Gordon Plotkin",
      "Matthijs V√°k√°r"
    ],
    "abstract": "Combinatory Homomorphic Automatic Differentiation (CHAD) was originally\nformulated as a semantics-driven source-to-source transformation for\nreverse-mode AD of total (terminating) functional programs. In this work, we\nextend CHAD to encompass programs featuring constructs such as partial\n(potentially non-terminating) operations, data-dependent conditionals (e.g.,\nreal-valued tests), and iteration constructs (i.e. while-loops), while\nmaintaining CHAD's core principle of structure-preserving semantics.\n  A central contribution is the introduction of iteration-extensive indexed\ncategories, which provide a principled integration of iteration into\ndependently typed programming languages. This integration is achieved by\nrequiring that iteration in the base category lifts to parameterized initial\nalgebras in the indexed category, yielding an op-fibred iterative structure\nthat models while-loops and other iteration constructs in the total category,\nwhich corresponds to the category of containers of our dependently typed\nlanguage.\n  Through the idea of iteration-extensive indexed categories, we extend the\nCHAD transformation to looping programs as the unique structure-preserving\nfunctor in a suitable sense. Specifically, it is the unique iterative Freyd\ncategory morphism from the iterative Freyd category corresponding to the source\nlanguage to the category of containers obtained from the target language, such\nthat each primitive operation is mapped to its (transposed) derivative. We\nestablish the correctness of this extended transformation via the universal\nproperty of the syntactic categorical model of the source language, showing\nthat the differentiated programs compute correct reverse-mode derivatives of\ntheir originals.",
    "pdf_url": "http://arxiv.org/pdf/2505.15002v2",
    "published": "2025-05-21T01:10:40+00:00",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.LG",
      "math.CT",
      "math.LO",
      "18C10, 18C15, 18C20, 18D05, 03B70, 03F52, 68Q55, 68N18, 68T07",
      "F.3.2; F.3.3; D.3.1; D.3.2; D.2.4; G.4; I.2.3; I.2.6; G.1.10"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15857v1",
    "title": "Simulating Prosocial Behavior and Social Contagion in LLM Agents under Institutional Interventions",
    "authors": [
      "Yujia Zhou",
      "Hexi Wang",
      "Qingyao Ai",
      "Zhen Wu",
      "Yiqun Liu"
    ],
    "abstract": "As large language models (LLMs) increasingly serve as autonomous agents in\nsocial contexts, understanding their capacity for prosocial behavior becomes\nessential. We present ProSim, a simulation framework designed to examine how\nprosocial behavior emerges, adapts, and erodes in LLM-based agents under\ndiverse social and institutional conditions. The framework comprises four\ncomponents: individual simulation, scenario simulation, interaction simulation,\nand intervention simulation. We conduct three progressive studies to evaluate\nprosocial alignment. First, we show that LLM agents can demonstrate stable and\ncontext-sensitive prosocial behavior across diverse scenarios and adapt their\nresponses under normative policy interventions. Second, we find that agents\nengage in fairness-based third-party punishment and respond systematically to\nvariations in inequity magnitude and enforcement cost. Third, we show that\npolicy-induced inequities suppress prosocial behavior, propagate through social\nnetworks, and are mediated by agents' perceptions of unfairness. These findings\nlay the groundwork for evaluating social alignment and modeling institutional\ndynamics in agent-driven societies.",
    "pdf_url": "http://arxiv.org/pdf/2505.15857v1",
    "published": "2025-05-21T01:09:37+00:00",
    "categories": [
      "cs.SI",
      "J.4"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15001v1",
    "title": "Photonic chip-based high-efficiency soliton microcombs via electroopitc-Kerr synergy",
    "authors": [
      "Rui Niu",
      "Shuai Wan",
      "Pi-Yu Wang",
      "Rui Ma",
      "Jin Li",
      "Fang Bo",
      "Zhen Shen",
      "Guang-Can Guo",
      "Fang-Wen Sun",
      "Junqiu Liu",
      "Chun-Hua Dong"
    ],
    "abstract": "Temporal soliton mode-locking in coherently pumped microcavities provides a\npromising platform for miniaturized frequency comb systems. While significant\nprogress has been made, achieving high conversion efficiency in such microcombs\nremains a critical challenge. Soliton generation through pulse pumping has\nemerged as an effective strategy to improve conversion efficiency. However, the\non-chip integration of pulse generation with dissipative Kerr soliton (DKS)\nformation within the photonic chip has not yet been realized. In this work, we\ndemonstrate a photonic chip-based soliton microcomb with high conversion\nefficiency, achieved by integrating on-chip pulse generation and DKS\ngeneration. The pulsed laser, fabricated on a lithium niobate-on-insulator\n(LNOI) platform, delivers a 35.5GHz repetition rate with broadly tunable center\nfrequencies. By coupling these on-chip pulses to a silicon nitride\nmicroresonator, we achieve stable DKS generation with a pump-to-soliton\nconversion efficiency of 43.9% under steady-state conditions. This integrated\narchitecture establishes a viable pathway toward chip-scale soliton microcombs\nwith unprecedented efficiency, opening up new possibilities for optical\ncommunications, precision spectroscopy, and photonic sensing.",
    "pdf_url": "http://arxiv.org/pdf/2505.15001v1",
    "published": "2025-05-21T01:07:50+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.15000v1",
    "title": "Towards Spoken Mathematical Reasoning: Benchmarking Speech-based Models over Multi-faceted Math Problems",
    "authors": [
      "Chengwei Wei",
      "Bin Wang",
      "Jung-jae Kim",
      "Nancy F. Chen"
    ],
    "abstract": "Recent advances in large language models (LLMs) and multimodal LLMs (MLLMs)\nhave led to strong reasoning ability across a wide range of tasks. However,\ntheir ability to perform mathematical reasoning from spoken input remains\nunderexplored. Prior studies on speech modality have mostly focused on factual\nspeech understanding or simple audio reasoning tasks, providing limited insight\ninto logical step-by-step reasoning, such as that required for mathematical\nproblem solving. To address this gap, we introduce Spoken Math Question\nAnswering (Spoken-MQA), a new benchmark designed to evaluate the mathematical\nreasoning capabilities of speech-based models, including both cascade models\n(ASR + LLMs) and end-to-end speech LLMs. Spoken-MQA covers a diverse set of\nmath problems, including pure arithmetic, single-step and multi-step contextual\nreasoning, and knowledge-oriented reasoning problems, all presented in\nunambiguous natural spoken language. Through extensive experiments, we find\nthat: (1) while some speech LLMs perform competitively on contextual reasoning\ntasks involving basic arithmetic, they still struggle with direct arithmetic\nproblems; (2) current LLMs exhibit a strong bias toward symbolic mathematical\nexpressions written in LaTex and have difficulty interpreting verbalized\nmathematical expressions; and (3) mathematical knowledge reasoning abilities\nare significantly degraded in current speech LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.15000v1",
    "published": "2025-05-21T01:07:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.14999v2",
    "title": "Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision",
    "authors": [
      "Eric Hanchen Jiang",
      "Haozheng Luo",
      "Shengyuan Pang",
      "Xiaomin Li",
      "Zhenting Qi",
      "Hengli Li",
      "Cheng-Fu Yang",
      "Zongyu Lin",
      "Xinfeng Li",
      "Hao Xu",
      "Kai-Wei Chang",
      "Ying Nian Wu"
    ],
    "abstract": "Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs), often requiring robust multi step logical consistency. While\nChain of Thought (CoT) prompting elicits reasoning steps, it doesn't guarantee\ncorrectness, and improving reliability via extensive sampling is\ncomputationally costly. This paper introduces the Energy Outcome Reward Model\n(EORM), an effective, lightweight, post hoc verifier. EORM leverages Energy\nBased Models (EBMs) to simplify the training of reward models by learning to\nassign a scalar energy score to CoT solutions using only outcome labels,\nthereby avoiding detailed annotations. It achieves this by interpreting\ndiscriminator output logits as negative energies, effectively ranking\ncandidates where lower energy is assigned to solutions leading to correct final\noutcomes implicitly favoring coherent reasoning. On mathematical benchmarks\n(GSM8k, MATH), EORM significantly improves final answer accuracy (e.g., with\nLlama 3 8B, achieving 90.7% on GSM8k and 63.7% on MATH). EORM effectively\nleverages a given pool of candidate solutions to match or exceed the\nperformance of brute force sampling, thereby enhancing LLM reasoning outcome\nreliability through its streamlined post hoc verification process.",
    "pdf_url": "http://arxiv.org/pdf/2505.14999v2",
    "published": "2025-05-21T01:06:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.14998v1",
    "title": "Integer Reasoning Modulo Different Constants in SMT",
    "authors": [
      "Elizaveta Pertseva",
      "Alex Ozdemir",
      "Shankara Pailoor",
      "Alp Bassa",
      "Sorawee Porncharoenwase",
      "I≈üil Dillig",
      "Clark Barrett"
    ],
    "abstract": "This paper presents a new refutation procedure for multimodular systems of\ninteger constraints that commonly arise when verifying cryptographic protocols.\nThese systems, involving polynomial equalities and disequalities modulo\ndifferent constants, are challenging for existing solvers due to their\ninability to exploit multimodular structure. To address this issue, our method\npartitions constraints by modulus and uses lifting and lowering techniques to\nshare information across subsystems, supported by algebraic tools like weighted\nGr\\\"obner bases. Our experiments show that the proposed method outperforms\nexisting state-of-the-art solvers in verifying cryptographic implementations\nrelated to Montgomery arithmetic and zero-knowledge proofs.",
    "pdf_url": "http://arxiv.org/pdf/2505.14998v1",
    "published": "2025-05-21T01:05:15+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.11035v1",
    "title": "Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity",
    "authors": [
      "Moussa Koulako Bala Doumbouya",
      "Dan Jurafsky",
      "Christopher D. Manning"
    ],
    "abstract": "Work in psychology has highlighted that the geometric model of similarity\nstandard in deep learning is not psychologically plausible because its metric\nproperties such as symmetry do not align with human perception. In contrast,\nTversky (1977) proposed an axiomatic theory of similarity based on a\nrepresentation of objects as sets of features, and their similarity as a\nfunction of common and distinctive features. However, this model has not been\nused in deep learning before, partly due to the challenge of incorporating\ndiscrete set operations. We develop a differentiable parameterization of\nTversky's similarity that is learnable through gradient descent, and derive\nneural network building blocks such as the Tversky projection layer, which\nunlike the linear projection layer can model non-linear functions such as XOR.\nThrough experiments with image recognition and language modeling, we show that\nthe Tversky projection layer is a beneficial replacement for the linear\nprojection layer, which employs geometric similarity. On the NABirds image\nclassification task, a frozen ResNet-50 adapted with a Tversky projection layer\nachieves a 24.7% relative accuracy improvement over the linear layer adapter\nbaseline. With Tversky projection layers, GPT-2's perplexity on PTB decreases\nby 7.5%, and its parameter count by 34.8%. Finally, we propose a unified\ninterpretation of both projection layers as computing similarities of input\nstimuli to learned prototypes, for which we also propose a novel visualization\ntechnique highlighting the interpretability of Tversky projection layers. Our\nwork offers a new paradigm for thinking about the similarity model implicit in\ndeep learning, and designing networks that are interpretable under an\nestablished theory of psychological similarity.",
    "pdf_url": "http://arxiv.org/pdf/2506.11035v1",
    "published": "2025-05-21T01:01:48+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "68",
      "I.2.0; I.2.4; I.2.6; I.2.7; I.4.7; I.4.10; I.5.1; F.1.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.14997v1",
    "title": "Superconducting vacancy-ordered rock-salt NbO films",
    "authors": [
      "Jeong Rae Kim",
      "Sandra Glotzer",
      "Evan Krysko",
      "Matthew R. Barone",
      "Jinkwon Kim",
      "Salva Salmani-Rezaie",
      "Adrian Llanos",
      "Joseph Falson"
    ],
    "abstract": "We report molecular beam epitaxy synthesis of vacancy-ordered rocksalt NbO\nthin films which display superconductivity. A comparative study of substrates\nidentifies Al$_2$O$_3$ (0001) as the optimal platform for realizing\nhigh-quality, single-phase films when growing at temperatures exceeding 1000\n$^\\circ$C. The controlled NbO films exhibit superconductivity with critical\ntemperatures up to $T_\\mathrm{c}$ = 1.37 K, comparable to bulk single crystals.\nThis work addresses the fundamental bottlenecks encountered in the\nhigh-temperature epitaxy of compounds with uncommon oxidation states, while\nexpanding the scope of available thin-film superconductors.",
    "pdf_url": "http://arxiv.org/pdf/2505.14997v1",
    "published": "2025-05-21T00:57:15+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.14996v2",
    "title": "MAS-ZERO: Designing Multi-Agent Systems with Zero Supervision",
    "authors": [
      "Zixuan Ke",
      "Austin Xu",
      "Yifei Ming",
      "Xuan-Phi Nguyen",
      "Caiming Xiong",
      "Shafiq Joty"
    ],
    "abstract": "Multi-agent systems (MAS) leveraging the impressive capabilities of Large\nLanguage Models (LLMs) hold significant potential for tackling complex tasks.\nHowever, most current MAS depend on manually designed agent roles and\ncommunication protocols. These manual designs often fail to align with the\nunderlying LLMs' strengths and struggle to adapt to novel tasks. Recent\nautomatic MAS approaches attempt to mitigate these limitations but typically\nnecessitate a validation set for tuning and yield static MAS designs lacking\nadaptability during inference. We introduce MAS-ZERO, the first self-evolved,\ninference-time framework for automatic MAS design. MAS-ZERO employs meta-level\ndesign to iteratively generate, evaluate, and refine MAS configurations\ntailored to each problem instance, without requiring a validation set.\nCritically, it enables dynamic agent composition and problem decomposition\nthrough meta-feedback on solvability and completeness. Experiments across math,\ngraduate-level QA, and software engineering benchmarks, using both\nclosed-source and open-source LLM backbones of varying sizes, demonstrate that\nMAS-ZERO outperforms both manual and automatic MAS baselines, achieving a 7.44%\naverage accuracy improvement over the next strongest baseline while maintaining\ncost-efficiency. These findings underscore the promise of meta-level\nself-evolved design for creating effective and adaptive MAS.",
    "pdf_url": "http://arxiv.org/pdf/2505.14996v2",
    "published": "2025-05-21T00:56:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.14995v1",
    "title": "Pure-quartic domain-wall solitons as topological bits for data transmission",
    "authors": [
      "Pengfei Li",
      "Jun Ruan",
      "Shilong Liu",
      "Dumitru Mihalache",
      "Boris A. Malomed"
    ],
    "abstract": "Domain walls (DWs) are topological defects produced by symmetry-breaking\nphase transitions. Although DWs have been the subject of much work due to their\nfundamental physical properties, they have not been explored in optical systems\nwith higher-order dispersion. Recent experimental and theoretical works have\ndemonstrated that pure-quartic (PQ) solitons, with their specific energy-width\nscaling, arise from the interplay of the quartic group-velocity dispersion\n(GVD) and Kerr nonlinearity. Here, we report solutions for PQ-DW solitons for\nthe model of optical media with the PQ GVD. The analysis demonstrates that they\nare stable modes. Further investigation reveals their potential as data\ncarriers for optical telecommunications. These results broaden the variety of\noptical solitons maintained by diverse nonlinear media.",
    "pdf_url": "http://arxiv.org/pdf/2505.14995v1",
    "published": "2025-05-21T00:56:04+00:00",
    "categories": [
      "physics.optics",
      "nlin.PS"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.14994v2",
    "title": "Exact spin helix eigenstates in the anisotropic spin-$s$ Heisenberg model with arbitrary dimensions",
    "authors": [
      "Mingchen Zheng",
      "Chenguang Liang",
      "Shu Chen",
      "Xin Zhang"
    ],
    "abstract": "Spin helix states-characterized by their spatially modulated spin\ntextures-are exact eigenstates of the one-dimensional anisotropic\nspin-$\\frac{1}{2}$ Heisenberg model under specific parameter conditions. In\nthis work, we extend this framework by constructing exact spin helix\neigenstates for the fully anisotropic XYZ Heisenberg model with arbitrary\nspatial dimensions and arbitrary spin quantum numbers. Our results demonstrate\nthat some non-trivial exact eigenstates can persist beyond the integrable\nregime. The XXZ and XY cases are also analyzed to clarify the conditions for\nthe emergence of spin helix eigenstates and their key properties. Our results\nbroaden the class of analytically tractable exact eigenstates in non-integrable\nsystems and deepen understanding of spin modulation states in many-body\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.14994v2",
    "published": "2025-05-21T00:55:54+00:00",
    "categories": [
      "math-ph",
      "cond-mat.str-el",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17092v1",
    "title": "Covert Attacks on Machine Learning Training in Passively Secure MPC",
    "authors": [
      "Matthew Jagielski",
      "Daniel Escudero",
      "Rahul Rachuri",
      "Peter Scholl"
    ],
    "abstract": "Secure multiparty computation (MPC) allows data owners to train machine\nlearning models on combined data while keeping the underlying training data\nprivate. The MPC threat model either considers an adversary who passively\ncorrupts some parties without affecting their overall behavior, or an adversary\nwho actively modifies the behavior of corrupt parties. It has been argued that\nin some settings, active security is not a major concern, partly because of the\npotential risk of reputation loss if a party is detected cheating.\n  In this work we show explicit, simple, and effective attacks that an active\nadversary can run on existing passively secure MPC training protocols, while\nkeeping essentially zero risk of the attack being detected. The attacks we show\ncan compromise both the integrity and privacy of the model, including attacks\nreconstructing exact training data. Our results challenge the belief that a\nthreat model that does not include malicious behavior by the involved parties\nmay be reasonable in the context of PPML, motivating the use of actively secure\nprotocols for training.",
    "pdf_url": "http://arxiv.org/pdf/2505.17092v1",
    "published": "2025-05-21T00:46:45+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.11034v1",
    "title": "CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models",
    "authors": [
      "Aneesh Komanduri",
      "Karuna Bhaila",
      "Xintao Wu"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable ability in various\nlanguage tasks, especially with their emergent in-context learning capability.\nExtending LLMs to incorporate visual inputs, large vision-language models\n(LVLMs) have shown impressive performance in tasks such as recognition and\nvisual question answering (VQA). Despite increasing interest in the utility of\nLLMs in causal reasoning tasks such as causal discovery and counterfactual\nreasoning, there has been relatively little work showcasing the abilities of\nLVLMs on visual causal reasoning tasks. We take this opportunity to formally\nintroduce a comprehensive causal reasoning benchmark for multi-modal in-context\nlearning from LVLMs. Our CausalVLBench encompasses three representative tasks:\ncausal structure inference, intervention target prediction, and counterfactual\nprediction. We evaluate the ability of state-of-the-art open-source LVLMs on\nour causal reasoning tasks across three causal representation learning datasets\nand demonstrate their fundamental strengths and weaknesses. We hope that our\nbenchmark elucidates the drawbacks of existing vision-language models and\nmotivates new directions and paradigms in improving the visual causal reasoning\nabilities of LVLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.11034v1",
    "published": "2025-05-21T00:45:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.14993v3",
    "title": "On the equivalence between functionally affine LPV state-space representations and LFT models",
    "authors": [
      "Mih√°ly Petreczky",
      "Ziad Alkhoury",
      "Guillaume Merc√®re"
    ],
    "abstract": "We propose a transformation algorithm for a class of Linear Parameter-Varying\n(LPV) systems with functional affine dependence on parameters, where the system\nmatrices depend affinely on nonlinear functions of the scheduling varable, into\nLinear Fractional Transformation (LFT) systems. The transformation preserves\ninput-output behavior and minimality, and the uncertainity block of the\nresulting LFT system is linear in the scheduling variables of the LPV system.",
    "pdf_url": "http://arxiv.org/pdf/2505.14993v3",
    "published": "2025-05-21T00:43:10+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.14992v1",
    "title": "Effective and Efficient Schema-aware Information Extraction Using On-Device Large Language Models",
    "authors": [
      "Zhihao Wen",
      "Sheng Liang",
      "Yaxiong Wu",
      "Yongyue Zhang",
      "Yong Liu"
    ],
    "abstract": "Information extraction (IE) plays a crucial role in natural language\nprocessing (NLP) by converting unstructured text into structured knowledge.\nDeploying computationally intensive large language models (LLMs) on\nresource-constrained devices for information extraction is challenging,\nparticularly due to issues like hallucinations, limited context length, and\nhigh latency-especially when handling diverse extraction schemas. To address\nthese challenges, we propose a two-stage information extraction approach\nadapted for on-device LLMs, called Dual-LoRA with Incremental Schema Caching\n(DLISC), which enhances both schema identification and schema-aware extraction\nin terms of effectiveness and efficiency. In particular, DLISC adopts an\nIdentification LoRA module for retrieving the most relevant schemas to a given\nquery, and an Extraction LoRA module for performing information extraction\nbased on the previously selected schemas. To accelerate extraction inference,\nIncremental Schema Caching is incorporated to reduce redundant computation,\nsubstantially improving efficiency. Extensive experiments across multiple\ninformation extraction datasets demonstrate notable improvements in both\neffectiveness and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.14992v1",
    "published": "2025-05-21T00:40:05+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.14991v1",
    "title": "The Thurston compactification of the stability manifold of a generic analytic K3 surface",
    "authors": [
      "Anand Deopurkar"
    ],
    "abstract": "Let X be an analytic K3 surface with Pic X = 0. We describe the closure of\nthe Bridgeland stability manifold of X obtained using the masses of semi-rigid\nobjects.",
    "pdf_url": "http://arxiv.org/pdf/2505.14991v1",
    "published": "2025-05-21T00:37:54+00:00",
    "categories": [
      "math.AG",
      "math.CT",
      "math.RT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.14990v1",
    "title": "Language Specific Knowledge: Do Models Know Better in X than in English?",
    "authors": [
      "Ishika Agarwal",
      "Nimet Beyza Bozdag",
      "Dilek Hakkani-T√ºr"
    ],
    "abstract": "Code-switching is a common phenomenon of alternating between different\nlanguages in the same utterance, thought, or conversation. We posit that humans\ncode-switch because they feel more comfortable talking about certain topics and\ndomains in one language than another. With the rise of knowledge-intensive\nlanguage models, we ask ourselves the next, natural question: Could models hold\nmore knowledge on some topics in some language X? More importantly, could we\nimprove reasoning by changing the language that reasoning is performed in? We\ncoin the term Language Specific Knowledge (LSK) to represent this phenomenon.\nAs ethnic cultures tend to develop alongside different languages, we employ\nculture-specific datasets (that contain knowledge about cultural and social\nbehavioral norms). We find that language models can perform better when using\nchain-of-thought reasoning in some languages other than English, sometimes even\nbetter in low-resource languages. Paired with previous works showing that\nsemantic similarity does not equate to representational similarity, we\nhypothesize that culturally specific texts occur more abundantly in\ncorresponding languages, enabling specific knowledge to occur only in specific\n\"expert\" languages. Motivated by our initial results, we design a simple\nmethodology called LSKExtractor to benchmark the language-specific knowledge\npresent in a language model and, then, exploit it during inference. We show our\nresults on various models and datasets, showing an average relative improvement\nof 10% in accuracy. Our research contributes to the open-source development of\nlanguage models that are inclusive and more aligned with the cultural and\nlinguistic contexts in which they are deployed.",
    "pdf_url": "http://arxiv.org/pdf/2505.14990v1",
    "published": "2025-05-21T00:31:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.14989v1",
    "title": "Discrete Audio Representations for Automated Audio Captioning",
    "authors": [
      "Jingguang Tian",
      "Haoqin Sun",
      "Xinhui Hu",
      "Xinkang Xu"
    ],
    "abstract": "Discrete audio representations, termed audio tokens, are broadly categorized\ninto semantic and acoustic tokens, typically generated through unsupervised\ntokenization of continuous audio representations. However, their applicability\nto automated audio captioning (AAC) remains underexplored. This paper\nsystematically investigates the viability of audio token-driven models for AAC\nthrough comparative analyses of various tokenization methods. Our findings\nreveal that audio tokenization leads to performance degradation in AAC models\ncompared to those that directly utilize continuous audio representations. To\naddress this issue, we introduce a supervised audio tokenizer trained with an\naudio tagging objective. Unlike unsupervised tokenizers, which lack explicit\nsemantic understanding, the proposed tokenizer effectively captures audio event\ninformation. Experiments conducted on the Clotho dataset demonstrate that the\nproposed audio tokens outperform conventional audio tokens in the AAC task.",
    "pdf_url": "http://arxiv.org/pdf/2505.14989v1",
    "published": "2025-05-21T00:27:38+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.14988v1",
    "title": "Test of local realism via entangled $Œõ\\barŒõ$ system",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "M. R. An",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "I. Balossino",
      "Y. Ban",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "J. F. Chang",
      "T. T. Chang",
      "W. L. Chang",
      "G. R. Che",
      "G. Chelkov",
      "C. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "W. S. Cheng",
      "S. K. Choi",
      "X. Chu",
      "G. Cibinetto",
      "S. C. Coen",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. DeMori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Z. H. Duan",
      "P. Egorov",
      "Y. L. Fan",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "K. Fischer",
      "M. Fritsch",
      "C. Fritzsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "Y. N. Gao",
      "YangGao",
      "S. Garbolino",
      "I. Garzia",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "AGilman",
      "K. Goetzen",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "C. YGuan",
      "Z. L. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "T. T. Han",
      "W. Y. Han",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. HH. . Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "T. Holtmann",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "H. M. Hu",
      "J. F. Hu",
      "T. Hu",
      "Y. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "T. Hussain",
      "NH√ºsken",
      "W. Imoehl",
      "J. Jackson",
      "S. Jaeger",
      "S. Janchiv",
      "J. H. Jeong",
      "Q. Ji",
      "Q. P. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "X. Q. Jia",
      "Z. K. Jia",
      "H. J. Jiang",
      "P. C. Jiang",
      "S. S. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "R. Kappert",
      "M. Kavatsyuk",
      "B. C. Ke",
      "A. Khoukaz",
      "R. Kiuchi",
      "R. Kliemt",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "A. Kupsc",
      "W. K√ºhn",
      "J. J. Lane",
      "P. Larin",
      "A. Lavania",
      "L. Lavezzi",
      "T. T. Lei",
      "Z. H. Lei",
      "H. Leithoff",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "Cheng Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "J. W. Li",
      "K. L. Li",
      "Ke Li",
      "L. J Li",
      "L. K. Li",
      "LeiLi",
      "M. H. Li",
      "P. R. Li",
      "Q. X. Li",
      "S. X. Li",
      "T. Li",
      "W. D. Li",
      "W. G. Li",
      "X. H. Li",
      "X. L. Li",
      "Xiaoyu Li",
      "Y. G. Li",
      "Z. J. Li",
      "C. Liang",
      "H. Liang",
      "H. Liang",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "L. Z. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "D. X. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. H. Liu",
      "Fang Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. M. Liu",
      "Huanhuan Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. L. Liu",
      "J. Y. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. Liu",
      "L. C. Liu",
      "Lu Liu",
      "M. H. Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "X. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "X. L. Lu",
      "Y. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "X. R. Lyu",
      "Y. F. Lyu",
      "F. C. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "M. M. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "R. T. Ma",
      "X. Y. Ma",
      "Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "M. Maggiora",
      "S. Malde",
      "Q. A. Malik",
      "A. Mangoni",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "Z. X. Meng",
      "J. G. Messchendorp",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Y. Niu",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "P. Patteri",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "K. Peters",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "S. Pogodin",
      "V. Prasad",
      "F. Z. Qi",
      "H. Qi",
      "H. R. Qi",
      "M. Qi",
      "T. Y. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "J. J. Qin",
      "L. Q. Qin",
      "X. P. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "S. Q. Qu",
      "C. F. Redmer",
      "K. J. Ren",
      "A. Rivetti",
      "V. Rodin",
      "M. Rolo",
      "G. Rong",
      "Ch. Rosner",
      "S. N. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Schoenning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. C. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "Q. Q. Shi",
      "R. S. Shi",
      "X. Shi",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. J. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "W. Y. Sun",
      "Y. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. T. Sun",
      "Y. X. Tan",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "Y. A. Tang",
      "L. YTao",
      "Q. T. Tao",
      "M. Tat",
      "J. X. Teng",
      "V. Thoren",
      "W. H. Tian",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "S. J. Wang",
      "B. Wang",
      "B. L. Wang",
      "Bo Wang",
      "C. W. Wang",
      "D. Y. Wang",
      "F. Wang",
      "H. J. Wang",
      "H. P. Wang",
      "J. P. Wang",
      "K. Wang",
      "L. L. Wang",
      "M. Wang",
      "Meng Wang",
      "S. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. H. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "YaqianWang",
      "Yi Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. Y. Wang",
      "Ziyi Wang",
      "D. Wei",
      "D. H. Wei",
      "F. Weidner",
      "S. P. Wen",
      "C. W. Wenzel",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "L. Wollenberg",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "T. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "S. Y. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "H. Y. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "W. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. C. Xu",
      "Z. P. Xu",
      "Z. S. Xu",
      "F. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "Tao Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. X. Yang",
      "Yifan Yang",
      "Z. W. Yang",
      "Z. P. Yao",
      "M. Ye",
      "M. H. Ye",
      "J. H. Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "T. Yu",
      "X. D. Yu",
      "C. Z. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "X. Q. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "A. A. Zafar",
      "F. R. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. C. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. H. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. Y. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "Jiawei Zhang",
      "L. M. Zhang",
      "L. Q. Zhang",
      "Lei Zhang",
      "P. Zhang",
      "Q. Y. Zhang",
      "Shuihan Zhang",
      "Shulei Zhang",
      "X. D. Zhang",
      "X. M. Zhang",
      "X. Y. Zhang",
      "Xuyan Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Yan Zhang",
      "Yao Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "G. Zhao",
      "J. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "LeiZhao",
      "LingZhao",
      "M. G. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "X. Zhong",
      "H. Zhou",
      "L. P. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. Z. Zhou",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "S. Q. Zhu",
      "T. J. Zhu",
      "W. J. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "The non-locality of quantum correlations is a fundamental feature of quantum\ntheory. The Bell inequality serves as a benchmark for distinguishing between\npredictions made by quantum theory and local hidden variable theory (LHVT).\nRecent advancements in photon-entanglement experiments have addressed potential\nloopholes and have observed significant violations of variants of Bell\ninequality. However, examples of Bell inequalities violation in high energy\nphysics are scarce. In this study, we utilize $(10.087\\pm0.044)\\times10^{9}$\n$J/\\psi$ events collected with the BES-III detector at the BEPCII collider,\nperforming non-local correlation tests using the entangled hyperon pairs. The\nmassive-entangled $\\Lambda\\bar\\Lambda$ systems are formed and decay through\nstrong and weak interactions, respectively. Through measurements of the angular\ndistribution of $p\\bar{p}$ in $J/\\psi\\to \\gamma\\eta_c$ and subsequent\n$\\eta_c\\to\\Lambda(p\\pi^-)\\bar\\Lambda(\\bar{p}\\pi^{+})$ cascade decays, a\nsignificant violation of LHVT predictions is observed. The exclusion of LHVT is\nfound to be statistically significant at a level exceeding $5.2\\sigma$ in the\ntesting of three Bell-like inequalities.",
    "pdf_url": "http://arxiv.org/pdf/2505.14988v1",
    "published": "2025-05-21T00:23:06+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.14987v2",
    "title": "Singular Perturbation in Multiscale Stochastic Control Problems with Domain Restriction in the Slow Variable",
    "authors": [
      "Anderson O. Calixto",
      "Bernardo Freitas Paulo da Costa",
      "Glauco Valle"
    ],
    "abstract": "We study a multiscale stochastic optimal control problem subject to state\nconstraints on the slow variable. To address this class of problems, we develop\na rigorous theoretical framework based on singular perturbation analysis,\ntailored to settings with constrained dynamics. Our approach relies on the\ntheory of viscosity solutions for degenerate Hamilton-Jacobi-Bellman equations\nwith Neumann-type boundary conditions. We also establish the convergence of the\nmultiscale value functions in the infinite-horizon regime. Finally, we present\ntwo illustrative examples that highlight the applicability and effectiveness of\nthe proposed framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.14987v2",
    "published": "2025-05-21T00:23:00+00:00",
    "categories": [
      "math.OC",
      "math.PR"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.14986v1",
    "title": "AnyBody: A Benchmark Suite for Cross-Embodiment Manipulation",
    "authors": [
      "Meenal Parakh",
      "Alexandre Kirchmeyer",
      "Beining Han",
      "Jia Deng"
    ],
    "abstract": "Generalizing control policies to novel embodiments remains a fundamental\nchallenge in enabling scalable and transferable learning in robotics. While\nprior works have explored this in locomotion, a systematic study in the context\nof manipulation tasks remains limited, partly due to the lack of standardized\nbenchmarks. In this paper, we introduce a benchmark for learning\ncross-embodiment manipulation, focusing on two foundational tasks-reach and\npush-across a diverse range of morphologies. The benchmark is designed to test\ngeneralization along three axes: interpolation (testing performance within a\nrobot category that shares the same link structure), extrapolation (testing on\na robot with a different link structure), and composition (testing on\ncombinations of link structures). On the benchmark, we evaluate the ability of\ndifferent RL policies to learn from multiple morphologies and to generalize to\nnovel ones. Our study aims to answer whether morphology-aware training can\noutperform single-embodiment baselines, whether zero-shot generalization to\nunseen morphologies is feasible, and how consistently these patterns hold\nacross different generalization regimes. The results highlight the current\nlimitations of multi-embodiment learning and provide insights into how\narchitectural and training design choices influence policy generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.14986v1",
    "published": "2025-05-21T00:21:38+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.14985v2",
    "title": "Pre-validation Revisited",
    "authors": [
      "Jing Shang",
      "Sourav Chatterjee",
      "Trevor Hastie",
      "Robert Tibshirani"
    ],
    "abstract": "Pre-validation is a way to build prediction model with two datasets of\nsignificantly different feature dimensions. Previous work showed that the\nasymptotic distribution of the resulting test statistic for the pre-validated\npredictor deviates from a standard Normal, hence leads to issues in hypothesis\ntesting. In this paper, we revisit the pre-validation procedure and extend the\nproblem formulation without any independence assumption on the two feature\nsets. We propose not only an analytical distribution of the test statistic for\nthe pre-validated predictor under certain models, but also a generic bootstrap\nprocedure to conduct inference. We show properties and benefits of\npre-validation in prediction, inference and error estimation by simulations and\napplications, including analysis of a breast cancer study and a synthetic GWAS\nexample.",
    "pdf_url": "http://arxiv.org/pdf/2505.14985v2",
    "published": "2025-05-21T00:20:14+00:00",
    "categories": [
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.14984v1",
    "title": "CRAFT: Training-Free Cascaded Retrieval for Tabular QA",
    "authors": [
      "Adarsh Singh",
      "Kushal Raj Bhandari",
      "Jianxi Gao",
      "Soham Dan",
      "Vivek Gupta"
    ],
    "abstract": "Table Question Answering (TQA) involves retrieving relevant tables from a\nlarge corpus to answer natural language queries. Traditional dense retrieval\nmodels, such as DTR and ColBERT, not only incur high computational costs for\nlarge-scale retrieval tasks but also require retraining or fine-tuning on new\ndatasets, limiting their adaptability to evolving domains and knowledge. In\nthis work, we propose $\\textbf{CRAFT}$, a cascaded retrieval approach that\nfirst uses a sparse retrieval model to filter a subset of candidate tables\nbefore applying more computationally expensive dense models and neural\nre-rankers. Our approach achieves better retrieval performance than\nstate-of-the-art (SOTA) sparse, dense, and hybrid retrievers. We further\nenhance table representations by generating table descriptions and titles using\nGemini Flash 1.5. End-to-end TQA results using various Large Language Models\n(LLMs) on NQ-Tables, a subset of the Natural Questions Dataset, demonstrate\n$\\textbf{CRAFT}$ effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.14984v1",
    "published": "2025-05-21T00:09:34+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.14983v1",
    "title": "Toward Informed AV Decision-Making: Computational Model of Well-being and Trust in Mobility",
    "authors": [
      "Zahra Zahedi",
      "Shashank Mehrotra",
      "Teruhisa Misu",
      "Kumar Akash"
    ],
    "abstract": "For future human-autonomous vehicle (AV) interactions to be effective and\nsmooth, human-aware systems that analyze and align human needs with automation\ndecisions are essential. Achieving this requires systems that account for human\ncognitive states. We present a novel computational model in the form of a\nDynamic Bayesian Network (DBN) that infers the cognitive states of both AV\nusers and other road users, integrating this information into the AV's\ndecision-making process. Specifically, our model captures the well-being of\nboth an AV user and an interacting road user as cognitive states alongside\ntrust. Our DBN models infer beliefs over the AV user's evolving well-being,\ntrust, and intention states, as well as the possible well-being of other road\nusers, based on observed interaction experiences. Using data collected from an\ninteraction study, we refine the model parameters and empirically assess its\nperformance. Finally, we extend our model into a causal inference model (CIM)\nframework for AV decision-making, enabling the AV to enhance user well-being\nand trust while balancing these factors with its own operational costs and the\nwell-being of interacting road users. Our evaluation demonstrates the model's\neffectiveness in accurately predicting user's states and guiding informed,\nhuman-centered AV decisions.",
    "pdf_url": "http://arxiv.org/pdf/2505.14983v1",
    "published": "2025-05-21T00:02:39+00:00",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.14982v1",
    "title": "Green Hacks: Generating Sustainability-Targeting Attacks For Cyber-Physical Systems",
    "authors": [
      "Faysal Ahamed",
      "Tanushree Roy"
    ],
    "abstract": "Sustainability-targeting attacks (STA) or \"Green Hacks\" are a growing threat\nto cyber-physical system (CPS)-based infrastructure, as its performance\nobjectives are increasingly linked to sustainability goals. These attacks\nexploit the interdependence between control, energy efficiency, and\nenvironmental impact to degrade systems' overall performance. Thus, in this\nwork, we propose a general mathematical framework for modeling such STA and\nderive the feasibility conditions for generating a worst-case STA on a linear\nCPS using a max-min formulation. A gradient ascent descent algorithm is used to\nconstruct the worst-case attack policy. We simulated the worst-case STA for a\nlinear CPS to illustrate its impacts on the CPS performance and sustainability\ncost.",
    "pdf_url": "http://arxiv.org/pdf/2505.14982v1",
    "published": "2025-05-21T00:00:13+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  }
]