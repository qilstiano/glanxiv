[
  {
    "id": "http://arxiv.org/abs/2506.00756v1",
    "title": "\"Who experiences large model decay and why?\" A Hierarchical Framework for Diagnosing Heterogeneous Performance Drift",
    "authors": [
      "Harvineet Singh",
      "Fan Xia",
      "Alexej Gossmann",
      "Andrew Chuang",
      "Julian C. Hong",
      "Jean Feng"
    ],
    "abstract": "Machine learning (ML) models frequently experience performance degradation\nwhen deployed in new contexts. Such degradation is rarely uniform: some\nsubgroups may suffer large performance decay while others may not.\nUnderstanding where and how large differences in performance arise is critical\nfor designing targeted corrective actions that mitigate decay for the most\naffected subgroups while minimizing any unintended effects. Current approaches\ndo not provide such detailed insight, as they either (i) explain how average\nperformance shifts arise or (ii) identify adversely affected subgroups without\ninsight into how this occurred. To this end, we introduce a Subgroup-scanning\nHierarchical Inference Framework for performance drifT (SHIFT). SHIFT first\nasks \"Is there any subgroup with unacceptably large performance decay due to\ncovariate/outcome shifts?\" (Where?) and, if so, dives deeper to ask \"Can we\nexplain this using more detailed variable(subset)-specific shifts?\" (How?). In\nreal-world experiments, we find that SHIFT identifies interpretable subgroups\naffected by performance decay, and suggests targeted actions that effectively\nmitigate the decay.",
    "pdf_url": "http://arxiv.org/pdf/2506.00756v1",
    "published": "2025-05-31T23:50:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00755v1",
    "title": "Exponential speedup in quantum simulation of Kogut-Susskind Hamiltonian via orbifold lattice",
    "authors": [
      "Georg Bergner",
      "Masanori Hanada"
    ],
    "abstract": "We demonstrate that the orbifold lattice Hamiltonian -- an approach known for\nits efficiency in simulating SU($N$) Yang-Mills theory and QCD on digital\nquantum computers -- can reproduce the Kogut-Susskind Hamiltonian in a\ncontrolled limit. While the original Kogut-Susskind approach faces significant\nimplementation challenges on quantum hardware, we show that it emerges\nnaturally as the infinite scalar mass limit of the orbifold lattice\nformulation, even at finite lattice spacing. Our analysis provides both a\ngeneral analytical framework applicable to SU($N$) gauge theories in arbitrary\ndimensions and specific numerical evidence for $(2+1)$-dimensional SU($N$)\nYang-Mills theories ($N=2,3$). Using Euclidean path integral methods, we\nquantify the convergence rate by comparing the standard Wilson action with the\norbifold lattice action, matching lattice parameters, and systematically\nextrapolating results as the bare scalar mass approaches infinity. This\nreformulation resolves longstanding technical obstacles and offers a\nstraightforward implementation protocol for digital quantum simulation of the\nKogut-Susskind Hamiltonian with exponential speedup compared to classical\nmethods and previously known quantum methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00755v1",
    "published": "2025-05-31T23:50:27+00:00",
    "categories": [
      "quant-ph",
      "hep-lat",
      "hep-ph",
      "hep-th",
      "nucl-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00754v1",
    "title": "EcoLens: Leveraging Multi-Objective Bayesian Optimization for Energy-Efficient Video Processing on Edge Devices",
    "authors": [
      "Benjamin Civjan",
      "Bo Chen",
      "Ruixiao Zhang",
      "Klara Nahrstedt"
    ],
    "abstract": "Video processing for real-time analytics in resource-constrained environments\npresents a significant challenge in balancing energy consumption and video\nsemantics. This paper addresses the problem of energy-efficient video\nprocessing by proposing a system that dynamically optimizes processing\nconfigurations to minimize energy usage on the edge, while preserving essential\nvideo features for deep learning inference. We first gather an extensive\noffline profile of various configurations consisting of device CPU frequencies,\nframe filtering features, difference thresholds, and video bitrates, to\nestablish apriori knowledge of their impact on energy consumption and inference\naccuracy. Leveraging this insight, we introduce an online system that employs\nmulti-objective Bayesian optimization to intelligently explore and adapt\nconfigurations in real time. Our approach continuously refines processing\nsettings to meet a target inference accuracy with minimal edge device energy\nexpenditure. Experimental results demonstrate the system's effectiveness in\nreducing video processing energy use while maintaining high analytical\nperformance, offering a practical solution for smart devices and edge computing\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00754v1",
    "published": "2025-05-31T23:47:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00753v1",
    "title": "Torsion of $\\mathbb Q$-curves over number fields of small odd prime degree",
    "authors": [
      "Ivan Novak"
    ],
    "abstract": "We determine all groups which occur as torsion subgroups of $\\mathbb\nQ$-curves defined over number fields of degrees $3$, $5$ and $7$. In\nparticular, we prove that every torsion subgroup of a $\\mathbb Q$-curve defined\nover a number field of degree $3,5$ or $7$ already occurs as a torsion subgroup\nof an elliptic curve with rational $j$-invariant. As the quadratic case has\nbeen solved by Le Fourn and Najman, and the case of extensions of prime degree\ngreater than $7$ has been solved by Cremona and Najman, this paper completes\nthe classification of torsion of $\\mathbb Q$-curves over number fields of prime\ndegree.\n  We also establish that the torsion subgroup an elliptic curve over a number\nfield $K$ of prime degree which is isogenous to an elliptic curve with rational\n$j$-invariant is equal to the torsion subgroup of some elliptic curve defined\nover a degree $p$ number field with rational $j$-invariant.",
    "pdf_url": "http://arxiv.org/pdf/2506.00753v1",
    "published": "2025-05-31T23:44:53+00:00",
    "categories": [
      "math.NT",
      "11G05"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00752v2",
    "title": "Constructing Two Metrics for Spencer Cohomology: Hodge Decomposition of Constrained Bundles",
    "authors": [
      "Dongzhe Zheng"
    ],
    "abstract": "This paper establishes a metric framework for Spencer complexes based on the\ngeometric theory of compatible pairs $(D,\\lambda)$ in principal bundle\nconstraint systems, solving fundamental technical problems in computing Spencer\ncohomology of constraint systems. We develop two complementary and\ngeometrically natural metric schemes: a tensor metric based on constraint\nstrength weighting and an induced metric arising from principal bundle\ncurvature geometry, both maintaining deep compatibility with the strong\ntransversality structure of compatible pairs. Through establishing the\ncorresponding Spencer-Hodge decomposition theory, we rigorously prove that both\nmetrics provide complete elliptic structures for Spencer complexes, thereby\nguaranteeing the existence, uniqueness and finite-dimensionality of Hodge\ndecompositions. It reveals that the strong transversality condition of\ncompatible pairs is not only a necessary property of constraint geometry, but\nalso key to the elliptic regularity of Spencer operators, while the\nintroduction of constraint strength functions and curvature weights provides\nnatural weighting mechanisms for metric structures that coordinate with the\nintrinsic geometry of constraint systems. This theory tries to unify the\ndifferential geometric methods of constraint mechanics, cohomological analysis\ntools of gauge field theory, and classical techniques of Hodge theory in\ndifferential topology, establishing a mathematical foundation for understanding\nand computing topological invariants of complex constraint systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00752v2",
    "published": "2025-05-31T23:39:45+00:00",
    "categories": [
      "math.GM",
      "58J10, 58D27, 70G45, 53C07, 58A14, 81T13, 70Q05, 35R01"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00751v1",
    "title": "Alignment Revisited: Are Large Language Models Consistent in Stated and Revealed Preferences?",
    "authors": [
      "Zhuojun Gu",
      "Quan Wang",
      "Shuchu Han"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) highlight the need to align\ntheir behaviors with human values. A critical, yet understudied, issue is the\npotential divergence between an LLM's stated preferences (its reported\nalignment with general principles) and its revealed preferences (inferred from\ndecisions in contextualized scenarios). Such deviations raise fundamental\nconcerns for the interpretability, trustworthiness, reasoning transparency, and\nethical deployment of LLMs, particularly in high-stakes applications. This work\nformally defines and proposes a method to measure this preference deviation. We\ninvestigate how LLMs may activate different guiding principles in specific\ncontexts, leading to choices that diverge from previously stated general\nprinciples. Our approach involves crafting a rich dataset of well-designed\nprompts as a series of forced binary choices and presenting them to LLMs. We\ncompare LLM responses to general principle prompts stated preference with LLM\nresponses to contextualized prompts revealed preference, using metrics like KL\ndivergence to quantify the deviation. We repeat the analysis across different\ncategories of preferences and on four mainstream LLMs and find that a minor\nchange in prompt format can often pivot the preferred choice regardless of the\npreference categories and LLMs in the test. This prevalent phenomenon\nhighlights the lack of understanding and control of the LLM decision-making\ncompetence. Our study will be crucial for integrating LLMs into services,\nespecially those that interact directly with humans, where morality, fairness,\nand social responsibilities are crucial dimensions. Furthermore, identifying or\nbeing aware of such deviation will be critically important as LLMs are\nincreasingly envisioned for autonomous agentic tasks where continuous human\nevaluation of all LLMs' intermediary decision-making steps is impossible.",
    "pdf_url": "http://arxiv.org/pdf/2506.00751v1",
    "published": "2025-05-31T23:38:48+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00750v1",
    "title": "CodeSense: a Real-World Benchmark and Dataset for Code Semantic Reasoning",
    "authors": [
      "Monoshi Kumar Roy",
      "Simin Chen",
      "Benjamin Steenhoek",
      "Jinjun Peng",
      "Gail Kaiser",
      "Baishakhi Ray",
      "Wei Le"
    ],
    "abstract": "Understanding and reasoning about code semantics is essential for enhancing\ncode LLMs' abilities to solve real-world software engineering (SE) tasks.\nAlthough several code reasoning benchmarks exist, most rely on synthetic\ndatasets or educational coding problems and focus on coarse-grained reasoning\ntasks such as input/output prediction, limiting their effectiveness in\nevaluating LLMs in practical SE contexts. To bridge this gap, we propose\nCodeSense, the first benchmark that makes available a spectrum of fine-grained\ncode reasoning tasks concerned with the software engineering of real-world\ncode. We collected Python, C and Java software projects from real-world\nrepositories. We executed tests from these repositories, collected their\nexecution traces, and constructed a ground truth dataset for fine-grained\nsemantic reasoning tasks. We then performed comprehensive evaluations on\nstate-of-the-art LLMs. Our results show a clear performance gap for the models\nto handle fine-grained reasoning tasks. Although prompting techniques such as\nchain-of-thought and in-context learning helped, the lack of code semantics in\nLLMs fundamentally limit models' capabilities of code reasoning. Besides\ndataset, benchmark and evaluation, our work produced an execution tracing\nframework and tool set that make it easy to collect ground truth for\nfine-grained SE reasoning tasks, offering a strong basis for future benchmark\nconstruction and model post training. Our code and data are located at\nhttps://codesense-bench.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2506.00750v1",
    "published": "2025-05-31T23:32:01+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02047v1",
    "title": "Vector fields as a framework for modelling the mobility of commodities",
    "authors": [
      "Sima Farokhnejad",
      "Angélica S. da Mata",
      "Mariana Macedo",
      "Ronaldo Menezes"
    ],
    "abstract": "Commodities, including livestock, flow through trade networks globally, with\ntrajectories that can be effectively captured using mobility pattern modelling\napproaches similar to those used in human mobility studies. However,\ndocumenting these movements comprehensively presents significant challenges; it\ncan be unrealistic, costly, and may conflict with data protection regulations.\nAs a result, mobility datasets typically contain uncertainties due to sparsity\nand limitations in data collection. Origin-destination (OD) representations\noffer a powerful framework for modelling movement patterns and are widely\nadopted in mobility studies. However, these matrices possess inherent\nlimitations: locations absent from the OD framework lack spatial information on\npotential mobility directions and intensities. This spatial incompleteness\ncreates analytical gaps across different geographical scales, constraining our\nability to characterise movement patterns in underrepresented areas. In this\nstudy, we introduce a vector-field-based method to address these data\nchallenges, transforming OD data into vector fields capturing spatial flow\npatterns comprehensively enabling us to study mobility directions solidly. We\nuse cattle trade data from Minas Gerais, Brazil, as our case study for\ncommodity flows. This region's large livestock trading network makes it an\nideal test case. Cattle movements are significant as they affect disease\ntransmission, including foot-and-mouth disease. Accurately modelling these\nflows allows better surveillance and control strategies. Our vector-field\napproach reveals fundamental patterns in commodity mobility and can infer\nmovement information for unrepresented locations. Our approach offers an\nalternative to traditional network-based models, enhancing our capacity to\ninfer mobility patterns from incomplete datasets and advancing our\nunderstanding of large-scale commodity trades.",
    "pdf_url": "http://arxiv.org/pdf/2506.02047v1",
    "published": "2025-05-31T23:30:22+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00749v1",
    "title": "The workflow motif: a widely-userful performance diagnosis abstraction for distributed applications",
    "authors": [
      "Mania Abdi",
      "Peter Desnoyers",
      "Mark Crovella",
      "Raja R. Sambasivan"
    ],
    "abstract": "Diagnosing problems in deployed distributed applications continues to grow\nmore challenging. A significant reason is the extreme mismatch between the\npowerful abstractions developers have available to build increasingly complex\ndistributed applications versus the simple ones engineers have available to\ndiagnose problems in them. To help, we present a novel abstraction, the\nworkflow motif, instantiations of which represent characteristics of\nfrequently-repeating patterns within and among request executions. We argue\nthat workflow motifs will benefit many diagnosis tasks, formally define them,\nand use this definition to identify which frequent-subgraph-mining algorithms\nare good starting points for mining workflow motifs. We conclude by using an\nearly version of workflow motifs to suggest performance-optimization points in\nHDFS.",
    "pdf_url": "http://arxiv.org/pdf/2506.00749v1",
    "published": "2025-05-31T23:27:10+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00748v1",
    "title": "Translate With Care: Addressing Gender Bias, Neutrality, and Reasoning in Large Language Model Translations",
    "authors": [
      "Pardis Sadat Zahraei",
      "Ali Emami"
    ],
    "abstract": "Addressing gender bias and maintaining logical coherence in machine\ntranslation remains challenging, particularly when translating between natural\ngender languages, like English, and genderless languages, such as Persian,\nIndonesian, and Finnish. We introduce the Translate-with-Care (TWC) dataset,\ncomprising 3,950 challenging scenarios across six low- to mid-resource\nlanguages, to assess translation systems' performance. Our analysis of diverse\ntechnologies, including GPT-4, mBART-50, NLLB-200, and Google Translate,\nreveals a universal struggle in translating genderless content, resulting in\ngender stereotyping and reasoning errors. All models preferred masculine\npronouns when gender stereotypes could influence choices. Google Translate and\nGPT-4 showed particularly strong bias, favoring male pronouns 4-6 times more\nthan feminine ones in leadership and professional success contexts. Fine-tuning\nmBART-50 on TWC substantially resolved these biases and errors, led to strong\ngeneralization, and surpassed proprietary LLMs while remaining open-source.\nThis work emphasizes the need for targeted approaches to gender and semantic\ncoherence in machine translation, particularly for genderless languages,\ncontributing to more equitable and accurate translation systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00748v1",
    "published": "2025-05-31T23:27:07+00:00",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00747v1",
    "title": "Soft theorems of tree-level ${\\rm Tr}(φ^3)$, YM and NLSM amplitudes from $2$-splits",
    "authors": [
      "Kang Zhou"
    ],
    "abstract": "In this paper, we extend the method proposed in \\cite{Arkani-Hamed:2024fyd}\nfor deriving soft theorems of amplitudes, which relies exclusively on\nfactorization properties including conventional factorizations on physical\npoles, as well as newly discovered $2$-splits on special loci in kinematic\nspace. Using the extended approach, we fully reproduce the leading and\nsub-leading single-soft theorems for tree-level ${\\rm Tr}(\\phi^3)$ and\nYang-Mills (YM) amplitudes, along with the leading and sub-leading double-soft\ntheorems for tree-level amplitudes of non-linear sigma model (NLSM).\nFurthermore, we establish universal representations of higher-order single-soft\ntheorems for tree-level ${\\rm Tr}(\\phi^3)$ and YM amplitudes in reduced\nlower-dimensional kinematic spaces. All obtained soft factors maintain\nconsistency with momentum conservation; that is, while each explicit expression\nof the resulting soft behavior may changes under re-parameterization via\nmomentum conservation, the physical content remains equivalent. Additionally,\nwe find two interesting by-products: First, the single-soft theorems of YM\namplitudes and the double-soft theorems of NLSM, at leading and sub-leading\norders, are related by a simple kinematic replacement. This replacement also\ntransmutes gauge invariance to Adler zero. Second, we obtain universal\nsub-leading soft theorems for the resulting pure YM and NLSM currents in the\ncorresponding $2$-splits.",
    "pdf_url": "http://arxiv.org/pdf/2506.00747v1",
    "published": "2025-05-31T23:23:57+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.00746v1",
    "title": "Scalable Analysis and Design Using Automatic Differentiation",
    "authors": [
      "Julian Andrej",
      "Tzanio Kolev",
      "Boyan Lazarov"
    ],
    "abstract": "This article aims to demonstrate and discuss the applications of automatic\ndifferentiation (AD) for finding derivatives in PDE-constrained optimization\nproblems and Jacobians in non-linear finite element analysis. The main idea is\nto localize the application of AD at the integration point level by combining\nit with the so-called Finite Element Operator Decomposition. The proposed\nmethods are computationally effective, scalable, automatic, and non-intrusive,\nmaking them ideal for existing serial and parallel solvers and complex\nmultiphysics applications. The performance is demonstrated on large-scale\nsteady-state non-linear scalar problems. The chosen testbed, the MFEM library,\nis free and open-source finite element discretization library with proven\nscalability to thousands of parallel processes and state-of-the-art high-order\ndiscretization techniques.",
    "pdf_url": "http://arxiv.org/pdf/2506.00746v1",
    "published": "2025-05-31T23:18:09+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00745v1",
    "title": "Controlling the Spread of Epidemics on Networks with Differential Privacy",
    "authors": [
      "Dung Nguyen",
      "Aravind Srinivasan",
      "Renata Valieva",
      "Anil Vullikanti",
      "Jiayi Wu"
    ],
    "abstract": "Designing effective strategies for controlling epidemic spread by vaccination\nis an important question in epidemiology, especially in the early stages when\nvaccines are limited. This is a challenging question when the contact network\nis very heterogeneous, and strategies based on controlling network properties,\nsuch as the degree and spectral radius, have been shown to be effective.\nImplementation of such strategies requires detailed information on the contact\nstructure, which might be sensitive in many applications. Our focus here is on\nchoosing effective vaccination strategies when the edges are sensitive and\ndifferential privacy guarantees are needed. Our main contributions are\n$(\\varepsilon,\\delta)$-differentially private algorithms for designing\nvaccination strategies by reducing the maximum degree and spectral radius. Our\nkey technique is a private algorithm for the multi-set multi-cover problem,\nwhich we use for controlling network properties. We evaluate privacy-utility\ntradeoffs of our algorithms on multiple synthetic and real-world networks, and\nshow their effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2506.00745v1",
    "published": "2025-05-31T23:17:38+00:00",
    "categories": [
      "cs.DS",
      "cs.CE",
      "cs.SI"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00744v1",
    "title": "Blending Complementary Memory Systems in Hybrid Quadratic-Linear Transformers",
    "authors": [
      "Kazuki Irie",
      "Morris Yau",
      "Samuel J. Gershman"
    ],
    "abstract": "We develop hybrid memory architectures for general-purpose sequence\nprocessing neural networks, that combine key-value memory using softmax\nattention (KV-memory) with dynamic synaptic memory through fast-weight\nprogramming (FW-memory) -- the core principles of quadratic and linear\ntransformers, respectively. These two memory systems have complementary but\nindividually limited properties: KV-memory offers precise retrieval but is\nconstrained by quadratic complexity in sequence length, while FW-memory\nsupports arbitrarily long sequences and enables more expressive computation but\nsacrifices precise recall. We propose and compare three methods to blend these\ntwo systems into a single memory system to leverage the strengths of both. We\nconduct experiments on general language modeling and retrieval tasks by\ntraining 340M- and 1.3B-parameter models from scratch, as well as on synthetic\nalgorithmic tasks designed to precisely illustrate the benefits of certain\nhybrid methods over others. We also evaluate our hybrid memory systems on\nreinforcement learning in partially observable environments. Overall, we\ndemonstrate how a well-designed hybrid can overcome the limitations of its\nindividual components, offering new insights into the design principle of\nneural memory systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00744v1",
    "published": "2025-05-31T23:16:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.11067v1",
    "title": "A Large Language Model Based Pipeline for Review of Systems Entity Recognition from Clinical Notes",
    "authors": [
      "Hieu Nghiem",
      "Hemanth Reddy Singareddy",
      "Zhuqi Miao",
      "Jivan Lamichhane",
      "Abdulaziz Ahmed",
      "Johnson Thomas",
      "Dursun Delen",
      "William Paiva"
    ],
    "abstract": "Objective: Develop a cost-effective, large language model (LLM)-based\npipeline for automatically extracting Review of Systems (ROS) entities from\nclinical notes. Materials and Methods: The pipeline extracts ROS sections using\nSecTag, followed by few-shot LLMs to identify ROS entity spans, their\npositive/negative status, and associated body systems. We implemented the\npipeline using open-source LLMs (Mistral, Llama, Gemma) and ChatGPT. The\nevaluation was conducted on 36 general medicine notes containing 341 annotated\nROS entities. Results: When integrating ChatGPT, the pipeline achieved the\nlowest error rates in detecting ROS entity spans and their corresponding\nstatuses/systems (28.2% and 14.5%, respectively). Open-source LLMs enable\nlocal, cost-efficient execution of the pipeline while delivering promising\nperformance with similarly low error rates (span: 30.5-36.7%; status/system:\n24.3-27.3%). Discussion and Conclusion: Our pipeline offers a scalable and\nlocally deployable solution to reduce ROS documentation burden. Open-source\nLLMs present a viable alternative to commercial models in resource-limited\nhealthcare environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.11067v1",
    "published": "2025-05-31T23:11:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00743v1",
    "title": "Assortment of Attention Heads: Accelerating Federated PEFT with Head Pruning and Strategic Client Selection",
    "authors": [
      "Yeshwanth Venkatesha",
      "Souvik Kundu",
      "Priyadarshini Panda"
    ],
    "abstract": "Parameter Efficient Fine-Tuning (PEFT) has become the de-facto approach in\nadapting Large Language Models (LLMs) for downstream tasks in Natural Language\nProcessing. However, its adoption in privacy-preserving distributed learning\nframeworks, such as Federated Learning (FL), remains relatively limited. This\nis mainly due to challenges specific to FL, such as resource-constrained\ndevices and diverse data distributions among clients. In this paper, we propose\nan efficient method to perform PEFT within the FL framework for Multi-Head\nAttention (MHA) based language models. We address the challenges through head\npruning, a novel head-specific weighted aggregation mechanism, and a client\nselection strategy. Head pruning minimizes training complexity within the\nclients, guided by the importance score computed based on the confidence of the\nattention head. Weighted aggregation of heads ensures the global model captures\ncrucial updates from diverse clients complementing our client selection\nstrategy. We show results on the MultiNLI benchmark along with 20 Newsgroups,\nXL-Sum, and E2E NLG datasets. We use the MultiNLI dataset and T5-small model\nwith LoRA as our PEFT method, attaining sparsity levels of up to 90%, resulting\nin a communication advantage of up to 1.8x and a reduction in training OPs of\n3.9x while maintaining the accuracy drop under 2%.",
    "pdf_url": "http://arxiv.org/pdf/2506.00743v1",
    "published": "2025-05-31T23:09:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00742v1",
    "title": "ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary",
    "authors": [
      "Zeqi Gu",
      "Yin Cui",
      "Zhaoshuo Li",
      "Fangyin Wei",
      "Yunhao Ge",
      "Jinwei Gu",
      "Ming-Yu Liu",
      "Abe Davis",
      "Yifan Ding"
    ],
    "abstract": "Designing 3D scenes is traditionally a challenging task that demands both\nartistic expertise and proficiency with complex software. Recent advances in\ntext-to-3D generation have greatly simplified this process by letting users\ncreate scenes based on simple text descriptions. However, as these methods\ngenerally require extra training or in-context learning, their performance is\noften hindered by the limited availability of high-quality 3D data. In\ncontrast, modern text-to-image models learned from web-scale images can\ngenerate scenes with diverse, reliable spatial layouts and consistent, visually\nappealing styles. Our key insight is that instead of learning directly from 3D\nscenes, we can leverage generated 2D images as an intermediary to guide 3D\nsynthesis. In light of this, we introduce ArtiScene, a training-free automated\npipeline for scene design that integrates the flexibility of free-form\ntext-to-image generation with the diversity and reliability of 2D intermediary\nlayouts.\n  First, we generate 2D images from a scene description, then extract the shape\nand appearance of objects to create 3D models. These models are assembled into\nthe final scene using geometry, position, and pose information derived from the\nsame intermediary image. Being generalizable to a wide range of scenes and\nstyles, ArtiScene outperforms state-of-the-art benchmarks by a large margin in\nlayout and aesthetic quality by quantitative metrics. It also averages a 74.89%\nwinning rate in extensive user studies and 95.07% in GPT-4o evaluation. Project\npage: https://artiscene-cvpr.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2506.00742v1",
    "published": "2025-05-31T23:03:54+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00741v2",
    "title": "Data Swarms: Optimizable Generation of Synthetic Evaluation Data",
    "authors": [
      "Shangbin Feng",
      "Yike Wang",
      "Weijia Shi",
      "Yulia Tsvetkov"
    ],
    "abstract": "We propose Data Swarms, an algorithm to optimize the generation of synthetic\nevaluation data and advance quantitative desiderata of LLM evaluation. We first\ntrain a swarm of initial data generators using existing data, and define\nvarious evaluation objectives to reflect the desired properties of evaluation\n(e.g., generate more difficult problems for the evaluated models) and\nquantitatively evaluate data generators. We then employ particle swarm\noptimization to optimize the swarm of data generators, where they\ncollaboratively search through the model parameter space to find new generators\nthat advance these objectives. We further extend it to Adversarial Swarms,\nwhere the data generator swarm generates harder data while the test taker model\nswarm learns from such data, co-evolving dynamically for better data and models\nsimultaneously. Extensive experiments demonstrate that Data Swarms outperforms\neight data generation baselines across five evaluation objectives, while\nAdversarial Swarms produce more robust learning of synthetic data and stronger\ngeneralization. Further analysis reveals that Data Swarms successfully\noptimizes compositions of multiple evaluation objectives and generalizes to new\noff-the-shelf LLMs, unseen at optimization time.",
    "pdf_url": "http://arxiv.org/pdf/2506.00741v2",
    "published": "2025-05-31T23:03:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00740v1",
    "title": "Length Aware Speech Translation for Video Dubbing",
    "authors": [
      "Harveen Singh Chadha",
      "Aswin Shanmugam Subramanian",
      "Vikas Joshi",
      "Shubham Bansal",
      "Jian Xue",
      "Rupeshkumar Mehta",
      "Jinyu Li"
    ],
    "abstract": "In video dubbing, aligning translated audio with the source audio is a\nsignificant challenge. Our focus is on achieving this efficiently, tailored for\nreal-time, on-device video dubbing scenarios. We developed a phoneme-based\nend-to-end length-sensitive speech translation (LSST) model, which generates\ntranslations of varying lengths short, normal, and long using predefined tags.\nAdditionally, we introduced length-aware beam search (LABS), an efficient\napproach to generate translations of different lengths in a single decoding\npass. This approach maintained comparable BLEU scores compared to a baseline\nwithout length awareness while significantly enhancing synchronization quality\nbetween source and target audio, achieving a mean opinion score (MOS) gain of\n0.34 for Spanish and 0.65 for Korean, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2506.00740v1",
    "published": "2025-05-31T23:01:50+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00739v3",
    "title": "DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments",
    "authors": [
      "Chiyu Zhang",
      "Marc-Alexandre Cote",
      "Michael Albada",
      "Anush Sankaran",
      "Jack W. Stokes",
      "Tong Wang",
      "Amir Abdi",
      "William Blum",
      "Muhammad Abdul-Mageed"
    ],
    "abstract": "Large language model (LLM) agents have shown impressive capabilities in human\nlanguage comprehension and reasoning, yet their potential in cybersecurity\nremains underexplored. We introduce DefenderBench, a practical, open-source\ntoolkit for evaluating language agents across offense, defense, and\ncybersecurity knowledge-based tasks. DefenderBench includes environments for\nnetwork intrusion, malicious content detection, code vulnerability analysis,\nand cybersecurity knowledge assessment. It is intentionally designed to be\naffordable and easily accessible for researchers while providing fair and\nrigorous assessment. We benchmark several state-of-the-art (SoTA) and popular\nLLMs, including both open- and closed-weight models, using a standardized\nagentic framework. Our results show that Claude-3.7-sonnet performs best with a\nDefenderBench score of 81.65, followed by Claude-3.7-sonnet-think with 78.40,\nwhile the best open-weight model, Llama 3.3 70B, is not far behind with a\nDefenderBench score of 71.81. DefenderBench's modular design allows seamless\nintegration of custom LLMs and tasks, promoting reproducibility and fair\ncomparisons. An anonymized version of DefenderBench is available at\nhttps://github.com/microsoft/DefenderBench.",
    "pdf_url": "http://arxiv.org/pdf/2506.00739v3",
    "published": "2025-05-31T23:00:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.03194v3",
    "title": "HueManity: Probing Fine-Grained Visual Perception in MLLMs",
    "authors": [
      "Rynaa Grover",
      "Jayant Sravan Tamarapalli",
      "Sahiti Yerramilli",
      "Nilay Pande"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) excel at high-level visual\nreasoning, but their performance on nuanced perceptual tasks remains\nsurprisingly limited. We present HueManity, a benchmark designed to assess\nvisual perception in MLLMs. The dataset comprises 83,850 images featuring\ntwo-character alphanumeric strings embedded in Ishihara test style dot\npatterns, challenging models on precise pattern recognition. Our evaluation of\nnine state-of-the-art MLLMs on HueManity demonstrates a significant performance\ndeficit compared to human and traditional computer vision baselines. The\nbest-performing MLLM achieved a 33.6% accuracy on the numeric `easy' task and a\nstriking 3% on the alphanumeric `hard' task. In contrast, human participants\nachieved near-perfect scores (100% and 95.6%), and a fine-tuned ResNet50 model\nreached accuracies of 96.5% and 94.5%. These results highlight a critical gap\nin the visual capabilities of current MLLMs. Our analysis further explores\npotential architectural and training-paradigm factors contributing to this\nperceptual gap in MLLMs. We open-source HueManity dataset and code to foster\nfurther research in improving perceptual robustness of MLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.03194v3",
    "published": "2025-05-31T22:59:48+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00738v1",
    "title": "An Introduction to Algebraic Combinatorics",
    "authors": [
      "Darij Grinberg"
    ],
    "abstract": "This is an introduction to algebraic combinatorics, written for a\nquarter-long graduate course. It starts with a rigorous introduction to formal\npower series with some combinatorial applications, then discusses integer\npartitions (proving Jacobi's triple product identity), permutations (Lehmer\ncodes, cycles) and subtractive methods (alternating sums, cancellations and\ninclusion-exclusion principles, with a particular focus on sign-reversing\ninvolutions and determinants). The last chapter introduces symmetric\npolynomials and proves the Littlewood--Richardson rule using Bender--Knuth\ninvolutions (a la Stembridge).\n  The appendix contains over 200 exercises (without solutions).",
    "pdf_url": "http://arxiv.org/pdf/2506.00738v1",
    "published": "2025-05-31T22:58:31+00:00",
    "categories": [
      "math.CO",
      "05E05, 13F25, 11P81, 15A15, 05A15"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00737v1",
    "title": "Narrative Media Framing in Political Discourse",
    "authors": [
      "Yulia Otmakhova",
      "Lea Frermann"
    ],
    "abstract": "Narrative frames are a powerful way of conceptualizing and communicating\ncomplex, controversial ideas, however automated frame analysis to date has\nmostly overlooked this framing device. In this paper, we connect elements of\nnarrativity with fundamental aspects of framing, and present a framework which\nformalizes and operationalizes such aspects. We annotate and release a data set\nof news articles in the climate change domain, analyze the dominance of\nnarrative frame components across political leanings, and test LLMs in their\nability to predict narrative frames and their components. Finally, we apply our\nframework in an unsupervised way to elicit components of narrative framing in a\nsecond domain, the COVID-19 crisis, where our predictions are congruent with\nprior theoretical work showing the generalizability of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2506.00737v1",
    "published": "2025-05-31T22:55:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00736v1",
    "title": "IMPACT: Iterative Mask-based Parallel Decoding for Text-to-Audio Generation with Diffusion Modeling",
    "authors": [
      "Kuan-Po Huang",
      "Shu-wen Yang",
      "Huy Phan",
      "Bo-Ru Lu",
      "Byeonggeun Kim",
      "Sashank Macha",
      "Qingming Tang",
      "Shalini Ghosh",
      "Hung-yi Lee",
      "Chieh-Chi Kao",
      "Chao Wang"
    ],
    "abstract": "Text-to-audio generation synthesizes realistic sounds or music given a\nnatural language prompt. Diffusion-based frameworks, including the Tango and\nthe AudioLDM series, represent the state-of-the-art in text-to-audio\ngeneration. Despite achieving high audio fidelity, they incur significant\ninference latency due to the slow diffusion sampling process. MAGNET, a\nmask-based model operating on discrete tokens, addresses slow inference through\niterative mask-based parallel decoding. However, its audio quality still lags\nbehind that of diffusion-based models. In this work, we introduce IMPACT, a\ntext-to-audio generation framework that achieves high performance in audio\nquality and fidelity while ensuring fast inference. IMPACT utilizes iterative\nmask-based parallel decoding in a continuous latent space powered by diffusion\nmodeling. This approach eliminates the fidelity constraints of discrete tokens\nwhile maintaining competitive inference speed. Results on AudioCaps demonstrate\nthat IMPACT achieves state-of-the-art performance on key metrics including\nFr\\'echet Distance (FD) and Fr\\'echet Audio Distance (FAD) while significantly\nreducing latency compared to prior models. The project website is available at\nhttps://audio-impact.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2506.00736v1",
    "published": "2025-05-31T22:51:36+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00735v1",
    "title": "Involution-Infused DenseNet with Two-Step Compression for Resource-Efficient Plant Disease Classification",
    "authors": [
      "T. Ahmed",
      "S. Jannat",
      "Md. F. Islam",
      "J. Noor"
    ],
    "abstract": "Agriculture is vital for global food security, but crops are vulnerable to\ndiseases that impact yield and quality. While Convolutional Neural Networks\n(CNNs) accurately classify plant diseases using leaf images, their high\ncomputational demands hinder their deployment in resource-constrained settings\nsuch as smartphones, edge devices, and real-time monitoring systems. This study\nproposes a two-step model compression approach integrating Weight Pruning and\nKnowledge Distillation, along with the hybridization of DenseNet with\nInvolutional Layers. Pruning reduces model size and computational load, while\ndistillation improves the smaller student models performance by transferring\nknowledge from a larger teacher network. The hybridization enhances the models\nability to capture spatial features efficiently. These compressed models are\nsuitable for real-time applications, promoting precision agriculture through\nrapid disease identification and crop management. The results demonstrate\nResNet50s superior performance post-compression, achieving 99.55% and 98.99%\naccuracy on the PlantVillage and PaddyLeaf datasets, respectively. The\nDenseNet-based model, optimized for efficiency, recorded 99.21% and 93.96%\naccuracy with a minimal parameter count. Furthermore, the hybrid model achieved\n98.87% and 97.10% accuracy, supporting the practical deployment of\nenergy-efficient devices for timely disease intervention and sustainable\nfarming practices.",
    "pdf_url": "http://arxiv.org/pdf/2506.00735v1",
    "published": "2025-05-31T22:43:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00734v1",
    "title": "A Sequential Computation Algorithm for the Center of the Smallest Enclosing Ball",
    "authors": [
      "Kenji Nakagawa",
      "Yoshinori Takei"
    ],
    "abstract": "In this paper, we consider the problem of finding the center $Q^\\ast$ of the\nSEB (smallest enclosing ball) for $n$ points in $d$-dimensional Euclidean\nspace. One application of the SEB is SVDD (support vector data description) in\nsupport vector machines. Our objective is to develop a sequential computation\nalgorithm for determining the barycentric coordinate of $Q^\\ast$. To achieve\nit, we apply the concept of the Arimoto-Blahut algorithm, which is a sequential\ncomputation algorithm used to compute the channel capacity. We first consider\nthe case in which an equidistant point $\\widetilde{Q}$ from the $n$ points\nexists, and construct a recurrence formula that converges to the barycentric\ncoordinate $\\widetilde{\\bm\\lambda}$ of $\\widetilde{Q}$. When $\\widetilde{Q}$\nlies within the convex hull of the $n$ points, $\\widetilde{Q}$ coincides with\n$Q^\\ast$, hence in this case, the recurrence formula converges to the\nbarycentric coordinate $\\bm\\lambda^\\ast$ of $Q^\\ast$. The resulting recurrence\nformula is very simple because it uses only the coordinates of the $n$ points.\nThe computational complexity, with an approximation error of $\\epsilon$ to the\nexact solution $\\widetilde{\\bm\\lambda}$, is $O(\\kappa n^2\\log(1/\\epsilon))$,\nwhere $\\kappa$ is a value determined by the $n$ points. Furthermore, we modify\nthe algorithm so that it can also be applied in cases where $\\widetilde{Q}$\ndoes not exist, and evaluate the convergence performance numerically. We\ncompare the proposed algorithm with conventional algorithms in terms of run\ntime and computational accuracy through several examples. The proposed\nalgorithm has some advantages and some disadvantages compared to the\nconventional algorithms, but overall, since the proposed algorithm can be\ncomputed using a very simple formula, it is considered sufficiently practical.",
    "pdf_url": "http://arxiv.org/pdf/2506.00734v1",
    "published": "2025-05-31T22:42:35+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00733v1",
    "title": "Quantifying and Reducing Speaker Heterogeneity within the Common Voice Corpus for Phonetic Analysis",
    "authors": [
      "Miao Zhang",
      "Aref Farhadipour",
      "Annie Baker",
      "Jiachen Ma",
      "Bogdan Pricop",
      "Eleanor Chodroff"
    ],
    "abstract": "With its crosslinguistic and cross-speaker diversity, the Mozilla Common\nVoice Corpus (CV) has been a valuable resource for multilingual speech\ntechnology and holds tremendous potential for research in crosslinguistic\nphonetics and speech sciences. Properly accounting for speaker variation is,\nhowever, key to the theoretical and statistical bases of speech research. While\nCV provides a client ID as an approximation to a speaker ID, multiple speakers\ncan contribute under the same ID. This study aims to quantify and reduce\nheterogeneity in the client ID for a better approximation of a true, though\nstill anonymous speaker ID. Using ResNet-based voice embeddings, we obtained a\nsimilarity score among recordings with the same client ID, then implemented a\nspeaker discrimination task to identify an optimal threshold for reducing\nperceived speaker heterogeneity. These results have major downstream\napplications for phonetic analysis and the development of speaker-based speech\ntechnology.",
    "pdf_url": "http://arxiv.org/pdf/2506.00733v1",
    "published": "2025-05-31T22:39:48+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00732v1",
    "title": "Bregman Conditional Random Fields: Sequence Labeling with Parallelizable Inference Algorithms",
    "authors": [
      "Caio Corro",
      "Mathieu Lacroix",
      "Joseph Le Roux"
    ],
    "abstract": "We propose a novel discriminative model for sequence labeling called Bregman\nconditional random fields (BCRF). Contrary to standard linear-chain conditional\nrandom fields, BCRF allows fast parallelizable inference algorithms based on\niterative Bregman projections. We show how such models can be learned using\nFenchel-Young losses, including extension for learning from partial labels.\nExperimentally, our approach delivers comparable results to CRF while being\nfaster, and achieves better results in highly constrained settings compared to\nmean field, another parallelizable alternative.",
    "pdf_url": "http://arxiv.org/pdf/2506.00732v1",
    "published": "2025-05-31T22:36:21+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02046v1",
    "title": "Machine vs Machine: Using AI to Tackle Generative AI Threats in Assessment",
    "authors": [
      "Mohammad Saleh Torkestani",
      "Taha Mansouri"
    ],
    "abstract": "This paper presents a theoretical framework for addressing the challenges\nposed by generative artificial intelligence (AI) in higher education assessment\nthrough a machine-versus-machine approach. Large language models like GPT-4,\nClaude, and Llama increasingly demonstrate the ability to produce sophisticated\nacademic content, traditional assessment methods face an existential threat,\nwith surveys indicating 74-92% of students experimenting with these tools for\nacademic purposes. Current responses, ranging from detection software to manual\nassessment redesign, show significant limitations: detection tools demonstrate\nbias against non-native English writers and can be easily circumvented, while\nmanual frameworks rely heavily on subjective judgment and assume static AI\ncapabilities. This paper introduces a dual strategy paradigm combining static\nanalysis and dynamic testing to create a comprehensive theoretical framework\nfor assessment vulnerability evaluation. The static analysis component\ncomprises eight theoretically justified elements: specificity and\ncontextualization, temporal relevance, process visibility requirements,\npersonalization elements, resource accessibility, multimodal integration,\nethical reasoning requirements, and collaborative elements. Each element\naddresses specific limitations in generative AI capabilities, creating barriers\nthat distinguish authentic human learning from AI-generated simulation. The\ndynamic testing component provides a complementary approach through\nsimulation-based vulnerability assessment, addressing limitations in\npattern-based analysis. The paper presents a theoretical framework for\nvulnerability scoring, including the conceptual basis for quantitative\nassessment, weighting frameworks, and threshold determination theory.",
    "pdf_url": "http://arxiv.org/pdf/2506.02046v1",
    "published": "2025-05-31T22:29:43+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.3.1"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00731v1",
    "title": "MoPINNEnKF: Iterative Model Inference using generic-PINN-based ensemble Kalman filter",
    "authors": [
      "Binghang Lu",
      "Changhong Mou",
      "Guang Lin"
    ],
    "abstract": "Physics-informed neural networks (PINNs) have emerged as a powerful tool for\nsolving forward and inverse problems involving partial differential equations\n(PDEs) by incorporating physical laws into the training process. However, the\nperformance of PINNs is often hindered in real-world scenarios involving noisy\nobservational data and missing physics, particularly in inverse problems. In\nthis work, we propose an iterative multi-objective PINN ensemble Kalman filter\n(MoPINNEnKF) framework that improves the robustness and accuracy of PINNs in\nboth forward and inverse problems by using the \\textit{ensemble Kalman filter}\nand the \\textit{non-dominated sorting genetic algorithm} III (NSGA-III).\nSpecifically, NSGA-III is used as a multi-objective optimizer that can generate\nvarious ensemble members of PINNs along the optimal Pareto front, while\naccounting the model uncertainty in the solution space. These ensemble members\nare then utilized within the EnKF to assimilate noisy observational data. The\nEnKF's analysis is subsequently used to refine the data loss component for\nretraining the PINNs, thereby iteratively updating their parameters. The\niterative procedure generates improved solutions to the PDEs. The proposed\nmethod is tested on two benchmark problems: the one-dimensional viscous Burgers\nequation and the time-fractional mixed diffusion-wave equation (TFMDWE). The\nnumerical results show it outperforms standard PINNs in handling noisy data and\nmissing physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00731v1",
    "published": "2025-05-31T22:20:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.04249v1",
    "title": "ChemReservoir -- An Open-Source Framework for Chemically-Inspired Reservoir Computing",
    "authors": [
      "Mehmet Aziz Yirik",
      "Jakob Lykke Andersen",
      "Rolf Fagerberg",
      "Daniel Merkle"
    ],
    "abstract": "Reservoir computing is a type of a recurrent neural network, mapping the\ninputs into higher dimensional space using fixed and nonlinear dynamical\nsystems, called reservoirs. In the literature, there are various types of\nreservoirs ranging from in-silico to in-vitro. In cheminformatics, previous\nstudies contributed to the field by developing simulation-based chemically\ninspired in-silico reservoir models. Yahiro used a DNA-based chemical reaction\nnetwork as its reservoir and Nguyen developed a DNA chemistry-inspired tool\nbased on Gillespie algorithm. However, these software tools were designed\nmainly with the focus on DNA chemistry and their maintenance status has limited\ntheir current usability. Due to these limitations, there was a need for a\nproper open-source tool. This study introduces ChemReservoir, an open-source\nframework for chemically-inspired reservoir computing. In contrast to the\nformer studies focused on DNA-chemistry, ChemReservoir is a general framework\nfor the construction and analysis of chemically-inspired reservoirs, which also\naddresses the limitations in these previous studies by ensuring enhanced\ntesting, evaluation, and reproducibility. The tool was evaluated using various\ncycle-based reservoir topologies and demonstrated stable performance across a\nrange of configurations in memory capacity tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.04249v1",
    "published": "2025-05-31T22:12:05+00:00",
    "categories": [
      "cs.CE",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00730v1",
    "title": "Getting More from Less: Transfer Learning Improves Sleep Stage Decoding Accuracy in Peripheral Wearable Devices",
    "authors": [
      "William G Coon",
      "Diego Luna",
      "Akshita Panagrahi",
      "Matthew Reid",
      "Mattson Ogg"
    ],
    "abstract": "Transfer learning, a technique commonly used in generative artificial\nintelligence, allows neural network models to bring prior knowledge to bear\nwhen learning a new task. This study demonstrates that transfer learning\nsignificantly enhances the accuracy of sleep-stage decoding from peripheral\nwearable devices by leveraging neural network models pretrained on\nelectroencephalographic (EEG) signals. Consumer wearable technologies typically\nrely on peripheral physiological signals such as pulse plethysmography (PPG)\nand respiratory data, which, while convenient, lack the fidelity of clinical\nelectroencephalography (EEG) for detailed sleep-stage classification. We\npretrained a transformer-based neural network on a large, publicly available\nEEG dataset and subsequently fine-tuned this model on noisier peripheral\nsignals. Our transfer learning approach improved overall classification\naccuracy from 67.6\\% (baseline model trained solely on peripheral signals) to\n76.6\\%. Notable accuracy improvements were observed across sleep stages,\nparticularly lighter sleep stages such as REM and N1. These results highlight\ntransfer learning's potential to substantially enhance the accuracy and utility\nof consumer wearable devices without altering existing hardware. Future\nintegration of self-supervised learning methods may further boost performance,\nfacilitating more precise, longitudinal sleep monitoring for personalized\nhealth applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00730v1",
    "published": "2025-05-31T22:05:15+00:00",
    "categories": [
      "q-bio.QM",
      "q-bio.NC"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00729v2",
    "title": "On Groups of Linear Fractional Transformations Stabilizing Finite Sets of Four Elements",
    "authors": [
      "Patrick Nyadjo Fonga"
    ],
    "abstract": "Let $E$ be a subset of the projective line over a commutative field\n$\\mathbb{K}$. When $\\mathbb{K}$ has infinite cardinality, it is well known that\nif $E$ contains at most three elements, then the group of linear fractional\ntransformations preserving $E$ is either infinite or isomorphic to the\nsymmetric group on three elements. In this work, we investigate the case where\n$E$ consists of four elements. We show that the group of projective linear\ntransformations stabilizing $E$ is, depending on the characteristic of the\nfield $\\mathbb{K}$, isomorphic to either the Klein four-group $V_4$, the\ndihedral group $D_4$ of order eight, the alternating group $\\mathfrak{A}_4$ of\norder twelve, or the symmetric group $\\mathfrak{S}_4$ of order twenty-four.",
    "pdf_url": "http://arxiv.org/pdf/2506.00729v2",
    "published": "2025-05-31T22:04:58+00:00",
    "categories": [
      "math.NT",
      "math.GR"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00728v2",
    "title": "Geometric Duality Between Constraints and Gauge Fields: Mirror Symmetry and Spencer Isomorphisms of Compatible Pairs on Principal Bundles",
    "authors": [
      "Dongzhe Zheng"
    ],
    "abstract": "This paper develops a mirror symmetry theory of Spencer cohomology within the\ngeometric framework of constrained systems on principal bundles, revealing deep\nsymmetric structures in constraint geometry. Based on compatible pairs\n$(D,\\lambda)$ under strong transversality conditions, we construct a systematic\nfamily of mirror transformations: from basic sign mirrors $\\lambda \\mapsto\n-\\lambda$ to general automorphism-induced mirrors $\\lambda \\mapsto\n(d\\phi)^*(\\lambda)$. Our core result proves that these transformations preserve\nall geometric properties of compatible pairs and induce natural isomorphisms\nbetween Spencer cohomology groups. This theory unifies constraint mechanics,\ngauge field theory, and differential topology, establishing a complete\nmathematical framework for symmetry analysis of constraint systems and\nrevealing the special mirror structure of Spencer complexes in constraint\ngeometry.",
    "pdf_url": "http://arxiv.org/pdf/2506.00728v2",
    "published": "2025-05-31T22:04:53+00:00",
    "categories": [
      "math.GM",
      "58A15, 53C29, 70G45, 81T13, 22E70"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00727v1",
    "title": "Adaptive Plane Reformatting for 4D Flow MRI using Deep Reinforcement Learning",
    "authors": [
      "Javier Bisbal",
      "Julio Sotelo",
      "Maria I Valdés",
      "Pablo Irarrazaval",
      "Marcelo E Andia",
      "Julio García",
      "José Rodriguez-Palomarez",
      "Francesca Raimondi",
      "Cristián Tejos",
      "Sergio Uribe"
    ],
    "abstract": "Deep reinforcement learning (DRL) algorithms have shown robust results in\nplane reformatting tasks. In these methods, an agent sequentially adjusts the\nposition and orientation of an initial plane towards an objective location.\nThis process allows accurate plane reformatting, without the need for detailed\nlandmarks, which makes it suitable for images with limited contrast and\nresolution, such as 4D flow MRI. However, current DRL methods require the test\ndataset to be in the same position and orientation as the training dataset. In\nthis paper, we present a novel technique that utilizes a flexible coordinate\nsystem based on the current state, enabling navigation in volumes at any\nposition or orientation. We adopted the Asynchronous Advantage Actor Critic\n(A3C) algorithm for reinforcement learning, outperforming Deep Q Network (DQN).\nExperimental results in 4D flow MRI demonstrate improved accuracy in plane\nreformatting angular and distance errors (6.32 +- 4.15 {\\deg} and 3.40 +- 2.75\nmm), as well as statistically equivalent flow measurements determined by a\nplane reformatting process done by an expert (p=0.21). The method's flexibility\nand adaptability make it a promising candidate for other medical imaging\napplications beyond 4D flow MRI.",
    "pdf_url": "http://arxiv.org/pdf/2506.00727v1",
    "published": "2025-05-31T22:02:05+00:00",
    "categories": [
      "cs.LG",
      "cs.CV",
      "I.4.0"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00726v1",
    "title": "Structured Gradient Guidance for Few-Shot Adaptation in Large Language Models",
    "authors": [
      "Hongye Zheng",
      "Yichen Wang",
      "Ray Pan",
      "Guiran Liu",
      "Binrong Zhu",
      "Hanlu Zhang"
    ],
    "abstract": "This paper presents a gradient-informed fine-tuning method for large language\nmodels under few-shot conditions. The goal is to enhance task adaptability and\ntraining stability when data is limited. The method builds on a base loss\nfunction and introduces two gradient-related regularization terms. The first\nenforces gradient direction consistency to guide parameter updates along\ntask-relevant directions and prevent drift. The second controls gradient\nmagnitude to avoid abnormal updates. Together, these components support a more\nefficient and stable optimization path. To further improve cross-task\ngeneralization, the method incorporates a gradient alignment mechanism. This\nmechanism measures the consistency between optimization directions of the\nsource and target tasks. It enhances fine-tuning performance in multi-task and\ncross-domain scenarios. Across various natural language understanding tasks,\nthe method outperforms existing fine-tuning strategies in average accuracy,\ngradient stability, and directional alignment. Empirical evaluations under\ndifferent sample sizes and domain-specific tasks confirm the method's\nrobustness and broad applicability in low-resource environments. In particular,\nthe method shows clear advantages in controlling parameter update paths. The\nresults demonstrate that a gradient-based fine-tuning framework can effectively\nleverage the representational power of large language models. It ensures\ntraining stability while reducing dependence on large volumes of labeled data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00726v1",
    "published": "2025-05-31T21:59:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00725v1",
    "title": "A Foundation Model for Non-Destructive Defect Identification from Vibrational Spectra",
    "authors": [
      "Mouyang Cheng",
      "Chu-Liang Fu",
      "Bowen Yu",
      "Eunbi Rha",
      "Abhijatmedhi Chotrattanapituk",
      "Douglas L Abernathy",
      "Yongqiang Cheng",
      "Mingda Li"
    ],
    "abstract": "Defects are ubiquitous in solids and strongly influence materials' mechanical\nand functional properties. However, non-destructive characterization and\nquantification of defects, especially when multiple types coexist, remain a\nlong-standing challenge. Here we introduce DefectNet, a foundation machine\nlearning model that predicts the chemical identity and concentration of\nsubstitutional point defects with multiple coexisting elements directly from\nvibrational spectra, specifically phonon density-of-states (PDoS). Trained on\nover 16,000 simulated spectra from 2,000 semiconductors, DefectNet employs a\ntailored attention mechanism to identify up to six distinct defect elements at\nconcentrations ranging from 0.2% to 25%. The model generalizes well to unseen\ncrystals across 56 elements and can be fine-tuned on experimental data.\nValidation using inelastic scattering measurements of SiGe alloys and MgB$_2$\nsuperconductor demonstrates its accuracy and transferability. Our work\nestablishes vibrational spectroscopy as a viable, non-destructive probe for\npoint defect quantification in bulk materials, and highlights the promise of\nfoundation models in data-driven defect engineering.",
    "pdf_url": "http://arxiv.org/pdf/2506.00725v1",
    "published": "2025-05-31T21:51:51+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00724v1",
    "title": "A condensing approach to multiple shooting neural ordinary differential equation",
    "authors": [
      "Siddharth Prabhu",
      "Srinivas Rangarajan",
      "Mayuresh Kothare"
    ],
    "abstract": "Multiple-shooting is a parameter estimation approach for ordinary\ndifferential equations. In this approach, the trajectory is broken into small\nintervals, each of which can be integrated independently. Equality constraints\nare then applied to eliminate the shooting gap between the end of the previous\ntrajectory and the start of the next trajectory. Unlike single-shooting,\nmultiple-shooting is more stable, especially for highly oscillatory and long\ntrajectories. In the context of neural ordinary differential equations,\nmultiple-shooting is not widely used due to the challenge of incorporating\ngeneral equality constraints. In this work, we propose a condensing-based\napproach to incorporate these shooting equality constraints while training a\nmultiple-shooting neural ordinary differential equation (MS-NODE) using\nfirst-order optimization methods such as Adam.",
    "pdf_url": "http://arxiv.org/pdf/2506.00724v1",
    "published": "2025-05-31T21:51:33+00:00",
    "categories": [
      "cs.LG",
      "math.DS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00723v1",
    "title": "Pitfalls in Evaluating Language Model Forecasters",
    "authors": [
      "Daniel Paleka",
      "Shashwat Goel",
      "Jonas Geiping",
      "Florian Tramèr"
    ],
    "abstract": "Large language models (LLMs) have recently been applied to forecasting tasks,\nwith some works claiming these systems match or exceed human performance. In\nthis paper, we argue that, as a community, we should be careful about such\nconclusions as evaluating LLM forecasters presents unique challenges. We\nidentify two broad categories of issues: (1) difficulty in trusting evaluation\nresults due to many forms of temporal leakage, and (2) difficulty in\nextrapolating from evaluation performance to real-world forecasting. Through\nsystematic analysis and concrete examples from prior work, we demonstrate how\nevaluation flaws can raise concerns about current and future performance\nclaims. We argue that more rigorous evaluation methodologies are needed to\nconfidently assess the forecasting abilities of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00723v1",
    "published": "2025-05-31T21:49:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00722v1",
    "title": "Chain-of-Thought Training for Open E2E Spoken Dialogue Systems",
    "authors": [
      "Siddhant Arora",
      "Jinchuan Tian",
      "Hayato Futami",
      "Jee-weon Jung",
      "Jiatong Shi",
      "Yosuke Kashiwagi",
      "Emiru Tsunoo",
      "Shinji Watanabe"
    ],
    "abstract": "Unlike traditional cascaded pipelines, end-to-end (E2E) spoken dialogue\nsystems preserve full differentiability and capture non-phonemic information,\nmaking them well-suited for modeling spoken interactions. However, existing E2E\napproaches often require large-scale training data and generates responses\nlacking semantic coherence. We propose a simple yet effective strategy\nleveraging a chain-of-thought (CoT) formulation, ensuring that training on\nconversational data remains closely aligned with the multimodal language model\n(LM)'s pre-training on speech recognition~(ASR), text-to-speech synthesis\n(TTS), and text LM tasks. Our method achieves over 1.5 ROUGE-1 improvement over\nthe baseline, successfully training spoken dialogue systems on publicly\navailable human-human conversation datasets, while being compute-efficient\nenough to train on just 300 hours of public human-human conversation data, such\nas the Switchboard. We will publicly release our models and training code.",
    "pdf_url": "http://arxiv.org/pdf/2506.00722v1",
    "published": "2025-05-31T21:43:37+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00721v1",
    "title": "Common Inpainted Objects In-N-Out of Context",
    "authors": [
      "Tianze Yang",
      "Tyson Jordan",
      "Ninghao Liu",
      "Jin Sun"
    ],
    "abstract": "We present Common Inpainted Objects In-N-Out of Context (COinCO), a novel\ndataset addressing the scarcity of out-of-context examples in existing vision\ndatasets. By systematically replacing objects in COCO images through\ndiffusion-based inpainting, we create 97,722 unique images featuring both\ncontextually coherent and inconsistent scenes, enabling effective context\nlearning. Each inpainted object is meticulously verified and categorized as in-\nor out-of-context through a multimodal large language model assessment. Our\nanalysis reveals significant patterns in semantic priors that influence\ninpainting success across object categories. We demonstrate three key tasks\nenabled by COinCO: (1) training context classifiers that effectively determine\nwhether existing objects belong in their context; (2) a novel\nObjects-from-Context prediction task that determines which new objects\nnaturally belong in given scenes at both instance and clique levels, and (3)\ncontext-enhanced fake detection on state-of-the-art methods without\nfine-tuning. COinCO provides a controlled testbed with contextual variations,\nestablishing a foundation for advancing context-aware visual understanding in\ncomputer vision and image forensics. Our code and data are at:\nhttps://github.com/YangTianze009/COinCO.",
    "pdf_url": "http://arxiv.org/pdf/2506.00721v1",
    "published": "2025-05-31T21:42:12+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00720v1",
    "title": "Bi-Level optimization for parameter estimation of differential equations using interpolation",
    "authors": [
      "Siddharth Prabhu",
      "Srinivas Rangarajan",
      "Mayuresh Kothare"
    ],
    "abstract": "Inverse problem or parameter estimation of ordinary differential equations is\na process of obtaining the best parameters using experimental measurements of\nthe states. Single (Multiple)-shooting is a type of sequential optimization\nmethod that minimizes the error in the measured and numerically integrated\nstates. However, this requires computing sensitivities i.e. the derivatives of\nstates with respect to the parameters over the numerical integrator, which can\nget computationally expensive. To address this challenge, many\ninterpolation-based approaches have been proposed to either reduce the\ncomputational cost of sensitivity calculations or eliminate their need. In this\npaper, we use a bi-level optimization framework that leverages interpolation\nand exploits the structure of the differential equation to solve an inner\nconvex optimization problem. We apply this method to two different problem\nformulations. First, parameter estimation for differential equations, and\ndelayed differential equations, where the model structure is known but the\nparameters are unknown. Second, model discovery problems, where both the model\nstructure and parameters are unknown.",
    "pdf_url": "http://arxiv.org/pdf/2506.00720v1",
    "published": "2025-05-31T21:40:52+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00719v1",
    "title": "Browser Fingerprinting Using WebAssembly",
    "authors": [
      "Mordechai Guri",
      "Dor Fibert"
    ],
    "abstract": "Web client fingerprinting has become a widely used technique for uniquely\nidentifying users, browsers, operating systems, and devices with high accuracy.\nWhile it is beneficial for applications such as fraud detection and\npersonalized experiences, it also raises privacy concerns by enabling\npersistent tracking and detailed user profiling. This paper introduces an\nadvanced fingerprinting method using WebAssembly (Wasm) - a low-level\nprogramming language that offers near-native execution speed in modern web\nbrowsers. With broad support across major browsers and growing adoption,\nWebAssembly provides a strong foundation for developing more effective\nfingerprinting methods.\n  In this work, we present a new approach that leverages WebAssembly's\ncomputational capabilities to identify returning devices-such as smartphones,\ntablets, laptops, and desktops across different browsing sessions. Our method\nuses subtle differences in the WebAssembly JavaScript API implementation to\ndistinguish between Chromium-based browsers like Google Chrome and Microsoft\nEdge, even when identifiers such as the User-Agent are completely spoofed,\nachieving a false-positive rate of less than 1%. The fingerprint is generated\nusing a combination of CPU-bound operations, memory tasks, and I/O activities\nto capture unique browser behaviors. We validate this approach on a variety of\nplatforms, including Intel, AMD, and ARM CPUs, operating systems such as\nWindows, macOS, Android, and iOS, and in environments like VMWare, KVM, and\nVirtualBox. Extensive evaluation shows that WebAssembly-based fingerprinting\nsignificantly improves identification accuracy. We also propose mitigation\nstrategies to reduce the privacy risks associated with this method, which could\nbe integrated into future browser designs to better protect user privacy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00719v1",
    "published": "2025-05-31T21:39:17+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00718v1",
    "title": "From Local Cues to Global Percepts: Emergent Gestalt Organization in Self-Supervised Vision Models",
    "authors": [
      "Tianqin Li",
      "Ziqi Wen",
      "Leiran Song",
      "Jun Liu",
      "Zhi Jing",
      "Tai Sing Lee"
    ],
    "abstract": "Human vision organizes local cues into coherent global forms using Gestalt\nprinciples like closure, proximity, and figure-ground assignment -- functions\nreliant on global spatial structure. We investigate whether modern vision\nmodels show similar behaviors, and under what training conditions these emerge.\nWe find that Vision Transformers (ViTs) trained with Masked Autoencoding (MAE)\nexhibit activation patterns consistent with Gestalt laws, including illusory\ncontour completion, convexity preference, and dynamic figure-ground\nsegregation. To probe the computational basis, we hypothesize that modeling\nglobal dependencies is necessary for Gestalt-like organization. We introduce\nthe Distorted Spatial Relationship Testbench (DiSRT), which evaluates\nsensitivity to global spatial perturbations while preserving local textures.\nUsing DiSRT, we show that self-supervised models (e.g., MAE, CLIP) outperform\nsupervised baselines and sometimes even exceed human performance. ConvNeXt\nmodels trained with MAE also exhibit Gestalt-compatible representations,\nsuggesting such sensitivity can arise without attention architectures. However,\nclassification finetuning degrades this ability. Inspired by biological vision,\nwe show that a Top-K activation sparsity mechanism can restore global\nsensitivity. Our findings identify training conditions that promote or suppress\nGestalt-like perception and establish DiSRT as a diagnostic for global\nstructure sensitivity across models.",
    "pdf_url": "http://arxiv.org/pdf/2506.00718v1",
    "published": "2025-05-31T21:35:54+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00717v2",
    "title": "Vid2Coach: Transforming How-To Videos into Task Assistants",
    "authors": [
      "Mina Huh",
      "Zihui Xue",
      "Ujjaini Das",
      "Kumar Ashutosh",
      "Kristen Grauman",
      "Amy Pavel"
    ],
    "abstract": "People use videos to learn new recipes, exercises, and crafts. Such videos\nremain difficult for blind and low vision (BLV) people to follow as they rely\non visual comparison. Our observations of visual rehabilitation therapists\n(VRTs) guiding BLV people to follow how-to videos revealed that VRTs provide\nboth proactive and responsive support including detailed descriptions,\nnon-visual workarounds, and progress feedback. We propose Vid2Coach, a system\nthat transforms how-to videos into wearable camera-based assistants that\nprovide accessible instructions and mixed-initiative feedback. From the video,\nVid2Coach generates accessible instructions by augmenting narrated instructions\nwith demonstration details and completion criteria for each step. It then uses\nretrieval-augmented-generation to extract relevant non-visual workarounds from\nBLV-specific resources. Vid2Coach then monitors user progress with a camera\nembedded in commercial smart glasses to provide context-aware instructions,\nproactive feedback, and answers to user questions. BLV participants (N=8) using\nVid2Coach completed cooking tasks with 58.5\\% fewer errors than when using\ntheir typical workflow and wanted to use Vid2Coach in their daily lives.\nVid2Coach demonstrates an opportunity for AI visual assistance that strengthens\nrather than replaces non-visual expertise.",
    "pdf_url": "http://arxiv.org/pdf/2506.00717v2",
    "published": "2025-05-31T21:28:50+00:00",
    "categories": [
      "cs.HC",
      "cs.CV"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.02045v1",
    "title": "The Galactic Pizza: Flat Rotation Curves in the Context of Cosmological Time-Energy Coupling",
    "authors": [
      "Artur Novais",
      "André L. B. Ribeiro"
    ],
    "abstract": "The phenomenon of augmented gravity on the scale of galaxies, conventionally\nattributed to dark matter halos, is shown to possibly result from the\nincremental growth of galactic masses and radii over time. This approach\nelucidates the cosmological origins of the acceleration scale $a_0\\approx\ncH_0/2\\pi\\approx10^{-10}$ms$^{-2}$ at which galaxy rotation curves deviate from\nKeplerian behavior, with no need for new particles or modifications to the laws\nof gravity, i.e., it constitutes a new explanatory path beyond Cold Dark Matter\n(CDM) and Modified Newtonian Dynamics (MOND). Once one formally equates the\nenergy density of the universe to the critical value ($\\rho=\\rho_c$) and the\ncosmic age to the reciprocal of the Hubble parameter ($t=H^{-1}$),\nindependently of the epoch of observation, the result is the Zero-Energy\ncondition for the cosmic fluid's equation of state, with key repercussions for\nthe study of dark energy since the observables can be explained in the absence\nof a cosmological constant. Furthermore, this mass-energy evolution framework\nis able to reconcile the success of CDM models in describing structure assembly\nat $z\\lesssim6$ with the unexpected discovery of massive objects at\n$z\\gtrsim10$. Models that feature a strong coupling between cosmic time and\nenergy are favored by this analysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.02045v1",
    "published": "2025-05-31T21:23:18+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00716v1",
    "title": "Fovea Stacking: Imaging with Dynamic Localized Aberration Correction",
    "authors": [
      "Shi Mao",
      "Yogeshwar Mishra",
      "Wolfgang Heidrich"
    ],
    "abstract": "The desire for cameras with smaller form factors has recently lead to a push\nfor exploring computational imaging systems with reduced optical complexity\nsuch as a smaller number of lens elements. Unfortunately such simplified\noptical systems usually suffer from severe aberrations, especially in off-axis\nregions, which can be difficult to correct purely in software.\n  In this paper we introduce Fovea Stacking, a new type of imaging system that\nutilizes emerging dynamic optical components called deformable phase plates\n(DPPs) for localized aberration correction anywhere on the image sensor. By\noptimizing DPP deformations through a differentiable optical model, off-axis\naberrations are corrected locally, producing a foveated image with enhanced\nsharpness at the fixation point - analogous to the eye's fovea. Stacking\nmultiple such foveated images, each with a different fixation point, yields a\ncomposite image free from aberrations. To efficiently cover the entire field of\nview, we propose joint optimization of DPP deformations under imaging budget\nconstraints. Due to the DPP device's non-linear behavior, we introduce a neural\nnetwork-based control model for improved alignment between simulation-hardware\nperformance.\n  We further demonstrated that for extended depth-of-field imaging, fovea\nstacking outperforms traditional focus stacking in image quality. By\nintegrating object detection or eye-tracking, the system can dynamically adjust\nthe lens to track the object of interest-enabling real-time foveated video\nsuitable for downstream applications such as surveillance or foveated virtual\nreality displays.",
    "pdf_url": "http://arxiv.org/pdf/2506.00716v1",
    "published": "2025-05-31T21:15:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00715v1",
    "title": "Classifying weak Fano toric varieties of Picard rank $3$",
    "authors": [
      "Zhengning Hu",
      "Rohan Joshi"
    ],
    "abstract": "We provide a systematic method to classify all smooth weak Fano toric\nvarieties of Picard rank $3$ in any dimension using Macaulay2, and describe the\nclassification explicitly in dimensions $3$ and $4$. There are $28$ and $114$\nisomorphism classes of rank $3$ weak Fano toric threefolds and fourfolds,\nrespectively.",
    "pdf_url": "http://arxiv.org/pdf/2506.00715v1",
    "published": "2025-05-31T21:15:17+00:00",
    "categories": [
      "math.AG",
      "14M25, 14-04"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00714v1",
    "title": "An LLM Agent for Functional Bug Detection in Network Protocols",
    "authors": [
      "Mingwei Zheng",
      "Chengpeng Wang",
      "Xuwei Liu",
      "Jinyao Guo",
      "Shiwei Feng",
      "Xiangyu Zhang"
    ],
    "abstract": "Functional correctness is critical for ensuring the reliability and security\nof network protocol implementations. Functional bugs, instances where\nimplementations diverge from behaviors specified in RFC documents, can lead to\nsevere consequences, including faulty routing, authentication bypasses, and\nservice disruptions. Detecting these bugs requires deep semantic analysis\nacross specification documents and source code, a task beyond the capabilities\nof traditional static analysis tools. This paper introduces RFCScan, an\nautonomous agent that leverages large language models (LLMs) to detect\nfunctional bugs by checking conformance between network protocol\nimplementations and their RFC specifications. Inspired by the human auditing\nprocedure, RFCScan comprises two key components: an indexing agent and a\ndetection agent. The former hierarchically summarizes protocol code semantics,\ngenerating semantic indexes that enable the detection agent to narrow down the\nscanning scope. The latter employs demand-driven retrieval to iteratively\ncollect additional relevant data structures and functions, eventually\nidentifying potential inconsistencies with the RFC specifications effectively.\nWe evaluate RFCScan across six real-world network protocol implementations.\nRFCScan identifies 47 functional bugs with 81.9% precision, of which 20 bugs\nhave been confirmed or fixed by developers.",
    "pdf_url": "http://arxiv.org/pdf/2506.00714v1",
    "published": "2025-05-31T21:13:19+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00713v3",
    "title": "AKReF: An argumentative knowledge representation framework for structured argumentation",
    "authors": [
      "Debarati Bhattacharjee",
      "Ashish Anand"
    ],
    "abstract": "This paper presents a framework to convert argumentative texts into argument\nknowledge graphs (AKG). The proposed argumentative knowledge representation\nframework (AKReF) extends the theoretical foundation and enables the AKG to\nprovide a graphical view of the argumentative structure that is easier to\nunderstand. Starting with basic annotations of argumentative components (ACs)\nand argumentative relations (ARs), we enrich the information by constructing a\nknowledge base (KB) graph with metadata attributes for nodes. Next, we apply\nmodus ponens on premises and inference rules from the KB to form arguments.\nFrom these arguments, we create an AKG. The nodes and edges of the AKG have\nattributes capturing key argumentative features such as the type of premise\n(e.g., axiom, ordinary premise, assumption), the type of inference rule (e.g.,\nstrict, defeasible), preference order over defeasible rules, markers (e.g.,\n\"therefore\", \"however\"), and the type of attack (e.g., undercut, rebuttal,\nundermining). We identify inference rules by locating a specific set of\nmarkers, called inference markers (IM). This, in turn, makes it possible to\nidentify undercut attacks previously undetectable in existing datasets. AKG\nprepares the ground for reasoning tasks, including checking the coherence of\narguments and identifying opportunities for revision. For this, it is essential\nto find indirect relations, many of which are implicit. Our proposed AKG\nformat, with annotated inference rules and modus ponens, helps reasoning models\nlearn the implicit, indirect relations that require inference over arguments\nand their interconnections. We use an essay from the AAEC dataset to illustrate\nthe framework. We further show its application in complex analyses such as\nextracting a conflict-free set and a maximal set of admissible arguments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00713v3",
    "published": "2025-05-31T21:11:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00712v2",
    "title": "The fractional Lipschitz caloric capacity of Cantor sets",
    "authors": [
      "Joan Hernández"
    ],
    "abstract": "We characterize the s-parabolic Lipschitz caloric capacity of corner-like\n$s$-parabolic Cantor sets in $\\mathbb{R}^{n+1}$ for $1/2<s\\leq 1$. Despite the\nspatial gradient of the s-heat kernel lacking temporal anti-symmetry, we obtain\nanalogous results to those known for analytic and Riesz capacities.",
    "pdf_url": "http://arxiv.org/pdf/2506.00712v2",
    "published": "2025-05-31T21:04:48+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00711v1",
    "title": "QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training",
    "authors": [
      "Wei Dai",
      "Peilin Chen",
      "Chanakya Ekbote",
      "Paul Pu Liang"
    ],
    "abstract": "Clinical decision-making routinely demands reasoning over heterogeneous data,\nyet existing multimodal language models (MLLMs) remain largely vision-centric\nand fail to generalize across clinical specialties. To bridge this gap, we\nintroduce QoQ-Med-7B/32B, the first open generalist clinical foundation model\nthat jointly reasons across medical images, time-series signals, and text\nreports. QoQ-Med is trained with Domain-aware Relative Policy Optimization\n(DRPO), a novel reinforcement-learning objective that hierarchically scales\nnormalized rewards according to domain rarity and modality difficulty,\nmitigating performance imbalance caused by skewed clinical data distributions.\nTrained on 2.61 million instruction tuning pairs spanning 9 clinical domains,\nwe show that DRPO training boosts diagnostic performance by 43% in macro-F1 on\naverage across all visual domains as compared to other critic-free training\nmethods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation\ndata, it is able to highlight salient regions related to the diagnosis, with an\nIoU 10x higher than open models while reaching the performance of OpenAI\no4-mini. To foster reproducibility and downstream research, we release (i) the\nfull model weights, (ii) the modular training pipeline, and (iii) all\nintermediate reasoning traces at https://github.com/DDVD233/QoQ_Med.",
    "pdf_url": "http://arxiv.org/pdf/2506.00711v1",
    "published": "2025-05-31T21:02:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00710v1",
    "title": "RelDiff: Relational Data Generative Modeling with Graph-Based Diffusion Models",
    "authors": [
      "Valter Hudovernik",
      "Minkai Xu",
      "Juntong Shi",
      "Lovro Šubelj",
      "Stefano Ermon",
      "Erik Štrumbelj",
      "Jure Leskovec"
    ],
    "abstract": "Real-world databases are predominantly relational, comprising multiple\ninterlinked tables that contain complex structural and statistical\ndependencies. Learning generative models on relational data has shown great\npromise in generating synthetic data and imputing missing values. However,\nexisting methods often struggle to capture this complexity, typically reducing\nrelational data to conditionally generated flat tables and imposing limiting\nstructural assumptions. To address these limitations, we introduce RelDiff, a\nnovel diffusion generative model that synthesizes complete relational databases\nby explicitly modeling their foreign key graph structure. RelDiff combines a\njoint graph-conditioned diffusion process across all tables for attribute\nsynthesis, and a $2K+$SBM graph generator based on the Stochastic Block Model\nfor structure generation. The decomposition of graph structure and relational\nattributes ensures both high fidelity and referential integrity, both of which\nare crucial aspects of synthetic relational database generation. Experiments on\n11 benchmark datasets demonstrate that RelDiff consistently outperforms prior\nmethods in producing realistic and coherent synthetic relational databases.\nCode is available at https://github.com/ValterH/RelDiff.",
    "pdf_url": "http://arxiv.org/pdf/2506.00710v1",
    "published": "2025-05-31T21:01:02+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00709v1",
    "title": "Thermodynamic Properties and Superstatistics of Graphene under a Constant Magnetic Field",
    "authors": [
      "Yarou M. Assimiou",
      "Daniel S. Takou",
      "Boukari Amidou",
      "Guingarey Issoufou",
      "Finagnon A. Dossa",
      "Gabriel Y. H. Avossevou"
    ],
    "abstract": "In this paper, we present the solutions of the Dirac-Weyl equation for\ngraphene under a constant magnetic field. The resulting spectrum is used to\ndetermine the partition function, a key quantity in the study of thermodynamic\nproperties. From this function, we analyze the mean energy, specific heat,\nentropy, and free energy in two different frameworks: the canonical ensemble\nand the superstatistical approach. The study confirms the relativistic nature\nof electron transport in graphene under a magnetic field. It also reveals that\nfluctuations introduce additional disorder in the system. The obtained results\nare in good agreement with those already reported in the literature.",
    "pdf_url": "http://arxiv.org/pdf/2506.00709v1",
    "published": "2025-05-31T21:00:24+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.12062v1",
    "title": "Green Economic Load Dispatch: A Review and Implementation",
    "authors": [
      "Shahbaz Hussain"
    ],
    "abstract": "The economic dispatch of generators is a major concern in thermal power\nplants that governs the share of each generating unit with an objective of\nminimizing fuel cost by fulfilling load demand. This problem is not as simple\nas it looks because of system constraints that cannot be neglected practically.\nMoreover, increased awareness of clean technology imposes another important\nlimit on the emission of pollutants obtained from burning of fossil fuels.\nClassical optimization methods lack the ability of solving such a complex and\nmulti-objective problem. Hence, various modern artificial intelligence (AI)\ntechniques based on evolution and social behaviour of organisms are being used\nto solve such problems because they are easier to implement, give accurate\nresults and take less computational time. In this work, a study is done on most\nof the contemporary basic AI techniques being used in literature for power\nsystems in general and combined economic emission dispatch (CEED) in\nparticular. The dispatch problem is implemented on IEEE 30-bus benchmarked\nsystem in MATLAB for different load demands considering all gases (COX, NOX and\nSOX) using particle swarm optimization (PSO) and genetic algorithm (GA) and\ntheir results are compared with each other.",
    "pdf_url": "http://arxiv.org/pdf/2506.12062v1",
    "published": "2025-05-31T20:59:59+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00708v1",
    "title": "DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains",
    "authors": [
      "Yongkang Xiao",
      "Sinian Zhang",
      "Yi Dai",
      "Huixue Zhou",
      "Jue Hou",
      "Jie Ding",
      "Rui Zhang"
    ],
    "abstract": "Knowledge graph completion (KGC) aims to predict missing triples in knowledge\ngraphs (KGs) by leveraging existing triples and textual information. Recently,\ngenerative large language models (LLMs) have been increasingly employed for\ngraph tasks. However, current approaches typically encode graph context in\ntextual form, which fails to fully exploit the potential of LLMs for perceiving\nand reasoning about graph structures. To address this limitation, we propose\nDrKGC (Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph\nCompletion). DrKGC employs a flexible lightweight model training strategy to\nlearn structural embeddings and logical rules within the KG. It then leverages\na novel bottom-up graph retrieval method to extract a subgraph for each query\nguided by the learned rules. Finally, a graph convolutional network (GCN)\nadapter uses the retrieved subgraph to enhance the structural embeddings, which\nare then integrated into the prompt for effective LLM fine-tuning. Experimental\nresults on two general domain benchmark datasets and two biomedical datasets\ndemonstrate the superior performance of DrKGC. Furthermore, a realistic case\nstudy in the biomedical domain highlights its interpretability and practical\nutility.",
    "pdf_url": "http://arxiv.org/pdf/2506.00708v1",
    "published": "2025-05-31T20:56:54+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00707v1",
    "title": "High-Efficiency, High-Fidelity Charge Initialization of Shallow Nitrogen Vacancy Centers in Diamond",
    "authors": [
      "Marjana Mahdia",
      "Artur Lozovoi",
      "Jared Rovny",
      "Zhiyang Yuan",
      "Carlos A. Meriles",
      "Nathalie P. de Leon"
    ],
    "abstract": "Nitrogen vacancy (NV) centers in diamond exhibit long spin coherence times,\noptical initialization, and optical spin readout under ambient conditions,\nmaking them excellent quantum sensors. However, the conventional scheme for\ncharge state initialization based on off-resonant green excitation results in\nsignificant state preparation errors, typically around 30%. One method for\nimproving charge state initialization fidelity is to use multicolor excitation,\nwhich has been demonstrated to achieve a near-unity preparation fidelity for\nbulk NV centers by using a few milliseconds of near-infrared (5 mW) and green\n(10 {\\mu}W) excitation. The translation of such schemes to NV centers near the\ndiamond surface with higher efficiency optical pumping would enable myriad\ntasks in nanoscale sensing. Here, we demonstrate a protocol for efficient\ncharge initialization of shallow NV centers between 5 nm and 15 nm from the\ndiamond surface. By carefully studying the charge dynamics of shallow NV\ncenters, we identify a region of parameter space that allows for near-unity\n(95%) charge initialization within 300 {\\mu}s of near-infrared (1 mW) and green\n(10 {\\mu}W) excitation. The time to 90% charge initialization can be as fast as\n10 {\\mu}s for 4 mW of near-infrared and 39 {\\mu}W of green illumination. This\nfast, efficient charge initialization protocol will enable nanoscale sensing\napplications where state preparation errors currently prohibit scaling, such as\nmeasuring higher-order multi-point correlators.",
    "pdf_url": "http://arxiv.org/pdf/2506.00707v1",
    "published": "2025-05-31T20:53:05+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2507.17761v1",
    "title": "Co-constructing Explanations for AI Systems using Provenance",
    "authors": [
      "Jan-Christoph Kalo",
      "Fina Polat",
      "Shubha Guha",
      "Paul Groth"
    ],
    "abstract": "Modern AI systems are complex workflows containing multiple components and\ndata sources. Data provenance provides the ability to interrogate and\npotentially explain the outputs of these systems. However, provenance is often\ntoo detailed and not contextualized for the user trying to understand the AI\nsystem. In this work, we present our vision for an interactive agent that works\ntogether with the user to co-construct an explanation that is simultaneously\nuseful to the user as well as grounded in data provenance. To illustrate this\nvision, we present: 1) an initial prototype of such an agent; and 2) a scalable\nevaluation framework based on user simulations and a large language model as a\njudge approach.",
    "pdf_url": "http://arxiv.org/pdf/2507.17761v1",
    "published": "2025-05-31T20:52:41+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00706v1",
    "title": "On the Use of Björck Sequences in LEO-based PNT Systems",
    "authors": [
      "Harish K. Dureppagari",
      "Chiranjib Saha",
      "R. Michael Buehrer",
      "Harpreet S. Dhillon"
    ],
    "abstract": "In this paper, we investigate the use of Bj\\\"orck sequences, a class of\nconstant amplitude zero autocorrelation (CAZAC) sequences, as a potential\ncandidate for the design of positioning reference signals (PRS) in Low Earth\nOrbit (LEO)-based positioning, navigation, and timing (PNT) systems. Unlike\nlegacy systems such as Global Navigation Satellite Systems (GNSS) or\nterrestrial networks (TNs), LEO-based systems experience large Doppler shifts\nand delay spreads, where traditional orthogonalization methods become\nineffective. Compared to commonly used sequences such as Gold and Zadoff-Chu\n(ZC), Bj\\\"orck sequences offer improved ambiguity function behavior, nearly\nideal autocorrelation, greater resilience to interference, and accurate delay\nestimation in high Doppler environments. We further propose a novel sequence\nconstruction method to extend Bj\\\"orck sequences to non-prime lengths while\nminimizing cyclic autocorrelation. Focusing on LEO-based non-terrestrial\nnetwork (NTN) localization, we evaluate positioning accuracy under various\ninterference conditions, comparing the performance of Bj\\\"orck sequences\nagainst Gold sequences, which are traditionally used for PRS generation. While\nBj\\\"orck sequences demonstrate strong performance in Doppler-rich environments,\nwe identify an inherent Doppler-dependent behavior that may lead to sequence\nmisidentification. To mitigate this, we propose two strategies: 1) leveraging\nthe availability of a coarse Doppler estimate and 2) employing sequence subset\nselection to ensure sufficient separation between sequences to account for\nmaximum Doppler uncertainty. Finally, we present scalable sequence reuse\nstrategies for large LEO constellations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00706v1",
    "published": "2025-05-31T20:52:01+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02044v2",
    "title": "A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder",
    "authors": [
      "Xinxu Wei",
      "Kanhao Zhao",
      "Yong Jiao",
      "Lifang He",
      "Yu Zhang"
    ],
    "abstract": "As large language models (LLMs) continue to revolutionize AI research, there\nis a growing interest in building large-scale brain foundation models to\nadvance neuroscience. While most existing brain foundation models are\npre-trained on time-series signals or connectome features, we propose a novel\ngraph-based pre-training paradigm for constructing a brain graph foundation\nmodel. In this paper, we introduce the Brain Graph Foundation Model, termed\nBrainGFM, a unified framework that leverages graph contrastive learning and\ngraph masked autoencoders for large-scale fMRI-based pre-training. BrainGFM is\npre-trained on a diverse mixture of brain atlases with varying parcellations,\nsignificantly expanding the pre-training corpus and enhancing the model's\nability to generalize across heterogeneous fMRI-derived brain representations.\nTo support efficient and versatile downstream transfer, we integrate both graph\nprompts and language prompts into the model design, enabling BrainGFM to\nflexibly adapt to a wide range of atlases, neurological and psychiatric\ndisorders, and task settings. Furthermore, we employ meta-learning to optimize\nthe graph prompts, facilitating strong generalization to previously unseen\ndisorders under both few-shot and zero-shot learning conditions via\nlanguage-guided prompting. BrainGFM is pre-trained on 27 neuroimaging datasets\nspanning 25 common neurological and psychiatric disorders, encompassing 2 types\nof brain atlases (functional and anatomical) across 8 widely-used\nparcellations, and covering over 25,000 subjects, 60,000 fMRI scans, and a\ntotal of 400,000 graph samples aggregated across all atlases and parcellations.\nThe code is available at: https://github.com/weixinxu666/BrainGFM",
    "pdf_url": "http://arxiv.org/pdf/2506.02044v2",
    "published": "2025-05-31T20:35:53+00:00",
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00705v1",
    "title": "Observation of effects of inter-atomic interaction on Autler-Townes splitting in cold Rydberg atoms",
    "authors": [
      "Silpa B S",
      "Shovan Kanti Barik",
      "Varna Shenoy",
      "Soham Chandak",
      "Rejish Nath",
      "Sanjukta Roy"
    ],
    "abstract": "We demonstrate the effect of inter-atomic interaction in highly excited\nRydberg atoms via Autler- Townes splitting in cold atoms. We measure the\nAutler-Townes (AT) splitting of the 5S1/2, F=2 to 5P3/2, F'=3 transition of\n87Rb atoms arising due to the strong coupling of the transition via the cooling\nbeams used for the magneto-optical trap (MOT). The AT splitting is probed using\na weakly coupled transition from 5P3/2, F'=3 state to highly excited Rydberg\nstates for a wide range of principal quantum numbers (n = 35 - 117). We observe\nthe AT splitting via trap-loss spectroscopy in the MOT by scanning the probe\nfrequency. We observe a drastic increase in the broadening of the AT splitting\nsignal as a result of interaction-induced dephasing effect in cold Rydberg\natoms for highly excited Rydberg states with principal quantum number n > 100.\nWe explain our observations using theoretical modelling and numerical\nsimulations based on the Lindblad Master equation. We find a good agreement of\nthe results of the numerical simulation with the experimental measurements.",
    "pdf_url": "http://arxiv.org/pdf/2506.00705v1",
    "published": "2025-05-31T20:34:14+00:00",
    "categories": [
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00704v2",
    "title": "Nonlinear Optimal Recovery in Hilbert Spaces",
    "authors": [
      "Daozhe Lin",
      "Qiang Du"
    ],
    "abstract": "This paper investigates solution strategies for nonlinear problems in Hilbert\nspaces, such as nonlinear partial differential equations (PDEs) in Sobolev\nspaces, when only finite measurements are available. We formulate this as a\nnonlinear optimal recovery problem, establishing its well-posedness and proving\nits convergence to the true solution as the number of measurements increases.\nHowever, the resulting formulation might not have a finite-dimensional solution\nin general. We thus present a sufficient condition for the finite\ndimensionality of the solution, applicable to problems with well-defined point\nevaluation measurements. To address the broader setting, we introduce a relaxed\nnonlinear optimal recovery and provide a detailed convergence analysis. An\nillustrative example is given to demonstrate that our formulations and\ntheoretical findings offer a comprehensive framework for solving nonlinear\nproblems in infinite-dimensional spaces with limited data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00704v2",
    "published": "2025-05-31T20:19:07+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00703v1",
    "title": "Adaptive Traffic-Following Scheme for Orderly Distributed Control of Multi-Vehicle Systems",
    "authors": [
      "Anahita Jain",
      "Husni Idris",
      "John-Paul Clarke",
      "Daniel Delahaye"
    ],
    "abstract": "We present an adaptive control scheme to enable the emergence of order within\ndistributed, autonomous multi-agent systems. Past studies showed that under\nhigh-density conditions, order generated from traffic-following behavior\nreduces travel times, while under low densities, choosing direct paths is more\nbeneficial. In this paper, we leveraged those findings to allow aircraft to\nindependently and dynamically adjust their degree of traffic-following behavior\nbased on the current state of the airspace. This enables aircraft to follow\nother traffic only when beneficial. Quantitative analyses revealed that dynamic\ntraffic-following behavior results in lower aircraft travel times at the cost\nof minimal levels of additional disorder to the airspace. The sensitivity of\nthese benefits to temporal and spatial horizons was also investigated. Overall,\nthis work highlights the benefits, and potential necessity, of incorporating\nself-organizing behavior in making distributed, autonomous multi-agent systems\nscalable.",
    "pdf_url": "http://arxiv.org/pdf/2506.00703v1",
    "published": "2025-05-31T20:18:35+00:00",
    "categories": [
      "cs.MA",
      "cs.ET",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00702v1",
    "title": "Stabilization of the Gradient Method for Solving Linear Algebraic Systems -- A Method Related to the Normal Equation",
    "authors": [
      "Ibrahima Dione"
    ],
    "abstract": "Although it is relatively easy to apply, the gradient method often displays a\ndisappointingly slow rate of convergence. Its convergence is specially based on\nthe structure of the matrix of the algebraic linear system, and on the choice\nof the stepsize defining the new iteration. We propose here a simple and robust\nstabilization of the gradient method, which no longer assumes a structure on\nthe matrix (neither symmetric, nor positive definite) to converge, and which no\nlonger requires an approach on the choice of the stepsize. We establish the\nglobal convergence of the proposed stabilized algorithm under the only\nassumption of nonsingular matrix. Several numerical examples illustrating its\nperformances are presented, where we have tested small and large scale linear\nsystems, with and not structured matrices, and with well and ill conditioned\nmatrices.",
    "pdf_url": "http://arxiv.org/pdf/2506.00702v1",
    "published": "2025-05-31T20:17:00+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.04248v1",
    "title": "A New $q$-Heisenberg Algebra",
    "authors": [
      "Julio Cesar Jaramillo Quiceno"
    ],
    "abstract": "This work introduces a novel $q$-$\\hbar$ deformation of the Heisenberg\nalgebra, designed to unify and extend several existing $q$-deformed\nformulations. Starting from the canonical Heisenberg algebra defined by the\ncommutation relation $[\\hat{x}, \\hat{p}] = i\\hbar$ on a Hilbert space\n\\cite{Zettili2009}, we survey a variety of $q$-deformed structures previously\nproposed by Wess \\cite{Wess2000}, Schm\\\"udgen \\cite{Schmudgen1999},\nWess--Schwenk \\cite{Wess-Schwenk1992}, Gaddis \\cite{Jasson-Gaddis2016}, and\nothers. These frameworks involve position, momentum, and auxiliary operators\nthat satisfy nontrivial commutation rules and algebraic relations incorporating\ndeformation parameters. Our new $q$-$\\hbar$ Heisenberg algebra $\\mathcal{H}_q$\nis generated by elements $\\hat{x}_\\alpha$, $\\hat{y}_\\lambda$, and\n$\\hat{p}_\\beta$ with $\\alpha, \\lambda, \\beta \\in \\{1,2,3\\}$, and is defined\nthrough generalized commutation relations parameterized by real constants $n,\nm, l$ and three dynamical functions $\\Psi(q)$, $\\Phi(q)$, and $\\Pi(q)$\ndepending on the deformation parameter $q$ and the generators. By selecting\nappropriate values for these parameters and functions, our framework recovers\nseveral well-known algebras as special cases, including the classical\nHeisenberg algebra for $q = 1$ and $\\Psi = 1$, $\\Phi = \\Pi = 0$, and various\n$q$-deformed algebras for $q \\neq 1$. The algebraic consistency of these\ngeneralizations is demonstrated through a series of explicit examples, and the\nresulting structures are shown to align with quantum planes\n\\cite{Yuri-Manin2010} and enveloping algebras associated with Lie algebra\nhomomorphisms \\cite{Reyes2014a}. This construction offers a flexible and\nunified formalism for studying quantum deformations, with potential\napplications in quantum mechanics, noncommutative geometry, and quantum group\ntheory.",
    "pdf_url": "http://arxiv.org/pdf/2506.04248v1",
    "published": "2025-05-31T20:16:42+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00701v1",
    "title": "Bayesian Inference of Training Dataset Membership",
    "authors": [
      "Yongchao Huang"
    ],
    "abstract": "Determining whether a dataset was part of a machine learning model's training\ndata pool can reveal privacy vulnerabilities, a challenge often addressed\nthrough membership inference attacks (MIAs). Traditional MIAs typically require\naccess to model internals or rely on computationally intensive shadow models.\nThis paper proposes an efficient, interpretable and principled Bayesian\ninference method for membership inference. By analyzing post-hoc metrics such\nas prediction error, confidence (entropy), perturbation magnitude, and dataset\nstatistics from a trained ML model, our approach computes posterior\nprobabilities of membership without requiring extensive model training.\nExperimental results on synthetic datasets demonstrate the method's\neffectiveness in distinguishing member from non-member datasets. Beyond\nmembership inference, this method can also detect distribution shifts, offering\na practical and interpretable alternative to existing approaches.",
    "pdf_url": "http://arxiv.org/pdf/2506.00701v1",
    "published": "2025-05-31T20:14:38+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00700v2",
    "title": "Central Path Proximal Policy Optimization",
    "authors": [
      "Nikola Milosevic",
      "Johannes Müller",
      "Nico Scherf"
    ],
    "abstract": "In constrained Markov decision processes, enforcing constraints during\ntraining is often thought of as decreasing the final return. Recently, it was\nshown that constraints can be incorporated directly into the policy geometry,\nyielding an optimization trajectory close to the central path of a barrier\nmethod, which does not compromise final return. Building on this idea, we\nintroduce Central Path Proximal Policy Optimization (C3PO), a simple\nmodification of the PPO loss that produces policy iterates, that stay close to\nthe central path of the constrained optimization problem. Compared to existing\non-policy methods, C3PO delivers improved performance with tighter constraint\nenforcement, suggesting that central path-guided updates offer a promising\ndirection for constrained policy optimization.",
    "pdf_url": "http://arxiv.org/pdf/2506.00700v2",
    "published": "2025-05-31T20:14:29+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00699v3",
    "title": "What is a double star-product?",
    "authors": [
      "Nikita Safonkin"
    ],
    "abstract": "Double Poisson brackets, introduced by M. Van den Bergh in 2004, are\nnoncommutative analogs of the usual Poisson brackets in the sense of the\nKontsevich-Rosenberg principle: they induce Poisson structures on the space of\n$N$-dimensional representations $\\operatorname{Rep}_N(A)$ of an associative\nalgebra $A$ for any $N$. The problem of deformation quantization of double\nPoisson brackets was raised by D. Calaque in 2010, and had remained open since\nthen.\n  In this paper, we address this problem by answering the question in the\ntitle. We present a structure on $A$ that induces a star-product under the\nrepresentation functor and, therefore, according to the Kontsevich-Rosenberg\nprinciple, can be viewed as an analog of star-products in noncommutative\ngeometry. We also provide an explicit example for $A=\\Bbbk\\langle\nx_1,\\ldots,x_d\\rangle$ and prove a double formality theorem in this case. Along\nthe way, we invert the Kontsevich-Rosenberg principle by introducing a notion\nof double algebra over an arbitrary operad.",
    "pdf_url": "http://arxiv.org/pdf/2506.00699v3",
    "published": "2025-05-31T20:13:24+00:00",
    "categories": [
      "math.QA",
      "math-ph",
      "math.MP",
      "math.RA",
      "math.RT"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00698v1",
    "title": "Concept-Centric Token Interpretation for Vector-Quantized Generative Models",
    "authors": [
      "Tianze Yang",
      "Yucheng Shi",
      "Mengnan Du",
      "Xuansheng Wu",
      "Qiaoyu Tan",
      "Jin Sun",
      "Ninghao Liu"
    ],
    "abstract": "Vector-Quantized Generative Models (VQGMs) have emerged as powerful tools for\nimage generation. However, the key component of VQGMs -- the codebook of\ndiscrete tokens -- is still not well understood, e.g., which tokens are\ncritical to generate an image of a certain concept? This paper introduces\nConcept-Oriented Token Explanation (CORTEX), a novel approach for interpreting\nVQGMs by identifying concept-specific token combinations. Our framework employs\ntwo methods: (1) a sample-level explanation method that analyzes token\nimportance scores in individual images, and (2) a codebook-level explanation\nmethod that explores the entire codebook to find globally relevant tokens.\nExperimental results demonstrate CORTEX's efficacy in providing clear\nexplanations of token usage in the generative process, outperforming baselines\nacross multiple pretrained VQGMs. Besides enhancing VQGMs transparency, CORTEX\nis useful in applications such as targeted image editing and shortcut feature\ndetection. Our code is available at https://github.com/YangTianze009/CORTEX.",
    "pdf_url": "http://arxiv.org/pdf/2506.00698v1",
    "published": "2025-05-31T20:11:32+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00697v1",
    "title": "Overdetermined elliptic problems on model Riemannian manifolds",
    "authors": [
      "João Marcos do Ó",
      "Jaqueline de Lima",
      "Márcio Santos"
    ],
    "abstract": "We establish a rigidity theorem for annular sector-like domains in the\nsetting of overdetermined elliptic problems on model Riemannian manifolds.\nSpecifically, if such a domain admits a solution to the inhomogeneous Helmholtz\nequation satisfying both constant Dirichlet and constant Neumann boundary\nconditions, then the domain must be a spherical sector, and the solution must\nbe radially symmetric. This result underscores the strong geometric constraints\nimposed by overdetermined boundary conditions, extending classical rigidity\nphenomena to this more general framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.00697v1",
    "published": "2025-05-31T20:08:02+00:00",
    "categories": [
      "math.AP",
      "math.DG"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00696v2",
    "title": "Integrative, Scalable Modeling of Hydrological Systems with MBSE and HFGT",
    "authors": [
      "Megan Harris",
      "Ehsanoddin Ghorbanichemazkati",
      "Mohammad Mahdi Naderi",
      "John C. Little",
      "Amro M. Farid"
    ],
    "abstract": "Worsening global challenges in the Anthropocene demand complex, adaptive\nsolutions grounded in a systems-level understanding of coupled social and\nenvironmental dynamics. However, existing modeling approaches often fall short\ndue to disciplinary silos, limited scalability, and the absence of shared\nontological frameworks. Model-Based Systems Engineering (MBSE), when integrated\nwith Hetero-functional Graph Theory (HFGT), offers a powerful methodology for\nmodeling systems of systems while preserving subsystem heterogeneity and\nenabling cross-disciplinary integration. This paper presents the first\napplication of the MBSE-HFGT methodology to environmental systems, using a\nseries of worked examples involving flow through lake and land segments. These\nexamples demonstrate how the approach enables consistent, scalable, and\nintegrative modeling of complex environmental processes.",
    "pdf_url": "http://arxiv.org/pdf/2506.00696v2",
    "published": "2025-05-31T20:05:32+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00695v2",
    "title": "Multi-Controlled Quantum Gates in Linear Nearest Neighbor",
    "authors": [
      "Ben Zindorf",
      "Sougato Bose"
    ],
    "abstract": "Multi-controlled single-target (MC) gates are some of the most crucial\nbuilding blocks for varied quantum algorithms. How to implement them optimally\nis thus a pivotal question. To answer this question in an\narchitecture-independent manner, and to get a worst-case estimate, we should\nlook at a linear nearest-neighbor (LNN) architecture, as this can be embedded\nin almost any qubit connectivity. Motivated by the above, here we describe a\nmethod which implements MC gates using no more than $\\sim 4k+8n$ CNOT gates --\nup-to $60\\%$ reduction over state-of-the-art -- while allowing for complete\nflexibility to choose the locations of $n$ controls, the target, and a dirty\nancilla out of $k$ qubits. More strikingly, in case $k \\approx n$, our upper\nbound is $\\sim 12n$ -- the best known for unrestricted connectivity -- and if\n$n = 1$, our upper bound is $\\sim 4k$ -- the best known for a single long-range\nCNOT gate over $k$ qubits -- therefore, if our upper bound can be reduced, then\nthe cost of one or both of these simpler versions of MC gates will be\nimmediately reduced accordingly. In practice, our method provides circuits that\ntend to require fewer CNOT gates than our upper bound for almost any given\ninstance of MC gates.",
    "pdf_url": "http://arxiv.org/pdf/2506.00695v2",
    "published": "2025-05-31T20:01:21+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00694v2",
    "title": "Measuring Faithfulness and Abstention: An Automated Pipeline for Evaluating LLM-Generated 3-ply Case-Based Legal Arguments",
    "authors": [
      "Li Zhang",
      "Morgan Gray",
      "Jaromir Savelka",
      "Kevin D. Ashley"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate potential in complex legal tasks\nlike argument generation, yet their reliability remains a concern. Building\nupon pilot work assessing LLM generation of 3-ply legal arguments using human\nevaluation, this paper introduces an automated pipeline to evaluate LLM\nperformance on this task, specifically focusing on faithfulness (absence of\nhallucination), factor utilization, and appropriate abstention. We define\nhallucination as the generation of factors not present in the input case\nmaterials and abstention as the model's ability to refrain from generating\narguments when instructed and no factual basis exists. Our automated method\nemploys an external LLM to extract factors from generated arguments and\ncompares them against the ground-truth factors provided in the input case\ntriples (current case and two precedent cases). We evaluated eight distinct\nLLMs on three tests of increasing difficulty: 1) generating a standard 3-ply\nargument, 2) generating an argument with swapped precedent roles, and 3)\nrecognizing the impossibility of argument generation due to lack of shared\nfactors and abstaining. Our findings indicate that while current LLMs achieve\nhigh accuracy (over 90%) in avoiding hallucination on viable argument\ngeneration tests (Tests 1 & 2), they often fail to utilize the full set of\nrelevant factors present in the cases. Critically, on the abstention test (Test\n3), most models failed to follow instructions to stop, instead generating\nspurious arguments despite the lack of common factors. This automated pipeline\nprovides a scalable method for assessing these crucial LLM behaviors,\nhighlighting the need for improvements in factor utilization and robust\nabstention capabilities before reliable deployment in legal settings. Link:\nhttps://lizhang-aiandlaw.github.io/An-Automated-Pipeline-for-Evaluating-LLM-Generated-3-ply-Case-Based-Legal-Arguments/",
    "pdf_url": "http://arxiv.org/pdf/2506.00694v2",
    "published": "2025-05-31T19:56:40+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00693v1",
    "title": "Human Attention During Localization of Memory Bugs in C Programs",
    "authors": [
      "Emory Smith",
      "Robert Wallace",
      "Matthew Robison",
      "Yu Huang",
      "Collin McMillan"
    ],
    "abstract": "This paper presents a study of human visual attention during localization of\nmemory bugs in C. Human visual attention refers to the mechanical processes by\nwhich we selectively process and prioritize information. Visual attention is\nimportant to study because it is central to what information people (who are\nsighted) use to solve a particular problem. Meanwhile, memory bugs are among\nthe most common types of bugs in C programs that manifest as a variety of\nprogram faults. In this paper, we study human visual attention while people\nattempt to locate memory bugs in code. We recruit 11 programmers to locate\nbetween one and six memory bugs in three C programs for 1.5-2 hours each. In\ntotal we collected observations of 17 hours of programmer effort. The bugs in\nour study cover memory leaks, overflows, and double frees, which are among the\nmost common memory bugs. We analyze the task outcomes in terms of success rate\nand related factors, patterns of visual attention overall such as what lines\nand functions are read, and finally we explore differences of visual attention\npatterns during success versus failure cases.",
    "pdf_url": "http://arxiv.org/pdf/2506.00693v1",
    "published": "2025-05-31T19:56:16+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00692v1",
    "title": "Not Just $N_e$ $N_e$-more: New Applications for SMC from Ecology to Phylogenies",
    "authors": [
      "David Peede",
      "Trevor Cousins",
      "Arun Durvasula",
      "Anastasia Ignatieva",
      "Toby G. L. Kovacs",
      "Alba Nieto",
      "Emily E. Puckett",
      "Elizabeth T. Chevy"
    ],
    "abstract": "Genomes contain the mutational footprint of an organism's evolutionary\nhistory, shaped by diverse forces including ecological factors, selective\npressures, and life history traits. The sequentially Markovian coalescent (SMC)\nis a versatile and tractable model for the genetic genealogy of a sample of\ngenomes, which captures this shared history. Methods that utilize the SMC, such\nas PSMC and MSMC, have been widely used in evolution and ecology to infer\ndemographic histories. However, these methods ignore common biological\nfeatures, such as gene flow events and structural variation. Recently, there\nhave been several advancements that widen the applicability of SMC-based\nmethods: inclusion of an isolation with migration model, integration with the\nmulti-species coalescent, incorporation of ecological variables (such as\nselfing and dormancy), inference of dispersal rates, and many computational\nadvances in applying these models to data. We give an overview of the SMC model\nand its various recent extensions, discuss examples of biological discoveries\nthrough SMC-based inference, and comment on the assumptions, benefits and\ndrawbacks of various methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00692v1",
    "published": "2025-05-31T19:53:54+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00691v4",
    "title": "Optimizing Sensory Neurons: Nonlinear Attention Mechanisms for Accelerated Convergence in Permutation-Invariant Neural Networks for Reinforcement Learning",
    "authors": [
      "Junaid Muzaffar",
      "Khubaib Ahmed",
      "Ingo Frommholz",
      "Zeeshan Pervez",
      "Ahsan ul Haq"
    ],
    "abstract": "Training reinforcement learning (RL) agents often requires significant\ncomputational resources and prolonged training durations. To address this\nchallenge, we build upon prior work that introduced a neural architecture with\npermutation-invariant sensory processing. We propose a modified attention\nmechanism that applies a non-linear transformation to the key vectors (K),\nproducing enriched representations (K') through a custom mapping function. This\nNonlinear Attention (NLA) mechanism enhances the representational capacity of\nthe attention layer, enabling the agent to learn more expressive feature\ninteractions. As a result, our model achieves significantly faster convergence\nand improved training efficiency, while maintaining performance on par with the\nbaseline. These results highlight the potential of nonlinear attention\nmechanisms to accelerate reinforcement learning without sacrificing\neffectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2506.00691v4",
    "published": "2025-05-31T19:50:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00690v1",
    "title": "Effect of crystallinity on the frictional and wear performance of molybdenum disulfide: A molecular dynamics study",
    "authors": [
      "Abhiram B R",
      "Ilia Ponomarev",
      "Tomas Polcar"
    ],
    "abstract": "The frictional and wear performance of molybdenum disulfide (MoS2) is\nsignificantly influenced by its intrinsic arrangement of crystals or\ncrystallinity. In this study, we investigate the effect of crystallinty on\ncoefficient of friction (COF) and wear in MoS2 using a suite of reactive\nmolecular dynamics (MD) simulations. A range of configurations, from amorphous\nto crystalline, is modeled to capture the effect of structural order on the\ntribological behavior. To study friction and wear, we simulate the sliding of a\nspherical rigid carbon body over the MoS2 surface under varying crystallinity\nconditions. Our results reveal a pronounced reduction in COF with decreasing\ncrystallinity, with crystalline MoS2 exhibiting superlubricity. This behavior\nis attributed to the preservation of a flat sliding surface and frictional\nanisotropy, which enables lateral movement along low-resistance paths. In\ncontrast, amorphous and polycrystalline MoS2 with lower degrees of\ncrystallinity displays a substantially higher COF, driven by increased surface\nroughness and atomic-scale energy dissipation. Furthermore, we examine the wear\nmechanisms under high normal loads, demonstrating that crystallinity enhances\nwear resistance by mitigating material deformation. These findings provide\natomic-scale insights into the tribological performance of MoS2, emphasizing\nthe critical role of structural order in achieving ultralow friction. Our work\ncorroborates with previous studies on superlubricity in MoS2 and extends this\nunderstanding to rigid-body sliding conditions, offering valuable implications\nfor designing low-friction and wear resistant solid lubricants.",
    "pdf_url": "http://arxiv.org/pdf/2506.00690v1",
    "published": "2025-05-31T19:49:01+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00689v2",
    "title": "Mutual-visibility of the disjointness graph of segments in ${\\mathbb R}^2$",
    "authors": [
      "J. Leaños",
      "M. Lomelí-Haro",
      "Christophe Ndjatchi",
      "L. M. Ríos-Castro"
    ],
    "abstract": "Let $G=(V(G),E(G))$ be a simple graph, and let $U\\subseteq V(G)$. Two\ndistinct vertices $x,y\\in U$ are $U$-mutually visible if $G$ contains a\nshortest $x$-$y$ path that is internally disjoint from $U$. $U$ is called a\nmutual-visibility set of $G$ if any two vertices of $U$ are $U$-mutually\nvisible. The mutual-visibility number $\\mu(G)$ of $G$ is the size of a largest\nmutual-visibility set of $G$. Let $P$ be a set of $n\\geq 3$ points in ${\\mathbb\nR}^2$ in general position. The disjointness graph of segments $D(P)$ of $P$ is\nthe graph whose vertices are all the closed straight line segments with\nendpoints in $P$, two of which are adjacent in $D(P)$ if and only if they are\ndisjoint. In this paper we establish tight lower and upper bounds for\n$\\mu(D(P))$, and show that almost all edge disjointness graphs have diameter 2.",
    "pdf_url": "http://arxiv.org/pdf/2506.00689v2",
    "published": "2025-05-31T19:46:38+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00688v1",
    "title": "Existing Large Language Model Unlearning Evaluations Are Inconclusive",
    "authors": [
      "Zhili Feng",
      "Yixuan Even Xu",
      "Alexander Robey",
      "Robert Kirk",
      "Xander Davies",
      "Yarin Gal",
      "Avi Schwarzschild",
      "J. Zico Kolter"
    ],
    "abstract": "Machine unlearning aims to remove sensitive or undesired data from large\nlanguage models. However, recent studies suggest that unlearning is often\nshallow, claiming that removed knowledge can easily be recovered. In this work,\nwe critically examine standard unlearning evaluation practices and uncover key\nlimitations that shake our trust in those findings. First, we show that some\nevaluations introduce substantial new information into the model, potentially\nmasking true unlearning performance by re-teaching the model during testing.\nSecond, we demonstrate that evaluation outcomes vary significantly across\ntasks, undermining the generalizability of current evaluation routines.\nFinally, we find that many evaluations rely on spurious correlations, making\ntheir results difficult to trust and interpret. Taken together, these issues\nsuggest that current evaluation protocols may both overstate and understate\nunlearning success. To address this, we propose two principles for future\nunlearning evaluations: minimal information injection and downstream task\nawareness. We validate these principles through a series of targeted\nexperiments, showing how violations of each can lead to misleading conclusions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00688v1",
    "published": "2025-05-31T19:43:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00687v1",
    "title": "Observation of pseudogap in Cr_{1-x}Y_xN magnetic alloy and its impact on the Seebeck coefficient by ab-initio calculations",
    "authors": [
      "Luis Felipe Leon-Pinzon",
      "Elisabeth Restrepo-Parra",
      "Andres Manuel Garay-Tapia"
    ],
    "abstract": "Thermoelectric materials require high electronic conductivity and low thermal\nconductivity. CrN has been shown to have low phononic thermal conductivity,\nmaking it a potential candidate for thermoelectric applications. In addition,\nsimilarities have been observed between YN and ScN suggesting that the CrYN\nalloy may have interesting thermoelectric properties. As CrYN has not been\nstudied in detail at the level of thermoelectric properties, the first study on\nCrYN alloy of Seebeck coefficient and zT figure of merit is proposed in this\nstudy. For this purpose, cubic special quasirandom structures were constructed\nat values of x = 0.25, 0.5 and 0.75 in the alloy Cr_{1-x}Y_xN starting from\ndifferent magnetic structures. After analyzing lattice parameters, Cr magnetic\nmoments, octahedron deformation, second neighbors distribution around metals,\ndensity of states and band structures, it was concluded that to obtain high\nvalues of Seebeck coefficient and zT, it is necessary the presence of a pseudo\ngap in both spin channels and it is also necessary that the Fermi level is on a\nsteep decreasing slope of number of states, since due to Motts approximation,\nthe value of this slope is proportional to the Seebeck coefficient. Density of\nstates of all the structures shows a metallic behavior. In structures with\nx=0.5, the presence of small indirect energy gaps is observed. Although no\nstructure retains the initial magnetic configuration, there is a possible\ninfluence of this on the electronic structure. Considerable deformations in\noctahedra can suppress thermoelectric properties.",
    "pdf_url": "http://arxiv.org/pdf/2506.00687v1",
    "published": "2025-05-31T19:39:07+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00686v1",
    "title": "Ballistic particle transport and Drude weight in mono-atomic gases",
    "authors": [
      "Frank Göhmann",
      "Andreas Klümper",
      "Karol K. Kozlowski"
    ],
    "abstract": "Owing to the fact that, in the particular case of non-relativistic\nmono-atomic gases, the particle current operator is proportional to the\noperator of the total momentum, the particle transport in such systems is\nalways ballistic and fully characterized by a Drude weight $\\Delta$. The Drude\nweight can be calculated as a generalized susceptibility from a generalized\nGibbs ensemble. For the case of the integrable one dimensional Bose gas with\ncontact interactions this susceptibility can be obtained exactly and explicitly\nfrom a generalized Yang-Yang thermodynamic formalism. The result is temperature\nindependent and given by $\\Delta = 2 \\pi D = 2 k_F$, where $D$ is the density\nof the gas and $k_F$ its Fermi momentum. Our expression, derived by first\nprinciple calculations, confirms a more involved formula obtained heuristically\nby means of generalized hydrodynamics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00686v1",
    "published": "2025-05-31T19:38:10+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2506.06338v2",
    "title": "Closed Form of a Generalized Sinkhorn Limit",
    "authors": [
      "Max Chicky Fang"
    ],
    "abstract": "The Kruithof iterative scaling process, which adjusts matrices to meet target\nrow and column sums, is a longstanding problem that lacks a general closed form\nfor its limit. While Nathanson derived the closed form for the Sinkhorn limit\nof $2\\times 2$ matrices when target row and column sums are 1, and recent work\nby Rowland and Wu has advanced understanding of Sinkhorn limits for $3\\times\n3$, and general $n\\times m$ matrices through polynomials, a \"generalized\nSinkhorn limit\" (i.e. the original \"Kruithof limit\", with arbitrary target\nsums) remains elusive. Here, we derive the closed form for the generalized\nSinkhorn limit of $2\\times 2$ matrices, and discuss how this approach can be\nextended to larger matrices. More significantly, we prove that for any positive\n$n \\times m$ matrix and positive target row and column sums, each entry in the\ngeneralized Sinkhorn limit is algebraic over the input data with degree at most\n$\\binom{n+m-2}{n-1}$.",
    "pdf_url": "http://arxiv.org/pdf/2506.06338v2",
    "published": "2025-05-31T19:37:22+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00685v1",
    "title": "High-order interactions in quantum optomechanics: fluctuations, dynamics and thermodynamics",
    "authors": [
      "Alessandro Ferreri",
      "Vincenzo Macrì",
      "Yoshihiko Hasegawa",
      "David Edward Bruschi"
    ],
    "abstract": "Quantum optomechanics describes the interaction between a confined field and\na fluctuating wall due to radiation pressure. The dynamics of this system is\ntypically understood using perturbation theory up to second order in the small\ncoupling. Improving beyond this regime can shed light onto new phenomena. In\nthis work we study high-order resonant wall-field interactions characterized by\ntwo- and three-phonon scattering processes. We obtain the Hamiltonian, compute\nthe perturbed energy spectrum and explicitly calculate corrections to the\nground state. Finally, we study the dynamics of the system when second- and\nthird-order resonance conditions are activated, showing that the presence of\nhigh-order terms in the Hamiltonian drastically affects the populations of all\nparticles, as well as the entropy production rate.",
    "pdf_url": "http://arxiv.org/pdf/2506.00685v1",
    "published": "2025-05-31T19:37:05+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00684v1",
    "title": "Forecast Constraints on Bouncing Cosmology from High Frequency Gravitational Waves Using Superconducting LC Circuits and Resonant Cavities",
    "authors": [
      "Changhong Li"
    ],
    "abstract": "We exploit forecast sensitivities to high frequency gravitational waves\n(HFGWs) from superconducting LC circuits, traditional resonant cavity and\nsuperconducting radio frequency (SRF) cavities with electromagnetic and\nmechanical modes to derive the first projections of the bounce energy scale\nwithin the generic bouncing cosmology framework over the frequency window\n$1\\,$kHz $\\lesssim f\\lesssim10\\,$GHz. In comparison with existing astrophysical\nlimits (spanning $10^{-17}\\,$Hz $\\lesssim f\\lesssim1\\,$kHz and based on\nPlanck/BICEP, PTA, and aLIGO/LISA) our HFGW forecasts yield substantially\ntighter constraints across a broad region of parameter space. This work unifies\nconstraints from cosmological observations and quantum measurement experiments,\nproviding comprehensive coverage of the early Universe gravitational wave\nspectrum from $10^{-17}\\,\\mathrm{Hz}$ to $10\\,\\mathrm{GHz}$ and thereby probing\nthe cosmic initial non singularity at ultra high energy scales.",
    "pdf_url": "http://arxiv.org/pdf/2506.00684v1",
    "published": "2025-05-31T19:34:44+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00683v2",
    "title": "Statistical Signal Processing for Quantum Error Mitigation",
    "authors": [
      "Kausthubh Chandramouli",
      "Kelly Mae Allen",
      "Christopher Mori",
      "Dror Baron",
      "Mário A. T. Figueiredo"
    ],
    "abstract": "In the noisy intermediate-scale quantum (NISQ) era, quantum error mitigation\n(QEM) is essential for producing reliable outputs from quantum circuits. We\npresent a statistical signal processing approach to QEM that estimates the most\nlikely noiseless outputs from noisy quantum measurements. Our model assumes\nthat circuit depth is sufficient for depolarizing noise, producing corrupted\nobservations that resemble a uniform distribution alongside classical bit-flip\nerrors from readout. Our method consists of two steps: a filtering stage that\ndiscards uninformative depolarizing noise and an expectation-maximization (EM)\nalgorithm that computes a maximum likelihood (ML) estimate over the remaining\ndata. We demonstrate the effectiveness of this approach on small-qubit systems\nusing IBM circuit simulations in Qiskit and compare its performance to\ncontemporary statistical QEM techniques. We also show that our method scales to\nlarger qubit counts using synthetically generated data consistent with our\nnoise model. These results suggest that principled statistical methods can\noffer scalable and interpretable solutions for quantum error mitigation in\nrealistic NISQ settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.00683v2",
    "published": "2025-05-31T19:34:19+00:00",
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.06337v1",
    "title": "Optimized Local Updates in Federated Learning via Reinforcement Learning",
    "authors": [
      "Ali Murad",
      "Bo Hui",
      "Wei-Shinn Ku"
    ],
    "abstract": "Federated Learning (FL) is a distributed framework for collaborative model\ntraining over large-scale distributed data, enabling higher performance while\nmaintaining client data privacy. However, the nature of model aggregation at\nthe centralized server can result in a performance drop in the presence of\nnon-IID data across different clients. We remark that training a client locally\non more data than necessary does not benefit the overall performance of all\nclients. In this paper, we devise a novel framework that leverages a Deep\nReinforcement Learning (DRL) agent to select an optimized amount of data\nnecessary to train a client model without oversharing information with the\nserver. Starting without awareness of the client's performance, the DRL agent\nutilizes the change in training loss as a reward signal and learns to optimize\nthe amount of training data necessary for improving the client's performance.\nSpecifically, after each aggregation round, the DRL algorithm considers the\nlocal performance as the current state and outputs the optimized weights for\neach class, in the training data, to be used during the next round of local\ntraining. In doing so, the agent learns a policy that creates an optimized\npartition of the local training dataset during the FL rounds. After FL, the\nclient utilizes the entire local training dataset to further enhance its\nperformance on its own data distribution, mitigating the non-IID effects of\naggregation. Through extensive experiments, we demonstrate that training FL\nclients through our algorithm results in superior performance on multiple\nbenchmark datasets and FL frameworks. Our code is available at\nhttps://github.com/amuraddd/optimized_client_training.git.",
    "pdf_url": "http://arxiv.org/pdf/2506.06337v1",
    "published": "2025-05-31T19:32:42+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00682v1",
    "title": "Encouraging Students' Responsible Use of GenAI in Software Engineering Education: A Causal Model and Two Institutional Applications",
    "authors": [
      "Vahid Garousi",
      "Zafar Jafarov",
      "Aytan Movsumova",
      "Atif Namazov",
      "Huseyn Mirzayev"
    ],
    "abstract": "Context: As generative AI (GenAI) tools such as ChatGPT and GitHub Copilot\nbecome pervasive in education, concerns are rising about students using them to\ncomplete rather than learn from coursework-risking overreliance, reduced\ncritical thinking, and long-term skill deficits.\n  Objective: This paper proposes and empirically applies a causal model to help\neducators scaffold responsible GenAI use in Software Engineering (SE)\neducation. The model identifies how professor actions, student factors, and\nGenAI tool characteristics influence students' usage of GenAI tools.\n  Method: Using a design-based research approach, we applied the model in two\ncontexts: (1) revising four extensive lab assignments of a final-year Software\nTesting course at Queen's University Belfast (QUB), and (2) embedding\nGenAI-related competencies into the curriculum of a newly developed SE BSc\nprogram at Azerbaijan Technical University (AzTU). Interventions included GenAI\nusage declarations, output validation tasks, peer-review of AI artifacts, and\ncareer-relevant messaging.\n  Results: In the course-level case, instructor observations and student\nartifacts indicated increased critical engagement with GenAI, reduced passive\nreliance, and improved awareness of validation practices. In the\ncurriculum-level case, the model guided integration of GenAI learning outcomes\nacross multiple modules and levels, enabling longitudinal scaffolding of AI\nliteracy.\n  Conclusion: The causal model served as both a design scaffold and a\nreflection tool. It helped align GenAI-related pedagogy with SE education goals\nand can offer a useful framework for instructors and curriculum designers\nnavigating the challenges of GenAI-era education.",
    "pdf_url": "http://arxiv.org/pdf/2506.00682v1",
    "published": "2025-05-31T19:27:40+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00681v2",
    "title": "Learning to Upsample and Upmix Audio in the Latent Domain",
    "authors": [
      "Dimitrios Bralios",
      "Paris Smaragdis",
      "Jonah Casebeer"
    ],
    "abstract": "Neural audio autoencoders create compact latent representations that preserve\nperceptually important information, serving as the foundation for both modern\naudio compression systems and generation approaches like next-token prediction\nand latent diffusion. Despite their prevalence, most audio processing\noperations, such as spatial and spectral up-sampling, still inefficiently\noperate on raw waveforms or spectral representations rather than directly on\nthese compressed representations. We propose a framework that performs audio\nprocessing operations entirely within an autoencoder's latent space,\neliminating the need to decode to raw audio formats. Our approach dramatically\nsimplifies training by operating solely in the latent domain, with a latent L1\nreconstruction term, augmented by a single latent adversarial discriminator.\nThis contrasts sharply with raw-audio methods that typically require complex\ncombinations of multi-scale losses and discriminators. Through experiments in\nbandwidth extension and mono-to-stereo up-mixing, we demonstrate computational\nefficiency gains of up to 100x while maintaining quality comparable to\npost-processing on raw audio. This work establishes a more efficient paradigm\nfor audio processing pipelines that already incorporate autoencoders, enabling\nsignificantly faster and more resource-efficient workflows across various audio\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00681v2",
    "published": "2025-05-31T19:27:22+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.14795v1",
    "title": "Comparative Analysis of QNN Architectures for Wind Power Prediction: Feature Maps and Ansatz Configurations",
    "authors": [
      "Batuhan Hangun",
      "Emine Akpinar",
      "Oguz Altun",
      "Onder Eyecioglu"
    ],
    "abstract": "Quantum Machine Learning (QML) is an emerging field at the intersection of\nquantum computing and machine learning, aiming to enhance classical machine\nlearning methods by leveraging quantum mechanics principles such as\nentanglement and superposition. However, skepticism persists regarding the\npractical advantages of QML, mainly due to the current limitations of noisy\nintermediate-scale quantum (NISQ) devices. This study addresses these concerns\nby extensively assessing Quantum Neural Networks (QNNs)-quantum-inspired\ncounterparts of Artificial Neural Networks (ANNs), demonstrating their\neffectiveness compared to classical methods. We systematically construct and\nevaluate twelve distinct QNN configurations, utilizing two unique quantum\nfeature maps combined with six different entanglement strategies for ansatz\ndesign. Experiments conducted on a wind energy dataset reveal that QNNs\nemploying the Z feature map achieve up to 93% prediction accuracy when\nforecasting wind power output using only four input parameters. Our findings\nshow that QNNs outperform classical methods in predictive tasks, underscoring\nthe potential of QML in real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.14795v1",
    "published": "2025-05-31T19:17:53+00:00",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.06336v1",
    "title": "Research on E-Commerce Long-Tail Product Recommendation Mechanism Based on Large-Scale Language Models",
    "authors": [
      "Qingyi Lu",
      "Haotian Lyu",
      "Jiayun Zheng",
      "Yang Wang",
      "Li Zhang",
      "Chengrui Zhou"
    ],
    "abstract": "As e-commerce platforms expand their product catalogs, accurately\nrecommending long-tail items becomes increasingly important for enhancing both\nuser experience and platform revenue. A key challenge is the long-tail problem,\nwhere extreme data sparsity and cold-start issues limit the performance of\ntraditional recommendation methods. To address this, we propose a novel\nlong-tail product recommendation mechanism that integrates product text\ndescriptions and user behavior sequences using a large-scale language model\n(LLM). First, we introduce a semantic visor, which leverages a pre-trained LLM\nto convert multimodal textual content such as product titles, descriptions, and\nuser reviews into meaningful embeddings. These embeddings help represent\nitem-level semantics effectively. We then employ an attention-based user intent\nencoder that captures users' latent interests, especially toward long-tail\nitems, by modeling collaborative behavior patterns. These components feed into\na hybrid ranking model that fuses semantic similarity scores, collaborative\nfiltering outputs, and LLM-generated recommendation candidates. Extensive\nexperiments on a real-world e-commerce dataset show that our method outperforms\nbaseline models in recall (+12%), hit rate (+9%), and user coverage (+15%).\nThese improvements lead to better exposure and purchase rates for long-tail\nproducts. Our work highlights the potential of LLMs in interpreting product\ncontent and user intent, offering a promising direction for future e-commerce\nrecommendation systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.06336v1",
    "published": "2025-05-31T19:17:48+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00680v1",
    "title": "Understanding the European energy crisis through structural causal models",
    "authors": [
      "Anton Tausendfreund",
      "Sarah Schreyer",
      "Florian Immig",
      "Ulrich Oberhofer",
      "Julius Trebbien",
      "Aaron Praktiknjo",
      "Benjamin Schäfer",
      "Dirk Witthaut"
    ],
    "abstract": "Natural gas supplies in Europe were disrupted and energy prices soared in the\ncontext of Russia's invasion of Ukraine. Electricity prices in France\nexperienced the largest relative increase among European countries, even though\nnatural gas plays a negligible role in the French electricity system. In this\narticle, we demonstrate the importance of causal statistical methods and\npropose causal graphs to investigate the French electricity market and pinpoint\nkey influencing factors on electricity prices and net exports. We demonstrate\nthat a causal approach resolves paradoxical results of simple correlation\nstudies and enables a quantitative analysis of indirect causal effects. We\nintroduce a linear structural causal model as well as non-linear tree-based\nmachine learning combined with Shapley flows. The models elucidate the\ninterplay of gas prices and the unavailability of nuclear power plants during\nthe energy crisis: The high unavailability made France dependent on imports and\nlinked prices to neighbouring countries.",
    "pdf_url": "http://arxiv.org/pdf/2506.00680v1",
    "published": "2025-05-31T19:14:46+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00679v2",
    "title": "A versatile foundation model for cine cardiac magnetic resonance image analysis tasks",
    "authors": [
      "Yunguan Fu",
      "Wenjia Bai",
      "Weixi Yi",
      "Charlotte Manisty",
      "Anish N Bhuva",
      "Thomas A Treibel",
      "James C Moon",
      "Matthew J Clarkson",
      "Rhodri Huw Davies",
      "Yipeng Hu"
    ],
    "abstract": "Here we present a versatile foundation model that can perform a range of\nclinically-relevant image analysis tasks, including segmentation, landmark\nlocalisation, diagnosis, and prognostication. A multi-view\nconvolution-transformer masked autoencoder, named as CineMA, was trained on 15\nmillion cine images from 74,916 subjects. The model was validated on multiple\nimage analysis tasks and compared to existing models on >4,500 images from\neight independent datasets with diverse population characteristics,\nrepresenting the largest benchmark study for cine CMR so far. CineMA\nconsistently outperformed conventional convolutional neural networks (CNNs) in\ndelineating ventricular boundaries and estimating ejection fraction, a key\nmeasure of cardiac function. The improved performance was preserved, even when\nthe model only used half of fine-tuning data. CineMA also surpassed CNNs in\ndisease detection and matched their performance in long-axis function\nmeasurement. Interestingly, we found that CineMA can also detect cardiac\nchanges in systemic diseases, such as diabetes, hypertension and cancer, and\ncan also predict mortality. Finally, we assessed model fairness and\ndemonstrated consistent model performance across demographic subgroups. These\nfindings highlight CineMA's accuracy, learning efficiency, adaptability, and\nfairness, underscoring its potential as a foundation model for automated\ncardiac image analysis to support clinical workflow and cardiovascular\nresearch. All training and inference code and models are made publicly\navailable at https://github.com/mathpluscode/CineMA.",
    "pdf_url": "http://arxiv.org/pdf/2506.00679v2",
    "published": "2025-05-31T19:12:34+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00678v1",
    "title": "Evidence for supramolecular dynamics of non-hydrogen bonding polar van der Waals liquids",
    "authors": [
      "Shalin Patil",
      "Catalin Gainaru",
      "Roland Böhmer",
      "Shiwang Cheng"
    ],
    "abstract": "Non-hydrogen bonding van der Waals liquids with dipole-dipole interactions\nare typically viewed as non-associative and not considered able to sustain\nlarge supramolecular structures. Combining broadband dielectric spectroscopy\n(BDS) and rheology, we demonstrate the supramolecular formation in a group of\nnon-hydrogen-bonding van der Waals liquids, i.e. 1-bromo-2-ethylhexane,\n1-chloro-2-ethylhexane, and 1-bromo-3,7-dimethyloctane. BDS shows an emergence\nof a Debye-like process slower than their structural relaxation, which follows\nsuper-Arrhenius temperature dependence. Meanwhile, rheological measurements\nreveal a noticeable dynamical separation between the terminal relaxation and\nthe structural rearrangements. Interestingly, the rheological terminal time\nagrees remarkably well with the dielectric Debye-like relaxation time, pointing\nto a strong coupling between the terminal flow and the supramolecular dynamics\nof these van der Waals liquids. These results highlight the role of\nintermolecular dipole-dipole interactions on the structure and slow dynamics of\nvan der Waals liquids.",
    "pdf_url": "http://arxiv.org/pdf/2506.00678v1",
    "published": "2025-05-31T19:11:06+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00677v1",
    "title": "Review of Blockchain-Based Approaches to Spent Fuel Management in Nuclear Power Plants",
    "authors": [
      "Yuxiang Xu",
      "Wenjuan Yu",
      "Yuqian Wan",
      "Zhongming Zhang"
    ],
    "abstract": "This study addresses critical challenges in managing the transportation of\nspent nuclear fuel, including inadequate data transparency, stringent\nconfidentiality requirements, and a lack of trust among collaborating parties,\nissues prevalent in traditional centralized management systems. Given the high\nrisks involved, balancing data confidentiality with regulatory transparency is\nimperative. To overcome these limitations, a prototype system integrating\nblockchain technology and the Internet of Things (IoT) is proposed, featuring a\nmulti-tiered consortium chain architecture. This system utilizes IoT sensors\nfor real-time data collection, which is immutably recorded on the blockchain,\nwhile a hierarchical data structure (operational, supervisory, and public\nlayers) manages access for diverse stakeholders. The results demonstrate that\nthis approach significantly enhances data immutability, enables real-time\nmulti-sensor data integration, improves decentralized transparency, and\nincreases resilience compared to traditional systems. Ultimately, this\nblockchain-IoT framework improves the safety, transparency, and efficiency of\nspent fuel transportation, effectively resolving the conflict between\nconfidentiality and transparency in nuclear data management and offering\nsignificant practical implications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00677v1",
    "published": "2025-05-31T19:09:15+00:00",
    "categories": [
      "cs.CR",
      "cs.ET",
      "physics.app-ph"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.12061v1",
    "title": "Assessing the Quality of Binomial Samplers: A Statistical Distance Framework",
    "authors": [
      "Uddalok Sarkar",
      "Sourav Chakraborty",
      "Kuldeep S. Meel"
    ],
    "abstract": "Randomized algorithms depend on accurate sampling from probability\ndistributions, as their correctness and performance hinge on the quality of the\ngenerated samples. However, even for common distributions like Binomial, exact\nsampling is computationally challenging, leading standard library\nimplementations to rely on heuristics. These heuristics, while efficient,\nsuffer from approximation and system representation errors, causing deviations\nfrom the ideal distribution. Although seemingly minor, such deviations can\naccumulate in downstream applications requiring large-scale sampling,\npotentially undermining algorithmic guarantees. In this work, we propose\nstatistical distance as a robust metric for analyzing the quality of Binomial\nsamplers, quantifying deviations from the ideal distribution. We derive\nrigorous bounds on the statistical distance for standard implementations and\ndemonstrate the practical utility of our framework by enhancing APSEst, a DNF\nmodel counter, with improved reliability and error guarantees. To support\npractical adoption, we propose an interface extension that allows users to\ncontrol and monitor statistical distance via explicit input/output parameters.\nOur findings emphasize the critical need for thorough and systematic error\nanalysis in sampler design. As the first work to focus exclusively on Binomial\nsamplers, our approach lays the groundwork for extending rigorous analysis to\nother common distributions, opening avenues for more robust and reliable\nrandomized algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2506.12061v1",
    "published": "2025-05-31T19:05:10+00:00",
    "categories": [
      "stat.CO",
      "cs.LO"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00676v1",
    "title": "SafeTuneBed: A Toolkit for Benchmarking LLM Safety Alignment in Fine-Tuning",
    "authors": [
      "Saad Hossain",
      "Samanvay Vajpayee",
      "Sirisha Rambhatla"
    ],
    "abstract": "As large language models (LLMs) become ubiquitous, parameter-efficient\nfine-tuning methods and safety-first defenses have proliferated rapidly.\nHowever, the number of approaches and their recent increase have resulted in\ndiverse evaluations-varied datasets, metrics, and inconsistent threat\nsettings-making it difficult to fairly compare safety, utility, and robustness\nacross methods. To address this, we introduce SafeTuneBed, a benchmark and\ntoolkit unifying fine-tuning and defense evaluation. SafeTuneBed (i) curates a\ndiverse repository of multiple fine-tuning datasets spanning sentiment\nanalysis, question-answering, multi-step reasoning, and open-ended instruction\ntasks, and allows for the generation of harmful-variant splits; (ii) enables\nintegration of state-of-the-art defenses, including alignment-stage\nimmunization, in-training safeguards, and post-tuning repair; and (iii)\nprovides evaluators for safety (attack success rate, refusal consistency) and\nutility. Built on Python-first, dataclass-driven configs and plugins,\nSafeTuneBed requires minimal additional code to specify any fine-tuning regime,\ndefense method, and metric suite, while ensuring end-to-end reproducibility. We\nshowcase its value by benchmarking representative defenses across varied\npoisoning scenarios and tasks. By standardizing data, code, and metrics,\nSafeTuneBed is the first focused toolkit of its kind to accelerate rigorous and\ncomparable research in safe LLM fine-tuning. Code is available at:\nhttps://github.com/criticalml-uw/SafeTuneBed",
    "pdf_url": "http://arxiv.org/pdf/2506.00676v1",
    "published": "2025-05-31T19:00:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00675v2",
    "title": "Molecular dynamics simulation of the effects of neutron irradiation on Caesium Lead Bromide",
    "authors": [
      "Zhongming Zhang",
      "Samuel Murphy",
      "Michael Aspinall"
    ],
    "abstract": "With the development of fast neutron reactors and nuclear fusion reactors, it\nis necessary to find new radiation-hardened high-flux core neutron detectors.\nThe use of perovskite Caesium Lead Bromide (CsPbBr$_3$) for neutron radiation\ndetection is a new research direction. However, at high temperatures, the\neffects of neutron radiation, especially the Primary Knock-out Atom (PKA) and\nDisplacement Per Atom (DPA), and the defect distribution at the molecular level\nhave not been reported. This study investigated the effect on CsPbBr$_3$\nproduced by 14 MeV neutron irradiation under 100 K to 400 K. Molecular dynamics\nmethods are used to model the distribution of vacancies and interstitial atoms\nat the molecular level of materials. This study obtained the displacement\nthreshold energies of three atoms in CsPbBr$_3$ and obtained the distribution\nof vacancies and interstitial atoms within the material over time. Monte Carlo\nsimulations were used to obtain PKA and DPA information in CsPbBr$_3$ under\nneutron irradiation. This research will help to further study the performance\nchanges of halide perovskites under neutron irradiation to verify the\npossibility of using them as radiation-hardened neutron detectors.",
    "pdf_url": "http://arxiv.org/pdf/2506.00675v2",
    "published": "2025-05-31T19:00:08+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00674v1",
    "title": "Thinking Out of the Box: Hybrid SAT Solving by Unconstrained Continuous Optimization",
    "authors": [
      "Zhiwei Zhang",
      "Samy Wu Fung",
      "Anastasios Kyrillidis",
      "Stanley Osher",
      "Moshe Y. Vardi"
    ],
    "abstract": "The Boolean satisfiability (SAT) problem lies at the core of many\napplications in combinatorial optimization, software verification,\ncryptography, and machine learning. While state-of-the-art solvers have\ndemonstrated high efficiency in handling conjunctive normal form (CNF)\nformulas, numerous applications require non-CNF (hybrid) constraints, such as\nXOR, cardinality, and Not-All-Equal constraints. Recent work leverages\npolynomial representations to represent such hybrid constraints, but it relies\non box constraints that can limit the use of powerful unconstrained optimizers.\nIn this paper, we propose unconstrained continuous optimization formulations\nfor hybrid SAT solving by penalty terms. We provide theoretical insights into\nwhen these penalty terms are necessary and demonstrate empirically that\nunconstrained optimizers (e.g., Adam) can enhance SAT solving on hybrid\nbenchmarks. Our results highlight the potential of combining continuous\noptimization and machine-learning-based methods for effective hybrid SAT\nsolving.",
    "pdf_url": "http://arxiv.org/pdf/2506.00674v1",
    "published": "2025-05-31T18:58:33+00:00",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00673v1",
    "title": "DuAL-Net: A Hybrid Framework for Alzheimer's Disease Prediction from Whole-Genome Sequencing via Local SNP Windows and Global Annotations",
    "authors": [
      "Eun Hye Lee",
      "Taeho Jo"
    ],
    "abstract": "Alzheimer's disease (AD) dementia is the most common form of dementia. With\nthe emergence of disease-modifying therapies, predicting disease risk before\nsymptom onset has become critical. We introduce DuAL-Net, a hybrid deep\nlearning framework for AD dementia prediction using whole genome sequencing\n(WGS) data. DuAL-Net integrates two components: local probability modeling,\nwhich segments the genome into non-overlapping windows, and global\nannotation-based modeling, which annotates SNPs and reorganizes WGS input to\ncapture long-range functional relationships. Both employ out-of-fold stacking\nwith TabNet and Random Forest classifiers. Final predictions combine local and\nglobal probabilities using an optimized weighting parameter alpha. We analyzed\nWGS data from 1,050 individuals (443 cognitively normal, 607 AD dementia) using\nfive-fold cross-validation. DuAL-Net achieved an AUC of 0.671 using top-ranked\nSNPs, representing 35.0% and 20.3% higher performance than bottom-ranked and\nrandomly selected SNPs, respectively. ROC analysis demonstrated strong positive\ncorrelation between SNP prioritization rank and predictive power. The model\nidentified known AD-associated SNPs as top contributors alongside potentially\nnovel variants. DuAL-Net presents a promising framework improving both\npredictive accuracy and biological interpretability. The framework and web\nimplementation offer an accessible platform for broader research applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00673v1",
    "published": "2025-05-31T18:53:19+00:00",
    "categories": [
      "q-bio.GN"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.00672v1",
    "title": "Lie point symmetries of the biharmonic heat equation on surfaces of revolution",
    "authors": [
      "Aminu Ma'aruf Nass",
      "Kassimu Mpungu",
      "Rahmatullah Ibrahim Nuruddeen"
    ],
    "abstract": "This paper uses Lie symmetry analysis to investigate the biharmonic heat\nequation on a generalized surface of revolution. We classify the Lie point\nsymmetries associated with this equation, allowing for the identification of\nsurfaces and the corresponding infinitesimal generators. In a significant move,\nwe demonstrate that the biharmonic heat equation on a surface of revolution\nadmits the same Lie symmetries as the harmonic heat equation on the same\nsurface, highlighting a profound structural relationship between the two\nequations. Utilizing these symmetry groups, we derive similarity reductions\nthat yield invariant forms of the equation and facilitate the construction of\nexact solutions. Finally, we provide certain examples illustrating precise\nsolutions on the related surfaces with positive, negative, and zero Gaussian\ncurvatures, demonstrating the versatility of the approach. This work\ncontributes to the understanding of biharmonic heat equations on symmetric\nsurfaces.",
    "pdf_url": "http://arxiv.org/pdf/2506.00672v1",
    "published": "2025-05-31T18:52:16+00:00",
    "categories": [
      "math.AP",
      "math.DG",
      "31A30, 35B06, 58J70"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00671v1",
    "title": "DeepRAG: Integrating Hierarchical Reasoning and Process Supervision for Biomedical Multi-Hop QA",
    "authors": [
      "Yuelyu Ji",
      "Hang Zhang",
      "Shiven Verma",
      "Hui Ji",
      "Chun Li",
      "Yushui Han",
      "Yanshan Wang"
    ],
    "abstract": "We propose DeepRAG, a novel framework that integrates DeepSeek hierarchical\nquestion decomposition capabilities with RAG Gym unified retrieval-augmented\ngeneration optimization using process level supervision. Targeting the\nchallenging MedHopQA biomedical question answering task, DeepRAG systematically\ndecomposes complex queries into precise sub-queries and employs concept level\nreward signals informed by the UMLS ontology to enhance biomedical accuracy.\nPreliminary evaluations on the MedHopQA dataset indicate that DeepRAG\nsignificantly outperforms baseline models, including standalone DeepSeek and\nRAG Gym, achieving notable improvements in both Exact Match and concept level\naccuracy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00671v1",
    "published": "2025-05-31T18:52:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00670v1",
    "title": "Reconstruction techniques for inverse Sturm-Liouville problems with complex coefficients",
    "authors": [
      "Vladislav V. Kravchenko"
    ],
    "abstract": "A variety of inverse Sturm-Liouville problems is considered, including the\ntwo-spectrum inverse problem, the problem of recovering the potential from the\nWeyl function, as well as the recovery from the spectral function. In all cases\nthe potential in the Sturm-Liouville equation is assumed to be complex valued.\nA unified approach for the approximate solution of the inverse Sturm-Liouville\nproblems is developed, based on Neumann series of Bessel functions (NSBF)\nrepresentations for solutions and their derivatives. Unlike most existing\napproaches, it allows one to recover not only the complex-valued potential but\nalso the boundary conditions of the Sturm-Liouville problem. Efficient accuracy\ncontrol is implemented. The numerical method is direct. It involves only\nsolving linear systems of algebraic equations for the coefficients of the NSBF\nrepresentations, while eventually the knowledge only of the first NSBF\ncoefficients leads to the recovery of the Sturm-Liouville problem. Numerical\nefficiency is illustrated by several test examples.",
    "pdf_url": "http://arxiv.org/pdf/2506.00670v1",
    "published": "2025-05-31T18:49:55+00:00",
    "categories": [
      "math.CA",
      "cs.NA",
      "math-ph",
      "math.MP",
      "math.NA",
      "math.SP",
      "physics.comp-ph"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00669v1",
    "title": "On Linking Planet Formation Models, Protoplanetary Disk Properties, and Mature Gas Giant Exoplanet Atmospheres",
    "authors": [
      "Adina D. Feinstein",
      "Richard A. Booth",
      "Jennifer B. Bergner",
      "Joshua D. Lothringer",
      "Elisabeth C. Matthews",
      "Luis Welbanks",
      "Yamila Miguel",
      "Bertram Bitsch",
      "Linn E. J. Eriksson",
      "James Kirk",
      "Stefan Pelletier",
      "Anna B. T. Penzlin",
      "Anjali A. A. Piette",
      "Caroline Piaulet-Ghorayeb",
      "Kamber Schwarz",
      "Diego Turrini",
      "Lorena Acuña-Aguirre",
      "Eva-Maria Ahrer",
      "Madyson G. Barber",
      "Jonathan Brande",
      "Aritra Chakrabarty",
      "Ian J. M. Crossfield",
      "Gabriel-Dominique Marleau",
      "Helong Huang",
      "Anders Johansen",
      "Laura Kreidberg",
      "John H. Livingston",
      "Rafael Luque",
      "Maria Oreshenko",
      "Elenia Pacetti",
      "Guilia Perotti",
      "Jesse Polman",
      "Bibiana Prinoth",
      "Dmitry A. Semenov",
      "Jacob B. Simon",
      "Johanna Teske",
      "Niall Whiteford"
    ],
    "abstract": "Measuring a single elemental ratio (e.g., carbon-to-oxygen) provides\ninsufficient information for understanding the formation mechanisms and\nevolution that affect our observations of gas giant planet atmospheres.\nAlthough the fields of planet formation, protoplanetary disks, and exoplanets\nare well established and interconnected, our understanding of how to\nself-consistently and accurately link the theoretical and observational aspects\nof these fields together is lacking. To foster interdisciplinary conversations,\nthe Max-Planck Institut f\\\"ur Astronomie (MPIA) hosted a week-long workshop\ncalled, \"Challenge Accepted: Linking Planet Formation with Present-Day\nAtmospheres.\" Here, we summarize the latest theories and results in planet\nformation modeling, protoplanetary disk observations, and atmospheric\nobservations of gas giant atmospheres to address one of the challenges of\nhosting interdisciplinary conferences: ensuring everyone is aware of the\nstate-of-the-art results and technical language from each discipline\nrepresented. Additionally, we highlight key discussions held at the workshop.\nOur main conclusion is that it is unclear what the ideal observable is to make\nthis link between formation scenarios and exoplanet atmospheres, whether it be\nmultiple elemental abundance ratios, measuring refractory budgets, or something\nelse. Based on discussions held throughout the workshop, we provide several key\ntakeaways of what the workshop attendees feel need the most improvement and\nexploration within each discipline.",
    "pdf_url": "http://arxiv.org/pdf/2506.00669v1",
    "published": "2025-05-31T18:44:42+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00668v1",
    "title": "SafeTy Reasoning Elicitation Alignment for Multi-Turn Dialogues",
    "authors": [
      "Martin Kuo",
      "Jianyi Zhang",
      "Aolin Ding",
      "Louis DiValentin",
      "Amin Hass",
      "Benjamin F Morris",
      "Isaac Jacobson",
      "Randolph Linderman",
      "James Kiessling",
      "Nicolas Ramos",
      "Bhavna Gopal",
      "Maziyar Baran Pouyan",
      "Changwei Liu",
      "Hai Li",
      "Yiran Chen"
    ],
    "abstract": "Malicious attackers can exploit large language models (LLMs) by engaging them\nin multi-turn dialogues to achieve harmful objectives, posing significant\nsafety risks to society. To address this challenge, we propose a novel defense\nmechanism: SafeTy Reasoning Elicitation Alignment for Multi-Turn Dialogues\n(STREAM). STREAM defends LLMs against multi-turn attacks while preserving their\nfunctional capabilities. Our approach involves constructing a human-annotated\ndataset, the Safety Reasoning Multi-turn Dialogues dataset, which is used to\nfine-tune a plug-and-play safety reasoning moderator. This model is designed to\nidentify malicious intent hidden within multi-turn conversations and alert the\ntarget LLM of potential risks. We evaluate STREAM across multiple LLMs against\nprevalent multi-turn attack strategies. Experimental results demonstrate that\nour method significantly outperforms existing defense techniques, reducing the\nAttack Success Rate (ASR) by 51.2%, all while maintaining comparable LLM\ncapability.",
    "pdf_url": "http://arxiv.org/pdf/2506.00668v1",
    "published": "2025-05-31T18:38:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00667v1",
    "title": "Scene Detection Policies and Keyframe Extraction Strategies for Large-Scale Video Analysis",
    "authors": [
      "Vasilii Korolkov"
    ],
    "abstract": "Robust scene segmentation and keyframe extraction are essential preprocessing\nsteps in video understanding pipelines, supporting tasks such as indexing,\nsummarization, and semantic retrieval. However, existing methods often lack\ngeneralizability across diverse video types and durations. We present a\nunified, adaptive framework for automatic scene detection and keyframe\nselection that handles formats ranging from short-form media to long-form\nfilms, archival content, and surveillance footage. Our system dynamically\nselects segmentation policies based on video length: adaptive thresholding for\nshort videos, hybrid strategies for mid-length ones, and interval-based\nsplitting for extended recordings. This ensures consistent granularity and\nefficient processing across domains. For keyframe selection, we employ a\nlightweight module that scores sampled frames using a composite metric of\nsharpness, luminance, and temporal spread, avoiding complex saliency models\nwhile ensuring visual relevance. Designed for high-throughput workflows, the\nsystem is deployed in a commercial video analysis platform and has processed\ncontent from media, education, research, and security domains. It offers a\nscalable and interpretable solution suitable for downstream applications such\nas UI previews, embedding pipelines, and content filtering. We discuss\npractical implementation details and outline future enhancements, including\naudio-aware segmentation and reinforcement-learned frame scoring.",
    "pdf_url": "http://arxiv.org/pdf/2506.00667v1",
    "published": "2025-05-31T18:37:21+00:00",
    "categories": [
      "cs.CV",
      "cs.MM",
      "68T07",
      "I.2.10; I.4.8; I.5.1"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00666v1",
    "title": "Unbiased estimation in new Gini index extensions under gamma distributions",
    "authors": [
      "Roberto Vila",
      "Helton Saulo"
    ],
    "abstract": "In this paper, we propose two new flexible Gini indices (extended lower and\nupper) defined via differences between the $i$-th observation, the smallest\norder statistic, and the largest order statistic, for any $1 \\leqslant i\n\\leqslant m$. For gamma-distributed data, we obtain exact expectations of the\nestimators and establish their unbiasedness, generalizing prior works by\n[Deltas, G. 2003. The small-sample bias of the gini coefficient: Results and\nimplications for empirical research. Review of Economics and Statistics\n85:226-234] and [Baydil, B., de la Pe\\~na, V. H., Zou, H., and Yao, H. 2025.\nUnbiased estimation of the gini coefficient. Statistics & Probability Letters\n222:110376]. Finite-sample performance is assessed via simulation, and real\nincome data set is analyzed to illustrate the proposed measures.",
    "pdf_url": "http://arxiv.org/pdf/2506.00666v1",
    "published": "2025-05-31T18:35:28+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.00665v1",
    "title": "Decays of the vector charmonium and bottomonium hybrids",
    "authors": [
      "B. Barsbay"
    ],
    "abstract": "The full widths of the vector charmonium and bottomonium hybrid mesons $H_{\n\\mathrm{c}}$ and $H_{\\mathrm{b}}$, characterized by the quantum numbers $1^{\n\\mathrm{--}}$, are determined by analyzing their dominant strong decay modes:\n$H_{\\mathrm{c}} \\to D^{+}D^{-}$, $D_{0}\\overline{D}_{0}$, $ D_{s}^{+}D_{s}^{-}\n$ and $H_{\\mathrm{b}} \\to B^{+}B^{-}$, $B_{0}\\overline{B} _{0}$. To evaluate\nthe partial widths of these channels, we employ the QCD three-point sum rule\napproach, which provides a reliable method for extracting the strong coupling\nconstants at the relevant hybrid-meson-meson interaction vertices. Based on\nthis analysis, the full widths of these hybrid quarkonia are found to be\n$\\Gamma _{H_{\\mathrm{c}}} =(234.1\\pm 37.4)~ \\mathrm{MeV} $ and $\\Gamma\n_{H_{\\mathrm{b}}} =(78.8\\pm 15.4)~\\mathrm{MeV} $ . These results are expected\nto facilitate the interpretation of future experimental data concerning the\nspectroscopy and decay patterns of exotic charmonium- and bottomonium-like\nhybrid mesons.",
    "pdf_url": "http://arxiv.org/pdf/2506.00665v1",
    "published": "2025-05-31T18:34:21+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-lat"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00664v1",
    "title": "OntoRAG: Enhancing Question-Answering through Automated Ontology Derivation from Unstructured Knowledge Bases",
    "authors": [
      "Yash Tiwari",
      "Owais Ahmad Lone",
      "Mayukha Pal"
    ],
    "abstract": "Ontologies are pivotal for structuring knowledge bases to enhance question\nanswering (QA) systems powered by Large Language Models (LLMs). However,\ntraditional ontology creation relies on manual efforts by domain experts, a\nprocess that is time intensive, error prone, and impractical for large, dynamic\nknowledge domains. This paper introduces OntoRAG, an automated pipeline\ndesigned to derive ontologies from unstructured knowledge bases, with a focus\non electrical relay documents. OntoRAG integrates advanced techniques,\nincluding web scraping, PDF parsing, hybrid chunking, information extraction,\nknowledge graph construction, and ontology creation, to transform unstructured\ndata into a queryable ontology. By leveraging LLMs and graph based methods,\nOntoRAG enhances global sensemaking capabilities, outperforming conventional\nRetrieval Augmented Generation (RAG) and GraphRAG approaches in\ncomprehensiveness and diversity. Experimental results demonstrate OntoRAGs\neffectiveness, achieving a comprehensiveness win rate of 85% against vector RAG\nand 75% against GraphRAGs best configuration. This work addresses the critical\nchallenge of automating ontology creation, advancing the vision of the semantic\nweb.",
    "pdf_url": "http://arxiv.org/pdf/2506.00664v1",
    "published": "2025-05-31T18:33:39+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.14794v1",
    "title": "Assembly of Experts: Linear-time construction of the Chimera LLM variants with emergent and adaptable behaviors",
    "authors": [
      "Henrik Klagges",
      "Robert Dahlke",
      "Fabian Klemm",
      "Benjamin Merkel",
      "Daniel Klingmann",
      "David A. Reiss",
      "Dan Zecha"
    ],
    "abstract": "Requiring $10^{13}$-$10^{15}$ FLOPs to calculate one 8 bit weight in an LLM\nduring pretraining is extremely expensive and seems inefficient. To better\nleverage the huge investments made into pretrained models, we develop the new\n\"Assembly-of-Experts\" (AoE) construction method to create capable child\nvariants of existing Mixture-of-Experts parent models in linear time. Model\nweight tensors get interpolated individually, allowing to enhance or suppress\nsemantic features of the parents.\n  Varying the proportion of weights taken from the parent models, we observe\nsome properties of the AoE child model changing gradually, while other\nbehavioral traits emerge with a sharp transition. Surprisingly, nearly every\ngenerated model is functional and capable, which makes searching the model\nspace straightforward.\n  We construct the DeepSeek R1T \"Chimera\", a 671B open-weights hybrid model\ncombining DeepSeek's V3-0324 and R1 model variants. The child inherits only the\nrouted expert tensors of R1, but still achieves about R1-level intelligence. At\nthe same time, it uses about 40\\% fewer output tokens, close to V3 speed.\nConstructed without any fine-tuning or distillation, the Chimera exhibits\nsurprisingly compact, orderly reasoning compared to its parent models.",
    "pdf_url": "http://arxiv.org/pdf/2506.14794v1",
    "published": "2025-05-31T18:23:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00663v1",
    "title": "Counting methods of area integrals and Tchebychev polynomials of second kind on the ellipse",
    "authors": [
      "Abdelhamid Rehouma"
    ],
    "abstract": "We use Gronwall's area formula to find the area of some differents regions as\ncircles, ellipses and lemniscates.We use Laurent and Taylor series expansions\nof conformal mapping from the exterior of the unit disk to either of these\nregions to compute the area of them.We close this work with the discussion of\northogonal Tchebychev polynomials of second kind on the ellipse and\ninterpolation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00663v1",
    "published": "2025-05-31T18:23:10+00:00",
    "categories": [
      "math.CV"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00662v1",
    "title": "Uncertainty-Aware Genomic Classification of Alzheimer's Disease: A Transformer-Based Ensemble Approach with Monte Carlo Dropout",
    "authors": [
      "Taeho Jo",
      "Eun Hye Lee",
      "Alzheimer's Disease Sequencing Project"
    ],
    "abstract": "INTRODUCTION: Alzheimer's disease (AD) is genetically complex, complicating\nrobust classification from genomic data. METHODS: We developed a\ntransformer-based ensemble model (TrUE-Net) using Monte Carlo Dropout for\nuncertainty estimation in AD classification from whole-genome sequencing (WGS).\nWe combined a transformer that preserves single-nucleotide polymorphism (SNP)\nsequence structure with a concurrent random forest using flattened genotypes.\nAn uncertainty threshold separated samples into an uncertain (high-variance)\ngroup and a more certain (low-variance) group. RESULTS: We analyzed 1050\nindividuals, holding out half for testing. Overall accuracy and area under the\nreceiver operating characteristic (ROC) curve (AUC) were 0.6514 and 0.6636,\nrespectively. Excluding the uncertain group improved accuracy from 0.6263 to\n0.7287 (10.24% increase) and F1 from 0.5843 to 0.8205 (23.62% increase).\nDISCUSSION: Monte Carlo Dropout-driven uncertainty helps identify ambiguous\ncases that may require further clinical evaluation, thus improving reliability\nin AD genomic classification.",
    "pdf_url": "http://arxiv.org/pdf/2506.00662v1",
    "published": "2025-05-31T18:20:49+00:00",
    "categories": [
      "q-bio.GN",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.00661v2",
    "title": "LoRA as a Flexible Framework for Securing Large Vision Systems",
    "authors": [
      "Zander W. Blasingame",
      "Richard E. Neddo",
      "Chen Liu"
    ],
    "abstract": "Adversarial attacks have emerged as a critical threat to autonomous driving\nsystems. These attacks exploit the underlying neural network, allowing small --\nnearly invisible -- perturbations to completely alter the behavior of such\nsystems in potentially malicious ways. E.g., causing a traffic sign\nclassification network to misclassify a stop sign as a speed limit sign. Prior\nworking in hardening such systems to adversarial attacks have looked at robust\ntraining of the system or adding additional pre-processing steps to the input\npipeline. Such solutions either have a hard time generalizing, require\nknowledge of the adversarial attacks during training, or are computationally\nundesirable. Instead, we propose to take insights for parameter efficient\nfine-tuning and use low-rank adaptation (LoRA) to train a lightweight security\npatch -- enabling us to dynamically patch a large preexisting vision system as\nnew vulnerabilities are discovered. We demonstrate that our framework can patch\na pre-trained model to improve classification accuracy by up to 78.01% in the\npresence of adversarial examples.",
    "pdf_url": "http://arxiv.org/pdf/2506.00661v2",
    "published": "2025-05-31T18:16:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.12060v1",
    "title": "Organizational Adaptation to Generative AI in Cybersecurity: A Systematic Review",
    "authors": [
      "Christopher Nott"
    ],
    "abstract": "Cybersecurity organizations are adapting to GenAI integration through\nmodified frameworks and hybrid operational processes, with success influenced\nby existing security maturity, regulatory requirements, and investments in\nhuman capital and infrastructure. This qualitative research employs systematic\ndocument analysis and comparative case study methodology to examine how\ncybersecurity organizations adapt their threat modeling frameworks and\noperational processes to address generative artificial intelligence\nintegration. Through examination of 25 studies from 2022 to 2025, the research\ndocuments substantial transformation in organizational approaches to threat\nmodeling, moving from traditional signature-based systems toward frameworks\nincorporating artificial intelligence capabilities. The research identifies\nthree primary adaptation patterns: Large Language Model integration for\nsecurity applications, GenAI frameworks for risk detection and response\nautomation, and AI/ML integration for threat hunting. Organizations with mature\nsecurity infrastructures, particularly in finance and critical infrastructure\nsectors, demonstrate higher readiness through structured governance approaches,\ndedicated AI teams, and robust incident response processes. Organizations\nachieve successful GenAI integration when they maintain appropriate human\noversight of automated systems, address data quality concerns and\nexplainability requirements, and establish governance frameworks tailored to\ntheir specific sectors. Organizations encounter ongoing difficulties with\nprivacy protection, bias reduction, personnel training, and defending against\nadversarial attacks. This work advances understanding of how organizations\nadopt innovative technologies in high-stakes environments and offers actionable\ninsights for cybersecurity professionals implementing GenAI systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.12060v1",
    "published": "2025-05-31T18:16:11+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "K.6.5; I.2.0; K.4.1"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00660v1",
    "title": "Differential Privacy for Deep Learning in Medicine",
    "authors": [
      "Marziyeh Mohammadi",
      "Mohsen Vejdanihemmat",
      "Mahshad Lotfinia",
      "Mirabela Rusu",
      "Daniel Truhn",
      "Andreas Maier",
      "Soroosh Tayebi Arasteh"
    ],
    "abstract": "Differential privacy (DP) is a key technique for protecting sensitive patient\ndata in medical deep learning (DL). As clinical models grow more\ndata-dependent, balancing privacy with utility and fairness has become a\ncritical challenge. This scoping review synthesizes recent developments in\napplying DP to medical DL, with a particular focus on DP-SGD and alternative\nmechanisms across centralized and federated settings. Using a structured search\nstrategy, we identified 74 studies published up to March 2025. Our analysis\nspans diverse data modalities, training setups, and downstream tasks, and\nhighlights the tradeoffs between privacy guarantees, model accuracy, and\nsubgroup fairness. We find that while DP-especially at strong privacy\nbudgets-can preserve performance in well-structured imaging tasks, severe\ndegradation often occurs under strict privacy, particularly in underrepresented\nor complex modalities. Furthermore, privacy-induced performance gaps\ndisproportionately affect demographic subgroups, with fairness impacts varying\nby data type and task. A small subset of studies explicitly addresses these\ntradeoffs through subgroup analysis or fairness metrics, but most omit them\nentirely. Beyond DP-SGD, emerging approaches leverage alternative mechanisms,\ngenerative models, and hybrid federated designs, though reporting remains\ninconsistent. We conclude by outlining key gaps in fairness auditing,\nstandardization, and evaluation protocols, offering guidance for future work\ntoward equitable and clinically robust privacy-preserving DL systems in\nmedicine.",
    "pdf_url": "http://arxiv.org/pdf/2506.00660v1",
    "published": "2025-05-31T18:03:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00659v1",
    "title": "PackHero: A Scalable Graph-based Approach for Efficient Packer Identification",
    "authors": [
      "Marco Di Gennaro",
      "Mario D'Onghia",
      "Mario Polino",
      "Stefano Zanero",
      "Michele Carminati"
    ],
    "abstract": "Anti-analysis techniques, particularly packing, challenge malware analysts,\nmaking packer identification fundamental. Existing packer identifiers have\nsignificant limitations: signature-based methods lack flexibility and struggle\nagainst dynamic evasion, while Machine Learning approaches require extensive\ntraining data, limiting scalability and adaptability. Consequently, achieving\naccurate and adaptable packer identification remains an open problem. This\npaper presents PackHero, a scalable and efficient methodology for identifying\npackers using a novel static approach. PackHero employs a Graph Matching\nNetwork and clustering to match and group Call Graphs from programs packed with\nknown packers. We evaluate our approach on a public dataset of malware and\nbenign samples packed with various packers, demonstrating its effectiveness and\nscalability across varying sample sizes. PackHero achieves a macro-average\nF1-score of 93.7% with just 10 samples per packer, improving to 98.3% with 100\nsamples. Notably, PackHero requires fewer samples to achieve stable performance\ncompared to other Machine Learning-based tools. Overall, PackHero matches the\nperformance of State-of-the-art signature-based tools, outperforming them in\nhandling Virtualization-based packers such as Themida/Winlicense, with a recall\nof 100%.",
    "pdf_url": "http://arxiv.org/pdf/2506.00659v1",
    "published": "2025-05-31T18:01:50+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00658v2",
    "title": "Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques",
    "authors": [
      "Lang Xiong",
      "Raina Gao",
      "Alyssa Jeong",
      "Yicheng Fu",
      "Sean O'Brien",
      "Vasu Sharma",
      "Kevin Zhu"
    ],
    "abstract": "Sarcasm is a form of humor where expressions convey meanings opposite to\ntheir literal interpretations. Classifying and generating sarcasm using large\nlanguage models is vital for interpreting human communication. Sarcasm poses\nchallenges for computational models, due to its nuanced nature. We introduce\nSarc7, a benchmark that classifies 7 types of sarcasm: self-deprecating,\nbrooding, deadpan, polite, obnoxious, raging, and manic by annotating entries\nof the MUStARD dataset. Classification was evaluated using zero-shot, few-shot,\nchain-of-thought (CoT), and a novel emotion-based prompting technique. We\npropose an emotion-based generation method developed by identifying key\ncomponents of sarcasm-incongruity, shock value, and context dependency. Our\nclassification experiments show that Gemini 2.5, using emotion-based prompting,\noutperforms other setups with an F1 score of 0.3664. Human evaluators preferred\nour emotion-based prompting, with 38.46% more successful generations than\nzero-shot prompting.",
    "pdf_url": "http://arxiv.org/pdf/2506.00658v2",
    "published": "2025-05-31T18:01:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00657v1",
    "title": "Electromagnetically Reconfigurable Antennas for 6G: Enabling Technologies, Prototype Studies, and Research Outlook",
    "authors": [
      "Pinjun Zheng",
      "Ruiqi Wang",
      "Yuchen Zhang",
      "Md. Jahangir Hossain",
      "Anas Chaaban",
      "Atif Shamim",
      "Tareq Y. Al-Naffouri"
    ],
    "abstract": "The transition to the sixth-generation (6G) network is anticipated to\nredefine wireless transceiver architectures, demanding higher adaptability and\nefficiency at the antenna layer. Electromagnetically reconfigurable antennas\n(ERAs) have emerged as a promising solution capable of dynamically\nreconfiguring wireless channels to meet these requirements. This article\npresents an overview of recent advancements in ERA technology, underscoring its\ntransformative potential for 6G applications. Drawing from several initial\nstudies, we demonstrate that ERAs can significantly enhance communication rates\nand hardware efficiency. Nevertheless, critical challenges remain in hardware\ndesign and signal processing methodologies, necessitating concerted efforts\nfrom both the antenna and communication communities. We identify these gaps and\noutline key research directions to fully unlock the capabilities of ERAs in\nnext-generation wireless networks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00657v1",
    "published": "2025-05-31T17:57:15+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00656v1",
    "title": "Permutation-Invariant Transformer Neural Architectures for Set-Based Indoor Localization Using Learned RSSI Embeddings",
    "authors": [
      "Aris J. Aristorenas"
    ],
    "abstract": "We propose a permutation-invariant neural architecture for indoor\nlocalization using RSSI scans from Wi-Fi access points. Each scan is modeled as\nan unordered set of (BSSID, RSSI) pairs, where BSSIDs are mapped to learned\nembeddings and concatenated with signal strength. These are processed by a Set\nTransformer, enabling the model to handle variable-length, sparse inputs while\nlearning attention-based representations over access point relationships. We\nevaluate the model on a dataset collected across a campus environment\nconsisting of six buildings. Results show that the model accurately recovers\nfine-grained spatial structure and maintains performance across physically\ndistinct domains. In our experiments, a simple LSTM consistently outperformed\nall other models, achieving the lowest mean localization error across three\ntasks (E1 - E3), with average errors as low as 2.23 m. The Set Transformer\nperformed competitively, ranking second in every experiment and outperforming\nthe MLP, RNN, and basic attention models, particularly in scenarios involving\nmultiple buildings (E2) and multiple floors (E3). Performance degraded most in\nE2, where signal conditions varied substantially across buildings, highlighting\nthe importance of architectural robustness to domain diversity. This work\ndemonstrates that set-based neural models are a natural fit for signal-based\nlocalization, offering a principled approach to handling sparse, unordered\ninputs in real-world positioning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00656v1",
    "published": "2025-05-31T17:56:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00655v1",
    "title": "Over-the-Air Fronthaul Signaling for Uplink Cell-Free Massive MIMO Systems",
    "authors": [
      "Zakir Hussain Shaik",
      "Sai Subramanyam Thoota",
      "Emil Björnson",
      "Erik G. Larsson"
    ],
    "abstract": "We propose a novel resource-efficient over-the-air(OTA) computation framework\nto address the huge fronthaul computational and control overhead requirements\nin cell-free massive multiple-input multiple-output (MIMO) networks. We show\nthat the global sufficient statistics to decode the data symbols can be\ncomputed OTA using the locally available information at the access points\n(APs). We provide the essential signal processing aspects at the APs and the\ncentral processing unit (CPU) to facilitate the OTA computation of sufficient\nstatistics. The proposed framework scales effectively with an increase in the\nnumber of APs. We also make a comprehensive study of the benefits of an OTA\nframework compared to a conventional digital fronthaul in terms of the overhead\nassociated in transferring the sufficient statistics from the APs to the CPU.\nTo evaluate the performance of the OTA framework, we give closed-form\nexpressions for the mean-square error (MSE)of the estimators of sufficient\nstatistics and the overall data estimator. Furthermore, we assess the symbol\nerror rate (SER)and bit error rate (BER) of the user equipment (UEs) data to\ndemonstrate the efficacy of our method, and benchmark them against the\nstate-of-the-art wired fronthaul networks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00655v1",
    "published": "2025-05-31T17:51:49+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00654v1",
    "title": "Amatriciana: Exploiting Temporal GNNs for Robust and Efficient Money Laundering Detection",
    "authors": [
      "Marco Di Gennaro",
      "Francesco Panebianco",
      "Marco Pianta",
      "Stefano Zanero",
      "Michele Carminati"
    ],
    "abstract": "Money laundering is a financial crime that poses a serious threat to\nfinancial integrity and social security. The growing number of transactions\nmakes it necessary to use automatic tools that help law enforcement agencies\ndetect such criminal activity. In this work, we present Amatriciana, a novel\napproach based on Graph Neural Networks to detect money launderers inside a\ngraph of transactions by considering temporal information. Amatriciana uses the\nwhole graph of transactions without splitting it into several time-based\nsubgraphs, exploiting all relational information in the dataset. Our\nexperiments on a public dataset reveal that the model can learn from a limited\namount of data. Furthermore, when more data is available, the model outperforms\nother State-of-the-art approaches; in particular, Amatriciana decreases the\nnumber of False Positives (FPs) while detecting many launderers. In summary,\nAmatriciana achieves an F1 score of 0.76. In addition, it lowers the FPs by 55%\nwith respect to other State-of-the-art models.",
    "pdf_url": "http://arxiv.org/pdf/2506.00654v1",
    "published": "2025-05-31T17:47:29+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00653v3",
    "title": "Linear Representation Transferability Hypothesis: Leveraging Small Models to Steer Large Models",
    "authors": [
      "Femi Bello",
      "Anubrata Das",
      "Fanzhi Zeng",
      "Fangcong Yin",
      "Liu Leqi"
    ],
    "abstract": "It has been hypothesized that neural networks with similar architectures\ntrained on similar data learn shared representations relevant to the learning\ntask. We build on this idea by extending the conceptual framework where\nrepresentations learned across models trained on the same data can be expressed\nas linear combinations of a \\emph{universal} set of basis features. These basis\nfeatures underlie the learning task itself and remain consistent across models,\nregardless of scale. From this framework, we propose the \\textbf{Linear\nRepresentation Transferability (LRT)} Hypothesis -- that there exists an affine\ntransformation between the representation spaces of different models. To test\nthis hypothesis, we learn affine mappings between the hidden states of models\nof different sizes and evaluate whether steering vectors -- directions in\nhidden state space associated with specific model behaviors -- retain their\nsemantic effect when transferred from small to large language models using the\nlearned mappings. We find strong empirical evidence that such affine mappings\ncan preserve steering behaviors. These findings suggest that representations\nlearned by small models can be used to guide the behavior of large models, and\nthat the LRT hypothesis may be a promising direction on understanding\nrepresentation alignment across model scales.",
    "pdf_url": "http://arxiv.org/pdf/2506.00653v3",
    "published": "2025-05-31T17:45:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00652v2",
    "title": "Video Signature: In-generation Watermarking for Latent Video Diffusion Models",
    "authors": [
      "Yu Huang",
      "Junhao Chen",
      "Shuliang Liu",
      "Hanqian Li",
      "Qi Zheng",
      "Yi R.",
      "Fung",
      "Xuming Hu"
    ],
    "abstract": "The rapid development of Artificial Intelligence Generated Content (AIGC) has\nled to significant progress in video generation but also raises serious\nconcerns about intellectual property protection and reliable content tracing.\nWatermarking is a widely adopted solution to this issue, but existing methods\nfor video generation mainly follow a post-generation paradigm, which introduces\nadditional computational overhead and often fails to effectively balance the\ntrade-off between video quality and watermark extraction. To address these\nissues, we propose Video Signature (VIDSIG), an in-generation watermarking\nmethod for latent video diffusion models, which enables implicit and adaptive\nwatermark integration during generation. Specifically, we achieve this by\npartially fine-tuning the latent decoder, where Perturbation-Aware Suppression\n(PAS) pre-identifies and freezes perceptually sensitive layers to preserve\nvisual quality. Beyond spatial fidelity, we further enhance temporal\nconsistency by introducing a lightweight Temporal Alignment module that guides\nthe decoder to generate coherent frame sequences during fine-tuning.\nExperimental results show that VIDSIG achieves the best overall performance in\nwatermark extraction, visual quality, and generation efficiency. It also\ndemonstrates strong robustness against both spatial and temporal tampering,\nhighlighting its practicality in real-world scenarios. Our code is available at\n\\href{https://github.com/hardenyu21/Video-Signature}{here}",
    "pdf_url": "http://arxiv.org/pdf/2506.00652v2",
    "published": "2025-05-31T17:43:54+00:00",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00651v1",
    "title": "Innovative Tangible Interactive Games for Enhancing Artificial Intelligence Knowledge and Literacy in Elementary Education: A Pedagogical Framework",
    "authors": [
      "Nikolaos Sampanis"
    ],
    "abstract": "This paper presents an innovative pedagogical framework employing tangible\ninteractive games to enhance artificial intelligence (AI) knowledge and\nliteracy among elementary education students. Recognizing the growing\nimportance of AI competencies in the 21st century, this study addresses the\ncritical need for age-appropriate, experiential learning tools that demystify\ncore AI concepts for young learners. The proposed approach integrates physical\nrole-playing activities that embody fundamental AI principles, including neural\nnetworks, decision-making, machine learning, and pattern recognition. Through\ncarefully designed game mechanics, students actively engage in collaborative\nproblem solving, fostering deeper conceptual understanding and critical\nthinking skills. The framework further supports educators by providing detailed\nguidance on implementation and pedagogical objectives, thus facilitating\neffective AI education in early childhood settings. Empirical insights and\ntheoretical grounding demonstrate the potential of tangible interactive games\nto bridge the gap between abstract AI theories and practical comprehension,\nultimately promoting AI literacy at foundational educational levels. The study\ncontributes to the growing discourse on AI education by offering scalable and\nadaptable strategies that align with contemporary curricular demands and\nprepare young learners for a technologically driven future.",
    "pdf_url": "http://arxiv.org/pdf/2506.00651v1",
    "published": "2025-05-31T17:40:30+00:00",
    "categories": [
      "cs.CY",
      "68T99, 97D40, 97U50, 68T20, 97B50"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00650v1",
    "title": "Coherent error induced phase transition",
    "authors": [
      "Hanchen Liu",
      "Xiao Chen"
    ],
    "abstract": "We investigate the stability of logical information in quantum stabilizer\ncodes subject to coherent unitary errors. Beginning with a logical state, we\napply a random unitary error channel and subsequently measure stabilizer\nchecks, resulting in a syndrome-dependent post-measurement state. By examining\nboth this syndrome state and the associated syndrome distribution, we identify\na phase transition in the behavior of the logical state. Below a critical error\nthreshold pc, the syndrome state remains in the same logical state, enabling\nsuccessful recovery of the code's logical information via suitable\nerror-correction protocols. Above pc, however, the syndrome state shifts to a\ndifferent logical state, signaling the breakdown of efficient error correction.\nNotably, this process can often induce an effective unitary rotation within the\nlogical space. This transition is accompanied by qualitative changes in both\nthe global and local features of the syndrome distribution. We refer to this\nphenomenon as a coherent error induced phase transition. To illustrate this\ntransition, we present two classes of quantum error correcting code models the\ntoric code and non-local random stabilizer codes thereby shedding light on the\ndesign and performance limits of quantum error correction under coherent\nerrors.",
    "pdf_url": "http://arxiv.org/pdf/2506.00650v1",
    "published": "2025-05-31T17:37:57+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00649v1",
    "title": "GuideX: Guided Synthetic Data Generation for Zero-Shot Information Extraction",
    "authors": [
      "Neil De La Fuente",
      "Oscar Sainz",
      "Iker García-Ferrero",
      "Eneko Agirre"
    ],
    "abstract": "Information Extraction (IE) systems are traditionally domain-specific,\nrequiring costly adaptation that involves expert schema design, data\nannotation, and model training. While Large Language Models have shown promise\nin zero-shot IE, performance degrades significantly in unseen domains where\nlabel definitions differ. This paper introduces GUIDEX, a novel method that\nautomatically defines domain-specific schemas, infers guidelines, and generates\nsynthetically labeled instances, allowing for better out-of-domain\ngeneralization. Fine-tuning Llama 3.1 with GUIDEX sets a new state-of-the-art\nacross seven zeroshot Named Entity Recognition benchmarks. Models trained with\nGUIDEX gain up to 7 F1 points over previous methods without humanlabeled data,\nand nearly 2 F1 points higher when combined with it. Models trained on GUIDEX\ndemonstrate enhanced comprehension of complex, domain-specific annotation\nschemas. Code, models, and synthetic datasets are available at\nneilus03.github.io/guidex.com",
    "pdf_url": "http://arxiv.org/pdf/2506.00649v1",
    "published": "2025-05-31T17:36:18+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00648v1",
    "title": "A Framework for Nonlinearly-Constrained Gradient-Enhanced Local Bayesian Optimization with Comparisons to Quasi-Newton Optimizers",
    "authors": [
      "André L. Marchildon",
      "David W. Zingg"
    ],
    "abstract": "Bayesian optimization is a popular and versatile approach that is well suited\nto solve challenging optimization problems. Their popularity comes from their\neffective minimization of expensive function evaluations, their capability to\nleverage gradients, and their efficient use of noisy data. Bayesian optimizers\nhave commonly been applied to global unconstrained problems, with limited\ndevelopment for many other classes of problems. In this paper, two alternative\nmethods are developed that enable rapid and deep convergence of\nnonlinearly-constrained local optimization problems using a Bayesian optimizer.\nThe first method uses an exact augmented Lagrangian and the second augments the\nminimization of the acquisition function to contain additional constraints.\nBoth of these methods can be applied to nonlinear equality constraints, unlike\nmost previous methods developed for constrained Bayesian optimizers. The new\nmethods are applied with a gradient-enhanced Bayesian optimizer and enable\ndeeper convergence for three nonlinearly-constrained unimodal optimization\nproblems than previously developed methods for constrained Bayesian\noptimization. In addition, both new methods enable the Bayesian optimizer to\nreach a desired tolerance with fewer function evaluations than popular\nquasi-Newton optimizers from SciPy and MATLAB for problems with 2 to 30\nvariables. The Bayesian optimizer had similar results using both methods. It is\nrecommended that users first try using the second method, which adds\nconstraints to the acquisition function minimization, since its parameters are\nmore intuitive to tune for new problems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00648v1",
    "published": "2025-05-31T17:34:52+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00647v2",
    "title": "Indefinite Causal Order Skip Logic with Coherently Conditioned Subroutines and Application to Grover Search",
    "authors": [
      "Kym Derriman"
    ],
    "abstract": "Indefinite causal order (ICO) allows quantum circuits to coherently superpose\nthe sequence of operations, creating computational possibilities beyond fixed\ngate ordering. This work introduces the Quantum Skip Gate (QSG), a new unitary\ncircuit primitive that extends ICO to coherently control whether an expensive\nquantum subroutine is executed, without mid-circuit measurement or loss of\ncoherence. Unlike conventional ICO constructions that superpose gate sequences,\nthe QSG superposes the presence or absence of operations themselves, enabling\nconditional quantum logic in a fully unitary setting. Demonstrated\nexperimentally in a Grover-style search on IBM quantum hardware (n = 4, k = 3),\nthe QSG reduces costly subroutine calls by 9-25 percent, achieving a 31-61\npercent improvement in success-per-oracle efficiency relative to a fixed-order\nbaseline. Noise-model simulations confirm and strengthen these efficiency gains\n(up to 45 percent) when using an optimized \"swap-out\" design. These results\ndemonstrate that ICO can provide practical, coherence-preserving resource\nmanagement, significantly reducing runtime costs and noise accumulation in\nnear-term quantum algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2506.00647v2",
    "published": "2025-05-31T17:33:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00646v1",
    "title": "$F$-injectivity does not imply $F$-fullness in normal domains",
    "authors": [
      "Alessandro De Stefani",
      "Thomas Polstra",
      "Austyn Simpson"
    ],
    "abstract": "We construct examples of noetherian three-dimensional local geometrically\nnormal domains of prime characteristic which are $F$-injective but not\n$F$-full. Along the way, we find examples of two-dimensional local\ngeometrically normal domains which are $F$-injective but not\n$F$-anti-nilpotent. A crucial theme of our constructions is the behavior of\n$F$-injectivity along a purely inseparable finite base change.",
    "pdf_url": "http://arxiv.org/pdf/2506.00646v1",
    "published": "2025-05-31T17:32:45+00:00",
    "categories": [
      "math.AC"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00645v1",
    "title": "AWML: An Open-Source ML-based Robotics Perception Framework to Deploy for ROS-based Autonomous Driving Software",
    "authors": [
      "Satoshi Tanaka",
      "Samrat Thapa",
      "Kok Seang Tan",
      "Amadeusz Szymko",
      "Lobos Kenzo",
      "Koji Minoda",
      "Shintaro Tomie",
      "Kotaro Uetake",
      "Guolong Zhang",
      "Isamu Yamashita",
      "Takamasa Horibe"
    ],
    "abstract": "In recent years, machine learning technologies have played an important role\nin robotics, particularly in the development of autonomous robots and\nself-driving vehicles. As the industry matures, robotics frameworks like ROS 2\nhave been developed and provides a broad range of applications from research to\nproduction. In this work, we introduce AWML, a framework designed to support\nMLOps for robotics. AWML provides a machine learning infrastructure for\nautonomous driving, supporting not only the deployment of trained models to\nrobotic systems, but also an active learning pipeline that incorporates\nauto-labeling, semi-auto-labeling, and data mining techniques.",
    "pdf_url": "http://arxiv.org/pdf/2506.00645v1",
    "published": "2025-05-31T17:29:32+00:00",
    "categories": [
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00644v1",
    "title": "Clinical Annotations for Automatic Stuttering Severity Assessment",
    "authors": [
      "Ana Rita Valente",
      "Rufael Marew",
      "Hawau Olamide Toyin",
      "Hamdan Al-Ali",
      "Anelise Bohnen",
      "Inma Becerra",
      "Elsa Marta Soares",
      "Goncalo Leal",
      "Hanan Aldarmaki"
    ],
    "abstract": "Stuttering is a complex disorder that requires specialized expertise for\neffective assessment and treatment. This paper presents an effort to enhance\nthe FluencyBank dataset with a new stuttering annotation scheme based on\nestablished clinical standards. To achieve high-quality annotations, we hired\nexpert clinicians to label the data, ensuring that the resulting annotations\nmirror real-world clinical expertise. The annotations are multi-modal,\nincorporating audiovisual features for the detection and classification of\nstuttering moments, secondary behaviors, and tension scores. In addition to\nindividual annotations, we additionally provide a test set with highly reliable\nannotations based on expert consensus for assessing individual annotators and\nmachine learning models. Our experiments and analysis illustrate the complexity\nof this task that necessitates extensive clinical expertise for valid training\nand evaluation of stuttering assessment models.",
    "pdf_url": "http://arxiv.org/pdf/2506.00644v1",
    "published": "2025-05-31T17:18:20+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.14793v1",
    "title": "Protein Language Model Zero-Shot Fitness Predictions are Improved by Inference-only Dropout",
    "authors": [
      "Aditya Ravuri",
      "Neil D. Lawrence"
    ],
    "abstract": "Protein Language Models (PLMs) such as ESM2 have been shown to be capable of\nzero-shot prediction of critical scalar properties of proteins (fitness). In\nthis work, we show that injecting a dropout layer at inference time between a\nPLM's featurizer/embedding layer and its transformer, and averaging its output\nakin to Monte-Carlo dropout increases zero-shot performance on a subset of the\nProteinGym dataset. This is the case even when the model was not trained with\ndropouts to begin with, and does not require retraining or finetuning of the\nPLM. A dropout of 0.1 seems performant across all models.",
    "pdf_url": "http://arxiv.org/pdf/2506.14793v1",
    "published": "2025-05-31T17:16:59+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00643v2",
    "title": "SATA-BENCH: Select All That Apply Benchmark for Multiple Choice Questions",
    "authors": [
      "Weijie Xu",
      "Shixian Cui",
      "Xi Fang",
      "Chi Xue",
      "Stephanie Eckman",
      "Chandan K. Reddy"
    ],
    "abstract": "Large language models (LLMs) are increasingly evaluated on single-answer\nmultiple-choice tasks, yet many real-world problems require identifying all\ncorrect answers from a set of options. This capability remains underexplored.\nWe introduce SATA-BENCH, the first dedicated benchmark for evaluating LLMs on\nSelect All That Apply (SATA) questions across diverse domains, including\nreading comprehension, law, and biomedicine. Our evaluation of 27 open-source\nand proprietary models reveals a significant gap: even the strongest model\nachieves only 41.8% exact match, exposing LLMs' inability to reliably identify\nall correct answers. We find that this weakness stems from two core challenges:\nselection bias - models favor certain choices regardless of content, and count\nbias - models fail to predict the correct number of answers. To address these\nissues, we propose Choice Funnel, a decoding strategy that combines token\ndebiasing with adaptive thresholding to guide models toward complete and\naccurate selections. Choice Funnel achieves up to 29% higher exact match than\ncompetitive baselines while reducing inference cost by over 64%. Our findings\nexpose fundamental limitations in current LLMs and introduce a new framework\nfor diagnosing and improving multi-answer reasoning. We release SATA-BENCH and\nChoice Funnel to promote LLM development for robust decision-making in\nrealistic, multi-answer applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00643v2",
    "published": "2025-05-31T17:14:21+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T01",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00642v1",
    "title": "Rethinking Neural-based Matrix Inversion: Why can't, and Where can",
    "authors": [
      "Yuliang Ji",
      "Jian Wu",
      "Yuanzhe Xi"
    ],
    "abstract": "Deep neural networks have achieved substantial success across various\nscientific computing tasks. A pivotal challenge within this domain is the rapid\nand parallel approximation of matrix inverses, critical for numerous\napplications. Despite significant progress, there currently exists no universal\nneural-based method for approximating matrix inversion. This paper presents a\ntheoretical analysis demonstrating the fundamental limitations of neural\nnetworks in developing a general matrix inversion model. We expand the class of\nLipschitz functions to encompass a wider array of neural network models,\nthereby refining our theoretical approach. Moreover, we delineate specific\nconditions under which neural networks can effectively approximate matrix\ninverses. Our theoretical results are supported by experimental results from\ndiverse matrix datasets, exploring the efficacy of neural networks in\naddressing the matrix inversion challenge.",
    "pdf_url": "http://arxiv.org/pdf/2506.00642v1",
    "published": "2025-05-31T17:11:15+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00641v1",
    "title": "AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents",
    "authors": [
      "Hanjun Luo",
      "Shenyu Dai",
      "Chiming Ni",
      "Xinfeng Li",
      "Guibin Zhang",
      "Kun Wang",
      "Tongliang Liu",
      "Hanan Salam"
    ],
    "abstract": "Despite the rapid advancement of LLM-based agents, the reliable evaluation of\ntheir safety and security remains a significant challenge. Existing rule-based\nor LLM-based evaluators often miss dangers in agents' step-by-step actions,\noverlook subtle meanings, fail to see how small issues compound, and get\nconfused by unclear safety or security rules. To overcome this evaluation\ncrisis, we introduce \\sys, a universal, training-free, memory-augmented\nreasoning framework that empowers LLM evaluators to emulate human expert\nevaluators. \\sys constructs an experiential memory by having an LLM adaptively\nextract structured semantic features (e.g., scenario, risk, behavior) and\ngenerate associated chain-of-thought reasoning traces for past interactions. A\nmulti-stage, context-aware retrieval-augmented generation process then\ndynamically retrieves the most relevant reasoning experiences to guide the LLM\nevaluator's assessment of new cases. Moreover, we developed \\data, the first\nbenchmark designed to check how well LLM-based evaluators can spot both safety\nrisks and security threats. \\data comprises \\textbf{2293} meticulously\nannotated interaction records, covering \\textbf{15} risk types across\n\\textbf{29} application scenarios. A key feature of \\data is its nuanced\napproach to ambiguous risk situations, employing ``Strict'' and ``Lenient''\njudgment standards. Experiments demonstrate that \\sys not only consistently\nimproves the evaluation performance of LLMs across all benchmarks but also sets\na new state-of-the-art in LLM-as-a-judge for agent safety and security,\nachieving human-level accuracy. Our work is openly openly accessible.",
    "pdf_url": "http://arxiv.org/pdf/2506.00641v1",
    "published": "2025-05-31T17:10:23+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00640v1",
    "title": "Qualitative analysis of a quasi-magnetic universe",
    "authors": [
      "Alan G. Cesar",
      "Mario Novello",
      "Eduardo Bittencourt",
      "Fernando A. Franco"
    ],
    "abstract": "We investigate the cosmological dynamics induced by nonlinear electrodynamics\n(NLED) in a homogeneous and isotropic universe, focusing on the role of\nprimordial electromagnetic fields with random spatial orientations. Building\nupon a generalization of the Tolman-Ehrenfest averaging procedure, we derive a\nmodified energy-momentum tensor consistent with FLRW symmetry, incorporating\nthe influence of the dual invariant G and its statistical contributions. A\nspecific NLED model with quatratic corrections to Maxwell's Lagrangian is\nconsidered, giving rise to what we define as quasi-magnetic universe (qMU),\ninterpolating between purely magnetic and statistically null field\nconfigurations. We analyze the resulting cosmological dynamics through\nqualitative methods. By casting the equations into autonomous dynamical\nsystems, we identify the equilibrium points, determine their stability, and\nstudy the behavior of solutions under various spatial curvatures. Our findings\nreveal the existence of bouncing and cyclic solutions, regions where energy\nconditions are violated, and scenarios of accelerated expansion. Special\nattention is given to two limiting cases: the Magnetic Universe (MU) and the\nStatistical Null Universe (SNU), both of which exhibit qualitatively distinct\nphase portraits and energy-condition behavior. This work provides a\ncomprehensive framework for understanding the influence of nonlinear\nelectromagnetic fields in the early universe and opens avenues for exploring\ntheir observational consequences.",
    "pdf_url": "http://arxiv.org/pdf/2506.00640v1",
    "published": "2025-05-31T17:08:43+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.00639v2",
    "title": "Regularization Prescription for the Mixing Between Nonlocal Gluon and Quark Operators",
    "authors": [
      "Yao Ji",
      "Zhuoyi Pang",
      "Fei Yao",
      "Jian-Hui Zhang"
    ],
    "abstract": "It is well-known that in the study of mixing between nonlocal gluon and quark\nbilinear operators there exists an ambiguity when relating coordinate space and\nmomentum space results, which can be conveniently resolved through Mellin\nmoments matching in both spaces. In this work, we show that this ambiguity is\ndue to the lack of a proper regularization prescription of the singularity that\narises when the separation between the gluon/quark fields approaches zero. We\nthen demonstrate that dimensional regularization resolves this issue and yields\nconsistent results in both coordinate and momentum space. This prescription is\nalso compatible with lattice extractions of parton distributions from nonlocal\noperators.",
    "pdf_url": "http://arxiv.org/pdf/2506.00639v2",
    "published": "2025-05-31T17:04:15+00:00",
    "categories": [
      "hep-ph",
      "hep-lat",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00638v1",
    "title": "${\\varepsilon}$-optimality in reverse convex optimization",
    "authors": [
      "M. El Maghri",
      "H. Sellak"
    ],
    "abstract": "We characterize approximate global optimal solutions (${\\varepsilon}$-optima)\nto reverse optimization problems, namely, problems whose non-convex constraint\nis of the form $h(x) \\geq 0$. This issue has not been addressed previously in\nthe literature. Our idea consists of converting the reverse program into an\nunconstrained bicriteria DC program. The main condition presented is obtained\nin terms of Fenchel's ${\\varepsilon}$-subdifferentials thanks to an earlier\nresult in difference vector optimization by El Maghri. This extends and\nimproves similar results from the literature dealing with exact (${\\varepsilon}\n= 0$) solutions. Moreover, as we consider functions with extended values, our\napproach also applies to reverse problems subject to additional convex\nconstraints, provided that Moreau-Rockafellar or Attouch-Br\\'ezis constraint\nqualification conditions are satisfied. Similarly, new results for the special\ncase of a nonlinear equality constraint $h(x) = 0$ are also obtained.",
    "pdf_url": "http://arxiv.org/pdf/2506.00638v1",
    "published": "2025-05-31T17:02:29+00:00",
    "categories": [
      "math.OC",
      "90C26 (Primary) 90C29, 90C46 (Secondary)",
      "F.4.1"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00637v2",
    "title": "Improving the Calibration of Confidence Scores in Text Generation Using the Output Distribution's Characteristics",
    "authors": [
      "Lorenzo Jaime Yu Flores",
      "Ori Ernst",
      "Jackie Chi Kit Cheung"
    ],
    "abstract": "Well-calibrated model confidence scores can improve the usefulness of text\ngeneration models. For example, users can be prompted to review predictions\nwith low confidence scores, to prevent models from returning bad or potentially\ndangerous predictions. However, confidence metrics are not always well\ncalibrated in text generation. One reason is that in generation, there can be\nmany valid answers, which previous methods do not always account for. Hence, a\nconfident model could distribute its output probability among multiple\nsequences because they are all valid. We propose task-agnostic confidence\nmetrics suited to generation, which rely solely on the probabilities associated\nwith the model outputs without the need for further fine-tuning or heuristics.\nUsing these, we are able to improve the calibration of BART and Flan-T5 on\nsummarization, translation, and QA datasets.",
    "pdf_url": "http://arxiv.org/pdf/2506.00637v2",
    "published": "2025-05-31T17:01:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00636v1",
    "title": "ViToSA: Audio-Based Toxic Spans Detection on Vietnamese Speech Utterances",
    "authors": [
      "Huy Ba Do",
      "Vy Le-Phuong Huynh",
      "Luan Thanh Nguyen"
    ],
    "abstract": "Toxic speech on online platforms is a growing concern, impacting user\nexperience and online safety. While text-based toxicity detection is\nwell-studied, audio-based approaches remain underexplored, especially for\nlow-resource languages like Vietnamese. This paper introduces ViToSA\n(Vietnamese Toxic Spans Audio), the first dataset for toxic spans detection in\nVietnamese speech, comprising 11,000 audio samples (25 hours) with accurate\nhuman-annotated transcripts. We propose a pipeline that combines ASR and toxic\nspans detection for fine-grained identification of toxic content. Our\nexperiments show that fine-tuning ASR models on ViToSA significantly reduces\nWER when transcribing toxic speech, while the text-based toxic spans detection\n(TSD) models outperform existing baselines. These findings establish a novel\nbenchmark for Vietnamese audio-based toxic spans detection, paving the way for\nfuture research in speech content moderation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00636v1",
    "published": "2025-05-31T17:01:18+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.03193v1",
    "title": "Human Fall Detection using Transfer Learning-based 3D CNN",
    "authors": [
      "Ekram Alam",
      "Abu Sufian",
      "Paramartha Dutta",
      "Marco Leo"
    ],
    "abstract": "Unintentional or accidental falls are one of the significant health issues in\nsenior persons. The population of senior persons is increasing steadily. So,\nthere is a need for an automated fall detection monitoring system. This paper\nintroduces a vision-based fall detection system using a pre-trained 3D CNN.\nUnlike 2D CNN, 3D CNN extracts not only spatial but also temporal features. The\nproposed model leverages the original learned weights of a 3D CNN model\npre-trained on the Sports1M dataset to extract the spatio-temporal features.\nOnly the SVM classifier was trained, which saves the time required to train the\n3D CNN. Stratified shuffle five split cross-validation has been used to split\nthe dataset into training and testing data. Extracted features from the\nproposed 3D CNN model were fed to an SVM classifier to classify the activity as\nfall or ADL. Two datasets, GMDCSA and CAUCAFall, were utilized to conduct the\nexperiment. The source code for this work can be accessed via the following\nlink: https://github.com/ekramalam/HFD_3DCNN.",
    "pdf_url": "http://arxiv.org/pdf/2506.03193v1",
    "published": "2025-05-31T16:58:12+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00635v1",
    "title": "Learning with Calibration: Exploring Test-Time Computing of Spatio-Temporal Forecasting",
    "authors": [
      "Wei Chen",
      "Yuxuan Liang"
    ],
    "abstract": "Spatio-temporal forecasting is crucial in many domains, such as\ntransportation, meteorology, and energy. However, real-world scenarios\nfrequently present challenges such as signal anomalies, noise, and\ndistributional shifts. Existing solutions primarily enhance robustness by\nmodifying network architectures or training procedures. Nevertheless, these\napproaches are computationally intensive and resource-demanding, especially for\nlarge-scale applications. In this paper, we explore a novel test-time computing\nparadigm, namely learning with calibration, ST-TTC, for spatio-temporal\nforecasting. Through learning with calibration, we aim to capture periodic\nstructural biases arising from non-stationarity during the testing phase and\nperform real-time bias correction on predictions to improve accuracy.\nSpecifically, we first introduce a spectral-domain calibrator with\nphase-amplitude modulation to mitigate periodic shift and then propose a flash\nupdating mechanism with a streaming memory queue for efficient test-time\ncomputation. ST-TTC effectively bypasses complex training-stage techniques,\noffering an efficient and generalizable paradigm. Extensive experiments on\nreal-world datasets demonstrate the effectiveness, universality, flexibility\nand efficiency of our proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2506.00635v1",
    "published": "2025-05-31T16:48:27+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00634v1",
    "title": "Social Construction of Urban Space: Understanding Neighborhood Boundaries Using Rental Listings",
    "authors": [
      "Adam Visokay",
      "Ruth Bagley",
      "Ian Kennedy",
      "Chris Hess",
      "Kyle Crowder",
      "Rob Voigt",
      "Denis Peskoff"
    ],
    "abstract": "Rental listings offer a unique window into how urban space is socially\nconstructed through language. We analyze Chicago Craigslist rental\nadvertisements from 2018 to 2024 to examine how listing agents characterize\nneighborhoods, identifying mismatches between institutional boundaries and\nneighborhood claims. Through manual and large language model annotation, we\nclassify unstructured listings from Craigslist according to their neighborhood.\nGeospatial analysis reveals three distinct patterns: properties with\nconflicting neighborhood designations due to competing spatial definitions,\nborder properties with valid claims to adjacent neighborhoods, and ``reputation\nlaundering\" where listings claim association with distant, desirable\nneighborhoods. Through topic modeling, we identify patterns that correlate with\nspatial positioning: listings further from neighborhood centers emphasize\ndifferent amenities than centrally-located units. Our findings demonstrate that\nnatural language processing techniques can reveal how definitions of urban\nspaces are contested in ways that traditional methods overlook.",
    "pdf_url": "http://arxiv.org/pdf/2506.00634v1",
    "published": "2025-05-31T16:42:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00633v1",
    "title": "Text-to-CT Generation via 3D Latent Diffusion Model with Contrastive Vision-Language Pretraining",
    "authors": [
      "Daniele Molino",
      "Camillo Maria Caruso",
      "Filippo Ruffini",
      "Paolo Soda",
      "Valerio Guarrasi"
    ],
    "abstract": "Objective: While recent advances in text-conditioned generative models have\nenabled the synthesis of realistic medical images, progress has been largely\nconfined to 2D modalities such as chest X-rays. Extending text-to-image\ngeneration to volumetric Computed Tomography (CT) remains a significant\nchallenge, due to its high dimensionality, anatomical complexity, and the\nabsence of robust frameworks that align vision-language data in 3D medical\nimaging. Methods: We introduce a novel architecture for Text-to-CT generation\nthat combines a latent diffusion model with a 3D contrastive vision-language\npretraining scheme. Our approach leverages a dual-encoder CLIP-style model\ntrained on paired CT volumes and radiology reports to establish a shared\nembedding space, which serves as the conditioning input for generation. CT\nvolumes are compressed into a low-dimensional latent space via a pretrained\nvolumetric VAE, enabling efficient 3D denoising diffusion without requiring\nexternal super-resolution stages. Results: We evaluate our method on the\nCT-RATE dataset and conduct a comprehensive assessment of image fidelity,\nclinical relevance, and semantic alignment. Our model achieves competitive\nperformance across all tasks, significantly outperforming prior baselines for\ntext-to-CT generation. Moreover, we demonstrate that CT scans synthesized by\nour framework can effectively augment real data, improving downstream\ndiagnostic performance. Conclusion: Our results show that modality-specific\nvision-language alignment is a key component for high-quality 3D medical image\ngeneration. By integrating contrastive pretraining and volumetric diffusion,\nour method offers a scalable and controllable solution for synthesizing\nclinically meaningful CT volumes from text, paving the way for new applications\nin data augmentation, medical education, and automated clinical simulation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00633v1",
    "published": "2025-05-31T16:41:55+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00632v1",
    "title": "Nilpotent graphs over skew PBW extensions",
    "authors": [
      "Sebastián Higuera",
      "Armando Reyes"
    ],
    "abstract": "We investigate the diameter and girth of the nilpotent graph for skew PBW\nextensions over $2$-primal rings, generalizing similar results on skew\npolynomial rings. Under certain compatibility conditions, we establish bounds\nfor the diameter of the nilpotent graph and prove invariance of the girth under\npolynomial extensions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00632v1",
    "published": "2025-05-31T16:41:36+00:00",
    "categories": [
      "math.RA",
      "05C12, 05C20, 13A99, 16S15, 16S30, 16S32, 16S36, 16S38 16U99"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00631v2",
    "title": "Phase-space distortion as a key to unraveling galactic bar buckling",
    "authors": [
      "Viktor D. Zozulia",
      "Natalia Ya. Sotnikova",
      "Anton A. Smirnov"
    ],
    "abstract": "For the first time, we investigate the resonant structure of $N$-body\ngalactic bar at the stage of buckling using action-angle variables. We studied\nthe evolution of vertical actions ($J_z$) and angles associated with vertical\nresonance ($\\theta_\\mathrm{res}=\\theta_z - \\theta_R$) for all orbits in the\nbar. For this purpose, we divide the orbits into types according to the\nbehavior (libration or circulation) of their resonant angle with respect to\nfixed points $\\theta_\\mathrm{res}=0$ and $\\pi$ (vertical resonance). We show\nthat during buckling, flat bar orbits circulating with increasing\n$\\theta_\\mathrm{res}$ transformed into banana-shaped librating orbits (resonant\ncapture) or circulating orbits with decreasing $\\theta_\\mathrm{res}$ (resonant\nheating). The orbital transformation is accompanied by an increase in $J_z$ and\nthe formation of a boxy/peanut-shaped (B/PS) bulge. During buckling, the phase\nspace $J_z - \\theta_\\mathrm{res}$ undergoes a distortion creating an asymmetry\nin the position of the fixed points $\\theta_\\mathrm{res}=0$ and $\\pi$ and in\nbanana-shaped orbits near these points. The fixed point $\\theta_\\mathrm{res}=0$\nmay disappear completely. This also breaks the symmetry between the orbits,\nwhich are captured into resonance or go into circulation with decreasing\n$\\theta_\\mathrm{res}$ near $\\theta_\\mathrm{res}=0$ and $\\pi$. At the same time,\nnear $\\theta_\\mathrm{res}=0$, banana-shaped orbits with low vertical action\n$J_z$ appear. This reopens the path of orbital transformation through the fixed\npoint $\\theta_\\mathrm{res}=0$. The phase space transformation and orbit\ntransformation occur in a coordinated manner and lead to smoothing of phase\nspace perturbations and restoration of symmetry between orbits.",
    "pdf_url": "http://arxiv.org/pdf/2506.00631v2",
    "published": "2025-05-31T16:39:11+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00630v1",
    "title": "Probabilistic Forecasting for Building Energy Systems using Time-Series Foundation Models",
    "authors": [
      "Young Jin Park",
      "Francois Germain",
      "Jing Liu",
      "Ye Wang",
      "Toshiaki Koike-Akino",
      "Gordon Wichern",
      "Navid Azizan",
      "Christopher R. Laughman",
      "Ankush Chakrabarty"
    ],
    "abstract": "Decision-making in building energy systems critically depends on the\npredictive accuracy of relevant time-series models. In scenarios lacking\nextensive data from a target building, foundation models (FMs) represent a\npromising technology that can leverage prior knowledge from vast and diverse\npre-training datasets to construct accurate probabilistic predictors for use in\ndecision-making tools. This paper investigates the applicability and\nfine-tuning strategies of time-series foundation models (TSFMs) in building\nenergy forecasting. We analyze both full fine-tuning and parameter-efficient\nfine-tuning approaches, particularly low-rank adaptation (LoRA), by using\nreal-world data from a commercial net-zero energy building to capture signals\nsuch as room occupancy, carbon emissions, plug loads, and HVAC energy\nconsumption. Our analysis reveals that the zero-shot predictive performance of\nTSFMs is generally suboptimal. To address this shortcoming, we demonstrate that\nemploying either full fine-tuning or parameter-efficient fine-tuning\nsignificantly enhances forecasting accuracy, even with limited historical data.\nNotably, fine-tuning with low-rank adaptation (LoRA) substantially reduces\ncomputational costs without sacrificing accuracy. Furthermore, fine-tuned TSFMs\nconsistently outperform state-of-the-art deep forecasting models (e.g.,\ntemporal fusion transformers) in accuracy, robustness, and generalization\nacross varying building zones and seasonal conditions. These results underline\nthe efficacy of TSFMs for practical, data-constrained building energy\nmanagement systems, enabling improved decision-making in pursuit of energy\nefficiency and sustainability.",
    "pdf_url": "http://arxiv.org/pdf/2506.00630v1",
    "published": "2025-05-31T16:38:29+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00629v1",
    "title": "Foundations of the ionization potential condition for localized electron removal in density functional theory",
    "authors": [
      "Guy Ohad",
      "María Camarasa-Gómez",
      "Jeffrey B. Neaton",
      "Ashwin Ramasubramaniam",
      "Tim Gould",
      "Leeor Kronik"
    ],
    "abstract": "Optimal tuning of functional parameters in density functional theory\napproximations, based on enforcing the ionization potential theorem, has\nemerged as the method of choice for the non-empirical prediction of the\nelectronic structure of finite systems. This method has recently been extended\nto the bulk limit, based on an ansatz that generalizes the ionization potential\ntheorem to the removal of an electron from a localized Wannier orbital. This\nWannier-localization based optimal tuning method has been shown to be highly\nsuccessful for a wide range of periodic systems, accurately predicting\nelectronic and optical properties. However, a rigorous theoretical\njustification for its foundational ansatz has been lacking. Here, we establish\nan ionization potential condition for the removal of a localized electron, by\nextending the piecewise linearity and Janak's theorems in density functional\ntheory. We also provide numerical evidence supporting our theory.",
    "pdf_url": "http://arxiv.org/pdf/2506.00629v1",
    "published": "2025-05-31T16:36:04+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00628v2",
    "title": "LID Models are Actually Accent Classifiers: Implications and Solutions for LID on Accented Speech",
    "authors": [
      "Niyati Bafna",
      "Matthew Wiesner"
    ],
    "abstract": "Prior research indicates that LID model performance significantly declines on\naccented speech; however, the specific causes, extent, and characterization of\nthese errors remain under-explored. (i) We identify a common failure mode on\naccented speech whereby LID systems often misclassify L2 accented speech as the\nspeaker's native language or a related language. (ii) We present evidence\nsuggesting that state-of-the-art models are invariant to permutations of short\nspans of speech, implying they classify on the basis of short phonotactic\nfeatures indicative of accent rather than language. Our analysis reveals a\nsimple method to enhance model robustness to accents through input chunking.\n(iii) We present an approach that integrates sequence-level information into\nour model without relying on monolingual ASR systems; this reduces\naccent-language confusion and significantly enhances performance on accented\nspeech while maintaining comparable results on standard LID.",
    "pdf_url": "http://arxiv.org/pdf/2506.00628v2",
    "published": "2025-05-31T16:35:40+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00627v1",
    "title": "The Disparate Effects of Partial Information in Bayesian Strategic Learning",
    "authors": [
      "Srikanth Avasarala",
      "Serena Wang",
      "Juba Ziani"
    ],
    "abstract": "We study how partial information about scoring rules affects fairness in\nstrategic learning settings. In strategic learning, a learner deploys a scoring\nrule, and agents respond strategically by modifying their features -- at some\ncost -- to improve their outcomes. However, in our work, agents do not observe\nthe scoring rule directly; instead, they receive a noisy signal of said rule.\nWe consider two different agent models: (i) naive agents, who take the noisy\nsignal at face value, and (ii) Bayesian agents, who update a prior belief based\non the signal.\n  Our goal is to understand how disparities in outcomes arise between groups\nthat differ in their costs of feature modification, and how these disparities\nvary with the level of transparency of the learner's rule. For naive agents, we\nshow that utility disparities can grow unboundedly with noise, and that the\ngroup with lower costs can, perhaps counter-intuitively, be disproportionately\nharmed under limited transparency. In contrast, for Bayesian agents,\ndisparities remain bounded. We provide a full characterization of disparities\nacross groups as a function of the level of transparency and show that they can\nvary non-monotonically with noise; in particular, disparities are often\nminimized at intermediate levels of transparency. Finally, we extend our\nanalysis to settings where groups differ not only in cost, but also in prior\nbeliefs, and study how this asymmetry influences fairness.",
    "pdf_url": "http://arxiv.org/pdf/2506.00627v1",
    "published": "2025-05-31T16:34:30+00:00",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00626v1",
    "title": "Helmet ultrasound for brain imaging in post-hemicraniectomy patients",
    "authors": [
      "Yang Zhang",
      "Karteekeya Sastry",
      "Iyla Rossi",
      "Joshua Olick-Gibson",
      "Jonathan J. Russin",
      "Charles Y. Liu",
      "Lihong V. Wang"
    ],
    "abstract": "Noninvasive imaging deep into the adult brain at submillimeter and\nmillisecond scales remains a challenge in medical imaging. Here, we report a\nhelmet based ultrasound brain imager built from a customized helmet, a scanned\nultrasound array, and three dimensional printing for real time imaging of human\nbrain anatomical and functional information. Through its application to post\nhemicraniectomy patients in a sitting position, we achieved volumetric brain\ntissue structural, vascular, and blood flow images at centimeter scale depths\nwith submillimeter and millisecond spatiotemporal resolutions. We also\ndemonstrated the system capability to track cerebral blood flow over repeated\nimaging sessions, including during motion prone conditions. Our brain imager\ncircumvents the skull and bridges the gap between high resolution human brain\nimaging and wearable convenience. This imager may serve as a platform for\nfurther investigations into human brain dynamics in post hemicraniectomy\npatients and offer insights into the brain that could surpass those obtained\nfrom non human primate studies.",
    "pdf_url": "http://arxiv.org/pdf/2506.00626v1",
    "published": "2025-05-31T16:33:30+00:00",
    "categories": [
      "physics.med-ph",
      "eess.SP"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00625v1",
    "title": "Long-Tailed Visual Recognition via Permutation-Invariant Head-to-Tail Feature Fusion",
    "authors": [
      "Mengke Li",
      "Zhikai Hu",
      "Yang Lu",
      "Weichao Lan",
      "Yiu-ming Cheung",
      "Hui Huang"
    ],
    "abstract": "The imbalanced distribution of long-tailed data presents a significant\nchallenge for deep learning models, causing them to prioritize head classes\nwhile neglecting tail classes. Two key factors contributing to low recognition\naccuracy are the deformed representation space and a biased classifier,\nstemming from insufficient semantic information in tail classes. To address\nthese issues, we propose permutation-invariant and head-to-tail feature fusion\n(PI-H2T), a highly adaptable method. PI-H2T enhances the representation space\nthrough permutation-invariant representation fusion (PIF), yielding more\nclustered features and automatic class margins. Additionally, it adjusts the\nbiased classifier by transferring semantic information from head to tail\nclasses via head-to-tail fusion (H2TF), improving tail class diversity.\nTheoretical analysis and experiments show that PI-H2T optimizes both the\nrepresentation space and decision boundaries. Its plug-and-play design ensures\nseamless integration into existing methods, providing a straightforward path to\nfurther performance improvements. Extensive experiments on long-tailed\nbenchmarks confirm the effectiveness of PI-H2T.",
    "pdf_url": "http://arxiv.org/pdf/2506.00625v1",
    "published": "2025-05-31T16:31:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.04247v1",
    "title": "The GAIN Model: A Nature-Inspired Neural Network Framework Based on an Adaptation of the Izhikevich Model",
    "authors": [
      "Gage K. R. Hooper"
    ],
    "abstract": "While many neural networks focus on layers to process information, the GAIN\nmodel uses a grid-based structure to improve biological plausibility and the\ndynamics of the model. The grid structure helps neurons to interact with their\nclosest neighbors and improve their connections with one another, which is seen\nin biological neurons. While also being implemented with the Izhikevich model\nthis approach allows for a computationally efficient and biologically accurate\nsimulation that can aid in the development of neural networks, large scale\nsimulations, and the development in the neuroscience field. This adaptation of\nthe Izhikevich model can improve the dynamics and accuracy of the model,\nallowing for its uses to be specialized but efficient.",
    "pdf_url": "http://arxiv.org/pdf/2506.04247v1",
    "published": "2025-05-31T16:30:34+00:00",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.NE",
      "92B20, 37N25, 68T05",
      "I.2.6; I.5.1; I.6.3"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00624v2",
    "title": "Real-Time Sounding in ISAC networks: Design and Implementation of a Multi-Node Testbed with Synchronized Airborne and Ground-Based Sensors",
    "authors": [
      "Julia Beuster",
      "Carsten Andrich",
      "Sebastian Giehl",
      "Marc Miranda",
      "Lorenz Mohr",
      "Dieter Novotny",
      "Tom Kaufmann",
      "Christian Schneider",
      "Reiner S. Thomä"
    ],
    "abstract": "As integrated sensing and communication (ISAC) capabilities become more\nprevalent in the mobile 6G radio landscape, there is a substantial opportunity\nto enhance situational awareness across diverse applications through\nmulti-static radar sensing within meshed ISAC networks. To facilitate the\ndevelopment and testing of detection and localization algorithms across diverse\nscenarios, this paper introduces a synchronized distributed channel sounding\ntestbed with airborne and ground-based multi-channel transceiver nodes with\ncentimeter-level positioning accuracy enabled by real-time kinematic (RTK) and\ninertial navigation system (INS) data. Our modular experimental measurement\nsystem is designed to include stationary sensor nodes and light-weight to\nmedium-weight mobile nodes deployable on unmanned aerial vehicles (UAVs), cars,\npedestrians, and cyclists. Utilizing commercial off-the-shelf (COTS) hardware,\nspecifically software defined radios (SDRs), the testbed encourages\nreproducibility in academic research laboratories. We detail the individual\nmodules and integration steps required to achieve the specified performance.\nThe testbed's capabilities are validated through a real-world measurement\ncampaign, including stationary and flying sensor nodes, aimed at detecting\nradar targets such as vertical take-off and landing (VTOL) aircrafts, small\nhexacopters, cars and vulnerable road users (VRUs) in air-to-air (A2A) and\nair-to-ground (A2G) scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.00624v2",
    "published": "2025-05-31T16:28:51+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00623v1",
    "title": "Spins of Black Holes in X-ray Binaries and the Tension with the Gravitational Wave Measurements",
    "authors": [
      "Andrzej A. Zdziarski",
      "Gregoire Marcel",
      "Alexandra Veledina",
      "Aleksandra Olejak",
      "Debora Lancova"
    ],
    "abstract": "We review current challenges in understanding the values and origin of the\nspins of black holes in binaries. A key finding of the gravitational-wave\nobservatories is that premerger black holes in binaries have low spin values,\nwith an average dimensionless spin parameter of $a_*\\sim$0.1-0.2. Furthermore,\nthe spins in the first-born black holes appear lower than in the second-born\nones. This implies that the natal spins of black holes are generally low, and\nthe angular momentum transport in massive stars is efficient. On the other\nhand, most of the published spins in X-ray binaries are very high, $a_*\\gtrsim\n0.7$. This is the case, in particular, for binaries with high-mass donors\n(potential progenitors of mergers), where their published spins range from 0.8\nto 1.0, while their short lifetimes prevent significant spin-up by accretion.\nThose with low-mass donors could be spun-up to $a_*\\gtrsim 0.7$ by accretion,\nbut only if the donor initial masses were more than several solar masses, which\nremains unproven. However, we find the existing methods of spin measurements\nsuffer from significant systematic errors. The method relying on relativistic\nX-ray line broadening is based on the separation of the observed spectra into\nthe incident and reflected ones, which is intrinsically highly uncertain. The\nmethod of spectral fitting accretion disk continua uses models that predict the\ndisk to be highly unstable, while stability is observed. Improved stable models\ngive the disk temperatures higher than the standard models, and consequently\npredict lower spins. We postulate that the published spin measurements in X-ray\nbinaries are uncertain. We hypothesize that the spins of the binaries with\nhigh-mass donors are low, while those with low-mass donors have a broader spin\ndistribution, ranging from low to high, including high spins as required to\npower relativistic jets.",
    "pdf_url": "http://arxiv.org/pdf/2506.00623v1",
    "published": "2025-05-31T16:24:15+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00622v2",
    "title": "Improving Dialogue State Tracking through Combinatorial Search for In-Context Examples",
    "authors": [
      "Haesung Pyun",
      "Yoonah Park",
      "Yohan Jo"
    ],
    "abstract": "In dialogue state tracking (DST), in-context learning comprises a retriever\nthat selects labeled dialogues as in-context examples and a DST model that uses\nthese examples to infer the dialogue state of the query dialogue. Existing\nmethods for constructing training data for retrievers suffer from three key\nlimitations: (1) the synergistic effect of examples is not considered, (2) the\nlinguistic characteristics of the query are not sufficiently factored in, and\n(3) scoring is not directly optimized for DST performance. Consequently, the\nretriever can fail to retrieve examples that would substantially improve DST\nperformance. To address these issues, we present CombiSearch, a method that\nscores effective in-context examples based on their combinatorial impact on DST\nperformance. Our evaluation on MultiWOZ shows that retrievers trained with\nCombiSearch surpass state-of-the-art models, achieving a 20x gain in data\nefficiency and generalizing well to the SGD dataset. Moreover, CombiSearch\nattains a 12% absolute improvement in the upper bound DST performance over\ntraditional approaches when no retrieval errors are assumed. This significantly\nincreases the headroom for practical DST performance while demonstrating that\nexisting methods rely on suboptimal data for retriever training.",
    "pdf_url": "http://arxiv.org/pdf/2506.00622v2",
    "published": "2025-05-31T16:20:14+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00621v1",
    "title": "Drift, diffusion and divergence",
    "authors": [
      "Laurette S. Tuckerman"
    ],
    "abstract": "Turbulent Taylor-Couette flow displays traces of axisymmetric Taylor vortices\neven at high Reynolds numbers. With this motivation, Feldmann & Avila (2025)\ncarry out long-time numerical simulations of axisymmetric high-Reynolds-number\nTaylor-Couette flow. They find that the Taylor vortices, using the only degree\nof freedom that remains available to them, carry out Brownian motion in the\naxial direction, with a diffusion constant that diverges as the number of rolls\nis reduced below a critical value.",
    "pdf_url": "http://arxiv.org/pdf/2506.00621v1",
    "published": "2025-05-31T16:16:46+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.00620v1",
    "title": "Model Reprogramming Demystified: A Neural Tangent Kernel Perspective",
    "authors": [
      "Ming-Yu Chung",
      "Jiashuo Fan",
      "Hancheng Ye",
      "Qinsi Wang",
      "Wei-Chen Shen",
      "Chia-Mu Yu",
      "Pin-Yu Chen",
      "Sy-Yen Kuo"
    ],
    "abstract": "Model Reprogramming (MR) is a resource-efficient framework that adapts large\npre-trained models to new tasks with minimal additional parameters and data,\noffering a promising solution to the challenges of training large models for\ndiverse tasks. Despite its empirical success across various domains such as\ncomputer vision and time-series forecasting, the theoretical foundations of MR\nremain underexplored. In this paper, we present a comprehensive theoretical\nanalysis of MR through the lens of the Neural Tangent Kernel (NTK) framework.\nWe demonstrate that the success of MR is governed by the eigenvalue spectrum of\nthe NTK matrix on the target dataset and establish the critical role of the\nsource model's effectiveness in determining reprogramming outcomes. Our\ncontributions include a novel theoretical framework for MR, insights into the\nrelationship between source and target models, and extensive experiments\nvalidating our findings.",
    "pdf_url": "http://arxiv.org/pdf/2506.00620v1",
    "published": "2025-05-31T16:15:04+00:00",
    "categories": [
      "cs.LG",
      "68T05, 46E22"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00619v1",
    "title": "Over-the-air Multifunctional Wideband Electromagnetic Signal Processing using Dynamic Scattering Arrays",
    "authors": [
      "Davide Dardari"
    ],
    "abstract": "To meet the stringent requirements of next-generation wireless networks,\nmultiple-input multiple-output (MIMO) technology is expected to become massive\nand pervasive. Unfortunately, this could pose scalability issues in terms of\ncomplexity, power consumption, cost, and processing latency. Therefore, novel\ntechnologies and design approaches, such as the recently introduced holographic\nMIMO paradigm, must be investigated to make future networks sustainable. In\nthis context, we investigate the concept of a dynamic scattering array (DSA) as\na versatile electromagnetic (EM) structure capable of performing joint\nwave-based computing and radiation by moving the processing from the digital\ndomain to the EM domain. We provide a general, wideband analytical framework\nfor modeling the DSA, which includes a power matching network and realistic\nreconfigurable loads. Then we introduce specific design algorithms, and apply\nthem to various use cases. We demonstrate that some recent EM processing\nstructures can be seen as particular cases of our general framework. The\nexamples presented in the numerical results corroborate the potential of DSAs\nto reduce complexity and the number of radiofrequency (RF) chains in\nholographic MIMO systems while achieving enhanced EM wave processing and\nradiation flexibility for tasks such as beamforming and single- and multi-user\nMIMO, also exhibiting superdirectivity capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.00619v1",
    "published": "2025-05-31T16:08:20+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00618v3",
    "title": "RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents",
    "authors": [
      "Jingyi Yang",
      "Shuai Shao",
      "Dongrui Liu",
      "Jing Shao"
    ],
    "abstract": "With the rapid development of multimodal large language models (MLLMs), they\nare increasingly deployed as autonomous computer-use agents capable of\naccomplishing complex computer tasks. However, a pressing issue arises: Can the\nsafety risk principles designed and aligned for general MLLMs in dialogue\nscenarios be effectively transferred to real-world computer-use scenarios?\nExisting research on evaluating the safety risks of MLLM-based computer-use\nagents suffers from several limitations: it either lacks realistic interactive\nenvironments, or narrowly focuses on one or a few specific risk types. These\nlimitations ignore the complexity, variability, and diversity of real-world\nenvironments, thereby restricting comprehensive risk evaluation for\ncomputer-use agents. To this end, we introduce \\textbf{RiOSWorld}, a benchmark\ndesigned to evaluate the potential risks of MLLM-based agents during real-world\ncomputer manipulations. Our benchmark includes 492 risky tasks spanning various\ncomputer applications, involving web, social media, multimedia, os, email, and\noffice software. We categorize these risks into two major classes based on\ntheir risk source: (i) User-originated risks and (ii) Environmental risks. For\nthe evaluation, we evaluate safety risks from two perspectives: (i) Risk goal\nintention and (ii) Risk goal completion. Extensive experiments with multimodal\nagents on \\textbf{RiOSWorld} demonstrate that current computer-use agents\nconfront significant safety risks in real-world scenarios. Our findings\nhighlight the necessity and urgency of safety alignment for computer-use agents\nin real-world computer manipulation, providing valuable insights for developing\ntrustworthy computer-use agents. Our benchmark is publicly available at\nhttps://yjyddq.github.io/RiOSWorld.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2506.00618v3",
    "published": "2025-05-31T16:04:59+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00617v1",
    "title": "Robust Charge-Density Wave Correlations in Optimally-Doped YBa2Cu3Oy",
    "authors": [
      "Rui Zhou",
      "Igor Vinograd",
      "Hadrien Mayffre",
      "Juan Porras",
      "Hun-Ho Kim",
      "Toshinao Loew",
      "Yiran Liu",
      "Matthieu Le Tacon",
      "Bernhard Keimer",
      "Marc-Henri Julien"
    ],
    "abstract": "Charge-density wave (CDW) order is a key property of high-Tc cuprates, but\nits boundaries in the phase diagram and potential connections to other phases\nremain controversial. We report nuclear magnetic resonance (NMR) measurements\nin the prototypical cuprate YBa2Cu3Oy demonstrating that short-range static CDW\norder remains robust at optimal doping (p=0.165), exhibiting a strength and\ntemperature dependence in the normal state similar to those observed at p=0.11\nin the underdoped regime. For an overdoped sample with p=0.184, we detect no\nstatic CDW down to T=Tc, though weak CDW order plausibly emerges below Tc. More\nbroadly, we argue that both quenched disorder and competition with\nsuperconductivity influence the apparent boundary of the CDW phase, likely\ncausing an underestimation of its intrinsic extent in doping. These findings\nchallenge the view that the CDW phase boundary lies below p*=0.19, widely\nregarded as the critical doping where the pseudogap phase ends in YBa2Cu3Oy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00617v1",
    "published": "2025-05-31T16:04:52+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.00616v1",
    "title": "Exploiting Pinching-Antenna Systems in Multicast Communications",
    "authors": [
      "Shan Shan",
      "Chongjun Ouyang",
      "Yong Li",
      "Yuanwei Liu"
    ],
    "abstract": "The pinching-antenna system (PASS) reconfigures wireless links through\npinching beamforming, in which the activated locations of pinching antennas\n(PAs) along dielectric waveguides are optimized. This article investigates the\napplication of PASS in multicast communication systems, where pinching\nbeamforming is designed to maximize the multicast rate. i) In the\nsingle-waveguide scenario, a closed-form solution for the optimal activated\nlocation is derived under the assumption of a single PA and linearly\ndistributed users. Based on this, a closed-form expression for the achievable\nmulticast rate is obtained and proven to be larger than that of conventional\nfixed-location antenna systems. For the general multiple-PA case with arbitrary\nuser distributions, an element-wise alternating optimization (AO) algorithm is\nproposed to design the pinching beamformer. ii) In the multiple-waveguide\nscenario, an AO-based method is developed to jointly optimize the transmit and\npinching beamformers. Specifically, the transmit beamformer is updated using a\nmajorization-minimization (MM) framework together with second-order cone\nprogramming (SOCP), while the pinching beamformer is optimized via element-wise\nsequential refinement. Numerical results are provided to demonstrate that: i)\nPASS achieves significantly higher multicast rates than conventional\nfixed-location antenna systems, particularly when the number of users and\nspatial coverage increase; ii) increasing the number of PAs further improves\nthe multicast performance of PASS.",
    "pdf_url": "http://arxiv.org/pdf/2506.00616v1",
    "published": "2025-05-31T16:00:23+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00615v2",
    "title": "An Incremental Framework for Topological Dialogue Semantics: Efficient Reasoning in Discrete Spaces",
    "authors": [
      "Andreu Ballus Santacana"
    ],
    "abstract": "We present a tractable, incremental framework for topological dialogue\nsemantics based on finite, discrete semantic spaces. Building on the intuition\nthat utterances correspond to open sets and their combinatorial relations form\na simplicial complex (the dialogue nerve), we give a rigorous foundation, a\nprovably correct incremental algorithm for nerve updates, and a reference\nimplementation in the Wolfram Language. The framework supports negative nerve\ncomputation (inconsistency tracking), consequence extraction, and a\ntransparent, set-theoretic ranking of entailments. We clarify which\ncombinatorial properties hold in the discrete case, provide motivating\nexamples, and outline limitations and prospects for richer logical and\ncategorical extensions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00615v2",
    "published": "2025-05-31T15:58:05+00:00",
    "categories": [
      "cs.LO",
      "cs.AI",
      "math.AT",
      "math.LO",
      "03B05, 55U10, 68T27",
      "F.4.1; I.2.3; I.2.4"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00614v1",
    "title": "Predictability-Aware Compression and Decompression Framework for Multichannel Time Series Data",
    "authors": [
      "Ziqi Liu",
      "Pei Zeng",
      "Yi Ding"
    ],
    "abstract": "Real-world multichannel time series prediction faces growing demands for\nefficiency across edge and cloud environments, making channel compression a\ntimely and essential problem. Motivated by success of Multiple-Input\nMultiple-Output (MIMO) methods, we propose a predictability-aware\ncompression-decompression framework to reduce runtime, lower communication\ncost, and maintain prediction accuracy across diverse predictors. The core idea\ninvolves using a circular periodicity key matrix with orthogonality to capture\nunderlying time series predictability during compression and to mitigate\nreconstruction errors during decompression by relaxing oversimplified data\nassumptions. Theoretical and empirical analyses show that the proposed\nframework is both time-efficient and scalable under a large number of channels.\nExtensive experiments on six datasets across various predictors demonstrate\nthat the proposed method achieves superior overall performance by jointly\nconsidering prediction accuracy and runtime, while maintaining strong\ncompatibility with diverse predictors.",
    "pdf_url": "http://arxiv.org/pdf/2506.00614v1",
    "published": "2025-05-31T15:53:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00613v1",
    "title": "Evaluating Robot Policies in a World Model",
    "authors": [
      "Julian Quevedo",
      "Percy Liang",
      "Sherry Yang"
    ],
    "abstract": "Robotics has broad applications from automating house chores to taking care\nof patients. However, evaluating robot control policies is challenging, as\nreal-world testing is expensive, while handcrafted simulations often fail to\naccurately reflect real-world conditions, resulting in poor correlation between\nsimulated evaluation and real-world outcomes. In this work, we investigate\nWorld-model-based Policy Evaluation (WPE). We first train an action-conditioned\nvideo generation model as a proxy to real-world environments. To enable\nefficient rollouts of hundreds of interactive steps while mitigating error\naccumulation in the world model, we propose an inference scheme which we call\nBlockwise-Autoregressive Diffusion Transformer with adjustable context and\ndecoding horizon lengths. To ensure that the world model indeed follows action\ninput, we propose metrics based on the agreement between the ground truth video\nand generated video conditioned on the same sequence of actions to evaluate the\nworld model. We then use the world model for policy evaluation by performing\nMonte Carlo rollouts in the world model while employing a vision-language model\n(VLM) as a reward function. Interestingly, we found that WPE tends to\nunderestimate the policy values for in-distribution actions and overestimate\npolicy values for out-of-distribution actions. Nevertheless, WPE preserves the\nrelative rankings of different policies. In emulating real robot executions,\nWPE achieves high fidelity in mimicing robot arm movements as in real videos,\nwhile emulating highly realistic object interaction remains challenging.\nDespite this limitation, we show that a world model can serve as a starting\npoint for evaluating robot policies before real-world deployment.",
    "pdf_url": "http://arxiv.org/pdf/2506.00613v1",
    "published": "2025-05-31T15:51:56+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00612v3",
    "title": "Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge Graph Guided Distractor Generation",
    "authors": [
      "Running Yang",
      "Wenlong Deng",
      "Minghui Chen",
      "Yuyin Zhou",
      "Xiaoxiao Li"
    ],
    "abstract": "Clinical tasks such as diagnosis and treatment require strong decision-making\nabilities, highlighting the importance of rigorous evaluation benchmarks to\nassess the reliability of large language models (LLMs). In this work, we\nintroduce a knowledge-guided data augmentation framework that enhances the\ndifficulty of clinical multiple-choice question (MCQ) datasets by generating\ndistractors (i.e., incorrect choices that are similar to the correct one and\nmay confuse existing LLMs). Using our KG-based pipeline, the generated choices\nare both clinically plausible and deliberately misleading. Our approach\ninvolves multi-step, semantically informed walks on a medical knowledge graph\nto identify distractor paths-associations that are medically relevant but\nfactually incorrect-which then guide the LLM in crafting more deceptive\ndistractors. We apply the designed knowledge graph guided distractor generation\n(KGGDG) pipline, to six widely used medical QA benchmarks and show that it\nconsistently reduces the accuracy of state-of-the-art LLMs. These findings\nestablish KGGDG as a powerful tool for enabling more robust and diagnostic\nevaluations of medical LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00612v3",
    "published": "2025-05-31T15:51:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00611v2",
    "title": "Fast programmable entanglement of Barium ion qubits using Rydberg states and AC-Stark shifts",
    "authors": [
      "Adam R. Vernon",
      "Mitch Peaks"
    ],
    "abstract": "A scheme for excitation and individual addressing using Rydberg states of\ntrapped Barium ions is presented for the purpose of fast gates and\nentanglement. Dipole matrix elements, dynamic polarizabilities, and one- and\ntwo-photon transition strengths are computed with a Supersymmetric\nWentzel-Kramers-Brillouin (SWKB) method. A favorable two-photon excitation\ntransition is identified, linking the 7s$1/2$ state to high-lying Rydberg\nstates, with the strongest transition found to be 7s12->38s12. Additionally,\nthe 7s1/2 state exhibits high polarizability around the telecom band at 1310\nnm, enabling significant AC-Stark shift control with a turnkey laser at low\npower. This facilitates an individual addressing scheme by varying light\nintensity across an ion crystal, supporting sub-microsecond entangling gates\nbetween ion pairs with the strong and microwave-tunable Rydberg dipolar\ninteraction. Selective addressing of individual ions by laser frequency tuning\nusing the 6p3/2->7s1/2 transition is proposed.",
    "pdf_url": "http://arxiv.org/pdf/2506.00611v2",
    "published": "2025-05-31T15:50:35+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00610v1",
    "title": "Generic graded contractions of Lie algebras",
    "authors": [
      "Mikhail V. Kochetov",
      "Serhii D. Koval"
    ],
    "abstract": "We study generic graded contractions of Lie algebras from the perspectives of\ngroup cohomology, affine algebraic geometry and monoidal categories. We show\nthat generic graded contractions with a fixed support are classified by a\ncertain abelian group, which we explicitly describe. Analyzing the variety of\ngeneric graded contractions as an affine algebraic variety allows us to\ndescribe which generic graded contractions define graded degenerations of a\ngiven graded Lie algebra. Using the interpretation of generic $G$-graded\ncontractions as lax monoidal structures on the identity endofunctor of the\nmonoidal category of $G$-graded vector spaces, we establish a functorial\nversion of the Weimar-Woods conjecture on equivalence of generic graded\ncontractions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00610v1",
    "published": "2025-05-31T15:47:49+00:00",
    "categories": [
      "math.RA",
      "math-ph",
      "math.MP",
      "17B70 (Primary) 17B05 (Secondary)"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00609v1",
    "title": "TPHE-Graphene: A First-Principles Study of a New 2D Carbon Allotrope for Hydrogen Storage",
    "authors": [
      "José A. S. Laranjeira",
      "Nicolas F. Martins",
      "Kleuton A. L. Lima",
      "Luis A. Cabral",
      "Luiz A. Ribeiro",
      "Douglas S. Galvão",
      "Julio R. Sambrano"
    ],
    "abstract": "The shift from fossil fuels to renewable energy sources is essential for\nreducing global carbon emissions and addressing climate change. Developing\nadvanced materials for efficient hydrogen storage enables sustainable energy\nsolutions in this context. Herein, we propose sodium-decorated TPHE-graphene as\na high-performance two-dimensional material for hydrogen storage. Density\nfunctional theory (DFT) calculations demonstrate that TPHE-graphene exhibits\ndynamical, thermal, energetic, and mechanical stability, as confirmed by\ncohesive energy, phonon dispersion, and molecular dynamics simulations. The\nmonolayer displays metallic behavior and a high Young's modulus of 250.46 N/m.\nUpon sodium decoration, strong chemisorption occurs with a binding energy of\n-2.08 eV and minimal tendency for Na atom clustering. Hydrogen adsorption\nanalysis reveals that each Na atom can bind up to five H$_2$ molecules,\nresulting in a gravimetric storage capacity of 9.52 wt\\%. The calculated H$_2$\nadsorption energies range from -0.22 eV to -0.18 eV, falling within the ideal\nrange for reversible adsorption under ambient conditions. These findings\nhighlight Na-decorated TPHE-graphene as a structurally robust and efficient\nhydrogen storage material well-suited for future green energy applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00609v1",
    "published": "2025-05-31T15:42:35+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00608v1",
    "title": "PAKTON: A Multi-Agent Framework for Question Answering in Long Legal Agreements",
    "authors": [
      "Petros Raptopoulos",
      "Giorgos Filandrianos",
      "Maria Lymperaiou",
      "Giorgos Stamou"
    ],
    "abstract": "Contract review is a complex and time-intensive task that typically demands\nspecialized legal expertise, rendering it largely inaccessible to non-experts.\nMoreover, legal interpretation is rarely straightforward-ambiguity is\npervasive, and judgments often hinge on subjective assessments. Compounding\nthese challenges, contracts are usually confidential, restricting their use\nwith proprietary models and necessitating reliance on open-source alternatives.\nTo address these challenges, we introduce PAKTON: a fully open-source,\nend-to-end, multi-agent framework with plug-and-play capabilities. PAKTON is\ndesigned to handle the complexities of contract analysis through collaborative\nagent workflows and a novel retrieval-augmented generation (RAG) component,\nenabling automated legal document review that is more accessible, adaptable,\nand privacy-preserving. Experiments demonstrate that PAKTON outperforms both\ngeneral-purpose and pretrained models in predictive accuracy, retrieval\nperformance, explainability, completeness, and grounded justifications as\nevaluated through a human study and validated with automated metrics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00608v1",
    "published": "2025-05-31T15:38:21+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00607v1",
    "title": "Parallel Rescaling: Rebalancing Consistency Guidance for Personalized Diffusion Models",
    "authors": [
      "JungWoo Chae",
      "Jiyoon Kim",
      "Sangheum Hwang"
    ],
    "abstract": "Personalizing diffusion models to specific users or concepts remains\nchallenging, particularly when only a few reference images are available.\nExisting methods such as DreamBooth and Textual Inversion often overfit to\nlimited data, causing misalignment between generated images and text prompts\nwhen attempting to balance identity fidelity with prompt adherence. While\nDirect Consistency Optimization (DCO) with its consistency-guided sampling\npartially alleviates this issue, it still struggles with complex or stylized\nprompts. In this paper, we propose a parallel rescaling technique for\npersonalized diffusion models. Our approach explicitly decomposes the\nconsistency guidance signal into parallel and orthogonal components relative to\nclassifier free guidance (CFG). By rescaling the parallel component, we\nminimize disruptive interference with CFG while preserving the subject's\nidentity. Unlike prior personalization methods, our technique does not require\nadditional training data or expensive annotations. Extensive experiments show\nimproved prompt alignment and visual fidelity compared to baseline methods,\neven on challenging stylized prompts. These findings highlight the potential of\nparallel rescaled guidance to yield more stable and accurate personalization\nfor diverse user inputs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00607v1",
    "published": "2025-05-31T15:36:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00606v1",
    "title": "Heisenberg-limited Hamiltonian learning continuous variable systems via engineered dissipation",
    "authors": [
      "Tim Möbus",
      "Andreas Bluhm",
      "Tuvia Gefen",
      "Yu Tong",
      "Albert H. Werner",
      "Cambyse Rouzé"
    ],
    "abstract": "Discrete and continuous variables oftentimes require different treatments in\nmany learning tasks. Identifying the Hamiltonian governing the evolution of a\nquantum system is a fundamental task in quantum learning theory. While previous\nworks mostly focused on quantum spin systems, where quantum states can be seen\nas superpositions of discrete bit-strings, relatively little is known about\nHamiltonian learning for continuous-variable quantum systems. In this work we\nfocus on learning the Hamiltonian of a bosonic quantum system, a common type of\ncontinuous-variable quantum system. This learning task involves an\ninfinite-dimensional Hilbert space and unbounded operators, making\nmathematically rigorous treatments challenging. We introduce an analytic\nframework to study the effects of strong dissipation in such systems, enabling\na rigorous analysis of cat qubit stabilization via engineered dissipation. This\nframework also supports the development of Heisenberg-limited algorithms for\nlearning general bosonic Hamiltonians with higher-order terms of the creation\nand annihilation operators. Notably, our scheme requires a total Hamiltonian\nevolution time that scales only logarithmically with the number of modes and\ninversely with the precision of the reconstructed coefficients. On a\ntheoretical level, we derive a new quantitative adiabatic approximation\nestimate for general Lindbladian evolutions with unbounded generators. Finally,\nwe discuss possible experimental implementations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00606v1",
    "published": "2025-05-31T15:33:26+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00605v2",
    "title": "ABCDEFGH: An Adaptation-Based Convolutional Neural Network-CycleGAN Disease-Courses Evolution Framework Using Generative Models in Health Education",
    "authors": [
      "Ruiming Min",
      "Minghao Liu"
    ],
    "abstract": "With the advancement of modern medicine and the development of technologies\nsuch as MRI, CT, and cellular analysis, it has become increasingly critical for\nclinicians to accurately interpret various diagnostic images. However, modern\nmedical education often faces challenges due to limited access to high-quality\nteaching materials, stemming from privacy concerns and a shortage of\neducational resources (Balogh et al., 2015). In this context, image data\ngenerated by machine learning models, particularly generative models, presents\na promising solution. These models can create diverse and comparable imaging\ndatasets without compromising patient privacy, thereby supporting modern\nmedical education. In this study, we explore the use of convolutional neural\nnetworks (CNNs) and CycleGAN (Zhu et al., 2017) for generating synthetic\nmedical images. The source code is available at\nhttps://github.com/mliuby/COMP4211-Project.",
    "pdf_url": "http://arxiv.org/pdf/2506.00605v2",
    "published": "2025-05-31T15:32:58+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00604v1",
    "title": "Potassium Decoration on Graphenyldiene Monolayer for Advanced Reversible Hydrogen Storage",
    "authors": [
      "Jose A. S. Laranjeira",
      "Nicolas F. Martins",
      "Kleuton A. L. Lima",
      "Bill. D. Aparicio-Huacarpuma",
      "Luiz A. Ribeiro Junior",
      "Xihao Chen",
      "Douglas S. Galvao",
      "Julio R. Sambrano"
    ],
    "abstract": "Potassium-decorated graphenyldiene (K@GPD) is investigated as a promising\ntwo-dimensional material for reversible hydrogen storage using first-principles\ndensity functional theory calculations. Potassium atoms bind strongly to the\nGPD monolayer, and ab initio molecular dynamics (AIMD) simulations confirm the\nthermal stability of the functionalized system at 300 K. Hydrogen adsorption\nenergies range from -0.11 to -0.14 eV per H$_2$, denoting reversible storage.\nAt full coverage (18 H$_2$ molecules), the system reaches a storage capacity of\n8.82 wt\\%, exceeding the U.S. DOE target. AIMD simulations reveal spontaneous\nH$_2$ desorption at ambient temperature, demonstrating excellent reversibility.",
    "pdf_url": "http://arxiv.org/pdf/2506.00604v1",
    "published": "2025-05-31T15:29:38+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00603v1",
    "title": "Modelling laminar flow in V-shaped filters integrated with catalyst technologies for atmospheric pollutant removal",
    "authors": [
      "Samuel D. Tomlinson",
      "Aliki M. Tsopelakou",
      "Tzia M. Onn",
      "Steven R. H. Barrett",
      "Adam M. Boies",
      "Shaun D. Fitzgerald"
    ],
    "abstract": "Atmospheric pollution from particulate matter, volatile organic compounds and\ngreenhouse gases is a critical environmental and public health issue, leading\nto respiratory diseases and climate change. A potential mitigation strategy\ninvolves utilising ventilation systems, which process large volumes of indoor\nand outdoor air and remove particulate pollutants through filtration. However,\nthe integration of catalytic technologies with filters in ventilation systems\nremains underexplored, despite their potential to simultaneously remove\nparticulate matter and gases, as seen in flue gas treatment and automotive\nexhaust systems. In this study, we develop a predictive, long-wave model for\nV-shaped filters, with and without separators. The model, validated against\nexperimental and numerical data, provides a framework for enhancing flow rates\nby increasing fibre diameter and porosity while reducing aspect ratio and\nfilter thickness. These changes lead to increased permeability, which lowers\nenergy requirements. However, they also reduce the pollutant removal\nefficiency, highlighting the trade-off between flow, filtration performance and\noperational costs. Leveraging the long-wave model alongside experimental\nresults, we estimate the maximum potential removal rate ($2\\times10^{-4}$\nGtPM$_{2.5}$, $2\\times10^{-3}$ GtNO$_{\\text{x}}$, $9\\times10^{-3}$ GtCH$_{4}$\nper year) and minimum cost (\\$$7\\times10^{4}$ per tNO$_{\\text{x}}$,\n\\$$2\\times10^{4}$ per tCH$_{4}$) if a billion V-shaped filters integrated with\ncatalytic enhancements were deployed in operation. These findings highlight the\nfeasibility of catalytic filters as a scalable, high-efficiency solution for\nimproving air quality and mitigating atmospheric pollution.",
    "pdf_url": "http://arxiv.org/pdf/2506.00603v1",
    "published": "2025-05-31T15:29:27+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.00602v1",
    "title": "Assessing Honey Bee Colony Health Using Temperature Time Series",
    "authors": [
      "Karina Arias-Calluari",
      "Theotime Colin",
      "Tanya Latty",
      "Mary Myerscough",
      "Eduardo G. Altmann"
    ],
    "abstract": "Honey bees face an increasing number of stressors that disrupt the natural\nbehaviour of colonies and, in extreme cases, can lead to their collapse.\nQuantifying the status and resilience of colonies is essential to measure the\nimpact of stressors and to identify colonies at risk. In this manuscript, we\npresent and apply new methodologies to efficiently diagnose the status of a\nhoney bee colony from widely available time series of hive and environmental\ntemperature. Healthy hives have a remarkable ability to control temperature\nnear the brood area. Our method exploits this fact and quantifies the status of\na hive by measuring how resilient they are to extreme environmental\ntemperatures, which act as natural stressors. Analysing 22 hives during\ndifferent times of the year, including 3 hives that collapsed, we find the\nstatistical signatures of stress that reveal whether honeybees are doing well\nor are at risk of failure. Based on these analyses, we propose a simple scale\nof hive status (stable, warning, and collapse) that can be determined based on\na few temperature measurements. Our approach offers a lower-cost and practical\nbee-monitoring solution, providing a non-invasive way to track hive conditions\nand trigger interventions to save the hives from collapse.",
    "pdf_url": "http://arxiv.org/pdf/2506.00602v1",
    "published": "2025-05-31T15:28:41+00:00",
    "categories": [
      "stat.AP",
      "q-bio.QM",
      "92Bxx",
      "J.2.8; I.6.4"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00601v1",
    "title": "Dual-UAV-Aided Covert Communications for Air-to-Ground ISAC Networks",
    "authors": [
      "Jingke Sun",
      "Liang Yang",
      "Alexandros-Apostolos A. Boulogeorgos",
      "Theodoros A. Tsiftsis",
      "Hongwu Liu"
    ],
    "abstract": "To enhance both the sensing and covert communication performance, a\ndual-unmanned aerial vehicle (UAV)-aided scheme is proposed for integrated\nsensing and communication networks, in which one UAV maneuvers as the aerial\ndual-functional base-station (BS), while another UAV flies as the cooperative\njammer. Artificial noise (AN) transmitted by the jamming UAV is utilized not\nonly to confuse the ground warden but also to aid the aerial BS to sense\nmultiple ground targets by combing the target-echoed dual-functional waveform\nand AN components from a perspective of the hybrid monostatitc-bistatic radar.\nWe employ the distance-normalized beampattern sum-gain to measure the sensing\nperformance. To maximize the average covert rate (ACR) from the aerial BS to\nthe ground user, the dual-functional BS beamforming, jamming UAV beamforming,\nand dual-UAV trajectory are co-designed, subject to transmit power budgets, UAV\nmaneuver constraint, covertness requirement, and sensing performance\nconstraint. The imperfect successive interference cancellation (SIC) effects on\nthe received signal-to-interference-plus-noise ratio are also considered in\nmaximizing the ACR. To tackle the highly complicated non-convex ACR\nmaximization problem, dual-UAV beamforming and dual-UAV trajectory are\noptimized in a block coordinate descent way using the trust-region successive\nconvex approximation and semidefinite relaxation. To find the dual-UAV maneuver\nlocations suitable for sensing the ground targets, we first optimize the\ndual-UAV trajectory for the covert communication purpose only and then solve a\nweighted distance minimization problem for the covert communication and sensing\npurpose.",
    "pdf_url": "http://arxiv.org/pdf/2506.00601v1",
    "published": "2025-05-31T15:17:58+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00600v1",
    "title": "SatDreamer360: Geometry Consistent Street-View Video Generation from Satellite Imagery",
    "authors": [
      "Xianghui Ze",
      "Beiyi Zhu",
      "Zhenbo Song",
      "Jianfeng Lu",
      "Yujiao Shi"
    ],
    "abstract": "Generating continuous ground-level video from satellite imagery is a\nchallenging task with significant potential for applications in simulation,\nautonomous navigation, and digital twin cities. Existing approaches primarily\nfocus on synthesizing individual ground-view images, often relying on auxiliary\ninputs like height maps or handcrafted projections, and fall short in producing\ntemporally consistent sequences. In this paper, we propose {SatDreamer360}, a\nnovel framework that generates geometrically and temporally consistent\nground-view video from a single satellite image and a predefined trajectory. To\nbridge the large viewpoint gap, we introduce a compact tri-plane representation\nthat encodes scene geometry directly from the satellite image. A ray-based\npixel attention mechanism retrieves view-dependent features from the tri-plane,\nenabling accurate cross-view correspondence without requiring additional\ngeometric priors. To ensure multi-frame consistency, we propose an\nepipolar-constrained temporal attention module that aligns features across\nframes using the known relative poses along the trajectory. To support\nevaluation, we introduce {VIGOR++}, a large-scale dataset for cross-view video\ngeneration, with dense trajectory annotations and high-quality ground-view\nsequences. Extensive experiments demonstrate that SatDreamer360 achieves\nsuperior performance in fidelity, coherence, and geometric alignment across\ndiverse urban scenes.",
    "pdf_url": "http://arxiv.org/pdf/2506.00600v1",
    "published": "2025-05-31T15:15:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00599v2",
    "title": "XYZ-IBD: A High-precision Bin-picking Dataset for Object 6D Pose Estimation Capturing Real-world Industrial Complexity",
    "authors": [
      "Junwen Huang",
      "Jizhong Liang",
      "Jiaqi Hu",
      "Martin Sundermeyer",
      "Peter KT Yu",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "abstract": "We introduce XYZ-IBD, a bin-picking dataset for 6D pose estimation that\ncaptures real-world industrial complexity, including challenging object\ngeometries, reflective materials, severe occlusions, and dense clutter. The\ndataset reflects authentic robotic manipulation scenarios with\nmillimeter-accurate annotations. Unlike existing datasets that primarily focus\non household objects, which approach saturation,XYZ-IBD represents the unsolved\nrealistic industrial conditions. The dataset features 15 texture-less,\nmetallic, and mostly symmetrical objects of varying shapes and sizes. These\nobjects are heavily occluded and randomly arranged in bins with high density,\nreplicating the challenges of real-world bin-picking. XYZ-IBD was collected\nusing two high-precision industrial cameras and one commercially available\ncamera, providing RGB, grayscale, and depth images. It contains 75 multi-view\nreal-world scenes, along with a large-scale synthetic dataset rendered under\nsimulated bin-picking conditions. We employ a meticulous annotation pipeline\nthat includes anti-reflection spray, multi-view depth fusion, and\nsemi-automatic annotation, achieving millimeter-level pose labeling accuracy\nrequired for industrial manipulation. Quantification in simulated environments\nconfirms the reliability of the ground-truth annotations. We benchmark\nstate-of-the-art methods on 2D detection, 6D pose estimation, and depth\nestimation tasks on our dataset, revealing significant performance degradation\nin our setups compared to current academic household benchmarks. By capturing\nthe complexity of real-world bin-picking scenarios, XYZ-IBD introduces more\nrealistic and challenging problems for future research. The dataset and\nbenchmark are publicly available at https://xyz-ibd.github.io/XYZ-IBD/.",
    "pdf_url": "http://arxiv.org/pdf/2506.00599v2",
    "published": "2025-05-31T15:15:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00598v1",
    "title": "Ab-initio Study of Structural, Magnetic, Optoelectronic and Thermo-Physical Properties of HoPdBi Half-Heusler Semimetal",
    "authors": [
      "Tanvir Khan",
      "F. Parvin",
      "S. H. Naqib"
    ],
    "abstract": "In this investigation, we have used the density functional theory (DFT) to\ninvestigate several aspects of the half-Heusler compound HoPdBi. The following\nproperties have been studied: spin polarized electronic properties, magnetic\nmoment, phonon dispersion with phonon density of states, structural, elastic\nproperties, optical characteristics, and thermo-physical features. The\ncalculated unit cell volume and ground-state lattice characteristics closely\nmatch the experimental results. This study is the first to examine the\noptoelectronic, thermo-physical, and elastic characteristics of HoPdBi. The\nmechanical stability requirements were met by the calculated elastic constants.\nThe compound's ductility is shown by the estimated Pugh's ratio, Poisson's\nratio, and Cauchy pressure. Band structures and electronic energy density of\nstates have been evaluated in order to better understand the magnetic features\nwith spin polarization. Band structure simulations were conducted with and\nwithout the spin-orbit coupling (SOC) effect in order to look into any\ntopological signature. The electrical band structure of the compound shows\nsemi-metallic properties. The reflectivity, absorption coefficient, refractive\nindex, dielectric function, optical conductivity, and loss function of this\nsemi-metal have all been thoroughly examined. The compound is a good reflector\nin infrared region and a good absorber of ultraviolet (UV) light. This compound\nis a suitable candidate for high temperature applications and possesses\npotential as heat sink because of its high melting point and thermal\nconductivity. It is also suitable for spintronics applications. The majority of\nthis study's findings are completely novel.",
    "pdf_url": "http://arxiv.org/pdf/2506.00598v1",
    "published": "2025-05-31T15:15:01+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00597v1",
    "title": "Processing-in-memory for genomics workloads",
    "authors": [
      "William Andrew Simon",
      "Leonid Yavits",
      "Konstantina Koliogeorgi",
      "Yann Falevoz",
      "Yoshihiro Shibuya",
      "Dominique Lavenier",
      "Irem Boybat",
      "Klea Zambaku",
      "Berkan Şahin",
      "Mohammad Sadrosadati",
      "Onur Mutlu",
      "Abu Sebastian",
      "Rayan Chikhi",
      "The BioPIM Consortium",
      "Can Alkan"
    ],
    "abstract": "Low-cost, high-throughput DNA and RNA sequencing (HTS) data is the main\nworkforce for the life sciences. Genome sequencing is now becoming a part of\nPredictive, Preventive, Personalized, and Participatory (termed 'P4') medicine.\nAll genomic data are currently processed in energy-hungry computer clusters and\ncenters, necessitating data transfer, consuming substantial energy, and wasting\nvaluable time. Therefore, there is a need for fast, energy-efficient, and\ncost-efficient technologies that enable genomics research without requiring\ndata centers and cloud platforms. We recently started the BioPIM Project to\nleverage the emerging processing-in-memory (PIM) technologies to enable energy\nand cost-efficient analysis of bioinformatics workloads. The BioPIM Project\nfocuses on co-designing algorithms and data structures commonly used in\ngenomics with several PIM architectures for the highest cost, energy, and time\nsavings benefit.",
    "pdf_url": "http://arxiv.org/pdf/2506.00597v1",
    "published": "2025-05-31T15:13:06+00:00",
    "categories": [
      "q-bio.GN",
      "cs.AR"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.00596v1",
    "title": "Seg2Any: Open-set Segmentation-Mask-to-Image Generation with Precise Shape and Semantic Control",
    "authors": [
      "Danfeng li",
      "Hui Zhang",
      "Sheng Wang",
      "Jiacheng Li",
      "Zuxuan Wu"
    ],
    "abstract": "Despite recent advances in diffusion models, top-tier text-to-image (T2I)\nmodels still struggle to achieve precise spatial layout control, i.e.\naccurately generating entities with specified attributes and locations.\nSegmentation-mask-to-image (S2I) generation has emerged as a promising solution\nby incorporating pixel-level spatial guidance and regional text prompts.\nHowever, existing S2I methods fail to simultaneously ensure semantic\nconsistency and shape consistency. To address these challenges, we propose\nSeg2Any, a novel S2I framework built upon advanced multimodal diffusion\ntransformers (e.g. FLUX). First, to achieve both semantic and shape\nconsistency, we decouple segmentation mask conditions into regional semantic\nand high-frequency shape components. The regional semantic condition is\nintroduced by a Semantic Alignment Attention Mask, ensuring that generated\nentities adhere to their assigned text prompts. The high-frequency shape\ncondition, representing entity boundaries, is encoded as an Entity Contour Map\nand then introduced as an additional modality via multi-modal attention to\nguide image spatial structure. Second, to prevent attribute leakage across\nentities in multi-entity scenarios, we introduce an Attribute Isolation\nAttention Mask mechanism, which constrains each entity's image tokens to attend\nexclusively to themselves during image self-attention. To support open-set S2I\ngeneration, we construct SACap-1M, a large-scale dataset containing 1 million\nimages with 5.9 million segmented entities and detailed regional captions,\nalong with a SACap-Eval benchmark for comprehensive S2I evaluation. Extensive\nexperiments demonstrate that Seg2Any achieves state-of-the-art performance on\nboth open-set and closed-set S2I benchmarks, particularly in fine-grained\nspatial and attribute control of entities.",
    "pdf_url": "http://arxiv.org/pdf/2506.00596v1",
    "published": "2025-05-31T15:12:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00595v2",
    "title": "Antenna Q-Factor Topology Optimization with Auxiliary Edge Resistivities",
    "authors": [
      "Stepan Bosak",
      "Miloslav Capek",
      "Jiri Matas"
    ],
    "abstract": "This paper presents a novel bi-level topology optimization strategy within\nthe method-of-moments paradigm. The proposed approach utilizes an auxiliary\nvariables called edge resistivities related to the Rao-Wilton-Glisson\nmethod-of-moments basis functions, for a definition of a fast local\noptimization algorithm. The local algorithm combines automatic differentiation\nwith adaptive gradient descent. A Bayesian optimization scheme is applied on\ntop of the local algorithm to search for an optimum position of the delta-gap\nfeeding and optimizer hyperparameters. The strength of the algorithm is\ndemonstrated on Q-factor minimization for electrically small antennas.\nAuxiliary edge resistivity topology optimization outperforms current\nstate-of-the-art topology optimization methods, including material\ndensity-based approaches and memetic schemes, in terms of convergence. However,\ndue to the nature of gradient descent, careful tuning of the optimizer\nhyperparameters is required. Furthermore, the proposed method solves the known\nbinarization issue. Two designs that achieved self-resonance and approached the\nQ-factor lower bound were further assessed in CST Microwave Studio.",
    "pdf_url": "http://arxiv.org/pdf/2506.00595v2",
    "published": "2025-05-31T15:11:32+00:00",
    "categories": [
      "physics.comp-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00594v1",
    "title": "Graph Evidential Learning for Anomaly Detection",
    "authors": [
      "Chunyu Wei",
      "Wenji Hu",
      "Xingjia Hao",
      "Yunhai Wang",
      "Yueguo Chen",
      "Bing Bai",
      "Fei Wang"
    ],
    "abstract": "Graph anomaly detection faces significant challenges due to the scarcity of\nreliable anomaly-labeled datasets, driving the development of unsupervised\nmethods. Graph autoencoders (GAEs) have emerged as a dominant approach by\nreconstructing graph structures and node features while deriving anomaly scores\nfrom reconstruction errors. However, relying solely on reconstruction error for\nanomaly detection has limitations, as it increases the sensitivity to noise and\noverfitting. To address these issues, we propose Graph Evidential Learning\n(GEL), a probabilistic framework that redefines the reconstruction process\nthrough evidential learning. By modeling node features and graph topology using\nevidential distributions, GEL quantifies two types of uncertainty: graph\nuncertainty and reconstruction uncertainty, incorporating them into the anomaly\nscoring mechanism. Extensive experiments demonstrate that GEL achieves\nstate-of-the-art performance while maintaining high robustness against noise\nand structural perturbations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00594v1",
    "published": "2025-05-31T15:06:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00593v2",
    "title": "Look mom, no experimental data! Learning to score protein-ligand interactions from simulations",
    "authors": [
      "Michael Brocidiacono",
      "James Wellnitz",
      "Konstantin I. Popov",
      "Alexander Tropsha"
    ],
    "abstract": "Despite recent advances in protein-ligand structure prediction, deep learning\nmethods remain limited in their ability to accurately predict binding\naffinities, particularly for novel protein targets dissimilar from the training\nset. In contrast, physics-based binding free energy calculations offer high\naccuracy across chemical space but are computationally prohibitive for\nlarge-scale screening. We propose a hybrid approach that approximates the\naccuracy of physics-based methods by training target-specific neural networks\non molecular dynamics simulations of the protein in complex with random small\nmolecules. Our method uses force matching to learn an implicit free energy\nlandscape of ligand binding for each target. Evaluated on six proteins, our\napproach achieves competitive virtual screening performance using 100-500\n$\\mu$s of MD simulations per target. Notably, this approach achieves\nstate-of-the-art early enrichment when using the true pose for active\ncompounds. These results highlight the potential of physics-informed learning\nfor virtual screening on novel targets. We publicly release the code for this\npaper at https://github.com/molecularmodelinglab/lfm under the MIT license.",
    "pdf_url": "http://arxiv.org/pdf/2506.00593v2",
    "published": "2025-05-31T14:58:44+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00592v1",
    "title": "Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing Churn",
    "authors": [
      "Hongyao Tang",
      "Johan Obando-Ceron",
      "Pablo Samuel Castro",
      "Aaron Courville",
      "Glen Berseth"
    ],
    "abstract": "Plasticity, or the ability of an agent to adapt to new tasks, environments,\nor distributions, is crucial for continual learning. In this paper, we study\nthe loss of plasticity in deep continual RL from the lens of churn: network\noutput variability for out-of-batch data induced by mini-batch training. We\ndemonstrate that (1) the loss of plasticity is accompanied by the exacerbation\nof churn due to the gradual rank decrease of the Neural Tangent Kernel (NTK)\nmatrix; (2) reducing churn helps prevent rank collapse and adjusts the step\nsize of regular RL gradients adaptively. Moreover, we introduce Continual Churn\nApproximated Reduction (C-CHAIN) and demonstrate it improves learning\nperformance and outperforms baselines in a diverse range of continual learning\nenvironments on OpenAI Gym Control, ProcGen, DeepMind Control Suite, and\nMinAtar benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00592v1",
    "published": "2025-05-31T14:58:22+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00591v1",
    "title": "MR2US-Pro: Prostate MR to Ultrasound Image Translation and Registration Based on Diffusion Models",
    "authors": [
      "Xudong Ma",
      "Nantheera Anantrasirichai",
      "Stefanos Bolomytis",
      "Alin Achim"
    ],
    "abstract": "The diagnosis of prostate cancer increasingly depends on multimodal imaging,\nparticularly magnetic resonance imaging (MRI) and transrectal ultrasound\n(TRUS). However, accurate registration between these modalities remains a\nfundamental challenge due to the differences in dimensionality and anatomical\nrepresentations. In this work, we present a novel framework that addresses\nthese challenges through a two-stage process: TRUS 3D reconstruction followed\nby cross-modal registration. Unlike existing TRUS 3D reconstruction methods\nthat rely heavily on external probe tracking information, we propose a totally\nprobe-location-independent approach that leverages the natural correlation\nbetween sagittal and transverse TRUS views. With the help of our\nclustering-based feature matching method, we enable the spatial localization of\n2D frames without any additional probe tracking information. For the\nregistration stage, we introduce an unsupervised diffusion-based framework\nguided by modality translation. Unlike existing methods that translate one\nmodality into another, we map both MR and US into a pseudo intermediate\nmodality. This design enables us to customize it to retain only\nregistration-critical features, greatly easing registration. To further enhance\nanatomical alignment, we incorporate an anatomy-aware registration strategy\nthat prioritizes internal structural coherence while adaptively reducing the\ninfluence of boundary inconsistencies. Extensive validation demonstrates that\nour approach outperforms state-of-the-art methods by achieving superior\nregistration accuracy with physically realistic deformations in a completely\nunsupervised fashion.",
    "pdf_url": "http://arxiv.org/pdf/2506.00591v1",
    "published": "2025-05-31T14:55:03+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00590v1",
    "title": "Geometry and Dress groups with non-symmetric cost functions",
    "authors": [
      "Lukas Silvester Barth",
      "Parvaneh Joharinad",
      "Jürgen Jost",
      "Walter Wenzel"
    ],
    "abstract": "A metric relation by definition is symmetric. Since many data sets are\nnon-symmetric, in this paper we develop a systematic theory of non-symmetric\ncost functions. Betweenness relations play an important role. We also introduce\nthe notion of a Dress group in the non-symmetric setting and indicate a notion\nof curvature.",
    "pdf_url": "http://arxiv.org/pdf/2506.00590v1",
    "published": "2025-05-31T14:53:34+00:00",
    "categories": [
      "math.MG",
      "cs.IT",
      "math.CT",
      "math.GR",
      "math.IT",
      "51F99, 51D99, 37B99, 20C99, 18F99",
      "F.4.2; F.4.3"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00589v1",
    "title": "Constrained Stein Variational Gradient Descent for Robot Perception, Planning, and Identification",
    "authors": [
      "Griffin Tabor",
      "Tucker Hermans"
    ],
    "abstract": "Many core problems in robotics can be framed as constrained optimization\nproblems. Often on these problems, the robotic system has uncertainty, or it\nwould be advantageous to identify multiple high quality feasible solutions. To\nenable this, we present two novel frameworks for applying principles of\nconstrained optimization to the new variational inference algorithm Stein\nvariational gradient descent. Our general framework supports multiple types of\nconstrained optimizers and can handle arbitrary constraints. We demonstrate on\na variety of problems that we are able to learn to approximate distributions\nwithout violating constraints. Specifically, we show that we can build\ndistributions of: robot motion plans that exactly avoid collisions, robot arm\njoint angles on the SE(3) manifold with exact table placement constraints, and\nobject poses from point clouds with table placement constraints.",
    "pdf_url": "http://arxiv.org/pdf/2506.00589v1",
    "published": "2025-05-31T14:52:34+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00588v2",
    "title": "Temporal Chunking Enhances Recognition of Implicit Sequential Patterns",
    "authors": [
      "Jayanta Dey",
      "Nicholas Soures",
      "Miranda Gonzales",
      "Itamar Lerner",
      "Christopher Kanan",
      "Dhireesha Kudithipudi"
    ],
    "abstract": "In this pilot study, we propose a neuro-inspired approach that compresses\ntemporal sequences into context-tagged chunks, where each tag represents a\nrecurring structural unit or``community'' in the sequence. These tags are\ngenerated during an offline sleep phase and serve as compact references to past\nexperience, allowing the learner to incorporate information beyond its\nimmediate input range. We evaluate this idea in a controlled synthetic\nenvironment designed to reveal the limitations of traditional neural network\nbased sequence learners, such as recurrent neural networks (RNNs), when facing\ntemporal patterns on multiple timescales. We evaluate this idea in a controlled\nsynthetic environment designed to reveal the limitations of traditional neural\nnetwork based sequence learners, such as recurrent neural networks (RNNs), when\nfacing temporal patterns on multiple timescales. Our results, while\npreliminary, suggest that temporal chunking can significantly enhance learning\nefficiency under resource constrained settings. A small-scale human pilot study\nusing a Serial Reaction Time Task further motivates the idea of structural\nabstraction. Although limited to synthetic tasks, this work serves as an early\nproof-of-concept, with initial evidence that learned context tags can transfer\nacross related task, offering potential for future applications in transfer\nlearning.",
    "pdf_url": "http://arxiv.org/pdf/2506.00588v2",
    "published": "2025-05-31T14:51:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00587v1",
    "title": "Decoding the Stressed Brain with Geometric Machine Learning",
    "authors": [
      "Sonia Koszut",
      "Sam Nallaperuma-Herzberg",
      "Pietro Lio"
    ],
    "abstract": "Stress significantly contributes to both mental and physical disorders, yet\ntraditional self-reported questionnaires are inherently subjective. In this\nstudy, we introduce a novel framework that employs geometric machine learning\nto detect stress from raw EEG recordings. Our approach constructs graphs by\nintegrating structural connectivity (derived from electrode spatial\narrangement) with functional connectivity from pairwise signal correlations. A\nspatio-temporal graph convolutional network (ST-GCN) processes these graphs to\ncapture spatial and temporal dynamics. Experiments on the SAM-40 dataset show\nthat the ST-GCN outperforms standard machine learning models on all key\nclassification metrics and enhances interpretability, explored through ablation\nanalyses of key channels and brain regions. These results pave the way for more\nobjective and accurate stress detection methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00587v1",
    "published": "2025-05-31T14:47:48+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00586v2",
    "title": "Planck Law from a Classical Free Energy Extremum Involving Fisher Information",
    "authors": [
      "Carlos A. Gomez-Uribe"
    ],
    "abstract": "We derive the Planck law from a classical variational principle over\nprobability densities, without invoking quantum states, quantized oscillator\nenergies, or ensemble averages. We construct a generalized free energy\nfunctional involving entropy and Fisher information, with weights determined by\nthe dimensionless ratio of quantum to thermal energy. When extremized under a\nGaussian ansatz, this functional yields the exact Planck distribution. The only\nquantum input is a minimal threshold assumption: that an oscillator emits a\nphoton only when a thermal fluctuation delivers at least as much energy as the\nphoton has. We also present a complementary kinetic derivation, based on\nthreshold-activated thermal cascades, that yields the same result through\nclassical stochastic reasoning. Together, these approaches provide a\nthermodynamic and information-theoretic route to black-body radiation, grounded\nin classical principles and variational stability.",
    "pdf_url": "http://arxiv.org/pdf/2506.00586v2",
    "published": "2025-05-31T14:46:09+00:00",
    "categories": [
      "physics.class-ph"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00585v1",
    "title": "Entriever: Energy-based Retriever for Knowledge-Grounded Dialog Systems",
    "authors": [
      "Yucheng Cai",
      "Ke Li",
      "Yi Huang",
      "Junlan Feng",
      "Zhijian Ou"
    ],
    "abstract": "A retriever, which retrieves relevant knowledge pieces from a knowledge base\ngiven a context, is an important component in many natural language processing\n(NLP) tasks. Retrievers have been introduced in knowledge-grounded dialog\nsystems to improve knowledge acquisition. In knowledge-grounded dialog systems,\nwhen conditioning on a given context, there may be multiple relevant and\ncorrelated knowledge pieces. However, knowledge pieces are usually assumed to\nbe conditionally independent in current retriever models. To address this\nissue, we propose Entriever, an energy-based retriever. Entriever directly\nmodels the candidate retrieval results as a whole instead of modeling the\nknowledge pieces separately, with the relevance score defined by an energy\nfunction. We explore various architectures of energy functions and different\ntraining methods for Entriever, and show that Entriever substantially\noutperforms the strong cross-encoder baseline in knowledge retrieval tasks.\nFurthermore, we show that in semi-supervised training of knowledge-grounded\ndialog systems, Entriever enables effective scoring of retrieved knowledge\npieces and significantly improves end-to-end performance of dialog systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00585v1",
    "published": "2025-05-31T14:42:34+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00584v1",
    "title": "On local non-tangential growth of the resolvent of a banded Toeplitz operator",
    "authors": [
      "L. Golinskii",
      "S. Kupin"
    ],
    "abstract": "We study the growth of the resolvent of a Hardy--Toeplitz operator $T_b$ with\na Laurent polynomial symbol (\\emph{i.e., } the matrix $T_b$ is banded), at the\nneighborhood of a point $w_0\\in\\partial(\\sigma(T_b))$ on the boundary of its\nspectrum. We show that such growth is inverse linear in some non-tangential\ndomains at the vertex $w_0$, provided that $w_0$ does not belong to a certain\nfinite set on the complex plane.",
    "pdf_url": "http://arxiv.org/pdf/2506.00584v1",
    "published": "2025-05-31T14:40:02+00:00",
    "categories": [
      "math.SP",
      "Primary: 47B35, Secondary: 30H10, 47G10"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00583v1",
    "title": "The Hidden Language of Harm: Examining the Role of Emojis in Harmful Online Communication and Content Moderation",
    "authors": [
      "Yuhang Zhou",
      "Yimin Xiao",
      "Wei Ai",
      "Ge Gao"
    ],
    "abstract": "Social media platforms have become central to modern communication, yet they\nalso harbor offensive content that challenges platform safety and inclusivity.\nWhile prior research has primarily focused on textual indicators of offense,\nthe role of emojis, ubiquitous visual elements in online discourse, remains\nunderexplored. Emojis, despite being rarely offensive in isolation, can acquire\nharmful meanings through symbolic associations, sarcasm, and contextual misuse.\nIn this work, we systematically examine emoji contributions to offensive\nTwitter messages, analyzing their distribution across offense categories and\nhow users exploit emoji ambiguity. To address this, we propose an LLM-powered,\nmulti-step moderation pipeline that selectively replaces harmful emojis while\npreserving the tweet's semantic intent. Human evaluations confirm our approach\neffectively reduces perceived offensiveness without sacrificing meaning. Our\nanalysis also reveals heterogeneous effects across offense types, offering\nnuanced insights for online communication and emoji moderation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00583v1",
    "published": "2025-05-31T14:39:08+00:00",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00582v2",
    "title": "Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs",
    "authors": [
      "Chenjun Xu",
      "Bingbing Wen",
      "Bin Han",
      "Robert Wolfe",
      "Lucy Lu Wang",
      "Bill Howe"
    ],
    "abstract": "Psychology research has shown that humans are poor at estimating their\nperformance on tasks, tending towards underconfidence on easy tasks and\noverconfidence on difficult tasks. We examine three LLMs, Llama-3-70B-instruct,\nClaude-3-Sonnet, and GPT-4o, on a range of QA tasks of varying difficulty, and\nshow that models exhibit subtle differences from human patterns of\noverconfidence: less sensitive to task difficulty, and when prompted to answer\nbased on different personas -- e.g., expert vs layman, or different race,\ngender, and ages -- the models will respond with stereotypically biased\nconfidence estimations even though their underlying answer accuracy remains the\nsame. Based on these observations, we propose Answer-Free Confidence Estimation\n(AFCE) to improve confidence calibration and LLM interpretability in these\nsettings. AFCE is a self-assessment method that employs two stages of\nprompting, first eliciting only confidence scores on questions, then asking\nseparately for the answer. Experiments on the MMLU and GPQA datasets spanning\nsubjects and difficulty show that this separation of tasks significantly\nreduces overconfidence and delivers more human-like sensitivity to task\ndifficulty.",
    "pdf_url": "http://arxiv.org/pdf/2506.00582v2",
    "published": "2025-05-31T14:37:18+00:00",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00581v1",
    "title": "Joint Activity Detection and Channel Estimation for Massive Connectivity: Where Message Passing Meets Score-Based Generative Priors",
    "authors": [
      "Chang Cai",
      "Wenjun Jiang",
      "Xiaojun Yuan",
      "Ying-Jun Angela Zhang"
    ],
    "abstract": "Massive connectivity supports the sporadic access of a vast number of devices\nwithout requiring prior permission from the base station (BS). In such\nscenarios, the BS must perform joint activity detection and channel estimation\n(JADCE) prior to data reception. Message passing algorithms have emerged as a\nprominent solution for JADCE under a Bayesian inference framework. The existing\nmessage passing algorithms, however, typically rely on some hand-crafted and\noverly simplistic priors of the wireless channel, leading to significant\nchannel estimation errors and reduced activity detection accuracy. In this\npaper, we focus on the problem of JADCE in a multiple-input multiple-output\northogonal frequency division multiplexing (MIMO-OFDM) grant-free random access\nnetwork. We propose to incorporate a more accurate channel prior learned by\nscore-based generative models into message passing, so as to push towards the\nperformance limit of JADCE. Specifically, we develop a novel turbo message\npassing (TMP) framework that models the entire channel matrix as a super node,\nrather than factorizing it element-wise. This design enables the seamless\nintegration of score-based generative models as a minimum mean-squared error\n(MMSE) denoiser. The variance of the denoiser, which is essential in message\npassing, can also be learned through score-based generative models. Our\napproach, termed score-based TMP for JADCE (STMP-JADCE), takes full advantages\nof the powerful generative prior and, meanwhile, benefits from the fast\nconvergence speed of message passing. Numerical simulations show that\nSTMP-JADCE drastically enhances the activity detection and channel estimation\nperformance compared to the state-of-the-art baseline algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2506.00581v1",
    "published": "2025-05-31T14:36:02+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00580v1",
    "title": "Slow Feature Analysis as Variational Inference Objective",
    "authors": [
      "Merlin Schüler",
      "Laurenz Wiskott"
    ],
    "abstract": "This work presents a novel probabilistic interpretation of Slow Feature\nAnalysis (SFA) through the lens of variational inference. Unlike prior\nformulations that recover linear SFA from Gaussian state-space models with\nlinear emissions, this approach relaxes the key constraint of linearity. While\nit does not lead to full equivalence to non-linear SFA, it recasts the\nclassical slowness objective in a variational framework. Specifically, it\nallows the slowness objective to be interpreted as a regularizer to a\nreconstruction loss. Furthermore, we provide arguments, why -- from the\nperspective of slowness optimization -- the reconstruction loss takes on the\nrole of the constraints that ensure informativeness in SFA. We conclude with a\ndiscussion of potential new research directions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00580v1",
    "published": "2025-05-31T14:29:02+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00579v1",
    "title": "Observation of a Fault Tolerance Threshold with Concatenated Codes",
    "authors": [
      "Grace M. Sommers",
      "Michael Foss-Feig",
      "David Hayes",
      "David A. Huse",
      "Michael J. Gullans"
    ],
    "abstract": "We introduce a fault-tolerant protocol for code concatenation using a\nbutterfly network architecture with high noise thresholds and low ancilla\noverhead to allow implementation on current devices. We develop a probability\npassing decoder using tensor networks that applies Bayesian updates to the\nmarginal error probabilities after each layer of checks, achieving a state\npreparation threshold of $e_c \\approx 0.089$ for erasure errors, and $\\approx\n0.015$ for unheralded noise. We implement our state preparation protocol on\nion-trap hardware with added noise to demonstrate the threshold behavior in a\nreal quantum device. We further theoretically test the performance of our\nscheme as a quantum memory and for universal quantum computation through the\npreparation of low-noise magic states for state distillation and $T$-gate\ninjection.",
    "pdf_url": "http://arxiv.org/pdf/2506.00579v1",
    "published": "2025-05-31T14:24:43+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00578v1",
    "title": "Event-based multi-view photogrammetry for high-dynamic, high-velocity target measurement",
    "authors": [
      "Taihang Lei",
      "Banglei Guan",
      "Minzu Liang",
      "Xiangyu Li",
      "Jianbing Liu",
      "Jing Tao",
      "Yang Shang",
      "Qifeng Yu"
    ],
    "abstract": "The characterization of mechanical properties for high-dynamic, high-velocity\ntarget motion is essential in industries. It provides crucial data for\nvalidating weapon systems and precision manufacturing processes etc. However,\nexisting measurement methods face challenges such as limited dynamic range,\ndiscontinuous observations, and high costs. This paper presents a new approach\nleveraging an event-based multi-view photogrammetric system, which aims to\naddress the aforementioned challenges. First, the monotonicity in the\nspatiotemporal distribution of events is leveraged to extract the target's\nleading-edge features, eliminating the tailing effect that complicates motion\nmeasurements. Then, reprojection error is used to associate events with the\ntarget's trajectory, providing more data than traditional intersection methods.\nFinally, a target velocity decay model is employed to fit the data, enabling\naccurate motion measurements via ours multi-view data joint computation. In a\nlight gas gun fragment test, the proposed method showed a measurement deviation\nof 4.47% compared to the electromagnetic speedometer.",
    "pdf_url": "http://arxiv.org/pdf/2506.00578v1",
    "published": "2025-05-31T14:23:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00577v1",
    "title": "Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs",
    "authors": [
      "Yufa Zhou",
      "Shaobo Wang",
      "Xingyu Dong",
      "Xiangqi Jin",
      "Yifang Chen",
      "Yue Min",
      "Kexin Yang",
      "Xingzhang Ren",
      "Dayiheng Liu",
      "Linfeng Zhang"
    ],
    "abstract": "Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS)\nremains challenging due to intricate reward modeling, dynamic agent\ninteractions, and demanding generalization requirements. This paper explores\nwhether post-training techniques, specifically Supervised Fine-Tuning (SFT) and\nReinforcement Learning with Verifiable Rewards (RLVR), can effectively\n$\\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a\ntestbed, leveraging its strong foundations in mathematics and game theory, its\ndemand for structured analytical reasoning, and its relevance to real-world\napplications such as market design, resource allocation, and policy analysis.\nWe introduce $\\textbf{Recon}$ ($\\textbf{R}$easoning like an\n$\\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a\nhand-curated dataset of 2,100 high-quality economic reasoning problems.\nComprehensive evaluation on economic reasoning benchmarks and multi-agent games\nreveals clear improvements in structured reasoning and economic rationality.\nThese results underscore the promise of domain-aligned post-training for\nenhancing reasoning and agent alignment, shedding light on the roles of SFT and\nRL in shaping model behavior. Code is available at\nhttps://github.com/MasterZhou1/Recon .",
    "pdf_url": "http://arxiv.org/pdf/2506.00577v1",
    "published": "2025-05-31T14:22:40+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00576v1",
    "title": "ORAN-GUIDE: RAG-Driven Prompt Learning for LLM-Augmented Reinforcement Learning in O-RAN Network Slicing",
    "authors": [
      "Fatemeh Lotfi",
      "Hossein Rajoli",
      "Fatemeh Afghah"
    ],
    "abstract": "Advanced wireless networks must support highly dynamic and heterogeneous\nservice demands. Open Radio Access Network (O-RAN) architecture enables this\nflexibility by adopting modular, disaggregated components, such as the RAN\nIntelligent Controller (RIC), Centralized Unit (CU), and Distributed Unit (DU),\nthat can support intelligent control via machine learning (ML). While deep\nreinforcement learning (DRL) is a powerful tool for managing dynamic resource\nallocation and slicing, it often struggles to process raw, unstructured input\nlike RF features, QoS metrics, and traffic trends. These limitations hinder\npolicy generalization and decision efficiency in partially observable and\nevolving environments. To address this, we propose \\textit{ORAN-GUIDE}, a\ndual-LLM framework that enhances multi-agent RL (MARL) with task-relevant,\nsemantically enriched state representations. The architecture employs a\ndomain-specific language model, ORANSight, pretrained on O-RAN control and\nconfiguration data, to generate structured, context-aware prompts. These\nprompts are fused with learnable tokens and passed to a frozen GPT-based\nencoder that outputs high-level semantic representations for DRL agents. This\ndesign adopts a retrieval-augmented generation (RAG) style pipeline tailored\nfor technical decision-making in wireless systems. Experimental results show\nthat ORAN-GUIDE improves sample efficiency, policy convergence, and performance\ngeneralization over standard MARL and single-LLM baselines.",
    "pdf_url": "http://arxiv.org/pdf/2506.00576v1",
    "published": "2025-05-31T14:21:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00575v1",
    "title": "Quantum computation with longlived Rydberg-Landau atoms featuring suppressed ionization by the Magnetic Cage",
    "authors": [
      "Amirhossein Momtaheni",
      "Mohammadsadegh Khazali"
    ],
    "abstract": "Atomic processing units require robust entanglement between individual\nqubits, typically achieved via excitation to highly interacting Rydberg states.\nHowever, short Rydberg lifetimes and ionization risks limit the quantum volume\nscore of the atomic processing units. Inspired by Landau resonances in alkaline\natoms, we introduce Rydberg-Landau (rLandau) states created under a strong\nmagnetic field (2.5 Tesla). These states exhibit significantly extended\nlifetimes and a magnetic confinement mechanism that prevents ionization, even\nunder intense laser fields. We analyze their wavefunctions, excitation\ndynamics, dipole transition rules, lifetimes, and interactions, identifying\nstates optimal for high-fidelity quantum operations. This approach simplifies\nthe coherent excitation of long-lived, strongly interacting rLandau circular\nstates akin to Coulombic counterparts, enabling deeper and more complex quantum\nalgorithms.",
    "pdf_url": "http://arxiv.org/pdf/2506.00575v1",
    "published": "2025-05-31T14:14:01+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00574v1",
    "title": "Prompt-Tuned LLM-Augmented DRL for Dynamic O-RAN Network Slicing",
    "authors": [
      "Fatemeh Lotfi",
      "Hossein Rajoli",
      "Fatemeh Afghah"
    ],
    "abstract": "Modern wireless networks must adapt to dynamic conditions while efficiently\nmanaging diverse service demands. Traditional deep reinforcement learning (DRL)\nstruggles in these environments, as scattered and evolving feedback makes\noptimal decision-making challenging. Large Language Models (LLMs) offer a\nsolution by structuring unorganized network feedback into meaningful latent\nrepresentations, helping RL agents recognize patterns more effectively. For\nexample, in O-RAN slicing, concepts like SNR, power levels and throughput are\nsemantically related, and LLMs can naturally cluster them, providing a more\ninterpretable state representation. To leverage this capability, we introduce a\ncontextualization-based adaptation method that integrates learnable prompts\ninto an LLM-augmented DRL framework. Instead of relying on full model\nfine-tuning, we refine state representations through task-specific prompts that\ndynamically adjust to network conditions. Utilizing ORANSight, an LLM trained\non O-RAN knowledge, we develop Prompt-Augmented Multi agent RL (PA-MRL)\nframework. Learnable prompts optimize both semantic clustering and RL\nobjectives, allowing RL agents to achieve higher rewards in fewer iterations\nand adapt more efficiently. By incorporating prompt-augmented learning, our\napproach enables faster, more scalable, and adaptive resource allocation in\nO-RAN slicing. Experimental results show that it accelerates convergence and\noutperforms other baselines.",
    "pdf_url": "http://arxiv.org/pdf/2506.00574v1",
    "published": "2025-05-31T14:12:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00573v1",
    "title": "Neural Estimation for Scaling Entropic Multimarginal Optimal Transport",
    "authors": [
      "Dor Tsur",
      "Ziv Goldfeld",
      "Kristjan Greenewald",
      "Haim Permuter"
    ],
    "abstract": "Multimarginal optimal transport (MOT) is a powerful framework for modeling\ninteractions between multiple distributions, yet its applicability is\nbottlenecked by a high computational overhead. Entropic regularization provides\ncomputational speedups via the multimarginal Sinkhorn algorithm, whose time\ncomplexity, for a dataset size $n$ and $k$ marginals, generally scales as\n$O(n^k)$. However, this dependence on the dataset size $n$ is computationally\nprohibitive for many machine learning problems. In this work, we propose a new\ncomputational framework for entropic MOT, dubbed Neural Entropic MOT (NEMOT),\nthat enjoys significantly improved scalability. NEMOT employs neural networks\ntrained using mini-batches, which transfers the computational complexity from\nthe dataset size to the size of the mini-batch, leading to substantial gains.\nWe provide formal guarantees on the accuracy of NEMOT via non-asymptotic error\nbounds. We supplement these with numerical results that demonstrate the\nperformance gains of NEMOT over Sinkhorn's algorithm, as well as extensions to\nneural computation of multimarginal entropic Gromov-Wasserstein alignment. In\nparticular, orders-of-magnitude speedups are observed relative to the\nstate-of-the-art, with a notable increase in the feasible number of samples and\nmarginals. NEMOT seamlessly integrates as a module in large-scale machine\nlearning pipelines, and can serve to expand the practical applicability of\nentropic MOT for tasks involving multimarginal data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00573v1",
    "published": "2025-05-31T14:10:27+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00572v1",
    "title": "Machine-learning Growth at Risk",
    "authors": [
      "Tobias Adrian",
      "Hongqi Chen",
      "Max-Sebastian Dovì",
      "Ji Hyung Lee"
    ],
    "abstract": "We analyse growth vulnerabilities in the US using quantile partial\ncorrelation regression, a selection-based machine-learning method that achieves\nmodel selection consistency under time series. We find that downside risk is\nprimarily driven by financial, labour-market, and housing variables, with their\nimportance changing over time. Decomposing downside risk into its individual\ncomponents, we construct sector-specific indices that predict it, while\ncontrolling for information from other sectors, thereby isolating the downside\nrisks emanating from each sector.",
    "pdf_url": "http://arxiv.org/pdf/2506.00572v1",
    "published": "2025-05-31T14:06:53+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.00571v1",
    "title": "Triangles in the Plane and arithmetic progressions in thick compact subsets of $\\mathbb{R}^d$",
    "authors": [
      "Samantha Sandberg",
      "Krystal Taylor"
    ],
    "abstract": "This article focuses on the occurrence of three-point configurations in\nsubsets of $\\mathbb{R}^d$ for $d\\geq 1$ of sufficient thickness. We prove that\ncompact sets $A\\subset \\mathbb{R}^d$ contain a similar copy of any linear $3$\npoint configuration provided $A$ satisfies a mild Yavicoli-thickness condition\nand an $r$-uniformity condition for $d\\geq 2$; or, when $d=1$, the result holds\nprovided the Newhouse thickness of $A$ is at least $1$.\n  Moreover, we prove that compact sets $A\\subset \\mathbb{R}^2$ contain the\nvertices of an equilateral triangle (and more generally, the vertices of a\nsimilar copy of any given triangle) provided $A$ satisfies a mild\nYavicoli-thickness condition and an $r$-uniformity condition. Further, $C\\times\nC$ contains the vertices of an equilateral triangle (and more generally the\nvertices of a similar copy of any given three-point configuration) provided the\nNewhouse thickness of $C$ is at least $1$. These are among the first results in\nthe literature to give explicit criteria for the occurrence of three-point\nconfigurations in the plane.",
    "pdf_url": "http://arxiv.org/pdf/2506.00571v1",
    "published": "2025-05-31T14:03:13+00:00",
    "categories": [
      "math.CA",
      "math.CO"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00570v1",
    "title": "A \"Wenlu\" Brain System for Multimodal Cognition and Embodied Decision-Making: A Secure New Architecture for Deep Integration of Foundation Models and Domain Knowledge",
    "authors": [
      "Liang Geng"
    ],
    "abstract": "With the rapid penetration of artificial intelligence across industries and\nscenarios, a key challenge in building the next-generation intelligent core\nlies in effectively integrating the language understanding capabilities of\nfoundation models with domain-specific knowledge bases in complex real-world\napplications. This paper proposes a multimodal cognition and embodied\ndecision-making brain system, ``Wenlu\", designed to enable secure fusion of\nprivate knowledge and public models, unified processing of multimodal data such\nas images and speech, and closed-loop decision-making from cognition to\nautomatic generation of hardware-level code. The system introduces a\nbrain-inspired memory tagging and replay mechanism, seamlessly integrating\nuser-private data, industry-specific knowledge, and general-purpose language\nmodels. It provides precise and efficient multimodal services for enterprise\ndecision support, medical analysis, autonomous driving, robotic control, and\nmore. Compared with existing solutions, ``Wenlu\" demonstrates significant\nadvantages in multimodal processing, privacy security, end-to-end hardware\ncontrol code generation, self-learning, and sustainable updates, thus laying a\nsolid foundation for constructing the next-generation intelligent core.",
    "pdf_url": "http://arxiv.org/pdf/2506.00570v1",
    "published": "2025-05-31T14:01:34+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.06335v2",
    "title": "FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in Finance-Specific Deployment of Large Language Models",
    "authors": [
      "Xuan Xu",
      "Fufang Wen",
      "Beilin Chu",
      "Zhibing Fu",
      "Qinhong Lin",
      "Jiaqi Liu",
      "Binjie Fei",
      "Yu Li",
      "Linna Zhou",
      "Zhongliang Yang"
    ],
    "abstract": "In natural language processing (NLP), the focus has shifted from encoder-only\ntiny language models like BERT to decoder-only large language models(LLMs) such\nas GPT-3. However, LLMs' practical application in the financial sector has\nrevealed three limitations: (1) LLMs often perform worse than fine-tuned BERT\non discriminative tasks despite costing much higher computational resources,\nsuch as market sentiment analysis in financial reports; (2) Application on\ngenerative tasks heavily relies on retrieval augmented generation (RAG) methods\nto provide current and specialized information, with general retrievers showing\nsuboptimal performance on domain-specific retrieval tasks; (3) There are\nadditional inadequacies in other feature-based scenarios, such as topic\nmodeling. We introduce FinBERT2, a specialized bidirectional encoder pretrained\non a high-quality, financial-specific corpus of 32b tokens. This represents the\nlargest known Chinese financial pretraining corpus for models of this parameter\nsize. As a better backbone, FinBERT2 can bridge the gap in the\nfinancial-specific deployment of LLMs through the following achievements: (1)\nDiscriminative fine-tuned models (Fin-Labelers) outperform other (Fin)BERT\nvariants by 0.4%-3.3% and leading LLMs by 9.7%-12.3% on average across five\nfinancial classification tasks. (2) Contrastive fine-tuned models\n(Fin-Retrievers) outperform both open-source (e.g., +6.8\\% avg improvement over\nBGE-base-zh) and proprietary (e.g., +4.2\\% avg improvement over OpenAI's\ntext-embedding-3-large) embedders across five financial retrieval tasks; (3)\nBuilding on FinBERT2 variants, we construct the Fin-TopicModel, which enables\nsuperior clustering and topic representation for financial titles. Our work\nrevisits financial BERT models through comparative analysis with contemporary\nLLMs and offers practical insights for effectively utilizing FinBERT in the\nLLMs era.",
    "pdf_url": "http://arxiv.org/pdf/2506.06335v2",
    "published": "2025-05-31T13:59:44+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00569v1",
    "title": "AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs",
    "authors": [
      "Nicholas E. Corrado",
      "Julian Katz-Samuels",
      "Adithya Devraj",
      "Hyokun Yun",
      "Chao Zhang",
      "Yi Xu",
      "Yi Pan",
      "Bing Yin",
      "Trishul Chilimbi"
    ],
    "abstract": "When aligning large language models (LLMs), their performance on various\ntasks (such as being helpful, harmless, and honest) depends heavily on the\ncomposition of their training data. However, selecting a data mixture that\nachieves strong performance across all tasks is challenging. Existing\napproaches rely on large ablation studies, heuristics, or human intuition, but\nthese can be prohibitively expensive and suboptimal. We study this problem in\nthe setting of preference optimization via DPO and introduce AutoMixAlign\n(AMA), a theoretically-grounded algorithm that adaptively mixes datasets during\ntraining to balance performance across tasks. AMA first trains\n\\textit{specialist models} for each task to determine losses that correspond to\nstrong task performance. Then, it trains a generalist model using a novel\nminimax optimization that prioritizes tasks for which generalist model losses\ndeviate most from specialist model losses. To optimize this problem, we propose\ntwo algorithms: (1) AMA-R, which adaptively reweights the objective to\nprioritize tasks, and (2) AMA-S, which adaptively adjusts how much data is\nsampled from each task to prioritize tasks. Both algorithms achieve a\nconvergence rate of $O(1/\\sqrt{T})$ in the convex case. AMA-R's convergence\nresult follows from Sagawa et al. (2019), and we provide a convergence proof\nfor AMA-S using online learning techniques such as EXP3. We evaluate AMA on\nseveral multitask alignment setups and find that AMA outperforms the standard\nalignment approach -- which simply optimizes the total loss across all tasks --\nand also outperforms model merging methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00569v1",
    "published": "2025-05-31T13:57:10+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00568v1",
    "title": "CReFT-CAD: Boosting Orthographic Projection Reasoning for CAD via Reinforcement Fine-Tuning",
    "authors": [
      "Ke Niu",
      "Zhuofan Chen",
      "Haiyang Yu",
      "Yuwen Chen",
      "Teng Fu",
      "Mengyang Zhao",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "abstract": "Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing.\nOrthographic projection reasoning underpins the entire CAD workflow,\nencompassing design, manufacturing, and simulation. However, prevailing\ndeep-learning approaches employ standard 3D reconstruction pipelines as an\nalternative, which often introduce imprecise dimensions and limit the\nparametric editability required for CAD workflows. Recently, some researchers\nadopt vision-language models (VLMs), particularly supervised fine-tuning (SFT),\nto tackle CAD-related challenges. SFT shows promise but often devolves into\npattern memorization, yielding poor out-of-distribution performance on complex\nreasoning tasks. To address these gaps, we introduce CReFT-CAD, a two-stage\nfine-tuning paradigm that first employs a curriculum-driven reinforcement\nlearning stage with difficulty-aware rewards to build reasoning ability\nsteadily, and then applies supervised post-tuning to hone instruction following\nand semantic extraction. Complementing this, we release TriView2CAD, the first\nlarge-scale, open-source benchmark for orthographic projection reasoning,\ncomprising 200,000 synthetic and 3,000 real-world orthographic projections with\nprecise dimension annotations and six interoperable data modalities. We\nbenchmark leading VLMs on orthographic projection reasoning and demonstrate\nthat CReFT-CAD substantially improves reasoning accuracy and\nout-of-distribution generalizability in real-world scenarios, offering valuable\ninsights for advancing CAD reasoning research.",
    "pdf_url": "http://arxiv.org/pdf/2506.00568v1",
    "published": "2025-05-31T13:52:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00567v1",
    "title": "Existence and Properties of Frames of Iterations",
    "authors": [
      "A. Aguilera",
      "C. Cabrelli",
      "F. Negreira",
      "V. Paternostro"
    ],
    "abstract": "Let T be a bounded operator acting on an infinite-dimensional Hilbert space.\nWe provide necessary and sufficient conditions for the existence of a Parseval\nframe of iterations generated by T. Based in this result, we give a new proof\nof a known characterization concerning the existence of (not necessarily\nParseval) frames of iterations. As a consequence of our results, we obtain that\ncertain operators lack Parseval frames despite possessing frames of iterations.\nIn addition, we introduce the index of a bounded operator T as the minimal\nnumber of vectors required to generate a frame via its iterations. We obtain\nthe exact value of this index for both Parseval frames and general frames of\niterations, and we give a constructive method for generating such frames.\nAssuming that T satisfies the conditions ensuring that both T and T^* admit\nframes of iterations, we show how to construct Parseval frames generated by\niterations of T and also by iterations of T^*. This construction relies on\nuniversal models in vector-valued Hardy spaces and the theory of universal\ndilations. Furthermore, we provide necessary and sufficient conditions under\nwhich the frames generated by T and T^* are similar, in terms of the inner\nfunction of the associated model in the Hardy space of the operator T.",
    "pdf_url": "http://arxiv.org/pdf/2506.00567v1",
    "published": "2025-05-31T13:52:15+00:00",
    "categories": [
      "math.FA",
      "42C15, 47A15, 47A45, 30H10"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00566v1",
    "title": "Communication Efficient Multiparty Private Set Intersection from Multi-Point Sequential OPRF",
    "authors": [
      "Xinyu Feng",
      "Yukun Wang",
      "Cong Li",
      "Wu Xin",
      "Ming Yao",
      "Dian Zhang",
      "Wanwan Wang",
      "Hao He"
    ],
    "abstract": "Multiparty private set intersection (MPSI) allows multiple participants to\ncompute the intersection of their locally owned data sets without revealing\nthem. MPSI protocols can be categorized based on the network topology of nodes,\nwith the star, mesh, and ring topologies being the primary types, respectively.\nGiven that star and mesh topologies dominate current implementations, most\nexisting MPSI protocols are based on these two topologies. However,\nstar-topology MPSI protocols suffer from high leader node load, while mesh\ntopology protocols suffer from high communication complexity and overhead. In\nthis paper, we first propose a multi-point sequential oblivious pseudorandom\nfunction (MP-SOPRF) in a multi-party setting. Based on MP-SOPRF, we then\ndevelop an MPSI protocol with a ring topology, addressing the challenges of\ncommunication and computational overhead in existing protocols. We prove that\nour MPSI protocol is semi-honest secure under the Hamming correlation\nrobustness assumption. Our experiments demonstrate that our MPSI protocol\noutperforms state-of-the-art protocols, achieving a reduction of 74.8% in\ncommunication and a 6% to 287% improvement in computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2506.00566v1",
    "published": "2025-05-31T13:50:40+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00565v1",
    "title": "Asymptotic Plateau problem for $2$-convex hypersurface in $\\mathbb{H}^4$",
    "authors": [
      "Defa Chen",
      "Zhenan Sui",
      "Letao Sun"
    ],
    "abstract": "We prove the existence of smooth complete $2$-convex hypersurface which\nsatisfies prescribed curvature equation $(\\kappa_1 + \\kappa_2)(\\kappa_1 +\n\\kappa_3)(\\kappa_2 + \\kappa_3) = (2 \\sigma)^3$ and has prescribed asymptotic\nboundary at infinity of hyperbolic space of dimension 4, where $\\sigma \\in (0,\n1)$ is a constant. We also prove the existence for $\\sigma_k (\\kappa_2 + \\cdots\n+ \\kappa_n, \\cdots, \\kappa_1 + \\cdots + \\kappa_{n - 1}) = C_n^k (n - 1)^k\n\\sigma^k$ with $k < n$ in $\\mathbb{H}^{n + 1}$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00565v1",
    "published": "2025-05-31T13:46:37+00:00",
    "categories": [
      "math.DG",
      "math.AP"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00564v1",
    "title": "Image Restoration Learning via Noisy Supervision in the Fourier Domain",
    "authors": [
      "Haosen Liu",
      "Jiahao Liu",
      "Shan Tan",
      "Edmund Y. Lam"
    ],
    "abstract": "Noisy supervision refers to supervising image restoration learning with noisy\ntargets. It can alleviate the data collection burden and enhance the practical\napplicability of deep learning techniques. However, existing methods suffer\nfrom two key drawbacks. Firstly, they are ineffective in handling spatially\ncorrelated noise commonly observed in practical applications such as low-light\nimaging and remote sensing. Secondly, they rely on pixel-wise loss functions\nthat only provide limited supervision information. This work addresses these\nchallenges by leveraging the Fourier domain. We highlight that the Fourier\ncoefficients of spatially correlated noise exhibit sparsity and independence,\nmaking them easier to handle. Additionally, Fourier coefficients contain global\ninformation, enabling more significant supervision. Motivated by these\ninsights, we propose to establish noisy supervision in the Fourier domain. We\nfirst prove that Fourier coefficients of a wide range of noise converge in\ndistribution to the Gaussian distribution. Exploiting this statistical\nproperty, we establish the equivalence between using noisy targets and clean\ntargets in the Fourier domain. This leads to a unified learning framework\napplicable to various image restoration tasks, diverse network architectures,\nand different noise models. Extensive experiments validate the outstanding\nperformance of this framework in terms of both quantitative indices and\nperceptual quality.",
    "pdf_url": "http://arxiv.org/pdf/2506.00564v1",
    "published": "2025-05-31T13:43:56+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00563v2",
    "title": "Understanding Behavioral Metric Learning: A Large-Scale Study on Distracting Reinforcement Learning Environments",
    "authors": [
      "Ziyan Luo",
      "Tianwei Ni",
      "Pierre-Luc Bacon",
      "Doina Precup",
      "Xujie Si"
    ],
    "abstract": "A key approach to state abstraction is approximating behavioral metrics\n(notably, bisimulation metrics) in the observation space and embedding these\nlearned distances in the representation space. While promising for robustness\nto task-irrelevant noise, as shown in prior work, accurately estimating these\nmetrics remains challenging, requiring various design choices that create gaps\nbetween theory and practice. Prior evaluations focus mainly on final returns,\nleaving the quality of learned metrics and the source of performance gains\nunclear. To systematically assess how metric learning works in deep\nreinforcement learning (RL), we evaluate five recent approaches, unified\nconceptually as isometric embeddings with varying design choices. We benchmark\nthem with baselines across 20 state-based and 14 pixel-based tasks, spanning\n370 task configurations with diverse noise settings. Beyond final returns, we\nintroduce the evaluation of a denoising factor to quantify the encoder's\nability to filter distractions. To further isolate the effect of metric\nlearning, we propose and evaluate an isolated metric estimation setting, in\nwhich the encoder is influenced solely by the metric loss. Finally, we release\nan open-source, modular codebase to improve reproducibility and support future\nresearch on metric learning in deep RL.",
    "pdf_url": "http://arxiv.org/pdf/2506.00563v2",
    "published": "2025-05-31T13:43:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00562v1",
    "title": "SEED: A Benchmark Dataset for Sequential Facial Attribute Editing with Diffusion Models",
    "authors": [
      "Yule Zhu",
      "Ping Liu",
      "Zhedong Zheng",
      "Wei Liu"
    ],
    "abstract": "Diffusion models have recently enabled precise and photorealistic facial\nediting across a wide range of semantic attributes. Beyond single-step\nmodifications, a growing class of applications now demands the ability to\nanalyze and track sequences of progressive edits, such as stepwise changes to\nhair, makeup, or accessories. However, sequential editing introduces\nsignificant challenges in edit attribution and detection robustness, further\ncomplicated by the lack of large-scale, finely annotated benchmarks tailored\nexplicitly for this task. We introduce SEED, a large-scale Sequentially Edited\nfacE Dataset constructed via state-of-the-art diffusion models. SEED contains\nover 90,000 facial images with one to four sequential attribute modifications,\ngenerated using diverse diffusion-based editing pipelines (LEdits, SDXL, SD3).\nEach image is annotated with detailed edit sequences, attribute masks, and\nprompts, facilitating research on sequential edit tracking, visual provenance\nanalysis, and manipulation robustness assessment. To benchmark this task, we\npropose FAITH, a frequency-aware transformer-based model that incorporates\nhigh-frequency cues to enhance sensitivity to subtle sequential changes.\nComprehensive experiments, including systematic comparisons of multiple\nfrequency-domain methods, demonstrate the effectiveness of FAITH and the unique\nchallenges posed by SEED. SEED offers a challenging and flexible resource for\nstudying progressive diffusion-based edits at scale. Dataset and code will be\npublicly released at: https://github.com/Zeus1037/SEED.",
    "pdf_url": "http://arxiv.org/pdf/2506.00562v1",
    "published": "2025-05-31T13:39:45+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00561v1",
    "title": "Assessing Climate-Driven Mortality Risk: A Stochastic Approach with Distributed Lag Non-Linear Models",
    "authors": [
      "Jiacheng Min",
      "Han Li",
      "Thomas Nagler",
      "Shuanming Li"
    ],
    "abstract": "Assessing climate-driven mortality risk has become an emerging area of\nresearch in recent decades. In this paper, we propose a novel approach to\nexplicitly incorporate climate-driven effects into both single- and\nmulti-population stochastic mortality models. The new model consists of two\ncomponents: a stochastic mortality model, and a distributed lag non-linear\nmodel (DLNM). The first component captures the non-climate long-term trend and\nvolatility in mortality rates. The second component captures non-linear and\nlagged effects of climate variables on mortality, as well as the impact of heat\nwaves and cold waves across different age groups. For model calibration, we\npropose a backfitting algorithm that allows us to disentangle the\nclimate-driven mortality risk from the non-climate-driven stochastic mortality\nrisk. We illustrate the effectiveness and superior performance of our model\nusing data from three European regions: Athens, Lisbon, and Rome. Furthermore,\nwe utilize future UTCI data generated from climate models to provide mortality\nprojections into 2045 across these regions under two Representative\nConcentration Pathway (RCP) scenarios. The projections show a noticeable\ndecrease in winter mortality alongside a rise in summer mortality, driven by a\ngeneral increase in UTCI over time. Although we expect slightly lower overall\nmortality in the short term under RCP8.5 compared to RCP2.6, a long-term\nincrease in total mortality is anticipated under the RCP8.5 scenario.",
    "pdf_url": "http://arxiv.org/pdf/2506.00561v1",
    "published": "2025-05-31T13:36:11+00:00",
    "categories": [
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00560v1",
    "title": "Using Diffusion Ensembles to Estimate Uncertainty for End-to-End Autonomous Driving",
    "authors": [
      "Florian Wintel",
      "Sigmund H. Høeg",
      "Gabriel Kiss",
      "Frank Lindseth"
    ],
    "abstract": "End-to-end planning systems for autonomous driving are improving rapidly,\nespecially in closed-loop simulation environments like CARLA. Many such driving\nsystems either do not consider uncertainty as part of the plan itself, or\nobtain it by using specialized representations that do not generalize. In this\npaper, we propose EnDfuser, an end-to-end driving system that uses a diffusion\nmodel as the trajectory planner. EnDfuser effectively leverages complex\nperception information like fused camera and LiDAR features, through combining\nattention pooling and trajectory planning into a single diffusion transformer\nmodule. Instead of committing to a single plan, EnDfuser produces a\ndistribution of candidate trajectories (128 for our case) from a single\nperception frame through ensemble diffusion. By observing the full set of\ncandidate trajectories, EnDfuser provides interpretability for uncertain,\nmulti-modal future trajectory spaces, where there are multiple plausible\noptions. EnDfuser achieves a competitive driving score of 70.1 on the Longest6\nbenchmark in CARLA with minimal concessions on inference speed. Our findings\nsuggest that ensemble diffusion, used as a drop-in replacement for traditional\npoint-estimate trajectory planning modules, can help improve the safety of\ndriving decisions by modeling the uncertainty of the posterior trajectory\ndistribution.",
    "pdf_url": "http://arxiv.org/pdf/2506.00560v1",
    "published": "2025-05-31T13:33:27+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00559v2",
    "title": "Geometric adiabatic angle in anisotropic oscillators",
    "authors": [
      "Fumika Suzuki",
      "Nikolai A. Sinitsyn"
    ],
    "abstract": "We discuss a classical anisotropic oscillator and the Foucault pendulum as\nexamples illustrating non-conservation of action variables in integrable\nclassical mechanical systems with adiabatically slow evolution. We also\nemphasize the importance of the mass parameter of a harmonic oscillator,\nalongside its frequency, in explicitly time-dependent situations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00559v2",
    "published": "2025-05-31T13:30:26+00:00",
    "categories": [
      "physics.class-ph"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00558v2",
    "title": "ViVo: A Dataset for Volumetric Video Reconstruction and Compression",
    "authors": [
      "Adrian Azzarelli",
      "Ge Gao",
      "Ho Man Kwan",
      "Fan Zhang",
      "Nantheera Anantrasirichai",
      "Ollie Moolan-Feroze",
      "David Bull"
    ],
    "abstract": "As research on neural volumetric video reconstruction and compression\nflourishes, there is a need for diverse and realistic datasets, which can be\nused to develop and validate reconstruction and compression models. However,\nexisting volumetric video datasets lack diverse content in terms of both\nsemantic and low-level features that are commonly present in real-world\nproduction pipelines. In this context, we propose a new dataset, ViVo, for\nVolumetrIc VideO reconstruction and compression. The dataset is faithful to\nreal-world volumetric video production and is the first dataset to extend the\ndefinition of diversity to include both human-centric characteristics (skin,\nhair, etc.) and dynamic visual phenomena (transparent, reflective, liquid,\netc.). Each video sequence in this database contains raw data including\nfourteen multi-view RGB and depth video pairs, synchronized at 30FPS with\nper-frame calibration and audio data, and their associated 2-D foreground masks\nand 3-D point clouds. To demonstrate the use of this database, we have\nbenchmarked three state-of-the-art (SotA) 3-D reconstruction methods and two\nvolumetric video compression algorithms. The obtained results evidence the\nchallenging nature of the proposed dataset and the limitations of existing\ndatasets for both volumetric video reconstruction and compression tasks,\nhighlighting the need to develop more effective algorithms for these\napplications. The database and the associated results are available at\nhttps://vivo-bvicr.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2506.00558v2",
    "published": "2025-05-31T13:30:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.03192v1",
    "title": "Encoding of Demographic and Anatomical Information in Chest X-Ray-based Severe Left Ventricular Hypertrophy Classifiers",
    "authors": [
      "Basudha Pal",
      "Rama Chellappa",
      "Muhammad Umair"
    ],
    "abstract": "While echocardiography and MRI are clinical standards for evaluating cardiac\nstructure, their use is limited by cost and accessibility.We introduce a direct\nclassification framework that predicts severe left ventricular hypertrophy from\nchest X-rays, without relying on anatomical measurements or demographic inputs.\nOur approach achieves high AUROC and AUPRC, and employs Mutual Information\nNeural Estimation to quantify feature expressivity. This reveals clinically\nmeaningful attribute encoding and supports transparent model interpretation.",
    "pdf_url": "http://arxiv.org/pdf/2506.03192v1",
    "published": "2025-05-31T13:30:04+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00557v1",
    "title": "Score Matching With Missing Data",
    "authors": [
      "Josh Givens",
      "Song Liu",
      "Henry W J Reeve"
    ],
    "abstract": "Score matching is a vital tool for learning the distribution of data with\napplications across many areas including diffusion processes, energy based\nmodelling, and graphical model estimation. Despite all these applications,\nlittle work explores its use when data is incomplete. We address this by\nadapting score matching (and its major extensions) to work with missing data in\na flexible setting where data can be partially missing over any subset of the\ncoordinates. We provide two separate score matching variations for general use,\nan importance weighting (IW) approach, and a variational approach. We provide\nfinite sample bounds for our IW approach in finite domain settings and show it\nto have especially strong performance in small sample lower dimensional cases.\nComplementing this, we show our variational approach to be strongest in more\ncomplex high-dimensional settings which we demonstrate on graphical model\nestimation tasks on both real and simulated data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00557v1",
    "published": "2025-05-31T13:26:51+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00556v1",
    "title": "Estimands for Randomized Discontinuation Designs in Oncology",
    "authors": [
      "Ayon Mukherjee",
      "Oleksandr Sverdlov",
      "Ngoc-Thuy Ha",
      "Yu Deng"
    ],
    "abstract": "Randomized discontinuation design (RDD) is an enrichment strategy commonly\nused to address limitations of traditional placebo-controlled trials,\nparticularly the ethical concern of prolonged placebo exposure. RDD consists of\ntwo phases: an initial open-label phase in which all eligible patients receive\nthe investigational medicinal product (IMP), followed by a double-blind phase\nin which responders are randomized to continue with the IMP or switch to\nplacebo. This design tests whether the IMP provides benefit beyond the placebo\neffect. The estimand framework introduced in ICH E9(R1) strengthens the\ndialogue among clinical research stakeholders by clarifying trial objectives\nand aligning them with appropriate statistical analyses. However, its\napplication in oncology trials using RDD remains unclear. This manuscript uses\nthe phase III JAVELIN Gastric 100 trial and the phase II trial of sorafenib\n(BAY 43-9006) as case studies to propose an estimand framework tailored for\noncology trials employing RDD in phase III and phase II settings, respectively.\nWe highlight some similarities and differences between RDDs and traditional\nrandomized controlled trials in the context of ICH E9(R1). This approach aims\nto support more efficient regulatory decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2506.00556v1",
    "published": "2025-05-31T13:24:05+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.00555v2",
    "title": "MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning",
    "authors": [
      "Peng Xia",
      "Jinglu Wang",
      "Yibo Peng",
      "Kaide Zeng",
      "Xian Wu",
      "Xiangru Tang",
      "Hongtu Zhu",
      "Yun Li",
      "Shujie Liu",
      "Yan Lu",
      "Huaxiu Yao"
    ],
    "abstract": "Medical Large Vision-Language Models (Med-LVLMs) have shown strong potential\nin multimodal diagnostic tasks. However, existing single-agent models struggle\nto generalize across diverse medical specialties, limiting their performance.\nRecent efforts introduce multi-agent collaboration frameworks inspired by\nclinical workflows, where general practitioners (GPs) and specialists interact\nin a fixed sequence. Despite improvements, these static pipelines lack\nflexibility and adaptability in reasoning. To address this, we propose\nMMedAgent-RL, a reinforcement learning (RL)-based multi-agent framework that\nenables dynamic, optimized collaboration among medical agents. Specifically, we\ntrain two GP agents based on Qwen2.5-VL via RL: the triage doctor learns to\nassign patients to appropriate specialties, while the attending physician\nintegrates the judgments from multi-specialists and its own knowledge to make\nfinal decisions. To address the inconsistency in specialist outputs, we\nintroduce a curriculum learning (CL)-guided RL strategy that progressively\nteaches the attending physician to balance between imitating specialists and\ncorrecting their mistakes. Experiments on five medical VQA benchmarks\ndemonstrate that MMedAgent-RL not only outperforms both open-source and\nproprietary Med-LVLMs, but also exhibits human-like reasoning patterns.\nNotably, it achieves an average performance gain of 20.7% over supervised\nfine-tuning baselines.",
    "pdf_url": "http://arxiv.org/pdf/2506.00555v2",
    "published": "2025-05-31T13:22:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00554v1",
    "title": "Two-Sided Manipulation Games in Stable Matching Markets",
    "authors": [
      "Hadi Hosseini",
      "Grzegorz Lisowski",
      "Shraddha Pathak"
    ],
    "abstract": "The Deferred Acceptance (DA) algorithm is an elegant procedure for finding a\nstable matching in two-sided matching markets. It ensures that no pair of\nagents prefers each other to their matched partners. In this work, we initiate\nthe study of two-sided manipulations in matching markets as non-cooperative\ngames. We introduce the accomplice manipulation game, where a man misreports to\nhelp a specific woman obtain a better partner, whenever possible. We provide a\npolynomial time algorithm for finding a pure strategy Nash equilibrium (NE) and\nshow that our algorithm always yields a stable matching - although not every\nNash equilibrium corresponds to a stable matching. Additionally, we show how\nour analytical techniques for the accomplice manipulation game can be applied\nto other manipulation games in matching markets, such as one-for-many and the\nstandard self-manipulation games. We complement our theoretical findings with\nempirical evaluations of different properties of the resulting NE, such as the\nwelfare of the agents.",
    "pdf_url": "http://arxiv.org/pdf/2506.00554v1",
    "published": "2025-05-31T13:19:31+00:00",
    "categories": [
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00553v1",
    "title": "Boundedness of complements for fibered Fano threefolds in positive characteristic",
    "authors": [
      "Xintong Jiang"
    ],
    "abstract": "In this paper, we prove Shokurov's conjecture on boundedness of complements\nfor Fano type threefold pairs $(X,B)$ with fibration structures in large\ncharacteristics. In particular, we prove the conjecture when\n$-(K_X+B)\\not\\equiv 0$ is nef and not big in large characteristics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00553v1",
    "published": "2025-05-31T13:19:02+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00552v1",
    "title": "Drawdowns, Drawups, and Occupation Times under General Markov Models",
    "authors": [
      "Pingping Zeng",
      "Gongqiu Zhang",
      "Weinan Zhang"
    ],
    "abstract": "Drawdown risk, an important metric in financial risk management, poses\nsignificant computational challenges due to its highly path-dependent nature.\nThis paper proposes a unified framework for computing five important drawdown\nquantities introduced in Landriault et al. (2015) and Zhang (2015) under\ngeneral Markov models. We first establish linear systems and develop efficient\nalgorithms for such problems under continuous-time Markov chains (CTMCs), and\nthen establish their theoretical convergence to target quantities under general\nMarkov models. Notably, the proposed algorithms for most quantities achieve the\nsame complexity order as those for path-independent problems: cubic in the\nnumber of CTMC states for general Markov models and linear when applied to\ndiffusion models. Rigorous convergence analysis is conducted under weak\nregularity conditions, and extensive numerical experiments validate the\naccuracy and efficiency of the proposed algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2506.00552v1",
    "published": "2025-05-31T13:15:53+00:00",
    "categories": [
      "q-fin.MF"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2506.00551v2",
    "title": "AnnaAgent: Dynamic Evolution Agent System with Multi-Session Memory for Realistic Seeker Simulation",
    "authors": [
      "Ming Wang",
      "Peidong Wang",
      "Lin Wu",
      "Xiaocui Yang",
      "Daling Wang",
      "Shi Feng",
      "Yuxin Chen",
      "Bixuan Wang",
      "Yifei Zhang"
    ],
    "abstract": "Constrained by the cost and ethical concerns of involving real seekers in\nAI-driven mental health, researchers develop LLM-based conversational agents\n(CAs) with tailored configurations, such as profiles, symptoms, and scenarios,\nto simulate seekers. While these efforts advance AI in mental health, achieving\nmore realistic seeker simulation remains hindered by two key challenges:\ndynamic evolution and multi-session memory. Seekers' mental states often\nfluctuate during counseling, which typically spans multiple sessions. To\naddress this, we propose AnnaAgent, an emotional and cognitive dynamic agent\nsystem equipped with tertiary memory. AnnaAgent incorporates an emotion\nmodulator and a complaint elicitor trained on real counseling dialogues,\nenabling dynamic control of the simulator's configurations. Additionally, its\ntertiary memory mechanism effectively integrates short-term and long-term\nmemory across sessions. Evaluation results, both automated and manual,\ndemonstrate that AnnaAgent achieves more realistic seeker simulation in\npsychological counseling compared to existing baselines. The ethically reviewed\nand screened code can be found on https://github.com/sci-m-wang/AnnaAgent.",
    "pdf_url": "http://arxiv.org/pdf/2506.00551v2",
    "published": "2025-05-31T13:15:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00550v1",
    "title": "Identifying hyperons in neutron star matter from the slope of the mass-radius diagram",
    "authors": [
      "Márcio Ferreira",
      "Constança Providência"
    ],
    "abstract": "The slope of the neutron star mass radius curve $dM/dR$ determined from two\nlarge sets of relativistic mean field equations of state for nucleonic and\nhyperonic neutron star matter is discussed. It is shown that if the mass-radius\ncurve always has a negative slope the probability that the star has hyperons is\nvery small. A very small probability of the presence of hyperons can already be\nidentified by a negative slope for low-mass stars. A positive slope at\n$M/M_{\\odot} = 1.4$, could indicate the possible presence of hyperons.\nNucleonic EoS are found to be more probable than hyperonic ones, given the\nGW170817 and NICER observation constraints for PSR J0030+0451 and PSR\nJ0740+6620, and the highest probability is associated with nucleonic stars that\noriginate a mass radius curve with positive slope. Mass-radius curves with a\npositive slope greater than 1.8$M_\\odot$ are not expected to occur. The nuclear\nmatter property that most distinguishes the different scenarios is the\ncurvature of the symmetry energy, with nucleonic EoS with positive slope\npredicting the highest values that can go above 100 MeV.",
    "pdf_url": "http://arxiv.org/pdf/2506.00550v1",
    "published": "2025-05-31T13:13:59+00:00",
    "categories": [
      "nucl-th",
      "astro-ph.HE",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.00549v1",
    "title": "Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages",
    "authors": [
      "Hyangsuk Min",
      "Yuho Lee",
      "Minjeong Ban",
      "Jiaqi Deng",
      "Nicole Hee-Yeon Kim",
      "Taewon Yun",
      "Hang Su",
      "Jason Cai",
      "Hwanjun Song"
    ],
    "abstract": "Evaluation frameworks for text summarization have evolved in terms of both\ndomain coverage and metrics. However, existing benchmarks still lack\ndomain-specific assessment criteria, remain predominantly English-centric, and\nface challenges with human annotation due to the complexity of reasoning. To\naddress these, we introduce MSumBench, which provides a multi-dimensional,\nmulti-domain evaluation of summarization in English and Chinese. It also\nincorporates specialized assessment criteria for each domain and leverages a\nmulti-agent debate system to enhance annotation quality. By evaluating eight\nmodern summarization models, we discover distinct performance patterns across\ndomains and languages. We further examine large language models as summary\nevaluators, analyzing the correlation between their evaluation and\nsummarization capabilities, and uncovering systematic bias in their assessment\nof self-generated summaries. Our benchmark dataset is publicly available at\nhttps://github.com/DISL-Lab/MSumBench.",
    "pdf_url": "http://arxiv.org/pdf/2506.00549v1",
    "published": "2025-05-31T13:12:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00548v1",
    "title": "Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities",
    "authors": [
      "Jiahui Geng",
      "Thy Thy Tran",
      "Preslav Nakov",
      "Iryna Gurevych"
    ],
    "abstract": "Existing attacks against multimodal language models (MLLMs) primarily\ncommunicate instructions through text accompanied by adversarial images. In\ncontrast, we exploit the capabilities of MLLMs to interpret non-textual\ninstructions, specifically, adversarial images or audio generated by our novel\nmethod, Con Instruction. We optimize these adversarial examples to align\nclosely with target instructions in the embedding space, revealing the\ndetrimental implications of MLLMs' sophisticated understanding. Unlike prior\nwork, our method does not require training data or preprocessing of textual\ninstructions. While these non-textual adversarial examples can effectively\nbypass MLLM safety mechanisms, their combination with various text inputs\nsubstantially amplifies attack success. We further introduce a new Attack\nResponse Categorization (ARC) framework, which evaluates both the quality of\nthe model's response and its relevance to the malicious instructions.\nExperimental results demonstrate that Con Instruction effectively bypasses\nsafety mechanisms in multiple vision- and audio-language models, including\nLLaVA-v1.5, InternVL, Qwen-VL, and Qwen-Audio, evaluated on two standard\nbenchmarks: AdvBench and SafeBench. Specifically, our method achieves the\nhighest attack success rates, reaching 81.3% and 86.6% on LLaVA-v1.5 (13B). On\nthe defense side, we explore various countermeasures against our attacks and\nuncover a substantial performance gap among existing techniques. Our\nimplementation is made publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2506.00548v1",
    "published": "2025-05-31T13:11:14+00:00",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00547v1",
    "title": "Symmetrization for high dimensional dependent random variables",
    "authors": [
      "Jonathan B. Hill"
    ],
    "abstract": "We establish a generic symmetrization property for dependent random variables\n$\\{x_{t}\\}_{t=1}^{n}$ on $\\mathbb{R}^{p}$, where $p$ $>>$ $n$ is allowed. We\nlink $\\mathbb{E}\\psi (\\max_{1\\leq i\\leq p}|1/n\\sum_{t=1}^{n}(x_{i,t}$ $-$\n$\\mathbb{E}x_{i,t})|)$ to $\\mathbb{E}\\psi (\\max_{1\\leq i\\leq p}|1/n$\n$\\sum_{t=1}^{n}\\eta _{t}(x_{i,t}$ $-$ $\\mathbb{E}% x_{i,t})|)$ for\nnon-decreasing convex $\\psi $ $:$ $[0,\\infty )$ $\\rightarrow $ $\\mathbb{R}$,\nwhere $\\{\\eta _{t}\\}_{t=1}^{n}$ are block-wise independent random variables,\nwith a remainder term based on high dimensional Gaussian approximations that\nneed not hold at a high level. Conventional usage of $% \\eta _{t}(x_{i,t}$ $-$\n$\\tilde{x}_{i,t})$ with $\\{\\tilde{x}% _{i,t}\\}_{t=1}^{n} $ an independent copy\nof $\\{x_{i,t}\\}_{t=1}^{n}$, and Rademacher $\\eta _{t}$, is not required in a\ngeneric environment, although we may trivially replace $\\mathbb{E}x_{i,t}$ with\n$\\tilde{x}_{i,t}$. In the latter case with Rademacher $\\eta _{t}$ our result\nreduces to classic symmetrization under independence. We bound and therefore\nverify the Gaussian approximations in mixing and physical dependence settings,\nthus bounding $\\mathbb{E}\\psi (\\max_{1\\leq i\\leq p}|1/n\\sum_{t=1}^{n}(x_{i,t}$\n$-$ $\\mathbb{E}x_{i,t})|)$; and apply the main result to a generic % Nemirovski\n(2000)-like $\\mathcal{L}_{q}$-maximal moment bound for $\\mathbb{E}\\max_{1\\leq\ni\\leq p}|1/n\\sum_{t=1}^{n}(x_{i,t}$ $-$ $\\mathbb{E}x_{i,t})|^{q}$, $q$ $\\geq $\n$1$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00547v1",
    "published": "2025-05-31T13:11:05+00:00",
    "categories": [
      "math.PR",
      "math.ST",
      "stat.TH",
      "60-F10, 60-F25"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00546v1",
    "title": "Flying Co-Stereo: Enabling Long-Range Aerial Dense Mapping via Collaborative Stereo Vision of Dynamic-Baseline",
    "authors": [
      "Zhaoying Wang",
      "Xingxing Zuo",
      "Wei Dong"
    ],
    "abstract": "Lightweight long-range mapping is critical for safe navigation of UAV swarms\nin large-scale unknown environments. Traditional stereo vision systems with\nfixed short baselines face limited perception ranges. To address this, we\npropose Flying Co-Stereo, a cross-agent collaborative stereo vision system that\nleverages the wide-baseline spatial configuration of two UAVs for long-range\ndense mapping. Key innovations include: (1) a dual-spectrum\nvisual-inertial-ranging estimator for robust baseline estimation; (2) a hybrid\nfeature association strategy combining deep learning-based cross-agent matching\nand optical-flow-based intra-agent tracking; (3) A sparse-to-dense depth\nrecovery scheme,refining dense monocular depth predictions using exponential\nfitting of long-range triangulated sparse landmarks for precise metric-scale\nmapping. Experiments demonstrate the Flying Co-Stereo system achieves dense 3D\nmapping up to 70 meters with 2.3%-9.7% relative error, outperforming\nconventional systems by up to 350% in depth range and 450% in coverage area.\nThe project webpage: https://xingxingzuo.github.io/flying_co_stereo",
    "pdf_url": "http://arxiv.org/pdf/2506.00546v1",
    "published": "2025-05-31T13:11:02+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00545v1",
    "title": "Imputation of Missing Data in Smooth Pursuit Eye Movements Using a Self-Attention-based Deep Learning Approach",
    "authors": [
      "Mehdi Bejani",
      "Guillermo Perez-de-Arenaza-Pozo",
      "Julián D. Arias-Londoño",
      "Juan I. Godino-LLorente"
    ],
    "abstract": "Missing data is a relevant issue in time series, especially in biomedical\nsequences such as those corresponding to smooth pursuit eye movements, which\noften contain gaps due to eye blinks and track losses, complicating the\nanalysis and extraction of meaningful biomarkers. In this paper, a novel\nimputation framework is proposed using Self-Attention-based Imputation networks\nfor time series, which leverages the power of deep learning and self-attention\nmechanisms to impute missing data. We further refine the imputed data using a\ncustom made autoencoder, tailored to represent smooth pursuit eye movement\nsequences. The proposed approach was implemented using 5,504 sequences from 172\nParkinsonian patients and healthy controls. Results show a significant\nimprovement in the accuracy of reconstructed eye movement sequences with\nrespect to other state of the art techniques, substantially reducing the values\nfor common time domain error metrics such as the mean absolute error, mean\nrelative error, and root mean square error, while also preserving the signal's\nfrequency domain characteristics. Moreover, it demonstrates robustness when\nlarge intervals of data are missing. This method offers an alternative solution\nfor robustly handling missing data in time series, enhancing the reliability of\nsmooth pursuit analysis for the screening and monitoring of neurodegenerative\ndisorders.",
    "pdf_url": "http://arxiv.org/pdf/2506.00545v1",
    "published": "2025-05-31T13:10:30+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00544v1",
    "title": "On geometric hydrodynamics and infinite dimensional magnetic systems",
    "authors": [
      "Levin Maier"
    ],
    "abstract": "In this article, we combine V. Arnold's celebrated approach via the\nEuler-Arnold equation -- describing the geodesic flow on a Lie group equipped\nwith a right-invariant metric~\\cite{Arnold66} -- with his formulation of the\nmotion of a charged particle in a magnetic field~\\cite{ar61}. We introduce the\n\\emph{magnetic Euler-Arnold equation}, which is the Eulerian form of the\nmagnetic geodesic flow for an infinite-dimensional magnetic system on a Lie\ngroup endowed with a right-invariant metric and a right-invariant closed\ntwo-form serving as the magnetic field. As an illustration, we demonstrate that\nthe Korteweg--de Vries equation, the generalized Camassa-Holm equation, the\ninfinite conductivity equation, and the global quasi-geostrophic equations can\nall be interpreted as magnetic Euler-Arnold equations. In particular, we obtain\nboth local and global well-posedness results for the magnetic Euler-Arnold\nequation associated with the global quasi-geostrophic equations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00544v1",
    "published": "2025-05-31T13:09:24+00:00",
    "categories": [
      "math.SG",
      "math-ph",
      "math.DG",
      "math.MP"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00543v1",
    "title": "Hydrodynamical modelling of Type IIb SNe",
    "authors": [
      "Mattias Ergon",
      "Maximilian Stritzinger",
      "Francesco Taddia",
      "Jesper Sollerman",
      "Claes Fransson"
    ],
    "abstract": "We present HYDE, a new one-dimensional hydrodynamical code, and use it to\nconstruct a grid of supernova (SN) models based on solar-metallicity bare\nhelium-core models evolved to the verge of core-collapse with MESA STAR. This\ngrid is suited to model Type IIb SNe, which progenitor stars are thought to\nhave lost all but a tiny fraction of their hydrogen envelopes. Using an\nautomated procedure we fit the bolometric lightcurves and photospheric\nvelocities for a large sample of (17) Type IIb SNe to the grid of SN models. We\nfind that the distribution of initial masses for the sample can be reasonably\nwell described by a standard Salpeter IMF, although there is an\nunder-population in the >25 M$_\\odot$ range. The fractions of SNe with initial\nmasses <15 M$_\\odot$ and <20 M$_\\odot$ are 56 and 81 percent, respectively,\nsuggesting either the binary channel to dominate the production of Type IIb SNe\nor a flaw in our understanding of single-star mass-loss. We find correlations\nbetween the explosion energy, initial mass and mass of $^{56}$Ni; the explosion\nenergy increases with initial mass and the mass of $^{56}$Ni increases with\nexplosion energy. The method used allows us to determine the errors in the\nmodel parameters arising from the observed quantities and the degeneracy of the\nsolution. We find that an error in the distance and extinction propagates\nmainly to the derived mass of $^{56}$Ni, whereas an error in the photospheric\nvelocity propagates mainly to the derived helium-core mass and explosion\nenergy. Fits using the bolometric lightcurve alone are completely degenerate\nalong the M$_{\\mathrm{ej}}^{2}$/E$_{\\mathrm{ej}}$=const curve, whereas fits\nusing also the photospheric velocities are quite robust for well-sampled SNe.\nFinally, we provide a description and tests of the HYDE code, and a discussion\nof the limitations of the method used.",
    "pdf_url": "http://arxiv.org/pdf/2506.00543v1",
    "published": "2025-05-31T13:06:26+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00542v2",
    "title": "A finite Linear Dependence of Discrete Series Multiplicities",
    "authors": [
      "Kaustabh Mondal",
      "Gunja Sachdeva"
    ],
    "abstract": "Let $G$ be a connected semisimple simply connected Lie group with a compact\nCartan subgroup and let $\\Gamma$ be a uniform lattice in $G$. Let\n$\\widehat{G}_d$ denote the set of equivalence classes of unitary discrete\nseries representations of $G$. We prove that for any finite subset of\n$\\widehat{G}_d$ satisfying a certain condition, the associated finite set of\ndiscrete series multiplicities in $L^2(\\Gamma \\backslash G)$ determines all\ndiscrete series multiplicities in $L^2(\\Gamma \\backslash G)$. This allows us to\nobtain a refinement of the strong multiplicity one result for discrete series\nrepresentations. As an application, we deduce that for two given levels, the\nequality of the dimensions of the spaces of cusp forms over a suitable finite\nset of weights implies the equality of the dimensions of the spaces of cusp\nforms for all weights.",
    "pdf_url": "http://arxiv.org/pdf/2506.00542v2",
    "published": "2025-05-31T13:05:10+00:00",
    "categories": [
      "math.RT",
      "math.NT",
      "22E40, 22E46, 11F11"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00541v2",
    "title": "3D Trajectory Reconstruction of Moving Points Based on Asynchronous Cameras",
    "authors": [
      "Huayu Huang",
      "Banglei Guan",
      "Yang Shang",
      "Qifeng Yu"
    ],
    "abstract": "Photomechanics is a crucial branch of solid mechanics. The localization of\npoint targets constitutes a fundamental problem in optical experimental\nmechanics, with extensive applications in various missions of UAVs. Localizing\nmoving targets is crucial for analyzing their motion characteristics and\ndynamic properties. Reconstructing the trajectories of points from asynchronous\ncameras is a significant challenge. It encompasses two coupled sub-problems:\ntrajectory reconstruction and camera synchronization. Present methods typically\naddress only one of these sub-problems individually. This paper proposes a 3D\ntrajectory reconstruction method for point targets based on asynchronous\ncameras, simultaneously solving both sub-problems. Firstly, we extend the\ntrajectory intersection method to asynchronous cameras to resolve the\nlimitation of traditional triangulation that requires camera synchronization.\nSecondly, we develop models for camera temporal information and target motion,\nbased on imaging mechanisms and target dynamics characteristics. The parameters\nare optimized simultaneously to achieve trajectory reconstruction without\naccurate time parameters. Thirdly, we optimize the camera rotations alongside\nthe camera time information and target motion parameters, using tighter and\nmore continuous constraints on moving points. The reconstruction accuracy is\nsignificantly improved, especially when the camera rotations are inaccurate.\nFinally, the simulated and real-world experimental results demonstrate the\nfeasibility and accuracy of the proposed method. The real-world results\nindicate that the proposed algorithm achieved a localization error of 112.95 m\nat an observation range of 15 ~ 20 km.",
    "pdf_url": "http://arxiv.org/pdf/2506.00541v2",
    "published": "2025-05-31T13:04:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02043v1",
    "title": "Docker under Siege: Securing Containers in the Modern Era",
    "authors": [
      "Gogulakrishnan Thiyagarajan",
      "Prabhudarshi Nayak"
    ],
    "abstract": "Containerization, driven by Docker, has transformed application development\nand deployment by enhancing efficiency and scalability. However, the rapid\nadoption of container technologies introduces significant security challenges\nthat require careful management. This paper investigates key areas of container\nsecurity, including runtime protection, network safeguards, configuration best\npractices, supply chain security, and comprehensive monitoring and logging\nsolutions. We identify common vulnerabilities within these domains and provide\nactionable recommendations to address and mitigate these risks. By integrating\nsecurity throughout the Software Development Lifecycle (SDLC), organizations\ncan reinforce their security posture, creating a resilient and reliable\ncontainerized application infrastructure that withstands evolving threats.",
    "pdf_url": "http://arxiv.org/pdf/2506.02043v1",
    "published": "2025-05-31T13:00:52+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.11066v2",
    "title": "CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval",
    "authors": [
      "Jiahui Geng",
      "Fengyu Cai",
      "Shaobo Cui",
      "Qing Li",
      "Liangwei Chen",
      "Chenyang Lyu",
      "Haonan Li",
      "Derui Zhu",
      "Walter Pretschner",
      "Heinz Koeppl",
      "Fakhri Karray"
    ],
    "abstract": "Code retrieval is essential in modern software development, as it boosts code\nreuse and accelerates debugging. However, current benchmarks primarily\nemphasize functional relevance while neglecting critical dimensions of software\nquality. Motivated by this gap, we introduce CoQuIR, the first large-scale,\nmultilingual benchmark specifically designed to evaluate quality-aware code\nretrieval across four key dimensions: correctness, efficiency, security, and\nmaintainability. CoQuIR provides fine-grained quality annotations for 42,725\nqueries and 134,907 code snippets in 11 programming languages, and is\naccompanied by two quality-centric evaluation metrics: Pairwise Preference\nAccuracy and Margin-based Ranking Score. Using CoQuIR, we benchmark 23\nretrieval models, covering both open-source and proprietary systems, and find\nthat even top-performing models frequently fail to distinguish buggy or\ninsecure code from their more robust counterparts. Furthermore, we conduct\npreliminary investigations into training methods that explicitly encourage\nretrievers to recognize code quality. Using synthetic datasets, we demonstrate\npromising improvements in quality-aware metrics across various models, without\nsacrificing semantic relevance. Downstream code generation experiments further\nvalidate the effectiveness of our approach. Overall, our work highlights the\nimportance of integrating quality signals into code retrieval systems, laying\nthe groundwork for more trustworthy and robust software development tools.",
    "pdf_url": "http://arxiv.org/pdf/2506.11066v2",
    "published": "2025-05-31T13:00:17+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.06334v1",
    "title": "Preference-based learning for news headline recommendation",
    "authors": [
      "Alexandre Bouras",
      "Audrey Durand",
      "Richard Khoury"
    ],
    "abstract": "This study explores strategies for optimizing news headline recommendations\nthrough preference-based learning. Using real-world data of user interactions\nwith French-language online news posts, we learn a headline recommender agent\nunder a contextual bandit setting. This allows us to explore the impact of\ntranslation on engagement predictions, as well as the benefits of different\ninteractive strategies on user engagement during data collection. Our results\nshow that explicit exploration may not be required in the presence of noisy\ncontexts, opening the door to simpler but efficient strategies in practice.",
    "pdf_url": "http://arxiv.org/pdf/2506.06334v1",
    "published": "2025-05-31T12:57:56+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00540v3",
    "title": "Manipulation of photonic spin Hall effect in the Rydberg atomic medium",
    "authors": [
      "Wenzhang Liu",
      "Muqaddar Abbas",
      "Jiawei Lai",
      "Pei Zhang"
    ],
    "abstract": "We present a theoretical study demonstrating enhanced tunability of the\nphotonic spin Hall effect (PSHE) using a strongly interacting Rydberg atomic\nmedium under electromagnetically induced transparency (EIT) conditions. In\ncontrast to conventional approaches that rely on static refractiveindex\nprofiles or metamaterials, here the PSHE is controlled via a nonlocal\nthird-order nonlinear susceptibility arising from long range Rydberg-Rydberg\ninteractions. We show that this nonlocal nonlinearity enables dynamic\nmodulation of spin-dependent light trajectories, amplifying the normally weak\nPSHE into a readily observable and adjustable effect. These results pave the\nway for new capabilities in photonic information processing and sensing. In\nparticular, an adjustable PSHE may enable beam steering based on photon spin,\nimprove the sensitivity of precision measurements, and support photonic devices\nwhose functionality can be reconfigured in real time.",
    "pdf_url": "http://arxiv.org/pdf/2506.00540v3",
    "published": "2025-05-31T12:55:55+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00539v2",
    "title": "ARIA: Training Language Agents with Intention-Driven Reward Aggregation",
    "authors": [
      "Ruihan Yang",
      "Yikai Zhang",
      "Aili Chen",
      "Xintao Wang",
      "Siyu Yuan",
      "Jiangjie Chen",
      "Deqing Yang",
      "Yanghua Xiao"
    ],
    "abstract": "Large language models (LLMs) have enabled agents to perform complex reasoning\nand decision-making through free-form language interactions. However, in\nopen-ended language action environments (e.g., negotiation or question-asking\ngames), the action space can be formulated as a joint distribution over tokens,\nresulting in an exponentially large action space. Sampling actions in such a\nspace can lead to extreme reward sparsity, which brings large reward variance,\nhindering effective reinforcement learning (RL). To address this, we propose\nARIA, a method that Aggregates Rewards in Intention space to enable efficient\nand effective language Agents training. ARIA aims to project natural language\nactions from the high-dimensional joint token distribution space into a\nlow-dimensional intention space, where semantically similar actions are\nclustered and assigned shared rewards. This intention-aware reward aggregation\nreduces reward variance by densifying reward signals, fostering better policy\noptimization. Extensive experiments demonstrate that ARIA not only\nsignificantly reduces policy gradient variance, but also delivers substantial\nperformance gains of an average of 9.95% across four downstream tasks,\nconsistently outperforming offline and online RL baselines.",
    "pdf_url": "http://arxiv.org/pdf/2506.00539v2",
    "published": "2025-05-31T12:54:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00538v1",
    "title": "Magnetic interactions as a pivotal determinant in stabilizing a novel AgIIAgIIIF5 polymorph with high spin AgIII",
    "authors": [
      "Daniel Jezierski",
      "Wojciech Grochala"
    ],
    "abstract": "Based on theoretical calculations, we introduce a new AgIIAgIIIF5 monoclinic\npolymorph with a rare high spin AgIII. Our analysis of the experimental xray\ndiffraction data available in the literature reveals that this polymorph was\nlikely prepared in the past in a mixture with the triclinic form of the same\ncompound. Theoretical calculations reproduce very well the lattice parameters\nof both forms. Calculations suggest that under ambient conditions, the\nmonoclinic form is the more energetically stable phase of Ag2F5. We predict a\nstrong one-dimensional antiferromagnetic superexchange between silver cations\nof different valences with superexchange constant of minus 207 meV (hybrid\nfunctional result). The polymorph with high spin AgIII owes its stability over\nthe one with low spin AgIII, to these magnetic interactions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00538v1",
    "published": "2025-05-31T12:54:01+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00537v1",
    "title": "Huntsman may need to be irradiated",
    "authors": [
      "Shunyi Lan",
      "Xiangcun Meng"
    ],
    "abstract": "Millisecond pulsars are rapidly rotating neutron stars, and it is now widely\naccepted that their extremely short rotation periods result from the accretion\nof material from a companion star. Binary evolution theory predicts that\nmillisecond pulsars can have various types of companion stars. However, in\nobservations, binary pulsars with giant companions, referred to as ``huntsman\npulsars'', are extremely rare. Following the initial discovery of the first\nhuntsman pulsar, 1FGL J1417.7-4407, a second huntsman millisecond pulsar\nbinary, PSR J1947-1120, has been recently reported approximately a decade\nlater. In this paper, we model the formation and evolution of two huntsman\npulsars. Our model with the irradiation effect can explain the observed\nproperties of huntsman pulsar binaries and suggests that if the irradiation\neffect is considered, the companion star may be a normal red giant star, rather\nthan just a red bump star.",
    "pdf_url": "http://arxiv.org/pdf/2506.00537v1",
    "published": "2025-05-31T12:52:08+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00536v1",
    "title": "Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing",
    "authors": [
      "Changyue Wang",
      "Weihang Su",
      "Qingyao Ai",
      "Yujia Zhou",
      "Yiqun Liu"
    ],
    "abstract": "Knowledge editing aims to efficiently update Large Language Models (LLMs) by\nmodifying specific knowledge without retraining the entire model. Among\nknowledge editing approaches, in-context editing (ICE) offers a lightweight\nsolution by injecting new knowledge directly into the input context, leaving\nmodel parameters unchanged. However, existing ICE approaches do not explicitly\nseparate the newly injected knowledge from the model's original reasoning\nprocess. This entanglement often results in conflicts between external updates\nand internal parametric knowledge, undermining the consistency and accuracy of\nthe reasoning path.In this work, we conduct preliminary experiments to examine\nhow parametric knowledge influences reasoning path planning. We find that the\nmodel's reasoning is tightly coupled with its internal knowledge, and that\nnaively injecting new information without adapting the reasoning path often\nleads to performance degradation, particularly in multi-hop tasks. To this end,\nwe propose DecKER, a novel ICE framework that decouples reasoning from\nknowledge editing by generating a masked reasoning path and then resolving\nknowledge edits via hybrid retrieval and model-based validation. Experiments on\nmulti-hop QA benchmarks show that DecKER significantly outperforms existing ICE\nmethods by mitigating knowledge conflicts and preserving reasoning consistency.\nOur code is available at: https://github.com/bebr2/DecKER .",
    "pdf_url": "http://arxiv.org/pdf/2506.00536v1",
    "published": "2025-05-31T12:51:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00535v1",
    "title": "A Novel Approach to Fast Calculation of High-Order Q-Cumulants",
    "authors": [
      "L. Nađđerđ",
      "J. Milošević",
      "D. Devetak",
      "F. Wang",
      "X. Zhu"
    ],
    "abstract": "The method of Q-cumulants has been shown as a powerful tool to study the fine\ndetails of the azimuthal anisotropies in high-energy nucleus-nucleus\ncollisions. A new method for the fast calculation of arbitrary order Q-cumulant\nv_{n}\\{2k\\} values, based on the partition of a non-negative integer l $\\le$ m\nfor calculation of the 2m-particle azimuthal correlations is presented in this\npaper. Unlike the standard Q-cumulants method in which the calculation of\nhigh-order multi-particle calculations is impractical, the newly proposed\nmethod enables easy calculation. The validity of the method is proven via a toy\nmodel that uses the elliptic power distribution to simulate anisotropic\nemission of particles. The method enables the study of fine details of the\nv_{2} distribution, such as higher-order central moments of the v_{2}\ndistribution, as well as the hydrodynamic behavior of the Quark-Gluon Plasma.",
    "pdf_url": "http://arxiv.org/pdf/2506.00535v1",
    "published": "2025-05-31T12:45:01+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00534v1",
    "title": "The Security Threat of Compressed Projectors in Large Vision-Language Models",
    "authors": [
      "Yudong Zhang",
      "Ruobing Xie",
      "Xingwu Sun",
      "Jiansheng Chen",
      "Zhanhui Kang",
      "Di Wang",
      "Yu Wang"
    ],
    "abstract": "The choice of a suitable visual language projector (VLP) is critical to the\nsuccessful training of large visual language models (LVLMs). Mainstream VLPs\ncan be broadly categorized into compressed and uncompressed projectors, and\neach offering distinct advantages in performance and computational efficiency.\nHowever, their security implications have not been thoroughly examined. Our\ncomprehensive evaluation reveals significant differences in their security\nprofiles: compressed projectors exhibit substantial vulnerabilities, allowing\nadversaries to successfully compromise LVLMs even with minimal knowledge of\nstructural information. In stark contrast, uncompressed projectors demonstrate\nrobust security properties and do not introduce additional vulnerabilities.\nThese findings provide critical guidance for researchers in selecting optimal\nVLPs that enhance the security and reliability of visual language models. The\ncode will be released.",
    "pdf_url": "http://arxiv.org/pdf/2506.00534v1",
    "published": "2025-05-31T12:43:56+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00533v3",
    "title": "RsGCN: Rescaling Enhances Generalization of GCNs for Solving Scalable Traveling Salesman Problems",
    "authors": [
      "Junquan Huang",
      "Zong-Gan Chen",
      "Yuncheng Jiang",
      "Zhi-Hui Zhan"
    ],
    "abstract": "Neural traveling salesman problem (TSP) solvers face two critical challenges:\npoor generalization for scalable TSPs and high training costs. To address these\nchallenges, we propose a new Rescaling Graph Convolutional Network (RsGCN).\nFocusing on the scale-dependent features (i.e., features varied with problem\nscales) related to nodes and edges that influence the sensitivity of GCNs to\nthe problem scales, a Rescaling Mechanism in RsGCN enhances the generalization\ncapability by (1) rescaling adjacent nodes to construct a subgraph with a\nuniform number of adjacent nodes for each node across various scales of TSPs,\nwhich stabilizes the graph message aggregation; (2) rescaling subgraph edges to\nadjust the lengths of subgraph edges to the same magnitude, which maintains\nnumerical consistency. In addition, an efficient training strategy with a\nmixed-scale dataset and bidirectional loss is used in RsGCN. To fully exploit\nthe heatmaps generated by RsGCN, we design an efficient post-search algorithm\ntermed Re2Opt, in which a reconstruction process based on adaptive weight is\nincorporated to help avoid local optima. Based on a combined architecture of\nRsGCN and Re2Opt, our solver achieves remarkable generalization and low\ntraining cost: with only 3 epochs of training on the mixed-scale dataset\ncontaining instances with up to 100 nodes, it can be generalized successfully\nto 10K-node instances without any fine-tuning. Extensive experiments\ndemonstrate our state-of-the-art performance across uniform distribution\ninstances of 9 different scales from 20 to 10K nodes and 78 real-world\ninstances from TSPLIB, while requiring the fewest learnable parameters and\ntraining epochs among neural competitors.",
    "pdf_url": "http://arxiv.org/pdf/2506.00533v3",
    "published": "2025-05-31T12:40:02+00:00",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00532v1",
    "title": "Generative AI and Organizational Structure in the Knowledge Economy",
    "authors": [
      "Fasheng Xu",
      "Jing Hou",
      "Wei Chen",
      "Karen Xie"
    ],
    "abstract": "The adoption of GenAI is fundamentally reshaping organizations in the\nknowledge economy. GenAI can significantly enhance workers' problem-solving\nabilities and productivity, yet it also presents a major reliability challenge:\nhallucinations, or errors presented as plausible outputs. This study develops a\ntheoretical model to examine GenAI's impact on organizational structure and the\nrole of human-in-the-loop oversight. Our findings indicate that successful\nGenAI adoption hinges primarily on maintaining hallucination rates below a\ncritical level. After adoption, as GenAI advances in capability or reliability,\norganizations optimize their workforce by reducing worker knowledge\nrequirements while preserving operational effectiveness through GenAI\naugmentation-a phenomenon known as deskilling. Unexpectedly, enhanced\ncapability or reliability of GenAI may actually narrow the span of control,\nincreasing the demand for managers rather than flattening organizational\nhierarchies. To effectively mitigate hallucination risks, many firms implement\nhuman-in-the-loop validation, where managers review GenAI-enhanced outputs\nbefore implementation. While the validation increases managerial workload, it\ncan, surprisingly, expand the span of control, reducing the number of managers\nneeded. Furthermore, human-in-the-loop validation influences GenAI adoption\ndifferently based on validation costs and hallucination rates, deterring\nadoption in low-error, high-cost scenarios, while promoting it in high-error,\nlow-cost cases. Finally, productivity improvements from GenAI yield distinctive\norganizational shifts: as productivity increases, firms tend to employ fewer\nbut more knowledgeable workers, gradually expanding managerial spans of\ncontrol.",
    "pdf_url": "http://arxiv.org/pdf/2506.00532v1",
    "published": "2025-05-31T12:33:08+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2506.02042v1",
    "title": "General Numerical Radius for Products of Sectorial Matrices",
    "authors": [
      "Mohammad Alakhrass"
    ],
    "abstract": "In this paper, we investigate the generalized numerical radius $\\omega_N$,\nassociated with a matrix norm $N$ defined by $\\omega_N(X) = \\sup_{\\theta \\in\n\\mathbb{R}} N(\\operatorname{Re}(e^{i\\theta}X))$. We focus on matrices whose\nnumerical ranges are contained in sectors of the complex plane (sectorial\nmatrices) and derive upper bounds for $\\omega_N(XY)$ and $\\omega_N(X \\circ Y)$\nfor such matrices $X$ and $Y$. Our results generalize and refine well known\nnumerical radius inequalities. Several known inequalities for $\\omega(X)$ are\nrecovered as special cases.",
    "pdf_url": "http://arxiv.org/pdf/2506.02042v1",
    "published": "2025-05-31T12:32:45+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00531v1",
    "title": "M2WLLM: Multi-Modal Multi-Task Ultra-Short-term Wind Power Prediction Algorithm Based on Large Language Model",
    "authors": [
      "Hang Fana",
      "Mingxuan Lib",
      "Zuhan Zhanga",
      "Long Chengc",
      "Yujian Ye",
      "Dunnan Liua"
    ],
    "abstract": "The integration of wind energy into power grids necessitates accurate\nultra-short-term wind power forecasting to ensure grid stability and optimize\nresource allocation. This study introduces M2WLLM, an innovative model that\nleverages the capabilities of Large Language Models (LLMs) for predicting wind\npower output at granular time intervals. M2WLLM overcomes the limitations of\ntraditional and deep learning methods by seamlessly integrating textual\ninformation and temporal numerical data, significantly improving wind power\nforecasting accuracy through multi-modal data. Its architecture features a\nPrompt Embedder and a Data Embedder, enabling an effective fusion of textual\nprompts and numerical inputs within the LLMs framework. The Semantic Augmenter\nwithin the Data Embedder translates temporal data into a format that the LLMs\ncan comprehend, enabling it to extract latent features and improve prediction\naccuracy. The empirical evaluations conducted on wind farm data from three\nChinese provinces demonstrate that M2WLLM consistently outperforms existing\nmethods, such as GPT4TS, across various datasets and prediction horizons. The\nresults highlight LLMs' ability to enhance accuracy and robustness in\nultra-short-term forecasting and showcase their strong few-shot learning\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.00531v1",
    "published": "2025-05-31T12:27:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00530v1",
    "title": "CityLens: Benchmarking Large Language-Vision Models for Urban Socioeconomic Sensing",
    "authors": [
      "Tianhui Liu",
      "Jie Feng",
      "Hetian Pang",
      "Xin Zhang",
      "Tianjian Ouyang",
      "Zhiyuan Zhang",
      "Yong Li"
    ],
    "abstract": "Understanding urban socioeconomic conditions through visual data is a\nchallenging yet essential task for sustainable urban development and policy\nplanning. In this work, we introduce $\\textbf{CityLens}$, a comprehensive\nbenchmark designed to evaluate the capabilities of large language-vision models\n(LLVMs) in predicting socioeconomic indicators from satellite and street view\nimagery. We construct a multi-modal dataset covering a total of 17 globally\ndistributed cities, spanning 6 key domains: economy, education, crime,\ntransport, health, and environment, reflecting the multifaceted nature of urban\nlife. Based on this dataset, we define 11 prediction tasks and utilize three\nevaluation paradigms: Direct Metric Prediction, Normalized Metric Estimation,\nand Feature-Based Regression. We benchmark 17 state-of-the-art LLVMs across\nthese tasks. Our results reveal that while LLVMs demonstrate promising\nperceptual and reasoning capabilities, they still exhibit limitations in\npredicting urban socioeconomic indicators. CityLens provides a unified\nframework for diagnosing these limitations and guiding future efforts in using\nLLVMs to understand and predict urban socioeconomic patterns. Our codes and\ndatasets are open-sourced via https://github.com/tsinghua-fib-lab/CityLens.",
    "pdf_url": "http://arxiv.org/pdf/2506.00530v1",
    "published": "2025-05-31T12:25:33+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00529v1",
    "title": "Coherent functors, powers of ideals, and asymptotic stability",
    "authors": [
      "Souvik Dey",
      "Dipankar Ghosh",
      "Siddhartha Pramanik",
      "Tony J. Puthenpurakal",
      "Samarendra Sahoo"
    ],
    "abstract": "Let $R$ be a Noetherian ring, $I_1,\\ldots,I_r$ be ideals of $R$, and\n$N\\subseteq M$ be finitely generated $R$-modules. Let $S =\n\\bigoplus_{\\underline{n} \\in \\mathbb{N}^r} S_{\\underline{n}}$ be a Noetherian\nstandard $\\mathbb{N}^r$-graded ring with $S_{\\underline{0}} = R$, and\n$\\mathcal{M} $ be a finitely generated $\\mathbb{Z}^r$-graded $S$-module. For $\n\\underline{n} = (n_1,\\dots,n_r) \\in \\mathbb{N}^r$, set $G_{\\underline{n}} :=\n\\mathcal{M}_{\\underline{n}}$ or $G_{\\underline{n}} := M/{\\bf I}^{\\underline{n}}\nN$, where ${\\bf I}^{\\underline{n}} = I_1^{n_1} \\cdots I_r^{n_r}$. Suppose $F$\nis a coherent functor on the category of finitely generated $R$-modules. We\nprove that the set $\\rm{Ass}_R \\big(F(G_{\\underline{n}}) \\big)$ of associate\nprimes and $\\rm{grade}\\big(J, F(G_{\\underline{n}})\\big)$ stabilize for all\n$\\underline{n} \\gg 0$, where $J$ is a non-zero ideal of $R$. Furthermore, if\nthe length $\\lambda_R(F(G_{\\underline{n}}))$ is finite for all $\\underline{n}\n\\gg 0$, then there exists a polynomial $P$ in $r$ variables over $\\mathbb{Q}$\nsuch that $\\lambda_R(F(G_{\\underline{n}})) = P(\\underline{n})$ for all\n$\\underline{n}\\gg 0$. When $R$ is a local ring, and $G_{\\underline{n}} = M/{\\bf\nI}^{\\underline{n}} N$, we give a sharp upper bound of the total degree of $P$.\nAs applications, when $R$ is a local ring, we show that for each fixed $i \\geq\n0$, the $i$th Betti number $\\beta_i^R(F(G_{\\underline{n}}))$ and Bass number\n$\\mu^i_R(F(G_{\\underline{n}}))$ are given by polynomials in $\\underline{n}$ for\nall $\\underline{n} \\gg 0$. Thus, in particular, the projective dimension\n$\\rm{pd}_R(F(G_{\\underline{n}}))$ (resp., injective dimension\n$\\rm{id}_R(F(G_{\\underline{n}}))$) is constant for all $\\underline{n}\\gg 0$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00529v1",
    "published": "2025-05-31T12:25:23+00:00",
    "categories": [
      "math.AC",
      "13D07, 13A15 (Primary), 13A02, 13D02 (Secondary)"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00528v1",
    "title": "Ultra-Quantisation: Efficient Embedding Search via 1.58-bit Encodings",
    "authors": [
      "Richard Connor",
      "Alan Dearle",
      "Ben Claydon"
    ],
    "abstract": "Many modern search domains comprise high-dimensional vectors of floating\npoint numbers derived from neural networks, in the form of embeddings. Typical\nembeddings range in size from hundreds to thousands of dimensions, making the\nsize of the embeddings, and the speed of comparison, a significant issue.\n  Quantisation is a class of mechanism which replaces the floating point values\nwith a smaller representation, for example a short integer. This gives an\napproximation of the embedding space in return for a smaller data\nrepresentation and a faster comparison function.\n  Here we take this idea almost to its extreme: we show how vectors of\narbitrary-precision floating point values can be replaced by vectors whose\nelements are drawn from the set {-1,0,1}. This yields very significant savings\nin space and metric evaluation cost, while maintaining a strong correlation for\nsimilarity measurements.\n  This is achieved by way of a class of convex polytopes which exist in the\nhigh-dimensional space. In this article we give an outline description of these\nobjects, and show how they can be used for the basis of such radical\nquantisation while maintaining a surprising degree of accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00528v1",
    "published": "2025-05-31T12:22:24+00:00",
    "categories": [
      "cs.LG",
      "cs.DB"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00527v1",
    "title": "Retrieval-Augmented Generation Systems for Intellectual Property via Synthetic Multi-Angle Fine-tuning",
    "authors": [
      "Runtao Ren",
      "Jian Ma",
      "Jianxi Luo"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems in the Intellectual Property\n(IP) field often struggle with diverse user queries, including colloquial\nexpressions, spelling errors, and ambiguous terminology, leading to inaccurate\nretrieval and suboptimal responses. To address this challenge, we propose\nMulti-Angle Question Generation and Retrieval Fine-Tuning Method (MQG-RFM), a\nnovel framework that leverages large language models (LLMs) to simulate varied\nuser inquiries and fine-tunes retrieval models to align semantically equivalent\nbut linguistically diverse questions. Unlike complex architectural\nmodifications, MQG-RFM adopts a lightweight Data-to-Tune paradigm, combining\nprompt-engineered query generation with hard negative mining to enhance\nretrieval robustness without costly infrastructure changes. Experimental\nresults on a Taiwan patent Q&A dataset show 185.62% improvement in retrieval\naccuracy on the Patent Consultation dataset and 262.26% improvement on the\nNovel Patent Technology Report dataset, with 14.22% and 53.58% improvements in\ngeneration quality over the baselines, respectively. By bridging the gap\nbetween user intent and system comprehension through semantic-aware retrieval\noptimization, MQG-RFM offers a practical, scalable approach for rapid,\ncost-effective deployment among small and medium-sized agencies seeking\nreliable patent intelligence solutions. Additionally, our proposed method has\nalready been adopted by ScholarMate, the largest professional research social\nnetworking platform in China, to support real-world development and deployment.\nA demo version of the instantiated is available at\nhttps://github.com/renruntao/patent_rag.",
    "pdf_url": "http://arxiv.org/pdf/2506.00527v1",
    "published": "2025-05-31T12:19:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00526v1",
    "title": "Your Demands Deserve More Bits: Referring Semantic Image Compression at Ultra-low Bitrate",
    "authors": [
      "Chenhao Wu",
      "Qingbo Wu",
      "Haoran Wei",
      "Shuai Chen",
      "Mingzhou He",
      "King Ngi Ngan",
      "Fanman Meng",
      "Hongliang Li"
    ],
    "abstract": "With the help of powerful generative models, Semantic Image Compression (SIC)\nhas achieved impressive performance at ultra-low bitrate. However, due to\ncoarse-grained visual-semantic alignment and inherent randomness, the\nreliability of SIC is seriously concerned for reconstructing completely\ndifferent object instances, even they are semantically consistent with original\nimages. To tackle this issue, we propose a novel Referring Semantic Image\nCompression (RSIC) framework to improve the fidelity of user-specified content\nwhile retaining extreme compression ratios. Specifically, RSIC consists of\nthree modules: Global Description Encoding (GDE), Referring Guidance Encoding\n(RGE), and Guided Generative Decoding (GGD). GDE and RGE encode global semantic\ninformation and local features, respectively, while GGD handles the\nnon-uniformly guided generative process based on the encoded information. In\nthis way, our RSIC achieves flexible customized compression according to user\ndemands, which better balance the local fidelity, global realism, semantic\nalignment, and bit overhead. Extensive experiments on three datasets verify the\ncompression efficiency and flexibility of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2506.00526v1",
    "published": "2025-05-31T12:15:03+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00525v2",
    "title": "Gravitomagnetism from Temporal Dimensional Reduction",
    "authors": [
      "Mehran Z-Abyaneh",
      "Mehrdad Farhoudi"
    ],
    "abstract": "We propose that the Taub-NUT metric can be envisaged as a (3+1) dimensional\nanalog of the Kaluza-Klein (4+1) dimensional metric. After dimensional\nreduction of the Taub-NUT metric to (3) spatial dimensions, by treating time as\nthe extra curled dimension (since the closed time-like curves can exist in the\nTaub-NUT framework, such a dimensional reduction is justified), we end up with\nthree dimensional Einstein field equations plus the Maxwell equations for the\ngravitomagnetic field, which also acts as a source to Einstein field equations.\nHence, the Taub-NUT metric unifies gravity and the NUT charge related\ngavitomagnetism in four dimensions, at the same footing the Kaluza-Klein metric\nunifies gravity and electromagnetism in five dimensions. We also find an\ninteresting relation between the four dimensional gravitational constant and\nthe Taub-NUT charge. The result is derived from classical field equations in\nLorentzian signature.",
    "pdf_url": "http://arxiv.org/pdf/2506.00525v2",
    "published": "2025-05-31T12:14:53+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.00524v1",
    "title": "Experimental demonstration of generalized quantum fluctuation theorems in the presence of coherence",
    "authors": [
      "Hui Li",
      "Jie Xie",
      "Hyukjoon Kwon",
      "Yixin Zhao",
      "M. S. Kim",
      "Lijian Zhang"
    ],
    "abstract": "Fluctuation theorems have elevated the second law of thermodynamics to a\nstatistical realm by establishing a connection between time-forward and\ntime-reversal probabilities, providing invaluable insight into nonequilibrium\ndynamics. While well established in classical systems, their quantum\ngeneralization, incorporating coherence and the diversity of quantum noise,\nremains open. We report the experimental validation of a quantum fluctuation\ntheorem (QFT) in a photonic system, applicable to general quantum processes\nwith nonclassical characteristics, including quasi-probabilistic descriptions\nof entropy production and multiple time-reversal processes. Our experiment\nconfirms that the ratio between the quasi-probabilities of the time-forward and\nany multiple time-reversal processes obeys a generalized Crooks QFT. Moreover,\ncoherence induced by a quantum process leads to the imaginary components of\nquantum entropy production, governing the phase factor in the QFT. These\nfindings underscore the fundamental symmetry between a general quantum process\nand its time reversal, providing an elementary toolkit to explore noisy quantum\ninformation processing.",
    "pdf_url": "http://arxiv.org/pdf/2506.00524v1",
    "published": "2025-05-31T12:00:59+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00523v1",
    "title": "SenseFlow: Scaling Distribution Matching for Flow-based Text-to-Image Distillation",
    "authors": [
      "Xingtong Ge",
      "Xin Zhang",
      "Tongda Xu",
      "Yi Zhang",
      "Xinjie Zhang",
      "Yan Wang",
      "Jun Zhang"
    ],
    "abstract": "The Distribution Matching Distillation (DMD) has been successfully applied to\ntext-to-image diffusion models such as Stable Diffusion (SD) 1.5. However,\nvanilla DMD suffers from convergence difficulties on large-scale flow-based\ntext-to-image models, such as SD 3.5 and FLUX. In this paper, we first analyze\nthe issues when applying vanilla DMD on large-scale models. Then, to overcome\nthe scalability challenge, we propose implicit distribution alignment (IDA) to\nregularize the distance between the generator and fake distribution.\nFurthermore, we propose intra-segment guidance (ISG) to relocate the timestep\nimportance distribution from the teacher model. With IDA alone, DMD converges\nfor SD 3.5; employing both IDA and ISG, DMD converges for SD 3.5 and FLUX.1\ndev. Along with other improvements such as scaled up discriminator models, our\nfinal model, dubbed \\textbf{SenseFlow}, achieves superior performance in\ndistillation for both diffusion based text-to-image models such as SDXL, and\nflow-matching models such as SD 3.5 Large and FLUX. The source code will be\navaliable at https://github.com/XingtongGe/SenseFlow.",
    "pdf_url": "http://arxiv.org/pdf/2506.00523v1",
    "published": "2025-05-31T11:59:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00522v1",
    "title": "Integrated Sensing, Computing and Semantic Communication for Vehicular Networks",
    "authors": [
      "Yinchao Yang",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Wei Xu",
      "Zhaoyang Zhang",
      "Dusit Niyato",
      "Mohammad Shikh-Bahaei"
    ],
    "abstract": "This paper introduces a novel framework for integrated sensing, computing,\nand semantic communication (ISCSC) within vehicular networks comprising a\nroadside unit (RSU) and multiple autonomous vehicles. Both the RSU and the\nvehicles are equipped with local knowledge bases to facilitate semantic\ncommunication. The framework incorporates a secure communication design to\nensure that messages intended for specific vehicles are protected against\ninterception. In this model, an extended Kalman filter (EKF) is employed by the\nRSU to accurately track all vehicles. We formulate a joint optimization problem\nthat balances maximizing the probabilistically constrained semantic secrecy\nrate for each vehicle while minimizing the sum of the posterior Cram\\'er-Rao\nbound (PCRB), subject to the RSU's computing capabilities. This non-convex\noptimization problem is addressed using Bernstein-type inequality (BTI) and\nalternating optimization (AO) techniques. Simulation results validate the\neffectiveness of the proposed framework, demonstrating its advantages in\nreliable sensing, high data throughput, and secure communication.",
    "pdf_url": "http://arxiv.org/pdf/2506.00522v1",
    "published": "2025-05-31T11:49:54+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00521v6",
    "title": "Convergence rates of regularized quasi-Newton methods without strong convexity",
    "authors": [
      "Shida Wang",
      "Jalal Fadili",
      "Peter Ochs"
    ],
    "abstract": "In this paper, we study convergence rates of the cubic regularized proximal\nquasi-Newton method (\\csr) for solving non-smooth additive composite problems\nthat satisfy the so-called Kurdyka-\\L ojasiewicz (K\\L ) property with respect\nto some desingularization function $\\phi$ rather than strong convexity. After a\nnumber of iterations $k_0$, Cubic SR1 PQN exhibits non-asymptotic explicit\nsuper-linear convergence rates for any $k\\geq k_0$. In particular, when\n$\\phi(t)=ct^{1/2}$, Cubic SR1 PQN has a convergence rate of order\n$\\left(\\frac{C}{(k-k_0)^{1/2}}\\right)^{(k-k_0)/2}$, where $k$ is the number of\niterations and $C>0$ is a constant. For the special case, i.e. functions which\nsatisfy \\L ojasiewicz inequality, the rate becomes global and non-asymptotic.\nThis work presents, for the first time, non-asymptotic explicit convergence\nrates of regularized (proximal) SR1 quasi-Newton methods applied to non-convex\nnon-smooth problems with K\\L\\ property. Actually, the rates are novel even in\nthe smooth non-convex case. Notably, we achieve this without employing line\nsearch or trust region strategies, without assuming the Dennis-Mor\\'e\ncondition, without any assumptions on quasi-Newton metrics and without assuming\nstrong convexity. Furthermore, for convex problems, we focus on a more\ntractable gradient regularized quasi-Newton method (Grad SR1 PQN) which can\nachieve results similar to those obtained with cubic regularization. We also\ndemonstrate, for the first time, the non-asymptotic super-linear convergence\nrate of Grad SR1 PQN for solving convex problems with the help of the \\L\nojasiewicz inequality instead of strong convexity.",
    "pdf_url": "http://arxiv.org/pdf/2506.00521v6",
    "published": "2025-05-31T11:48:12+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00520v1",
    "title": "Temac: Multi-Agent Collaboration for Automated Web GUI Testing",
    "authors": [
      "Chenxu Liu",
      "Zhiyu Gu",
      "Guoquan Wu",
      "Ying Zhang",
      "Jun Wei",
      "Tao Xie"
    ],
    "abstract": "Quality assurance of web applications is critical, as web applications play\nan essential role in people's daily lives. To reduce labor costs, automated web\nGUI testing (AWGT) is widely adopted, exploring web applications via GUI\nactions such as clicks and text inputs. However, these approaches face\nlimitations in generating continuous and meaningful action sequences capable of\ncovering complex functionalities. Recent work incorporates large language\nmodels (LLMs) for GUI testing. However, these approaches face various\nchallenges, including low efficiency of LLMs, high complexity of rich web\napplication contexts, and a low success rate of LLMs in executing GUI tasks.\n  To address these challenges, in this paper, we propose Temac, an approach\nthat enhances AWGT using LLM-based multi-agent collaboration to increase code\ncoverage. Temac is motivated by our insight that LLMs can enhance AWGT in\nexecuting complex functionalities, while the information discovered during AWGT\ncan, in turn, be provided as the domain knowledge to improve the LLM-based task\nexecution. Specifically, given a web application, Temac initially runs an\nexisting approach to broadly explore application states. When the testing\ncoverage stagnates, Temac then employs LLM-based agents to summarize the\ncollected information to form a knowledge base and to infer not-covered\nfunctionalities. Guided by this knowledge base, Temac finally uses specialized\nLLM-based agents to target and execute the not-covered functionalities,\nreaching deeper states beyond those explored by the existing approach.\n  Our evaluation results show that Temac exceeds state-of-the-art approaches\nfrom 12.5% to 60.3% on average code coverage on six complex open-source web\napplications, while revealing 445 unique failures in the top 20 real-world web\napplications. These results strongly demonstrate the effectiveness and the\ngeneral applicability of Temac.",
    "pdf_url": "http://arxiv.org/pdf/2506.00520v1",
    "published": "2025-05-31T11:43:37+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00519v2",
    "title": "CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy Abstention",
    "authors": [
      "Yuxi Sun",
      "Aoqi Zuo",
      "Wei Gao",
      "Jing Ma"
    ],
    "abstract": "Large Language Models (LLMs) often exhibit knowledge disparities across\nlanguages. Encouraging LLMs to \\textit{abstain} when faced with knowledge gaps\nis a promising strategy to reduce hallucinations in multilingual settings.\nCurrent abstention strategies for multilingual scenarios primarily rely on\ngenerating feedback in various languages using LLMs and performing\nself-reflection. However, these methods can be adversely impacted by\ninaccuracies and biases in the generated feedback. To address this, from a\ncausal perspective, we introduce \\textit{CausalAbstain}, a method that helps\nLLMs determine whether to utilize multiple generated feedback responses and how\nto identify the most useful ones. Extensive experiments demonstrate that\n\\textit{CausalAbstain} effectively selects helpful feedback and enhances\nabstention decisions with interpretability in both native language\n(\\textsc{Casual-native}) and multilingual (\\textsc{Causal-multi}) settings,\noutperforming strong baselines on two benchmark datasets covering encyclopedic\nand commonsense knowledge QA tasks. Our code and data are open-sourced at\nhttps://github.com/peachch/CausalAbstain.",
    "pdf_url": "http://arxiv.org/pdf/2506.00519v2",
    "published": "2025-05-31T11:35:31+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00518v1",
    "title": "Robust and Verifiable MPC with Applications to Linear Machine Learning Inference",
    "authors": [
      "Tzu-Shen Wang",
      "Jimmy Dani",
      "Juan Garay",
      "Soamar Homsi",
      "Nitesh Saxena"
    ],
    "abstract": "In this work, we present an efficient secure multi-party computation MPC\nprotocol that provides strong security guarantees in settings with dishonest\nmajority of participants who may behave arbitrarily. Unlike the popular MPC\nimplementation known as SPDZ [Crypto '12], which only ensures security with\nabort, our protocol achieves both complete identifiability and robustness. With\ncomplete identifiability, honest parties can detect and unanimously agree on\nthe identity of any malicious party. Robustness allows the protocol to continue\nwith the computation without requiring a restart, even when malicious behavior\nis detected. Additionally, our approach addresses the performance limitations\nobserved in the protocol by Cunningham et al. [ICITS '17], which, while\nachieving complete identifiability, is hindered by the costly exponentiation\noperations required by the choice of commitment scheme.\n  Our protocol is based on the approach by Rivinius et al. [S&P '22], utilizing\nlattice-based commitment for better efficiency. We achieved robustness with the\nhelp of a semi-honest trusted third party. We benchmark our robust protocol,\nshowing the efficient recovery from parties' malicious behavior.\n  Finally, we benchmark our protocol on a ML-as-a-service scenario, wherein\nclients off-load the desired computation to the servers, and verify the\ncomputation result. We benchmark on linear ML inference, running on various\ndatasets. While our efficiency is slightly lower compared to SPDZ's, we offer\nstronger security properties that provide distinct advantages.",
    "pdf_url": "http://arxiv.org/pdf/2506.00518v1",
    "published": "2025-05-31T11:26:57+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.11065v1",
    "title": "Smotrom tvoja pa ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study",
    "authors": [
      "Alexey Tikhonov",
      "Sergei Shteiner",
      "Anna Bykova",
      "Ivan P. Yamshchikov"
    ],
    "abstract": "Russenorsk, a pidgin language historically used in trade interactions between\nRussian and Norwegian speakers, represents a unique linguistic phenomenon. In\nthis paper, we attempt to analyze its lexicon using modern large language\nmodels (LLMs), based on surviving literary sources. We construct a structured\ndictionary of the language, grouped by synonyms and word origins. Subsequently,\nwe use this dictionary to formulate hypotheses about the core principles of\nword formation and grammatical structure in Russenorsk and show which\nhypotheses generated by large language models correspond to the hypotheses\npreviously proposed ones in the academic literature. We also develop a\n\"reconstruction\" translation agent that generates hypothetical Russenorsk\nrenderings of contemporary Russian and Norwegian texts.",
    "pdf_url": "http://arxiv.org/pdf/2506.11065v1",
    "published": "2025-05-31T11:26:00+00:00",
    "categories": [
      "cs.CL",
      "Primary 68T50, Secondary 68T05, 91F20",
      "I.2.7; I.2.6; I.5.4"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00517v1",
    "title": "Giant Atmospheric Showers Detected by the Yakutsk Extensive Air Shower Array",
    "authors": [
      "A. V. Glushkov",
      "K. G. Lebedev",
      "L. T. Ksenofontov",
      "A. V. Saburov",
      "O. N. Ivanov",
      "A. F. Boyakinov",
      "A. A. Ivanov",
      "S. P. Knurenko",
      "A. D. Krasilnikov",
      "S. V. Matarkin",
      "V. P. Mokhnachevskaya",
      "N. Ya. Muksunov",
      "I. S. Petrov",
      "I. E. Sleptsov"
    ],
    "abstract": "The two most powerful extensive air showers (EAS) with energies of about\n$10^{20}$ eV, registered at the Yakutsk EAS array during the entire observation\nperiod of 1974-2024, are considered. Both showers hit the array near the center\nand triggered all surface detectors and underground muon detectors with a\nthreshold energy of $E_{\\mu} = 1.0 \\times \\cos \\theta$ GeV. These events have\nan abnormally high fraction of muons, which is beyond current model\npredictions. This may change our understanding of hadron interactions at\nultra-high energy, but there is also a possibility that these showers were\ninitiated by some exotic primary particles.",
    "pdf_url": "http://arxiv.org/pdf/2506.00517v1",
    "published": "2025-05-31T11:25:13+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00516v1",
    "title": "Jet breakup dynamics of viscoelastic carboxymethyl cellulose solutions",
    "authors": [
      "Ketan Vinayak Warghat",
      "Yogesh Biswal",
      "Sukesh Sharma",
      "Pankaj Sharadchandra Kolhe",
      "Lakshmana Dora Chandrala",
      "Kirti Chandra Sahu"
    ],
    "abstract": "We experimentally investigate the breakup dynamics of viscoelastic jets\ncomposed of carboxymethyl cellulose (CMC) solutions, focusing on the dripping\nand Rayleigh regimes at low flow rates. By varying the CMC concentration,\nneedle diameter ($D_n$), and flow rate ($Q$), we analyze the effects of\nelasticity, viscosity, and flow conditions on jet stability and droplet\nformation. Our results show that increasing CMC concentration enhances\nviscoelastic effects, leading to prolonged jet lifetimes, extended liquid\nthreads, and modified pinch-off behavior. At higher concentrations, elasticity\nsuppresses capillary-driven instabilities, slowing thinning and facilitating\nthe formation of beaded structures. We observe that the interplay between\ninertial, capillary, and elastic forces, influenced by CMC concentration,\ngoverns the jet length, droplet volume, and breakup time, with needle diameter\nand flow rate playing a crucial role in jet breakup phenomenon.",
    "pdf_url": "http://arxiv.org/pdf/2506.00516v1",
    "published": "2025-05-31T11:24:27+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.00515v1",
    "title": "Complete universal scaling of first-order phase transitions in the two-dimensional Ising model",
    "authors": [
      "Yuxiang Zhang",
      "Fan Zhong"
    ],
    "abstract": "Phase transitions, as one of the most intriguing phenomena in nature, are\ndivided into first-order phase transitions (FOPTs) and continuous ones in\ncurrent classification. While the latter shows striking phenomena of scaling\nand universality, the former has recently also been demonstrated to exhibit\nscaling and universal behavior within a mesoscopic, coarse-grained\nLandau-Ginzburg theory. Here we apply this theory to a microscopic model -- the\nparadigmatic Ising model, which undergoes FOPTs between two ordered phases\nbelow its critical temperature -- and unambiguously demonstrate universal\nscaling behavior in such FOPTs. These results open the door for extending the\ntheory to other microscopic FOPT systems and experimentally testing them to\nsystematically uncover their scaling and universal behavior.",
    "pdf_url": "http://arxiv.org/pdf/2506.00515v1",
    "published": "2025-05-31T11:20:36+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2506.00514v1",
    "title": "Evaluating the Evaluation of Diversity in Commonsense Generation",
    "authors": [
      "Tianhui Zhang",
      "Bei Peng",
      "Danushka Bollegala"
    ],
    "abstract": "In commonsense generation, given a set of input concepts, a model must\ngenerate a response that is not only commonsense bearing, but also capturing\nmultiple diverse viewpoints. Numerous evaluation metrics based on form- and\ncontent-level overlap have been proposed in prior work for evaluating the\ndiversity of a commonsense generation model. However, it remains unclear as to\nwhich metrics are best suited for evaluating the diversity in commonsense\ngeneration. To address this gap, we conduct a systematic meta-evaluation of\ndiversity metrics for commonsense generation. We find that form-based diversity\nmetrics tend to consistently overestimate the diversity in sentence sets, where\neven randomly generated sentences are assigned overly high diversity scores. We\nthen use an Large Language Model (LLM) to create a novel dataset annotated for\nthe diversity of sentences generated for a commonsense generation task, and use\nit to conduct a meta-evaluation of the existing diversity evaluation metrics.\nOur experimental results show that content-based diversity evaluation metrics\nconsistently outperform the form-based counterparts, showing high correlations\nwith the LLM-based ratings. We recommend that future work on commonsense\ngeneration should use content-based metrics for evaluating the diversity of\ntheir outputs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00514v1",
    "published": "2025-05-31T11:18:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00513v1",
    "title": "SSAM: Self-Supervised Association Modeling for Test-Time Adaption",
    "authors": [
      "Yaxiong Wang",
      "Zhenqiang Zhang",
      "Lechao Cheng",
      "Zhun Zhong",
      "Dan Guo",
      "Meng Wang"
    ],
    "abstract": "Test-time adaption (TTA) has witnessed important progress in recent years,\nthe prevailing methods typically first encode the image and the text and design\nstrategies to model the association between them. Meanwhile, the image encoder\nis usually frozen due to the absence of explicit supervision in TTA scenarios.\nWe identify a critical limitation in this paradigm: While test-time images\noften exhibit distribution shifts from training data, existing methods\npersistently freeze the image encoder due to the absence of explicit\nsupervision during adaptation. This practice overlooks the image encoder's\ncrucial role in bridging distribution shift between training and test. To\naddress this challenge, we propose SSAM (Self-Supervised Association Modeling),\na new TTA framework that enables dynamic encoder refinement through dual-phase\nassociation learning. Our method operates via two synergistic components: 1)\nSoft Prototype Estimation (SPE), which estimates probabilistic category\nassociations to guide feature space reorganization, and 2) Prototype-anchored\nImage Reconstruction (PIR), enforcing encoder stability through\ncluster-conditional image feature reconstruction. Comprehensive experiments\nacross diverse baseline methods and benchmarks demonstrate that SSAM can\nsurpass state-of-the-art TTA baselines by a clear margin while maintaining\ncomputational efficiency. The framework's architecture-agnostic design and\nminimal hyperparameter dependence further enhance its practical applicability.",
    "pdf_url": "http://arxiv.org/pdf/2506.00513v1",
    "published": "2025-05-31T11:13:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00512v2",
    "title": "Pro3D-Editor : A Progressive-Views Perspective for Consistent and Precise 3D Editing",
    "authors": [
      "Yang Zheng",
      "Mengqi Huang",
      "Nan Chen",
      "Zhendong Mao"
    ],
    "abstract": "Text-guided 3D editing aims to precisely edit semantically relevant local 3D\nregions, which has significant potential for various practical applications\nranging from 3D games to film production. Existing methods typically follow a\nview-indiscriminate paradigm: editing 2D views indiscriminately and projecting\nthem back into 3D space. However, they overlook the different cross-view\ninterdependencies, resulting in inconsistent multi-view editing. In this study,\nwe argue that ideal consistent 3D editing can be achieved through a\n\\textit{progressive-views paradigm}, which propagates editing semantics from\nthe editing-salient view to other editing-sparse views. Specifically, we\npropose \\textit{Pro3D-Editor}, a novel framework, which mainly includes\nPrimary-view Sampler, Key-view Render, and Full-view Refiner. Primary-view\nSampler dynamically samples and edits the most editing-salient view as the\nprimary view. Key-view Render accurately propagates editing semantics from the\nprimary view to other key views through its Mixture-of-View-Experts Low-Rank\nAdaption (MoVE-LoRA). Full-view Refiner edits and refines the 3D object based\non the edited multi-views. Extensive experiments demonstrate that our method\noutperforms existing methods in editing accuracy and spatial consistency.",
    "pdf_url": "http://arxiv.org/pdf/2506.00512v2",
    "published": "2025-05-31T11:11:55+00:00",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00511v1",
    "title": "Topological phase control in Mn1-xGexBi2Te4 via spin-orbit coupling and magnetic configuration engineering",
    "authors": [
      "A. M. Shikin",
      "N. L. Zaitsev",
      "A. V. Eryzhenkov",
      "R. V. Makeev",
      "T. P. Estyunina",
      "D. A. Estyunin",
      "A. V. Tarasov"
    ],
    "abstract": "Magnetic topological systems based on MnBi2Te4 have recently attracted\nsignificant attention due to their rich interplay between magnetism and\ntopological electronic states. In this work, using density functional theory\n(DFT), we investigate topological phase transitions (TPTs) in Mn1-xGexBi2Te4\ncompounds with both ferromagnetic (FM) and antiferromagnetic (AFM) ordering\nunder variations of spin-orbit coupling (SOC) strength and uniaxial strain\nalong the c axis. We show that the emergence of a Weyl semimetal (WSM) phase\nrequires the crossing of bands with opposite sz spin projections along the\n{\\Gamma}Z direction. Modulation of SOC and strain can annihilate Weyl points\nvia spin-selective hybridization, driving transitions into trivial or\ntopological insulating phases. Furthermore, we demonstrate that local asymmetry\nin Mn/Ge substitution, particularly at 37.5% Ge concentration\n(Mn0.625Ge0.375Bi2Te4) can locally disrupt AFM interlayer coupling and induce a\nWSM state even in globally AFM systems, without external remagnetization. To\noptimize Weyl point separation and enhance the anomalous Hall effect (AHE), we\npropose partial substitution of Mn by Fe and Te by Se.",
    "pdf_url": "http://arxiv.org/pdf/2506.00511v1",
    "published": "2025-05-31T11:03:59+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00510v1",
    "title": "Quark Wigner distribution in frame-independent 3-dimensional space",
    "authors": [
      "Sujit Janaa",
      "Vikash Kumar Ojha"
    ],
    "abstract": "We investigate the quark Wigner distribution in a frame-independent,\nthree-dimensional position space within the framework of the dressed quark\nmodel. It is observed that the distributions are concentrated near the center\nof the target and gradually diminish as one moves away in both the longitudinal\nand transverse directions. The distribution exhibits symmetry along both axes,\nindicating an equal probability of locating the quark in either direction\naround the center. Interestingly, the spatial profile of the distribution\nresembles that of atomic orbitals, where the probability of finding an electron\nis highest in certain regions compared to others.",
    "pdf_url": "http://arxiv.org/pdf/2506.00510v1",
    "published": "2025-05-31T11:02:44+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00509v1",
    "title": "Goal-Aware Identification and Rectification of Misinformation in Multi-Agent Systems",
    "authors": [
      "Zherui Li",
      "Yan Mi",
      "Zhenhong Zhou",
      "Houcheng Jiang",
      "Guibin Zhang",
      "Kun Wang",
      "Junfeng Fang"
    ],
    "abstract": "Large Language Model-based Multi-Agent Systems (MASs) have demonstrated\nstrong advantages in addressing complex real-world tasks. However, due to the\nintroduction of additional attack surfaces, MASs are particularly vulnerable to\nmisinformation injection. To facilitate a deeper understanding of\nmisinformation propagation dynamics within these systems, we introduce\nMisinfoTask, a novel dataset featuring complex, realistic tasks designed to\nevaluate MAS robustness against such threats. Building upon this, we propose\nARGUS, a two-stage, training-free defense framework leveraging goal-aware\nreasoning for precise misinformation rectification within information flows.\nOur experiments demonstrate that in challenging misinformation scenarios, ARGUS\nexhibits significant efficacy across various injection attacks, achieving an\naverage reduction in misinformation toxicity of approximately 28.17% and\nimproving task success rates under attack by approximately 10.33%. Our code and\ndataset is available at: https://github.com/zhrli324/ARGUS.",
    "pdf_url": "http://arxiv.org/pdf/2506.00509v1",
    "published": "2025-05-31T11:02:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.03191v1",
    "title": "Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward",
    "authors": [
      "Muhammad Islam",
      "Tao Huang",
      "Euijoon Ahn",
      "Usman Naseem"
    ],
    "abstract": "This paper presents an in-depth survey on the use of multimodal Generative\nArtificial Intelligence (GenAI) and autoregressive Large Language Models (LLMs)\nfor human motion understanding and generation, offering insights into emerging\nmethods, architectures, and their potential to advance realistic and versatile\nmotion synthesis. Focusing exclusively on text and motion modalities, this\nresearch investigates how textual descriptions can guide the generation of\ncomplex, human-like motion sequences. The paper explores various generative\napproaches, including autoregressive models, diffusion models, Generative\nAdversarial Networks (GANs), Variational Autoencoders (VAEs), and\ntransformer-based models, by analyzing their strengths and limitations in terms\nof motion quality, computational efficiency, and adaptability. It highlights\nrecent advances in text-conditioned motion generation, where textual inputs are\nused to control and refine motion outputs with greater precision. The\nintegration of LLMs further enhances these models by enabling semantic\nalignment between instructions and motion, improving coherence and contextual\nrelevance. This systematic survey underscores the transformative potential of\ntext-to-motion GenAI and LLM architectures in applications such as healthcare,\nhumanoids, gaming, animation, and assistive technologies, while addressing\nongoing challenges in generating efficient and realistic human motion.",
    "pdf_url": "http://arxiv.org/pdf/2506.03191v1",
    "published": "2025-05-31T11:02:24+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00508v1",
    "title": "Symbolic Higher-Order Analysis of Multivariate Time Series",
    "authors": [
      "Andrea Civilini",
      "Fabrizio de Vico Fallani",
      "Vito Latora"
    ],
    "abstract": "Identifying patterns of relations among the units of a complex system from\nmeasurements of their activities in time is a fundamental problem with many\npractical applications. Here, we introduce a method that detects dependencies\nof any order in multivariate time series data. The method first transforms a\nmultivariate time series into a symbolic sequence, and then extract\nstatistically significant strings of symbols through a Bayesian approach. Such\nmotifs are finally modelled as the hyperedges of a hypergraph, allowing us to\nuse network theory to study higher-order interactions in the original data.\nWhen applied to neural and social systems, our method reveals meaningful\nhigher-order dependencies, highlighting their importance in both brain function\nand social behaviour.",
    "pdf_url": "http://arxiv.org/pdf/2506.00508v1",
    "published": "2025-05-31T11:02:11+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.SI",
      "physics.app-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00507v1",
    "title": "Exploring In-context Example Generation for Machine Translation",
    "authors": [
      "Dohyun Lee",
      "Seungil Chad Lee",
      "Chanwoo Yang",
      "Yujin Baek",
      "Jaegul Choo"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong performance across\nvarious tasks, leveraging their exceptional in-context learning ability with\nonly a few examples. Accordingly, the selection of optimal in-context examples\nhas been actively studied in the field of machine translation. However, these\nstudies presuppose the presence of a demonstration pool with human-annotated\npairs, making them less applicable to low-resource languages where such an\nassumption is challenging to meet. To overcome this limitation, this paper\nexplores the research direction of in-context example generation for machine\ntranslation. Specifically, we propose Demonstration Augmentation for\nTranslation (DAT), a simple yet effective approach that generates example pairs\nwithout relying on any external resources. This method builds upon two prior\ncriteria, relevance and diversity, which have been highlighted in previous work\nas key factors for in-context example selection. Through experiments and\nanalysis on low-resource languages where human-annotated pairs are scarce, we\nshow that DAT achieves superior translation quality compared to the baselines.\nFurthermore, we investigate the potential of progressively accumulating\ngenerated pairs during test time to build and reuse a demonstration pool. Our\nimplementation is publicly available at https://github.com/aiclaudev/DAT.",
    "pdf_url": "http://arxiv.org/pdf/2506.00507v1",
    "published": "2025-05-31T11:00:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00506v2",
    "title": "Quality Assessment of Noisy and Enhanced Speech with Limited Data: UWB-NTIS System for VoiceMOS 2024 and Beyond",
    "authors": [
      "Marie Kunešová"
    ],
    "abstract": "In this preprint, we present the UWB-NTIS-TTS team's submission to Track 3 of\nthe VoiceMOS 2024 Challenge, the goal of which was to automatically assess the\nspeech quality of noisy and de-noised speech in terms of the ITU-T P.835\nmetrics of \"SIG\", \"BAK\", and \"OVRL\". Our proposed system, based on wav2vec 2.0,\nplaced among the top systems in the challenge, achieving the best prediction of\nthe BAK scores (background noise intrusiveness), the second-best prediction of\nthe OVRL score (overall audio quality), and the third-best prediction of SIG\n(speech signal quality) out of the five participating systems. We describe our\napproach, such as the two-stage fine-tuning process we used to contend with the\nchallenge's very limiting restrictions on allowable training data, and present\nthe results achieved both on the VoiceMOS 2024 Challenge data and on the\nrecently released CHiME 7 - UDASE dataset.",
    "pdf_url": "http://arxiv.org/pdf/2506.00506v2",
    "published": "2025-05-31T11:00:15+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00505v1",
    "title": "From Rules to Rewards: Reinforcement Learning for Interest Rate Adjustment in DeFi Lending",
    "authors": [
      "Hanxiao Qu",
      "Krzysztof Gogol",
      "Florian Groetschla",
      "Claudio Tessone"
    ],
    "abstract": "Decentralized Finance (DeFi) lending enables permissionless borrowing via\nsmart contracts. However, it faces challenges in optimizing interest rates,\nmitigating bad debt, and improving capital efficiency. Rule-based interest-rate\nmodels struggle to adapt to dynamic market conditions, leading to\ninefficiencies. This work applies Offline Reinforcement Learning (RL) to\noptimize interest rate adjustments in DeFi lending protocols. Using historical\ndata from Aave protocol, we evaluate three RL approaches: Conservative\nQ-Learning (CQL), Behavior Cloning (BC), and TD3 with Behavior Cloning\n(TD3-BC). TD3-BC demonstrates superior performance in balancing utilization,\ncapital stability, and risk, outperforming existing models. It adapts\neffectively to historical stress events like the May 2021 crash and the March\n2023 USDC depeg, showcasing potential for automated, real-time governance.",
    "pdf_url": "http://arxiv.org/pdf/2506.00505v1",
    "published": "2025-05-31T10:56:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00504v1",
    "title": "On a class of bounded Hermitian operators for the Bell-CHSH inequality in Quantum Field Theory",
    "authors": [
      "M. S. Guimaraes",
      "I. Roditi",
      "S. P. Sorella"
    ],
    "abstract": "The violation of the Bell-CHSH inequality in a relativistic scalar Quantum\nField Theory is analysed by means of a set of bounded Hermitian operators\nconstructed out of the unitary Weyl operators. These operators allow for both\nanalytic and numerical approaches. While the former relies on the modular\ntheory of Tomita-Takesaki, the latter is devised through an explicit\nconstruction of the test functions needed for the localization of the\naforementioned operators. The case of causal tangent diamonds in $1+1$\nMinkowski spacetime is scrutinized.",
    "pdf_url": "http://arxiv.org/pdf/2506.00504v1",
    "published": "2025-05-31T10:53:27+00:00",
    "categories": [
      "quant-ph",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00503v1",
    "title": "Reconstructing the Milky Way chemical map with Galactic Chemical Evolution tool OMEGA+ from SDSS-MWM",
    "authors": [
      "Viola Hegedűs",
      "Szabolcs Mészáros",
      "Blanka Világos",
      "Marco Pignatari",
      "J. Emily Griffith",
      "Diogo Souto",
      "Maria Lugaro"
    ],
    "abstract": "We obtain two-infall galactic chemical evolution (GCE) models simulating the\nchemical evolution of the Milky Way as constrained by a golden sample of\n$394,000$ stellar abundances of the Milky Way Mapper survey from the 19th data\nrelease of SDSS-V. The separation between the chemical thin and thick disks is\ndefined using [Mg/M]. We use the chemical evolution environment\n$\\texttt{OMEGA+}$, combined with Levenberg-Marquardt and bootstrapping. We\nsimulate the entire Galactic disk and six galactocentric regions for a more\ndetailed analysis of the formation of the inner, middle, and outer Galaxy. We\ninvestigate the evolution of $\\alpha$, odd-Z, and iron-peak elements: 15\nspecies altogether. The chemical thin and thick disks are separated by Mg\nobservations, which the other $\\alpha$-elements show similar trends with, while\nodd-Z species demonstrate different patterns as functions of metallicity. In\nthe inward Galactic disk regions the locus of the low-Mg sequence is gradually\nshifted toward higher metallicity, while the high-Mg phase is less populated.\nThe best-fit GCE models show a well-defined peak in the rate of the infalling\nmatter as a function of the Galactic age, confirming a merger event about $10$\nGyr ago. We show that the timescale of gas accretion, the time of the second\ninfall as well as the ratio between the surface mass densities associated to\nthe second infall and the formation event vary with the distance from the\nGalactic center. The disk is assembled within a timescale of\n$(0.32\\pm0.02)~$Gyr during a primary formation phase, then a\n$(0.55\\pm0.06)~$Gyr-timescale, increasing accretion rate was followed by a\nrelaxation that lasted $(2.86\\pm0.70)~$Gyr, with a second peak of the infall\nrate at $(4.13\\pm0.19)~$Gyr. Our best Galaxy evolution models are consistent\nwith an inside-out formation scenario of the Milky Way disk, in agreement with\nrecent chemo-dynamical simulations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00503v1",
    "published": "2025-05-31T10:46:40+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00502v2",
    "title": "Modeling and Optimal Control of Thermal Environment in Pig Houses",
    "authors": [
      "Mingxin Wei",
      "Jinrui Zhang",
      "Peter Groot Koerkamp",
      "Andre Aarnink",
      "Congcong Sun"
    ],
    "abstract": "The management of thermal environments in pig farming is crucial for\noptimizing animal health, productivity, and operational energy efficiency. This\nstudy introduces a novel thermal ventilation model (TVM) based on enthalpy\nbalance, which integrates both temperature and humidity control to address the\nspecific thermal regulation requirements of pig housing in regions\ncharacterized by high temperatures and humidity, such as Guangdong, China.\nThese challenging environmental conditions can lead to heat stress in pigs,\nadversely affecting their health and productivity. The TVM provides a precise\nrepresentation of thermal comfort by accounting for the combined effects of\ntemperature and humidity. Building on the TVM, we formulate an optimization\nproblem using Model Predictive Control (MPC), which dynamically adjusts\nventilation rates in real-time by modifying weight factors to minimize energy\nconsumption while keeping the temperature and humidity within the comfort zone\nof the pigs. The accuracy of the TVM is validated against real-world\nenvironmental data from pig housing facilities in Guangdong. The root mean\nsquare error of temperature in winter, spring and summer were 1.23, 0.81, and\n0.60, demonstrating its reliability and robustness across diverse climatic\nconditions. Furthermore, simulation results show that the proposed MPC strategy\nsignificantly improves energy efficiency and environmental comfort, achieving a\n100% comfort temperature zone in spring and 83% in summer, compared to 91% and\n43% with traditional rule-based control, respectively. However, the model's\nenergy consumption in summer (91.2 kWh) was higher than that of rule-based\ncontrol (80.8 kWh), reflecting the trade-off between maintaining optimal\ncomfort and energy efficiency under extreme conditions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00502v2",
    "published": "2025-05-31T10:43:53+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00501v1",
    "title": "Preconditioned primal-dual dynamics in convex optimization: non-ergodic convergence rates",
    "authors": [
      "Vassilis Apidopoulos",
      "Cesare Molinari",
      "Juan Peypouquet",
      "Silvia Villa"
    ],
    "abstract": "We introduce and analyze a continuous primal-dual dynamical system in the\ncontext of the minimization problem $f(x)+g(Ax)$, where $f$ and $g$ are convex\nfunctions and $A$ is a linear operator. In this setting, the trajectories of\nthe Arrow-Hurwicz continuous flow may not converge, accumulating at points that\nare not solutions. Our proposal is inspired by the primal-dual algorithm of\nChambolle and Pock (2011), where convergence and splitting on the primal-dual\nvariable are ensured by adequately preconditioning the proximal-point\nalgorithm. We consider a family of preconditioners, which are allowed to depend\non time and on the operator $A$, but not on the functions $f$ and $g$, and\nanalyze asymptotic properties of the corresponding preconditioned flow. Fast\nconvergence rates for the primal-dual gap and optimality of its (weak) limit\npoints are obtained, in the general case, for asymptotically antisymmetric\npreconditioners, and, in the case of linearly constrained optimization\nproblems, under milder hypotheses. Numerical examples support our theoretical\nfindings, especially in favor of the antisymmetric preconditioners.",
    "pdf_url": "http://arxiv.org/pdf/2506.00501v1",
    "published": "2025-05-31T10:39:32+00:00",
    "categories": [
      "math.OC",
      "34D05, 65K05, 65K10, 90C25"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00500v1",
    "title": "Scaling DeFi with ZK Rollups: Design, Deployment, and Evaluation of a Real-Time Proof-of-Concept",
    "authors": [
      "Krzysztof Gogol",
      "Szczepan Gurgul",
      "Faizan Nehal Siddiqui",
      "David Branes",
      "Claudio Tessone"
    ],
    "abstract": "Ethereum's scalability limitations pose significant challenges for the\nadoption of decentralized applications (dApps). Zero-Knowledge Rollups (ZK\nRollups) present a promising solution, bundling transactions off-chain and\nsubmitting validity proofs on-chain to enhance throughput and efficiency. In\nthis work, we examine the technical underpinnings of ZK Rollups and stress test\ntheir performance in real-world applications in decentralized finance (DeFi).\nWe set up a proof-of-concept (PoC) consisting of ZK rollup and decentralized\nexchange, and implement load balancer generating token swaps. Our results show\nthat the rollup can process up to 71 swap transactions per second, compared to\n12 general transaction by Ethereum. We further analyze transaction finality\ntrade-offs with related security concerns, and discuss the future directions\nfor integrating ZK Rollups into Ethereum's broader ecosystem.",
    "pdf_url": "http://arxiv.org/pdf/2506.00500v1",
    "published": "2025-05-31T10:39:24+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00499v1",
    "title": "Federated learning framework for collaborative remaining useful life prognostics: an aircraft engine case study",
    "authors": [
      "Diogo Landau",
      "Ingeborg de Pater",
      "Mihaela Mitici",
      "Nishant Saurabh"
    ],
    "abstract": "Complex systems such as aircraft engines are continuously monitored by\nsensors. In predictive aircraft maintenance, the collected sensor measurements\nare used to estimate the health condition and the Remaining Useful Life (RUL)\nof such systems. However, a major challenge when developing prognostics is the\nlimited number of run-to-failure data samples. This challenge could be overcome\nif multiple airlines would share their run-to-failure data samples such that\nsufficient learning can be achieved. Due to privacy concerns, however, airlines\nare reluctant to share their data in a centralized setting. In this paper, a\ncollaborative federated learning framework is therefore developed instead.\nHere, several airlines cooperate to train a collective RUL prognostic machine\nlearning model, without the need to centrally share their data. For this, a\ndecentralized validation procedure is proposed to validate the prognostics\nmodel without sharing any data. Moreover, sensor data is often noisy and of low\nquality. This paper therefore proposes four novel methods to aggregate the\nparameters of the global prognostic model. These methods enhance the robustness\nof the FL framework against noisy data. The proposed framework is illustrated\nfor training a collaborative RUL prognostic model for aircraft engines, using\nthe N-CMAPSS dataset. Here, six airlines are considered, that collaborate in\nthe FL framework to train a collective RUL prognostic model for their\naircraft's engines. When comparing the proposed FL framework with the case\nwhere each airline independently develops their own prognostic model, the\nresults show that FL leads to more accurate RUL prognostics for five out of the\nsix airlines. Moreover, the novel robust aggregation methods render the FL\nframework robust to noisy data samples.",
    "pdf_url": "http://arxiv.org/pdf/2506.00499v1",
    "published": "2025-05-31T10:32:51+00:00",
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.ET",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00498v2",
    "title": "UNSURF: Uncertainty Quantification for Cortical Surface Reconstruction of Clinical Brain MRIs",
    "authors": [
      "Raghav Mehta",
      "Karthik Gopinath",
      "Ben Glocker",
      "Juan Eugenio Iglesias"
    ],
    "abstract": "We propose UNSURF, a novel uncertainty measure for cortical surface\nreconstruction of clinical brain MRI scans of any orientation, resolution, and\ncontrast. It relies on the discrepancy between predicted voxel-wise signed\ndistance functions (SDFs) and the actual SDFs of the fitted surfaces. Our\nexperiments on real clinical scans show that traditional uncertainty measures,\nsuch as voxel-wise Monte Carlo variance, are not suitable for modeling the\nuncertainty of surface placement. Our results demonstrate that UNSURF estimates\ncorrelate well with the ground truth errors and: \\textit{(i)}~enable effective\nautomated quality control of surface reconstructions at the subject-, parcel-,\nmesh node-level; and \\textit{(ii)}~improve performance on a downstream\nAlzheimer's disease classification task.",
    "pdf_url": "http://arxiv.org/pdf/2506.00498v2",
    "published": "2025-05-31T10:31:51+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00497v3",
    "title": "Second-Order Characterization of Micro Doppler Radar Signatures of Drone Swarms",
    "authors": [
      "Anders Malthe Westerkam",
      "Alba Spliid Damkjær",
      "Rasmus Erik Villadsen",
      "Magnus Ørum Bastrup Poulsen",
      "Troels Pedersen"
    ],
    "abstract": "We investigate the second-order characteristics of the radar return signal\nfrom a swarm of rotor drones. We consider the case of a swarm of identical\ndrones, with each a number of rotors comprised of a number of rotor blades. By\nconsidering the orientation and speed of each rotor as stochastic variables, we\nderive expressions for the autocorrelation function (ACF) and power spectral\ndensity (PSD). The ACF and PSD are in the form of an infinite series with\ncoefficients that drop to zero at a predictable limit. Thus in practical\napplications, the series may be truncated. As a special case, we show that for\ndeterministic rotor speed, the ACF can be expressed in closed form. We further\ninvestigate how system parameters (Blade length, Rotor speed, number of blades,\nand number of drones) influence the derived expressions for the ACF and PSD.",
    "pdf_url": "http://arxiv.org/pdf/2506.00497v3",
    "published": "2025-05-31T10:30:03+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00496v1",
    "title": "Monitoring Robustness and Individual Fairness",
    "authors": [
      "Ashutosh Gupta",
      "Thomas A. Henzinger",
      "Konstantin Kueffner",
      "Kaushik Mallik",
      "David Pape"
    ],
    "abstract": "Input-output robustness appears in various different forms in the literature,\nsuch as robustness of AI models to adversarial or semantic perturbations and\nindividual fairness of AI models that make decisions about humans.\n  We propose runtime monitoring of input-output robustness of deployed,\nblack-box AI models, where the goal is to design monitors that would observe\none long execution sequence of the model, and would raise an alarm whenever it\nis detected that two similar inputs from the past led to dissimilar outputs.\n  This way, monitoring will complement existing offline ``robustification''\napproaches to increase the trustworthiness of AI decision-makers.\n  We show that the monitoring problem can be cast as the fixed-radius nearest\nneighbor (FRNN) search problem, which, despite being well-studied, lacks\nsuitable online solutions.\n  We present our tool Clemont, which offers a number of lightweight monitors,\nsome of which use upgraded online variants of existing FRNN algorithms, and one\nuses a novel algorithm based on binary decision diagrams -- a data-structure\ncommonly used in software and hardware verification.\n  We have also developed an efficient parallelization technique that can\nsubstantially cut down the computation time of monitors for which the distance\nbetween input-output pairs is measured using the $L_\\infty$ norm.\n  Using standard benchmarks from the literature of adversarial and semantic\nrobustness and individual fairness, we perform a comparative study of different\nmonitors in \\tool, and demonstrate their effectiveness in correctly detecting\nrobustness violations at runtime.",
    "pdf_url": "http://arxiv.org/pdf/2506.00496v1",
    "published": "2025-05-31T10:27:54+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00495v1",
    "title": "FLoE: Fisher-Based Layer Selection for Efficient Sparse Adaptation of Low-Rank Experts",
    "authors": [
      "Xinyi Wang",
      "Lirong Gao",
      "Haobo Wang",
      "Yiming Zhang",
      "Junbo Zhao"
    ],
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a widely\nadopted strategy for adapting pre-trained Large Language Models (LLMs) to\ndownstream tasks, significantly reducing memory and computational costs.\nHowever, most existing PEFT techniques uniformly deploy LoRA adapters across\nall layers, disregarding the intrinsic heterogeneity of layer contributions and\ntask-specific rank requirements. This uniform paradigm leads to redundant\nparameter allocation and suboptimal adaptation efficiency. To address these\nlimitations, we propose FLoE, a novel PEFT framework that introduces two key\ninnovations: (i) a Fisher information-guided importance scoring mechanism to\ndynamically identify task-critical transformer layers for MoE-based low-rank\nadaptation, enabling sparse adapter deployment; and (ii) a Bayesian\noptimization-driven rank allocator that automatically determines optimal LoRA\nranks on specific datasets without exhaustive grid search. Extensive\nexperiments across diverse LLMs and benchmarks reveal that FLoE achieves\nimpressive efficiency-accuracy trade-offs, making FLoE particularly\nadvantageous in resource-constrained environments that necessitate rapid\nadaptation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00495v1",
    "published": "2025-05-31T10:27:08+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00494v1",
    "title": "Multi-Objective Neural Network Assisted Design Optimization of Soft Fin-Ray Grippers for Enhanced Grasping Performance",
    "authors": [
      "Ali Ghanizadeh",
      "Ali Ahmadi",
      "Arash Bahrami"
    ],
    "abstract": "Soft Fin-Ray grippers can perform delicate and careful manipulation, which\nhas caused notable attention in different fields. These grippers can handle\nobjects of various forms and sizes safely. The internal structure of the\nFin-Ray finger plays a significant role in its adaptability and grasping\nperformance. However, modeling the non-linear grasp force and deformation\nbehaviors for design purposes is challenging. Moreover, when the Fin-Ray finger\nbecomes more rigid and capable of exerting higher forces, it becomes less\ndelicate in handling objects. The contrast between these two objectives gives\nrise to a multi-objective optimization problem. In this study, we employ finite\nelement method (FEM) to estimate the deflections and contact forces of the\nFin-Ray, grasping cylindrical objects. This dataset is then used to construct a\nmultilayer perception (MLP) for prediction of the contact force and the tip\ndisplacement. The FEM dataset consists of three input and four target features.\nThe three input features of the MLP and optimization design variables are the\nthickness of the front and supporting beams, the thickness of the cross beams,\nand the equal spacing between the cross beams. In addition, the target features\nare the maximum contact forces and maximum tip displacements in x- and\ny-directions. The magnitude of maximum contact force and magnitude of maximum\ntip displacement are the two objectives, showing the trade-off between force\nand delicate manipulation in soft Fin-Ray grippers. Furthermore, the optimized\nset of solutions are found using multi-objective optimal techniques. We use\nnon-dominated sorting genetic algorithm (NSGA-II) method for this purpose. Our\nfindings demonstrate that our methodologies can be used to improve the design\nand gripping performance of soft robotic grippers, helping us to choose a\ndesign not only for delicate grasping but also for high-force applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00494v1",
    "published": "2025-05-31T10:16:58+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00493v5",
    "title": "Asteroseismology of the G8 subgiant beta Aquilae with SONG-Tenerife, SONG-Australia and TESS",
    "authors": [
      "Hans Kjeldsen",
      "Timothy R. Bedding",
      "Yaguang Li",
      "Frank Grundahl",
      "Mads Fredslund Andersen",
      "Duncan J. Wright",
      "Jack Soutter",
      "Robert Wittenmyer",
      "Claudia Reyes",
      "Dennis Stello",
      "Courtney Crawford",
      "Yixiao Zhou",
      "Mathieu Clerte",
      "Pere L. Palle",
      "Sergio Simon-Diaz",
      "Joergen Christensen-Dalsgaard",
      "Rasmus Handberg",
      "Hasse Hansen",
      "Paul Heeren",
      "Jens Jessen-Hansen",
      "Mikkel N. Lund",
      "Mia S. Lundkvist",
      "Karsten Brogaard",
      "Rene Tronsgaard",
      "Jonatan Rudrasingam",
      "Luca Casagrande",
      "Jonathan Horner",
      "Daniel Huber",
      "John Lattanzio",
      "Sarah L. Martell",
      "Simon J. Murphy"
    ],
    "abstract": "We present time-series radial velocities of the G8 subgiant star beta Aql\nobtained in 2022 and 2023 using SONG-Tenerife and, for the first time,\nSONG-Australia. We also analyse a sector of TESS photometry that overlapped\nwith the 2022 SONG data. The resulting power spectrum clearly shows solar-like\noscillations centred at 430 muHz. The TESS light curve shows the oscillations\nat lower signal-to-noise, reflecting the fact that photometric measurements are\nmuch more affected by the granulation background than are radial velocities.\nThe simultaneous observations in velocity and photometry represent the best\nsuch measurements for any star apart from the Sun. They allowed us to measure\nthe ratio between the bolometric photometric amplitude and the velocity\namplitude to be 26.6 +/- 3.1 ppm/(m/s). We measured this ratio for the Sun from\npublished SOHO data to be 19.5 +/- 0.7 ppm/(m/s) and, after accounting for the\ndifference in effective temperatures of and the Sun, these values align with\nexpectations. In both the Sun and beta Aql, the photometry-to-velocity ratio\nappears to be a function of frequency. We also measured the phase shift of the\noscillations in beta Aql between SONG and TESS to be -113 +/- 7 deg, which\nagrees with the value for the Sun and also with a 3-D simulation of a star with\nsimilar properties to beta Aql. Importantly for exoplanet searches, we argue\nthat simultaneous photometry can be used to predict the contribution of\noscillations to radial velocities. We measured frequencies for 22 oscillation\nmodes in beta Aql and carried out asteroseismic modelling, yielding an\nexcellent fit to the frequencies. We derived accurate values for the mass and\nage, and were able to place quite strong constraints on the mixing-length\nparameter. Finally, we show that the oscillation properties of beta Aql are\nvery similar to stars in the open cluster M67.",
    "pdf_url": "http://arxiv.org/pdf/2506.00493v5",
    "published": "2025-05-31T10:01:21+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00492v2",
    "title": "Energy Time Ptychography for one-dimensional phase retrieval",
    "authors": [
      "Ankita Negi",
      "Leon Merten Lohse",
      "Sven Velten",
      "Ilya Sergeev",
      "Olaf Leupold",
      "Sakshath Sadashivaiah",
      "Dimitrios Bessas",
      "Aleksandr Chumakhov",
      "Christina Brandt",
      "Lars Bocklage",
      "Guido Meier",
      "Ralf Röhlsberger"
    ],
    "abstract": "Phase retrieval is at the heart of adaptive optics and modern high-resolution\nimaging. Without phase information, optical systems are limited to\nintensity-only measurements, hindering full reconstruction of object structures\nand wavefront dynamics essential for advanced applications. Here, we address a\none-dimensional phase problem linking energy and time, which arises in X-ray\nscattering from ultrasharp nuclear resonances. We leverage the M\\\"ossbauer\neffect, where nuclei scatter radiation without energy loss to the lattice, and\nare sensitive to their magneto-chemical environments. Rather than using\ntraditional spectroscopy with radioactive gamma-ray sources, we measure nuclear\nforward scattering of synchrotron X-ray pulses in the time domain, providing\nsuperior sensitivity and faster data acquisition. Extracting spectral\ninformation from a single measurement is challenging due to the missing phase\ninformation, typically requiring extensive modeling. Instead, we use multiple\nenergetically overlapping measurements to retrieve both the transmission\nspectrum and the phase of the scattering response, similar to ptychographic\nphase retrieval in imaging. Our robust approach can overcome the bandwidth\nlimitations of gamma-ray sources, opening new research directions with modern\nX-ray sources and M\\\"ossbauer isotopes.",
    "pdf_url": "http://arxiv.org/pdf/2506.00492v2",
    "published": "2025-05-31T09:59:14+00:00",
    "categories": [
      "physics.optics",
      "physics.atom-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.00491v1",
    "title": "Optimizing Question Semantic Space for Dynamic Retrieval-Augmented Multi-hop Question Answering",
    "authors": [
      "Linhao Ye",
      "Lang Yu",
      "Zhikai Lei",
      "Qin Chen",
      "Jie Zhou",
      "Liang He"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is usually integrated into large\nlanguage models (LLMs) to mitigate hallucinations and knowledge obsolescence.\nWhereas,conventional one-step retrieve-and-read methods are insufficient for\nmulti-hop question answering, facing challenges of retrieval semantic\nmismatching and the high cost in handling interdependent subquestions. In this\npaper, we propose Optimizing Question Semantic Space for Dynamic\nRetrieval-Augmented Multi-hop Question Answering (Q-DREAM). Q-DREAM consists of\nthree key modules: (1) the Question Decomposition Module (QDM), which\ndecomposes multi-hop questions into fine-grained subquestions; (2) the\nSubquestion Dependency Optimizer Module (SDOM), which models the interdependent\nrelations of subquestions for better understanding; and (3) the Dynamic Passage\nRetrieval Module (DPRM), which aligns subquestions with relevant passages by\noptimizing the semantic embeddings. Experimental results across various\nbenchmarks demonstrate that Q-DREAM significantly outperforms existing RAG\nmethods, achieving state-of-the-art performance in both in-domain and\nout-of-domain settings. Notably, Q-DREAM also improves retrieval efficiency\nwhile maintaining high accuracy compared with recent baselines.",
    "pdf_url": "http://arxiv.org/pdf/2506.00491v1",
    "published": "2025-05-31T09:57:07+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00490v2",
    "title": "LLM-Driven Instance-Specific Heuristic Generation and Selection",
    "authors": [
      "Shaofeng Zhang",
      "Shengcai Liu",
      "Ning Lu",
      "Jiahao Wu",
      "Ji Liu",
      "Yew-Soon Ong",
      "Ke Tang"
    ],
    "abstract": "Combinatorial optimization problems are widely encountered in real-world\napplications. Designing high-quality heuristic algorithms that efficiently\napproximate optimal solutions within reasonable time is a critical research\nchallenge. In recent years, many works have explored integrating Large Language\nModels (LLMs) with Evolutionary Algorithms to automate heuristic algorithm\ndesign through prompt engineering. However, these approaches generally adopt a\nproblem-specific paradigm, applying a single algorithm across all problem\ninstances, failing to account for the heterogeneity across instances. In this\npaper, we propose InstSpecHH, a novel framework that introduces the concept of\ninstance-specific heuristic generation. InstSpecHH partitions the overall\nproblem class into sub-classes based on instance features and performs\ndifferentiated, automated heuristic design for each problem subclass. By\ntailoring heuristics to the unique features of different sub-classes,\nInstSpecHH achieves better performance at the problem class level while\navoiding redundant heuristic generation for similar instances, thus reducing\ncomputational overhead. This approach effectively balances the trade-off\nbetween the cost of automatic heuristic design and the quality of the obtained\nsolutions. To evaluate the performance of InstSpecHH, we conduct experiments on\n4,500 subclasses of the Online Bin Packing Problem (OBPP) and 365 subclasses of\nthe Capacitated Vehicle Routing Problem (CVRP). Experimental results show that\nInstSpecHH demonstrates strong intra-subclass and inter-subclass generalization\ncapabilities. Compared to previous problem-specific methods, InstSpecHH reduces\nthe average optimality gap by more than 5.6\\% for OBPP and 0.9\\% for CVRP.\nThese results highlight the potential of instance-aware automatic heuristic\ndesign to further enhance solution quality.",
    "pdf_url": "http://arxiv.org/pdf/2506.00490v2",
    "published": "2025-05-31T09:54:36+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00489v1",
    "title": "A phylogeny of biological patterns formed by nonlocal advection",
    "authors": [
      "Valeria Giunta",
      "Thomas Hillen",
      "Mark A. Lewis",
      "Jonathan R. Potts"
    ],
    "abstract": "From tumour invasion to cell sorting and animal territoriality, many\nbiological systems rely on nonlocal interactions that drive complex spatial\norganisation. Partial differential equations (PDEs) with nonlocal advection are\nincreasingly recognised as powerful tools for capturing such phenomena.\nHowever, most research has focused on one-dimensional domains, leaving their\ntwo-dimensional behaviour largely unexplored. Here, we present a detailed\nnumerical study of the patterns formed by these systems on 2D domains.\nDepending on the underlying mechanisms, a wide variety of spatial patterns can\nemerge - including segregated clusters, stripes, volcanos, and polygonal\nmosaics - many of which have been observed in natural systems. By\nsystematically varying model parameters, we classify the links between emergent\npatterns and their underlying movement mechanisms. In comparing these patterns\nwith empirical observations, we show how this modelling framework can help\nreveal possible mechanisms of self-organisation in various situations within\nthe life sciences, from ecology and developmental biology to cancer research.",
    "pdf_url": "http://arxiv.org/pdf/2506.00489v1",
    "published": "2025-05-31T09:52:19+00:00",
    "categories": [
      "q-bio.PE",
      "math.AP"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00488v1",
    "title": "Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection",
    "authors": [
      "Shuguo Hu",
      "Jun Hu",
      "Huaiwen Zhang"
    ],
    "abstract": "Large Language Models (LLMs) can assist multimodal fake news detection by\npredicting pseudo labels. However, LLM-generated pseudo labels alone\ndemonstrate poor performance compared to traditional detection methods, making\ntheir effective integration non-trivial. In this paper, we propose Global Label\nPropagation Network with LLM-based Pseudo Labeling (GLPN-LLM) for multimodal\nfake news detection, which integrates LLM capabilities via label propagation\ntechniques. The global label propagation can utilize LLM-generated pseudo\nlabels, enhancing prediction accuracy by propagating label information among\nall samples. For label propagation, a mask-based mechanism is designed to\nprevent label leakage during training by ensuring that training nodes do not\npropagate their own labels back to themselves. Experimental results on\nbenchmark datasets show that by synergizing LLMs with label propagation, our\nmodel achieves superior performance over state-of-the-art baselines.",
    "pdf_url": "http://arxiv.org/pdf/2506.00488v1",
    "published": "2025-05-31T09:50:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00487v2",
    "title": "Initial condition for the Balitsky-Kovchegov equation at next-to-leading order",
    "authors": [
      "Carlisle Casuga",
      "Henri Hänninen",
      "Heikki Mäntysaari"
    ],
    "abstract": "We determine the initial condition of the Balitsky-Kovchegov evolution\nequation at next-to-leading order (NLO) accuracy using HERA deep inelastic\nscattering data. Posterior distributions characterizing the initial condition\nare extracted using Bayesian inference. The total cross section and charm quark\nproduction data from HERA are found to provide stringent constraints on the\nposterior. These distributions quantify the uncertainty in the initial\ncondition and serve as necessary input for propagating uncertainties to all NLO\ncalculations within the Color Glass Condensate framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.00487v2",
    "published": "2025-05-31T09:50:26+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00486v3",
    "title": "It Takes a Good Model to Train a Good Model: Generalized Gaussian Priors for Optimized LLMs",
    "authors": [
      "Jun Wu",
      "Yirong Xiong",
      "Jiangtao Wen",
      "Yuxing Han"
    ],
    "abstract": "Despite rapid advancements in the research and deployment of large language\nmodels (LLMs), the statistical distribution of model parameters, as well as\ntheir influence on initialization, training dynamics, and downstream\nefficiency, has received surprisingly little attention. A recent work\nintroduced BackSlash, a training-time compression algorithm. It first\ndemonstrated that pre-trained LLM parameters follow generalized Gaussian\ndistributions (GGDs) better. By optimizing GG priors during training, BackSlash\ncan reduce parameters by up to 90\\% with minimal performance loss. Building on\nthis foundational insight, we propose a unified, end-to-end framework for LLM\noptimization based on the GG model. Our contributions are threefold: (1)\nGG-based initialization scheme that aligns with the statistical structure of\ntrained models, resulting in faster convergence and improved accuracy; (2)\nDeepShape, a post-training regularization method that reshapes weight\ndistributions to match a GG profile, improving compressibility with minimized\ndegradation in performance; and (3) RF8, a compact and hardware-efficient 8-bit\nfloating-point format designed for GG-distributed-initialized BackSlash\ntraining, enabling low-cost inference without compromising accuracy.\nExperiments across diverse model architectures show that our framework\nconsistently yields smaller and faster models that match or outperform standard\ntraining baselines. By grounding LLM development in principled statistical\nmodeling, this work forges a new path toward efficient, scalable, and\nhardware-aware AI systems. The code is available on our project page:\nhttps://huggingface.co/spaces/shifeng3711/gg_prior.",
    "pdf_url": "http://arxiv.org/pdf/2506.00486v3",
    "published": "2025-05-31T09:49:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00485v2",
    "title": "Information Geometry on the $\\ell^2$-Simplex via the $q$-Root Transform",
    "authors": [
      "Levin Maier"
    ],
    "abstract": "In this paper, we introduce \\emph{$\\ell^p$-information geometry}, an infinite\ndimensional framework that shares key features with the geometry of the space\nof probability densities \\( \\mathrm{Dens}(M) \\) on a closed manifold, while\nalso incorporating aspects of measure-valued information geometry. We define\nthe \\emph{$\\ell^2$-probability simplex} with a noncanonical differentiable\nstructure induced via the \\emph{$q$-root transform} from an open subset of the\n$\\ell^p$-sphere. This structure renders the $q$-root map an \\emph{isometry},\nenabling the definition of \\emph{Amari--\\v{C}encov $\\alpha$-connections} in\nthis setting.\n  We further construct \\emph{gradient flows} with respect to the $\\ell^2$\nFisher--Rao metric, which solve an infinite-dimensional linear optimization\nproblem. These flows are intimately linked to an \\emph{integrable Hamiltonian\nsystem} via a \\emph{momentum map} arising from a Hamiltonian group action on\nthe infinite-dimensional complex projective space.",
    "pdf_url": "http://arxiv.org/pdf/2506.00485v2",
    "published": "2025-05-31T09:47:24+00:00",
    "categories": [
      "math.SG",
      "math.DG",
      "math.DS"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00484v2",
    "title": "Reconstruction of Partial Dissimilarity Matrices for Cognitive Neuroscience",
    "authors": [
      "Denise Moerel",
      "Tijl Grootswagers"
    ],
    "abstract": "In cognitive neuroscience research, Representational Dissimilarity Matrices\n(RDMs) are often incomplete because pairwise similarity judgments cannot always\nbe exhaustively collected as the number of pairs rapidly increases with the\nnumber of conditions. Existing methods to fill these missing values, such as\ndeep neural network imputation, are powerful but computationally demanding and\nrelatively opaque. We introduce a simple algorithm based on geometric inference\nthat fills missing dissimilarity matrix entries using known distances. We use\ntests on publicly available empirical cognitive neuroscience datasets, as well\nas simulations, to demonstrate the method's effectiveness and robustness across\nvarying sparsity and matrix sizes. We have made this geometric reconstruction\nalgorithm, implemented in Python and MATLAB, publicly available. This method\nprovides a fast and accurate solution for completing partial dissimilarity\nmatrices in the cognitive neurosciences.",
    "pdf_url": "http://arxiv.org/pdf/2506.00484v2",
    "published": "2025-05-31T09:44:14+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00483v1",
    "title": "Auto-Patching: Enhancing Multi-Hop Reasoning in Language Models",
    "authors": [
      "Aviv Jan",
      "Dean Tahory",
      "Omer Talmi",
      "Omar Abo Mokh"
    ],
    "abstract": "Multi-hop questions still stump large language models (LLMs), which struggle\nto link information across multiple reasoning steps. We introduce Auto-Patch, a\nnovel method that dynamically patches hidden states during inference to enhance\nmulti-hop reasoning in LLMs. Building on the PatchScopes framework, Auto-Patch\nselectively modifies internal representations using a learned classifier.\nEvaluated on the MuSiQue dataset, Auto-Patch improves the solve rate from\n18.45\\% (baseline) to 23.63~$\\pm$~0.7\\% (3 runs), narrowing the gap to\nChain-of-Thought prompting (27.44\\%). Our results highlight the potential of\ndynamic hidden state interventions for advancing complex reasoning in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00483v1",
    "published": "2025-05-31T09:30:59+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00482v1",
    "title": "BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM Evaluation",
    "authors": [
      "Eunsu Kim",
      "Haneul Yoo",
      "Guijin Son",
      "Hitesh Patel",
      "Amit Agarwal",
      "Alice Oh"
    ],
    "abstract": "As large language models (LLMs) continue to advance, the need for up-to-date\nand well-organized benchmarks becomes increasingly critical. However, many\nexisting datasets are scattered, difficult to manage, and make it challenging\nto perform evaluations tailored to specific needs or domains, despite the\ngrowing importance of domain-specific models in areas such as math or code. In\nthis paper, we introduce BenchHub, a dynamic benchmark repository that empowers\nresearchers and developers to evaluate LLMs more effectively. BenchHub\naggregates and automatically classifies benchmark datasets from diverse\ndomains, integrating 303K questions across 38 benchmarks. It is designed to\nsupport continuous updates and scalable data management, enabling flexible and\ncustomizable evaluation tailored to various domains or use cases. Through\nextensive experiments with various LLM families, we demonstrate that model\nperformance varies significantly across domain-specific subsets, emphasizing\nthe importance of domain-aware benchmarking. We believe BenchHub can encourage\nbetter dataset reuse, more transparent model comparisons, and easier\nidentification of underrepresented areas in existing benchmarks, offering a\ncritical infrastructure for advancing LLM evaluation research.",
    "pdf_url": "http://arxiv.org/pdf/2506.00482v1",
    "published": "2025-05-31T09:24:32+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00481v1",
    "title": "PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion Strategies, Viewer Characteristics, and Persuasiveness Ratings",
    "authors": [
      "Junseo Kim",
      "Jongwook Han",
      "Dongmin Choi",
      "Jongwook Yoon",
      "Eun-Ju Lee",
      "Yohan Jo"
    ],
    "abstract": "Visual persuasion, which uses visual elements to influence cognition and\nbehaviors, is crucial in fields such as advertising and political\ncommunication. With recent advancements in artificial intelligence, there is\ngrowing potential to develop persuasive systems that automatically generate\npersuasive images tailored to individuals. However, a significant bottleneck in\nthis area is the lack of comprehensive datasets that connect the persuasiveness\nof images with the personal information about those who evaluated the images.\nTo address this gap and facilitate technological advancements in personalized\nvisual persuasion, we release the Personalized Visual Persuasion (PVP) dataset,\ncomprising 28,454 persuasive images across 596 messages and 9 persuasion\nstrategies. Importantly, the PVP dataset provides persuasiveness scores of\nimages evaluated by 2,521 human annotators, along with their demographic and\npsychological characteristics (personality traits and values). We demonstrate\nthe utility of our dataset by developing a persuasive image generator and an\nautomated evaluator, and establish benchmark baselines. Our experiments reveal\nthat incorporating psychological characteristics enhances the generation and\nevaluation of persuasive images, providing valuable insights for personalized\nvisual persuasion.",
    "pdf_url": "http://arxiv.org/pdf/2506.00481v1",
    "published": "2025-05-31T09:21:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00480v1",
    "title": "The Coupling Effect of Sensing Targets on the Environment for 3GPP ISAC Channels: Observation, Modeling, and Validation",
    "authors": [
      "Yameng Liu",
      "Jianhua Zhang",
      "Yuxiang Zhang",
      "Hongbo Xing",
      "Yifeng Xiong",
      "Zhiqiang Yuan",
      "Guangyi Liu"
    ],
    "abstract": "Integrated Sensing And Communication (ISAC) has been identified as a key 6G\napplication by ITU and 3GPP, with standardization efforts already underway.\nSensing tasks, such as target localization, demand more precise\ncharacterization of the sensing target (ST) in ISAC channel modeling. The ST\ncouples complexly with environmental scatterers, potentially blocking some\nmultipaths and generating new ones, resulting in power variations compared to\nthe original channel. To accurately model this effect, this paper proposes a\ncoupled ISAC channel model based on measurements and validates it through\nsimilarity analysis between simulated and measured channels. In this work, we\nfirst conduct ISAC channel measurements in an indoor factory scenario at 105\nGHz, where the multipath power variations caused by the ST's interaction with\nthe environment are clearly observed. Then, we propose an ISAC channel modeling\nframework that incorporates two novel parameters: the Blockage-Region Coupling\nFactor (BR-CF) and the Forward-Scattering (FS)-CF, which characterize the\nspatial region and intensity of the coupling effect, respectively. Finally, the\nproposed model is validated through similarity comparison with measured data,\ndemonstrating higher accuracy for both LoS and NLoS scenarios compared to the\nnon-coupled model. This realistic ISAC channel model provides an effective\nframework for capturing the ST-environment coupling effect, supporting the\ndesign and evaluation of ISAC technologies.",
    "pdf_url": "http://arxiv.org/pdf/2506.00480v1",
    "published": "2025-05-31T09:20:48+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.05378v1",
    "title": "A Compendium of Autonomous Navigation using Object Detection and Tracking in Unmanned Aerial Vehicles",
    "authors": [
      "Mohit Arora",
      "Pratyush Shukla",
      "Shivali Chopra"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) are one of the most revolutionary inventions\nof 21st century. At the core of a UAV lies the central processing system that\nuses wireless signals to control their movement. The most popular UAVs are\nquadcopters that use a set of four motors, arranged as two on either side with\nopposite spin. An autonomous UAV is called a drone. Drones have been in service\nin the US army since the 90's for covert missions critical to national\nsecurity. It would not be wrong to claim that drones make up an integral part\nof the national security and provide the most valuable service during\nsurveillance operations. While UAVs are controlled using wireless signals,\nthere reside some challenges that disrupt the operation of such vehicles such\nas signal quality and range, real time processing, human expertise, robust\nhardware and data security. These challenges can be solved by programming UAVs\nto be autonomous, using object detection and tracking, through Computer Vision\nalgorithms. Computer Vision is an interdisciplinary field that seeks the use of\ndeep learning to gain a high-level understanding of digital images and videos\nfor the purpose of automating the task of human visual system. Using computer\nvision, algorithms for detecting and tracking various objects can be developed\nsuitable to the hardware so as to allow real time processing for immediate\njudgement. This paper attempts to review the various approaches several authors\nhave proposed for the purpose of autonomous navigation of UAVs by through\nvarious algorithms of object detection and tracking in real time, for the\npurpose of applications in various fields such as disaster management, dense\narea exploration, traffic vehicle surveillance etc.",
    "pdf_url": "http://arxiv.org/pdf/2506.05378v1",
    "published": "2025-05-31T09:13:43+00:00",
    "categories": [
      "cs.CV",
      "cs.RO",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00479v1",
    "title": "EffiVLM-BENCH: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Vision-Language Models",
    "authors": [
      "Zekun Wang",
      "Minghua Ma",
      "Zexin Wang",
      "Rongchuan Mu",
      "Liping Shan",
      "Ming Liu",
      "Bing Qin"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable success, yet\ntheir significant computational demands hinder practical deployment. While\nefforts to improve LVLM efficiency are growing, existing methods lack\ncomprehensive evaluation across diverse backbones, benchmarks, and metrics. In\nthis work, we systematically evaluate mainstream acceleration techniques for\nLVLMs, categorized into token and parameter compression. We introduce\nEffiVLM-Bench, a unified framework for assessing not only absolute performance\nbut also generalization and loyalty, while exploring Pareto-optimal trade-offs.\nOur extensive experiments and in-depth analyses offer insights into optimal\nstrategies for accelerating LVLMs. We open-source code and recipes for\nEffiVLM-Bench to foster future research.",
    "pdf_url": "http://arxiv.org/pdf/2506.00479v1",
    "published": "2025-05-31T09:10:43+00:00",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00478v1",
    "title": "Dynamic Domain Adaptation-Driven Physics-Informed Graph Representation Learning for AC-OPF",
    "authors": [
      "Hongjie Zhu",
      "Zezheng Zhang",
      "Zeyu Zhang",
      "Yu Bai",
      "Shimin Wen",
      "Huazhang Wang",
      "Daji Ergu",
      "Ying Cai",
      "Yang Zhao"
    ],
    "abstract": "Alternating Current Optimal Power Flow (AC-OPF) aims to optimize generator\npower outputs by utilizing the non-linear relationships between voltage\nmagnitudes and phase angles in a power system. However, current AC-OPF solvers\nstruggle to effectively represent the complex relationship between variable\ndistributions in the constraint space and their corresponding optimal\nsolutions. This limitation in constraint modeling restricts the system's\nability to develop diverse knowledge representations. Additionally, modeling\nthe power grid solely based on spatial topology further limits the integration\nof additional prior knowledge, such as temporal information. To overcome these\nchallenges, we propose DDA-PIGCN (Dynamic Domain Adaptation-Driven\nPhysics-Informed Graph Convolutional Network), a new method designed to address\nconstraint-related issues and build a graph-based learning framework that\nincorporates spatiotemporal features. DDA-PIGCN improves consistency\noptimization for features with varying long-range dependencies by applying\nmulti-layer, hard physics-informed constraints. It also uses a dynamic domain\nadaptation learning mechanism that iteratively updates and refines key state\nvariables under predefined constraints, enabling precise constraint\nverification. Moreover, it captures spatiotemporal dependencies between\ngenerators and loads by leveraging the physical structure of the power grid,\nallowing for deep integration of topological information across time and space.\nExtensive comparative and ablation studies show that DDA-PIGCN delivers strong\nperformance across several IEEE standard test cases (such as case9, case30, and\ncase300), achieving mean absolute errors (MAE) from 0.0011 to 0.0624 and\nconstraint satisfaction rates between 99.6% and 100%, establishing it as a\nreliable and efficient AC-OPF solver.",
    "pdf_url": "http://arxiv.org/pdf/2506.00478v1",
    "published": "2025-05-31T09:07:19+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00477v1",
    "title": "Flashbacks to Harmonize Stability and Plasticity in Continual Learning",
    "authors": [
      "Leila Mahmoodi",
      "Peyman Moghadam",
      "Munawar Hayat",
      "Christian Simon",
      "Mehrtash Harandi"
    ],
    "abstract": "We introduce Flashback Learning (FL), a novel method designed to harmonize\nthe stability and plasticity of models in Continual Learning (CL). Unlike prior\napproaches that primarily focus on regularizing model updates to preserve old\ninformation while learning new concepts, FL explicitly balances this trade-off\nthrough a bidirectional form of regularization. This approach effectively\nguides the model to swiftly incorporate new knowledge while actively retaining\nits old knowledge. FL operates through a two-phase training process and can be\nseamlessly integrated into various CL methods, including replay, parameter\nregularization, distillation, and dynamic architecture techniques. In designing\nFL, we use two distinct knowledge bases: one to enhance plasticity and another\nto improve stability. FL ensures a more balanced model by utilizing both\nknowledge bases to regularize model updates. Theoretically, we analyze how the\nFL mechanism enhances the stability-plasticity balance. Empirically, FL\ndemonstrates tangible improvements over baseline methods within the same\ntraining budget. By integrating FL into at least one representative baseline\nfrom each CL category, we observed an average accuracy improvement of up to\n4.91% in Class-Incremental and 3.51% in Task-Incremental settings on standard\nimage classification benchmarks. Additionally, measurements of the\nstability-to-plasticity ratio confirm that FL effectively enhances this\nbalance. FL also outperforms state-of-the-art CL methods on more challenging\ndatasets like ImageNet.",
    "pdf_url": "http://arxiv.org/pdf/2506.00477v1",
    "published": "2025-05-31T09:04:58+00:00",
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02041v1",
    "title": "Enhancing Multimodal Continual Instruction Tuning with BranchLoRA",
    "authors": [
      "Duzhen Zhang",
      "Yong Ren",
      "Zhong-Zhi Li",
      "Yahan Yu",
      "Jiahua Dong",
      "Chenxing Li",
      "Zhilong Ji",
      "Jinfeng Bai"
    ],
    "abstract": "Multimodal Continual Instruction Tuning (MCIT) aims to finetune Multimodal\nLarge Language Models (MLLMs) to continually align with human intent across\nsequential tasks. Existing approaches often rely on the Mixture-of-Experts\n(MoE) LoRA framework to preserve previous instruction alignments. However,\nthese methods are prone to Catastrophic Forgetting (CF), as they aggregate all\nLoRA blocks via simple summation, which compromises performance over time. In\nthis paper, we identify a critical parameter inefficiency in the MoELoRA\nframework within the MCIT context. Based on this insight, we propose\nBranchLoRA, an asymmetric framework to enhance both efficiency and performance.\nTo mitigate CF, we introduce a flexible tuning-freezing mechanism within\nBranchLoRA, enabling branches to specialize in intra-task knowledge while\nfostering inter-task collaboration. Moreover, we incrementally incorporate\ntask-specific routers to ensure an optimal branch distribution over time,\nrather than favoring the most recent task. To streamline inference, we\nintroduce a task selector that automatically routes test inputs to the\nappropriate router without requiring task identity. Extensive experiments on\nthe latest MCIT benchmark demonstrate that BranchLoRA significantly outperforms\nMoELoRA and maintains its superiority across various MLLM sizes.",
    "pdf_url": "http://arxiv.org/pdf/2506.02041v1",
    "published": "2025-05-31T09:02:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00476v2",
    "title": "Towards Graph-Based Privacy-Preserving Federated Learning: ModelNet -- A ResNet-based Model Classification Dataset",
    "authors": [
      "Abhisek Ray",
      "Lukas Esterle"
    ],
    "abstract": "Federated Learning (FL) has emerged as a powerful paradigm for training\nmachine learning models across distributed data sources while preserving data\nlocality. However, the privacy of local data is always a pivotal concern and\nhas received a lot of attention in recent research on the FL regime. Moreover,\nthe lack of domain heterogeneity and client-specific segregation in the\nbenchmarks remains a critical bottleneck for rigorous evaluation. In this\npaper, we introduce ModelNet, a novel image classification dataset constructed\nfrom the embeddings extracted from a pre-trained ResNet50 model. First, we\nmodify the CIFAR100 dataset into three client-specific variants, considering\nthree domain heterogeneities (homogeneous, heterogeneous, and random).\nSubsequently, we train each client-specific subset of all three variants on the\npre-trained ResNet50 model to save model parameters. In addition to\nmulti-domain image data, we propose a new hypothesis to define the FL algorithm\nthat can access the anonymized model parameters to preserve the local privacy\nin a more effective manner compared to existing ones. ModelNet is designed to\nsimulate realistic FL settings by incorporating non-IID data distributions and\nclient diversity design principles in the mainframe for both conventional and\nfuturistic graph-driven FL algorithms. The three variants are ModelNet-S,\nModelNet-D, and ModelNet-R, which are based on homogeneous, heterogeneous, and\nrandom data settings, respectively. To the best of our knowledge, we are the\nfirst to propose a cross-environment client-specific FL dataset along with the\ngraph-based variant. Extensive experiments based on domain shifts and\naggregation strategies show the effectiveness of the above variants, making it\na practical benchmark for classical and graph-based FL research. The dataset\nand related code are available online.",
    "pdf_url": "http://arxiv.org/pdf/2506.00476v2",
    "published": "2025-05-31T08:53:16+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00475v1",
    "title": "BAGNet: A Boundary-Aware Graph Attention Network for 3D Point Cloud Semantic Segmentation",
    "authors": [
      "Wei Tao",
      "Xiaoyang Qu",
      "Kai Lu",
      "Jiguang Wan",
      "Shenglin He",
      "Jianzong Wang"
    ],
    "abstract": "Since the point cloud data is inherently irregular and unstructured, point\ncloud semantic segmentation has always been a challenging task. The graph-based\nmethod attempts to model the irregular point cloud by representing it as a\ngraph; however, this approach incurs substantial computational cost due to the\nnecessity of constructing a graph for every point within a large-scale point\ncloud. In this paper, we observe that boundary points possess more intricate\nspatial structural information and develop a novel graph attention network\nknown as the Boundary-Aware Graph attention Network (BAGNet). On one hand,\nBAGNet contains a boundary-aware graph attention layer (BAGLayer), which\nemploys edge vertex fusion and attention coefficients to capture features of\nboundary points, reducing the computation time. On the other hand, BAGNet\nemploys a lightweight attention pooling layer to extract the global feature of\nthe point cloud to maintain model accuracy. Extensive experiments on standard\ndatasets demonstrate that BAGNet outperforms state-of-the-art methods in point\ncloud semantic segmentation with higher accuracy and less inference time.",
    "pdf_url": "http://arxiv.org/pdf/2506.00475v1",
    "published": "2025-05-31T08:51:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00474v1",
    "title": "A European Multi-Center Breast Cancer MRI Dataset",
    "authors": [
      "Gustav Müller-Franzes",
      "Lorena Escudero Sánchez",
      "Nicholas Payne",
      "Alexandra Athanasiou",
      "Michael Kalogeropoulos",
      "Aitor Lopez",
      "Alfredo Miguel Soro Busto",
      "Julia Camps Herrero",
      "Nika Rasoolzadeh",
      "Tianyu Zhang",
      "Ritse Mann",
      "Debora Jutz",
      "Maike Bode",
      "Christiane Kuhl",
      "Wouter Veldhuis",
      "Oliver Lester Saldanha",
      "JieFu Zhu",
      "Jakob Nikolas Kather",
      "Daniel Truhn",
      "Fiona J. Gilbert"
    ],
    "abstract": "Detecting breast cancer early is of the utmost importance to effectively\ntreat the millions of women afflicted by breast cancer worldwide every year.\nAlthough mammography is the primary imaging modality for screening breast\ncancer, there is an increasing interest in adding magnetic resonance imaging\n(MRI) to screening programmes, particularly for women at high risk. Recent\nguidelines by the European Society of Breast Imaging (EUSOBI) recommended\nbreast MRI as a supplemental screening tool for women with dense breast tissue.\nHowever, acquiring and reading MRI scans requires significantly more time from\nexpert radiologists. This highlights the need to develop new automated methods\nto detect cancer accurately using MRI and Artificial Intelligence (AI), which\nhave the potential to support radiologists in breast MRI interpretation and\nclassification and help detect cancer earlier. For this reason, the ODELIA\nconsortium has made this multi-centre dataset publicly available to assist in\ndeveloping AI tools for the detection of breast cancer on MRI.",
    "pdf_url": "http://arxiv.org/pdf/2506.00474v1",
    "published": "2025-05-31T08:45:02+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00473v1",
    "title": "Cold pools, Breezes, and Monsoons: Propagating Convection over New Guinea",
    "authors": [
      "Mingyue Tang",
      "Jimy Dudhia",
      "Changhai Liu",
      "Giuseppe Torri"
    ],
    "abstract": "The diurnal cycle of precipitation near New Guinea involves intricate\nland-ocean-atmosphere interactions, posing substantial challenges for tropical\nweather and climate simulations. Using over two decades of GPM satellite\nobservations and convection-permitting WRF simulations, this study examines the\nphysical mechanisms governing the pronounced offshore propagation of diurnal\nconvection over New Guinea. We identify two distinct offshore propagation\nmodes: (1) a \"ridge-to-coast\" mode originated over elevated terrain and\nmigrating toward the coastline, and (2) an \"over-ocean\" mode initiated near the\ncoast, separated by a spatial gap of approximately 100 km. Our findings\nhighlight the critical role of multi-scale density currents in shaping boundary\nlayer dynamics over warm ocean waters. Specifically, the afternoon sea-breeze\nfront advects cooler air onshore, stabilizing the lower atmosphere and\ninterrupting the continuous propagation of the first mode. At night, the land\nbreeze interacts with residual cold pools, generating offshore moist patches\nthat facilitate the convective regeneration and propagation of the second mode.\nThese offshore convective systems interact with monsoonal background winds,\nsustaining precipitation well beyond 200-600 km from the coast. Sensitivity\nexperiments indicate that even a modest increase in sea surface temperature can\nenhance convective intensity and extend offshore propagation. These results\nshed light on the mechanisms that enable diurnal offshore convection to persist\novernight and propagate far from the coastline, highlighting the importance of\nboundary-layer density currents and offering insights for improving\nprecipitation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00473v1",
    "published": "2025-05-31T08:44:27+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00472v1",
    "title": "Disturbance-Aware Adaptive Compensation in Hybrid Force-Position Locomotion Policy for Legged Robots",
    "authors": [
      "Yang Zhang",
      "Buqing Nie",
      "Zhanxiang Cao",
      "Yangqing Fu",
      "Yue Gao"
    ],
    "abstract": "Reinforcement Learning (RL)-based methods have significantly improved the\nlocomotion performance of legged robots. However, these motion policies face\nsignificant challenges when deployed in the real world. Robots operating in\nuncertain environments struggle to adapt to payload variations and external\ndisturbances, resulting in severe degradation of motion performance. In this\nwork, we propose a novel Hybrid Force-Position Locomotion Policy (HFPLP)\nlearning framework, where the action space of the policy is defined as a\ncombination of target joint positions and feedforward torques, enabling the\nrobot to rapidly respond to payload variations and external disturbances. In\naddition, the proposed Disturbance-Aware Adaptive Compensation (DAAC) provides\ncompensation actions in the torque space based on external disturbance\nestimation, enhancing the robot's adaptability to dynamic environmental\nchanges. We validate our approach in both simulation and real-world deployment,\ndemonstrating that it outperforms existing methods in carrying payloads and\nresisting disturbances.",
    "pdf_url": "http://arxiv.org/pdf/2506.00472v1",
    "published": "2025-05-31T08:41:10+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00471v1",
    "title": "DiffPINN: Generative diffusion-initialized physics-informed neural networks for accelerating seismic wavefield representation",
    "authors": [
      "Shijun Cheng",
      "Tariq Alkhalifah"
    ],
    "abstract": "Physics-informed neural networks (PINNs) offer a powerful framework for\nseismic wavefield modeling, yet they typically require time-consuming\nretraining when applied to different velocity models. Moreover, their training\ncan suffer from slow convergence due to the complexity of of the wavefield\nsolution. To address these challenges, we introduce a latent diffusion-based\nstrategy for rapid and effective PINN initialization. First, we train multiple\nPINNs to represent frequency-domain scattered wavefields for various velocity\nmodels, then flatten each trained network's parameters into a one-dimensional\nvector, creating a comprehensive parameter dataset. Next, we employ an\nautoencoder to learn latent representations of these parameter vectors,\ncapturing essential patterns across diverse PINN's parameters. We then train a\nconditional diffusion model to store the distribution of these latent vectors,\nwith the corresponding velocity models serving as conditions. Once trained,\nthis diffusion model can generate latent vectors corresponding to new velocity\nmodels, which are subsequently decoded by the autoencoder into complete PINN\nparameters. Experimental results indicate that our method significantly\naccelerates training and maintains high accuracy across in-distribution and\nout-of-distribution velocity scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.00471v1",
    "published": "2025-05-31T08:41:06+00:00",
    "categories": [
      "physics.geo-ph",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00470v1",
    "title": "Star-Planet Interactions: A Computational View",
    "authors": [
      "A. A. Vidotto"
    ],
    "abstract": "There are several physical processes that mediate the interaction between an\nexoplanet and its host star, with the four main ones being due to magnetic,\nparticle (stellar outflow), radiative and tidal interactions. These\ninteractions can be observed at different wavelengths, from X-ray to radio.\nTheir strengths depend on the architecture of planetary systems, as well as the\nage and activity level of the host stars. In particular, exoplanets in close-in\norbits and/or orbiting active host stars can experience strong physical\ninteractions, some of which are negligible or absent in the present-day Solar\nSystem planets. Here, I present an overview of star-planet interactions through\nthe lens of three-dimensional (3D) numerical models. The main conclusions are:\n  * Models are fundamental to interpret and guide observations. The powerful\ncombination of observations and models allows us to extract important physical\nparameters of the system, such as, planetary magnetic fields, stellar wind\nproperties, etc.\n  * The non-axisymmetric forces of the interactions generate spatially\nasymmetric features (e.g., planetary material trailing the orbit, shock\nformation), thus requiring the use of 3D models.\n  * Star-planet interactions vary in different timescales (from hours to\ngiga-years) that are related to both planetary (orbital motion, rotation) and\nstellar (flares, cycles, and long-term evolution) properties. Understanding\nthese variations require time-dependent models.\n  I advocate that future 3D models should be informed by multi-wavelength,\n(near-)simultaneous observations. The use of observations is twofold: some\ngenerate inputs for models (eg stellar magnetic field maps), whereas others are\nfitted by models (eg spectroscopic transits). This combination of observations\nand models provides a powerful tool to derive physical properties of the system\nthat would otherwise remain unknown.",
    "pdf_url": "http://arxiv.org/pdf/2506.00470v1",
    "published": "2025-05-31T08:39:05+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00469v1",
    "title": "Massively Multilingual Adaptation of Large Language Models Using Bilingual Translation Data",
    "authors": [
      "Shaoxiong Ji",
      "Zihao Li",
      "Jaakko Paavola",
      "Indraneil Paul",
      "Hengyu Luo",
      "Jörg Tiedemann"
    ],
    "abstract": "This paper investigates a critical design decision in the practice of\nmassively multilingual continual pre-training -- the inclusion of parallel\ndata. Specifically, we study the impact of bilingual translation data for\nmassively multilingual language adaptation of the Llama3 family of models to\n500 languages. To this end, we construct the MaLA bilingual translation corpus,\ncontaining data from more than 2,500 language pairs. Subsequently, we develop\nthe EMMA-500 Llama 3 suite of four massively multilingual models -- continually\npre-trained from the Llama 3 family of base models extensively on diverse data\nmixes up to 671B tokens -- and explore the effect of continual pre-training\nwith or without bilingual translation data. Comprehensive evaluation across 7\ntasks and 12 benchmarks demonstrates that bilingual data tends to enhance\nlanguage transfer and performance, particularly for low-resource languages. We\nopen-source the MaLA corpus, EMMA-500 Llama 3 suite artefacts, code, and model\ngenerations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00469v1",
    "published": "2025-05-31T08:37:17+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00468v1",
    "title": "Regionalized Metric Framework: A Novel Approach for Evaluating Multimodal Multi-Objective Optimization Algorithms",
    "authors": [
      "Jintai Chen",
      "Fangqing Liu",
      "Xueming Yan",
      "Han Huang"
    ],
    "abstract": "This study aims to optimize the evaluation metric of multimodal\nmulti-objective optimization problems using a Regionalized Metric Framework,\nwhich provides a certain boost to research in this field. Existing evaluation\nmetrics usually use the reference set as the evaluation basis, which inevitably\nleads to reference set dependence. To optimize this problem, this study\nproposes an evaluation metric based on a Regionalized Metric Framework. The\nalgorithm divides the set of solutions to be evaluated into three regions, and\nevaluates each solution according to a unique scoring function for each region,\nwhich is combined to form the evaluation value of the solution set. To verify\nthe feasibility of this method, a comparative experiment was conducted in this\nstudy. The results of the experiment are roughly the same as the trend of\nexisting indicators, and at the same time, it can accurately judge the\nadvantages and disadvantages of points equidistant from the reference set. Our\nmethod provides a new perspective for further research on evaluation metrics\nfor multimodal multi-objective optimization algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2506.00468v1",
    "published": "2025-05-31T08:36:55+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00467v1",
    "title": "SST: Self-training with Self-adaptive Thresholding for Semi-supervised Learning",
    "authors": [
      "Shuai Zhao",
      "Heyan Huang",
      "Xinge Li",
      "Xiaokang Chen",
      "Rui Wang"
    ],
    "abstract": "Neural networks have demonstrated exceptional performance in supervised\nlearning, benefiting from abundant high-quality annotated data. However,\nobtaining such data in real-world scenarios is costly and labor-intensive.\nSemi-supervised learning (SSL) offers a solution to this problem. Recent\nstudies, such as Semi-ViT and Noisy Student, which employ consistency\nregularization or pseudo-labeling, have demonstrated significant achievements.\nHowever, they still face challenges, particularly in accurately selecting\nsufficient high-quality pseudo-labels due to their reliance on fixed\nthresholds. Recent methods such as FlexMatch and FreeMatch have introduced\nflexible or self-adaptive thresholding techniques, greatly advancing SSL\nresearch. Nonetheless, their process of updating thresholds at each iteration\nis deemed time-consuming, computationally intensive, and potentially\nunnecessary. To address these issues, we propose Self-training with\nSelf-adaptive Thresholding (SST), a novel, effective, and efficient SSL\nframework. SST introduces an innovative Self-Adaptive Thresholding (SAT)\nmechanism that adaptively adjusts class-specific thresholds based on the\nmodel's learning progress. SAT ensures the selection of high-quality\npseudo-labeled data, mitigating the risks of inaccurate pseudo-labels and\nconfirmation bias. Extensive experiments demonstrate that SST achieves\nstate-of-the-art performance with remarkable efficiency, generalization, and\nscalability across various architectures and datasets. Semi-SST-ViT-Huge\nachieves the best results on competitive ImageNet-1K SSL benchmarks, with 80.7%\n/ 84.9% Top-1 accuracy using only 1% / 10% labeled data. Compared to the\nfully-supervised DeiT-III-ViT-Huge, which achieves 84.8% Top-1 accuracy using\n100% labeled data, our method demonstrates superior performance using only 10%\nlabeled data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00467v1",
    "published": "2025-05-31T08:34:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00466v1",
    "title": "M3ANet: Multi-scale and Multi-Modal Alignment Network for Brain-Assisted Target Speaker Extraction",
    "authors": [
      "Cunhang Fan",
      "Ying Chen",
      "Jian Zhou",
      "Zexu Pan",
      "Jingjing Zhang",
      "Youdian Gao",
      "Xiaoke Yang",
      "Zhengqi Wen",
      "Zhao Lv"
    ],
    "abstract": "The brain-assisted target speaker extraction (TSE) aims to extract the\nattended speech from mixed speech by utilizing the brain neural activities, for\nexample Electroencephalography (EEG). However, existing models overlook the\nissue of temporal misalignment between speech and EEG modalities, which hampers\nTSE performance. In addition, the speech encoder in current models typically\nuses basic temporal operations (e.g., one-dimensional convolution), which are\nunable to effectively extract target speaker information. To address these\nissues, this paper proposes a multi-scale and multi-modal alignment network\n(M3ANet) for brain-assisted TSE. Specifically, to eliminate the temporal\ninconsistency between EEG and speech modalities, the modal alignment module\nthat uses a contrastive learning strategy is applied to align the temporal\nfeatures of both modalities. Additionally, to fully extract speech information,\nmulti-scale convolutions with GroupMamba modules are used as the speech\nencoder, which scans speech features at each scale from different directions,\nenabling the model to capture deep sequence information. Experimental results\non three publicly available datasets show that the proposed model outperforms\ncurrent state-of-the-art methods across various evaluation metrics,\nhighlighting the effectiveness of our proposed method. The source code is\navailable at: https://github.com/fchest/M3ANet.",
    "pdf_url": "http://arxiv.org/pdf/2506.00466v1",
    "published": "2025-05-31T08:33:57+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00465v1",
    "title": "On the natural domain of Bregman operators",
    "authors": [
      "Andreas Themelis",
      "Ziyuan Wang"
    ],
    "abstract": "The Bregman proximal mapping and Bregman-Moreau envelope are traditionally\nstudied for functions defined on the entire space $\\mathbb{R}^n$, even though\nthese constructions depend only on the values of the function within (the\ninterior of) the domain of the distance-generating function (dgf). While this\nconvention is largely harmless in the convex setting, it leads to substantial\nlimitations in the nonconvex case, as it fails to embrace important classes of\nfunctions such as relatively weakly convex ones. In this work, we revisit\nfoundational aspects of Bregman analysis by adopting a domain-aware\nperspective: we define functions on the natural domain induced by the dgf and\nimpose properties only relative to this set. This framework not only\ngeneralizes existing results but also rectifies and simplifies their statements\nand proofs. Several examples illustrate both the necessity of our assumptions\nand the advantages of this refined approach.",
    "pdf_url": "http://arxiv.org/pdf/2506.00465v1",
    "published": "2025-05-31T08:31:31+00:00",
    "categories": [
      "math.OC",
      "49J52, 49J53, 49M27, 47H04, 26B25"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00464v1",
    "title": "Design and Validation of the Digital Receiver System for the next-generation radio interferometer",
    "authors": [
      "Donghao Qu",
      "Jiajun Zhang",
      "Yajun Wu",
      "Zhang Zhao",
      "Yanbin Yang",
      "Zixuan Liu"
    ],
    "abstract": "This paper presents the design and validation of a digital receiver system\ndeveloped for the next-generation radio interferometer projects. The receiver\nsupports 8 analog inputs with 12-bit, 4GHz sampling and performs real-time\nsignal processing using FPGA-based channelization. Field experiments were\nconducted to observe the Sun, a satellite beacon, and Cassiopeia A.\nInterference fringes were analyzed and modeled. Time delay compensation was\nimplemented in two ways: theoretical calculation and Gaussian Process\nRegression (GPR) fitting. Results show sub-nanosecond consistency between the\ntwo methods. The field experiments demonstrate the receiver's suitability for\nfuture radio telescopes such as the BINGO-ABDUS project.",
    "pdf_url": "http://arxiv.org/pdf/2506.00464v1",
    "published": "2025-05-31T08:30:50+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00463v1",
    "title": "Deterministic Kalman filters for uncertain dynamical systems",
    "authors": [
      "Karl Kunisch",
      "Jesper Schröder"
    ],
    "abstract": "The Kalman(-Bucy) filter is the natural choice for the state reconstruction\nof disturbed, linear dynamical systems based on flawed and incomplete\nmeasurements. Taking a deterministic viewpoint this work investigates possible\nextensions of the concept to systems with uncertain dynamics and noise\ncovariances. In a theoretical analysis error bounds in terms of the variance of\nthe uncertainties are derived. The article concludes with a numerical\nimplementation of two example systems allowing for a comparison of the\nestimators.",
    "pdf_url": "http://arxiv.org/pdf/2506.00463v1",
    "published": "2025-05-31T08:29:42+00:00",
    "categories": [
      "math.DS",
      "math.OC",
      "math.PR"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.06333v2",
    "title": "Extending AALpy with Passive Learning: A Generalized State-Merging Approach",
    "authors": [
      "Benjamin von Berg",
      "Bernhard K. Aichernig"
    ],
    "abstract": "AALpy is a well-established open-source automata learning library written in\nPython with a focus on active learning of systems with IO behavior. It provides\na wide range of state-of-the-art algorithms for different automaton types\nranging from fully deterministic to probabilistic automata. In this work, we\npresent the recent addition of a generalized implementation of an important\nmethod from the domain of passive automata learning: state-merging in the\nred-blue framework. Using a common internal representation for different\nautomaton types allows for a general and highly configurable implementation of\nthe red-blue framework. We describe how to define and execute state-merging\nalgorithms using AALpy, which reduces the implementation effort for\nstate-merging algorithms mainly to the definition of compatibility criteria and\nscoring. This aids the implementation of both existing and novel algorithms. In\nparticular, defining some existing state-merging algorithms from the literature\nwith AALpy only takes a few lines of code.",
    "pdf_url": "http://arxiv.org/pdf/2506.06333v2",
    "published": "2025-05-31T08:29:32+00:00",
    "categories": [
      "cs.LG",
      "cs.FL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00462v1",
    "title": "XMAD-Bench: Cross-Domain Multilingual Audio Deepfake Benchmark",
    "authors": [
      "Ioan-Paul Ciobanu",
      "Andrei-Iulian Hiji",
      "Nicolae-Catalin Ristea",
      "Paul Irofti",
      "Cristian Rusu",
      "Radu Tudor Ionescu"
    ],
    "abstract": "Recent advances in audio generation led to an increasing number of deepfakes,\nmaking the general public more vulnerable to financial scams, identity theft,\nand misinformation. Audio deepfake detectors promise to alleviate this issue,\nwith many recent studies reporting accuracy rates close to 99%. However, these\nmethods are typically tested in an in-domain setup, where the deepfake samples\nfrom the training and test sets are produced by the same generative models. To\nthis end, we introduce XMAD-Bench, a large-scale cross-domain multilingual\naudio deepfake benchmark comprising 668.8 hours of real and deepfake speech. In\nour novel dataset, the speakers, the generative methods, and the real audio\nsources are distinct across training and test splits. This leads to a\nchallenging cross-domain evaluation setup, where audio deepfake detectors can\nbe tested ``in the wild''. Our in-domain and cross-domain experiments indicate\na clear disparity between the in-domain performance of deepfake detectors,\nwhich is usually as high as 100%, and the cross-domain performance of the same\nmodels, which is sometimes similar to random chance. Our benchmark highlights\nthe need for the development of robust audio deepfake detectors, which maintain\ntheir generalization capacity across different languages, speakers, generative\nmethods, and data sources. Our benchmark is publicly released at\nhttps://github.com/ristea/xmad-bench/.",
    "pdf_url": "http://arxiv.org/pdf/2506.00462v1",
    "published": "2025-05-31T08:28:36+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.00461v1",
    "title": "Bridging the Gap between Hardware Fuzzing and Industrial Verification",
    "authors": [
      "Ruiyang Ma",
      "Tianhao Wei",
      "Jiaxi Zhang",
      "Chun Yang",
      "Jiangfang Yi",
      "Guojie Luo"
    ],
    "abstract": "As hardware design complexity increases, hardware fuzzing emerges as a\npromising tool for automating the verification process. However, a significant\ngap still exists before it can be applied in industry. This paper aims to\nsummarize the current progress of hardware fuzzing from an industry-use\nperspective and propose solutions to bridge the gap between hardware fuzzing\nand industrial verification. First, we review recent hardware fuzzing methods\nand analyze their compatibilities with industrial verification. We establish\ncriteria to assess whether a hardware fuzzing approach is compatible. Second,\nwe examine whether current verification tools can efficiently support hardware\nfuzzing. We identify the bottlenecks in hardware fuzzing performance caused by\ninsufficient support from the industrial environment. To overcome the\nbottlenecks, we propose a prototype, HwFuzzEnv, providing the necessary support\nfor hardware fuzzing. With this prototype, the previous hardware fuzzing method\ncan achieve a several hundred times speedup in industrial settings. Our work\ncould serve as a reference for EDA companies, encouraging them to enhance their\ntools to support hardware fuzzing efficiently in industrial verification.",
    "pdf_url": "http://arxiv.org/pdf/2506.00461v1",
    "published": "2025-05-31T08:26:19+00:00",
    "categories": [
      "cs.CR",
      "cs.AR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00460v1",
    "title": "Mocking IFU observations and metallicity diagnostics from cosmological simulations",
    "authors": [
      "A. Cornejo-Cárdenas",
      "E. Sillero",
      "P. B. Tissera",
      "M. Boquien",
      "J. Vilchez",
      "G. Bruzual",
      "P. Jofré"
    ],
    "abstract": "Hydrodynamic simulations are powerful tools for studying galaxy formation.\nHowever, it is crucial to test and improve the sub-grid physics underlying\nthese simulations by comparing their predictions with observations. To this\naim, observable quantities can be derived for simulated galaxies, enabling the\nanalysis of simulated properties through an observational approach. Our goal is\nto develop a new numerical tool capable of generating synthetic emission line\nspectra from spatially resolved regions in simulated galaxies, mocking Integral\nField Unit (IFU) observations. Synthetic spectra of simulated galaxies are\nproduced by integrating the software CIGALE with the outcomes of hydrodynamical\nsimulations. We consider contributions of both stellar populations and nebular\nemission. The nebular emission lines in the spectra are modeled by considering\nonly the contributions from the simulated star-forming regions. Our model\nconsiders the properties of the surrounding interstellar medium to estimate the\nionizing parameters, the metallicity, the velocity dispersion and the electron\ndensity. We present the new numerical tool PRISMA. Leveraging synthetic spectra\ngenerated by our model, PRISMA successfully computed and recovered the\nintrinsic values of the star formation rate and gas-phase metallicity in local\nregions of simulated galaxies. Additionally, we examine the behavior of\nmetallicity tracers such as N2, R23, O3N2, N2O2, recovered by PRISMA and\npropose new calibrations based on our simulated result. These findings show the\nrobustness of our tool in recovering the intrinsic properties of simulated\ngalaxies through their synthetic spectra, thereby becoming a powerful tool to\nconfront simulations and observational data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00460v1",
    "published": "2025-05-31T08:25:30+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00459v1",
    "title": "Comparing Traditional and Reinforcement-Learning Methods for Energy Storage Control",
    "authors": [
      "Elinor Ginzburg",
      "Itay Segev",
      "Yoash Levron",
      "Sarah Keren"
    ],
    "abstract": "We aim to better understand the tradeoffs between traditional and\nreinforcement learning (RL) approaches for energy storage management. More\nspecifically, we wish to better understand the performance loss incurred when\nusing a generative RL policy instead of using a traditional approach to find\noptimal control policies for specific instances. Our comparison is based on a\nsimplified micro-grid model, that includes a load component, a photovoltaic\nsource, and a storage device. Based on this model, we examine three use cases\nof increasing complexity: ideal storage with convex cost functions, lossy\nstorage devices, and lossy storage devices with convex transmission losses.\nWith the aim of promoting the principled use RL based methods in this\nchallenging and important domain, we provide a detailed formulation of each use\ncase and a detailed description of the optimization challenges. We then compare\nthe performance of traditional and RL methods, discuss settings in which it is\nbeneficial to use each method, and suggest avenues for future investigation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00459v1",
    "published": "2025-05-31T08:25:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00458v1",
    "title": "Reinforcement Learning for Hanabi",
    "authors": [
      "Nina Cohen",
      "Kordel K. France"
    ],
    "abstract": "Hanabi has become a popular game for research when it comes to reinforcement\nlearning (RL) as it is one of the few cooperative card games where you have\nincomplete knowledge of the entire environment, thus presenting a challenge for\na RL agent. We explored different tabular and deep reinforcement learning\nalgorithms to see which had the best performance both against an agent of the\nsame type and also against other types of agents. We establish that certain\nagents played their highest scoring games against specific agents while others\nexhibited higher scores on average by adapting to the opposing agent's\nbehavior. We attempted to quantify the conditions under which each algorithm\nprovides the best advantage and identified the most interesting interactions\nbetween agents of different types. In the end, we found that temporal\ndifference (TD) algorithms had better overall performance and balancing of play\ntypes compared to tabular agents. Specifically, tabular Expected SARSA and deep\nQ-Learning agents showed the best performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.00458v1",
    "published": "2025-05-31T08:24:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00457v1",
    "title": "Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models",
    "authors": [
      "Junwoo Park",
      "Hyuck Lee",
      "Dohyun Lee",
      "Daehoon Gwak",
      "Jaegul Choo"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable performance across diverse\ntasks without domain-specific training, fueling interest in their potential for\ntime-series forecasting. While LLMs have shown potential in zero-shot\nforecasting through prompting alone, recent studies suggest that LLMs lack\ninherent effectiveness in forecasting. Given these conflicting findings, a\nrigorous validation is essential for drawing reliable conclusions. In this\npaper, we evaluate the effectiveness of LLMs as zero-shot forecasters compared\nto state-of-the-art domain-specific models. Our experiments show that LLM-based\nzero-shot forecasters often struggle to achieve high accuracy due to their\nsensitivity to noise, underperforming even simple domain-specific models. We\nhave explored solutions to reduce LLMs' sensitivity to noise in the zero-shot\nsetting, but improving their robustness remains a significant challenge. Our\nfindings suggest that rather than emphasizing zero-shot forecasting, a more\npromising direction would be to focus on fine-tuning LLMs to better process\nnumerical sequences. Our experimental code is available at\nhttps://github.com/junwoopark92/revisiting-LLMs-zeroshot-forecaster.",
    "pdf_url": "http://arxiv.org/pdf/2506.00457v1",
    "published": "2025-05-31T08:24:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00456v1",
    "title": "Overgroups of the arboreal representation of PCF polynomial",
    "authors": [
      "Wayne Peng"
    ],
    "abstract": "Consider a number field $K$ and a rational function $f$ of degree greater\nthan 1 over $K$. By taking preimages of $\\alpha\\in K$ under successive iterates\nof $f$, an infinite $d$-ary tree $T_\\infty$ rooted at $\\alpha$ can be\nconstructed. An edge is assigned between two preimages $x$ and $y$ if $f(x)=y$.\nThe absolute Galois group of $K$, acting on $T_\\infty$ through tree\nautomorphisms, generates a subgroup $\\text{Gal}_f^\\infty(\\alpha)$ in the group\nof all automorphisms of $T_\\infty$, $\\text{Aut}(T_\\infty)$.\n  We have discovered a new class of natural overgroups in which the image of\nthe Galois representation attached to a PCF polynomial must reside. Moreover,\nwe have found that the image of the Galois representation of a new PCF\npolynomial is isomorphic to one of these overgroups. We also investigate the\nstructure of these overgroups for specific maps, such as normalized dynamical\nBelyi polynomials, and show that the normal subgroups of these overgroups form\na unique chief series. This allows us to bound the number of generators through\ngroup-theoretic analysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.00456v1",
    "published": "2025-05-31T08:22:44+00:00",
    "categories": [
      "math.NT",
      "math.DS"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00455v3",
    "title": "Diffusion Graph Neural Networks for Robustness in Olfaction Sensors and Datasets",
    "authors": [
      "Kordel K. France",
      "Ovidiu Daescu"
    ],
    "abstract": "Robotic odour source localization (OSL) is a critical capability for\nautonomous systems operating in complex environments. However, current OSL\nmethods often suffer from ambiguities, particularly when robots misattribute\nodours to incorrect objects due to limitations in olfactory datasets and sensor\nresolutions. To address this challenge, we introduce a novel machine learning\nmethod using diffusion-based molecular generation to enhance odour localization\naccuracy that can be used by itself or with automated olfactory dataset\nconstruction pipelines. This generative process of our diffusion model expands\nthe chemical space beyond the limitations of both current olfactory datasets\nand training methods, enabling the identification of potential odourant\nmolecules not previously documented. The generated molecules can then be more\naccurately validated using advanced olfactory sensors, enabling them to detect\nmore compounds and inform better hardware design. By integrating visual\nanalysis, language processing, and molecular generation, our framework enhances\nthe ability of olfaction-vision models on robots to accurately associate odours\nwith their correct sources, thereby improving navigation and decision-making\nthrough better sensor selection for a target compound in critical applications\nsuch as explosives detection, narcotics screening, and search and rescue. Our\nmethodology represents a foundational advancement in the field of artificial\nolfaction, offering a scalable solution to challenges posed by limited\nolfactory data and sensor ambiguities. Code and data are made available to the\ncommunity at the following URL:\nhttps://github.com/KordelFranceTech/OlfactionVisionLanguage-Dataset.",
    "pdf_url": "http://arxiv.org/pdf/2506.00455v3",
    "published": "2025-05-31T08:22:09+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.11064v1",
    "title": "PMF-CEC: Phoneme-augmented Multimodal Fusion for Context-aware ASR Error Correction with Error-specific Selective Decoding",
    "authors": [
      "Jiajun He",
      "Tomoki Toda"
    ],
    "abstract": "End-to-end automatic speech recognition (ASR) models often struggle to\naccurately recognize rare words. Previously, we introduced an ASR\npostprocessing method called error detection and context-aware error correction\n(ED-CEC), which leverages contextual information such as named entities and\ntechnical terms to improve the accuracy of ASR transcripts. Although ED-CEC\nachieves a notable success in correcting rare words, its accuracy remains low\nwhen dealing with rare words that have similar pronunciations but different\nspellings. To address this issue, we proposed a phoneme-augmented multimodal\nfusion method for context-aware error correction (PMF-CEC) method on the basis\nof ED-CEC, which allowed for better differentiation between target rare words\nand homophones. Additionally, we observed that the previous ASR error detection\nmodule suffers from overdetection. To mitigate this, we introduced a retention\nprobability mechanism to filter out editing operations with confidence scores\nbelow a set threshold, preserving the original operation to improve error\ndetection accuracy. Experiments conducted on five datasets demonstrated that\nour proposed PMF-CEC maintains reasonable inference speed while further\nreducing the biased word error rate compared with ED-CEC, showing a stronger\nadvantage in correcting homophones. Moreover, our method outperforms other\ncontextual biasing methods, and remains valuable compared with LLM-based\nmethods in terms of faster inference and better robustness under large biasing\nlists.",
    "pdf_url": "http://arxiv.org/pdf/2506.11064v1",
    "published": "2025-05-31T08:18:34+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00454v1",
    "title": "Towards Temporally Explainable Dysarthric Speech Clarity Assessment",
    "authors": [
      "Seohyun Park",
      "Chitralekha Gupta",
      "Michelle Kah Yian Kwan",
      "Xinhui Fung",
      "Alexander Wenjun Yip",
      "Suranga Nanayakkara"
    ],
    "abstract": "Dysarthria, a motor speech disorder, affects intelligibility and requires\ntargeted interventions for effective communication. In this work, we\ninvestigate automated mispronunciation feedback by collecting a dysarthric\nspeech dataset from six speakers reading two passages, annotated by a speech\ntherapist with temporal markers and mispronunciation descriptions. We design a\nthree-stage framework for explainable mispronunciation evaluation: (1) overall\nclarity scoring, (2) mispronunciation localization, and (3) mispronunciation\ntype classification. We systematically analyze pretrained Automatic Speech\nRecognition (ASR) models in each stage, assessing their effectiveness in\ndysarthric speech evaluation (Code available at:\nhttps://github.com/augmented-human-lab/interspeech25_speechtherapy,\nSupplementary webpage: https://apps.ahlab.org/interspeech25_speechtherapy/).\nOur findings offer clinically relevant insights for automating actionable\nfeedback for pronunciation assessment, which could enable independent practice\nfor patients and help therapists deliver more effective interventions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00454v1",
    "published": "2025-05-31T08:16:54+00:00",
    "categories": [
      "eess.AS",
      "cs.HC",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00453v1",
    "title": "TMetaNet: Topological Meta-Learning Framework for Dynamic Link Prediction",
    "authors": [
      "Hao Li",
      "Hao Wan",
      "Yuzhou Chen",
      "Dongsheng Ye",
      "Yulia Gel",
      "Hao Jiang"
    ],
    "abstract": "Dynamic graphs evolve continuously, presenting challenges for traditional\ngraph learning due to their changing structures and temporal dependencies.\nRecent advancements have shown potential in addressing these challenges by\ndeveloping suitable meta-learning-based dynamic graph neural network models.\nHowever, most meta-learning approaches for dynamic graphs rely on fixed weight\nupdate parameters, neglecting the essential intrinsic complex high-order\ntopological information of dynamically evolving graphs. We have designed Dowker\nZigzag Persistence (DZP), an efficient and stable dynamic graph persistent\nhomology representation method based on Dowker complex and zigzag persistence,\nto capture the high-order features of dynamic graphs. Armed with the DZP ideas,\nwe propose TMetaNet, a new meta-learning parameter update model based on\ndynamic topological features. By utilizing the distances between high-order\ntopological features, TMetaNet enables more effective adaptation across\nsnapshots. Experiments on real-world datasets demonstrate TMetaNet's\nstate-of-the-art performance and resilience to graph noise, illustrating its\nhigh potential for meta-learning and dynamic graph analysis. Our code is\navailable at https://github.com/Lihaogx/TMetaNet.",
    "pdf_url": "http://arxiv.org/pdf/2506.00453v1",
    "published": "2025-05-31T08:15:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00452v1",
    "title": "Attention-Aided MMSE for OFDM Channel Estimation: Learning Linear Filters with Attention",
    "authors": [
      "TaeJun Ha",
      "Chaehyun Jung",
      "Hyeonuk Kim",
      "Jeongwoo Park",
      "Jeonghun Park"
    ],
    "abstract": "In orthogonal frequency division multiplexing (OFDM), accurate channel\nestimation is crucial. Classical signal processing based approaches, such as\nminimum mean-squared error (MMSE) estimation, often require second-order\nstatistics that are difficult to obtain in practice. Recent deep neural\nnetworks based methods have been introduced to address this; yet they often\nsuffer from high complexity. This paper proposes an Attention-aided MMSE\n(A-MMSE), a novel model-based DNN framework that learns the optimal MMSE filter\nvia the Attention Transformer. Once trained, the A-MMSE estimates the channel\nthrough a single linear operation for channel estimation, eliminating nonlinear\nactivations during inference and thus reducing computational complexity. To\nenhance the learning efficiency of the A-MMSE, we develop a two-stage Attention\nencoder, designed to effectively capture the channel correlation structure.\nAdditionally, a rank-adaptive extension of the proposed A-MMSE allows flexible\ntrade-offs between complexity and channel estimation accuracy. Extensive\nsimulations with 3GPP TDL channel models demonstrate that the proposed A-MMSE\nconsistently outperforms other baseline methods in terms of normalized MSE\nacross a wide range of SNR conditions. In particular, the A-MMSE and its\nrank-adaptive extension establish a new frontier in the performance complexity\ntrade-off, redefining the standard for practical channel estimation methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00452v1",
    "published": "2025-05-31T08:12:04+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00451v1",
    "title": "A Formula for Connected Bosonic \\(n\\)-Point Functions for the BKP Hierarchy",
    "authors": [
      "Xuhui Zhang",
      "Jian Zhou"
    ],
    "abstract": "We present a formula for the connected \\(n\\)-point functions of a tau-funtion\nof the BKP hierarchy by embedding BKP hierarchy into KP hierarchy. This formula\nis different from the one given by Wang and Yang. We prove that these two\nformulae are equivalent.",
    "pdf_url": "http://arxiv.org/pdf/2506.00451v1",
    "published": "2025-05-31T08:10:19+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.15713v1",
    "title": "An application of machine learning to the motion response prediction of floating assets",
    "authors": [
      "Michael T. M. B. Morris-Thomas",
      "Marius Martens"
    ],
    "abstract": "The real-time prediction of floating offshore asset behavior under stochastic\nmetocean conditions remains a significant challenge in offshore engineering.\nWhile traditional empirical and frequency-domain methods work well in benign\nconditions, they struggle with both extreme sea states and nonlinear responses.\nThis study presents a supervised machine learning approach using multivariate\nregression to predict the nonlinear motion response of a turret-moored vessel\nin 400 m water depth. We developed a machine learning workflow combining a\ngradient-boosted ensemble method with a custom passive weathervaning solver,\ntrained on approximately $10^6$ samples spanning 100 features. The model\nachieved mean prediction errors of less than 5% for critical mooring parameters\nand vessel heading accuracy to within 2.5 degrees across diverse metocean\nconditions, significantly outperforming traditional frequency-domain methods.\nThe framework has been successfully deployed on an operational facility,\ndemonstrating its efficacy for real-time vessel monitoring and operational\ndecision-making in offshore environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.15713v1",
    "published": "2025-05-31T08:10:12+00:00",
    "categories": [
      "cs.LG",
      "physics.data-an",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00450v1",
    "title": "DV365: Extremely Long User History Modeling at Instagram",
    "authors": [
      "Wenhan Lyu",
      "Devashish Tyagi",
      "Yihang Yang",
      "Ziwei Li",
      "Ajay Somani",
      "Karthikeyan Shanmugasundaram",
      "Nikola Andrejevic",
      "Ferdi Adeputra",
      "Curtis Zeng",
      "Arun K. Singh",
      "Maxime Ransan",
      "Sagar Jain"
    ],
    "abstract": "Long user history is highly valuable signal for recommendation systems, but\neffectively incorporating it often comes with high cost in terms of data center\npower consumption and GPU. In this work, we chose offline embedding over\nend-to-end sequence length optimization methods to enable extremely long user\nsequence modeling as a cost-effective solution, and propose a new user\nembedding learning strategy, multi-slicing and summarization, that generates\nhighly generalizable user representation of user's long-term stable interest.\nHistory length we encoded in this embedding is up to 70,000 and on average\n40,000. This embedding, named as DV365, is proven highly incremental on top of\nadvanced attentive user sequence models deployed in Instagram. Produced by a\nsingle upstream foundational model, it is launched in 15 different models\nacross Instagram and Threads with significant impact, and has been production\nbattle-proven for >1 year since our first launch.",
    "pdf_url": "http://arxiv.org/pdf/2506.00450v1",
    "published": "2025-05-31T08:09:54+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00449v1",
    "title": "Resonant interlayer coupling in NbSe$_2$-graphite epitaxial moir{é} superlattices",
    "authors": [
      "S. Mo",
      "K. Kovalenka",
      "S. Buchberger",
      "B. K. Saika",
      "A. Azhar",
      "A. Rajan",
      "A. Zivanovic",
      "Y. -C. Yao",
      "R. V. Belosludov",
      "M. D. Watson",
      "M. S. Bahramy",
      "P. D. C. King"
    ],
    "abstract": "Moir{\\'e} heterostructures, created by stacking two-dimensional (2D)\nmaterials together with a finite lattice mismatch or rotational twist,\nrepresent a new frontier of designer quantum materials. Typically, however,\nthis requires the painstaking manual assembly of heterostructures formed from\nexfoliated materials. Here, we observe clear spectroscopic signatures of\nmoir{\\'e} lattice formation in epitaxial heterostructures of monolayer (ML)\nNbSe$_2$ grown on graphite substrates. Our angle-resolved photoemission\nmeasurements and theoretical calculations of the resulting electronic structure\nreveal moir{\\'e} replicas of the graphite $\\pi$ states forming pairs of\ninterlocking Dirac cones. Interestingly, these intersect the NbSe$_2$ Fermi\nsurface at the $\\mathbf{k}$-space locations where NbSe$_2$'s charge-density\nwave (CDW) gap is maximal in the bulk. This provides a natural route to\nunderstand the lack of CDW enhancement for ML-NbSe$_2$/graphene as compared to\na more than four-fold enhancement for NbSe$_2$ on insulating support\nsubstrates, and opens new prospects for using moir{\\'e} engineering for\ncontrolling the collective states of 2D materials.",
    "pdf_url": "http://arxiv.org/pdf/2506.00449v1",
    "published": "2025-05-31T08:09:40+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall",
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00448v1",
    "title": "Fact-Controlled Diagnosis of Hallucinations in Medical Text Summarization",
    "authors": [
      "Suhas BN",
      "Han-Chin Shing",
      "Lei Xu",
      "Mitch Strong",
      "Jon Burnsky",
      "Jessica Ofor",
      "Jordan R. Mason",
      "Susan Chen",
      "Sundararajan Srinivasan",
      "Chaitanya Shivade",
      "Jack Moriarty",
      "Joseph Paul Cohen"
    ],
    "abstract": "Hallucinations in large language models (LLMs) during summarization of\npatient-clinician dialogues pose significant risks to patient care and clinical\ndecision-making. However, the phenomenon remains understudied in the clinical\ndomain, with uncertainty surrounding the applicability of general-domain\nhallucination detectors. The rarity and randomness of hallucinations further\ncomplicate their investigation. In this paper, we conduct an evaluation of\nhallucination detection methods in the medical domain, and construct two\ndatasets for the purpose: A fact-controlled Leave-N-out dataset -- generated by\nsystematically removing facts from source dialogues to induce hallucinated\ncontent in summaries; and a natural hallucination dataset -- arising\norganically during LLM-based medical summarization. We show that general-domain\ndetectors struggle to detect clinical hallucinations, and that performance on\nfact-controlled hallucinations does not reliably predict effectiveness on\nnatural hallucinations. We then develop fact-based approaches that count\nhallucinations, offering explainability not available with existing methods.\nNotably, our LLM-based detectors, which we developed using fact-controlled\nhallucinations, generalize well to detecting real-world clinical\nhallucinations. This research contributes a suite of specialized metrics\nsupported by expert-annotated datasets to advance faithful clinical\nsummarization systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00448v1",
    "published": "2025-05-31T08:04:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00447v1",
    "title": "Performance Analysis of Few-Shot Learning Approaches for Bangla Handwritten Character and Digit Recognition",
    "authors": [
      "Mehedi Ahamed",
      "Radib Bin Kabir",
      "Tawsif Tashwar Dipto",
      "Mueeze Al Mushabbir",
      "Sabbir Ahmed",
      "Md. Hasanul Kabir"
    ],
    "abstract": "This study investigates the performance of few-shot learning (FSL) approaches\nin recognizing Bangla handwritten characters and numerals using limited labeled\ndata. It demonstrates the applicability of these methods to scripts with\nintricate and complex structures, where dataset scarcity is a common challenge.\nGiven the complexity of Bangla script, we hypothesize that models performing\nwell on these characters can generalize effectively to languages of similar or\nlower structural complexity. To this end, we introduce SynergiProtoNet, a\nhybrid network designed to improve the recognition accuracy of handwritten\ncharacters and digits. The model integrates advanced clustering techniques with\na robust embedding framework to capture fine-grained details and contextual\nnuances. It leverages multi-level (both high- and low-level) feature extraction\nwithin a prototypical learning framework. We rigorously benchmark\nSynergiProtoNet against several state-of-the-art few-shot learning models:\nBD-CSPN, Prototypical Network, Relation Network, Matching Network, and\nSimpleShot, across diverse evaluation settings including Monolingual\nIntra-Dataset Evaluation, Monolingual Inter-Dataset Evaluation, Cross-Lingual\nTransfer, and Split Digit Testing. Experimental results show that\nSynergiProtoNet consistently outperforms existing methods, establishing a new\nbenchmark in few-shot learning for handwritten character and digit recognition.\nThe code is available on GitHub:\nhttps://github.com/MehediAhamed/SynergiProtoNet.",
    "pdf_url": "http://arxiv.org/pdf/2506.00447v1",
    "published": "2025-05-31T08:03:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02040v3",
    "title": "Beyond the Protocol: Unveiling Attack Vectors in the Model Context Protocol (MCP) Ecosystem",
    "authors": [
      "Hao Song",
      "Yiming Shen",
      "Wenxuan Luo",
      "Leixin Guo",
      "Ting Chen",
      "Jiashui Wang",
      "Beibei Li",
      "Xiaosong Zhang",
      "Jiachi Chen"
    ],
    "abstract": "The Model Context Protocol (MCP) is an emerging standard designed to enable\nseamless interaction between Large Language Model (LLM) applications and\nexternal tools or resources. Within a short period, thousands of MCP services\nhave already been developed and deployed. However, the client-server\nintegration architecture inherent in MCP may expand the attack surface against\nLLM Agent systems, introducing new vulnerabilities that allow attackers to\nexploit by designing malicious MCP servers. In this paper, we present the first\nsystematic study of attack vectors targeting the MCP ecosystem. Our analysis\nidentifies four categories of attacks, i.e., Tool Poisoning Attacks, Puppet\nAttacks, Rug Pull Attacks, and Exploitation via Malicious External Resources.\nTo evaluate the feasibility of these attacks, we conduct experiments following\nthe typical steps of launching an attack through malicious MCP servers:\nupload-download-attack. Specifically, we first construct malicious MCP servers\nand successfully upload them to three widely used MCP aggregation platforms.\nThe results indicate that current audit mechanisms are insufficient to identify\nand prevent the proposed attack methods. Next, through a user study and\ninterview with 20 participants, we demonstrate that users struggle to identify\nmalicious MCP servers and often unknowingly install them from aggregator\nplatforms. Finally, we demonstrate that these attacks can trigger harmful\nbehaviors within the user's local environment-such as accessing private files\nor controlling devices to transfer digital assets-by deploying a\nproof-of-concept (PoC) framework against five leading LLMs. Additionally, based\non interview results, we discuss four key challenges faced by the current\nsecurity ecosystem surrounding MCP servers. These findings underscore the\nurgent need for robust security mechanisms to defend against malicious MCP\nservers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02040v3",
    "published": "2025-05-31T08:01:11+00:00",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00446v1",
    "title": "Off-Policy Evaluation of Ranking Policies via Embedding-Space User Behavior Modeling",
    "authors": [
      "Tatsuki Takahashi",
      "Chihiro Maru",
      "Hiroko Shoji"
    ],
    "abstract": "Off-policy evaluation (OPE) in ranking settings with large ranking action\nspaces, which stems from an increase in both the number of unique actions and\nlength of the ranking, is essential for assessing new recommender policies\nusing only logged bandit data from previous versions. To address the high\nvariance issues associated with existing estimators, we introduce two new\nassumptions: no direct effect on rankings and user behavior model on ranking\nembedding spaces. We then propose the generalized marginalized inverse\npropensity score (GMIPS) estimator with statistically desirable properties\ncompared to existing ones. Finally, we demonstrate that the GMIPS achieves the\nlowest MSE. Notably, among GMIPS variants, the marginalized reward interaction\nIPS (MRIPS) incorporates a doubly marginalized importance weight based on a\ncascade behavior assumption on ranking embeddings. MRIPS effectively balances\nthe trade-off between bias and variance, even as the ranking action spaces\nincrease and the above assumptions may not hold, as evidenced by our\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00446v1",
    "published": "2025-05-31T07:58:53+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00445v1",
    "title": "G2S: A General-to-Specific Learning Framework for Temporal Knowledge Graph Forecasting with Large Language Models",
    "authors": [
      "Long Bai",
      "Zixuan Li",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng",
      "Tat-Seng Chua"
    ],
    "abstract": "Forecasting over Temporal Knowledge Graphs (TKGs) which predicts future facts\nbased on historical ones has received much attention. Recent studies have\nintroduced Large Language Models (LLMs) for this task to enhance the models'\ngeneralization abilities. However, these models perform forecasting via\nsimultaneously learning two kinds of entangled knowledge in the TKG: (1)\ngeneral patterns, i.e., invariant temporal structures shared across different\nscenarios; and (2) scenario information, i.e., factual knowledge engaged in\nspecific scenario, such as entities and relations. As a result, the learning\nprocesses of these two kinds of knowledge may interfere with each other, which\npotentially impact the generalization abilities of the models. To enhance the\ngeneralization ability of LLMs on this task, in this paper, we propose a\nGeneral-to-Specific learning framework (G2S) that disentangles the learning\nprocesses of the above two kinds of knowledge. In the general learning stage,\nwe mask the scenario information in different TKGs and convert it into\nanonymous temporal structures. After training on these structures, the model is\nable to capture the general patterns across different TKGs. In the specific\nlearning stage, we inject the scenario information into the structures via\neither in-context learning or fine-tuning modes. Experimental results show that\nG2S effectively improves the generalization abilities of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00445v1",
    "published": "2025-05-31T07:57:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00444v1",
    "title": "Detecting non-uniform patterns on high-dimensional hyperspheres",
    "authors": [
      "Tiefeng Jiang",
      "Tuan Pham"
    ],
    "abstract": "We propose a new probabilistic characterization of the uniform distribution\non hyperspheres in terms of its inner product, extending the ideas of\n\\cite{cuesta2009projection,cuesta2007sharp} in a data-driven manner. Using this\ncharacterization, we define a new distance that quantifies the deviation of an\narbitrary distribution from uniformity. As an application, we construct a novel\nnonparametric test for the uniformity testing problem: determining whether a\nset of \\(n\\) i.i.d. random points on the \\(p\\)-dimensional hypersphere is\napproximately uniformly distributed. The proposed test is based on a degenerate\nU-process and is universally consistent in fixed-dimensional settings.\nFurthermore, in high-dimensional settings, it stands apart from existing tests\nwith its simple implementation and asymptotic theory, while also possessing a\nmodel-free consistency property. Specifically, it can detect any alternative\noutside a ball of radius \\(n^{-1/2}\\) with respect to the proposed distance.",
    "pdf_url": "http://arxiv.org/pdf/2506.00444v1",
    "published": "2025-05-31T07:56:32+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.02039v1",
    "title": "No Audiogram: Leveraging Existing Scores for Personalized Speech Intelligibility Prediction",
    "authors": [
      "Haoshuai Zhou",
      "Changgeng Mo",
      "Boxuan Cao",
      "Linkai Li",
      "Shan Xiang Wang"
    ],
    "abstract": "Personalized speech intelligibility prediction is challenging. Previous\napproaches have mainly relied on audiograms, which are inherently limited in\naccuracy as they only capture a listener's hearing threshold for pure tones.\nRather than incorporating additional listener features, we propose a novel\napproach that leverages an individual's existing intelligibility data to\npredict their performance on new audio. We introduce the Support Sample-Based\nIntelligibility Prediction Network (SSIPNet), a deep learning model that\nleverages speech foundation models to build a high-dimensional representation\nof a listener's speech recognition ability from multiple support (audio, score)\npairs, enabling accurate predictions for unseen audio. Results on the Clarity\nPrediction Challenge dataset show that, even with a small number of support\n(audio, score) pairs, our method outperforms audiogram-based predictions. Our\nwork presents a new paradigm for personalized speech intelligibility\nprediction.",
    "pdf_url": "http://arxiv.org/pdf/2506.02039v1",
    "published": "2025-05-31T07:55:03+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00443v2",
    "title": "Definable ranks",
    "authors": [
      "Lothar Sebastian Krapp",
      "Salma Kuhlmann",
      "Lasse Vogel"
    ],
    "abstract": "We introduce the notion of the definable rank of an ordered field, ordered\nabelian group and ordered set, respectively. We study the relation between the\ndefinable rank of an ordered field and the definable rank of the value group of\nits natural valuation. Similarly we compare the definable rank of an ordered\nabelian group and the value set of its natural valuation. We consider in\nparticular the case of an almost real closed field and give conditions under\nwhich the definable ranks on the level of field, of value group and of value\nset coincide.",
    "pdf_url": "http://arxiv.org/pdf/2506.00443v2",
    "published": "2025-05-31T07:54:22+00:00",
    "categories": [
      "math.LO",
      "math.AC",
      "03C64, 03C40 (Primary) 12J15, 12L12, 12J10, 06F20, 06A05 (Secondary)"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00442v2",
    "title": "Critical scattering for the nonlinear Schrödinger equation on waveguide manifolds",
    "authors": [
      "Yongming Luo"
    ],
    "abstract": "We study the small data scattering problem in critical spaces for the\nnonlinear Schr\\\"odinger equation (NLS) on waveguide manifolds. Our work is\nprimarily inspired by the recent paper of Kwak and Kwon \\cite{KwakKwon} that\nestablished the local well-posedness of the periodic NLS with possibly\nnon-algebraic nonlinearity. While we adopt a framework similar to\n\\cite{KwakKwon} for our problem, two main obstacles prevent its direct\nadaptation to the waveguide setting. First, the classical Strichartz estimates\nfor NLS in critical product spaces, introduced by Hani and Pausader, possess\nlimited endpoints and are thus inapplicable to high-dimensional waveguides.\nSecond, the crucial fractional arguments used in \\cite{KwakKwon} rely on a\nwell-known fractional derivative formula due to Strichartz, which admits only a\nHilbert space-valued extension and is therefore incompatible with our model\nsetting.\n  To overcome these difficulties, we develop an anisotropic generalization of\nthe framework in \\cite{KwakKwon} using the anisotropic Strichartz estimates\nestablished by Tzvetkov and Visciglia, which allow for nearly unlimited\nendpoints. We also resolve several new challenges arising from the\nvector-valued and anisotropic nature of the model by employing novel\ninterpolation techniques within Besov spaces. As a further novelty, we provide\na new proof of the main result based on classical fixed point arguments,\ndiffering from the approximation methods used in \\cite{KwakKwon}. Consequently,\nwe settle the small data scattering problem in critical spaces for the NLS with\narbitrary mass-supercritical nonlinearity on waveguide manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2506.00442v2",
    "published": "2025-05-31T07:49:29+00:00",
    "categories": [
      "math.AP",
      "math.CA"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00441v1",
    "title": "K-order Ranking Preference Optimization for Large Language Models",
    "authors": [
      "Shihao Cai",
      "Chongming Gao",
      "Yang Zhang",
      "Wentao Shi",
      "Jizhi Zhang",
      "Keqin Bao",
      "Qifan Wang",
      "Fuli Feng"
    ],
    "abstract": "To adapt large language models (LLMs) to ranking tasks, existing list-wise\nmethods, represented by list-wise Direct Preference Optimization (DPO), focus\non optimizing partial-order or full-order list ranking consistency for LLMs to\nenhance their ranking abilities. However, we argue that optimizing top-K\nranking consistency could be more appropriate for real-world applications.\nThere are two main reasons: (1) users are typically concerned with only the\ntop-K results, making top-K ranking more important, and (2) tail items often\nlack precise feedback, making top-K ranking more reliable. Based on this, we\npropose K-order Ranking Preference Optimization (KPO) by extending the DPO's\nPlackett-Luce model to accommodate top-K rankings. Additionally, recognizing\nthat the number of important items can vary across queries, we extend KPO to\ndynamically determine appropriate K for different samples and introduce a\ncurriculum learning strategy to boost training efficiency. Extensive\nexperiments demonstrate the effectiveness of KPO, highlighting its high sample\nefficiency and robustness to noise. The code is available at\nhttps://github.com/Lanyu0303/KPO.",
    "pdf_url": "http://arxiv.org/pdf/2506.00441v1",
    "published": "2025-05-31T07:46:42+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00440v1",
    "title": "PSI-PFL: Population Stability Index for Client Selection in non-IID Personalized Federated Learning",
    "authors": [
      "Daniel-M. Jimenez-Gutierrez",
      "David Solans",
      "Mohammed Elbamby",
      "Nicolas Kourtellis"
    ],
    "abstract": "Federated Learning (FL) enables decentralized machine learning (ML) model\ntraining while preserving data privacy by keeping data localized across\nclients. However, non-independent and identically distributed (non-IID) data\nacross clients poses a significant challenge, leading to skewed model updates\nand performance degradation. Addressing this, we propose PSI-PFL, a novel\nclient selection framework for Personalized Federated Learning (PFL) that\nleverages the Population Stability Index (PSI) to quantify and mitigate data\nheterogeneity (so-called non-IIDness). Our approach selects more homogeneous\nclients based on PSI, reducing the impact of label skew, one of the most\ndetrimental factors in FL performance. Experimental results over multiple data\nmodalities (tabular, image, text) demonstrate that PSI-PFL significantly\nimproves global model accuracy, outperforming state-of-the-art baselines by up\nto 10\\% under non-IID scenarios while ensuring fairer local performance.\nPSI-PFL enhances FL performance and offers practical benefits in applications\nwhere data privacy and heterogeneity are critical.",
    "pdf_url": "http://arxiv.org/pdf/2506.00440v1",
    "published": "2025-05-31T07:41:42+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00439v1",
    "title": "RLAE: Reinforcement Learning-Assisted Ensemble for LLMs",
    "authors": [
      "Yuqian Fu",
      "Yuanheng Zhu",
      "Jiajun Chai",
      "Guojun Yin",
      "Wei Lin",
      "Qichao Zhang",
      "Dongbin Zhao"
    ],
    "abstract": "Ensembling large language models (LLMs) can effectively combine diverse\nstrengths of different models, offering a promising approach to enhance\nperformance across various tasks. However, existing methods typically rely on\nfixed weighting strategies that fail to adapt to the dynamic, context-dependent\ncharacteristics of LLM capabilities. In this work, we propose Reinforcement\nLearning-Assisted Ensemble for LLMs (RLAE), a novel framework that reformulates\nLLM ensemble through the lens of a Markov Decision Process (MDP). Our approach\nintroduces a RL agent that dynamically adjusts ensemble weights by considering\nboth input context and intermediate generation states, with the agent being\ntrained using rewards that directly correspond to the quality of final outputs.\nWe implement RLAE using both single-agent and multi-agent reinforcement\nlearning algorithms ($\\text{RLAE}_\\text{PPO}$ and $\\text{RLAE}_\\text{MAPPO}$ ),\ndemonstrating substantial improvements over conventional ensemble methods.\nExtensive evaluations on a diverse set of tasks show that RLAE outperforms\nexisting approaches by up to $3.3\\%$ accuracy points, offering a more effective\nframework for LLM ensembling. Furthermore, our method exhibits superior\ngeneralization capabilities across different tasks without the need for\nretraining, while simultaneously achieving lower time latency.",
    "pdf_url": "http://arxiv.org/pdf/2506.00439v1",
    "published": "2025-05-31T07:38:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00437v1",
    "title": "Is Your Explanation Reliable: Confidence-Aware Explanation on Graph Neural Networks",
    "authors": [
      "Jiaxing Zhang",
      "Xiaoou Liu",
      "Dongsheng Luo",
      "Hua Wei"
    ],
    "abstract": "Explaining Graph Neural Networks (GNNs) has garnered significant attention\ndue to the need for interpretability, enabling users to understand the behavior\nof these black-box models better and extract valuable insights from their\npredictions. While numerous post-hoc instance-level explanation methods have\nbeen proposed to interpret GNN predictions, the reliability of these\nexplanations remains uncertain, particularly in the out-of-distribution or\nunknown test datasets. In this paper, we address this challenge by introducing\nan explainer framework with the confidence scoring module ( ConfExplainer),\ngrounded in theoretical principle, which is generalized graph information\nbottleneck with confidence constraint (GIB-CC), that quantifies the reliability\nof generated explanations. Experimental results demonstrate the superiority of\nour approach, highlighting the effectiveness of the confidence score in\nenhancing the trustworthiness and robustness of GNN explanations.",
    "pdf_url": "http://arxiv.org/pdf/2506.00437v1",
    "published": "2025-05-31T07:34:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00438v1",
    "title": "PointODE: Lightweight Point Cloud Learning with Neural Ordinary Differential Equations on Edge",
    "authors": [
      "Keisuke Sugiura",
      "Mizuki Yasuda",
      "Hiroki Matsutani"
    ],
    "abstract": "Embedded edge devices are often used as a computing platform to run\nreal-world point cloud applications, but recent deep learning-based methods may\nnot fit on such devices due to limited resources. In this paper, we aim to fill\nthis gap by introducing PointODE, a parameter-efficient ResNet-like\narchitecture for point cloud feature extraction based on a stack of MLP blocks\nwith residual connections. We leverage Neural ODE (Ordinary Differential\nEquation), a continuous-depth version of ResNet originally developed for\nmodeling the dynamics of continuous-time systems, to compress PointODE by\nreusing the same parameters across MLP blocks. The point-wise normalization is\nproposed for PointODE to handle the non-uniform distribution of feature points.\nWe introduce PointODE-Elite as a lightweight version with 0.58M trainable\nparameters and design its dedicated accelerator for embedded FPGAs. The\naccelerator consists of a four-stage pipeline to parallelize the feature\nextraction for multiple points and stores the entire parameters on-chip to\neliminate most of the off-chip data transfers. Compared to the ARM Cortex-A53\nCPU, the accelerator implemented on a Xilinx ZCU104 board speeds up the feature\nextraction by 4.9x, leading to 3.7x faster inference and 3.5x better\nenergy-efficiency. Despite the simple architecture, PointODE-Elite shows\ncompetitive accuracy to the state-of-the-art models on both synthetic and\nreal-world classification datasets, greatly improving the trade-off between\naccuracy and inference cost.",
    "pdf_url": "http://arxiv.org/pdf/2506.00438v1",
    "published": "2025-05-31T07:34:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00436v2",
    "title": "Learning from Double Positive and Unlabeled Data for Potential-Customer Identification",
    "authors": [
      "Masahiro Kato",
      "Yuki Ikeda",
      "Kentaro Baba",
      "Takashi Imai",
      "Ryo Inokuchi"
    ],
    "abstract": "In this study, we propose a method for identifying potential customers in\ntargeted marketing by applying learning from positive and unlabeled data (PU\nlearning). We consider a scenario in which a company sells a product and can\nobserve only the customers who purchased it. Decision-makers seek to market\nproducts effectively based on whether people have loyalty to the company.\nIndividuals with loyalty are those who are likely to remain interested in the\ncompany even without additional advertising. Consequently, those loyal\ncustomers would likely purchase from the company if they are interested in the\nproduct. In contrast, people with lower loyalty may overlook the product or buy\nsimilar products from other companies unless they receive marketing attention.\nTherefore, by focusing marketing efforts on individuals who are interested in\nthe product but do not have strong loyalty, we can achieve more efficient\nmarketing. To achieve this goal, we consider how to learn, from limited data, a\nclassifier that identifies potential customers who (i) have interest in the\nproduct and (ii) do not have loyalty to the company. Although our algorithm\ncomprises a single-stage optimization, its objective function implicitly\ncontains two losses derived from standard PU learning settings. For this\nreason, we refer to our approach as double PU learning. We verify the validity\nof the proposed algorithm through numerical experiments, confirming that it\nfunctions appropriately for the problem at hand.",
    "pdf_url": "http://arxiv.org/pdf/2506.00436v2",
    "published": "2025-05-31T07:33:48+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.EM",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00435v2",
    "title": "Spectral Hardening Reveals Afterglow Emergence in Long-Duration Fast X-ray Transients: A Case Study of GRB 250404A/EP250404a",
    "authors": [
      "Yi-Han Iris Yin",
      "Yuan Fang",
      "Bin-Bin Zhang",
      "Chen Deng",
      "Jun Yang",
      "Run-Chao Chen",
      "Yuan Liu",
      "Yehao Cheng",
      "Dong Xu",
      "Xiaofeng Wang",
      "Rongfeng Shen",
      "Rui-Zhi Li",
      "Jirong Mao",
      "Wen-Xiong Li",
      "Alberto Javier Castro-Tirado",
      "Weihua Lei",
      "Shao-Yu Fu",
      "Yuan-Pei Yang",
      "Shuai-Qing Jiang",
      "Jie An",
      "Chun Chen",
      "Zhong-Nan Dong",
      "Guowang Du",
      "Ali Esamdin",
      "Zhou Fan",
      "Haicheng Feng",
      "Lu Feng",
      "Emilio Fernández-García",
      "Xing Gao",
      "Maria Gritsevich",
      "Wei-Jian Guo",
      "Jingwei Hu",
      "You-Dong Hu",
      "Yanlong Hua",
      "Abdusamatjan Iskandar",
      "Junjie Jin",
      "Niu Li",
      "Xia Li",
      "Ziwei Li",
      "Jia-Qi Lin",
      "Dezi Liu",
      "Jinzhong Liu",
      "Qichun Liu",
      "Xiaowei Liu",
      "Xing Liu",
      "Daniele B. Malesani",
      "Ignacio Pérez-García",
      "Hui Sun",
      "Xue-Feng Wu",
      "Yun-Ao Xiao",
      "Ding-Rong Xiong",
      "Shengyu Yan",
      "Beibei Zhang",
      "Jinghua Zhang",
      "Haichang Zhu",
      "Zipei Zhu",
      "Hu Zou",
      "Weimin Yuan",
      "Bing Zhang"
    ],
    "abstract": "The prompt emission and afterglow phases of gamma-ray bursts (GRBs) have been\nextensively studied, yet the transition between these two phases remains\ninadequately characterized due to limited multiwavelength observational\ncoverage. Among the recent growing samples of fast X-ray transients observed by\nEinstein Probe (EP), a subgroup of GRBs are captured with long-duration X-ray\nemission, potentially containing featured evolution from prompt emission to the\nafterglow phase. In this Letter, we present a detailed analysis of GRB\n250404A/EP250404a, a bright fast X-ray transient detected simultaneously by EP\nand the Fermi Gamma-ray Burst Monitor in X-rays and gamma rays. Its continuous\nX-ray emission reveals a long-duration tail, accompanied by distinct spectral\nevolution manifested by the spectral index $\\alpha_{\\rm X}$ with an initial\nsoftening, followed by an evident hardening, eventually reaching a plateau at\nthe value of $\\sim$ -2. Early optical and near-infrared observations enable\nbroadband modeling with forward- and reverse-shock components, confirming that\nthe X-ray hardening signals the emergence of the external-shock afterglow. From\nthis spectral hardening we infer that the prompt phase in soft X-rays lasted\n$\\sim300\\;\\mathrm{s}$, which is more than 3 times longer than the gamma-ray\n$T_{90}$. This well-tracked soft-hard-flat spectral pattern provides a clear\nindication of afterglow emergence from the fading prompt emission and offers a\npractical criterion for identifying a distinct population of GRBs among fast\nX-ray transients, even when the detection of the gamma-ray counterpart or\nobvious temporal break is absent.",
    "pdf_url": "http://arxiv.org/pdf/2506.00435v2",
    "published": "2025-05-31T07:33:02+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.03190v1",
    "title": "MINT: Memory-Infused Prompt Tuning at Test-time for CLIP",
    "authors": [
      "Jiaming Yi",
      "Ruirui Pan",
      "Jishen Yang",
      "Xiulong Yang"
    ],
    "abstract": "Improving the generalization ability of Vision-Language Pre-trained Models\n(VLMs) under test-time data distribution shifts remains a critical challenge.\nThe existing Test-Time Adaptation (TTA) methods fall short in fully leveraging\nthe model's internal knowledge, particularly in dynamically adapting to complex\nand hierarchical visual semantic information. In this paper, we propose\nMemory-Infused Prompt Tuning (MINT), a novel framework to address this issue.\nInspired by human associative memory theory, MINT introduces a Memory Prompt\nBank (MPB), which stores learnable key-value prompt pairs that work as a memory\nof previously seen samples. During the test time, relevant prompt pairs in the\nMPB are retrieved by the hierarchical visual features of test images to\ndynamically assemble Associative Prompts. The associative prompts are then\ninjected into the image encoder for fine-grained, customized visual contextual\nguidance. MINT also utilizes learnable text prompts. MINT thus enables rapid,\nprecise VLM adaptation at test time by leveraging this MPB-acquired memory,\nwithout source data or retraining. The code is available at\nhttps://github.com/Jamieyi2004/MINT.",
    "pdf_url": "http://arxiv.org/pdf/2506.03190v1",
    "published": "2025-05-31T07:31:20+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00434v1",
    "title": "Efficient 3D Brain Tumor Segmentation with Axial-Coronal-Sagittal Embedding",
    "authors": [
      "Tuan-Luc Huynh",
      "Thanh-Danh Le",
      "Tam V. Nguyen",
      "Trung-Nghia Le",
      "Minh-Triet Tran"
    ],
    "abstract": "In this paper, we address the crucial task of brain tumor segmentation in\nmedical imaging and propose innovative approaches to enhance its performance.\nThe current state-of-the-art nnU-Net has shown promising results but suffers\nfrom extensive training requirements and underutilization of pre-trained\nweights. To overcome these limitations, we integrate Axial-Coronal-Sagittal\nconvolutions and pre-trained weights from ImageNet into the nnU-Net framework,\nresulting in reduced training epochs, reduced trainable parameters, and\nimproved efficiency. Two strategies for transferring 2D pre-trained weights to\nthe 3D domain are presented, ensuring the preservation of learned relationships\nand feature representations critical for effective information propagation.\nFurthermore, we explore a joint classification and segmentation model that\nleverages pre-trained encoders from a brain glioma grade classification proxy\ntask, leading to enhanced segmentation performance, especially for challenging\ntumor labels. Experimental results demonstrate that our proposed methods in the\nfast training settings achieve comparable or even outperform the ensemble of\ncross-validation models, a common practice in the brain tumor segmentation\nliterature.",
    "pdf_url": "http://arxiv.org/pdf/2506.00434v1",
    "published": "2025-05-31T07:30:37+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00433v2",
    "title": "Latent Wavelet Diffusion: Enabling 4K Image Synthesis for Free",
    "authors": [
      "Luigi Sigillo",
      "Shengfeng He",
      "Danilo Comminiello"
    ],
    "abstract": "High-resolution image synthesis remains a core challenge in generative\nmodeling, particularly in balancing computational efficiency with the\npreservation of fine-grained visual detail. We present Latent Wavelet Diffusion\n(LWD), a lightweight framework that enables any latent diffusion model to scale\nto ultra-high-resolution image generation (2K to 4K) for free. LWD introduces\nthree key components: (1) a scale-consistent variational autoencoder objective\nthat enhances the spectral fidelity of latent representations; (2) wavelet\nenergy maps that identify and localize detail-rich spatial regions within the\nlatent space; and (3) a time-dependent masking strategy that focuses denoising\nsupervision on high-frequency components during training. LWD requires no\narchitectural modifications and incurs no additional computational overhead.\nDespite its simplicity, it consistently improves perceptual quality and reduces\nFID in ultra-high-resolution image synthesis, outperforming strong baseline\nmodels. These results highlight the effectiveness of frequency-aware,\nsignal-driven supervision as a principled and efficient approach for\nhigh-resolution generative modeling.",
    "pdf_url": "http://arxiv.org/pdf/2506.00433v2",
    "published": "2025-05-31T07:28:32+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.12059v1",
    "title": "CMT-LLM: Contextual Multi-Talker ASR Utilizing Large Language Models",
    "authors": [
      "Jiajun He",
      "Naoki Sawada",
      "Koichi Miyazaki",
      "Tomoki Toda"
    ],
    "abstract": "In real-world applications, automatic speech recognition (ASR) systems must\nhandle overlapping speech from multiple speakers and recognize rare words like\ntechnical terms. Traditional methods address multi-talker ASR and contextual\nbiasing separately, limiting performance in complex scenarios. We propose a\nunified framework that combines multi-talker overlapping speech recognition and\ncontextual biasing into a single task. Our ASR method integrates pretrained\nspeech encoders and large language models (LLMs), using optimized finetuning\nstrategies. We also introduce a two-stage filtering algorithm to efficiently\nidentify relevant rare words from large biasing lists and incorporate them into\nthe LLM's prompt input, enhancing rare word recognition. Experiments show that\nour approach outperforms traditional contextual biasing methods, achieving a\nWER of 7.9% on LibriMix and 32.9% on AMI SDM when the biasing size is 1,000,\ndemonstrating its effectiveness in complex speech scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.12059v1",
    "published": "2025-05-31T07:26:44+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00432v1",
    "title": "Channel Normalization for Time Series Channel Identification",
    "authors": [
      "Seunghan Lee",
      "Taeyoung Park",
      "Kibok Lee"
    ],
    "abstract": "Channel identifiability (CID) refers to the ability to distinguish between\nindividual channels in time series (TS) modeling. The absence of CID often\nresults in producing identical outputs for identical inputs, disregarding\nchannel-specific characteristics. In this paper, we highlight the importance of\nCID and propose Channel Normalization (CN), a simple yet effective\nnormalization strategy that enhances CID by assigning distinct affine\ntransformation parameters to each channel. We further extend CN in two ways: 1)\nAdaptive CN (ACN) dynamically adjusts parameters based on the input TS,\nimproving adaptability in TS models, and 2) Prototypical CN (PCN) introduces a\nset of learnable prototypes instead of per-channel parameters, enabling\napplicability to datasets with unknown or varying number of channels and\nfacilitating use in TS foundation models. We demonstrate the effectiveness of\nCN and its variants by applying them to various TS models, achieving\nsignificant performance gains for both non-CID and CID models. In addition, we\nanalyze the success of our approach from an information theory perspective.\nCode is available at https://github.com/seunghan96/CN.",
    "pdf_url": "http://arxiv.org/pdf/2506.00432v1",
    "published": "2025-05-31T07:24:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00431v1",
    "title": "TIDFormer: Exploiting Temporal and Interactive Dynamics Makes A Great Dynamic Graph Transformer",
    "authors": [
      "Jie Peng",
      "Zhewei Wei",
      "Yuhang Ye"
    ],
    "abstract": "Due to the proficiency of self-attention mechanisms (SAMs) in capturing\ndependencies in sequence modeling, several existing dynamic graph neural\nnetworks (DGNNs) utilize Transformer architectures with various encoding\ndesigns to capture sequential evolutions of dynamic graphs. However, the\neffectiveness and efficiency of these Transformer-based DGNNs vary\nsignificantly, highlighting the importance of properly defining the SAM on\ndynamic graphs and comprehensively encoding temporal and interactive dynamics\nwithout extra complex modules. In this work, we propose TIDFormer, a dynamic\ngraph TransFormer that fully exploits Temporal and Interactive Dynamics in an\nefficient manner. We clarify and verify the interpretability of our proposed\nSAM, addressing the open problem of its uninterpretable definitions on dynamic\ngraphs in previous works. To model the temporal and interactive dynamics,\nrespectively, we utilize the calendar-based time partitioning information and\nextract informative interaction embeddings for both bipartite and non-bipartite\ngraphs using merely the sampled first-order neighbors. In addition, we jointly\nmodel temporal and interactive features by capturing potential changes in\nhistorical interaction patterns through a simple decomposition. We conduct\nextensive experiments on several dynamic graph datasets to verify the\neffectiveness and efficiency of TIDFormer. The experimental results demonstrate\nthat TIDFormer excels, outperforming state-of-the-art models across most\ndatasets and experimental settings. Furthermore, TIDFormer exhibits significant\nefficiency advantages compared to previous Transformer-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00431v1",
    "published": "2025-05-31T07:23:05+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00430v1",
    "title": "MIRROR: Cognitive Inner Monologue Between Conversational Turns for Persistent Reflection and Reasoning in Conversational LLMs",
    "authors": [
      "Nicole Hsing"
    ],
    "abstract": "Human intelligence relies on inner monologue to process complex information\nthrough simultaneous reflection, memory retrieval, and response formulation. We\nintroduce MIRROR (Modular Internal Reasoning, Reflection, Orchestration, and\nResponse), a cognitive architecture that systematically implements these\nparallel reasoning capabilities in large language models. MIRROR operates as a\nunified system with two distinct functional layers: the Thinker and the Talker.\nThe Thinker encompasses: (1) the Inner Monologue Manager, coordinating\nreasoning threads across cognitive dimensions (Goals, Reasoning, and Memory);\nand (2) the Cognitive Controller, synthesizing these threads into a coherent\ninternal narrative maintained across conversation turns. The Talker component\nthen leverages this integrated narrative for context-aware responses. Evaluated\non the CuRaTe benchmark--testing personalized dialogue with safety-critical\nconstraints, conflicting preferences, and multi-turn consistency--LLMs\nutilizing the MIRROR architecture achieve up to 156% relative improvement in\ncritical safety scenarios involving three persons with conflicting preferences,\nmaintaining an average accuracy of ~>80% on all scenarios. Across\nscenario-specific comparisons, GPT-4o, Gemini 1.5 Pro, Claude 3.7 Sonnet, Llama\n4 variants, and Mistral 3 variants with the MIRROR architecture outperformed\nbaseline models by 21% on average (15.5 percentage points absolute). MIRROR\ndirectly addresses three critical LLM failure modes: sycophancy, attentional\ndeficits to critical information, and inconsistent prioritization of\nconflicting constraints. This work bridges cognitive science and AI by\nimplementing modular internal reasoning inspired by human cognition, creating a\npersistent internal model that significantly enhances multi-turn conversation\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.00430v1",
    "published": "2025-05-31T07:17:48+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00429v1",
    "title": "Combinatorial $t$-Designs from Finite Abelian Groups and Their Applications to Elliptic Curve Codes",
    "authors": [
      "Hengfeng Liu",
      "Chunming Tang",
      "Cuiling Fan",
      "Rong Luo"
    ],
    "abstract": "In this paper, we establish the conditions for some finite abelian groups and\nthe family all the $k$-sets in each of them summing up to an element $x$ to\nform $t$-designs. We fully characterize the sufficient and necessary conditions\nfor the incidence structures to form $1$-designs in finite abelian $p$-groups,\ngeneralizing existing results on vector spaces over finite fields. For finite\nabelian groups of exponent $pq$, we also propose sufficient and necessary\nconditions for the incidence structures to form a $1$-designs. Furthermore,\nsome interesting observations of the general case when the group is cyclic or\nnon-cyclic are presented and the relations between $(t-1)$-designs and\n$t$-designs from subset sums are established. As an application, we demonstrate\nthe correspondence between $t$-designs from the minimum-weight codewords in\nelliptic curve codes and subset-sum designs in their groups of rational points.\nBy such a correspondence, elliptic curve codes supporting designs can be simply\nderived from subset sums in finite abelian groups that supporting designs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00429v1",
    "published": "2025-05-31T07:16:20+00:00",
    "categories": [
      "math.CO",
      "cs.IT",
      "math.IT",
      "05B05, 94B05"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00428v1",
    "title": "Faster negative length shortest paths by bootstrapping hop reducers",
    "authors": [
      "Yufan Huang",
      "Peter Jin",
      "Kent Quanrud"
    ],
    "abstract": "The textbook algorithm for real-weighted single-source shortest paths takes\n$O(m n)$ time on a graph with $m$ edges and $n$ vertices. The breakthrough\nalgorithm by Fineman [Fin24] takes $\\tilde{O}(m n^{8/9})$ randomized time. The\nrunning time was subsequently improved to $\\tilde{O}(mn^{4/5})$ [HJQ25].\n  We build on [Fin24; HJQ25] to obtain an $\\tilde{O}(m n^{3/4} + m^{4/5} n)$\nrandomized running time. (Equivalently, $\\tilde{O}(mn^{3/4})$ for $m \\geq\nn^{5/4}$, and $\\tilde{O}(m^{4/5} n)$ for $m \\leq n^{5/4}$.) The main new\ntechnique replaces the hop-reducing auxiliary graph from [Fin24] with a\nbootstrapping process where constant-hop reducers for small subgraphs of the\ninput graph are iteratively amplified and expanded until the desired\npolynomial-hop reduction is achieved over the entire graph.",
    "pdf_url": "http://arxiv.org/pdf/2506.00428v1",
    "published": "2025-05-31T07:11:00+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00427v1",
    "title": "Huge anisotropic magneto-thermal switching in high-purity polycrystalline compensated metals",
    "authors": [
      "Poonam Rani",
      "Yuto Watanabe",
      "Takuma Shiga",
      "Yuya Sakuraba",
      "Hikaru Takeda",
      "Minoru Yamashita",
      "Ken-ichi Uchida",
      "Aichi Yamashita",
      "Yoshikazu Mizuguchi"
    ],
    "abstract": "Magneto-thermal transport is a promising physical property for thermal\nmanagement applications. Magneto-thermal switching enables active control of\nheat flows, and a high switching ratio is desirable for improving performance.\nHere, we report on the observation of a huge magneto-thermal switching (MTS)\neffect in high-purity (5N) Pb polycrystalline wires, where magnetic fields\nperpendicular to the heat current direction are applied at low temperatures. At\nT = 3 K and B = 0.1 T, the measured thermal conductivity (\\k{appa}) of the Pb\nwire is about 2500 W m-1 K-1 but is reduced to ~150 and ~5 W m-1 K-1 at B = 1\nand 9 T, respectively. This strong suppression is attributed to\nmagnetoresistance in compensated metals. Although the huge magnetoresistance\nhas been studied in single crystals with field along the selected orbitals, our\nresults demonstrate that a huge MTS can similarly be realized even in flexible\npolycrystalline wires. This finding highlights the practical potential of\nmagneto-thermal control in low-temperature thermal management, including\napplications in space environments where temperatures are around 3 K.",
    "pdf_url": "http://arxiv.org/pdf/2506.00427v1",
    "published": "2025-05-31T07:09:47+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00426v1",
    "title": "Hybrid Cloud Security: Balancing Performance, Cost, and Compliance in Multi-Cloud Deployments",
    "authors": [
      "Anjani kumar Polinati"
    ],
    "abstract": "The pervasive use of hybrid cloud computing models has changed enterprise as\nwell as Information Technology services infrastructure by giving businesses\nsimple and cost-effective options of combining on-premise IT equipment with\npublic cloud services. hybrid cloud solutions deploy multifaceted models of\nsecurity, performance optimization, and cost efficiency, conventionally\nfragmented in the cloud computing milieu. This paper examines how organizations\nmanage these parameters in hybrid cloud ecosystems while providing solutions to\nthe challenges they face in operationalizing hybrid cloud adoptions. The study\ncaptures the challenges of achieving a balance in resource distribution between\non-premise and cloud resources (herein referred to as the \"resource allocation\nchallenge\"), the complexity of pricing models from cloud providers like AWS,\nMicrosoft Azure, Google Cloud (herein called the 'pricing complexity problem'),\nand the urgency for strong security infrastructure to safeguard sensitive\ninformation (known as 'the information security problem'). This study\ndemonstrates the security and performance management solutions proposed were\nvalidated in a detailed case study of adoption of AWS and Azure based hybrid\ncloud and provides useful guidance. Also, a hybrid cloud security and cost\noptimization framework based on zero trust architecture, encryption, hybrid\ncloud policies, and others, is proposed.\n  The conclusion includes recommendations for research on automation of hybrid\ncloud service management, integration of multi-clouds, and the ever-present\nquestion of data privacy, stressing how those matters affect contemporary\nenterprises.",
    "pdf_url": "http://arxiv.org/pdf/2506.00426v1",
    "published": "2025-05-31T07:04:08+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00425v1",
    "title": "Inter-Passage Verification for Multi-evidence Multi-answer QA",
    "authors": [
      "Bingsen Chen",
      "Shengjie Wang",
      "Xi Ye",
      "Chen Zhao"
    ],
    "abstract": "Multi-answer question answering (QA), where questions can have many valid\nanswers, presents a significant challenge for existing retrieval-augmented\ngeneration-based QA systems, as these systems struggle to retrieve and then\nsynthesize a large number of evidence passages. To tackle these challenges, we\npropose a new multi-answer QA framework -- Retrieval-augmented Independent\nReading with Inter-passage Verification (RI$^2$VER). Our framework retrieves a\nlarge set of passages and processes each passage individually to generate an\ninitial high-recall but noisy answer set. Then we propose a new inter-passage\nverification pipeline that validates every candidate answer through (1)\nVerification Question Generation, (2) Gathering Additional Evidence, and (3)\nVerification with inter-passage synthesis. Evaluations on the QAMPARI and RoMQA\ndatasets demonstrate that our framework significantly outperforms existing\nbaselines across various model sizes, achieving an average F1 score improvement\nof 11.17%. Further analysis validates that our inter-passage verification\npipeline enables our framework to be particularly beneficial for questions\nrequiring multi-evidence synthesis.",
    "pdf_url": "http://arxiv.org/pdf/2506.00425v1",
    "published": "2025-05-31T07:03:52+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00424v2",
    "title": "COGNATE: Acceleration of Sparse Tensor Programs on Emerging Hardware using Transfer Learning",
    "authors": [
      "Chamika Sudusinghe",
      "Gerasimos Gerogiannis",
      "Damitha Lenadora",
      "Charles Block",
      "Josep Torrellas",
      "Charith Mendis"
    ],
    "abstract": "Sparse tensor programs are essential in deep learning and graph analytics,\ndriving the need for optimized processing. To meet this demand, specialized\nhardware accelerators are being developed. Optimizing these programs for\naccelerators is challenging for two reasons: program performance is highly\nsensitive to variations in sparse inputs, and early-stage accelerators rely on\nexpensive simulators. Therefore, ML-based cost models used for optimizing such\nprograms on general-purpose hardware are often ineffective for early-stage\naccelerators, as they require large datasets for proper training. To this end,\nwe introduce COGNATE, a novel framework that leverages inexpensive data samples\nfrom general-purpose hardware (e.g., CPUs) to train cost models, followed by\nfew-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity of\ninput features across hardware platforms while effectively mitigating\nheterogeneity, enabling cost model training with just 5% of the data samples\nneeded by accelerator-specific models to achieve comparable performance. We\nconduct extensive experiments to demonstrate that COGNATE outperforms existing\ntechniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and\n1.39x (up to 4.22x) for SDDMM.",
    "pdf_url": "http://arxiv.org/pdf/2506.00424v2",
    "published": "2025-05-31T06:59:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.ET"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02038v1",
    "title": "Blockchain Powered Edge Intelligence for U-Healthcare in Privacy Critical and Time Sensitive Environment",
    "authors": [
      "Anum Nawaz",
      "Hafiz Humza Mahmood Ramzan",
      "Xianjia Yu",
      "Zhuo Zou",
      "Tomi Westerlund"
    ],
    "abstract": "Edge Intelligence (EI) serves as a critical enabler for privacy-preserving\nsystems by providing AI-empowered computation and distributed caching services\nat the edge, thereby minimizing latency and enhancing data privacy. The\nintegration of blockchain technology further augments EI frameworks by ensuring\ntransactional transparency, auditability, and system-wide reliability through a\ndecentralized network model. However, the operational architecture of such\nsystems introduces inherent vulnerabilities, particularly due to the extensive\ndata interactions between edge gateways (EGs) and the distributed nature of\ninformation storage during service provisioning. To address these challenges,\nwe propose an autonomous computing model along with its interaction topologies\ntailored for privacy-critical and time-sensitive health applications. The\nsystem supports continuous monitoring, real-time alert notifications, disease\ndetection, and robust data processing and aggregation. It also includes a data\ntransaction handler and mechanisms for ensuring privacy at the EGs. Moreover, a\nresource-efficient one-dimensional convolutional neural network (1D-CNN) is\nproposed for the multiclass classification of arrhythmia, enabling accurate and\nreal-time analysis of constrained EGs. Furthermore, a secure access scheme is\ndefined to manage both off-chain and on-chain data sharing and storage. To\nvalidate the proposed model, comprehensive security, performance, and cost\nanalyses are conducted, demonstrating the efficiency and reliability of the\nfine-grained access control scheme.",
    "pdf_url": "http://arxiv.org/pdf/2506.02038v1",
    "published": "2025-05-31T06:58:52+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00423v1",
    "title": "Homomorphisms from ${\\rm SL}(2, k)$ to ${\\rm SL}(4, k)$ in positive characteristic",
    "authors": [
      "Ryuji Tanimoto"
    ],
    "abstract": "Let $k$ be an algebraically closed field of positive characteistic $p$ and\nlet ${\\rm SL}(n, k)$ denote the special linear algebraic group of degree $n$\nover $k$. In this paper, we describe homomorphisms from ${\\rm SL}(2, k)$ to\n${\\rm SL}(4, k)$. As by-products of this description, we give a classification\nof homomorphisms from ${\\rm SL}(2, k)$ to ${\\rm SL}(4, k)$ and describe the\nindecomposable decompositions of homomorphisms from ${\\rm SL}(2, k)$ to ${\\rm\nSL}(4, k)$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00423v1",
    "published": "2025-05-31T06:54:54+00:00",
    "categories": [
      "math.RT",
      "Primary 15A21, Secondary 15A54"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00422v1",
    "title": "DYNAC: Dynamic Vocabulary based Non-Autoregressive Contextualization for Speech Recognition",
    "authors": [
      "Yui Sudo",
      "Yosuke Fukumoto",
      "Muhammad Shakeel",
      "Yifan Peng",
      "Chyi-Jiunn Lin",
      "Shinji Watanabe"
    ],
    "abstract": "Contextual biasing (CB) improves automatic speech recognition for rare and\nunseen phrases. Recent studies have introduced dynamic vocabulary, which\nrepresents context phrases as expandable tokens in autoregressive (AR) models.\nThis method improves CB accuracy but with slow inference speed. While dynamic\nvocabulary can be applied to non-autoregressive (NAR) models, such as\nconnectionist temporal classification (CTC), the conditional independence\nassumption fails to capture dependencies between static and dynamic tokens.\nThis paper proposes DYNAC (Dynamic Vocabulary-based NAR Contextualization), a\nself-conditioned CTC method that integrates dynamic vocabulary into\nintermediate layers. Conditioning the encoder on dynamic vocabulary, DYNAC\neffectively captures dependencies between static and dynamic tokens while\nreducing the real-time factor (RTF). Experimental results show that DYNAC\nreduces RTF by 81% with a 0.1-point degradation in word error rate on the\nLibriSpeech 960 test-clean set.",
    "pdf_url": "http://arxiv.org/pdf/2506.00422v1",
    "published": "2025-05-31T06:53:25+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00421v1",
    "title": "Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions",
    "authors": [
      "Jihyoung Jang",
      "Minwook Bae",
      "Minji Kim",
      "Dilek Hakkani-Tur",
      "Hyounghun Kim"
    ],
    "abstract": "As chatbots continue to evolve toward human-like, real-world, interactions,\nmultimodality remains an active area of research and exploration. So far,\nefforts to integrate multimodality into chatbots have primarily focused on\nimage-centric tasks, such as visual dialogue and image-based instructions,\nplacing emphasis on the \"eyes\" of human perception while neglecting the \"ears\",\nnamely auditory aspects. Moreover, these studies often center around static\ninteractions that focus on discussing the modality rather than naturally\nincorporating it into the conversation, which limits the richness of\nsimultaneous, dynamic engagement. Furthermore, while multimodality has been\nexplored in multi-party and multi-session conversations, task-specific\nconstraints have hindered its seamless integration into dynamic, natural\nconversations. To address these challenges, this study aims to equip chatbots\nwith \"eyes and ears\" capable of more immersive interactions with humans. As\npart of this effort, we introduce a new multimodal conversation dataset,\nMultimodal Multi-Session Multi-Party Conversation ($M^3C$), and propose a novel\nmultimodal conversation model featuring multimodal memory retrieval. Our model,\ntrained on the $M^3C$, demonstrates the ability to seamlessly engage in\nlong-term conversations with multiple speakers in complex, real-world-like\nsettings, effectively processing visual and auditory inputs to understand and\nrespond appropriately. Human evaluations highlight the model's strong\nperformance in maintaining coherent and dynamic interactions, demonstrating its\npotential for advanced multimodal conversational agents.",
    "pdf_url": "http://arxiv.org/pdf/2506.00421v1",
    "published": "2025-05-31T06:50:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00420v1",
    "title": "A New Spatiotemporal Correlation Anomaly Detection Method that Integrates Contrastive Learning and Few-Shot Learning in Wireless Sensor Networks",
    "authors": [
      "Miao Ye",
      "Suxiao Wang",
      "Jiaguang Han",
      "Yong Wang",
      "Xiaoli Wang",
      "Jingxuan Wei",
      "Peng Wen",
      "Jing Cui"
    ],
    "abstract": "Detecting anomalies in the data collected by WSNs can provide crucial\nevidence for assessing the reliability and stability of WSNs. Existing methods\nfor WSN anomaly detection often face challenges such as the limited extraction\nof spatiotemporal correlation features, the absence of sample labels, few\nanomaly samples, and an imbalanced sample distribution. To address these\nissues, a spatiotemporal correlation detection model (MTAD-RD) considering both\nmodel architecture and a two-stage training strategy perspective is proposed.\nIn terms of model structure design, the proposed MTAD-RD backbone network\nincludes a retentive network (RetNet) enhanced by a cross-retention (CR)\nmodule, a multigranular feature fusion module, and a graph attention network\nmodule to extract internode correlation information. This proposed model can\nintegrate the intermodal correlation features and spatial features of WSN\nneighbor nodes while extracting global information from time series data.\nMoreover, its serialized inference characteristic can remarkably reduce\ninference overhead. For model training, a two-stage training approach was\ndesigned. First, a contrastive learning proxy task was designed for time series\ndata with graph structure information in WSNs, enabling the backbone network to\nlearn transferable features from unlabeled data using unsupervised contrastive\nlearning methods, thereby addressing the issue of missing sample labels in the\ndataset. Then, a caching-based sample sampler was designed to divide samples\ninto few-shot and contrastive learning data. A specific joint loss function was\ndeveloped to jointly train the dual-graph discriminator network to address the\nproblem of sample imbalance effectively. In experiments carried out on real\npublic datasets, the designed MTAD-RD anomaly detection method achieved an F1\nscore of 90.97%, outperforming existing supervised WSN anomaly detection\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00420v1",
    "published": "2025-05-31T06:50:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00419v2",
    "title": "Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences",
    "authors": [
      "Mohammad Saqib Hasan",
      "Saikat Chakraborty",
      "Santu Karmaker",
      "Niranjan Balasubramanian"
    ],
    "abstract": "LLM generated code often contains security issues. We address two key\nchallenges in improving secure code generation. First, obtaining high quality\ntraining data covering a broad set of security issues is critical. To address\nthis, we introduce a method for distilling a preference dataset of insecure and\nsecure code pairs from frontier LLMs, along with a security reasoning that\nexplains the issues and the fix. The key idea here is to make use of security\nknowledge sources to devise a systematic prompting strategy that ensures broad\ncoverage. Second, aligning models to secure code requires focusing on localized\nregions of code. Direct preference optimization methods, like SimPO, are not\ndesigned to handle these localized differences and turn out to be ineffective.\nWe address this with a new localized preference optimization algorithm that\nmasks the security related tokens in both the winning (secure) and losing\n(insecure) responses. To prevent loss in code quality, we also add a\nregularizer. Evaluations show that both training on our dataset, DiSCo, and the\nnew preference optimization algorithm, LPO, yield substantial reductions in\ncode insecurity while also improving overall code quality. Code and dataset are\navailable at https://github.com/StonyBrookNLP/disco-lpo.",
    "pdf_url": "http://arxiv.org/pdf/2506.00419v2",
    "published": "2025-05-31T06:48:12+00:00",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00418v2",
    "title": "Dual Debiasing for Noisy In-Context Learning for Text Generation",
    "authors": [
      "Siqi Liang",
      "Sumyeong Ahn",
      "Paramveer S. Dhillon",
      "Jiayu Zhou"
    ],
    "abstract": "In context learning (ICL) relies heavily on high quality demonstrations drawn\nfrom large annotated corpora. Existing approaches detect noisy annotations by\nranking local perplexities, presuming that noisy samples yield higher\nperplexities than their clean counterparts. However, this assumption breaks\ndown when the noise ratio is high and many demonstrations are flawed. We\nreexamine the perplexity based paradigm for text generation under noisy\nannotations, highlighting two sources of bias in perplexity: the annotation\nitself and the domain specific knowledge inherent in large language models\n(LLMs). To overcome these biases, we introduce a dual debiasing framework that\nuses synthesized neighbors to explicitly correct perplexity estimates, yielding\na robust Sample Cleanliness Score. This metric uncovers absolute sample\ncleanliness regardless of the overall corpus noise level. Extensive experiments\ndemonstrate our method's superior noise detection capabilities and show that\nits final ICL performance is comparable to that of a fully clean demonstration\ncorpus. Moreover, our approach remains robust even when noise ratios are\nextremely high.",
    "pdf_url": "http://arxiv.org/pdf/2506.00418v2",
    "published": "2025-05-31T06:44:48+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00417v1",
    "title": "World Models for Cognitive Agents: Transforming Edge Intelligence in Future Networks",
    "authors": [
      "Changyuan Zhao",
      "Ruichen Zhang",
      "Jiacheng Wang",
      "Gaosheng Zhao",
      "Dusit Niyato",
      "Geng Sun",
      "Shiwen Mao",
      "Dong In Kim"
    ],
    "abstract": "World models are emerging as a transformative paradigm in artificial\nintelligence, enabling agents to construct internal representations of their\nenvironments for predictive reasoning, planning, and decision-making. By\nlearning latent dynamics, world models provide a sample-efficient framework\nthat is especially valuable in data-constrained or safety-critical scenarios.\nIn this paper, we present a comprehensive overview of world models,\nhighlighting their architecture, training paradigms, and applications across\nprediction, generation, planning, and causal reasoning. We compare and\ndistinguish world models from related concepts such as digital twins, the\nmetaverse, and foundation models, clarifying their unique role as embedded\ncognitive engines for autonomous agents. We further propose Wireless Dreamer, a\nnovel world model-based reinforcement learning framework tailored for wireless\nedge intelligence optimization, particularly in low-altitude wireless networks\n(LAWNs). Through a weather-aware UAV trajectory planning case study, we\ndemonstrate the effectiveness of our framework in improving learning efficiency\nand decision quality.",
    "pdf_url": "http://arxiv.org/pdf/2506.00417v1",
    "published": "2025-05-31T06:43:00+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00416v1",
    "title": "Blockchain-Enabled Privacy-Preserving Second-Order Federated Edge Learning in Personalized Healthcare",
    "authors": [
      "Anum Nawaz",
      "Muhammad Irfan",
      "Xianjia Yu",
      "Zhuo Zou",
      "Tomi Westerlund"
    ],
    "abstract": "Federated learning (FL) has attracted increasing attention to mitigate\nsecurity and privacy challenges in traditional cloud-centric machine learning\nmodels specifically in healthcare ecosystems. FL methodologies enable the\ntraining of global models through localized policies, allowing independent\noperations at the edge clients' level. Conventional first-order FL approaches\nface several challenges in personalized model training due to heterogeneous\nnon-independent and identically distributed (non-iid) data of each edge client.\nRecently, second-order FL approaches maintain the stability and consistency of\nnon-iid datasets while improving personalized model training. This study\nproposes and develops a verifiable and auditable optimized second-order FL\nframework BFEL (blockchain-enhanced federated edge learning) based on optimized\nFedCurv for personalized healthcare systems. FedCurv incorporates information\nabout the importance of each parameter to each client's task (through Fisher\nInformation Matrix) which helps to preserve client-specific knowledge and\nreduce model drift during aggregation. Moreover, it minimizes communication\nrounds required to achieve a target precision convergence for each edge client\nwhile effectively managing personalized training on non-iid and heterogeneous\ndata. The incorporation of Ethereum-based model aggregation ensures trust,\nverifiability, and auditability while public key encryption enhances privacy\nand security. Experimental results of federated CNNs and MLPs utilizing Mnist,\nCifar-10, and PathMnist demonstrate the high efficiency and scalability of the\nproposed framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.00416v1",
    "published": "2025-05-31T06:41:04+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00415v1",
    "title": "Wide Reflective Equilibrium in LLM Alignment: Bridging Moral Epistemology and AI Safety",
    "authors": [
      "Matthew Brophy"
    ],
    "abstract": "As large language models (LLMs) become more powerful and pervasive across\nsociety, ensuring these systems are beneficial, safe, and aligned with human\nvalues is crucial. Current alignment techniques, like Constitutional AI (CAI),\ninvolve complex iterative processes. This paper argues that the Method of Wide\nReflective Equilibrium (MWRE) -- a well-established coherentist moral\nmethodology -- offers a uniquely apt framework for understanding current LLM\nalignment efforts. Moreover, this methodology can substantively augment these\nprocesses by providing concrete pathways for improving their dynamic\nrevisability, procedural legitimacy, and overall ethical grounding. Together,\nthese enhancements can help produce more robust and ethically defensible\noutcomes. MWRE, emphasizing the achievement of coherence between our considered\nmoral judgments, guiding moral principles, and relevant background theories,\narguably better represents the intricate reality of LLM alignment and offers a\nmore robust path to justification than prevailing foundationalist models or\nsimplistic input-output evaluations. While current methods like CAI bear a\nstructural resemblance to MWRE, they often lack its crucial emphasis on\ndynamic, bi-directional revision of principles and the procedural legitimacy\nderived from such a process. While acknowledging various disanalogies (e.g.,\nconsciousness, genuine understanding in LLMs), the paper demonstrates that MWRE\nserves as a valuable heuristic for critically analyzing current alignment\nefforts and for guiding the future development of more ethically sound and\njustifiably aligned AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00415v1",
    "published": "2025-05-31T06:40:59+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00414v1",
    "title": "On the local metric dimension of $K_4$-free graphs",
    "authors": [
      "Ali Ghalavand",
      "Sandi Klavžar",
      "Xueliang Li"
    ],
    "abstract": "Let $G$ be a graph of order $ n(G) $, local metric dimension $ \\dim_l(G) $,\nand clique number $ \\omega(G) $. It has been conjectured that if $ n(G) \\geq\n\\omega(G) + 1 \\geq 4 $, then $ \\dim_l(G) \\leq \\left( \\frac{\\omega(G) -\n2}{\\omega(G) - 1} \\right) n(G) $. In this paper the conjecture is confirmed for\nthe case $ \\omega(G) = 3 $. Consequently, a problem regarding the local metric\ndimension of planar graphs is also resolved.",
    "pdf_url": "http://arxiv.org/pdf/2506.00414v1",
    "published": "2025-05-31T06:31:09+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2507.19493v1",
    "title": "From Bench to Bedside: A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice",
    "authors": [
      "Yaowei Bai",
      "Ruiheng Zhang",
      "Yu Lei",
      "Jingfeng Yao",
      "Shuguang Ju",
      "Chaoyang Wang",
      "Wei Yao",
      "Yiwan Guo",
      "Guilin Zhang",
      "Chao Wan",
      "Qian Yuan",
      "Xuhua Duan",
      "Xinggang Wang",
      "Tao Sun",
      "Yongchao Xu",
      "Chuansheng Zheng",
      "Huangxuan Zhao",
      "Bo Du"
    ],
    "abstract": "A global shortage of radiologists has been exacerbated by the significant\nvolume of chest X-ray workloads, particularly in primary care. Although\nmultimodal large language models show promise, existing evaluations\npredominantly rely on automated metrics or retrospective analyses, lacking\nrigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray\ninterpretation system based on DeepSeek Janus-Pro model, was developed and\nrigorously validated through a multicenter prospective trial (NCT06874647). Our\nsystem outperforms state-of-the-art X-ray report generation models in automated\nreport generation, surpassing even larger-scale models including ChatGPT 4o\n(200B parameters), while demonstrating robust detection of eight clinically\ncritical radiographic findings (area under the curve, AUC > 0.8). Retrospective\nevaluation confirms significantly higher report accuracy than Janus-Pro and\nChatGPT 4o. In prospective clinical deployment, AI assistance significantly\nimproved report quality scores (4.37 vs. 4.11, P < 0.001), reduced\ninterpretation time by 18.5% (P < 0.001), and was preferred by a majority of\nexperts (3 out of 5) in 52.7% of cases. Through lightweight architecture and\ndomain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and\nworkflow efficiency, particularly in resource-constrained settings. The model\narchitecture and implementation framework will be open-sourced to facilitate\nthe clinical translation of AI-assisted radiology solutions.",
    "pdf_url": "http://arxiv.org/pdf/2507.19493v1",
    "published": "2025-05-31T06:13:50+00:00",
    "categories": [
      "cs.HC",
      "eess.IV"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00413v1",
    "title": "Accelerating Diffusion LLMs via Adaptive Parallel Decoding",
    "authors": [
      "Daniel Israel",
      "Guy Van den Broeck",
      "Aditya Grover"
    ],
    "abstract": "The generation speed of LLMs are bottlenecked by autoregressive decoding,\nwhere tokens are predicted sequentially one by one. Alternatively, diffusion\nlarge language models (dLLMs) theoretically allow for parallel token\ngeneration, but in practice struggle to achieve the speed of autoregressive\nmodels without significantly sacrificing quality. We therefore introduce\nadaptive parallel decoding (APD), a novel method that dynamically adjusts the\nnumber of tokens sampled in parallel. We achieve this by defining a\nmultiplicative mixture between the dLLM marginal probabilities and the joint\nprobability of sequences under a small auxiliary autoregressive model. This\ninverts the standard setup of speculative decoding, where the goal is to sample\nfrom a large autoregressive verifier by drafting from a smaller model. We\nfurther optimize APD by enabling KV caching and limiting the size of the masked\ninput. Altogether, our method puts forward three tunable parameters to flexibly\ntradeoff throughput and quality. We show that APD provides markedly higher\nthroughput with minimal quality degradations on downstream benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00413v1",
    "published": "2025-05-31T06:10:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00412v1",
    "title": "Concentrating solutions of the fractional $(p,q)$-Choquard equation with exponential growth",
    "authors": [
      "Yueqiang Song",
      "Xueqi Sun",
      "Dušan D. Repovš"
    ],
    "abstract": "This article deals with the following fractional $(p,q)$-Choquard equation\nwith exponential growth of the form:\n$$\\varepsilon^{ps}(-\\Delta)_{p}^{s}u+\\varepsilon^{qs}(-\\Delta)_q^su+\nZ(x)(|u|^{p-2}u+|u|^{q-2}u)=\\varepsilon^{\\mu-N}[|x|^{-\\mu}*F(u)]f(u) \\ \\\n\\mbox{in} \\ \\ \\mathbb{R}^N,$$ where $s\\in (0,1),$ $\\varepsilon>0$ is a\nparameter, $2\\leq p=\\frac{N}{s}<q,$ and $0<\\mu<N.$ The nonlinear function $f$\nhas an exponential growth at infinity and the continuous potential function $Z$\nsatisfies suitable natural conditions. With the help of the\nLjusternik-Schnirelmann category theory and variational methods, the\nmultiplicity and concentration of positive solutions are obtained for\n$\\varepsilon>0$ small enough. In a certain sense, we generalize some previously\nknown results.",
    "pdf_url": "http://arxiv.org/pdf/2506.00412v1",
    "published": "2025-05-31T06:09:04+00:00",
    "categories": [
      "math.AP",
      "35A15, 35A23, 35J35, 35J60, 35R11"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.15712v1",
    "title": "BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling",
    "authors": [
      "Songqi Zhou",
      "Ruixue Liu",
      "Yixing Wang",
      "Jia Lu",
      "Benben Jiang"
    ],
    "abstract": "Accurate fault detection in lithium-ion batteries is essential for the safe\nand reliable operation of electric vehicles and energy storage systems.\nHowever, existing methods often struggle to capture complex temporal\ndependencies and cannot fully leverage abundant unlabeled data. Although large\nlanguage models (LLMs) exhibit strong representation capabilities, their\narchitectures are not directly suited to the numerical time-series data common\nin industrial settings. To address these challenges, we propose a novel\nframework that adapts BERT-style pretraining for battery fault detection by\nextending the standard BERT architecture with a customized time-series-to-token\nrepresentation module and a point-level Masked Signal Modeling (point-MSM)\npretraining task tailored to battery applications. This approach enables\nself-supervised learning on sequential current, voltage, and other\ncharge-discharge cycle data, yielding distributionally robust, context-aware\ntemporal embeddings. We then concatenate these embeddings with battery metadata\nand feed them into a downstream classifier for accurate fault classification.\nExperimental results on a large-scale real-world dataset show that models\ninitialized with our pretrained parameters significantly improve both\nrepresentation quality and classification accuracy, achieving an AUROC of 0.945\nand substantially outperforming existing approaches. These findings validate\nthe effectiveness of BERT-style pretraining for time-series fault detection.",
    "pdf_url": "http://arxiv.org/pdf/2506.15712v1",
    "published": "2025-05-31T06:06:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00411v1",
    "title": "LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon Embodied Tasks",
    "authors": [
      "Yi Yang",
      "Jiaxuan Sun",
      "Siqi Kou",
      "Yihan Wang",
      "Zhijie Deng"
    ],
    "abstract": "Real-world embodied agents face long-horizon tasks, characterized by\nhigh-level goals demanding multi-step solutions beyond single actions.\nSuccessfully navigating these requires both high-level task planning (i.e.,\ndecomposing goals into sub-tasks) and low-level motion control (i.e.,\ngenerating precise robot actions). While existing vision language action (VLA)\nmodels and hierarchical architectures offer potential in embodied tasks, the\nformer often falter in planning, and the latter can suffer from coordination\nissues, both hampering performance. We introduce a new unified VLA framework\nfor long-horizon tasks, dubbed LoHoVLA, to overcome these limitations. LoHoVLA\nleverages a large pretrained vision language model (VLM) as the backbone to\njointly generate language and action tokens for sub-task generation and robot\naction prediction, respectively. This shared representation promotes better\ngeneralization across tasks. Additionally, LoHoVLA embraces a hierarchical\nclosed-loop control mechanism to mitigate errors originating from both\nhigh-level planning and low-level control. To train LoHoVLA, we introduce\nLoHoSet, a dataset built on the Ravens simulator, containing 20 long-horizon\ntasks, each with 1,000 expert demonstrations composed of visual observations,\nlinguistic goals, sub-tasks, and robot actions. Experimental results show that\nLoHoVLA significantly surpasses both hierarchical and standard VLA approaches\non long-horizon embodied tasks in the Ravens simulator. These findings\nunderscore the promise of unified architectures for advancing generalizable\nembodied intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2506.00411v1",
    "published": "2025-05-31T06:01:03+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00410v1",
    "title": "JojoSCL: Shrinkage Contrastive Learning for single-cell RNA sequence Clustering",
    "authors": [
      "Ziwen Wang"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) has revolutionized our understanding\nof cellular processes by enabling gene expression analysis at the individual\ncell level. Clustering allows for the identification of cell types and the\nfurther discovery of intrinsic patterns in single-cell data. However, the high\ndimensionality and sparsity of scRNA-seq data continue to challenge existing\nclustering models. In this paper, we introduce JojoSCL, a novel self-supervised\ncontrastive learning framework for scRNA-seq clustering. By incorporating a\nshrinkage estimator based on hierarchical Bayesian estimation, which adjusts\ngene expression estimates towards more reliable cluster centroids to reduce\nintra-cluster dispersion, and optimized using Stein's Unbiased Risk Estimate\n(SURE), JojoSCL refines both instance-level and cluster-level contrastive\nlearning. Experiments on ten scRNA-seq datasets substantiate that JojoSCL\nconsistently outperforms prevalent clustering methods, with further validation\nof its practicality through robustness analysis and ablation studies. JojoSCL's\ncode is available at: https://github.com/ziwenwang28/JojoSCL.",
    "pdf_url": "http://arxiv.org/pdf/2506.00410v1",
    "published": "2025-05-31T05:59:56+00:00",
    "categories": [
      "cs.LG",
      "q-bio.GN",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00409v1",
    "title": "Evidence of Gaia Enceladus experiencing at least two passages around the Milky Way",
    "authors": [
      "Ása Skúladóttir",
      "Heitor Ernandes",
      "Diane K. Feuillet",
      "Alice Mori",
      "Sofia Feltzing",
      "Romain E. R. Lucchesi",
      "Paola Di Matteo"
    ],
    "abstract": "One of the major recent breakthroughs has been the discovery of the last\nMajor Merger to happen in the history of the Milky Way. Around 10 Gyr ago the\ngalaxy Gaia Enceladus, with estimated ~10% of the Milky Way mass, fell into its\npotential, bringing a large amount of stars which can be identified through\ntheir unique chemical and kinematic signatures. Simulations have long predicted\nthat a galaxy of this size should experience several passages through the disk\nof the Milky Way before eventually being fully dispersed. For the first time,\nwe present observational evidence to support this. We identify two\nsubpopulations accreted from Gaia Enceladus: 1) stars which today have large\nkinematic energy, which originate from the outskirts of Gaia Enceladus and were\naccreted during early passages; 2) stars with low kinetic energy accreted at\nlater passages, originating from the inner parts of Gaia Enceladus. Through the\nuse of high-precision chemical abundances, crucially including new aluminum\nmeasurements, we show that in all observed abundance ratios ([Fe/H], [Al/Fe],\n[Mg/Fe] and [Mg/Ba]), stars with high energy show evidence of coming from a\nless chemically evolved outer region of Gaia Enceladus, compared to the stars\nwith low energy. We therefore conclude that Gaia Enceladus experienced several\npassages before merging with the main body of our Galaxy. This discovery has\nwide implications for our understanding of this event, and consolidates Gaia\nEnceladus as a benchmark for studying galaxy mergers and hierarchical galaxy\nformation in extraordinary details.",
    "pdf_url": "http://arxiv.org/pdf/2506.00409v1",
    "published": "2025-05-31T05:57:01+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00408v6",
    "title": "Old Quantum Mechanics by Bohr and Sommerfeld from a Modern Perspective",
    "authors": [
      "Kamal K. Barley",
      "Andreas Ruffing",
      "Sergei K. Suslov"
    ],
    "abstract": "We review Bohr's atomic model and its extension by Sommerfeld from a\nmathematical perspective of wave mechanics. The derivation of quantization\nrules and energy levels is revisited using semiclassical methods.\nSommerfeld-type integrals are evaluated by elementary techniques, and\nconnections with the Schr\\\"{o}dinger and Dirac equations are established.\nHistorical developments and key transitions from classical to quantum theory\nare discussed to clarify the structure and significance of the old quantum\nmechanics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00408v6",
    "published": "2025-05-31T05:55:28+00:00",
    "categories": [
      "quant-ph",
      "physics.hist-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00407v1",
    "title": "Bias as a Virtue: Rethinking Generalization under Distribution Shifts",
    "authors": [
      "Ruixuan Chen",
      "Wentao Li",
      "Jiahui Xiao",
      "Yuchen Li",
      "Yimin Tang",
      "Xiaonan Wang"
    ],
    "abstract": "Machine learning models often degrade when deployed on data distributions\ndifferent from their training data. Challenging conventional validation\nparadigms, we demonstrate that higher in-distribution (ID) bias can lead to\nbetter out-of-distribution (OOD) generalization. Our Adaptive Distribution\nBridge (ADB) framework implements this insight by introducing controlled\nstatistical diversity during training, enabling models to develop bias profiles\nthat effectively generalize across distributions. Empirically, we observe a\nrobust negative correlation where higher ID bias corresponds to lower OOD\nerror--a finding that contradicts standard practices focused on minimizing\nvalidation error. Evaluation on multiple datasets shows our approach\nsignificantly improves OOD generalization. ADB achieves robust mean error\nreductions of up to 26.8% compared to traditional cross-validation, and\nconsistently identifies high-performing training strategies, evidenced by\npercentile ranks often exceeding 74.4%. Our work provides both a practical\nmethod for improving generalization and a theoretical framework for\nreconsidering the role of bias in robust machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2506.00407v1",
    "published": "2025-05-31T05:54:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00406v1",
    "title": "iDPA: Instance Decoupled Prompt Attention for Incremental Medical Object Detection",
    "authors": [
      "Huahui Yi",
      "Wei Xu",
      "Ziyuan Qin",
      "Xi Chen",
      "Xiaohu Wu",
      "Kang Li",
      "Qicheng Lao"
    ],
    "abstract": "Existing prompt-based approaches have demonstrated impressive performance in\ncontinual learning, leveraging pre-trained large-scale models for\nclassification tasks; however, the tight coupling between foreground-background\ninformation and the coupled attention between prompts and image-text tokens\npresent significant challenges in incremental medical object detection tasks,\ndue to the conceptual gap between medical and natural domains. To overcome\nthese challenges, we introduce the \\method~framework, which comprises two main\ncomponents: 1) Instance-level Prompt Generation (\\ipg), which decouples\nfine-grained instance-level knowledge from images and generates prompts that\nfocus on dense predictions, and 2) Decoupled Prompt Attention (\\dpa), which\ndecouples the original prompt attention, enabling a more direct and efficient\ntransfer of prompt information while reducing memory usage and mitigating\ncatastrophic forgetting. We collect 13 clinical, cross-modal, multi-organ, and\nmulti-category datasets, referred to as \\dataset, and experiments demonstrate\nthat \\method~outperforms existing SOTA methods, with FAP improvements of\n5.44\\%, 4.83\\%, 12.88\\%, and 4.59\\% in full data, 1-shot, 10-shot, and 50-shot\nsettings, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2506.00406v1",
    "published": "2025-05-31T05:53:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00405v1",
    "title": "Partially hyperbolic diffeomorphisms homotopic to the identity in dimension three",
    "authors": [
      "Ziqiang Feng",
      "Raúl Ures"
    ],
    "abstract": "We show that any conservative partially hyperbolic diffeomorphism homotopic\nto the identity is accessible unless the fundamental group of its ambient\n3-manifold is virtually solvable. As a consequence, such diffeomorphisms are\nergodic, giving an affirmative answer to the Hertz-Hertz-Ures Ergodicity\nConjecture in the homotopy class of identity.",
    "pdf_url": "http://arxiv.org/pdf/2506.00405v1",
    "published": "2025-05-31T05:52:47+00:00",
    "categories": [
      "math.DS",
      "37A25, 37C86, 37D30, 57R30"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.00404v1",
    "title": "Using Code Snippets to Teach Programming Languages",
    "authors": [
      "Joshua Akingbade",
      "Jianhua Yang",
      "Mir Seyedebrahimi"
    ],
    "abstract": "Coding is a fundamental skill required in the engineering discipline, and\nmuch work exists exploring better ways of teaching coding in the higher\neducation context. In particular, Code Snippets (CSs) are approved to be an\neffective way of introducing programming language units to students. CSs are\nportions of source code of varying size and content. They can be used in a\nmyriad of ways, one of which is to teach the code they contain as well as its\nfunction. To further explore the use of CSs, a pedagogical summer internship\nproject was set up at the Warwick Manufacturing Group (WMG). The scope of the\nconsiderations for the study derives from an educational standpoint. Within the\nevaluations made, the focus was primarily given to pieces of information which\nproved to provide evidence pertaining to the methodology involved in either\nteaching or developing teaching materials. By taking the results produced into\naccount from a pedagogical perspective, it was found that several qualities of\npopular code snippet tutorials which benefit or hinder the learning process,\nincluding code length, interactivity, further support, and quality of\nexplanation. These qualities are then combined and used to present a plan for\nthe design of an effective learning resource which makes use of code snippets.",
    "pdf_url": "http://arxiv.org/pdf/2506.00404v1",
    "published": "2025-05-31T05:51:32+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00403v1",
    "title": "Transient Error Analysis of the LMS and RLS Algorithm for Graph Signal Estimation",
    "authors": [
      "Haiquan Zhao",
      "Chengjin Li"
    ],
    "abstract": "Recently, the proposal of the least mean square (LMS) and recursive least\nsquares (RLS) algorithm for graph signal processing (GSP) provides excellent\nsolutions for processing signals defined on irregular structures such as sensor\nnetworks. The existing work has completed the steady state error analysis of\nthe GSP LMS algorithm and GSP RLS algorithm in Gaussian noise scenarios, and a\nrange of values for the step size of the GSP LMS algorithm has also been given.\nMeanwhile, the transient error analysis of the GSP LMS algorithm and GSP RLS\nalgorithm is also important and challenging. Completing the above work will\nhelp to quantitatively analyze the performance of the graph signal adaptive\nestimation algorithm at transient moments, which is what this paper is working\non. By using formula derivation and mathematical induction, the transient\nerrors expressions of the GSP LMS and GSP RLS algorithm are given in this\npaper. Based on the Brazilian temperature datasets, the related simulation\nexperiments are executed, which strongly demonstrate the correctness of our\nproposed theoretical analysis",
    "pdf_url": "http://arxiv.org/pdf/2506.00403v1",
    "published": "2025-05-31T05:48:30+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00402v1",
    "title": "Causal Structure Discovery for Error Diagnostics of Children's ASR",
    "authors": [
      "Vishwanath Pratap Singh",
      "Md. Sahidullah",
      "Tomi Kinnunen"
    ],
    "abstract": "Children's automatic speech recognition (ASR) often underperforms compared to\nthat of adults due to a confluence of interdependent factors: physiological\n(e.g., smaller vocal tracts), cognitive (e.g., underdeveloped pronunciation),\nand extrinsic (e.g., vocabulary limitations, background noise). Existing\nanalysis methods examine the impact of these factors in isolation, neglecting\ninterdependencies-such as age affecting ASR accuracy both directly and\nindirectly via pronunciation skills. In this paper, we introduce a causal\nstructure discovery to unravel these interdependent relationships among\nphysiology, cognition, extrinsic factors, and ASR errors. Then, we employ\ncausal quantification to measure each factor's impact on children's ASR. We\nextend the analysis to fine-tuned models to identify which factors are\nmitigated by fine-tuning and which remain largely unaffected. Experiments on\nWhisper and Wav2Vec2.0 demonstrate the generalizability of our findings across\ndifferent ASR systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00402v1",
    "published": "2025-05-31T05:44:43+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00401v2",
    "title": "$L_2$-norm posterior contraction in Gaussian models with unknown variance",
    "authors": [
      "Seonghyun Jeong"
    ],
    "abstract": "The testing-based approach is a fundamental tool for establishing posterior\ncontraction rates. Although the Hellinger metric is attractive owing to the\nexistence of a desirable test function, it is not directly applicable in\nGaussian models, because translating the Hellinger metric into more intuitive\nmetrics typically requires strong boundedness conditions. When the variance is\nknown, this issue can be addressed by directly constructing a test function\nrelative to the $L_2$-metric using the likelihood ratio test. However, when the\nvariance is unknown, existing results are limited and rely on restrictive\nassumptions. To overcome this limitation, we derive a test function tailored to\nan unknown variance setting with respect to the $L_2$-metric and provide\nsufficient conditions for posterior contraction based on the testing-based\napproach. We apply this result to analyze high-dimensional regression and\nnonparametric regression.",
    "pdf_url": "http://arxiv.org/pdf/2506.00401v2",
    "published": "2025-05-31T05:44:28+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.00400v1",
    "title": "Scaling Textual Gradients via Sampling-Based Momentum",
    "authors": [
      "Zixin Ding",
      "Junyuan Hong",
      "Jiachen T. Wang",
      "Zinan Lin",
      "Zhangyang Wang",
      "Yuxin Chen"
    ],
    "abstract": "As prompts play an increasingly critical role in large language models\n(LLMs), optimizing textual prompts has become a crucial challenge. The Textual\nGradient Descent (TGD) framework has emerged as a promising data-driven\napproach that iteratively refines textual prompts using LLM - suggested updates\n(or textual gradients) over minibatches of training samples. In this paper, we\nempirically demonstrate that scaling the number of training examples initially\nimproves but later degrades TGD's performance across multiple downstream NLP\ntasks. However, while data scaling improves results for most tasks, it also\nsignificantly increases the computational cost when leveraging LLMs. To address\nthis, we draw inspiration from numerical gradient descent and propose Textual\nStochastic Gradient Descent with Momentum (TSGD-M) - a method that facilitates\nscalable in-context learning by reweighting prompt sampling based on past batch\ndistributions. Across nine NLP tasks spanning three domains - including\nBIG-Bench Hard (BBH), natural language understanding tasks, and reasoning tasks\n- TSGD-M significantly outperforms TGD baselines that do not incorporate\nreweighted sampling, while also reducing variance in most tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00400v1",
    "published": "2025-05-31T05:35:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00399v1",
    "title": "Evolution of wind-generated shallow water waves in a Benney-Luke equation",
    "authors": [
      "Montri Maleewong",
      "Roger Grimshaw"
    ],
    "abstract": "In recent papers, denoted by MG24, MG25 in this text, we used the Korteweg-de\nVries (KdV) equation and its two-dimensional extension, the\nKadomtsev-Petviashvili (KP) equation to describe the evolution of wind-driven\nwater wave packets in shallow water. Both equations were modified to include\nthe effect of wind forcing, modelled using the Miles critical level instability\ntheory. In this paper that is extended to a Benney-Luke (BL) equation,\nsimilarly modified for wind forcing. The motivation is that the BL equation is\nisotropic in the horizontal space variables, unlike the KP model, and noting\nthat the KdV model is one-dimensional. The modified BL equation is studied\nusing wave modulation theory as in MG24, MG25, and with comprehensive numerical\nsimulations. Despite the very different spatial structure the results show that\nunder the right initial conditions and parameter settings, solitary wave trains\nemerge as in MG24, MG25.",
    "pdf_url": "http://arxiv.org/pdf/2506.00399v1",
    "published": "2025-05-31T05:35:15+00:00",
    "categories": [
      "physics.flu-dyn",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.00398v1",
    "title": "Position: Olfaction Standardization is Essential for the Advancement of Embodied Artificial Intelligence",
    "authors": [
      "Kordel K. France",
      "Rohith Peddi",
      "Nik Dennler",
      "Ovidiu Daescu"
    ],
    "abstract": "Despite extraordinary progress in artificial intelligence (AI), modern\nsystems remain incomplete representations of human cognition. Vision, audition,\nand language have received disproportionate attention due to well-defined\nbenchmarks, standardized datasets, and consensus-driven scientific foundations.\nIn contrast, olfaction - a high-bandwidth, evolutionarily critical sense - has\nbeen largely overlooked. This omission presents a foundational gap in the\nconstruction of truly embodied and ethically aligned super-human intelligence.\nWe argue that the exclusion of olfactory perception from AI architectures is\nnot due to irrelevance but to structural challenges: unresolved scientific\ntheories of smell, heterogeneous sensor technologies, lack of standardized\nolfactory datasets, absence of AI-oriented benchmarks, and difficulty in\nevaluating sub-perceptual signal processing. These obstacles have hindered the\ndevelopment of machine olfaction despite its tight coupling with memory,\nemotion, and contextual reasoning in biological systems. In this position\npaper, we assert that meaningful progress toward general and embodied\nintelligence requires serious investment in olfactory research by the AI\ncommunity. We call for cross-disciplinary collaboration - spanning\nneuroscience, robotics, machine learning, and ethics - to formalize olfactory\nbenchmarks, develop multimodal datasets, and define the sensory capabilities\nnecessary for machines to understand, navigate, and act within human\nenvironments. Recognizing olfaction as a core modality is essential not only\nfor scientific completeness, but for building AI systems that are ethically\ngrounded in the full scope of the human experience.",
    "pdf_url": "http://arxiv.org/pdf/2506.00398v1",
    "published": "2025-05-31T05:35:13+00:00",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00397v1",
    "title": "A Family of Robust Generalized Adaptive Filters and Application for Time-series Prediction",
    "authors": [
      "Yi Peng",
      "Haiquan Zhao",
      "Jinhui Hu"
    ],
    "abstract": "The continuous development of new adaptive filters (AFs) based on novel cost\nfunctions (CFs) is driven by the demands of various application scenarios and\nnoise environments. However, these algorithms typically demonstrate optimal\nperformance only in specific conditions. In the event of the noise change, the\nperformance of these AFs often declines, rendering simple parameter adjustments\nineffective. Instead, a modification of the CF is necessary. To address this\nissue, the robust generalized adaptive AF (RGA-AF) with strong adaptability and\nflexibility is proposed in this paper. The flexibility of the RGA-AF's CF\nallows for smooth adaptation to varying noise environments through parameter\nadjustments, ensuring optimal filtering performance in diverse scenarios.\nMoreover, we introduce several fundamental properties of negative RGA (NRGA)\nentropy and present the negative asymmetric RGA-AF (NAR-GA-AF) and kernel\nrecursive NRGA-AF (KRNRGA-AF). These AFs address asymmetric noise distribution\nand nonlinear filtering issues, respectively. Simulations of linear system\nidentification and time-series prediction for Chua's circuit under different\nnoise environments demonstrate the superiority of the proposed algorithms in\ncomparison to existing techniques.",
    "pdf_url": "http://arxiv.org/pdf/2506.00397v1",
    "published": "2025-05-31T05:33:43+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00396v1",
    "title": "Speculative Reward Model Boosts Decision Making Ability of LLMs Cost-Effectively",
    "authors": [
      "Jiawei Gu",
      "Shangsong Liang"
    ],
    "abstract": "Effective decision-making in Large Language Models (LLMs) is essential for\nhandling intricate tasks. However, existing approaches prioritize performance\nbut often overlook the balance between effectiveness and computational cost. To\naddress this, we first introduce the 3E Criteria to systematically assess the\ncost-effectiveness of search strategies, revealing that existing methods often\ntrade significant efficiency for marginal performance gains. To improve LLM\ndecision-making while maintaining efficiency, we propose the Speculative Reward\nModel (SRM), a plug-and-play framework that seamlessly integrates with existing\nsearch strategies. Specifically, SRM employs an external reward assigner to\npredict optimal actions, reducing reliance on LLMs' internal self-evaluation.\nAnd a speculative verification mechanism is used to prune suboptimal choices\nand guide the search toward more promising steps. We evaluate SRM on several\ncomplex decision-making tasks including mathematical reasoning, planning and\nnumerical reasoning in specialized domains. Experimental results show that SRM\nreduces costs to 1/10 of the original search framework on average while\nmaintaining effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2506.00396v1",
    "published": "2025-05-31T05:32:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00395v1",
    "title": "Modular orthogonal Yangians",
    "authors": [
      "Hao Chang",
      "Hongmei Hu"
    ],
    "abstract": "We study the (extended) orthogonal Yangians associated to the Lie algebras\ntypes $B$ and $D$ over a field of positive characteristic. We define the\n$p$-center for the Yangians and obtain an explicit description of the center in\nterms of Drinfeld generators, showing that the center is generated by its\nHarish-Chandra center together with a large $p$-center.",
    "pdf_url": "http://arxiv.org/pdf/2506.00395v1",
    "published": "2025-05-31T05:30:35+00:00",
    "categories": [
      "math.QA",
      "math.RT"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00394v1",
    "title": "Sequence-Based Identification of First-Person Camera Wearers in Third-Person Views",
    "authors": [
      "Ziwei Zhao",
      "Xizi Wang",
      "Yuchen Wang",
      "Feng Cheng",
      "David Crandall"
    ],
    "abstract": "The increasing popularity of egocentric cameras has generated growing\ninterest in studying multi-camera interactions in shared environments. Although\nlarge-scale datasets such as Ego4D and Ego-Exo4D have propelled egocentric\nvision research, interactions between multiple camera wearers remain\nunderexplored-a key gap for applications like immersive learning and\ncollaborative robotics. To bridge this, we present TF2025, an expanded dataset\nwith synchronized first- and third-person views. In addition, we introduce a\nsequence-based method to identify first-person wearers in third-person footage,\ncombining motion cues and person re-identification.",
    "pdf_url": "http://arxiv.org/pdf/2506.00394v1",
    "published": "2025-05-31T05:25:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00393v1",
    "title": "Asymptotic analysis of high-dimensional uniformity tests under heavy-tailed alternatives",
    "authors": [
      "Tiefeng Jiang",
      "Tuan Pham"
    ],
    "abstract": "We study the high-dimensional uniformity testing problem, which involves\ntesting whether the underlying distribution is the uniform distribution, given\n$n$ data points on the $p$-dimensional unit hypersphere. While this problem has\nbeen extensively studied in scenarios with fixed $p$, only three testing\nprocedures are known in high-dimensional settings: the Rayleigh test\n\\cite{Cutting-P-V}, the Bingham test \\cite{Cutting-P-V2}, and the packing test\n\\cite{Jiang13}. Most existing research focuses on the former two tests, and the\nconsistency of the packing test remains open. We show that under certain\nclasses of alternatives involving projections of heavy-tailed distributions,\nthe Rayleigh test is asymptotically blind, and the Bingham test has asymptotic\npower equivalent to random guessing. In contrast, we show theoretically that\nthe packing test is powerful against such alternatives, and empirically that\nits size suffers from severe distortion due to the slow convergence nature of\nextreme-value statistics. By exploiting the asymptotic independence of these\nthree tests, we then propose a new test based on Fisher's combination technique\nthat combines their strengths. The new test is shown to enjoy all the\noptimality properties of each individual test, and unlike the packing test, it\nmaintains excellent type-I error control.",
    "pdf_url": "http://arxiv.org/pdf/2506.00393v1",
    "published": "2025-05-31T05:18:22+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.00392v1",
    "title": "The vector-valued Allen-Cahn equation with potentials of high-dimensional double-wells under Robin boundary conditions",
    "authors": [
      "Xingyu Wang"
    ],
    "abstract": "This work investigates the vector-valued Allen-Cahn equation with potentials\nof high-dimensional double-wells under Robin boundary conditions. We establish\nlocal-in-time convergence of solutions to mean curvature flow with a fixed\ncontact angle $0<\\alpha\\leq 90^\\circ$, for a broad class of boundary energy\ndensities and well-prepared initial data. The limiting sharp-interface system\nis derived, comprising harmonic heat flows in the bulk and minimal pair\nconditions at phase boundaries. The analysis combines the relative entropy\nmethod with gradient flow calibrations and weak convergence techniques. These\nresults extend prior works on the analysis of the vector-valued case without\nboundary effects (Comm. Pure Appl. Math., 78:1199-1247, 2025) and the\nscalar-valued case with boundary contact energy (Calc. Var. Partial Differ.\nEqu., 61:201, 2022).",
    "pdf_url": "http://arxiv.org/pdf/2506.00392v1",
    "published": "2025-05-31T04:52:12+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00391v1",
    "title": "SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL",
    "authors": [
      "Ge Qu",
      "Jinyang Li",
      "Bowen Qin",
      "Xiaolong Li",
      "Nan Huo",
      "Chenhao Ma",
      "Reynold Cheng"
    ],
    "abstract": "Current self-correction approaches in text-to-SQL face two critical\nlimitations: 1) Conventional self-correction methods rely on recursive\nself-calls of LLMs, resulting in multiplicative computational overhead, and 2)\nLLMs struggle to implement effective error detection and correction for\ndeclarative SQL queries, as they fail to demonstrate the underlying reasoning\npath. In this work, we propose SHARE, an SLM-based Hierarchical Action\ncorREction assistant that enables LLMs to perform more precise error\nlocalization and efficient correction. SHARE orchestrates three specialized\nSmall Language Models (SLMs) in a sequential pipeline, where it first\ntransforms declarative SQL queries into stepwise action trajectories that\nreveal underlying reasoning, followed by a two-phase granular refinement. We\nfurther propose a novel hierarchical self-evolution strategy for data-efficient\ntraining. Experimental results demonstrate that SHARE effectively enhances\nself-correction capabilities while proving robust across various LLMs.\nFurthermore, our comprehensive analysis shows that SHARE maintains strong\nperformance even in low-resource training settings, which is particularly\nvaluable for text-to-SQL applications with data privacy constraints.",
    "pdf_url": "http://arxiv.org/pdf/2506.00391v1",
    "published": "2025-05-31T04:51:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00390v1",
    "title": "A large scaling property of level sets for degenerate $p$-Laplacian equations with logarithmic BMO matrix weights",
    "authors": [
      "Thanh-Nhan Nguyen",
      "Minh-Phuong Tran"
    ],
    "abstract": "In this study, we deal with generalized regularity properties for solutions\nto $p$-Laplace equations with degenerate matrix weights. It has already been\nobserved in previous interesting works [A. Kh. Balci, L. Diening, R. Giova, A.\nPassarelli di Napoli, SIAM J. Math. Anal. 54(2022), 2373-2412] and [A. Kh.\nBalci, S.-S. Byun, L. Diening, H.-S. Lee, J. Math. Pures Appl. (9) 177(2023),\n484-530] that gaining Calder\\'on-Zygmund estimates for nonlinear equations with\ndegenerate weights under the so-called $\\log$-$\\mathrm{BMO}$ condition and\nminimal regularity assumption on the boundary. In this paper, we also follow\nthis direction and extend general gradient estimates for level sets of the\ngradient of solutions up to more subtle function spaces. In particular, we\nconstruct a covering of the super-level sets of the spatial gradient $|\\nabla\nu|$ with respect to a large scaling parameter via fractional maximal operators.",
    "pdf_url": "http://arxiv.org/pdf/2506.00390v1",
    "published": "2025-05-31T04:49:11+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00389v1",
    "title": "Decoding Cellular Temperature via Neural Network-Aided Fluorescent Thermometry",
    "authors": [
      "Tong Zhang",
      "Tian-Tian Li",
      "Jing-Ru Wang",
      "Yu-Wen Zhang",
      "Chao Sun",
      "Zheng Huang",
      "Jing-Juan Xu",
      "Bin Kang"
    ],
    "abstract": "The temperature distribution within cells, especially the debates on\nmitochondrial temperature, has recently attracted widespread attention. Some\nstudies have claimed that the temperature of mitochondria can reach up to 50-53\ndegrees Celsius. Yet others have questioned that this is due to measurement\nerrors from fluorescent thermometry caused by other factors, like cell\nviscosity. Here we present a neural network-aided fluorescent thermometry and\ndecouple the effect of cellular viscosity on temperature measurements. We found\nthat cellular viscosity may cause significant deviations in temperature\nmeasurements. We investigated the dynamic temperature changes in different\norganelles within the cell under stimulation and observed a distinct\ntemperature gradient within the cell. Eliminating the influence of viscosity,\nthe upper limit of mitochondrial temperature does not exceed 42-43 degrees\nCelsius, supporting our knowledge about the inactivation temperature of\nenzymes. The temperature of mitochondria is closely related to their functions\nand morphology, such as fission and fusion. Our results help to clarify the\nquestion of \"how hot are mitochondria?\" and promote a better understanding on\ncellular thermodynamics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00389v1",
    "published": "2025-05-31T04:48:56+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.06332v1",
    "title": "Introduction to Predictive Coding Networks for Machine Learning",
    "authors": [
      "Mikko Stenlund"
    ],
    "abstract": "Predictive coding networks (PCNs) constitute a biologically inspired\nframework for understanding hierarchical computation in the brain, and offer an\nalternative to traditional feedforward neural networks in ML. This note serves\nas a quick, onboarding introduction to PCNs for machine learning practitioners.\nWe cover the foundational network architecture, inference and learning update\nrules, and algorithmic implementation. A concrete image-classification task\n(CIFAR-10) is provided as a benchmark-smashing application, together with an\naccompanying Python notebook containing the PyTorch implementation.",
    "pdf_url": "http://arxiv.org/pdf/2506.06332v1",
    "published": "2025-05-31T04:48:53+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.00388v3",
    "title": "CLARIFY: Contrastive Preference Reinforcement Learning for Untangling Ambiguous Queries",
    "authors": [
      "Ni Mu",
      "Hao Hu",
      "Xiao Hu",
      "Yiqin Yang",
      "Bo Xu",
      "Qing-Shan Jia"
    ],
    "abstract": "Preference-based reinforcement learning (PbRL) bypasses explicit reward\nengineering by inferring reward functions from human preference comparisons,\nenabling better alignment with human intentions. However, humans often struggle\nto label a clear preference between similar segments, reducing label efficiency\nand limiting PbRL's real-world applicability. To address this, we propose an\noffline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback\n(CLARIFY), which learns a trajectory embedding space that incorporates\npreference information, ensuring clearly distinguished segments are spaced\napart, thus facilitating the selection of more unambiguous queries. Extensive\nexperiments demonstrate that CLARIFY outperforms baselines in both non-ideal\nteachers and real human feedback settings. Our approach not only selects more\ndistinguished queries but also learns meaningful trajectory embeddings.",
    "pdf_url": "http://arxiv.org/pdf/2506.00388v3",
    "published": "2025-05-31T04:37:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00387v1",
    "title": "Heralded deterministic Knill-Laflamme-Milburn entanglement generation for solid-state emitters via waveguide-assisted photon scattering",
    "authors": [
      "Fang-Fang Du",
      "Xin-Shan Du",
      "Zhuo-Ya Bai",
      "Qiu-Lin Tan"
    ],
    "abstract": "The realization of quantum networks that exploit multiqubit entanglement\nopens avenues for transformative applications in the realm of quantum\ncommunication. In the paper, we present a set of heralded deterministic\nprotocols designed for the generation of two-qubit, three-qubit, and $N$-qubit\nKnill-Laflamme-Milburn (KLM) states by the photon scattering property in\none-dimensional waveguide-emitter system. In each protocol, the auxiliary\nsingle photon functions as a universal interface to bridge all stationary\nqubits. Our proposed protocols allow for the conversion of irregular scattering\nincidents occasioned by nonideal coupling and frequency detuning into\ndetectable events by triggering the detectors, which mean that our protocols\nfor the generation of arbitrary KLM states with the predictive operational\ncharacter and high fidelities. Owing to the significant breakthroughs in the\nintegration of quantum emitters with nanophotonic waveguides, our protocolfs\npossess ideal features that position them as the promising candidate for\ndeployment in long-range multiqubit quantum networks systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00387v1",
    "published": "2025-05-31T04:35:12+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00386v1",
    "title": "Adaptive-VP: A Framework for LLM-Based Virtual Patients that Adapts to Trainees' Dialogue to Facilitate Nurse Communication Training",
    "authors": [
      "Keyeun Lee",
      "Seolhee Lee",
      "Esther Hehsun Kim",
      "Yena Ko",
      "Jinsu Eun",
      "Dahee Kim",
      "Hyewon Cho",
      "Haiyi Zhu",
      "Robert E. Kraut",
      "Eunyoung Suh",
      "Eun-mee Kim",
      "Hajin Lim"
    ],
    "abstract": "Effective communication training is essential to preparing nurses for\nhigh-quality patient care. While standardized patient (SP) simulations provide\nvaluable experiential learning, they are often costly and inflexible. Virtual\npatient (VP) systems offer a scalable alternative, but most fail to adapt to\nthe varying communication skills of trainees. In particular, when trainees\nrespond ineffectively, VPs should escalate in hostility or become\nuncooperative--yet this level of adaptive interaction remains largely\nunsupported. To address this gap, we introduce Adaptive-VP, a VP dialogue\ngeneration framework that leverages large language models (LLMs) to dynamically\nadapt VP behavior based on trainee input. The framework features a pipeline for\nconstructing clinically grounded yet flexible VP scenarios and a modular system\nfor assessing trainee communication and adjusting VP responses in real time,\nwhile ensuring learner safety. We validated Adaptive-VP by simulating\nchallenging patient conversations. Automated evaluation using a corpus from\npracticing nurses showed that our communication skill evaluation mechanism\nreflected real-world proficiency levels. Expert nurses further confirmed that\nAdaptive-VP produced more natural and realistic interactions than existing\napproaches, demonstrating its potential as a scalable and effective tool for\nnursing communication training.",
    "pdf_url": "http://arxiv.org/pdf/2506.00386v1",
    "published": "2025-05-31T04:34:55+00:00",
    "categories": [
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00385v1",
    "title": "MagiCodec: Simple Masked Gaussian-Injected Codec for High-Fidelity Reconstruction and Generation",
    "authors": [
      "Yakun Song",
      "Jiawei Chen",
      "Xiaobin Zhuang",
      "Chenpeng Du",
      "Ziyang Ma",
      "Jian Wu",
      "Jian Cong",
      "Dongya Jia",
      "Zhuo Chen",
      "Yuping Wang",
      "Yuxuan Wang",
      "Xie Chen"
    ],
    "abstract": "Neural audio codecs have made significant strides in efficiently mapping raw\naudio waveforms into discrete token representations, which are foundational for\ncontemporary audio generative models. However, most existing codecs are\noptimized primarily for reconstruction quality, often at the expense of the\ndownstream modelability of the encoded tokens. Motivated by the need to\novercome this bottleneck, we introduce $\\textbf{MagiCodec}$, a novel\nsingle-layer, streaming Transformer-based audio codec. MagiCodec is designed\nwith a multistage training pipeline that incorporates Gaussian noise injection\nand latent regularization, explicitly targeting the enhancement of semantic\nexpressiveness in the generated codes while preserving high reconstruction\nfidelity. We analytically derive the effect of noise injection in the frequency\ndomain, demonstrating its efficacy in attenuating high-frequency components and\nfostering robust tokenization. Extensive experimental evaluations show that\nMagiCodec surpasses state-of-the-art codecs in both reconstruction quality and\ndownstream tasks. Notably, the tokens produced by MagiCodec exhibit Zipf-like\ndistributions, as observed in natural languages, thereby improving\ncompatibility with language-model-based generative architectures. The code and\npre-trained models are available at https://github.com/Ereboas/MagiCodec.",
    "pdf_url": "http://arxiv.org/pdf/2506.00385v1",
    "published": "2025-05-31T04:31:02+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.00384v1",
    "title": "Deep-Learning-Driven Prefetching for Far Memory",
    "authors": [
      "Yutong Huang",
      "Zhiyuan Guo",
      "Yiying Zhang"
    ],
    "abstract": "Modern software systems face increasing runtime performance demands,\nparticularly in emerging architectures like far memory, where local-memory\nmisses incur significant latency. While machine learning (ML) has proven\neffective in offline systems optimization, its application to high-frequency,\nruntime-level problems remains limited due to strict performance,\ngeneralization, and integration constraints. We present FarSight, a Linux-based\nfar-memory system that leverages deep learning (DL) to efficiently perform\naccurate data prefetching. FarSight separates application semantics from\nruntime memory layout, allowing offline-trained DL models to predict access\npatterns using a compact vocabulary of ordinal possibilities, resolved at\nruntime through lightweight mapping structures. By combining asynchronous\ninference, lookahead prediction, and a cache-resident DL model, FarSight\nachieves high prediction accuracy with low runtime overhead. Our evaluation of\nFarSight on four data-intensive workloads shows that it outperforms the\nstate-of-the-art far-memory system by up to 3.6 times. Overall, this work\ndemonstrates the feasibility and advantages of applying modern ML techniques to\ncomplex, performance-critical software runtime problems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00384v1",
    "published": "2025-05-31T04:27:22+00:00",
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.OS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00383v1",
    "title": "Sensor Fusion Methods for Gaussian Mixture Models",
    "authors": [
      "Ishan Paranjape",
      "Islam Hussein",
      "Jeremy Murray-Krezan",
      "Sean Phillips",
      "Suman Chakravorty"
    ],
    "abstract": "Consensus is a popular technique for distributed state estimation. This\nformulation allows networks of connected agents or sensors to exchange\ninformation about the distribution of a set of targets with their immediate\nneighbors without the need of a centralized node or layer. We present\ndecentralized consensus-based fusion techniques for a system whose target prior\nestimates are a weighted mixture of Gaussian probability density functions\n(PDFs) for the following cases: 1) in which all agents have the same a priori\nGaussian mixture estimate of the target, and 2) in which agents have different\na priori Gaussian mixture estimates of the target. For the second case, we\npresent a formulation that fuses each agent's a priori estimate without using\nlocal observations such that each agent's posterior estimate is the same across\nthe network.",
    "pdf_url": "http://arxiv.org/pdf/2506.00383v1",
    "published": "2025-05-31T04:25:37+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00382v2",
    "title": "Spectral Insights into Data-Oblivious Critical Layers in Large Language Models",
    "authors": [
      "Xuyuan Liu",
      "Lei Hsiung",
      "Yaoqing Yang",
      "Yujun Yan"
    ],
    "abstract": "Understanding how feature representations evolve across layers in large\nlanguage models (LLMs) is key to improving their interpretability and\nrobustness. While recent studies have identified critical layers linked to\nspecific functions or behaviors, these efforts typically rely on data-dependent\nanalyses of fine-tuned models, limiting their use to post-hoc settings. In\ncontrast, we introduce a data-oblivious approach to identify intrinsic critical\nlayers in pre-fine-tuned LLMs by analyzing representation dynamics via Centered\nKernel Alignment(CKA). We show that layers with significant shifts in\nrepresentation space are also those most affected during fine-tuning--a pattern\nthat holds consistently across tasks for a given model. Our spectral analysis\nfurther reveals that these shifts are driven by changes in the top principal\ncomponents, which encode semantic transitions from rationales to conclusions.\nWe further apply these findings to two practical scenarios: efficient domain\nadaptation, where fine-tuning critical layers leads to greater loss reduction\ncompared to non-critical layers; and backdoor defense, where freezing them\nreduces attack success rates by up to 40%.",
    "pdf_url": "http://arxiv.org/pdf/2506.00382v2",
    "published": "2025-05-31T04:21:39+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00381v1",
    "title": "Neuro2Semantic: A Transfer Learning Framework for Semantic Reconstruction of Continuous Language from Human Intracranial EEG",
    "authors": [
      "Siavash Shams",
      "Richard Antonello",
      "Gavin Mischler",
      "Stephan Bickel",
      "Ashesh Mehta",
      "Nima Mesgarani"
    ],
    "abstract": "Decoding continuous language from neural signals remains a significant\nchallenge in the intersection of neuroscience and artificial intelligence. We\nintroduce Neuro2Semantic, a novel framework that reconstructs the semantic\ncontent of perceived speech from intracranial EEG (iEEG) recordings. Our\napproach consists of two phases: first, an LSTM-based adapter aligns neural\nsignals with pre-trained text embeddings; second, a corrector module generates\ncontinuous, natural text directly from these aligned embeddings. This flexible\nmethod overcomes the limitations of previous decoding approaches and enables\nunconstrained text generation. Neuro2Semantic achieves strong performance with\nas little as 30 minutes of neural data, outperforming a recent state-of-the-art\nmethod in low-data settings. These results highlight the potential for\npractical applications in brain-computer interfaces and neural decoding\ntechnologies.",
    "pdf_url": "http://arxiv.org/pdf/2506.00381v1",
    "published": "2025-05-31T04:17:19+00:00",
    "categories": [
      "cs.CL",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00380v2",
    "title": "Convex Geometries via Hopf Monoids: Combinatorial Invariants, Reciprocity, and Supersolvability",
    "authors": [
      "Yichen Ma"
    ],
    "abstract": "We study the Hopf monoid of convex geometries, which contains partial orders\nas a Hopf submonoid, and investigate the combinatorial invariants arising from\ncanonical characters. Each invariant consists of a pair: a polynomial and a\nmore general quasisymmetric function. We give combinatorial descriptions of the\npolynomial invariants and prove combinatorial reciprocity theorems for the\nEdelman-Jamison and Billera-Hsiao-Provan polynomials, which generalize the\norder and enriched order polynomials, respectively, within a unified framework.\nFor the quasisymmetric invariants, we show that their coefficients enumerate\nfaces of certain simplicial complexes, including subcomplexes of the Coxeter\ncomplex and a simplicial sphere structure introduced by Billera, Hsiao, and\nProvan. We also examine the associated $ab$- and $cd$-indices. We establish an\nequivalent condition for convex geometries to be supersolvable and use this\nresult to give a geometric interpretation of the $ab$- and $cd$-index\ncoefficients for this class of convex geometries.",
    "pdf_url": "http://arxiv.org/pdf/2506.00380v2",
    "published": "2025-05-31T04:16:07+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00379v1",
    "title": "Label-shift robust federated feature screening for high-dimensional classification",
    "authors": [
      "Qi Qin",
      "Erbo Li",
      "Xingxiang Li",
      "Yifan Sun",
      "Wu Wang",
      "Chen Xu"
    ],
    "abstract": "Distributed and federated learning are important tools for high-dimensional\nclassification of large datasets. To reduce computational costs and overcome\nthe curse of dimensionality, feature screening plays a pivotal role in\neliminating irrelevant features during data preprocessing. However, data\nheterogeneity, particularly label shifting across different clients, presents\nsignificant challenges for feature screening. This paper introduces a general\nframework that unifies existing screening methods and proposes a novel utility,\nlabel-shift robust federated feature screening (LR-FFS), along with its\nfederated estimation procedure. The framework facilitates a uniform analysis of\nmethods and systematically characterizes their behaviors under label shift\nconditions. Building upon this framework, LR-FFS leverages conditional\ndistribution functions and expectations to address label shift without adding\ncomputational burdens and remains robust against model misspecification and\noutliers. Additionally, the federated procedure ensures computational\nefficiency and privacy protection while maintaining screening effectiveness\ncomparable to centralized processing. We also provide a false discovery rate\n(FDR) control method for federated feature screening. Experimental results and\ntheoretical analyses demonstrate LR-FFS's superior performance across diverse\nclient environments, including those with varying class distributions, sample\nsizes, and missing categorical data.",
    "pdf_url": "http://arxiv.org/pdf/2506.00379v1",
    "published": "2025-05-31T04:14:49+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00378v1",
    "title": "The origin of the metallicity difference between star-forming and passive galaxies: Insights from ν2GC semi-analytic model",
    "authors": [
      "Qiansheng Liu",
      "Takashi Okamoto",
      "Taira Oogi",
      "Masahiro Nagashima"
    ],
    "abstract": "We investigate the origin of the observed metallicity difference between\nstar-forming and passive galaxies using the semi-analytic galaxy formation\nmodel nu2GC. Our fiducial model successfully reproduces the observed\nmetallicity differences in local galaxies while simultaneously matching the\npotential-metallicity relations of both star-forming and passive galaxies. By\nvarying the star formation efficiency, we identify strangulation as the primary\ndriver of the metallicity difference. This finding highlights the critical role\nof star formation timescales in explaining the observed metallicity difference.\nOur results suggest that metallicity differences serve as a valuable diagnostic\nfor evaluating star formation models in both semi-analytic models and\ncosmological simulations. Furthermore, galaxies quenched by processes\nresembling strangulation -- where the supply of cold gas is halted in a slowly\ngrowing halo -- exhibit higher metallicities than star-forming galaxies of the\nsame stellar mass. In our model, this occurs in isolated, low-mass galaxies\nwhere rapid cooling leads to an effect resembling strangulation due to the\ndiscrete treatment of gas accretion onto dark matter halos. We propose that the\nmetallicities of isolated, low-mass passive galaxies could provide key insights\ninto refining models of hot gas halo growth.",
    "pdf_url": "http://arxiv.org/pdf/2506.00378v1",
    "published": "2025-05-31T04:14:05+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00377v2",
    "title": "A Systematic Review of Metaheuristics-Based and Machine Learning-Driven Intrusion Detection Systems in IoT",
    "authors": [
      "Mohammad Shamim Ahsan",
      "Salekul Islam",
      "Swakkhar Shatabda"
    ],
    "abstract": "The widespread adoption of the Internet of Things (IoT) has raised a new\nchallenge for developers since it is prone to known and unknown cyberattacks\ndue to its heterogeneity, flexibility, and close connectivity. To defend\nagainst such security breaches, researchers have focused on building\nsophisticated intrusion detection systems (IDSs) using machine learning (ML)\ntechniques. Although these algorithms notably improve detection performance,\nthey require excessive computing power and resources, which are crucial issues\nin IoT networks considering the recent trends of decentralized data processing\nand computing systems. Consequently, many optimization techniques have been\nincorporated with these ML models. Specifically, a special category of\noptimizer adopted from the behavior of living creatures and different aspects\nof natural phenomena, known as metaheuristic algorithms, has been a central\nfocus in recent years and brought about remarkable results. Considering this\nvital significance, we present a comprehensive and systematic review of various\napplications of metaheuristics algorithms in developing a machine\nlearning-based IDS, especially for IoT. A significant contribution of this\nstudy is the discovery of hidden correlations between these optimization\ntechniques and machine learning models integrated with state-of-the-art\nIoT-IDSs. In addition, the effectiveness of these metaheuristic algorithms in\ndifferent applications, such as feature selection, parameter or hyperparameter\ntuning, and hybrid usages are separately analyzed. Moreover, a taxonomy of\nexisting IoT-IDSs is proposed. Furthermore, we investigate several critical\nissues related to such integration. Our extensive exploration ends with a\ndiscussion of promising optimization algorithms and technologies that can\nenhance the efficiency of IoT-IDSs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00377v2",
    "published": "2025-05-31T04:09:37+00:00",
    "categories": [
      "cs.CR",
      "cs.NE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00376v1",
    "title": "Understanding Remote Communication between Grandparents and Grandchildren in Distributed Immigrant Families",
    "authors": [
      "Jiawen Stefanie Zhu",
      "Jian Zhao"
    ],
    "abstract": "Grandparent-grandchild bonds are crucial for both parties. Many immigrant\nfamilies are geographically dispersed, and the grandparents and grandchildren\nneed to rely on remote communication to maintain their relationships. In\naddition to geographical separation, grandparents and grandchildren in such\nfamilies also face language and culture barriers during remote communication.\nThe associated challenges and needs remain understudied as existing research\nprimarily focuses on non-immigrant families or co-located immigrant families.\nTo address this gap, we conducted interviews with six Chinese immigrant\nfamilies in Canada. Our findings highlight unique challenges faced by immigrant\nfamilies during remote communication, such as amplified language and cultural\nbarriers due to geographic separation, and provide insights into how technology\ncan better support remote communication. This work offers empirical knowledge\nabout the communication needs of distributed immigrant families and provides\ndirections for future research and design to support grandparent-grandchild\nremote communication in these families.",
    "pdf_url": "http://arxiv.org/pdf/2506.00376v1",
    "published": "2025-05-31T04:05:24+00:00",
    "categories": [
      "cs.HC",
      "cs.CY",
      "H.5.0"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00375v1",
    "title": "RPRA-ADD: Forgery Trace Enhancement-Driven Audio Deepfake Detection",
    "authors": [
      "Ruibo Fu",
      "Xiaopeng Wang",
      "Zhengqi Wen",
      "Jianhua Tao",
      "Yuankun Xie",
      "Zhiyong Wang",
      "Chunyu Qiang",
      "Xuefei Liu",
      "Cunhang Fan",
      "Chenxing Li",
      "Guanjun Li"
    ],
    "abstract": "Existing methods for deepfake audio detection have demonstrated some\neffectiveness. However, they still face challenges in generalizing to new\nforgery techniques and evolving attack patterns. This limitation mainly arises\nbecause the models rely heavily on the distribution of the training data and\nfail to learn a decision boundary that captures the essential characteristics\nof forgeries. Additionally, relying solely on a classification loss makes it\ndifficult to capture the intrinsic differences between real and fake audio. In\nthis paper, we propose the RPRA-ADD, an integrated\nReconstruction-Perception-Reinforcement-Attention networks based forgery trace\nenhancement-driven robust audio deepfake detection framework. First, we propose\na Global-Local Forgery Perception (GLFP) module for enhancing the acoustic\nperception capacity of forgery traces. To significantly reinforce the feature\nspace distribution differences between real and fake audio, the Multi-stage\nDispersed Enhancement Loss (MDEL) is designed, which implements a dispersal\nstrategy in multi-stage feature spaces. Furthermore, in order to enhance\nfeature awareness towards forgery traces, the Fake Trace Focused Attention\n(FTFA) mechanism is introduced to adjust attention weights dynamically\naccording to the reconstruction discrepancy matrix. Visualization experiments\nnot only demonstrate that FTFA improves attention to voice segments, but also\nenhance the generalization capability. Experimental results demonstrate that\nthe proposed method achieves state-of-the-art performance on 4 benchmark\ndatasets, including ASVspoof2019, ASVspoof2021, CodecFake, and FakeSound,\nachieving over 20% performance improvement. In addition, it outperforms\nexisting methods in rigorous 3*3 cross-domain evaluations across Speech, Sound,\nand Singing, demonstrating strong generalization capability across diverse\naudio domains.",
    "pdf_url": "http://arxiv.org/pdf/2506.00375v1",
    "published": "2025-05-31T04:03:38+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.00374v1",
    "title": "Physics-based Generative Models for Geometrically Consistent and Interpretable Wireless Channel Synthesis",
    "authors": [
      "Satyavrat Wagle",
      "Akshay Malhotra",
      "Shahab Hamidi-Rad",
      "Aditya Sant",
      "David J. Love",
      "Christopher G. Brinton"
    ],
    "abstract": "In recent years, machine learning (ML) methods have become increasingly\npopular in wireless communication systems for several applications. A critical\nbottleneck for designing ML systems for wireless communications is the\navailability of realistic wireless channel datasets, which are extremely\nresource-intensive to produce. To this end, the generation of realistic\nwireless channels plays a key role in the subsequent design of effective ML\nalgorithms for wireless communication systems. Generative models have been\nproposed to synthesize channel matrices, but outputs produced by such methods\nmay not correspond to geometrically viable channels and do not provide any\ninsight into the scenario being generated. In this work, we aim to address both\nthese issues by integrating established parametric, physics-based geometric\nchannel (PPGC) modeling frameworks with generative methods to produce realistic\nchannel matrices with interpretable representations in the parameter domain. We\nshow that generative models converge to prohibitively suboptimal stationary\npoints when learning the underlying prior directly over the parameters due to\nthe non-convex PPGC model. To address this limitation, we propose a linearized\nreformulation of the problem to ensure smooth gradient flow during generative\nmodel training, while also providing insights into the underlying physical\nenvironment. We evaluate our model against prior baselines by comparing the\ngenerated, scenario-specific samples in terms of the 2-Wasserstein distance and\nthrough its utility when used for downstream compression tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00374v1",
    "published": "2025-05-31T04:00:44+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00373v1",
    "title": "Adversarial Machine Learning for Robust Password Strength Estimation",
    "authors": [
      "Pappu Jha",
      "Hanzla Hamid",
      "Oluseyi Olukola",
      "Ashim Dahal",
      "Nick Rahimi"
    ],
    "abstract": "Passwords remain one of the most common methods for securing sensitive data\nin the digital age. However, weak password choices continue to pose significant\nrisks to data security and privacy. This study aims to solve the problem by\nfocusing on developing robust password strength estimation models using\nadversarial machine learning, a technique that trains models on intentionally\ncrafted deceptive passwords to expose and address vulnerabilities posed by such\npasswords. We apply five classification algorithms and use a dataset with more\nthan 670,000 samples of adversarial passwords to train the models. Results\ndemonstrate that adversarial training improves password strength classification\naccuracy by up to 20% compared to traditional machine learning models. It\nhighlights the importance of integrating adversarial machine learning into\nsecurity systems to enhance their robustness against modern adaptive threats.\n  Keywords: adversarial attack, password strength, classification, machine\nlearning",
    "pdf_url": "http://arxiv.org/pdf/2506.00373v1",
    "published": "2025-05-31T03:54:04+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02037v2",
    "title": "FinS-Pilot: A Benchmark for Online Financial RAG System",
    "authors": [
      "Feng Wang",
      "Yiding Sun",
      "Jiaxin Mao",
      "Wei Xue",
      "Danqing Xu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious professional domains, with their performance typically evaluated\nthrough standardized benchmarks. In the financial field, the stringent demands\nfor professional accuracy and real-time data processing often necessitate the\nuse of retrieval-augmented generation (RAG) techniques. However, the\ndevelopment of financial RAG benchmarks has been constrained by data\nconfidentiality issues and the lack of dynamic data integration. To address\nthis issue, we introduce FinS-Pilot, a novel benchmark for evaluating RAG\nsystems in online financial applications. Constructed from real-world financial\nassistant interactions, our benchmark incorporates both real-time API data and\ntext data, organized through an intent classification framework covering\ncritical financial domains. The benchmark enables comprehensive evaluation of\nfinancial assistants' capabilities in handling both static knowledge and\ntime-sensitive market information.Through systematic experiments with multiple\nChinese leading LLMs, we demonstrate FinS-Pilot's effectiveness in identifying\nmodels suitable for financial applications while addressing the current gap in\nspecialized evaluation tools for the financial domain. Our work contributes\nboth a practical evaluation framework and a curated dataset to advance research\nin financial NLP systems. The code and dataset are accessible on GitHub.",
    "pdf_url": "http://arxiv.org/pdf/2506.02037v2",
    "published": "2025-05-31T03:50:19+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00372v1",
    "title": "Random Utility with Aggregated Alternatives",
    "authors": [
      "Yuexin Liao",
      "Kota Saito",
      "Alec Sandroni"
    ],
    "abstract": "This paper studies when discrete choice data involving aggregated\nalternatives such as categorical data or an outside option can be rationalized\nby a random utility model (RUM). Aggregation introduces ambiguity in\ncomposition: the underlying alternatives may differ across individuals and\nremain unobserved by the analyst. We characterize the observable implications\nof RUMs under such ambiguity and show that they are surprisingly weak, implying\nonly monotonicity with respect to adding aggregated alternatives and standard\nRUM consistency on unaggregated menus. These are insufficient to justify the\nuse of an aggregated RUM. We identify two sufficient conditions that restore\nfull rationalizability: non-overlapping preferences and menu-independent\naggregation. Simulations show that violations of these conditions generate\nestimation bias, highlighting the practical importance of how aggregated\nalternatives are defined.",
    "pdf_url": "http://arxiv.org/pdf/2506.00372v1",
    "published": "2025-05-31T03:48:20+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2506.00371v1",
    "title": "Tunable Virtual IMU Frame by Weighted Averaging of Multiple Non-Collocated IMUs",
    "authors": [
      "Yizhou Gao",
      "Tim Barfoot"
    ],
    "abstract": "We present a new method to combine several rigidly connected but physically\nseparated IMUs through a weighted average into a single virtual IMU (VIMU).\nThis has the benefits of (i) reducing process noise through averaging, and (ii)\nallowing for tuning the location of the VIMU. The VIMU can be placed to be\ncoincident with, for example, a camera frame or GNSS frame, thereby offering a\nquality-of-life improvement for users. Specifically, our VIMU removes the need\nto consider any lever-arm terms in the propagation model. We also present a\nquadratic programming method for selecting the weights to minimize the noise of\nthe VIMU while still selecting the placement of its reference frame. We tested\nour method in simulation and validated it on a real dataset. The results show\nthat our averaging technique works for IMUs with large separation and\nperformance gain is observed in both the simulation and the real experiment\ncompared to using only a single IMU.",
    "pdf_url": "http://arxiv.org/pdf/2506.00371v1",
    "published": "2025-05-31T03:46:57+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.06331v1",
    "title": "How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG",
    "authors": [
      "Qiming Zeng",
      "Xiao Yan",
      "Hao Luo",
      "Yuhao Lin",
      "Yuxiang Wang",
      "Fangcheng Fu",
      "Bo Du",
      "Quanqing Xu",
      "Jiawei Jiang"
    ],
    "abstract": "By retrieving contexts from knowledge graphs, graph-based retrieval-augmented\ngeneration (GraphRAG) enhances large language models (LLMs) to generate quality\nanswers for user questions. Many GraphRAG methods have been proposed and\nreported inspiring performance in answer quality. However, we observe that the\ncurrent answer evaluation framework for GraphRAG has two critical flaws, i.e.,\nunrelated questions and evaluation biases, which may lead to biased or even\nwrong conclusions on performance. To tackle the two flaws, we propose an\nunbiased evaluation framework that uses graph-text-grounded question generation\nto produce questions that are more related to the underlying dataset and an\nunbiased evaluation procedure to eliminate the biases in LLM-based answer\nassessment. We apply our unbiased framework to evaluate 3 representative\nGraphRAG methods and find that their performance gains are much more moderate\nthan reported previously. Although our evaluation framework may still have\nflaws, it calls for scientific evaluations to lay solid foundations for\nGraphRAG research.",
    "pdf_url": "http://arxiv.org/pdf/2506.06331v1",
    "published": "2025-05-31T03:36:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00370v2",
    "title": "Theory of terahertz pulse transmission through ferroelectric nanomembranes",
    "authors": [
      "Yujie Zhu",
      "Aiden Ross",
      "Xiangwei Guo",
      "Venkatraman Gopalan",
      "Long-Qing Chen",
      "Jia-Mian Hu"
    ],
    "abstract": "An analytical model is developed to predict the temporal evolution of the\nlattice polarization in ferroelectric nanomembranes upon the excitation by a\nterahertz (THz) electromagnetic pulse of an arbitrary waveform, and the\nconcurrent transmission of the THz pulse in both the linear and the nonlinear\nregimes. It involves the use of the perturbation method to solve the equation\nof motion for the lattice polarization in both unclamped and strained\nferroelectric nanomembranes within the framework of Landau-Ginzburg-Devonshire\ntheory. The model is applicable to perovskite oxides such as BaTiO3 and SrTiO3,\nwurtzite Al1-xScxN, and trigonal LiNbO3. Our analytical model provides a\ntheoretical basis for determining the thermodynamic and kinetic parameters of\nferroelectric materials through THz transmission experiment. The calculation\nresults also suggest an approach to reversing the chirality of a circularly\npolarized THz pulse by harnessing the resonant polarization-photon coupling in\nferroelectrics. This capability of chirality reversal, along with the high\ntunability from a strain applied along any arbitrarily oriented in-plane axis,\nprovides new opportunities for THz wave modulation without relying on complex\nmetasurface designs.",
    "pdf_url": "http://arxiv.org/pdf/2506.00370v2",
    "published": "2025-05-31T03:30:02+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.00369v1",
    "title": "The Interplay between Additive and Multiplicative Central Sets Theorems",
    "authors": [
      "Pintu Debnath",
      "Sayan Goswami",
      "Chunlin Liu"
    ],
    "abstract": "The concept of Central sets, introduced by Furstenberg through the framework\nof topological dynamics, has played a pivotal role in combinatorial number\ntheory. Furstenberg's Central Sets Theorem highlighted their rich combinatorial\nstructure. Later, De, Hindman, and Strauss strengthen this theorem using the\nalgebraic framework of the Stone--\\v{C}ech compactification. In this article,\nwe establish a unified version of the Central Sets Theorem that simultaneously\ncaptures both additive and multiplicative structures.",
    "pdf_url": "http://arxiv.org/pdf/2506.00369v1",
    "published": "2025-05-31T03:28:41+00:00",
    "categories": [
      "math.CO",
      "05D10, 22A15, 54D35"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00368v1",
    "title": "Neural Network-based Information-Theoretic Transceivers for High-Order Modulation Schemes",
    "authors": [
      "Ngoc Long Pham",
      "Tri Nhu Do"
    ],
    "abstract": "Neural network (NN)-based end-to-end (E2E) communication systems, in which\neach system component may consist of a portion of a neural network, have been\ninvestigated as potential tools for developing artificial intelligence\n(Al)-native E2E systems. In this paper, we propose an NN-based bitwise receiver\nthat improves computational efficiency while maintaining performance comparable\nto baseline demappers. Building on this foundation, we introduce a novel\nsymbol-wise autoencoder (AE)-based E2E system that jointly optimizes the\ntransmitter and receiver at the physical layer. We evaluate the proposed\nNN-based receiver using bit-error rate (BER) analysis to confirm that the\nnumerical BER achieved by NN-based receivers or transceivers is accurate.\nResults demonstrate that the AE-based system outperforms baseline\narchitectures, particularly for higher-order modulation schemes. We further\nshow that the training signal-to-noise ratio (SNR) significantly affects the\nperformance of the systems when inference is conducted at different SNR levels.",
    "pdf_url": "http://arxiv.org/pdf/2506.00368v1",
    "published": "2025-05-31T03:22:26+00:00",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00367v2",
    "title": "The ringdown of a black hole surrounded by a thin shell of matter",
    "authors": [
      "Andrew Laeuger",
      "Colin Weller",
      "Dongjun Li",
      "Yanbei Chen"
    ],
    "abstract": "Recent studies have shown that far-field perturbations to the curvature\npotential of a black hole spacetime may destabilize its quasinormal mode (QNM)\nspectrum while only mildly affecting time-domain ringdown signals. In this\nwork, we study the QNM spectrum and ringdown behavior of a Schwarzschild black\nhole with a far-field perturbation to its physical environment -- a thin matter\nshell with finite surface tension. After accounting for the dynamics of the\ninteraction between GWs and the shell, we find that the fundamental mode can\nmigrate perturbatively or be destabilized by the appearance of new modes with\nno analogue in the vacuum case, much like studies of ``bumps\" in the curvature\npotential. However, unlike these previous works, we find that the coupling\nbetween metric perturbations and oscillations of the shell also sources\nweakly-damped QNMs which are exclusive to the polar sector. We then study\nwhether the analysis tools of least-squares QNM fits and the full and rational\nringdown filters can clearly identify the signatures of the shell in\nrepresentative ringdown waveforms. We conclude that ringdown at sufficiently\nearly times is insensitive to the shell; weakly-damped QNMs (in the polar\nsector) and echoes, which may enable the analysis methods considered here to\ninfer the presence of a shell, only appear at late times and are generally\nweak.",
    "pdf_url": "http://arxiv.org/pdf/2506.00367v2",
    "published": "2025-05-31T03:22:22+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.00366v1",
    "title": "On Quantum Entanglement and Nonlocality",
    "authors": [
      "Mafiz Uddin"
    ],
    "abstract": "Bell inequalities on local hidden variables were used to test particle\nentanglement given by the quantum mechanics wavefunction. The experiments on\ncorrelated photon pairs showed a clear violation of Bell inequalities and\nagreement with quantum mechanics. This study revealed that the Bell\ninequalities on normalized density function is true only for photon\npolarization at individual instances but it does not hold over the entire\npopulation in a given system. The Bell inequalities is not an incompatibility\ncriterion for local hidden variables vs quantum mechanics rather it is a\ncriterion for an individual nature vs population dynamics. The study found that\nthe local variables (photon polarization) described each quantity in Bell test\nand a complete agreement with the experiments where quantum mechanics was\nincapable to provide as it is a unified system. The paper concludes with great\nsatisfaction that the simultaneous measurement of two correlated photons at a\ndistance was a local cause (photon-filter interaction did not violate the\nspecial theory of relativity) and the nonlocality description given by the\nwavefunction was not physical.",
    "pdf_url": "http://arxiv.org/pdf/2506.00366v1",
    "published": "2025-05-31T03:18:56+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00365v1",
    "title": "Feature Fusion and Knowledge-Distilled Multi-Modal Multi-Target Detection",
    "authors": [
      "Ngoc Tuyen Do",
      "Tri Nhu Do"
    ],
    "abstract": "In the surveillance and defense domain, multi-target detection and\nclassification (MTD) is considered essential yet challenging due to\nheterogeneous inputs from diverse data sources and the computational complexity\nof algorithms designed for resource-constrained embedded devices, particularly\nfor Al-based solutions. To address these challenges, we propose a feature\nfusion and knowledge-distilled framework for multi-modal MTD that leverages\ndata fusion to enhance accuracy and employs knowledge distillation for improved\ndomain adaptation. Specifically, our approach utilizes both RGB and thermal\nimage inputs within a novel fusion-based multi-modal model, coupled with a\ndistillation training pipeline. We formulate the problem as a posterior\nprobability optimization task, which is solved through a multi-stage training\npipeline supported by a composite loss function. This loss function effectively\ntransfers knowledge from a teacher model to a student model. Experimental\nresults demonstrate that our student model achieves approximately 95% of the\nteacher model's mean Average Precision while reducing inference time by\napproximately 50%, underscoring its suitability for practical MTD deployment\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.00365v1",
    "published": "2025-05-31T03:11:44+00:00",
    "categories": [
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02036v1",
    "title": "Multi-Operator Quantum Uncertainty Relations from New Cauchy-Schwarz Inequalities",
    "authors": [
      "Samuel R. Hedemann"
    ],
    "abstract": "We present new generalizations of Cauchy-Schwarz (CS) inequalities to\nmultiple vectors and use them to derive multi-operator quantum uncertainty\nrelations and propose multi-operator squeezing.",
    "pdf_url": "http://arxiv.org/pdf/2506.02036v1",
    "published": "2025-05-31T03:09:50+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00364v1",
    "title": "On a distinctive property of Fourier bases associated with $N$- Bernoulli Convolutions",
    "authors": [
      "Zi-Chao Chi",
      "Xing-Gang He",
      "Zhi-Yi Wu"
    ],
    "abstract": "A distinctive problem of harmonic analysis on $\\R$ with respect to a Borel\nprobability measure $\\mu$ is identifying all $t\\in\\R$ such that both\n\\[\\left\\{e^{-2\\pi i\\lambda x}: \\lambda\\in\\Lambda\\right\\}\\quad\\text{and}\\quad\n\\left\\{e^{-2\\pi i\\lambda x}: \\lambda\\in t\\Lambda\\right\\}\\] form orthonormal\nbases of the space $L^2(\\mu)$. Currently, this phenomenon has been observed\nonly in certain singular measures. It is deeply connected to the convergence of\nMock Fourier series with respect to the aforementioned bases. In this paper, we\napply classical number theory to solve the general conjecture and basic\nproblems in this field within the setting of $N$-Bernoulli convolutions, which\nextend almost all known results and give some new ones.",
    "pdf_url": "http://arxiv.org/pdf/2506.00364v1",
    "published": "2025-05-31T03:07:44+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00363v1",
    "title": "Adapting General-Purpose Embedding Models to Private Datasets Using Keyword-based Retrieval",
    "authors": [
      "Yubai Wei",
      "Jiale Han",
      "Yi Yang"
    ],
    "abstract": "Text embedding models play a cornerstone role in AI applications, such as\nretrieval-augmented generation (RAG). While general-purpose text embedding\nmodels demonstrate strong performance on generic retrieval benchmarks, their\neffectiveness diminishes when applied to private datasets (e.g.,\ncompany-specific proprietary data), which often contain specialized terminology\nand lingo. In this work, we introduce BMEmbed, a novel method for adapting\ngeneral-purpose text embedding models to private datasets. By leveraging the\nwell-established keyword-based retrieval technique (BM25), we construct\nsupervisory signals from the ranking of keyword-based retrieval results to\nfacilitate model adaptation. We evaluate BMEmbed across a range of domains,\ndatasets, and models, showing consistent improvements in retrieval performance.\nMoreover, we provide empirical insights into how BM25-based signals contribute\nto improving embeddings by fostering alignment and uniformity, highlighting the\nvalue of this approach in adapting models to domain-specific data. We release\nthe source code available at https://github.com/BaileyWei/BMEmbed for the\nresearch community.",
    "pdf_url": "http://arxiv.org/pdf/2506.00363v1",
    "published": "2025-05-31T03:06:09+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00362v1",
    "title": "FSNet: Feasibility-Seeking Neural Network for Constrained Optimization with Guarantees",
    "authors": [
      "Hoang T. Nguyen",
      "Priya L. Donti"
    ],
    "abstract": "Efficiently solving constrained optimization problems is crucial for numerous\nreal-world applications, yet traditional solvers are often computationally\nprohibitive for real-time use. Machine learning-based approaches have emerged\nas a promising alternative to provide approximate solutions at faster speeds,\nbut they struggle to strictly enforce constraints, leading to infeasible\nsolutions in practice. To address this, we propose the\nFeasibility-Seeking-Integrated Neural Network (FSNet), which integrates a\nfeasibility-seeking step directly into its solution procedure to ensure\nconstraint satisfaction. This feasibility-seeking step solves an unconstrained\noptimization problem that minimizes constraint violations in a differentiable\nmanner, enabling end-to-end training and providing guarantees on feasibility\nand convergence. Our experiments across a range of different optimization\nproblems, including both smooth/nonsmooth and convex/nonconvex problems,\ndemonstrate that FSNet can provide feasible solutions with solution quality\ncomparable to (or in some cases better than) traditional solvers, at\nsignificantly faster speeds.",
    "pdf_url": "http://arxiv.org/pdf/2506.00362v1",
    "published": "2025-05-31T03:05:29+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00361v1",
    "title": "Single-layer Circular SIW Filtenna With Beam Scanning Capability for 5G Millimeter Wave Communication Applications",
    "authors": [
      "Jiawang Li"
    ],
    "abstract": "In this communication, two novel low-cost single-layer filtering antennas\n(filtennas) are proposed for millimeter wave (mmWave) applications. The\nproposed filtennas consists of a compact circular substrate integrated\nwaveguide (SIW) cavity, a metal post close to the center of the cavity for\npower feeding, a metal post in the center for modes controlling, and a slot for\nradiating power. In the passband, the fundamental TM010 mode and the TM110 mode\nin the circular SIW cavity are excited by the feeding post. In addition, thanks\nto the high-pass characteristics of the cavity, it exhibits more than 20 dB\nsuppression in the lower frequency band. There are three radiation nulls in\nFiltenna 1 and one radiation null in Filtenna 2 in the upper band which\nincrease the suppression level as high as 18 dB. As a proof of concept, the\nproposed filtennas are fabricated and measured. It is shown that the Filtenna 1\ncan achieve simulated and measured -10 dB impedance fractional bandwidth (FBW)\nof 7.1% (27.14 - 29.13 GHz) and 8.6% (27.62 - 30.11 GHz), respectively. While\nfiltenna 2 can achieve simulated and measured -10 dB FBW of 7.4% (27.86 - 29.99\nGHz) and 10.1% (28.11 - 31.09 GHz), respectively. The filtennas features stable\nradiation patterns with an average gain of 5.0 dBi. The lower and upper\nsideband suppression levels for both filtennas exceed 18 dB. These filtennas\nare good candidates for 5G mmWave applications, as they simultaneously provide\nbeam scanning and filtering capability with a low cost, and single layer\nstructure.",
    "pdf_url": "http://arxiv.org/pdf/2506.00361v1",
    "published": "2025-05-31T03:04:30+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.00360v1",
    "title": "Tiling symmetric groups by transpositions",
    "authors": [
      "Teng Fang",
      "Binzhou Xia"
    ],
    "abstract": "For two nonempty subsets $X$ and $Y$ of a group $G$, we say that $(X,Y)$ is a\ntiling of $G$ if every element of $G$ can be uniquely expressed as $xy$ for\nsome $x\\in X$ and $y\\in Y$. In 1966, Rothaus and Thompson studied whether the\nsymmetric group $S_n$ with $n\\geq3$ admits a tiling $(T_n,Y)$, where $T_n$\nconsists of the identity and all the transpositions in $S_n$. They showed that\nno such tiling exists if $1+n(n-1)/2$ is divisible by a prime number at least\n$\\sqrt{n}+2$. In this paper, we establish a new necessary condition for the\nexistence of such a tiling: the subset $Y$ must be partition-transitive with\nrespect to certain partitions of $n$. This generalizes the result of Rothaus\nand Thompson, as well as a result of Nomura in 1985. We also study whether\n$S_n$ can be tiled by the set $T_n^*$ of all transpositions, which finally\nleads us to conjecture that neither $T_n$ nor $T_n^*$ tiles $S_n$ for any\n$n\\geq3$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00360v1",
    "published": "2025-05-31T03:01:58+00:00",
    "categories": [
      "math.CO",
      "math.RT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00359v1",
    "title": "Keeping an Eye on LLM Unlearning: The Hidden Risk and Remedy",
    "authors": [
      "Jie Ren",
      "Zhenwei Dai",
      "Xianfeng Tang",
      "Yue Xing",
      "Shenglai Zeng",
      "Hui Liu",
      "Jingying Zeng",
      "Qiankun Peng",
      "Samarth Varshney",
      "Suhang Wang",
      "Qi He",
      "Charu C. Aggarwal",
      "Hui Liu"
    ],
    "abstract": "Although Large Language Models (LLMs) have demonstrated impressive\ncapabilities across a wide range of tasks, growing concerns have emerged over\nthe misuse of sensitive, copyrighted, or harmful data during training. To\naddress these concerns, unlearning techniques have been developed to remove the\ninfluence of specific data without retraining from scratch. However, this paper\nreveals a critical vulnerability in fine-tuning-based unlearning: a malicious\nuser can craft a manipulated forgetting request that stealthily degrades the\nmodel's utility for benign users. We demonstrate this risk through a\nred-teaming Stealthy Attack (SA), which is inspired by two key limitations of\nexisting unlearning (the inability to constrain the scope of unlearning effect\nand the failure to distinguish benign tokens from unlearning signals). Prior\nwork has shown that unlearned models tend to memorize forgetting data as\nunlearning signals, and respond with hallucinations or feigned ignorance when\nunlearning signals appear in the input. By subtly increasing the presence of\ncommon benign tokens in the forgetting data, SA enhances the connection between\nbenign tokens and unlearning signals. As a result, when normal users include\nsuch tokens in their prompts, the model exhibits unlearning behaviors, leading\nto unintended utility degradation. To address this vulnerability, we propose\nScope-aware Unlearning (SU), a lightweight enhancement that introduces a scope\nterm into the unlearning objective, encouraging the model to localize the\nforgetting effect. Our method requires no additional data processing,\nintegrates seamlessly with existing fine-tuning frameworks, and significantly\nimproves robustness against SA. Extensive experiments validate the\neffectiveness of both SA and SU.",
    "pdf_url": "http://arxiv.org/pdf/2506.00359v1",
    "published": "2025-05-31T02:57:24+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00358v1",
    "title": "$\\texttt{AVROBUSTBENCH}$: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time",
    "authors": [
      "Sarthak Kumar Maharana",
      "Saksham Singh Kushwaha",
      "Baoming Zhang",
      "Adrian Rodriguez",
      "Songtao Wei",
      "Yapeng Tian",
      "Yunhui Guo"
    ],
    "abstract": "While recent audio-visual models have demonstrated impressive performance,\ntheir robustness to distributional shifts at test-time remains not fully\nunderstood. Existing robustness benchmarks mainly focus on single modalities,\nmaking them insufficient for thoroughly assessing the robustness of\naudio-visual models. Motivated by real-world scenarios where shifts can occur\n$\\textit{simultaneously}$ in both audio and visual modalities, we introduce\n$\\texttt{AVROBUSTBENCH}$, a comprehensive benchmark designed to evaluate the\ntest-time robustness of audio-visual recognition models.\n$\\texttt{AVROBUSTBENCH}$ comprises four audio-visual benchmark datasets,\n$\\texttt{AUDIOSET-2C}$, $\\texttt{VGGSOUND-2C}$, $\\texttt{KINETICS-2C}$, and\n$\\texttt{EPICKITCHENS-2C}$, each incorporating 75 bimodal audio-visual\ncorruptions that are $\\textit{co-occurring}$ and $\\textit{correlated}$. Through\nextensive evaluations, we observe that state-of-the-art supervised and\nself-supervised audio-visual models exhibit declining robustness as corruption\nseverity increases. Furthermore, online test-time adaptation (TTA) methods, on\n$\\texttt{VGGSOUND-2C}$ and $\\texttt{KINETICS-2C}$, offer minimal improvements\nin performance under bimodal corruptions. We further propose $\\texttt{AV2C}$, a\nsimple TTA approach enabling on-the-fly cross-modal fusion by penalizing\nhigh-entropy samples, which achieves improvements on $\\texttt{VGGSOUND-2C}$. We\nhope that $\\texttt{AVROBUSTBENCH}$ will steer the development of more effective\nand robust audio-visual TTA approaches. Our code is available\n$\\href{https://github.com/sarthaxxxxx/AV-C-Robustness-Benchmark}{here}$.",
    "pdf_url": "http://arxiv.org/pdf/2506.00358v1",
    "published": "2025-05-31T02:56:07+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.00357v1",
    "title": "Dynamic Control of Momentum-Polarization Photoluminescence States with Liquid-Crystal-tuned Nanocavities",
    "authors": [
      "Chengkun Dong",
      "Matthew R. Chua",
      "Rasna Maruthiyodan Veetil",
      "T. Thu Ha Do",
      "Lu Ding",
      "Deepak K. Sharma",
      "Jun Xia",
      "Ramón Paniagua-Domínguez"
    ],
    "abstract": "Dynamic control of light, and in particular beam steering, is pivotal in\nvarious optical applications, including telecommunications, LiDAR, and\nbiomedical imaging. Traditional approaches achieve this by interfacing a\ntunable modulating device with an external light source, facing challenges in\nachieving compact devices. Here, we introduce a dynamic photoluminescence (PL)\nmodulating device, with which the properties of light directly emitted by a\nquasi-two-dimensional perovskite (in particular its directionality and\npolarization) can be modified continuously and over a large range. The device\nis based on a liquid-crystal-tunable Fabry-Perot (FP) nanocavity and uses the\nFP energy-momentum dispersion and spin-orbit coupling between the excitons and\nthe cavity modes to enable this dynamic control over the emitted radiation.\nWith this device, we achieve electrically-controlled, continuous and variable\nemission angles up to a maximum of 28{\\deg}, as well as manipulation of the PL\npolarization state, enabling both the creation of polarization gradients and\nthe achievement of polarization conversion at specific emission angles.\nMoreover, due to its resonant character, a 3-fold increase in the emission\nintensity is observed, as confirmed through time-resolved photoluminescence\n(TRPL) measurements. Our approach leverages the unique properties of actively\ntunable birefringent nanocavities to improve emission directivity, angle\ntunability and polarization control, presenting a promising solution for\nnext-generation, deeply integrated beam steering devices.",
    "pdf_url": "http://arxiv.org/pdf/2506.00357v1",
    "published": "2025-05-31T02:52:36+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.00356v1",
    "title": "Exploring the Performance of Perforated Backpropagation through Further Experiments",
    "authors": [
      "Rorry Brenner",
      "Evan Davis",
      "Rushi Chaudhari",
      "Rowan Morse",
      "Jingyao Chen",
      "Xirui Liu",
      "Zhaoyi You",
      "Laurent Itti"
    ],
    "abstract": "Perforated Backpropagation is a neural network optimization technique based\non modern understanding of the computational importance of dendrites within\nbiological neurons. This paper explores further experiments from the original\npublication, generated from a hackathon held at the Carnegie Mellon Swartz\nCenter in February 2025. Students and local Pittsburgh ML practitioners were\nbrought together to experiment with the Perforated Backpropagation algorithm on\nthe datasets and models which they were using for their projects. Results\nshowed that the system could enhance their projects, with up to 90% model\ncompression without negative impact on accuracy, or up to 16% increased\naccuracy of their original models.",
    "pdf_url": "http://arxiv.org/pdf/2506.00356v1",
    "published": "2025-05-31T02:52:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00355v2",
    "title": "Pinching Antenna-Aided Wireless Powered Communication Networks",
    "authors": [
      "Yixuan Li",
      "Hongbo Xu",
      "Ming Zeng",
      "Yuanwei Liu"
    ],
    "abstract": "In this letter, we investigate a novel pinching antenna (PA)-aided wireless\npowered communication network (WPCN), in which multiple PAs are activated along\na waveguide to establish robust line-of-sight links with multiple devices. Both\ntime division multiple access (TDMA) and non-orthogonal multiple access (NOMA)\nprotocols are considered in the PA-WPCN. Moreover, some practical\nconsiderations, including a proportional power model for the PAs, a waveguide\ntransmission loss model, and a nonlinear energy harvesting model, are\nincorporated into the PA-WPCN. Furthermore, we formulate a sum-rate\nmaximization problem by jointly optimizing resource allocation and PAs\nposition. To address the challenging problem of the PAs position optimization,\nwe propose a high-performance element-wise (EW) algorithm and a low-complexity\nstochastic parameter differential evolution (SPDE) algorithm. Numerical results\nvalidate the remarkable performance of the proposed PA-WPCN and the\neffectiveness of our algorithms, indicating that optimal performance is\nattained when the PA power distribution ratio of approximately 0.55-0.6.",
    "pdf_url": "http://arxiv.org/pdf/2506.00355v2",
    "published": "2025-05-31T02:37:31+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2507.19492v1",
    "title": "ChartGen: Scaling Chart Understanding Via Code-Guided Synthetic Chart Generation",
    "authors": [
      "Jovana Kondic",
      "Pengyuan Li",
      "Dhiraj Joshi",
      "Zexue He",
      "Shafiq Abedin",
      "Jennifer Sun",
      "Ben Wiesel",
      "Eli Schwartz",
      "Ahmed Nassar",
      "Bo Wu",
      "Assaf Arbelle",
      "Aude Oliva",
      "Dan Gutfreund",
      "Leonid Karlinsky",
      "Rogerio Feris"
    ],
    "abstract": "Chart-to-code reconstruction -- the task of recovering executable plotting\nscripts from chart images -- provides important insights into a model's ability\nto ground data visualizations in precise, machine-readable form. Yet many\nexisting multimodal benchmarks largely focus primarily on answering questions\nabout charts or summarizing them. To bridge this gap, we present ChartGen, a\nfully-automated pipeline for code-guided synthetic chart generation. Starting\nfrom seed chart images, ChartGen (i) prompts a vision-language model (VLM) to\nreconstruct each image into a python script, and (ii) iteratively augments that\nscript with a code-oriented large language model (LLM). Using ChartGen, we\ncreate 222.5K unique chart-image code pairs from 13K seed chart images, and\npresent an open-source synthetic chart dataset covering 27 chart types, 11\nplotting libraries, and multiple data modalities (image, code, text, CSV,\nDocTags). From this corpus, we curate a held-out chart-to-code evaluation\nsubset of 4.3K chart image-code pairs, and evaluate six open-weight VLMs (3B -\n26B parameters), highlighting substantial room for progress. We release the\npipeline, prompts, and the dataset to help accelerate efforts towards robust\nchart understanding and vision-conditioned code generation:\nhttps://github.com/SD122025/ChartGen/",
    "pdf_url": "http://arxiv.org/pdf/2507.19492v1",
    "published": "2025-05-31T02:35:38+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00354v1",
    "title": "A Geometric Quantum Speed Limit: Theoretical Insights and Photonic Implementation",
    "authors": [
      "Qianyi Wang",
      "Ben Wang",
      "Jun Wang",
      "Lijian Zhang"
    ],
    "abstract": "Quantum mechanics imposes a lower bound on the time required for a quantum\nsystem to reach certain given targets. In this paper, from a geometric\nperspective, we introduce a new quantum speed limit (QSL) based on the Bloch\nangle and derive the condition for it to saturate. Experimentally, we\ndemonstrate the feasibility of measuring this QSL using a photonic system\nthrough direct Bloch angle measurements via a swap test, bypassing the need for\ncomprehensive quantum state tomography. Compared to the existing\nBloch-angle-based QSL mentioned in prior work, our QSL requires fewer\ncomputational and experimental resources and provides tighter constraints for\nspecific dynamics. Our work underscores the Bloch angle's effectiveness in\nproviding tighter and experimentally accessible QSLs and advances the\nunderstanding of quantum dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00354v1",
    "published": "2025-05-31T02:34:47+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00353v4",
    "title": "ILC250 Cost Update -- 2024",
    "authors": [
      "Gerald Dugan",
      "Andrew J. Lankford",
      "Benno List",
      "Shinichiro Michizono",
      "Tatsuya Nakada",
      "Marc Ross",
      "Hiroshi R. Sakai",
      "Steinar Stapnes",
      "Nobuhiro Terunuma",
      "Nicholas Walker",
      "Akira Yamamoto"
    ],
    "abstract": "The International Linear Collider was conceived as a global project for an\nenergy-frontier electron-positron collider.It employs superconducting RF and\nnano-beam technologies with a center-of-mass energy of 500 GeV. Its cost was\nestimated in 2013, based on the Technical Design Report published in\n2013.Japan's high-energy community proposed to host the ILC in Japan as a Higgs\nboson factory at 250 GeV in its first phase, and a revised cost estimate was\nconducted in 2017 to host it in Japan. However, due to global price increases\nand currency fluctuations that emerged afterward, the 2017 estimate is now\noutdated. A new cost evaluation has therefore been performed, according for\nglobal inflation tends, exchange rate shifts, and recent experiences in SRF\nbased accelerators. This report describes the cost update performed in 2024.\nThe cost update is included in the ILC Status Report in May 2025, contributing\nto the ongoing 2026 update of the European Strategy for Particle Physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.00353v4",
    "published": "2025-05-31T02:33:16+00:00",
    "categories": [
      "physics.acc-ph",
      "hep-ex"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00352v1",
    "title": "Enabling Secure and Ephemeral AI Workloads in Data Mesh Environments",
    "authors": [
      "Chinkit Patel",
      "Kee Siong Ng"
    ],
    "abstract": "Many large enterprises that operate highly governed and complex ICT\nenvironments have no efficient and effective way to support their Data and AI\nteams in rapidly spinning up and tearing down self-service data and compute\ninfrastructure, to experiment with new data analytic tools, and deploy data\nproducts into operational use. This paper proposes a key piece of the solution\nto the overall problem, in the form of an on-demand self-service data-platform\ninfrastructure to empower de-centralised data teams to build data products on\ntop of centralised templates, policies and governance. The core innovation is\nan efficient method to leverage immutable container operating systems and\ninfrastructure-as-code methodologies for creating, from scratch, vendor-neutral\nand short-lived Kubernetes clusters on-premises and in any cloud environment.\nOur proposed approach can serve as a repeatable, portable and cost-efficient\nalternative or complement to commercial Platform-as-a-Service (PaaS) offerings,\nand this is particularly important in supporting interoperability in complex\ndata mesh environments with a mix of modern and legacy compute infrastructure.",
    "pdf_url": "http://arxiv.org/pdf/2506.00352v1",
    "published": "2025-05-31T02:30:22+00:00",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00351v2",
    "title": "Recasting Classical Motion Planning for Contact-Rich Manipulation",
    "authors": [
      "Lin Yang",
      "Huu-Thiet Nguyen",
      "Chen Lv",
      "Domenico Campolo"
    ],
    "abstract": "In this work, we explore how conventional motion planning algorithms can be\nreapplied to contact-rich manipulation tasks. Rather than focusing solely on\nefficiency, we investigate how manipulation aspects can be recast in terms of\nconventional motion-planning algorithms. Conventional motion planners, such as\nRapidly-Exploring Random Trees (RRT), typically compute collision-free paths in\nconfiguration space. However, in many manipulation tasks, contact is either\nunavoidable or essential for task success, such as for creating space or\nmaintaining physical equilibrium. As such, we presents Haptic Rapidly-Exploring\nRandom Trees (HapticRRT), a planning algorithm that incorporates a recently\nproposed optimality measure in the context of \\textit{quasi-static}\nmanipulation, based on the (squared) Hessian of manipulation potential. The key\ncontributions are i) adapting classical RRT to operate on the quasi-static\nequilibrium manifold, while deepening the interpretation of haptic obstacles\nand metrics; ii) discovering multiple manipulation strategies, corresponding to\nbranches of the equilibrium manifold. iii) validating the generality of our\nmethod across three diverse manipulation tasks, each requiring only a single\nmanipulation potential expression. The video can be found at\nhttps://youtu.be/R8aBCnCCL40.",
    "pdf_url": "http://arxiv.org/pdf/2506.00351v2",
    "published": "2025-05-31T02:25:11+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00350v1",
    "title": "DiffDSR: Dysarthric Speech Reconstruction Using Latent Diffusion Model",
    "authors": [
      "Xueyuan Chen",
      "Dongchao Yang",
      "Wenxuan Wu",
      "Minglin Wu",
      "Jing Xu",
      "Xixin Wu",
      "Zhiyong Wu",
      "Helen Meng"
    ],
    "abstract": "Dysarthric speech reconstruction (DSR) aims to convert dysarthric speech into\ncomprehensible speech while maintaining the speaker's identity. Despite\nsignificant advancements, existing methods often struggle with low speech\nintelligibility and poor speaker similarity. In this study, we introduce a\nnovel diffusion-based DSR system that leverages a latent diffusion model to\nenhance the quality of speech reconstruction. Our model comprises: (i) a speech\ncontent encoder for phoneme embedding restoration via pre-trained\nself-supervised learning (SSL) speech foundation models; (ii) a speaker\nidentity encoder for speaker-aware identity preservation by in-context learning\nmechanism; (iii) a diffusion-based speech generator to reconstruct the speech\nbased on the restored phoneme embedding and preserved speaker identity. Through\nevaluations on the widely-used UASpeech corpus, our proposed model shows\nnotable enhancements in speech intelligibility and speaker similarity.",
    "pdf_url": "http://arxiv.org/pdf/2506.00350v1",
    "published": "2025-05-31T02:23:38+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.00349v1",
    "title": "Shuffle Tableaux, Littlewood--Richardson Coefficients, and Schur Log-Concavity",
    "authors": [
      "Chau Nguyen",
      "Son Nguyen",
      "Dora Woodruff"
    ],
    "abstract": "We give a new formula for the Littlewood--Richardson coefficients in terms of\npeelable tableaux compatible with shuffle tableaux, in the same fashion as\nRemmel--Whitney rule. This gives an efficient way to compute generalized\nLittlewood--Richardson coefficients for Temperley--Lieb immanants of\nJacobi--Trudi matrices. We will also show that our rule behaves well with\nBender--Knuth involutions, recovering the symmetry of Littlewood--Richardson\ncoefficients. As an application, we use our rule to prove a special case of a\nSchur log-concavity conjecture by Lam--Postnikov--Pylyavskyy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00349v1",
    "published": "2025-05-31T02:17:39+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00348v1",
    "title": "Beyond Winning: Margin of Victory Relative to Expectation Unlocks Accurate Skill Ratings",
    "authors": [
      "Shivam Shorewala",
      "Zihao Yang"
    ],
    "abstract": "Knowledge of accurate relative skills in any competitive system is essential,\nbut foundational approaches such as ELO discard extremely relevant performance\ndata by concentrating exclusively on binary outcomes. While margin of victory\n(MOV) extensions exist, they often lack a definitive method for incorporating\nthis information. We introduce Margin of Victory Differential Analysis (MOVDA),\na framework that enhances traditional rating systems by using the deviation\nbetween the true MOV and a $\\textit{modeled expectation}$. MOVDA learns a\ndomain-specific, non-linear function (a scaled hyperbolic tangent that captures\nsaturation effects and home advantage) to predict expected MOV based on rating\ndifferentials. Crucially, the $\\textit{difference}$ between the true and\nexpected MOV provides a subtle and weighted signal for rating updates,\nhighlighting informative deviations in all levels of contests. Extensive\nexperiments on professional NBA basketball data (from 2013 to 2023, with 13,619\ngames) show that MOVDA significantly outperforms standard ELO and Bayesian\nbaselines. MOVDA reduces Brier score prediction error by $1.54\\%$ compared to\nTrueSkill, increases outcome accuracy by $0.58\\%$, and most importantly\naccelerates rating convergence by $13.5\\%$, while maintaining the computational\nefficiency of the original ELO updates. MOVDA offers a theoretically motivated,\nempirically superior, and computationally lean approach to integrating\nperformance magnitude into skill rating for competitive environments like the\nNBA.",
    "pdf_url": "http://arxiv.org/pdf/2506.00348v1",
    "published": "2025-05-31T02:16:51+00:00",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.00347v1",
    "title": "Quantum Geometric Tensor for Mixed States Based on the Covariant Derivative",
    "authors": [
      "Qianyi Wang",
      "Ben Wang",
      "Jun Wang",
      "Lijian Zhang"
    ],
    "abstract": "The quantum geometric tensor (QGT) is a fundamental quantity for\ncharacterizing the geometric properties of quantum states and plays an\nessential role in elucidating various physical phenomena. The traditional QGT,\ndefined only for pure states, has limited applicability in realistic scenarios\nwhere mixed states are common. To address this limitation, we generalize the\ndefinition of the QGT to mixed states using the purification bundle and the\ncovariant derivative. Notably, our proposed definition reduces to the\ntraditional QGT when mixed states approach pure states. In our framework, the\nreal and imaginary parts of this generalized QGT correspond to the Bures metric\nand the mean gauge curvature, respectively, endowing it with a broad range of\npotential applications. Additionally, using our proposed mixed-state QGT\n(MSQGT), we derive the geodesic equation applicable to mixed states. This work\nestablishes a unified framework for the geometric analysis of both pure and\nmixed states, thereby deepening our understanding of the geometric properties\nof quantum states.",
    "pdf_url": "http://arxiv.org/pdf/2506.00347v1",
    "published": "2025-05-31T02:15:07+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00346v1",
    "title": "Full- and low-rank exponential midpoint schemes for forward and adjoint Lindblad equations",
    "authors": [
      "Hao Chen",
      "Alfio Borzi"
    ],
    "abstract": "The Lindblad equation is a widely used quantum master equation to model the\ndynamical evolution of open quantum systems whose states are described by\ndensity matrices. This equation is also a fundamental building block to design\noptimal control functions. In this paper we develop full- and low-rank\nexponential midpoint integrators for solving both the forward and adjoint\nLindblad equations. These schemes are applicable to optimize-then-discretize\napproaches for optimal control of open quantum systems. We show that the\nproposed schemes preserve positivity and trace unconditionally. Furthermore,\nconvergence of these numerical schemes is proved theoretically and verified\nnumerically.",
    "pdf_url": "http://arxiv.org/pdf/2506.00346v1",
    "published": "2025-05-31T02:15:00+00:00",
    "categories": [
      "quant-ph",
      "cs.NA",
      "math.NA",
      "math.OC"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00345v1",
    "title": "Strain Enhanced Spin Readout Contrast in Silicon Carbide Membranes",
    "authors": [
      "Haibo Hu",
      "Guodong Bian",
      "Ailun Yi",
      "Chunhui Jiang",
      "Junhua Tan",
      "Qi Luo",
      "Bo Liang",
      "Zhengtong Liu",
      "Xinfang Nie",
      "Dawei Lu",
      "Shumin Xiao",
      "Xin Ou",
      "Adam Gali",
      "Yu Zhou",
      "Qinghai Song"
    ],
    "abstract": "Quantum defects in solids have emerged as a transformative platform for\nadvancing quantum technologies. A key requirement for these applications is\nachieving high-fidelity single-spin readout, particularly at room temperature\nfor quantum biosensing. Here, we demonstrate through ab initio simulations of a\nprimary quantum defect in 4H silicon carbide that strain is an effective\ncontrol parameter for significantly enhancing readout contrast. We validate\nthis principle experimentally by inducing local strain in silicon\ncarbide-on-insulator membranes, achieving a readout contrast exceeding 60%\nwhile preserving the favorable coherence properties of single spins. Our\nfindings establish strain engineering as a powerful and versatile strategy for\noptimizing coherent spin-photon interfaces in solid-state quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00345v1",
    "published": "2025-05-31T02:13:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00344v1",
    "title": "Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs",
    "authors": [
      "Sungjae Lee",
      "Hoyoung Kim",
      "Jeongyeon Hwang",
      "Eunhyeok Park",
      "Jungseul Ok"
    ],
    "abstract": "Scaling test-time computation--generating and analyzing multiple or\nsequential outputs for a single input--has become a promising strategy for\nimproving the reliability and quality of large language models (LLMs), as\nevidenced by advances in uncertainty quantification and multi-step reasoning. A\nkey shared component is semantic clustering, which groups outputs that differ\nin form but convey the same meaning. Semantic clustering enables estimation of\nthe distribution over the semantics of outputs and helps avoid redundant\nexploration of reasoning paths. However, existing approaches typically rely on\nexternal models, which introduce substantial computational overhead and often\nfail to capture context-aware semantics. We propose Latent Semantic Clustering\n(LSC), a lightweight and context-sensitive method that leverages the generator\nLLM's internal hidden states for clustering, eliminating the need for external\nmodels. Our extensive experiment across various LLMs and datasets shows that\nLSC significantly improves the computational efficiency of test-time scaling\nwhile maintaining or exceeding the performance of existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00344v1",
    "published": "2025-05-31T02:08:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00343v1",
    "title": "The iNaturalist Sounds Dataset",
    "authors": [
      "Mustafa Chasmai",
      "Alexander Shepard",
      "Subhransu Maji",
      "Grant Van Horn"
    ],
    "abstract": "We present the iNaturalist Sounds Dataset (iNatSounds), a collection of\n230,000 audio files capturing sounds from over 5,500 species, contributed by\nmore than 27,000 recordists worldwide. The dataset encompasses sounds from\nbirds, mammals, insects, reptiles, and amphibians, with audio and species\nlabels derived from observations submitted to iNaturalist, a global citizen\nscience platform. Each recording in the dataset varies in length and includes a\nsingle species annotation. We benchmark multiple backbone architectures,\ncomparing multiclass classification objectives with multilabel objectives.\nDespite weak labeling, we demonstrate that iNatSounds serves as a useful\npretraining resource by benchmarking it on strongly labeled downstream\nevaluation datasets. The dataset is available as a single, freely accessible\narchive, promoting accessibility and research in this important domain. We\nenvision models trained on this data powering next-generation public engagement\napplications, and assisting biologists, ecologists, and land use managers in\nprocessing large audio collections, thereby contributing to the understanding\nof species compositions in diverse soundscapes.",
    "pdf_url": "http://arxiv.org/pdf/2506.00343v1",
    "published": "2025-05-31T02:07:37+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.00342v1",
    "title": "Influence of a magnetic field on the frequency of a laser stabilized to molecular iodine",
    "authors": [
      "Jonathan Gillot",
      "Joannes Barbarat",
      "Charles Philippe",
      "Hector Alvarez-Martinez",
      "Rodolphe Letargat",
      "Ouali Acef"
    ],
    "abstract": "We report on the effect of a weak magnetic field applied on an iodine cell\nused to frequency stabilize a laser. A 1.5$~\\mu$m laser is frequency tripled in\norder to excite the molecular transitions at 0.51$~\\mu$m and frequency locked\non a hyperfine line. With this frequency reference, we report short-term\nstability about $3\\,\\times\\,10^{-14}~\\tau^{-1/2}$, with a minimum value of\n$4\\,\\times\\,10^{-15}$ at 200~s. The lower part of $10^{-15}$ frequency\nstability domain is reached, in our case, only by adding an efficient magnetic\nshield around the sealed quartz iodine cell. In order to quantify the Zeeman\neffect, we applied magnetic fields of several $\\,\\times\\,10^{-4}$~T on the cell\ncontaining the iodine vapour. The Zeeman effect affects the lineshape\ntransition in such a way that we observe a modification of the laser frequency.\nWe have measured this linear Zeeman shift at $(1062\\pm6)\\,\\times\\,10^{4}$~Hz/T\nfor the $a1$ hyperfine component of the R(34)~44-0 transition, near 514~nm by\napplying a magnetic field along the cell. Thus, in case of uncontrolled\nmagnetic fields of an order of magnitude of 1$\\,\\times\\,10^{-4}$~T, the\nfrequency stability is limited in the upper of the $10^{-14}$ domain.",
    "pdf_url": "http://arxiv.org/pdf/2506.00342v1",
    "published": "2025-05-31T02:05:43+00:00",
    "categories": [
      "physics.atom-ph",
      "physics.optics"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00341v1",
    "title": "Chaotic dynamics of Bose-Einstein condensates in a tilted optical lattice",
    "authors": [
      "C. Selvaraju",
      "S. Sabari",
      "O. T. Lekeufack",
      "F. Kenmogne",
      "N. Athavan"
    ],
    "abstract": "This study investigates the emergence of chaotic dynamics in Bose-Einstein\ncondensates (BECs) subjected to both alternating (AC) and constant (DC)\ncomponents of the interaction strength, modeled through the scattering length.\nWe systematically explore how the interplay of AC and DC nonlinearities affect\nthe dynamical evolution of the condensate under a tilted optical lattice\npotential. Various types of chaos are identified across different parametric\nregimes, with numerical simulations revealing a clear distinction between\nregular and chaotic domains. The width of the regular domains is quantified,\nand the influence of AC and DC components in promoting stochastic behavior is\nhighlighted. Lyapunov exponents, Poincar\\'e sections, and other chaos\nindicators then confirm the transition to chaotic dynamics, in agreement with\nanalytical expectations. A qualitative conjecture is proposed for the role of\nthese interactions in BEC stabilization. Our findings offer insights into the\ndynamic control of BECs, with potential applications in quantum simulation and\ncoherent matter-wave engineering, in line with entanglement and quantum\ntransport, that are crucial for developing robust and reliable quantum\ntechnologies.",
    "pdf_url": "http://arxiv.org/pdf/2506.00341v1",
    "published": "2025-05-31T02:02:06+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.quant-gas"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00340v2",
    "title": "Bayesian inference of the magnetic field and chemical potential on holographic jet quenching in heavy-ion collisions",
    "authors": [
      "Liqiang Zhu",
      "Zhan Gao",
      "Weiyao Ke",
      "Hanzhong Zhang"
    ],
    "abstract": "Jet quenching is studied in a background magnetic field and a finite baryon\nchemical potential. The production of energetic partons is calculated using the\nnext-to-leading order (NLO) perturbative Quantum Chromodynamics (pQCD) parton\nmodel, while the parton energy loss formula is obtained from the AdS/CFT\ncorrespondence incorporating the magnetic field and baryon chemical potential\neffects. Using Bayesian inference, we systemically compare the theoretical\ncalculations with experimental data for the nuclear modification factor\n$R_{AA}$ of the large transverse momentum hadrons in different-centrality\nnucleus-nucleus collisions at 0.2, 2.76 and 5.02 TeV, respectively. The form of\nthe holographic energy loss leads to a strong negative correlation between the\nmagnetic field and the chemical potential after the calibration, from which we\ndiscussed the sensitivity of jet quenching phenomena to magnetic field and\nbaryon chemical potential.",
    "pdf_url": "http://arxiv.org/pdf/2506.00340v2",
    "published": "2025-05-31T02:00:55+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00339v3",
    "title": "Comparing effective temperatures in standard and Tsallis distributions from transverse momentum spectra in small collision systems",
    "authors": [
      "Peng-Cheng Zhang",
      "Pei-Pin Yang",
      "Ting-Ting Duan",
      "Hailong Zhu",
      "Fu-Hu Liu",
      "Khusniddin K. Olimov"
    ],
    "abstract": "The transverse momentum ($p_T$) spectra of identified light charged hadrons,\nspecifically bosons ($\\pi^{\\pm}$ and $K^{\\pm}$) as well as fermions [$p(\\bar\np)$], produced in small collision systems, namely deuteron-gold (d+Au) and\nproton-proton (p+p) collisions at the top energy of the Relativistic Heavy Ion\nCollider (RHIC) with a center-of-mass energy of $\\sqrt{s_{NN}}=200$ GeV, are\ninvestigated in this paper. In present study, d+Au collisions are categorized\ninto three centrality classes: central (0--20\\%), semi-central (20--40\\%), and\nperipheral (40--100\\%) collisions. Various types of distributions, including\nstandard [Bose-Einstein (Fermi-Dirac) and Boltzmann] and Tsallis distributions,\nare employed to fit the same $p_T$ spectra to derive different effective\ntemperatures denoted as $T_{eff}$. The results indicate that $T_{eff}$ values\nobtained from Bose-Einstein, Boltzmann, Fermi-Dirac, and Tsallis distributions\nexhibit systematically a decreasing trend. Meanwhile, these $T_{eff}$ values\nalso show a decreasing trend with a decrease in collision centrality.\nFurthermore, based on the spectra of given particles, a perfect linear\nrelationship is observed between different pairwise combinations of $T_{eff}$\nderived from both Boltzmann and Bose-Einstein (Fermi-Dirac) distributions as\nwell as between Tsallis and Bose-Einstein (Fermi-Dirac) distributions.",
    "pdf_url": "http://arxiv.org/pdf/2506.00339v3",
    "published": "2025-05-31T02:00:53+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2507.19491v1",
    "title": "Exploring the Alignment of Perceived and Measured Sleep Quality with Working Memory using Consumer Wearables",
    "authors": [
      "Peter Neigel",
      "David Antony Selby",
      "Shota Arai",
      "Benjamin Tag",
      "Niels van Berkel",
      "Sebastian Vollmer",
      "Andrew Vargo",
      "Koichi Kise"
    ],
    "abstract": "Wearable devices offer detailed sleep-tracking data. However, whether this\ninformation enhances our understanding of sleep or simply quantifies\nalready-known patterns remains unclear. This work explores the relationship\nbetween subjective sleep self-assessments and sensor data from an Oura ring\nover 4--8 weeks in-the-wild. 29 participants rated their sleep quality daily\ncompared to the previous night and completed a working memory task. Our\nfindings reveal that differences in REM sleep, nocturnal heart rate, N-Back\nscores, and bedtimes highly predict sleep self-assessment in significance and\neffect size. For N-Back performance, REM sleep duration, prior night's REM\nsleep, and sleep self-assessment are the strongest predictors. We demonstrate\nthat self-report sensitivity towards sleep markers differs among participants.\nWe identify three groups, highlighting that sleep trackers provide more\ninformation gain for some users than others. Additionally, we make all\nexperiment data publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2507.19491v1",
    "published": "2025-05-31T01:56:21+00:00",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00338v1",
    "title": "OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning",
    "authors": [
      "Yifan Peng",
      "Shakeel Muhammad",
      "Yui Sudo",
      "William Chen",
      "Jinchuan Tian",
      "Chyi-Jiunn Lin",
      "Shinji Watanabe"
    ],
    "abstract": "The Open Whisper-style Speech Models (OWSM) project has developed a series of\nfully open speech foundation models using academic-scale resources, but their\ntraining data remains insufficient. This work enhances OWSM by integrating\nYODAS, a large-scale web-crawled dataset with a Creative Commons license.\nHowever, incorporating YODAS is nontrivial due to its wild nature, which\nintroduces challenges such as incorrect language labels and audio-text\nmisalignments. To address this, we develop a scalable data-cleaning pipeline\nusing public toolkits, yielding a dataset with 166,000 hours of speech across\n75 languages. Our new series of OWSM v4 models, trained on this curated dataset\nalongside existing OWSM data, significantly outperform previous versions on\nmultilingual benchmarks. Our models even match or surpass frontier industrial\nmodels like Whisper and MMS in multiple scenarios. We will publicly release the\ncleaned YODAS data, pre-trained models, and all associated scripts via the\nESPnet toolkit.",
    "pdf_url": "http://arxiv.org/pdf/2506.00338v1",
    "published": "2025-05-31T01:44:44+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00337v1",
    "title": "Channel-Imposed Fusion: A Simple yet Effective Method for Medical Time Series Classification",
    "authors": [
      "Ming Hu",
      "Jianfu Yin",
      "Mingyu Dou",
      "Yuqi Wang",
      "Ruochen Dang",
      "Siyi Liang",
      "Cong Hu",
      "Yao Wang",
      "Bingliang Hu",
      "Quan Wang"
    ],
    "abstract": "The automatic classification of medical time series signals, such as\nelectroencephalogram (EEG) and electrocardiogram (ECG), plays a pivotal role in\nclinical decision support and early detection of diseases. Although Transformer\nbased models have achieved notable performance by implicitly modeling temporal\ndependencies through self-attention mechanisms, their inherently complex\narchitectures and opaque reasoning processes undermine their trustworthiness in\nhigh stakes clinical settings. In response to these limitations, this study\nshifts focus toward a modeling paradigm that emphasizes structural\ntransparency, aligning more closely with the intrinsic characteristics of\nmedical data. We propose a novel method, Channel Imposed Fusion (CIF), which\nenhances the signal-to-noise ratio through cross-channel information fusion,\neffectively reduces redundancy, and improves classification performance.\nFurthermore, we integrate CIF with the Temporal Convolutional Network (TCN),\nknown for its structural simplicity and controllable receptive field, to\nconstruct an efficient and explicit classification framework. Experimental\nresults on multiple publicly available EEG and ECG datasets demonstrate that\nthe proposed method not only outperforms existing state-of-the-art (SOTA)\napproaches in terms of various classification metrics, but also significantly\nenhances the transparency of the classification process, offering a novel\nperspective for medical time series classification.",
    "pdf_url": "http://arxiv.org/pdf/2506.00337v1",
    "published": "2025-05-31T01:44:30+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.12058v1",
    "title": "Revisiting Taxicab Apollonius Circles",
    "authors": [
      "Kevin P. Thompson"
    ],
    "abstract": "The existence of excircles and an Apollonius circle for a triangle in taxicab\ngeometry are connected to the concept of inscribed triangles.",
    "pdf_url": "http://arxiv.org/pdf/2506.12058v1",
    "published": "2025-05-31T01:33:09+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2506.00336v1",
    "title": "Structured Column Subset Selection for Bayesian Optimal Experimental Design",
    "authors": [
      "Hugo Díaz",
      "Arvind K. Saibaba",
      "Srinivas Eswar",
      "Vishwas Rao",
      "Zichao Wendy Di"
    ],
    "abstract": "We consider optimal experimental design (OED) for Bayesian inverse problems,\nwhere the experimental design variables have a certain multiway structure.\nGiven $d$ different experimental variables with $m_i$ choices per design\nvariable $1 \\le i\\le d$, the goal is to select $k_i \\le m_i$ experiments per\ndesign variable. Previous work has related OED to the column subset selection\nproblem by mapping the design variables to the columns of a matrix\n$\\mathbf{A}$. However, this approach is applicable only to the case $d=1$ in\nwhich the columns can be selected independently. We develop an extension to the\ncase where the design variables have a multi-way structure. Our approach is to\nmap the matrix $\\mathbf{A}$ to a tensor and perform column subset selection on\nmode unfoldings of the tensor. We develop an algorithmic framework with three\ndifferent algorithmic templates, and randomized variants of these algorithms.\nWe analyze the computational cost of all the proposed algorithms and also\ndevelop greedy versions to facilitate comparisons. Numerical experiments on\nfour different applications -- time-dependent inverse problems, seismic\ntomography, X-ray tomography, and flow reconstruction -- demonstrate the\neffectiveness and scalability of our methods for structured experimental design\nin Bayesian inverse problems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00336v1",
    "published": "2025-05-31T01:29:50+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "8F15 (Primary), 58F17, 53C35 (Secondary)"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.00335v2",
    "title": "Recover Experimental Data with Selection Bias using Counterfactual Logic",
    "authors": [
      "Jingyang He",
      "Shuai Wang",
      "Ang Li"
    ],
    "abstract": "Selection bias, arising from the systematic inclusion or exclusion of certain\nsamples, poses a significant challenge to the validity of causal inference.\nWhile Bareinboim et al. introduced methods for recovering unbiased\nobservational and interventional distributions from biased data using partial\nexternal information, the complexity of the backdoor adjustment and the\nmethod's strong reliance on observational data limit its applicability in many\npractical settings. In this paper, we formally discover the recoverability of\n$P(Y^*_{x^*})$ under selection bias with experimental data. By explicitly\nconstructing counterfactual worlds via Structural Causal Models (SCMs), we\nanalyze how selection mechanisms in the observational world propagate to the\ncounterfactual domain. We derive a complete set of graphical and theoretical\ncriteria to determine that the experimental distribution remain unaffected by\nselection bias. Furthermore, we propose principled methods for leveraging\npartially unbiased observational data to recover $P(Y^*_{x^*})$ from biased\nexperimental datasets. Simulation studies replicating realistic research\nscenarios demonstrate the practical utility of our approach, offering concrete\nguidance for mitigating selection bias in applied causal inference.",
    "pdf_url": "http://arxiv.org/pdf/2506.00335v2",
    "published": "2025-05-31T01:23:39+00:00",
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.00334v1",
    "title": "Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models",
    "authors": [
      "Gerard Christopher Yeo",
      "Kokil Jaidka"
    ],
    "abstract": "Datasets used for emotion recognition tasks typically contain overt cues that\ncan be used in predicting the emotions expressed in a text. However, one\nchallenge is that texts sometimes contain covert contextual cues that are rich\nin affective semantics, which warrant higher-order reasoning abilities to infer\nemotional states, not simply the emotions conveyed. This study advances beyond\nsurface-level perceptual features to investigate how large language models\n(LLMs) reason about others' emotional states using contextual information,\nwithin a Theory-of-Mind (ToM) framework. Grounded in Cognitive Appraisal\nTheory, we curate a specialized ToM evaluation dataset1 to assess both forward\nreasoning - from context to emotion- and backward reasoning - from emotion to\ninferred context. We showed that LLMs can reason to a certain extent, although\nthey are poor at associating situational outcomes and appraisals with specific\nemotions. Our work highlights the need for psychological theories in the\ntraining and evaluation of LLMs in the context of emotion reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2506.00334v1",
    "published": "2025-05-31T01:18:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00333v1",
    "title": "Test-time Vocabulary Adaptation for Language-driven Object Detection",
    "authors": [
      "Mingxuan Liu",
      "Tyler L. Hayes",
      "Massimiliano Mancini",
      "Elisa Ricci",
      "Riccardo Volpi",
      "Gabriela Csurka"
    ],
    "abstract": "Open-vocabulary object detection models allow users to freely specify a class\nvocabulary in natural language at test time, guiding the detection of desired\nobjects. However, vocabularies can be overly broad or even mis-specified,\nhampering the overall performance of the detector. In this work, we propose a\nplug-and-play Vocabulary Adapter (VocAda) to refine the user-defined\nvocabulary, automatically tailoring it to categories that are relevant for a\ngiven image. VocAda does not require any training, it operates at inference\ntime in three steps: i) it uses an image captionner to describe visible\nobjects, ii) it parses nouns from those captions, and iii) it selects relevant\nclasses from the user-defined vocabulary, discarding irrelevant ones.\nExperiments on COCO and Objects365 with three state-of-the-art detectors show\nthat VocAda consistently improves performance, proving its versatility. The\ncode is open source.",
    "pdf_url": "http://arxiv.org/pdf/2506.00333v1",
    "published": "2025-05-31T01:15:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.06330v1",
    "title": "ExplainBench: A Benchmark Framework for Local Model Explanations in Fairness-Critical Applications",
    "authors": [
      "James Afful"
    ],
    "abstract": "As machine learning systems are increasingly deployed in high-stakes domains\nsuch as criminal justice, finance, and healthcare, the demand for interpretable\nand trustworthy models has intensified. Despite the proliferation of local\nexplanation techniques, including SHAP, LIME, and counterfactual methods, there\nexists no standardized, reproducible framework for their comparative\nevaluation, particularly in fairness-sensitive settings.\n  We introduce ExplainBench, an open-source benchmarking suite for systematic\nevaluation of local model explanations across ethically consequential datasets.\nExplainBench provides unified wrappers for popular explanation algorithms,\nintegrates end-to-end pipelines for model training and explanation generation,\nand supports evaluation via fidelity, sparsity, and robustness metrics. The\nframework includes a Streamlit-based graphical interface for interactive\nexploration and is packaged as a Python module for seamless integration into\nresearch workflows.\n  We demonstrate ExplainBench on datasets commonly used in fairness research,\nsuch as COMPAS, UCI Adult Income, and LendingClub, and showcase how different\nexplanation methods behave under a shared experimental protocol. By enabling\nreproducible, comparative analysis of local explanations, ExplainBench advances\nthe methodological foundations of interpretable machine learning and\nfacilitates accountability in real-world AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.06330v1",
    "published": "2025-05-31T01:12:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00332v2",
    "title": "Disentangling Codemixing in Chats: The NUS ABC Codemixed Corpus",
    "authors": [
      "Svetlana Churina",
      "Akshat Gupta",
      "Insyirah Mujtahid",
      "Kokil Jaidka"
    ],
    "abstract": "Code-mixing involves the seamless integration of linguistic elements from\nmultiple languages within a single discourse, reflecting natural multilingual\ncommunication patterns. Despite its prominence in informal interactions such as\nsocial media, chat messages and instant-messaging exchanges, there has been a\nlack of publicly available corpora that are author-labeled and suitable for\nmodeling human conversations and relationships. This study introduces the first\nlabeled and general-purpose corpus for understanding code-mixing in context\nwhile maintaining rigorous privacy and ethical standards. Our live project will\ncontinuously gather, verify, and integrate code-mixed messages into a\nstructured dataset released in JSON format, accompanied by detailed metadata\nand linguistic statistics. To date, it includes over 355,641 messages spanning\nvarious code-mixing patterns, with a primary focus on English, Mandarin, and\nother languages. We expect the Codemix Corpus to serve as a foundational\ndataset for research in computational linguistics, sociolinguistics, and NLP\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2506.00332v2",
    "published": "2025-05-31T01:09:04+00:00",
    "categories": [
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00331v1",
    "title": "TreeRare: Syntax Tree-Guided Retrieval and Reasoning for Knowledge-Intensive Question Answering",
    "authors": [
      "Boyi Zhang",
      "Zhuo Liu",
      "Hangfeng He"
    ],
    "abstract": "In real practice, questions are typically complex and knowledge-intensive,\nrequiring Large Language Models (LLMs) to recognize the multifaceted nature of\nthe question and reason across multiple information sources. Iterative and\nadaptive retrieval, where LLMs decide when and what to retrieve based on their\nreasoning, has been shown to be a promising approach to resolve complex,\nknowledge-intensive questions. However, the performance of such retrieval\nframeworks is limited by the accumulation of reasoning errors and misaligned\nretrieval results. To overcome these limitations, we propose TreeRare (Syntax\nTree-Guided Retrieval and Reasoning), a framework that utilizes syntax trees to\nguide information retrieval and reasoning for question answering. Following the\nprinciple of compositionality, TreeRare traverses the syntax tree in a\nbottom-up fashion, and in each node, it generates subcomponent-based queries\nand retrieves relevant passages to resolve localized uncertainty. A\nsubcomponent question answering module then synthesizes these passages into\nconcise, context-aware evidence. Finally, TreeRare aggregates the evidence\nacross the tree to form a final answer. Experiments across five question\nanswering datasets involving ambiguous or multi-hop reasoning demonstrate that\nTreeRare achieves substantial improvements over existing state-of-the-art\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00331v1",
    "published": "2025-05-31T01:07:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00330v1",
    "title": "Accurate Estimation of Mutual Information in High Dimensional Data",
    "authors": [
      "Eslam Abdelaleem",
      "K. Michael Martini",
      "Ilya Nemenman"
    ],
    "abstract": "Mutual information (MI) is a measure of statistical dependencies between two\nvariables, widely used in data analysis. Thus, accurate methods for estimating\nMI from empirical data are crucial. Such estimation is a hard problem, and\nthere are provably no estimators that are universally good for finite datasets.\nCommon estimators struggle with high-dimensional data, which is a staple of\nmodern experiments. Recently, promising machine learning-based MI estimation\nmethods have emerged. Yet it remains unclear if and when they produce accurate\nresults, depending on dataset sizes, statistical structure of the data, and\nhyperparameters of the estimators, such as the embedding dimensionality or the\nduration of training. There are also no accepted tests to signal when the\nestimators are inaccurate. Here, we systematically explore these gaps. We\npropose and validate a protocol for MI estimation that includes explicit checks\nensuring reliability and statistical consistency. Contrary to accepted wisdom,\nwe demonstrate that reliable MI estimation is achievable even with severely\nundersampled, high-dimensional datasets, provided these data admit accurate\nlow-dimensional representations. These findings broaden the potential use of\nmachine learning-based MI estimation methods in real-world data analysis and\nprovide new insights into when and why modern high-dimensional, self-supervised\nalgorithms perform effectively.",
    "pdf_url": "http://arxiv.org/pdf/2506.00330v1",
    "published": "2025-05-31T01:06:18+00:00",
    "categories": [
      "physics.data-an",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "physics.data-an"
  },
  {
    "id": "http://arxiv.org/abs/2506.00329v1",
    "title": "Foresight: Adaptive Layer Reuse for Accelerated and High-Quality Text-to-Video Generation",
    "authors": [
      "Muhammad Adnan",
      "Nithesh Kurella",
      "Akhil Arunkumar",
      "Prashant J. Nair"
    ],
    "abstract": "Diffusion Transformers (DiTs) achieve state-of-the-art results in\ntext-to-image, text-to-video generation, and editing. However, their large\nmodel size and the quadratic cost of spatial-temporal attention over multiple\ndenoising steps make video generation computationally expensive. Static caching\nmitigates this by reusing features across fixed steps but fails to adapt to\ngeneration dynamics, leading to suboptimal trade-offs between speed and\nquality.\n  We propose Foresight, an adaptive layer-reuse technique that reduces\ncomputational redundancy across denoising steps while preserving baseline\nperformance. Foresight dynamically identifies and reuses DiT block outputs for\nall layers across steps, adapting to generation parameters such as resolution\nand denoising schedules to optimize efficiency. Applied to OpenSora, Latte, and\nCogVideoX, Foresight achieves up to 1.63x end-to-end speedup, while maintaining\nvideo quality. The source code of Foresight is available at\n\\texttt{https://github.com/STAR-Laboratory/foresight}.",
    "pdf_url": "http://arxiv.org/pdf/2506.00329v1",
    "published": "2025-05-31T00:52:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00328v3",
    "title": "BASIL: Best-Action Symbolic Interpretable Learning for Evolving Compact RL Policies",
    "authors": [
      "Kourosh Shahnazari",
      "Seyed Moein Ayyoubzadeh",
      "Mohammadali Keshtparvar"
    ],
    "abstract": "The quest for interpretable reinforcement learning is a grand challenge for\nthe deployment of autonomous decision-making systems in safety-critical\napplications. Modern deep reinforcement learning approaches, while powerful,\ntend to produce opaque policies that compromise verification, reduce\ntransparency, and impede human oversight. To address this, we introduce BASIL\n(Best-Action Symbolic Interpretable Learning), a systematic approach for\ngenerating symbolic, rule-based policies via online evolutionary search with\nquality-diversity (QD) optimization. BASIL represents policies as ordered lists\nof symbolic predicates over state variables, ensuring full interpretability and\ntractable policy complexity. By using a QD archive, the methodology in the\nproposed study encourages behavioral and structural diversity between\ntop-performing solutions, while a complexity-aware fitness encourages the\nsynthesis of compact representations. The evolutionary system supports the use\nof exact constraints for rule count and system adaptability for balancing\ntransparency with expressiveness. Empirical comparisons with three benchmark\ntasks CartPole-v1, MountainCar-v0, and Acrobot-v1 show that BASIL consistently\nsynthesizes interpretable controllers with compact representations comparable\nto deep reinforcement learning baselines. Herein, this article introduces a new\ninterpretable policy synthesis method that combines symbolic expressiveness,\nevolutionary diversity, and online learning through a unifying framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.00328v3",
    "published": "2025-05-31T00:47:24+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00327v1",
    "title": "Latent Guidance in Diffusion Models for Perceptual Evaluations",
    "authors": [
      "Shreshth Saini",
      "Ru-Ling Liao",
      "Yan Ye",
      "Alan C. Bovik"
    ],
    "abstract": "Despite recent advancements in latent diffusion models that generate\nhigh-dimensional image data and perform various downstream tasks, there has\nbeen little exploration into perceptual consistency within these models on the\ntask of No-Reference Image Quality Assessment (NR-IQA). In this paper, we\nhypothesize that latent diffusion models implicitly exhibit perceptually\nconsistent local regions within the data manifold. We leverage this insight to\nguide on-manifold sampling using perceptual features and input measurements.\nSpecifically, we propose Perceptual Manifold Guidance (PMG), an algorithm that\nutilizes pretrained latent diffusion models and perceptual quality features to\nobtain perceptually consistent multi-scale and multi-timestep feature maps from\nthe denoising U-Net. We empirically demonstrate that these hyperfeatures\nexhibit high correlation with human perception in IQA tasks. Our method can be\napplied to any existing pretrained latent diffusion model and is\nstraightforward to integrate. To the best of our knowledge, this paper is the\nfirst work on guiding diffusion model with perceptual features for NR-IQA.\nExtensive experiments on IQA datasets show that our method, LGDM, achieves\nstate-of-the-art performance, underscoring the superior generalization\ncapabilities of diffusion models for NR-IQA tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00327v1",
    "published": "2025-05-31T00:41:59+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00326v1",
    "title": "Music-driven Robot Swarm Painting",
    "authors": [
      "Jingde Cheng",
      "Gennaro Notomista"
    ],
    "abstract": "This paper proposes a novel control framework for robotic swarms capable of\nturning a musical input into a painting. The approach connects the two artistic\ndomains, music and painting, leveraging their respective connections to\nfundamental emotions. The robotic units of the swarm are controlled in a\ncoordinated fashion using a heterogeneous coverage policy to control the motion\nof the robots which continuously release traces of color in the environment.\nThe results of extensive simulations performed starting from different musical\ninputs and with different color equipments are reported. Finally, the proposed\nframework has been implemented on real robots equipped with LED lights and\ncapable of light-painting.",
    "pdf_url": "http://arxiv.org/pdf/2506.00326v1",
    "published": "2025-05-31T00:41:10+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.00325v1",
    "title": "Towards Effective and Efficient Adversarial Defense with Diffusion Models for Robust Visual Tracking",
    "authors": [
      "Long Xu",
      "Peng Gao",
      "Wen-Jia Tang",
      "Fei Wang",
      "Ru-Yue Yuan"
    ],
    "abstract": "Although deep learning-based visual tracking methods have made significant\nprogress, they exhibit vulnerabilities when facing carefully designed\nadversarial attacks, which can lead to a sharp decline in tracking performance.\nTo address this issue, this paper proposes for the first time a novel\nadversarial defense method based on denoise diffusion probabilistic models,\ntermed DiffDf, aimed at effectively improving the robustness of existing visual\ntracking methods against adversarial attacks. DiffDf establishes a multi-scale\ndefense mechanism by combining pixel-level reconstruction loss, semantic\nconsistency loss, and structural similarity loss, effectively suppressing\nadversarial perturbations through a gradual denoising process. Extensive\nexperimental results on several mainstream datasets show that the DiffDf method\ndemonstrates excellent generalization performance for trackers with different\narchitectures, significantly improving various evaluation metrics while\nachieving real-time inference speeds of over 30 FPS, showcasing outstanding\ndefense performance and efficiency. Codes are available at\nhttps://github.com/pgao-lab/DiffDf.",
    "pdf_url": "http://arxiv.org/pdf/2506.00325v1",
    "published": "2025-05-31T00:37:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00324v1",
    "title": "Improving Optical Flow and Stereo Depth Estimation by Leveraging Uncertainty-Based Learning Difficulties",
    "authors": [
      "Jisoo Jeong",
      "Hong Cai",
      "Jamie Menjay Lin",
      "Fatih Porikli"
    ],
    "abstract": "Conventional training for optical flow and stereo depth models typically\nemploys a uniform loss function across all pixels. However, this\none-size-fits-all approach often overlooks the significant variations in\nlearning difficulty among individual pixels and contextual regions. This paper\ninvestigates the uncertainty-based confidence maps which capture these\nspatially varying learning difficulties and introduces tailored solutions to\naddress them. We first present the Difficulty Balancing (DB) loss, which\nutilizes an error-based confidence measure to encourage the network to focus\nmore on challenging pixels and regions. Moreover, we identify that some\ndifficult pixels and regions are affected by occlusions, resulting from the\ninherently ill-posed matching problem in the absence of real correspondences.\nTo address this, we propose the Occlusion Avoiding (OA) loss, designed to guide\nthe network into cycle consistency-based confident regions, where feature\nmatching is more reliable. By combining the DB and OA losses, we effectively\nmanage various types of challenging pixels and regions during training.\nExperiments on both optical flow and stereo depth tasks consistently\ndemonstrate significant performance improvements when applying our proposed\ncombination of the DB and OA losses.",
    "pdf_url": "http://arxiv.org/pdf/2506.00324v1",
    "published": "2025-05-31T00:37:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00323v1",
    "title": "Birational geometry of weighted complete intersections of type $(12, 14)$ in $\\mathbb{P} (1, 2, 3, 4, 7, 11)$",
    "authors": [
      "Takuzo Okada"
    ],
    "abstract": "We show that any quasismooth Fano threefold weighted complete intersections\nof type $(12, 14)$ in $\\mathbb{P} (1, 2, 3, 4, 7, 11)$ is birationally solid.",
    "pdf_url": "http://arxiv.org/pdf/2506.00323v1",
    "published": "2025-05-31T00:28:30+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00322v1",
    "title": "dpmm: Differentially Private Marginal Models, a Library for Synthetic Tabular Data Generation",
    "authors": [
      "Sofiane Mahiou",
      "Amir Dizche",
      "Reza Nazari",
      "Xinmin Wu",
      "Ralph Abbey",
      "Jorge Silva",
      "Georgi Ganev"
    ],
    "abstract": "We propose dpmm, an open-source library for synthetic data generation with\nDifferentially Private (DP) guarantees. It includes three popular marginal\nmodels -- PrivBayes, MST, and AIM -- that achieve superior utility and offer\nricher functionality compared to alternative implementations. Additionally, we\nadopt best practices to provide end-to-end DP guarantees and address well-known\nDP-related vulnerabilities. Our goal is to accommodate a wide audience with\neasy-to-install, highly customizable, and robust model implementations.\n  Our codebase is available from https://github.com/sassoftware/dpmm.",
    "pdf_url": "http://arxiv.org/pdf/2506.00322v1",
    "published": "2025-05-31T00:23:05+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02035v1",
    "title": "Asymmetry by Design: Boosting Cyber Defenders with Differential Access to AI",
    "authors": [
      "Shaun Ee",
      "Chris Covino",
      "Cara Labrador",
      "Christina Krawec",
      "Jam Kraprayoon",
      "Joe O'Brien"
    ],
    "abstract": "As AI-enabled cyber capabilities become more advanced, we propose\n\"differential access\" as a strategy to tilt the cybersecurity balance toward\ndefense by shaping access to these capabilities. We introduce three possible\napproaches that form a continuum, becoming progressively more restrictive for\nhigher-risk capabilities: Promote Access, Manage Access, and Deny by Default.\nHowever, a key principle across all approaches is the need to prioritize\ndefender access, even in the most restrictive scenarios, so that defenders can\nprepare for adversaries gaining access to similar capabilities. This report\nprovides a process to help frontier AI developers choose and implement one of\nthe three differential access approaches, including considerations based on a\nmodel's cyber capabilities, a defender's maturity and role, and strategic and\ntechnical implementation details. We also present four example schemes for\ndefenders to reference, demonstrating how differential access provides value\nacross various capability and defender levels, and suggest directions for\nfurther research.",
    "pdf_url": "http://arxiv.org/pdf/2506.02035v1",
    "published": "2025-05-31T00:20:22+00:00",
    "categories": [
      "cs.CR",
      "cs.CY",
      "K.4.1"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00321v1",
    "title": "QTP-Net: A Quantum Text Pre-training Network for Natural Language Processing",
    "authors": [
      "Ren-Xin Zhao"
    ],
    "abstract": "Natural Language Processing (NLP) faces challenges in the ability to quickly\nmodel polysemous words. The Grover's Algorithm (GA) is expected to solve this\nproblem but lacks adaptability. To address the above dilemma, a Quantum Text\nPre-training Network (QTP-Net) is proposed to improve the performance of NLP\ntasks. First, a Quantum Enhanced Pre-training Feature Embedding (QEPFE) is\ndeveloped to encode multiple meanings of words into quantum superposition\nstates and exploit adaptive GA to fast capture rich text features.\nSubsequently, the QEPFE is combined with the Enhanced Representation through\nkNowledge IntEgration (ERNIE), a pre-trained language model proposed by Baidu,\nto construct QTP-Net, which is evaluated on Sentiment Classification (SC) and\nWord Sense Disambiguation (WSD) tasks. Experiments show that in SC, the QTP-Net\nimproves the average accuracy by 0.024 and the F1 score by 0.029 on six\nbenchmark datasets, comprehensively outperforming both classical and\nquantum-inspired models. In WSD, it reaches 0.784 average F1 score, which is\n0.016 higher than the sub-optimal GlossBERT, and significantly leads on SE2,\nSE13, and SE15. QTP-Net provides a new solution for implicit semantic modeling\nin NLP and lays the foundation for future research on quantum-enhanced models.",
    "pdf_url": "http://arxiv.org/pdf/2506.00321v1",
    "published": "2025-05-31T00:17:35+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00320v1",
    "title": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents",
    "authors": [
      "Xiao Yu",
      "Baolin Peng",
      "Ruize Xu",
      "Michel Galley",
      "Hao Cheng",
      "Suman Nath",
      "Jianfeng Gao",
      "Zhou Yu"
    ],
    "abstract": "Recent progress in reasoning with large language models (LLMs), such as\nDeepSeek-R1, demonstrates impressive capabilities in domains like mathematics\nand coding, by exhibiting complex cognitive behaviors such as verification,\ngoal decomposition, and self-reflection. However, it is unclear what behavior\nis effective and what behavior is missing for long-horizon AI agents tasks. In\nthis work, we propose Dyna-Think, a thinking framework that integrates planning\nwith an internal world model with reasoning and acting to enhance AI agent\nperformance. To enable Dyna-Think, we propose Dyna-Think Imitation Learning\n(DIT) and Dyna-Think Dyna Training (DDT). To initialize a policy with\nDyna-Think, DIT reconstructs the thinking process of R1 to focus on performing\nworld model simulation relevant to the proposed (and planned) action, and\ntrains the policy using this reconstructed data. To enhance Dyna-Think, DDT\nuses a two-stage training process to first improve the agent's world modeling\nability via objectives such as state prediction or critique generation, and\nthen improve the agent's action via policy training. We evaluate our methods on\nOSWorld, and demonstrate that Dyna-Think improves the agent's in-domain and\nout-of-domain performance, achieving similar best-of-n performance compared to\nR1 while generating 2x less tokens on average. Our extensive empirical studies\nreveal that 1) using critique generation for world model training is effective\nto improve policy performance; and 2) AI agents with better performance\ncorrelate with better world modeling abilities. We believe our results suggest\na promising research direction to integrate world model simulation into AI\nagents to enhance their reasoning, planning, and acting capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.00320v1",
    "published": "2025-05-31T00:10:18+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00319v1",
    "title": "SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation",
    "authors": [
      "Yufei Tian",
      "Jiao Sun",
      "Nanyun Peng",
      "Zizhao Zhang"
    ],
    "abstract": "As language models evolve to tackle complex, multifaceted tasks, their\nevaluation must adapt to capture this intricacy. A granular, skill-specific\nunderstanding of model capabilities can empower researchers to make informed\nmodel development plans. In this paper, we introduce SkillVerse, an\nunsupervised tree-structured diagnosis framework for understanding model\nproficiency in specific abilities. With LLM as a judge, SkillVerse first\ncritiques the model responses, and then organizes them into a hierarchical\nstructure termed dendrogram. Given proficiency at arbitrary levels of\ngranularity, SkillVerse is flexible to produce insights of behaviors of modern\nlarge models. We also demonstrate its efficacy in two downstream tasks: 1)\nimproving model in-context learning by 25% using a tree-search algorithm to\nselect more informative few-shot demonstrations, and 2) accurately predicting\nnew model weaknesses with a 55% success rate, 22% higher than without\nSkillVerse.",
    "pdf_url": "http://arxiv.org/pdf/2506.00319v1",
    "published": "2025-05-31T00:08:59+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00318v1",
    "title": "Chain-of-Frames: Advancing Video Understanding in Multimodal LLMs via Frame-Aware Reasoning",
    "authors": [
      "Sara Ghazanfari",
      "Francesco Croce",
      "Nicolas Flammarion",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami",
      "Siddharth Garg"
    ],
    "abstract": "Recent work has shown that eliciting Large Language Models (LLMs) to generate\nreasoning traces in natural language before answering the user's request can\nsignificantly improve their performance across tasks. This approach has been\nextended to multimodal LLMs, where the models can produce chain-of-thoughts\n(CoT) about the content of input images and videos. In this work, we propose to\nobtain video LLMs whose reasoning steps are grounded in, and explicitly refer\nto, the relevant video frames. For this, we first create CoF-Data, a large\ndataset of diverse questions, answers, and corresponding frame-grounded\nreasoning traces about both natural and synthetic videos, spanning various\ntopics and tasks. Then, we fine-tune existing video LLMs on this\nchain-of-frames (CoF) data. Our approach is simple and self-contained, and,\nunlike existing approaches for video CoT, does not require auxiliary networks\nto select or caption relevant frames. We show that our models based on CoF are\nable to generate chain-of-thoughts that accurately refer to the key frames to\nanswer the given question. This, in turn, leads to improved performance across\nmultiple video understanding benchmarks, for example, surpassing leading video\nLLMs on Video-MME, MVBench, and VSI-Bench, and notably reducing the\nhallucination rate. Code available at\nhttps://github.com/SaraGhazanfari/CoF}{github.com/SaraGhazanfari/CoF.",
    "pdf_url": "http://arxiv.org/pdf/2506.00318v1",
    "published": "2025-05-31T00:08:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00317v2",
    "title": "Local Frames: Exploiting Inherited Origins to Bypass Content Blockers",
    "authors": [
      "Alisha Ukani",
      "Hamed Haddadi",
      "Alex C. Snoeren",
      "Peter Snyder"
    ],
    "abstract": "We present a study of how local frames (i.e., iframes loading content like\n\"about:blank\") are mishandled by a wide range of popular Web security and\nprivacy tools. As a result, users of these tools remain vulnerable to the very\nattack techniques against which they seek to protect themselves, including\nbrowser fingerprinting, cookie-based tracking, and data exfiltration. The tools\nwe study are vulnerable in different ways, but all share a root cause: legacy\nWeb functionality interacts with browser privacy boundaries in unexpected ways,\nleading to systemic vulnerabilities in tools developed, maintained, and\nrecommended by privacy experts and activists.\n  We consider four core capabilities supported by most privacy tools and\ndevelop tests to determine whether each can be evaded through the use of local\nframes. We apply our tests to six popular Web privacy and security tools --\nidentifying at least one vulnerability in each for a total of 19 -- and extract\ncommon patterns regarding their mishandling of local frames. Our measurement of\npopular websites finds that 56% employ local frames and that 73.7% of the\nrequests made by these local frames should be blocked by popular filter lists\nbut instead trigger the vulnerabilities we identify. From another perspective,\n14.3% of all sites that we crawl make requests that should be blocked inside of\nlocal frames. We disclosed these vulnerabilities to the tool authors and\ndiscuss both our experiences working with them to patch their products and the\nimplications of our findings for other privacy and security research.",
    "pdf_url": "http://arxiv.org/pdf/2506.00317v2",
    "published": "2025-05-31T00:07:24+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00316v1",
    "title": "Active Learning via Regression Beyond Realizability",
    "authors": [
      "Atul Ganju",
      "Shashaank Aiyer",
      "Ved Sriraman",
      "Karthik Sridharan"
    ],
    "abstract": "We present a new active learning framework for multiclass classification\nbased on surrogate risk minimization that operates beyond the standard\nrealizability assumption. Existing surrogate-based active learning algorithms\ncrucially rely on realizability$\\unicode{x2014}$the assumption that the optimal\nsurrogate predictor lies within the model class$\\unicode{x2014}$limiting their\napplicability in practical, misspecified settings. In this work we show that\nunder conditions significantly weaker than realizability, as long as the class\nof models considered is convex, one can still obtain a label and sample\ncomplexity comparable to prior work. Despite achieving similar rates, the\nalgorithmic approaches from prior works can be shown to fail in non-realizable\nsettings where our assumption is satisfied. Our epoch-based active learning\nalgorithm departs from prior methods by fitting a model from the full class to\nthe queried data in each epoch and returning an improper classifier obtained by\naggregating these models.",
    "pdf_url": "http://arxiv.org/pdf/2506.00316v1",
    "published": "2025-05-31T00:04:07+00:00",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00315v1",
    "title": "Power-of-Two (PoT) Weights in Large Language Models (LLMs)",
    "authors": [
      "Mahmoud Elgenedy"
    ],
    "abstract": "Complexity of Neural Networks is increasing rapidly due to the massive\nincrease in model parameters. Specifically, in Large Language Models (LLMs),\nthe number of model parameters has grown exponentially in the past few years,\nfor example, from 1.5 billion parameters in GPT2 to 175 billion in GPT3. This\nraises a significant challenge for implementation, especially for Edge devices\nwhere memory and processing power are very limited. In this work, we\ninvestigate reducing LLM complexity with special type of quantization, power of\ntwo (PoT), for linear layers weights and transformer tables. PoT not only\nprovides memory reduction but more importantly provides significant\ncomputational reduction through converting multiplication to bit shifting. We\nobtained preliminary results of PoT quantization on Nano-GPT implementation\nusing Shakespeare dataset. We then extended results to 124-M GPT-2 model. The\nPoT quantization results are shown to be very promising with cross entropy loss\ndegradation $\\approx$[1.3-0.88] with number of bits range [4-6] to represent\npower levels.",
    "pdf_url": "http://arxiv.org/pdf/2506.00315v1",
    "published": "2025-05-31T00:01:25+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  }
]